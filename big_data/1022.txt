Unsupervised Link Discovery in Multi-relational Data via Rarity Analysis Shou-de Lin Computer Science Department University of Southern California sdlin@isi.edu Hans Chalupsky Information Sciences Institute University of Southern California hans@isi.edu Abstract 000 A significant portion of knowledge discovery and data mining research focuses on finding patterns of interest in data. Once a pattern is found, it can be used to recognize satisfying instances. The new area of link discovery requires a complementary appr 
oach, since patterns of interest might not yet be known or might have too few examples to be learnable. This paper presents an unsupervised link discovery met hod aimed at discovering unusual, interestingly linked entities in multi-relational datasets. Various notions of rarity are introduced to measure the "interestingness" of sets of paths and entities. These measu rements have been implemented and applied to a real-world bibliographic dataset where they give very promising results 1 Introduction Link discovery is a relativ 
ely new form of data mining with the goal of automa tically identifying abnormal or threatening activities in large an d heterogeneous data sets  ribe it as the task of \215identifying known, complex, multi-relationa l patterns that indicate potentially threatening activities in large amounts of relational data.\216 Under this view of link discovery, once a pattern of interest is known or has been learned, a sophisticated pattern matcher can use it to detect satisfying instances in the data. The match process is usually difficult given the scale, heterogeneity distribution, incompleteness and corruption of the data. Its 
biggest limitation is, however, that it can only detect instances of known patterns and cannot cope with previously unknown or evolving patterns of interest Senator [1 describes link discove ry m o re br oa dly as the process of looking for \215evidence of known patterns and perhaps more important, for unexplainable connections that may indicate previously unknown but significant connections, representing, for example, a new group threat, or capability.\216 It is this requirement for being able to discover novel, pre viously unknown kinds of links that motivated the work presented in this paper. We will call 
this requirement the novel link discovery NLD\ problem to distinguish it from the overall or more traditional pattern-based link discovery problem \(LD In the following we describe an unsupervised link discovery approach based on rarity analysis to address the NLD problem. Unsupervised link discovery is different from traditional link discovery from an input/output perspective. A traditional LD program takes multirelational evidence data and a set of learned patterns as inputs and produces \(usually partial\nstantiations of the patterns as results. For example, given some police 
evidence database and a pattern description of contract murders, the program will try to detect and report instances of such murder events. An unsupervised link discovery program takes the same evidence data as input but does not use any pattern information. Instead of pattern instantiations, the results are any interesting connections found in the evidence data based on some model of \215interestingness\216. For example, given the same evidence database the result might be a list of interesting connections between certain criminals or gangs Traditionally, knowledge discovery and data mining research focuses on discovering and extracting previously 
unknown, valid, novel, potentially useful and understandable patterns from lower-level data [20 Su ch patterns can be represented as association rules classification rules, clusters, sequential patterns, time series, contingency tables, etc 215interesting\216 information in large, multi-relational data sets without using a pattern, on the other hand, has not received much attention at all. We argue, however, that patterns and rules are not the only things that should be mined from data sets, and that some version of unsupervised, pattern-free link discovery is necessary to handle the NLD problem 
The next section describes the problem and underlying assumptions in more detail Section 3 defines different rarity measures and how they can be applied to NLD problems. Section 4 describes experiments performed to validate the proposed rarity measures, Section 5 describes related work and in the last section we conclude with a discussion and future work Proceedings of the Third IEEE Internati onal Conference on Data Mining \(ICDM\22203 0-7695-1978-4/03 $ 17.00 \251 2003 IEEE 


2 The problem In this paper we focus on discovering \215interesting\216 paths and nodes from data that can be represented as sets of entities connected by a set of binary relations. In other words, each object in the data set is treated as a separate entity and there are different types of binary relations connecting these entities. This ki nd of data can naturally be represented by a labeled graph such as the one shown in Figure 1 where nodes stand for entities and links for binary relations. For example social network data or  Web-pages with proper classification on hyperlinks can be represented in this way. We also assume that the data employs a rich vocabulary of relations where different link types represent different semantic relationships. For example, we have different links representing that \215X wrote a letter to Y\216 or that \215X is the brother of Y\216 Therefore, different graphs with iden tical structure will usually have very different meanings depending on the types of links involved Given these assumptions, we define the following three classes of NLD problems addressed by our approach 1 Novel path discovery given an arbitrary pair of entities in a graph, find the most interesting or novel paths between them 2 Novel loop discovery given an arbitrary entity in a graph, find the most interesting or novel loops starting and ending at it 3 Significant node discovery given an arbitrary entity in a graph, find other entities that are most significantly connected to it. For example, given some person A, find the set of people that A is most significantly connected to 000 2.1 Challenges in novel link discovery The first challenge of the NLD problem is that the term 215novelty\216 or \215interestingness\216 is user dependent. Each person might view data from different angles and, thus which connections interest them varies. A good NLD program should therefore take users preferences into consideration while still doing most of the work automatically. Balancing th is trade-off is a challenging design issue The second challenge is that "interestingness" is domain specific, that is, it depends on the characteristics of the particular domain described by the data. For example, for the novel path discovery problem most people would probably think that the link "A killed B" is more interesting than "A wrote a letter to B". The justification for this is that, empirically, the event killing" happens less frequently than the event "writing a letter". This, however, is only true if the mined data set describes the behavior of the general population. If instead we were looking at a police murder database containing primarily murder events, the reverse would be the case. This is because in th is data set everybody is more or less involved in some "killing" event while writing a letter" is considerably more rare or unusual. In other words, when investigating this data set, users will expect to find data related to \215killing\216 but not necessarily to "writing a letter". Informati on-theoretically, we can say that \215killing\216 conveys less in formation in this context Therefore, the ev idence "writing a letter" might surprise a user and trigger him or her to consult additional sources for further information. This explains why it is not sufficient to tackle the NLD prob lem simply by analyzing individual semantics of the relations, but that it is very important to consider the domain and context the data is in A typical supervised learni ng approach for this problem would be to learn a weight of interestingness for each relation or series of relations in a data set and then apply a shortest path algorithm accumulating these weights to look for solutions. This, ho wever, is not practical due to the difficulty of generating unbiased training data. Take the novel path discovery prob lem for example. To obtain unbiased training data we have to rank the novelty of training paths manually with consistency. In other words we have to develop a \215standard operating procedure\216 about how to quantify interestingness of paths in a specific domain. The third challenge arises from this 215chicken and egg\216 dilemma: if we could develop a standard evaluation criterion to judge the interestingness of paths or nodes, then we could apply it directly as our novel link finder and would no t have to learn it. But since we do not have such a criteri on, we also cannot generate labeled training examples to learn it. This limits the applicability of a supervised learning approach to solve the NLD problem and shows that we are really dealing with a discovery and not a learning problem There is a significant body of work in data mining that deals with measuring th e interestingness of discovered association or classification rule s [4 howe ver, these  interestingness measures are not appropriate for the NLD problem. The reasons are twofold. First, most of these methods assume the data is in the form of a feature-vector a single relational table\while for the NLD problem we have to be able to handle multi-relational data with potentially large vocabularies of relations. The second and more serious problem is that one has to first learn a pattern or rule before its interestin gness can be measured This, however, is only pos sible if there are enough supporting cases in the data to warrant the discovery of a particular rule. If a pattern of interest occurs only once, no rule or pattern would be available to be evaluated with one of these measures. These measures are therefore not directly applicable for novel link discovery 000 3 Novel link discovery via rarity analysis In this section we propose a set of rarity measures to capture the notion of \215interestingness\216. These measures Proceedings of the Third IEEE Internati onal Conference on Data Mining \(ICDM\22203 0-7695-1978-4/03 $ 17.00 \251 2003 IEEE 


form the foundation on which all our novel path, novel loop and significant node disc overy algorithms are based 000 3.1 Novel path discovery Besides the challenges described in the previous section, another problem for novel path discovery is that the interestingness of a path is non-linearly related to the interestingness of its indivi dual links. That is, each individual link of a path might not be interesting at all but it is the combination of them that represents something special. This non-linearity characteristic limits the effectiveness of a shortest-path like algorithm that might simply accumulate statically assigned link interestingness to compute path interestingness To deal with novel path discovery problems, we observe that to some extent rarity carries the information of interestingness That is, an event that occurs infrequently compared to othe r events has the potential to be interesting and, thus, wort h being reported. Using asure for interestingn ess fulfills the need of capturing domain specificity: the same event can be rare in one domain but not in the other. For example, the event 215A cites B\220s paper\216 could be interesting in a criminal database because it occurs rarely, despite the fact that people might think it to be uninteresting, since in general this citation behavior is no t rare. Rarity is also flexible enough to handle different points of view. For example 215A cites B\220s paper\216 can be rare from A\220s point of view but not from B\220s point of view due to the fact that A rarely cites others but B is commonly cited by many other people To apply these ideas to the novel path discovery problem, we have to define rarity measurements for paths in the network. Note that in a multi-relational network as shown in Figure 1, every path occurs exactly once, thus all of them are equally rare. We therefore need a more relaxed definition to measure pat h rarity. We do this by defining the rarity of a path as the reciprocal of the number of similar paths to it. We accommodate view dependency by defining four different measures based on different views of similarity An n step path can in general be defined as a combination of n 1 entities \(or nodes e i and n relations or links i between them 01 1 012  n rr r n eee e 212 001\001 002\001\001 002\001\001\002 Note that in the novel path discovery problem we do not consider paths that contain loops \(in other words all n entities in a path must be distinct We define the type of a path as the ordered sequences of relations [r 0 203.r n-1  path For e x a m ple, the path 215A writes a paper that cites a paper published at time t1\216 and the path \215B writes a paper that cites a paper published at time t2\216 are of the same type [writes, cites publishe   Figure 1: Example bibliography dataset containing 16 nodes and 21 links The first path rarity measurement considers two paths as similar if they have the same type as well as identical source and target nodes. Then the rarity of a path P can be defined as 1/N1, where N1 is the total number of paths in the dataset that are similar to P in this sense. For example in Figure 1 the path p 1 215A1 is the author of P2 and P2 cites P1\216 \(between A1 and P1\there exists only one other similar path \215A1 is the author of P3 and P3 cites P1\216. For convenience we call N1 \215spindle fan-out value\216 since acc ording to the constraints the path emanates from the source and termin ates to the target just like a spindle The second path rarity measu rement considers two paths as similar if they have the same type and emanate from the same source node. The rarity of a path P can then be defined as 1/N2, where N2 is the total number paths in the dataset that are similar to P in this sense According to this rarity measure, the path p 1 described above has rarity 1/3, since there is one more path \215A1 is the author of P2 and P2 cites P5\216 that matches the similarity criteria. We call N2 the \215source fan-out value\216 since similar paths fans ou t from the source The third measure 1/N3 is similar to the previous one but with identical target instead of source. The rarity of path p 1 in this sense is 1/3, since besides the paths that satisfy N1 rarity, there is one more path \215A4 is the author of P3 and P3 cites P1\216 that matches the criteria. N3 is called \215target fan-out value\216, since similar paths fan out from the same target The fourth path rarity measure considers two paths with the same type as being similar. This rarity measure is defined as 1/N4 where N4 equals the total number of paths of the same type in the dataset. According to this measure, the rarity of p 1 is 1/5 since there are five paths in Figure 1 of the type \215 X is the author of Y and Y cites Z 216 We call N4 the \215global fan-out value\216, since it represents how rare this type of path is in general Equipped with these measures, we can now answer novel path discovery questions fo r the graph displayed in  A1 P1 A u t hor of O1 J1 J2 K1 K2 T1 T2 A2 A3 P2 O2 P3 P4 P5 ci te s A u t h o r o f P u b l i s h e d j o u r n a l P u b l i s h e d j o u r n a l H as k e y w o r d H a s k e y w o r d Author of A u t h o r o f A u t h o r o f O r g a n i z a t i o n o f O r g a n i z a t i o n o f P u b l i s h e d t i m e P u b l i s h e d t i m e P u b l i s h e d t i m e A u t h o r o f O r g a n i z a t i o n o f P u b l i s h e d t i m e H a s k e y w o r d c it e s Published journal        c i t e s ci te s A4 A u t h o r o f Proceedings of the Third IEEE Internati onal Conference on Data Mining \(ICDM\22203 0-7695-1978-4/03 $ 17.00 \251 2003 IEEE 


Figure 1. For example: Is the path \215A1 writes P2 and P2 cites P1\216 more interesting than the path \215A1 writes P3, P3 is published in journal J1 and J1 also contains P1\216? This query will have different an swers for different points of view \(spindle, source, target, global fan out\nd which view is chosen will depend on the user\220s focus. For example, if the user is the author of P1, he/she might be interested in viewing things from P1 and using 1/N3 as the rarity measure. Therefore, he/she could discover that the first path is more interesting than the second given that not a lot of people in the dataset cite the paper, but many of them have papers pu blished in the same journal In general, 1/N2 can be used when the user cares more about the source than the target and 1/N3 is used vice versa. 1/N1 is used when the user focuses on both the source and the target. 1/N4 is used when the user is concerned more about the general rarity of the path-type or pattern\ without focusing on any individual nodes Sometimes the query itself determines the view as well For example, it is reasonable to use the target fan-out value when being asked whether \215K1 is the keyword of paper P1 and P1\220s author belongs Organization O1\216 is more interesting than \215A1 belongs to O1\216, since both paths ends at the same node With these rarity measures, we have a systematic way to answer a query such as \215what is the most interesting path between nodes X and Y 216 We simply enumerate all paths between X and Y and return the one with the highest rarity value. By using rarity to determine the most interesting path, we not on ly take the domain specificity and user views into consideration, but also avoid being misled by the apparent meaning of the links 000 3.2 Novel loop discovery The novel loop discovery problem aims at finding interesting loops in the dataset. It is a variation of novel scovery, since a loop can be treated as a special type of a path that has identical source and target. The rarity of a loop such as this one going from e 0 to e 0 e 0  r 0 e 1 r 1 e 2  r n-1 e n-1 000 can be measured similarly to path rarity. But since in a loop the source node is id entical to the target, the N1, N2 N3 value will be the same. Thus, there are only two different loop rarity measurements: 1/N1 measures how rare a specific loop is to th e source and 1/N4 determines how rare this type of loop is in general 000 3.3 Significant node discovery The significant node discovery problem aims at finding the entities most significantly conn ected to a given node Our intuition is that whethe r two nodes are significantly connected or not depends not only on the quantity but also on the quality of paths that connect them. In other words two nodes are significantly con nected with each other if there are many interesting or rare paths between them. We therefore claim that the significance between two nodes can be measured by aggregating the rarity of paths between them. Equation 1 shows how we compute the significance of connection between two nodes A and B by accumulating the path rarity of all paths connecting them paths between \(A,B _ _ i i P node gnificance A B path rarity P 003  000\246 Equation 1: Computing the connection significance value between two nodes A and B Again, which path rarity me asure needs to be applied in Equation 1 depends on different points of view. Equation 2 shows how we determine the node that is the most significantly connected with node A. Note that in this case the source fan-out valu e N2 is used for path rarity since we have to adopt A\220s point of view to judge the rarity paths paths between   between   1 argmax _   argmax  2  i i i XX PP i AX AX path rarity P NP 003\003  000\246\000\246 Equation 2: Determining the node that is most significantly connected to a given node A For a specific type of path, the N1 value represents the total number of times it occurs between source and target The N2 value stands for the total number of times the path occurs between the source and somebody else \(this is the source fan-out value\ Since 1/N2 stands for how rare a path is from the source\220s po int of view and N1 stands for how many times the path occurs between source and target, it is easy to show that the node significance value defined in Equation 1 is equivalent to the accumulation of N1/N2 for all different types of paths. Therefore, we call the N1/N2 value of a particular path type its contribution to the overall significance value According to our definition, finding an entity that is significantly connected with th e source entity A is not equivalent to finding an entity that is tightly connected with A. For example, entities A and B might have much more connections between each other than entities A and C, but entity C can still be more significant to A given that there are more rare paths between A and C 4 Experiments Below we describe a set of experiments aimed to illustrate the validity and usefuln ess of our approach. The experiments are performed on the \215High Energy Physics Theory\216 bibliographic database \(or HEP-Th\ which is a Proceedings of the Third IEEE Internati onal Conference on Data Mining \(ICDM\22203 0-7695-1978-4/03 $ 17.00 \251 2003 IEEE 


natural dataset that was used as the experimental dataset for the KDD Cup 2003 1  The HEP-Th dataset contains a total of 29016 papers with 1.7Gbytes of associated data. Each paper in the dataset is described by a un ique ID, its authors, their email addresses, paper title, the journal it appeared in publication date, abstract and a set of other papers cited by it. The source text of each paper is also available which we ignore To model the data we used five different types of nodes and ten different types of links. Nodes represent paper IDs 29016\thor names \(12755\journal names \(267 organization names \(753\ and publication times encoded as year/season pairs \(60\bers in parentheses indicate the number of different entities for each type in the dataset. Organizations are not given directly but inferred from author\220s e-mail addre sses. Different spellings of author names were not consolidated and resulted in multiple nodes We defined the following types of links to connect nodes author_of  a  p connects author a to his/her paper p  date_published  p  d onnects paper p to its publication date d  affiliation  a  o connects person p to an organization o he/she belongs to published_in  p  j paper p to journal j it is in cites  p  r onnects paper p to a paper r it cites All of these links are viewed to be directional with an implicit inverse link, thus there are a total of 5*2 link types In sum there are 42871 different nodes and 461932 links in the graph representing the data. We then applied our rarity measures to identify interesting paths, loops and significant nodes in this graph 4.1 Significant node discovery In our first experiment we attempted to evaluate our significant node discovery me thod. That is, given some source node S we wanted to find other nodes of various types that were significan tly connected to S Since the nodes represent real-world entities such as people, we can then manually \215verify\216 the computed results by investigating whether they reflected real-world significant connections visibl e on the World-Wide Web For the experiment we picked C.N. Pope as the source node S since in this dataset he is the one with the highest number of publications \(130 in total\h provides us with a rich number of connections through this node Table 1 lists the top three interesting nodes connected to C.N. Pope for various different node types with their significance scores relative to Pope  1 http://www.cs.cornell.edu/projects/kddcup/datasets.html Table 1: Nodes significantly connected to C.N. Pope The results show that among the 12755 people in this dataset, the one that is the mo st significantly connected to Pope is H. Lu, while M. Cvetic is the second and K.S Stelle is the third. To get some further insight why these people were picked as the most significant ones, we can look at what path types cont ributed the most to the overall significance value. The most significant path for person entities connected to C.N. Pope is that of co-authorship This type of path emanates from Pope a total of 332 times and ends up at H. Lu 117 times, i.e., Lu contributes 35 of them while the runners up Cvetic and Stelle contribute 42 times \(12.6%\21 times \(6.3%\respectively. The second-most significant pat h represents a chain of coauthorship \(i.e., Person1 writes with Person2 and Person2 writes with Person3 on different papers\This path is not really rare from Pope\220s point of view \(it occurs 34473 times\etic was involved in it 5376 times thus, for her this type of relatio n still contributes 15.6% to the overall score. It shows that a significant path is not necessarily a rare path; it could be a non-rare one but occurs frequently for a specific target. The third-most significant path represents a citation relationship. Pope cites Lu\220s papers much more often than those of others Looking for organizations that are interestingly connected with Mr. Pope, we found that U. Texas A&M is the most important surpassing the second U. Michigan and third U Pennsylvania significantly Next we tried to verify whether the discovered relationships actually repre sent important real-world relationships visible th rough other means. After investigating through the World-Wide Web, we found that Dr. Pope is a professor at U. Texas A&M and he was Dr. Lu\220s thesis advisor \(1988-1994\ and that Dr. Lu is currently a post-doc at U. Michigan. Dr. Cvetic is a professor at U. Pennsylvania, has similar research interests to Pope and works clos ely with him. Dr. Stelle is a professor of Imperial College London who has ties with Pope not only academically but also personally. For example, Dr. Pope\220s homepage shows a picture showing him, Dr. Stelle, and others traveling together in Afghanistan Node Type Top-Three Scoring Nodes sum of path rarity  Person H. Lu 4.1 M. Cvetic 2.60 K.S. Stelle 0.98 Organization UTexas 3.42 UMich 1.80 UPenn 1.18 Journal Nucl.Phys 1.33 Phys.Lett 0.30 Phys.Rev 0.27 Time Spring 2000 0.40 Summer 2002 0.37 Winter1995 0.37 Proceedings of the Third IEEE Internati onal Conference on Data Mining \(ICDM\22203 0-7695-1978-4/03 $ 17.00 \251 2003 IEEE 


While this \215verification\216 is anecdotal, it does indicate that our unsupervised method, which did not know any semantics of the entities and links in this domain, is capable of returning signi ficant relationships that are relevant in the real world The rest of Table 1 describes journals and time periods significantly connected to Pope. The results show that the journal Nucl.Phys. has the highest score followed by Phys.Lett. and Phys.Rev. We checked the three types of paths that contribute the most to each of these rarity values. The most important relationship discovered and taken into account by ou r program is frequency of publication, which intuitiv ely makes sense. Pope published a total of 110 journal papers and 52 of them are in Nucl.Phys. He did not publish that many papers in Phys.Lett., but a significant portion of his colleagues\220 papers are published there. For his connection with Phys.Rev. the program discovered that the papers cited by Mr. Pope\220s papers are also frequently cited by papers published in Phys.Rev. As to the time periods, Spring 2000 followed by Summer 2002 and Winter 1995 connect significantly to Mr. Pope, because various types of paths such as, for example, the publica tion time for his papers and the publication time for his colleagues\220 papers contribute relatively highly fro m these nodes to Pope 4.2 Novel path discovery We also experimented with novel path discovery questions such as, for example, which path is the most interesting \(or rarest\two people. To determine rare paths between two known nodes, we applied 1/N1 as our rarity measure where N1 is the spindle fan-out described in Section 3.1. Looking at all paths between Pope and Lu we find the path \215Pope belongs to organization O that has another member P who writes a paper together with Lu\216 to be the rarest according to this measure. This indicates that not many of Pope\220s colleagues at his university write pa pers with Lu, which is consistent with Lu\220s role as Pope 220s student. However, this type of path is not the rarest between Pope and Cvetic instead \215Pope co-authors a paper with Cvetic\216 is rarer since Cvetic seems to write more with Pope\220s colleagues than with him. The examples show that our novel path discovery method can take poi nt-of-view into account since the computed interestin gness of paths changes when the view shifts \(e.g. from Lu to Cvetic in this case In this domain rarity of indi vidual paths does not convey such strong semantic relati onships as node significance and is harder to evaluate. In this sense the relationship between path rarity and node significance resembles the relationship between a probability density function and its corresponding probab ility distribution function, since the integrated probability usually carries more real-world meaning than the density function itself 4.3 Novel loop discovery For experiments on novel l oop discovery, we calculated loop rarity via 1/N4 004 where N4 004 is a variation of global fan-out \(see Section 3.1\th e additional requirement that source and target have to be the same node. Said differently, for each possible path type leading from a node to itself we count how often that path occurs in the dataset. The rarest, least frequent loops are listed in the top portion of Table 2, the most common loops are listed at the bottom Table 2: The rarest and the most common loops The rarest loops are papers citing themselves directly which only occurs 28 time s in the whole dataset. We do not have a real world explan ation for this and can only attribute it to errors in the dataset. The second third and fourth loops are also citation loops of different length The explanation behind this finding is that for a paper to cite another, the cited pape r needs to be published earlier In this sense a citation loop such as \215P1 cites P2 cites P3 cites P1\216 is really a temporal contradiction and should not occur at all. One explanation for such \215contradictions\216 is that sometimes an author \(or close colleague\ight cite one of his/her own submitted but not yet published papers P2 \(which has already cited P1\ in a paper P1. The other explanation is that one journal might have a very long revising period and during th at period other people can access the previous version. For both explanations we have found supporting instances from the dataset. The fifth path shows a similar concept where it is rare for a paper to cite another paper that was published during the same time period. This type of loop could also be an indicator for authors that wo rk closely with each other Finally, the last path shows that people seldom publish multiple papers at the same time Top 6 loops with highest rarity value PaperX cites PaperX PaperX cites Paper1 000\306 Paper1 cites PaperX PaperX cites Paper1 000\306 Paper1 cites Paper2 000\306 Paper2 cites PaperX PaperX cites Paper1 000\306 Paper1 cites Paper2 000\306 Paper2 cites Paper3 000\306 Paper3 cites PaperX PaperX cites \(or cited by\ Paper1 000\306 Paper 1 published at Time1 000\306 At Time1, PaperX also published PaperX is written by Person1 000\306 Person 1 has another Paper1 000\306 as PaperX Bottom 3 loops with lowest rarity value PaperX cites PaperY 000\306 PaperY is being cited by PaperZ 000\306 PaperZ is being cited by PaperX PaperX cites PaperY 000\306 PaperY published in the same journal as PaperZ 000\306 PaperZ cites PaperX PaperX is cited by Paper Y 000\306 Paper Y published in same season as PaperZ 000\306 PaperZ cites Paper X Proceedings of the Third IEEE Internati onal Conference on Data Mining \(ICDM\22203 0-7695-1978-4/03 $ 17.00 \251 2003 IEEE 


The bottom portion of th e table shows the most frequently occurring loops as a contrast to the rare loops described above. For example, the most frequent loops are two papers published at the same time period that both cite X. They are loops that intuitively should occur very frequently. Note that \215A cites B cites C\216 is a very common path, thus, we did not expect it to be interesting as a loop and were surprised by the results The experiments demonstrate that our approach is capable of uncovering in teresting instances masked inside thousands of uninteresting facts. Furthermore, the instances found by novel loop discovery lead us to the discovery of interesting hypotheses or patterns, e.g., that citation loops are an indicator for authors who work closely with each other or for journals that have a long revision cycle 4.4 Discussion The experiments show that our program can find interesting connections in a network without having to learn the patterns of interestingn ess. For the bibliography dataset, which does not have too many different types of be able to write a rule-based system or supervised learning program to answer similar queries as we did. However, it is time consuming to do this, since different rules or training data are required for different queries \(e.g. the rules to id entify the people that are interestingly connect to a keyword are different from the ones required to determine the organizations that are interestingly connected to a person\he advantage of our method is that it does everything in an unsupervised manner and eliminates the necessity to regenerate new rules or new training data for different queries or even when the whole domain is changed. It also eliminates the risk of being biased by th e apparent meaning of link types Another advantage of our approach is that it can focus the user\220s attention on events that are otherwise hard to be noticed. The inspirations triggered by such evidences can sometimes lead to the discovery of pattern/knowledge For example, without being made aware of those rare loops, we might not ever look into the issue of citation loops at all, since there are thousands of different loops in the dataset that mask this phenomenon. They also prompt us to discover other related knowledge when we try to explain them, for example, that citation loops can be an indicator of authors adding additional citations during a revision of a journal submission 000 5 Related work To our knowledge there is no other work that addresses the NLD problem in multi-relational data via an unsupervised approach. One focus of current link discovery research is on learning patterns from complex multi-relational data. For example, inductive logic programming has been applied to learn relational patterns  p h-bas ed m e thods s u ch as 6 have  been used to learn subgraph ca tegories and isomorphisms These approaches either require training examples or learn things at the structure/schema level, while for the NLD problem it is necessary to perform discovery at the instance level by using unsupervised methods Kovalerchuk and V ityaev\220s hybrid evidence correlation technique [1 id en tifies co mm o n p a ttern s v i a standard data mining techniques and then hypothesizes interesting or unusual patterns by negating some of the statistically significant patterns fou nd. It is conceptually similar to our approach but requires the occurrence of very common patterns in the data Other analysis algorithms such as PageRank compute the importance of links through the connections between nodes in an unsupervised manner [12  In t h at  framework, however, all relations are treated to be identical \(that is, \215A kills B\216 is not different from \215A writes to B\215\therefore, this approach is not suitable for the multi-relational NLD problem The area of outlier detection in data mining and statistics aims at detecting points that are considerably dissimilar or inconsistent with th e remainder of the data 2, 3, 7, 14 c e ptually related to our use of rarity analysis to solve th e NLD problem. Current research on outlier detection, however, analyzes primarily numerical entity-attribute data instead of multi-relational social network data. In threat detection each individual event is usually not an ou tlier; nevertheless, combinations of seemingly harmless events can suddenly become threatening when they occur in a particular context Outlier computations that do not take such combinations into account will fail to detect such threats. Our path rarity analysis is designed to search for these kinds of unusual connections in a multi-relational dataset The area of social network analysis has investigated multi-relational social behavior using graph and matrixtheoretic representations [16  Th e con cep t  o f 215cen trality\216  is applied widely to determin e important nodes in a network from a global point of view, while our significant node discovery tries to tackle the problem locally by answering \215which node is im portant to a chosen node\216 Moreover, centrality analysis uses only the connectivity the number of paths\to judge the significance while our algorithm considers no t only the quan tity but also the quality \(rarity\of the paths Valdes-Perez h a r acteriz es disc overy i n science as the generation of novel, in teresting, plausible and intelligible knowledge about the objects of study. In this sense the novel link discovery problem is similar to literature-based discovery introduced by Swanson [18   since t h e y bot h inte nd to find i n teres ting fa cts and connections in large amounts of data. Since 1986 Swanson has triggered interesting discoveries in Proceedings of the Third IEEE Internati onal Conference on Data Mining \(ICDM\22203 0-7695-1978-4/03 $ 17.00 \251 2003 IEEE 


biomedicine strictly by looking for mediators that connect otherwise unconnected corpora of scientific literature Literature-based discovering systems are primarily aimed at finding one-step connections between independent corpora instead of ranking the interestingness of the multi-step paths in a multi-relational network, and are therefore different from our approach 6 Conclusion We presented an unsupervised link discovery method aimed at detecting interesting paths or interestingly connected nodes in multi-relational datasets Interestingness is modeled via different measures of rarity that are based on computing how often similar paths occur in the data. The method does not rely on any preexisting or learnable pattern information and can detect novel, interesting connections that do not need to be conceived prior to the analysis. Our approach is a generalpurpose method and can be applied to arbitrary multirelational datasets. Potential applications are in law enforcement, threat detection, data  and scientific discovery. The experiment shows that our approach can capture interesting connections that are representative of meaningful real-world relationships Future work will include more extensive evaluation with different data sets, handling of temporal information negation and better handling of noise and corruption 7 Acknowledgements This research was supported by the Defense Advance Research Projects Agency under Air Force Research Laboratory contract F30602-01-2-0583 8 References  B. Kovalerchuk E. Vity aev  Correlation of complex evidences and link discovery  The Fifth International Conference on Forensic Statistics 2002. Venice, Italy  C. Aggarwal, P.Yu Outlier detection for high dimensional data  ACM SIGMOD Conference 2001  E.M. Knorr, R  T. Ng Algorithms for Mining DistanceBased Outliers in Large Datasets  Proc. of VLDB Conf 1998  A. A. Freitas  On rule interestingness measures  Knowledge-Based Systems 1999 5] R.Kimball Dealing with Dirty Data  DBMS Magazine  1996  L. B  Hold er, D J Cook  IEEE Intelligent Systems 15, 2000  M.M. Breun ig H.P. Krieg el R T. Ng and J. Sa nder Optics-of: Identifying local outliers  Proc. of PKDD '99   P.N. Tan, V. Kumar Interestingness measures for association patterns: A perspective  KDD 2000  R Hild erm an , H Ham ilton  Knowledge discovery and interestingness measures: A survey 1999, Technical Report University of Regina  R. J. Mooney P Melville L. P Rupert Tang J Shavlik I.d. Dutra, D. Page, V. S. Costa Relational Data Mining with Inductive Logic Programming for Link Discovery  Proceedings of the National Science Foundation Workshop on Next Generation Data Mining 2002  R.J. Mooney  P.Melville, L P. R upert Tang J. Shavlik I  d Dutra, D. Page, V. S. Costa Relational Data Mining with Inductive Logic Programming for Link Discovery  Proceedings of the National Science Foundation Workshop on Next Generation Data Mining 2002  S Brin, L Page The anatomy of a large-scale hypertextual Web search engine  Proceedings of the 7th International World Wide Web Conference 1998  S. Candan W.S. Li Reasoning for Web Document Associations and Its Applications in Site Map Construction International Journal of Data and Knowledge Engineering 2002: p.121-150  S. Ramaswam y   R. Rastog i, K. S h im Efficient algorithms for mining outliers from large data sets  Proceedings of the ACM SIGMOD Conference 2000  S. Shekhar C  T. Lu, P Zhang  Detecting Graph-based Spatial Outliers: Algorithms and Applications  The Seventh ACM SIGKDD 2001  S. Wasserman K. Faust Social Network Analysis: Methods Applications 1994: Cambridge, UK: Cambridge University Press  Sen ator  Evidence Extraction and Link Discovery Program 2002, DARPATech 2002 http://www.darpa.mil/DARPATech2002/presentations/iao_ pdf/speeches/SENATOR.pdf  D. R. Swanson Fish Oil, Raynaud's syndrome and undiscovered public knowledge Perspectives in Biology and Medicine, 1986  D. R. Swanson Somatomedin C and arginine: Implicit connections between mutually isolated literatures Perspectives in Biology and Medicine, 1990  U Fayy ad G. Piatetsky Shapiro P Smy th The KDD Process for Extracting Useful Knowledge from Volumes of Data Communications of the ACM, 1996. p.27-34  R. E  Va ldes-Per ez Principles of human-computer collaboration for knowledge discovery in science Artificial Intelligence, 1999 Proceedings of the Third IEEE Internati onal Conference on Data Mining \(ICDM\22203 0-7695-1978-4/03 $ 17.00 \251 2003 IEEE 


21  and denote wjk as the set of weights for Yj where    k j k jw 1 1.  A classifier H is defined as YD ? such that it assigns a weight of the correct class label to an instance as  iWdH where deD, and k j i WW ? . For a set of single-class instances I = &lt; \(x1 y1 x2, y2  xn, yn Proceedings of the Fourth IEEE International Conference on Data Mining \(ICDM  04 0-7695-2142-8/04 $ 20.00 IEEE Table 4. Classification accuracy of PART RIPPER, CBA and MMAC Dataset PART RIPPER CBA MMAC Tic-Tac 92.58  97.54  98.60  99.29 Contactlenses 83.33  75.00  66.67  79.69 Led7 73.56 69.34  72.39  73.20 Breastcancer 71.32  70.97  68.18  72.10 Weather 57.14  64.28  85.00  71.66 Heart-c 81.18  79.53  78.54  81.51 Heart-s 78.57  78.23  71.20  82.45 Lymph 76.35  77.70  74.43  82.20 Mushroom 99.81 99.90  98.92  99.78 primarytumor 39.52  36.28  36.49  43.92 Vote 87.81  87.35  87.39  89.21 CRX 84.92  84.92  86.75  86.47 Sick 93.90  93.84  93.88  93.78 Balancescale 77.28  71.68  74.58  86.10 Autos 61.64  56.09  35.79  67.47 Breast-w 93.84  95.42  94.68  97.26 Hypothyroid 92.28 92.28  92.29  92.23 zoo 91.08  85.14  83.18  96.15 kr-vs-kp 71.93 70.24  42.95  68.75 is  m k ii i ydHw m 1  1 ?  , where          yxif yxif yx 0 1  For example, if an item \(A ,a labels  c1    c2  and  c3  7, 5  and 3 times 


labels  c1    c2  and  c3  7, 5  and 3 times respectively, in the training data. Each class label will be assigned a weight, i.e. 7/15, 5/15, and 3/15, respectively for labels  c1    c2  and  c3  This technique assigns the predicted class label weight to the case if the predicted class label matches the case class label. For instance if label  c2  of item \(A, a test data that has  c2  as its class, then the case will be considered a hit, and 5/15 will be assigned to the case 5. Experimental Results We investigated our approach against 19 different datasets from [20] as well as a different datasets for forecasting the behaviour of an optimisation heuristic within a hyperheuristic framework [5, 16]. Stratified tenfold cross-validation was used to derive the classifiers and error rates in the experiments. Cross-validation is a standard evaluation measure for calculating error rate on data in machine learning. Three popular classification techniques a decision tree rule \(PART CBA have been compared to MMAC in terms of classification accuracy, in order to evaluate the predictive power of the proposed method The choice of such learning methods is based on the different strategies they use to generate the rules. Since the chosen techniques are only suitable for traditional classification problems where there is only one class assigned to each training instance, we therefore used classification accuracy derived by only the top-label evaluation measure for fair comparison All experiments were conducted on a Pentium IV 1.6 GH PC.  The experiments of PART and RIPPER were conducted using the Weka software system [20]. Weka stands for Waikato Environment for Knowledge Analysis. It is an open java source code for the machine teaching community that includes implementations of different methods for several different data mining tasks such as classification, clustering, association rule and regression. CBA experiments were conducted using a VC++ implementation version provided by [19]. Finally MMAC was implemented using Java We have evaluated 19 selected datasets from Weka data collection [20], in which, a few of them \(6 reduced by ignoring their integer and/or real attributes Several tests using ten-fold cross-validation have been performed to ensure that the removal of any real/integer attributes from some of the datasets does not significantly affect the classification accuracy. To do so we only considered datasets where the error rate was not more than 6% worse than the error rate obtained on the same dataset before the removal of any real/integer attributes.  Thus, the ignored attributes do not impact on the error rate too significantly Many studies have shown that the support threshold plays a major role in the overall classification accuracy of the set of rules produced by existing associative classification techniques [9, 12]. Moreover, the support value has a larger impact on the number of rules produced in the classifier and the processing time and storage needed during the algorithm rules discovery and generation. From our experiments, we noticed that the support rates that ranged between 2% to 5% usually achieve the best balance between accuracy rates and the size of the resulted classifiers. Moreover, the classifiers derived when the support was set to 2% and 3 achieved high accuracy, and most often better than that of decision trees rule \(PART the MinSupp was set to 3% in the experiments. The confidence threshold, on the other hand, is less complex and does not have a large effect on the behaviour of any associative classification method as support value, and thus it has been set to 30 


Table 4 represents the classification rate of the classifiers generated by PART, RIPPER, CBA and MMAC against 19 benchmark problems from Weka data Proceedings of the Fourth IEEE International Conference on Data Mining \(ICDM  04 0-7695-2142-8/04 $ 20.00 IEEE 3 5.00 2 5.00 15.00 5.00 5.00 15.00 2 5.00 3 5.00 4 5.00 55.00 6 5.00 75.00 8 5.00 9 5.00 1 2 3 4 5 6 7 8 9 Nine  Scheduling Runs D iff er en ce  in  A cc u ra cy  CB A To p-label A ll-label A ny-label Figure 3a. Difference of accuracy between MMAC evaluation measures and CBA algorithm 35.00 25.00 15.00 5.00 5.00 15.00 25.00 35.00 45.00 55.00 65.00 75.00 85.00 95.00 1 2 3 4 5 6 7 8 9 Nine  Scheduling Runs D iff er en ce in  A cc u ra cy  P A RT To p-label A ll-label A ny-label Figure 3b. Difference of accuracy between MMAC   evaluation measures and PART 


MMAC   evaluation measures and PART algorithm 0 2 4 6 8 10 12 14 16 18 20 22 24 26 Run1 Run2 Run3 Run4 Run5 Run6 Run7 Run8 Run9 Ten Runs  Scheduling Data N um be r o f R ul es To p Label P A RT CB A Figure 4. Classifier sizes of MMAC \(toplabel the scheduling   data collection. The accuracy of MMAC has been derived using the top-label evaluation measure. Our algorithm outperforms the rule learning methods in terms of accuracy rate, and the won-loss-tied records of MMAC against PART, RIPPER and CBA 13-6-0, 15-4-0 and 154-0, respectively The evaluation measures of MMAC have been compared on 9 solution runs produced by the Peckish hyperheuristic [5] with regard to accuracy, and number of rules produced. Figures 3a and 3b represent the relative prediction accuracy that indicates the difference of the classification accuracy of MMAC evaluation measures with respect to those derived by CBA and PART, respectively. In other words, how much better or worse MMAC measures perform with respect to CBA and PART learning methods. The relative prediction accuracy numbers shown in Figures 3a and 3b are conducted using the formula PART PARTMMAC Accuracy AccuracyAccuracy  and CBA CBAMMAC Accuracy AccuracyAccuracy  respectively. After analysing the charts, we found out that there is consistency between the top-label and label-weight measures, since both of them consider only one class in the prediction. The top-label takes into account the topranked class, and the label-weight considers only the weight for the predicted class that matches the test case Thus, both of these evaluation measures are applicable to traditional single-class classification problems. On the other hand, the any-label measure considers any class in the set of the predicted classes as a hit whenever it matches the predicted class regardless of its weight or rank. Is should be noted that, the relative accuracy of MMAC evaluation methods against dataset number 8 in Figure 3a and 3b, is negative since CBA and PART 


Figure 3a and 3b, is negative since CBA and PART achieved a higher classification rate against this particular dataset A comparison of the knowledge representation produced by our method, PART and CBA has been conducted to evaluate the effectiveness of the set of rules derived. Figure 4 represents the classifiers generated form the hyperheuristic datasets. Analysis of the rules sets indicated that MMAC derives a few more rules than PART and CBA for the majority of the datasets. In particular, the proposed method produced more rules than PART and CBA on 8 and 7 datasets, respectively. A possible reason for extracting more rules is based on the recursive learning phase that MMAC employs to discover more hidden information that most of the associative classification techniques discard, since they only extract the highest confidence rule for each frequent item that survives MinConf Proceedings of the Fourth IEEE International Conference on Data Mining \(ICDM  04 0-7695-2142-8/04 $ 20.00 IEEE 6. Conclusions A new approach for multi-class, and multi-label classification has been proposed that has many distinguishing features over traditional and associative classification methods in that it \(1 that contain rules with multiple labels, \(2 evaluation measures for evaluating accuracy rate, \(3 employs a new method of discovering the rules that require only one scan over the training data, \(4 introduces a ranking technique which prunes redundant rules, and ensures only high effective ones are used for classification, and \(5 discovery and rules generation in one phase to conserve less storage and runtime. Performance studies on 19 datasets from Weka data collection and 9 hyperheuristic scheduling runs indicated that our proposed approach is effective, consistent and has a higher classification rate than the-state-of-the-art decision tree rule \(PART and RIPPER algorithms. In further work, we anticipate extending the method to treat continuous data and creating a hyperheuristic approach to learn  on the fly   which low-level heuristic method is the most effective References 1] R. Agrawal, T. Amielinski and A. Swami. Mining association rule between sets of items in large databases In Proceeding of the 1993 ACM SIGMOD International Conference on Management of Data, Washington, DC May 26-28 1993, pp. 207-216 2] R. Agrawal and R. Srikant. Fast algorithms for mining association rule. In Proceeding of the 20th International Conference on Very Large Data Bases, 1994, pp. 487   499 3] M. Boutell, X. Shen, J. Luo and C. Brown. Multi-label semantic scene classification. Technical report 813 Department of Computer Science, University of Rochester Rochester , NY 14627 &amp; Electronic Imaging Products R &amp D, Eastern Kodak Company, September 2003 4] A. Clare and R.D. King. Knowledge discovery in multilabel phenotype data. In L. De Raedt and A. Siebes editors, PKDD01, volume 2168 of Lecture Notes in Artificial Intelligence, Springer - Verlag, 2001,  pp. 42-53 5] P. Cowling and K. Chakhlevitch. Hyperheuristics for Managing a Large Collection of Low Level Heuristics to Schedule Personnel. In Proceeding of 2003 IEEE conference on Evolutionary Computation, Canberra Australia, 8-12 Dec 2003 6] R. Duda, P. Hart, and D. Strok. Pattern classification Wiley, 2001 7] E. Frank and I. Witten. Generating accurate rule sets without global optimisation. In Shavlik, J., ed., Machine Learning: In Proceedings of the Fifteenth International 


Learning: In Proceedings of the Fifteenth International Conference, Madison, Wisconsin. Morgan Kaufmann Publishers, San Francisco, CA, pp. 144-151 8] J. Furnkranz. Separate-and-conquer rule learning Technical Report TR-96-25, Austrian Research Institute for Artificial Intelligence, Vienna, 1996 9] W. Li, J. Han and J. Pei. CMAR: Accurate and efficient classification based on multiple class association rule. In ICDM  01, San Jose, CA, Nov. 2001, pp. 369-376 10 ] T. Joachims. Text categorisation with Support Vector Machines: Learning with many relevant features. In Proceeding Tenth European Conference on Machine Learning, 1998,  pp. 137-142 11] T. S. Lim, W. Y. Loh and Y. S. Shih. A comparison of prediction accuracy, complexity and training time of thirtythree old and new classification algorithms. Machine Learning, 39, 2000 12] B. Liu, W. Hsu and Y. Ma. Integrating Classification and association rule mining. In KDD  98,  New York, NY, Aug 1998 13] J.R. Quinlan. C4.5: Programs for Machine Learning. San Mateo, CA: Morgan Kaufmann, San Francisco, 1993 14] J.R. Quinlan. Generating production rules from decision trees. In Proceeding of the 10th International Joint Conferences on Artificial Intelligence,  Morgan Kaufmann San Francisco, 1987, pp. 304-307 15] R. Schapire and Y. Singer, "BoosTexter: A boosting-based system for text categorization," Machine Learning, vol. 39 no. 2/3, 2000, pp. 135-168 16] F. Thabtah, P. Cowling and Y. Peng. Comparison of Classification techniques for a personnel scheduling problem. In Proceeding of the 2004 International Business Information Management Conference, Amman, July 2004 17]Y. Yang. An evaluation of statistical approaches to text categorisation. Technical Report CMU-CS-97-127 Carnegie Mellon University, April 1997 18] X. Yin and J. Han. CPAR: Classification based on predictive association rule. In  SDM  2003, San Francisco CA, May 2003 19]CBA:http://www.comp.nus.edu.sg/~dm2/ p_download.html 20] Weka: Data Mining Software in Java http://www.cs.waikato.ac.nz/ml/weka 21] M. J. Zaki, S. Parthasarathy, M. Ogihara, and W. Li. New algorithms for fast discovery of association rules. In Proceedings of the 3rd KDD Conference, Aug. 1997 pp.283-286 Proceedings of the Fourth IEEE International Conference on Data Mining \(ICDM  04 0-7695-2142-8/04 $ 20.00 IEEE pre></body></html 


Low Medium 1.152e3 1.153e3 5.509e3 3.741e3 20 20.0 393 0.647 0.9900 0.0092 1.0000 0.0093 R=1000 1e-4 0.2 High 1.153e3 1.154e3 3.180e3 2.698e3 45 45.0 597 0.214 0.9900 0.0071 1.0000 0.0162 2e-4 2e-4 Low 0.4017 0.4024 109.291 71.994 4 4.0 39.7 0.996 0.9960 0.0075 0.9995 0.0012 2e-3 1.0 1e-3 Medium Medium 0.4128 0.4129 17.488 19.216 6 6.0 29.6 0.992 0.9938 0.0018 0.9987 0.0034 R=0.1 0.01 4e-3 High 0.4612 0.4722 4.1029 5.410e3 12 12.0 28.0 0.992 0.9902 0.0045 1.0000 0.0132 0.04 1e-8 Low 0.0250 0.0272 253.917 155.263 3 3.0 38.0 1.002 0.9991 0.0001 0.9994 0.0008 1e-3 1e4 1e-7 High Medium 0.0338 0.0290 17.303 12.837 3 3.0 14.5 0.332 0.9900 0.0058 0.9951 0.0045 R=1e-5 1e-2 1e-6 High 0.0918 0.0557 1.6071 1.225e5 8 8.0 9.9 0.992 0.9906 0.0034 0.9994 0.0142 1e-3 TABLE II SIMULATION RESULTS FOR: TRACKING REGIME PD=1, Q=100, ?=0.1 PDET PFA PDET PFA NTA NCD ST?sirf ST?sim SL?sirf SL?sim n n  T n  L ?np Theory Theory Exper. Exper 2e-4 Low 0.0408 0.0407 2.9255 2.0060 5 5.0 30.3 0.996 0.9933 0.0016 0.9998 0.0020 0.02 1.0 1e-3 Medium Medium 0.0446 0.0446 0.5143 333.138 10 10.0 27.8 0.996 0.9900 0.0042 0.9995 0.0093 R=0.01 0.1 4e-3 High 0.0763 0.1062 0.1580 3.402e3 84 84.0 90.9 0.793 0.9900 0.0099 1.0000 0.0334 0.4 TABLE III SIMULATION RESULTS FOR: TRACKING REGIME PD=0.9, Q=1000, ?=0.1 PDET PFA PDET PFA NTA NCD ST?sirf ST?sim SL?sirf SL?sim n n  T n  L ?np Theory Theory Exper. Exper 0.05 Low 1.166e3 1.167e3 1.073e4 3.357e4 11 12.2 257 0.542 0.9900 0.0089 1.000 0.0073 5e-5 1e-4 0.1 Low Medium 1.167e3 1.167e3 5.509e3 1.481e4 21 23.2 309 0.858 0.9900 0.0067 1.0000 0.0052 R=1000 1e-4 0.2 High 1.168e3 1.170e3 3.180e3 6.979e3 46 50.6 475 0.798 0.9900 0.0089 1.000 0.0022 2e-4 3] T. Fortmann, Y. Bar-Shalom, Y. Scheffe, and S. B. Gelfand  Detection Thresholds for Tracking in Clutter- A Connection Between Estimation and Signal Processing  IEEE Trans Auto. Ctrl., Mar 1985 4] S. B. Gelfand, T. Fortmann, and Y. Bar-Shalom  Adaptive Threshold Detection Optimization for Tracking in Clutter  IEEE Trans. Aero. &amp; Elec. Sys., April 1996 5] Ch. M. Gadzhiev  Testing the Covariance Matrix of a Renovating Sequence Under Operating Control of the Kalman Filter  IEEE Auto. &amp; Remote Ctrl., July 1996 6] L. C. Ludeman, Random Processes: Filtering, Estimation and Detection, Wiley, 2003 7] L. Y. Pao and W. Khawsuk  Determining Track Loss Without Truth Information for Distributed Target Tracking Applications  Proc. Amer. Ctrl. Conf., June 2000 8] L. Y. Pao and R. M. Powers  A Comparison of Several Different Approaches for Target Tracking in Clutter  Proc Amer. Ctrl. Conf., June 2003 9] X. R. Li and Y. Bar-Shalom  Stability Evaluation and Track Life of the PDAF Tracking in Clutter  IEEE Trans. Auto Ctrl., May 1991 10] X. R. Li and Y. Bar-Shalom  Performance Prediction of 


10] X. R. Li and Y. Bar-Shalom  Performance Prediction of Tracking in Clutter with Nearest Neighbor Filters  SPIE Signal and Data Processing of Small Targets, July 1994 11] X. R. Li and Y. Bar-Shalom  Detection Threshold Selection for Tracking Performance Optimization  IEEE Trans. on Aero. &amp; Elect. Sys., July 1994 12] D. Salmond  Mixture Reduction Algorithms for Target Tracking in Clutter  SPIE Signal and Data Processing of Small Targets, Oct. 1990 13] L. Trailovic and L. Y. Pao  Position Error Modeling Using Gaussian Mixture Distributions with Application to Comparison of Tracking Algorithms  Proc. Amer. Ctrl. Conf., June 2003 4323 pre></body></html 


dense data sets for evaluating pattern mining algorithms These two data sets are obtained from IBM Almaden at http://www.almaden.ibm.com/cs/quest/demos.html. Recently, theMAFIA algorithm [6] was proposed to ef?ciently discover maximal frequent patterns. As shown in their paper, MAFIA can be several orders better than some alternatives, such as DepthProject, for mining maximal frequent patterns. Hence, we chose MAFIA as the base line for our performance evaluation. Finally, please note that only the size-2 patterns are generated in the ?rst BFS phase Experimental Platform We implemented the MHP algorithms using C++ and all experiments were performed Proceedings of the 16th IEEE International Conference on Tools with Artificial Intelligence \(ICTAI 2004 1082-3409/04 $20.00  2004 IEEE on a Pentium III    MHz PC machine with    megabytes main memory, running Linux Redhat 6.1 operating system 5.2. A Performance Comparison 100 1000 10000 100000 1e+06 1e+07 1e+08 1e+09 1e+10 1e+11 0.02 0.025 0.03 0.035 0.04 0.045 0.05 0.055 0.06 N um be r o f C he ck ed P at te rn s Support threshold Mafia Min_Conf=0 Min_Conf=0.1 Min_Conf=0.3 Min_Conf=0.5 Min_Conf=0.7 Min_Conf=0.9 


Figure 4. The Number of Checked Patterns on the Pumsb* Data Set 10 100 1000 10000 100000 0.02 0.025 0.03 0.035 0.04 0.045 0.05 0.055 0.06 R un T im e s ec  Support Threshold Mafia Min_Conf=0 Min_Conf=0.1 Min_Conf=0.3 Min_Conf=0.5 Min_Conf=0.7 Min_Conf=0.9 Figure 5. The RunTime Comparison on the Pumsb* Data Set Figure 4 shows the number of patterns that MHP and MAFIA have to check during the pattern mining process on the pumsb* data set. As can be seen, for MHP, the number of checked patterns is increased with the decrease of the h-con?dence threshold. However, the number of checked patterns of MHP can be signi?cantly smaller than that of MAFIA even if a low h-con?dence threshold is speci?ed To check a pattern, we need to count the support of the patterns. Counting the support of a pattern is the most timeconsuming task during the pattern mining process, since we need to retrieve all the transactions which include one of its sub-pattern, or for Ma?a, retrieve all the bit of the bitmap of this pattern [6]. Therefore, an algorithm is more ef?cient if smaller number of patterns need to be checked 100 1000 10000 100000 1e+06 1e+07 1e+08 1e+09 0.1 0.2 0.3 0.4 0.5 0.6 0.7 N 


um be r o f C he ck ed P at te rn s Support Threshold Mafia Min_Conf=0.5 Min_Conf=0.7 Min_Conf=0.9 Figure 6. The Number of Checked Patterns on the Pumsb Data Set 10 100 1000 10000 0.1 0.2 0.3 0.4 0.5 0.6 0.7 R un T im e s ec  Support Threshold Mafia Min_Conf=0.5 Min_Conf=0.7 Min_Conf=0.9 Figure 7. The RunTime Comparison on the Pumsb Data Set The runtime comparison of MHP and MAFIA on the Pumsb* data set is shown in Figure 5. In the ?gure, we can observe that the runtime of MHP can be signi?cantly reduced with the increase of h-con?dence thresholds. Also the runtime of MHP can be several orders of magnitude less than that of MAFIA even if the h-con?dence threshold is as low as 0.3. The reason is that the number of checked patterns of MHP is sign?cantly smaller than that of MAFIA Similar results are also obtained from the pumsb data set as shown in Figure 6 and Figure 7. For the pumsb data set the number of checked patterns of MHP is much smaller 


than that of MAFIA and the runtime of MHP can be significantly less than that of MAFIA 5.3. The Effect of the MHP Algorithm on Finding Maximal Hyperclique Patterns Figure 8 and Figure 9 show the number of maximal patterns identi?ed byMHP andMAFIA on Pumsb* and Pumsb data sets respectively. As can be seen, the number of maximal hyperclique patterns identi?ed by MHP can be orders of magnitude smaller than the number of maximal frequent patterns identi?ed by MAFIA. In other words, the number Proceedings of the 16th IEEE International Conference on Tools with Artificial Intelligence \(ICTAI 2004 1082-3409/04 $20.00  2004 IEEE 100 1000 10000 100000 1e+06 1e+07 1e+08 1e+09 0.02 0.025 0.03 0.035 0.04 0.045 0.05 0.055 0.06 N um be r o f C ou nt ed P at te rn s Support Threshold Mafia Min_Conf=0 Min_Conf=0.1 Min_Conf=0.3 Min_Conf=0.5 Min_Conf=0.7 Min_Conf=0.9 Figure 8. The Number of MFI/MHP Patterns in the Pumsb* Data Set 100 1000 10000 100000 1e+06 


1e+07 1e+08 0.1 0.2 0.3 0.4 0.5 0.6 0.7 N um be r o f C ou nt ed P at te rn s Support Threshold Mafia Min_Conf=0.5 Min_Conf=0.7 Min_Conf=0.9 Figure 9. The number of MFI/MHP Patterns in the Pumsb Data Set of maximal hyperclique patterns is much easier to manage than that of maximal frequent patterns. Indeed, in realworld applications, it is dif?cult to interpret several million maximal frequent patterns. However, it is possible to interpret the results of maximal hyperclique pattern mining In addition, due to the memory limitation, we cannot extract maximal frequent patterns with MAFIA on the Pumsb data set if the support threshold is less than 0.4, as shown in Figure 7. In contrast, MHP can identify maximal hyperclique patterns when the support threshold is 0.1, if we set the h-con?dence threshold to 0.5. In other words, MHP has the ability to identify patterns which can be dif?cult to identify for MAFIA. Hence, MHP can better explore the pattern space and ?nd interesting patterns at low levels of support 6. Conclusions and Future Work In this paper, we present a two-phase Maximal Hyperclique Pattern \(MHP best features of both the BFS strategy and the DFS strategy. More speci?cally, we adapted DFS pruning methods such as equivalence pruning, to an apriori-like approach In addition, we proved the correctness and completeness of the MHP algorithm. Finally, our experimental results show that the MHP algorithm can be several orders of magnitude faster than standard maximal frequent pattern mining algorithms and has the ability to identify patterns at extremely low levels of support in dense data sets There are several directions for future work. First, in 


this paper, we only generate the size-2 patterns in the BFS phase. It will be interesting to investigate the impact on the performance if the ?rst phase is stopped at a deeper level Also, the projection is a very ef?cient method for ?nding patterns, especially for parallel implementation of pattern mining algorithms [1]. We plan to adapt the projection ideas into our algorithm and design an ef?cient parallel algorithm for mining maximal hyperclique patterns References 1] R. Agarwal, C. Aggarwal, and V. Prasad. A Tree Projection Algorithm For Generation of Frequent Itemsets. pages 350 371, Feb 2001 2] R. Agrawal, T. Imielinski, and A. Swami. Mining Association Rules between Sets of Items in Large Databases. In Proc. of the ACM SIGMOD Conference on Management of Data, pages 207216,May 1993 3] R. Agrawal and R. Srikant. Fast Algorithms for Mining Association Rules. In Proc. of the 20th Intl Conference on Very LargeData Bases, 1994 4] R. Bayardo. Ef?ciently mining long patterns from databases In Proc. of the ACM SIGMOD Conference, 1998 5] R. Bayardo and R. Agrawal. Mining the Most Interesting Rules. In Proc. of the ACM SIGKDD Conference, 1999 6] D. Burdick, M. Calimlim, and J. Gehrke. Ma?a: AMaximal Frequent Itemset Algorithm for Transactional Databases. In Proc. of IEEE Conf. on Data Engineering, 2001 7] Y. Huang, H. Xiong, W. Wu, and Z. Zhang. A Hybrid Approach for Mining Maximal Hyperclique Patterns. In In Technical Report UTDCS-34-04, Department of computer science, University of Texas - Dallas, 2004 8] J.Han, J.Pei, and Y. Yin. Mining Frequent Patterns without Candidate Generation. In Proc. of the ACM SIGMOD International Conference on Management of Data, 2000 9] M.J.Zaki and C.Hsiao. ChARM: An ef?cient algorithm for closed itemset mining. In Proc. of 2nd SIAM International Conference on Data Mining, 2002 10] R.Rymon. Search through Systematic Set Enumeration. In Proc. Third Intl Conference on Principles of Knowledge Representation and Reasoning, 1992 11] H. Xiong, M. Steinbach, P.-N. Tan, and V. Kumar. HICAP: Hierarchial Clustering with Pattern Preservation. In Proc. of 2004 SIAM International Conference on Data Mining \(SDM 12] H. Xiong, P.-N. Tan, and V. Kumar. Mining Strong Af?nity Association Patterns in Data Set with Skewed Support. In Proc. of the Third IEEE International Conference on Data Mining \(ICDM Proceedings of the 16th IEEE International Conference on Tools with Artificial Intelligence \(ICTAI 2004 1082-3409/04 $20.00  2004 IEEE 





