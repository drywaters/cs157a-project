Proceedings of the Fifth International Conference on Mach ine Learning and Cybernetics, Dalian, 13-16 August 2006 1-4244-0060-0/06/$20.00 ©2006 IEEE 1076 THE CANONICAL BASIS OF IMPLICATIONAL SYSTEM HUI-FENG SHI 1 QIANG HUA 2 BO ZHANG 3 1 College of Applied Math. and Phys., North China Electric Power University, Baoding 071003, China 2 Faculty of Mathematics and Computer Science, Hebei University, Baoding 071002, China 3 College of Basic Sciences, Agricultural University of Hebei, Baoding 071001, China E-MAIL: shihuifeng_mcm@yahoo.com.cn, huaq@mail.hbu.edu.cn  Abstract In this paper, using the clos ure of the Galois connection 
two algorithm are proposed for computing all closed itemsets and their generators of a formal context. The canonical implications basis is a minimal no-redundant implication set from which all implications can be inferred by the Armstrong rules. The canonical basis relies on the particular sort itemsets called pseudo-closecd itemsets of formal context are presented Keywords  Formal context; closure operator; implicational system closed itemset; pseudo-closed 1.  Introduction Formal concept analysis\(FCA is a d i scip lin e th e hierarchical structures induced by a binary relation. The term concept lattice and formal concept analysis are due to 
Wille[10 Concep t lattices is an app r o p riate fram e wo rk  fo r data mining especially association rules mining[1,2  T h e  notion of closure operator and Moore family both involve the concept of logical or entail implication, used for in knowledge acquisition me thod called attribute exploration an d as soci at i o n r u l e s i n  d a t a m i ni ng T h e notion of implicational system \(IS for short\was defined in[4 e prop erties of im p licational Moore families and ISs have been studied in[11,4  In gene ral   e v en f o r a sm al l  formal context, its implicational system maybe very large and has a huge proportion of redundant implications, i.e implications conveying the same information. Hence 
finding the smallest set of implications such that other implications can be inferred form these implications by the Armstrong rules[6 is a i n terest wo rk Thu s set of implications is called the canonical basis of implicational system. By the theorem in[2  o r d e r to g e t th e can o n i cal basis of implicational system, the main works are finding all pseudo-closed itemsets and finding all closed itemsets  The paper is organized as follows. Section 2 gives the background knowledge of formal context and concept lattice. In Section 3, some definitions, lemmas and the theorems about implicational system which will be used in our algorithms are presented. In Section 4, we propose four 
algorithms for computing the canonical basis of implicational system of a formal context. The following Section 5 gives experimental results on a simpler formal context and the UCI KDDís archivesís database  2  Formal contest and concept lattice Definition1 A formal context is a triple  K OAR  where O and A are finite sets of objects and attributes\(items\ectively, and ROA is a binary relation between O and A If 
 oi R then object oO has the attribute iA object oO is related to the item iA  A formal context is usually represented by a cross table. For example, the followi ng table is a cross table of the formal context  12345   K O R abcde  This formal context always mentioned in this paper   Table 1. The cross table of formal context 
  a  b  c  d  e  1      2     3      
4    5       We define two maps between 2 O and 2 A for arbitrary 2 OO and 2 MA  


Proceedings of the Fifth International Conference on Mach ine Learning and Cybernetics, Dalian, 13-16 August 2006  1077      forall       for all  f OmMom oO gM o O om R m M    The couple of  f g  is called the Galois connection between power sets 2 O and 2 A For 22  OOM A  M  is said to be common to O if  gM O  Proposition 1 The following three conditions is holding for arbitrary 12 2 OO O  and 12 2 II I   1. if 12 OO then 21   f OfO  2. if 12 II then 21   gI gI  3  OgI  if and only if  IfO  Let  f g be the Galois connection. Setting f g  and gf It is easily to prove that and are two closure operators in 2 O and 2 A i.e. for arbitrary 2 12 OOO O   2 12 III A   and satisfies the following conditions  1 12 1 2    I III     12 2 1   OO O O     2    I IO O    3   I I       OO     Definition 2 Itemset 2 IA  is closed, if  II  For any itemset IA   I  is called the closure of I  corresponding to closure operator i.e  I is the smallest closed itemset containing I  Let    KOAR be a formal context 22 OOAA  binary couple  OA  is called a formal concept of K if  f OB and  gA O  O is called the extent and A the intent of formal concept  OA  Let C  be the set of all formal concepts of    KOAR  We define a partial order on C For 11 22   OM OM C   11 2 2 1 2 2 1   or OM O M O O B B  1 Theorem 1  7 Let   be a formal context  f g the Galois connection. The partial ordered set  C is a complete lattice. The in fimum and supremum are respectively    tt t t tT tT tT OM O M  2     tt t t tT tT tT OM O M  3 The Hash graph of concept lattice is also called the line diagram. It would be too messy to label each concept by its extent and its intent. So, one concept is labeled by its extent or its intent. In the line diagram, the node labeled by objects represents the smallest concept with those objects in its extent; the node labeled by items represents the greatest concept with those items in its intent. Thus, if object o has an attribute m if and only if there is an ascending path from the node labeled by o to the node labeled by m in the line diagram. The extent of a co ncept consists of all objects whose labels are below in the line diagram, and the intent consists of all items labeled to concepts above in the hierarchy  Figure 1. The Hash graph of context formal repre-sented by table 1 In figure1, the concept labeled by A has 1 3 5 as its extent and   AC  as the intent; the concept labeled by 3 5  is the smallest concept which extent is 3 5 and intent is    AB E     BC E is the greatest itemset common to the objects set 2 3 5  3.  The implicational system Definition 3 A closure system \(also called Moore family\ily  of subsets of  satisfying the two following properties  1 F  2 12 FF F implies 12 FF F  The poset  F is a lattice, for each 12 FF F the least upper bound\(LUD\ and th e greatest lower bound\(GLD 


Proceedings of the Fifth International Conference on Mach ine Learning and Cybernetics, Dalian, 13-16 August 2006  1078 are 12 1 2 F FFF  and  12 12  FF FFFF F   It is well known that the set of all closure systems and the set of all closure operators on set M are in a one-to-one correspondence. For a given closure operator the closure system associated to is the set of all closed elements of    FFMF F  4 The closure operator associated to the closure system F is such that, for any X M    F X is the least element F that contains X      F XFFXF  5 Let    KOAR  be a formal context, An implication on  is written as AB  A  is called the premise and B  the conclusion. The implication AB holds in if   gA gB Subset X is a model of implication AB if AX implies BX Implication AB holds for an object oO if  f o is a model of AB An implication is valid in formal context    KOAR if it holds for all objects in O Let be the set of all implications that are valid in formal context K  Setting   FXAXBXAB   then F is clearly a closure system and its elements is closed. by \(4\and \(5\It is ea sily to prove that the closure operator associated to F is the closure operator f g  In general, even for a small formal context K the closure system K is huge and some implications are redundant. Hence, a special inte rest is finding the smallest subset of K such that all other implications in can be inferred by the three Armstrong rules Th us s ubset  i s  called the canonical basis of K  denoted K B  Definition4 Let    KOAR  be a formal context  f g  the Galois connection. Subset A is pseudo-closed if  AA and  BA for any pseudo-closed subset BA  Theorem 2 5  Let    KOAR be a formal context f g  the closure operator on      is pseudo closed BA AAAMA  3 is a non-redundant base of   4  The canonical basis of implicational system  By theorem5, in order to get the basis K B of K  one must finish two main computing works. One is finding all pseudo-closed sets in K The other one is computing the closure of each pseudo-close d set. By the definition of pseudo-closed, getting the pseudo-closed sets, one needs to find all closed itemsets. In this section, we present the algorithms of computing the pseudo-closed itemsets and their closure  4.1.  The Generators Definition 5 Let  KOAR   be a formal context  f g the Galois connection. Itemset IA is a minimal\of closed itemset C if and only if  IC and there exist no other itemset AI such that  AC A generator of cardinality k  is called a k generator, the set of all k generators is denoted as k G  Lemma 1 Let  KOAR  be a formal context  f g  the Galois connection of K For any two itemsets 12 II A  12 1 2  II I I    Proof  Let 12 II A be two non-empty itemsets  then 1122   IIII   12 1 2   II I I  so  12 1 2  II I I    6  On other hands 112 I II  and 212 I II   112    I II   and 212    I II   According to the idempotency  property of the closure operators, we have 12 12         I III       12 12       I III     7 7 12 1 2  II I I    Lemma 2 Let  KOAR  be a formal context  f g  the Galois connection of K For any two itemsets 12 I IA  if 12   gI gI Then 12   II and for any subset 31323  IMII II   Proof By the definition of closure operator  1122     IfgIfgI I  Let 3 IM Then 


Proceedings of the Fifth International Conference on Mach ine Learning and Cybernetics, Dalian, 13-16 August 2006  1079 according to Lemma 1  13 2 3 23  II I I II    8 By lemma1 and lemma2, the candidate 1 i generators 1 i G can be obtained using i generators in i G any two generators in i G with the same first 1 i items are joined, producing a new potential generator of size 1 i The candidate 1 i G  may be redundant, i.e. the closure of some generators in 1 i G already be computed. Hence these generators were pruned from 1 i G  by the following two rules 1. The candidate 1 i generator c is deleted from 1 i G if some i subset s of c  is not in i G  2. The candidate 1 i generator c is deleted from 1 i G if there exist some i subset s such that   gs gc this means that the closure of c  is equal to those of s  The pseudo-code of obtaining 1 i generators 1 i G  is given in algorithm 1 Algorithm 1 The generator function Input i G  1 i G  For arbitrary two i generators i pq G with the same first 1 i  items 11  ii GGpq  For all candidate generators 1 i cG do  if there exist some i subset s of c s.t i sG  then  11   ii GGc  end if end for for all  candidate generators 1 i cG  do  if there exist some i subset s of c s.t   gs gc  then   11   ii GGc  end if end for  Output 1 i G  4.2.  The closed itemsets  Theorem3 Let  K OAR   be a formal context  fg   the Galois connection of K The closure  I  of an itemset I is the intersection of all objects in the context that common to I i.e       oO IfoIfo 9 Proof For any items  I Setting  SoOIfo   and   SoOogI 012    By the definition of the Galois connections f and g if   Ifo then  ogI On the other hand, if  ogI then    IIfgIfo  Hence SS and              ogI oS oS I fgI fo fo fo    By the above theorem, the closure of an itemset can be easily computed, the pseudo code of closure function is given as following Algorithm 2 The closure function  for all oO   o GppGpfo   for all  o pG  do  if   p  then     pfo  else    ppfo  end if   end for end for  Answer   pGp G p p   As finding all closed itemsets, one first determines the set 1 G  of 1-generators. Then, the level variable is set to 0 In each of iteration, the Generator function is applied to the set of generators i G determining the candidate 1 i  generators 1 i G This pricess takes place until i G is empty. Finally, closures of all generators produced are determined. Using the level variable, we construct two sets 


Proceedings of the Fifth International Conference on Mach ine Learning and Cybernetics, Dalian, 13-16 August 2006  1080 of generators. The set G which contains generators p  for which size is less than 1 level and so that are closed The set  G  which contains generators for which size is at least 1 level among which some are not closed, and so for which closure computation is necessary. The closure of generators in  G are determined by applying the Generator function to  G 012 Then all closed itemsets have been produced. The pseudo-code of this process is  Algorithm3 The pseudo-code of finding all closed itemsets Input 1 G  0 l level variable for  1 i  i G  i  do  1 Generator  ii GG  end for  if  2 l  then   1 j GGjl   for all  pG  do   Generator pp  end for   if  0 l   1 j GGjl    Closure  GG   end if end if    FC c c G C   4.3  The algorithm of computing the canonical basis When all closed itemsets have been computed, by the definition4, the work of computing all pseudo-closed itemsets becomes easier. Let iii I CP  be sets of the itemsets, closed itemsets and pseudo-closed itemsets with size i  respectively. The pseudo-codes of the algorithm are presented in Algorithm 4  Algorithm 4 the code of computing the canonical basis  Input the set of all closed itemsets C  Output the base K B   K B  if  0  C   then  0 P   else  0  P   end if  for  1 iiki  do   iii PIC  for all  i LP do   1 ps   for all  j PPji   do  if  PL P L  then   0 ps    ii PPL   end if   end for if 1 ps then    min  j LcCLcji   end if end for  end for  for all  1 n i i PP  do   KK BBP PP   end for  5.  Experimental results Executing our algorithms on the example formal context in section 4, we obtain the following result showed in table 2. The mushroom database consists of 8416 objects of an average size of 23 attr ibutes\(23 items by objects and 127 items on the whole\describing the characteristics of mushrooms. We implement the algorithms described above on mushroom database. The implication system has 8231 implications and itís canonical basis consists of 78 implications 


Proceedings of the Fifth International Conference on Mach ine Learning and Cybernetics, Dalian, 13-16 August 2006  1081 Table 2. The table of experiment result  Generators Closed itemsets Implications  A   AC  AC   B   BE  BE   C   C    D     AC D  DAC   E   BE  EB   AB   ABC E  AB CE   AE   ABC E  AE BC   BC   BC E  CB E   CE   BC E  CE B  6.  Conclusions  The attribute implication rules in formal concept analysis can give the plausible dependencies in data that can be used for data recovery, cl assification, etc. In general the size of the implicational system is huge, even for a small context. And some implication rules are redundant in the sense that it could be retrieved from smaller sets of implication rules. The canonical implication basis is a minimal no-redundant implication set from which all valid implication can be inferred by the Armstrong rules. In this paper, we discuss how to construct the canonical basis in formal context. By the theorem in [5 e k e ys o f  constructing the canonical basis are finding all pseudo-closed itemsets and computing their closures. In order to finding all pseudo-closed, one must find all closed itemsets and their generators. We write out the pseudo-code of algorithms for above computing works. Experimental result show that the algorithms presented in this paper are feasible and efficient for large database Acknowledgements This paper is supported by the Homecoming Fund of North China Electric Power University \(200514001 References    R  Ag ra wal an d R  Sri k a n d. Fa st al gori t h m s for m i ni ng  association rules. Proceeding of the 20th Intíl Conference on Very Large Data Bases, pages 478-499 June 1994, Expanded version in IBM Research Report RJ9839 2  R. Agrawal T  Im ielin sk i, an d A. Swami. Min i n g  association rules between sets of items in large databases. Proc. SIGMOD conf., pp 207-216, May 1993 3  G  Birk ho f f  Lattices th eo ry In Co ll. Pu b. XXV   volume 25. American Mathem atical Society, 1967 Third edition   N. C a s p a r d an d B  M o nja r det  S o m e l a tt i ces o f cl os u r e  system on a finite set. Discrete Mathematics ang Theoretical Computer Sciences, 6:163-190, 2004   5  Dav i d Maier  Th e th eo ty o f  relatio n a l d a ta b a se Computer Science Press, Rockville 1983  6  Gan t er B. W ille R. Form al Co n cep t An alysis Mathematical Foundations[M  Spri nger, 1999  7  N  Pasq u i er Y. Bastid e, an d L. Lakh al D i sco v e r i ng fr  equent closed itemsets for association rules. In LLNCS Springer Verlag, editor, ICDTí99, 1540 398-416,1999 8  G e rd  Stu m m e  A ttr ibu t e exp l o r ation  w ith back gro und implications and exceptions. In:Hans-Herrmann Bock Wolfgang Polasek, editors. Data analysis and information system. Springer, Berlin-Heidlberg-New York, 1996,pp. 457ff  9  W ille R. Reco n s t r u c ting lattice th eory: an app r o a ch based on hierarchies of co ncepts. In: Rival, I ed Ordered Sets Dordrecht-Boston: Reidel, 1982 445-470  W i l d  M. A theory of finite closure s p ace base d on implications. Advances in Mathematics, 108:118-139 1994  


nal published from April 2 1990 through September 28 1990 for the performance comparison between PMIHP and Count Distribution as well a s between MIHP and Apriori The sample contains 21,703 documents and 116,849 unique words We varied the minimum support level from 5 to 1.75 to measure its impact on the miners For PMIHP and Count Distribution the 6-month sample was sequentially distributed to the processing nodes by assigning the articles of 16 or 17 days to each node Figure 4 shows the total execution times of Apriori FPGrowth and MIHP and Figure 5 shows the total execution times of PMIHP and Count Distribution when both algorithms were run on 8 nodes The Apriori and Count Distribution algorithms were not able to run within the memory constraint of 416 Mbytes when the minimum support level is below 2 The memory requirement for the candidate itemsets is the limiting factor for both Apriori and Count Distribution MIHP has much better performance than Apriori because MIHP prunes many candidate itemsets by using the Inverted Hashing and Pruning and processes a limited number of candidate itemsets at a time based on the Multipass approach More performance analysis result of MIHP is available in 12 The FP-Growth algorithm performed well at the higher minimum support levels However its performance deteriorated at the 2 minimum support level The FP-tree becomes too large when the minimum support level is low and as a result the total execution time increases sharply Lower minimum support levels were not attempted As shown in Figure 5 PMIHP performs signiﬁcantly better than Count Distribution and the performance gain increases as the minimum support level decreases It is important to note that the minimum support levels were selected in this test such that the miners would run within the constraint of the main memory and thus eliminates the effect of paging upon the performance Comparing Figures 4 and 5 we can see that the speedup of Count Distribution over Apriori is fairly good When the minimum support level is 2 it is about 6 whereas the speedup of PMIHP over MIHP is about 4 However as we shall see below the speedup of PMIHP is quite good at a lower minimum support level of 0.15 Since the amount of computation increases rapidly as the minimum support level decreases the speedup improvement at low minimum support levels is quite encouraging To evaluate the effect of the number of processing nodes on the performance of PMIHP we used a 8-day sample of the Wall Street Journal starting from October 1 1991 There were 1,427 documents and 31,290 unique words We used a minimum support count of 2 documents i.e minimum support of 0.15 and a stop-word list from Fox 8  There were 12,828 frequent words The minimum support count of two documents was selected based upon the result  Apriori  FP-Growth  MIHP Minimum Support Time \(seconds              0 100000 200000 300000 400000 500000 5.00 4.00 3.00 2.00 1.75 Figure 4 Total execution time to nd all frequent itemsets in 21,703 documents  CD  PMIHP Minimum Support Time \(seconds          0 20000 40000 60000 80000 5.00 4.00 3.00 2.00 1.75 Figure 5 Total execution time to nd all frequent itemsets in 21,703 documents on 8 nodes of our experiments showing that low minimum support levels are required to use the frequent itemsets for document retrieval and ranking We did not stem the words but we monocased the words The database was assigned to the processing nodes sequentially by day For the 2-node case one node was assigned the articles of the rst 4 days and another node was assigned the articles of the last 4 days The assignments for the 4-node and 8-node cases were done in a similar manner These daily collections have a mean of 178 a standard deviation of 22.58 and a median of 174 documents Figure 6 shows the total execution time of PMIHP required to nd frequent 3-itemsets as the number of processing nodes changes and Figure 7 shows the corresponding speedup over the sequential processing We can see that the speedup increases as the number of processing nodes increases and the increasing rate is slightly higher than lin0-7695-2132-0/04/$17.00 \(C Proceedings of the 18th International Parallel and Distributed Processing Symposium \(IPDPSê04 


ear The speedup is 1.65 for the 2-node system indicating some degree of parallelization overhead mainly due to the interprocess communication to exchange the support count information The speedup is 3.76 for the 4-node system but the increasing rate of the speedup is 2.27 as the number of nodes is doubled from 2 to 4 As the number of nodes is doubled from 4 to 8 the increasing rate of the speedup is higher than linear again which indicates that PMIHP is quite scalable Number of Processors Time \(seconds 0 20000 40000 60000 80000 1 2 4 8 Figure 6 Total execution time of PMIHP to nd frequent 3-itemsets in 1,427 documents minsup  0.15 Number of Processors Speedup    0 2 4 6 8 2 4 8 Figure 7 Speedup of PMIHP minsup  0.15 The PMIHP algorithm has two main data mining activities counting the support of local candidate itemsets in the corresponding local database and counting the support of global candidate itemsets in multiple local databases These two activities are interleaved during the mining as the global support counting is invoked when the number of identiﬁed global candidate itemsets exceeds a certain number at each processing node which was set to 20,000 in our experiments To measure this global support counting time we reconﬁgured PMIHP to defer the global support counting of the global candidate itemsets at each node and synchronized the nodes before the start of the global support counting phase Figure 8 shows the global support counting time of the mining process with the logest run time among all the mining processes executed on different processing nodes Moreover we used the wall clock time to measure this global counting time hence it is an upper bound of the actual global support counting time of all the mining processes Comparing Figures 6 and 8 we can see that the 2-node case has a much longer global support counting phase than 4-node and 8-node cases The portion of the global support counting phase for the 2-node case is about 8 of the total execution time but it is about 4 for the 4-node case and about 3 for the 8-node case Thus the impact of the global support counting time on the overall speedup is very small and it is reduced further as the number of processing nodes increases Number of Processors Time \(seconds 0 1000 2000 3000 4000 2 4 8 Figure 8 Global support counting time to nd frequent 3-itemsets Since our processing environment does not provide the statistics for job accounting exact CPU time measurement was not feasible So we measured the average execution of a processing node using the wall clock time Figure 9 shows the average execution time of a node in the 1-node 2-node 4-node and 8-node conﬁgurations We can see that the 2-node case requires signiﬁcantly less average execution time per node than the 1-node case and as the number of processing nodes increases further the average execution time per node deceases more than linearly This result is completely consistent with the observed speedup values and also indicates that increased efﬁciency is behind the performance gain Since the identical PMIHP algorithm was executed on all of our system conﬁgurations the differences in execution time must be associated with some workload differences Figure 10 shows the average number of candidate 0-7695-2132-0/04/$17.00 \(C Proceedings of the 18th International Parallel and Distributed Processing Symposium \(IPDPSê04 


Number of Processors Time \(seconds 0 20000 40000 60000 80000 1 2 4 8 Figure 9 Average execution time per node to nd frequent 3-itemsets 2-itemsets processed by each node in our four different system conﬁgurations Note that the number of candidate 2itemsets for the 1-node case is approximately the same as the average number of candidate 2-itemsets for the 2-node case This result is consistent with the observed total and average execution times for the 1-node and 2-node cases There is signiﬁcant reduction in the average number of candidate 2-itemsets processed for the 4-node and 8-node cases over the 1-node and 2-node cases This result represents the nonuniform distribution of itemsets over the local databases as well as the effective reduction of the candidate itemsets by the Inverted Hashing and Pruning technique Number of Candidate 2-itemsets 0 100000 200000 300000 400000 MIHP 2-node PM IHP 4-node PM IHP 8-node PM IHP Figure 10 Average number of candidate 2itemsets per node Figure 11 shows the average number of candidate 3itemsets processed by each node We included the number of candidate 3-itemsets processed in Apriori to demonstrate the usefulness of the Inverted Hashing and Pruning The number of candidate 2-itemsets for Apriori was about 82 million which is why we did not show that in Figure 10 We can observe the same pattern of reduction in the candidates 3-itemsets as in the candidate 2-itemsets This reduction in the average number of candidate itemsets processed by each processing node may be the most clear explanation for the high increasing rate of the speedup observed as the number of processing nodes increases Number of Candidate 3-itemsets 0 200000 400000 600000 800000 Apriori MIHP 2-node PM IHP 4-node PM IHP 8-node P M IHP Figure 11 Average number of candidate 3itemsets per node We also ran a test with a larger database 8 weeks of the Wall Street Journal published from January 2 1991 through February 22 1991 February 23rd was a Wall Street Journal holiday There were 6,170 documents and 64,191 unique words of which 31,948 were frequent words at the minimum support level of 0.03 i.e 2 out of 6,170 documents The 1-node system required 845,702 seconds to nd 1,554,442 frequent 2-itemsets whereas the 8-node system required 33,183 seconds This performance represents a superliner speedup of 25.5 of the 8-node system over the 1-node system Thus we can conclude that the performance of PMIHP is quite scalable when the database is large and the minimum support level is low which is the case of high workload The 1-node case generated 16,174,357 candidate 2itemsets whereas the 8-node case generated 2,459,629 candidate 2-itemsets per node on the average The total number of candidate 2-itemsets counted by the 8 nodes were 19,677,031 which means that only 21.7 of the candidate 2-itemsets were counted at more than one processing node This implies that the distribution of words across the 8-week sample of the Wall Street Journal is quite skewed In the Count Distribution algorithm all the nodes count the same set of candidate itemsets in each pass over the database regardless of the distribution of items over the local databases On the other hand in our PMIHP algorithm not all candidate itemsets are counted at more than one node when the distribution of items over the local databases is not uniform Obviously the more skewed the data distribution the better the performance of PMIHP Cheung et al 4 propos ed s e v e ral approaches to partition the databas e 0-7695-2132-0/04/$17.00 \(C Proceedings of the 18th International Parallel and Distributed Processing Symposium \(IPDPSê04 


to achieve a high degree of skewness Text documents arranged in a chronological order do appear to have a high degree of skewness and beneﬁt the PMIHP algorithm 4 Conclusions The proposed Parallel Multipass with Inverted Hashing and Pruning PMIHP algorithm is a parallel version of our Multipass with Inverted Hashing and Pruning MIHP algorithm and it is effective for mining frequent itemsets in large text databases The Multipass approach reduces the required memory space at each processor by partitioning the frequent items and pro cessing each partition separately Thus the number of candidate itemsets to be processed is limited at each instance The Inverted Hashing and Pruning is used to prune the local and global candidate itemsets at each processing node and it also allows each processing node to determine the other peer processing nodes to poll in order to collect the local support counts of each global candidate itemset PMIHP distributes the workload to multiple processing nodes to reduce the total mining time without incurring much parallelization overhead The average number of candidate itemsets to be counted at each processing node is much smaller than the case of sequential mining while the time for the synchronization between processing nodes to exchange the count information for the global candidate itemsets is very small compared to the total execution time PMIHP is able to exploit the natural skewed distribution of words in text databases and demonstrates a superlinear speedup as the number of processing nodes increases It has a much better performance than well-known parallel Count Distribution algorithm 2 becaus e the a v erage number of candidate itemsets to be counted at each processing node is much smaller especially when the minimum support level is low Overall the performance of PMIHP is quite scalable even when the size of the text database is large and the minimum support level is low which is the case of high workload References  R  A gra w al and R  S r i kant   Fast Al gori t h ms for M i n i n g A ssociation Rules Proc of the 20th VLDB Conf  1994 pp 487–499  R Agra w a l and J C S hafer  Paral l e l M i n i n g o f A ssoci at i o n Rules IEEE Trans on Knowledge and Data Engineering  Vol 8 No 6 1996 pp 962–969 3 M  S  C hen J Han and P  S  Y u   Dat a Mi ni ng An Overview from a Database Perspective IEEE Trans on Knowledge and Data Engineering  Vol 8 No 6 1996 pp 866–883 4 D  W  C heung S  D L ee and Y  Xi ao  E f f ect of Dat a S k e w ness and Workload Balance in Parallel Data Mining IEEE Trans on Knowledge and Data Engineering  Vol 14 No 3 2002 pp 498–514 5 S  M  C hung and J Y ang  A Par al l e l D i s t r i b ut i v e J oi n A l gorithm for Cube-Connected Multiprocessors IEEE Trans on Parallel and Distributed Systems  Vol 7 No 2 1996 pp 127–137  R  F e l dman and H Hi rsh F i ndi ng Associ at i ons i n Col l ections of Text Machine Learning and Data Mining Methods and Applications  R Michalski I Bratko and M Kubat editors John Wiley and Sons 1998 pp 223–240  R F e l dman I Dagen and H  H i rsh Mi ni ng T e xt Usi n g Keyword Distributions Journal of Intelligent Information Systems  Vol 10 No 3 1998 pp 281–300  C  Fox L e x i cal Anal ysi s and S t opl i s t s   Inforamtion Retrieval Data Structures and Algorithms W.FrakesandR Baeza-Yates editors Prentice Hall 1992 pp 102–130 9 M  G or don and S  Dumai s Usi ng L a t e nt S e mant i c I nde xi ng for Literature Based Discovery Journal of the Amer Soc of Info Science  Vol 49 No 8 1998 pp 674–685  J Han J P e i  and Y  Y i n Mi n i n g F r equent Pat t e r n s w i t hout Candidate Generation Proc of ACM SIGMOD Intêl Conf on Management of Data  2000 pp 1–12  J D Holt and S  M Chung Multipass Algorithms for Mining Association Rules in Text Databases Knowledge and Information Systems  Vol 3 No 2 Springer-Verlag 2001 pp 168–183  J D Hol t and S  M C hung Mi ni ng Associ at i o n R ul es Using Inverted Hashing and Pruning Information Processing Letters  Vol 83 No 4 Elsevier Science 2002 pp 211–220  J D Hol t and S  M C hung Mi ni ng associ at i o n R ul es i n Text Databases Using Multipass with Inverted Hashing and Pruning Proc of the 14th IEEE Intêl Conf on Tools with Artiìcial Intelligence  2002 pp 49–56  J S  Park M S  C hen and P  S  Y u   Usi n g a Hash-B a sed Method with Transaction Trimming for Mining Association Rules IEEE Trans on Knowledge and Data Engineering  Vol 9 No 5 1997 pp 813–825  G  S a l t on Automatic Text Processing The Transformation Analysis and Retrieval of Information by Computer  Addison-Wesley Publishing 1988  E  M V oorhees and D K Harmon edi t o rs The Fifth Text Retrieval Conference  National Institute of Standards and Technology 1997  O R  Z a i a ne and M L  Ant o i ne C l assi f y i n g T e x t D ocuments by Associating Terms with Text Categories Proc of the 13th Australian Database Conf  2002 0-7695-2132-0/04/$17.00 \(C Proceedings of the 18th International Parallel and Distributed Processing Symposium \(IPDPSê04 


  11 could be improved by a simple modification of the feed by adding a small tuning vane to th e feed. Therefore, it can be stated that some improvement can be expected by modification of the feeds, and adaptation of the test antenna in such a way that surrounding Ku-band element are closed   Figure 28 Reflection coefficient of Ku-band stacked patch antenna element in dual-frequency antenna stack  Figure 29 shows the influence of the L-band slots on the return loss of the Ku-band antenna element. To this end, the four connectors of the L-band elements were alternately open and terminated by means of 50 loads. The deviations were measured with respect to the set-up where all connectors were terminated Apparently, the deviations are acceptable  Figure 29 Influence of L-band termination on return loss of Ku-band antenna element, with and without termination Figure 30 and Figure 31 show the isolation between the Lband and Ku-band elements in L-band and Ku-band respectively. To this end the S21-parameters have been measured. These figures reveal that the mutual coupling between the L-band and Ku-band elements is sufficiently small  Figure 30 Measured isolation between L-band and Ku-band antennas in L-band frequencies  Figure 31 Measured isolation between L-band and Ku-band antennas in Ku-band frequencies From these measurements it can be concluded that opportunities should be considered to improve the design of the dual-frequency antenna \(by optimizing the feeds of the Ku-band elements antenna and the measurement set-up \(closure of surrounding Ku-band ports and use of appropriate connectors for the open Ku-band ports 7  M ODIFIED DUAL FREQUENCY ANTENNA  In order to benefit the str ong points of the two separate designs as discussed in section 4, an alternative antenna is proposed that exploits the properties of a \221best of both worlds\222 solution employing ideas from both designs. The modified antenna possesses an aperture fed L-band patch of a similar form to first design, but situated towards the bottom of the stack. Ku band el ements are located within the L-band perforations and para sitic patches are situated above a foam spacer \(see Figure 32 and Figure 33\A measurement campaign is underway to assess the behaviour of this modified test antenna 


  12  Figure 32 Bottom view of dual frequency antenna tile with perforated L-band patc h in lower layer with Kuband patches  Figure 33 Layer stack with perforated L-band patch in lower layer with Ku-band patches  8  B EAM FORMING N ETWORK  A major keystone for the su ccess of phased array antenna onboard aircraft is the capability of steering the main beam in the direction of the geosta tionary satellites. This requires the inclusion of a broadband beam forming network. Beam steering can be realized by adding RF-phase shifters and LNA\222s to the antenna elements of the array. However traditional phase shifters in ge neral have a narrow band, and hence do not yield the re quired broadband capability Alternative technologies for broadband beam forming are switched beam networks \(using Butler matrices innovative designs for RF-compone nts such as phase shifter LNA components in \(M\IC technology, or beam forming by using opti cal ring resonators  The German SME IMST is involved in several projects for development of electronica lly steerable phased array antennas for satellite communication. In the NATALIA project \(New Automotive Track ing Antenna for Low-cost Innovative Applications\ ESA, IMST is investigating the possibility of realizing a compact costeffective solution for a recei ve-only full electronically steerable antenna for cars in Ku-band. This antenna is a planar array composed of approximately 150 patches circularly polarised by using a 90\260 hybrid, and arranged in a hexagonal fashion. Each patc h is equipped with a MMIC corechip containing a phase sh ifting unit, LNA and digital steering logic  In the Netherlands, a consortiu m \(consisting of University of Twente, Lionix BV, National Aerospace Laboratory NLR and Cyner Substrates developing in the national FlySmart project technology for a broadband optical beam forming network. For the steering of the beam of the conformal phased array a squi nt-free, continuously tunable mechanism is proposed that is based on a fully integrated optical beam forming network \(OBFN optical ring resonators \(ORRs as tunable delay elements. A narrowband continuously tunabl e optical TTD device is realized as a recirculating wa veguide coupled to a straight waveguide. This straight wave guide can behave as a bandpass filter with a periodic, bell-shaped tunable group delay response. The maximum group delay occurs at a tunable resonance frequency. A larger delay-bandwidth product can be achieved by cascading multiple ORR sections. A complete OBFN can be obtaine d by grouping several delays and combining elements in one optical circuit. Such an OBFN can be realized on a si ngle-chip. Electrical/Optical E/O O E by means of filter based single-sideband modulation suppressing the carrier lanced coherent optical detection. Further details of the optical beamforming network have been presented in Re The proof-ofconcept has been shown by manufacturing a chip for an 8x1 OBFN. Essential components of the OBFN are the optical modulators, which are used to modulate the light in the ORR system 9  C ONCLUSIONS  For enhanced communicati on on board aircraft, novel antenna systems with broa dband satellite-based capabilities are required. So far, existi ng L-band satellite based systems for communications are used primarily for passenger application \(APC\i nistrative communications AAC and now data are tending to evolve towards broadband dig ital applications \(Voice over IP\any studies are going on worldwide to employ Kuband TV geostationary sate llites for communication with mobile terminals on aircraft The inbound traffic is about 5 times higher than the outbound The inbound traffic requires the availability of a broadband Ku-band antenna in receive mode only. The outbound traffic services can be supplied by the Inmarsat SBB link, whic h requires the installation of an L-band transmit antenna. In order to avoid both the installation of L-band antenna and Ku-band antenna, the concept of a hybrid dual frequency antenna operating L 


  13 band and Ku-band with low aerodynamic profile has been investigated in this paper. Keyaspects of this research are 200  Design and testing dual-fre quency antenna elements operating in both L-band and Ku-band 200  Conformal aspects of Ku-band phased array antennas 200  Beam forming algorithms for planar and conformal phased array antennas Two designs for dual-frequency antenna tiles consisting of 8x8 Ku-band antenna elements and one L-band element The designs have been analysed by means of computer simulations. Both designs show promising performance both in L-band and Ku-band. The design with slotted Lband antenna has a resonant fre quency in receive mode with a bandwidth of about 1 GHz. The Ku-band antenna is a stacked patch configuration where a parasitic element is placed above a lower patch separated by dedicated space filler. The manufactured protot ype antennas indicate that the bandwidth is sufficiently large In order to be able to communicate with geostationary satellites also at high latitudes e.g. during inter-continental flights\stem should have sufficient performance at low elevation angles. The antenna Ku-band system is required to have a small beamwidth \(to discriminate between the satellite signals\gain 30 dB angles. The effects of these requirements on the size and positioning of the antenna on the aircraft fuselage have been investigated. These requirements can be best satisfi ed by installing two planar phased array antennas on both side s of the fuselage with at least 1600 Ku-band elements. Each element has two feed lines, one for each polarization Every feed line has to be connected to the beam formi ng network. This means that the connections cannot be routed to one of the four sides of the antenna. Instead the concept of vertical feed lines \(by means of vias in a sufficiently thick substrate recommended. These vertical f eed lines connect the L-band and Ku-band antenna elements in the upper layer with feed networks in multiple lower laye rs. This vertical feed line system was not available so far due to manufacturing problems The performances of one dua l-frequency antenna design have been investigated by manufacturing two test antennas without vertical feed line syst em. The first antenna contains only a multilayer structure with L-band slots and 8x8 Kuband stacked patches. The performances of the L-band slots and Ku-band stacked patches c ould be measured separately It was concluded that opportun ities should be considered to improve the design of the dual-frequency antenna \(by optimizing the feeds of the Ku-b and elements the dual frequency test-antenna and the measurement set-up More important, however, is the realization of a mechanically stable vertical feed line system, so that the properties of L-band and Ku-band elements can be measured adequately The second test antenna contains only a multilayer structure with 8x8 Ku-band stacked patches and a feed network with 8 combiners, where each comb iner coherently sums 8 antenna elements. In combination with a prototype 8x1 OBFN, a Ku-band phased arra y antenna is obtained of which the beam can be steered in one direction. This second test antenna is used to analyze the broadband properties of the 8x8 Ku-band antenna array and 8x1 OBFN. The measured performances of this antenna are presented in Ref   A CKNOWLEDGMENT  This work was part of the EU 6 th Framework project ANASTASIA., and the FlySmart project, supported by the Dutch Ministry of Economic A ffairs, SenterNovem project numbers ISO53030 The FlySmart project is part of the Eureka PIDEA  project SMART Cyner Substrates is acknowle dged for technical assistance during the fabrication of the prototype antennas 


  14 R EFERENCES  1  P. Jorna, H. Schippers, J. Verpoorte, \223Beam Synthesis for Conformal Array Antennas with Efficient Tapering\224 Proceedings of 5 th European Workshop on Conformal Antennas, Bristol, September 11-12, 2007 2  The Radio Regulations, editi on of 2004, contain the complete texts of the Radio Regulations as adopted by the World Radio-communication Conference \(Geneva WRC-95 tly revised and adopted by the World Radio-communication Conference WRC-97\RadioWRC2000\and the World Radio-communication Conference WRC-03 Resolutions, Recommendations and ITU-R Recommendations incorporat ed by reference 3  RECOMMENDATION ITU-R M.1643, Technical and operational requirements for ai rcraft earth stations of aeronautical mobile-satellite service including those using fixed satellite service network transponders in the band 14-14.5 GHz \(Earth-to-space 4  ETSI EN 302 186 v1.1.1 \(2004-01 Stations and Systems \(SES\onised European Norms for satellite mobile Aircraft Earth Stations AESs\the 11 12/14 GHz frequency bands covering essential requirement s under article 3.2 of the R&TTE directive 5  EUROCAE ED-14E; Environmental Conditions and Test procedures for Airbor ne Equipment, March 2005 6  F. Croq and D. M. Pozar, \223Millimeter wave design of wide-band aperture-coupled stacked microstrip antennas,\224 IEEE Trans. Antennas Propagation, vol. 39 pp. 1770\2261776, Dec. 1991 7  S. D. Targonski, R. B. Waterhouse, D. M. Pozar Design of wide-band aperture stacked patch microstrip antennas ", IEEE Transactions on Antennas and Propagation, vol. 46, no. 9, Sep. 1998, pp. 1245-1251 8  R. B. Waterhouse, "Design of probe-fed stacked patches", IEEE Transactions on Antennas and Propagation, vol. 47, no. 12, Dec. 1999, pp. 1780-1784 9  D.M. Pozar, S. D. Targonski, \223A shared aperture dualband dual-polarised microstrip array\224, IEEE Transactions on Antennas and Propagation,Vol. 49 no. 2,Feb. 2001, pp. 150-157 10  http://www.ansoft.com 11  J-F. Z\374rcher, F.E. Gardiol, \223Broadband patch antennas\224 Artech House, \(1995\N 0-89006-777-5 12  H. Schippers, J. Verpoorte, P. Jorna, A. Hulzinga, A Meijerink, C. G. H. Roeloffzen, L. Zhuang, D. A. I Marpaung, W. van Etten, R. G. Heideman, A. Leinse, A Borreman, M. Hoekman M. Wintels, \223Broadband Conformal Phased array with Optical Beamforming for Airborne Satellite Communication\224, Proc. of the IEEE Aerospace Conference, March 2008, Big Sky, Montana US 13  H. Schippers, J. Verpoorte, P. Jorna, A. Hulzinga, L Zhuang, A. Meijerink, C. G. H. Roeloffzen, D. A. I Marpaung, W. van Etten, R. G. Heideman, A. Leinse M. Wintels, \223Broadband Op tical Beam Forming for Airborne Phased Array An tenna\224, Proc. of the IEEE Aerospace Conference, March 2009, Big Sky, Montana US 


  15  B IOGRAPHIES  Harmen Schippers is senior scientist at the National Aerospace Laboratory NLR. He received his Ph. D. degree in applied mathematics from the University of Technology Delft in 1982. Since 1981 he has been employed at the National Aerospace laboratory NLR. He has research experience in computational methods for aero-eleastics, aeroacoustic and electromagnetic problems. His current research activities are development of technology for integration of smart antennas in aircraft structures, and development of computational tools for installed antenna analysis on aircraft and spacecraft  Jaco Verpoorte has more than 10 years research experience on antennas and propagation Electromagnetic compatibility \(EMC and radar and satellite navigation He is head of the EMC-laboratory of NLR. He is project manager on several projects concerning EMCanalysis and development of advanced airborne antennas    Adriaan Hulzinga received his BEng degree in electronics from the hogeschool Windesheim in Zwolle Since 1996 he has been employed at the National Aerospace laboratory \(NLR as a senior application engineer. He is involved in projects concerning antennas and Electromagnetic compatibility \(EMC  Pieter Jorna received the M.Sc degree in applied mathematics from the University of Twente in 1999 From 1999 to 2005 he was with the Laboratory of Electromagnetic Research at the University of Technology Delft. In 2005 he received the Ph.D. degree for his research on numerical computation of electromagnetic fields in strongly inhomogeneous media Since 2005 he is with the National Aerospace Laboratory NLR\ in the Netherlands as R&D engineer   Andrew Thain is a research engineer in the field of electromagnetic modelling of antennas. He specialises in the use of surface integral methods for the calculation of coupling and radiation patterns and works closely with Airbus on the topic of antenna positioning. He has experience in the field of electromagnetic modelling  Gilles Peres is head of the Electromagnetics group of EADS-IW He has a wide experience in computational EM modelling particularly the use of FDTD, integral and asymptotic techniques for antenna structure interactions. He has contributed with Airbus experts to the certification campaign of the A340/500 and A340/600. Dr Peres holds a PhD thesis from University of Toulouse \(1998\ on impulsive Electromagnetic Propagation effects through plasma   Hans van Gemeren has a BEng degree in electronics. From the beginning of Cyner substrates he is involved in development and production of prototyping and nonconventional Printed Circuit boards Working mainly for design and research centers Cyner got involved in many high tech projects and from this developed a great expertise in the use of different \(RF materials. In the FlySmart project Hans and his colleagues are able to do what they like most: In close cooperation with designers, creatively working on substrate solutions 


  16  


NIMBUS NOAA 8 NOAA 15 NPOESS Preparatory Project Orbital Maneuvering Vehicle Orbcomm Orbiting Carbon Observatory Orbiting Solar Observatory-8 Orbview 2 Orion 1 P78 Pas 4 Phoenix Pioneer P-30 Pioneer Venus Bus/Orbiter Small Probe and Large Probe Pioneer-I 0 Polar QuikSCAT Radarsat Reuven High Energy Solar Spectroscopic Imager REX-II Rosetta Instruments Sage III SAMPEX Satcom C3 Satcom C4 SBS 5 SCATHA Seastar SMART-1 SNOE Solar Dynamics Observatory Solar Maximum Mission Solar Mesosphere Explorer Solar Radiation and Climate Experiment Solar Terrestrial Relations Observatory Space Interferometry Mission Space Test Program Small Secondary Satellite 3 Spitzer Space Telescope SPOT 5A Stardust  Sample Return Capsule STEPO STEPI STEP3 STEP4 STRV ID Submillimeter Wave Astronomy Satellite Surfsat Surveyor Swift Gamma Ray Burst Exporer Synchronous Meterological Satellite-I TACSAT TACSAT 2 TDRS F7 Tellura Terra Terriers Tethered Satellite System Thermosphere Ionosphere Mesosphere Energetics and Dynamics TIMED TIROS-M TIROS-N TOMS-EP Total Ozone Mapping Spectrometer TOPEX TRACE Triana Tropical Rain Measuring Mission TSX-5 UFO I UFO 4 UFO 9 Ulysses Upper Atmosphere Research Satellite Vegetation Canopy Lidar VELA-IV Viking Viking Lander Viking Orbiter Voyager Wilkinson Microwave Anisotropy Probe WIND WIRE XMM X-Ray Timing Explorer XTE XSS-iO XSS-ii APPENDIX B FIELDS COLLECTED Mission Mission Scenario Mission Type Launch Year Launch Vehicle Bus Model Bus Config Bus Diameter Location Expected Life Flight Profile Flight Focus Technical Orbit Currency Total Cost Including Launch Unit Sat Costs Average Sat Cost Production Costs Launch Costs Operations Cost Orbit Weight Wet Weight Dry Weight Max Power EOL Power BOL Power  of Batts 17 


Batt Power Batt Type Stabilization Type Propulsion Mechanism  of Solar Panels  of Solar Cells Manufacturing Qty Satellites in Constellation On-Orbit Spares Channels Number of Bands Data Storage Processing Power Source type Block Name Thermal Control Material Type Level of Technology Known Inheritance Propulsion station keeping Number of Axes Ground Based Spares Pointing Accuracy APPENDIX C EXISTING MODELS Numerous models are today in use for estimating spacecraft cost Two of the most common are the NASA/Air Force Cost Model and the Aerospace Small Satellite Cost Model Here is a description of the NAFCOM model The NASA/Air Force Cost Model NAFCOM is a parametric estimating toolfor space hardware It is based on historical NASA and Air Force space projects and is primarily used in the very early phases of a development project NAFCOM can be used at the subsystem or component levels The database currently includes 122 missions including 76 unmanned earth orbiting 24 unmanned planetary 11 launch vehicles 8 manned 3 engines It uses parametric relationships to estimate subsystem or component level costs for any aerospace hardware including earth orbital spacecraft manned spacecraft launch vehicle upper stages liquid rocket engines scientific instruments or planetary spacecraft 7 And for the Aerospace Small Satellite Cost Model SSCM employs a parametric methodology for estimation of program cost and is best suited to the early conceptual development phase of a spacecraft program during which time the design is likely to be less mature and when cost and performance trades can be easily performed SSCM consists of a collection of cost-estimating relationships or CERs which estimate the costs of developing andproducing a spacecraft system with the following subsystems  Attitude Determination and Control Subsystem ADCS  Propulsion  Power  Telemetry Tracking  Command TT&C  Command  Data Handling C&DH  Structure  Thermal CERs were also developed for integration assembly and test IA&T program management PM and systems engineering SE and launch and orbital operations support LOOS Individual subsystem cost estimates are statistically rolled up to yield a cost-risk distribution which provides the estimator with a range of cost estimates andpercentiles 8 The SSCM was calibrated from over 100 post-1990 Earth-orbiting andplanetary missions REFERENCES 1 Lack of Disciplined Cost-Estimating Processes Hinders Effective Program Management GAO study 04-642 2 Jilla Cyrus D and Miller David W Satellite Design Past Present and Future International Journal of Small Satellite Engineering 12 February 1997 3 Bearden David A A Complexity Based Risk Assessment of Low-Cost Planetary Missions:When Is A Mission Too Fast and Too Cheap Fourth IAA International Conference On Low-Cost Planetary Missions JHU/APL MAY 2-5 2000 4 Kellogg Mahr and Lobbia An Analogy-based Method for Estimating the Costs of Spacecraft IEEEAC paper 1371 Version 4 5 Hoeting Jennifer A Methodology for Bayesian Model Averaging An Update f 6]btp/ewiieiao iiAaos 7 Keith Smith NASA/Air Force Cost Model Science Applications International Corporation 8 18 


BIOGRAPHIES Lee Fischman served as Principle Investigator for this project Lee is Senior Director of Development at Galorath Incorporated where he directs much of the new product development and research at the firm He developed SEER for Software  Hardware Integrations with Microsoft Project the Comparison Sizing tool COTS Software model in addition to various data mining information extraction and expert systems Previously he was a software designerlprogrammer in the New York financial industry Lee earned a BA from the University of Chicago and an MA from UCLA both in economics Mike Kimel carried out statistical work on the project Mike is an Economist for Galorath Inc in addition to maintaining his own quantitative consulting practice He has also taught Economics and Advanced Statistics at the Graziadio School of Business and Management at Pepperdine University run the Competitive Strategy group for a Fortune 500 Telecom Company and worked as a Consultant at PriceWaterhouse LLC now PriceWaterhouse-Coopers He earned a Ph.D in Economicsfrom UCLA Troy Masters programmed analytic methods and is integrating the Far Out model into its parent product SEER for Hardware previously SEER-H Troy is a Software Engineer with Galorath Incorporated where he has been the primary developer for a range ofproducts He earned a BS in computer science from UCLA David J Pine was our subject matter expert helping us assemble data and gain insight into technical trends Dave is retired after a 34-year career with the National Aeronautics and Space Administration NASA currently is a consultant to various government and industry entities While at NASA his organizations in the Office of the Chief Financial Officer and later at the IPAO at Langley Research Center were responsible for the conduct of major NASA program analyses and evaluations for the NASA Administrator and Deputy Administrator From early 1988 through the end of 1990 he was the Deputy Program Manager for the Hubble Space Telescope Program specifically responsible for the telescope operations and science support aspects of the program He earned a BS in Aerospace Engineering from the Polytechnic Institute of Brooklyn and a Masters of Engineering Administration from the George Washington University 19 


  20 Angeles, where he also received a B.S. in Applied Mathematics  Eric Fetzer is a Senior Member of the Technical Staff at the Jet Propulsion Laboratory, Pasadena, California specializing in satellite observations of the atmosphere.  His scientific interests include planetary boundary layer processes, tropical phenomena, upper tropospheric variability, and climatologies of temperature, water vapor and clouds.  His technical interests include analysis of large data sets, and of multi-sensor observations. He has over 20 peer-reviewed publications and given numerous scientific presentations, public lectures and media interviews about climate science. Eric received a B.A. in Physics from the University of California Berkeley, and a Ph.D. in Astrophysical, Planetary and Atmospheric Sciences from the University of Colorado, Boulder   Amy Braverman is a Senior Statistician at the Jet Propulsion Laboratory, California Institute of Technology She holds a B.A. in Economics from Swarthmore College an M.A. in Mathematics from UCLA, and a Ph.D. in Statistics also from UCLA. Prior to her current position in JPL's Science Data Understanding Group, she was a Caltech Post-doctoral Scholar at the Jet Propulsion Laboratory, and a Scientist in the Flight Sciences Experiments Section of the Science Division. Dr Braverman conducts research on information-theoretic methods for the analysis of massive data sets and streams statistical data fusion, high-dimensional data analysis, and statistical analysis for climate model evaluation and diagnosis. She has published in both the statistics and geoscience literature, and is active in both communities She is a member of the Multi-angle Imaging SpectroRadiometer Science Team, and serves as a member of the Atmospheric Infrared Sounder Science Integration Team. Her responsibilities on both missions include designing data reduction algorithms for massive, remote sensing data sets. Dr. Braverman also holds an appointment in the Department of Statistics at UCLA as Adjunct Associate Professor, and is active in UCLA\222s Center for Environmental Statistics. She is member of the Committee on Applied and Theoretical Statistics of the US National Academy of Science. She has refereed for the Journal of the American Statistical Association, the Journal of Computational and Gr aphical Statistics, IEEE Transactions on Geoscience and Remote Sensing, and the Journal of Applied Meteorology and Climatology Seungwon Lee is a senior member of the High Capability Computing and Modeling Group at Jet Propulsion Laboratory. She is conducti ng research on comet gas dynamics, nonlinear dynamics control, climate model parameterization, Earth science data analysis, parallel computing, and advanced numerical algorithms. She received her Ph.D in Physics fr om the Ohio State University and her M.S. and B.S. in Physics from the Seoul National University, Korea  Matthew Henderson is software engineer in the High Capability Computing and Mode ling group at JPL. His current work includes Web Services and Instrument Data Level 2 subsetting. He received a B.S. Computer Science from CSU Pomona, and is currently pursuing M.S Computer Science  Steven J. Lewis is a member of the Information System and Computer Science staff member at the Jet Propulsion Laboratory.  He received a BS in Mathematics from the University of California, Los Angeles in June 2001, and the MS and Ph.D. Degree from Claremont Graduate University in May 2004 and May 2007, respectively.  He worked as a post doctoral fellow at Keck Graduate Institute from June 2007 until he joined JPL in March of 2008.  During his graduate and post doctoral work, his studies focused on applications of Bayesian methods to hidden Markov models with particular interest and application to protein sequencing.  His work at JPL has focused on integrating web services into various programming platforms for the purposes of accessing NASA satellite data, as well as developing object tracking so ftware and contributing to image enhancement and restoration efforts Van Dang is a member of the Science Data Understanding Group at the Jet Propulsion Laboratory. She was responsible for the NEWS Level 2 processing that generated the formal merged Level 2 data from multiple A-Train instruments  Manuel de la Torre is a Physicist from the Universidad Complutense at Madrid \(Spain\. After finishing his Ph.D work at the University of Bayreuth \(Germany\ on pattern formation in turbulent flows and a 7 1/2 year stunt as Ass and Assoc. Prof. at the Escuela T\351cnica Superior de Ingenieros Aeron\341uticos in Madrid \(Spain\, he came to the Jet Propulsion Laboratory on a 1-year Sabatical leave in 1997 wanting to apply fundamental concepts of nonlinear systems and geophysical fluid dynamics to something that might be directly useful to soci ety. He discovered the JPL as a great place to achieve that goal and extende d his stay a bit longer, becoming Technical staff and working on different aspects of remote sensing, validation of satellite instruments, and data analysis of atmospheric processes and climate  


