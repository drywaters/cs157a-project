1 Utilizing Fuzzy OLAP Mining Towards Novel Approach to Multiagent Modular Reinforcement Learning Mehmet KAYA Department of Computer Engineering Firat University 23119 Elazig, TURKEY kaya@firat.edu.tr Reda ALHAJJ ADSA Lab & Department of Computer Science University of Calgary Calgary, Alberta, CANADA ucalgary.ca Abstract vel multiagent learning approach for modular cooperative rporates fuzziness and online analytical processing \(OLAP\ based mining to effectively 
we describe a fuzzy data cube OLAP architecture to facilitate ate information y, the action of the other nt, even not in the visual environment 001 the agent ly be predicted by s from the constructed data cube. Second, we present a new action selection les mining. Finally ates, by les from the proposed s obtained on a well 
it domain show the robustness and effectiveness of the proposed approach Index Terms data cube, data mining, fuzziness multiagent systems, OLAP, reinforcement learning 1. Introduction ch to model multiagent learning is to augment the state of each agent with the information ts [14, 17  H o w e ve r  a s  t h e  number of agents in a multiagent environment increases lly. This ems become computationally intractable by standard reinforcement learning approaches. In order to remedy the problem of 
osion in multiagent reinforcement learning, some methods have been proposed including modular architecture and generalization of states. Most of  widely used method in multiagent learning. However, it s, including modeling other learning agents and experiencing some states less than others 001 Visual depth is assumed 6 in this paper, unless otherwise specified during the learning phase. Having some states not  
e. On the nd, an agent cannot exhibit a certain behavior in may be experienced sufficiently before ting the learning process In order to handle these problems, in this paper we ure and learning approach for multiagent systems. The proposed approach alytical processing \(OLAP based association rules mining [2, 7 a n d mo d u l a r i t y  in to   s effective storage and ng of the state information reported by agents 
her agent, even not in the ronment of the agent under consideration, can es w action selection model, which is also based on association rules mining. Finally, we generalize not sufficiently experienced states, by mining multi-level association rules from the proposed fuzzy data cube. Experimental domain show the ss and effectiveness of the proposed fuzzy OLAP mining based modular learning approach. Finally, we ch presented in this 
r and compared it with our previous work on learning [11, 12  this per can be summarized as follows: 1\ integrating the ss and association rules mining; 2\ defining a fuzzy data cube for both the internal model database and the database holding er agents even when they are not seen in the visual es be; 4\electing the e action of the agent under consideration by 
using association rules mined from the constructed fuzzy be; and 5\generalizing states by mining multilevel association rules from the constructed fuzzy data cube in order to effectively accomplish the capturing task The rest of the paper is organized as follows. Section 2 nd and related work Proceedings of the IEEE/WIC/ACM International C onference on Intelligent Agent Technology \(IAT\22204 0-7695-2101-0/04 $ 20.00 IEEE 


2 Section 3 describes a variant of the pursuit problem, to be this  scuss the results of the experiments conducted for the considered lusions 2. Background and Related Work 2.1 Q-Learning Algorithm lects an action based on an action-value function, called Qich is updated using the agent\222s experience Definition 1 \(Q-function ven action a in state s and reward r e Q-function of a in s denoted Q  s  a s formally defined as   max 1 365\365 Aa asQrasQasQ 365 002 212 003 004 004  where A is the set of all possible actions 004 0 005\004 1\nd 003 0 005\003\005 nt parameter spectively; and  ll asQ is value of action a l in state s l  2.2 Fuzzy Association Rules ven a set of items I an association rule is a correlation of the form X 006 Y where IYX 007  U and b   YX I nded meaning of X 006 Y is that when a saction t i 007 I contains the items in X then it is ems in Y as well. A rule is generally rated according to several criteria, none of which should fall below a certain threshold ortion of transactions present in D and contain YX U e sup YX DYX U 006 or     sup D D YX YX U 006 Confidence is applications of the rule, i.e    X YX D D YX conf U 006 where D X   T 002 D  X 007 T denotes  D and contain items in X  and D X is its cardinality e to humans because of the linguistic terms associated with fuzziness [4, 6 To de f i n e f u zzy as s o c iatio n r u le s   ven a database of transactions T  t 1  t 2  311  t n its es I and the fuzzy sets es in I Each transaction t i contains values of some attributes from I and each attribute in I s at least two corresponding fuzzy ng form for fuzzy association rules   If X  x 1 x 2 x p is A  f 1 f 2 311, f p then Y  y 1 y 2 311, y q is B  g 1 g 2 311, g q   where A and B contain the fuzzy sets associated with onding attributes in X and Y respectively, i.e f i is e x i and g j is the fuzzy set bute y j Finally, for a rule to be interesting ld have enough support and high confidence s  r learning agent is explicitly considered. For instance, Littma  2-player zero-sum stochastic games for and Wellman  introduced a different multiagent reinforcement learning ver her on, the agent under consideration should ons and the actual rewards received from the environment. Also, the former agent er t. Then, Nagayuki et al  p r o p o s e d a n o t h e r em; their learning method is th one agent estimates the ead of Q-function. Thus, there is rewards received from the environment, and to know the e other agent uses for Q-learning Finally, Ishiwaka et al 1 r e s e n t e d a m e t h o d f o r t w o ting in pursuit domain. One of these predictions is the location of the other hunter and prey agents, and the other is the ep. For this reason, they performed some experiments on a continuous action state space and showed the effectiveness of their approach In a previous work [11  w e pr o p o s e d a n e w a n d  ly combining advantages of the modular approach, fuzzy logic and the internal model a b Fig. 1 Sample \(a\ initial position; \(b\ goal state 3. Problem Domain Samples of the multiagent environment considered in is a variant of the it domain. It has the following stics. First, it is fully dynamic, partially Proceedings of the IEEE/WIC/ACM International C onference on Intelligent Agent Technology \(IAT\22204 0-7695-2101-0/04 $ 20.00 IEEE 


3 observable and non-deterministic. Second, five agents ist in an n 327 n grid world as ial position of each agent is determined randomly. Third, at each time step, agents ve actions: staying at ng from the current position e hunter agent r, a hunter cannot share a cell with the prey. Also, an agent is not allowed to move off the environment. The latter two moves are considered illegal and any agent that tries an illegal move is not stay in its current ers are learning agents and the prey d or an d hunters. Fourth, every agent can see objects at a certain distance. The distance and the cells sual depth and the sual environment of the agent. A hunter can locate the her ronment. Finally, the prey is captured, either when the hunter agents occupy its four neighbor positions as shown in Figure 1-b, or when it is surrounded by hunter agents and the border of the environment \(at one of the four corners\. Then, the prey and all the four hunters are relocated at new random positions in the grid world and the next trial starts 4. Fuzzy Association Rules Based Modular Reinforcement Learning 4.1 Fuzzy Data Cube Construction Consider a quantitative attribute, say x it is possible to ne at least two corresponding fuzzy sets with a membership function per fuzzy set such that each value of bute x es to be in one or more of the fuzzy sets specified for attribute x  p  bute x and let  21 l xxxx fffF  be a set of l fuzzy sets associated with x  j x f 265 on of the j th fuzzy set j x f in x F it  is a mapping from the domain of x 0,1  F o r m al ly    1  0  006 x f Domain j x 265 For every value v of x if 1  v j x f 265 then v totally and certainly belongs to fuzzy set j x f e other hand 0  v j x f 265 means that v is not a member of the fuzzy set j x f tween 0 and 1, exclusive degree  finition 2 is used in building a fuzzy data cube as outlined next Definition 3 \(Fuzzy Data Cube  with n dimensions, and given an association rules mining ved with dimensions d 1  d 2 205 d n of the data cube. Each dimension of the cube contains 1 1  000  k i i l slots where k es in dimension X  i l is the number of membership functions \(fuzzy sets\ for bute x i in dimension X and \223+1\224 in the formula ores the s. These lues show one of the essential features of    D  down  middle  up right up No t Av a ila b l e  down  middle  up right up Not Available 1 other a 2 other a 3 other a 4 other a 5 other a   Hunter Prey Action Both Not Available C ount 2 Count 1 Count 3 tal Count 000\000\000\000 000\000\000\000 000\000\000 000\000\000 000\000\000\000 000\000\000\000 000\000\000\000 C 000\000\000\000 000\000\000\000 000\000\000\000 000\000\000\000 000\000\000\000 000\000\000\000 000\000\000\000\000\000\000 000\000\000\000 000\000\000\000 000\000\000\000 Count 3 AB Fig. 2 The proposed fuzzy data cube to hold internal model related knowledge ace fferent ed the state space of the hunters with fuzzy internal model approach [11, 12 I n  the study described in this paper, we facilitate viewing the relationship between the actions and the state space of fferent perspectives by extracting interesting rules from the fuzzy data cube gure 2 is a fuzzy data cube with three er agent. Two dimensions of this cube deal with the states of the hunter and the prey in the hunter\222s visual presents the action space of the other hunter. In the fuzzy data cube 2, the dimensions concerning the state space are values of the two coordinates x and y such as  left  down  n d left  middle   w h er e left shows the x whereas down and middle present the y coordinate. Finally, each cell of the cube shown in Figure spect to the observed action of the other agent and states Proposition 1  ring Rate Computation Consider a fuzzy data cube with 3 dimensions, if the location of the ip degrees  hunterother x 265 and  hunterother y 265 along the x and y spectively; the location of the prey has corresponding membership degrees  prey x 265 and  prey y 265 spectively; and the s membership degree   hunterother action 265 then the sharing rate of all the Proceedings of the IEEE/WIC/ACM International C onference on Intelligent Agent Technology \(IAT\22204 0-7695-2101-0/04 $ 20.00 IEEE 


4 ed as      hunterotherpreyhunterother action statestate 265 265 265 where    hunterotherhunterotherhunterother yx state 265 265 265  and    preypreyprey yx state 265 265 265   del Data Cube of the work already done on multiagent learning assumes a stationary environment, i.e., the behavior of the e environment. Whereas c environment in arns and each other agent may change its behavior with time too. In such a case, the standard Q-learning approach is not appropriate In the work described in this paper, as a given agent on, we also consider the other agent\222s have an internal model er agent oying a fuzzy logic l model data cube, as presented in the previous section gure 2. In this cube, as long as a hunter agent observes new states during her d. So, as  calculated with respect to the given state and the observed action. Finally, in order to explicitly express the dependency of the other agent\222s action, the hunter\222s Qfunction is adjusted according to the formalism given next 4 4 Function\  Consider a hunter h 1 which tries to estimate the action of an agent h 2 The ted as   other self aaSQ where S er h 1 can observe  selfself Aa 002 and  otherother Aa 002 are actions of h 1 and h 2  respectively; here self A and self A represent sets of all ble actions for h 1 and h 2 spectively.  Let  max arg   other Aa other asFa otherother 002      preypreyprey yx state 265 265 265  and    hunterotherhunterotherhunterother yx state 265 265 265   then   max        1      other self k Aa other self k other self k aasQr hunterotherprey aasQ hunterotherprey aasQ selfself 002  212\t 003 265 265 004 265 265 004 ding on whether the ven agent is good or not depends on the other words other a is a hidden and major factor in selecting the action self a In this study the action other a sed on the association rules extracted from the constructed data cube. If one hunter observes the other hunter in its visual ronment, then the association rule other aS 006 can be st e hunter could not perceive the other hunter, a prediction is done based on ng proposition in order to estimate the direction of the action of the unseen other agent on of the unseen hunter Consider two hunter agents h 1 and h 2 and a prey agent P if h 1 sualize h 2  while P in sual environment of h 1 then the action of h 2 to the general trend of the actions taken by h 2 in the visual environment of h 1 when P was at the same location For instance, assume that the prey is at location [6, 6  sual environment. In this case, a cell of row C of the data cube to row D  which shows the number of times the prey visited location 6  r e ga rdl e s s o f t h e po s i t i o n o f t h e o t h e r  h u nt e r   bed in Section 2.3, the user specifies at the beginning of the learning process a minimum support value for the action count, indicated as count3 in Figure 2. If the count value of a state reaches this minimum support value, then it is rienced sufficiently r consideration to the herwise, if a state is not experienced sufficiently, then the agent under her agent with spect to the user specified confidence value. If the ction pair is less than the user specified minimum confidence value, then such lected in the corresponding state. Also, if actions exceeding the minimum bility of selecting an action a i is computed as  000 002 006 006      MinConf Aa j i i j aS conf aS conf Sap where  i aS conf 006  i aS 006 and  MinConf A is the possible set of actions that exceed the minimum confidence value of the onding agent. At the beginning of the learning stage, the minimum confidence value is set to 0%. Then gger value to let the agents learn the special properties of different ronment is encouraged at the early stages of the learning process lar Learning In this section, we present our approach of utilizing the constructed fuzzy data cube in mining OLAP association p, and hence guide agents in making their decisions on the next move e Proceedings of the IEEE/WIC/ACM International C onference on Intelligent Agent Technology \(IAT\22204 0-7695-2101-0/04 $ 20.00 IEEE 


5 ers. The l her agents to contain the Q-values of the learning process. The mining process employed for this purpose is described in Algorithm 1 Table 1 A part of a snapshot of the fuzzy data cube at a particular moment of the learning process Action State 1 self a 2 self a 3 self a 4 self a 5 self a count  s 0 5 other a  52.125 94.657 24.696 83.232 34.763 128.10 s 1  5 other a  74.632 19.632 13.698 92.820 69.834  s 2  5 other a  91.852 64.633 25.367 41.140 80.978 462.10 s 3  5 other a  69.854 78.012 96.325 53.901 12.658  S 1 Total\(S 1  288.463 256.934 160.086 271.093 198.233 717.53    s 0 2 other a  23.478 87.412 74.987 54.410 92.103 514.0 s 1 2 other a  8.954 91.789 73.587 45.031 76.657 97.8 s 2 2 other a  72.683 54.312 37.189 87.205 10.002 214.0 s 3 2 other a  94.127 51.978 7.014 46.879 34.478 310.6 S n Total\(S n  199.242 285.491 192.777 233.525 231.240 1136.4 Algorithm 1  Mining Based Multiagent Learning learning process involves the following steps 1 The hunter under consideration observes the current state S and estimates the other agent\222s action other a based on the association rules extracted from the fuzzy data If the occurrence number of S is greater than the minimum support value, then action other a  lected. If the occurrence number of S  support value, then the action other a d on the value of  Sap i tions exceeding the minimum confidence value in state S at that moment 2 The action self a ed according to the estimated value other a For instance, Table 1 shows a part of a of the data cube at a certain moment of the each cell gives the Q-value of  indicates the number of occurrences of the of chosen other a assume that 5 other a is chosen\. In a way similar to the previous association rules mining process, if the total count value of a state5 other a ir is greater than or equal to the before, then it is e and 5 other a were experienced sufficiently. In this case, the hunter agent the highest confidence value 3 Each cell in the row Total\(S 1  in Table 1 shows the sum of Q-values of the corresponding stateself a pair in  5 other a is chosen. If the state5 other a pair is not on with respect to  000 selfself aSQap 1  4 en found for all the er under consideration executes the action self a selected by the mediator rule miner. The action is chosen based on the criteria 000   002 3 1 l i other self i Aa aaSQ selfself  max arg 5 tion  other a  6 The environment changes to a new state  S 7 The hunter under consideration receives a reward r  as follows 7.1 All the cells     other k aSsF 002 are updated in the fuzzy internal model data cube 7.2 All the cells     other self k aaSsQ 002 d according to Definition 4 8 w state  S es a terminal condition, then l. Otherwise, let SS 006  and 1 Up Not Available left right Not Available 1 other a 2 other a 3 other a 4 other a 5 other a Hunter Prey Action Both Not Available Total Total Total Total Sum Total 000\000\000 000\000\000 000\000\000\000\000 000\000\000\000\000 000\000\000 000\000\000 000\000\000 000\000\000 middle 000\000\000 000\000\000 000\000\000 000\000\000\000\000\000 000\000\000\000\000\000 000\000\000\000\000\000 000\000\000\000\000\000 Middle Down  Fig. 3 The cube generated from rolling up 4.4. State Generalization by Mining MultipleLevel Fuzzy Association Rules s showed that when the learning process is over, some state-action pairs are experienced sufficiently d according to the escaping sed ronment. In ent to mine association rules. In such a case, the information or the data is generalized from low levels to higher levels gure 3 is obtained by Figure 2 along the two dimensions Prey and Hunter gies of reshold for different levels of reshold is to be changed at different levels W e de c i de d t o us e  minimum support at lower levels, where lower Proceedings of the IEEE/WIC/ACM International C onference on Intelligent Agent Technology \(IAT\22204 0-7695-2101-0/04 $ 20.00 IEEE 


6 levels of abstraction use smaller minimum support values this is the common trend for most work on OLAP mining 5. Experimental Results the es d on s in the main factors that affect the learning process: minimum support, minimum al depth. All the experiments have been conducted on a Pentium III 1.4GHz CPU with 512 MB of memory and running Windows 2000. Further, the learning process in the experiments consists of a series of trials and each reported result is the average value over 10 distinct runs. Each trial begins with a single prey and four de the domain and or at 2000 time ly receive a reward=100 upon capturing the prey To show the effectiveness and applicability of the per, we compare it with our learning [11  of this section y, we used the learning rate 004 0.8, discount factor 003 0.9, the initial value of the sual depth of the agents is set was riments, the x axis presents the number of trials and the y axis gives the d to capture the prey  0 250 500 750 1000 1250 1500 1750 2000 0 5000 10000 15000 20000 25000 30000 35000 0 45000 50000 Trials A v er a g e T i m e  S t eps MinSup6K\(Conf 0%->20 MinSup6K\(Conf 10%->20 MinSup8K\(Conf 0%->20 FQ L Fig. 4 Learning curves of hunters for different values of minimum support and confidence e the learning curves for different minimum support and 4 d sponds to FQL. It can be easily seen from Figure 4 that learning curve labeled MinSup6K\(Conf 0 006 e set er than MinSup8K\(Conf 0 006 20%\ although the s. On the other hand when the minimum support value is fixed at 6K and the minimum confidence value is changed from 10% to 20 steps to capture the prey because the agent is not given the scover its environment enough as in the when the minimum confidence starts at 0%. The e advantage of the proposed approach over FQL in terms of average steps and number of trials 0 250 500 750 1000 1250 1500 1750 2000 0 10000 20000 30000 40000 50000 Trial s Av er a g e T i m e S t e p s FS3VD6 FS3VD8 FS4VD6 FS4VD8 Fig. 5 Effect of the change in visual depth and number of fuzzy set of the number of fuzzy sets and the value of visual depth. Here we compared four different cases namely, FS3VD6 FS3VD8, FS4VD6 and FS4VD8, where FS and VD sual al h and the number of fuzzy sets are set at 4 and 8 d that the decision space s. However, the hunter s a larger area On the other hand, by selecting the number of fuzzy sets a ss convergence steps dicated to investigate the multiple levels case, and the main goal is to generalize rienced enough with the s the environment from a higher level and decides on the best s, the number of fuzzy sets is depth of the agents is set to 6. The Figure 6 and Figure 7 fferent total count values \(200K and 250K\and two different minimum support values \(6K and 8K\. When the total count values reach the pre-determined threshold value and the minimum support value of the current state is below the threshold, the agent goes up to a high level in order to get more general information from the environment when only states of the hunter agents are generalized, Figure 7 shows states of both the prey and the hunter 7 es of the prey and the hunter agents together Proceedings of the IEEE/WIC/ACM International C onference on Intelligent Agent Technology \(IAT\22204 0-7695-2101-0/04 $ 20.00 IEEE 


7  0 250 500 750 1000 1250 1500 1750 2000 0 5000 10000 15000 20000 25000 30000 35000 40000 45000 50000 Trials A v er ag e T i me S t ep s talCount K talCount K talCount K FQL Fig. 6 Learning curves when only states of hunter agents are generalized 0 250 500 750 1000 1250 1500 1750 2000 0 5000 10000 15000 20000 25000 30000 35000 40000 45000 50000 Trials A v er ag e T i m e S t ep s talCount K talCount K Fig. 7 Learning curves when states of both prey and hunters are generalized 6. Summary and Conclusions per, we proposed a novel multiagent d on fuzzy OLAP association rules mining. For this purpose, we started by t concept into the state space in order to decrease the number of states that an agent could encounter. Then, we defined a fuzzy data cube for holding ronment related information obtained by agents By using this cube effectively, we extracted fuzzy association rules from the previous actions of agents Based on these rules, we handled two important problems nt learning. First, we er agent, even when environment of the agent under consideration. Second, we presented a new action  appropriate action. For this purpose, we generalized the states that were not experienced sufficiently. In fact lt problem in general c attributes of the problem. However, experimental results obtained the proposed fuzzy OLAP mining based learning approach is or of multiagent systems. Currently, we are investigating the possibility of ems that require continuous state space and to develop and improve different corresponding algorithms References 1 O A b u l, F  P o la t a n d R  A l h a jj 223 M u l t i a g e n t re in f o rc e m e n t  ng using function approximation,\224 IEEE SMC-C  Vol.30, No.4, pp.485-497, 2000 2 R  A l ha j j an d M K a y a  223I nt eg r a t i ng Fuz z i nes s i n t o O L A P  for Multidimensional Fuzzy Association Rules Mining,\224 IEEE ICDM Melbourne, FL, Nov. 2003 3 C  C  A g g a r w a l a n d P  S  Yu  223 A Ne w A p p r o a c h t o On l i n e  Generation of Association Rules,\224 IEEE TKDE Vol.13 pp.527-540, 2001 4 W  H  A u a n d K  C  C  C h an  223Mi n i n g F u zz y A s s o ci a t i o n  Rules in a Bank-Account Database\224 IEEE Transactions on Fuzzy Systems 238-248, 2003 5 S  C h au dhu r i a nd U  D a y a l  223A n o v e r v i e w of dat a g and OLAP technology,\224 ACM SIGMOD Record 65-74, 1997 6 M  D e l g ado  et al  223F uz zy  A ssoc i a t i o n R u l e s G ener al  Model and Applications,\224 IEEE TFS No.2 pp.214-225, 2003 7 J. H a n  223 O L A P Min in g   A n  I n te g r a tio n o f OL A P w ith D a ta  Mining,\224 Proc. of IFIP International Conference on Data Semantics 11, 1997 8 J. H a n  a n d Y  F u 223 M in in g m u l tip le l e v e l a sso c i a t io n ru le s  in large databases,\224 IEEE TKDE No.5, pp.798804, 1999 9 J  H u  and M  P  W e l l m a n   223M ul t i ag ent r e i n f o r c em ent  learning: theoretical framework and an algorithm,\224 Proc. of ICML 250, 1998  Y  I s hi w a ka  T   Sa t o and Y  K a kaz u  223A n appr o a c h t o t h e   using reinforcement learning,\224 Robotic and Autonomous Systems 256, 2003  M K a y a and R  A l ha j j  223 M o dul ar F u z z y R e i n f o r c em ent  Learning Approach with Internal Model Capabilities for Multiagent Systems,\224 IEEE SMC-B Vol.34, No.2, 2004  M K a y a and R  A l haj j   223R e i nf o r c e m e nt L ear n i ng i n  Multiagent Systems: A Modular Fuzzy Approach with Model Capabilities,\224 Proc. of IEEE ICTAI  Washington DC  Nov. 2002  C  M  K u o k  A  W  Fu and M  H  W o ng  223M i n i n g f u zz y  association rules in databases,\224 SIGMOD Record Vol.17 pp.41-46, 1998 14 M  L  L i tt ma n  223 M a r k o v g a me s a s a fra me wo r k fo r  reinforcement learning,\224 Proc. of ICML  pp.157-163, San Francisco, CA, 1994  Y  N a g a y uki  S  I s hi i and K  D o y a  223Mul t i A g ent  reinforcement learning: An approach based on the other agent\222s internal model,\224 Proc. of IEEE MAS pp.215-221 Boston, 2000  N  O n o and K  Fuko m o t o  223Mul t i a g e nt r e i n f o r c em ent  learning: A modular approach,\224 Proc. of IEEE MAS pp.252-258, 1996  T  W  San dho l m and R  H  C r i t es  223 M u l t i ag ent  reinforcement learning in the Iterated Prisoner\222s Dilemma,\224 Biosystems 166, 1995  M T a n  223 M u l t i ag ent r e i n f o r c em ent l ear ni ng i ndep end ent  vs. cooperative agents,\224 Proc. of ICML 330-337, 1993 Proceedings of the IEEE/WIC/ACM International C onference on Intelligent Agent Technology \(IAT\22204 0-7695-2101-0/04 $ 20.00 IEEE 


to decide the optimal parameters values are expressed as 1 1   this way the optimal operation parameters are decided according to the load and the other related condition. The optimization values attained from data mining are reachable in operation and can reflect the actual status in operation According to the method mentioned above, the history data from recent three months are analyzed. A total of 4212 transactions consisted of the operation parameters of the typical stable load of 100%, 90% and 80% are obtained These transactions are standardized by formula \(1 minimum support value is set at 30% and the minimum confidence is set at 75%. The membership function of the parameters is shown in Figure 2 75 82 86 92686458  1 Low Middle High 0.5  Figure 2. The membership function 1645 Proceedings of  the Fourth International Conference on Machine Learning and Cybernetics  Guangzhou, 18-21 August 2005 minimum confidence. This rule can be expressed as The corresponding range is This rule means that when the load is 300MW and the coal consumption is lower the optimal range of the excessive air coefficient is 1.342~1.350. The average of the interval can be adopted to decide the optimization point. The optimization value of excessive air coefficient 100 ,34.5,35.7eM ?&lt; &gt;?&lt 300 ,1.34eM MW ?&lt; &gt;?&lt gt gt;2,1.350 is set at 1.346 when the load is 300MW \(100 the method mentioned above, by utilizing the fuzzy association algorithm to mine the optimization value when the typical load of 100%, 90% and 75%, etc, a set of optimization values is obtained. The optimal values attained from the fuzzy data mining and the reference values attained in traditional way are listed in Table 1 300MW 16.67 Referenc Optimal Parameters Main steam temperature Reheat temperature Feed water temperature Flue gas temperature Excessive air coefficient Main Steam Pressure MPa 537 537 270.5 138.4 137.1 1.352 1.346 16.71 538.3 538.1 


538.1 268.1 270MW e/ Referenc Optimal 16.67 537 537 264.2 135.2 133.6 1.432 1.431 16.66 538.1 537.4 264.6 Table 1. Optimization value analysis result of 300MW power unit 225MW e/ Reference Optimal 13.89 537 537 254.1 129.8 130.4 1.480 1.484 13.96 537.2 535.4 258.4  The controllable parameters are optimized based on the results of the fuzzy data mining in power plant. The performance of the boiler improved obviously. The average boiler efficiency improved about 0.924% and the coal consumption reduced about 3.72g/kW.h. The optimization value is close to the reference value in trend and can be used to guide the industry process. The newly founded rules and knowledge can be added to model base or the knowledge base. The operation optimization base on data mining is an effective method to improve the efficiency in power plant The execution times of fuzzy association mining in different minimum support with a computer Pentium 1.7G/256M are shown in Figure 3. For a total of about 4000 transactions in the data set and the minimum support is set at 20%, the execution time is about 150s. The fuzzy association mining is high efficiency. The execution time of fuzzy association mining increases linearly with the transactions in data set. So it is applicable to large data sets 80% 60% 40% 20 50 100 150 200 minimum support tim e s  Figure 3. The time of fuzzy association mining in different minimum support 5. Conclusion The operation optimization is the mainly method to improve the performance in power plant and the decision of optimization value is the key point in operation optimization. In this paper, we proposed the operation optimization based on data mining and applied the fuzzy 


optimization based on data mining and applied the fuzzy association rules to find the optimization value from the history data of the equipments in power plant. The fuzzy sets theory was introduced into the association mining process in order to soften the partition boundary of the domain and generalize and abstract the data. Base on the history data in power plant, the optimization values are reachable in operation and easy to guide operation. The rules mined out exhibit quantitative regularity in large database and can be used to provide guides and suggestions to the appropriate operator. Experimental results with the data in a 300MW power plant show that the algorithm base on fuzzy set operation performs very well and can be used to guide the operating process to achieve a good performance References 1] Wang X Z  Automatic classification for mining process operational data  Ind. Eng. Chem. Res., 37 pp.2215-2222, 1998 2] Tony Ogilvie, B W Hogg  Use of data mining techniques in the performance monitoring and operation of a thermal power plant  IEEE Colloquium on Knowledge Discovery and Data Mining, 1998 3] Ren HaoRen, Li Wei  The analyze of operation index for the power unit under different loads  Proceedings of the CSEE, Vol 19, No. 9, pp.50-52,56, 1999 4] Agrawal R, Imielinski T, Swami A  Mining 1646 Proceedings of  the Fourth International Conference on Machine Learning and Cybernetics  Guangzhou, 18-21 August 2005 association rules between sets of items in large database  Proc of the ACM SIGMOD conf on Management of data, Washingtong D.C, pp.207-216 May 1993 5] Agrawal R, Srikant R  Fast algorithms for mining association rules in large databases  The International Conference on Very Large Data Bases, Santiago, Chile pp. 487-499, 1994 6] Srikant R, Agrawal R  Mining quantitative association rules in large relational tables   Proceedings of the ACM SIGMOD International Conference on Management of Data, Montreal Canada, pp.1-12, 1996 7] Zou XiaoFeng, LU JianJian, Song ZiLin  Mining linguistic valued association rules  Journal of System Simulation, Vol 14, No. 9, pp.1130-1132, 2002 8] T. P. Hong, J. B. Chen  Finding relevant attributes and membership functions  Fuzzy Sets and Systems Vol 103, No. 3, pp.389-404, 1999 9] T.P.Hong, C.S.Kuo, S.C.Chi  Mining association rules from quantitative data  Intelligent Data Analysis, Vol 3, No. 5, pp.363-376, 1999   1647 pre></body></html 


0-7695-2263-7/05 $20.00  2005 IEEE pre></body></html 


n M L N n t n t n t n t L M L t L t L tt L t kkkk kkkk kkk kkkk kkkkkkkkP VK VK VK VK PP       kkP t 31 where L  s the error covariance associated with the state estimate t i    kkLX  tt kkk P1  00 0  0                     s s sss s s sss s s sssss N n t n t n 


n t n N n t n t n t n N n t n t n t n t n t n c t L kkkkkk kkkkk kP VKVK VKVK  32 4. Simulations One has run simulations comparing the sequential implementations of MSJPDA algorithm and the new algorithm here. A typical multisensor multitarget tracking environment is assumed in the simulations. According to article [1,3], One known that the performance of sequential MSJPDA is better than the performance of parallel MSJPDA. Therefore, the performance of parallel MSJPDA algorithm will not be compared here There are three sensors, which are fixed in three platforms. Regarding the 2nd sensor as fusion centre situation of the other sensors are: =?-500m?-500m 0m??N =?-500m? 500m?0m??The distance error of each sensor is: =300m, =200m, =100m?The bear error of each sensor is 0.03rad, =0.02rad, =0.01rad?The of sample is T=1s?The nonparametric model of clutter is used in the simulations, and expected number of false measurement is m=1.8 1 sN 3 s 1r 2 2r 3 3r 1 Simulations have been run for racking two targets. The true initialization state of the targets is X1?[-29500m,400m/s,34500m,-400m/s X ?[-26250m,296m/s,34500m,-400m/s]'? 2 The two targets will cross above 31seconds later. To evaluate tracking performance, 50 Monte Carlo runs were performed for three case of the target detection probability Pd=0.97 ? Pd=0.76 ? Pd=0.58. In every run, the total simulation time is 140 steps 


simulation time is 140 steps            Figure 1  RMS position error in case of Pd=0.97          Figure 2  RMS velocity error in case of Pd=0.97       Figure 3  RMS position error in case of Pd=0.76 567 Proceedings of  the Fourth International Conference on Machine Learning and Cybernetics  Guangzhou, 18-21 August 2005         Figure 4  RMS velocity error in case of Pd=0.76         Figure 5  RMS position error in case of Pd=0.58          Figure 6  RMS velocity error in case of Pd=0.58  Table 1 The emanative times comparison for sequential MSJPDA and SD-CMSJPDA algorithm  Pd N A  0.97 0. 76 0.58 Sequential MSJPDA 2 11 17 SD-CMSJPDA 0 3 5 Pd denotes detection probability, N denotes emanative 


Pd denotes detection probability, N denotes emanative times, A denotes the kind of algorithm Table 1 shows the summation of emanative times for sequential MSJPDA and SD-CMSJPDA algorithm in 50 Monte Carlo simulations. From table 1 , it is shown that the stability of SD-CMSJPDA is better than that of sequential MSJPDA as the detection probability varied Figure 1,2 show the RMS errors for position and velocity in case of Pd=0. 97, respectively; Figure 3,4 show the RMS errors for position and velocity in case of Pd=0.76 respectively; Figure 3,4 show the RMS errors for position and velocity in case of Pd=0.58, respectively. From the figures we can see that the average RMS position error is lower for the SD-CMS JPDA algorithm. We also see that the state estimation precision of sequential MSJPDA get worse as the detection probability decreases The reasons for these simulation results lies:1 state estimation precision will get worse when the detection probability decrease;2 algorithm is to process measurement from each sensor using single sensor JPDA algorithm sequentially. Therefore the estimation error from each sensor will be accumulated Moreover, the sequential MSJPDA algorithm can  t improve the joint detection probability of the multisensor system The estimation error of the SD- CMSJPDA  algorithm will not be accumulated for it processes the measurement from each sensor directly in the mean time .What  s more the new method can greatly improve the joint detection probability of the multisensor system. Therefore, the tracking performance of SD-CMSJPDA algorithm is better than that of sequential MSJPDA. Algorithm All of the simulations are run in the personal computer with a 2.0G CPU and a 256M memory. The average cost time per step is 0.0251 in the sequential implementations of MSJPDA algorithm. And the average cost time per step is 0.0282 in the sequential implementations of MSJPDA algorithm. According to the results we can see that there is few difference in real time between the new method and the sequential   MSJPDA when there is not so many sensors and targets 568 Proceedings of  the Fourth International Conference on Machine Learning and Cybernetics  Guangzhou, 18-21 August 2005  5. Conclusion In order to solve the problem of multisensor multi target tracking, a new centralized multisensor  joint probabilistic data association  algorithm is proposed in this paper. The simulation results shows that the tracking performance of the new algorithm is better than that of the sequential MSJPDA algorithm The computational complexity of the new method will increase as the number of sensors and targets grow Therefore, how to improve the real time of SD- CMSJPDA algorithm will be pay attention References 1] He You, Wang Guohong, Lu Dajin, Peng Yingning Multisensor Information Fusion With Application[M Publishion House of Electronics Industry. 2000, Beijing.  [11] B..Zhou and N.K.Bose Multitarget  Tracking in Clutter:Faste Algorithms for Data Association .IEEE Transaction on Aerospace and Electronic Systems 1993,29\(2 2] Bar-shalom,Y\(Ed Applications and Advances,2: Norwood,MA Artech  House, 1992 3] L.Y. Pao, C.W.Frei. A Comparison of Parallel and Sequential Implementation of a Multisensor Multitarget Tracking Algorithm. Proc. 1995 American Control Conf. Seattie, Washington,June 1995 1683~1687 


4] K. Chang, C. Chong, Bar-Shalom, Joint Probabilistic Data Association in Distributed Sensor Networks IEEE Transactions on Automatic Control, AC-31\(10 octobre 1986 5] Bar-shalom, Multitarget Multisensor Tracking Advanced Application ,:YBS Publishing, 1990 6] Bar-shalom, Multitarget Multisensor Tracking Principles and Techenices ,:YBS Publishing, 1995 7] Hu Wenlong, Mao shiyi, Multisensor Data Association Based on Combinatorial Optimization[J]. Journal of Systems Engineering and Electronics . 1997 NO.1,1~9 8] Pattipati K R, Passive Multisensor Data Association Using a New Relaxation Algorithm.In Multitarget-Multisensor Tracking: Advanced and Applications,Y.Barshalom,Norwood,MA:Aretech,199 0 9] Deb S,et al, An S-Dimentional Assignment Algorithm for Track Initiation ,Proc. Of the IEEE Int. Conf Systems Engineering, Kobe, Japan,Sept 1992 527~530 10] Deb S,et al, A Multisensor-Multitarget Data Association Algorithm for Heterogeneous Sensors[J].IEEE Trans. on AES 1993 ,29 \(2 560~568 12] Bar-shalom,Y.,and Fortmann,T.E  Tracking and Data Association  New York:Academic press,1988 13] J,A,Roecher and G.L.Phillis,Suboptimal Joint Probabilistic Data Association .IEEE Transaction on Aerospace Electronic Systems.1993,29\(2 14] J,A,Roecker,A Class of Near Optimal JPDA Algorithm IEEE Transaction on Aerospace and Electronic Systems,1994,30\(2 15] Han Yanfei, Analysis and Improvement of Multisensor Multitarget Probabbilistic Data Association Filting Algorithm[J].  Journal of Systems Engineering and Electronics, 2002, Vol.24, 36~38  569 pre></body></html 


dense data sets for evaluating pattern mining algorithms These two data sets are obtained from IBM Almaden at http://www.almaden.ibm.com/cs/quest/demos.html. Recently, theMAFIA algorithm [6] was proposed to ef?ciently discover maximal frequent patterns. As shown in their paper, MAFIA can be several orders better than some alternatives, such as DepthProject, for mining maximal frequent patterns. Hence, we chose MAFIA as the base line for our performance evaluation. Finally, please note that only the size-2 patterns are generated in the ?rst BFS phase Experimental Platform We implemented the MHP algorithms using C++ and all experiments were performed Proceedings of the 16th IEEE International Conference on Tools with Artificial Intelligence \(ICTAI 2004 1082-3409/04 $20.00  2004 IEEE on a Pentium III    MHz PC machine with    megabytes main memory, running Linux Redhat 6.1 operating system 5.2. A Performance Comparison 100 1000 10000 100000 1e+06 1e+07 1e+08 1e+09 1e+10 1e+11 0.02 0.025 0.03 0.035 0.04 0.045 0.05 0.055 0.06 N um be r o f C he ck ed P at te rn s Support threshold Mafia Min_Conf=0 Min_Conf=0.1 Min_Conf=0.3 Min_Conf=0.5 Min_Conf=0.7 Min_Conf=0.9 


Figure 4. The Number of Checked Patterns on the Pumsb* Data Set 10 100 1000 10000 100000 0.02 0.025 0.03 0.035 0.04 0.045 0.05 0.055 0.06 R un T im e s ec  Support Threshold Mafia Min_Conf=0 Min_Conf=0.1 Min_Conf=0.3 Min_Conf=0.5 Min_Conf=0.7 Min_Conf=0.9 Figure 5. The RunTime Comparison on the Pumsb* Data Set Figure 4 shows the number of patterns that MHP and MAFIA have to check during the pattern mining process on the pumsb* data set. As can be seen, for MHP, the number of checked patterns is increased with the decrease of the h-con?dence threshold. However, the number of checked patterns of MHP can be signi?cantly smaller than that of MAFIA even if a low h-con?dence threshold is speci?ed To check a pattern, we need to count the support of the patterns. Counting the support of a pattern is the most timeconsuming task during the pattern mining process, since we need to retrieve all the transactions which include one of its sub-pattern, or for Ma?a, retrieve all the bit of the bitmap of this pattern [6]. Therefore, an algorithm is more ef?cient if smaller number of patterns need to be checked 100 1000 10000 100000 1e+06 1e+07 1e+08 1e+09 0.1 0.2 0.3 0.4 0.5 0.6 0.7 N 


um be r o f C he ck ed P at te rn s Support Threshold Mafia Min_Conf=0.5 Min_Conf=0.7 Min_Conf=0.9 Figure 6. The Number of Checked Patterns on the Pumsb Data Set 10 100 1000 10000 0.1 0.2 0.3 0.4 0.5 0.6 0.7 R un T im e s ec  Support Threshold Mafia Min_Conf=0.5 Min_Conf=0.7 Min_Conf=0.9 Figure 7. The RunTime Comparison on the Pumsb Data Set The runtime comparison of MHP and MAFIA on the Pumsb* data set is shown in Figure 5. In the ?gure, we can observe that the runtime of MHP can be signi?cantly reduced with the increase of h-con?dence thresholds. Also the runtime of MHP can be several orders of magnitude less than that of MAFIA even if the h-con?dence threshold is as low as 0.3. The reason is that the number of checked patterns of MHP is sign?cantly smaller than that of MAFIA Similar results are also obtained from the pumsb data set as shown in Figure 6 and Figure 7. For the pumsb data set the number of checked patterns of MHP is much smaller 


than that of MAFIA and the runtime of MHP can be significantly less than that of MAFIA 5.3. The Effect of the MHP Algorithm on Finding Maximal Hyperclique Patterns Figure 8 and Figure 9 show the number of maximal patterns identi?ed byMHP andMAFIA on Pumsb* and Pumsb data sets respectively. As can be seen, the number of maximal hyperclique patterns identi?ed by MHP can be orders of magnitude smaller than the number of maximal frequent patterns identi?ed by MAFIA. In other words, the number Proceedings of the 16th IEEE International Conference on Tools with Artificial Intelligence \(ICTAI 2004 1082-3409/04 $20.00  2004 IEEE 100 1000 10000 100000 1e+06 1e+07 1e+08 1e+09 0.02 0.025 0.03 0.035 0.04 0.045 0.05 0.055 0.06 N um be r o f C ou nt ed P at te rn s Support Threshold Mafia Min_Conf=0 Min_Conf=0.1 Min_Conf=0.3 Min_Conf=0.5 Min_Conf=0.7 Min_Conf=0.9 Figure 8. The Number of MFI/MHP Patterns in the Pumsb* Data Set 100 1000 10000 100000 1e+06 


1e+07 1e+08 0.1 0.2 0.3 0.4 0.5 0.6 0.7 N um be r o f C ou nt ed P at te rn s Support Threshold Mafia Min_Conf=0.5 Min_Conf=0.7 Min_Conf=0.9 Figure 9. The number of MFI/MHP Patterns in the Pumsb Data Set of maximal hyperclique patterns is much easier to manage than that of maximal frequent patterns. Indeed, in realworld applications, it is dif?cult to interpret several million maximal frequent patterns. However, it is possible to interpret the results of maximal hyperclique pattern mining In addition, due to the memory limitation, we cannot extract maximal frequent patterns with MAFIA on the Pumsb data set if the support threshold is less than 0.4, as shown in Figure 7. In contrast, MHP can identify maximal hyperclique patterns when the support threshold is 0.1, if we set the h-con?dence threshold to 0.5. In other words, MHP has the ability to identify patterns which can be dif?cult to identify for MAFIA. Hence, MHP can better explore the pattern space and ?nd interesting patterns at low levels of support 6. Conclusions and Future Work In this paper, we present a two-phase Maximal Hyperclique Pattern \(MHP best features of both the BFS strategy and the DFS strategy. More speci?cally, we adapted DFS pruning methods such as equivalence pruning, to an apriori-like approach In addition, we proved the correctness and completeness of the MHP algorithm. Finally, our experimental results show that the MHP algorithm can be several orders of magnitude faster than standard maximal frequent pattern mining algorithms and has the ability to identify patterns at extremely low levels of support in dense data sets There are several directions for future work. First, in 


this paper, we only generate the size-2 patterns in the BFS phase. It will be interesting to investigate the impact on the performance if the ?rst phase is stopped at a deeper level Also, the projection is a very ef?cient method for ?nding patterns, especially for parallel implementation of pattern mining algorithms [1]. We plan to adapt the projection ideas into our algorithm and design an ef?cient parallel algorithm for mining maximal hyperclique patterns References 1] R. Agarwal, C. Aggarwal, and V. Prasad. A Tree Projection Algorithm For Generation of Frequent Itemsets. pages 350 371, Feb 2001 2] R. Agrawal, T. Imielinski, and A. Swami. Mining Association Rules between Sets of Items in Large Databases. In Proc. of the ACM SIGMOD Conference on Management of Data, pages 207216,May 1993 3] R. Agrawal and R. Srikant. Fast Algorithms for Mining Association Rules. In Proc. of the 20th Intl Conference on Very LargeData Bases, 1994 4] R. Bayardo. Ef?ciently mining long patterns from databases In Proc. of the ACM SIGMOD Conference, 1998 5] R. Bayardo and R. Agrawal. Mining the Most Interesting Rules. In Proc. of the ACM SIGKDD Conference, 1999 6] D. Burdick, M. Calimlim, and J. Gehrke. Ma?a: AMaximal Frequent Itemset Algorithm for Transactional Databases. In Proc. of IEEE Conf. on Data Engineering, 2001 7] Y. Huang, H. Xiong, W. Wu, and Z. Zhang. A Hybrid Approach for Mining Maximal Hyperclique Patterns. In In Technical Report UTDCS-34-04, Department of computer science, University of Texas - Dallas, 2004 8] J.Han, J.Pei, and Y. Yin. Mining Frequent Patterns without Candidate Generation. In Proc. of the ACM SIGMOD International Conference on Management of Data, 2000 9] M.J.Zaki and C.Hsiao. ChARM: An ef?cient algorithm for closed itemset mining. In Proc. of 2nd SIAM International Conference on Data Mining, 2002 10] R.Rymon. Search through Systematic Set Enumeration. In Proc. Third Intl Conference on Principles of Knowledge Representation and Reasoning, 1992 11] H. Xiong, M. Steinbach, P.-N. Tan, and V. Kumar. HICAP: Hierarchial Clustering with Pattern Preservation. In Proc. of 2004 SIAM International Conference on Data Mining \(SDM 12] H. Xiong, P.-N. Tan, and V. Kumar. Mining Strong Af?nity Association Patterns in Data Set with Skewed Support. In Proc. of the Third IEEE International Conference on Data Mining \(ICDM Proceedings of the 16th IEEE International Conference on Tools with Artificial Intelligence \(ICTAI 2004 1082-3409/04 $20.00  2004 IEEE 





