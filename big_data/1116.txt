Self-Teaching Semantic Annotation Method for Knowledge Discovery from Text   Kaiquan Xu Department of Information Systems, City University of Hong Kong kaiquan.xu@student.cityu.edu.hk  Stephen Shaoyi Liao Department of Information Systems, City University of Hong Kong  issliao@cityu.edu.hk  Raymond Y.K. Lau Department of Information 
Systems, City University of Hong Kong raylau@cityu.edu.hk   Lejian Liao Department of Computer Science Beijing Institute of Technology liaolj@bit.edu.cn    Heng Tang Faculty of Business Administration, University of Macao hengtang@umac.mo          Abstract As much valuable domain knowledge is hidden in 
enterprises' text repositories \(e.g., email archives digital libraries, etc.\ desirable to develop effective knowledge management tools to process this unstructured data so as to extract  domain knowledge for business decision making. Ontology-based semantic annotation of documents is one of the promising ways for knowledge discovery from text repositories. Existing semantic annotation methods usually require many labeled training examples before they can effectively operate, and this bottleneck holds back the widely applications of these semantic annotation methods.  In this paper, we propose a semisupervised semantic annotation method, self-teaching 
SVM-struct, which uses fewer labeled examples to improve the annotating performance. The key of the self-teaching method is how to identify the reliably predicted examples for retraining. Two novel confidence measures are developed to estimate prediction confidence. The experimental results show that the prediction performance of our self-teaching semantic annotation method is promising   1. Introduction  Nowadays, knowledge has become a very key factor for making successful decisions, and most big companies make large investments in Knowledge 
Management Systems \(KMS\ and knowledge discovery for decision support. But most data stored in KMS are text documents, and current KMS has limited capabilities for interpreting the text documents. In order to effectively use the valuable text data for decision support, it is necessary to make these texts to be "understandable" by Decision Support Systems DSS Semantic annotating documents using domain ontology is one of the promising ways to implement this object. Semantic annotation formally identifies 
concepts and relations between concepts in documents and is intended primarily for use by machines example, a semantic annotation might relate Bei Jing  in a text to an ontology which both identifies it as the abstract concept City and links it to the instance China of the abstract concept Country with the relation of CapitalOf Semantic annotation allows for more accurate information retrieval and better interoperability. For example, when searching 
information about city Bei Jing will be hit, since it is an instance of City Interoperability is particularly important for organizations, since their legacy databases exist in different proprietary formats Semantic annotation with common ontology can facilitate the integration of these heterogeneous data sources. As a result, with semantic annotation, DSS can effectively utilize the valuable knowledge hidden in the text repositories: 1\ DSS can "understand documents to retrieve more accurate information and 
make better inference for decision support; 2\ DSS can exploit vast and heterogeneous legacy data for decision support Manual annotating documents needs lots of labor cost and time, so some automatic and semi-automatic methods are proposed. Among them, sequence model based approaches are very effective for semantic annotation, since these models can describe the Proceedings of the 42nd Hawaii International Conference on System Sciences - 2009 1 978-0-7695-3450-3/09 $25.00  2009 IEEE 
 


dependencies between different parts of information These sequence models include Hidden Markov Model HMM d ition a l Ran d om Fields \(CRF d  SVM-struct u t th es e s e qu en ce m odel s requ ire  many labeled examples as the training examples, and it is generally more complicated and time consuming to annotate the structured training examples for semantic annotation rather than labeling documents for the general classification problems. As a result, sequence models have not been widely used for semantic annotation in practice One main contribution of this paper is that a semisupervised learning method, self-teaching SVM-struct is proposed for semantic annotation, which only needs fewer labeled examples. The idea of this method is using the reliably predicted examples as the training examples to retrain the SVM-struct model to improve performance. The latest and best sequence model SVM-struct ad opted h e re. A n d accordin g to th e  characters of SVM-struct, we design two confidence measures to identify the reliably predicted examples for retraining. The experimental results show that this method really improved the performance of semantic annotation The rest of the paper is organized as follows Section 2 introduces some background knowledge of semantic annotation and SVM-struct model. Section 3 describes our self-teaching SVM-struct algorithm and the confidence measures. Section 4 describes our experiment and results. Section 5 introduces the related research in semantic annotation. Finally, we offer concluding remarks and describe future direction of our research work  2. Background Knowledge  2.1. Semantic Annotation as Sequence Labeling  Semantic annotation can be resolved with the rule induction and classification methods. But recently sequence model based methods become a promising way for it, since these models enable describing dependencies between concepts, and the dependencies can be utilized to improve the accuracy of the annotation w e  u s e an ex a m ple to illustrate  that semantic annotation is modeled as the sequence labeling problem, and then is resolved with the sequence models  Bei Jing is the capital of the People's Republic of China  City  Country   In the above sentence Bei Jing is an instance of concept City and People's Republic of China is an instance of Country Then its corresponding label sequence is  Bei      Jing    is  the  capital  of   People's      Republic    of                China B-City I-City O  O    O          O    B-Country  I-Country  I-Country   I-Country  Here, the region information is coded by three kinds of labels B-concept  I-concept and O  B-concept  means that the current word is the beginning of an instance of the concept I-concept means that the current word is in an instance of the concept. And O  indicates that the word is not in an instance of any concept After reframing semantic annotation as sequence labeling problem, the task of semantic annotation can be seen as: for a given sentence, finding the right label sequence for it. For the sequence model-based methods, some examples with right label sequences are given as training examples first, and a sequence model is trained based on these examples. Finally, the trained model is used to predicate the label sequences of other unlabeled sentences The formal definition of semantic annotation with sequence models is given below For a given the ontology Ont the concept set is defined as    Ont c c ClassSet i i   here i c is a concept Then, the label set from this ontology is defined as     _  _     O c I l c B l ClassSet c l LabelSet j i j i j i           that is LabelSet consists of the labels with B_ or I_ as the prefixes of concepts. The sequence modelbased method for semantic annotation is The input space is       2 1 WordSet w w w w w x x X t T t i i    here i x is a sentence consisting of multiple words The output space is       2 1 LabelSet l l l l l y y Y t T t i i    here i y is the label sequence Given some labeled training examples n i i i y x 1     here Y y X x i i    a mapping function Y X f   is learnt using these training examples. For an unlabeled sentence x    x f is the predicted label sequence which is the semantic annotation for that sentence  2.2. SVM-struct for Sequence Labeling  There are several sequence models for sequence labeling, such as HMM and CRF. Here, we will adopt SVM-struct, since it leads to better performance than HMM and CRF T h e m o ti v a tion of th e SVM s tru c t  algorithm is driven by the idea of the maximum large margin from Support Vector Machine \(SVM o r structured output problems, such as sequence labeling and syntactic tree analysis i n d a righ t  Proceedings of the 42nd Hawaii International Conference on System Sciences - 2009 2 
 


parameter to optimally separate the right structured output from other. The basic idea of SVM-struct is as follows Let X and Y are the input and output space, and Y y X x     y can be any complex structure\d n i i i y x 1     is a set of training examples. First, a linear discriminant function is defined by            y x y x F 012 012 here    y x  is the feature representation function and represents the combined features of input x and output y The corresponding mapping function f is defined by the expression     max arg    012 012 y x F x f Y y   The SVM-struct method solves the following optimization problem     to get the right parameter 012 to achieve optimal separation. Here    y y i  is the loss function For the sequence labeling problem x is a sentence and y is a label sequence. Similar with HMM, the feature representation function can include the combined features of input sentences and labels, and features between adjacent labels. The maximization of        y x i 012 over y can be carried out by dynamic programming \(Viterbi algorithm th e f o llo w i ng sections, we exactly utilize the characters of Viterbi algorithm for our novel prediction confidence measures  3. Self-teaching SVM-struct for Semantic Annotation  Although, the previous research shows that SVMstruct leads to promising performance for sequence labeling when compared with other sequence models  s u ff ers  f r o m th e s a m e  w e akn e ss of oth e r  sequence models, that is, requiring a large number of labeled training examples. In this section, a novel selfteaching method of SVM-struct is proposed to alleviate this partially for semantic annotation  3.1. Self-Teaching SVM-struct Algorithm  The self-teaching learning is a kind of semisupervised learning, which uses the reliably predicted unlabeled examples to retrain the model to improve the prediction performance. The process of the selfteaching is: first train a learning model based on small amount of labeled data, and then use the learning model to predict unlabeled examples. Typically, the most confident unlabeled examples, together with their predicted labels, are added into the training example set. The learning model is re-trained and the procedure is repeated until the stop condition is satisfied [8 h e self-teaching SVM-struct algorithm for semantic annotation uses SVM-struct model in the self-teaching process. The algorithm is as follows  Table 1. Self-teaching SVM-struct Algorithm ____________________________________________ Let L i i i L y x D 1      be the initial labeled training examples Let U L j j U x D 1      be the unlabeled examples 1. Train SVM-struct model M on L D  2. Use M to predict the label sequence  j y for every j x in U D  3              j j j L L y conf y x D D  4. If           j j y conf y decreases, or iteration number 015  Then stop, Else go to step 1 ____________________________________________  The key step 3 in this algorithm means if the confidence of the prediction  j y is high enough  j y  together with the sentence j x is added into the training examples set to retrain SVM-struct model. The performance of this algorithm heavily depends on the prediction confidence measure. In the following section, two novel confidence measures are proposed  3.2. Confidence Measure  In the self-teaching SVM-struct algorithm, the confidence measure of the predicted label sequence plays the key role. A good measure can select the good predicted examples to retrain SVM-struct model, and improve the semantic annotation performance Otherwise, the poor predicted examples will damage the performance For usual generative sequence models \(such as HMM\e conditional probability     j j x y P is a very good measure to identify how probable  j y is the right label sequence for j x But SVM-struct is a discriminative model rather than a generative model so the conditional probability     j j x y P is not readily available here. According to the character of SVMstruct, two special confidence measures are described  3.2.1 Ratio of the Top Two Viterbi Path Costs Measure In the section 2.2, we know that, when    n i i C 1 2  2 1 min  012  012 i i i i i y y y x F y x F y n j t s                     1    Proceedings of the 42nd Hawaii International Conference on System Sciences - 2009 3 
 


making the prediction for the input x SVM-struct tries to find an output y to maximize     012 y x F and then this y is the prediction for x For the sequence labeling problem, SVM-struct adopts the Viterbi algorithm a x i m i ze     012 y x F efficiently. The process is as follows  Table 2. Viterbi algorithm used in SVM-struct ____________________________________________ Let T t w w w w x   2 1  be the input sentence Let 1 l  2 l  i l  LabelSet l LabelSet  be possible labels Let   i t l  store the maximal cost of the label path with i l at the ending position t   Initialization         1 1 i i l w l  012    where the feature weight vector 012 represents the weights of different features, and the feature representation function    1 i l w  represents the combined features of the word 1 w and the label i l   Recursion             max    1  1           i i t t l i t l l l w l l  012  012     1  1   T t where the feature representation function     i l l  represents the combined features of the adjacent labels  l at the position t and i l at the position 1  t  ____________________________________________  Assuming   i T l  is the maximal cost, and the labels covered by   i T l  compose the predicted label sequence for input x     Picture 1. An Example of the Prediction  In picture 1, the path indicated by the solid arrow has the maximal cost, so the labels \(the black points covered by this path are the prediction for the sentence  Bei Jing is the capital of the People's Republic of China  From the above, we know that the prediction for a sentence is the label sequence with maximal path cost If a prediction is highly confident, its path cost should have an obvious difference with the second largest path cost. Otherwise, if the difference is small, it is very possible that this prediction is not right. So the ratio of the maximal path cost to the second largest path cost is a good indicator for the prediction confidence. If this ratio exceeds a special threshold, we can think this prediction is confident and can be added into the training example set. Also this ratio can be calculated efficiently with the Viterbi algorithm for the maximal path cost and second largest path cost  3.2.2 Annotated Semantic Concepts Confidence Measure Although the ratio of the top two path costs can measure the confidence of the predicted label sequence, it does not differentiate the semantic concept labels B-Concept and I-Concept rom the blank label O d handle them totally equally. So this measure does not consider the confidence of the annotated semantic concepts, which should be the focus points in semantic annotation. We propose another confidence measure, the Annotated Semantic Concepts Confidence Measure. The intuition of this measure is that assuming the semantic concepts annotated in the maximal cost path are right, and these right concepts are labeled as other concepts in another path, this path cost will decrease greatly. So we use the ratio of the maximal path cost to the maximal cost of the path, which bypasses the semantic concepts annotated in the maximal cost path, as the second confidence measure O B-City I-City B-Country  I-Country    Bei       Jing         is            ......         of     China  Proceedings of the 42nd Hawaii International Conference on System Sciences - 2009 4 
 


  Picture 2. An Example of the maximal cost path bypassing the semantic concepts  In picture 2, the concept labels covered by the maximal cost path in picture 1 are circled, which the label sequence must not pass when searching the maximal cost path bypassing the annotated semantic concepts In this example, if the searched path is the one indicated by the dashed arrow, the prediction confidence using this measure is the ratio of the cost of the black arrow path in picture 1 to the cost of the dashed arrow path in picture 2 For calculating the maximal cost of the path bypassing the special semantic concept labels, some constrains are added into the Viterbi algorithm, like  h e con s train t   t t l s C   means that at position t the label path can not pass the label t l For the above example C should be  _  _  2 1 City I s City B s   After adding some constrains, the formulas d table 2 are modified separately as follows otherwise l l if l w l i i i       0   1 1 1      012   otherwise l l if l l l w l l t i i i t t l i t               max 0   1  1  1              012  012   So this confidence measure can also be computing efficiently  4. Experimental Evaluation  4.1. Experiment Design  In order to evaluate the performance of the selfteaching SVM-struct for semantic annotation, a controlled experiment was performed. The results were compared with the sequence model based methods The GENIA benchmark corpus [9  w a s use d fo r  this experiment. The GENIA corpus is an annotated corpus for the biology domain. Some terms are annotated with the GENIA concept labels. The ontology for this experiment comes from the organic  branch of the GENIA ontology and contains 27 classes with 4 levels and 23 leaf node classes. After some preprocessing, 1144 sentences and the related label sequences were obtained. Two types of features associated with input sentences were used: 1\ord feature k w   2  1  0  1  2     k  k is the relative position from the current word, a negative value represents the preceding word, and a positive value represents the following word. 2\Part-Of-Speech \(POS\ of the current word pos  The sequence model based method and the selfteaching SVM-struct method with the two confidence measures were applied separately in this experiment The three metrics widely used in the information retrieval field, precision, recall, and f-score, were adopted in this experiment. Precision means the ratio of the right predicted semantic concepts to all predicted semantic concepts by the algorithm, recall means the ratio of the right predicted semantic concepts by the algorithm to all original semantic concepts, and f-score is a mixture of precision and recall     2  recall precision recall precision score f      The SVMstru o f t w a re pack a g es  w e re rev i s e d in t h i s  experiment The experiment contained two settings. In setting 1 917 sentences \(about 24,000 words\d their labels were as the training examples, and 227 sentences about 6,000 words\were as the testing examples. In setting 2, 193 sentences \(about 5,000 words\d their labels were as the training examples, and 227 sentences about 6,000 words\were as the testing examples  4.2. Experimental Results  The initial experimental results are report in table 3 4 and figure 3, 4 \(confidence measure 1 is the ratio of the top two path costs; confidence measure 2 is the annotated semantic concepts confidence measure  Table 3. The Experiment Result in Setting 1 Method f-score Precision Recall SVM-struct 54.46% 60.70% 50.64 Self-teaching SVM-struct with confidence measure 1 54.38% 60.56 49.57 Self-teaching SVM-struct with confidence measure 2 55.04% 61.20 50.00  Table 4.The Experiment Result in Setting 2  Method f-score Precision Recall SVM-struct 36.52% 43.84% 31.70 O B-City I-City B-Country  I-Country    Bei       Jing         is              ......         of     China Proceedings of the 42nd Hawaii International Conference on System Sciences - 2009 5 
 


Self-teaching SVM-struct with confidence measure 1 37.09% 45.34 31.49 Self-teaching SVM-struct with confidence measure 2 36.66% 44.51 31.28   0.00 10.00 20.00 30.00 40.00 50.00 60.00 70.00 f-score Precision Recall SVM-struct Self-teaching SVM-struct w ith confidence measure 1 Self-teaching SVM-struct w ith confidence measure 2  Figure 3. The Experiment Result in Setting 1  0.00 5.00 10.00 15.00 20.00 25.00 30.00 35.00 40.00 45.00 50.00 f-score Precision Recall SVM-struct Self-teaching SVM-struct w ith confidence measure 1 Self-teaching SVM-struct w ith confidence measure 2  Figure 4.The Experiment Result in Setting 2  The above tables and charts show that, in setting 1 and 2, the self-teaching SVM-struct with annotated semantic concept confidence measure achieves better f-score and precision obviously, although it decreases recall slightly. The self-teaching SVM-struct with the ratio of top two path costs raises f-score and precision in setting 2, but damages them in setting 1 This experiment indicates the self-teaching SVMstruct with annotated semantic concept confidence measure can stably improve the performance, but the one with the top two path costs measure does not always improve the performance  5. Related Work  Many research efforts have been done for semantic annotation. However, most of the previous work uses classification methods or sequence model based methods, and few of them tried to use fewer labeled training examples to improve the performance. The previous work can be categorized as the follows 1. Rule Induction Method. Rule induction is employed for the semantic annotation. For example  learn an n o tatio n ru le s f r o m t h e trai n i ng data  Although rule induction has better precision, the recall is not very high 2. Classification Method. The method views semantic annotation as a problem of classification. It learns a classifier from training examples to detect the types of the test examples. For example, SCORE Enhancement Engine \(SEE\upports web page annotation by using classification model [11    3. Sequence Model Based Meth tilized  HMM in semantic annotation. But HMM needs lots of training examples to enumerate all possible observation sequences  6. Conclusions and Future Work  In this paper, a novel self-teaching SVM-struct model is proposed to improve the performance of semantic annotation with fewer labeled examples Especially, two prediction confidence measures are described for the self-teaching SVM-struct. The experimental results show this method achieves promising performances In the future, more features from text, such as prefix, suffix, verb, syntactic relations, etc. will be added into the models to improve the precision. In addition, the co-training method is also an optional way to increase the performance, and we will explore the co-training between CRF and SVM-struct models for semantic annotation  7. References    V i cto r ia Uren   P h ili p p Ci m i an o  Jo se Iria  S i egf r ied  Handschuh, Maria Vargas-Vera, Enrico Motta, Fabio Ciravegna. "Semantic annotation for knowledge management: Requirements and a survey of the state of the art". Web Semantics: Science, Services and Agents on the World Wide Web, Vol. 4, No. 1. January 2006, pp. 14-28  2 L a w r e n c e R  R a bine r A  Tutoria l  on H i dde n Ma rk ov  Models and Selected Applications in Speech Recognition Proceedings of the IEEE, 77 \(2\ 1989, pp. 257 286  3 J o h n L a ff ert y  A n d r ew McCallu m  Fern an d o  P e reira Conditional Random Fields: Probabilistic Models for Segmenting and Labeling Sequence Data". In Proceedings of the Eighteenth International Conference on Machine Learning, Morgan Kaufmann, San Francisco, \(2001\, pp 282-289  Proceedings of the 42nd Hawaii International Conference on System Sciences - 2009 6 
 


 F  Ci ravegn a L P 2  an ad ap t i v e al go ri t h m f o r information extraction from web-related texts". In Proceedings of the IJCAI2001 Workshop on Adaptive Text Extraction and Mining held in conjunction with 17th IJCAI2001, Seattle, USA. 2001. pp. 1251-1256  5 Ioa n nis T s oc ha nta r idis T h ors t e n J o a c h im s  T hom a s  Hofmann, Yasemin Altun. "Large Margin Methods for Structured and Interdependent Output Variables". Journal of Machine Learning  Research, 6, 2005, pp. 1453 1484  6 J i e T a ng Ming c a i H ong J u a n z i L i a nd B a ng y ong  L i a n g   Tree-structured Conditional Random Fields for Semantic Annotation", In Pr oceedings of ISWC 2006, 2006, pp.640653  7 N a m N g u y e n a nd Y u ns on g G uo C om pa r i s ons of  sequence labeling algorithms and extensions". Proceedings of the 24th international conference on Machine learning Zoubin Ghahramani Ed.\ ACM, US, Oregon, 2007, pp. 681 688  8  X i a o ji n Z h u   S e m i-Supe rv ise d L e a r ning L ite ra ture  Survey".  2007  9 T  O h ta Y  T a te isi, J. K i m   H  Mim a a n d T s ujii J  T he  GENIA corpus: An annotated research abstract corpus in molecular biology domain". In the Proceedings of he Human Language Technology Conference \(HLT 2002\, 2002, pp 73-77  1 T h o r st en J o ach i m s  S V M st ru ct  S up po rt  V e ct o r  Machine for Complex Outputs http://svmlight.joachims.org/svm_struct.html, 2007  11 B  H a m m ond, A  She t h a nd K  K o c h ut  S e m a n tic  enhancement engine: a modular document enhancement platform for semantic applications over heterogeneous content, in real world semantic web applications". IOS Press 2002. pp. 29-49  12 T a k u K u d o CRF   Y e t A nothe r CRF t oolk it  http://crfpp.sourceforge.net, 2008  13 L  R e e v e   I nte g ra ting hi dde n Ma rk ov m ode ls i n to  semantic web annotation platforms.Technique Report". 2004  14 A r on C u l o tta A ndre w Mc C a llum   C onf ide n c e  estimation for information extraction", HLT-2004, 2004  15  V l a d im ir N  V a p n ik  T he N a ture of Sta tistic a l L e a r ning Theory", New York:Springer-Verlag, 1995  Proceedings of the 42nd Hawaii International Conference on System Sciences - 2009 7 
 


also exist in BG/P communication libraries, but the program object ?les are the same A. Memory Benchmarks We evaluated the memory performance using two benchmarks: a streaming copy benchmark and the random memory access benchmark from Section III The streaming copy benchmark is simple: it allocates a memory buffer, divides it in two, and copies data from one region to the other using PowerPC 450 parallel load/store instructions. The benchmark reports the theoretical peak memory performance if it is run in a noise-free environment The results for several different buffer sizes can be found in Table III. With a 16KB buffer size, which ?ts well in the L1 cache, all kernels perform equally well, because no TLB misses are caused by the benchmark even under standard Linux with 4KB pages. With larger buffers, such as 4MB \(which ?t in the L3 cache which do not ?t Linux kernel is signi?cantly lower than under CNK. Linux with Big Memory shows a 0.2% loss compared to CNK This is a small performance hit, but it is still larger than expected, given that the noise level has been measured at just 0.03% \(see Section III detailed investigation of this phenomenon, but we suspect that instruction cache thrashing at context switch time caused by the OS tick update might be responsible; the benchmark issues a series of parallel load/store instructions, and the cost of cache thrashing might be higher than for an FPU benchmark Table III STREAMING COPY BENCHMARK \(GB/S 16KB 4MB 256MB CNK 6.74 4.60 3.85 Linux 4KB 6.73 3.85 3.35 Linux 64KB 6.74 4.51 3.82 Linux Big Memory 6.74 4.59 3.84 In Section III, we showed the results of the random memory access benchmark on CNK and on Linux with paged memory; there was a large difference in performance Table IV adds the result for Linux with Big Memory support the gap to CNK is narrowed to 0.04%, or within the system noise level Table IV RANDOM MEMORY ACCESS BENCHMARK MB/s CNK 44.70 Linux 4KB 14.39 Linux 64KB 16.40 Linux Big Memory 44.68 B. FFT Benchmark To obtain more realistic performance numbers, we ran a simple FFT benchmark linked to the standard FFTW library version 3.1.2  5000 in size, which consumes approx. 763MB of memory Table V shows the results of executing a forward FFT on the array. Clearly, standard Linux does not perform well; 64KB pages improve performance by only 9%. On the other hand Linux with Big Memory shows just a 0.08% performance loss compared to the CNK Table V FFT BENCHMARK Elapsed Time \(s CNK 11.25 Linux 4KB 21.43 Linux 64KB 19.61 Linux Big Memory 11.24 C. NAS Parallel Benchmarks So far we have shown that the Big Memory implementation de?nitely improves memory performance of applications on a single node. To evaluate parallel performance we ran the NAS Parallel benchmarks [14] version 3.3 on 


we ran the NAS Parallel benchmarks [14] version 3.3 on both CNK and Linux with Big Memory support. We ran the experiment on 1024 nodes, in SMP mode \(one process per 70 node in Table VI. The performance is close: Linux runs were slower on most benchmarks compared to those using CNK by approx. 0.1% to 0.7%, with the exception of the IS benchmark, where Linux was 0.5% faster Although the table contains only the results using 1024 nodes, we have submitted most NAS Parallel benchmarks with 256, 512, and 1024 nodes to investigate scalability. We haven  t observed any scaling issue on our Linux kernel up to 1024 nodes Table VI NAS PARALLEL BENCHMARK Type CNK \(Mop/s Mop/s IS 3991 4010 1.005 CG 15749 15707 0.997 MG 134955 134380 0.996 FT 96594 96385 0.998 LU 40890 40617 0.993 EP 2503 2500 0.999 SP 106009 105709 0.997 BT 165240 164777 0.997 D. LOFAR Online Central Processing We had the opportunity to observe the performance of Big Memory in a real-life application. LOFAR is a radio telescope being built in the Netherlands [15]. In contrast to current radio telescopes that employ custom-built hardware as a correlator, LOFAR uses a Blue Gene/P supercomputer Our previous work discusses the LOFAR central processor in more detail [7], [16 LOFAR stations stream UDP/IP data directly into the Blue Gene/P I/O nodes at a rate of slightly more than 3Gbps These I/O nodes store the data in a main memory ring buffer which is used to absorb network delays or temporary hiccups in the processing pipeline. From here the data is transported to the compute nodes, where the information is correlated Poor main memory performance of the I/O node running the default Linux kernel proved to be one of the major bottlenecks in trying to achieve optimum data throughput Table VII shows a breakdown of the tasks on the Blue Gene/P I/O nodes running the LOFAR online processing application in a fairly standard 16-bit observation mode and a more challenging 4-bit mode. The required CPU resources in processor cores, are shown for the stock IBM I/O node kernel in the 16-bit mode and for a ZeptoOS compute node kernel, modi?ed to run on the I/O nodes, for both the 16bit and 4-bit modes. We see that using the original I/O node kernel would require almost two entire I/O node cores just to handle the ring buffer, and that there are not enough compute resources available to perform all the tasks in real time, even for the less demanding 16-bit mode We used a slightly modi?ed ZeptoOS compute node kernel, including support for the Ethernet device and excluding compute node speci?c devices like the torus network, on the I/O node. We reserved 1536MB of main memory as the Big Memory area and used it for the ring buffer using six 256MB TLB entries. The I/O node application was also adapted to copy 128 UDP/IP packets into the ring buffer at once, instead of one at a time. These two optimizations reduce the resources required to copy data into the ring buffer by more than 600%, about half of which can be attributed to the lack of TLB misses in the Big Memory area The more challenging 4-bit mode signi?cantly increases the potential number of TLB misses. Although limitations in the default kernel make direct comparison impossible smallscale memory benchmarks show a more than 500 reduction in required CPU cycles using Big Memory when 


reduction in required CPU cycles using Big Memory when copying UDP/IP packets one by one Clearly, the access pattern of the LOFAR I/O node application is very susceptible to performance hits caused by TLB misses. With the stock I/O node kernel, the processor was unable to achieve our throughput requirements. Preventing TLB misses for at least part of the application, combined with several other optimizations not discussed here, allowed us to reduce CPU load considerably, increasing I/O node performance to well beyond our original requirements Table VII LOFAR I/O NODE PROCESSING \(#CORES Stock ZeptoOS 16 bit 16 bit 4 bit Receive UDP/IP packets 1.44 1.44 1.22 Copy data to ring buffer 1.80 0.27 0.37 Send ring buffer to CN 1.40 0.52 0.61 Receive data from CN 1.00 0.10 0.35 Send results to storage 0.40 0.32 0.64 Total system load 151% 66.5% 79.7 VI. CONCLUSIONS This paper presented the implementation of Big Memory support for BG/P Linux  a transparent, ?at memory space for computational processes. Big Memory addresses two major issues encountered when attempting to run highperformance code on the BG/P Linux: poor memory performance caused by TLB misses handled in software, and the dif?culties of writing an ef?cient communication stack caused by the limitations of the BG/P torus  DMA engine Our experiments have shown that benchmarks running under a standard Linux kernel with paged memory can run up to three times slower than under CNK. With Big Memory support, Linux is slower by only 0.03  0.2%. We think that the 0.03% loss is due to the time spent executing the OS tick interrupt handler; with some benchmarks this can grow to 0.2%, presumably because of instruction cache thrashing With further kernel tuning, it should be possible to reduce the noise level to close to zero. Experiments at scale showed a slowdown of well under 1 71 Employing Big Memory on the I/O nodes was instrumental in reducing the I/O node CPU resources required for LOFAR online central processing. A 500  600% performance increase was observed in key parts of the application allowing the I/O nodes to achieve their required throughput Our modi?cations to the Linux kernel are relatively small principally because we focused exclusively on the requirements of computational processes, rather than trying to solve the problem in a generally applicable way, which would have been far more complicated. We maintain two versions of Linux kernel, and we found porting the Big Memory patches between the kernels to be straightforward Contemporary parallel architectures such as Blue Gene/P Cray XT5, and Roadrunner use commodity CPUs such as Intel Xeon, AMD Opteron, or IBM PowerPC, instead of designs dedicated to computational environments. The memory management units in these processors are essentially designed to support a highly multitasking environment. It would be interesting if future designs had hardware support for computational process address space similar to the Big Memory area that we implemented, to allow for a seamless coexistence of high-performance applications and standard Unix processes on the compute nodes Along with the Big Memory implementation, we conceived the idea of a special process that the kernel treats differently from other processes. In the case of Big Memory the kernel creates a different application address space, and we showed that this idea works for compute nodes. We have also experimented with other uses of this feature, such as disabling nonessential interrupts when a computational process gets scheduled in order to reduce the system noise Our current implementation is suitable for benchmarking 


Our current implementation is suitable for benchmarking and simple applications. We need to make several improvements in the quality of implementation, such as the granularity of the Big Memory area. So far, we have had little experience with running large, real-world applications on the compute nodes using our modi?ed kernel; this area will be explored as part of our future research Acknowledgments: We thank IBM  s Todd Inglett Thomas Musta, Thomas Gooding, George Alma  si, Sameer Kumar, Michael Blocksome, and Robert Wisniewski for their advice on programming the Blue Gene hardware. We also thank our past summer interns Peter Boonstoppel Hajime Fujita, Satya Popuri, and Taku Shimosawa, who contributed to the ZeptoOS kernel. Additionally, we thank Astron  s John W. Romein, who evaluated Big Memory on the I/O nodes This research used resources of the Argonne Leadership Computing Facility at Argonne National Laboratory REFERENCES 1  IBM Blue Gene  http://www.research.ibm.com/bluegene 2] J. E. Moreira et al  Blue Gene/L programming and operating environment  IBM Journal of Research and Development vol. 49, no. 2/3, pp. 367  376, Mar. 2005 3] J. E. Moreira et al  Designing a highly-scalable operating system: The Blue Gene/L story  in Proceedings of the ACM/IEEE Conference on Supercomputing, Tampa, FL, Nov 2006 4  ZeptoOS project  http://www.zeptoos.org 5] P. Beckman, K. Iskra, K. Yoshii, and S. Coghlan  The in?uence of operating systems on the performance of collective operations at extreme scale  in Proceedings of the 8th IEEE International Conference on Cluster Computing, Barcelona Spain, Sep. 2006 6] P. Beckman, K. Iskra, K. Yoshii, S. Coghlan, and A. Nataraj  Benchmarking the effects of operating system interference on extreme-scale parallel machines  Cluster Computing vol. 11, no. 1, pp. 3  16, Mar. 2008 7] K. Iskra, J. W. Romein, K. Yoshii, and P. Beckman  ZOID I/O-forwarding infrastructure for petascale architectures  in Proceedings of the 13th ACM SIGPLAN Symposium on Principles and Practice of Parallel Programming, Salt Lake City UT, Feb. 2008, pp. 153  162 8] IBM Blue Gene team  Overview of the IBM Blue Gene/P project  IBM Journal of Research and Development, vol. 52 no. 1/2, pp. 199  220, 2008 9] K. Chen, R. Seth, and H. Nueckel  Improving enterprise database performance on Intel Itanium architecture  in Proceedings of the Linux Symposium, Ottawa, ON, Canada, Jul 2003, pp. 98  108 10] E. Shmueli, G. Alma  si, J. Brunheroto, J. Castan  os, G. Do  zsa S. Kumar, and D. Lieber  Evaluating the effect of replacing CNK with Linux on the compute-nodes of Blue Gene/L  in Proceedings of the 22nd ACM International Conference on Supercomputing, Kos, Greece, Jul. 2008, pp. 165  174 11] D. Gibson and A. Litke  libhugetlbfs  http://sourceforge.net projects/libhugetlbfs 12] J. Navarro, S. Iyer, P. Druschel, and A. Cox  Practical transparent operating system support for superpages  in Proceedings of the 5th ACM Symposium on Operating System Design and Implementation, ser. ACM SIGOPS Operating Systems Review, vol. 36, Boston, MA, Dec. 2002, pp. 89  104 13] P. Beckman, K. Iskra, K. Yoshii, and S. Coghlan  Operating system issues for petascale systems  ACM SIGOPS Operating Systems Review, vol. 40, no. 2, pp. 29  33, Apr. 2006 14] D. Bailey et al  The NAS parallel benchmarks  International Journal of High Performance Computing Applications vol. 5, no. 3, pp. 63  73, 1991 15] H. R. Butcher  LOFAR: First of a new generation of radio 


15] H. R. Butcher  LOFAR: First of a new generation of radio telescopes  in Proceedings of SPIE, vol. 548, Oct. 2004, pp 537  544 16] J. W. Romein, P. C. Broekema, E. van Meijeren, K. van der Schaaf, and W. H. Zwart  Astronomical real-time streaming signal processing on a Blue Gene/L supercomputer  in Proceedings of the 18th ACM Symposium on Parallelism in Algorithms and Architectures, Cambridge, MA, Jul. 2006, pp 59  66 72 pre></body></html 


interact with strategic and structural properties of a firm Also, as we see growing amounts of regulation and stronger public reactions to how firms conduct their business, compliance issues have received increased attention. Especially from an IT governance perspective, two questions are exciting to ask: How are alignment and compliance related, i.e. to what extent can or should the dimensions of alignment be an explicit part of compliance activities? And one step further: As regulation regarding internal controls like the Sarbanes-Oxley Act in the USA affects almost all IT activities [61] this is a highly relevant issue. From an IT business value perspective, IT business alignment may be a driver but IT compliance may act as a constraint In practice, combining the demands for compliance and value delivery of IT is widely seen as the domain of IT governance [43]. This leads to the second question: Is there a positive business value impact from compliance beside just being compliant, i.e. do improvements from better governance/alignment structures and actions would have been worth the effort even without external regulatory pressure Proceedings of the 42nd Hawaii International Conference on System Sciences - 2009 8 References   1] Alavi, M. and Leidner, D.E., "Review: Knowledge Management and Knowledge Management Systems: Conceptual Foundations and Research Issues", MIS Quarterly 25\(1 2] Armstrong, J.S. and Overton, T.S., "Estimating Nonresponse Bias in Mail Surveys", Journal of Marketing Research, 14 3] Avison, D., Jones, J., Powell, P., and Wilson, D., "Using and Validating the Strategic Alignment Model", Journal of Strategic Information Systems, 13\(3 4] Barua, A., Kriebel, C.H., and Mukhopadhyay, T., "Information Technologies and Business Value: An Analytical and Empirical Investigation", Information Systems Research, 6\(1 5] Bassellier, G. and Benbasat, I., "Business Competence of Information Technology Professionals: Conceptual Development and Influence on IT-Business Partnerships MIS Quarterly, 28\(4 6] Beimborn, D., Franke, J., Gomber, P., Wagner, H.-T and Weitzel, T., "Die Bedeutung des Alignments von IT und Fachressourcen in Finanzprozessen: Eine empirische Untersuchung", Wirtschaftsinformatik, 48\(5 339 7] Beimborn, D., Franke, J., Wagner, H.-T., and Weitzel T., "The impact of outsourcing on IT business alignment and IT flexibility: a survey in the German banking industry",  Twelfth Americas Conference on Information Systems AMCIS 8] Beimborn, D., Franke, J., Wagner, H.-T., and Weitzel T., "Strategy matters - The role of strategy type for IT business value",  12th Americas Conference on Information Systems \(AMCIS 9] Beimborn, D., Franke, J., Wagner, H.-T., and Weitzel T., "The impact of operational alignment on IT flexibility Empirical evidence from a survey in the German banking industry",  13th Americas Conference on Information Systems \(AMCIS CO 10] Beimborn, D., Franke, J., Wagner, H.-T., and Weitzel T., "The Influence of Alignment on the PostImplementation Success of a Core Banking Information System: An Embedded Case Study",  40th Hawaii International Conference on System Sciences \(HICSS Big Island \(HI 


Big Island \(HI 11] Beimborn, D., Hirschheim, R., Schlosser, F., Schwarz A., and Weitzel, T., "How to Achieve IT Business Alignment? Investigating the Role of Business Process Documentation in US and German Banks",  14th Americas Conference on Information Systems \(AMCIS 2008 12] Bergeron, F., Raymond, L., and Rivard, S., "Ideal patterns of strategic alignment and business performance Information &amp; Management, 41\(8 13] Bhatt, G.D., "Managing information systems competence for competitive advantage: an empirical analysis 24th International Conference on Information Systems ICIS WA 14] Bhatt, G.D. and Grover, V., "Types of Information Technology Capabilities and Their Role in Competitive Advantage: An Empirical Study", Journal of Management Information Systems, 22\(2 15] Boynton, A.C., Zmud, R.W., and Jacobs, G.C., "The influence of IT management practice on IT use in large organizations", MIS Quarterly, 18\(3 16] Broadbent, M., Leading Governance, Business and IT Processes: the Organizational Fabric of Business and IT Partnership, Gartner ITEP Findings, 1998 17] Broadbent, M. and Weill, P., "Improving business and information strategy alignment: learning from the banking industry", IBM Systems Journal, 32\(1 18] Burn, J.M. and Szeto, C., "A Comparison of the Views of Business and IT Management on Success Factors for Strategic Alignment", Information &amp; Management, 37\(4 2000, 197-216 19] Carmeli, A. and Tishler, A., "The Relationships Between Intangible Organizational Elements and Organizational Performance", Strategic Management Journal 25\(13 20] Carr, N.G., "IT doesn't matter", Harvard Business Review, \(May 21] Castanias, R.P. and Helfat, C.E., "Managerial Resources and Rents", Journal of Management, 17\(1 155-171 22] Chan, Y.E., Huff, A.S., Barclay, D.W., and Copeland D.G., "Business strategic orientation, information systems strategic orientation, and strategic alignment", Information Systems Research, 8\(2 23] Chang, J.C.-J. and King, W.R., "Measuring the performance of information systems: a functional scorecard Journal of Management Information Systems, 22\(1 85-115 24] Chiasson, M.W. and Davidson, E., "Taking Industry Seriously in Information Systems Research", MIS Quarterly, 29\(4 25] Chin, W.W., "The partial least squares approach for structural equation modelling" in: Marcoulides, G. A. \(Ed Modern Methods for Business Research,  Lawrence Erlbaum Associates, Mahwah \(NJ 26] Chung, S.H., Rainer, R.K., and Lewis, B.R., "The impact of information technology infrastructure flexibility on strategic alignment and applications implementation Communications of the AIS, 11 27] Cragg, P.B., King, M., and Hussin, H., "IT Alignment and Firm Performance in Small Manufacturing Firms Journal of Strategic Information Systems, 11\(2 132 28] De Haes, S. and Van Grembergen, W., "IT Governance and its Mechanisms", Information Systems Control Journal, 1 29] De Haes, S. and Van Grembergen, W., "Information Technology Governance Best Practices in Belgian Organisations",  39th Hawaii International Conference on System Sciences, Hawaii, 2006 30] Eisenhardt, K.M., "Building theories from case study research", Academy of Management Review, 14\(4 


research", Academy of Management Review, 14\(4 532-550 Proceedings of the 42nd Hawaii International Conference on System Sciences - 2009 9 31] Feurer, R., Chaharbaghi, K., Weber, M., and Wargin J., "Aligning Strategies, Processes, and IT: A Case Study Information Systems Management, 17\(1 32] Galbraith, J.R., Organization Design, AddisonWesley, Reading \(MA 33] Galunic, D.C. and Rodan, S., "Resource recombinations in the firm: knowledge structures and the potential for Schumpeterian innovation", Strategic Management Journal, 19\(12 34] Gefen, D., Straub, D.W., and Boudreau, M., "Structural Equation Modeling and Regression: Guidelines for Research Practice", Communications of the AIS, 4\(7 35] Gordon, J.R. and Gordon, S.R., "Structuring the Interaction between IT and Business Units: Prototypes for Service Delivery", Information Systems Management 17\(1 36] Griffiths, G.H. and Finlay, P.N., "IS-enabled sustainable competitive advantage in financial services, retailing and manufacturing", Journal of Strategic Information Systems, 13\(1 37] Guldentops, E., "IT Governance: Part and Parcel of Corporate Governance",  CIO Summit, European Financial Management &amp; Market Conference, Brussels, 2002 38] Hansen, M.T., "The search-transfer problem: the role of weak ties in sharing knowledge across organization subunits", Administrative Science Quarterly, 44\(1 82-111 39] Henderson, B.D. and Venkatraman, N., "Strategic alignment: leveraging information technology for transforming organizations", IBM Systems Journal, 32\(1 4-16 40] Holsapple, C.W. and Luo, W., "A Framework for Studying Computer Support of Organizational Infrastructure", Information &amp; Management, 31\(1 41] Hulland, J., "Use of Partial Least Squares \(PLS strategic management research. A review of four recent studies", Strategic Management Journal, 20\(2 204 42] Hult, G.T.M., Ketchen Jr., D.J., and Nichols Jr., E.L An Examination of Cultural Competitiveness and Order Fulfillment Cycle Time within Supply Chains", Academy of management Journal, 45\(3 43] Institute, I.G., Board Briefing on IT Governance, IT Govnernace Institute, Rolling Meadows \(IL 44] Kearns, G., S. and Lederer, A.L., "The Impact of Industry Contextual Factors on IT Focus and the Use of IT for Competitive Advantage", Information &amp; Management 41\(7 45] Lederer, A.L. and Mendelow, A.L., "Coordination of information systems plans with business plans", Journal of Management Information Systems, 6\(2 46] Luftman, J., Competing in the Information Age. Align the Stand, Oxford University Press, Oxford \(MA 47] Luftman, J. and Brier, T., "Achieving and Sustaining Business-IT Alignment", California Management Review 42\(1 48] Mooney, J.G., Gurbaxani, V., and Kraemer, K.L., "A Process Oriented Framework for Assessing the Business Value of Information Technology", The DATA BASE for Advances in Information Systems, 27\(2 49] Nelson, K.M. and Cooprider, J.G., "The contribution of shared knowledge to IS group performance", MIS Quarterly, 20\(4 50] Nunnally, J.C., Psychometric theory, McGraw Hill New York \(NY 51] Peterson, R., "Crafting Information Technology Governance", Information Systems Management, 21\(4 7-22 


52] Peterson, R.R., "Information Strategies and Tactics for Information Technology Governance" in: Van Grembergen, W. \(Ed vernance,  Idea Group Publishing, Hershey \(PA 80 53] Podsakoff, P.M., MacKenzie, S.B., Lee, J.-Y., and Podsakoff, N., "Common Method Biases in Bevioral Research: A Critical Review of the Literature and Recommended Remedies", Journal of Applied Psychology, 88\(5 2003, 879-903 54] Powell, T.C. and Dent-Micallef, A., "Information Technology as Competitive Advantage: The Role of Human, Business, and Technology Resources", Strategic Management Journal, 18\(5 55] Reich, B.H. and Benbasat, I., "Measuring the linkage between business and information technology objectives MIS Quarterly, 20\(1 56] Reich, B.H. and Benbasat, I., "Factors that influence the social dimension of alignment between business and information technology objectives", MIS Quarterly, 24\(1 2000, 81-113 57] Reich, B.H. and Kaarst-Brown, M.L., "Creating Social and Intellectual Capital through IT Career Transitions Journal of Strategic Information Systems, 12\(2 109 58] Ringle, C.M., Wende, S., and Will, A., "SmartPLS 2.0 M3 \(beta 59] Sambamurthy, V. and Zmud, R.W., "At the Heart of Success: Organizationwide Management Competencies" in Sauer, Christopher and Yetton, Philip \(Eds Future: Fresh Thinking on the Management of IT-based Organizational Transformation,  Jossey-Bass Publishers San Francisco, 1997, 143-163 60] Segars, A.H. and Grover, V., "Strategic Information Systems Planning Success: An Investigation of the Construct and Its measurement", MIS Quarterly, 22\(2 139-163 61] Smith, H.A. and McKeen, J.D., "Developments in Practice XXI: IT in the New World of Corporate Governance Forms", Communications of the AIS, 17 62] Straub, D.W., Boudreau, M.-C., and Gefen, D., "Validation Guidelines for IS Positivist Research", Communications of the AIS, 13 63] Tallon, P.P., Kreamer, K.L., and Gurbaxani, V., "Executives perception of the business value of information technology: a process-oriented approach", Journal of Management Information Systems, 16\(4 64] Teo, T.S.H. and Ang, J.S.K., "Critical Success Factors in the Alignment of IS Plans with Business Plans", International Journal of Information Management, 19\(2 173-185 65] Teo, T.S.H. and King, W.R., "Integration between Business Planning and Information Systems Planning: An Proceedings of the 42nd Hawaii International Conference on System Sciences - 2009 10 Evolutionary-Contingency Perspective", Journal of Management Information Systems, 14\(1 66] Tiwana, A., Bharadwaj, A., and Sambamurthy, V The antecedents of information systems development capability in firms: a knowledge integration perspective 24th International Conference on Information Systems ICIS WA 67] Van Der Zee, J.T.M. and De Jong, B., "Alignment is not Enough: Integrating Business and Information Technology Management with the Balanced Business Scorecard", Journal of Management Information Systems, 16\(2 1999, 137-158 68] Van Grembergen, W., "The Balanced Scorecard and IT Governance", Information Systems Control Journal 2\(1 69] Van Grembergen, W. and De Haes, S., "Measuring and Improving IT Governance through the Balanced Score 


and Improving IT Governance through the Balanced Scorecard", Information Systems Control Journal, 2 70] Van Grembergen, W., De Haes, S., and Guldentops E., "Structures, Processes and Relational Mechanisms for IT Governance" in: Van Grembergen, W. \(Ed for Information Technology Governance,  Idea Group Publishing, 2004, 1-37 71] Wagner, H.-T., A resource-based perspective on IT business alignment and firm performance - Theoretical foundation and empirical evidence, ibidem, Stuttgart, Germany, 2007 72] Wagner, H.-T. and Weitzel, T., "IT Business Alignment as Governance Tool for Firm-Internal Relationship Quality: A Longitudinal Case Study",  41th Hawaii International Conference on System Sciences \(HICSS-41 Island, Hawaii, 2008 73] Webb, P., Pollard, C., and Ridley, G., "Attempting to Define IT Governance: Wisdom or Folly?",  39th Hawaii International Conference on System Sciences, Kauai, Hawaii, 2006 74] Zahra, S.A. and George, G., "The Net-Enabled Business Innovation Cycle and the Evolution of Dynamic Capabilities", Information Systems Research, 13\(2 147-150 75] Zmud, R.W., "Building relationships throughout the corporate entity" in: Elam, J., Ginzberg, M., Keen, P., and Zmud, R.W. \(Eds mission, the framework, the transition,  1988, Washington 1988, 55-82   Appendix  Table 5. Used indicators All items have been evaluated by using a 5-point Likert scale ranging from ?strongly agree? to  strongly disagree ID Item References Executive support \(ES ES1 The IT unit is sufficiently represented in our bank  s executive board. [18 ES2 Top management actively supports interplay between business and IT Strategic Alignment \(SA SA1 I am familiar with the IT strategy. [55 SA2 The IT strategy is accurately aligned with the business strategy. [22, 54, 55, 63 SA3 The IT strategy is documented. [17, 54 Governance Mechanisms \(GM GM1 There are explicit incentives rewarding good interaction with the IT unit. [51 GM2 The back office is proactively involved into IT planning. [17, 26, 55 GM3 There is a specific organizational unit or function to improve the communication be-tween  the IT and the back office 17, 26 Operational Alignment \(OA OA1 There is mutual trust and respect between IT unit and the back office. [13, 46, 64 OA2 IT and the back office regularly consult each other. [13, 17, 19 OA3 There are meetings on a regular basis between IT and back office for identifying business process improvements 17, 26, 55  OA4 There is extensive communication between IT unit and back office. [15, 17, 26 OA5 IT employees are able to interpret business related problems and develop solutions. [13, 60  64 Process Performance \(PP PP1 The configuration of our credit process allows us to sustain a competitive advantage in the  relevant market 36 PP2 The configuration of our credit process allows us to differentiate us from the competi-tors  in the relevant market 36, 42 PP3 Compared to our competitors, the operational efficiency of our loans process is higher. [23  27 PP4 Compared to our competitors, the design of our business loans process is ? \(much better 1  


PP4 Compared to our competitors, the design of our business loans process is ? \(much better 1  5 much worse 71 Proceedings of the 42nd Hawaii International Conference on System Sciences - 2009 11 pre></body></html 


The HyspIRI mission utilizes innovative techniques to both reduce the amount of data that must be transmitted to the ground and accommodate the required data volume on the ground The infrastructure and techniques developed by this mission will open the door to future high data volume science missions The designs presented here are the work of the authors and may differ from the current HyspIRI mission baseline A CKNOWLEDGMENTS This research was carried out at the Jet Propulsion Laboratory California Institute of Technology and was sponsored by the Space Grant program and the National Aeronautics and Space Administration R EFERENCES  K W ar\002eld T  V  Houten C Hee g V  Smith S Mobasser B Cox Y He R Jolly C Baker S Barry K Klassen A Nash M Vick S Kondos M Wallace J Wertz Chen R Cowley W Smythe S Klein L Cin-Young D Morabito M Pugh and R Miyake 223Hyspiri-tir mission study 2007-07 002nal report internal jpl document,\224 TeamX 923 Jet Propulsion Laboratory California Institute of Technology 4800 Oak Grove Drive Pasadena CA 91109 July 2007  R O Green 223Hyspiri summer 2008 o v ervie w  224 2008 Information exchanged during presentation  S Hook 2008 Information e xchanged during meeting discussion July 16th  R O Green 223Measuring the earth wi th imaging spectroscopy,\224 2008  223Moore s la w Made real by intel inno v ation 224 http://www.intel.com/technology/mooreslaw/index.htm  T  Doggett R Greele y  S Chein R Castano and B Cichy 223Autonomous detection of cryospheric change with hyperion on-board earth observing-1,\224 Remote Sensing of Environment  vol 101 pp 447\226462 2006  R Castano D Mazzoni N T ang and T  Dogget 223Learning classi\002ers for science event detection in remote sensing imagery,\224 in Proceedings of the ISAIRAS 2005 Conference  2005  S Shif fman 223Cloud detection from satellite imagery A comparison of expert-generated and autmatically-generated decision trees.\224 ti.arc.nasa.gov/m/pub/917/0917 Shiffman  M Griggin H Burk e D Mandl and J Miller  223Cloud cover detection algorithm for eo-1 hyperion imagery,\224 Geoscience and Remote Sensing Symposium 2003 IGARSS 03 Proceedings 2003 IEEE International  vol 1 pp 86\22689 July 2003  V  V apnik Advances in Kernel Methods Support Vector Learning  MIT Press 1999  C Bur ges 223 A tutorial on support v ector machines for pattern recognition,\224 Data Mining and Knowledge Discovery  vol 2 pp 121\226167 1998  M Klemish 223F ast lossless compression of multispectral imagery internal jpl document,\224 October 2007  F  Rizzo 223Lo w-comple xity lossless compression of h yperspectral imagery via linear prediction,\224 p 2 IEEE Signal Processing Letters IEEE 2005  R Roosta 223Nasa jpl Nasa electronic parts and packaging program.\224 http://nepp.nasa.gov/docuploads/3C8F70A32452-4336-B70CDF1C1B08F805/JPL%20RadTolerant%20FPGAs%20for%20Space%20Applications.pdf December 2004  I Xilinx 223Xilinx  Radiation-hardened virtex-4 qpro-v family overview.\224 http://www.xilinx.com/support/documentation data sheets/ds653.pdf March 2008  G S F  Center  223Tdrss o v ervie w  224 http://msp.gsfc.nasa.gov/tdrss/oview.html 7  H Hemmati 07 2008 Information e xchanged during meeting about LaserComm  223W orldvie w-1 224 http://www digitalglobe.com/inde x.php 86/WorldView-1 2008  223Sv albard ground station nor way.\224 http://www.aerospacetechnology.com/projects/svalbard 7 2008  223Satellite tracking ground station 224 http://www.asf.alaska.edu/stgs 2008  R Flaherty  223Sn/gn systems o v ervie w  224 tech rep Goddard Space Flight Center NASA 7 2002  223Geoe ye-1 f act sheet 224 http://launch.geoeye.com/launchsite/about/fact sheet.aspx 2008  L-3 Communications/Cincinnati Electronics Space Electronics 7500 Innovation Way Mason OH 45040 T-720 Transmitter  5 2007 PDF Spec Sheet for the T720 Ku-Band TDRSS Transmitter  L-3 Communications/Cincinnati Electronics Space Electronics 7500 Innovation Way Mason OH 45040 T-722 X-Band  7 2007 PDF Spec Sheet for the T-722  J Smith 07 2008 Information e xchanged during meeting about GDS  J Carpena-Nunez L Graham C Hartzell D Racek T Tao and C Taylor 223End-to-end data system design for hyspiri mission.\224 Jet Propulsion Laboratory Education Of\002ce 2008  J Behnk e T  W atts B K obler  D Lo we S F ox and R Meyer 223Eosdis petabyte archives Tenth anniversary,\224 Mass Storage Systems and Technologies 2005 Proceedings 22nd IEEE  13th NASA Goddard Conference on  pp 81\22693 April 2005 19 


 M Esf andiari H Ramapriyan J Behnk e and E So\002nowski 223Evolving a ten year old data system,\224 Space Mission Challenges for Information Technology 2006 SMC-IT 2006 Second IEEE International Conference on  pp 8 pp.\226 July 2006  S Marle y  M Moore and B Clark 223Building costeffective remote data storage capabilities for nasa's eosdis,\224 Mass Storage Systems and Technologies 2003 MSST 2003 Proceedings 20th IEEE/11th NASA Goddard Conference on  pp 28\22639 April 2003  223Earth science data and information system esdis project.\224 http://esdis.eosdis.nasa.gov/index.html  M Esf andiari H Ramapriyan J Behnk e and E So\002nowski 223Evolution of the earth observing system eos data and information system eosdis\\224 Geoscience and Remote Sensing Symposium 2006 IGARSS 2006 IEEE International Conference on  pp 309\226312 31 2006Aug 4 2006  223Earth science mission operations esmo 224 http://eos.gsfc.nasa.gov/esmo  E Masuoka and M T eague 223Science in v estig ator led global processing for the modis instrument,\224 Geoscience and Remote Sensing Symposium 2001 IGARSS 01 IEEE 2001 International  vol 1 pp 384\226386 vol.1 2001  M Esf andiari H Ramapriyan J Behnk e and E So\002nowski 223Earth observing system eos data and information system eosdis 227 evolution update and future,\224 Geoscience and Remote Sensing Symposium 2007 IGARSS 2007 IEEE International  pp 4005\2264008 July 2007  D McAdam 223The e v olving role of tape in the data center,\224 The Clipper Group Explorer  December 2006  223Sun microsystems announces w orld s 002rst one terabyte tape storage drive.\224 http://www.sun.com/aboutsun/pr/200807/sun\003ash.20080714.2.xml July 2008  223P anasas 227 welcome 224 http://www panasas.com  R Domikis J Douglas and L Bisson 223Impacts of data format variability on environmental visual analysis systems.\224 http://ams.confex.com/ams/pdfpapers/119728.pdf  223Wh y did nasa choose hdf-eos as the format for data products from the earth observing system eos instruments?.\224 http://hdfeos.net/reference/Info docs/SESDA docs/NASA chooses HDFEOS.php July 2001  R E Ullman 223Status and plans for hdfeos nasa's format for eos standard products.\224 http://www.hdfeos.net/hdfeos status HDFEOSStatus.htm July 2001  223Hdf esdis project.\224 http://hdf.ncsa.uiuc.edu/projects/esdis/index.html August 2007  223W elcome to the ogc website 224 http://www.opengeospatial.org 2008  223Open gis Gis lounge geographic information systems.\224 http://gislounge.com/open-gis Christine M Hartzell received her B.S in Aerospace Engineering for Georgia Institute of Technology with Highest Honors in 2008 She is currently a PhD student at the University of Colorado at Boulder where she is researching the impact of solar radiation pressure on the dynamics of dust around asteroids She has spent two summers working at JPL on the data handling system for the HyspIRI mission with particular emphasis on the cloud detection algorithm development and instrument design Jennifer Carpena-Nunez received her B.S in physics in 2008 from the University of Puerto Rico where she is currently a PhD student in Chemical Physics Her research involves 002eld emission studies of nanostructures and she is currently developing a 002eld emission setup for further studies on nano\002eld emitters The summer of 2008 she worked at JPL on the HyspIRI mission There she was responsible for the science analysis of the data handling system speci\002cally de\002ning the data level and processing and determining potential mission collaborations Lindley C Graham is currently a junior at the Massachusetts Institute of Technology where she is working towards a B.S in Aerospace Engineering She spent last summer working at JPL on the data handling system for the HyspIRI mission focusing on developing a data storage and distribution strategy 20 


David M Racek is a senior working toward a B.S in Computer Engineering at Montana State University He works in the Montana State Space Science and Engineering Laboratory where he specializes in particle detector instruments and circuits He spent last summer working at JPL on compression algorithms for the HyspIRI mission Tony S Tao is currently a junior honor student at the Pennsylvania State University working towards a B.S in Aerospace Engineering and a Space Systems Engineering Certi\002cation Tony works in the PSU Student Space Programs Laboratory as the project manager of the OSIRIS Cube Satellite and as a systems engineer on the NittanySat nanosatellite both of which aim to study the ionosphere During his work at JPL in the summer of 2008 Tony worked on the communication and broadcast system of the HyspIRI satellite as well as a prototype Google Earth module for science product distribution Christianna E Taylor received her B.S from Boston University in 2005 and her M.S at Georgia Institute of Technology in 2008 She is currently pursing her PhD at the Georgia Institute of Technology and plans to pursue her MBA and Public Policy Certi\002cate in the near future She worked on the ground station selection for the HyspIRI mission during the summer of 2008 and looks forward to working at JPL in the coming year as a NASA GSRP fellow Hannah R Goldberg received her M.S.E.E and B.S.E from the Department of Electrical Engineering and Computer Science at the University of Michigan in 2004 and 2003 respectively She has been employed at the Jet Propulsion Laboratory California Institute of Technology since 2004 as a member of the technical staff in the Precision Motion Control and Celestial Sensors group Her research interests include the development of nano-class spacecraft and microsystems Charles D Norton is a Principal Member of Technical Staff at the Jet Propulsion Laboratory California Institute of Technology He received his Ph.D in Computer Science from Rensselaer and his B.S.E in Electrical Engineering and Computer Science from Princeton University Prior to joining JPL he was a National Research Council resident scientist His work covers advanced scienti\002c software for Earth and space science modeling with an emphasis on high performance computing and 002nite element adaptive methods Additionally he is leading efforts in development of smart payload instrument concepts He has given 32 national and international keynote/invited talks published in numerous journals conference proceedings and book chapters He is a member of the editorial board of the journal Scienti\002c Programming the IEEE Technical Committee on Scalable Computing a Senior Member of IEEE recipient of the JPL Lew Allen Award and a NASA Exceptional Service Medal 21 


this paper, we only generate the size-2 patterns in the BFS phase. It will be interesting to investigate the impact on the performance if the ?rst phase is stopped at a deeper level Also, the projection is a very ef?cient method for ?nding patterns, especially for parallel implementation of pattern mining algorithms [1]. We plan to adapt the projection ideas into our algorithm and design an ef?cient parallel algorithm for mining maximal hyperclique patterns References 1] R. Agarwal, C. Aggarwal, and V. Prasad. A Tree Projection Algorithm For Generation of Frequent Itemsets. pages 350 371, Feb 2001 2] R. Agrawal, T. Imielinski, and A. Swami. Mining Association Rules between Sets of Items in Large Databases. In Proc. of the ACM SIGMOD Conference on Management of Data, pages 207216,May 1993 3] R. Agrawal and R. Srikant. Fast Algorithms for Mining Association Rules. In Proc. of the 20th Intl Conference on Very LargeData Bases, 1994 4] R. Bayardo. Ef?ciently mining long patterns from databases In Proc. of the ACM SIGMOD Conference, 1998 5] R. Bayardo and R. Agrawal. Mining the Most Interesting Rules. In Proc. of the ACM SIGKDD Conference, 1999 6] D. Burdick, M. Calimlim, and J. Gehrke. Ma?a: AMaximal Frequent Itemset Algorithm for Transactional Databases. In Proc. of IEEE Conf. on Data Engineering, 2001 7] Y. Huang, H. Xiong, W. Wu, and Z. Zhang. A Hybrid Approach for Mining Maximal Hyperclique Patterns. In In Technical Report UTDCS-34-04, Department of computer science, University of Texas - Dallas, 2004 8] J.Han, J.Pei, and Y. Yin. Mining Frequent Patterns without Candidate Generation. In Proc. of the ACM SIGMOD International Conference on Management of Data, 2000 9] M.J.Zaki and C.Hsiao. ChARM: An ef?cient algorithm for closed itemset mining. In Proc. of 2nd SIAM International Conference on Data Mining, 2002 10] R.Rymon. Search through Systematic Set Enumeration. In Proc. Third Intl Conference on Principles of Knowledge Representation and Reasoning, 1992 11] H. Xiong, M. Steinbach, P.-N. Tan, and V. Kumar. HICAP: Hierarchial Clustering with Pattern Preservation. In Proc. of 2004 SIAM International Conference on Data Mining \(SDM 12] H. Xiong, P.-N. Tan, and V. Kumar. Mining Strong Af?nity Association Patterns in Data Set with Skewed Support. In Proc. of the Third IEEE International Conference on Data Mining \(ICDM Proceedings of the 16th IEEE International Conference on Tools with Artificial Intelligence \(ICTAI 2004 1082-3409/04 $20.00  2004 IEEE 





