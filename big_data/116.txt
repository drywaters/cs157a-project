  Privacy preserving Data Mining Algorithms without the  use of Secure Computation or Perturbation    Alex Gurevich                                                                     Ehud Gudes  Department of Computer Science Department of Computer Science Ben-Gurion University                                                Ben-Gurion University Beer-Sheva                                                                       Beer-Sheva 
Israel                                                                                Israel gurevich@cs.bgu.ac.il ehud@cs.bgu.ac.il    Abstract   In our era Knowledge  is not "just" information anymore, it is an asset. Data mining can be used to extract important knowledge from large databases These days, it is often the case that such databases are distributed among several organizations who would 
like to cooperate in order to extract global knowledge but at the same time, privacy concerns may prevent the parties from directly sharing the data among them The two current main methods to perform data mining tasks without compromising privacy are: the perturbation method and the secure computation method. Many papers and published algorithms are based on those two methods. Yet, both have some disadvantages, like reduced accuracy for the first and increased overhead for the second In this article we offer a  new paradigm to perform privacy-preserving distributed data mining without using those methods,  we  present three algorithms for 
association rule mining which use this paradigm, and discuss their privacy and performance characteristics  Keywords  Privacy, Association rules, Secure Computation, Distributed Data Mining    1  Introduction  In recent years the data mining community has faced a new problem. After it was shown how effective its tools are in revealing the knowledge locked within large databases, it is now required to develop methods that limit the power of these tools to protect the 
privacy of individuals. This requirement arises from popular concern about the powers of large corporations and  government agencies \226 concern which has been reflected in the actions of legislative bodies  Not surprisingly, the same corporations and government organizations which are the cause of concern are also among the main pursuers of such privacy-preserving methodologies. This is because of their pressing need to cooperate with each other on many data analytic missions \(e.g., for cooperative cyber-security systems, failure analysis in integrative 
products, detection of multilateral fraud schemes, and more The first approach that was taken toward privacy protection in data mining was to perturb the input \(the data\ before the mining [1   T h u s  it w as c l ai me d  t h e  original data would remain secret, while the added noise would average out in the output. This approach has the benefit of simplicity. At the same time, it takes advantage of the statistical nature of data mining and directly protects the privacy of the data. The drawback of the perturbation   approach is that it lacks a formal 
framework for proving how much privacy is guaranteed. Despite the existence of several models 1,5,7,9 f o r s t u d y i n g t h e p r iv ac y attai n ab le t h r o u g h  perturbation, there is no formal way to model and quantify the privacy threat from mining of perturbed data, and recently there  has been some evidence that for some data, and some kinds of noise, perturbation provides almost no privacy at all [14   At the same time, a second approach  for  privacy preserving data mining was developed, using cryptographic techniques [3,10   m o s t o f t e n t h e  
secure computation technique is used [6,11,23    This approach  became very  popular for two reasons first, cryptography offers a well defined model for privacy, which includes methodologies for proving and quantifying it. Second, there exists a vast toolset of cryptographic algorithms and constructs which can 


 be used for implementing privacy-preserving data mining algorithms While Secure computation \(SC\ has an advantage over perturbation in that it provides accurate results and not approximation, it is a much slower method and requires considerable computation and communication overhead for each SC step Naturally we would like to develop algorithms which include the advantages of the two approaches and do not include their disadvantages In this paper we offer a new paradigm to perform privacy-preserving distributed data mining without using the above  methods and we  present three algorithms for association rule mining which use this paradigm : One for vertically partitioned databases one for horizontally partitioned databases and one for the general case. The main idea is in the architecture which separates the entity which computes the results and the entity which finally gets the results and know what they mean. For each algorithm we present, we analyze its privacy  and its performance overhead The rest of this paper is structured as follows Section 2 presents the background and related work and especially the work by Vaidya and Clifton[22,23   and the related  work by  Rozenberg and Gudes 12,13  o n v e r tic a lly p a r ti tio n e d as s o c iatio n  r u le s  mining Section 3 presents our proposed architecture and the three algorithms and discusses their privacy and performance properties, and Section four is the conclusions   2. Background and Related Work  2.1 General   The centralized data mining model assumes that all the data required by any data mining algorithm is either available at or can be sent to a central site. A simple approach to data mining over multiple sources that will not share data is to run existing data mining tools at each site independently and combine the results. But, this will often fail to give globally valid results[3,19 I s s u es th a t cau s e a d i f f er en ce b et w een  local and global results include: values for a single entity may be split across sources., the same item may be duplicated at different sites, and will be overweighted in the results, and data at a single site is likely to be from a homogeneous population, hiding geographic, demographic or other distinctions between that population and others. Several algorithms have been proposed for distributed data mining. Cheung et al. proposed a method for horizontally partitioned data[4  an d  m o r e r ecen t w o r k h a s d ea l t w i th p r i v a c y  in this model[18 D i s t r i b u te d c l as s i f i c atio n w as a l s o  investigated.  A meta-learning approach has been developed that uses classifiers trained at different sites to develop a global classifier [19  T h i s c o ul d p r o t e c t  the individual entities, but it remains to be shown that the individual classifiers do not disclose private information. Recent work has addressed classification using Bayesian Networks in vertically partitioned data 14   a n d  i t d i sc u sse s si t u a t i o n s w h e r e t h e d i st r i b u t i o n  itself is the interesting property learned  2.2 Privacy preserving solutions    There has been some research considering how much information can be inferred, calculated or revealed from the data made available through data mining process, and how to minimize the leakage of information.. I  d a t a pe r t u r b a t i o n t e c hni que s a r e  used to protect individual privacy for classification, by adding random values from a normal/Gaussian distribution of mean 0 to the actual data values. One problem with this approach is the existing tradeoff between the privacy and the accuracy of the results More recently, data perturbation has been applied to Boolean association rules A n i nt e r e s t i ng f e a t ur e  of this work is a flexible definition of privacy; e.g., the ability to correctly guess a value of `1' from the perturbed data can be considered a greater threat to privacy than correctly learning a `0 Another line of  work is in cooperative computation between entities that mutually distrust one another Secure two party computation was first investigated by Yao [24  a n d l a te r g e n e r a lize d to mu lt ip a r ty  computation. The seminal paper by Goldreic  proves existence of a secure solution for any functionality. The idea is as follows: the function F to be computed is first represented as a combinatorial circuit, and then the parties run a short protocol to securely  compute every gate in the circuit. Every participant gets corresponding shares of the input wires and the output wires for every gate. This approach, though appealing in its generality and simplicity, means that the size of the protocol depends on the size of the circuit, which depends on the size of the input. This is inefficient for large inputs, as is the case in data mining. Nevertheless, the SC approach has become very popular. Lindell and Pinkas[18 e  SC protocols to achieve complete zero knowledge leakage for the ID3 classification algorithm for two parties with horizontally partitioned data. Du and Atallah[6 d i sc u ss se v e r a l p r o b l e m s i n t h e  relationships between Data Mining and Secure Multiparty Computation. Although this shows that secure solutions exist, achieving efficient secure solutions for privacy preserving distributed data mining is still open   


 2.3 Privacy preserving association rules mining   Association rules have become one of the most common techniques for data mining, many algorithms were developed, and the most popular one is the Apriori algorithm [2  P r iv acy p r e s e r v in g  as s o c iatio n  rules mining is also an active area of research Specifically, when data is distributed across multiple sites, and the sites have to mine it cooperatively, the privacy issue is most important. Kantarcioglu, and Clifton [16 i n v e s tig a te d t h e p r o b le m o f p r iv acy preserving distributed mining of association rules on Horizontally partitioned data. The algorithm uses three basic ideas, randomization of the first result encryption of  results at each local site and a final step of secure computation. Vaidya and Clifton [22  developed algorithms, we call them VDC, for privacy preserving association rule mining in Vertically partitioned data.  In such databases, item-set in one database is represented as a Boolean membership vector, and the main technique, which uses the Apriori algorithm as its base, computes securely the scalar product of two or more membership vectors and checks whether the result is larger than the support threshold. Again, quite  complex cryptographic and randomization processes are used. Gudes and Rozenberg[12 G R  h o w e d s o m e di s a dv a n t a ge s  of the VDC approach and presented a different method that uses also the Apriori algorithm but also uses the idea of faked transactions, and as a result saves considerable computation overhead Next we want to present the last two algorithms in more detail since they are very related to the work presented here In the VDC algorithm,  for the two-party situation 23 t h e alg o r i t h m u s e s th e ap r i o r ig e n f u n c tio n to  generate all candidate itemsets. For each found itemset, the algorithm calculates the support by secure computation of the scalar product. For the n>2 parties case [22 t h ey u s e th e f ac t th at a s o lu tio n to f in d i n g  association rules in vertically partitioned data is to have each site generate a list of the transaction identifiers that contain all the items in the item set which are present in that site. The intersection of these lists is the set of transactions that support the rule. To obtain this intersection, VDC uses commutative encryption; it has the property that the same data item encrypted with k different keys gives the same cipher text even if the order of encryption differs. To compute the list intersection\222s size, each site picks a local key and uses it to encrypt all of its items. It then sends the encrypted list to the next site, which does the same thing. After all the sites have encrypted all the lists, they can intersect them because the encryption is commutative. The resulting intersection set\222s size gives the required result. None of the sites sees an unencrypted item other than its own, and decryption is never performed, so none of the sites learns anything from the other sites[22   As mentioned above, the VDC algorithms involve considerable computation overhead, and also have the disadvantage that the relevant parties know exactly the item-set which is currently being computed. Another problem of the VDC  algorithms is  the fact that all parties know the exact support of each itemset which can compromise privacy. This fact can cause almost complete exposure of the real data as was demonstrated in [13   Th at m o t i v a t ed R o z en b er g t o  propose another way to solve the problem using the fake transactions[12,13,21 me t h o d  T h is  me t h o d  obscures the exact support from the parties and additionally reduces the communication between the sides. For example, let us describe the two-party algorithm in more details. The n>2 case is very similar. Both algorithms  follow the basic collaborative Apriori algorithm of VDC  H ow e ve r  b e fo r e  applying the algorithm there is a pre-processing step that populates the individual databases with fake transactions. After this step, each party can send the resulting database to the opposite party to calculate the frequent itemsets in the resulted database. Since the fake transactions do not change real data, but only add fake information, all items with real high support will be found and we only need to eliminate the false positive results In the first phase, one site is designated as a Master which initiates the protocol and will get the results and the other site as a Slave, which only contributes its information but will not do any global computations The Master is looking for all large itemsets according to its own real transactions, and then check whether the found itemsets are present in the Slave real transactions. This is done with the help of a third untrusted party \(this party is not trusted with the database, but it is trusted with computations\ or using secure computation. The parties change roles at the end of the phase The GR  algorithms also have some problems. Here are few of them 1\hey expose some real data to the parties \(even though the parties don\222t know which data is real and which is fake 2\All the intermediate results are given to the party/parties which hold some database part, which increases the possibility to infer information by this party 3\ They are sensitive to the probing attack. Although in [12 t h e r e is a me t h o d c alle d t h e e ap p r o x im at io n  method which considerably reduces the risk of a probing attack. The idea is basically  to report success 


 whenever the support is in the range of [S, S-e n d  not using an exact support threshold  The problems with both the VDC and GR algorithms motivated us to propose some new, more general way to solve the privacy-preserving association rules mining problem. The main idea is an architectural one We add to the N involved parties two new components called Miner and Calculator which divide the work of the various algorithms and thus achieving privacy. The algorithms based on this idea  will be described in the next section  3. The new architecture and algorithms  The new architecture is depicted in Figure 1. It is composed of the participating databases, a Miner which decides what computation to be done, and the Calculator which computes without really knowing what itemset it computes. It is important to note, that only the Miner and the participants get the mining results while the Calculator only performs auxiliary computations, without knowing their meaning. Based on this basic architecture we develop three different models and algorithms. The first model supports vertically partitioned association rules mining, the second model supports horizontally partitioned association rules mining, and the third model is general and supports any data mining task. All three models use the following basic assumptions 1\ The  database  is distributed between N participants vertically  or horizontally  partitioned 2\ There is a computer called "miner" which manages the data mining process and reports the results to the participants 3\he miner has no part of the database 4\ There is a computer called "calculator" which performs all the calculations 5\he "calculator" has no part of the database 6\ There is no collaboration between all the participants from paragraph 1 7\ The model is semi \226 honest  8\ There is no external knowledge present at any side  Next we present first model which deals with vertically partitioned data    Figure 1: the Architecture  3.1 First algorithm  for vertically partitioned DB   The model see Figure 1  The goal  Computation of the frequent itemsets in vertically partitioned database without compromising the participants\222  privacy  Privacy definition  The privacy will be compromised if it will be possible for any participant to compute some specific value of the database with high probability. By specific value we mean a value in a database cell which belongs to some specific transaction  The algorithm  Step 1 The miner sets the variable i the size of the itemsets being checked now  to 1  Step 2 The miner chooses a random permutation of itemsets of i elements and then iteratively select each of them  Step 3 For each itemset from step 2 If all the subsets of current itemset are frequent apriori principle\,  the miner orders all participants to encrypt   the Transaction-ids of the   transactions using the same key.  The miner then asks every participant about  frequency of current itemset The participants send the encrypted numbers of all relevant transactions-ids to the "calculator". The calculator" finds the intersection of    the encrypted transactions-ids.  The "calculator" informs the miner if the  current set is frequent   Step 4  While i is smaller from the number of database attributes The value of i is incremented by 1 Miner  calculator Db1 Db2 Db3  Dbn 


 The algorithm returns to Step 2   Step 5  The miner sends the results to the participants  Although this algorithm is somewhat similar to the VDC algorithm in [23 it i s d i f f er en t in t w o r es p ect s    First, the calculator doesn\222t know which itemset is being checked, and the  exact support value is not disclosed. Furthermore, only one level of encryption is used. \(only transaction\226ids are encrypted and not the itemsets  The privacy analysis  The participants and the "miner" learn nothing but the results as in  secure computation The "calculator" learns the support of the itemsets but without the possibility to know which itemset is being tested No probing attack is possible, since the miner does not hold any part of the database However, since the results are known to each participant, there is a probability of exposure in case the local support is exactly the support threshold as discussed in detail in  T h e r e   t h e e a pp r o xi m a t i o n method was suggested and it can be used here as well Note that the problem of inferring knowledge from the results of data mining is independent of the algorithm used and exists also in all secure computation based methods  The computation and communication cost  In VDC  two sided algorithm, for every itemset frequency computation it was  necessary to perform secure scalar product computation which takes for every tested set at least three times sending the N values between two sides. In our algorithm in the worst case every party sends once N values to the calculator, which is much less communication overhead. In the n-party case we have the same communication as in VDC but our algorithm is simpler, since we use one level of encryption only Comparing to GR we save all the preprocessing stage of sending the database with faked transactions   3.2 Second algorithm  for horizontally partitioned DB   The model  We use the same model but for horizontally partitioned database and  with the addition of one more "calculator". The modified architecture is depicted in Fig. 2. We also add the assumption  that the database is binary. The goal and privacy definition stay as in the first algorithm We are going to use the following lemma which was already proven in [16  Lemma : If the database is horizontally partitioned and if an itemset has support > p% globally, it must have support > p% in at least one of the individual parties databases  3.2.1  The algorithm\( first version without using  the lemma   The first version is not realistic since it requires exponential space, but its useful for explaining the concept  Step 1 The "miner" sends to every participant two instructions  to create two databases each containing for each itemset the frequency of its occurrence Then each   participants   add to   each such frequency a random noise sent by the miner one  database  with  positive noise,  and  the other with negative noise  to send the first database to "calculator1 and  to  send  the  second    database   to calculator2 After execution of this step "calculator1" and calculator2" both have the whole information about the number of appearances of each itemset but with noise  Step 2 The "miner" performs apriori  algorithm  against the calculators. When the miner needs to compute support for some itemset, he sends the request to both calculators and some random number to one of them The first calculator, who gets the random number adds to it the value which appears in his database about this itemset and sends the result to the second calculator. The second  adds his value and sends the result back to the miner. The miner divides the result by  \(2 * \(size of the database\nd gets the real support Privacy analysis  The parties \226 learn nothing but the results The calculators \226 learn nothing; because of the random number they don\222t know the real support The miner \226 learns global support of the itemsets but nothing on the local databases  Communication overhead  Much less than in the first algorithm since the parties communicates only once with the calculators, although in this one time they send a large database Let us see a small example 


 Suppose we have three parties :d1, d2, d3 ; the "miner and two calculators. Let us take a look on some itemset ABC, see Figure 2 The Miner sends the random noises: 3,2,1 to the three parties respectively   Figure 2:  The second algorithm  Next, all the parties add the noise to the number of appearances of every set and send the results to both calculators, in this case for ABC: the first party sends 2+3 = 5 and 2-3 = -1, the second 2+2 = 4 and 2-2=0 the third 2+1=3 and 2-1=1 Next \(see Figure 3\ng the Apriori algorithm to compute support of some itemset, the Miner selects some random number R, sends R to first calculator which adds his support about the itemset and sends R1 to the  second calculator, which  computes R2 and sends it to the Miner. The Miner computes R2 \226 R\\(2*3\ and this is the support of itemset ABC    Figure 3: Second algorithm \226 computing the support  3.2.2 Second version \(using the lemma  Basically the same algorithm, except for the following  changes 1 Initially, the miner chooses an encryption key to encrypt each item-set and send it to all participants 2 The participants, before sending their two databases to the calculators encrypt the corresponding itemsets 3 the participants compute the frequent itemsets locally and send results to the miner The Miner does the Apriori only for itemsets of which one of the local parties has found frequent! \(i.e. using the Lemma For those   itemsets, it sends the calculators their encrypted for to enable them to retrieve their respective frequency  Privacy analysis  Same as the first algorithm  except  that the Miner now knows frequency of itemset at local sites  The purpose of the encryption is to prevent the calculators from knowing that a particular itemset is frequent at some local database  To prevent the Miner from knowing the local site frequency, we can add an extra Mediator site. The mediator will not know the itemset which is currently being tested, but will get the frequency counts from the various sites and just send the Miner a flag whether there is a site in which the frequency of the itemset is above the threshold. This increases the privacy but introduces additional communication overhead The computation and communication overhead are less than in the previous  algorithm because of the use of the Lemma, but obviously, this algorithm also requires exponential space for each of the local databases, therefore we need the third  version   3.2.3 Third version \(using Apriori and the lemma  This algorithm is a mix of the first algorithm \(3.1 and the last one The Miner performs the Apriori algorithm, and at each step asks the participants to send the two frequency results with the noise to the calculators. Then the Miner asks for the support from the calculators as before. This algorithm has the same security properties as the previous two, however, no encryption is necessary, since as in the first algorithm, the Claculators don\222t know which itemset is being computed The  communication overhead of this version  is higher than in the first two versions and is similar to the overhead in the first algorithm. The main advantage of-course is that the local parties don\222t need to create and send large \(exponential\  databases  3.3 Third algorithm General DB   The mode l The same as in the first model, one miner, one calculator and N participants. Also, all the definitions stay as in the first algorithm,  except the for goal  The goal  To perform any data mining algorithm without compromising privacy  The algorithm  The mine r   Calculato r 1 Calculato r 2 A B C  1 | 1  1 1 2 | 1  1 1 3 |0  0  1 A B C  4 | 1  1 1 5 | 1  1 1 6 |0  0  1 A B C  7 | 1  1 1 8 | 1  1 1 9 | 0  0 1 The mine r  Calculato r 1 Calculato r 2 


 Step 1 The "miner" tells to the participants to add N versions of  specific pseudorandom  noise to their data and to send it to the "calculator". That it, the calculator gets from each participant its database N times.\(with a different noise  Step 2 The miner sends to the calculator some "seed" to create the pseudo-random noise. This seed will create a noise which is identical to one of the N noises, but the calculator doesn\222t know which one it is  Step 3 For every created noise the calculator subtract the noise from all N databases and perform the mining and sends the results back to the miner  Step 4 The miner picks up the right results  Privacy analysis  The parties \226 learn nothing but the results The miner \226 learns global data mining results but nothing on the local databases The calculator \226 The Calculator has one real database out of the N databases, so he has the probability of 1/N to learn everything! Obviously we can reduce this probability by adding some more artificial partcipants but each such participant increases the computation overhead  Computation and Communication overhead  The computation overhead is much higher, it is essentially multiplied by N. The communication overhead is N*overhead of Algorithm 2, but this is a one-shot overhead, and the communication overhead between the Miner and the Calculator is greatly reduced \(one message only  4. Conclusions   We discussed the problem of privacy-preserving data mining in distributed databases. We suggested a new architecture \(paradigm\ which is based on using two separate entities: a Miner and a Calculator, both not having parts of the database. We presented three algorithms which are based on this paradigm, one for Vertically partitioned data, one for Horizontally partitioned data, and one for any data mining method In contrast to the previously known methods of Perturbation or Secure computation, our algorithms produce accurate results \(better than perturbation\, but usually with much less computation and communication overhead than secure computation In the future we plan to investigate these algorithms and evaluate their performance on real-life databases   Acknowledgment   Thanks to the reviewers for their useful comments    References  1 R  A g r a w a l a nd R   Sr i k a n t  P r i v ac y pr es e r v i ng da t a  mining. In Proc. of the ACM SIGMOD\22200, pages 439\226450 Dallas, Texas, USA, May 2000  2 R  A g r a w a l and R  Sr i k a n t  Fa s t A l g o r i t h m s f o r M i ni ng  Association Rule  Proceedings . of the 20th Int'l Conf. on VLDB}, Santiago, Chile, 1994  3 P C h an A n E x t e ns i b l e M e t a L ear n i ng A ppr o a c h  f o r  Scalable and Accurate Inductive Learning. PhD thesis Department of Computer Science, Columbia University, New York, NY, 1996. \(Technical Report CUCS044-96  4  W  L  C h e u n g  V  N g  A  W  C  F u a n d Y  F u  Efficient mining of association rules in distributed databases IEEE Transactions on Knowledge and Data Engineering 8\(6\:911-922, Dec. 1996  5  I   D in u r a n d K  N is s im R e v e a l in g in f o rm a tio n w h i le  preserving privacy. In Proc. of PODS\22203, pages 202 \226 210 June 2003  6 W  D u and M  J  A t a l l a h Sec u r e m u l t i par t y co m put at i o n  problems and their applications: A review and open problems. In Proceedings of the 2001 New Security Paradigms Workshop, Cloudcroft, New Mexico, Sept. 11-13 2001  7 C  D w o r k a nd K  N i s s i m  P r i v ac y pr es er v i ng dat a m i ni ng  on vertically partitioned databases. In Proc. of CRYPTO\22204 August 2004  8  E v fi mi e v s k i  J  Ge h r k e   a n d R  S r i k a n t L i mit in g  privacy breaches in privacy preserving data mining. In Proc of PODS\22203, pages 211\226222, San Diego, California, USA June 9-12 2003  9 A  E v fi mi e v s k i R  S r i k a n t  R  A g r a w a l  a n d  J  G e h r k e  Privacy preserving mining of association rules. In Proc. of ACM SIGKDD\22202, pages 2 17\226228, Canada, July 2002   B  G i l bu r d A  Sc hus t e r  and R  W o l f f  kt t p a new  privacy model for large-scale distributed environments. In Proc. of ACM SIGKDD\22204, pages 563\226568, 2004   O  G o l dr e i c h S  M i c a l i  and A  W i g der s o n H o w t o play any mental game \226 a completeness theorem for 


 protocols with honest majority. In 19th ACM Symposium on the Theory of Computing, pages 218-229, 1987   E  G u d e s  B  R o z e nber g  C o l l abo r a t i v e P r i v acy  Preserving Frequent Item Set Mining in Vertically Partitioned Databases. Proceedings of DBSec 2003: 91-104   E  G ude s  B  R o z e nbe r g  A n al y s i s o f T w o  A ppr o a c h es  for Association Rules Mining in Vertically Partitioned Databases , Proceedings of ICDM Workshop on Privacy and Security Aspects of Data Mining, Brighton, UK, November 2004   Z  H u ang  W  D u  an d B  C h en D e r i v i ng pr i v a t e  information from randomized data. In Proc. of ACM SIGMOD\22205, 2005   M  K a nt a r c i o g l u and C  C l i f t o n Pr i v ac y pr es e r v i ng  distributed mining of association rules on horizontally partitioned data. In The ACM SIGMOD Workshop on Research Issues on Data Mining and Knowledge Discovery DMKD'02\, June  2002  16 M  K a n t a r c i o g l u  C  C lif to n  P r iv a c y P re s e rv in g  Distributed Mining of Association Rules on Horizontally Partitioned Data. IEEE Trans. Knowl. Data Eng. 16\(9 1026-1037,  2004   H  K a r g upt a S  D a t t a  Q  W a ng  an d K   Si v a kum ar   On the privacy preserving properties of random data perturbation techniques. In Proc. of ICDM\22203, page 99 Washington, DC, USA, 2003. IEEE Computer Society   Y  L i nd el l  and B  P i nk as  P r i v acy pr es e r v i ng da t a  mining. In Proc. of CRYPTO\22200, pages 36\22654. SpringerVerlag, 2000  19 A  P r od r om i d i s  P  C h an  a n d S St ol f o M e t a l e a r n i n g in distributed data mining  systems: Issues and approaches chapter 3. AAAI/MIT Press, 2000   S J  R i z v i and J  R  H a r i t s a  P r i v ac y pr es e r v i ng  association rule mining. In  Proceedings of 28 th International Conference on Very Large Data Bases. VLDB, Aug. 20-23 2002    B.Rozenberg , MSc thesis, Ben-Gurion University 2003  22 J  V a id y a C  C lif to n  S e c u re  s e t i n t e r s e c tio n c a r d i n a li ty  with application to association rule mining. Journal of Computer Security 13\(4\: 593-622 \(2005  23 J  V a id y a C  C lif to n  P r iv a c y P r e s e r v in g A s s o c ia tio n  Rule Mining in Vertically Partitioned Data. In Proceedings of SIGKDD 2002, Edmonton, Alberta, Canada, 2002  24 A  C  Y a o H o w  t o ge n e r a t e  a n d e x ch an ge s e cr e t s   In Proceedings of the 27th IEEE Symposium on Foundations of Computer Science pages 162-167,  1986           


Number of Processors Time \(seconds 0 20000 40000 60000 80000 1 2 4 8 Figure 9 Average execution time per node to nd frequent 3-itemsets 2-itemsets processed by each node in our four different system conﬁgurations Note that the number of candidate 2itemsets for the 1-node case is approximately the same as the average number of candidate 2-itemsets for the 2-node case This result is consistent with the observed total and average execution times for the 1-node and 2-node cases There is signiﬁcant reduction in the average number of candidate 2-itemsets processed for the 4-node and 8-node cases over the 1-node and 2-node cases This result represents the nonuniform distribution of itemsets over the local databases as well as the effective reduction of the candidate itemsets by the Inverted Hashing and Pruning technique Number of Candidate 2-itemsets 0 100000 200000 300000 400000 MIHP 2-node PM IHP 4-node PM IHP 8-node PM IHP Figure 10 Average number of candidate 2itemsets per node Figure 11 shows the average number of candidate 3itemsets processed by each node We included the number of candidate 3-itemsets processed in Apriori to demonstrate the usefulness of the Inverted Hashing and Pruning The number of candidate 2-itemsets for Apriori was about 82 million which is why we did not show that in Figure 10 We can observe the same pattern of reduction in the candidates 3-itemsets as in the candidate 2-itemsets This reduction in the average number of candidate itemsets processed by each processing node may be the most clear explanation for the high increasing rate of the speedup observed as the number of processing nodes increases Number of Candidate 3-itemsets 0 200000 400000 600000 800000 Apriori MIHP 2-node PM IHP 4-node PM IHP 8-node P M IHP Figure 11 Average number of candidate 3itemsets per node We also ran a test with a larger database 8 weeks of the Wall Street Journal published from January 2 1991 through February 22 1991 February 23rd was a Wall Street Journal holiday There were 6,170 documents and 64,191 unique words of which 31,948 were frequent words at the minimum support level of 0.03 i.e 2 out of 6,170 documents The 1-node system required 845,702 seconds to nd 1,554,442 frequent 2-itemsets whereas the 8-node system required 33,183 seconds This performance represents a superliner speedup of 25.5 of the 8-node system over the 1-node system Thus we can conclude that the performance of PMIHP is quite scalable when the database is large and the minimum support level is low which is the case of high workload The 1-node case generated 16,174,357 candidate 2itemsets whereas the 8-node case generated 2,459,629 candidate 2-itemsets per node on the average The total number of candidate 2-itemsets counted by the 8 nodes were 19,677,031 which means that only 21.7 of the candidate 2-itemsets were counted at more than one processing node This implies that the distribution of words across the 8-week sample of the Wall Street Journal is quite skewed In the Count Distribution algorithm all the nodes count the same set of candidate itemsets in each pass over the database regardless of the distribution of items over the local databases On the other hand in our PMIHP algorithm not all candidate itemsets are counted at more than one node when the distribution of items over the local databases is not uniform Obviously the more skewed the data distribution the better the performance of PMIHP Cheung et al 4 propos ed s e v e ral approaches to partition the databas e 0-7695-2132-0/04/$17.00 \(C Proceedings of the 18th International Parallel and Distributed Processing Symposium \(IPDPSê04 


to achieve a high degree of skewness Text documents arranged in a chronological order do appear to have a high degree of skewness and beneﬁt the PMIHP algorithm 4 Conclusions The proposed Parallel Multipass with Inverted Hashing and Pruning PMIHP algorithm is a parallel version of our Multipass with Inverted Hashing and Pruning MIHP algorithm and it is effective for mining frequent itemsets in large text databases The Multipass approach reduces the required memory space at each processor by partitioning the frequent items and pro cessing each partition separately Thus the number of candidate itemsets to be processed is limited at each instance The Inverted Hashing and Pruning is used to prune the local and global candidate itemsets at each processing node and it also allows each processing node to determine the other peer processing nodes to poll in order to collect the local support counts of each global candidate itemset PMIHP distributes the workload to multiple processing nodes to reduce the total mining time without incurring much parallelization overhead The average number of candidate itemsets to be counted at each processing node is much smaller than the case of sequential mining while the time for the synchronization between processing nodes to exchange the count information for the global candidate itemsets is very small compared to the total execution time PMIHP is able to exploit the natural skewed distribution of words in text databases and demonstrates a superlinear speedup as the number of processing nodes increases It has a much better performance than well-known parallel Count Distribution algorithm 2 becaus e the a v erage number of candidate itemsets to be counted at each processing node is much smaller especially when the minimum support level is low Overall the performance of PMIHP is quite scalable even when the size of the text database is large and the minimum support level is low which is the case of high workload References  R  A gra w al and R  S r i kant   Fast Al gori t h ms for M i n i n g A ssociation Rules Proc of the 20th VLDB Conf  1994 pp 487–499  R Agra w a l and J C S hafer  Paral l e l M i n i n g o f A ssoci at i o n Rules IEEE Trans on Knowledge and Data Engineering  Vol 8 No 6 1996 pp 962–969 3 M  S  C hen J Han and P  S  Y u   Dat a Mi ni ng An Overview from a Database Perspective IEEE Trans on Knowledge and Data Engineering  Vol 8 No 6 1996 pp 866–883 4 D  W  C heung S  D L ee and Y  Xi ao  E f f ect of Dat a S k e w ness and Workload Balance in Parallel Data Mining IEEE Trans on Knowledge and Data Engineering  Vol 14 No 3 2002 pp 498–514 5 S  M  C hung and J Y ang  A Par al l e l D i s t r i b ut i v e J oi n A l gorithm for Cube-Connected Multiprocessors IEEE Trans on Parallel and Distributed Systems  Vol 7 No 2 1996 pp 127–137  R  F e l dman and H Hi rsh F i ndi ng Associ at i ons i n Col l ections of Text Machine Learning and Data Mining Methods and Applications  R Michalski I Bratko and M Kubat editors John Wiley and Sons 1998 pp 223–240  R F e l dman I Dagen and H  H i rsh Mi ni ng T e xt Usi n g Keyword Distributions Journal of Intelligent Information Systems  Vol 10 No 3 1998 pp 281–300  C  Fox L e x i cal Anal ysi s and S t opl i s t s   Inforamtion Retrieval Data Structures and Algorithms W.FrakesandR Baeza-Yates editors Prentice Hall 1992 pp 102–130 9 M  G or don and S  Dumai s Usi ng L a t e nt S e mant i c I nde xi ng for Literature Based Discovery Journal of the Amer Soc of Info Science  Vol 49 No 8 1998 pp 674–685  J Han J P e i  and Y  Y i n Mi n i n g F r equent Pat t e r n s w i t hout Candidate Generation Proc of ACM SIGMOD Intêl Conf on Management of Data  2000 pp 1–12  J D Holt and S  M Chung Multipass Algorithms for Mining Association Rules in Text Databases Knowledge and Information Systems  Vol 3 No 2 Springer-Verlag 2001 pp 168–183  J D Hol t and S  M C hung Mi ni ng Associ at i o n R ul es Using Inverted Hashing and Pruning Information Processing Letters  Vol 83 No 4 Elsevier Science 2002 pp 211–220  J D Hol t and S  M C hung Mi ni ng associ at i o n R ul es i n Text Databases Using Multipass with Inverted Hashing and Pruning Proc of the 14th IEEE Intêl Conf on Tools with Artiìcial Intelligence  2002 pp 49–56  J S  Park M S  C hen and P  S  Y u   Usi n g a Hash-B a sed Method with Transaction Trimming for Mining Association Rules IEEE Trans on Knowledge and Data Engineering  Vol 9 No 5 1997 pp 813–825  G  S a l t on Automatic Text Processing The Transformation Analysis and Retrieval of Information by Computer  Addison-Wesley Publishing 1988  E  M V oorhees and D K Harmon edi t o rs The Fifth Text Retrieval Conference  National Institute of Standards and Technology 1997  O R  Z a i a ne and M L  Ant o i ne C l assi f y i n g T e x t D ocuments by Associating Terms with Text Categories Proc of the 13th Australian Database Conf  2002 0-7695-2132-0/04/$17.00 \(C Proceedings of the 18th International Parallel and Distributed Processing Symposium \(IPDPSê04 


  11 could be improved by a simple modification of the feed by adding a small tuning vane to th e feed. Therefore, it can be stated that some improvement can be expected by modification of the feeds, and adaptation of the test antenna in such a way that surrounding Ku-band element are closed   Figure 28 Reflection coefficient of Ku-band stacked patch antenna element in dual-frequency antenna stack  Figure 29 shows the influence of the L-band slots on the return loss of the Ku-band antenna element. To this end, the four connectors of the L-band elements were alternately open and terminated by means of 50 loads. The deviations were measured with respect to the set-up where all connectors were terminated Apparently, the deviations are acceptable  Figure 29 Influence of L-band termination on return loss of Ku-band antenna element, with and without termination Figure 30 and Figure 31 show the isolation between the Lband and Ku-band elements in L-band and Ku-band respectively. To this end the S21-parameters have been measured. These figures reveal that the mutual coupling between the L-band and Ku-band elements is sufficiently small  Figure 30 Measured isolation between L-band and Ku-band antennas in L-band frequencies  Figure 31 Measured isolation between L-band and Ku-band antennas in Ku-band frequencies From these measurements it can be concluded that opportunities should be considered to improve the design of the dual-frequency antenna \(by optimizing the feeds of the Ku-band elements antenna and the measurement set-up \(closure of surrounding Ku-band ports and use of appropriate connectors for the open Ku-band ports 7  M ODIFIED DUAL FREQUENCY ANTENNA  In order to benefit the str ong points of the two separate designs as discussed in section 4, an alternative antenna is proposed that exploits the properties of a \221best of both worlds\222 solution employing ideas from both designs. The modified antenna possesses an aperture fed L-band patch of a similar form to first design, but situated towards the bottom of the stack. Ku band el ements are located within the L-band perforations and para sitic patches are situated above a foam spacer \(see Figure 32 and Figure 33\A measurement campaign is underway to assess the behaviour of this modified test antenna 


  12  Figure 32 Bottom view of dual frequency antenna tile with perforated L-band patc h in lower layer with Kuband patches  Figure 33 Layer stack with perforated L-band patch in lower layer with Ku-band patches  8  B EAM FORMING N ETWORK  A major keystone for the su ccess of phased array antenna onboard aircraft is the capability of steering the main beam in the direction of the geosta tionary satellites. This requires the inclusion of a broadband beam forming network. Beam steering can be realized by adding RF-phase shifters and LNA\222s to the antenna elements of the array. However traditional phase shifters in ge neral have a narrow band, and hence do not yield the re quired broadband capability Alternative technologies for broadband beam forming are switched beam networks \(using Butler matrices innovative designs for RF-compone nts such as phase shifter LNA components in \(M\IC technology, or beam forming by using opti cal ring resonators  The German SME IMST is involved in several projects for development of electronica lly steerable phased array antennas for satellite communication. In the NATALIA project \(New Automotive Track ing Antenna for Low-cost Innovative Applications\ ESA, IMST is investigating the possibility of realizing a compact costeffective solution for a recei ve-only full electronically steerable antenna for cars in Ku-band. This antenna is a planar array composed of approximately 150 patches circularly polarised by using a 90\260 hybrid, and arranged in a hexagonal fashion. Each patc h is equipped with a MMIC corechip containing a phase sh ifting unit, LNA and digital steering logic  In the Netherlands, a consortiu m \(consisting of University of Twente, Lionix BV, National Aerospace Laboratory NLR and Cyner Substrates developing in the national FlySmart project technology for a broadband optical beam forming network. For the steering of the beam of the conformal phased array a squi nt-free, continuously tunable mechanism is proposed that is based on a fully integrated optical beam forming network \(OBFN optical ring resonators \(ORRs as tunable delay elements. A narrowband continuously tunabl e optical TTD device is realized as a recirculating wa veguide coupled to a straight waveguide. This straight wave guide can behave as a bandpass filter with a periodic, bell-shaped tunable group delay response. The maximum group delay occurs at a tunable resonance frequency. A larger delay-bandwidth product can be achieved by cascading multiple ORR sections. A complete OBFN can be obtaine d by grouping several delays and combining elements in one optical circuit. Such an OBFN can be realized on a si ngle-chip. Electrical/Optical E/O O E by means of filter based single-sideband modulation suppressing the carrier lanced coherent optical detection. Further details of the optical beamforming network have been presented in Re The proof-ofconcept has been shown by manufacturing a chip for an 8x1 OBFN. Essential components of the OBFN are the optical modulators, which are used to modulate the light in the ORR system 9  C ONCLUSIONS  For enhanced communicati on on board aircraft, novel antenna systems with broa dband satellite-based capabilities are required. So far, existi ng L-band satellite based systems for communications are used primarily for passenger application \(APC\i nistrative communications AAC and now data are tending to evolve towards broadband dig ital applications \(Voice over IP\any studies are going on worldwide to employ Kuband TV geostationary sate llites for communication with mobile terminals on aircraft The inbound traffic is about 5 times higher than the outbound The inbound traffic requires the availability of a broadband Ku-band antenna in receive mode only. The outbound traffic services can be supplied by the Inmarsat SBB link, whic h requires the installation of an L-band transmit antenna. In order to avoid both the installation of L-band antenna and Ku-band antenna, the concept of a hybrid dual frequency antenna operating L 


  13 band and Ku-band with low aerodynamic profile has been investigated in this paper. Keyaspects of this research are 200  Design and testing dual-fre quency antenna elements operating in both L-band and Ku-band 200  Conformal aspects of Ku-band phased array antennas 200  Beam forming algorithms for planar and conformal phased array antennas Two designs for dual-frequency antenna tiles consisting of 8x8 Ku-band antenna elements and one L-band element The designs have been analysed by means of computer simulations. Both designs show promising performance both in L-band and Ku-band. The design with slotted Lband antenna has a resonant fre quency in receive mode with a bandwidth of about 1 GHz. The Ku-band antenna is a stacked patch configuration where a parasitic element is placed above a lower patch separated by dedicated space filler. The manufactured protot ype antennas indicate that the bandwidth is sufficiently large In order to be able to communicate with geostationary satellites also at high latitudes e.g. during inter-continental flights\stem should have sufficient performance at low elevation angles. The antenna Ku-band system is required to have a small beamwidth \(to discriminate between the satellite signals\gain 30 dB angles. The effects of these requirements on the size and positioning of the antenna on the aircraft fuselage have been investigated. These requirements can be best satisfi ed by installing two planar phased array antennas on both side s of the fuselage with at least 1600 Ku-band elements. Each element has two feed lines, one for each polarization Every feed line has to be connected to the beam formi ng network. This means that the connections cannot be routed to one of the four sides of the antenna. Instead the concept of vertical feed lines \(by means of vias in a sufficiently thick substrate recommended. These vertical f eed lines connect the L-band and Ku-band antenna elements in the upper layer with feed networks in multiple lower laye rs. This vertical feed line system was not available so far due to manufacturing problems The performances of one dua l-frequency antenna design have been investigated by manufacturing two test antennas without vertical feed line syst em. The first antenna contains only a multilayer structure with L-band slots and 8x8 Kuband stacked patches. The performances of the L-band slots and Ku-band stacked patches c ould be measured separately It was concluded that opportun ities should be considered to improve the design of the dual-frequency antenna \(by optimizing the feeds of the Ku-b and elements the dual frequency test-antenna and the measurement set-up More important, however, is the realization of a mechanically stable vertical feed line system, so that the properties of L-band and Ku-band elements can be measured adequately The second test antenna contains only a multilayer structure with 8x8 Ku-band stacked patches and a feed network with 8 combiners, where each comb iner coherently sums 8 antenna elements. In combination with a prototype 8x1 OBFN, a Ku-band phased arra y antenna is obtained of which the beam can be steered in one direction. This second test antenna is used to analyze the broadband properties of the 8x8 Ku-band antenna array and 8x1 OBFN. The measured performances of this antenna are presented in Ref   A CKNOWLEDGMENT  This work was part of the EU 6 th Framework project ANASTASIA., and the FlySmart project, supported by the Dutch Ministry of Economic A ffairs, SenterNovem project numbers ISO53030 The FlySmart project is part of the Eureka PIDEA  project SMART Cyner Substrates is acknowle dged for technical assistance during the fabrication of the prototype antennas 


  14 R EFERENCES  1  P. Jorna, H. Schippers, J. Verpoorte, \223Beam Synthesis for Conformal Array Antennas with Efficient Tapering\224 Proceedings of 5 th European Workshop on Conformal Antennas, Bristol, September 11-12, 2007 2  The Radio Regulations, editi on of 2004, contain the complete texts of the Radio Regulations as adopted by the World Radio-communication Conference \(Geneva WRC-95 tly revised and adopted by the World Radio-communication Conference WRC-97\RadioWRC2000\and the World Radio-communication Conference WRC-03 Resolutions, Recommendations and ITU-R Recommendations incorporat ed by reference 3  RECOMMENDATION ITU-R M.1643, Technical and operational requirements for ai rcraft earth stations of aeronautical mobile-satellite service including those using fixed satellite service network transponders in the band 14-14.5 GHz \(Earth-to-space 4  ETSI EN 302 186 v1.1.1 \(2004-01 Stations and Systems \(SES\onised European Norms for satellite mobile Aircraft Earth Stations AESs\the 11 12/14 GHz frequency bands covering essential requirement s under article 3.2 of the R&TTE directive 5  EUROCAE ED-14E; Environmental Conditions and Test procedures for Airbor ne Equipment, March 2005 6  F. Croq and D. M. Pozar, \223Millimeter wave design of wide-band aperture-coupled stacked microstrip antennas,\224 IEEE Trans. Antennas Propagation, vol. 39 pp. 1770\2261776, Dec. 1991 7  S. D. Targonski, R. B. Waterhouse, D. M. Pozar Design of wide-band aperture stacked patch microstrip antennas ", IEEE Transactions on Antennas and Propagation, vol. 46, no. 9, Sep. 1998, pp. 1245-1251 8  R. B. Waterhouse, "Design of probe-fed stacked patches", IEEE Transactions on Antennas and Propagation, vol. 47, no. 12, Dec. 1999, pp. 1780-1784 9  D.M. Pozar, S. D. Targonski, \223A shared aperture dualband dual-polarised microstrip array\224, IEEE Transactions on Antennas and Propagation,Vol. 49 no. 2,Feb. 2001, pp. 150-157 10  http://www.ansoft.com 11  J-F. Z\374rcher, F.E. Gardiol, \223Broadband patch antennas\224 Artech House, \(1995\N 0-89006-777-5 12  H. Schippers, J. Verpoorte, P. Jorna, A. Hulzinga, A Meijerink, C. G. H. Roeloffzen, L. Zhuang, D. A. I Marpaung, W. van Etten, R. G. Heideman, A. Leinse, A Borreman, M. Hoekman M. Wintels, \223Broadband Conformal Phased array with Optical Beamforming for Airborne Satellite Communication\224, Proc. of the IEEE Aerospace Conference, March 2008, Big Sky, Montana US 13  H. Schippers, J. Verpoorte, P. Jorna, A. Hulzinga, L Zhuang, A. Meijerink, C. G. H. Roeloffzen, D. A. I Marpaung, W. van Etten, R. G. Heideman, A. Leinse M. Wintels, \223Broadband Op tical Beam Forming for Airborne Phased Array An tenna\224, Proc. of the IEEE Aerospace Conference, March 2009, Big Sky, Montana US 


  15  B IOGRAPHIES  Harmen Schippers is senior scientist at the National Aerospace Laboratory NLR. He received his Ph. D. degree in applied mathematics from the University of Technology Delft in 1982. Since 1981 he has been employed at the National Aerospace laboratory NLR. He has research experience in computational methods for aero-eleastics, aeroacoustic and electromagnetic problems. His current research activities are development of technology for integration of smart antennas in aircraft structures, and development of computational tools for installed antenna analysis on aircraft and spacecraft  Jaco Verpoorte has more than 10 years research experience on antennas and propagation Electromagnetic compatibility \(EMC and radar and satellite navigation He is head of the EMC-laboratory of NLR. He is project manager on several projects concerning EMCanalysis and development of advanced airborne antennas    Adriaan Hulzinga received his BEng degree in electronics from the hogeschool Windesheim in Zwolle Since 1996 he has been employed at the National Aerospace laboratory \(NLR as a senior application engineer. He is involved in projects concerning antennas and Electromagnetic compatibility \(EMC  Pieter Jorna received the M.Sc degree in applied mathematics from the University of Twente in 1999 From 1999 to 2005 he was with the Laboratory of Electromagnetic Research at the University of Technology Delft. In 2005 he received the Ph.D. degree for his research on numerical computation of electromagnetic fields in strongly inhomogeneous media Since 2005 he is with the National Aerospace Laboratory NLR\ in the Netherlands as R&D engineer   Andrew Thain is a research engineer in the field of electromagnetic modelling of antennas. He specialises in the use of surface integral methods for the calculation of coupling and radiation patterns and works closely with Airbus on the topic of antenna positioning. He has experience in the field of electromagnetic modelling  Gilles Peres is head of the Electromagnetics group of EADS-IW He has a wide experience in computational EM modelling particularly the use of FDTD, integral and asymptotic techniques for antenna structure interactions. He has contributed with Airbus experts to the certification campaign of the A340/500 and A340/600. Dr Peres holds a PhD thesis from University of Toulouse \(1998\ on impulsive Electromagnetic Propagation effects through plasma   Hans van Gemeren has a BEng degree in electronics. From the beginning of Cyner substrates he is involved in development and production of prototyping and nonconventional Printed Circuit boards Working mainly for design and research centers Cyner got involved in many high tech projects and from this developed a great expertise in the use of different \(RF materials. In the FlySmart project Hans and his colleagues are able to do what they like most: In close cooperation with designers, creatively working on substrate solutions 


  16  


NIMBUS NOAA 8 NOAA 15 NPOESS Preparatory Project Orbital Maneuvering Vehicle Orbcomm Orbiting Carbon Observatory Orbiting Solar Observatory-8 Orbview 2 Orion 1 P78 Pas 4 Phoenix Pioneer P-30 Pioneer Venus Bus/Orbiter Small Probe and Large Probe Pioneer-I 0 Polar QuikSCAT Radarsat Reuven High Energy Solar Spectroscopic Imager REX-II Rosetta Instruments Sage III SAMPEX Satcom C3 Satcom C4 SBS 5 SCATHA Seastar SMART-1 SNOE Solar Dynamics Observatory Solar Maximum Mission Solar Mesosphere Explorer Solar Radiation and Climate Experiment Solar Terrestrial Relations Observatory Space Interferometry Mission Space Test Program Small Secondary Satellite 3 Spitzer Space Telescope SPOT 5A Stardust  Sample Return Capsule STEPO STEPI STEP3 STEP4 STRV ID Submillimeter Wave Astronomy Satellite Surfsat Surveyor Swift Gamma Ray Burst Exporer Synchronous Meterological Satellite-I TACSAT TACSAT 2 TDRS F7 Tellura Terra Terriers Tethered Satellite System Thermosphere Ionosphere Mesosphere Energetics and Dynamics TIMED TIROS-M TIROS-N TOMS-EP Total Ozone Mapping Spectrometer TOPEX TRACE Triana Tropical Rain Measuring Mission TSX-5 UFO I UFO 4 UFO 9 Ulysses Upper Atmosphere Research Satellite Vegetation Canopy Lidar VELA-IV Viking Viking Lander Viking Orbiter Voyager Wilkinson Microwave Anisotropy Probe WIND WIRE XMM X-Ray Timing Explorer XTE XSS-iO XSS-ii APPENDIX B FIELDS COLLECTED Mission Mission Scenario Mission Type Launch Year Launch Vehicle Bus Model Bus Config Bus Diameter Location Expected Life Flight Profile Flight Focus Technical Orbit Currency Total Cost Including Launch Unit Sat Costs Average Sat Cost Production Costs Launch Costs Operations Cost Orbit Weight Wet Weight Dry Weight Max Power EOL Power BOL Power  of Batts 17 


Batt Power Batt Type Stabilization Type Propulsion Mechanism  of Solar Panels  of Solar Cells Manufacturing Qty Satellites in Constellation On-Orbit Spares Channels Number of Bands Data Storage Processing Power Source type Block Name Thermal Control Material Type Level of Technology Known Inheritance Propulsion station keeping Number of Axes Ground Based Spares Pointing Accuracy APPENDIX C EXISTING MODELS Numerous models are today in use for estimating spacecraft cost Two of the most common are the NASA/Air Force Cost Model and the Aerospace Small Satellite Cost Model Here is a description of the NAFCOM model The NASA/Air Force Cost Model NAFCOM is a parametric estimating toolfor space hardware It is based on historical NASA and Air Force space projects and is primarily used in the very early phases of a development project NAFCOM can be used at the subsystem or component levels The database currently includes 122 missions including 76 unmanned earth orbiting 24 unmanned planetary 11 launch vehicles 8 manned 3 engines It uses parametric relationships to estimate subsystem or component level costs for any aerospace hardware including earth orbital spacecraft manned spacecraft launch vehicle upper stages liquid rocket engines scientific instruments or planetary spacecraft 7 And for the Aerospace Small Satellite Cost Model SSCM employs a parametric methodology for estimation of program cost and is best suited to the early conceptual development phase of a spacecraft program during which time the design is likely to be less mature and when cost and performance trades can be easily performed SSCM consists of a collection of cost-estimating relationships or CERs which estimate the costs of developing andproducing a spacecraft system with the following subsystems  Attitude Determination and Control Subsystem ADCS  Propulsion  Power  Telemetry Tracking  Command TT&C  Command  Data Handling C&DH  Structure  Thermal CERs were also developed for integration assembly and test IA&T program management PM and systems engineering SE and launch and orbital operations support LOOS Individual subsystem cost estimates are statistically rolled up to yield a cost-risk distribution which provides the estimator with a range of cost estimates andpercentiles 8 The SSCM was calibrated from over 100 post-1990 Earth-orbiting andplanetary missions REFERENCES 1 Lack of Disciplined Cost-Estimating Processes Hinders Effective Program Management GAO study 04-642 2 Jilla Cyrus D and Miller David W Satellite Design Past Present and Future International Journal of Small Satellite Engineering 12 February 1997 3 Bearden David A A Complexity Based Risk Assessment of Low-Cost Planetary Missions:When Is A Mission Too Fast and Too Cheap Fourth IAA International Conference On Low-Cost Planetary Missions JHU/APL MAY 2-5 2000 4 Kellogg Mahr and Lobbia An Analogy-based Method for Estimating the Costs of Spacecraft IEEEAC paper 1371 Version 4 5 Hoeting Jennifer A Methodology for Bayesian Model Averaging An Update f 6]btp/ewiieiao iiAaos 7 Keith Smith NASA/Air Force Cost Model Science Applications International Corporation 8 18 


BIOGRAPHIES Lee Fischman served as Principle Investigator for this project Lee is Senior Director of Development at Galorath Incorporated where he directs much of the new product development and research at the firm He developed SEER for Software  Hardware Integrations with Microsoft Project the Comparison Sizing tool COTS Software model in addition to various data mining information extraction and expert systems Previously he was a software designerlprogrammer in the New York financial industry Lee earned a BA from the University of Chicago and an MA from UCLA both in economics Mike Kimel carried out statistical work on the project Mike is an Economist for Galorath Inc in addition to maintaining his own quantitative consulting practice He has also taught Economics and Advanced Statistics at the Graziadio School of Business and Management at Pepperdine University run the Competitive Strategy group for a Fortune 500 Telecom Company and worked as a Consultant at PriceWaterhouse LLC now PriceWaterhouse-Coopers He earned a Ph.D in Economicsfrom UCLA Troy Masters programmed analytic methods and is integrating the Far Out model into its parent product SEER for Hardware previously SEER-H Troy is a Software Engineer with Galorath Incorporated where he has been the primary developer for a range ofproducts He earned a BS in computer science from UCLA David J Pine was our subject matter expert helping us assemble data and gain insight into technical trends Dave is retired after a 34-year career with the National Aeronautics and Space Administration NASA currently is a consultant to various government and industry entities While at NASA his organizations in the Office of the Chief Financial Officer and later at the IPAO at Langley Research Center were responsible for the conduct of major NASA program analyses and evaluations for the NASA Administrator and Deputy Administrator From early 1988 through the end of 1990 he was the Deputy Program Manager for the Hubble Space Telescope Program specifically responsible for the telescope operations and science support aspects of the program He earned a BS in Aerospace Engineering from the Polytechnic Institute of Brooklyn and a Masters of Engineering Administration from the George Washington University 19 


  20 Angeles, where he also received a B.S. in Applied Mathematics  Eric Fetzer is a Senior Member of the Technical Staff at the Jet Propulsion Laboratory, Pasadena, California specializing in satellite observations of the atmosphere.  His scientific interests include planetary boundary layer processes, tropical phenomena, upper tropospheric variability, and climatologies of temperature, water vapor and clouds.  His technical interests include analysis of large data sets, and of multi-sensor observations. He has over 20 peer-reviewed publications and given numerous scientific presentations, public lectures and media interviews about climate science. Eric received a B.A. in Physics from the University of California Berkeley, and a Ph.D. in Astrophysical, Planetary and Atmospheric Sciences from the University of Colorado, Boulder   Amy Braverman is a Senior Statistician at the Jet Propulsion Laboratory, California Institute of Technology She holds a B.A. in Economics from Swarthmore College an M.A. in Mathematics from UCLA, and a Ph.D. in Statistics also from UCLA. Prior to her current position in JPL's Science Data Understanding Group, she was a Caltech Post-doctoral Scholar at the Jet Propulsion Laboratory, and a Scientist in the Flight Sciences Experiments Section of the Science Division. Dr Braverman conducts research on information-theoretic methods for the analysis of massive data sets and streams statistical data fusion, high-dimensional data analysis, and statistical analysis for climate model evaluation and diagnosis. She has published in both the statistics and geoscience literature, and is active in both communities She is a member of the Multi-angle Imaging SpectroRadiometer Science Team, and serves as a member of the Atmospheric Infrared Sounder Science Integration Team. Her responsibilities on both missions include designing data reduction algorithms for massive, remote sensing data sets. Dr. Braverman also holds an appointment in the Department of Statistics at UCLA as Adjunct Associate Professor, and is active in UCLA\222s Center for Environmental Statistics. She is member of the Committee on Applied and Theoretical Statistics of the US National Academy of Science. She has refereed for the Journal of the American Statistical Association, the Journal of Computational and Gr aphical Statistics, IEEE Transactions on Geoscience and Remote Sensing, and the Journal of Applied Meteorology and Climatology Seungwon Lee is a senior member of the High Capability Computing and Modeling Group at Jet Propulsion Laboratory. She is conducti ng research on comet gas dynamics, nonlinear dynamics control, climate model parameterization, Earth science data analysis, parallel computing, and advanced numerical algorithms. She received her Ph.D in Physics fr om the Ohio State University and her M.S. and B.S. in Physics from the Seoul National University, Korea  Matthew Henderson is software engineer in the High Capability Computing and Mode ling group at JPL. His current work includes Web Services and Instrument Data Level 2 subsetting. He received a B.S. Computer Science from CSU Pomona, and is currently pursuing M.S Computer Science  Steven J. Lewis is a member of the Information System and Computer Science staff member at the Jet Propulsion Laboratory.  He received a BS in Mathematics from the University of California, Los Angeles in June 2001, and the MS and Ph.D. Degree from Claremont Graduate University in May 2004 and May 2007, respectively.  He worked as a post doctoral fellow at Keck Graduate Institute from June 2007 until he joined JPL in March of 2008.  During his graduate and post doctoral work, his studies focused on applications of Bayesian methods to hidden Markov models with particular interest and application to protein sequencing.  His work at JPL has focused on integrating web services into various programming platforms for the purposes of accessing NASA satellite data, as well as developing object tracking so ftware and contributing to image enhancement and restoration efforts Van Dang is a member of the Science Data Understanding Group at the Jet Propulsion Laboratory. She was responsible for the NEWS Level 2 processing that generated the formal merged Level 2 data from multiple A-Train instruments  Manuel de la Torre is a Physicist from the Universidad Complutense at Madrid \(Spain\. After finishing his Ph.D work at the University of Bayreuth \(Germany\ on pattern formation in turbulent flows and a 7 1/2 year stunt as Ass and Assoc. Prof. at the Escuela T\351cnica Superior de Ingenieros Aeron\341uticos in Madrid \(Spain\, he came to the Jet Propulsion Laboratory on a 1-year Sabatical leave in 1997 wanting to apply fundamental concepts of nonlinear systems and geophysical fluid dynamics to something that might be directly useful to soci ety. He discovered the JPL as a great place to achieve that goal and extende d his stay a bit longer, becoming Technical staff and working on different aspects of remote sensing, validation of satellite instruments, and data analysis of atmospheric processes and climate  


