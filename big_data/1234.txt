html><head></head><body><pre style="word-wrap: break-word; white-space: pre-wrap;">Fuzzy  Subgroup Mining for Gene Associations Marco Ortolani Ondine Callan David E. Patterson University of Palermo VistaGen Therapeutics, Inc. Tripos, Inc Dept. of Electrical Engineering 1450 Rollins Road 90128 Palermo, Italy Burlingame, CA 94010, USA Michael R. Berthold Dept. of Computer and Information Science Konstanz University Fach M712, 78457 Konstanz, Germany Email: Michael.Berthold@uni-konstanz.de 601 Gateway Blvd., Suite 720 South San Francisco, CA 94080, USA Abstract- When studying the therapeutic efficacy of potential new drugs, it would be much more efficient to use predictors in order to assess their toxicity before going into clinical trials One promising line of research has focused on the discovery of sets of candidate gene profiles to be used as toxicity indicators in future drug development. In particular genomic microarrays may be used to analyze the causality relationship between the administration of the drugs and the so called gene expmiou, a parameter typically used by biologists to measure its influence at gene level. l%is kind of experiments involves a high throughput analysis of noisy and particularly unreliable data, which makes the application of many data mining techniques very difficult In this paper we explore a fuzzy formulation of the a priori algorithm, a technique whose crisp version is commonly used to mine for subgroups in large datasets; the purpose is to extend the original method, already suitable to deal with large amount of data, in a way that naturally allows the user to deal with the intrinsic imprecision in the data The algorithm is tested on real data coming from experimental genomic data I. INTRODUCTION Genomic arrays are a powerful instrument of analysis for the experts in the field of drug toxicity research, since they provide them with a better global picture and allow them to analyze the interactions among thousands of genes simultaneously One important advantage when working with micromays is thus the high data throughput; on the other hand this implies the need of coupling their use with sophisticated data mining techniques in order to extract the information that is actually useful for the case at hand. Moreover, as in many other real world applications, the original data is usually not reliable enough, because of imprecisions in the measurements, noise or other causes inherent to the nature of the data itself In this paper we present a modification of the a priori algorithm, a well known method aimed at finding regularities in a series of data in order to discover co-occurring elements The very large amount of possible Combinations that need to he analyzed cannot be dealt with through exhaustive search, so obviously particular attention must be paid to the choice of the data structure used to store the information. Also, as already pointed out, the poor quality of the data cannot be ignored The fuzzy formulation of the a priori algorithm presented here addresses the laner point Section I1 introduces the basic concept of  association rule   and Section I11 summarizes the original formulation of the a priori algorithm; Section IV then presents the fuzzy extension We discuss our results in Section V and finally in Section VI we conclude and discuss possible further extensions 11. ASSOCIATION RULES The a priori algorithm belongs to a class of methods whose goal is to find regularities in a set of data in order to discover co-occurring elements and to generate a set of rules that can be used for prediction [l], [2 A field in which it may typically find applications is market basket analysis, where one wants to determine the items that customers buy together so that, knowing what products are already in the shopping cart, it may be possible to infer the presence of other products; such information is stored in the 


presence of other products; such information is stored in the form of an association rule An association rule stores the attributes for a particular sample; in the case of market basket analysis, the customers represent the samples, and the items they bought are the re spective attributes. In the standard formulation of the problem an association rule contains crisp information \(either an item has been bought or not of interesting rules from the whole set, so some measure is required in order to attach a relevance value to each rule One of the quantities that are commonly considered is the so called support of the rule, that is the percentage of samples for which the rule applies. Usually a minimum support is specified so that only the samples represented by those rules whose attributes satisfy at least the specified number of rules are selected \(that is, we are interested in frequent subgroups of items Despite not being conceptually too challenging in principle the task of rule selection presents obvious difficulties, since an exhaustive search through all the rules is practically unfeasible due to the very high number of possible combinations; what is needed is an effective way to store the elements and to process them 560 0-7803-8376-1/04/$20.00 Copyright 2004 IEEE Choose minimum required suppoi? B Initialize variables n = 1 //fmntier counrer Initialize firsr fmnrier FI = {\(a a Build remaining fmnriers REPEAT Expand each subgmu in previous fmntier VS := {\(af,a;,. . . , a n - l using elements f" the firsr fmnrier A = \(a,il\(a indez\(a a:- l Va E A : F, = F, U \(Sa f clean n-fmntier F, = {s, E ~ ~ l l Fn = Fn - Fn Update fmmier counter n = n + l Fig. 1. A prefix Vee built using five attributes. The nodes represent the subgroups with their associated counters; when no pruning occurs. the tree grows until no more elemen&amp; can be added to a subgroup: the ordering of the attributes emu re^ that duplicate subgroups are avoided Many sophisticated algorithms for mining association rules exist in literature [2] and several modifications of the basic formulation of the problem have been proposed in an attempt to improve performance [7], or to consider different definitions for the constraints [5] and so on. We argue that an a prion based approach combined with use of fuzzy logic may still prove effective, especially when dealing with unreliable data 111. THE A PRIORI ALGORITHM In this paper we follow the implementation described in [3 and use a p r e f i  free as the main data structure The structure of this tree is sketched in Figure 1. Each node of the tree represents an association rule identified through its attributes; it also needs to contain a counter indicating the frequency of the rule in the original dataset in order to be able to assess whether the support constraint is satisfied or UNTIL \(F stop condition Fig. 2. Pseudo-code describing the process of building the prefix tree whose index is greater than the those of the elements already present. Obviously the tree is greatly simplified by eliminating this redundancy No element added to a subgroup that does not satisfy the support constraint may possibly generate a frequent subgroup at any successive level thus justifying the early pruning of the tree. Since growing the tree may cause a combinatorial explosion, the pruning mechanism is meant to try and keep the 


explosion, the pruning mechanism is meant to try and keep the memory consumption low since the frontiers deep in the tree will contain fewer and fewer elements to be further expanded This iterative process is repeated until it is no more possible to expand the last frontier or another stop condition is true, as may be the case if a maximum depth for the tree was specified Figure 1 shows an example of such prefix tree, with its typical highly unbalanced structure. In this example, the tree not implementation also affects the performance during the search appear in at least as many rules  as by the chosen for frequent subgroups. The idea behind a pref i  free is that support; in other words, those  elements will we do not need to store the complete information about a rule frontier at each node. Assuming that all nodes satisfy the constraint for the support in the tree at each depth level, no pruning will be required; nevertheless n attributes and it will also contain the counter. The whole are avoided, All subgroups can be  easily retrieved from this rule can be easily reconstructed and this solution seems also a data SVUCture natural implementation that facilitates later access to the data code in Figure 2, where we use the term "n-frontier" to indicate the collection of all subgroups containing n attributes The generic n-th iteration consists of two steps: at first all rules containing n attributes are generated; after that, the ones not satisfying the frequency requirement are pruned, thus generating a clean n-frontier. The rules of size n + 1 can be easily built by selecting one element at a time from the 1-frontier and adding it to one of the subgroups of size n Moreover, since for our purposes two subgroups are identical regardless of how the elements they contain are arranged, we can avoid testing unnecessary combinations if all the elements are assigned an identifier that defines an order on them Extending a subgroup will only be allowed with elements Storing the tree is expensive in terms Of and was built starting from five attributes that, by  themselves the More precisely* each Of the nodes at depth represents the last element in a rule describing a sample with the ordering of the attributes  that repeated subgroups The tree is built incrementally as described by the pseudo- Iv. FUZZY SUBGROUP MINING The approach just outlined provides an efficient solution in terms of memory and time requirements. One limitation though, is that in the original formulation the association rules are meant to represent crisp information \(in the market basket analysis example, a customer either bought an item or not In many real world applications it is very unlikely that the original data is already accurate enough to he used as an input for the algorithm; for instance, when working with biological data it is mandatory to take into account some imprecision due to measurements or  just biological variability, so such crisp decision lines are inappropriate Moreover, the generation of the association rules themselves is an intrinsically imprecise task since a clearly cut decision 561 Chose minimum required suppor? 8 Initialize variables n = 1 //frontier counter FOR all chosen f m y  thresholds pa, p i , .  . . , pk Rebuild firsf fmntier using data obtained with current fuuy threshold FP' = {\(a a Build additzonal frontiers REPEAT Expand each subgmup in previous frontier previousp;rier ma$ have been built during last nut VS := { \(a , ,az  ,..., F , - I using elements from the firsr frontier Va E A :  F, = F, U \( $ a clean n-frontier F, = {S% E F&amp;llpport\(SJ &lt;e F, = F, - F Update frontier counter n = n + l 


n = n + l UNTIL \(F,, = {I slop condition ENDFOR A = {a,\\\\\(a indm\(a az Fig. 3 several runs each using a different fuzzy threshold Pseudo-code describing the process of building the prefix tree in line is rarely available: on the contrary, it is often desirable to leave some freedom to the users, in terms of interaction with the algorithm A natural extension is thus the embedding of fuzzy logic [I31 in the algorithm itself by letting the attributes stored in the association rules represent a fuzzy degree of membership. Computing the support for each rule will require the choice of a threshold, which of course will influence the pruning of the prefix tree The choice of a fuzzy threshold obviously modifies the starting data; in particular a lower threshold may allow more elements to satisfy the constraint on the support and eventually larger subgroups to be discovered. Since in most cases the original data is imprecise, allowing this kind of flexibility may represent a great advantage The algorithm is described in the form of pseudo-code in Figure 3. Besides the additional loop introduced to consider one different fuzzy threshold at a time, the main difference with Figure 2 is in the construction of the first frontier. The notation F p  shows that it is now dependent on the fuzzy threshold, as already explained; in summary more elements are added to the first frontier and only the last frontier is considered as a source for subgroups to expand The underlying idea is that, by choosing a maximum allowed number of elements per subgroup, a minimum support and a fuzzy threshold for each iteration, the user is now able to tune the algorithm toward a subset of the whole search space where it is more likely to find useful subgroups The example in Figure 4 illustrates this point. Let us assume that after choosing a fuzzy threshold 0 ,  five attributes initially satisfy the support constraint \(let them be a, b, c, d and f As previously mentioned, the attributes are ordered using an internal index In this first iteration, the tree is built as described earlier Fig. 4. The evolution of the prefix tree under two successive choices for the fuzzy threshold. In the bottom half, the dashed area represent the p m  of the tree that will be expanded, whereas the shadowed area will be "fmzen and for the sake of the example we assume that two of the discovered subgroups do not satisfy the requirements for the minimum support and are pruned from the tree, as shown in the upper part of Figure 4 A successive run with a fuzzy threshold 1 &lt; o discovers another attribute \(9 attribute e is reconsidered and accepted in the expanded first frontier because, thanks to the lower fuzzy threshold, it now satisfies the support constraint. This attribute is assigned a higher internal index and is appended at the end of the list of available attributes \(this is indicated by e' in the lower part of Figure 4 The tree may now continue to grow by expanding the subgroups found in the last frontier; however the process is slightly different than in the original formulation of the algorithm. The shadowed area in the figure shows a part of the tree that was generated by previous runs; the leaves of the tree contained in this area will not be expanded anymore; rather we ignore this part of the search tree and focus only on the last frontier Since we are arguably interested in finding larger subgroups this represents a trade-off that allows us to get a deeper insight into what was already found with a more restrictive constraint while keeping the tree small. Comparing the bottom half of Figure 4 with the top one, it is evident that we have succeeded in further expanding the tree \(depth-wise consider possibly less interesting subgroups Obviously this technique poses a problem for the ordering 


Obviously this technique poses a problem for the ordering of the elements, that we want to maintain homogeneous throughout different runs in order to keep the tree consistent 562 Newly found elements will be assigned a higher intemal index so that the sorting will be consistent \(as in the case of g in the example elements whose support increases \(and possibly now satisfies the constraint e   It is clear from this example that two main steps may be isolated in the process of building the prefix tree. Initially a  basic  set of subgroups satisfying the requirements is selected, which corresponds to narrowing the search space down to a particular region of interest. An initial conservative choice for the support helps in keeping the search tree small but may be too restrictive and overlook potential candidates By softening the fuzzy constraints this hard core will be ailowed to expand, adding larger subgroups to the initial set newly found subgroups will still satisfy the original support requirement and will in a way represent a  refinement  of the original solution V. EXPERIMENTS The research we are considering as the source of our data originated from a study conducted at VistaGen Therapeutics Inc.; the purpose of this study is to investigate the possibility of using gene expression profiles as predictors for potential drug toxicity A. The data The data used in our experiments was generated using gene microarray technology [ 1 I]. Microarrays can be regarded as matrices in which each spot contains information ahout the amount of RNA for a particular sample; the number of spots per array is typically in the order of several thousands This kind of data has often presented a challenge to re searcher in the field of data mining due to its characteristics of noisiness and unreliability, and many different approaches have been already documented in literature [41, [61, [SI, [IO For our purposes it is sufficient to say that, starting from the raw data, it is possible to generate a matrix of intensity values representing RNA expression profiles An experiment then consists in measuring the effects pro duced by a particular drug in terms of variation in the gene expression levels; even though the actual biological path may remain partially unknown, the idea is that a relationships may be observed between the final effects \(the gene expression levels the administration of the drug Our experiments involved a set of nephrotoxic drugs tested on two selected kidney cell lines to produce an output con sisting in the expression levels of about 8000 genes. Previous tests conducted in laboratories on human renal epithelial cells suggest that they show different sensitivities to different drugs very much as observed in vivo. In particular the two cell lines considered here are two different areas of the kidney the Proximal Straight Tubule, or PST, and the Collecting  hhule, or CT to treatment The object of the present research are genes that are involved in the early response to the drugs, that is before acute 563 TABLE I THE EXPERTS  DEFINITIONS FOR FOUR GROUPS OF INTEREST. THEY CAN BE EASILY TRANSLATED INTO FUZZY RULES I I I h g  5 A gnphrcal repre*enulion of Ihe furry groups defined m Table I The horden of the fully region, vary depending on b e  choice of Ihe Ihmhold toxicity manifests itself; in order to identify them, an appropri ate concentration was selected for five target drugs: Cisplatin Cyclosporin, Gentamycin, Tohramycin and Kanamycin The gene subgroup discovery process is complicated by the fact that the role of most genes is still unknown; indeed one of the aims of the biologists is to find groups of undocumented 


the aims of the biologists is to find groups of undocumented genes in order to broaden their knowledge of the biological pathways that cause a drug to be toxic In a situation like this an exploratory analysis that allows the scientist to get some preliminary results in order to re test, refine them and possibly validate them against existing literature is of much greater use than a static algorithm B. Mining for  predictors From previous studies it is already known to biologists that potentially interesting genes are the ones that show a differential response in the two considered cell lines \(PST and CT the expected targets in terms of groups of interest, which will then be used to define the association rules, or in other words to decide whether a gene is to be considered overall expressed or not for a certain drug The quantity that would be natural to consider for this purpose is the bare expression level for a given gene, but unfor tunately this is usually not particularly useful per se, since it is influenced by too many factors, including intrinsic biological variability, which basically deteriorate the signdnoise ratio Biologists prefer to rely on a different quantity, the so called fold expression, which is defined as the ratio of the expression TABLE 11 EACH ROW SHOWS, FOR THE GIVEN THRESHOLD, HOW M A N Y  GENES WERE SELECTED, HOW M A N Y  GENES HAD THEIR SUPPORTCHANGED BECAUSE OF THE NEW FUZZY THRESHOLD A N 0  WHAT SUBGROUPS WERE DISCOVERED. FOR THE LAST COLUMN, THE NOTATION X\(Y THAT Y SUBGROUPS WERE POUND CONTAINING X GENES. Gmup 1 Group 1 Threshold Found Changed Subgmups 8\(1 1 0.8 44\(C FSTjold I CTf.ld AND Gmup 2 Thn-shold Found Changed Subgmups 0.9 6\(1 0.8 14 1 7\(1 2\(1 1 levels of genes observed in the sample before \(contml after \(treatment Table I presents four such groups as defined by the bi ologists depending on the relative importance of the gene expression in the two cell lines. For instance, they argue that a decrease in the fold expression in the PST region coupled with a contemporary increase or stability in the CT region is a sign of drug toxicity \(as represented by group I Even so, there is no criterion providing an all-purpose cutoff value to decide what values of fold expression correspond to the  expressed  status. A 2-fold expression cut seemed a reasonable choice for the present data, even though a very large amount of genes would lie very close to either side of this crisp border As already pointed out, the binary perspective is probably too restrictive, so we reformulated the definitions of such groups in term of fuuy rules, which have the advantage of expressing in a better and more intuitive way the imprecise background knowledge provided by the expert When PST and CT are regarded as linguistic variables, the fuzzy property up corresponds to  over-expressed  and the opposite holds for down. An unnoticeable modification in the value of the fold expression is indicated by no change The properties can be combined using the usual fuzzy opera tors [9], [12 A graphical representation of the fuzzy groups is given in Figure 5 Table I1 presents the results produced by our algorithm in this case. For all the groups we required a minimum support Fig. 6. A graphical representation of the fuzzy gmups defined in Table Ill Both axes are in logarithmic scale; WO choices of the fuzy  threshold show how the boden vary 


how the boden vary of at least four of the drugs. We considered three runs with fuzzy thresholds o = 1.0, 1 = 0.9, 2 = 0.8 respectively Let us consider Group 1 as an example of the way the algorithm works. For 0 = 1.0, the largest subgroup found contains 17 genes; the total number of genes that, considered singularly, satisfy the constraint is 45. There are also several smaller subgroups that differ in at least one gene or for the drugs they cover \(for instance, there are three subgroups containing six genes each 1 = 0.9, we expand the first frontier to contain 43 new genes. Moreover, three genes that were previously excluded now meet the requirements for the support. This results in the discovery of a new subgroup containing 34 genes With 2 = 0.8, 48 more genes are allowed; the support is now high enough for six more genes and finally a subgroup of 44 genes is discovered Those results were examined by the biologists and com pared to what is already known from literature; they then de cided to modify the definition of the groups, while maintaining the basic idea, that is selecting genes whose expression levels are noticeably different in PST and CT In the new definition, only two larger groups were cou When we lower the threshold to 564 Genes of Interest TNF, LTBR, p21, Cytochmme P450, EZF3. GAP\(DH Interleukin, PIK3, STAT, Toll-like receptor. Uncoupling Protein Caspase 9, STAT, DEFCAP, Calpain 6, multiple HSP, GSTPI, IGW LTB,c-AMP, Cytochrome C CREB, CAPG, CDC, CDK, GADD45, EZF,COX, Cytochrome p450 EIF,FGF, HSP, HIE U, MAPK8, PPAR ARL2, ASB3, Calpain , CDC, CENPE, DEFCAP. Laminin, LTB Acetyltransferase, CAMP kinase, SRC phosphoprotein 2 Cytochrome C, Elongation factor B sidered, ideally corresponding to the two cases in which the influence in PST is qualitatively more relevant than in CI and vice versa. This new formulation takes into account not only the value of the fold-expression in PST or Cr, but their ratio as well, as is summarized in Table 111. A graphical interpretation is given in Figure 6 Experiments analogous to the ones previously described were carried on using the new groups and we considered genes expressed in either of the two groups It is worth noting that in this case some of the resulting subgroups were considered relevant from the biological point of view, since they corresponded to groupings already known from literature Biologists defined a list of  classes  that grouped some of the drugs according to their known mechanism of action and examined the suhgmups discovered by our algorithm that fell into one of those classes \(that is, whose support matched one of the classes They noticed that some of the genes belonging to those subgroups had already been described in the literature and were known to be related to that particular mechanism of action, while other genes were a new addition. Those genes appeared to be related to particular drugs, responding to them and signaling their toxicity, thus representing good candidates as predictors for the respective drug class Table IV presents a selection of those genes together with the class they describe and the drugs that form this class VI. CONCLUSIONS The use of a fuzzified version of the a priori algorithm proved to be very promising for the application to genomic data mining The peculiar nature of the data, namely highly noisy hio logical data, makes it very difficult to use traditional crisp data analysis tools; our approach, in addition, was considered very intuitive by the experts and allowed them to explore the data 


intuitive by the experts and allowed them to explore the data and refine their hypotheses, in some cases confirming them and to select a smaller sample of interesting candidates fmm the whole dataset The results found during the preliminary experiments de scribed here are encouraging, since they are supported by existing literature and also offer new insights that open the way to further research 5 Class DmT DNA damage Cisplahn Aminoglycosides Ge n tam y c i n Tobramycin, Kanamycin Calcium Kanamycin h2llSpoR Cyclosporin Ribosomal GentamyCin inhibitors Tobramycin Future work  will include more testing on larger datasets and will benefit from increased interaction between the experts in the two fields of data analysis and biology REFERENCES I ]  e h  Agrawal, Tomasz hielinski, and Arun N. Swami. Mining association mles between sets of items in large databases. In Peter Buneman and Sushi1 Jajodia, editon, Pmceedings of the 1993 ACM SIGMOD Inlemlionol Conference on Mnnogemnr of Dolo, pages 207 216, Washington, D.C., 2628 1993 2] Rakesh Agrawal and Ramakrishnan Srikant. Fast algorithms for mining association rules. In lorge B. Bocea, Matthias Jarke, and Carlo Zaniolo editors, Pmc. 20th Inc. Con$ Very Large Data Bases, VLDB, pages 487 499. Morgan Kaufmann. 12-15 1994 3] Christian Borgelt and Rudolf h s e .  Induction of association rules A priori implementation. In Physica Verlag, editor, P m .  of the 15th Conference on Computational Statistics \(Compstat 2W2, Berlin Gemnyj ,  Heidelberg, Germany, 2Mn 141 M. Brown, W. Gmndy. D. Lin. N. Cristianini. C. Sugnet T. Furey M. Jr, and D. Haussler. Knowledge-based analysis of microarray gene expression data by using support vector machines. In Pmc. Nod. Acod Sci.. volume 97, pages 262-267, 2Mx 5] Edith Cohen, Mayur Dam, Shinji Fujiwara, Aristides Gionis, Piotr Indyk, Rajeev Mohuani. Jeffrey D. Ullman. and Cheng Yang. Finding interesting associations without support pmning. Knowledge ond Dofa Engineering, 13\(1 6] Sandrine Dudoit, Jane Fridlyand, and Terence P. Speed. Comparison of discrimination methods for the classification of tumors using gene expression data. Jouml of the American Starirtical Assacintion 97\(457 171 Christian Hidber. Online association rule mining. In ACM SIGMOD In!. Con$ on Momgemem of Doto, pages 145-156, 1999 8] P. 0. Brown M. B. Eisen. P. T. Spellman and D. Botstein. Cluster analysis and display of genome-wide expression patterns. In Pmc. Norl Acod. Sci. USA, volume 95. pages 14863-14868, Dec 1998 9] A. D. Nola and A. Venue, editors. The Marhemtics of F y r y  System Tiiv, Rheinland, Koln, 1986 IO] Donna K. S h i m ,  Pablo Tamayo. Jill P. Mesirov, Todd R. Golub, and Eric S .  Lander. Class prediction and discovely using gene expression data. In RECOMB, pages 263-272, 2wO I l l  Gordon K. Smyth. Yee Hwa Yang, and Teny Speed. Statistical issues in cDNA micromy data analysis. FvnclioMl Genomics: Methods and Pmrocols, 2002 A general concept of fuzzy connectives, negations and implications based on t-noms and I-conorms. Fuuy Sets and System 95113-134, Oct 1983 I31 Lotfi A. Zadeh. Fuzzy sets. Infomtion and Conrml, 8338-353. 1965 I21 S .  Weber i6.5 pre></body></html 


9 Here are some observations and explanations on the results 1\The total time of our comparison includes the time to write the association rules to a file; Bit-AssocRule is 2 to 3 orders of magnitude faster than the various Apriori algorithms \(64-221 times faster\he test data set, the big the time difference between the BitAssocRule and the various Apriori algorithms. We havent compared our algorithm with some of the other association rule algorithms such as VIPER  13,24] \(CHARM and CL OSE are base d on the closed frequent itemsets concept\d on their published comparison results with Apriori, our BitAssocRule is very competitive compared to them and a direct comparison will be conducted and reported in the near future 2\e or litter longer time than the various Apriori algorithms in constructing the 1-itemsets because of the extra cost of building the bitmaps for the 1-itemsets. But after the 1-itsemtset is done, Bit-AssocRule is significant faster than the Apriori algorithms in constructing large frequent itemsets because it only uses the fast bit operations \(AND COUNT and SHIFT\nd doesnt need to test the subsets of the newly candidate 3\aps of the frequent items, and the bitmap storage \(uncompressed less than the original data set \(1/2 to 1/4 of the original data size The main reasons that Bit-AssocRule algorithm is significant faster than Apriori and its variations are 1\ocRule adopts the divide-and-conquer strategy, the transaction is decompose into vertical bitmap format and leads to focused search of smaller domain There is no repeated scan of entire database in BitAssocRule 2\snt follow the traditional candidate-generate-and test approach, thus saves significant amount of time to test the candidates 3\basic operations are bit Count and bit And operations, which are extremely faster than the pattern search and matching operations used in Apriori and its variations 5. Conclusion The contributions of this paper are in two aspects:  we extend the application domains of bitmap techniques and introduce the bitmap techniques for complex DSS query optimization and association algorithm. We present a bitmap based query optimization algorithm to optimize complex query with multiple table join based on outer join operations and push the outer join operations from the data flow level to the bitmap level and achieve significant performance gain.   We introduce a novel algorithm to calculate the foundset for those tables involved in the prejoin table by using prejoin_bitmap_indexes and integrate this algorithm into the current commercial data flow based query engine seamlessly. Our query optimization can achieve an order of magnitude faster than conventional query engine Secondly we introduce the bitmap technique to the data mining procedure and develop a bitmap-based algorithm Bit-AssocRule to find association rules. Our BitAssocRule avoids the time-consuming table scan to find and prune the itemsets, all the operations of finding large itemsets from the datasets are the fast bit operations. The experimental result of our Bit-AssocRule algorithm with Apriori and AprioirHybrid algorithms shows Bit-AssocRule is2 to 3 orders of magnitude faster. This research indicates that bitmap technique can greatly enhance the performance for decision support queries and finding association rule, and bitmap techniques are very promising for the decision support query optimization and DM applications Bitmap technique is only one way to improve the performance of complex DSS queries and DM algorithm Parallelism is another crucial factor to improve the performance of DSS and data mining.  We are currently working on paralleling the bitmap-based algorithms and hope to report our findings in the near future 6. References  Agrawal R. Sri kant R., Fast al gorithm for mining association rules, Prod. of the 20 th VLDB Conf. 1994  Agrawal R., Mannila H., Sri kant R., Toivone n H., Verkamo A., Fast discovery of  association rules, in Advances in Knowledge Discovery and Data Mining, MIT 1996  AIP D Tec hnical P u blications In Syba se IQ Administration Guide, Sybase IQ Release  11.2 Collection, Sybase Inc Proceedings of the Seventh International Database Engineering and Applications Symposium \(IDEAS03 1098-8068/03 $17.00  2003 IEEE 


10  er-Yahia S., Johnson T., Optimizing queries on compressed bitmaps, Prod. of the 20 th VLDB  Conf  wa l, R., Gunopul os D  Constraint-based rule mining in large, dense databases Proc. of the 15th Int'l Conf. on Data Engineering \(ICDE1999 6] Bertino E., Ooi B.C., Sacks-Davis R. etc, Indexing techniques for advanced database systems Kluwer Academic Publishers  n C Ioa nnidis Y B itm ap index design and evaluation, Prod of the  SIGMOD-96  h atziant oni ou D Akinde  M, Johnson T Kim  S, The md-join: an operator for complex olap. Prod of the 18 th Intl Conference on Data Engineering \(ICDE2001  outer join, Prod of the 2nd International Conf. on Databases   Fre nch C  One size fits all databa se arc hitecture do not work for dss, Prof of the  SIGMOD-95  hal, A., Oute r join simplification and reordering for query optimization, ACM TODS, 22\(1\1997  G., Volcano, an extensible and pa rallel query evaluation system, IEEE Transaction on Knowledge and Data Engineering, 6\(6  e i, J. Yin. Y  Mining fre quent patterns without candidate generation", Prod of the SIGMOD-2002    Hanusa R., A lesso n in outer joins \(learned the hard way!\data Review, Spring 1998  aine C., Data A A novel inde x s u pporting high volume data warehouse insertion Prod of the 25th VLDB Conf  on T , Perform ance m easurem ents of compressed bitmap indices Prod. of the 25th VLDB conf   Y Data m i ni ng and m achine oriented modeling: a granular computing approach, Journal of Applied Intelligence, Oct. 2000  Lin T.Y., Fi nding ass ociation rules using fast bit computation: machine-oriented modeling ISMIS-2000  M., Group bit map index: a structure for association rules retrieval Prod. of the 4 th Intl Conf. on Knowledge Discovery and Data Mining \(KDD-98  ONeil P Graefe G., M ulti-table joi ns  through bitmapped join indexes, SIGMOD September 1995, 8-11   ONeil P., Quass D., Im prove d que ry pe rformance with variant indexes, Prod of the SIGMOD-1997   Inform ix and inde xing s u pport for data warehouses,  Informix Whitepaper  a p join i n dex  http://technet.oracle.com/products/oracle9i/daily/a pr09.html  n, H. Lu, S. Ni shio, S. Ta ng, and D  Yang. "H-mine: hyper-structure mining of frequent patterns in large databases", Proc. The 2001 IEEE Intl Conference on Data Mining  ONeil P.,  ONeil E.,  BitSliced Index Arithmetic, Prod of the SIGMOD2001  vase re , A Om iecinski E Na vat he S  An efficient algorithm for mining association rules in large databases, in Prod. of the 21 st VLDB conf  She noy P Bhal otia G Haritsa J B a wa M Sudarshan S., Shah D., Turbo-charging vertical mining of large database, Prod. of the SIGMOD2000  a processi ng for com plex queries, Red Brick/Informix White Paper  as and starjoi n technology Red Brick/Informix White Paper  P C be nchm ark d de cision s u pport  dard specification, Release 2.2. \(Transaction Processing Performance Council \(TPC  durie x P J oi n indexe s ACM TODS 12\(2\ 1987  W u M Buchm ann A  Encoding bitm ap indexing for data warehouse, Proc. of the 14th  Intl Conference on Data Engineering, 220-231, 1998   Gouda K., F ast vertical usi ng diffsets, Tech report, Dept. of  computer science, RPI  Y., Des hpa nde P., Naughton J Shukla A.,  Simultaneous optimization and evaluation of multiple dimensional queries, SIGMOD-98, 271282 Proceedings of the Seventh International Database Engineering and Applications Symposium \(IDEAS03 1098-8068/03 $17.00  2003 IEEE 


20% 4 4 4 12 12 30% 4 3 3 12 12 40% 3 3 3 12 11 50% 3 2 2 11 10 60% 2 1 2 11 10 70% 2 1 2 11 11 80% 2 2 2 10 11 90% 2 2 2 9 10 99% 0 1 1 6 10 Looking at Table 9, one may wonder why the representation determined for minSup = 70% has shorter longest elements in its Bd  GDFree \(here: length = 1 than the representation determined for minSup = 80 here: length = 2 border elements in Bd  GDFree, which are infrequent in the representation determined for minSup = 80 become frequent when lowering the support threshold to 70 7. Related work The most similar to the representations based on generalized disjunctive sets is the NDR representation which consists of all frequent non-derivable itemsets [7 8], and the representations based on ?-free sets [7, 9]. It was shown in [8], that for each non-empty itemset Z, one can derive the lower bound \(l\(Z u\(Z on sup\(Z from the fact that sup\(Z Non-derivable itemsets are those for which u\(Z Z gt; 0. If u\(Z Z sup\(Z supersets Y of a derivable itemset are also derivable and u\(Y Y Y such that neither sup\(Z Z Z Z It was proved in [7, 8] that u\(Z Z  u\(Z?{a Z?{a for |Z| ? 1 This important result was used in [7, 8] to determine the upper bound on the length of non-derivable itemsets namely: non-derivable itemsets are not longer than log2|D|? + 1 Hence, the bound on the length of non-derivable itemsets is identical to the bound on the length of generalized disjunction-free sets \(please see Theorem 3.2 It has been proved in [7] that ?-free sets are a subset of non-derivable itemsets, so their length is also bounded by ?log2|D|? + 1 There is a claim in [7, 9] that the generalized disjunction-free sets equal the ?-free sets. This claim however, is not correct, which we will prove by the example beneath. Table 4 contains all generalized disjunction-free sets. Among them, there is {fh}, the support of which equals 0. The support bounds for {fh are found as follows \(please, see [7] for the details  sup\({fh f h   sup\({fh f  sup\({fh h  sup\({fh Proceedings of the 16th International Conference on Scientific and Statistical Database  Management \(SSDBM  04 1099-3371/04 $ 20.00  2004 IEEE Hence, l\({fh fh fh sup\({fh free, is not a ?-free set Since the families of the generalized disjunction-free sets and ?-free sets may differ, finding the relationship between them or between the generalized disjunction-free sets and non-derivable itemsets remains a challenge 8. Conclusions The representations based on generalized disjunctionfree sets belong to the most concise ones among all lossless frequent patterns representations with borders. In 


lossless frequent patterns representations with borders. In practice, they are also much more concise than representations based on closed itemsets and approximate representations. In this paper, we offered three methods of deriving an upper bound on the length of sets in such representations. We proved that the upper bound on the length of a longest generalized disjunction-free set depends logarithmically on the number of records in the database. The obtained result is of high importance as it guarantees that any generalized disjunction-free set representation for all patterns \(both frequent and infrequent scans, where n is the number of records in the database irrespectively how strong or weak correlations among items in the database are and irrespectively of the lengths of records and number of distinct items The modifications of the basic estimation take into account the support threshold of the representation to be found or, additionally, the information on the length of longest sets of the representation already calculated for a higher support threshold. Though these estimations are more accurate than the basic one, they are still quite rough. Further improvements of the quality of estimating the length of longest itemsets in generalized disjunctionfree representations is subject to further research References 1] R. Agrawal, H. Mannila, R. Srikant, H. Toivonen, A.I Verkamo  Fast Discovery of Association Rules   Advances in Knowledge Discovery and Data Mining AAAI, CA, 1996 2] J. Baptiste, J.-F. Boulicaut  Constraint-Based Discovery and Inductive Queries: Application to Association Rule Mining  Pattern Detection and Discovery, Springer London, UK, September 2002, pp. 110-124 3] E. Baralis, S. Chiusano, P. Garza  On Support Thresholds in Associative Classification  SAC, ACM, Taipei Taiwan, March 2004, pp. 553-558 4] Y. Bastide, N. Pasquier, R. Taouil, G. Stumme, L. Lakhal  Mining Minimal Non-redundant Association Rules Using Frequent Closed Itemsets  Computational Logic, 2000 pp. 972  986 5] J.-F. Boulicaut, A. Bykowski, C. Rigotti  Approximation of Frequency Queries by Means of Free-Sets  PKDD Springer, Lyon, France, September 2000, pp. 75-85 6] A. Bykowski, C. Rigotti  A Condensed Representation to Find Frequent Patterns  PODS, ACM, Santa Barbara USA, May 2001, pp. 267-273 7] T. Calders, Axiomatization and Deduction Rules for the Frequency of Itemsets, Ph.D. Thesis, University of Antwerp, 2003 8] T. Calders, B. Goethals  Mining All Non-derivable Frequent Itemsets  PKDD, Springer, Helsinki, Finland August 2002, pp. 74?85 9] T. Calders, B. Goethals  Minimal k-free Representations of Frequent Sets  ECML/PKDD, Springer, CavtatDubrovnik, Croatia, September 2003, pp. 71-82 10] J. Han, M. Kamber, Data Mining: Concepts and Techniques, Morgan Kaufmann Publishers, 2000 11] S.K. Harms, J. Deogun, J. Saquer, T. Tadesse  Discovering Representative Episodal Association Rules from Event Sequences Using Frequent Closed Episode Sets and Event Constraints  ICDM, IEEE Computer Society, San Jose, California, USA, November-December 2001, pp. 603  606 12] M. Kryszkiewicz  Closed Set Based Discovery of Representative Association Rules  IDA, Springer Cascais, Portugal, September 2001, pp. 350-359 13] M. Kryszkiewicz  Concise Representation of Frequent Patterns based on Disjunction  free Generators  ICDM IEEE Computer Society, San Jose, California, USA 


IEEE Computer Society, San Jose, California, USA November-December 2001, pp. 305  312 14] M. Kryszkiewicz M  Inferring Knowledge from Frequent Patterns  Soft-Ware, Springer, Belfast, Northern Ireland April 2002, pp. 247  262 15] M. Kryszkiewicz  Concise Representations of Association Rules  Pattern Detection and Discovery, Springer London, UK, September 2002, pp. 92-109 16] M. Kryszkiewicz, Concise Representation of Frequent Patterns and Association Rules, Habilitation Thesis Publishing House of Warsaw University of Technology 2002 Proceedings of the 16th International Conference on Scientific and Statistical Database  Management \(SSDBM  04 1099-3371/04 $ 20.00  2004 IEEE 17] M. Kryszkiewicz  Reducing Infrequent Borders of Downward Complete Representations of Frequent Patterns  Proc. of The First Symposium on Databases Data Warehousing and Knowledge Discovery, Scientific Publishers OWN, Baden-Baden, Germany, July, 2003, pp 29-42 18] M. Kryszkiewicz  Closed Set Based Discovery of Maximal Covering Rules  International Journal of Uncertainty, Fuzziness and Knowledge-Based Systems Vol. 11. World Scientific Publishing Company, Singapore September 2003, pp. 15-29 19] M. Kryszkiewicz  Reducing Borders of k-Disjunction Free Representations of Frequent Patterns  SAC, ACM Taipei, Taiwan, March 2004, pp. 559  563 20] M. Kryszkiewicz  Reducing Main Components of k-Disjunction Free Representations of Frequent Patterns   Proc. of IPMU  2004 \(in print 21] M. Kryszkiewicz, M. Gajek  Concise Representation of Frequent Patterns based on Generalized Disjunction  Free Generators  PAKDD, Springer, Taipei, Taiwan, May 2002, pp. 159-171 22] M. Kryszkiewicz, M. Gajek  Why to Apply Generalized Disjunction-Free Generators Representation of Frequent Patterns  ISMIS, Springer, Lyon, France, June 2002, pp 383  392 23] M. Kryszkiewicz, H. Rybi?ski, M. Gajek  Dataless Transitions between Concise Representations of Frequent Patterns  Journal of Intelligent Information Systems JIIS Netherlands, 2004, pp. 41-70 24] N. Pasquier, Data mining: Algorithmes d  extraction et de R  duction des R  gles d  association dans les Bases de Donn  es, Th  se de Doctorat, Universit  Blaise Pascal   Clermont  Ferrand II, 2000 25] N. Pasquier, Y. Bastide, R. Taouil, L. Lakhal  Efficient Mining of Association Rules Using Closed Itemset Lattices  Journal of Information Systems, Vol. 24, No. 1 1999, pp. 25  46 26] N. Pasquier, Y. Bastide, R. Taouil, L. Lakhal  Discovering Frequent Closed Itemsets for Association Rules  ICDT, Springer, Jerusalem, Israel, January 1999 pp. 398  416 27] J. Pei, G. Dong, W. Zou, J. Han  On Computing Condensed Frequent Pattern Bases  ICDM, IEEE Computer Society, Maebashi City, Japan, December 2002 pp. 378-385 28] V. Phan-Luong V  Representative Bases of Association Rules  ICDM, IEEE Computer Society, San Jose California, USA, November-December 2001, pp. 639-640 29] A. Savinov  Mining Dependence Rules by Finding Largest Itemset Support Quota  SAC, ACM, Taipei Taiwan, March 2004, pp. 525-529 30] M.J. Zaki, C.J. Hsiao  CHARM: An Efficient Algorithm for Closed Itemset Mining  SIAM, Arlington, 2002 


for Closed Itemset Mining  SIAM, Arlington, 2002 Proceedings of the 16th International Conference on Scientific and Statistical Database  Management \(SSDBM  04 1099-3371/04 $ 20.00  2004 IEEE pre></body></html 


                                                  S J       


                                                      


                         L A                                        


          L A  Table 7. Table of Granules at left-hand-side is isomorphic to  at right- hand-side: By Theorem  3.1 one can ?nd patterns in either table as a single generalized concept  Internal points  are:[4]\(1, 1, 0, 0 tions; [5]\(0, 1, 1, 0  0, 1, 0, 1  0, 1, 1, 1  1, 1 1, 0  1, 1, 0, 1  1, 0, 1, 1 11]\(1, 1, 1, 1 form and simplify them into disjoint normal forms 1  T E N    S J    T E N    S J 2  T W E N T Y    L A    T H I R T Y   A 3  T W E N T Y      T H I R T Y   A 4  T W E N T Y            L A 5  T E N      T W E N T Y    L A    T E N    T W E N T Y   A   S J    T W E N T Y   A      T H I R T Y    L A     Y 7  T E N      T W E N T Y      T H I R T Y   L A    T E N   L A    S  J   A 8  T W E N T Y      T E N      T W E N T Y    L A    T E N   T W E N T Y      T H I R T Y 9  T W E N T Y    N Y    T E N    S J    T H I R T Y    L A      T W E N T Y    L A  1 0  T W E N T Y    N Y    T W E N T Y    L A    T H I R T Y   A    J 1 1  T W E N T Y          T W E N T Y    L A   T H I R T Y    L A    a l l If the simpli?ed expression is a single clause \(in the original symbols non-generalized the following associations 1   T E N     S J    T E N    S J  2. SJ   J 4   L A    T W E N T Y    L A    T H I R T Y    6 Conclusions Data, patterns, method of derivations, and useful-ness are key ingredients in AM. In this paper, we formalize the current state of AM: Data are a table of symbols. The patterns are the formulas of input symbols that repeat. The method of derivations is the most conservative and reliable one, namely, mathematical deductions. The results are somewhat surprising 1. Patterns are properties of the isomorphic class, not an individual relation - This implies that the notion of patterns may not mature yet and explains why there are so many extracted association rules 2. Un-interpreted attributes \(features can be enumerated 3. Generalized associations can be found by solving integral linear inequalities. Unfortunately, the number is enormous. This signi?es the current notion of data and patterns \(implied by the algorithms 4. Real world modeling may be needed to create a much more meaningful notion of patterns. In the current state of AM, a pattern is simply a repeated data that may have no real world meaning. So we may need to introduce some semantics into the data model [12],[10],[11 Proceedings of the Fourth IEEE International Conference on Data Mining \(ICDM  04 0-7695-2142-8/04 $ 20.00 IEEE References 1] R. Agrawal, T. Imielinski, and A. Swami  Mining Association Rules Between Sets of Items in Large Databases  in Proceeding of ACM-SIGMOD international Conference on Management of Data, pp. 207216, Washington, DC, June, 1993 


216, Washington, DC, June, 1993 2] Richard A. Brualdi, Introductory Combinatorics, Prentice Hall, 1992 3] A. Barr and E.A. Feigenbaum, The handbook of Arti?cial Intelligence, Willam Kaufmann 1981 4] Margaret H. Dunham, Data Mining Introduction and Advanced Topics Prentice Hall, 2003, ISBN 0-13088892-3 5] Fayad U. M., Piatetsky-Sjapiro, G. Smyth, P. \(1996 From Data Mining to Knowledge Discovery: An overview. In Fayard, Piatetsky-Sjapiro, Smyth, and Uthurusamy eds., Knowledge Discovery in Databases AAAI/MIT Press, 1996 6] H Gracia-Molina, J. Ullman. &amp; J. Windin, J, Database Systems The Complete Book, Prentice Hall, 2002 7] T. T. Lee  Algebraic Theory of Relational Databases  The Bell System Technical Journal Vol 62, No 10, December, 1983, pp.3159-3204 8] T. Y. Lin  Deductive Data Mining: Mathematical Foundation of Database Mining  in: the Proceedings of 9th International Conference, RSFDGrC 2003 Chongqing, China, May 2003, Lecture Notes on Arti?cial Intelligence LNAI 2639, Springer-Verlag, 403-405 9] T. Y. Lin  Attribute \(Feature  The Theory of Attributes from Data Mining Prospect  in: Proceeding of IEEE international Conference on Data Mining, Maebashi, Japan, Dec 9-12, 2002, pp. pp.282-289 10] T. Y. Lin  Data Mining and Machine Oriented Modeling: A Granular Computing Approach  Journal of Applied Intelligence, Kluwer, Vol. 13, No 2, September/October,2000, pp.113-124 11] T. Y. Lin, N. Zhong, J. Duong, S. Ohsuga  Frameworks for Mining Binary Relations in Data  In: Rough sets and Current Trends in Computing, Lecture Notes on Arti?cial Intelligence 1424, A. Skoworn and L Polkowski \(eds 12] E. Louie,T. Y. Lin  Semantics Oriented Association Rules  In: 2002 World Congress of Computational Intelligence, Honolulu, Hawaii, May 12-17, 2002, 956961 \(paper # 5702 13  The Power and Limit of Neural Networks  Proceedings of the 1996 EngineeringSystems Design and Analysis Conference, Montpellier, France, July 1-4, 1996 Vol. 7, 49-53 14] Morel, Jean-Michel and Sergio Solimini, Variational methods in image segmentation : with seven image processing experiments Boston : Birkhuser, 1995 15] H. Liu and H. Motoda  Feature Transformation and Subset Selection  IEEE Intelligent Systems, Vol. 13 No. 2, March/April, pp.26-28 \(1998 16] Z. Pawlak, Rough sets. Theoretical Aspects of Reasoning about Data, Kluwer Academic Publishers, 1991 Proceedings of the Fourth IEEE International Conference on Data Mining \(ICDM  04 0-7695-2142-8/04 $ 20.00 IEEE pre></body></html 


than that of MAFIA and the runtime of MHP can be significantly less than that of MAFIA 5.3. The Effect of the MHP Algorithm on Finding Maximal Hyperclique Patterns Figure 8 and Figure 9 show the number of maximal patterns identi?ed byMHP andMAFIA on Pumsb* and Pumsb data sets respectively. As can be seen, the number of maximal hyperclique patterns identi?ed by MHP can be orders of magnitude smaller than the number of maximal frequent patterns identi?ed by MAFIA. In other words, the number Proceedings of the 16th IEEE International Conference on Tools with Artificial Intelligence \(ICTAI 2004 1082-3409/04 $20.00  2004 IEEE 100 1000 10000 100000 1e+06 1e+07 1e+08 1e+09 0.02 0.025 0.03 0.035 0.04 0.045 0.05 0.055 0.06 N um be r o f C ou nt ed P at te rn s Support Threshold Mafia Min_Conf=0 Min_Conf=0.1 Min_Conf=0.3 Min_Conf=0.5 Min_Conf=0.7 Min_Conf=0.9 Figure 8. The Number of MFI/MHP Patterns in the Pumsb* Data Set 100 1000 10000 100000 1e+06 


1e+07 1e+08 0.1 0.2 0.3 0.4 0.5 0.6 0.7 N um be r o f C ou nt ed P at te rn s Support Threshold Mafia Min_Conf=0.5 Min_Conf=0.7 Min_Conf=0.9 Figure 9. The number of MFI/MHP Patterns in the Pumsb Data Set of maximal hyperclique patterns is much easier to manage than that of maximal frequent patterns. Indeed, in realworld applications, it is dif?cult to interpret several million maximal frequent patterns. However, it is possible to interpret the results of maximal hyperclique pattern mining In addition, due to the memory limitation, we cannot extract maximal frequent patterns with MAFIA on the Pumsb data set if the support threshold is less than 0.4, as shown in Figure 7. In contrast, MHP can identify maximal hyperclique patterns when the support threshold is 0.1, if we set the h-con?dence threshold to 0.5. In other words, MHP has the ability to identify patterns which can be dif?cult to identify for MAFIA. Hence, MHP can better explore the pattern space and ?nd interesting patterns at low levels of support 6. Conclusions and Future Work In this paper, we present a two-phase Maximal Hyperclique Pattern \(MHP best features of both the BFS strategy and the DFS strategy. More speci?cally, we adapted DFS pruning methods such as equivalence pruning, to an apriori-like approach In addition, we proved the correctness and completeness of the MHP algorithm. Finally, our experimental results show that the MHP algorithm can be several orders of magnitude faster than standard maximal frequent pattern mining algorithms and has the ability to identify patterns at extremely low levels of support in dense data sets There are several directions for future work. First, in 


this paper, we only generate the size-2 patterns in the BFS phase. It will be interesting to investigate the impact on the performance if the ?rst phase is stopped at a deeper level Also, the projection is a very ef?cient method for ?nding patterns, especially for parallel implementation of pattern mining algorithms [1]. We plan to adapt the projection ideas into our algorithm and design an ef?cient parallel algorithm for mining maximal hyperclique patterns References 1] R. Agarwal, C. Aggarwal, and V. Prasad. A Tree Projection Algorithm For Generation of Frequent Itemsets. pages 350 371, Feb 2001 2] R. Agrawal, T. Imielinski, and A. Swami. Mining Association Rules between Sets of Items in Large Databases. In Proc. of the ACM SIGMOD Conference on Management of Data, pages 207216,May 1993 3] R. Agrawal and R. Srikant. Fast Algorithms for Mining Association Rules. In Proc. of the 20th Intl Conference on Very LargeData Bases, 1994 4] R. Bayardo. Ef?ciently mining long patterns from databases In Proc. of the ACM SIGMOD Conference, 1998 5] R. Bayardo and R. Agrawal. Mining the Most Interesting Rules. In Proc. of the ACM SIGKDD Conference, 1999 6] D. Burdick, M. Calimlim, and J. Gehrke. Ma?a: AMaximal Frequent Itemset Algorithm for Transactional Databases. In Proc. of IEEE Conf. on Data Engineering, 2001 7] Y. Huang, H. Xiong, W. Wu, and Z. Zhang. A Hybrid Approach for Mining Maximal Hyperclique Patterns. In In Technical Report UTDCS-34-04, Department of computer science, University of Texas - Dallas, 2004 8] J.Han, J.Pei, and Y. Yin. Mining Frequent Patterns without Candidate Generation. In Proc. of the ACM SIGMOD International Conference on Management of Data, 2000 9] M.J.Zaki and C.Hsiao. ChARM: An ef?cient algorithm for closed itemset mining. In Proc. of 2nd SIAM International Conference on Data Mining, 2002 10] R.Rymon. Search through Systematic Set Enumeration. In Proc. Third Intl Conference on Principles of Knowledge Representation and Reasoning, 1992 11] H. Xiong, M. Steinbach, P.-N. Tan, and V. Kumar. HICAP: Hierarchial Clustering with Pattern Preservation. In Proc. of 2004 SIAM International Conference on Data Mining \(SDM 12] H. Xiong, P.-N. Tan, and V. Kumar. Mining Strong Af?nity Association Patterns in Data Set with Skewed Support. In Proc. of the Third IEEE International Conference on Data Mining \(ICDM Proceedings of the 16th IEEE International Conference on Tools with Artificial Intelligence \(ICTAI 2004 1082-3409/04 $20.00  2004 IEEE 





