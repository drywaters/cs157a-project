html><head></head><body><pre style="word-wrap: break-word; white-space: pre-wrap;">Proceedings  of the Third International Conference on Machine Learning and Cybernetics, Shanghai, 26-29  August 2004 DISCOVERING WEB USAGE PATTERNS BY MINING CROSS-TRANSACTION ASSOCIATION RULES JIAN CHEN l, JIAN m l, ANTHONY K.H.  TUNG^, BIN LIU  Department of Computer Science, Zhongshan University, Guangzhou 5 10275, China  Department of Computer Science, National University of Singapore, 3 Science Drive 2,117543  Singapore E-MAIL: ellachen@ 163.com Abstract Web Usage Mining is the application of data mining techniques to large Web log databases in order to extract usage patterns. However, most of the previous studies on usage patterns discovery just focus on mining intra transaction associations, i.e., the associations among items within the same user transaction. A . cross-transaction association rule describes the association relationships among different user transactions. In this paper, the closure property of frequent itemsets is used to mining cross-transaction association rules from web log databases. An approach and algorithmic framework beads on it is designed and analyzed   Keywords cross-transaction; frequent closed pageviews sets Web usage mining; usage patterns; association rules 1. Introduction The ease and speed with which business transaction can be carried out over the Web has been a key driving force in the rapid growth of electronic commerce. As the number of online users grows, so does the volume of transaction data collected at the Web servers. Web usage mining is the process of applying data mining techniques to the discovery of usage patterns from Web data. Web usage mining techniques, which rely on offline pattern discovery from users  transactions, can capture more fine-grained information of users  browsing behaviors. One interesting information type is the Web association pattern, which describes the potential association rules between the items or pages in the same users  transactions. However, there is an important form of association rule, which is useful but could not be discovered by existing association rule mining algorithm. Let us take Web users  transactions database as an example. By specifying the value of minsupp \(minimum support minimum confidence association rule mining may find the rules like 0 RI: 55.6% of the user who accessed page A and page B also accessed page C While RI reflects some relationship among the pages in the same user transaction, its scope of prediction is limited; and people may be more interested in the following type of rules 0 R2: If the first user accesses page A and page B, then at 72.6% of probability, the next fourth user will view page C Anthony K.H. Tung  proposed the concept of inter transaction association rules which like R2 first. While classical association rule like RI expresses the associations among items within the same user transaction, Rule Rz represents some association relationship among the field values from different user transaction records. It is obvious that the description scope of the latter is deep and wide than the former The rest of this paper is organized as follows: we start by giving the problem description and the related definitions of Web cross-transaction association pattern in Section 2. Next, Section 3 presents an approach and algorithmic framework for mining cross-transaction frequent closed pageviews sets. In Section 4, an experimental example is presented to illustrate each phase 


experimental example is presented to illustrate each phase in details. Finally, we draw a conclusion in Section 5 2. Problem Statement 2.1. Basic Description of Web Association Patterns A complete statement of Web user transactions database includes a set of n pageviews, P = { pI , p z ,  ..., p and a set of m user transactions, T = {t ,  ,t2 ,..., t,,, } , where each ti E T \(with a unique identifier TID Pageviews are semantically meaningful entities to which mining tasks are applied \(such as pages or items Transactions is semantically meaningful groupings of pageviews in each user session. Conceptually, we view each transaction t as an 1-length sequence of ordered pairs 0-78o3g4o3-2/o4/$20.00 \(92004 IEEE 2655 Proceedings of the Third International Conference on Machine Learning and Cybernetics, Shanghai  26-29 August 2004 t =&lt; \( p ~ , ~ \( p p ~ , w \( p p ~ , ~ \( p where each p: = pi for somejE \( I ,  ..., n ] ,  andw\(pl weight associated with pageview pf in the transaction t. The weights can be determined in a number of ways. In this paper, since our focus is on association rule mining, we only use binary weights to represent existence or non-existence of pageviews access in the user transactions Thus, a transaction can be viewed as a set of pageviews s, = { pl! I1 I i I I A w\(pf rules capture the relationships among pageviews based on the navigational patterns of users. Given a transaction set T We call a group of pageviews as frequent pageviews sets if all of these pageviews are occumng frequently together in many transactions \(i.e., satisfying minsiupp threshold set F ={f,,f,, ..., f,} be a frequent pageviews sets over T The support of a pageviews set A E F is defined as An association rule is an implication expression of the formX + Y ,  whereX G F  , Y  G F ,  X n Y  ~ 0 ,  and the confidence a = a \( X  U Y X minconf O \( A  TI A. Cl 2.2. Defdtions and ProperW of Clross-transaction For mining cross-transaction association rules, related definitions and notions will be giving as following Defdtion 1 \(sliding window a transactions database T is a block of o continuous intervals, which starting from intend dl such that T contains a transaction at interval d,. H[ere o is called the span of window. Each interval dj in W is called a sub-window of W denoted as W,, where u=d,-dl, 1 5 ~ 3 The definition of sliding window breaks the barrier of transaction and extends the scope of association rules from traditional intra-transaction to cross-transaction. The target of mining is to find out the rules which span less than or equal to o intervals Definition 2 \(extended pageview and W, extended pageview is defined as pi \(U  W w h e r e p , E P , l I i I m , l l u I w .  Then the extended pageviews set can be expressed as EP = {PI \(I 0 I 0 Defintion 3 \(extended transaction window W starts from kth transaction, an extended transaction will be generated et, = {pi\(u pi where1 I i 5 I ,1 I u I 0  , I  I k I n  -0 ,k I j I k + 0 Definition 4 \(extended user transactions database ED =\(etk I1 I k I n - a Definition 5 \(cross-transaction closed pageviews set A pageviews set CCP c_ EP is a cross-transaction closed pageviews set if there exists no another pageviews set C c EP , such that 1  is a proper superset of CCP, and 2 C   


C   A closed pageviews sets is frequent if its support is higher than minsupp Property 1: If CCP is a cross-transaction closed pageviews set, and then in any sub-window W, over CCP, C  pi  I p i \( u transaction closed pageviews set Proof: We will prove this property by contradiction Given the above conditions, if there exists a sub-window W, such that C  is not an intra-transaction closed pageviews set. From the definition of closed pageviews set, there exists another pageviews set L  which make the following statements true  C  c  L  and  L  is a closed pageviews set  and  o\(C   L    Let ZE L  C  then its extended form z\(u contains C  also contains z, so each extended transaction which contains CCP also contains t\(u L = CCP +{z\(u  CCP c L  and  o\(C   L    This conclusion contradicts to the fact that  CCP is a cross-transaction closed pageviews set Property 2: The support of a frequent cross-transaction frequent pageviews set is equal to the support of its cross-transaction closure Definition 6 \(Web cross-tiansaction association pattern transaction association pattern is an implication expression of the form X + Y , which satisfies n X E E P , Y  ~ E P , x n Y 5 0 3itemi \(1 3itemj\(u a = a \( X  u Y X A Framework for Mining Web Cross-transaction Assodation Patterns Generally speaking, Web cross-transaction association patterns mining involve 3 phases: data preparation cross-transaction frequent pageviews sets discovery and 2656 Proceedmgs of the Third International Conference on Machine Learning and Cybemetics, Shanghai  26-29 August 2004 pattew generation 3.1. Data Preparation The starting and critical for our successful target based on Web is data preparation. Data cleaning is the task of removing log entries that are not necessary for the mining process, including eliminating irrelevant and unreasonable items and removing all log entries with filename suffixes representing images and sounds. In addition, common scripts as  cgi  can also be removed. User transaction identification is the task of identifying semantically meaningful groupings of pageviews in each user session There are three divide transaction identification approaches in common use. The first two, reference length and maximal forward reference, make an attempt to identify semantically meaningful transactions. The third, time window, is not based on any browsing mode, and is mainly used as a benchmark to compare with the other two algorithms. The final step of preparation is formatting the data necessary for the specific data mining algorithm ta be usedr2 3.2. Mining Cross-transaction Frequent Closed Pageviews Sets This phase is the bottleneck of the whole mining process. Because the boundary of transactions is broken the number of potential association rules becomes extremely large. We provide a new efficient algorithm to mining cross-transaction frequent pageviews set by using its closure property. In Section 2, Property 1 shows that a pageviews set must be closed in intra- transaction if its extended form is closed in cross- transaction. It provides a different view of mining process. Instead of mining the 


different view of mining process. Instead of mining the cross-transaction patterns from extended user transactions database directly, we decompose the whole phase two into three steps 1 sets and store them and their related TidSet 2 closed pageviews sets into sub-window W, when sliding window W moves dymaticly 3 sets by calculating the frequency of the intersection of each two pageviews sets in different window Step 1: Many traditional frequent closed itemsets mining algorithms can be utilized in this step, such as C L O S ~ ,  A-CLOSE, MAFIA, etc.  CHARM[^] enumerates closed sets using a dual itemset-tidset search tree, using an efficient hybrid search that skips many levels and using a fast hash-based approach to remove any  non-closed  sets found during computation. Experiments on a number of real and synthetic databases show that CHARM significantly outperforms previous methods. So we take CHARM to mining intra-transaction frequent closed pageviews sets. All intra-transaction frequent closed pageviews sets and their related TidSet will be stored properly Step 2: With the continuous moving of the sliding window W, the old simple TidSet can not reflect the status information of intra-transaction frequent closed pageviews sets in cross-transaction. If some set of transaction nl appears in uth sub-window, in this time, sliding window W must start from transaction n,-u+l. This situation is shown as following Frequent Closed  nl- u+l I Figure 1 .  W which start from Transaction nl-u+l takes FCPS as FCPS\(u Then, we will extend TidSet\(FCPS\(u place of W starting from while FCPS appears in sub-window W Definition 7 \(extended transaction ID set FCPS\(U U tTID1 For any FCPS in the results of step 1, suppose its TidSet is TidSet\(FCPS nl,n2, ... nk sub-window W,, its extended TidSet will be TidSet\(FCPS\(u efficient strategies to prune illegal TIDs from each new TidSet 1 2 And two judgments are used to remove the whole unreasonable TidSets 3 nxminsupp, then it cannot satisfy the support threshold 4 number n null transaction 2657 Proceedings of the Third International Conference on Machine Learning and Cybernetics, Shanghai  26-29 August 2004 if FCPSl c FCPS2 and TidSet\(FCPSl\(u TidSet\(FCPS2\(u u will be stored Algorithm 1 : Extent-TidSet w: FT\(FCPS, TidSet pageviews sets and their related TidSets W. an array recorded every transaction ID where sliding window W starts from 


sliding window W starts from Output: CFT\(FCPS\(sub-Win u and its related extended TidSets Method CFT for u=l to o extend each FCPS and its TidSet in FT for each \(X,TidSet for each TidE TidSet new-Tid= Tid-u+ I add new-Tid to new-TidSet end for add \(X\(u end for prune unreasonable TIDs and TidSlets for \(X\(u for each TIDE new-EdSet strategy \(1 2 iflnew-Tidel and new-Tid@ W end if end for strategy \(3 if hew-TidSetl &lt;nxminsupp end if I* strategy \(4 if 3 Y\(u delete TID from new-TidSet delete new-TidSetfrom CIT IX.new-TidSetl = I Enew-TidSetl delete new-TidSetfrom CFT end i f end for end for Step 3: After Step 2, all TIDs in TidSets have unique meanings Definition 8 \(cross-transaction frequent closed pageviews set frequent closed pageviews sets, TidSet\(FCPSl\( 1 m2,. . .,mk FCPS2\(i 2410 the total elements number of their TidSet intersection III ITidSet\(FCPS1\( 1 FCPS2\(i CFpS=FCPSI\( l i the definition 5,  it is a cross-transaction frequent closed pageviews set According the above definition, we have the following algorithm to mining cross-transaction frequent closed pageviews sets Algorithm 2: Mining-CFCPS m: CFT\(FCPS\(sub-Win above OutDut: CFCPS\(CFPS, TidSet frequent closed pageviews sets Method CFCPS each FCPS always appears in the first sub-window for each \(FcPS\(l CFPS = \(FCPS\(I add CFPS to CFCPS  end for find CFPS sub-window by sub-window for u=2 to w for each CFPSE CFCPS for each \(X\(u I = CFPS.TidSet rl X\(u i f  IIlLnxminsupp end if add CFPS U X\(u end for end for end for remove that original FCPS\(1 for each CFPSE CFCPS 


ifall items  CFPS are in the same sub-window end i f remove CFPS from CFCPS end for 3.3. Patterns Generation To generate patterns, for every CFCPS in the results of Step 3 above, we find all non empty subsets of CFCPS. For every such subset SE CFCPS, we output a rule of the form s * \(CFCPS-s CFCPS s shows that if s*\(CFCPS-s s 3 \(CFCPS- S in reference [4] to complete this phase  4. Experimental Example In Section 3, we give the framework to mining cross-transaction frequent closed pageviews sets. In the three phases of this framework, Phase 1 and Phase 3 are traditional matured Web mining techniques. Now, we 2658 Proceedings of the Third International Conference on Machine Learning and Cybernetics, Shanghai  26-29 August 2004 present an experimental example to illustrate the main idea and processes of Phase 2. Suppose the minimum support minsupp threshold is specified as 0.4 and minco$is 0.6. Let us take the user transactions database segment given in Figure 2 as an example. 1 T; I Pageviews I Sliding Winsow W I I I T ,  I 1- I I '; iI I I J --e Figure 2. The transactions database with sliding window The above user transactions database includes 5 useful transactions \(we take the transaction which don't contain the items studies as null W must start from a transaction which contains at least one pageview. t3=\(c,d,e becomes W1 along with the next movement of W. To utilize the algorithm CHARM successfully, we change the format of transaction data from horizontal to vertical. CHARM results in the following intra-transaction frequent closed pageviews sets Table 1. The results of Step 1 I support Table 2. The results of Step 2 By calculate the length of the intersection of two FCPS in different sub-window, which described in Algorithm 2, we can find cross-transaction frequent closed pageviews sets. To illustrate the process of it, we keep our eyes on the changing of the elements in the queue of CFCPS a wl Add thenew CFPS to the tail of queue a I c \( l l 2 c\(lMW3 a ii;i 1 ~ ~ \( 2 l 1 ~ 4 remove the original FCPS\(1 bf\(lM2 Figure 3. The process of Step 3 Thus, we got the final cross-transaction frequent closed pageviews sets bf\(I 2 l rlf and c\(l 3 Web association patterns bf\(1 2 1 3 bRl We apply Algorithm 1 to the data above, all TidSets of the intra- transaction frequent closed pageviews sets are extended. Each unreasonable and irrelevant TID has been eliminated 5. Conclusions As the number of Web users grows, Web usage patkerns which describe the hidden association information 


patkerns which describe the hidden association information of users' browsing interest has attracted more and more attention of researchers. Knowledge derived from the Web association patterns can be used to improve the 2659 Proceedings of the Third International Conference on Machine Learning and Cybernetics, Shanghai  26-29 August 2004 organization of Web sites, efficient personality and References recommendation systems, and collecting business intelligence about the behavior of Web users, etc. In this paper, we provide a new view of Web association pattems by extending the scope of it. The related definitions of properties are given and an efficient mining approach for this new form association rules is present in detail Acknowledgements l 121 This work is supported by the National Natural Science Foundation of China \(60205007 Foundation of Guangdong Province \(001264,03 1558 Research Foundation of Science and Technology Plan Project in Guangdong Province \(2003C50118 Research Foundation of State Key Laboratory for L41 131 Novel Software Technology at Nanjing University Anthony K.H. Tung, Hongjun Lu, Jiawei Hq, and Ling Feng  Efficient Mining of Intertransaction Association Rules  IEEE Transactions on Knowledge and Data Engineering, Vol. 15, No.1 JanuaryFebruary 2003, pp. 43-56 R.. Cooley, B. Mobasher, and J. Srivastava  Data preparation for mining world wide web browsing pattems   Joumal of Knowledge and Information Systems, Vol. 1, No l., February 1999. pp 5-32 Zaki,MJ, Hsiao CJ  CHARM: An efficient algorithm for closed itemset mining  In: Grossman R, et al. eds Proc. of the 2nd SIAM Int  l. Conf. on Data Mining Arlington: SIAM, 2002. pp 12-28 Agrawal R, Srikant R  Fast algorithms for mining association rules  In: Beeri C, et al, eds. Roc. of the 20th Int  l. Conf. on Very Large Databases. Santiago Morgan Kaufmann Publishers, 1994. pp 487-499 2660 pre></body></html 


In Figure 5 for the same reason as  results for the Partitioning algorithm is not shown It is still the slowest comparing the total running time This is because it generates too many candidate frequent itemsets from the dense dataset Together with the data structures the candidate sets use up main memory and virtual memory s used In Figure 5 a the time used for disk I/O\222s of the Aggressive algorithm is still remarkably less than the time used for disk I/O\222s of the Basic Algorithm We can again notice that the CPU time of the Basic Algorithm is less than that of the Aggressive algorithm This is because Kosarak is a dense dataset so the FP-array technique does not help a lot In addition calculating the statistics takes an amount of time To test the effectiveness of the techniques for grouping items we run Diskmine on T100I20D100K and see how close the estimation of the FP-tree size for each group is to its real size We still set the main memory size as 128 megabytes the minimum support is 2 When generating the projected databases items were grouped into 7 groups the total number of frequent items is 826 As we can see from Figure 6 a in all groups the estimated size is always slightly larger than the real size Compared with the Basic Algorithm which constructs an FP-tree for each item from its projected database the Aggressive algorithm almost fully uses the main memory for each group to construct an FP-tree                 Estimation size vs. Real size 0 20 40 60 80 100 120 140 160 1234567 Group Memo ry M eg ab yt es  Estimated size  Real size a   Scalability 0 100 200 300 400 500 600 700 200 400 600 800 1000 1200 1400 1600 1800 2000 NO. of Transactions \(k Time s  CPU Disk I/O b Figure 6 Estimation Accuracy and Scalability of Diskmine As a ivide-and-conquer algorithm one f the most important properties of Diskmine is its good scalability We ran Diskmine on a set of synthetic datasets In all datasets the item number s set as 10000 items the average transaction length as 100 and the average pattern length as 20 The number of the transactions in the datasets ried from 200,000 to 2,000,000 Datasets size ranges from 100 megabytes to 1 gigabyte Minimum support was set as 1.5 and the available main memory was 128 megabytes Figure 6 b shows the results In the 036gure the CPU and the disk I/O time is always kept in a small range of acceptable values Even for the datasets with 2 million transactions the total running time is less than 1000 seconds Extrapolating from these 036gures using formula 4 we can conclude that a dataset the size of the Library of Congress collection 25 Terabytes could be mined in around 18 hours with current technology 5 Conclusions We have investigated several divide-and-conquer algorithms for mining frequent itemset from secondary memory We also analyzed the recurrences and disk I/O\222s of all algorithms We then gave a detailed divide-and-conquer algorithm which almost fully uses the limited main memory and saves a numerous number of disk I/O\222s We introduced many l techniques used in our algorithm Our experimental results show that our algorithm successfully reduces the number of disk access sometimes by orders of magnitude and that our algorithm scales up to terabytes of data The experiments also validate that the estimation techniques used in our algorithm are accurate Future extensions of this work will include mining maximal and closed frequent itemsets as well as exploring disk layout for various datastructures for instance for candidate sets since there are some situations where Apriori indeed outperforms the FP-tree based methods References  R C Agarw al C C Aggarw al and V  V  V  Prasad Depth 036rst generation of long patterns In KDD\32500  pages 108\226 118 2000  R Agra w al T  Imielinski and A N Sw ami Mining association rules between sets of items in large databases In ACM SIGMOD\32593  pages 207\226216 Washington D.C 1993  R Agra w a l and R Srikant F ast algorithms for mining association rules In VLDB\32594  pages 487\226499 1994  R Agra w a l and R Srikant Mining sequential patterns In ICDE\32595  pages 3\22614 1995  B Goethals and M J Zaki Adv ances in frequent itemset mining implementations Introduction to 036mi03 In Prodeeding of the 1st IEEE ICDM Workshop on Frequent Itemset Mining Implementations FIMI\32503  ov 2003  G Grahne and J Zhu Ef 036ciently using pre\036x-trees in mining frequent itemsets In 1st IEEE ICDM Workshop on Frequent Itemset Mining Implementations FIMI\32503 Nov 2003  J Han J Pei Y  Y in and R Mao Mining frequent patterns without candidate generation A frequent-pattern tree approach Data Mining and Knowledge Discovery  8:53\226 87 2004  M Kamber  J  Han and J Chiang Metarule-guided mining of multi-dimensional association rules using data cubes In Knowledge Discovery and Data Mining  pages 207\226210 1997  H Mannila H T o i v onen and A  I  V erkamo Disco v ery of frequent episodes in event sequences Data Mining and Knowledge Discovery  1\(3 1997  A Sa v asere E Omiecinski and S B Na v athe An ef 036cient algorithm for mining association rules in large databases In VLDB\32595  pages 432\226444 1995  H T o i v onen Sampling lar ge databases for association rules In VLDB\32596  pages 134\226145 Sep 1996  M Zaki and K Gouda F ast v ertical mining using dif fsets In ACM SIGKDD\32503  Washington DC Aug 2003 Proceedings of the Fourth IEEE Internati onal Conference on Data Mining \(ICDM\22204 0-7695-2142-8/04 $ 20.00 IEEE 


are computed from the transactions without taking into account the other attributes When multiple mdis are obtained, one of them is focused and the transactions in the mdi is retained. Next, the identiProceedings of the The 2005 Symposium on Applications and the Internet Workshops \(SAINT-W  05 0-7695-2263-7/05 $20.00  2005 IEEE Figure 2. Trie data structure Figure 3. Time complexity cal process is applied to   and this recursively continues in depth ?rst search \(DFS   is computed, the process continues again from  until the mdi of every              c o n v e r g e s   T h e  m d i s  a l w a y s  c o n v e r g e to these of the mdr  because the denseness is a MINT measure. After the convergence, the search is backtracked to the next mdr  The computation of mdis in each step requires       t i m e  a t  m o s t   I n  t h e  w o r s t  c a s e   o n l y  o n e t r a n s a c t i o n  i s  d r o p p e d  i n  e a c h  s t e p   a n d    s t e p s  r e q u i r e d until the mdis converge. Thus         H o w e v e r   t h i s  d o e s not likely occur. Practically, only a portion of the transact i o n s  a r e  r e t a i n e d  i n  e a c h  s t e p   L e t          b e  a n  e x pected rate of transactions retained in each step the required steps for convergence. The process to search an mdr stops at the latest when the number of retained transa c t i o n s     b e c o m e s  l e s s  t h a n   By solving the equation       w i t h   is        A c cordingly, the expected time complexity of this most expensive process is         4. Performance Evaluation The performance of QARMINT has been evaluated through both arti?cial data and real bench mark data Sets of arti?cial data have been generated under various conditions. The characteristics of the computation time is simlilar to the conventional Basket Analysis except for       T h e  t i m e  m o d e r a t e l y  i n c r e a s e s  w h e n s of all attributes are increased. This is because wider permissible ranges increases the number of mdrs. Figure 3 shows the dependency of the computation time on the n u m b e r  o f  t r a n s a c t i o n      T h e  c u r v e  a l m o s t  f o l l o w s  t h e  r e lation         The real bench mark data  Labor relations Database  in UCI Machine Learning Repository [3] was analyzed by QARMINT. It contains 57 instances, 8 numeric attributes and 8 categorical attributes and many missing values. We ignored the attributes of missing values in each instance and transformed the data into transactions. Though the size 


and transformed the data into transactions. Though the size of this data is quite small, we found many interesting QARs associated with the labor conditions under      and      w h i c h  i s  1 0   o f  t h e  m a x i m u m  a n d  m i n i mum values of each  in the data. The following two are examples                                                                                                                  These rules indicate that the workers having longer durat i o n  c o n t r a c t s  a n d  e v a l u a t i n g  t h e i r  l a b o r  c o n d i t i o n  a s   admit longer working times and less wage increase. These evaluations indicate the suf?cient tractability and the practical applicability of QARMINT 5. Conclusion The mathematical characterization and the extension of the Basket Analysis presented in this paper are expected to provide variety of new approaches of data mining. Their potential has demonstrated by a novel approach called QARMINT for complete mining of generic QARs within a low time complexity. We are implementing QARMINT in a more ef?cient algorithm and evaluating its performance in near future Acknowledgement This research has conducted under the support of JSPS Kiban Kenkyuu \(B 2 References 1] R. Agrawal and R. Srikant. Fast algorithms for mining association rules. Proc. of 20th Int. Conf. on Very Large Data Bases VLDB  499, 1994 2] R. Srikant and R. Agrawal. Mining quantitative association rules in large relational tables. Proc. of 1996 ACM SIGMOD Int. Conf. on Management of Data, pages 1  12, 1996 3] U. C. I. \(UCI http://www.ics.uci.edu/ mlearn/MLRepository.html, 2004 4] J. Wijsen and R. Meersman. On the complexity of mining quantitative association rules. Data Mining and Knowledge Discovery, 2\(3  281, September 1998 Proceedings of the The 2005 Symposium on Applications and the Internet Workshops \(SAINT-W  05 0-7695-2263-7/05 $20.00  2005 IEEE 


0-7695-2263-7/05 $20.00  2005 IEEE pre></body></html 


n M L N n t n t n t n t L M L t L t L tt L t kkkk kkkk kkk kkkk kkkkkkkkP VK VK VK VK PP       kkP t 31 where L  s the error covariance associated with the state estimate t i    kkLX  tt kkk P1  00 0  0                     s s sss s s sss s s sssss N n t n t n 


n t n N n t n t n t n N n t n t n t n t n t n c t L kkkkkk kkkkk kP VKVK VKVK  32 4. Simulations One has run simulations comparing the sequential implementations of MSJPDA algorithm and the new algorithm here. A typical multisensor multitarget tracking environment is assumed in the simulations. According to article [1,3], One known that the performance of sequential MSJPDA is better than the performance of parallel MSJPDA. Therefore, the performance of parallel MSJPDA algorithm will not be compared here There are three sensors, which are fixed in three platforms. Regarding the 2nd sensor as fusion centre situation of the other sensors are: =?-500m?-500m 0m??N =?-500m? 500m?0m??The distance error of each sensor is: =300m, =200m, =100m?The bear error of each sensor is 0.03rad, =0.02rad, =0.01rad?The of sample is T=1s?The nonparametric model of clutter is used in the simulations, and expected number of false measurement is m=1.8 1 sN 3 s 1r 2 2r 3 3r 1 Simulations have been run for racking two targets. The true initialization state of the targets is X1?[-29500m,400m/s,34500m,-400m/s X ?[-26250m,296m/s,34500m,-400m/s]'? 2 The two targets will cross above 31seconds later. To evaluate tracking performance, 50 Monte Carlo runs were performed for three case of the target detection probability Pd=0.97 ? Pd=0.76 ? Pd=0.58. In every run, the total simulation time is 140 steps 


simulation time is 140 steps            Figure 1  RMS position error in case of Pd=0.97          Figure 2  RMS velocity error in case of Pd=0.97       Figure 3  RMS position error in case of Pd=0.76 567 Proceedings of  the Fourth International Conference on Machine Learning and Cybernetics  Guangzhou, 18-21 August 2005         Figure 4  RMS velocity error in case of Pd=0.76         Figure 5  RMS position error in case of Pd=0.58          Figure 6  RMS velocity error in case of Pd=0.58  Table 1 The emanative times comparison for sequential MSJPDA and SD-CMSJPDA algorithm  Pd N A  0.97 0. 76 0.58 Sequential MSJPDA 2 11 17 SD-CMSJPDA 0 3 5 Pd denotes detection probability, N denotes emanative 


Pd denotes detection probability, N denotes emanative times, A denotes the kind of algorithm Table 1 shows the summation of emanative times for sequential MSJPDA and SD-CMSJPDA algorithm in 50 Monte Carlo simulations. From table 1 , it is shown that the stability of SD-CMSJPDA is better than that of sequential MSJPDA as the detection probability varied Figure 1,2 show the RMS errors for position and velocity in case of Pd=0. 97, respectively; Figure 3,4 show the RMS errors for position and velocity in case of Pd=0.76 respectively; Figure 3,4 show the RMS errors for position and velocity in case of Pd=0.58, respectively. From the figures we can see that the average RMS position error is lower for the SD-CMS JPDA algorithm. We also see that the state estimation precision of sequential MSJPDA get worse as the detection probability decreases The reasons for these simulation results lies:1 state estimation precision will get worse when the detection probability decrease;2 algorithm is to process measurement from each sensor using single sensor JPDA algorithm sequentially. Therefore the estimation error from each sensor will be accumulated Moreover, the sequential MSJPDA algorithm can  t improve the joint detection probability of the multisensor system The estimation error of the SD- CMSJPDA  algorithm will not be accumulated for it processes the measurement from each sensor directly in the mean time .What  s more the new method can greatly improve the joint detection probability of the multisensor system. Therefore, the tracking performance of SD-CMSJPDA algorithm is better than that of sequential MSJPDA. Algorithm All of the simulations are run in the personal computer with a 2.0G CPU and a 256M memory. The average cost time per step is 0.0251 in the sequential implementations of MSJPDA algorithm. And the average cost time per step is 0.0282 in the sequential implementations of MSJPDA algorithm. According to the results we can see that there is few difference in real time between the new method and the sequential   MSJPDA when there is not so many sensors and targets 568 Proceedings of  the Fourth International Conference on Machine Learning and Cybernetics  Guangzhou, 18-21 August 2005  5. Conclusion In order to solve the problem of multisensor multi target tracking, a new centralized multisensor  joint probabilistic data association  algorithm is proposed in this paper. The simulation results shows that the tracking performance of the new algorithm is better than that of the sequential MSJPDA algorithm The computational complexity of the new method will increase as the number of sensors and targets grow Therefore, how to improve the real time of SD- CMSJPDA algorithm will be pay attention References 1] He You, Wang Guohong, Lu Dajin, Peng Yingning Multisensor Information Fusion With Application[M Publishion House of Electronics Industry. 2000, Beijing.  [11] B..Zhou and N.K.Bose Multitarget  Tracking in Clutter:Faste Algorithms for Data Association .IEEE Transaction on Aerospace and Electronic Systems 1993,29\(2 2] Bar-shalom,Y\(Ed Applications and Advances,2: Norwood,MA Artech  House, 1992 3] L.Y. Pao, C.W.Frei. A Comparison of Parallel and Sequential Implementation of a Multisensor Multitarget Tracking Algorithm. Proc. 1995 American Control Conf. Seattie, Washington,June 1995 1683~1687 


4] K. Chang, C. Chong, Bar-Shalom, Joint Probabilistic Data Association in Distributed Sensor Networks IEEE Transactions on Automatic Control, AC-31\(10 octobre 1986 5] Bar-shalom, Multitarget Multisensor Tracking Advanced Application ,:YBS Publishing, 1990 6] Bar-shalom, Multitarget Multisensor Tracking Principles and Techenices ,:YBS Publishing, 1995 7] Hu Wenlong, Mao shiyi, Multisensor Data Association Based on Combinatorial Optimization[J]. Journal of Systems Engineering and Electronics . 1997 NO.1,1~9 8] Pattipati K R, Passive Multisensor Data Association Using a New Relaxation Algorithm.In Multitarget-Multisensor Tracking: Advanced and Applications,Y.Barshalom,Norwood,MA:Aretech,199 0 9] Deb S,et al, An S-Dimentional Assignment Algorithm for Track Initiation ,Proc. Of the IEEE Int. Conf Systems Engineering, Kobe, Japan,Sept 1992 527~530 10] Deb S,et al, A Multisensor-Multitarget Data Association Algorithm for Heterogeneous Sensors[J].IEEE Trans. on AES 1993 ,29 \(2 560~568 12] Bar-shalom,Y.,and Fortmann,T.E  Tracking and Data Association  New York:Academic press,1988 13] J,A,Roecher and G.L.Phillis,Suboptimal Joint Probabilistic Data Association .IEEE Transaction on Aerospace Electronic Systems.1993,29\(2 14] J,A,Roecker,A Class of Near Optimal JPDA Algorithm IEEE Transaction on Aerospace and Electronic Systems,1994,30\(2 15] Han Yanfei, Analysis and Improvement of Multisensor Multitarget Probabbilistic Data Association Filting Algorithm[J].  Journal of Systems Engineering and Electronics, 2002, Vol.24, 36~38  569 pre></body></html 


dense data sets for evaluating pattern mining algorithms These two data sets are obtained from IBM Almaden at http://www.almaden.ibm.com/cs/quest/demos.html. Recently, theMAFIA algorithm [6] was proposed to ef?ciently discover maximal frequent patterns. As shown in their paper, MAFIA can be several orders better than some alternatives, such as DepthProject, for mining maximal frequent patterns. Hence, we chose MAFIA as the base line for our performance evaluation. Finally, please note that only the size-2 patterns are generated in the ?rst BFS phase Experimental Platform We implemented the MHP algorithms using C++ and all experiments were performed Proceedings of the 16th IEEE International Conference on Tools with Artificial Intelligence \(ICTAI 2004 1082-3409/04 $20.00  2004 IEEE on a Pentium III    MHz PC machine with    megabytes main memory, running Linux Redhat 6.1 operating system 5.2. A Performance Comparison 100 1000 10000 100000 1e+06 1e+07 1e+08 1e+09 1e+10 1e+11 0.02 0.025 0.03 0.035 0.04 0.045 0.05 0.055 0.06 N um be r o f C he ck ed P at te rn s Support threshold Mafia Min_Conf=0 Min_Conf=0.1 Min_Conf=0.3 Min_Conf=0.5 Min_Conf=0.7 Min_Conf=0.9 


Figure 4. The Number of Checked Patterns on the Pumsb* Data Set 10 100 1000 10000 100000 0.02 0.025 0.03 0.035 0.04 0.045 0.05 0.055 0.06 R un T im e s ec  Support Threshold Mafia Min_Conf=0 Min_Conf=0.1 Min_Conf=0.3 Min_Conf=0.5 Min_Conf=0.7 Min_Conf=0.9 Figure 5. The RunTime Comparison on the Pumsb* Data Set Figure 4 shows the number of patterns that MHP and MAFIA have to check during the pattern mining process on the pumsb* data set. As can be seen, for MHP, the number of checked patterns is increased with the decrease of the h-con?dence threshold. However, the number of checked patterns of MHP can be signi?cantly smaller than that of MAFIA even if a low h-con?dence threshold is speci?ed To check a pattern, we need to count the support of the patterns. Counting the support of a pattern is the most timeconsuming task during the pattern mining process, since we need to retrieve all the transactions which include one of its sub-pattern, or for Ma?a, retrieve all the bit of the bitmap of this pattern [6]. Therefore, an algorithm is more ef?cient if smaller number of patterns need to be checked 100 1000 10000 100000 1e+06 1e+07 1e+08 1e+09 0.1 0.2 0.3 0.4 0.5 0.6 0.7 N 


um be r o f C he ck ed P at te rn s Support Threshold Mafia Min_Conf=0.5 Min_Conf=0.7 Min_Conf=0.9 Figure 6. The Number of Checked Patterns on the Pumsb Data Set 10 100 1000 10000 0.1 0.2 0.3 0.4 0.5 0.6 0.7 R un T im e s ec  Support Threshold Mafia Min_Conf=0.5 Min_Conf=0.7 Min_Conf=0.9 Figure 7. The RunTime Comparison on the Pumsb Data Set The runtime comparison of MHP and MAFIA on the Pumsb* data set is shown in Figure 5. In the ?gure, we can observe that the runtime of MHP can be signi?cantly reduced with the increase of h-con?dence thresholds. Also the runtime of MHP can be several orders of magnitude less than that of MAFIA even if the h-con?dence threshold is as low as 0.3. The reason is that the number of checked patterns of MHP is sign?cantly smaller than that of MAFIA Similar results are also obtained from the pumsb data set as shown in Figure 6 and Figure 7. For the pumsb data set the number of checked patterns of MHP is much smaller 


than that of MAFIA and the runtime of MHP can be significantly less than that of MAFIA 5.3. The Effect of the MHP Algorithm on Finding Maximal Hyperclique Patterns Figure 8 and Figure 9 show the number of maximal patterns identi?ed byMHP andMAFIA on Pumsb* and Pumsb data sets respectively. As can be seen, the number of maximal hyperclique patterns identi?ed by MHP can be orders of magnitude smaller than the number of maximal frequent patterns identi?ed by MAFIA. In other words, the number Proceedings of the 16th IEEE International Conference on Tools with Artificial Intelligence \(ICTAI 2004 1082-3409/04 $20.00  2004 IEEE 100 1000 10000 100000 1e+06 1e+07 1e+08 1e+09 0.02 0.025 0.03 0.035 0.04 0.045 0.05 0.055 0.06 N um be r o f C ou nt ed P at te rn s Support Threshold Mafia Min_Conf=0 Min_Conf=0.1 Min_Conf=0.3 Min_Conf=0.5 Min_Conf=0.7 Min_Conf=0.9 Figure 8. The Number of MFI/MHP Patterns in the Pumsb* Data Set 100 1000 10000 100000 1e+06 


1e+07 1e+08 0.1 0.2 0.3 0.4 0.5 0.6 0.7 N um be r o f C ou nt ed P at te rn s Support Threshold Mafia Min_Conf=0.5 Min_Conf=0.7 Min_Conf=0.9 Figure 9. The number of MFI/MHP Patterns in the Pumsb Data Set of maximal hyperclique patterns is much easier to manage than that of maximal frequent patterns. Indeed, in realworld applications, it is dif?cult to interpret several million maximal frequent patterns. However, it is possible to interpret the results of maximal hyperclique pattern mining In addition, due to the memory limitation, we cannot extract maximal frequent patterns with MAFIA on the Pumsb data set if the support threshold is less than 0.4, as shown in Figure 7. In contrast, MHP can identify maximal hyperclique patterns when the support threshold is 0.1, if we set the h-con?dence threshold to 0.5. In other words, MHP has the ability to identify patterns which can be dif?cult to identify for MAFIA. Hence, MHP can better explore the pattern space and ?nd interesting patterns at low levels of support 6. Conclusions and Future Work In this paper, we present a two-phase Maximal Hyperclique Pattern \(MHP best features of both the BFS strategy and the DFS strategy. More speci?cally, we adapted DFS pruning methods such as equivalence pruning, to an apriori-like approach In addition, we proved the correctness and completeness of the MHP algorithm. Finally, our experimental results show that the MHP algorithm can be several orders of magnitude faster than standard maximal frequent pattern mining algorithms and has the ability to identify patterns at extremely low levels of support in dense data sets There are several directions for future work. First, in 


this paper, we only generate the size-2 patterns in the BFS phase. It will be interesting to investigate the impact on the performance if the ?rst phase is stopped at a deeper level Also, the projection is a very ef?cient method for ?nding patterns, especially for parallel implementation of pattern mining algorithms [1]. We plan to adapt the projection ideas into our algorithm and design an ef?cient parallel algorithm for mining maximal hyperclique patterns References 1] R. Agarwal, C. Aggarwal, and V. Prasad. A Tree Projection Algorithm For Generation of Frequent Itemsets. pages 350 371, Feb 2001 2] R. Agrawal, T. Imielinski, and A. Swami. Mining Association Rules between Sets of Items in Large Databases. In Proc. of the ACM SIGMOD Conference on Management of Data, pages 207216,May 1993 3] R. Agrawal and R. Srikant. Fast Algorithms for Mining Association Rules. In Proc. of the 20th Intl Conference on Very LargeData Bases, 1994 4] R. Bayardo. Ef?ciently mining long patterns from databases In Proc. of the ACM SIGMOD Conference, 1998 5] R. Bayardo and R. Agrawal. Mining the Most Interesting Rules. In Proc. of the ACM SIGKDD Conference, 1999 6] D. Burdick, M. Calimlim, and J. Gehrke. Ma?a: AMaximal Frequent Itemset Algorithm for Transactional Databases. In Proc. of IEEE Conf. on Data Engineering, 2001 7] Y. Huang, H. Xiong, W. Wu, and Z. Zhang. A Hybrid Approach for Mining Maximal Hyperclique Patterns. In In Technical Report UTDCS-34-04, Department of computer science, University of Texas - Dallas, 2004 8] J.Han, J.Pei, and Y. Yin. Mining Frequent Patterns without Candidate Generation. In Proc. of the ACM SIGMOD International Conference on Management of Data, 2000 9] M.J.Zaki and C.Hsiao. ChARM: An ef?cient algorithm for closed itemset mining. In Proc. of 2nd SIAM International Conference on Data Mining, 2002 10] R.Rymon. Search through Systematic Set Enumeration. In Proc. Third Intl Conference on Principles of Knowledge Representation and Reasoning, 1992 11] H. Xiong, M. Steinbach, P.-N. Tan, and V. Kumar. HICAP: Hierarchial Clustering with Pattern Preservation. In Proc. of 2004 SIAM International Conference on Data Mining \(SDM 12] H. Xiong, P.-N. Tan, and V. Kumar. Mining Strong Af?nity Association Patterns in Data Set with Skewed Support. In Proc. of the Third IEEE International Conference on Data Mining \(ICDM Proceedings of the 16th IEEE International Conference on Tools with Artificial Intelligence \(ICTAI 2004 1082-3409/04 $20.00  2004 IEEE 





