html><head></head><body><pre style="word-wrap: break-word; white-space: pre-wrap;">Clustering  on Demand for Multiple Data Streams Bi-Ru Dai, Jen-Wei Huang, Mi-Yen Yeh, and Ming-Syan Chen Department of Electrical Engineering National Taiwan University Taipei, Taiwan, ROC E-mail:mschen@cc.ee.ntu.edu.tw, {brdai, jwhuang, miyen}@arbor.ee.ntu.edu.tw Abstract In the data stream environment, the patterns generated by the mining techniques are usually distinct at different time because of the evolution of data. In order to deal with various types of multiple data streams and to support ?exible mining requirements, we devise in this paper a Clustering on Demand framework, abbreviated as COD framework, to dynamically cluster multiple data streams While providing a general framework of clustering on multiple data streams, the COD framework has two major features, namely one data scan for online statistics collection and compact multi-resolution approximations, which are designed to address, respectively, the time and the space constraints in a data stream environment. Furthermore with the multi-resolution approximations of data streams exible clustering demands can be supported 1 Introduction In recent years, several query problems and mining capabilities have been explored for the data stream environment 2], including those on the statistics [3], the aggregate query 4], association rules [8], frequent patterns [10], data clustering [1][5][9], and data classi?cation [6], to name a few For data stream applications, the volume of data is usually too huge to be stored on permanent devices or to be scanned thoroughly more than once. It is hence recognized that both approximation and adaptivity are key ingredients for executing queries and performing mining tasks over rapid data streams In this paper, the problem of clustering multiple data streams is addressed. It is assumed that at each time stamp data points from individual streams arrive simultaneously and the data points are highly correlative to previous ones in the same stream. Unlike that of prior studies, the objective in this work is to partition these data streams, rather than their data points, into clusters. Note that the data streams are not of a ?xed length. Instead, they are still evolving when the clustering results are observed at users  requests The problem studied in this paper is different from the one discussed in [7], which focuses on clustering the windows of a single streaming time series. On the other hand, clustering of evolving streams is discussed in [11]. However the objective in [11] is to continuously report clusters satisfying the speci?ed distance threshold. To further enhance these techniques, clustering requests of ?exible time ranges are supported in our framework In the data stream environment, the patterns generated by the mining techniques are usually distinct at different time because of the evolution of data. Depending on different applications, the frequency for patterns in data streams to change varies. For example, the streams gathered from adjacent sensors may always be in the same cluster. However for stock prices, some companies are probably within the same cluster during several months but in different clusters afterward. The clusters obtained hence change frequently. Therefore, an important question arises: "Can we design a scheme for modeling both fast and slow evolving patterns adaptively?" Furthermore, the clustering request is unknown when the data is collected and processed After the time range of clustering request reveals, recommendations for short-term or long-term investments are desired to be offered precisely. This leads to another important issue: "Can we provide a system to support various clustering requirements at the same time?" Consequently we devise in this paper a framework of Clustering on De 


we devise in this paper a framework of Clustering on Demand, abbreviated as COD framework, to dynamically cluster multiple data streams. While providing a general framework of clustering on multiple data streams, the proposed COD framework has two advantageous features: \(1 data scan for online statistics collection, and \(2 multi-resolution approximations, that are designed to address, respectively, the time and the space constraints in a data stream environment. Furthermore, with the multiresolution approximations of data streams, ?exible clustering demands can be supported. Note that since the clusterProceedings of the Fourth IEEE International Conference on Data Mining \(ICDM  04 0-7695-2142-8/04 $ 20.00 IEEE ing algorithms are only applied to the statistics maintained rather than to the original data streams, the COD proposed is very ef?cient in practice The COD framework proposed consists of two phases namely the online maintaining phase and the of?ine clustering phase. The online maintaining phase provides an ef?cient algorithm to maintain the summary hierarchies of the data streams with multiple resolutions in the time complexity linear to both the number of streams and the number of data points in each stream. On the other hand, an adaptive clustering algorithm is devised for the of?ine phase to retrieve the approximations of the desired sub-streams from the summary hierarchies as precisely as possible according to the clustering queries speci?ed by the users. In general, we keep ?ner approximations for more recent data and coarser approximations for more obsolete data. The COD framework performs very ef?ciently in the data stream environment while producing clustering results of very high quality The rest of this paper is organized as follows. Preliminaries and advantages of the COD framework are described in Section 2. The online maintaining phase and the of?ine clustering phase of the COD framework are presented in Section 3. This paper concludes with Section 4 2 Clustering on Demand Framework 2.1 Framework De?nitions The COD framework has two phases, i.e., the online maintaining phase and the of?ine clustering phase. In the online maintaining phase, the arriving data streams are processed and only very brief summaries are maintained. The of?ine clustering phase deals with the clustering queries. The COD framework supports clustering queries with a ?exible window size and a desired number of windows to observe. For example, a clustering query could be 12 windows with the window size of 30 days to observe the clusters of each month during a year. Based on the limited space property in the data stream environment, the raw data streams are parsed only once and then discarded. Therefore the clustering algorithm in our framework is applied to the statistics maintained by the online phase rather than to the original streams, as illustrated in Figure 1 At any time stamp, each stream receives a new value simultaneously, and there are totally q data streams More speci?cally, we have the q streams {V1&gt; V2&gt; ===&gt; Vq at time stamp p where Vl = {i1l &gt; i2l &gt; ===&gt; ipl }, for 1      q   a n d  i  m l  i s  t h e  v a l u e  o f  s t r e a m  V l  t h a t  a r rives at time m. First, we introduce the of?ine clustering phase. Let n denote the number of clusters, and let z be the window size of the clustering query submitted at time stamp wqrz. The algorithm proposed will generate at most s windows of n-clustering results where Online maintenance Clustering query Cluster number: k Window size: w Windows observed: p Statistics S1, S2, S4  S3, S9  w2 S1, S4  S2, S3, S7  w1 


S1, S4  S2, S3, S7  w1 ClustersWindow w2 w1 S1 S2 S3  Sn0 10 20 30 40 50 60 70 0 5 10 15 Time Value Figure 1. Clustering of multiple data streams by COD at wqrz = 15, for a query of n = 2 z = 5 and s = 2 F o  z l      F 1  z l   g t   F 2  z l   g t       g t   F n  z l     f o r  1    l    s  which minimizes each clustering cost Frvw\(Fo\(zl s u b s t r e a m s  i n  t h e  i n t e r v a l   w q r z  z  l  g t   w q r z  z  l    Note that Fm\(zl the properties of n m=1 Fm\(zl n m=1 Fm\(zl V1\(zl zl zl zl  i   w q r z  z  l   1 t   g t   i   w q r z  z  l   2 t   g t       g t   i   w q r z  z  l      Example 1: Consider the ?rst three data streams V1&gt; V2&gt; V3} in Figure 1 at time stamp wqrz=15, where S1={64,48,16,32,56,56,48,24,32,24,16,16,24,32,40 S2={24,38,46,52,54,56,40,16,24,26,34,28,20,14,8}, and S3={32,46,54,60,62,64,66,64,58,50,42,36,28,22,16 Assume that the clustering query is n = 2&gt; z = 5&gt and s = 2. The algorithm will generate at most 2 windows of 2-clustering results, Fo\(z1 z1 z1 and Fo\(z2 z2 z2 sulting clusters of window z1 are F1\(z1 F2\(z1 t h e  i n t e r v a l   1 5      1  g t   1 5       1        1 0  g t   1 5   In window z2, the clusters are F1\(z2 F2\(z2 v a l   1 5  5   2  g t   1 5  5    2   1       5  g t   1 0    We next describe the online maintaining phase. To support various clustering queries in the of?ine clustering phase, adequate information has to be preserved during the online maintaining phase for discovering fast and slowly evolving patterns. Note that the resolution of statistics maintained could affect the patterns obtained. With a small interval used for summarization, short-term patterns can be observed, but long-term patterns are likely to be neglected. Also, the summaries are possibly affected by noises and oscillations, and the summaries should be updated or reconstructed frequently. On the other hand, if a large interval is used, long-term patterns can be observed while neglecting short-term patterns. Also, the patterns may not catch up with the changes of the data streams. Moreover, the patterns could be very rough because of the generalization/summarization of streams. Therefore, we devise a hierarchical structure to store data summaries at different Proceedings of the Fourth IEEE International Conference on Data Mining \(ICDM  04 0-7695-2142-8/04 $ 20.00 IEEE resolutions in the online maintaining phase. Whenever a clustering query is submitted, the algorithm of the of?ine clustering phase will select the approximations from appro 


clustering phase will select the approximations from appropriate levels of the summary hierarchies to support the requirements of the clustering query. Details of the online and of?ine phases will be described in following sections 2.2 Advantages of the COD Framework Since the summaries maintained in the summary hierarchies are at multiple resolutions, the COD framework is able to support the clusters for variable window sizes. Applying the conventional time series clustering algorithms to the raw streams with the desired window sizes is not practical in the streaming environment because there is not enough space for the storage of continuous streams. On the other hand, the summarization techniques which maintain the streams with a ?xed resolution do not perform well for various window sizes. Although the prior work [11] for clustering of evolving streams continuously reports clusters within the given distance threshold, it does not allow the user to specify a desired window size to be observed. In our COD framework, even though the data streams are collected and summarized into the summary hierarchies before the clustering queries are submitted, the clusters with various window sizes can be obtained directly from the existing summary hierarchies without parsing the data streams again to construct the summaries for the desired resolutions. For example, suppose that the summary hierarchies of the stock prices have been kept for the prices in ten years. Then, clusters in one day, one month, or even one year can be observed very ef?ciently without resorting to the old prices again From the de?nition of clustering query, at most s windows of clustering results can be obtained for a query. It is very ef?cient to observe the trends and changes of clusters at one time. The behaviors of the clusters, such as the moving paths of clusters, the merges and splits of clusters, and the streams jumping between clusters, can be investigated from the results of a clustering query. Consider the example of stock prices again. Assume that the window size is one month and 12 windows are inspected. We might ?nd out that stock D and stock E are in the same cluster for one month and then stock D jumps to another cluster for the following several months. Such trends and changes within one year can be extended from the results of this clustering query 3 The Framework of COD 3.1 Online Maintaining Phase The main objective of this online maintaining phase is to provide a one scan algorithm of the incoming multiple data streams for statistics collection. A summary hierarchy F\([t6T+1,t7T t5T+1,t6T t4T+1,t5T t3T+1,t4T t2T+1,t3T tT+1,t2T te 0 F\([t4T+1,t6T t2T+1,t4T t1,t2T te 1 F\([t1,t4T te 2 L=3 Fitting models in the summary hierarchy Raw bucket Temporary bucket Current time Figure 2. The illustration of summary hierarchy, where I \(k i n  t h e  t i m e  i n t e r v a l  k     w v  g t   w h    a n d    is maintained incrementally to provide multi-resolution ap 


is maintained incrementally to provide multi-resolution approximations for a stream. Multiple levels in the hierarchy correspond to various resolutions A ?tting model I \(k a raw sub-stream in the interval k = [wv&gt; wh] by some summarization techniques. The ?tting model on level O is gene r a t e d  b y  t h e  a g g r e g a t i o n  o f  E k  m o d e l s  o n  l e v e l   O    and each level keeps the time stamp of the latest data point which has been summarized to that level, as the end time wh of the level. The procedure of generating and updating the summary hierarchy of a stream is described as follows Procedure of the online maintaining phase 1 For each incoming value, put it in the temporary bucket 2 If the number of items in the temporary bucket is less than the bucket size Ew, go to Step 1. Else 2.1 A new ?tting model of level 0 is generated according to the values in the temporary bucket 2.2 Update the end time w0h of level 0 2.3 Move all the items from the temporary bucket to the raw bucket 2.4 If the number of items in the raw bucket is more than    r e m o v e  t h e  o l d e s t  i t e m s  t o  k e e p  t h e  n u m b e r  n o  l a r g e r    3 For each level O, if Ek new models are accumulated 3.1 A new model of level \(O + 1 aggregating the latest Ek models in level O 3.2 Update the end time wO+1h of level \(O+ 1 3.3 If the number of models in level \(O+1    r e m o v e  t h e  o l d e s t  m o d e l  f r o m  t h a t  l e v e l  As shown in the procedure, to achieve the space limitation in the streaming environment, the number of ?tting models maintained at each level is limited to be the maxim u m  n u m b e r  o f     N o t e  t h e    s h o u l d  b e  s e t  t o  a  n u m b e r no smaller than Ek in order to have enough ?tting models for the model generation in a higher level. Figure 2 gives an example of the summary hierarchy 3.2 Of?ine Clustering Phase Proceedings of the Fourth IEEE International Conference on Data Mining \(ICDM  04 0-7695-2142-8/04 $ 20.00 IEEE As the clustering query shown in Section 2.1, the users want to inspect clusters with window size z, and at most s windows will be observed. Note that the window size desired could be different from those maintained in the summary hierarchy. In this situation, we have to select the ?tting models from appropriate levels of the hierarchy to approximate the desired windows. We have the following theorems for adaptive level selection Theorem 1: The highest level to approximate a sub-stream with window size z is Opd j orjEk z Ew k  Theorem 2: The lowest level to approximate a sub-stream with window size z is Oplq min O      w q r z    w O h         kO    w h e r e  O  i s  t h e  e x a c t number of ?tting models in level O, and kO = Ew  Ek is the window size of the ?tting models in level O From the above theorems, ?tting models in the levels between Oplq and Opd{ are able to approximate the substreams in the windows of clustering queries. The ?tting models in higher levels span longer intervals and thus provide more generalized ?ttings to the original streams. In contrast, the ?tting models in lower levels possess shorter 


contrast, the ?tting models in lower levels possess shorter spans and can thus provide more speci?c and accurate ?tt i n g s  t o  t h e  o r i g i n a l  s t r e a m s   H o w e v e r   o n l y    m o d e l s  a r e maintained in each level. Therefore, we devise an adaptive clustering algorithm for the of?ine clustering phase to approximate each window of data streams with the ?tting models as accurately as possible. Note that the of?ine clustering phase is not designed for a speci?c clustering algorithm. Therefore, users can adopt any traditional clustering algorithm with minor modi?cation if so necessary Procedure of adaptive clustering algorithm 1. Calculate Oplq and Opd{. For each data stream, do Step 2 and 3 2. If the end time wOplqh of level Oplq is not equal to the current time, aggregate the models of lower levels \(from O p l q   1  t o  0   a n d  t h e  t e m p o r a r y  b u c k e t  t o  g e n e r a t e  a  t e m porary model characterizing the interval between wOplqh and the current time. Then, aggregate this temporary model to the latest model in level Oplq 3. Encapsulate the ?tting models between level Oplq and Opd{ to generate at most s entries, where each entry represents a window with sizez. Set O = Oplq initially. For the windows from z1 to zs, if the range of a desired window is covered by the interval of the ?tting models in level O, encapsulate an appropriate number of ?tting models into that entry. Else, increase O by one to look for the ?tting models with enough coverage. This step stops when s entries have been retrieved or when O exceeds the maximum level Opd w i t h  s u  e n t r i e s  o b t a i n e d   w h e r e  s u    4. Run the clustering algorithm to cluster these sub-streams by the retrieved entries for each window 4 Conclusions In order to deal with various types of multiple data streams and to support ?exible mining requirements, we devised a COD Framework to dynamically cluster multiple data streams. While providing a general framework of clustering on multiple data streams, COD framework had two major advantages, namely one data scan for online statistics collection and compact multi-resolution approximations. The online maintaining phase of COD provided an ef?cient algorithm to maintain the summaries of the data streams with multiple resolutions. On the other hand, an adaptive clustering algorithm was devised for the of?ine phase of COD to retrieve the approximations of the desired sub-streams from the summary hierarchies as precisely as possible according to the clustering queries. The COD framework performed very ef?ciently in the data stream environment while producing clustering results of very high quality Acknowledgement The work was supported in part by the National Science Council of Taiwan, R.O.C., under Contract NSC93-2752E-002-006-PAE References 1] C. C. Aggarwal, J. Han, J. Wang, and P. S. Yu. A framework for clustering evolving data streams. In Proc. of VLDB 2003 2] B. Babcock, S. Babu, M. Datar, R. Motwani, and J. Widom Models and issues in data stream systems. In Proc. of PODS June 2002 3] A. Bulut and A. K. Singh. Swat: Hierarchical stream summarization in large networks. In Proc. of ICDE, pages 303  314, Mar. 2003 4] A. Dobra, M. N. Garofalakis, J. Gehrke, and R. Rastogi Processing complex aggregate queries over data streams. In Proc. of ACM SIGMOD, pages 61  72, June 2002 5] S. Guha, N. Mishra, R. Motwani, and L. O  Callaghan. Clustering data streams. In Proc. of FOCS, pages 359  366, 2000 6] G. Hulten, L. Spencer, and P. Domingos. Mining timechanging data streams. In Proc. of ACM SIGKDD, pages 97  106, Aug. 2001 


97  106, Aug. 2001 7] E. Keogh, J. Lin, and W. Truppel. Clustering of time series subsequences is meaningless: Implications for past and future research. In Proc. of ICDM, Nov. 2003 8] G. S. Manku and R. Motwani. Approximate frequency counts over streaming data. In Proc. of VLDB, pages 346  357, Aug. 2002 9] L. O  Callaghan, N. Mishra, A. Meyerson, S. Guha, and R. Motwani. Streaming-data algorithms for high-quality clustering. In Proc. of ICDE, 2002 10] W.-G. Teng, M.-S. Chen, and P. S. Yu. A regression-based temporal pattern mining scheme for data streams. In Proc of VLDB, Sep. 2003 11] J. Yang. Dynamic clustering of evolving streams with a single pass. In Proc. of ICDE03, Mar. 2003 Proceedings of the Fourth IEEE International Conference on Data Mining \(ICDM  04 0-7695-2142-8/04 $ 20.00 IEEE pre></body></html 


Maneuvering Target Tracking. National Defence Industry Press, 1991 14] He You, Wang Guohong. Multisensor Information Fusion With Applications. Publishing House of Electronics Industry, 2000 15] Simon J.Julier, Jeffrey K.Uhlmann. A New Extension of the Kalman Filter to Nonlinear Systems [J]. SPIE Vol.3068, 1997:182~193 Figure 1 RMS position error for target 1 in case of ? =0.5 16] Simon J.Julier, Jeffrey K.Uhlmann. A New Method for the Nonlinear Transformation of Means and Covariances in Filters and Estimators [J]. IEEE Trans on AC, Vol.45, No.3 2000:477~482  5. Conclusions  In order to solve the multisensor multitarget tracking problem of nonlinear non-Gaussian system the paper proposes a new multisensor joint probabi listic data association particle algorithm. The results of the simulations show that the MJPDAP algorithm can increase the global estimation accuracy of a system 17] Ya Xue, Darryl Morrell. Target Tracking and Data Fusion using Multiple Adaptive Foveal Sensors [EB/OL http://www.eas.asu.edu/~morrell/pubs/IF2003.pdf 18] Xenofon Koutsoukos, James Kurien, Feng Zhao Estimation of Distributed Hybrid Systems Using Particle Filtering Methods [EB/OL]. http://www.isis.Vanderbilt.edu publications/archive/koutsoukos_X_0_0_2003_Estimation.p df References [19] Matt Rosencrantz, Geoffrey Gordon, Sebastian Thrun Decentralized sensor fusion with distributed particle filters EB/OL]. http://www-2.cs.cmu.edu/~ggordon/mrosen ggordon- thrun.decentralzied.pdf  1] Gordon, N.J., Salmond, Novel Approach to Nonlinear/Non-Gaussian Baysian State Estimation[J]. IEEProceedings, Pt.F.140, No.2, 1993:107-113  [20] Dirk Schulz, Wolfram Burgard. Tracking Multiple Moving Targets with a Mobile Robot using Particle Filters and Statistical Data Assocation [J]. In IEEE Proc International Conference on Robotics and Automation, Vol.2 2001:1665~1670 2] H.Carvalho, P.Del Moral. Optimal Nonlinear Filtering in GPS/INS Intergation[J]. IEEE Trans AES, Vol.33, No.3 1997:835~849 3] M.Pitt, N.Shephard. Filtering Via Simulation: Auxiliary Particle Filters[J], Journal of the American Statistical Association, Vol.94, No.446, 1999:590~599 21] Oliver Frank, Juan Xieto. Multiple Target Tracking using Sequential Monte Carlo Methods and Statistical Data Assocation [EB/OL]. http://www.acfr.usyd.edu.au/projects research/environment-rep/oliverF/FrankIR0S03.pdf 4] Rudolph van der Merve, Arnaud Doucet. the Unscented Particle Filter[R], Technical report CUED/F-INFENG/TR 380, Cambridge University, 2000. [22] Rickard Karlsson, Fredrik Gustafsson. Monte Carlo Data Assocation for multiple target tracking [EB/OL]. http www.control.isy.liu.se/~fredrik/reports/01iee.pdf 5] M.Sanjeev Arulampalam, Simon Maskell, Neil Gordon a Tutorial on Particle Filters for Online Nonlinear/NonGaussian Bayesial Tracking[J]. IEEE Trans AES, Vol.55 NO.2, 2002:174~188 23] Bar-shalom. Multitarget Multisensor Tracking Principles and Techenices [M] ,:YBS Publishing, 1995 24] Hu Wen-long, Mao Shi-yi. Multisensor Data Association Based on combinatorial Optimization. System Engineering and Electronics, 1997,NO.1,1~9  6] A.Farina, B.Ristic. Tracking a Ballistic Target Comparison of several Nonlinear filters[J]. IEEE Trans on AES, Vol.38, No.3, 2002:477~482 7] Shawn Michael Herman. A Particle Filtering Approach 


7] Shawn Michael Herman. A Particle Filtering Approach to Joint Passive Radar Tracking and Target Classification[D University of Illinois, 2002 309 pre></body></html 


use an Apriori-like algorithm. The algorithm in [12], as reported, performed much slower \(about 100 times or even more ber of mismatches from 1 to 2. Compared to this our approach provides two main advantages: \(1 matching is based on a more general scheme  edit operations. It allows the individual treatment of every single item, which enables a better involvement of background knowledge. \(2 many times \(which is the case in Apriori-like algorithms Instead it looks for \(locally projected databases and combines them with the associated pre?x \(which is the frequent pattern found so far the frequent patterns. Thus it is more ef?cient, as can be seen in Table 2. The execution time in the case of allowing two insertions is only about thrice that for one insertion Up to now, we only investigated how to edit an item set by insertion. However, there are also other interesting editing operations. If we take the order of items into account operations like exchanging the order of two items are de?nitely worth to be studied References 1] Synthetic data generation code for associations and sequential patterns. Intelligent Information Systems, IBM Almaden Research Center http://www.almaden.ibm.com/software/quest/Resources index.shtml 2] R. Agrawal, T. Imielienski, and A. Swami. Mining association rules between sets of items in large databases. In Proc Conf. on Management of Data, pages 207  216, New York NY, USA, 1993. ACM Press 3] R. Agrawal, H. Mannila, R. Srikant, H. Toivonen, and A. Verkamo. Fast discovery of association rules. In U.M. Fayyad, G. Piatetsky-Shapiro, P. Smyth, and R. Uthurusamy, eds. Advances in Knowledge Discovery and Data Mining, pages 307  328, Cambridge,CA,USA, 1996. AAAI Press / MIT Press 4] C. L. Blake and C. J. Merz. UCI repository of machine learning databases. Dept. of Information and Computer Science, UC Irvine, CA, USA, 1998 http://www.ics.uci.edu  mlearn/MLRepository.html 5] C. Borgelt. Keeping things simple: Finding frequent item sets by recursive elimination. In Proc. Workshop Open Source Data Mining Software \(OSDM  05, Chicago, IL 6] C. Borgelt. Ef?cient implementations of apriori and eclat. In Proc. 1st IEEE ICDMWorkshop on Frequent Itemset Mining Implementations \(FIMI 2003, Melbourne, FL shop Proc. 90, Aachen, Germany, 2003. http://www.ceurws.org/Vol-90 7] Y. Cheng, U. Fayyad, and P. Bradley. Ef?cient discovery of error-tolerant frequent itemsets in high dimensions. In Proc 7th Int. Conf. on Knowledge Discovery and Data Mining KDD  01, San Francisco, CA  203, New York NY, USA, 2001. ACM Press 8] J. Han, H. Pei, and Y. Yin. Mining frequent patterns without candidate generation. In Proc. Conf. on the Management of Data \(SIGMOD  00, Dallas, TX  12, New York NY, USA, 2000. ACM Press 9] C. Kuok, A. Fu, and M. Wong. Mining fuzzy association rules in databases. SIGMOD Record, 27\(1  46, 1998 10] P. Moen. Attribute, Event Sequence, and Event Type Similarity Notions for Data Mining. Report A-2000-1. PhD thesis Department of Computer Science, University of Helsinki Finland, 2000 11] J. Pei, J. Han, H. Lu, S. Nishio, S. Tang, and D. Yang. Hmine: Hyper-structure mining of frequent patterns in large databases. In Proc. IEEE Conf. on Data Mining \(ICDM  01 San Jose, CA  448, Piscataway, NJ, USA, 2001 IEEE Press 12] J. Pei, A. K. H. Tung, and J. Han. Fault-tolerant frequent pattern mining: Problems and challenges. In Proc. ACM 


pattern mining: Problems and challenges. In Proc. ACM SIGMOD Workshop on Research Issues in Data Mining and Knowledge Discovery \(DMK  01, Santa Babara, CA May 2001, Santa Babara, CA 13] M. Zaki, S. Parthasarathy, M. Ogihara, and W. Li. New algorithms for fast discovery of association rules. In Proc 3rd Int. Conf. on Knowledge Discovery and Data Mining \(KDD  97, Newport Beach, CA  296, Menlo Park, CA, USA, 1997. AAAI Press Proceedings of the Fourth International Conference on Machine Learning and Applications  ICMLA  05 0-7695-2495-8/05 $20.00  2005 IEEE pre></body></html 


Proceedings of the Ninth ACM SIGKDD International Conference on Knowledge Discovery and Data Mining 7 Conclusion and Future Work References frontier  pages 487\320499 Morgan Kaufmann 1994  W orkshop on frequent itemset mining implementations 2003 http://\336mi.cs.helsinki.\336/\336mi03  W orkshop on frequent itemset mining implementations 2004 http://\336mi.cs.helsinki.\336/\336mi04  J  Han J  Pei and Y  Y in Mining frequent patterns without candidate generation In Proceedings of 20th International Conference on Very Large Data Bases VLDB VLDB Journal Very Large Data Bases Data Mining and Knowledge Discovery An International Journal Lecture Notes in Computer Science  2004  J W ang and G Karypis Harmon y Ef 336ciently mining the best rules for classi\336cation In The Tenth ACM SIGKDD International Conference on Knowledge Discovery and Data Mining KDD\32504 Symposium on Principles of Database Systems 2 b Average time taken per frequent itemset shown on two scales T10I4D100K is increased and hence the number of frequent items decreases Figure 5\(c also shows that the maximum frontier size is very small Finally we reiterate that we can avoid using the pre\336x tree and sequence map so the only space required are the itemvectors and the minSup SIAM International Conference on Data Mining required drops quite quickly as ACM SIGMOD Workshop on Research Issues in Data Mining and Knowledge Discovery 2000 ACM SIGMOD Intl Conference on Management of Data Figure 5 Results  8\(3\3204 2000  F  P an G C ong A T ung J Y ang and M Zaki Carpenter Finding closed patterns in long biological datasets In  2121:236 2001  M Steinbach P N T an H Xiong and V  K umar  Generalizing the notion of support In a Runtime ratios T10I4D100K c Number of Itemvectors needed and maximum frontier size T10I4D100K  pages 1\32012 ACM Press May 2000  F  K orn A Labrinidis Y  K otidis and C F aloutsos Quanti\336able data mining using ratio rules  Morgan Kaufmann 2003  J Pei J Han and L Lakshmanan Pushing convertible constraints in frequent itemset mining We showed interesting consequences of viewing transaction data as itemvectors in transactionspace and developed a framework for operating on itemvectors This abstraction gives great 337exibility in the measures used and opens up the potential for useful transformations on the data Our future work will focus on 336nding useful geometric measures and transformations for itemset mining One problem is to 336nd a way to use SVD prior to mining for itemsets larger than  pages 205\320215 2005  We also presented GLIMIT a novel algorithm that uses our framework and signi\336cantly departs from existing algorithms GLIMIT mines itemsets in one pass without candidate generation in linear space and time linear in the number of interesting itemsets Experiments showed that it beats FP-Growth above small support thresholds Most importantly it allows the use of transformations on the data that were previously impossible  That is the space required is truly linear  D Achlioptas Database-friendly random projections In  2001  R Agra w al and R Srikant F ast algorithms for mining association rules In  8:227\320252 May 2004  J Pei J Han and R Mao CLOSET An ef 336cient algorithm for mining frequent closed itemsets In  pages 21\32030 2000  S Shekhar and Y  Huang Disco v ering spatial colocation patterns A summary of results 


mator from sensor 1 also shown 6. CONCLUSIONS This paper derives a Bayesian procedure for track association that can solve a large scale distributed tracking problem where many sensors track many targets. When noninformative prior of the target state is assumed, the single target test becomes a chi-square test and it can be extended to the multiple target case by solving a multidimensional assignment problem. With the noninformative prior assumption, the optimal track fusion algorithm can be a biased one where the regularized estimate has smaller mean square estimation error. A regularized track fusion algorithm was presented which modifies the optimal linear unbiased fusion rule by a less-than-unity scalar. Simulation results indicate the effectiveness of the proposed track association and fusion algorithm through a three-sensor two-target tracking scenario 7. REFERENCES 1] Y. Bar-Shalom and W. D. Blair \(editors Tracking: Applications and Advances, vol. III, Artech House, 2000 2] Y. Bar-Shalom and H. Chen  Multisensor Track-to-Track Association for Tracks with Dependent Errors  Proc. IEEE Conf. on Decision and Control, Atlantis, Bahamas, Dec. 2004 3] Y. Bar-Shalom and X. R. Li, Multitarget-Multisensor Tracking Principles and Techniques, YBS Publishing, 1995 4] Y. Bar-Shalom, X. R. Li and T. Kirubarajan, Estimation with Applications to Tracking and Navigation: Algorithms and Software for Information Extraction, Wiley, 2001 5] S. Blackman, and R. Popoli  Design and Analysis of Modern Tracking Systems  Artech House, 1999 10 15 20 25 30 35 40 45 50 55 60 2 4 6 8 10 12 14 Time N o rm a li z e d e s ti m a ti o n e rr o r s q u a re d Target 1 Sensor 1 Centralized Est Track Fusion 10 15 20 25 30 35 40 45 50 55 60 0 2 


2 4 6 8 10 12 14 Time N o rm a li z e d e s ti m a ti o n e rr o r s q u a re d Target 2 Sensor 1 Centralized Est Track Fusion Fig. 7. Comparison of the NEES for centralized IMM estimator \(configuration \(i estimators \(configuration \(ii sensor 1 also shown 6] H. Chen, T. Kirubarajan, and Y. Bar-Shalom  Performance Limits of Track-to-Track Fusion vs. Centralized Estimation: Theory and Application  IEEE Trans. Aerospace and Electronic Systems 39\(2  400, April 2003 7] H. Chen, K. R. Pattipati, T. Kirubarajan and Y. Bar-Shalom  Data Association with Possibly Unresolved Measurements Using Linear Programming  Proc. 5th ONR/GTRI Workshop on Target Tracking Newport, RI, June 2002 8] Y. Eldar, and A. V. Oppenheim  Covariance Shaping Least-Square Estimation  IEEE Trans. Signal Processing, 51\(3 pp. 686-697 9] Y. Eldar  Minimum Variance in Biased Estimation: Bounds and Asymptotically Optimal Estimators  IEEE Trans. Signal Processing, 52\(7 10] Y. Eldar, A. Ben-Tal, and A. Nemirovski  Linear Minimax Regret Estimation of Deterministic Parameters with Bounded Data Uncertainties  IEEE Trans. Signal Processing, 52\(8 Aug. 2004 11] S. Kay  Conditional Model Order Estimation  IEEE Transactions on Signal Processing, 49\(9 12] X. R. Li, Y. Zhu, J. Wang, and C. Han  Optimal Linear Estimation Fusion  Part I: Unified Fusion Rules  IEEE Trans. Information Theory, 49\(9  2208, Sept. 2003 13] X. R. Li  Optimal Linear Estimation Fusion  Part VII: Dynamic Systems  in Proc. 2003 Int. Conf. Information Fusion, Cairns, Australia, pp. 455-462, July 2003 14] X. D. Lin, Y. Bar-Shalom and T. Kirubarajan  Multisensor Bias Estimation Using Local Tracks without A Priori Association  Proc SPIE Conf. Signal and Data Processing of Small Targets \(Vol 


SPIE Conf. Signal and Data Processing of Small Targets \(Vol 5204 15] R. Popp, K. R. Pattipati, and Y. Bar-Shalom  An M-best Multidimensional Data Association Algorithm for Multisensor Multitarget Tracking  IEEE Trans. Aerospace and Electronic Systems, 37\(1 pp. 22-39, January 2001 pre></body></html 


20 0  50  100  150  200  250  300 Pe rc en ta ge o f a dd iti on al tr af fic Cache size 200 clients using CMIP 200 clients using UIR c Figure 6. The percentage of additional traf?c the cache at every clock tick. A similar scheme has been proposed in [13], which uses fv, a function of the access rate of the data item only, to evaluate the value of each data item i that becomes available to the client on the channel If there exists a data item j in the client  s cache such that fv\(i j replaced with i A prefetch scheme based on the cache locality, called UIR scheme, was proposed in [7]. It assumes that a client has a large chance to access the invalidated cache items in the near future. It proposes to prefetch these data items if it is possible to increase the cache hit ratio. In [6], Cao improves the UIR scheme by reducing some unnecessary prefetches based on the prefetch access ratio \(PAR scheme, the client records how many times a cached data item has been accessed and prefetched, respectively. It then calculates the PAR, which is the number of prefetches divided by the number of accesses, for each data item. If the PAR is less than one, it means that the data item has been accessed a number of times and hence the prefetching is useful. The clients can mark data items as non-prefetching when PAR &gt; b, where b is a system tuning factor. The scheme proposes to change the value of b dynamically according to power consumption. This can make the prefetch scheme adaptable, but no clear methodology as to how and when b should be changed. Yin et al. [19] proposed a power-aware prefetch scheme, called value-based adaptive prefetch \(VAP the number of prefetches based on the current energy level to prolong the system running time. The VAP scheme de?nes a value function which can optimize the prefetch cost to achieve better performance These existing schemes have ignored the following characteristics of a mobile environment: \(1 query some data items frequently, \(2 during a period of time are related to each other, \(3 miss is not a isolated events; a cache miss is often followed by a series of cache misses, \(4 eral requests in one uplink request consumes little additional bandwidth but reduces the number of future uplink requests. In this paper, we addressed these issues using a cache-miss-initiated prefetch scheme, which is based on association rule mining technique. Association rule mining is a widely used technique in ?nding the relationships among data items. The problem of ?nding association rules among items is clearly de?ned by Agrawal et al. in [5]. However in the mobile environment, one cannot apply the existing association rule mining algorithm [4] directly because it is too complex and expensive to use This makes our algorithm different from that of [4] in 


This makes our algorithm different from that of [4] in twofold. First, we are interested in rules with only one data item in the antecedent and several data items in the consequent. Our motivation is to prefetch several data items which are highly related to the cache-miss data item within Proceedings of the 2004 IEEE International Conference on Mobile Data Management \(MDM  04 0-7695-2070-7/04 $20.00  2004 IEEE the cache-miss initiated uplink request. We want to generate rules where the antecedent is one data item, but the cache-missed data item and the consequent is a series of data items, which are highly related to the antecedent. If we have such rules, we can easily ?nd the data items which should also be piggybacked in the uplink request. Second in mobile environment, the client  s computation and power resources are limited. Thus, the rule-mining process should not be too complex and resource expensive. It should not take a long time to mine the rules. It should not have high computation overhead. However, most of the association rule mining algorithms [4, 5] have high computation requirements to generate such rules 5. Conclusions Client-side prefetching technique can be used to improve system performance in mobile environments. However, prefetching also consumes a large amount of system resources such as computation power and energy. Thus, it is very important to only prefetch the right data. In this paper, we proposed a cache-miss-initiated prefetch \(CMIP scheme to help the mobile clients prefetch the right data The CMIP scheme relies on two prefetch sets: the alwaysprefetch set and the miss-prefetch set. Novel association rule based algorithms were proposed to construct these prefetch sets. When a cache miss happens, instead of sending an uplink request to only ask for the cache-missed data item, the client requests several items, which are within the miss-prefetch set, to reduce future cache misses. Detailed experimental results veri?ed that the CMIP scheme can greatly improve the system performance in terms of increased cache hit ratio, reduced uplink requests and negligible additional traf?c References 1] S. Acharya, M. Franklin, and S. Zdonik. Prefetching From a Broadcast Disk. Proc. Int  l Conf. on Data Eng., pages 276  285, Feb. 1996 2] S. Acharya, M. Franklin, and S. Zdonik. Balancing Push and Pull for Data Broadcast. Proc. ACM SIGMOD, pages 183  194, May 1997 3] S. Acharya, R. Alonso, M. Franklin, and S. Zdonik. Broadcast disks: Data Management for Asymmetric Communication Environments. Proc. ACM SIGMOD, pages 199  210 May 1995 4] R. Agrawal and R. Srikant. Fast Algorithms for Mining Association Rules. In J. B. Bocca, M. Jarke, and C. Zaniolo editors, Proc. 20th Int. Conf. Very Large Data Bases, VLDB pages 487  499. Morgan Kaufmann, 12  15 1994 5] R. Agrawal, Tomasz Imielinski, and Arun Swami. Mining Association Rules Between Sets of Items in Large Databases. In Proc. of the ACM SIGMOD Conference on Management of Data, pages 207  216, Washington, D.C May 1993 6] G. Cao. Proactive Power-Aware Cache Management for Mobile Computing Systems. IEEE Transactions on Computers, 51\(6  621, June 2002 7] G. Cao. A Scalable Low-Latency Cache Invalidation Strategy for Mobile Environments. IEEE Transactions on Knowledge and Data Engineering, 15\(5 ber/October 2003 \(A preliminary version appeared in ACM MobiCom  00 8] K. Chinen and S. Yamaguchi. An Interactive Prefetching Proxy Server for Improvement of WWW Latency. In Proc INET 97, June 1997 9] E. Cohen and H. Kaplan. Prefetching the means for docu 


9] E. Cohen and H. Kaplan. Prefetching the means for document transfer: A new approach for reducing web latency. In Proceedings of IEEE INFOCOM, pages 854  863, 2000 10] R. Cooley, B. Mobasher, and J. Srivastava. Data preparation for mining world wide web browsing patterns. Knowledge and Information Systems, 1\(1  32, 1999 11] C. R. Cunha, Azer Bestavros, and Mark E. Crovella. Characteristics of WWW Client Based Traces. Technical Report TR-95-010, Boston University, CS Dept, Boston, MA 02215, July 1995 12] D. Duchamp. Prefetching hyperlinks. In USENIX Symposium on Internet Technologies and Systems \(USITS  99 1999 13] V. Grassi. Prefetching Policies for Energy Saving and Latency Reduction in a Wireless Broadcast Data Delivery System. In ACM MSWIM 2000, Boston MA, 2000 14] S. Hameed and N. Vaidya. Ef?cient Algorithms for Scheduling Data Broadcast. ACM/Baltzer Wireless Networks \(WINET  193, May 1999 15] Q. Hu and D. Lee. Cache Algorithms based on Adaptive Invalidation Reports for Mobile Environments. Cluster Computing, pages 39  48, Feb. 1998 16] Z. Jiang and L. Kleinrock. An Adaptive Network Prefetch Scheme. IEEE Journal on Selected Areas in Communications, 16\(3  11, April 1998 17] V. Padmanabhan and J. Mogul. Using Predictive Prefetching to Improve World Wide Web Latency. Computer Communication Review, pages 22  36, July 1996 18] N. Vaidya and S. Hameed. Scheduling Data Broadcast in Asymmetric Communication Environments. ACM/Baltzer Wireless Networks \(WINET  182, May 1999 19] L. Yin, G. Cao, C. Das, and A. Ashraf. Power-Aware Prefetch in Mobile Environments. IEEE International Conference on Distributed Computing Systems \(ICDCS 2002 Proceedings of the 2004 IEEE International Conference on Mobile Data Management \(MDM  04 0-7695-2070-7/04 $20.00  2004 IEEE pre></body></html 


um be r o f C he ck ed P at te rn s Support Threshold Mafia Min_Conf=0.5 Min_Conf=0.7 Min_Conf=0.9 Figure 6. The Number of Checked Patterns on the Pumsb Data Set 10 100 1000 10000 0.1 0.2 0.3 0.4 0.5 0.6 0.7 R un T im e s ec  Support Threshold Mafia Min_Conf=0.5 Min_Conf=0.7 Min_Conf=0.9 Figure 7. The RunTime Comparison on the Pumsb Data Set The runtime comparison of MHP and MAFIA on the Pumsb* data set is shown in Figure 5. In the ?gure, we can observe that the runtime of MHP can be signi?cantly reduced with the increase of h-con?dence thresholds. Also the runtime of MHP can be several orders of magnitude less than that of MAFIA even if the h-con?dence threshold is as low as 0.3. The reason is that the number of checked patterns of MHP is sign?cantly smaller than that of MAFIA Similar results are also obtained from the pumsb data set as shown in Figure 6 and Figure 7. For the pumsb data set the number of checked patterns of MHP is much smaller 


than that of MAFIA and the runtime of MHP can be significantly less than that of MAFIA 5.3. The Effect of the MHP Algorithm on Finding Maximal Hyperclique Patterns Figure 8 and Figure 9 show the number of maximal patterns identi?ed byMHP andMAFIA on Pumsb* and Pumsb data sets respectively. As can be seen, the number of maximal hyperclique patterns identi?ed by MHP can be orders of magnitude smaller than the number of maximal frequent patterns identi?ed by MAFIA. In other words, the number Proceedings of the 16th IEEE International Conference on Tools with Artificial Intelligence \(ICTAI 2004 1082-3409/04 $20.00  2004 IEEE 100 1000 10000 100000 1e+06 1e+07 1e+08 1e+09 0.02 0.025 0.03 0.035 0.04 0.045 0.05 0.055 0.06 N um be r o f C ou nt ed P at te rn s Support Threshold Mafia Min_Conf=0 Min_Conf=0.1 Min_Conf=0.3 Min_Conf=0.5 Min_Conf=0.7 Min_Conf=0.9 Figure 8. The Number of MFI/MHP Patterns in the Pumsb* Data Set 100 1000 10000 100000 1e+06 


1e+07 1e+08 0.1 0.2 0.3 0.4 0.5 0.6 0.7 N um be r o f C ou nt ed P at te rn s Support Threshold Mafia Min_Conf=0.5 Min_Conf=0.7 Min_Conf=0.9 Figure 9. The number of MFI/MHP Patterns in the Pumsb Data Set of maximal hyperclique patterns is much easier to manage than that of maximal frequent patterns. Indeed, in realworld applications, it is dif?cult to interpret several million maximal frequent patterns. However, it is possible to interpret the results of maximal hyperclique pattern mining In addition, due to the memory limitation, we cannot extract maximal frequent patterns with MAFIA on the Pumsb data set if the support threshold is less than 0.4, as shown in Figure 7. In contrast, MHP can identify maximal hyperclique patterns when the support threshold is 0.1, if we set the h-con?dence threshold to 0.5. In other words, MHP has the ability to identify patterns which can be dif?cult to identify for MAFIA. Hence, MHP can better explore the pattern space and ?nd interesting patterns at low levels of support 6. Conclusions and Future Work In this paper, we present a two-phase Maximal Hyperclique Pattern \(MHP best features of both the BFS strategy and the DFS strategy. More speci?cally, we adapted DFS pruning methods such as equivalence pruning, to an apriori-like approach In addition, we proved the correctness and completeness of the MHP algorithm. Finally, our experimental results show that the MHP algorithm can be several orders of magnitude faster than standard maximal frequent pattern mining algorithms and has the ability to identify patterns at extremely low levels of support in dense data sets There are several directions for future work. First, in 


this paper, we only generate the size-2 patterns in the BFS phase. It will be interesting to investigate the impact on the performance if the ?rst phase is stopped at a deeper level Also, the projection is a very ef?cient method for ?nding patterns, especially for parallel implementation of pattern mining algorithms [1]. We plan to adapt the projection ideas into our algorithm and design an ef?cient parallel algorithm for mining maximal hyperclique patterns References 1] R. Agarwal, C. Aggarwal, and V. Prasad. A Tree Projection Algorithm For Generation of Frequent Itemsets. pages 350 371, Feb 2001 2] R. Agrawal, T. Imielinski, and A. Swami. Mining Association Rules between Sets of Items in Large Databases. In Proc. of the ACM SIGMOD Conference on Management of Data, pages 207216,May 1993 3] R. Agrawal and R. Srikant. Fast Algorithms for Mining Association Rules. In Proc. of the 20th Intl Conference on Very LargeData Bases, 1994 4] R. Bayardo. Ef?ciently mining long patterns from databases In Proc. of the ACM SIGMOD Conference, 1998 5] R. Bayardo and R. Agrawal. Mining the Most Interesting Rules. In Proc. of the ACM SIGKDD Conference, 1999 6] D. Burdick, M. Calimlim, and J. Gehrke. Ma?a: AMaximal Frequent Itemset Algorithm for Transactional Databases. In Proc. of IEEE Conf. on Data Engineering, 2001 7] Y. Huang, H. Xiong, W. Wu, and Z. Zhang. A Hybrid Approach for Mining Maximal Hyperclique Patterns. In In Technical Report UTDCS-34-04, Department of computer science, University of Texas - Dallas, 2004 8] J.Han, J.Pei, and Y. Yin. Mining Frequent Patterns without Candidate Generation. In Proc. of the ACM SIGMOD International Conference on Management of Data, 2000 9] M.J.Zaki and C.Hsiao. ChARM: An ef?cient algorithm for closed itemset mining. In Proc. of 2nd SIAM International Conference on Data Mining, 2002 10] R.Rymon. Search through Systematic Set Enumeration. In Proc. Third Intl Conference on Principles of Knowledge Representation and Reasoning, 1992 11] H. Xiong, M. Steinbach, P.-N. Tan, and V. Kumar. HICAP: Hierarchial Clustering with Pattern Preservation. In Proc. of 2004 SIAM International Conference on Data Mining \(SDM 12] H. Xiong, P.-N. Tan, and V. Kumar. Mining Strong Af?nity Association Patterns in Data Set with Skewed Support. In Proc. of the Third IEEE International Conference on Data Mining \(ICDM Proceedings of the 16th IEEE International Conference on Tools with Artificial Intelligence \(ICTAI 2004 1082-3409/04 $20.00  2004 IEEE 





