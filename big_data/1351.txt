Applications of Clustering Data Mining in Customer Analysis in Department Store Wencai Liu Yu Luo College of Automation Chongqing University Chongqing 400044 China  liuwc cqu.edu.cn luoyu0521 sina.com.cn Absbuct Data mining is used for knowledge discovering from mass data to support decision making The implementation aspects of applying clustering data mining method to customer analysis of department store are studied in this paper 
A dah warehouse is built based on the OLTP database of Chongqing Liangbai Department Store Two data mining models are applied to the aaalysis of customer characteristics and the relationship between customers and the product categories The mining results are analyzed Keywords data warehouse data mining clustering analysis I INTRODUCTION Many retail trade enterprises have accumulated huge amount of data from their OLTP On-Line Analysis Processing\systems, which might have been used for many years. How to use the data 
to provide decision support for managers is paid more and more attention today Data Warehouse On-Line Analysis Processing OLAP and Data Mining technologies hihe been developed to help us to solve data analysis problems Data Warehouse stores and manages huge mass of data in such a way that the data can be easily analyzed OLAP provides an efficient way to query data in various dimensions and levels Data Mining can discover valuable unknown knowledge such as relationships rules and patterns Data Mining uses complex algorithms to analyze data and create models to represent information in the data These models 
can predict the characteristics of new data or recognize the data entities that have similar characteristics There are many data mining types, such as association rules decision trees clustering, neural networks etc The applications of data mining in retail trade enterprises are mainly concentrated in association rules This kind of data mining can discover such kind of rules that customers probably buy products B while buying products A[51 As various kinds of the customer cards which can provide information about customers has been adapted in many retail trade enterprises, the customer analysis of retail trade enterprises using data mining technologies becomes realistic This paper discusses clustering 
data mining applications in customer analysis of department stores The algorithms of cIustering are briefly summarized first then the data warehouse based on the OLTP On-Line Transaction Processing database of Chongqing Liangbai Department Store CLDS is introduced the customer characteristics and the relationship between customers and the categories of products are analyzed using Microsoft clustering algorithm U CLUSTERING ALGORITHMS Clustering data mining divides data objects into several groups or clusters automatically so that the objects in the same group have high similarities and the objects in different groups have big differences. Clustering algorithms have been studied for many years The typical algorithms are k-means and k-medoids In 
k-means every group is represented by the average value of the objects in the group The clustering process is randomly choose k objects each object initially represents the average of each group assign each remaining object to one of the k groups to which the object has the shortest distance CalcuIate the average of each group and regroup all objects according to the distance to the new averages Do average and regroup steps again until the groups are no longer changed In k-medoids, each group is represented by the object that is at the center of the group The clustering process is similar to k-means Above algorithms need 
scan instance data many times Microsoft provided an efficient algorithm  Scdable Expectation Maximization SEM 21\(31 which only scans data one time The basic idea is to create clusters by the density of the instance objects The calculation process can be stopped anywhere and restarted again We can get a reasonable result at any point in the process The algorithm creates some clusters when processing data records and changes the centers of the clusters while more data are processed in order to find a duster set that can describe the characteristics of similar instance objects best III 
CREATING DATA WAREHOUSE A Data Warehouse is a subject-oriented integrated non-volatile, and time variant collection of data in support of management\222s decision making process 14 The database of data warehouse consists of fact tables and dimension tables that are structured as star forms or snowflake forms The data in data warehouse are come from OLTP database and other data sources of the enterprise through extracting organizing and transforming The data source used in this paper is the OLTP database of Chongqing Liangbai  1042 0-7803-897 1-9/05/$20.00 2005 EEE 


Department Store A About the datu source The management information system of Chongqing Liangbai Department Store was installed in 1998 From August 2002 customer card has been used to integrate the amount of customer purchases Since then some customer information has been collected The structure of the OLTP database related to sales analysis is shown in Fig 1 which is a conceptual data model CDM designed with PowerDesigner L61 The Sales Transaction entity contains the data of each transaction \(time amount of money type of payment customer integration etc Sales Product entity contains the data of products sold in each transaction quantity price discount rate, amount of money etc Inventory entity contains account data for every batch of store purchases bakh number, in-out-time in-out-type quantity prime cost amount 221of money The three entities above are the data sources of the fact tables of the data waiehouse There is no batch infomation of products in the data from the POS point of sell terminals The system accumulates the sales quantity for every product by day and then decomposes them into product batches by the rule of 221Tit in and first out\224 This process adds batch information to the sold products therefore the products have prime cost infomation and we can do profit analyses There are three types of sell counters in the store: normal joint and rent There is no product information for joint and rent counters in the OLTP database Each joint and rent counter uses only one product code and uses counter\222s name as the 223product name\224 Therefore we can not do product analyses for products sold in these kinds of counters I__ p__ product sub categq pnducts 1 product-name I I product-speafication 221j product-bar-code I  Rddm12 unit I    _ t M __ _._  cuslomers 1-r Mz customer-integration cM customer-name cM lD-cardpnumber iMz gender bi rth-year-month I phongnumber mail-address I education-level I occupation L ___..-~I--__ L i sales-transaction i ___ _I transaction IO sal e-date sale-time cashier Mr 1 cah-payment bank-card-payment 1 chectpament 1 store-card-payment expences-integration  I   Fig 1 Part of the E-R model of CLDS MIS FowerDesigner CDM B The dimension tables and fact tables According to the requirements of clustering analyses of this paper, we only need two dimension tables: customer and product Taking the requirements of the whole sails analyses into account; there should also be a time dimension table and a counter dimension table Using star structure we design the data warehouse for sales analyses as Fig 2 which is a PowerDesigner physical data model PDM 61 All dimension tables are shared dimensions Because only part of the sales records has customer information, there should be a special record in the customer dimension table \(here we use card number 221 1999999999\222\to represent unknown customers to ensure reference integrity There is an age segment field in customer dimension table for the needs of analysis of age characteristics of customer Because age is time variable we should construct a sales fact table called year sales fact table, which only has one year\222s sales data and set the values of age segment in customer dimension table correspondingly 


The sales fact table in Fig 2 has dl sales records of all counters include joint and rent counters but only the normal counter's records have actual product information therefore we should construct another sales fact table, called normal counter sales fact table in which the sales records of joint and rent counters have been deleted for the analyses related to products The customer information available from the OLTP data is customer name, age and gender ID card is required when a customer apply customer card so the above information is available for all customers Most customers do not fill f I date-ID int pk I I date char\(l0 month char\(9 I season char\(2 i year char\(4 I day char 9 I  additional information, such as education level, profession etc into the application forms so we can not analyze other characteristics of customers When analyze customer characteristics we need year sales fact table and when we analyze the relationships between customer characteristics and product categories we need normal counter sales fact table In the same time the two fact tables should not contain records that have no actual customer information I __  counters counter-code char\(4 coun ter-name char varying 10 counter-type char\(4 department-name char varying\(l0   counter-ID int pk   __ __            I customers I customer-ID int pk j customer-name char varying\(20 I customer-number char 10 I gender char 2 I age-segmen t char 6 education level char\(6 occupation char varying\(l0 mail address char varying\(30 phone-number char 16 1  _.._I _ _-_~____ products I __  product-ID int pk product-code char 10 product-name char varying330 produc t-speci f icat ion char varying 30 sub-category char varying\(l0 category char varying\(l0 supper-category char varying\(l0 FK_SALESFACT  sales-fact customer-ID int fkl product-ID int fk2 date-ID int fk3 counter-ID int fk4 quantity_of_sale decimal amount-of-money money grossgrof i t money _   ERENCE_PRODUCFS C Data abstracting and loading Wq abstract data from the OLTF database and load it into the dimension tables and the fact tabie of the data warehouse shown in Fig.2 The dimension tables should be loaded first and then the fact table From Fig 1 and Fig 2 we can see that it is simple to get data for dimension tables but complex for the fact table The customer dimension table can get data directly from the customer table of the OLTP'database, and insert a special record of 1999999999 as card number The counter dimension table should be get data jointly from the department table and the counter table of the OLTP database And the product dimension table is loaded with data jointly retrieved from the super category category subcategory and product table of the OLTP database An agent key is set for each dimension table The value of the key is assigned automatically by DBMS while record is inserted Sales fact data are abstracted as foIlows fist compute the average prime cost for each product sold in each day from the inventory table and store the averages in a temporary table Second, retrieve sales quantity amount of money prime cost jointly from sales product table and the prime cost temporary table and caculate the gross profit for each product sold In the second step all the dimension tables should also be jointed into the retrieve to get the joint key values of the sales fact table IV DATA MINING MODELS AND mG RESULTS A CZusrering of custumer characteristics By inquiry of the sales data in 2003 we know that there are only 15 records have customer information Although the percentage is small it still has certain representative role The sales data in 2003 is used in this paper for customer analysis Therefore we need a new sales fact table, named as 2003_sales which only be loaded with data that has customer information in 2003 from the sales fact table In 


 set as follows Datu type relational data Fact table 2003-sales-normai Dimension tables customers products Mining algorithm Microsoft clustering Key of instunce product ID Training data customer age segment customer gender supper category of products sales amount of money Number of cluster 10 TABLE 2 3 4 the same time the values of the age segment field of the customer dimension table should be assigned according to customer's birth year In order for clustering the instances of customer it is needed to aggregate sales facts grouped by customer We can avoid this step by clustering based on an OLAP multi dimension data set in which the gender and age segment fields are set as two properties of customer identified by card number We create the data mining model in MicrosoftEd Analysis Manager[21 as foIlows Data type OLAP multi dimension data set 2003-sales Data mining alggon'thm Microsoft clustering Dimension customer Level customer card number Training data customer age segment customer gender sales amount of money Number of cluster 10 The mining results show that in all the 6485 instances female customers take 75 customers with age above 35 take 62 the average expenses per customer are 537 Yuan RMB The main characteristics of customers of the 10 clusters are shown as Tab 1 TABLE 1  59 11.5 A 35-40 F 98 VI33 50 72 11.2 A35-40 SO F 92 Y171 IF CUSTOMES AND PRODUCT cakes Daily use dcles Span time foods Daily use articles Cosmetics 64 Drinking powders 54 Cosmetics Daily use articles Spare time foods 52 Cosmetics Grains  oils Drinking MAIN CHARACTORISTIC Y13.16 Y 18.36 Y33.52 CAI Customer main age segments 30 A35-40 67 A30-40 5 57 A40-50 56 5 6 GORIE main gender F 57  55 10.64 A30-40 52 F 63 Y291 9.9 A30 35-40 F 59 Y486  Clus ter instance  propor tion 14.8 f 2.9 11.9 Main I Amount product of instance  1 Cosmetics 54951   Daily use I Y4.24 2  3 F 85 F 69 articles Spare time foods Spare time Candies  cakes Spare time foods MAIN CHARACTORISTICS cluster hstadce Percentag segment 13.0 A25 4[k 12.0 A30 5th IF CUSTOMER Maid I Average 4  5 11.1 10.35 9.8 9.1 customer F 94 6 F 69 TI550 9.0 Y886 10 3.7 7 F 67 We can see from the mining results that the main customers of the store are female people above 35 years old the less the number of instances in a cluster, the higher the average expenses per customer male customers with the age between 30 to 45 has a very high expenses the 10 cluster  These analyses results can help the managers improve their management tactics For example, increase the products that satisfy the needs of the main customer group more in order to increase their expenses design golden card to increase the proportion of the high expenses customers etc Clustering of customer churaeteristics and products In order to further inquire the relationship between customer characteristics and products we cluster customers together with product categories For this purpose we create a new sales fact table named as 2003_sales_normal and load it with data of normal counters with customer information in 2003 from 2003-sales The mining model is 8 9.0 F 72 9 8.5 10  2.5 alcohol 172.77 cosmetics The mining results show that in all the 59051 instances female customers take 69 customers with age above 35 take 60 This result indicates that the main customer group for normal counters is the same as the main customer group  1045  


of the store The product categories expensed by main customer group are mainly concentrated in 5 categories daily use articles cosmetics spare time foods dry foods and candies  cakes which represent the product categories that are most frequently bought by customers The instances of above categories take 71 of the total sales instances and these categories take 28 of the total 18 product categories in the store This result approximately fills the "two-eight rule Inspiring the 10 clusters we can get the main characteristics of each cluster shown as Tab 2 which represents the relationships between customer characteristics and product categories These relationships can be used to make advertising, sale promotions and customer receptions more specific and more effective These results can also be used to direct OLAP inquiring to get more valuable decision support information TV CONCLUSION Clustering data mining can be used to group instance data automatically according to their similarities to get useful modes contained in the data Enterprise managers can get decision supports by inquiring the mining results Clustering analysis can provide an approximate understandmg to a problem and can usually point out other areas that need to be inquired Clustering is usually the first step of data analyses It is obvious that the customer analyses are very important for retail trade enterprises This paper provides two application examples of clustering in customer analyses in department store and gives the whole process of realizing the analyses These examples show that the clustering data mining is useful and effective Retail enterprises that have costumer information can use clustering data mining techniques as the examples provided in this paper to get valuable information for decision making Using Microsoft@ Analyses Services the data mining itself is simple The main work to do the mining is building data warehouse which is case specific and needs domain knowledge and infomation system skills Because only partial customer information can be available the results of clustering analyses in this paper have certain limitations for decision support REFERENCES Jiawei Han and Micheline Umber Data Mining Concepts and Techniques San Francisco Morgan Kaufmann Publishers Inc 2001 Tony Bain etc Professional SQL Server 2000 Data Warehousing with Analysis Services Wrox Press 2001 Paul S Bradley Usama M Fayyad and Cory A Reina bctober 1999 Scaling EM Expectation Maximization Clustering to hge Databases Available W.H.Inmon Building the data warehouse NJ John Wiley  Sons Inc Press 1996 R Agrawal and T Imielinski A Swami Mining Association Rules Between Sets of Items In Large Database Proc ACM SIGMDO 1993 Shangwang Bai and Weichao Dang PowerDesigner Software Engineering Technology Beijing Publishing House of Electronics Industry 2004 ftp:/lftp.~s~~h.~~~~~.~~~~~b/tr/t 207-21 6  1046 


probably due to loss of episodic memory of previous responses in the task Recent electrophysiological studies have demonstrated selective neuronal spiking activity dependent upon prior or future responses in this task Wood et al 2000 and ongoing simulations and experiments are addressing specific mechanisms of this selective spiking activity References Bragin A Iando G Nadasdy Z Hctke I Wisc K Buzsaki G Gamma 40-IO0 Hz oscillation in the hippocampus of the bchaving rat JournalqfNeuroscience 15 47-60 \(1995 Brankack J Stew M Fox SE 1993 Current source density analysis of the hippocampal theta rhythm associated sustained potentials and candidate synaptic gcnerators Brain Research 615\(2 310-327 Buzsaki G Lcung LW Vandcnvolf CH 1983 Cellular bases of hippocampal EEG in the bchaving rat Brain Res. 287\(2 Cannon R.C Hasselma M.E and Koene R.A 2002 From biophysics to behavior Catacomb2 and the design of biologically plausiblc models for spatial navigation Ncuroinformatics l\(1 3-42 Fox S E 1989 Mcmbrane potential and impedence changes in hippocampal pyramidal cells during thcta rhythm Exp Brain Res 77 283-294 Givens B I 996\Stimulus-cvokcd resetting ofthc dentate theta rhythm relation to working mcmory Neurorepon 8 159-163 Golding NL Staff NP Spruston N 2002 Dcndritic spikes as a mechanism for coopcrativc long-term potentiation Nature 418\(6895 326-331 Gustafsson B Wigstram H Abraham WC, Huang YY 1987 Long term potentiation in thc hippocampus using dcpolarizing current pulses as thc conditioning stimulus to single volley synaptic potentials J NCUTOSC 7\(3 Hassclmo M.E Badelon C and Wyblc B.P 2002a A proposcd function for hippocampal thcta rhythm Separate phases of encoding and rctrieval enhance rcvcrsal of prior Icaming Neural Computation 14\(4 793-817 Hassclmo M.E Hay J Ilyn M and Gorchetchnikov A 2002b Ncuromodulation thcta rhythm and rat spatial navigation Ncural Networks 15 689-707 Hassclmo M.E and McClclland J.L 1999 Ncural modcls of memory Cum Opinion Ncurobiol 9 184-188 Hasselmo M.E Wyblc, B.P and Cannon R.C 2002 From spike frcqucncy to frec mall How ncural circuits pcrform encoding and rctricval In A Parkcr T.J Bussey E. Wilding \(eds.\Thc cognitive neuroscience of memory Encoding and retrieval. London: Psychology Prcss Holscher C Anwyl, R, Rowan MI 1997 Stimulation on fhc positivc phasc ofhippocampal thcta rhythm induces long-term potcntiation that can Bc dcpotentiatcd by stimulation on thc nogativc phaac in arca CAI in vivo JNeurosci 17\(16\6470.6477 Hucrta PT Lisman JE 1995 Bidirectional synaptic plasticity induccd by a single burst during cholinergic thcta oscillation in CAI in vitro Neuron 15\(5 1053-1063 Hyman JM Wyblc BP Goyal V Hassolmo ME 2001 Phasc relationship of LTP inducation and bchavior to thcta rhythm in the rat hippocampus Sac Ncurosci. Abstr. 27 Hyman I Wyble, B.P Rossi,C.A Hasselmo, M.E. \(2002\Coherence between theta rhythm in rat medial prefrontal conex and hippaeampm Sac Neurosci Abslr 28: 477.6 Jensen 0 Lisman JE 1996 Novel lists of7  2 known items can be reliably stored in an oscillatory short-term memory network intcraction with long-term memory Learn Man 3\(2-3 Kamondi A Acsady L Wang XJ Buzsaki G 1998 Theta oscillations in somata and dendrites of hippocampal pyramidal cells in vivo activily-dependent phase-precession of action potentials Hippocampus 8\(3\244-61 Kacne R.A., Cannon, R.C and Hasselmo M.E 2001 Goaldirected spatial navigation of the rat depends on phases of theta oscillation in hippocampal circuitry. Proc. IJCNN 2003 Kohonen T 1984 Self-organization and Associative Memory Springer-Verlag Macrides F Eichenbaum HB Forbes W.B 1982 Temporal relationship between sniffing and the limbic theta rhythm during odor discrimination rcvemal leaming J Neurosei 2 1705-1717 Markowska AL Olton DS Murray EA Gaffan D 1989 A comparative analysis of the role of fomix and cingulate cortex in memory rals Exp Brain Res. 74\(1 M'Hani M Palacios A Monmaur P Willig F Houcine 0 and Delacour 1 1987 Effects of selective lesions of fimbria-fomix an learning set in the rat Physiol  Behav. 40 181-188 OKcefe J and Recce M.L 1993 Phase relationship between hippocampal place unis and the EEG theta rhythm Hippocampus 3 3 17-330 On G Rao G Stevenson GD Bames CA McNaughton BL 1999 Hippocampal synaptic plasticity is modulated by the theta rhythm in thc fascia dcntata of freely behaving rats Soc Neurosci Abstr 25 2165 \(864.14 Rempcl-Clower NL Zola SM Squire LR, Amaral DG 1996 Three cases ofcnduring memory impairment afler bilateral damage limited to the hippocampal formation I Neurosci 16\(16\5233-5255 Skaggs W.E McNaughton B.L Wilson M.A and Bames C.A 1996 Theta phase preccssion in hippocampal neuronal populations and the compression of temporal sequences Hippocampus 6 149 172 Sohal V.S and Hasselmo M.E 1998a Changes in GABAB modulation during a theta cycle may be analogous to the fall of tcmperahlrc during annealing Neural Compuralion 10 889-902 Tsodyks MY, Skaggs WE Sejnowski TJ and McNaughton BL 1996 Population dynamics and theta rhythm phase precession of hippocampal place ccll.firing a spiking neuron model Hippocampus 6\(3 271-280 Wallenstein G.V and Hasselmo M.E 1997a GABAergic modulation of hippocampal population activity Sequence leaming place field devclopmcnt and the phase precession effect J Neurophysiol 78\(1\393-408 Wiener SI Paul CA Eichenbaum H 1989 Spatial and bchaviaral correlates of hippocampal n~uronal activity J Nmrosci 9\(8 Wood ER Dudchcnko PA Robisek RJ Eichenbaum H 2000 Hippocampal neurons encode information about different types of memory episodes occurring in the samc location Neuron 27\(3 31 Wyble BP Linstcr C Hasselmo ME 2000 Size of CAI-cvoked synaptic potentials is rclated to theta rhythm phase in rat hippocampus I Ncuraphysiol 83\(4 1475 


I] Hu. K. and Xia S.W., Data mining based on large data warehouse, Journal of software, Vol 9,No.l,pp.53-63,Jan.1998 2] Agrawal. R., Mining association rules between sets of items in large database, Proc. ACM SIGMOD int  l conf. Management of data, Washington DC, pp 207-216.May.1993 3] Alex. B. and Stephen. IS., Data warebouse, Data mining and OLAP, McGraw-Hill Book Co. 1999 4] Chen. M.S. and Philip. S., Data mining: an overview from database perspective, IEEE Transaction on knowledge and data engineering pp.866-883 Aug.1996 Roberto. J., Efficiently mining long pattems from databases, Proceedings of the 1998 ACM-SIGMOD int  l conf. on management of data pp.85-93,1998 6] Duda. R.O., Hart. P.E. and Stork. D.J., Pattem recognition, Wiley, New York, 2001 7] Zaki, M.J., Ogibara. M. and Li. W., New algorithms for fast discovery of association rules, Proceedings of the third Int  l conf. on knowledge discovery in database and data mining, pp.283-286.1997 8] Goulboume. G.,  Coenen. F. and Leng. P., Algorithms for computing association rules using a partial-support tree, Knowledge-Based Systems, Vol 13 pp.141-149,2000 9] Yingwu Fang, Guangpeng Zhang, Dewei Wu and Wang Yi, Research on distributive data mining calculating process-DDCP algorithm, Joiirnal of university of elechonic science and technology, Vo132 No. 1, pp.80-84, Feb.2003 5 1660 pre></body></html 


It should be noted that after the above process the resulting support constraint set may become inconsistent Thus in the next round the value c   m i 1 z i may be larger If that happens the larger value c does not interpret as the privacy condence level Instead it should be interpreted as an indicator for inconsistency of the support constraint set Thus the above privacy deletion procedure should only be carried out one time We should note that even if the condence level is higher that is c   m i 1 z i is small there is still possibility that the condential information specied by  I,s,S  is leaked in theory That is for each transaction database D that satises the constraints S wehave support  I D    s S   However no one may be able to recover this information since it is NP hard to infer this fact Support constraint inference has been extensively studied by Calders in 2 3 It would be interesting to consider conditional privacypreserving synthetic transaction database generations That is we say that no private information is leaked unless some hardness problems are solved efciently This is similar to the methodologies that are used in public key cryptography For example we believe that RSA encryption scheme is secure unless one can factorize large integers In our case we may assume that it is hard on average to efciently solve integer linear programs Based on this assumption we can say that unless integer linear programs could be solved efciently on average no privacy specied in P is leaked by S if the computed condence level c   m i 1 z i is small 5 Conclusions In this paper we discussed the general problems regarding privacy preserving synthetic transaction database generation for benchmark testing purpose In particular we showed that this problem is generally NP hard Approximation algorithms for both synthetic transaction database generation and privacy leakage condence level approximation have been proposed These approximation algorithms include solving a continuous variable linear program According to 6 l i n ear probl ems ha vi ng hundreds of t housands of continuous variables are regularly solved Thus if the support constraint set size is in the order of hundreds of thousands then these approximation algorithms are efcient on regular Pentium-based computers If more constraints are necessary then more powerful computers are needed to generate synthetic transaction databases References 1 R  A g r a w al T  Imilien sk i an d A  S w a mi Min in g association rules between sets of items in large databases In Proc of ACM SIGMOD International Conference on Management of Database  pages 207216 1993  T  C a lders  Axiomatization and Deduction Rules for the Frequency of Itemsets  PhD Thesis Universiteit Antwerpen 2003  T  C a l ders  C omput at i onal compl e x i t y of i t e ms et frequency satisability In Proc 23rd ACM PODS 04  pages 143154 ACM Press 2004  R  F agi n J  Hal pern and N Me gi ddo A l ogi c f or reasoning about probabilities Information and Computation  87 1,2\78128 1990  G Geor gak opoul os  D  K a v v a di as  a nd C  P a padi mitriou Probabilistic satisability J of Complexity  4 111 1988  Li near P r ogrammi ng F r equent l y As k e d Q ues t i ons  http://www-unix.mcs.anl.gov/otc Guide/faq/linear-programming-faq html  T  M ielik  ainen On inverse frequent set mining In Proc of 2nd Workshop on Privacy Preserving Data Mining PPDM  pages 1823 IEEE Computer Society 2003  C  P o t t s  A nal ys i s of a l i n ear programmi ng heuri s t i c for scheduling unrelated parallel machines Discrete Appl Math 10 155164 1985 9 G  R amesh  W  Man iatty  a n d M Zak i Feasib le itemset distributions in data mining theory and application In Proc 22nd ACM PODS  pages 284295 2003  Y  W a ng X W u  a nd Y  Zheng P r i v ac y p res ervi ng data generation for database application performance testing In Proc 1st Int Conf on Trust and Privacy in Digital Business TrustBus 04 together with DEXA  LNCS 3184 pages 142-151 2004 Springer-Verlag  X W u  Y  W u Y  W a ng and Y  Li P ri v a c y a w are mar ket basket data set generation a feasible approach for inverse frequent set mining In Proc 5th SIAM International Conference on Data Mining  April 2005  Z Zheng R  K oha vi  a nd L Mas on R eal w o rl d performance of association rule algorithms In Proc of the ACM-SIGKDD International Conference on Knowledge Discovery and Data Mining  pages 401 406 ACM Press 2001 8 Proceedings of the Fifth IEEE International Conference on Data Mining \(ICDM05 1550-4786/05 $20.00  2005 IEEE 


Discovery, 8, 2004, pp. 7-23 20] W. Teng, M. Hsieh, and M. Chen. On the Mining of Substitution Rules for Statistically Dependent Items Proceedings of IEEE International Conference on Data Mining \(ICDM  02 Proceedings of the Fourth IEEE International Conference on Data Mining \(ICDM  04 0-7695-2142-8/04 $ 20.00 IEEE pre></body></html 


14] Kryszkiewicz, M., and Rybinski, H. \(1999  Incomplete Database Issues for Representative Association Rules  ISBN: 3-540-65965-X, pp. 583-591 15] Little, R.J.A., and Rubin, D.B. \(2002 analysis with missing data, Wiley, New York, ISBN 0471183865 16] Omiecinski, E.R. \(2003  Alternative interest measures for mining associations in databases  IEEE TKDE vol. 15, no. 1, pp.57-69 17] Piramuthu, S. \(1998  Evaluating feature selection methods for learning in data mining applications  in the Proceedings of the Thirty-First Annual Hawaii International Conference on System Sciences, vol. 5, pp. 294-301 18] Pyle, D. \(1999 Morgan Kaufmann Publishers, Inc.ISBN:1-55860-529-0 19] Ragel, A., and Cremilleux, B. \(1999  MVC - A preprocessing Method to deal with missing values   knowledge based system, vol. 12, pp.285-291 20] Ramoni, M., and Sebastiani, P. \(2000  Bayesian Inference with Missing Data Using Bound and Collapse   Journal of Computational and Graphical Statistics, vol. 9, no 4, pp. 779-800 21] Ramoni, M., and Sebastiani, P. \(2001  Robust Bayes Classifiers  AI, vol. 125, no. 1-2, pp. 207-224 22] Ramoni, M., and Sebastiani, P. \(2001  Robust Learning with Missing Data  Machine Learning, vol. 45, no 2 , pp. 147-170 23] Scott, R.E. \(1993 Logic and Practice, SAGE Publications, ISBN: 0803941072 24] Zaki, M.J., and Hsiao, C.J. \(2002  CHARM: An efficient algorithm for closed itemset mining  in the Proceedings of the Second SIAM International Conference on Data Mining Proceedings of the Fourth International Conference on Hybrid Intelligent Systems \(HIS  04 0-7695-2291-2/04 $ 20.00 IEEE pre></body></html 


13: else 14: E|i?1| = E|i?1| ? s The backward process in Algorithm 1, generates level-wise every possible subset starting from the borProceedings of the Fourth IEEE International Conference on Data Mining \(ICDM  04 0-7695-2142-8/04 $ 20.00 IEEE der de?ned by Edge without getting into equivalence classes which have been already mined \(Line 10 such subset satis?es the constraint then it can be added to the output \(Line 12 reused later to generate new subsets \(Line 14 have a monotone constraint in conjunction, the backward process is stopped whenever the monotone border B+\(Th\(CM Lines 3 and 8 4.3. Closed Constrained Itemsets Miner The two techniques which have been discussed above are independent. We push monotone constraints working on the dataset, and anti-monotone constraints working on the search space. It  s clear that these two can coexist consistently. In Algorithm 2 we merge them in a Closet-like computation obtaining CCIMiner Algorithm 2 CCIMiner Input: X,D |X , C, Edge,MP5, CAM , CM X is a closed itemset D |X is the conditional dataset C is the set of closed itemsets visited so far Edge set of itemsets to be used in the BackwardMining MP5 solution itemsets discovered so far CAM , CM constraints Output: MP5 1: C = C ?X 2: if  CAM \(X 3: Edge = Edge ?X 4: else 5: if CM \(X 6: MP5 = MP5 ?X 7: for all i ? flist\(D |X 8: I = X ? {i} // new itemset avoid duplicates 9: if  Y ? C | I ? Y ? supp\(I Y then 10: D |I= ? // create conditional fp-tree 11: for all t ? D |X do 12: if CM \(X ? t 13: D |I= D |I ?{t |I  reduction 14: for all items i occurring in D |I do 15: if i /? flist\(D |I 16: D |I= D |I \\i // ?-reduction 17: for all j ? flist\(D |I 18: if supD|I \(j I 19: I = I ? {j} // accumulate closure 20: D |I= D |I \\{j 21: CCIMiner\(I,D |I , C,B,MP5, CAM , CM 22: MP5 = Backward-Mining\(Edge,MP5, CAM , CM For the details about FP-Growth and Closet see [10 16]. Here we want to outline three basic steps 1. the recursion is stopped whenever an itemset is found to violate the anti-monotone constraint CAM Line 2 2  and ? reductions are merged in to the computation by pruning every projected conditional FPTree \(as done in FP-Bonsai [7 Lines 11-16 3. the Backward-Mining has to be performed to retrieve closed itemsets of those equivalence classes which have been cut by CAM \(Line 22 5. Experimental Results The aim of our experimentation is to measure performance bene?ts given by our framework, and to quantify the information gained w.r.t. the other lossy approaches 


approaches All the tests were conducted on a Windows XP PC equipped with a 2.8GHz Pentium IV and 512MB of RAM memory, within the cygwin environment. The datasets used in our tests are those ones of the FIMI repository1, and the constraints were applied on attribute values \(e.g. price gaussian distribution within the range [0, 150000 In order to asses the information loss of the postprocessing approach followed by previous works, in Figure 4\(a lution sets given by two interpretations, i.e. |I2 \\ I1 On both datasets PUMBS and CHESS this di?erence rises up to 105 itemsets, which means about the 30 of the solution space cardinality. It is interesting to observe that the di?erence is larger for medium selective constraints. This seems quite natural since such constraints probably cut a larger number of equivalence classes of frequency In Figure 4\(b built during the mining is reported. On every dataset tested, the number of FP-trees decrease of about four orders of magnitude with the increasing of the selectivity of the constraint. This means that the technique is quite e?ective independently of the dataset Finally, in Figure 4\(c of our algorithm CCIMiner w.r.t. Closet at di?erent selectivity of the constraint. Since the post-processing approach must ?rst compute all closed frequent itemsets, we can consider Closet execution-time as a lowerbound on the post-processing approach performance Recall that CCIMiner exploits both requirements \(satisfying constraints and being closed ing time. This exploitation can give a speed up of about to two orders of magnitude, i.e. from a factor 6 with the dataset CONNECT, to a factor of 500 with the dataset CHESS. Obviously the performance improvements become stronger as the constraint become more selective 1 http://fimi.cs.helsinki.fi/data Proceedings of the Fourth IEEE International Conference on Data Mining \(ICDM  04 0-7695-2142-8/04 $ 20.00 IEEE Information loss Number of FP-trees generated Run time performance 0 2 4 6 8 10 12 14 x 10 5 10 0 10 1 10 2 10 3 10 4 10 5 10 6 m I 2 I 1  PUMSB@29000 CHESS @ 1200 0 0.2 0.4 0.6 0.8 1 1.2 1.4 1.6 1.8 2 x 10 6 10 


10 1 10 2 10 3 10 4 10 5 10 6 10 7 m n u m b e r o f fp t re e s PUMSB @ 29000 CHESS @ 1200 CONNECT@11000 0 2 4 6 8 10 12 14 x 10 5 10 0 10 1 10 2 10 3 10 4 m e x e c u ti o n  ti m e  s e c  CCI Miner  \(PUMSB @ 29000 closet         \(PUMSB @ 29000 CCI Miner  \(CHESS @ 1200 closet         \(CHESS @ 1200 CCI Miner  \(CONNECT @ 11000 closet         \(CONNECT @ 11000 a b c Figure 4. Experimental results with CAM ? sum\(X.price 6. Conclusions 


6. Conclusions In this paper we have addressed the problem of mining frequent constrained closed patterns from a qualitative point of view. We have shown how previous works in literature overlooked this problem by using a postprocessing approach which is not lossless, in the sense that the whole set of constrained frequent patterns cannot be derived. Thus we have provided an accurate de?nition of constrained closed itemsets w.r.t the conciseness and losslessness of this constrained representation, and we have deeply characterized the computational problem. Finally we have shown how it is possible to quantitative push deep both requirements \(satisfying constraints and being closed process gaining performance bene?ts with the increasing of the constraint selectivity References 1] R. Agrawal, T. Imielinski, and A. N. Swami. Mining association rules between sets of items in large databases In Proceedings ACM SIGMOD, 1993 2] R. Agrawal and R. Srikant. Fast Algorithms for Mining Association Rules in LargeDatabases. InProceedings of the 20th VLDB, 1994 3] R. J. Bayardo. E?ciently mining long patterns from databases. In Proceedings of ACM SIGMOD, 1998 4] F. Bonchi, F. Giannotti, A.Mazzanti, andD. Pedreschi Adaptive Constraint Pushing in frequent pattern mining. In Proceedings of 7th PKDD, 2003 5] F. Bonchi, F. Giannotti, A.Mazzanti, andD. Pedreschi ExAMiner: Optimized level-wise frequent pattern mining withmonotone constraints. InProc. of ICDM, 2003 6] F. Bonchi, F. Giannotti, A.Mazzanti, andD. Pedreschi Exante: Anticipated data reduction in constrained pattern mining. In Proceedings of the 7th PKDD, 2003 7] F. Bonchi and B. Goethals. FP-Bonsai: the art of growing and pruning small fp-trees. In Proc. of the Eighth PAKDD, 2004 8] J. Boulicaut and B. Jeudy. Mining free itemsets under constraints. In International Database Engineering and Applications Symposium \(IDEAS 9] C. Bucila, J. Gehrke, D. Kifer, and W. White DualMiner: A dual-pruning algorithm for itemsets with constraints. In Proc. of the 8th ACM SIGKDD, 2002 10] J. Han, J. Pei, and Y. Yin. Mining frequent patterns without candidate generation. In Proceedings of ACM SIGMOD, 2000 11] L.Jia, R. Pei, and D. Pei. Tough constraint-based frequent closed itemsets mining. In Proc.of the ACM Symposium on Applied computing, 2003 12] H. Mannila and H. Toivonen. Multiple uses of frequent sets and condensed representations: Extended abstract In Proceedings of the 2th ACM KDD, page 189, 1996 13] R. T. Ng, L. V. S. Lakshmanan, J. Han, and A. Pang Exploratory mining and pruning optimizations of constrained associations rules. In Proc. of SIGMOD, 1998 14] N. Pasquier, Y. Bastide, R. Taouil, and L. Lakhal. Discovering frequent closed itemsets for association rules In Proceedings of 7th ICDT, 1999 15] J.Pei, J.Han,andL.V.S.Lakshmanan.Mining frequent item sets with convertible constraints. In \(ICDE  01 pages 433  442, 2001 16] J. Pei, J. Han, and R. Mao. CLOSET: An e?cient algorithm formining frequent closed itemsets. InACMSIGMODWorkshop on Research Issues in Data Mining and Knowledge Discovery, 2000 17] J. Pei, J. Han, and J. Wang. Closet+: Searching for the best strategies for mining frequent closed itemsets. In SIGKDD  03, August 2003 18] L. D. Raedt and S. Kramer. The levelwise version space algorithm and its application to molecular fragment ?nding. In Proc. IJCAI, 2001 


ment ?nding. In Proc. IJCAI, 2001 19] R. Srikant, Q. Vu, and R. Agrawal. Mining association rules with item constraints. In Proceedings ACM SIGKDD, 1997 20] M. J. Zaki and C.-J. Hsiao. Charm: An e?cient algorithm for closed itemsets mining. In 2nd SIAM International Conference on Data Mining, April 2002 Proceedings of the Fourth IEEE International Conference on Data Mining \(ICDM  04 0-7695-2142-8/04 $ 20.00 IEEE pre></body></html 


4] K. Chang, C. Chong, Bar-Shalom, Joint Probabilistic Data Association in Distributed Sensor Networks IEEE Transactions on Automatic Control, AC-31\(10 octobre 1986 5] Bar-shalom, Multitarget Multisensor Tracking Advanced Application ,:YBS Publishing, 1990 6] Bar-shalom, Multitarget Multisensor Tracking Principles and Techenices ,:YBS Publishing, 1995 7] Hu Wenlong, Mao shiyi, Multisensor Data Association Based on Combinatorial Optimization[J]. Journal of Systems Engineering and Electronics . 1997 NO.1,1~9 8] Pattipati K R, Passive Multisensor Data Association Using a New Relaxation Algorithm.In Multitarget-Multisensor Tracking: Advanced and Applications,Y.Barshalom,Norwood,MA:Aretech,199 0 9] Deb S,et al, An S-Dimentional Assignment Algorithm for Track Initiation ,Proc. Of the IEEE Int. Conf Systems Engineering, Kobe, Japan,Sept 1992 527~530 10] Deb S,et al, A Multisensor-Multitarget Data Association Algorithm for Heterogeneous Sensors[J].IEEE Trans. on AES 1993 ,29 \(2 560~568 12] Bar-shalom,Y.,and Fortmann,T.E  Tracking and Data Association  New York:Academic press,1988 13] J,A,Roecher and G.L.Phillis,Suboptimal Joint Probabilistic Data Association .IEEE Transaction on Aerospace Electronic Systems.1993,29\(2 14] J,A,Roecker,A Class of Near Optimal JPDA Algorithm IEEE Transaction on Aerospace and Electronic Systems,1994,30\(2 15] Han Yanfei, Analysis and Improvement of Multisensor Multitarget Probabbilistic Data Association Filting Algorithm[J].  Journal of Systems Engineering and Electronics, 2002, Vol.24, 36~38  569 pre></body></html 


dense data sets for evaluating pattern mining algorithms These two data sets are obtained from IBM Almaden at http://www.almaden.ibm.com/cs/quest/demos.html. Recently, theMAFIA algorithm [6] was proposed to ef?ciently discover maximal frequent patterns. As shown in their paper, MAFIA can be several orders better than some alternatives, such as DepthProject, for mining maximal frequent patterns. Hence, we chose MAFIA as the base line for our performance evaluation. Finally, please note that only the size-2 patterns are generated in the ?rst BFS phase Experimental Platform We implemented the MHP algorithms using C++ and all experiments were performed Proceedings of the 16th IEEE International Conference on Tools with Artificial Intelligence \(ICTAI 2004 1082-3409/04 $20.00  2004 IEEE on a Pentium III    MHz PC machine with    megabytes main memory, running Linux Redhat 6.1 operating system 5.2. A Performance Comparison 100 1000 10000 100000 1e+06 1e+07 1e+08 1e+09 1e+10 1e+11 0.02 0.025 0.03 0.035 0.04 0.045 0.05 0.055 0.06 N um be r o f C he ck ed P at te rn s Support threshold Mafia Min_Conf=0 Min_Conf=0.1 Min_Conf=0.3 Min_Conf=0.5 Min_Conf=0.7 Min_Conf=0.9 


Figure 4. The Number of Checked Patterns on the Pumsb* Data Set 10 100 1000 10000 100000 0.02 0.025 0.03 0.035 0.04 0.045 0.05 0.055 0.06 R un T im e s ec  Support Threshold Mafia Min_Conf=0 Min_Conf=0.1 Min_Conf=0.3 Min_Conf=0.5 Min_Conf=0.7 Min_Conf=0.9 Figure 5. The RunTime Comparison on the Pumsb* Data Set Figure 4 shows the number of patterns that MHP and MAFIA have to check during the pattern mining process on the pumsb* data set. As can be seen, for MHP, the number of checked patterns is increased with the decrease of the h-con?dence threshold. However, the number of checked patterns of MHP can be signi?cantly smaller than that of MAFIA even if a low h-con?dence threshold is speci?ed To check a pattern, we need to count the support of the patterns. Counting the support of a pattern is the most timeconsuming task during the pattern mining process, since we need to retrieve all the transactions which include one of its sub-pattern, or for Ma?a, retrieve all the bit of the bitmap of this pattern [6]. Therefore, an algorithm is more ef?cient if smaller number of patterns need to be checked 100 1000 10000 100000 1e+06 1e+07 1e+08 1e+09 0.1 0.2 0.3 0.4 0.5 0.6 0.7 N 


um be r o f C he ck ed P at te rn s Support Threshold Mafia Min_Conf=0.5 Min_Conf=0.7 Min_Conf=0.9 Figure 6. The Number of Checked Patterns on the Pumsb Data Set 10 100 1000 10000 0.1 0.2 0.3 0.4 0.5 0.6 0.7 R un T im e s ec  Support Threshold Mafia Min_Conf=0.5 Min_Conf=0.7 Min_Conf=0.9 Figure 7. The RunTime Comparison on the Pumsb Data Set The runtime comparison of MHP and MAFIA on the Pumsb* data set is shown in Figure 5. In the ?gure, we can observe that the runtime of MHP can be signi?cantly reduced with the increase of h-con?dence thresholds. Also the runtime of MHP can be several orders of magnitude less than that of MAFIA even if the h-con?dence threshold is as low as 0.3. The reason is that the number of checked patterns of MHP is sign?cantly smaller than that of MAFIA Similar results are also obtained from the pumsb data set as shown in Figure 6 and Figure 7. For the pumsb data set the number of checked patterns of MHP is much smaller 


than that of MAFIA and the runtime of MHP can be significantly less than that of MAFIA 5.3. The Effect of the MHP Algorithm on Finding Maximal Hyperclique Patterns Figure 8 and Figure 9 show the number of maximal patterns identi?ed byMHP andMAFIA on Pumsb* and Pumsb data sets respectively. As can be seen, the number of maximal hyperclique patterns identi?ed by MHP can be orders of magnitude smaller than the number of maximal frequent patterns identi?ed by MAFIA. In other words, the number Proceedings of the 16th IEEE International Conference on Tools with Artificial Intelligence \(ICTAI 2004 1082-3409/04 $20.00  2004 IEEE 100 1000 10000 100000 1e+06 1e+07 1e+08 1e+09 0.02 0.025 0.03 0.035 0.04 0.045 0.05 0.055 0.06 N um be r o f C ou nt ed P at te rn s Support Threshold Mafia Min_Conf=0 Min_Conf=0.1 Min_Conf=0.3 Min_Conf=0.5 Min_Conf=0.7 Min_Conf=0.9 Figure 8. The Number of MFI/MHP Patterns in the Pumsb* Data Set 100 1000 10000 100000 1e+06 


1e+07 1e+08 0.1 0.2 0.3 0.4 0.5 0.6 0.7 N um be r o f C ou nt ed P at te rn s Support Threshold Mafia Min_Conf=0.5 Min_Conf=0.7 Min_Conf=0.9 Figure 9. The number of MFI/MHP Patterns in the Pumsb Data Set of maximal hyperclique patterns is much easier to manage than that of maximal frequent patterns. Indeed, in realworld applications, it is dif?cult to interpret several million maximal frequent patterns. However, it is possible to interpret the results of maximal hyperclique pattern mining In addition, due to the memory limitation, we cannot extract maximal frequent patterns with MAFIA on the Pumsb data set if the support threshold is less than 0.4, as shown in Figure 7. In contrast, MHP can identify maximal hyperclique patterns when the support threshold is 0.1, if we set the h-con?dence threshold to 0.5. In other words, MHP has the ability to identify patterns which can be dif?cult to identify for MAFIA. Hence, MHP can better explore the pattern space and ?nd interesting patterns at low levels of support 6. Conclusions and Future Work In this paper, we present a two-phase Maximal Hyperclique Pattern \(MHP best features of both the BFS strategy and the DFS strategy. More speci?cally, we adapted DFS pruning methods such as equivalence pruning, to an apriori-like approach In addition, we proved the correctness and completeness of the MHP algorithm. Finally, our experimental results show that the MHP algorithm can be several orders of magnitude faster than standard maximal frequent pattern mining algorithms and has the ability to identify patterns at extremely low levels of support in dense data sets There are several directions for future work. First, in 


this paper, we only generate the size-2 patterns in the BFS phase. It will be interesting to investigate the impact on the performance if the ?rst phase is stopped at a deeper level Also, the projection is a very ef?cient method for ?nding patterns, especially for parallel implementation of pattern mining algorithms [1]. We plan to adapt the projection ideas into our algorithm and design an ef?cient parallel algorithm for mining maximal hyperclique patterns References 1] R. Agarwal, C. Aggarwal, and V. Prasad. A Tree Projection Algorithm For Generation of Frequent Itemsets. pages 350 371, Feb 2001 2] R. Agrawal, T. Imielinski, and A. Swami. Mining Association Rules between Sets of Items in Large Databases. In Proc. of the ACM SIGMOD Conference on Management of Data, pages 207216,May 1993 3] R. Agrawal and R. Srikant. Fast Algorithms for Mining Association Rules. In Proc. of the 20th Intl Conference on Very LargeData Bases, 1994 4] R. Bayardo. Ef?ciently mining long patterns from databases In Proc. of the ACM SIGMOD Conference, 1998 5] R. Bayardo and R. Agrawal. Mining the Most Interesting Rules. In Proc. of the ACM SIGKDD Conference, 1999 6] D. Burdick, M. Calimlim, and J. Gehrke. Ma?a: AMaximal Frequent Itemset Algorithm for Transactional Databases. In Proc. of IEEE Conf. on Data Engineering, 2001 7] Y. Huang, H. Xiong, W. Wu, and Z. Zhang. A Hybrid Approach for Mining Maximal Hyperclique Patterns. In In Technical Report UTDCS-34-04, Department of computer science, University of Texas - Dallas, 2004 8] J.Han, J.Pei, and Y. Yin. Mining Frequent Patterns without Candidate Generation. In Proc. of the ACM SIGMOD International Conference on Management of Data, 2000 9] M.J.Zaki and C.Hsiao. ChARM: An ef?cient algorithm for closed itemset mining. In Proc. of 2nd SIAM International Conference on Data Mining, 2002 10] R.Rymon. Search through Systematic Set Enumeration. In Proc. Third Intl Conference on Principles of Knowledge Representation and Reasoning, 1992 11] H. Xiong, M. Steinbach, P.-N. Tan, and V. Kumar. HICAP: Hierarchial Clustering with Pattern Preservation. In Proc. of 2004 SIAM International Conference on Data Mining \(SDM 12] H. Xiong, P.-N. Tan, and V. Kumar. Mining Strong Af?nity Association Patterns in Data Set with Skewed Support. In Proc. of the Third IEEE International Conference on Data Mining \(ICDM Proceedings of the 16th IEEE International Conference on Tools with Artificial Intelligence \(ICTAI 2004 1082-3409/04 $20.00  2004 IEEE 





