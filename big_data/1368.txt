Using Concept Maps as a Cross-Language Resource Discovery Tool for Large Documents in Digital Libraries Ryan Richardson  Edward A. Fox Virginia Tech Digital Library Research Laboratory Blacksburg, Virginia 24061 USA 1-540-231-3615 ryanr, fox@vt.edu  Categories and Subject Descriptors  H.3.7 Information Storage and Retrieval   In f o rm at i o n S earch  and Retrieval information filtering, search process General Terms  Algorithms, Experimentation, Human Factors Keywords 
 Concept maps, crosslingual information retrieval, automatic summarization ABSTRACT Project Gutenburg, the Million Book Project, the Networked Digital Library of Theses and Dissertations, Amazons book search service, and the recently announced collaboration of Google and leading libraries, all aim to make available large numbers of book-length objects, in a variety of languages Traditional approaches to discovering a suitable book for a particular purpose have generally relied on catalog records sometimes enhanced with abstracts. Full-text searching 
popular, e.g., with legal and government documents  and passage retrieval techniques, suitable for encyclopedias and reference works, have not been adequately tested with large collections of large objects  Figure 1: Automatically generated We demonstrate an alternative approach, integrating visualization text mining, and simple machine translation techniques.  We show how electronic theses and dissertations \(ETDs\, in both English 
and Spanish, can be summarized as concept maps, according to three different design layouts: whole document maps, chapterlevel maps, and table of contents-based maps.  Our initial experiments are in the computer science and industrial systems engineering fields  Concept maps \(see Figure 1\ are graphical representations of knowledge that are comprised of concepts and the relationships between them [4  C onc e p t m a ps a llow s t ude nts to a c quir e  knowledge more quickly than usual [2  H o w e v e r  c onc e p t m a ps  have yet to be extensively researched as aids to knowledge 
discovery. Our demonstration will show how this can work including for multi-lingual collections. We argue that 1\rs can more quickly grasp the key ideas of a work from a concept map than from an abstract alone; 2\it is easier to automatically generate concept maps than good abstracts; and 3\ it is easier to automatically translate concept maps than abstracts We have tested several methods of finding relations in the texts such as association rules [1   t sco r es  P earso n  s  2 Dices coefficient, and mutual information. Using part-of-speech 
information from MontyTagger [3  w e can f i n d n o u n p h r ases which appear as nodes in the maps.  Other parts-of-sp eech usually verbs or prepositions, are used as the links between the nodes.  Our demonstration highlights these techniques ACKNOWLEDGMENTS This work was partially supported by NSF grants DUE-0121679 and IIS-0080748, and by SAIC as part of the Research and Development Experimental CollaborationApplied Research Center.  We also would like to thank Marcos Gonalves, Rao 
Shen, and Jess Trespalacios who assisted with user experiments REFERENCES 1  A g ra w a l, R. a n d Srik a n t, R Fast Algorithms for Mining Association Rules in Large Databases Presented at 20th International Conference on Very Large Databases VLDB'94\, Santiago, Chile, Sept. 1994 2  Ch m i el ew ski  T  L  an d Dan s ereau  D F   Enhancing the recall of text: Knowledge mapping training promotes implicit transfer Journal of Educational Psychology, vol 90\(3\, pp. 407-413, Sept. 1998 3  L i u, H   M onty T a g g e r  1.2 e d C a m b r i dg e  Ma s s  2003 
http://web.media.mit.edu/~hugo/montytagger  4  No vak, J. D. an d G o w i n  D. B Learning How To Learn  Cambridge, UK, Cambridge University Press, 1984  Copyright is held by the author/owner\(s JCDL05 June 711, 2005, Denver, Colorado, USA ACM 1-58113-876-8/05/0006 


examine the network faults, and predict severe faults The advantage of using the techniques of association rules mining is that the availability of the network topological structure is not required. When the topological structure changes, the system can analyze according to the history of alarms and find new correlation rules about alarms automatically, so the correlation alarm system based on associated rule mining can adjust very quickly to adapt to some variable telecommunication networks and solve new problems in these networks. Methods based on data mining have better compatibility Most of the previous research of alarm correlation didnt consider the correlation between the generation and the release of alarms. Recent years, we focus on how to use the correlation between alarm time and clear time of the alarm to reorganize alarm data so that better mining result will be obtained. In our previous work [12  w e p r o p o s ed a n a p p r o a ch  t o co m b i n e th e correlated alarms to form an alarm transaction. The approach not only solves the problem of asynchrony of correlated alarm in the network, but also discards many redundant data, and reduces the volume of alarm data and the number of rules in the result. In this paper, we have improved our previous approach by adding alarm sequence analysis. The experiments show that the improved method reduces the volume of alarm data further and obtains better results. In the section 4, well show some results of our experiments Comparing with other methods 4] [5 6 7  our method has the following features Versatile: All this analysis method needs is the general historical records of alarm data. It does not need any information about the topological structure of the network and can be used in different telecommunication networks Easy implementation: After preprocessing, the data can be processed directly with general association rule mining algorithms [8  9   1 0  o r  sequential pattern mining algorithms 1 1] f o r the task of mining association rules about alarms Accuracy: During organizing alarm transactions this method considers not only the time of detecting alarms, but also the time of releasing alarms. The reorganization of raw alarm records to set up a set of alarm transactions discards most redundant data, task-irrelevant data and almost all of noisy data. Therefore, the mining results will be better Clear results: The mined association rules reflect the correlation between different alarms and different alarm devices The rest of the paper is arranged as follows. In section 2, the basic form of alarm data is described. In section 3, a method of alarm correlation analysis is proposed. Finally, some experiment results and a summary are given in the section 4 and 5 respectively 2. Alarms Data Telecommunication network problems are anomalies of electric devices or software modules in the network. The system status changes during these situations, then alarm events are triggered. Normally a telecommunication network alarm contains the names and types of devices whose system situation changes symptoms of anomalies, the time and alarm levels without the detailed data of places and reasons for the detection of these anomalies. Telecommunication networks consist of many types of devices, so anomaly of one part could affect many other devices and cause alarms from many devices, or alarms from the same device repetitively. A huge number of alarms have provided us abundant data for data mining, because these data recorded the changes of related parts in this system. All kinds of rules for the anomalies are just behind the historical records for alarms To analyze and process an alarm message, it is required that this message contains the part name for this alarm, the detailed error message, and the error time. Normally professional network management systems have the functions of receiving, saving, and searching alarms. These data can be obtained from the alarm list. Table 1 displays the data attributes in a general alarm list, which is used as the dataset for alarm association rule mining. For example, in the instance for Table 2, the TID: LCJT01/NALC01A represents the name of a device in the local network in Quanzhou, this name is required during the solution of this problem to determine where this error happens and other related information; NEtype: ISM4RDI shows that this transmission device is a ISM \(Intelligent Sync Mux and software data are up and down, it describes the type of this device, so is not very useful for the treatment of alarms; address: TP7.14 shows that a component of that device to generate information directly, TP shows that the type is a branch unit disk, 7 represents the seventh disk and 14 represents the fourteenth branch; EntityType: CEPT1 means that the port for TP7.14 is 2M Severity: INFO shows that the type of this alarm is information, a low-level alarm Levels for alarms are used to remind network administrators of whether a quick reaction is required with these alarm levels maintenance technicians can figure out the deadline for the repair. Levels can be CRITICAL PROMPT DEFFERD INFO CLEARD \(from high to low\, for which the relationship between CLEARD and others is generation versus release. In Table 2, the first record shows the generation of an alarm, while the third 


record displays the release of the same alarm Condition PFcREM shows that the signal is bad and the error is sending signals of alarm parts and receiving signals of distant devices. This message is required during the solution of this problem so that the specific position of the error is determined and maintenance technicians are sent to where the error happens ServiceAffect: NSA\(no service affected\ shows that the alarm does not affect the use of that network, SA service affected means that it is affected, this definition is different for different manufacturers, so it is not very useful; For EventTime, 2004-12-01 23:59:55 in Record No. 1 means December 1st 2004 and 23 59 55 is the time of receiving that alarm 2004-12-02 0: 09:20 in Record No. 3 means December 2nd, 2004 and 0 09 20 is the time of releasing that alarm Actually TID, ADDRESS, CONDITION, and EventTime are the main attributes for the analysis and treatment of specific alarms and locating an error. We have to know the names of network unit devices and related components so that we can find the specific physical device and the port position; we have to know the detailed information to determine the possible problems and find feasible solutions; we have to know the time of generating an alarm to analyze the alarm and master the treatment and timing requirement for that alarm Table 1: Main data attributes for alarms ID Attribute Name Description  1 TID The name of devices which generate the alarms 2 NEType The type of network devices 3 Address The port positions and the specific units 4 EntityType The port property, e.g., EPT1 5 Condition Detailed description of alarms 6 Severity The alarm level 7 EventTime The time for events 8 SeviceAffect Whether the work is disturbed, NSA or SA Table 2: Some examples of alarms Tid Netype Address Entity Type Severity Condition Service affecting status Eventtime LOCALHTMUXONE/02 ISM4RDI TP6.16 CEPT1 INFO PFcAIS SA 2004-12-01 23:59:55 LCJT01/NALC01A ISM4RDI TP7.14 CEPT1 INFO PFcREM NSA 2004-12-02 0:01:03  LOCALHTMUXONE/02 ISM4RDI TP6.16 CEPT1 CLEARD PFcAIS SA 2004-12-02 0:09:20 3. Alarm Association Rules Mining 3.1. Association Rules Mining Association rule mining searches for interesting association rules that describe the dependence and relationship between different objects in the given data and the basic concept of association rules is [8 Let I= {i 1 i 2   i m be a set of items. Let D, the task-relevant data, be a set of database transactions where each transaction T is a set of items such that T  I. Each transaction is associated with an identifier called TID. Let A be a set of items. A transaction T is said to contain A if and only if A  T An association rule is an implication of the form A  B, where A  I, B  I, and A  B  The rule A  B holds in the transaction set D with support s and 


confidence c, where s is the percentage of transactions in D that contain A  B, and c is the percentage of transactions in D containing A that also contain B The problem of association rule mining is to find all association rules with support and confidence greater than or equal to a user-specified support and confidence from a given set of transactions 3.2. A Method of Alarm Association Rules Mining A fault of the networks may incur many alarms There are several reasons for generating many alarms For example, a single fault may be detected by multiple network components, then each one of them emits an alarm notification; a fault of a component may affect several other components, causing the propagation of this fault; a fault may be intrinsically intermittent which implies in the sending of a notification at each new occurrence, etc. Many association relationships do exist among alarms However, we cannot apply the association rule mining algorithm to sets of raw alarms directly, because the alarms that are incurred by the same fault are not guaranteed to be synchronous, in other words, the values of EventTime of these alarms are different and the set of raw alarms may contain some incorrect attribute values, incomplete data or some alarms which are irrelevant to the correlated alarm sequence. Dirty data can cause confusion for the mining procedure resulting in unreliable output Based on an in-depth study of the features of alarms, we propose the following preprocessing techniques 1\ Extract Tid, Address, Condition, alarm time \(the EventTime of generating the alarm\ and cleared time \(the EventTime of clearing the alarm\ for each raw alarm from alarm database of telecommunication network management system Here the cleared time of an alarm exists among its subsequent alarms. It can be identified and extracted from the subsequent alarms. For example in table 2, the cleared time of the first alarm is the EventTime of the alarm in the fourth row 2\ Combine Tid, Address and Condition as a complexitem. We have to know the names of network unit devices and related components so that we can find the specific physical device and the port position and we have to know the detailed information to determine the possible problems and find feasible solutions 3\ Define a transaction time interval to deal with the asynchronous problem of alarms. The alarms whose values of EventTime are within the same short time interval may be incurred by the same fault 4\ Reorganize alarm transactions. Combine all the alarms with the following conditions to form an alarm transaction The values of alarm time are within the same time interval The values of cleared time are within the same time interval Their orders are the same Base on above preprocessing techniques, we propose a method for alarm association Rule mining The method is described as follows Let TID+ADDRESS+CONDITION be an alarm item, namely an alarm item is a complex item consisting of values of attribute TID  ADDRESS and CONDITION of an alarm. Let L be the length of a time interval Let AD the task-relevant data, be a set of alarm transactions where each alarm transaction AT is a sequence of alarm items, which consists of all alarm items with alarm time within the same time interval cleared time within the same time interval and their orders are the same For example: for 4 alarms in table 2, which are extracted from a raw alarm database, 2 alarm transactions will be formed \(in table 3\, if L=2 minutes Obviously, reorganizing raw alarm records to set up a set of alarm transactions will discard most redundant Table 2: four alarms extracted from a raw alarm database No. TID+ADDRESS+CONDITION Alarmtime Cleartime  1000 LCJT01/NALC01A+TP7.14+PFcREM 2004-12-01 0:07:42 2004-12-1 0:27:52 1001 LCJT01/CNCLB01 +TP5.4+HcLOS 2004-12-01 0:08:00 2004-12-1 0:28:11 1002 LOCALAXMUXFOUR/03+TP6.9+PFcAIS 2004-12-01 23:59:01 2004-12-2 0:09:33 1003 LOCALTMMUXTHREE/03+TP8.15+PFcREM 2004-12-01 23:59:02 2004-12-2 0:09:34 


Table 3: two alarm transactions ATID Alarm items sequence  0001 LCJT01/NALC01A+TP7.14+PFcREM, LCJT01/CNCLB01 +TP5.4+HcLOS 0002 LOCALAXMUXFOUR/03+TP6.9+PFcAIS, LOCALTMMUXTHREE/03+TP8.15+PFcREM data, task-irrelevant data and almost all the noisy data Let A be a sequence of alarm items. An alarm transaction AT is said to contain A if and only if A is a subsequence of AT  An alarm association rule is an implication of the form A  B where both A and B are sequences of alarm items, and they do not contain any same alarm item The rule A  B holds in the alarm transaction set AD with support s and confidence c where s is the percentage of alarm transactions in AD that contain A  B and c is the percentage of transactions in AD containing A that also contain B Given a set of alarm transactions AD the problem of alarm association rule mining is to find all alarm association rules with support and confidence greater than or equal to a user-specified support and confidence from AD  4. Experiments 4.1. Data Preparation The preparation of data is a necessary step for data mining, and it is very important for whether data mining can succeed. In our experiments, we collected more than 70,000 raw alarm recorders from a local telecommunication network management system in Quanzhou, Fujian, China. The time of alarm events ranges from 2004-12-01 to 2005-03-01. In order to discover useful alarm association rules in the sequence of alarms, we have finished following tasks of data preprocessing 1. Extract the values of Tid, Address, Condition, alarm time and cleared time for each raw alarm 2. Set up a set of alarm transactions. Let L=2 minutes then an alarm transaction is a sequence of alarm items consisting of all alarm items with alarm time within the same time interval of 2 minutes, and cleared time within the same time interval of 2 minutes, their orders are  the same After data preprocessing, we have established an alarm transaction database with 8,213 transactions Next we can apply general association rule mining algorithms and sequence analysis techniques for the task of finding alarm association rules directly 4.2. Mining Alarm Association Rules There are several ways to implement the method of alarm association rule mining which has been described above. In the experiments, we considered 2 solutions. The first solution is to modify Apriori algorithm  t o f i n d  a f r e que nt s e que n c e o f a l a r m  items and then generate alarm association rules from found frequent sequence of alarm items. The second solution is to use the association rule mining function of IBM DB2 Intelligent Miner to generate association rules among alarm items and then filter out all rules that do not satisfy the definition of alarm association rule Set Min_supp as 1%, min_conf as 25%. Using the second solution, the alarm association rules we got are shown in figure 1, totally 137 rules Figure 1 alarm association rules 


4.3. Analysis Result Most rules reflected the correlation of alarms and network devices, as what we expected For example, the rule [DONGHAIDP/50  LOCALXPMUXTWO/02 s h o w s t h a t t h e d e v i c e  DONGHAIDP/50 has high alarm correlation with another device LOCALXPMUXTWO/02, after the examination, we know that the reason is that there are many pathways between these two devices Here is another example, given the rule [ NANANLD 31 + TP7.12 + HcLOS  NANANMS / 10 TP7.12 + PFcREM it is clear that the alarm HcLOS from the part TP7.12 of NANANLD/31 triggered the alarm PFcREM of the part TP7.12 of NANANMS/10 this correlation rule displays two facts:  The correlation between network resources NANANLD/31+TP7.12 and NANANMS/ 10+TP7.12 are correlative in the network.  The correlation of alarms: the alarm HCLOS is correlative with the alarm PFCREM According to the analysis of experienced maintenance men, this method included the time of clearing alarms, which is very effective for this problem but ignored in all the previous studies. We filtered out 12 useless rules from the 137 rules according to the following knowledge of telecommunication: \(1\ Alarms for physically disconnected devices are irrelevant. \(2\ A high-level alarm will never trigger a low-level alarm. \(3 Different types of devices without logical correlation are irrelevant. It shows that our results are very accurate 5. Summary Based on an in-depth study of the features of alarms, this paper proposed a method of alarm association rules mining which is based on association rule mining and alarm sequence analysis. We used C++ to develop a program for preprocessing alarm data and implemented the functions for the selection of time interval, the detection of releasing alarms, etc., so that the raw alarms are reorganized as a series of alarm transactions. Experiment results showed that alarm event sets after processing can be used with common association rule mining tools for the task of alarm association rule mining, so the method of alarm correlation analysis proposed in this paper is practical and has some innovation In the next step, we will select raw alarms for different time periods for data mining, sort mined alarm correlation rules statistically, obtain the count table for alarm correlation rules, invite professional maintenance technicians to help us to analyze the results, filter the mined rule sets, and discover useful alarm rules, then study automatically filtering and processing of mined results Acknowledge: This research was partly supported by the research grant from Oversea Chinese Affairs Office of Chinese State Council No.03QZR5 and Science and Technology Office of Fujian Province, China \(No.2004I014 6. References 1 H o n g S h eng Q i an  R es ear c h o n  Me t h o d o f Mo del  Telecommunication Management \(in Chinese\, http www.gxlu.com.cn 2 B i n g L i ang  B R M  T h e ap pl i c at i o n o f new t e c hno l o gy t o  Industry \(in Chinese\, Computer World, 2003, N0.14 3 n i s e W Gu e r L r fa n k h a n R i c h a r d Og i e r A n  Artificial Intelligence Approach to Network Fault Management, http://www.sce.carleton.ca/netmanage/docs An_AI_ Approach.pdf 4 H a t o nen K  K l em e t t i n en  M m a n i l a H e t  al  K no w l e d g e  Discovery from Telecommunication Network Alarm Database, Proceedings of the 12th international conference on Data Engineering \(ICDE96\, New Orleans, Louisiana 5 H  t  ne n  K   K l e m et t i ne n M   M a nn i l a H   R o n k a i n en  P   Toivonen. H., TASA. Telecommunications Alarm Sequence Analyzer, Proceedings of IEEE/IFIP Network Operations and Management Symposium \(NOMS96\, 520-529, Kyoto Japan, April 1996 6 Q i n ggu o Z h e n g K e X u  Wei f e n g L v  Sh i l on g M a   Intelligent Search of Correlated Alarms from Database Containing Noise Data, Proceedings of IEEE/IFIP 2002 Network Operations and Management Symposium NOMS'2002\, Florence, Italy, April 2002 7 Q i ng G u o Z h eng  W e i F eng L v  R es ear c h o n A l ar m  Correlation of Telecommunication Network \(in Chinese Computer Engineering and Application, 2002.2 8 J i a w ei H a n  a n d Mi ch el i n e K a m b er   Data Mining Concepts and Techniques Morgan Kaufrmann Publishers 9 A  S a va se r e  E  O m i e ci n s ki  a n d S N a vat h e   A n  Efficient Algorithm for Mining Association Rules in Large Databases, Proceedings of VLDB Conference, 1995 pp.432-444  S S a r a w a g i  S T h o m as   and R  A g r a w a l   I nt eg r a t i ng  Association Rule Mining with Relational Database Systems Alternatives and Implications, Proceedings of ACM SIGMOD Intl Conference on Management of Data, 1998 pp. 343-354  A G R A WA L  R    S R I K A N T  R   M i n i n g S e q u en t i al  Patterns. Proceedings International Conference on Data Engineering \(ICDE'95\, Taipei, Taiwan, 3-14  Y a ng Y a ng W u  H u a i N a n C H E N  A n A sso c i at i o nR u l e  Based Model for Telecom Alarm Correlation Analysis Journal of Communication and Computer \(in traditional Chinese\, 2004.12 


2?  value according to the relationship between the local and global maximum 2?  values for current rule and database. The dilation procedure is nonlinear and empirically achieved excellent results, which will be demonstrated in next section     2                     where lmax D lmax gmaxdia 2 Therefore           lmax D dia The parameter ? is used to control the impact of global and local maximum 2?  values and tuned for different classification problems. The dilated 2 values for the three rules are respectively 117.0, 136.1 and 95.1 if 5.0=? , which is much more reasonable to our intuition. For a given training dataset, the size of D is fixed and irrelevant to the ranking of interestingness of rules It is visible that the dilated 2?  value is sensitive when the size of s\(Y these rules with high confidence and very low support dilate 2?  values estimate their interestingness in a more cautious way We now adapted CBA by taking intensity of implication and dilated 2?  respectively as the primary criteria when do the ranking work. Rule ri has a higher rank than rule rj if it has a larger value of intensity of Proceedings of the 2005 IEEE International Conference on e-Business Engineering \(ICEBE  05 0-7695-2430-3/05 $20.00  2005 IEEE 


0-7695-2430-3/05 $20.00  2005 IEEE implication \(or dilated 2 same values of intensity of implication \(or dilated 2 mechanism of the original CBA, which is mentioned in section 2.2 4. Empirical Section This part is to validate our adapted CBA algorithms on three credit scoring datasets in table 1. In order to get a more comprehensive evaluation, these datasets are also classified by original CBA, the classical decision tree technique C4.5 [14] and Neural Network three layers and Back propagation employed parameter ?  in dilated chi-square and the number of neurons in hidden layer were tuned for best classification accuracy. C4.5 and Neural Network were implemented by the software package of WEKA [15 The number of The continuous attributes are discretized based on entropy [16] if needed datasets Inputs \(con./dis Austr 14\(6/8 Germ 20\(7/13 Bene 28\(18/10 Table 1. Credit scoring datasets Among these three datasets, Austr and Germ are from UCI repository datasets [17], and Bene is from one major financial institution in the Benelux Belgium, The Netherlands and Luxembourg the dataset size of Austr and Germ are no more than 1000, 10-cross validation method was applied to evaluate the classification performance so as to reduce the fluctuations that stem from random sampling. For dataset Bene, 2/3 of its samples were taken as the training set and 1/3 of them as test set As shown in Table 2, adapted CBA 1 and CBA 2  which correspond to the adapted CBA algorithms that incorporate intensity of implication and dilated 2 respectively, perform well with respect to classification accuracy and number of rules they generated \(for Austr and Germ, the number of rules are the average results of 10-cross validation carried out on Bene in a train/test way, McNemar test 18] are employed to examine whether the predictive performance of these algorithms are significantly different with each other. The test results are listed as follows Original CBA Adapted CBA1 Adapted CBA2 C45 NN Original CBA 1.000 0.393 0.554 0.005 0.752 Adapted CBA1 1.000 0.221 0.038 0.718 Adapted CBA2 1.000 0.001 0.377 C45 1.000 0.019 NN 1.000 Table 3. McNemar test on dataset Bene The p-values in table 3 reveals that there are no significant differences among original CBA, adapted CBA and Neural Networks at 1% confidence level 


CBA and Neural Networks at 1% confidence level while they are all significantly better than C4.5 decision tree. Taking the interpretability of classification model into account, these two adapted CBA algorithm seem to be appropriate choices for credit scoring because they generated much more compact decision lists \(less sequential rules original CBA. They therefore favour the well-known Occam  s Razor theory and are more suitable for decision makers to understand. A deeper insight into the rules structures shows that original CBA and adapted CBA 1 both focus on generating classification rules that predict good clients \(with bad clients as the default class implication, numerous rules with high confidence but low support have lower ranks than they are in original CBA. These rules are finally discarded since they are not fired by any training samples, which are matched by these rules with higher intensity of implications thus making the decision lists generated by adapted CBA 1 more compact. Adapted CBA 2 mainly mines these classification rules for bad clients \(with good clients as the default class compact rule sets Original CBA Adapted CBA1 Adapted CBA2 C45 NN dataset accuracy no. of rules accuracy num. of rules accuracy no. of rules accuracy accuracy 1 Austr 85.65% 130.5 86.52% 26.4 86.96% 12.4 86.52% 85.07 2 Germ 73.30% 134 74.40% 56.5 73.20% 19.7 72.40% 74.90 3 Bene 72.92% 393 72.30% 186 73.51% 51 70.21% 72.63 Table 2. Experiment results Proceedings of the 2005 IEEE International Conference on e-Business Engineering \(ICEBE  05 0-7695-2430-3/05 $20.00  2005 IEEE In addition, decision makers in financial institution certainly pay more attentions to those rules that predict bad clients, which will be extraordinary costly if they are regarded as good ones 5. Conclusion Intensity of implication is proposed in the beginning as an interestingness measure for association rules Another novel interestingness measure called dilated chi-square is designed by us to reveal the statistical interdependence between the antecedents and consequents of association rules We then adapt CBA algorithm, which can be used to build classifiers based on class association rules, by coupling it with intensity of implication and dilated chi-square respectively. More concretely, Intensity of implication \(or dilated chi-square primary criterion to rank class association rules at the first step of the database coverage pruning procedure in CBA algorithm. Experiments on three credit scoring datasets proved that these two adapted algorithms compared with original CBA, classical C4.5 decision tree and neural network, achieve satisfactory performance and generates classifiers much more compact than CBA 6. Acknowledgement The work was partly supported by National Natural Science Foundation of China \(70231010/70321001 7. References 1] Wang, K. and S. Zhou, Growing decision trees on support-less association rules. in KDD'00. 2000. Boston,MA 2] Liu, B., W. Hsu, and Y. Ma, Integrating Classification and Association Rule Mining. in the 4th International Conference on Discovery and Data Mining. 1998. New 


Conference on Discovery and Data Mining. 1998. New York,U.S 3] Dong, G., et al, CAEP:Classification by aggregating emerging patterns. in 2nd International Conference on Discovery Science,\(DS'99 Artificial Intelligence. 1999. Tokyo,Japan: Springer-Verlag 4] Liu, W., J. Han, and J. Pei, CMAR: Accurate and efficient classification based on multiple class-association rules. in ICDM'01. 2001. San Jose, CA 5] Yin, X. and J. Han, CPAR:Classification based on predictive association rules. in 2003 SIAM International Conference on Data Mining \(SDM'03 Fransisco,CA 6] Agrawal, R. and R. Srikant, Fast algorithm for mining association rules. in the 20th International Conference on Very Large Data Bases. 1994. Santiago,Chile 7] Agrawal, R., T. Imielinski, and A. Swami, Mining association rules between sets of items in large databases. in the ACM SIGMOID Conference on Management of Data 1993. Washington,D.C 8] Guillaume, S., F. Guillet, and J. Philippe, Improving the discovery of association rules with intensity of implication Principles of Data Mining and Knowledge Discovery, 1998 1510: p. 318-327 9] Janssens, D., et al, Adapting the CBA-algorithm by means of intensity of implication. in the First International Conference on Fuzzy Information Processing Theories and Applications. 2003. Beijing, China 10] Gras, G. and A. Lahrer, L'implication statistique: une nouvelle methode d'analysis de donnees. Mathematiques Informatique et Sciences Humaines n 20, 1993 11] Suzuki, E. and Y. Kodratoff, Discovery of  surprising exception rules based on intensity of implication. in PKDD'98. 1998. Berlin: Springer 12] Mills, F., Statistical Methods. 1955: Pitman 13] Lan, Y., et al, Dilated Chi-square: A novel interestingness measure to build accurate and compact decision list. in International conference on intelligent information processing. 2004. Beijing,China 14] Quinlan, J.R., C4.5 programs for machine learning 1993: Morgan Kaufmann 15] Witten, I.H. and E. Frank, Data Mining: practical machine learning tools and techniques with Java implementations. 2000: Morgan Kaufmann, San Francisco 16] Fayyad, U.M. and K.B. Irani, Multi-interval discretization of continuous valued attributes for classification learning. in the Thirteenth International Joint Conference on Artificial Intelligence \(IJCAI Chambery,France: Morgan Kaufmann 17] Blake, C.L. and C.J. Merz, UCI repository of machine learning databases http://www.ics.uci.edu/~mlearn/mlrepository.htm]. 1998 Irvine,CA:University of California, Dept. of Information and Computor Science 18] Dietterich, T.G., Approximate statistical tests for comparing supervised classification learning algorithms Neural Computation, 1998. 10\(7 Proceedings of the 2005 IEEE International Conference on e-Business Engineering \(ICEBE  05 0-7695-2430-3/05 $20.00  2005 IEEE pre></body></html 


absolute values. The results can vary on other computers. But it can be guaranteed that performance ratio of the algorithms will remain the same After making the comparisons with sample data, we came to the conclusion that PD algorithm performs significantly better than the other two especially with larger datasets. PD outperforms DCP and PIP regarding running time. On the other hand, since PD reduces the dataset, mining time does not necessary increase as the number of transactions increases and experiments reveals that PD has better scalability than DCP and PIP. So, PD has the ability to handle the large data mine in practical field like market basket analysis and medical report documents mining 5. References 1] R. Agrawal and R. Srikant, "Fast algoritlnns for mining association rules", VLDB'94, pp. 487-499 2] R. J. Bayardo, "Efficiently mining long patterns from databases", SIGMOD'98, pp.85-93 3] J. Pei, J. Han, and R. Mao, "CLOSET: An Efficient Algorithm for Mining Frequent Closed Itemsets \(PDF Proc. 2000 ACM-SIGMOD International Workshop on Data Mining and Knowledge Discovery, Dallas, TX, May 2000 4] Qinghua Zou, Henry Chiu, Wesley Chu, David Johnson, "Using Pattern Decomposition\( PD Finding All Frequent Patterns in Large Datasets", Computer Science Department University of California - Los Angeles 5] J. Han, J. Pei, and Y. Yin, "Mining Frequent Patterns without Candidate Generation \(PDF  SIGMOD International Con! on Management of Data SIGMOD'OOj, Dallas, TX, May 2000 6] S. Orlando, P. Palmerini, and R. Perego, "The DCP algoritlnn for Frequent Set Counting", Technical Report CS2001-7, Dip. di Informatica, Universita di Venezia 2001.Available at http://www.dsi.unive.itl?orlando/TR017.pdf 7] MD. Mamun-Or-Rashid, MD.Rezaul Karim, "Predictive item pruning FP-tree algoritlnn", The Dhaka University  Journal of Science, VOL. 52, NO. 1, October,2003, pp. 3946 8] Park, J. S., Chen, M.-S., and Yu, P. S, "An Effective Hash Based Algoritlnn for Mining Association Rules", Proc ofthe 1995 ACM-SIGMOD Con! on Management of Data 175-186 9] Brin, S., Motwani, R., Ullman, J., and Tsur, S, "Dynamic Itemset Counting and Implication Rules for Market Basket Data", In Proc. of the 1997 ACM-SIGMOD Conf On Management of Data, 255-264 10] Zaki, M. J., Parthasarathy, S., Ogihara, M., and Li, W New Algoritlnns for Fast Discovery of Association Rules In Proc. of the Third Int'l Con! on Knowledge Discovery in Databases and Data Mining, 283-286 11] Lin, D.-I and Kedem, Z. M., "Pincer-Search: A New Algoritlnn for Discovering the Maximum Frequent Set", In Proc. of the Sixth European Conf on Extending DatabaseTechnology, 1998 12] R. Ramakrishnan, Database Management Systems University of Wisconsin, Madison, WI, USA; International Edition 1998 pre></body></html 


tors such as union, di?erence and intersection are de?ned for pairs of classes of the same pattern type Renaming. Similarly to the relational context, we consider a renaming operator ? that takes a class and a renaming function and changes the names of the pattern attributes according to the speci?ed function Projection. The projection operator allows one to reduce the structure and the measures of the input patterns by projecting out some components. The new expression is obtained by projecting the formula de?ning the expression over the remaining attributes [12 Note that no projection is de?ned over the data source since in this case the structure and the measures would have to be recomputed Let c be a class of pattern type pt. Let ls be a non empty list of attributes appearing in pt.Structure and lm a list of attributes appearing in pt.Measure. Then the projection operator is de?ned as follows ls,lm c id s m f p ? c, p = \(pid, s, d,m, f In the previous de?nition, id ing new pids for patterns, ?mlm\(m projection of the measure component and ?sls\(s ned as follows: \(i s usual relational projection; \(ii sls\(s and removing the rest from set elements. The last component ?ls?lm\(f computed in certain cases, when the theory over which the formula is constructed admits projection. This happens for example for the polynomial constraint theory 12 Selection. The selection operator allows one to select the patterns belonging to one class that satisfy a certain predicate, involving any possible pattern component, chosen among the ones presented in Section 5.1.1 Let c be a class of pattern type pt. Let pr be a predicate. Then, the selection operator is de?ned as follows pr\(c p Join. The join operation provides a way to combine patterns belonging to two di?erent classes according to a join predicate and a composition function speci?ed by the user Proceedings of the 16th International Conference on Scientific and Statistical Database  Management \(SSDBM  04 1099-3371/04 $ 20.00  2004 IEEE Let c1 and c2 be two classes over two pattern types pt1 and pt2. A join predicate F is any predicate de?ned over a component of patterns in c1 and a component of patterns in c2. A composition function c pattern types pt1 and pt2 is a 4-tuple of functions c cStructureSchema, cDataSchema, cMeasureSchema, cFormula one for each pattern component. For example, function cStructureSchema takes as input two structure values of the right type and returns a new structure value, for a possible new pattern type, generated by the join. Functions for the other pattern components are similarly de?ned. Given two patterns p1 = \(pid1, s1, d1,m1, f1 p2 = \(pid2, s2, d2,m2, f2 p1, p2 ned as the pattern p with the following components Structure : cStructureSchema\(s1, s2 Data : cDataSchema\(d1, d2 Measure : cMeasureSchema\(m1,m2 Formula : cformula\(f1, f2 The join of c1 and c2 with respect to the join predicate F and the composition function c, denoted by c 1   F  c  c 2   i s  n o w  d e  n e d  a s  f o l l o w s    F  c  c 2     c  p 1   p 2   p 1    c 1  p 2    c 2  F   p 1   p 2     t r u e   5.1.3. Cross-over database operators OCD Drill-Through. The drill-through operator allows one to 


Drill-Through. The drill-through operator allows one to navigate from the pattern layer to the raw data layer Thus it takes as input a pattern class and it returns a raw data set. More formally, let c be a class of pattern type pt and let d be an instance of the data schema ds of pt. Then, the drill-through operator is denoted by c c Data-covering. Given a pattern p and a dataset D sometimes it is important to determine whether the pattern represents it or not. In other words, we wish to determine the subset S of D represented by p \(p can also be selected by some query the formula as a query on the dataset. Let p be a pattern, possibly selected by using query language operators, and D a dataset with schema \(a1, ..., an ible with the source schema of p. The data-covering operator, denoted by ?d\(p,D responding to all tuples in D represented by p. More formally d\(p,D t.a1, ..., t.an In the previous expression, t.ai denotes a speci?c component of tuple t belonging to D and p.formula\(t.a1, ..., t.an instantiated by replacing each variable corresponding to a pattern data component with values of the considered tuple t Note that, since the drill-though operator uses the intermediate mapping and the data covering operator uses the formula, the covering ?\(p,D D = ?\(p not be equal to D. This is due to the approximating nature of the pattern formula 5.1.4. Cross-over pattern base operators OCP Pattern-covering. Sometimes it can be useful to have an operator that, given a class of patterns and a dataset, returns all patterns in the class representing that dataset \(a sort of inverse data-covering operation Let c be a pattern class and D a dataset with schema a1, ..., an pattern type. The pattern-covering operator, denoted as ?p\(c,D all patterns in c representing D. More formally p\(c,D t.a1, ..., t.an true Note that: ?p\(c,D p,D 6. Related Work Although signi?cant e?ort has been invested in extending database models to deal with patterns, no coherent approach has been proposed and convincingly implemented for a generic model There exist several standardization e?orts for modeling patterns, like the Predictive Model Markup Language \(PMML  eling approach, the ISO SQL/MM standard [2], which is SQL-based, and the Common Warehouse Model CWM  ing e?ort. Also, the Java Data Mining API \(JDMAPI 3] addresses the need for a language-based management of patterns. Although these approaches try to represent a wide range of data mining result, the theoretical background of these frameworks is not clear. Most importantly, though, they do not provide a generic model capable of handling arbitrary cases of pattern types; on the contrary only a given list of prede?ned pattern types is supported To our knowledge, research has not dealt with the issue of pattern management per se, but, at best, with peripheral proximate problems. For example, the paper by Ganti et. al. [9] deals with the measurement 


per by Ganti et. al. [9] deals with the measurement of similarity \(or deviation, in the authors  vocabulary between decision trees, frequent itemsets and clusters Although this is already a powerful approach, it is not generic enough for our purpose. The most relevant research e?ort in the literature, concerning pattern management is found in the ?eld of inductive databases Proceedings of the 16th International Conference on Scientific and Statistical Database  Management \(SSDBM  04 1099-3371/04 $ 20.00  2004 IEEE meant as databases that, in addition to data, also contain patterns [10], [7]. Our approach di?ers from the inductive database one mainly in two ways. Firstly, while only association rules and string patterns are usually considered there and no attempt is made towards a general pattern model, in our approach no prede?ned pattern types are considered and the main focus lies in devising a general and extensible model for patterns Secondly, di?erently from [10], we claim that the peculiarities of patterns in terms of structure and behavior together with the characteristic of the expected workload on them, call for a logical separation between the database and the pattern-base in order to ensure e?cient handling of both raw data and patterns through dedicated management systems Finally, we remark that even if some languages have been proposed for pattern generation and retrieval 14, 11], they mainly deal with speci?c types of patterns \(in general, association rules sider the more general problem of de?ning safe and su?ciently expressive language for querying heterogeneous patterns 7. Conclusions and Future Work In this paper we have dealt with the issue of modelling and managing patterns in a database-like setting Our approach is enabled through a Pattern-Base Management System, enabling the storage, querying and management of interesting abstractions of data which we call patterns. In this paper, we have \(a de?ned the logical foundations for the global setting of PBMS management through a model that covers data patterns and intermediate mappings and \(b language issues for PBMS management. To this end we presented a pattern speci?cation language for pattern management along with safety constraints for its usage and introduced queries and query operators and identi?ed interesting query classes Several research issues remain open. First, it is an interesting topic to incorporate the notion of type and class hierarchies in the model [15]. Second, we have intentionally avoided a deep discussion of statistical measures in this paper: it is more than a trivial task to de?ne a generic ontology of statistical measures for any kind of patterns out of the various methodologies that exist \(general probabilities Dempster-Schafer, Bayesian Networks, etc. [16 nally, pattern-base management is not a mature technology: as a recent survey shows [6], it is quite cumbersome to leverage their functionality through objectrelational technology and therefore, their design and engineering is an interesting topic of research References 1] Common Warehouse Metamodel \(CWM http://www.omg.org/cwm, 2001 2] ISO SQL/MM Part 6. http://www.sql99.org/SC32/WG4/Progression Documents/FCD/fcddatamining-2001-05.pdf, 2001 3] Java Data Mining API http://www.jcp.org/jsr/detail/73.prt, 2003 4] Predictive Model Markup Language \(PMML http://www.dmg.org 


http://www.dmg.org pmmlspecs v2/pmml v2 0.html, 2003 5] S. Abiteboul and C. Beeri. The power of languages for the manipulation of complex values. VLDB Journal 4\(4  794, 1995 6] B. Catania, A. Maddalena, E. Bertino, I. Duci, and Y.Theodoridis. Towards abenchmark for patternbases http://dke.cti.gr/panda/index.htm, 2003 7] L. De Raedt. A perspective on inductive databases SIGKDD Explorations, 4\(2  77, 2002 8] M. Escobar-Molano, R. Hull, and D. Jacobs. Safety and translation of calculus queries with scalar functions. In Proceedings of PODS, pages 253  264. ACMPress, 1993 9] V. Ganti, R. Ramakrishnan, J. Gehrke, andW.-Y. Loh A framework for measuring distances in data characteristics. PODS, 1999 10] T. Imielinski and H. Mannila. A database perspective on knowledge discovery. Communications of the ACM 39\(11  64, 1996 11] T. Imielinski and A. Virmani. MSQL: A Query Language for Database Mining. Data Mining and Knowledge Discovery, 2\(4  408, 1999 12] P. Kanellakis, G. Kuper, and P. Revesz. Constraint QueryLanguages. Journal of Computer and SystemSciences, 51\(1  52, 1995 13] P. Lyman and H. R. Varian. How much information http://www.sims.berkeley.edu/how-much-info, 2000 14] R.Meo, G. Psaila, and S. Ceri. An Extension to SQL for Mining Association Rules. Data Mining and Knowledge DiscoveryM, 2\(2  224, 1999 15] S. Rizzi, E. Bertino, B. Catania, M. Golfarelli M. Halkidi, M. Terrovitis, P. Vassiliadis, M. Vazirgiannis, and E. Vrachnos. Towards a logical model for patterns. In Proceedings of ER 2003, 2003 16] A. Siblerschatz and A. Tuzhillin. What makes patterns interesting in knowledge discovery systems. IEEE TKDE, 8\(6  974, 1996 17] D. Suciu. Domain-independent queries on databases with external functions. In Proceedings ICDT, volume 893, pages 177  190, 1995 18] M.Terrovitis, P.Vassiliadis, S. Skadopoulos, E. Bertino B. Catania, and A. Maddalena. Modeling and language support for the management of patternbases. Technical Report TR-2004-2, National Technical University of Athens, 2004. Available at http://www.dblab.ece.ntua.gr/pubs Proceedings of the 16th International Conference on Scientific and Statistical Database  Management \(SSDBM  04 1099-3371/04 $ 20.00  2004 IEEE pre></body></html 


The reason of the hiding failure of SWA is the same in Fig.8 Notice the result at x = 0.7646 in Fig.14, because the hiding failure is occurred at the seeds of the sensitive patterns, a high weakness is produced As shown in Fig.15 and Fig.16, the misses cost and dissimil arity of our work decreases as RL2 increases. This is because the larger RL2 is, the less effect on non-sensitive patterns. Also weakness and dissimilarity of SWA are independent of RL2 5. Conclusion In the paper, a novel method improving the balance between sensitive knowledge protecting and discovery on frequent patte rns has been proposed. By setting entries of a sanitization matrix to appropriate values and multiplying the original database by the matrix with some probability policies, a sanitized database is gotten. Moreover, it can avoid F-I Attack absolutely when the confidence level given by users approximates to 1. The experimental results revealed that although misses cost and dissimilarity between the original and sanitized database of our process are little more than SWA, ours provide more safely protection than SWA. Unlike SWA, our sanitization process could not suffer from F-I Attack and the probability policies in our approach also take the minimum support into account, the users only need to decide the confidence level which affects the degree of patterns hiding 6. Reference 1] M. Atallah, E. Bertino, A. Elmagarmid, M. Ibrahim and V. Verykios Disclosure Limitation of Sensitive Rules", Proc. of IEEE Knowledge and Data Engineering Exchange Workshop 1999 2] R. Agrawal and R. Srikant. Fast algorithms for mining association rules. VLDB, Santiago, Chile, 1994 3] R. Agrawal and R. Srikant. Privacy preserving data mining. In ACM SIGMOD, Dallas, Texas, May 2000 4] E. Dasseni, V. Verykios, A. Elmagarmid and E. Bertino, Hiding Association Rules by Using Confidence and Support", Proc. of 4th Intl Information Hiding Workshop \(IHW 5] A. Evfimievski, J. Gehrke, and R. Srikant. Limiting Privacy Breac hed in privacy preserving data mining. SIGMOD/PODS, 2003 6] A. Evfimievski, R. Srikant, R. Agrawal, and J. Gehrke. Privacy preserving mining of association rules. KDD 2002 7] M. Kantarcioglu and C. Clifton. Privacy-preserving distributed mining of association rules on horizontally partitioned data. In ACM SIGMOD Workshop on Research Issues on Data Mining and Knowledge Discovery, June 2002 8] Guanling Lee, Chien-Yu Chang and Arbee L.P Chen. Hiding sensitive patterns in association rules mining. The 28th Annual International Computer Software and Applications Conference 9] Y. Lindell and B. Pinkas. Privacy Preserving Data mining. In CRYPTO, pages 36-54, 2000 10] S. R. M. Oliveira and O. R. Za  ane. Privacy Preserving Frequent Itemset Mining. In Proc. of IEEE ICDM  02 Workshop on Privacy Security, and Data Mining 11] S. R. M. Oliveira and O. R. Za  ane. Algorithms for Balancing Priv acy and Knowledge Discovery in Association Rule Mining. IDEAS  03 12] S. R. M. Oliveira and O. R. Za  ane. Protecting Sensitive Knowledge By Data Sanitization, ICDM  03 13] S. R. M. Oliveira, O. R. Za  ane and Y  cel Saygin. Secure Association Rule Sharing, PAKDD-04 14] Benny Pinks. Cryptographic Techniques For Privacy-Preserving D ata Mining. ACM SIGKDD Explorations Newsletter Vol. 4, Is. 2, 2002 15] S. J. Rizvi and J. R. Haritsa. Maintaining data privacy in association rule mining. VLDB, 2002 16] J. Vaidya and C. W. Clifton. Privacy preserving association rule mining in vertically partitioned data. KDD2002 17] Verykios, V.S.; Elmagarmid, A.K.; Bertino, E.; Saygin, Y.; Dasseni E. Association rule hiding. IEEE Transactions On Knowledge And Data Engineering, Vol. 16, No. 4, April 2004 Proceedings of the 29th Annual International Computer Software and Applications Conference  COMPSAC  05 0730-3157/05 $20.00  2005 IEEE pre></body></html 


pre></body></html 


Batt Power Batt Type Stabilization Type Propulsion Mechanism  of Solar Panels  of Solar Cells Manufacturing Qty Satellites in Constellation On-Orbit Spares Channels Number of Bands Data Storage Processing Power Source type Block Name Thermal Control Material Type Level of Technology Known Inheritance Propulsion station keeping Number of Axes Ground Based Spares Pointing Accuracy APPENDIX C EXISTING MODELS Numerous models are today in use for estimating spacecraft cost Two of the most common are the NASA/Air Force Cost Model and the Aerospace Small Satellite Cost Model Here is a description of the NAFCOM model The NASA/Air Force Cost Model NAFCOM is a parametric estimating toolfor space hardware It is based on historical NASA and Air Force space projects and is primarily used in the very early phases of a development project NAFCOM can be used at the subsystem or component levels The database currently includes 122 missions including 76 unmanned earth orbiting 24 unmanned planetary 11 launch vehicles 8 manned 3 engines It uses parametric relationships to estimate subsystem or component level costs for any aerospace hardware including earth orbital spacecraft manned spacecraft launch vehicle upper stages liquid rocket engines scientific instruments or planetary spacecraft 7 And for the Aerospace Small Satellite Cost Model SSCM employs a parametric methodology for estimation of program cost and is best suited to the early conceptual development phase of a spacecraft program during which time the design is likely to be less mature and when cost and performance trades can be easily performed SSCM consists of a collection of cost-estimating relationships or CERs which estimate the costs of developing andproducing a spacecraft system with the following subsystems  Attitude Determination and Control Subsystem ADCS  Propulsion  Power  Telemetry Tracking  Command TT&C  Command  Data Handling C&DH  Structure  Thermal CERs were also developed for integration assembly and test IA&T program management PM and systems engineering SE and launch and orbital operations support LOOS Individual subsystem cost estimates are statistically rolled up to yield a cost-risk distribution which provides the estimator with a range of cost estimates andpercentiles 8 The SSCM was calibrated from over 100 post-1990 Earth-orbiting andplanetary missions REFERENCES 1 Lack of Disciplined Cost-Estimating Processes Hinders Effective Program Management GAO study 04-642 2 Jilla Cyrus D and Miller David W Satellite Design Past Present and Future International Journal of Small Satellite Engineering 12 February 1997 3 Bearden David A A Complexity Based Risk Assessment of Low-Cost Planetary Missions:When Is A Mission Too Fast and Too Cheap Fourth IAA International Conference On Low-Cost Planetary Missions JHU/APL MAY 2-5 2000 4 Kellogg Mahr and Lobbia An Analogy-based Method for Estimating the Costs of Spacecraft IEEEAC paper 1371 Version 4 5 Hoeting Jennifer A Methodology for Bayesian Model Averaging An Update f 6]btp/ewiieiao iiAaos 7 Keith Smith NASA/Air Force Cost Model Science Applications International Corporation 8 18 


BIOGRAPHIES Lee Fischman served as Principle Investigator for this project Lee is Senior Director of Development at Galorath Incorporated where he directs much of the new product development and research at the firm He developed SEER for Software  Hardware Integrations with Microsoft Project the Comparison Sizing tool COTS Software model in addition to various data mining information extraction and expert systems Previously he was a software designerlprogrammer in the New York financial industry Lee earned a BA from the University of Chicago and an MA from UCLA both in economics Mike Kimel carried out statistical work on the project Mike is an Economist for Galorath Inc in addition to maintaining his own quantitative consulting practice He has also taught Economics and Advanced Statistics at the Graziadio School of Business and Management at Pepperdine University run the Competitive Strategy group for a Fortune 500 Telecom Company and worked as a Consultant at PriceWaterhouse LLC now PriceWaterhouse-Coopers He earned a Ph.D in Economicsfrom UCLA Troy Masters programmed analytic methods and is integrating the Far Out model into its parent product SEER for Hardware previously SEER-H Troy is a Software Engineer with Galorath Incorporated where he has been the primary developer for a range ofproducts He earned a BS in computer science from UCLA David J Pine was our subject matter expert helping us assemble data and gain insight into technical trends Dave is retired after a 34-year career with the National Aeronautics and Space Administration NASA currently is a consultant to various government and industry entities While at NASA his organizations in the Office of the Chief Financial Officer and later at the IPAO at Langley Research Center were responsible for the conduct of major NASA program analyses and evaluations for the NASA Administrator and Deputy Administrator From early 1988 through the end of 1990 he was the Deputy Program Manager for the Hubble Space Telescope Program specifically responsible for the telescope operations and science support aspects of the program He earned a BS in Aerospace Engineering from the Polytechnic Institute of Brooklyn and a Masters of Engineering Administration from the George Washington University 19 


  20 Angeles, where he also received a B.S. in Applied Mathematics  Eric Fetzer is a Senior Member of the Technical Staff at the Jet Propulsion Laboratory, Pasadena, California specializing in satellite observations of the atmosphere.  His scientific interests include planetary boundary layer processes, tropical phenomena, upper tropospheric variability, and climatologies of temperature, water vapor and clouds.  His technical interests include analysis of large data sets, and of multi-sensor observations. He has over 20 peer-reviewed publications and given numerous scientific presentations, public lectures and media interviews about climate science. Eric received a B.A. in Physics from the University of California Berkeley, and a Ph.D. in Astrophysical, Planetary and Atmospheric Sciences from the University of Colorado, Boulder   Amy Braverman is a Senior Statistician at the Jet Propulsion Laboratory, California Institute of Technology She holds a B.A. in Economics from Swarthmore College an M.A. in Mathematics from UCLA, and a Ph.D. in Statistics also from UCLA. Prior to her current position in JPL's Science Data Understanding Group, she was a Caltech Post-doctoral Scholar at the Jet Propulsion Laboratory, and a Scientist in the Flight Sciences Experiments Section of the Science Division. Dr Braverman conducts research on information-theoretic methods for the analysis of massive data sets and streams statistical data fusion, high-dimensional data analysis, and statistical analysis for climate model evaluation and diagnosis. She has published in both the statistics and geoscience literature, and is active in both communities She is a member of the Multi-angle Imaging SpectroRadiometer Science Team, and serves as a member of the Atmospheric Infrared Sounder Science Integration Team. Her responsibilities on both missions include designing data reduction algorithms for massive, remote sensing data sets. Dr. Braverman also holds an appointment in the Department of Statistics at UCLA as Adjunct Associate Professor, and is active in UCLA\222s Center for Environmental Statistics. She is member of the Committee on Applied and Theoretical Statistics of the US National Academy of Science. She has refereed for the Journal of the American Statistical Association, the Journal of Computational and Gr aphical Statistics, IEEE Transactions on Geoscience and Remote Sensing, and the Journal of Applied Meteorology and Climatology Seungwon Lee is a senior member of the High Capability Computing and Modeling Group at Jet Propulsion Laboratory. She is conducti ng research on comet gas dynamics, nonlinear dynamics control, climate model parameterization, Earth science data analysis, parallel computing, and advanced numerical algorithms. She received her Ph.D in Physics fr om the Ohio State University and her M.S. and B.S. in Physics from the Seoul National University, Korea  Matthew Henderson is software engineer in the High Capability Computing and Mode ling group at JPL. His current work includes Web Services and Instrument Data Level 2 subsetting. He received a B.S. Computer Science from CSU Pomona, and is currently pursuing M.S Computer Science  Steven J. Lewis is a member of the Information System and Computer Science staff member at the Jet Propulsion Laboratory.  He received a BS in Mathematics from the University of California, Los Angeles in June 2001, and the MS and Ph.D. Degree from Claremont Graduate University in May 2004 and May 2007, respectively.  He worked as a post doctoral fellow at Keck Graduate Institute from June 2007 until he joined JPL in March of 2008.  During his graduate and post doctoral work, his studies focused on applications of Bayesian methods to hidden Markov models with particular interest and application to protein sequencing.  His work at JPL has focused on integrating web services into various programming platforms for the purposes of accessing NASA satellite data, as well as developing object tracking so ftware and contributing to image enhancement and restoration efforts Van Dang is a member of the Science Data Understanding Group at the Jet Propulsion Laboratory. She was responsible for the NEWS Level 2 processing that generated the formal merged Level 2 data from multiple A-Train instruments  Manuel de la Torre is a Physicist from the Universidad Complutense at Madrid \(Spain\. After finishing his Ph.D work at the University of Bayreuth \(Germany\ on pattern formation in turbulent flows and a 7 1/2 year stunt as Ass and Assoc. Prof. at the Escuela T\351cnica Superior de Ingenieros Aeron\341uticos in Madrid \(Spain\, he came to the Jet Propulsion Laboratory on a 1-year Sabatical leave in 1997 wanting to apply fundamental concepts of nonlinear systems and geophysical fluid dynamics to something that might be directly useful to soci ety. He discovered the JPL as a great place to achieve that goal and extende d his stay a bit longer, becoming Technical staff and working on different aspects of remote sensing, validation of satellite instruments, and data analysis of atmospheric processes and climate  


