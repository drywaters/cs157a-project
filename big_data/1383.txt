 Hiding Sensitive Predictive Association Rules  Shyue-Liang Wang, Ayat Jafari Department of Computer Science New York Institute of Technology New York, New York USA slwang@nyit.edu  Abstract  Privacy-preserving data mining [22  is a n o vel research direction in data mining and statistical databases where data mining algorithms are analyzed for the side effects they incur in data privacy.  For example, through data mining, one is able to infer sensitive information including personal information or even patterns, from nonsensitive information or unclassified data.  There have been 
two types of privacy concerning data mining.  The first type of privacy is that the data is altered so that the mining result will preserve certain privacy.  The second type of privacy is that the data is manipulated so that the mining result is not affected or minimally affected  Given specific rules to be hidden, many data altering techniques for hiding association, classification and clustering rules have been proposed.  However, to specify hidden rules, entire data mining process needs to be executed.  For some applications, we are only interested in hiding certain sensitive predicative rules that contain given items.  In this work, we assume that only sensitive items 
are given and propose two algorithms, ISL \(Increase Support of LHS\ and DSR \(Decrease Support of RHS\,  to modify data in database so that sensitive predicative rules containing specified items on the left hand side of rule cannot be inferred through association rule mining Examples illustrating the proposed algorithms are given The characteristics of the algorithms are analyzed.  The efficiency of the proposed approach is further compared with Verykios etc [9,2 app ro ac h.  I t i s s how n t hat o u r  approach required less number of databases scanning and 
prune more number of hidden rules.  However, our approach must hide all rules containing the hidden items on the left hand side, where Verykios etc approach can hide any specific rule Keywords privacy preserving data mining, predictive association rule 1 Introduction  The concept of privacy preserving data mining has been recently proposed in response to the concerns of preserving personal information from data mining algorithms [3,4,5,15,16,22  Th ere h a ve b een two t y p e s of  privacy concerning data mining.  The first type of privacy is that the data is altered so that the mining result will 
preserve certain privacy.  Many techniques have been proposed for this type of output privacy 1,6,7,8,9,17,18,20 Fo r e x a m pl e  pe r t ur ba t i on blocking, aggregation or merging, swapping, and sampling are some alternation methods that have recently been proposed.  The second type of privacy is that the data is manipulated so that the mining result is not affected or minimally affected [10,11,12,13,21  For example, the cryptography-based techniques like secure multiparty computation  allow users access to only a subset of data while global data mining results can still be discovered The reconstruction-based technique where the original 
distribution of the data can be reconstructed from the randomized data is another method for this type of input privacy  Given specific rules to be hidden, many data altering techniques for hiding association, classification and clustering rules have been proposed.  However, to specify hidden rules, entire data mining process needs to be executed.  For some applications, we are only interested in hiding certain sensitive predicative rules that contain given items.  In this work, we assume that only sensitive items are given and propose two algorithms to modify data in database so that sensitive predicative rules containing 
specified items on the left hand side of rule cannot be inferred through association rule mining.  The proposed algorithms are based on modifying or perturbing the database transactions so that the confidence of the association rules can be reduced.  Examples demonstrating the proposed algorithms are shown.  The characteristics of the proposed algorithms are analyzed.  The efficiency of the proposed approach is further compared with Verykios etc approach.  It is shown that our approach required less number of databases scanning and prune more number of hidden rules.  However, our approach must hide all rules containing the hidden items on the left hand side, where 
Verykios etc approach can hide any specific rule  The rest of the paper is organized as follows.  Section 2 presents the statement of the problem and the notation used in the paper.  Section 3 presents the proposed algorithms for hiding sensitive predictive association rules that contain the specified items. Section 4 shows some examples of the proposed algorithms.  Section 5 analyses the characteristics of proposed algorithms and further compare with Verykios etc approach.  Concluding remarks and future works are described in section 6 


 2 Problem Statement 2.1 Predicative Association Rules  The problem of mining association rules was introduced in [2   Let          2 1 m i i i I be a set of literals, called items.  Given a set of transactions D where each transaction T is a set of items such that  I T an association rule is an expression Y X where  I X   I Y and  Y X The X and Y are called respectively the body \(left hand side\ and head \(right hand side\ of the rule.  An example of such a rule is that 90% of customers buy hamburgers also buy Coke.  The 90% here is called the confidence of the rule, which means that 90% of transaction that contains X also contains Y The confidence is calculated as      X Y X The support of the rule is the percentage of transactions that contain both X and Y which is calculated as  N Y X   where N is the number of transactions in D In other words, the confidence of a rule measures the degree of the correlation between itemsets while the support of a rule measures the significance of the correlation between itemsets.  The problem of mining association rules is to find all rules that are greater than the user-specified minimum support and minimum confidence   As an example, for a given database in Table 1, a minimum support of 33% and a minimum confidence of 70%, nine association rules can be found as follows B  A 66%, 100 C  A 66%, 100 B  C 50%, 75 C  B 50%, 75 AB  C 50%, 75 AC  B 50 75 BC  A 50%, 100 C  AB 50%, 75 B  AC 50%, 75   Table 1: Database D  TID Items T 1 ABC T 2 ABC T 3 ABC T 4 AB T 5 A T 6 AC   However, mining association rules usually generates a large number of rules, most of which are unnecessary for the purpose of prediction.  For example, given itemset for prediction P = {C the rule set that contains only two rules C  A 66%, 100 C  B 50%, 75%\l generate the same predicted itemset Q = {A, B as the nine association rules found from Table 1.  A predictive association rule set or informative rule set\4 can be inf o r m ally d efin e d  as the smallest rule set that makes the same prediction as the association rule set by confidence priority 2.2 Problem Description  The objective of data mining is to extract hidden or potentially unknown interesting rules or patterns from databases.  However, the objective of privacy preserving data mining is to hide certain sensitive information so that they cannot be discovered through data mining techniques 1,4-12,16  In  this wo rk we assu m e th at on ly sen s i t iv e items are given and propose two algorithms to modify data in database so that sensitive predictive association rules cannot be inferred through association rule mining.  More specifically, given a transaction database D a minimum support, a minimum confidence and a set of sensitive items X the objective is to modify the database D such that no predictive association rules containing X on the left hand side will be discovered  As an example, for a given database in Table 1, a minimum support of 33%, a minimum confidence of 70 and a hidden item X  C if transaction T 5 is modified as AC then the following rules that contain item C on the left hand side will be hidden C  B 50%, 60 AC  B 50 60 C  AB 50%, 60  The following notation will be used in the paper Each database transaction has three elements: T=<TID list_of_elements, size>.  The TID is the unique identifier of the transaction T and list_of_elements is a list of all items in the database.  However, each element has value 1 if the corresponding item is supported by the transaction and 0 otherwise. Size means the number of elements in the list_of_elements having value 1.  For example, if I   A,B,C a transaction that has the items A, C will be represented as t T1,101,2>.  In addition, a transaction t  supports an itemset I when the elements of t.list_of_elements corresponding to items of I are all set to 1.  A transaction t  partially supports an itemset I when the elements are not all set to 1.  For example, if I  A,B,C  111   p T1,[111  3 a n d q T2,[001  1 t h e n we  would say that p  supports  I and q  partially supports  I  3 Proposed Algorithms  In order to hide an association rule, we can either decrease its support or its confidence to be smaller than pre-specified minimum support and minimum confidence To decrease the confidence of a rule, we can either \(1 increase the support of X i.e., the left hand side of the rule but not support of X Y or \(2\ecrease the support of the itemset X Y For the second case, if we only decrease the support of Y the right hand side of the rule, it would reduce the confidence faster than simply reducing the support of X Y To decrease support of an item, we will modify one item at a time in a selected transaction by changing from 1 


 to 0 and from 0 to 1 to increase the support   Based on these two strategies, we propose two datamining algorithms for hiding sensitive predictive association rules, namely I ncrease S upport of LHS    ISL  and D ecrease S upport of R HS DSR The first algorithm tries to increase the support of left hand side of the rule The second algorithm tries to decrease the support of the right hand side of the rule.  The details of the two algorithms are described as follow Algorithm ISL Input  1\ a source database D   2\ a min_support 3\ a min_confidence  4\a set of hidden items X  Output a transformed database D where rules containing X on LHS will be hidden  1 Find large 1-item sets from D  2 For each hidden item x X  3 If x is not a large 1-itemset, then X := X -{x  4. If H is empty, then EXIT;// no AR contains X in LHS  5 Find large 2-itemsets from D  6. For each x X  7 For each large 2-itemset containing x  8 Compute confidence of rule U where U is a rule like x h  9 If confidence\(U min_conf, then 10 Go to next large 2-itemset 11 Else Increase Support of LHS  12  Find T L  t in D  t does not support U  13  Sort T L in ascending order by the number of Items 14  While confidence\(U min_conf and T L is not empty 15  Choose the first transaction t from T L   16  Modify t to support x the LHS  U  17  Compute support and confidence of U  18 Remove and save the first transaction t from T L  19 end While 20  end if 21. If T L is empty, then 22 Can not hide x h  23. Restore D  24 Go to next large-2 itemset 25 end if T L is empty 26 end of for each large 2-itemset 27. Remove x from X  28 end of for each x  29. Output updated D as the transformed D   Algorithm DSR Input  1\ a source database D   2\ a min_support 3\ a min_confidence  4\a set of hidden items X  Output a transformed database D where rules containing X on LHS will be hidden  1 Find large 1-item sets from D  2 For each hidden item x X  3 If x is not a large 1-itemset, then X := X -{x  4. If H is empty, then EXIT;// no AR contains X in LHS  5 Find large 2-itemsets from D  6. For each x X  7 For each large 2-itemset containing x  8 Compute confidence of rule U where U is a rule like x h  9 If confidence\(U min_conf, then 10 Go to next large 2-itemset 11 Else Decrease Support of RHS  12. Find T R  t in D  t fully support U  13. Sort T R in ascending order by the number of   Items 14. While confidence\(U min_conf and T R    is not empty 15 Choose the first transaction t from T R   16. Modify t so that h is not supported 17 Compute support and confidence of U  18 Remove and save the first transaction t  from T R  19 end While 20 end if 21. If T R is empty, then 22 Can not hide x h  23. Restore D  24 Go to next large-2 itemset 25 end if T R is empty 26 end of for each large 2-itemset 27. Remove x from X  28 end of for each x  29. Output updated D as the transformed D   4 Examples  This section shows four examples for demonstrating the two proposed algorithms in hiding sensitive predictive association rules in the association rule mining  For a given database in Table 1, a minimum support of 33% and a minimum confidence of 70%, the first two examples hide the sensitive rules using the ISL algorithm The difference of the two examples is that the order of hiding item is different.  The first example hides item C and then item B.  The second example hides item B and then item C.  The result is given in section 4.1   The third and fourth examples hide the sensitive predictive association rules using DSR algorithm.  The difference is also the order of items to be hidden.  The result is given in section 4.2   


 Table 2: Database D using the specified notation TID Items Size T1 111 3 T2 111 3 T3 111 3 T4 110 2 T5 100 1 T6 101 2   4.1 Examples Running ISL Algorithm  Example 1 Assuming that the min_supp = 33% and min_conf = 70%, the result of hiding item C and then item B using ISL algorithm is as follows.  To hide item C the rule C => B 50%, 75%\ will be hidden if transaction T 5 is modified from 100 to 101 using ISL \(Increase Support of LHS The new database D 1 is shown in Table 3.  The rule C => B will have support = 50% and confidence = 60 However, rules C => A  B => A  B => C cannot be hidden by ISL algorithm  Table 3  Databases before and after hiding item C and item B using ISL            Example 2 As in example 1, reversing the order of hiding items, the result of hiding item B and then item C using ISL  algorithm is as follows.  To hide item B the rule B => C 50%, 75%\ will be hidden if transaction T 5 is modified from 100 to 110 using ISL.  The new database D 2 is shown in Table 4.  The rule B => C will have support = 50% and confidence = 60%.  However, rules B => A  C => A  C B cannot be hidden by ISL algorithm  One observation we can make is that different sequences of hiding items will result in different transformed databases i.e D 1  and D 2 for ISL algorithm  Table 4 Databases before and after hiding item B and item C using ISL  TID D D 2  T1 111 111 T2 111 111 T3 111 111 T4 110 110 T5 100 110  T6 101 101  4.2 Examples Running DSR Algorithm  Example 3 Assuming that the min_supp=33% and min_conf=70%, the result of hiding item C and then item B using DSR algorithm is as follows.  To hide item C the rule C => A 60%, 100 C => B 50%, 75 B => C  50%, 75 B => A 60%, 100%\ will be hidden if transaction T 6 is modified from 101 to 001 T 1 is modified from 111 to 011 T 1 is modified from 011 to 001, and T 4 is modified from 110 to 010, using DSR.  The new database D 3 is shown in Table 5  Table 5  Databases before and after hiding item C and item B using DSR  TID D D 3  T1 111 001  T2 111 111 T3 111 111 T4 110 010  T5 100 100 T6 101 001   Example 4 As in example 3, reversing the order of hiding items, the result of hiding item B and then item C using DSR algorithm is as follows.  To hide item B the rule B A 60%, 100 B => C 50%, 75 C => A 60 100 C => B 50%, 75%\ will be hidden if transaction T 4  is modified from 110 to 010 T 1 is modified from 111 to 011 T 1 is modified from 011 to 010 T 6 is modified from 101 to 001, using DSR.  The new database D 4 is shown in Table 6  Table 6  Databases before and after hiding item B and item C using DSR  TID D D 4  T1 111 010  T2 111 111 T3 111 111 T4 110 010  T5 100 100 T6 101 001    One observation is that different sequences of hiding items will result in different transformed databases, i.e D 3  and D 4 for DSR algorithm  5 Analysis  This section analyzes some of the characteristics of the proposed algorithms and compares with the algorithms proposed in Verykios etc’s [9,23  Th e fir s t ch aracteristic we observe is the item ordering effect.  The transformed databases are different under different ordering of hiding items, even though the same set of sensitive items is specified.  The second characteristic we observe is the algorithm effect.  The transformed databases will be different under different algorithm. These characteristics TID D D 1  T1 111 111 T2 111 111 T3 111 111 T4 110 110 T5 100 101  T6 101 101 


 are demonstrated in the four examples in section 4 and summarized in Table 7.  Databases D 1 and D 2 are resulting databases using ISL algorithm and D 3 and D 4 are resulting databases using DSR algorithm Table 7  Databases before and after hiding items B and C  using ISL and DSR  TID D D 1 D 2 D 3 D 4  T1 111 111 111 001 010 T2 111 111 111 111 111 T3 111 111 111 111 111 T4 110 110 110 010 010 T5 100 101 110  100 100 T6 101 101 101 001 001   The third characteristic we analyze is the efficiency of the proposed algorithm compared with the Verykios etc algorithms.  Even though it is the hidden rules, instead of hidden items, that are specified in [9,23 we co m p are t h e number of database scanning and the number of rules pruned between the two approaches.  Table 8 summarizes the results   For ISL algorithm, the number of database scanning comes from the calculation of large one itemsets, large two itemsets, and transactions T L The rules pruned are AC B and C => AB For Verykios etc’s 1a algorithm, the number of database scanning comes from the calculation of large one itemsets, large two itemsets, large three itemsets and partial support transactions T No rules are pruned in the Verykios etc’s algorithm.  It can be seen that the ISL algorithm requires less database scanning and prune more number of association rules.  Similar results are obtained for comparing DSR algorithm and Verykios etc’s 1b algorithm  Table 8  Database scans and rules pruned in hiding item C  using ISL DB Scans Rules Pruned ISL 3 2 Dasseni’s 1a 4 0   One of the reasons that Verykios etc’s approach does not prune rules is that hidden rules are given in advance and the algorithms try to hide every single rule without checking to see if rules can be pruned after some transactions have been changed   However, our approach needs to hide all rules containing hidden items on the left hand side.  But Verykios etc’s approach can hide some of the rules containing hidden item on the left hand side.  For example for hidden item C Verykios etc’s approach can hide C A but show C => B whereas our approach must hide both C => A and C => B    The fourth characteristic we analyze is efficiency comparison of the ISL and DSR algorithms.  One observation we conclude from the examples in section four is that DSR algorithm seems to be more effective when the support count of the hidden item is large.  This is due to when support of right hand side of the rule is large increase support of left hand side usually does not reduce the confidence of the rule.  However, decrease support of right hand side usually decreases the confidence of the rule  6 Conclusions  In this work, we have studied the database privacy problems caused by data mining technology and proposed two naïve algorithms for hiding sensitive predictive association rules in association rules mining.  The proposed algorithms are based on modifying the database transactions so that the confidence of the association rules can be reduced.  Examples demonstrating the proposed algorithms are shown.  The item ordering and algorithm ordering characteristics of the proposed algorithms are analyzed.  The efficiency of the proposed approach is further compared with Verykios etc’s [9,2 I t  was sh own  that our approach required less number of database scanning and prune more number of hidden rules However, our approach must hide all rules containing the hidden items on the left hand side, where Verykios etc’s approach can hide any specified rule.  Currently we are performing numerical simulation on the time effects and side effects \(the number of lost rules and new rules due to alternation of the database\and will be included in this work.  In the future, we will examine and compare with other alternation techniques for hiding predictive association rules based on current approach  References 1  D Ag rawal and  C C. Ag gar w al, “On t h e d e sig n  and  quantification of privacy preserving data mining algorithms”, In Proceedings of the 20th Symposium on Principles of Database Systems Santa Barbara, California USA, May 2001  2  R   A g r a wal, T  Im iel i n s k i and A. Sw am i Min ing  Association Rules between Sets of Items in Large Databases”, In Proceedings of ACM SIGMOD International Conference on Management of Data Washington DC, May 1993  3  R   Ag rawal  an d  R. Srik ant, ”Pr i vacy p reser vin g data mining”, In ACM SIGMOD Conference on Management of Data pages 439–450, Dallas, Texas, May 2000  4  Ljilj ana Bran ko v i c an d V l ad im ir Estivill-Castro   Privacy Issues in Knowledge Discovery and Data Mining 


 Australian Institute of Computer Ethics Conference, July 1999, Lilydale  5  C. Clifton  and  D. Mark s, “Secu rity an d Privacy Implications of Data Mining”, in SIGMOD Workshop on Research Issues on Data Mining and knowledge Discovery 1996  6  C  C l i f t on P ro t e c t i ng Ag a i ns t Da t a  M i ni ng T h r oug h Samples”, in Proceedings of the Thirteenth Annual IFIP WG 11.3 Working Conference on Database Security, 1999  7  C  C l i f t on   U s i ng S a m p l e Si z e t o L i m i t E xpo s u re  t o  Data Mining”, Journal of Computer Security, 8\(4\, 2000 8  Chr i s Clifto n, Mur a nt Kan t arcio g lu  Xiaod o n g Lin and  Michael Y. Zhu, “ Tools for Privacy Preserving Distributed Data Mining”, SIGKDD Explorations, 4\(2\, 1-7, Dec. 2002  9  E. Dass eni V. Ver ykio s A. Elm a g arm id an d E Bertino, “Hiding Association Rules by Using Confidence and Support” in Proceedings of 4 th Information Hiding Workshop, 369-383, Pittsburgh, PA, 2001  1 A. Ev fim i ev sk i, R. Srik an t  R Ag rawal an d J Geh r ke Privacy preserving mining of association rules”, In Proc Of the 8th ACM SIGKDD Int’l Conference on Knowledge Discovery and Data Mining Edmonton, Canada, July 2002  1 Alex and r e E v f i m i evs k i, “Rand o m izati o n i n Privacy Preserving Data Mining”, SIGKDD Explorations, 4\(2 Issue 2, 43-48, Dec. 2002  1 Alex and r e Ev fim i ev sk i  Joh an n e s  Gehr ke and  Ramakrishnan Srikant, “Limiting Privacy Breaches in Privacy Preserving Data Mining”, PODS 2003, June 9-12 2003, San Diego, CA  1 M Kan t ar ci o g l u an d C. Cl ifto n  Privacyp r e serv ing  distributed mining of association rules on horizontally partitioned data”, In ACM SIGMOD Workshop on Research Issues on Data Mining and Knowledge Discovery June 2002  14  J i u y on g L i H ong She n a nd R odn e y T opo r  M i n i n g the Smallest Association Rule Set for Predictions Proceedings of the 2001 IEEE International Conference on Data Mining, 361-368  1 Y Lind ell  an d B. Pi n k a s, “Privacy pr eserv in g data mining”, In CRYPTO pages 36–54, 2000  1 D. E O’ Leary Kn o wledg e Disco v ery as a Th r eat  t o  Database Security”, In G. Piatetsky-Shapiro and W. J Frawley, editors, Knowledge Discovery in Databases, 507516, AAAI Press/ MIT Press, Menlo Park, CA, 1991  1 S. O l iv ei r a O. Z a ian e Alg or it h m s fo r B a lan c ing  Priacy and Knowledge Discovery in Association Rule Mining”, Proceedings of 7 th International Database Engineering and Applications Symposium \(IDEAS03 Hong Kong, July 2003  1 S. Oliveira, O. Zaian e Pr o t ecting Sen s iti v e Knowledge by Data Sanitization”, Proceedings of IEEE International Conference on Da ta Mining, November 2003  1 S. J. Rizvi an d J   R  Haritsa, “Pr i vacy-p res erv ing  association rule mining”, In Proc. of the 28th Int’l Conference on Very Large Databases August 2002  20  Y  S a y g i n  V. V e ry ki o s  a nd C  C l i f t on  U s i n g  Unknowns to Prevent Discovery of Association Rules SIGMOD Record 30\(4\: 45-54, December 2001  2 J. Vaidya a n d C.W   Clifto n. “Pr i v acy p res erv ing  association rule mining in vertically partitioned data”, In Proc. of the 8 th ACM SIGKDD Int’l Conference on Knowledge Discovery and Data Mining Edmonton Canada, July 2002  22   V  V e ry k i os  E  B e r t i n o I  G  F ovi n o L P. Pr ov e n z a   Y. Saygin, and Y. Theodoridis,  “State-of-the-art in Privacy Preserving Data Mining”, SIGMOD Record, Vol. 33, No. 1 50-57, March 2004  23  V  Ve r y k i os A E l m a g a rm i d  E B e rt i no Y S a y g i n  and E. Dasseni,  “Association Rules Hiding”, IEEE Transactions on Knowledge and Data Engineering, Vol. 16 No. 4, 434-447, April 2004 


 2  5  L ea rni ng  fo r  C o n di ti o ns  o f t he  R ul e  A s  r e p r e s e n t e d  i n  S e c t i o n  2  4  a n d  A l g o r i t h m  1   t h e r e  a r e  t w o  l e a r n i n g  p r o c e s s e s  i n  c u r r e n t  r e s e a r c h   O n e  i s  t h e  s u p p l e m e n t  l e a r n i n g  t h a t  a p p e n d s  n e w  c o n d i t i o n a l  a t o m s  i n t o  t h e  o r i g i n a l  p r e d i c t i o n  t o  e l i m i n a t e  t h e  n e g a t i v e  i n s t a n c e s   T h e  o t h e r  i s  t h e  f u l l  l e a r n i n g  t h a t  d i s c a r d s  t h e  o r i g i n a l  g u e s s  i f  t h e  c o v e r a g e  i s  v e r y  l o w  a n d  s t a r t s  a  n e w  l e a r n i n g  p r o c e s s  t o  w o r k  o u t  t h e  r u l e s       a  T r a i n i n g  d a t a    b   S u p p l e m e n t  l e a r n i n g  p r o c e s s   F i g u r e  3   S u p p l e m e n t  l e a r n i n g  W e  f i r s t  f o c u s  o n  t h e  s u p p l e m e n t  l e a r n i n g   A s  s h o w n  i n  F i g u r e  3   a r e a  2   3  a n d  4  c o m p o s e  t h e  n e g a t i v e  s e t    F i g u r e  3   b   d e s c r i b e s  a  l e a r n i n g  p r o c e s s  A r e a  5  i s  o n e  o f  t h e  m i d d l e  l e a r n i n g  r e s u l t s  c o v e r i n g  n o t  o n l y  p o s i t i v e  i n s t a n c e s  b u t  a l s o  s o m e  n e g a t i v e  i n s t a n c e s   W i t h  t h e  l e a r n i n g  p r o c e e d i n g  b y  a p p e n d i n g  o t h e r  a t t r i b u t e s  o r  p a r a m e t e r s   t h e  s y s t e m  g e t s  a r e a  6   A n d  t h e n   t h e  l e a r n i n g  p r o c e s s  e n d s  a t  a r e a  7  t h a t  c o v e r s  o n l y  t h e  p o s i t i v e s   O n c e  w e  g e t  t h e  s u p p l e m e n t  o f  c o n d i t i o n s   w e  s h o u l d  c o m b i n e  t h e  r e s u l t  w i t h  t h e  o r i g i n a l  c o n d i t i o n  t o  s a t i s f y  t h e  o r i g i n a l  c o n s e q u e n c e   I f  t h e  c u r r e n t l y  g e n e r a t e d  r u l e s  c a n  t  c o v e r  a l l  t h e  p o s i t i v e  i n s t a n c e s   t h e  s y s t e m  n e e d s  t o  c o n t i n u e  l e a r n i n g  o t h e r  n e w  r u l e s  t i l l  t h e  p o s i t i v e  s e t  i s  e m p t y  o r  i t  r e a c h e s  a  v e r y  h i g h  c o v e r a g e   S o  e a c h  t i m e   t h e  s y s t e m  n e e d s  t o  r e a d j u s t  t h e  p o s i t i v e  s e t  b y  e l i m i n a t i n g  t h e  c o v e r e d  p o s i t i v e s  i n  a r e a  1    B e c a u s e  w e  a r e  n o w  u s i n g  t h e  r e l a t i o n a l  d a t a   i t  i s  b e n e f i c i a l  t o  d e c r e a s e  t h e  s e a r c h i n g  s c a l e  b y  f i x i n g  t h e  c u r r e n t  p a r a m e t r i c  a t t r i b u t e  t o  b e  u s e d  i n  t h e  n e x t  s t e p   F o r  t h e  d e t a i l  o f  l e a r n i n g  p r o c e s s   w e  m a i n l y  u s e  t h e  i n d u c t i v e  l e a r n i n g  o f  H o r n  c l a u s e s  t o  l e a r n  t h e  f i r s t o r d e r  l o g i c  r u l e s   1 8   1 9    T h i s  i s  b a s e d  o n  a  r u l e l e a r n i n g  a l g o r i t h m  c a l l e d  I n c r e m e n t a l  R e d u c e d  E r r o r  P r u n i n g   I R E P    2 0    T h e  c o n d i t i o n a l  l i t e r a l  a d d e d  i s  t h e  o n e  t h a t  y i e l d s  t h e  l a r g e s t  i n f o r m a t i o n  g a i n  f o r  r u l e i  1  r e l a t i v e  t o  r u l e i   1 9    I n f o r m a t i o n  g a i n  i s  d e f i n e d  a s     1 1   w h e r e  T i    T i   i s  t h e  n u m b e r  o f  p o s i t i v e   n e g a t i v e   i n s t a n c e s  i n  t h e  g r o w i n g  s e t  c o v e r e d  b y  r u l e i   I n f o r m a t i o n  g a i n  r e w a r d s  r u l e i  1 t h a t  i n c r e a s e  t h e  d e n s i t y  o f  p o s i t i v e  i n s t a n c e s  c o v e r e d  b y  t h e  r u l e   w i t h o u t  g r e a t l y  r e d u c i n g  t h e  t o t a l  n u m b e r  o f  c o v e r e d  p o s i t i v e  i n s t a n c e s   A f t e r  g r o w i n g  a  r u l e   t h e  r u l e  i s  p r u n e d   A t  e a c h  s t a g e   I R E P  c o n s i d e r s  d e l e t i n g  a n y  f i n a l  s e q u e n c e  o f  c o n d i t i o n s  f r o m  t h e  r u l e  a n d  c h o o s e s  t h e  d e l e t i o n  t h a t  m a x i m i z e s  t h e  f u n c t i o n                              1 2   w h e r e  U i  1    U i  1   i s  t h e  n u m b e r  o f  p o s i t i v e   n e g a t i v e   i n s t a n c e s  i n  t h e  p r u n i n g  s e t  c o v e r e d  b y  t h e  n e w  r u l e   A f t e r  p r u n i n g   t h e  p r u n e d  c l a u s e  i s  a d d e d  t o  t h e  r u l e  s e t   a n d  t h e  i n s t a n c e s  c o v e r e d  b y  i t  a r e  r e m o v e d   A l g o r i t h m  3      S u p p l e m e n t  l e a r n i n g  P u t  t h e  o r i g i n a l  a t t r i b u t e s  a n d  p a r a m e t e r s  i n t o  2  a r r a y s    A t t r i b u t e s _ t o _ b e _ l e a r n e d  a n d  P a r a m e t e r s _ t o _ b e _ l e a r n e d   R e c o r d  t h e  M i n i m u m   M a x i m u m  a n d  m i n i m u m  I n t e r v a l       o f  p a r a m e t e r s   i n  P a r a m e t e r s _ t o _ b e _ l e a r n e d    C o n d i t i o n   A t t r      A t t r i b u t e s _ t o _ b e _ l e a r n e d   C o n d i t i o n   A t t r  P a r      P a r a m e t e r s _ t o _ b e _ l e a r n e d   i f f    A t t r i b u t e s _ t o _ b e _ l e a r n e d   N U L L            i f f    P a r a m e t e r s _ t o _ b e _ l e a r n e d   N U L L                 i f f   t h e  v a l u e  o f  t h e  p a r a m e t e r  i s  n u m e r i c                  V a l u e   M i n i m u m                 f o r   i  M i n i m u m   M a x i m u m   I n t e r v a l                           C o n d i t i o n   A t t r  P a r  V a l u e    V a l u e                       C o m p u t e  I n f o r m a t i o n  G a i n   r u l e i  1   r u l e i                           i f f  G a i n  i s  i n c r e a s i n g    K e e p  t h i s  v a l u e  a n d                 a t t r i b u t e  i n  t h e  P r u n i n g  S e t               i f f   t h e  G a i n  d o e s n  t  i n c r e a s e  a n y  m o r e                    b r e a k              V a l u e  V a l u e   I n t e r v a l                                     L e a r n i n g  p r o c e s s  f o r  c a t e g o r i c a l  a t t r i b u t e s           e l s e                  C o n d i t i o n   A t t r  P a r  V a l u e                                                       P a r a m e t e r s _ t o _ b e _ l e a r n e d         C o m p u t e  I n f o r m a t i o n  G a i n                     i f f  G a i n  i s  i n c r e a s i n g    K e e p  t h i s  v a l u e  a n d            a t t r i b u t e  i n  t h e  P r u n i n g  S e t        i f f   t h e  n e g a t i v e s  a r e  r e d u c e d  t o  a  g i v e n  m i n i m u m             b r e a k        P a r a m e t e r s _ t o _ b e _ l e a r n e d                            P a r a m e t e r s _ t o _ b e _ l e a r n e d            C o n d i t i o n   A t t r  P a r    P a r a m e t e r s _ t o _ b e _ l e a r n e d                 A t t r i b u t e s _ t o _ b e _ l e a r n e d          C o n d i t i o n   A t t r      A t t r i b u t e s _ t o _ b e _ l e a r n e d        P r u n e  t h e  c o n d i t i o n s  i n  t h e  P r u n i n g  S e t   M e r g e  t h e  p a r a m e t r i c  v a l u e s  a n d  r a n g e s  t o g e t h e r   D e l e t e  t h e  p o s i t i v e s  c o v e r e d  b y  t h e  f o r m e r  c o n d i t i o n s   i f f   t h e  P o s i t i v e  S e t  i s  e m p t y  o r  C o v e r a g e  i s   s a t i s f i e d                  


       s t o p  l e a r n i n g   e l s e                   s t a r t  a  l e a r n i n g  p r o c e s s  a g a i n       L e a r n i n g  E n d s  A s  f o r  t h e  f u l l  l e a r n i n g   t h e  w h o l e  p r o c e s s  i s  s i m i l a r  t o  t h e  s u p p l e m e n t  l e a r n i n g  e x c e p t  f o r  n e g l e c t i n g  t h e  o r i g i n a l  c o n d i t i o n  a n d  b e g i n n i n g  f r o m  s c r a t c h  t o  f i n d  t h e  r u l e s   B e s i d e s   t h e  p o s i t i v e  a n d  n e g a t i v e  s e t s  n e e d  t o  b e  r e p a r t i t i o n e d  o n l y  a c c o r d i n g  t o  w h e t h e r  t h e  i n s t a n c e  b e l o n g s  t o  t h e  C o n s e q u e n c e  P a r t  o r  N o n C o n s e q u e n c e  P a r t    3  C on c l u s i on s  an d  F u t u r e  Wor k  I n  t h i s  p a p e r   w e  h a v e  e x p l a i n e d  a  n e w  a p p r o a c h  t o  g e n e r a t i n g  h i g h d i m e n s i o n a l  a s s o c i a t i o n  r u l e s   T h i s  m e t h o d  i n c l u d e s  a  s e t  o f  t a s k s  s u c h  a s  1   c o n s t r u c t i o n  o f  p r e d i c t i o n  s p a c e   2   g e n e r a t i o n  o f  p r e d i c t i o n s   3   v a l i d a t i o n  o f  t h e  p r o p o s e d  p r e d i c t i o n s   a n d  4   p r o d u c t i o n  o f  n e w  r u l e s   W e  s h o w e d  t h a t  o u r  a p p r o a c h  i s  s o l i d  a n d  s o u n d     W e  h a v e  i n t r o d u c e d  h e r e  a n  e x h a u s t  s e a r c h i n g  m e t h o d  t o  p r o p o s e  t h e  p o s s i b l e  p r e d i c t i o n s  b a s e d  o n  a  u n i f o r m  d i s t r i b u t i o n   A c t u a l l y   t h e r e  w o u l d  b e  s o m e  r o u t i n e s  a n d  r e l a t i o n s h i p s  e x i s t i n g  a m o n g  t h e  a t t r i b u t e s  a n d  t h e i r  p a r a m e t e r s   F o r  f u t u r e  w o r k   w e  n e e d  t o  d e v e l o p  a  s e t  o f  a p p r o p r i a t e  a l g o r i t h m s  t o  e n h a n c e  t h e  a u t o m a t i c  p r o p o s i n g  a l g o r i t h m s  o f  p r e d i c t i o n s   T h e s e  a l g o r i t h m s  s h o u l d  b e  r o b u s t  a n d  f l e x i b l e  t o  c o n t r o l  t h e  p r o p o s i n g  p r o c e s s   a n d  s h o u l d  w i s e l y  j u d g e  a n d  r e c o g n i z e  w h a t  k i n d s  o f  a t t r i b u t e s  w i l l  b e  p r o p o s e d  a t  n e x t  s t e p  b a s e d  o n  s t a t i s t i c a l  a n a l y s i s  a n d  f i e l d  k n o w l e d g e    O u r  c u r r e n t  t a r g e t  d a t a s e t  c o n s i s t s  o f  a  l a r g e  v o l u m e  o f  r e l a t i o n a l  d a t a   W e  w i l l  e x t e n d  t h e  c u r r e n t  w o r k  t o  o b j e c t  r e l a t i o n a l  a p p l i c a t i o n s   T h e  r e p r e s e n t a t i o n  a n d  s t o r a g e  m e a n s  w i l l  d i f f e r  f r o m  t h o s e  o f  r e l a t i o n a l  d a t a    R e f e r e n c e s   1   A b r a h a m  S i l b e r s c h a t z   H e n r y  F   K o r t h   S   S u d a r s h a n   D a t a b a s e  S y s t e m  C o n c e p t   t h e  4 t h  e d i t i o n   M c G r a w  H i l l  P r e s s   2 0 0 2    2   J i a n j i a n g  L u   B a o w e n  X u   J i x i a n g  J i a n g   322 A  p r e d i c t i o n  m e t h o d  o f  f u z z y  a s s o c i a t i o n  r u l e s 323   I E E E  I n t e r n a t i o n a l  C o n f e r e n c e  o n  I n f o r m a t i o n  R e u s e  a n d  I n t e g r a t i o n   2 0 0 3   p p   9 8  1 0 3    3   O o i  B o o n  Y a i k   C h a n  H u a h  Y o n g   F   H a r o n   322 T i m e  S e r i e s  P r e d i c t i o n  u s i n g  A d a p t i v e  A s s o c i a t i o n  R u l e s 323   1 s t  I n t e r n a t i o n a l  C o n f e r e n c e  o n  D i s t r i b u t e d  F r a m e w o r k s  f o r  M u l t i m e d i a  A p p l i c a t i o n s   2 0 0 5   p p   3 1 0 3 1 4    4   L i  M i n  F u   E  H    S h o r t l i f f e   322 T h e  A p p l i c a t i o n  o f  C e r t a i n t y  F a c t o r s  t o  N e u r a l  C o m p u t i n g  f o r  R u l e  d i s c o v e r y 323   I E E E  T r a n s a c t i o n s  o n  N e u r a l  N e t w o r k s   v o l   1 1   n o   3   2 0 0 0   p p   6 4 7 6 5 7    5   L  J   M a z l a c k   322 C a u s a l  P o s s i b i l i t y  M o d e l  S t r u c t u r e s 323   T h e  1 2 t h  I E E E  I n t e r n a t i o n a l  C o n f e r e n c e  o n  F u z z y  S y s t e m s   2 0 0 3   v o l   1   n o   2 5   p p   6 8 4 6 8 9    6   Y  P   S i n g h   A r a b y   322 N  A  R  E v o l u t i o n a r y  A p p r o a c h  t o  D a t a  M i n i n g 323   P r o c e e d i n g s  o f  I E E E  I n t e r n a t i o n a l  C o n f e r e n c e  o n  I n d u s t r i a l  T e c h n o l o g y   v o l   1   2 0 0 0   p p   7 5 6 7 6 0    7   W   H   I n m o n r i i l d   S   O s t e r f e l t   U n d e r s t a n d i n g  D a t a  P a t t e r n  P r o c e s s i n g   Q E D  T e c h n i c a l  P u b l i s h i n g  G r o u p   W e l l e s l e y   M A   1 9 9 1    8   W a i H o  A u   C h a n   K  C  C    322 F u z z y  D a t a  M i n i n g  f o r  D i s c o v e r i n g  C h a n g e s  i n  A s s o c i a t i o n  R u l e s  O v e r  T i m e 323   P r o c e e d i n g s  o f  I E E E  I n t e r n a t i o n a l  C o n f e r e n c e  o n  F u z z y  S y s t e m s   2 0 0 2   v o l   2    n o   1 2   p p   8 9 0 8 9 5    9   Y u n f e n g  D u a n   T a n g  S h i w e i   Y a n g  D o n g q i n g  a n d  M e i n a  S o n g   322 A s s o c i a t i o n  R u l e  M i n i n g  B a s e d  o n  t h e  M u l t i p l e D i m e n s i o n a l  I t e m  A t t r i b u t e s 323   P r o c e e d i n g s  o f  C o n c e p t u a l  M o d e l i n g  f o r  A d v a n c e d  A p p l i c a t i o n  D o m a i n s  E R   2 0 0 4  W o r k s h o p s   S h a n g h a i   C h i n a   N o v e m b e r  8 1 2   2 0 0 4     1 0   J i a w e i  H a n   Y   C a i  a n d  N   C e r c o n e   322 K n o w l e d g e  D i s c o v e r y  i n  D a t a b a s e s   A n  A t t r i b u t e O r i e n t e d  A p p r o a c h 323   V L D B   V a n c o u v e r   C a n a d a   1 9 9 2   p p   5 4 7 5 5 9    1 1   G   C o o p e r   322 A  S i m p l e  C o n s t r a i n t b a s e d  A l g o r i t h m  f o r  E f f i c i e n t l y  M i n i n g  O b s e r v a t i o n a l  D a t a b a s e s  f o r  C a u s a l  r e l a t i o n s h i p s 323   D a t a  M i n i n g  a n d  K n o w l e d g e  D i s c o v e r y   v o l   2   1 9 9 7    1 2   S i l v e r s t e i n   C    S   B r i n   R   M o t w a n i   a n d  J   U l l m a n   322 S c a l a b l e  T e c h n i q u e s  f o r  M i n i n g  C a u s a l  S t r u c t u r e s 323   P r o c e e d i n g s  o f  t h e  2 4 t h  I n t e r n a t i o n a l  C o n f e r e n c e  o n  V e r y  L a r g e  D a t a  B a s e s   A u g u s t  2 4   2 7   1 9 9 8   p p   5 9 4   6 0 5    1 3   J i a n j i a n g  L u   B a o w e n  X u   J i x i a n g  J i a n g   322 A  P r e d i c t i o n  M e t h o d  o f  F u z z y  A s s o c i a t i o n  R u l e s 323   I E E E  I n t e r n a t i o n a l  C o n f e r e n c e  o n  I n f o r m a t i o n  R e u s e  a n d  I n t e g r a t i o n   2 7 2 9  O c t   2 0 0 3   p p   9 8 1 0 3    1 4   L i  M i n  F u   S h o r t l i f f e   E  H   322 T h e  A p p l i c a t i o n  o f  C e r t a i n t y  F a c t o r s  t o  N e u r a l  C o m p u t i n g  f o r  R u l e  D i s c o v e r y 323   I E E E  T r a n s a c t i o n s  o n  N e u r a l  N e t w o r k s   v o l   1 1   n o   3   M a y  2 0 0 0   p p   6 4 7 6 5 7    1 5   R   A g r a w a l   S  P  G h o s h   322 A n  I n t e r v a l  C l a s s i f i e r  f o r  D a t a b a s e  M i n i n g  A p p l i c a t i o n s 323   P r o c e e d i n g  o f  t h e  I n t e r n a t i o n a l  C o n f   o n  V e r y  L a r g e  D a t a b a s e   1 9 9 2   p p   5 6 0 5 7 3    1 6   J  C   S h a f e r   R   A g r a w a l   a n d  M  M e h t a   322 S P R I N T   A  S c a l a b l e  P a r a l l e l  C l a s s i f i e r  f o r  D a t a  M i n i n g 323   P r o c e e d i n g  o f  t h e  I n t e r n a t i o n a l  C o n f e r e n c e  o n  V e r y  L a r g e  d a t a b a s e s   1 9 9 6   p p   5 4 4 5 5 5    1 7   A g n e r  F o g   D e f i n i t i o n  o f  d i s t r i b u t i o n s   h t t p    w w w  a g n e r  o r g  r a n d o m   J a n u a r y  2 0 0 4     1 8   N i l s  J   N i l s s o n   A r t i f i c i a l  I n t e l l i g e n c e   A  N e w  S y n t h e s i s   M o r g a n  K a u f m a n n  P u b l i s h e r   I n c   1 9 9 8     1 9   Q u i n l a n   J  R    322 L e a r n i n g  L o g i c a l  D e f i n i t i o n s  f r o m  r e l a t i o n s 323   M a c h i n e  L e a r n i n g   v o l   5   n o   3   1 9 9 0   p p  2 3 9 2 6 6   2 0   F 206 R N K R A N Z   J   A N D  W I D M E R   G   322 I n c r e m e n t a l  R e d u c e d  E r r o r  P r u n i n g 323   P r o c e e d i n g s  o f  t h e  1 1 t h  A n n u a l  C o n f e r e n c e  o n  M a c h i n e  L e a r n i n g   M o r g a n  K a u f m a n n  P u b l i s h e r s  I n c    N e w  B r u n s w i c k   N J   1 9 9 4    


4J H. Fu and E. Mephu Nguifo. Partitioning large data to scale up lattice-based algorithm. In Proceedings ofICTAI03 pages S37-S41, Sacramento, CA, November 20 03. IEEE Press SJ H. Fu and E. Mephu Nguifo. How well go lattice algo  rithms on currently used machine learning testbeds? In 4emes journees d' Extraction et de Gestion des Connais  sances, pages 373-384, France, 20 04 61 B. Ganter and R. Wille. Formal Concept Analysis. Mathe  matical Foundations. Springer, 1999 7J J. Han, J. Pei, and Y. Yin. Mining frequent patterns without candidate generation. In W. Chen, J. Naughton, and P. A Bernstein, editors, 2000 ACM SIGMOD Intl. Conference on Management of Data, pages 1-12. ACM Press, OS 2000 Data file Objects Items Min support FCI PFC \(msec msec audiology 26 110 1 30401 1302 8563 soybean-small 47 79 1 3541 516 431 lung-cancer 32 228 1 186092 21381 279689 promoters 106 228 3 298772 120426 111421 soybean-large 307 133 1 806030 357408 364524 dermatogogy 366 130 50 192203 20204 18387 breast-cancer-wis 699 110 1 9860 3529 1131 kr-vs-kp 3196 75 1100 2770846 1823092 483896 agaricus-Iepiota 8124 124 100 38347 34815 1462 connect-4bi.data 67557 126 1000 2447136 1165806 65084 Table 1. Experiments on real data.\(FCI means frequent closed itemsets. msec means milliseconds For Ref., + means PFC is faster than CLOSET Data file Min support FCI PFC \(msec msec Worst16 1 65534 571 470 271 9 Worst17 1 131070 1112 1002 541 9 Worst18 1 262142 2243 2174 1091 9 Worst19 1 524286 4576 4466 2213 10 Worst20 1 1048574 9243 9484 4606 10 Worst25 20 68405 2103 66916 451 11 Worst25 19 245505 6099 1095065 1552 11 Worst25 18 726205 15452 10235287 4486 11 Worst25 17 1807780 33348 / 10755 11 Worst25 15 7119515 102237 / 39296 11 Worst30 25 174436 6980 426964 1302 12 Worst30 20 53009101 1029771 / 344035 12 Worst50 47 20875 1132 1042 422 14 Worst50 45 2369935 227207 / 29102 14 Worst60 57 36050 7320 3205 821 15 Worst60 56 523685 82938 1665715 9123 15 Worst60 55 5985197 772210 / 92102 15 Worst70 68 2485 1102 190 121 15 Worst70 67 57225 18096 9483 1933 15 Worst70 66 974120 242138 / 26398 15 Table 2. Experiments on the worst case data 8] S. Kuznetsov and S. Obiedkov. Comparing performance of algorithms for generating concept lattices. lETAI Special Issue on Concept Lattice for KDD, 14\(2/3 9j E. Mephu Nguifo, M. Liquiere, and V. Duquenne. lETA Special Issue on Concept Lattice for KDD. Taylor and Fran  cis, 2002 IOj N. Pasquier, Y. Bastide, R. Taouil, and L. Lakhal. Efficient mining of association rules using closed itemsets lattices lournal of Information Systems, 24\(1 II j 1. Pei, 1. Han, and R. Mao. CLOSET: An efficient algo  rithm for mining frequent closed itemsets. InACM SIGMOD Workshop on Research Issues in Data Mining and Knowl  edge Discovery, pages 21-3 0, 200 0 12] 1. Wang, 1. Han, and 1. Pei. Closet+: Searching for the best strategies for mining frequent closed itelnsets. In In Pro  ceedings of the Ninth ACM SIGKDD International Confer  ence on Knowledge Discovery and Data Mining \(KDD'03 Washington, DC, USA, 2003 13] M. I. Zaki and C.-I. Hsiao. CHARM: An efficient algorithm for closed item set mining. Technical Report 99-10, Rensse  laer Polytechnic Institute, 1999 


laer Polytechnic Institute, 1999 pre></body></html 


efficiency then AOFI. However utilization of fuzzy concept hierarchies provides more flexibility in reflecting expert knowledge and so allows better modeling of real-life dependencies among attribute values, which will lead to more satisfactory overall results for the induction process. The drawback of the computational cost may additionally decline when we notice that, in contrast to many other data mining algorithms, hierarchical induction algorithms need to run only once through the original \(i.e. massive dataset. We are continuing an investigation of computational costs of our approach for large datasets ACKNOWLEDGMENT Rafal Angryk would like to thank the Montana NASA EPSCoR Grant Consortium for sponsoring this research REFERENCES 1] J. Han , M. Kamber, Data Mining: Concepts and Techniques, Morgan Kaufmann, New York, NY 2000 2] J. Han, Y. Cai, and N. Cercone  Knowledge discovery in databases: An attribute-oriented approach  Proc. 18th Int. Conf. Ver y Large Data Bases, Vancouver, Canada, 1992, pp. 547-559 3] J. Han  Towards Efficient Induction Mechanisms in Database Systems  Theoretical Computing Science, 133, 1994, pp. 361-385 4] J. Han, Y. Fu  Discovery of Multiple-Level Association Rules from Large Databases  IEEE Trans.  on KD E, 11\(5 5] C.L. Carter, H.J. Hamilton  Efficient AttributeOriented Generalization for Knowledge Discovery from Large Databases  IEEE Trans. on KDE 10\(2 6] R.J. Hilderman, H.J. Hamilton, and N. Cercone  Data mining in large databases using domain generalization graphs  Journal of Intelligent Information Systems, 13\(3 7] C.-C. Hsu  Extending attribute-oriented induction algorithm for major values and numeric values   Expert Systems with Applications , 27, 2004, pp 187-202 8] D.H. Lee, M.H. Kim  Database summarization using fuzzy ISA hierarchies  IEEE Trans . on SMC - part B, 27\(1 9] K.-M. Lee  Mining generalized fuzzy quantitative association rules with fuzzy generalization hierarchies  20th NAFIPS Int'l Conf., Vancouver Canada, 2001, pp. 2977-2982 10] J. C. Cubero, J.M. Medina, O. Pons &amp; M.A. Vila  Data Summarization in Relational Databases through  Fuzzy Dependencies  Information Sciences, 121\(3-4 11] G. Raschia, N. Mouaddib  SAINTETIQ:a fuzzy set-based approach to database summarization   Fuzzy Sets and Systems, 129\(2 162 12] R. Angryk, F. Petry  Consistent fuzzy concept hierarchies for attribute generalization  Proceeding of the IASTED Int. Conf. on Information and Knowledge Sharing, Scottsdale AZ, USA, November 2003, pp. 158-163 13] Toxics Release Inventory \(TRI available EPA database hosted at http://www.epa.gov/tri/tridata/tri01/index.htm The 2005 IEEE International Conference on Fuzzy Systems790 pre></body></html 


the initial global candidate set would be similar to the set of global MFIs. As a result, during the global mining phase the communication and synchronization overhead is low  0 2 4 6 8 1 0 Number of Nodes Figure 5. Speedup of DMM 4.4.2 Sizeup For the sizeup test, we fixed the system to the 8-node con figuration, and distributed each database listed in Table 2 to the 8 nodes. Then, we increased the local database sire at each node from 45 MB to 215 MB by duplicating the initial database partition allocated to the node. Thus, the data distribution characteristics remained the same as the local database size was increased. This is different from the speedup test, where the database repartitioning was per formed when the number of nodes was increased. The per formance of DMM is affected by the database repartitioning to some extent, although it is usually very small. During the sizeup test, the local mining result of DMM is not changed at all at each node The results shown in Figure 6 indicate that DMM has a very good sizeup property. Since increasing the size of local database did not affect the local mining result of DMM at each node, the total execution time increased just due to more disk U 0  and computation cost which scaled almost linearly with sizeup 5 Conclusions In this paper, we proposed a new parallel maximal fre quent itemset \(MFI Max-Miner \(DMM tems. DMM is a parallel version of Max-Miner, and it re quires low synchronization and communication overhead compared to other parallel algorithms. In DMM, Max Miner is applied on each database partition during the lo 0 45 90 135 180 225 270 Amwnt of Data per Node \(ME Figure 6. Sizeup of DMM cal mining phase. Only one synchronization is needed at thc end of this phase to construct thc initial global candi date set. In the global mining phase, a top-down search is performed on the candidate set, and a prefix tree is used to count the candidates with different length efficiently. Usu ally, just a few passes are needed to find all global maximal frequent itemsets. Thus, DMM largely reduces the number of synchronizations required between processing nodes Compared with Count Distribution, DMM shows a great improvement when some frequent itemscts are large \(i.e long patterns employed by DMM for efficient communication between nodes; and global support estimation, subset-infrequency based pruning, and superset-frequency based pruning are used to reduce the size of global candidate set. DMM has very good speedup and sizeup properties References I ]  R. Agrawal and R. Srikant  FdSt Algorithms for Mining As sociation Rules  Pmc. o f f h e  ZOrh VLDB Conf, 1994, pp 487499 2] R. Agrawal and I. C. Shafer  Parallel Mining of Association Rules  IEEE Trans. on Knowledge and Dura Engineering Vol. 8, No. 6, 1996, pp. 962-969 3] R. I. Bayardo  Efficient Mining Long Patlems from Databases  Proc. ofrhe ACM SIGMOD Inf  l Conf on Man ogemenr ofDara, 1998, pp. 85-91 4] S.  M. Chung and J. Yang  A Parallel Distributive Join Al gorithm for Cube-Connected Multiprocessors  IEEE Trans on Parallel and Disrribured Systems, Vol. 7, No. 2, 1996, pp 127-137 51 M. Snir, S. Otto. S. Huss-Lederman, D. Walker, and J. Don gana, MPI: The Complete Reference, The MIT Press, 1996 


gana, MPI: The Complete Reference, The MIT Press, 1996 6] R. Rymon  Search through Systematic Set Enumeralion   Pmc. of3rd Inr  l Con$ on Principles of Knowledge Repre sentation and Reasoning, 1992, pp. 539-550 507 pre></body></html 


sketch-index in answering aggregate queries. Then Section 5.2 studies the effect of approximating spatiotemporal data, while Section 5.3 presents preliminary results for mining association rules 5.1 Performance of sketch-indexes Due to the lack of real spatio-temporal datasets we generate synthetic data in a way similar to [SJLL00 TPS03] aiming at simulation of air traffic. We first adopt a real spatial dataset [Tiger] that contains 10k 2D points representing locations in the Long Beach county \(the data space is normalized to unit length on each dimension These points serve as the  airbases  At the initial timestamp 0, we generate 100k air planes, such that each plane \(i uniformly generated in [200,300], \(ii, iii destination that are two random different airbases, and iv  the velocity direction is determined by the orientation of the line segment connecting its source and destination airbases move continually according to their velocities. Once a plane reaches its destination, it flies towards another randomly selected also uniform in [0.02, 0.04 reports to its nearest airbase, or specifically, the database consists of tuples in the form &lt;time t, airbase b, plane p passenger # a&gt;, specifying that plane p with a passengers is closest to base b at time t A spatio-temporal count/sum query has two parameters the length qrlen of its query \(square number qtlen of timestamps covered by its interval. The actual extent of the window \(interval uniformly in the data space \(history, i.e., timestamps 0,100 air planes that report to airbases in qr during qt, while a sum query returns the sum of these planes  passengers. A workload consists of 100 queries with the same parameters qrlen and qtlen The disk page size is set to 1k in all cases \(the relatively small page size simulates situations where the database is much more voluminous specialized method for distinct spatio-temporal aggregation, we compare the sketch-index to the following relational approach that can be implemented in a DBMS. Specifically, we index the 4-tuple table lt;t,b,p,a&gt; using a B-tree on the time t column. Given a count query \(with window qr and interval qt SELECT distinct p FROM &lt;t,b,p,a&gt WHERE t?qt &amp; b contained in qr The performance of each method is measured as the average number of page accesses \(per query processing a workload. For the sketch-index, we also report the average \(relative Specifically, let acti and esti be the actual and estimated results of the i-th query in the workload; then the error equals \(1/100 set the number of bits in each sketch to 24, and vary the number of sketches The first experiment evaluates the space consumption Figure 5.1 shows the sketch index size as a function of the number of sketches used \(count- and sum-indexes have the same results more sketches are included, but is usually considerably smaller than the database size \(e.g., for 16 signatures, the size is only 40% the database size 0 20 40 60 80 


80 100 120 140 160 8 16 32 number of sketches size \(mega bytes database size Figure 5.1: Size comparison Next we demonstrate the superiority of the proposed sketch-pruning query algorithm, with respect to the na  ve one that applies only spatio-temporal predicates. Figure 5.2a illustrates the costs of both algorithms for countworkloads with qtlen=10 and various qrlen \(the index used in this case has 16 sketches also illustrate the performance of the relational method which, however, is clearly incomparable \(for qrlen?0.1, it is worse by an order of magnitude we omit this technique Sketch-pruning always outperforms na  ve \(e.g., eventually two times faster for qrlen=0.25 increases with qrlen, since queries returning larger results tend to set bits in the result sketch more quickly, thus enhancing the power of Heuristics 3.1 and 3.2. In Figure 5.2b, we compare the two methods by fixing qrlen to 0.15 and varying qtlen. Similar to the findings of [PTKZ02]4 both algorithms demonstrate  step-wise  growths in their costs, while sketch-pruning is again significantly faster The experiments with sum-workloads lead to the same observations, and therefore we evaluate sketch-indexes using sketch-pruning in the rest of the experiments 4 As explained in [PTKZ02], query processing accesses at most two paths from the root to the leaf level of each B-tree regardless the length of the query interval Proceedings of the 20th International Conference on Data Engineering \(ICDE  04 1063-6382/04 $ 20.00  2004 IEEE sketch-pruning naive relational 0 100 200 300 400 500 600 700 800 900 0.05 0.1 0.15 0.2 0.25 number of disk accesses query rectangle length 300 0 100 200 400 500 600 1 5 10 15 20 number of disk accesses query interval length a qtlen=10 b qrlen=0.15 Figure 5.2: Superiority of sketch-pruning \(count As discussed in Section 2, a large number of sketches reduces the variance in the resulting estimate. To verify this, Figure 5.3a plots the count-workload error of indexes 


using 8-, 16-, and 32- sketches, as a function of qrlen qtlen=10 error \(below 10 it increases slowly with qrlen used, however, the error rate is much higher \(up to 30 and has serious fluctuation, indicating the prediction is not robust. The performance of 16-sketch is in between these two extremes, or specifically, its accuracy is reasonably high \(average error around 15 much less fluctuation than 8-sketch 32-sketch 16-sketch 8-sketch relative error 0 5 10 15 20 25 30 35 0.05 0.1 0.15 0.2 0.25 query rectangle length relative error 0 5 10 15 20 25 30 35 1 5 10 15 20 query interval length a qtlen=10, count b qrlen=0.15, count relative error query rectangle length 0 5 10 15 20 25 0.05 0.1 0.15 0.2 0.25 relative error query interval length 0 5 10 15 20 25 30 1 5 10 15 20 c qtlen=10, sum d qrlen=0.15, sum Figure 5.3: Accuracy of the approximate results The same phenomena are confirmed in Figures 5.3b where we fix qrlen to 0.15 and vary qtlen 5.3d \(results for sum-workloads number of sketches improves the estimation accuracy, it also leads to higher space requirements \(as shown in Figure 5.1 Figures 5.4a and 5.4b show the number of disk accesses for the settings of Figures 5.3a and 5.3b. All indexes have almost the same behavior, while the 32-sketch is clearly more expensive than the other two indexes. The interesting observation is that 8- and 16-sketches have 


interesting observation is that 8- and 16-sketches have almost the same overhead due to the similar heights of their B-trees. Since the diagrams for sum-workloads illustrate \(almost avoid redundancy 32-sketch 16-sketch 8-sketch number of disk accesses query rectangle length 0 50 100 150 200 250 300 350 400 0.05 0.1 0.15 0.2 0.25 number of disk accesses query interval length 0 50 100 150 200 250 300 350 1 5 10 15 20 a qtlen=10 b qrlen=0.15 Figure 5.4: Costs of indexes with various signatures Summary: The sketch index constitutes an effective method for approximate spatio-temporal \(distinct aggregate processing. Particularly, the best tradeoff between space, query time, and estimation accuracy obtained by 16 sketches, which leads to size around 40 the database, fast response time \(an order of magnitude faster than the relational method average relative error 5.2 Approximating spatio-temporal data We proceed to study the efficiency of using sketches to approximate spatio-temporal data \(proposed in Section 4.1 as in the last section, except that at each timestamp all airplanes report their locations to a central server \(instead of their respective nearest bases maintains a table in the form &lt;time t, plane p, x, y&gt;, where x,y with parameters qrlen and qtlen distinct planes satisfying the spatial and temporal conditions. For comparison, we index the table using a 3D R*-tree on the columns time, x, and y. Given a query, this tree facilitates the retrieval of all qualifying tuples, after which a post-processing step is performed to obtain the Proceedings of the 20th International Conference on Data Engineering \(ICDE  04 1063-6382/04 $ 20.00  2004 IEEE number of distinct planes \(in the sequel, we refer to this method as 3DR method introduces a regular res  res grid of the data space, where the resolution res is a parameter. We adopt 16 sketches because, as mentioned earlier, this number gives the best overall performance Figure 5.5 compares the sizes of the resulting sketch indexes \(obtained with resolutions res=25, 50, 100 the database size. In all cases, we achieve high compression rate \(e.g., the rate is 25% for res=25 evaluate the query efficiency, we first set the resolution to the median value 50, and use the sketch index to answer workloads with various qrlen \(qtlen=10 


workloads with various qrlen \(qtlen=10 size \(mega bytes database size 0 20 40 60 80 100 120 140 160 25 50 100 resolution Figure 5.5: Size reduction Figure 5.6a shows the query costs \(together with the error in each case method. The sketch index is faster than 3DR by an order of magnitude \(note that the vertical axis is in logarithmic scale around 15% error observations using workloads with different qtlen Finally, we examine the effect of resolution res using a workload with qrlen=0.15 and qtlen=10. As shown in Figure 5.6c, larger res incurs higher query overhead, but improves the estimation accuracy Summary: The proposed sketch method can be used to efficiently approximate spatio-temporal data for aggregate processing. It consumes significantly smaller space, and answers a query almost in real-time with low error 3D Rsketch number of disk accesses query rectangle length 1 10 100 1k 10k 0.05 0.1 0.15 0.2 0.25 16 14% 15 15% 13 relative error number of disk accesses query interval length 1 10 100 1k 10k 1 5 10 15 20 16 15% 15% 12% 11 relative error a qtlen=10, res=25 b qrlen=0.15, res=25 0 500 1000 1500 2000 2500 25 50 100 number of disk accesses resolution 20% 15% 14 relative error c qrlen=0.15, qtlen=10 


c qrlen=0.15, qtlen=10 Figure 5.6: Query efficiency \(costs and error 5.3 Mining association rules To evaluate the proposed algorithm for mining spatiotemporal association rules, we first artificially formulate 1000 association rules in the form \(r1,T,90 with 90% confidence i randomly picked from 10k ones, \(ii in at most one rule, and \(iii Then, at each of the following 100 timestamps, we assign 100k objects to the 10k regions following these rules. We execute our algorithms \(using 16 sketches these rules, and measure \(i  correct  rules divided by the total number of discovered rules, and \(ii successfully mined Figures 5.7a and 5.7b illustrate the precision and recall as a function of T respectively. Our algorithm has good precision \(close to 90 majority of the rules discovered are correct. The recall however, is relatively low for short T, but gradually increases \(90% for T=25 evaluated in the previous sections, the estimation error decreases as the query result becomes larger \(i.e., the case for higher T 78 80 82 84 86 88 90 92 94 96 5 10 2015 25 precision HT 78 80 82 84 86 88 90 92 94 96 5 10 2015 25 recall HT a b Figure 5.7: Efficiency of the mining algorithm Summary: The preliminary results justify the usefulness of our mining algorithm, whose efficiency improves as T increases Proceedings of the 20th International Conference on Data Engineering \(ICDE  04 1063-6382/04 $ 20.00  2004 IEEE 6. Conclusions While efficient aggregation is the objective of most spatio-temporal applications in practice, the existing solutions either incur prohibitive space consumption and query time, or are not able to return useful aggregate results due to the distinct counting problem. In this paper we propose the sketch index that integrates traditional approximate counting techniques with spatio-temporal indexes. Sketch indexes use a highly optimized query algorithm resulting in both smaller database size and faster query time. Our experiments show that while a sketch index consumes only a fraction of the space required for a conventional database, it can process 


required for a conventional database, it can process queries an order of magnitude faster with average relative error less than 15 While we chose to use FM sketches, our methodology can leverage any sketches allowing union operations Comparing the efficiency of different sketches constitutes a direction for future work, as well as further investigation of more sophisticated algorithms for mining association rules. For example, heuristics similar to those used for searching sketch indexes may be applied to improve the brute-force implementation ACKNOWLEDGEMENTS Yufei Tao and Dimitris Papadias were supported by grant HKUST 6197/02E from Hong Kong RGC. George Kollios, Jeffrey Considine and were Feifei Li supported by NSF CAREER IIS-0133825 and NSF IIS-0308213 grants References BKSS90] Beckmann, N., Kriegel, H., Schneider, R Seeger, B. The R*-tree: An Efficient and Robust Access Method for Points and Rectangles. SIGMOD, 1990 CDD+01] Chaudhuri, S., Das, G., Datar, M., Motwani R., Narasayya, V. Overcoming Limitations of Sampling for Aggregation Queries. ICDE 2001 CLKB04] Jeffrey Considine, Feifei Li, George Kollios John Byers. Approximate aggregation techniques for sensor databases. ICDE, 2004 CR94] Chen, C., Roussopoulos, N. Adaptive Selectivity Estimation Using Query Feedback. SIGMOD, 1994 FM85] Flajolet, P., Martin, G. Probabilistic Counting Algorithms for Data Base Applications JCSS, 32\(2 G84] Guttman, A. R-Trees: A Dynamic Index Structure for Spatial Searching. SIGMOD 1984 GAA03] Govindarajan, S., Agarwal, P., Arge, L. CRBTree: An Efficient Indexing Scheme for Range Aggregate Queries. ICDT, 2003 GGR03] Ganguly, S., Garofalakis, M., Rastogi, R Processing Set Expressions Over Continuous Update Streams. SIGMOD, 2003 HHW97] Hellerstein, J., Haas, P., Wang, H. Online Aggregation. SIGMOD, 1997 JL99] Jurgens, M., Lenz, H. PISA: Performance Models for Index Structures with and without Aggregated Data. SSDBM, 1999 LM01] Lazaridis, I., Mehrotra, S. Progressive Approximate Aggregate Queries with a Multi-Resolution Tree Structure. SIGMOD 2001 PGF02] Palmer, C., Gibbons, P., Faloutsos, C. ANF A Fast and Scalable Tool for Data Mining in Massive Graphs. SIGKDD, 2002 PKZT01] Papadias,  D., Kalnis, P.,  Zhang, J., Tao, Y Efficient OLAP Operations in Spatial Data Warehouses. SSTD, 2001 PTKZ02] Papadias, D., Tao, Y., Kalnis, P., Zhang, J Indexing Spatio-Temporal Data Warehouses ICDE, 2002 SJLL00] Saltenis, S., Jensen, C., Leutenegger, S Lopez, M.A. Indexing the Positions of Continuously Moving Objects. SIGMOD 2000 SRF87] Sellis, T., Roussopoulos, N., Faloutsos, C The R+-tree: A Dynamic Index for MultiDimensional Objects. VLDB, 1987 TGIK02] Thaper, N., Guha, S., Indyk, P., Koudas, N Dynamic Multidimensional Histograms 


SIGMOD, 2002 Tiger] www.census.gov/geo/www/tiger TPS03] Tao, Y., Papadias, D., Sun, J. The TPR*Tree: An Optimized Spatio-Temporal Access Method for Predictive Queries. VLDB, 2003 TPZ02] Tao, Y., Papadias, D., Zhang, J. Aggregate Processing of Planar Points. EDBT, 2002 TSP03] Tao, Y., Sun, J., Papadias, D. Analysis of Predictive Spatio-Temporal Queries. TODS 28\(4 ZMT+01] Zhang, D., Markowetz, A., Tsotras, V Gunopulos, D., Seeger, B. Efficient Computation of Temporal Aggregates with Range Predicates. PODS, 2001 ZTG02] Zhang, D., Tsotras, V., Gunopulos, D Efficient Aggregation over Objects with Extent PODS, 2002 Proceedings of the 20th International Conference on Data Engineering \(ICDE  04 1063-6382/04 $ 20.00  2004 IEEE pre></body></html 


