html><head></head><body><pre style="word-wrap: break-word; white-space: pre-wrap;">A Novel  Approach to Mining Inter-Transaction Fuzzy Association Rules from Stock Price Variation Data Yo-Ping Huang and Li-Jen Kao Department of Computer Science and Engineering Tatung University Taipei, Taiwan 10451 R.O.C Email: yphuang@ttu.edu.tw Abstract- Most of the previous studies on mining association rules focused on mining Boolean intra-transaction associations i.e., the association rules among binary attributes within the same transaction where the notion of the transaction could be the items bought by the same customer. In this paper, we deal with the problem of mining association rules in databases containing quantitative attributes to discover the associations among different transactions. An example of such an association might be  if company A  s stock closing price goes up 1% to 3 company B  s price goes up 2% to 4% the next day  In this case no matter whether we treat company or day as the unit of transaction, the associated items belong to different transactions However, a problem is caused by sharp boundary in this example. For instance, if A  s stock closing price goes up only 0.99%, the example we illustrate is not applicable to predict company B  s stock price the next day. The fuzzy set concept can help us tackle this kind of problem since fuzzy sets provide a smooth transition between member and non-member of a set Besides, to mine inter-transaction association rules from the 1-dimensional database, a sliding window concept is introduced Each sliding window in the database forms a mega-transaction and the associations from these mega-transactions can thus be found. Our algorithm first employs fuzzy set to map quantitative attributes into fuzzy attributes and an Apriori-like method is developed to find inter-transaction fuzzy association rules. As compared with conventional methods, more useful results can be found from the proposed fuzzy association rules I. INTRODUCTION During the past decade, data mining, also known as knowledge discovery in databases, has established its position as a prominent and important research area. Mining association rules is one of the important research problems in data mining. The problem of mining Boolean association rules over market basket data was introduced by Agrawal et al. [6]. Conceptually, this problem can be viewed as finding associations between the  1  values in the relational table where all the attributes are Boolean. The table has an attribute corresponding to each item and a record corresponding to each transaction. The value of an attribute for a given record is  1  if the item corresponding to the attribute is present in the transaction and  0  otherwise. But relational tables in most business or scientific domains have richer attribute types. Attributes can be quantitative \(e.g. age, income  and a quantitative association rule may be: &lt;Age: 30..39&gt and &lt;Income: $30000..$50000&gt  lt;NumCars: 2&gt Mining quantitative association rules was first introduced in [7]. In [7], the algorithm found the association rules by partitioning the attribute domain, combining adjacent partitions, and then transforming the problem into binary one This algorithm caused the sharp boundary problem, that is the algorithm either ignored or over-emphasized the elements near the boundary of the intervals. A fuzzy approach to solving the sharp boundary problem was proposed by Gyenesei [1]. The method developed by Gyenesei deals with mining fuzzy association rules of the form  if X is A, then Y is B  In these rules, X and Y are attributes and A and B are fuzzy sets which characterize X and Y, respectively. The fuzzy sets provide a smooth transition between member and non-member of a set; therefore, there are fewer boundary elements being excluded Another form of association rules can be found like  if company A  s stock closing price goes up 1% to 3%, then 


company A  s stock closing price goes up 1% to 3%, then company B  s price goes up 2% to 4% the next day   Comparing with the rule  when company A  s stock closing price goes up 1% to 3%, company B  s price goes up 2% to 4  you may find there is a fundamental difference between the above two rules. The latter rule expresses the relationship among items purchased by one customer or stock price variation within a day, i.e., associations among items within the same transaction record. The rules like this are called intra-transaction association rules [4]. On the other hand, the former rule states the associations among items from different transaction records and will be defined as inter-transaction rule that breaks the barriers of transaction and can be used for certain applications such as prediction Tung et al. proposed an inter-transaction association rules mining framework that is based on Apriori algorithm [2]. In 2], in order to limit the search space, a sliding window concept is applied to the 1-dimensional transaction database to form mega-transactions. Another important contribution in 2] is that the mining work is achieved within a reasonable amount of time by using the property that  a frequent inter-transaction itemsets must be made up of frequent intra-transaction itemsets   However, no data mining algorithms investigate the problems of how to quantitatively extract the inter-transaction association rules from large databases. Our research aims to establish a scheme not only can get associations from database with quantitative attributes but also can take associations among records into consideration. The proposed algorithm will first map a quantitative attribute into several fuzzy attributes. A normalization process needs to be taken to prevent the total contribution of fuzzy attributes more than 0-7803-9158-6/05/$20.00  2005 IEEE. The 2005 IEEE International Conference on Fuzzy Systems791 one. In order to extract the inter-transaction association rules both dimensional attribute and sliding window concepts are introduced into our Apriori-like method which will find inter-frequent itemsets The rest of this paper is organized as follows. In section 2 we summarize the problems at hand and introduce the related works. In section 3 we describe our proposed algorithm and in section 4 a prediction example of stock price variation is given to examine our algorithm. We will give a brief conclusion in section 5 II. PROBLEM DEFINITION In this section, we will describe the problems of mining fuzzy quantitative inter-transaction association rules. We will also give some definitions before describing our proposed algorithm 2.1. Quantitative Attributes Many algorithms have been proposed to find the binary association rules in the past [3,5]. However, some of the attributes in a database may be quantitative \(e.g., stock closing price, age, income e.g., gender algorithm proposed by Srikant et al. finds the association rules by partitioning the quantitative attribute domain combining adjacent partitions, and then transforming the problem into binary one [7]. Table 1 gives an example with a quantitative attribute  age  Table 2 shows the transformed result for attribute  age  in Table 1. Age is partitioned into three intervals: {young| age ? [20, 29]}, {middle age| age 30, 45]} and {senior| age ? [46, 99 A sharp boundary problem results from using interval partitions. From Table 2, we can have the intervals, [20, 29 30, 45] and [46, 99] with 33.3%, 33.3%, and 33.4% supports respectively. However, if the minimum support is set to 40 none of these intervals will be considered for further analysis In case a user is interested in finding the associations from the interval of [20, 30], the sharp boundary may not be able to respond the desired result The attribute partitioning method is subject to the effect of sharp boundaries because of classical set theory [1]. We can 


sharp boundaries because of classical set theory [1]. We can improve the problem by introducing fuzzy set theory. In fuzzy set theory, an element can belong to a set with a membership degree in [0, 1]. This value is assigned by the membership function associated with each fuzzy set. Fig. 1 is an example of fuzzy membership functions for age. The fuzzy set provides a smooth transition to tackle the sharp boundary problem. An example of stock price variation is given to show this transformation Example 1. Table 3 contains company A  s stock closing price variation data. If we consider the raise condition only, we can transform the data in Table 3 by partitioning the quantitative attribute  closing price variation  into 3 fuzzy intervals raise little, if price goes up from 0 to 4%}, {raise medium, if price goes up from 1.7 to 5.2%}, {raise high, if price goes up from 4% to 7%}. Fig. 2 shows the fuzzy set definition and the associated membership functions and Table 4 shows the results after transformation In Table 3, we can find that the company A  s closing price variation in day 1 is 3.5% and it has membership degree of 0.17 in  raise little  0.9 in  raise medium  and 0 otherwise That is, this record will contribute 0.17 to the support of the fuzzy set  raise little  and 0.9 to  raise medium  The sum of the item  closing price variation  in this record  s contributions to all fuzzy intervals is greater than 1. This means that the record will be counted 1.07 times for the item  closing price variation  This also means that the item in the record is more important than the same item in the other records. This is not reasonable since any item should have equal contribution in any transaction. To solve this problem, a further normalization process for the fuzzy attributes should be taken Let t = {t.v1, t.v2  t.vm} be a transaction with m attributes, where t.vj, 1d j d m, is the value of a certain fuzzy attribute j. Suppose l represents the maximum number of fuzzy sets for attribute j and Pi\(t.vj of t.vj in the ith fuzzy set. Then t.vj can be mapped to {\(Pi\(t.vj for all i, 1didf\(j follows  c  l i ji ji ji vt vt vt 1       P P P The above example can be further transformed from raise little, 0.17 raise medium, 0.9 raise little 0.143 raise medium, 0.857 2.2. Inter-transaction Association Rules Tung et al. proposed a framework for mining inter-transaction association rules that is based on Apriori algorithm [2]. In this section, we are going to introduce some important concepts and give some definitions before dealing with the problem of inter-transaction association rules mining Definition 1. Let I = {i1, i2  ik} be a set of items. Let D be a dimensional attribute and Dom\(D transaction database is a database containing records in the form \(d, Ij D 


form \(d, Ij D of database a 1-dimensional database The dimensional attribute is used to describe the properties associated with the items, such as time and location. It is assumed that the domain of the dimensional attribute is ordinal and can be divided into equal length intervals. For example, time can be divided into day, week month, etc. These intervals can be represented by integers 0 1, 2, etc., without loss of generality An inter-transaction association rule that spans across p intervals is found if an association exists between items that are p intervals apart. Many resources may be required to The 2005 IEEE International Conference on Fuzzy Systems792 discover all possible inter-transaction association rules that may span across different intervals. Besides, users may not be interested in the rules that span longer than a certain number of intervals. In order to avoid spending unnecessary resources to mine the rules which users are not interested in a sliding window denoted by w is introduced. When mining inter-transaction association rules, only the rules spanning shorter than or equal to w intervals will be discovered. Users can thus use sliding window to avoid mining the rules that span across lengthy intervals. The following is an example to illustrate this concept Example 2. Fig. 3 shows an 1-dimensional transaction database T with its dimensional attribute, trading day. In database, five transactions locate at intervals 1, 3, 6, 9, and 11 Assuming that the length of sliding window is 4, we will have five sliding windows W1, W2, W3, W4, and W5, with addresses of 1, 3, 6, 9, and 11, respectively. From Fig. 3, it can be seen that the sub-window W1[0] contains items a, b, e and g while the sub-window W1[3] contains c, f, and i Each sliding window forms a mega-transaction. A mega-transaction M that is contained within W will be denoted as follows M = {ik\(j   1}, where W is a sliding window with w intervals and u is the number of items in I = {i1, i2  iu In example 1, the mega-transaction in W1 will be {a\(0 b\(0 0 0 2 2 2 mega-transaction from the items in a traditional transaction the items in a mega-transaction are called extended items. We denote the set of all possible extended items as Ic. Given I and w, we will have Ic = {i1\(0  i1\(w-1 0  i2\(w-1  iu\(0   iu\(w-1 Now, we can define the concept of inter-transaction association rule Definition 2. An inter-transaction itemset is a set of extended i t e m s  B    I c  s u c h  t h a t   i k  0     B   1  d  k  d  u  Definition 3. An inter-transaction association rule has the form X ? Y, where 1. X ? Ic, Y ? Ic 2    i k  0     X   1  d  k  d  u    i k  j     Y   1  d  k  d  u   j  z  0  4. X ? Y Definition 4. Let MTxy be the set of mega-transactions that contains a set of extended items X ? Y and MTx be the set of mega-transactions that contains X. Let S be the number of transactions in the transaction database. Then, the support and confidence of an inter-transaction association rule X ? Y are defined as sup x xyxy T T confidence S T port 


port Like the mining algorithm for intra-association rule, a minimum support, minsup, and a minimum confidence minconf, will be given and our task is to discover the inter-transaction association rules from the transaction database with support and confidence greater than or equal to the minimum requirements III. THE PROPOSED INTER-TRANSACTION FUZZY ASSOCIATIONS Although the association rules mining research has fascinating progress in many directions, there is no algorithm that deals with quantitative inter-transaction association rules Two examples of stock price variations are given to compare the difference between the proposed inter-transaction fuzzy association rules and intra-transaction ones Example 3. Intra-transaction association rule: When the price of company A goes up, the price of company B also goes up the same day The above example reflects some relationships among the prices and it expresses the associations among the price variation in the same transaction \(day think the prediction has limited reference value and hope to know the associations among different transactions. The following example gives this idea Example 4. Inter-transaction fuzzy association rule: When the price of company A goes up 2% to 3%, the price of company B goes up 3% to 5% the next day Current mining algorithms cannot discover the rule like example 4. Tung et al. proposed a framework that can only discover inter-transaction association rules, whereas Srikant et al. proposed an approach to mine quantitative intra-transaction association rules. In order to discover quantitative inter-transaction association rules, a new method is developed to extract rules from 1-dimensional transaction database Our mining process of inter-transaction fuzzy association rules from 1-dimensional database can be divided into four steps: data preparation, quantitative attribute transformation the discovery of frequent inter-transaction itemsets, and association rule generation 3.1. Data Preparation The first step is to organize the transactions based on intervals of the dimensional attribute. For example, to find the long-term variation trend of stock prices across different weeks or months, we need to convert daily prices variation into weekly group or monthly group 3.2. Quantitative Attribute Transformation The second step is to map each quantitative attribute into its fuzzy intervals. Note that only the quantitative attributes The 2005 IEEE International Conference on Fuzzy Systems793 need to be transformed to its fuzzy intervals. After quantitative attributes are mapped to their fuzzy intervals, the number of items will increase. Let I = {i1, i2  ik} be the set of all items that belongs to the original database. In order to simplify the explanation here, we assume the database has only one quantitative attribute, ij, where 1 d j d k. If ij is mapped to l fuzzy intervals, then the new set of all items If will become as {i\(1, B 2, B  i\(j, 1 j, 2  i\(j, l j+1, B   i\(k, B r, B j,s is a fuzzy attribute For a quantitative attribute value x and its domain domx, if the membership function is f for a certain fuzzy interval A then we have fA\(x x x membership degree for that quantitative attribute in a certain fuzzy interval A While mapping a certain quantitative attribute into its fuzzy intervals, the summation of membership degrees for all fuzzy intervals may be greater than 1; therefore, an extra normalization process needs to be taken. Otherwise, the record will be counted more than once for that attribute 3.3. The Discovery of Frequent Inter-Transaction Itemsets 


3.3. The Discovery of Frequent Inter-Transaction Itemsets Let If be the new set of all items that is defined from the previous phase and W be a sliding window with w intervals along the dimensional attribute. We now redefine a mega-transaction M contained within W to be M = {i\(j, x t j, x  a binary attribute, else 1 d x d l if it is a fuzzy attribute, 0 d t d w  1 We also need to redefine the set of all possible extended items as fI c  = {i\(1, B 0  i\(1, B w - 1 2, B 0  i\(2, B w   1  i\(j, 1 0  i\(j, 1 w - 1  i\(j, l 0  i\(j l w  1 j+1, B 0  i\(j+1, B w  1  i\(k B 0  i\(k, B w  1 Now, we could proceed to find frequent itemsets. An inter-transaction k-itemset is the set B = {i\(1, x t1 2, x t2   i  k   x   t k     w h e r e  B     s u c h  t h a t   i f I  c   j  x   0     B   1  d  j  d  k   T o find the frequent itemsets, we can follow the Apriori algorithm to perform level-wise mining work, i.e., using inter-transaction frequent k-itemsets \(for k t 2 candidate \(k+1 Apriori algorithm. The processing cost of the first two iterations \(i.e., obtaining L1 and L2 mining cost [5]. The reason is that, for a given minimum support, we usually have a very large L1, which in turn results in a huge number of itemsets in C2 to process. In the inter-transaction association rules, this situation becomes much more serious as a lot of additional 2-itemsets like i\(j,x 0 j,x 1 amount of C2. In order to improve the performance EH-Apriori adopts a similar technique of hashing as [5] to filter out unnecessary candidate 2-itemsets. When the support of candidate C1 is counted by scanning the database EH-Apriori accumulates information about candidate 2-itemsets in advance in such a way that all possible 2-itemsets are hashed to a hash table. Each bucket in the hash table consists of a number to represent how many itemsets have been hashed to this bucket thus far. Such a resulting hash table can greatly reduce the number of 2-itemsets in C2 The following is a more detail description of how frequent itemsets are generated Step 1. Discover the frequent 1-itemset L1. In fact, the candidate set C1 of 1-itemsets is , the set of all possible extended items. We can scan the database from mega-transaction T fI c 1 to determine whether a special item i\(j,x t j,x t a binary attribute, else calculate its membership degree, if it is a fuzzy attribute. Through one scan of the database, L1 can be found Step 2. Generate the 2-item candidate set. The 2-item candidate set is of the form C2 = {{a\(0 t 0 t L1, \(t = 0 ? a &lt; b t z 0 b cannot be fuzzy attributes that come from the same quantitative attribute at the same time. For example, in Table 2, the fuzzy attribute young cannot join with fuzzy attribute middle age to form a 2-item candidate set Step 3. Reduce the size of C2. In order to reduce the number of 2-itemsets in C2, hash-based technique is used in this phase. We can hash all 2-itemsets like {a\(0 t contained in the current series of transactions into the corresponding buckets of a hash table and prune the unnecessary 2-itemsets from C2, whose corresponding bucket count in the hash table is less than the minsup. A single 2-itemset in its hash table bucket is not always counted as 1, that is, its support value is not always 1. A valid k-itemset B  s support value sup can be calculated as follows  Bi xj 


xj xj iB      P , where P\(i\(j,x j,x Boolean attribute, else P\(i\(j,x degree, if it is a fuzzy attribute Step 4. Discover the frequent 2-itemset L2. Now the size of C2 is smaller and then simply apply the Apriori algorithm to get L2 Step 5. Generate the k-item candidate set Ck and discover the frequent k-itemset Lk, where k &gt; 2. Given Lk-1, we can get Ck by join Lk-1 with Lk-1. Then all itemsets B?Ck that have k-1 in the pruning phase. Fig. 4 gives the detail algorithm of the join phase Step 6. Repeat step 5 until no more frequent itemsets can be found Step 7. Generate the association rules. The generation of inter-transaction association rules is similar to the generation of the classical association rules, except the The 2005 IEEE International Conference on Fuzzy Systems794 calculation of rules  confidence should be     x xy , where sup\(xy of items X ? Y and sup\(x that contains items X IV. EXPERIMENTAL RESULTS AND DISCUSSIONS In this section an example is given to illustrate how the proposed framework is applied to mining the inter-transaction fuzzy association rules Table 5 shows the original 3 stocks  price variation data To simplify our work, we only consider the raise condition for each stock. The quantitative attribute  closing price variation  is mapped to three fuzzy intervals, {raise little, if price goes up from 0% to 4%}, {raise medium, if price goes up from 1.7% to 5.2%} and {raise high, if price goes up from 4% to 7%}. Table 6 shows the result after transformation Next, we rename the fuzzy attribute {raise little} for company A to a1, {raise medium} to a2, and {raise high} to a3. The same rule applies to company B and C. Fig. 5 shows the result after this transformation. The sliding window length is set to 4 days, and we assume the minsup and minconf being 30% and 45%, respectively. Tables 6 and 7 indicate that the data increases and this will result in more itemsets added to candidate itemsets, especially to C2. In order to construct a smaller C2, we hash all the possible 2-itemsets first, and prune all the unnecessary 2-itemsets so that the corresponding bucket value in the hash table will become less than the minimum support. Then we generate 2-item candidate itemsets from L1, and we can see that there should be 6 candidates but now only three 2-itemsets left in Table 8.Table 7 shows the 1-item candidate set C1 and frequent 1-item set L1. Table 8 shows the 2-item candidate set C2 and frequent 2-item set L2. From Table 9, we can find an inter-transaction fuzzy association rule a1\(0 0 3  if company A  s stock price raise little and company B  s stock price raise medium the same day, then company C  s stock price will raise little three days later  The inter-association fuzzy rules we generate not only can predict the stock price variation trend but also tell us how big the variation and when this variation will happen in the future If we try to discover the classical intra-transaction association rules, we can get L1 = {\(stock A raise little stock B raise medium stock C raise little stock A raise little, stock B raise medium 


stock A raise little, stock B raise medium same minimum support and confidence values. The rule we get is  if company A  s stock price raise little, then company B  s stock price raise medium the same day  Comparing to inter-transaction fuzzy association rule, the prediction function from the classical association rules has limited use and investors may dislike them V. CONCLUSION In this paper we proposed a model to find inter-transaction fuzzy association rules that can predict the variations of events. The proposed algorithm first mapped a quantitative attribute into several fuzzy attributes. A normalization process was taken to prevent the total contribution of fuzzy attributes from being larger than 1. In order to mine inter-transaction fuzzy association rules, both the dimensional attribute and sliding window concepts were introduced into our framework. The method of finding frequent itemsets was based on Apriori algorithm. Since items may increase dramatically, a hash-based technique was implemented to help reduce the complexity. In fact, there still has space to discuss the strategy of candidate itemsets generation. The future work will include finding n-dimensional inter-transaction association rules. For example, by adding spatial attribute, one can mine spatial-temporal inter-transaction association rules in the remote sensing data ACKNOWLEDGMENT This work is supported by National Science Council, Taiwan R.O.C. under Grants NSC93-2213-E-036-024 NSC92-2516-S-036-001, and by Tatung University under Grant B93-I01-032 REFERENCES 1] A. Gyenesei  A fuzzy approach for mining quantitative association rules  Technical Report of Turku Centre for Computer Science, no. 336 March 2000 2] A.K.H. Tung, H. Lu, J. Han and L. Feng  Efficient mining of intertransaction association rules  IEEE Transactions on Knowledge and Data Engineering, vol. 15, no. 1, pp.43-56, Jan./Feb. 2003 3] A. Savasere, E. Omiecinski, and S. Navathe  An efficient algorithm for mining association rules in large databases  Proc. Int  l Conf. Very Large Data Bases, pp.432-443, Sept. 1995 4] H. Lu, J. Han, and L. Feng  Stock movement and n-dimensional intertransaction association rules  Proc. SIGMOD Workshop Research Issues on Data Mining and Knowledge Discovery, vol. 12, pp.1-7, June 1998 5] J.S. Park, M.S. Chen, and P.S. Yu  An effective hash-based algorithm for mining association rules  Proc. ACM SIGMOD Int  l Conf. Management of Data, pp.175-186, May 1995 6] R. Agrawal, T. Imielinski, and A. Swami  Mining association rules between sets of items in large database  Proc. of ACM SIGMOD Int  l Conf Management of Data, pp.207-216, 1993 7] R. Srikant and R. Agrawal  Mining quantitative association rules in large relation tables  Proc. of ACM SIGMOD Int  l Conf. Management of Data pp.1-12, 1996 Table 1. A database with a quantitative attribute  age  and a categorical attribute  gender   ID Name Gender Age 1 Peter Male 29 2 Mary Female 30 3 John Male 51 Table 2. The data transformed from Table 1. Gender is mapped to male and female. Age is mapped to [20, 29] , [30, 45], and [46, 99 ID Name Male Female Young 20, 29 Middle age 30, 45 Senior 46, 99 1 Peter 1 0 1 0 0 2 Mary 0 1 0 1 0 3 John 1 0 0 0 1 The 2005 IEEE International Conference on Fuzzy Systems795 


The 2005 IEEE International Conference on Fuzzy Systems795 Table 3. The original stock price variation data Day Company A  s stock closing price variation 1 0.035 2 0.015 3  Fig 1. An example of the fuzzy sets associated with membership functions.Table 4. The data  transformed from Table 3. The  closing price variation  is mapped to 3 fuzzy intervals, {raise little}, {raise medium}, {raise high Day Company A  s stock closing price variation Raise little Raise medium Raise high 1 0.17 0.9 0 2 1 0 0 3  Fig 2. The fuzzy sets and associated membership functions for Example 1 Table 5. The original stock price variation data Day T 1 a, b, e, g 2 3 c, f, i 4 5 6 a, e, d, h 7 8 9 a, e, d 10 11 b, c, f 12 13 14 Day Company A stock closing price variation Company B stock closing price variation Company C stock closing price variation W1 W2 1 0.019 0.036 0.056 4 0.018 6 0.0176 0.041 9 0.0177 0.042 0.01 10 0.009 0.018 W3 W4 W5 Table 7. The 1-item candidate itemsets and the corresponding support value 1-item candidate itemset Support value Frequent itemset minsup = 1.5 a1\(0 a1\(2 a1\(3 a2\(0 a2\(2 b1\(0 b1\(1 b2\(0 b2\(2 b2\(3 b3\(0 b3\(2 b3\(3 c1\(0 c1\(1 c1\(3 Fig. 3. An 1-dimensional database with a sliding window of 4 intervals Lk: frequent inter-transaction k-itemset, Ck: candidate inter-transaction k-itemset 


Lk: frequent inter-transaction k-itemset, Ck: candidate inter-transaction k-itemset Definition: itemi\(titemi titemj 1 2 D e f i n i t i o n   i t e m i  t i t e m i     i t e m j  t i t e m j    i f  a n d  o n l y  i f  e i t h e r  o f  t h e  c o n d i t i o n s  h o l d   1    t i t e m i    t i t e m j      i t e m i    i t e m j     2   t i t e m i   j Insert into Ck Select p.item1\(titem1 titem2   p.itemk-1\(titemk-1 titemk-1 From Lk-1 p, Lk-1 q Where p.item1\(titem1 titem1   p.itemk-2\(titemk-2 titemk-2 p   i t e m k 2  t i t e m k 1     q  i t e m k 1  t i t e m k 1  F i g   4   T h e  d e t a i l  a l g o r i t h m  f o r  j o i n i n g   w i t h   1  1  L Day T 1 a1, a2, b1, b2, c3 2 3 4 c1, c2 5 6 a1, a2, b2, b3 7 8 9 a1, b2, b3, c1 10 b1, c1, c2 11 12 13 W1c2\(0 c2\(1 c2\(3 c3\(0 W2 W3 Table 8. The 2-item candidate itemsets and the corresponding support value 2-item candidate itemset Support value Frequent itemset a1\(0 0 a1\(0 3 b2\(0 3 W4 Table 9. The 3-item candidate itemsets and the corresponding support value 3-item candidate itemset Support value Frequent itemset a1\(0 0 3 Fig. 5. The 1-dimensional data set which is transformed from Table 6. The sliding window length is 4 intervals W5 Table 6. The data transformed from Table 5 Company A stock closing price variation Company B stock closing price variation Company C stock  closing price variation Day Raise little Raise medium Raise high Raise little Raise medium Raise high Raise little Raise  medium Raise high 1 0.90 0.1 0.15 0.85 1 4 0.95 0.05 6 0.95 0.05 0.90 0.10 9 1 0.90 0.10 1 10 1 0.95 0.05 The 2005 IEEE International Conference on Fuzzy Systems796 pre></body></html 


0-7695-2263-7/05 $20.00  2005 IEEE pre></body></html 


n M L N n t n t n t n t L M L t L t L tt L t kkkk kkkk kkk kkkk kkkkkkkkP VK VK VK VK PP       kkP t 31 where L  s the error covariance associated with the state estimate t i    kkLX  tt kkk P1  00 0  0                     s s sss s s sss s s sssss N n t n t n 


n t n N n t n t n t n N n t n t n t n t n t n c t L kkkkkk kkkkk kP VKVK VKVK  32 4. Simulations One has run simulations comparing the sequential implementations of MSJPDA algorithm and the new algorithm here. A typical multisensor multitarget tracking environment is assumed in the simulations. According to article [1,3], One known that the performance of sequential MSJPDA is better than the performance of parallel MSJPDA. Therefore, the performance of parallel MSJPDA algorithm will not be compared here There are three sensors, which are fixed in three platforms. Regarding the 2nd sensor as fusion centre situation of the other sensors are: =?-500m?-500m 0m??N =?-500m? 500m?0m??The distance error of each sensor is: =300m, =200m, =100m?The bear error of each sensor is 0.03rad, =0.02rad, =0.01rad?The of sample is T=1s?The nonparametric model of clutter is used in the simulations, and expected number of false measurement is m=1.8 1 sN 3 s 1r 2 2r 3 3r 1 Simulations have been run for racking two targets. The true initialization state of the targets is X1?[-29500m,400m/s,34500m,-400m/s X ?[-26250m,296m/s,34500m,-400m/s]'? 2 The two targets will cross above 31seconds later. To evaluate tracking performance, 50 Monte Carlo runs were performed for three case of the target detection probability Pd=0.97 ? Pd=0.76 ? Pd=0.58. In every run, the total simulation time is 140 steps 


simulation time is 140 steps            Figure 1  RMS position error in case of Pd=0.97          Figure 2  RMS velocity error in case of Pd=0.97       Figure 3  RMS position error in case of Pd=0.76 567 Proceedings of  the Fourth International Conference on Machine Learning and Cybernetics  Guangzhou, 18-21 August 2005         Figure 4  RMS velocity error in case of Pd=0.76         Figure 5  RMS position error in case of Pd=0.58          Figure 6  RMS velocity error in case of Pd=0.58  Table 1 The emanative times comparison for sequential MSJPDA and SD-CMSJPDA algorithm  Pd N A  0.97 0. 76 0.58 Sequential MSJPDA 2 11 17 SD-CMSJPDA 0 3 5 Pd denotes detection probability, N denotes emanative 


Pd denotes detection probability, N denotes emanative times, A denotes the kind of algorithm Table 1 shows the summation of emanative times for sequential MSJPDA and SD-CMSJPDA algorithm in 50 Monte Carlo simulations. From table 1 , it is shown that the stability of SD-CMSJPDA is better than that of sequential MSJPDA as the detection probability varied Figure 1,2 show the RMS errors for position and velocity in case of Pd=0. 97, respectively; Figure 3,4 show the RMS errors for position and velocity in case of Pd=0.76 respectively; Figure 3,4 show the RMS errors for position and velocity in case of Pd=0.58, respectively. From the figures we can see that the average RMS position error is lower for the SD-CMS JPDA algorithm. We also see that the state estimation precision of sequential MSJPDA get worse as the detection probability decreases The reasons for these simulation results lies:1 state estimation precision will get worse when the detection probability decrease;2 algorithm is to process measurement from each sensor using single sensor JPDA algorithm sequentially. Therefore the estimation error from each sensor will be accumulated Moreover, the sequential MSJPDA algorithm can  t improve the joint detection probability of the multisensor system The estimation error of the SD- CMSJPDA  algorithm will not be accumulated for it processes the measurement from each sensor directly in the mean time .What  s more the new method can greatly improve the joint detection probability of the multisensor system. Therefore, the tracking performance of SD-CMSJPDA algorithm is better than that of sequential MSJPDA. Algorithm All of the simulations are run in the personal computer with a 2.0G CPU and a 256M memory. The average cost time per step is 0.0251 in the sequential implementations of MSJPDA algorithm. And the average cost time per step is 0.0282 in the sequential implementations of MSJPDA algorithm. According to the results we can see that there is few difference in real time between the new method and the sequential   MSJPDA when there is not so many sensors and targets 568 Proceedings of  the Fourth International Conference on Machine Learning and Cybernetics  Guangzhou, 18-21 August 2005  5. Conclusion In order to solve the problem of multisensor multi target tracking, a new centralized multisensor  joint probabilistic data association  algorithm is proposed in this paper. The simulation results shows that the tracking performance of the new algorithm is better than that of the sequential MSJPDA algorithm The computational complexity of the new method will increase as the number of sensors and targets grow Therefore, how to improve the real time of SD- CMSJPDA algorithm will be pay attention References 1] He You, Wang Guohong, Lu Dajin, Peng Yingning Multisensor Information Fusion With Application[M Publishion House of Electronics Industry. 2000, Beijing.  [11] B..Zhou and N.K.Bose Multitarget  Tracking in Clutter:Faste Algorithms for Data Association .IEEE Transaction on Aerospace and Electronic Systems 1993,29\(2 2] Bar-shalom,Y\(Ed Applications and Advances,2: Norwood,MA Artech  House, 1992 3] L.Y. Pao, C.W.Frei. A Comparison of Parallel and Sequential Implementation of a Multisensor Multitarget Tracking Algorithm. Proc. 1995 American Control Conf. Seattie, Washington,June 1995 1683~1687 


4] K. Chang, C. Chong, Bar-Shalom, Joint Probabilistic Data Association in Distributed Sensor Networks IEEE Transactions on Automatic Control, AC-31\(10 octobre 1986 5] Bar-shalom, Multitarget Multisensor Tracking Advanced Application ,:YBS Publishing, 1990 6] Bar-shalom, Multitarget Multisensor Tracking Principles and Techenices ,:YBS Publishing, 1995 7] Hu Wenlong, Mao shiyi, Multisensor Data Association Based on Combinatorial Optimization[J]. Journal of Systems Engineering and Electronics . 1997 NO.1,1~9 8] Pattipati K R, Passive Multisensor Data Association Using a New Relaxation Algorithm.In Multitarget-Multisensor Tracking: Advanced and Applications,Y.Barshalom,Norwood,MA:Aretech,199 0 9] Deb S,et al, An S-Dimentional Assignment Algorithm for Track Initiation ,Proc. Of the IEEE Int. Conf Systems Engineering, Kobe, Japan,Sept 1992 527~530 10] Deb S,et al, A Multisensor-Multitarget Data Association Algorithm for Heterogeneous Sensors[J].IEEE Trans. on AES 1993 ,29 \(2 560~568 12] Bar-shalom,Y.,and Fortmann,T.E  Tracking and Data Association  New York:Academic press,1988 13] J,A,Roecher and G.L.Phillis,Suboptimal Joint Probabilistic Data Association .IEEE Transaction on Aerospace Electronic Systems.1993,29\(2 14] J,A,Roecker,A Class of Near Optimal JPDA Algorithm IEEE Transaction on Aerospace and Electronic Systems,1994,30\(2 15] Han Yanfei, Analysis and Improvement of Multisensor Multitarget Probabbilistic Data Association Filting Algorithm[J].  Journal of Systems Engineering and Electronics, 2002, Vol.24, 36~38  569 pre></body></html 


dense data sets for evaluating pattern mining algorithms These two data sets are obtained from IBM Almaden at http://www.almaden.ibm.com/cs/quest/demos.html. Recently, theMAFIA algorithm [6] was proposed to ef?ciently discover maximal frequent patterns. As shown in their paper, MAFIA can be several orders better than some alternatives, such as DepthProject, for mining maximal frequent patterns. Hence, we chose MAFIA as the base line for our performance evaluation. Finally, please note that only the size-2 patterns are generated in the ?rst BFS phase Experimental Platform We implemented the MHP algorithms using C++ and all experiments were performed Proceedings of the 16th IEEE International Conference on Tools with Artificial Intelligence \(ICTAI 2004 1082-3409/04 $20.00  2004 IEEE on a Pentium III    MHz PC machine with    megabytes main memory, running Linux Redhat 6.1 operating system 5.2. A Performance Comparison 100 1000 10000 100000 1e+06 1e+07 1e+08 1e+09 1e+10 1e+11 0.02 0.025 0.03 0.035 0.04 0.045 0.05 0.055 0.06 N um be r o f C he ck ed P at te rn s Support threshold Mafia Min_Conf=0 Min_Conf=0.1 Min_Conf=0.3 Min_Conf=0.5 Min_Conf=0.7 Min_Conf=0.9 


Figure 4. The Number of Checked Patterns on the Pumsb* Data Set 10 100 1000 10000 100000 0.02 0.025 0.03 0.035 0.04 0.045 0.05 0.055 0.06 R un T im e s ec  Support Threshold Mafia Min_Conf=0 Min_Conf=0.1 Min_Conf=0.3 Min_Conf=0.5 Min_Conf=0.7 Min_Conf=0.9 Figure 5. The RunTime Comparison on the Pumsb* Data Set Figure 4 shows the number of patterns that MHP and MAFIA have to check during the pattern mining process on the pumsb* data set. As can be seen, for MHP, the number of checked patterns is increased with the decrease of the h-con?dence threshold. However, the number of checked patterns of MHP can be signi?cantly smaller than that of MAFIA even if a low h-con?dence threshold is speci?ed To check a pattern, we need to count the support of the patterns. Counting the support of a pattern is the most timeconsuming task during the pattern mining process, since we need to retrieve all the transactions which include one of its sub-pattern, or for Ma?a, retrieve all the bit of the bitmap of this pattern [6]. Therefore, an algorithm is more ef?cient if smaller number of patterns need to be checked 100 1000 10000 100000 1e+06 1e+07 1e+08 1e+09 0.1 0.2 0.3 0.4 0.5 0.6 0.7 N 


um be r o f C he ck ed P at te rn s Support Threshold Mafia Min_Conf=0.5 Min_Conf=0.7 Min_Conf=0.9 Figure 6. The Number of Checked Patterns on the Pumsb Data Set 10 100 1000 10000 0.1 0.2 0.3 0.4 0.5 0.6 0.7 R un T im e s ec  Support Threshold Mafia Min_Conf=0.5 Min_Conf=0.7 Min_Conf=0.9 Figure 7. The RunTime Comparison on the Pumsb Data Set The runtime comparison of MHP and MAFIA on the Pumsb* data set is shown in Figure 5. In the ?gure, we can observe that the runtime of MHP can be signi?cantly reduced with the increase of h-con?dence thresholds. Also the runtime of MHP can be several orders of magnitude less than that of MAFIA even if the h-con?dence threshold is as low as 0.3. The reason is that the number of checked patterns of MHP is sign?cantly smaller than that of MAFIA Similar results are also obtained from the pumsb data set as shown in Figure 6 and Figure 7. For the pumsb data set the number of checked patterns of MHP is much smaller 


than that of MAFIA and the runtime of MHP can be significantly less than that of MAFIA 5.3. The Effect of the MHP Algorithm on Finding Maximal Hyperclique Patterns Figure 8 and Figure 9 show the number of maximal patterns identi?ed byMHP andMAFIA on Pumsb* and Pumsb data sets respectively. As can be seen, the number of maximal hyperclique patterns identi?ed by MHP can be orders of magnitude smaller than the number of maximal frequent patterns identi?ed by MAFIA. In other words, the number Proceedings of the 16th IEEE International Conference on Tools with Artificial Intelligence \(ICTAI 2004 1082-3409/04 $20.00  2004 IEEE 100 1000 10000 100000 1e+06 1e+07 1e+08 1e+09 0.02 0.025 0.03 0.035 0.04 0.045 0.05 0.055 0.06 N um be r o f C ou nt ed P at te rn s Support Threshold Mafia Min_Conf=0 Min_Conf=0.1 Min_Conf=0.3 Min_Conf=0.5 Min_Conf=0.7 Min_Conf=0.9 Figure 8. The Number of MFI/MHP Patterns in the Pumsb* Data Set 100 1000 10000 100000 1e+06 


1e+07 1e+08 0.1 0.2 0.3 0.4 0.5 0.6 0.7 N um be r o f C ou nt ed P at te rn s Support Threshold Mafia Min_Conf=0.5 Min_Conf=0.7 Min_Conf=0.9 Figure 9. The number of MFI/MHP Patterns in the Pumsb Data Set of maximal hyperclique patterns is much easier to manage than that of maximal frequent patterns. Indeed, in realworld applications, it is dif?cult to interpret several million maximal frequent patterns. However, it is possible to interpret the results of maximal hyperclique pattern mining In addition, due to the memory limitation, we cannot extract maximal frequent patterns with MAFIA on the Pumsb data set if the support threshold is less than 0.4, as shown in Figure 7. In contrast, MHP can identify maximal hyperclique patterns when the support threshold is 0.1, if we set the h-con?dence threshold to 0.5. In other words, MHP has the ability to identify patterns which can be dif?cult to identify for MAFIA. Hence, MHP can better explore the pattern space and ?nd interesting patterns at low levels of support 6. Conclusions and Future Work In this paper, we present a two-phase Maximal Hyperclique Pattern \(MHP best features of both the BFS strategy and the DFS strategy. More speci?cally, we adapted DFS pruning methods such as equivalence pruning, to an apriori-like approach In addition, we proved the correctness and completeness of the MHP algorithm. Finally, our experimental results show that the MHP algorithm can be several orders of magnitude faster than standard maximal frequent pattern mining algorithms and has the ability to identify patterns at extremely low levels of support in dense data sets There are several directions for future work. First, in 


this paper, we only generate the size-2 patterns in the BFS phase. It will be interesting to investigate the impact on the performance if the ?rst phase is stopped at a deeper level Also, the projection is a very ef?cient method for ?nding patterns, especially for parallel implementation of pattern mining algorithms [1]. We plan to adapt the projection ideas into our algorithm and design an ef?cient parallel algorithm for mining maximal hyperclique patterns References 1] R. Agarwal, C. Aggarwal, and V. Prasad. A Tree Projection Algorithm For Generation of Frequent Itemsets. pages 350 371, Feb 2001 2] R. Agrawal, T. Imielinski, and A. Swami. Mining Association Rules between Sets of Items in Large Databases. In Proc. of the ACM SIGMOD Conference on Management of Data, pages 207216,May 1993 3] R. Agrawal and R. Srikant. Fast Algorithms for Mining Association Rules. In Proc. of the 20th Intl Conference on Very LargeData Bases, 1994 4] R. Bayardo. Ef?ciently mining long patterns from databases In Proc. of the ACM SIGMOD Conference, 1998 5] R. Bayardo and R. Agrawal. Mining the Most Interesting Rules. In Proc. of the ACM SIGKDD Conference, 1999 6] D. Burdick, M. Calimlim, and J. Gehrke. Ma?a: AMaximal Frequent Itemset Algorithm for Transactional Databases. In Proc. of IEEE Conf. on Data Engineering, 2001 7] Y. Huang, H. Xiong, W. Wu, and Z. Zhang. A Hybrid Approach for Mining Maximal Hyperclique Patterns. In In Technical Report UTDCS-34-04, Department of computer science, University of Texas - Dallas, 2004 8] J.Han, J.Pei, and Y. Yin. Mining Frequent Patterns without Candidate Generation. In Proc. of the ACM SIGMOD International Conference on Management of Data, 2000 9] M.J.Zaki and C.Hsiao. ChARM: An ef?cient algorithm for closed itemset mining. In Proc. of 2nd SIAM International Conference on Data Mining, 2002 10] R.Rymon. Search through Systematic Set Enumeration. In Proc. Third Intl Conference on Principles of Knowledge Representation and Reasoning, 1992 11] H. Xiong, M. Steinbach, P.-N. Tan, and V. Kumar. HICAP: Hierarchial Clustering with Pattern Preservation. In Proc. of 2004 SIAM International Conference on Data Mining \(SDM 12] H. Xiong, P.-N. Tan, and V. Kumar. Mining Strong Af?nity Association Patterns in Data Set with Skewed Support. In Proc. of the Third IEEE International Conference on Data Mining \(ICDM Proceedings of the 16th IEEE International Conference on Tools with Artificial Intelligence \(ICTAI 2004 1082-3409/04 $20.00  2004 IEEE 





