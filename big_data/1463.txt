TIME SERIES PREDICTION USING ADAPTIVE ASSOCIATION RULES Ooi Boon Yaik, Chan Huah Yong and Fazilah Haron School of Computer Science, Universiti Sains Malaysia, 11800 Penang  Abstract Grid computing is formed by a large collection of interconnected heterogeneous and distributed system One of the grid computing purposes is to share computational resources. The efficiency and effectiveness of resource utilization of a grid greatly depend on the scheduler algorithm. The scheduler will be able to manage the grid resources more effectively if we able to predict and provide it with the future state of grid 
resources. Therefore, this paper proposes a model to perform time series prediction using adaptive association rules. This model uses the idea that if a segment of a repeatable time series pattern has occurred it has the possibility that the following segments of the repeatable pattern will appear. Data mining and pattern matching techniques are being applied to mine for repeatable time series patterns. This model has the ability to provide confident level for each prediction it made and perform continuous adaptation. A prototype of this model is being developed and tested with four test 
cases. These test cases are relatively simple because our work on this time series prediction using adaptive association rules is very much in its early stages. The result from the experiment s hows that our model is able to capture repetitive time series patterns and perform prediction using those patterns. However, this model has s such as it required high computational power and required large storage 1. Introduction The objective of grid computing is to create a computer from a large collection of interconnected heterogeneous and distributed systems where users can share resources. The interconnected resources of a virtual computer, however, need an 
effective scheduling system to make such virtual computer to be successfully utilized. Furthermore, the resources of a grid is not owned and maintained by the s, neither and they are not exclusively to certain applications. The load of the resources and the availability vary over time and this will affect the performance of a job on the grid. In order to manage grid resources more effectively, the scheduler should also consider the future state of the resources instead of just considering past and current state. The future state of the resources in a grid can be provided to the scheduler by performing time series analysis and 
prediction on the past resources behavi  Time series research is a method that can be phenomena and processes of a system under study. Therefore, time series prediction can be applied on the grid resources to enable the scheduler to know the future state of grid resources We propose to perform time series prediction using adaptive association rules. This model performs time series prediction by analyzing the behavior of a time series and then from the understanding of the time series behavior to perform prediction. Time series prediction using adaptive association rules technique uses the datamining concept. Data mining has the ability to perform 
knowledge discovery by extracting meaningful new patterns from a huge database, we applied it to time series to extract repetitive patterns. In our model, we use data mining process to discover the behavior of a time series. The challenging part of developing this model is to represent time series in a format that allows data mining and pattern-matching algorithm to process them We have developed a prototype of this model and it shows that our model is able to perform prediction This paper has five sections. The first section is s are related work, methodology, experime nt and conclusion. The details of the design and implementation of this model 
will be elaborated at the methodology segment of this paper 2. Related work Currently most of the time series prediction techniques use statistical and artificial intelligent approach. Box-Jenkins forecasting model is one of the statistical models that based on statistical concepts and princip Thi s m o del i s a b le t o m ode l a w i de  spectrum of time series behavior. However, statistical methods can model time series well but not well enough when there are noises in the time series such as incomplete or inaccurate data. On the other hand, neural networks are one of the well-known artificial intelligent 
techniques that use generalized regression to approximate nonlinear functions of a time series. Neural networks have been claimed to achieve better prediction compared to statistical methods n d be com e a n  alternative to classical methods to perform time series prediction. However, according to ura l  netw orks  have difficulty in pre-selecting the system architecture catastrophic forgetting, excessive training time and lack Proceedings of the First Inte rnational Conference on Distributed Framewor ks for Multimedia Applications \(DFMA\22205 0-7695-2273-4/05 $ 20.00 IEEE 


of knowledge representation facilities. As the consequence, it is hard to justify the correctness and confidence of a neural network prediction because of its numerical knowledge representation. For example neural networks will still provide prediction even if the provided time series data is a random time series In the previous work, we developed a multi layer perceptions \(MLP\l network that uses back propagation training algorithm to perform time series prediction. This neural network is being tested with a few time series that we generated. From our experiment we discover that the result of neural network prediction accuracy depends on the neural network architecture and the length of the time series. Different architecture of neural networks will generate prediction with different accuracy and is hard to determine the best architecture Besides that, we also discovered that neural network prediction has problems in convincing users of its prediction even if its prediction is very accurate. This is because the neural network uses numerical knowledge representation and this causes the user unable to know how well the neural network captures its knowledge The motivation of this study is to develop a prediction model that has further term of prediction reliable and adaptive for life long prediction. We propose ive association rules. In our model, we define the behavior of a time series as the tendency of the time series to repeat one or more patterns. The term of prediction of a model means how many points ahead a model can predict and the definition of the range of long, medium and short term depends on application. The term of prediction of this model is dynamic. It depends on the time series previous data, if a time series has high repetitive pattern rate, the term of prediction of this model will be long and if the repetitive pattern rate is low, the term of prediction of this model will eventually be short This model is able to recognize random data because this model depends on repetitive patterns to perform prediction. Therefore, if a time series is random the repetitive patterns rate will be very low and this model will not perform any prediction. Besides that, this model also provides confident level for each prediction it made according to the time series previous data This model is also being designed so that it is able to perform life long adaptation and reinforcement learning for continuous prediction. This adaptation and cement learning is being done by a simple punish and reward system. If a prediction being made is inaccurate and the error rate is above a given threshold this model will perform adaptation by reducing the confident level of using the repetitive pattern again for prediction and look for new repetitive patterns. If the prediction is accurate, this model will perform reinforcement to increase its confident level on the particular repetitive pattern 3. Methodology Data mining is a part of knowledge discovery process. The goal of data mining can be categorize into four categories, which are prediction, identification classification and optimization. Data mining perform prediction by analyzing data and look for the data behavior pattern. From the discovered behavior pattern data mining can show how likely the data will behave in the future. Association rules is one of the types of knowledge representation that data mining discovers Association rules correlate the presence of a set of items with another range of values for another set of variables   F o r exam p l es, if ye ste rd a y a nd t oda y CP U usage s ar e high then tomorrow CPU usage will most likely be high Figure 2 shows the process flow of our time series prediction model. This model can be divided into three sub modules. The first sub module is the Analyze Time Series sub module. This sub module is responsible for performing preprocessing and data mining on the time series. The preprocessing purpose is to convert the time series into chain code so that the time series can be processed by data mining Figure 2. The process flow of Time Series Prediction using Adaptive Association Rules We represent the times series in a chain code format to keep track of the rate-of-change of a time series. The rate-of-change of a time series is being calculated using the gradient between every two points in the time series. Every gradient value in the chain code will be label. Each label will consist of a range of gradient value. The purpose of labeling is to make the exact value of a time series to be fuzzy because we want Proceedings of the First Inte rnational Conference on Distributed Framewor ks for Multimedia Applications \(DFMA\22205 0-7695-2273-4/05 $ 20.00 IEEE 


to perform pattern matching. This chain code will then be parsed into multiple sizes and become multiple itemsets for the data mining to process. The data mining process will go through every itemsets and mines for repeatable patterns. Finally, all the detected repetitive patterns will be stored in database in the form of association rules. Figure 3 shows the process flow of generating the chain code This prediction model will be ready to perform prediction after the mining process. The second sub module is the Prediction sub module that is responsible to perform prediction. This sub module will apply preprocessing on the time series before performing prediction. Then, the prediction is done by taking C  t 205 1 C  t 205 2 C  t 205 3\\203 C  t 205 n the C is the chain code value t is the time and n is the number of points that being taken from the time series as inputs to perform pattern matching with the discovered repetitive patterns in the database ble time series pattern matches with the inputs, it may happens that the following segment of the particular repetitive pattern has the possibility of reoccurrence. This prediction model will then use the following segment of the repetitive pattern as prediction and the possibility of reoccurrence as the confident level. The value n is the number of points being used to perform prediction. This value is dynamic because it depends on the prediction confident threshold. It is also possible that more then one repetitive patterns being used to perform prediction. For examples if one pattern uses n = 10 with the confidence that 60 that the following pattern will reoccur and the other pattern uses n = 3 with the confidence that 30% that the owing pattern will reoccur, this model will choose the n = 10 to perform prediction. However, if there are two n 10 patterns in the database, the model will use both of them to perform prediction. Therefore, it is possible for this model to generate one or more prediction on a same time series e level of each pattern is actually regarding its implication possibilities. For example, the confidence of E, B, F imply G is compute as support \(E B, F, G\ / support \(E, B, F\. The support here refers to how frequently a specific pattern occurs in the time series. If the support is low this implies that according to the time series history the percentage that E, B, F will imply G is low. Otherwise, if the support is high, the percentage that E, B, F will imply G will be high. This means that according to the time series history the pattern of E, B, F imply G has been discovered before and have occurs over a number of times. Therefore, this model will predict next value wills most probably going to be G and provide the support \(E, B, F, G\ / support \(E G going to reoccur. This process will repeat for the entire repetitive pattern that being discovered earlier by the data mining process. For example, in the database E, B, F, G and H is a pattern that being discovered earlier in a time series. The lculate the confidence level of E, B, F, G, H to reoccur if E, B, F happens For the third sub module is the Adaptation sub module. Data mining process is usually single session process, meaning that the mining process is usually being executed once over the whole set of available data. After the mining process, usually only the output being used and the data mining process will never be execute again Therefore, in order to enable our model to have the abilities to perform adaptation and reinforcement learning like neural network we modified the data mining process to be a lifelong process. Instead of mining the time series, repeatedly which is very compute intensive, we modified the support value of each pattern accordingly. If the prediction of the model is incorrect this model will reduce the predicted pattern\220s support value. Otherwise, if the prediction is correct, the model will increase the predicted pattern\220s support value of a particular pattern Therefore, in our database we only keep support value and not confidence for a pattern. For example, we keep support \(E, B, F, G\ = 6 and support \(E, B, F\ 10 in database. Our model will calculate the confidence that G going to reoccur as support \(E, B, F, G\ / support \(E B, F\h is 0.6. If the prediction is correct then this model will modified the support \(E, B, F, G\ = 7 and support \(E, B, F\11 in the database. Thus, if E, B, F happens again, this model will predict that G going to reoccur as support \(E, B, F, G\ / support \(E, B, F\ which is now 0.63. Otherwise, if the prediction is wrong, this model will modified the support \(E, B, F, G\ = 6 and support \(E, B, F\ = 11 in the database. This will reduces the confidence of G going to reoccur to support \(E, B, F G\ support \(E, B, F\ 0.54. At the same time, new pattern will emerge if the prediction is wrong such as support \(E, B, F, X\ = 1 will be keep in database. If support \(E, B, F, X\eps on increasing, it will eventually have higher confidence level that X is going to reoccur instead of G Figure 3: Example of the chain code being generated  Differencing X2-X1=0.98 X3-X2=-1.89 X4-X3=2.0 X5-X4=1.12 Gradient Y1= tan 1 X2-X1\42 Y2= tan 1 X3-X2\2.11 Y3= tan 1 X4-X3\43 Y4= tan 1 X5-X4\23 Chain Code C1=E C2=B C3=F C4=G I f 44 < Yn <48 then label E If -62 < Yn <-64 then label B If 62 < Yn <64 then label F If 48 < Yn <50 then label G Time Series Data X1 = 2.23 X2 = 3.21 X3 = 1.32 X4 = 3.32 X5 = 4.44 Proceedings of the First Inte rnational Conference on Distributed Framewor ks for Multimedia Applications \(DFMA\22205 0-7695-2273-4/05 $ 20.00 IEEE 


Therefore, by modifying those repetitive patterns\220 support in the database will enable our model continuously takes input from a time series and continuously mines for new patterns and discards patterns that no longer repeat 4. Experimental Results We here tested our model using four simple test cases. The purpose of these four test cases is to test how good our model mines for new patterns and perform prediction using those patterns. Each of this time series is being generated with different repetitive patterns. The first test case is a simple time series with periodic time sequence. For the second test case, we tried to test our model with a more complicated time series. We generated this time series with combination of two different repetitive patterns. Then, we added some random characteristic to the time series data to make it more complicated in the third test case. On the fourth test case, we decided to test our model with random time series to test whether our model able to distinguish random and non-random time series Figure 5 shows and our model successfully mines and predicts the next patterns. This model uses time series data from point A to point B to perform prediction. It predicts that from point B to point C will have 100% or reoccurrence Figure 6 shows the second test case, which is slightly more complicated if compared with the first test case. In this test, our model is able to identify and predict the coming pattern. It also shows the confidence of its prediction. This model uses time series data from point A to point B to perform prediction. It predicts that from point B to point C will have 100% or reoccurrence Figure 7 shows the prediction made by our model on the third test case, shows us that there are two possible outcomes. According to our model prediction pattern could be from point B to point C or from point B to point D. Each of the predicted data has its own confident level of reoccurrence. The first prediction, from point B to point C has 66% while the prediction from point B to point D has 33% of confident to reoccur. This is because according to the time series previous data, this time series has more tendency of repeating the first prediction instead of the second prediction. However, both of these patterns will still have the chances to reoccur The result of the fourth test is that our model successfully identifies that the time series data is random This is because random data do not have repetitive patterns and our model unable to perform any prediction and consider it as random However, at this stage, we discover that our model has advantages and disadvantages compare with neural networks. For example, our model prediction is supported with probability and this makes our model\220s prediction easier to be justified. Besides that, this model is capable to overcome some of neural network disadvantages such as lack of knowledge representation and catastrophic forgetting effect. The name \215Adaptive Association Rules\216 is being used because this model performs prediction by using association rules representation and it is able to perform adaptation and reinforcement learning The drawback of this model is that it required intensive computational power and large storage However, we are confident of solving this disadvantage by either adding a heuristic module or parallelizing this model\220s data mining process. With the help of a heuristic module, this model will mine pattern intelligently by choosing the possible length of a pattern instead of brutally mine every single length pattern. Besides that our model has some problem in converting predicted pattern back into time series data because earlier we converted the original time series data into fuzzy value for pattern matching purpose Figure 5. First test case that has a simple repetitive pattern in this time series Figure 6. This is the second test case that is slightly more complicated then the first test case Proceedings of the First Inte rnational Conference on Distributed Framewor ks for Multimedia Applications \(DFMA\22205 0-7695-2273-4/05 $ 20.00 IEEE 


Figure 7. This is the third test case that has a little random characteristic 5. Conclusion and Future Work Based on the results of the four simple test cases, our model seems to be working although we have yet to test this model with real time series data like CPU usage. However, the preliminary results show that our prediction model can use data mining to perform prediction on univariate time series The future work includes enhancing the model by using scalable time scale such as minute, hour, day week and year of a same time series. We then aggregate all the results from different time scale prediction to perform prediction. This is hope to provide a more robust prediction References  i m o Kos kela, Markus V a rsta, Jukka He i k ko nen, and Kimmo Kaski. \215Time Series Prediction using Recurrent SOM with Local Linear Models\216 Research Report B15 Helsinki University of Technology, Laboratory of Computational Engineering, Finland. Oct 1997  S higeo Ka m i ts uji an d Ritei  S h i b ata  215Eff ecti ve n ess o f  Stochastic Neural Network for Prediction of Fall or Rise of TOPIX\216 Research Paper, Keio University, 2004 3 o l a  Ka sa bo v 215Evo lv in g C o nn e c t io ni st Sys te ms\216   Springer-Verlag London Limited 2003  Ri ch W o ls k i  215 D ynami call y Fo recasti ng Netw o r k Performance Using the Network Weather Service\216, in Journal of Cluster Computing, Volume 1, pp. 119-132 January, 1998  Ri ch W o ls k i  N e il S p ri ng, and Ji m Hay es 215 T he N e two rk   Weather Service: A Distributed Resource Performance Forecasting Service for Metacomputing\216, Journal of Future Generation Computing Systems,Volume 15, Numbers 5 6, pp. 757-768, October, 1999  Ram ez Elm asri and  S h am k a nt B. Nav ath e. \215F u n dam ent als of Database Systems 4 th Edition\216. Addison Wesley Publication, pp. 867-897. 2004  il liam W S  W e i  215Ti m e  Series An a l ysis: Un i v ari ate an d Multivariate Methods\216. Addison Wesley Publication  Proceedings of the First Inte rnational Conference on Distributed Framewor ks for Multimedia Applications \(DFMA\22205 0-7695-2273-4/05 $ 20.00 IEEE 


the measurements generated by the detected points It is fundamentally different than in standard approaches where it is taken equal to the state predictions VI R ESULTS The multi-target tracking algorithm proposed in this paper is currently being implemented on a optical motion capture system We implemented the algorithm in matlab and we tested it on data previously acquired with the motion capture system Twentytwo markers have been attached to a human subject three on the head two on the shoulders two on each arm ve on the torso and four on each leg A rigid object with six markers on it was held by the subject in his hand during the acquisition of motion The total of 28 markers was tracked by a six 50 Hz camera motion capture system for approximately two minutes i.e for about 6000 frames The rst 2000 frames were used to determine and initialize the estimate of the invariants of motion All the markers attached to the rigid body held by the subject in his hand satisfy the mutual distance invariants and even KendallÕs invariant when there are no occlusions The coordination graph clearly exhibits the articulation structure of the human body All the markers on the torso for example belong to the same clique of maximum order equal to ve The markers on the feet all belong to a complete subgraph This is because the subject was asked not to move his feet in order to check adaptability to changes in the coordination and the effect of the forgetting factor As an example the statistics of some invariants are described in the following table  Invariant distance among two targets Mean Std Persistence interval max frames Targets 1 and 3 both on the head 16.8cm 0.12cm All Targets 12 and 13 on the left arm 29.7cm 0.57cm 786 The total number of trajectories segments has been taken as a performance index of the data association algorithm Ideally the number of trajectories should have been equal to the total number of markers i.e 28 An implementation of the JPDA alone generated 112 segments The number of trajectory segments is furthermore highly dependent on the choice of noise covariances in the Kalman lters If the covariances are set too small the measurements do not fall within the validation gates and are associated to clutter If the covariance is set too large the data association becomes very difÞcult because the number of possible associations increases After a few trials we found a choice that led to the best result of 112 segments The shape integrated JPDA generated 36 segments where most of the wrongly labeled segments were produced because of the incorrect invariants detected between the feet of the subject Tuning the forgetting factor  for the invariants is important to obtain signiÞcant results A small  leads to the creation of invariants which persist in time very brießy A large  renders the scheme rigid and not adaptable so that wrong invariants declared as such because of not sufÞciently exciting dynamics lead to wrong data association VII C ONCLUSIONS This paper continues along the research line presented in  The spirit is to include information due to the statistical dependence among the targets in standard algorithms multi target tracking algorithms that otherwise treat targets as independent This information is of great help in solving the data association problem The proposed schemes should also improve on the techniques proposed in the computer vision literature based on statistical learning methods which do not imply any local coherence in time of the targets trajectories Coordination among targets has been models by the means of motion symmetries or invariants The shape description proposed by Kendall is used as an invariant but since this is not robust w.r.t occlusions it has been integrated with pairwise distances among targets and angles between target velocities The possibility of slow drifts in time of the invariants is dealt with by introducing forgetting factors in the estimate of their statistics In experiments with a motion capture system segmentation of the tracks has been substantially reduced compared to the standard JPDA assuming the possibility of learning the invariants on a sufÞciently long time interval with persistently exciting dynamics R EFERENCES  Y  Bar Shalom and T  F ortman Tracking and data association  Academic Press 1988  D B Reid An algorithm for tracking multiple targets  IEEE Trans on Automatic Control 25  No 6 pp 843-854 1979  G Gennari A Chiuso F  Cuzzolin and R Frezza Integrating shape and dynamic probabilistic models for data association and tracking  IEEE Conference on Decision and Control 2002  G Gennari A Chiuso F  Cuzzolin and R Frezza Integration of shape constraints in data association lter  IEEE Conference on Decision and Control 2004  I N Goodman and D H Jonson Orthogonal decompositions of multivariate statistical dependence measures  Int Conf on Acoustics Speech and Signal Processing ICASSP 2004 Montreal CA May 2004  I Gordon and D G Lo we Scene modelling recognition and tracking with invariant image features  International Symposium on Mixed and Augmented Reality ISMAR Arlington VA Nov 2004 pp 110-119  D G K endall A survey of the statistical theory of shape with discussion  Statist Sci 4  1989 pp 87-120  M Isard and A Blak e Condensation  conditional density propagation for visual tracking  Int J Computer Vision 1998  K Okuma A T ale ghani N De Freitas J J Little and D G Lo we A Boosted Particle Filter Multitarget Detection and Tracking  European Conference on Computer Vision ECCV Prague May 2004 pp 2839  C Rasmussen and G.D Hager  Joint probabilistic techniques for tracking multi-part objects  Int Conf on Computer Vision and Pattern Recognition 1998  C Rasmussen and G.D Hager  Probabilistic data association methods for tracking complex visual objects  IEEE Transaction on Patter Analysis and Machine Intelligence 23 2001 560Ð576  Y  Song L Gonca v es E Di Bernardo and P  Perona Monocular perception of biological motion detection and labelling  Int Conf on Computer Vision 1999 pp 805Ð812  Y  Song L Gonca v e s and P  Perona Unsupervised learning of human motion  IEEE Transaction on Patter Analysis and Machine Intelligence 25 2003 1Ð14  Y  Zhu EfÞcient Recursive State Estimator for Dynamic Systems without Knowledge of Noise Covariances  IEEE Transaction on Aerospace and Electronic Systems 35 1999 102Ð114 6058 


2          f o r  a l l  c a t e g o r i c a l              let          3          f o r  a l l  c a t e g o r i c a l              let           4   G i v e n  a n  m d i  o f       f o r  a l l  n u m e r i c       let           Given                   a n d                r       f o r  e a c h  c a t e g o r i c a l       a n d        o r       f o r  e a c h  c a t e g o r i c a l       from \(1 3 4 t h e  d e n s e n e s s  b e i n g  a  M I N T  m e a s u r e         f o r  e a c h  n u m e r i c       a n d        f o r  e a c h  n u m e r i c       Accordi n g l y         a n d         a n d  t h e  j o i n            g i v e s the upper bounds of       m a y  n o t  b e  u n i q u e   s i n c e  m u l tiple mdrs  s  c a n  b e  d e r i v e d   A l s o    m a y  n o t  e x i s t   s i n c e      c a n  b e  o b t a i n e d  i n   1    o r  t h e  m d r   can not exist, i.e      i n   4    F i g u r e  1  d e p i c t s  t h e s e  c a s e s   I n Figure 1. Derivation of  by join a  o f  t h e  c o m b i n e d  i t e m s e t    i s  m u l t i p l e  d u e  t o  t h e  l a c k of uniformity of     even if  and  of the original itemsets are unique respectively. In \(b  


nal itemsets are unique respectively. In \(b  does not exist due to the low denseness of       A c c o r d i n g l y    rived via       i s  a  f a m i l y  o f  s e t s  i n  g e n e r a l   T h e n  w e  o b t a i n  t h e  j o i n  o p e r a t i o n         b y  E q   2    F r o m  t h e  a b o v e d i s c u s s i o n                      a n d  t h u s       i l a r l y          T h i s  i n d i c a t e s  t h a t  t h e  j o i n      g i v e s  t h e upper bound of    a n d  a n  u p p e r  s e m i l a t t i c e    Based on this de?nition of join operation on families of sets with denseness and the de?nitions of support and con?dence, the most of the standard algorithms of the Basket Analysis whose complexity is       c a n  b e  a p p l i e d  t o  d e rive generic QARs from data 3.2. Implementation To assess the basic features of QARMINT, we used the standard Apriori-TID algorithm [1], since it is principally an algorithm running on memory, and its computational features are well known. Instead of hash tables, the trie data structure as depicted in Fig. 2 was used under lexicographically ordered itemsets. If any subsets of the joined s e t                a r e  n o t  f r e q u e n t  a c c o r d i n g  t o  a  g i v e n      i s  p r u n e d  b e f o r e  i t s  m d r   is computed. Moreover, after computing the mdr      i s  p r u n e d  i f    i s  n o t frequent. The pruning by these checks are indicated by the slashed itemsets in Fig. 2. A difference from the original Apriori-TID algorithm is that the join of two itemsets    within a family depicted by a solid box is not allowed, and t h e  i t e m s e t s   s  o b t a i n e d  f r o m  a  p a i r  o f  f a m i l i e s    l o n g  t o  a n  i d e n t i c a l  f a m i l y     A n o t h e r  d i f f e r e n c e  i s  t h a t  a join of     c a n  g e n e r a t e  m u l t i p l e  i t e m s e t s   s  a s  d e p i c t e d  i n a dashed box The most expensive process in QARMINT is to derive the mdr  s  o f  j o i n e d  i t e m s e t     W e  i n t r o d u c e  a n  i t e r a t i v e approach to reduce the required computation time. Given                     r s t   a l l  t r a n s a c t i o n s  i n  are sorted for each attribute   i n     T h i s  i s           T h e n  the mdis on the number line of  


are computed from the transactions without taking into account the other attributes When multiple mdis are obtained, one of them is focused and the transactions in the mdi is retained. Next, the identiProceedings of the The 2005 Symposium on Applications and the Internet Workshops \(SAINT-W  05 0-7695-2263-7/05 $20.00  2005 IEEE Figure 2. Trie data structure Figure 3. Time complexity cal process is applied to   and this recursively continues in depth ?rst search \(DFS   is computed, the process continues again from  until the mdi of every              c o n v e r g e s   T h e  m d i s  a l w a y s  c o n v e r g e to these of the mdr  because the denseness is a MINT measure. After the convergence, the search is backtracked to the next mdr  The computation of mdis in each step requires       t i m e  a t  m o s t   I n  t h e  w o r s t  c a s e   o n l y  o n e t r a n s a c t i o n  i s  d r o p p e d  i n  e a c h  s t e p   a n d    s t e p s  r e q u i r e d until the mdis converge. Thus         H o w e v e r   t h i s  d o e s not likely occur. Practically, only a portion of the transact i o n s  a r e  r e t a i n e d  i n  e a c h  s t e p   L e t          b e  a n  e x pected rate of transactions retained in each step the required steps for convergence. The process to search an mdr stops at the latest when the number of retained transa c t i o n s     b e c o m e s  l e s s  t h a n   By solving the equation       w i t h   is        A c cordingly, the expected time complexity of this most expensive process is         4. Performance Evaluation The performance of QARMINT has been evaluated through both arti?cial data and real bench mark data Sets of arti?cial data have been generated under various conditions. The characteristics of the computation time is simlilar to the conventional Basket Analysis except for       T h e  t i m e  m o d e r a t e l y  i n c r e a s e s  w h e n s of all attributes are increased. This is because wider permissible ranges increases the number of mdrs. Figure 3 shows the dependency of the computation time on the n u m b e r  o f  t r a n s a c t i o n      T h e  c u r v e  a l m o s t  f o l l o w s  t h e  r e lation         The real bench mark data  Labor relations Database  in UCI Machine Learning Repository [3] was analyzed by QARMINT. It contains 57 instances, 8 numeric attributes and 8 categorical attributes and many missing values. We ignored the attributes of missing values in each instance and transformed the data into transactions. Though the size 


and transformed the data into transactions. Though the size of this data is quite small, we found many interesting QARs associated with the labor conditions under      and      w h i c h  i s  1 0   o f  t h e  m a x i m u m  a n d  m i n i mum values of each  in the data. The following two are examples                                                                                                                  These rules indicate that the workers having longer durat i o n  c o n t r a c t s  a n d  e v a l u a t i n g  t h e i r  l a b o r  c o n d i t i o n  a s   admit longer working times and less wage increase. These evaluations indicate the suf?cient tractability and the practical applicability of QARMINT 5. Conclusion The mathematical characterization and the extension of the Basket Analysis presented in this paper are expected to provide variety of new approaches of data mining. Their potential has demonstrated by a novel approach called QARMINT for complete mining of generic QARs within a low time complexity. We are implementing QARMINT in a more ef?cient algorithm and evaluating its performance in near future Acknowledgement This research has conducted under the support of JSPS Kiban Kenkyuu \(B 2 References 1] R. Agrawal and R. Srikant. Fast algorithms for mining association rules. Proc. of 20th Int. Conf. on Very Large Data Bases VLDB  499, 1994 2] R. Srikant and R. Agrawal. Mining quantitative association rules in large relational tables. Proc. of 1996 ACM SIGMOD Int. Conf. on Management of Data, pages 1  12, 1996 3] U. C. I. \(UCI http://www.ics.uci.edu/ mlearn/MLRepository.html, 2004 4] J. Wijsen and R. Meersman. On the complexity of mining quantitative association rules. Data Mining and Knowledge Discovery, 2\(3  281, September 1998 Proceedings of the The 2005 Symposium on Applications and the Internet Workshops \(SAINT-W  05 0-7695-2263-7/05 $20.00  2005 IEEE 


0-7695-2263-7/05 $20.00  2005 IEEE pre></body></html 


n M L N n t n t n t n t L M L t L t L tt L t kkkk kkkk kkk kkkk kkkkkkkkP VK VK VK VK PP       kkP t 31 where L  s the error covariance associated with the state estimate t i    kkLX  tt kkk P1  00 0  0                     s s sss s s sss s s sssss N n t n t n 


n t n N n t n t n t n N n t n t n t n t n t n c t L kkkkkk kkkkk kP VKVK VKVK  32 4. Simulations One has run simulations comparing the sequential implementations of MSJPDA algorithm and the new algorithm here. A typical multisensor multitarget tracking environment is assumed in the simulations. According to article [1,3], One known that the performance of sequential MSJPDA is better than the performance of parallel MSJPDA. Therefore, the performance of parallel MSJPDA algorithm will not be compared here There are three sensors, which are fixed in three platforms. Regarding the 2nd sensor as fusion centre situation of the other sensors are: =?-500m?-500m 0m??N =?-500m? 500m?0m??The distance error of each sensor is: =300m, =200m, =100m?The bear error of each sensor is 0.03rad, =0.02rad, =0.01rad?The of sample is T=1s?The nonparametric model of clutter is used in the simulations, and expected number of false measurement is m=1.8 1 sN 3 s 1r 2 2r 3 3r 1 Simulations have been run for racking two targets. The true initialization state of the targets is X1?[-29500m,400m/s,34500m,-400m/s X ?[-26250m,296m/s,34500m,-400m/s]'? 2 The two targets will cross above 31seconds later. To evaluate tracking performance, 50 Monte Carlo runs were performed for three case of the target detection probability Pd=0.97 ? Pd=0.76 ? Pd=0.58. In every run, the total simulation time is 140 steps 


simulation time is 140 steps            Figure 1  RMS position error in case of Pd=0.97          Figure 2  RMS velocity error in case of Pd=0.97       Figure 3  RMS position error in case of Pd=0.76 567 Proceedings of  the Fourth International Conference on Machine Learning and Cybernetics  Guangzhou, 18-21 August 2005         Figure 4  RMS velocity error in case of Pd=0.76         Figure 5  RMS position error in case of Pd=0.58          Figure 6  RMS velocity error in case of Pd=0.58  Table 1 The emanative times comparison for sequential MSJPDA and SD-CMSJPDA algorithm  Pd N A  0.97 0. 76 0.58 Sequential MSJPDA 2 11 17 SD-CMSJPDA 0 3 5 Pd denotes detection probability, N denotes emanative 


Pd denotes detection probability, N denotes emanative times, A denotes the kind of algorithm Table 1 shows the summation of emanative times for sequential MSJPDA and SD-CMSJPDA algorithm in 50 Monte Carlo simulations. From table 1 , it is shown that the stability of SD-CMSJPDA is better than that of sequential MSJPDA as the detection probability varied Figure 1,2 show the RMS errors for position and velocity in case of Pd=0. 97, respectively; Figure 3,4 show the RMS errors for position and velocity in case of Pd=0.76 respectively; Figure 3,4 show the RMS errors for position and velocity in case of Pd=0.58, respectively. From the figures we can see that the average RMS position error is lower for the SD-CMS JPDA algorithm. We also see that the state estimation precision of sequential MSJPDA get worse as the detection probability decreases The reasons for these simulation results lies:1 state estimation precision will get worse when the detection probability decrease;2 algorithm is to process measurement from each sensor using single sensor JPDA algorithm sequentially. Therefore the estimation error from each sensor will be accumulated Moreover, the sequential MSJPDA algorithm can  t improve the joint detection probability of the multisensor system The estimation error of the SD- CMSJPDA  algorithm will not be accumulated for it processes the measurement from each sensor directly in the mean time .What  s more the new method can greatly improve the joint detection probability of the multisensor system. Therefore, the tracking performance of SD-CMSJPDA algorithm is better than that of sequential MSJPDA. Algorithm All of the simulations are run in the personal computer with a 2.0G CPU and a 256M memory. The average cost time per step is 0.0251 in the sequential implementations of MSJPDA algorithm. And the average cost time per step is 0.0282 in the sequential implementations of MSJPDA algorithm. According to the results we can see that there is few difference in real time between the new method and the sequential   MSJPDA when there is not so many sensors and targets 568 Proceedings of  the Fourth International Conference on Machine Learning and Cybernetics  Guangzhou, 18-21 August 2005  5. Conclusion In order to solve the problem of multisensor multi target tracking, a new centralized multisensor  joint probabilistic data association  algorithm is proposed in this paper. The simulation results shows that the tracking performance of the new algorithm is better than that of the sequential MSJPDA algorithm The computational complexity of the new method will increase as the number of sensors and targets grow Therefore, how to improve the real time of SD- CMSJPDA algorithm will be pay attention References 1] He You, Wang Guohong, Lu Dajin, Peng Yingning Multisensor Information Fusion With Application[M Publishion House of Electronics Industry. 2000, Beijing.  [11] B..Zhou and N.K.Bose Multitarget  Tracking in Clutter:Faste Algorithms for Data Association .IEEE Transaction on Aerospace and Electronic Systems 1993,29\(2 2] Bar-shalom,Y\(Ed Applications and Advances,2: Norwood,MA Artech  House, 1992 3] L.Y. Pao, C.W.Frei. A Comparison of Parallel and Sequential Implementation of a Multisensor Multitarget Tracking Algorithm. Proc. 1995 American Control Conf. Seattie, Washington,June 1995 1683~1687 


4] K. Chang, C. Chong, Bar-Shalom, Joint Probabilistic Data Association in Distributed Sensor Networks IEEE Transactions on Automatic Control, AC-31\(10 octobre 1986 5] Bar-shalom, Multitarget Multisensor Tracking Advanced Application ,:YBS Publishing, 1990 6] Bar-shalom, Multitarget Multisensor Tracking Principles and Techenices ,:YBS Publishing, 1995 7] Hu Wenlong, Mao shiyi, Multisensor Data Association Based on Combinatorial Optimization[J]. Journal of Systems Engineering and Electronics . 1997 NO.1,1~9 8] Pattipati K R, Passive Multisensor Data Association Using a New Relaxation Algorithm.In Multitarget-Multisensor Tracking: Advanced and Applications,Y.Barshalom,Norwood,MA:Aretech,199 0 9] Deb S,et al, An S-Dimentional Assignment Algorithm for Track Initiation ,Proc. Of the IEEE Int. Conf Systems Engineering, Kobe, Japan,Sept 1992 527~530 10] Deb S,et al, A Multisensor-Multitarget Data Association Algorithm for Heterogeneous Sensors[J].IEEE Trans. on AES 1993 ,29 \(2 560~568 12] Bar-shalom,Y.,and Fortmann,T.E  Tracking and Data Association  New York:Academic press,1988 13] J,A,Roecher and G.L.Phillis,Suboptimal Joint Probabilistic Data Association .IEEE Transaction on Aerospace Electronic Systems.1993,29\(2 14] J,A,Roecker,A Class of Near Optimal JPDA Algorithm IEEE Transaction on Aerospace and Electronic Systems,1994,30\(2 15] Han Yanfei, Analysis and Improvement of Multisensor Multitarget Probabbilistic Data Association Filting Algorithm[J].  Journal of Systems Engineering and Electronics, 2002, Vol.24, 36~38  569 pre></body></html 


dense data sets for evaluating pattern mining algorithms These two data sets are obtained from IBM Almaden at http://www.almaden.ibm.com/cs/quest/demos.html. Recently, theMAFIA algorithm [6] was proposed to ef?ciently discover maximal frequent patterns. As shown in their paper, MAFIA can be several orders better than some alternatives, such as DepthProject, for mining maximal frequent patterns. Hence, we chose MAFIA as the base line for our performance evaluation. Finally, please note that only the size-2 patterns are generated in the ?rst BFS phase Experimental Platform We implemented the MHP algorithms using C++ and all experiments were performed Proceedings of the 16th IEEE International Conference on Tools with Artificial Intelligence \(ICTAI 2004 1082-3409/04 $20.00 © 2004 IEEE on a Pentium III    MHz PC machine with    megabytes main memory, running Linux Redhat 6.1 operating system 5.2. A Performance Comparison 100 1000 10000 100000 1e+06 1e+07 1e+08 1e+09 1e+10 1e+11 0.02 0.025 0.03 0.035 0.04 0.045 0.05 0.055 0.06 N um be r o f C he ck ed P at te rn s Support threshold Mafia Min_Conf=0 Min_Conf=0.1 Min_Conf=0.3 Min_Conf=0.5 Min_Conf=0.7 Min_Conf=0.9 


Figure 4. The Number of Checked Patterns on the Pumsb* Data Set 10 100 1000 10000 100000 0.02 0.025 0.03 0.035 0.04 0.045 0.05 0.055 0.06 R un T im e s ec  Support Threshold Mafia Min_Conf=0 Min_Conf=0.1 Min_Conf=0.3 Min_Conf=0.5 Min_Conf=0.7 Min_Conf=0.9 Figure 5. The RunTime Comparison on the Pumsb* Data Set Figure 4 shows the number of patterns that MHP and MAFIA have to check during the pattern mining process on the pumsb* data set. As can be seen, for MHP, the number of checked patterns is increased with the decrease of the h-con?dence threshold. However, the number of checked patterns of MHP can be signi?cantly smaller than that of MAFIA even if a low h-con?dence threshold is speci?ed To check a pattern, we need to count the support of the patterns. Counting the support of a pattern is the most timeconsuming task during the pattern mining process, since we need to retrieve all the transactions which include one of its sub-pattern, or for Ma?a, retrieve all the bit of the bitmap of this pattern [6]. Therefore, an algorithm is more ef?cient if smaller number of patterns need to be checked 100 1000 10000 100000 1e+06 1e+07 1e+08 1e+09 0.1 0.2 0.3 0.4 0.5 0.6 0.7 N 


um be r o f C he ck ed P at te rn s Support Threshold Mafia Min_Conf=0.5 Min_Conf=0.7 Min_Conf=0.9 Figure 6. The Number of Checked Patterns on the Pumsb Data Set 10 100 1000 10000 0.1 0.2 0.3 0.4 0.5 0.6 0.7 R un T im e s ec  Support Threshold Mafia Min_Conf=0.5 Min_Conf=0.7 Min_Conf=0.9 Figure 7. The RunTime Comparison on the Pumsb Data Set The runtime comparison of MHP and MAFIA on the Pumsb* data set is shown in Figure 5. In the ?gure, we can observe that the runtime of MHP can be signi?cantly reduced with the increase of h-con?dence thresholds. Also the runtime of MHP can be several orders of magnitude less than that of MAFIA even if the h-con?dence threshold is as low as 0.3. The reason is that the number of checked patterns of MHP is sign?cantly smaller than that of MAFIA Similar results are also obtained from the pumsb data set as shown in Figure 6 and Figure 7. For the pumsb data set the number of checked patterns of MHP is much smaller 


than that of MAFIA and the runtime of MHP can be significantly less than that of MAFIA 5.3. The Effect of the MHP Algorithm on Finding Maximal Hyperclique Patterns Figure 8 and Figure 9 show the number of maximal patterns identi?ed byMHP andMAFIA on Pumsb* and Pumsb data sets respectively. As can be seen, the number of maximal hyperclique patterns identi?ed by MHP can be orders of magnitude smaller than the number of maximal frequent patterns identi?ed by MAFIA. In other words, the number Proceedings of the 16th IEEE International Conference on Tools with Artificial Intelligence \(ICTAI 2004 1082-3409/04 $20.00 © 2004 IEEE 100 1000 10000 100000 1e+06 1e+07 1e+08 1e+09 0.02 0.025 0.03 0.035 0.04 0.045 0.05 0.055 0.06 N um be r o f C ou nt ed P at te rn s Support Threshold Mafia Min_Conf=0 Min_Conf=0.1 Min_Conf=0.3 Min_Conf=0.5 Min_Conf=0.7 Min_Conf=0.9 Figure 8. The Number of MFI/MHP Patterns in the Pumsb* Data Set 100 1000 10000 100000 1e+06 


1e+07 1e+08 0.1 0.2 0.3 0.4 0.5 0.6 0.7 N um be r o f C ou nt ed P at te rn s Support Threshold Mafia Min_Conf=0.5 Min_Conf=0.7 Min_Conf=0.9 Figure 9. The number of MFI/MHP Patterns in the Pumsb Data Set of maximal hyperclique patterns is much easier to manage than that of maximal frequent patterns. Indeed, in realworld applications, it is dif?cult to interpret several million maximal frequent patterns. However, it is possible to interpret the results of maximal hyperclique pattern mining In addition, due to the memory limitation, we cannot extract maximal frequent patterns with MAFIA on the Pumsb data set if the support threshold is less than 0.4, as shown in Figure 7. In contrast, MHP can identify maximal hyperclique patterns when the support threshold is 0.1, if we set the h-con?dence threshold to 0.5. In other words, MHP has the ability to identify patterns which can be dif?cult to identify for MAFIA. Hence, MHP can better explore the pattern space and ?nd interesting patterns at low levels of support 6. Conclusions and Future Work In this paper, we present a two-phase Maximal Hyperclique Pattern \(MHP best features of both the BFS strategy and the DFS strategy. More speci?cally, we adapted DFS pruning methods such as equivalence pruning, to an apriori-like approach In addition, we proved the correctness and completeness of the MHP algorithm. Finally, our experimental results show that the MHP algorithm can be several orders of magnitude faster than standard maximal frequent pattern mining algorithms and has the ability to identify patterns at extremely low levels of support in dense data sets There are several directions for future work. First, in 


this paper, we only generate the size-2 patterns in the BFS phase. It will be interesting to investigate the impact on the performance if the ?rst phase is stopped at a deeper level Also, the projection is a very ef?cient method for ?nding patterns, especially for parallel implementation of pattern mining algorithms [1]. We plan to adapt the projection ideas into our algorithm and design an ef?cient parallel algorithm for mining maximal hyperclique patterns References 1] R. Agarwal, C. Aggarwal, and V. Prasad. A Tree Projection Algorithm For Generation of Frequent Itemsets. pages 350 371, Feb 2001 2] R. Agrawal, T. Imielinski, and A. Swami. Mining Association Rules between Sets of Items in Large Databases. In Proc. of the ACM SIGMOD Conference on Management of Data, pages 207216,May 1993 3] R. Agrawal and R. Srikant. Fast Algorithms for Mining Association Rules. In Proc. of the 20th Intl Conference on Very LargeData Bases, 1994 4] R. Bayardo. Ef?ciently mining long patterns from databases In Proc. of the ACM SIGMOD Conference, 1998 5] R. Bayardo and R. Agrawal. Mining the Most Interesting Rules. In Proc. of the ACM SIGKDD Conference, 1999 6] D. Burdick, M. Calimlim, and J. Gehrke. Ma?a: AMaximal Frequent Itemset Algorithm for Transactional Databases. In Proc. of IEEE Conf. on Data Engineering, 2001 7] Y. Huang, H. Xiong, W. Wu, and Z. Zhang. A Hybrid Approach for Mining Maximal Hyperclique Patterns. In In Technical Report UTDCS-34-04, Department of computer science, University of Texas - Dallas, 2004 8] J.Han, J.Pei, and Y. Yin. Mining Frequent Patterns without Candidate Generation. In Proc. of the ACM SIGMOD International Conference on Management of Data, 2000 9] M.J.Zaki and C.Hsiao. ChARM: An ef?cient algorithm for closed itemset mining. In Proc. of 2nd SIAM International Conference on Data Mining, 2002 10] R.Rymon. Search through Systematic Set Enumeration. In Proc. Third Intl Conference on Principles of Knowledge Representation and Reasoning, 1992 11] H. Xiong, M. Steinbach, P.-N. Tan, and V. Kumar. HICAP: Hierarchial Clustering with Pattern Preservation. In Proc. of 2004 SIAM International Conference on Data Mining \(SDM 12] H. Xiong, P.-N. Tan, and V. Kumar. Mining Strong Af?nity Association Patterns in Data Set with Skewed Support. In Proc. of the Third IEEE International Conference on Data Mining \(ICDM Proceedings of the 16th IEEE International Conference on Tools with Artificial Intelligence \(ICTAI 2004 1082-3409/04 $20.00 © 2004 IEEE 





