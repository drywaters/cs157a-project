  1 A Scalable Image Processing Framework for Gigapixel Mars and Other Celestial Body Images  Mark W. Powell, Ryan A. Rossi 206 and Khawaja Shams Jet Propulsion Laboratory, California Institute of Technology Mark.W.Powell, Ryan.A.Rossi, Khawaja.S.Shams}@ jpl.nasa.gov  Abstract 227The Mars Reconnaissance Orbiter\222s HiRISE High Resolution Imaging Science Experiment\era takes the largest images of the Martian surface. The image size is typically around 2.52 gigapixels. There is only a handful of software capable of doing a task as simple as reducing the size of the image by half and saving the result 
as a new image. The Scalable Image Processing Framework SIPF\overcomes these issues by creating a generalized tile-based processing pipeline that loads only a small portion of the image into memory. This allows for the data in memory at any given time to become manageable. Image tiles are an intrinsic property that provides scalability and efficiency while processing im ages. Distributed computing technologies such as cloud computing can be applied naturally. A mathematical framework for scalable image operations is defined that provides insight into the scalable considerations needed with each class of operations. We also formalize the deferred execution design pattern and 
show how it is used as a basis for our implementation. The SIPF has the ability to perform a variety of Scalable Image Operations such as Cropping Rotation, Scaling \(Bilinear and Nearest Neighbor Interpolation\Edge Detection Sharpening, Convolution \(Filters Brightness, Contrast, and Gaussian Blurring. The Scalable Image Processing Framework will be used to process incoming images from the Mars Exploration Rovers and eventually the Mars Science Laboratory. It will be integrated with the Maestro software \(science visualization and planning tool\Maestro is used for the Mars Exploration Rover Mission and other celestial body exploratory missions 1 2  
 1 978-1-4244-3888-4 10/$25.00 \2512010 IEEE 2 IEEEAC paper #1533, Version 1, Updated August 5, 2009 T ABLE OF C ONTENTS  1  I NTRODUCTION  1  2  M ATHEMATICAL F RAMEWORK  2  3  D EFERRED E XECUTION 
P ATTERN  4  4  D ESIGN AND I MPLEMENTATION  5  5  D ISTRIBUTED AND C LOUD C OMPUTING  8  6  C ONCLUSION  9  7 
 F UTURE W ORK  10  8  A CKNOWLEDGEMENTS  10  R EFERENCES  10  B IOGRAPHY  10  1  I NTRODUCTION  The Mars Reconnassance Orbiter\222s HiRISE camera takes very high resolution images up to 2.52 gigapixels \(2520 
megapixels\The HiRISE camera is a 0.5 m reflecting telescope and is the largest ever carried on a deep space mission. It has a resolution of about 1 microradian. The ground sample distance is 30cm per pixel from an altitude of 300km. The images can be either near infrared or redgreen-blu A few of t h e HiRISE images that we have worked on in the Operations Planning Software Research group at the Jet Propulsion Laboratory are shown below The Maestro team develops operations software used to conduct mission exploration of the Moon, Mars, and other celestial bodies Pl anni ng and operat i ng t h ese m i ssi ons all benefit from imaging and mapping planetary surfaces in detail. As the size and volume of imagery from planetary 
  


  2 missions increases, image processing software faces the challenge of keeping pace with the increase in scale while still providing the high performance that is expected of superior software  Most image processing software assumes you can load the entire image into memory a nd then perform an image operation. This is typically not possible due to the size of planetary imagery. The images at HiRISE provide a good example as these are typically in the gigapixel range \(one billion pixels 10 9 e overcome these issues by creating a generalized tile-based processing pipeline that loads only a small portion of tiles into memory at any given time. This creates a streaming pipeline of data for the image operations to take advantage of without having severe memory issues The memory needed to pro cess an arbitrary image is decoupled from the size of the image and is instead bounded by the size of the cache. This a pproach allows for images in the gigapixel range to be processed on consumer based computers as well as distri buted across computers very naturally and efficiently The science activity planning for the Mars Rovers and eventually the Mars Science Laboratory requires the most recent images from the rovers to evaluate the executed science. The Scalable Image Processing Framework will be used to process operations images to support scientists in the planning and operating of the Mars Exploration Rover and the Mars Science Laboratory. The scalability of the framework is a necessity due to the massive size and amount of images we will be processing on a daily basis We also take advantage of distributed computing technology as these technologies are intuitively applied with our framework. Our framework also supports tile-based delivery for web applications such as Google maps or our science delivery system that e fficiently delivers images to planning teams located in different countries In the next section we define the mathematical framework for scalable image operations. In the third section we formalize and briefly describe the deferred execution design pattern and explain how it is used as a basis for our Scalable Image Processing Framework. In the fourth section we describe the design and implementation details. Finally in the last section we describe the distributed and cloud computing strategies used with our Scalable Image Processing Framework 2  M ATHEMATICAL F RAMEWORK  In this section we describe the mathematical definitions to be used throughout the paper to define our scalable image processing framework. The definitions are used for representation and processing of tiles in a scalable manner Informally we define a matrix of tiles where the tiles are matrices themselves. These matrices will have weaker mathematical properties. Ther efore results that hold for normal matrices cannot be directly applied in the same way Let T i,j  002  003 w x h be a matrix corresponding to an image tile where i, j are the coordinates of the tile with respect to the image matrix denoted as I  and w x h are the width and height of the tile, respectively. Furthermore, let T i,j  x, y  e  a pixel value at location x, y  resp ect to th e wid t h an d  height of the image tile T i,j Therefore a tiled image I is defined as   Where n x m is the width and height of the image with respect to the tiles in the image. Furthermore let I i, j  be a tile at location i, j Therefore I i,j  T i,j and I i,j x, y T i,j  x, y   Now we list a few properties of this definition that are related to image processing 1  The total amount of pixels in the image plane is defined as nm   wh is the amount of tiles in the image and wh is the number of pixels in every tile  I 


  3 2  Given an arbitrary pixel location [x en  th e appropriate tile can be referenced by I x / w  y / h  3  It is also easy to see that iw - w, jh \226 h  i s t h e mi n i mu m pixel location and iw, jh  e m a x im u m  p ix e l lo catio n  of T i,j with respect to I  In the next few subsections we define the main scalable image operations and discuss the scalable considerations  2.1 Scalable Point Operations A point operation performs a mapping of a pixel value but without changing the size, geometry, or local structure of the image. We show a simple example of how a scalable point operation is defined. Below we increase the image\222s intensity by a factor 004 327  005         yxIyxI ji ji   1     This operation is easily made scalable since each new pixel value depends exclusively on the previous value at the same position. Therefore the computation is independent from its neighboring pixel values and the geometry of the image is unchanged  2.2 Scalable Convolution Linear convolution is a mathematical operation that combines two functions f and g producing a third function Convolution is the underlying concept of all filter operations in image processing and thus described as a black box operation. The results of convolution are defined by the convolution matrix or kernel. A kernel is generally defined as a nxn matrix denoted as K nxn     Convolution from an Image Processing perspective can be thought of as sliding a kernel K across an image I such that the middle coefficient of the kernel K is multiplied by every pixel in the image. Th erefore it is straightforward to see that scalable considerations ar e needed to appropriately convolve tiles  Now we define a simplified scalable smoothing operation To compute a new pixel in the smoothed image we average the original pixel and the eight neighboring pixels. Given the pixel location I i,j x + u, y where we know [x,y  i s i n  T i,j it is clear that if  iwuxwiw 002 006 005\005 327  005 Kvu ji ji vuKvyuxIyxI            4   Where K*\(u, v\s equivalent to K\(-u, -v\ated by 180 degrees  As an example the Laplace kernel is generally used for sharpening and enhancing edges. If a filter coefficient is negative it can be interpreted as the difference of two sums The filter essentially computes the difference between the center pixel and the weighted sum of the four surrounding pixels. In our scalable framework we have used convolution for Difference Filters, Gaussian Blur, Minimum Filter Dilation\, Maximum Filter \(Erosion\, Sharpening, and Edge Detection. Any filter operation can be easily performed by passing the corresponding kernel to the 004 where I i,j x,y the tile T i,j   212 212    005 1 1 1 1      9 1    vu ji ji vyuxI yxI  3     Furthermore the more general notion of convolution follows naturally. Let I i,j x b e a p i x el fro m th e im ag e I in th e tile T i,j and K nxn be a kernel. Linear convolution of the image I with the kernel K is defined as    212  jhvyhjh 212   2    then we are in a situation where the given pixel location is outside the tile T i,j Therefore let i   x + u  w and j   y + v  h be the tile corresponding with the pixel location x+u, y Now we can defi ne a si m p l e scal abl e 3x3 smoothing operation as   


  4 convolution function  2.3 Scalable Geometric Operations A geometric operation transforms an image I by modifying the coordinates of the pixels. Therefore given an image I i,j x, y t h e resul t of a geom et ri c operat i on i s denot ed as I i j x y where I is of size n x m with respect to the transformation. We use geometric operations to scale the size of an image \(Bilinear and Nearest Neighbor Interpolation\so for rotation. We define an arbitrary continuous mapping function M     yxMyandyxMx y x 007 005   ysyM y y 007 005    6   where s x and s y are scaling factors. We define a scalable scaling operation using nearest-neighbor interpolation Nearest-neighbor interpolation simply rounds the continuous coordinate to the closest integer and uses this as an approximation. Let I be an n x m matrix of tiles where n   nw x w  and  m   mh y h  Therefore given an arbitrary pixel in the transformed image I i j x y where i  and j are the tile coordinates with respect to the transformed image I then the interpolated pixel is I i,j round\(x s x  round\(y s y     It is straightforward to see how a form of convolution can be applied to geometric operations. The parameters used in a transformation can be found by solving a system of linear equations x Ma An interesting future direction will be to apply Singular Value Decomposition to predict the pixel values of an unknown region in an image using the known pixel values in I as a basis  2.4 Scalable Cropping Operation To crop an image we had to tr anslate coordinate systems to request the appropriate tiles needed to make the crop tiles Assuming tiles of size 256 x 256 if we started cropping at image location I 1,1 100,100] we would ha ve to request tiles T 1,1 T 2,1 T 1,2 T 2,2 to make the first crop tile    In the diagram above the tiles are designated by white lines where the dotted line represen ts the image region to be cropped. The crop operation will request the image tile T 3,1  thus calling the Image Reader where the tile will be randomly accessed and read. Th e crop operation will copy the appropriate data into the crop tile C 1,1 and make another request to read in the image tile T 3,2 and copy the remaining data into the tile C 1,1 If there are no more image operations to be performed on C 1,1 the writer will write the crop tile to disk. The scalable image processor will begin reading and processing the next tile C 1,2 in a similar manner until the operation is completed 3  D EFERRED E XECUTION P ATTERN  Design patterns originated with Christopher Alexander in 1977 as a way to describe fundamental building blocks of towns buildings, and construction Gamma et. al. extended the notion of design patterns to object oriented programming. A design pattern in object oriented programming can be described as a template or a reusable solution that can be applied to a similar common occurring problem in software engineering. Design patterns can speed up development by providing proven tested paradigm   005  005   5   Most transformed coordinates [x y will no longer fall onto the corresponding previous discrete point [x, y i n t h e image plane therefore interpol ation is used to compute intermediate pixel values. This can be thought of as using the original discrete image I and transforming it using a continuous function into another discrete image I without significantly reducing the quality of the image. Interpolation can be seen as trying to rec onstruct the transformed image made by a continuous function\ng the set of discrete pixel values from the original image. Therefore there is a need to estimate the intermediate pixel values of the transformed image using the original pixel values. An affine mapping function used to scale an image is denoted as  xsxM x x 


  5  In this section we discuss and formalize a design pattern called the Deferred Execution Pattern which is used as a basis for the design of our Scalable Image Processing Framework. The Deferred Execution Pattern is an adaptation of the Java Advanced Imaging model. We demonstrate how this design pattern is applied to our Scalable Image Processing Framework  The deferred execution pattern allows us to process pixel information only when needed, avoiding any unnecessary computations. In the design pattern, image operations are chained together where the read tile operation is declared first and the write tile operation is declared last. There can be any number of image operations chained in between the read and write operations as shown in the diagram. Pixels are not loaded until the write operation is invoked. This gives the illusion that the image operations are performed with no time \(or deferred executed\. The diagram illustrates that when the write\(\ethod is invoked the ScaleOperation requests the cropped tiles needed from CropOperation which will make a tile request to TileOperation. The TileOperation makes a request to the ReadOperation where the codestream is randomly accessed and the data needed to make the requested tile is read. This pattern allows us to process pixel information only when needed. A formal example is shown. In figure 1 we have three scalable image operations chained together such that ReadOperation CropOperation ScaleOperation  where the tiles of each operation are denoted as R i,j C i,j and S i,j respectively. In this oversimplified example the crop operations parameters are set to crop the image starting at location \(256, 256\th the width and height \(512, 512 Therefore assuming tiles of size 256 x 256 the read operation will simply read in the tiles {R 2,2 R 3,2 R 2,3 R 3,3  to complete the crop operation. The scale operations parameters are set to scale the cropped image by a factor of 1.5 on the x and y axes. Now we will describe the image operation pipeline using the notion of our deferred execution pattern. To make the first scale tile S 1,1 a request is made to retrieve the crop tiles needed. In this simple example the only crop tile needed is C 1,1 Therefore a request is made from the crop operation to read in R 2,2 The process is then repeated until the scale operation is finished One can see that S 2,2 is a slightly more expensive tile to make as the four crop tiles {C 1,1 C 2,1 C 1,2 C 2,2 are needed in the computation. Furthermore every scale tile S i,j is written to disk after being processed to maintain scalability It is also easy to see that the tiles in the operation pipeline are computed independently from one another allowing for them to be intuitively processed in parallel 4  D ESIGN AND I MPLEMENTATION  The Scalable Image Processi ng Framework uses the JPEG 2000 wavelet based standard. JPEG2000 has many advantages over the other image standards such as flexibility of the code-stream intrinsic support for tiles virtually unlimited file size, compression performance wavelet based\and support for floating point numbers [7   A feat ure t h at  i s  very i m port a nt t o us i s t h e random  code-stream access and processing. This allows us to perform operations such as rotation or scaling on random parts of the code-stream without having to read in the entire image into memory  We use the Kakadu JPEG2000 encoder and decoder software library. The Kakadu Java Native Interface allows us to make calls to the native C++ libraries. We created several supporting classes to read and write JPEG 2000 images in a scalable fashion. Kakadu is the first and only available implementation of the complete standard. The Kakadu SDK has been used in medical imaging applications, geospatial imag ing applications, and many other applications. We were tempted to use JJ2000 \(a reference implementation of the JPEG2000 codec written in Figure 1 \226 Scalable Image Operation Tiles The tiles from the three image operations in the pipeline are shown 


  6 Java\ we discovered problems with the random codestream access. Additionally, we found Kakadu to be much more efficient in regards to encoding and decoding. We plan to eventually provide support for the JPEG 2000 Interactivity Protocol \(JPIP\ich is a client-server communication protocol used to view images or parts of images in a networked environment through randomly accessing the codestream. There is currently no support for writing defined in JPIP \(part nine of the JPEG standard\or we could have used this as a basis for our scalable image processing framework  4.1 Framework Components The main components of the scalable image processing framework are the ImageTile, TiledImageData and ImageOperation classes  The ImageTile object stores the tiles pixels and the tiles coordinates \(i,j\l as the pixel coordinates [x,y wi t h  respect to the image operation The ImageTile object also has a copy of the specific ImageOperation\222s TiledImageData object and various other intrinsic attributes of the tile. This class also provides useful methods used to retrieve and copy data within the image plane. It is important to note that every image operation will create a set of tiles where the tile coordinates and pixel coordinates depend exclusively on the operation that is being performed    The TiledImageData object desc ribes the entire image to be tiled with respect to the image operation in the pipeline When an image operation is invoked a TiledImageData object is created with the appropr iate attributes such as the x, y\ are the starting coordinates and \(w, h\s the width and height of the image Therefore if a scaleOperation is invoked a TiledImageData object is created with bounds \(x, y, ws x hs y  x and s y  are the scaling factors. This also automatically updates image properties that are deri ved from the image plane such as the number of tiles in both x and y directions. The writeOperation will request a tile from the preceding image operation in the pipeline by calling the getTile\(i, j\method in the specific image operations TiledImageData object When the tile is returned it is written to disk and the process is repeated  4.2 Reading and Writing Tiles Tiles are read only when they are requested by an image operation. The read randomly accesses the codestream and decompresses the appropriate image region. The data is then stored in a tile object and sent to the requesting image operation. The tile will also be stored in the cache until it is removed with respect to the cache\222s eviction policy or used again by another operation. C onversely when a tile has been completely processed by the requesting image operations it is compressed and stored in the appropriate codestream location. The data is then written to disk. After the data is written to disk the tile is discarded  The Scalable Image Processing Framework 1  Reads in a tile only when requested by another image operation. The tile size we use is generally 256 x 256 pixels but can be set to an arbitrary size 2  Performs the appropriate image operation on the tile 3  Saves the result to the cache and the tile is sent back to the calling operation 4  If the resulting tile has no more image operations to be performed on it the tile is written to disk 5  Discards any tiles that are no longer needed 6  Repeats the process   Figure 3 \226 ImageTile object   Figure 2 \226 Ima g e tiles are an intrinsic propert y and onl y read into memor y  when they are needed by an image operation  


  7 4.3 Tiling Operation The tiling operation handles creating the tile object with the appropriate attributes. The pixels are read into the tile through the ReadOperation using the random code-stream access. The tile is then stor ed into the cache and passed back to the image operation that requested it. In the Mars photo in figure 2 the black squares represent tiles. Every tile has a set of tile coordinates that can be referenced and a set of x,y coordinates relative to the entire image.  As an example, tile T 1,2 would have starting x,y coordinates at positi and so fort h  The Scalable Image Proce ssing Framework uses Ehcache 13 to sto r e th e p r o cessed tiles so  th ey can  b e retriev ed  rapidly in the future.  We c hose to use Ehcache because it is fast, simple, scalable, supports memory/disk stores into the gigabytes, and provides dist ributed caching. Once in the cache the tiles can be repeated ly accessed inexpensively Our cache uses the Least Freque ntly Used eviction policy This algorithm keeps track of when the tiles were last used and discards them based on which ones are not used frequently. Caching speeds up things by using the notion of locality of reference; data that is near other data or has just been used is more likely to be used again. The cache is defined in the parent ImageOperation class and every tile produced by the children operations \(Tiling, Scaling Sharpening, Convolution, Rotation, Cropping, Edge Detection, \205 image operations. When an image operation is invoked through an API call a unique random number is generated We use the image operations name, tile coordinates and the random number as a key for a specific tile  4.4 Implementing Scalable Image Operations An image is read and processed in the form of tiles. These tiles are an intrinsic design component of our Scalable Image Processing Framework All implemented image operations must process the image in the form of tiles. This is often difficult, as many image operations require the neighboring tiles pixels as shown in the mathematical framework. As an example, suppose we use the bilinear operation to resize the image by half of its size. Bilinear interpolation is performed using the neighboring pixel values to estimate the resulting pixel value. To make the first bilinear tile B 1,1 the operation needs four tiles {T 1,1  T 1,2 T 2,1 T 2,2 from the original image  All scalable image operations extend the ImageOperation class that provides generic functionality for all image operations. The ImageOperation class provides functions to retrieve tiles from the cache, manage the cache, and add inputs. Image Operations can be easily added onto the existing framework in a scalable fashion  Scalable Image Operations are designed by implementing two simple methods. The first method addInput\(\205\ is invoked when the user is chaining together operations using our API. This method only needs to be modified if the image operation that you are designing will change the geometry of the image such as rotation, cropping or any scaling algorithm. The second method is performOperation\(TileX, TileY\ere it requires the image operation to be designed in a scalable manner. Every call to this method by getTile\(i, j\o be implemented in a way that processes only the tile T i,j The method Inputs.get returns the image operation in the pipeline preceding the operation to be implemented. Therefore the call to getTile\(i           Figure 4 \226 Level of detail tiling The first tile T 1,1 f rom ever y level o f detail is shown where the le f tmost tile is f rom the ori g inal ima g e. A small ima g e with onl y  f ive levels o f detail was used to demonstrate the al g orithm 


  8  j\ successfully returns the correct tile in the pipeline to be processed 5  D ISTRIBUTED AND C LOUD C OMPUTING  We are using the Amazon Elastic Cloud Computing service as well as our own machines \(at NASA JPL\o distribute the tiling and processing of images. This adds even more flexibility and scalability. The Amazon Elastic Cloud Computing is a web service that provides resizable computing capacity in the cloud. The cloud is elastic in that it can scale itself up and down in seconds depending on the needed resources of the Scalable Image Processing Framework. This provides a substantial increase in both speed and efficiency. A goal of our s is to eventually be able to process all MER \(Mars Exploration Rover\mages within a few hours. Implementing our image processing framework on the cloud is only natural as it is intrinsically scalable by the way of tiles where the tiles of a specific operation can be computed independently from one another  The Maestro Science Activity Planner delivers tiles on demand to scientists only when needed by the current viewing area of the application. The tiles are sent over the internet to scientists in all facets of the world. To support viewing images at different levels of detail the following basic level of detail tiling algorithm is implemented using our application programming interface  Let I be an n x m matrix of tiles T i,j  002  256256 x 002 I are shifted by one in the x and y directions in the image plane and written to disk. The image I is scaled by half in both the x and y axes using bilinear interpolation therefore I is an n x m matrix of tiles where n n/2 and m m/2. The process is re peated with the image I until it only contains one tile T n m as shown in figure 4  The border operation is needed for scaling the tiles at levels higher than their native resolution. Mars Rover images often need to be scaled by a fact or of two or more times to carefully target the in situ science instruments. The border operation creates a tile T i,j where each tile overlaps with its neighbor by one pixel on each si de for the interpolation to work properly without leaving artifacts when rendering the tiles in the viewer. Every tile is rendered as if it is two pixels smaller in the x and y directions  This method of tiling an image for multiple levels of detail is processed in a scalable fashion automatically with our scalable image processing framework. It is important to note that the scaling at every level of detail is incremental for both speed and the difference in quality that we noticed Assuming k levels of details \(LODs\he k level of detail refers to the level of detail from the original image Therefore if we have an image with k levels of detail the k \226 1 level of detail would need the scaled image from the k level of detail. This algorithm is used as a benchmark for our software. The images in figure 5 have been processed by our software using the level of detail tiling algorithm  These images were selected becau se they are of interest to scientists \(Future Exploration/Landing sites\e of the largest images. Th e Possible MSL Landing Surface Hazard image is 5.71GP \(1,000 times the size of a standard 6MP consumer based camera     We describe a few strategies for using distributed and cloud computing technologies to process gigapixel images using our Scalable Image Processing Framework. These strategies are described using the simple level of detail tiling algorithm for demonstration purposes. The strategies can be applied to various other problems that can be defined using our application programming interface  5.1 Processing Levels of Detail in Parallel As a first instance we could have assigned every level of detail to a machine in the cloud. Since the scaling is incremental the level of details has a dependency requiring the scaling of the k level of detail to be completed before other level of details can begin processing. The processing time of all levels of details is bounded by the amount of time it takes to complete the k level of detail. Therefore given an arbitrary level of detail we can decouple the scaling and writing of tiles to disk. This strategy provides a decent solution where only a limited amount of machines are needed  5.2 Distributing Regions of Tiles in the Cloud A set of tiles from an image operation in the operation Figure 5 \226 Opportunit y Rover Tracks at Victoria Crater 2.03GP [Gi g aPixel y 30015 : 1274.3MB Surface Hazards of Possible MSL Rover Landin g Site 5.71GP : 126021 b y 45357 : 2047.4MB\ble MSL Landing Site Mawrth Vallis \(2.29GP : 71319 b y 32248 1158.9MB\ and Possible Location of Spirit Rover in Columbia Hills \(1.17GP : 44364 by 26522 : 693MB  003 A one pixel border is created around I therefore the pixels in every tile T i,j 


  9 pipeline can be assigned to a machine in the cloud where the number of machines is constrained by the time in which we need the task completed. This assumes the time it takes to process one tile in the operation pipeline is less than the time constraint. This strategy requires a job handler that on demand assigns machines to the processing of tile regions within the image given some time constraint    In the above oversimplified example our image operation pipeline has only reading, scaling, brightness and writing operations. We are simply scaling the image down using bilinear interpolation with a factor of 0.75 in both the x and y axes and brightening the resulting image. Every tile T i,j 002  R, S, B} can be processed independently. Therefore we could assign a machine in the cl oud to every tile in the last image operation in the pipeline. In this example we would assign a machine to each of the tiles B i,j We show a diagram of the process below  The figure above shows that the tiles {B 1,1 B 2,1 205} are processed in parallel on machines in the cloud where the tiles needed from the other image operations in the operation pipeline are processed on demand and independently  This strategy can be applied to the level of detail tiling algorithm. Suppose we are performing the level of detail tiling algorithm on an arbitrary image I of size n x m tiles where k is the maximum number of levels of detail. We still have the previously defined dependency where the k \226 1 level of detail cannot begin until the k level scaling is completed. The solution is to distribute the scaling operation \(Bilinear Interpolation\ and the writing of tiles The scaling and writing operations are easily distributable since they operate on tiles and not the image itself Therefore we do not need to modify the operation or the framework. Informally we simply divide the image into regions and distribute these regions to machines on the cloud  Let R be a matrix of tiles corresponding to an image region where u, v are the coordinates of the region with respect to the image matrix denoted as I  and n r x m r are the width and height of the region, respectively. Therefore we have a new mathematical object I of regions where a region R u,v is a matrix of tiles T i,j Furthermore let c be the number of regions and consequently the initial number of machines The number of regions can be defined as a function of time  Every region in I is sent to a machine to scale the region and another machine writes the tiles in the region to disk. The more regions we have the less amount of time to process the image and consequently the more machines needed. As soon as these regions are scaled by half the next level of detail can begin writing the tiles and scaling these new regions    Only the most significant level of detail from I should be divided into regions as combinatorial problems are encountered otherwise and resources are often wasted. At a certain level of detail we must stitch together the regions to avoid the size of the region b ecoming less than the size of a tile. This depends on the number of regions defined in the image. Given enough resources it is easy to see that by using this strategy the 6 gigapixel image \(Mars Science Laboratory Landing Site Surface Hazards\be processed within seconds 6  C ONCLUSION  We have developed a Scalable Image Processing Framework capable of performing image operations on gigapixel images. A mathematical framework for the scalable image operations is defined to give insight into the  considerations needed with each class of image operations  We show how we used the Deferred Execution Pattern as a basis to design our Scalable Image Processing Framework Distributed and Cloud Computing technologies are applied Figure 6 \226 Re g ions of an ima g e are distributed and scalably processed by machines on a supercomputer  


  10 naturally with our framewo rk. The Scalable Image Processing Framework will be used to process incoming images from the Mars Exploration Rovers and eventually the Mars Science Laboratory. It will also be integrated with the Maestro software tools used to operate missions and technology concept studies for the Moon, Mars, and other celestial bodies 7  F UTURE W ORK  Image data is sometimes lost due to transmission problems when the data is sent from Mars to Earth using the Deep Space Network  Therefore an image region might be corrupt causing artifacts in the image or part of the image might even be lost. A future direction will be to explore the use of Singular Value Decomposition to automatically approximate the missing or corrupt pixel values. The error in approximation depends on the size of the region. If the region is small the approximation is likely to be very accurate. This would allow scientists to view data more accurately without obvious mistakes or artifacts  We will also explore how to integrate this framework with advanced visualization hardware such as the large multitouch display and CAVE augmented reality venues  8  A CKNOWLEDGEMENTS  The research was carried out at the Jet Propulsion Laboratory, California Ins titute of Technology, under a contract with the National Aeronautics and Space Administration and the NASA Undergraduate Research Fellowship R EFERENCES  1  Powell, M., Crockett, T., Fox, J., Joswig, C., Norris, J Shams, K., Torres, R., Deliver ing Images for Mars Rover Science Planning, IEEE Aerospace, 2008 2  Fox, J., Norris, J., Powell, M., Rabe, K., Shams, K., Advances in Distributed Operations a nd Mission Activity Planning for Mars Surface Exploration, Je t Propulsion Laboratory, 2006 3  Powell, M., Crockett, T., Fox, J., Joswig, C., Norris, J., Rabe J., McCurdy, M., Pyrzak, G., Targeting and Localization for Mars Rover Operations, IEEE Information Reuse and Integration, 2006 4  Norris, J., Powell, M., Fox, J., Rabe, J., Shu, I., Science Operations Interfaces for Mars Surface Exploration, IEEE Systems, Man, and Cybernetics, 2005 5  Norris, J., Powell, M., Vona, M., Backes, P., Wick, J., Mars Exploration Rover Operations with the Science Activity Planner, IEEE Robotics and Automation, 2005 6  McAffer, J. and Lemieux, J-M, Eclipse Rich Client Platform Designing, Coding, and Pack aging Java Applications Addison-Wesley 2005 7  Skodras, A., Christopoulos, T Ebrahimi, T., The JPEG 2000 Still Image Compression Standard, IEEE Signal Processing Magazine, 2001 8  Kopf, J., Uyttendaele, M., Deussen, O., Cohen, MF Capturing and viewing Gigapixe l images, ACM Transactions on Graphics, 2007 9  McEwen, A., Delamere, W., Eliason, E., Grant, J., Gulick, V Hansen, C., Herkenhoff, K., Keszthelyi, L., Kirk, R., Mellon M. et al., The High Resolution Imaging Science Experiment for Mars Reconnaissance Orbiter, 33 rd Lunar and Planetary Science Conference, 2002 10  Johnston, M., Graf, J., Zurek, R Eisen, H., Jai, B., The Mars Reconnaissance Orbiter Mission, IEEE Aerospace Conference, 2005 11  Gamma, E., Helm, R., Johnson R., Vlissides, J., Design patterns: elements of reusable object-oriented software Addison-Wesley 1995 12  Taubman, D., Marcellin, M., JPEG2000: Standard for Interactive Imaging, Proceedings of IEEE, 2002 13  Luck, G., Ehcache 1.5 Guide & Reference, Lulu Publishing 2008 B IOGRAPHY  Mark W. Powell is a Senior Member of Technical Staff at the Jet Propulsion Laboratory, Pasadena, CA since 2001. He received his Ph.D. in Computer Science and Engineering in 2000 from the University of South Florida, Tampa. His dissertation work was in the area of advanced illumination modeling, color and range image processing applied to robotics and medical imaging and received the award for Ou tstanding Dissertation from the University of South Florida. At JPL his area of focus is science data visualization and science planning for telerobotics. He supported the 2004 Mars Exploration Rover \(MER\ mission operations as a Science Downlink Coordinator, facilitating the timely downlink and analysis of science data from the rovers. He received the NASA Software of the Year Award for his work on the Science Activity Planner science visualization and activity planning software used for MER operations. He also received the Imager of the Year award from Advanced Imaging Magazine for his work on Maestro, the publicly available version of the Science Activity Planner for MER. Mark has been programming in Java and loving every minute of it since it was first used in web browsers in 1995. He, his wife Nina, and daughters Gwendolyn and Jacquelyn live in Tujunga, CA  Ryan A. Rossi is a research assistant in the Operations Planning Software Research group at the NASA Jet Propulsion Laboratory and will be pursuing a Ph.D. in Computer Science at Purdue University. He received three graduate fellowships for his research in machine learning and artificial intelligence. His research is supported by the National Defense Science and Engineering Graduate Fellowship, National Science Foundation Graduate Research Fellowship and the Purdue Andrews Fellowship He is sponsored by the Department of Defense and the Air  


  11 Force Research Laboratory. He has worked on research developing machine learning al gorithms for problems in security, link-analysis, search engines and bioinformatics He was previously a research assistant at University of Massachusetts Amherst, New Mexico Tech and Coastal Carolina University Khawaja Shams joined the Planning Software Systems group at the NASA Jet Propulsion Laboratory in 2005 and he has since been focused on development of OSGI-based web services to enable Maestro's rich client applications. His prior work experience includes employment at Malin Space Science Systems and the Internet Protocol Team at Nokia Mobile Phones. Khawaja earned a Master's degree in Computer Sciencetfom Cornell University, and a Bachelors degree in Computer Science from University of Califo rnia, San Diego. Khawajaes current research interests include browser-based telemetry monitoring systems for robotics, peer-to-peer systems, and RESTful web based services 


B IO GRAPHY  Aleksandr Ser geyev is currently an Assistant Professor in the Electrical Engineering Technology program in the School of Technology at Michigan Technological University Dr Aleksandr Sergeyev is earned his bachelor degree in electrical engineering in Moscow University of Electronics and Automation in 1995  He obtained the Master degree in Physics from Michigan Technological University in 2004 and the PhD degree in Electrical Engineering from Michigan Technological University in 2007  Dr Aleksandr Sergeyev research interests include high energy lasers propagation through the turbulent atmosphere developing advanced control algorithms for wavefront sensing and mitigating effects of the turbulent atmosphere digital inline holography digital signal processing and laser spectroscopy He is also involved in developing new eye-tracking experimental techniques for extracting 3-D shape of the object from the movement of human eyes Michael Roggemann is a Professor of Electrical Engineering at Michigan Technological University Houghton MI He is co-author of the book Imaging Through Turbulence and has authored or co-authored over 60 journal articles and over 50 conference papers Dr Roggemann is a member of the IEEE and is a Fellow of both the Optical Society of America and SPIE The International Society for Optical Engineering He was also brie\003y af\002liated with the Boeing Corporation where he served as a senior research scientist from 2002 to 2005  and was a Technical Fellow of the Boeing Corporation Dr Roggemann was an Associate Professor of Engineering Physics at the Air Force Institute of Technology WrightPatterson AFB Ohio from 1992 to 1997  He is an honorably retired Air Force Of\002cer at the rank of Major Dr Roggemann performed his undergraduate work at Iowa University graduating in 1982 with the BSEE degree He performed graduate work at the Air Force Institute of Technology completing the MSEE degree in 1983  and the Ph.D in 1989  Dr Roggemann has been an electro-optics program manager at Wright Laboratories Wright-Patterson AFB Ohio and an imaging researcher at the Phillips Laboratory Kirtland AFB NM His present research interests include imaging and beam projection through atmospheric turbulence optical remote sensing system design and analysis and signal and image processing Casey Demars is a senior Electrical Engineering undergraduate at Michigan Technological University He has developed under the Photonic's concentration and has worked in the CISSIC group since 2008  He is currently the Vice President of MTU's student chapter of SPIE His interests include atmospheric turbulence and signal processing 12 


   13  Data Exchange Specified by Schema  Data exchanges could be XML documents or APIs   Scenario Elements Initialization  Spacecrafts: Names & Orbits      - Imaging Payloads: Names & Patterns Feature of Interests: Names, Types, Boundaries & Viewing Constraints Geostationary Relay Satellites: Names and Longitudes Ground Stations: Names & Locations Scenario Start & Stop Times Feature Coverage Request  Feature of Interest Name Spacecraft & Payload Names Figure of Merit Request Feature Coverage Response  Coverage by Area and by Percent Min, Max & Average Response Time Min, Max & Average Revisit Time Coverage by Time Interval Accessibility Chain Request  Scenario Elements Accessibility Chain Response  Accessibility Interval Start & Stop Times  SysML Model Interface Prototype  Setup System Elements Determine Accessibility Determine Feature Coverage  Interface Prototype to AGI Components   Scenario Elements Cache  AGI Components  Cache Interface  Components Interface  Data Exchange  Scenario Elements Accessibility Request / Response Feature Coverage Request / Response Figure 8. Prototype Data Exchange Between FireSat SysML Model and AGI Components The data exchange will be enhanced to meet user needs 
 


   14 The schema has been defined for the FireSat SysML and AGI Components interaction of Figure 8.  The Setup System Elements and Determine Feature Coverage capabilities have been prototyped.  The next step is to prototype all the capabilities as both API and XML document interfaces 8  C ONCLUSIONS  An SPS providing a COTS GetFeasibility operation will make it easier for Users to discover sensors that fulfill their needs.  A COTS common inte rface will provide the User with one well-known set of operations for the initial discovery of candidate sensors A final selection of sensors can be carried out using the SPS operations of the individual DPs Additionally, an SPS server c ontaining a catalog of sensors can be created to provide the Users with one-stop-shopping for the initial discovery of candidate sensors The operations being developed now are for optical and radar sensors, but are extensible to Earth observation scientific sensors The design and implementation of the Magic Draw and ParaMagic FireSat SysML model interaction with AGI Components will be refined a nd then extended to other SysML tools The FireSat SysML model interaction with AGI Components proof of concept is also intended to provide the blueprint for the design and implementation of other types of SysML modeling of space based missions R EFERENCES   Docum e nt 07-014r3 at  http://www.opengeospatial.org   M a nas B a jaj, \223SLIM A C o l l a borat i v e, M odel B a sed Systems Engineering Work space for Next-Generation Complex System\224, 2011 IEEE Aerospace Applications Conference Proceedings, March 5-12, 2011 B IOGRAPHY  Dave Kaslow is Director, Product Data Management at Analytical Graphics, Inc.  He has thirty-seven years of experience in both the technical and management aspects of developing ground mi ssion capabilities He is also the editor of Spacecraft Digest www.stk.com/scdigest which tracks current and future spacecraft and spacecraft missions He is co-author of \223Defining and Developing the Mission Operations System\224, \223Activity Planning\224, \223FireSat\224 and 223Spacecraft Failures and Anomalies\224 in Cost-Effective Space Mission Operations He is also the author and co-author of papers for the International Council on Systems Engineering \(INCOSE Annual International Symposiums and for the IEEE Aerospace Conference A CKNOWLEDGEMENTS  The author gratefully acknowledges the prototyping support of colleague Sam Gilbert  
 


Eds Amsterdam: North Holland, 1997 19]  Kiger, J.I. "The Depth/Breadth Tradeoff in the Design of Menu-Driven Interfaces," International Journal of Man-Machine Studies \(20 20]   Miller, D.P. "The Depth/Breadth Tradeoff in Hierarchical Computer Menus," Human Factors Society 1981, pp. 296-300 21]  Newman, W. M. and Lamming, M. G., Interactive system design, Cambridge, MA, Addison-Wesley, 1995 22]  Nielsen, J. "Usability Engineering at a Discount International Conference on Human-Computer Interaction Elsevier Science, Boston, 1989, pp. 394-401 23]  Nielsen, J. Usability Engineering, Acad. Press, 1993  24]  Nielsen, J., ?Heuristic evaluation,? in J. Nielsen and R. Mack \(eds Wiley &amp; Sons, 1994  25]  Nielsen, J., ?Usability metrics:  Tracking interface improvements,? IEEE Software, Nov 1996, pp. 12-13 26]  Nielsen J www.useit.com/papers/heuristic/heuristic_list.html, 2002 27]  Nielsen, J. and Mack, R., Usability inspection methods, John Wiley &amp; Sons, Inc., 1994 28]  Niemela, M., and Saariluoma, P. "Layout Attributes and Recall," Behaviour &amp; Information Technology \(22:5 2003, pp 353-363 29]  Norman, K.L. The Psychology of Menu Selection Ablex Publishing Corporation, Norwood, NJ, 1991 30]  Norman, K.L., and Chin, J. "The Effect of Tree Structures on Search in a Hierarchical Menu Selection System," Behavior &amp; Information Technology \(7 51-65 31]  Perlman, G. http://edgarmatias.com/faq/G/G-1.html 2000 32]  Reiterer, H.,  Oppermann, R. Evaluation of User Interfaces: EVADIS II -- A Comprehensive Evaluation Approach. In Behaviour and Information Technology, 12 3 33]  Schenkman, B.N., and Jonsson, F.U. "Aesthetics and Preferences of Web Pages," Behavior &amp; Information Technology \(19:5 34]  Shackel, B., ?Usability ? context, framework definition, design and evaluation,? in Human Factors for Informatics Usability, edited by Shackel, B. and Richardson, S. J., Cambridge:  Cambridge University Press 1991, pp. 21-38 35]  Shneiderman, B., "Designing trust into online experiences,? Communications of the ACM, December 2000, pp. 57- 59  36]  Shneiderman, Ben, Designing the User Interface Strategies for Effective Human-Computer Interaction Reading, Mass., Addison-Wesley, 1986, 1987c 37]  Somberg, B.L. "A Comparison of Rule-Based and Positionally Constant Arrangements of Computer Menu Items," CHI and GI 1987, ACM, New York, New York 1987, pp. 255-260 38]  Vredenburg, K., et. al "A Survey of User-Centered Design Practice," SIGCHI Conference on Human Factors in Computing Systems, ACM, Minneapolis, Minnesota 2002, pp. 471-478 39]  Weiss, E., and Nielsen, J. "Heuristic evaluation, a system checklist, usability analysis &amp; design," Xerox Corporation 40]  Wharton, C., et. al,  ?The cognitive walkthrough method:  A practitioner?s guide,? in Nielsen, J., Mack, R Usability Inspection Methods, John Wiley &amp; Sons, 1994 41]  Whitefield, A., Wilson, F., and Dowell, J. "A Framewokr for Human Factors Evaluation," Behavior &amp Information Technology \(10:1 


42] Yu, B.-M., and Roh, S.-Z. "The Effects of Menu Design on Information-Seeking Performance and User's Attitude on the World Wide Web," Journal of the American Society for Information Science and Technology \(53:11 2002, pp 923-933 43]Zaphiris, P., and Mtei, L. "Depth vs. Breadth in the Arrangement of Web Links," 1997, p. Available online http://otal.umd.edu/SHORE/bs04 44]  Zaphiris, P., Shneiderman, B., and Norman, K.L Expandable Indexes vs. Sequential Menus for Searching Heirarchies on the World Wide Web," Behavior &amp Information Technology \(21:3 Proceedings of the 42nd Hawaii International Conference on System Sciences - 2009 10 pre></body></html 


and Improving IT Governance through the Balanced Scorecard", Information Systems Control Journal, 2 70] Van Grembergen, W., De Haes, S., and Guldentops E., "Structures, Processes and Relational Mechanisms for IT Governance" in: Van Grembergen, W. \(Ed for Information Technology Governance,  Idea Group Publishing, 2004, 1-37 71] Wagner, H.-T., A resource-based perspective on IT business alignment and firm performance - Theoretical foundation and empirical evidence, ibidem, Stuttgart, Germany, 2007 72] Wagner, H.-T. and Weitzel, T., "IT Business Alignment as Governance Tool for Firm-Internal Relationship Quality: A Longitudinal Case Study",  41th Hawaii International Conference on System Sciences \(HICSS-41 Island, Hawaii, 2008 73] Webb, P., Pollard, C., and Ridley, G., "Attempting to Define IT Governance: Wisdom or Folly?",  39th Hawaii International Conference on System Sciences, Kauai, Hawaii, 2006 74] Zahra, S.A. and George, G., "The Net-Enabled Business Innovation Cycle and the Evolution of Dynamic Capabilities", Information Systems Research, 13\(2 147-150 75] Zmud, R.W., "Building relationships throughout the corporate entity" in: Elam, J., Ginzberg, M., Keen, P., and Zmud, R.W. \(Eds mission, the framework, the transition,  1988, Washington 1988, 55-82   Appendix  Table 5. Used indicators All items have been evaluated by using a 5-point Likert scale ranging from ?strongly agree? to  strongly disagree ID Item References Executive support \(ES ES1 The IT unit is sufficiently represented in our bank  s executive board. [18 ES2 Top management actively supports interplay between business and IT Strategic Alignment \(SA SA1 I am familiar with the IT strategy. [55 SA2 The IT strategy is accurately aligned with the business strategy. [22, 54, 55, 63 SA3 The IT strategy is documented. [17, 54 Governance Mechanisms \(GM GM1 There are explicit incentives rewarding good interaction with the IT unit. [51 GM2 The back office is proactively involved into IT planning. [17, 26, 55 GM3 There is a specific organizational unit or function to improve the communication be-tween  the IT and the back office 17, 26 Operational Alignment \(OA OA1 There is mutual trust and respect between IT unit and the back office. [13, 46, 64 OA2 IT and the back office regularly consult each other. [13, 17, 19 OA3 There are meetings on a regular basis between IT and back office for identifying business process improvements 17, 26, 55  OA4 There is extensive communication between IT unit and back office. [15, 17, 26 OA5 IT employees are able to interpret business related problems and develop solutions. [13, 60  64 Process Performance \(PP PP1 The configuration of our credit process allows us to sustain a competitive advantage in the  relevant market 36 PP2 The configuration of our credit process allows us to differentiate us from the competi-tors  in the relevant market 36, 42 PP3 Compared to our competitors, the operational efficiency of our loans process is higher. [23  27 PP4 Compared to our competitors, the design of our business loans process is ? \(much better 1  


PP4 Compared to our competitors, the design of our business loans process is ? \(much better 1  5 much worse 71 Proceedings of the 42nd Hawaii International Conference on System Sciences - 2009 11 pre></body></html 


The HyspIRI mission utilizes innovative techniques to both reduce the amount of data that must be transmitted to the ground and accommodate the required data volume on the ground The infrastructure and techniques developed by this mission will open the door to future high data volume science missions The designs presented here are the work of the authors and may differ from the current HyspIRI mission baseline A CKNOWLEDGMENTS This research was carried out at the Jet Propulsion Laboratory California Institute of Technology and was sponsored by the Space Grant program and the National Aeronautics and Space Administration R EFERENCES  K W ar\002eld T  V  Houten C Hee g V  Smith S Mobasser B Cox Y He R Jolly C Baker S Barry K Klassen A Nash M Vick S Kondos M Wallace J Wertz Chen R Cowley W Smythe S Klein L Cin-Young D Morabito M Pugh and R Miyake 223Hyspiri-tir mission study 2007-07 002nal report internal jpl document,\224 TeamX 923 Jet Propulsion Laboratory California Institute of Technology 4800 Oak Grove Drive Pasadena CA 91109 July 2007  R O Green 223Hyspiri summer 2008 o v ervie w  224 2008 Information exchanged during presentation  S Hook 2008 Information e xchanged during meeting discussion July 16th  R O Green 223Measuring the earth wi th imaging spectroscopy,\224 2008  223Moore s la w Made real by intel inno v ation 224 http://www.intel.com/technology/mooreslaw/index.htm  T  Doggett R Greele y  S Chein R Castano and B Cichy 223Autonomous detection of cryospheric change with hyperion on-board earth observing-1,\224 Remote Sensing of Environment  vol 101 pp 447\226462 2006  R Castano D Mazzoni N T ang and T  Dogget 223Learning classi\002ers for science event detection in remote sensing imagery,\224 in Proceedings of the ISAIRAS 2005 Conference  2005  S Shif fman 223Cloud detection from satellite imagery A comparison of expert-generated and autmatically-generated decision trees.\224 ti.arc.nasa.gov/m/pub/917/0917 Shiffman  M Griggin H Burk e D Mandl and J Miller  223Cloud cover detection algorithm for eo-1 hyperion imagery,\224 Geoscience and Remote Sensing Symposium 2003 IGARSS 03 Proceedings 2003 IEEE International  vol 1 pp 86\22689 July 2003  V  V apnik Advances in Kernel Methods Support Vector Learning  MIT Press 1999  C Bur ges 223 A tutorial on support v ector machines for pattern recognition,\224 Data Mining and Knowledge Discovery  vol 2 pp 121\226167 1998  M Klemish 223F ast lossless compression of multispectral imagery internal jpl document,\224 October 2007  F  Rizzo 223Lo w-comple xity lossless compression of h yperspectral imagery via linear prediction,\224 p 2 IEEE Signal Processing Letters IEEE 2005  R Roosta 223Nasa jpl Nasa electronic parts and packaging program.\224 http://nepp.nasa.gov/docuploads/3C8F70A32452-4336-B70CDF1C1B08F805/JPL%20RadTolerant%20FPGAs%20for%20Space%20Applications.pdf December 2004  I Xilinx 223Xilinx  Radiation-hardened virtex-4 qpro-v family overview.\224 http://www.xilinx.com/support/documentation data sheets/ds653.pdf March 2008  G S F  Center  223Tdrss o v ervie w  224 http://msp.gsfc.nasa.gov/tdrss/oview.html 7  H Hemmati 07 2008 Information e xchanged during meeting about LaserComm  223W orldvie w-1 224 http://www digitalglobe.com/inde x.php 86/WorldView-1 2008  223Sv albard ground station nor way.\224 http://www.aerospacetechnology.com/projects/svalbard 7 2008  223Satellite tracking ground station 224 http://www.asf.alaska.edu/stgs 2008  R Flaherty  223Sn/gn systems o v ervie w  224 tech rep Goddard Space Flight Center NASA 7 2002  223Geoe ye-1 f act sheet 224 http://launch.geoeye.com/launchsite/about/fact sheet.aspx 2008  L-3 Communications/Cincinnati Electronics Space Electronics 7500 Innovation Way Mason OH 45040 T-720 Transmitter  5 2007 PDF Spec Sheet for the T720 Ku-Band TDRSS Transmitter  L-3 Communications/Cincinnati Electronics Space Electronics 7500 Innovation Way Mason OH 45040 T-722 X-Band  7 2007 PDF Spec Sheet for the T-722  J Smith 07 2008 Information e xchanged during meeting about GDS  J Carpena-Nunez L Graham C Hartzell D Racek T Tao and C Taylor 223End-to-end data system design for hyspiri mission.\224 Jet Propulsion Laboratory Education Of\002ce 2008  J Behnk e T  W atts B K obler  D Lo we S F ox and R Meyer 223Eosdis petabyte archives Tenth anniversary,\224 Mass Storage Systems and Technologies 2005 Proceedings 22nd IEEE  13th NASA Goddard Conference on  pp 81\22693 April 2005 19 


 M Esf andiari H Ramapriyan J Behnk e and E So\002nowski 223Evolving a ten year old data system,\224 Space Mission Challenges for Information Technology 2006 SMC-IT 2006 Second IEEE International Conference on  pp 8 pp.\226 July 2006  S Marle y  M Moore and B Clark 223Building costeffective remote data storage capabilities for nasa's eosdis,\224 Mass Storage Systems and Technologies 2003 MSST 2003 Proceedings 20th IEEE/11th NASA Goddard Conference on  pp 28\22639 April 2003  223Earth science data and information system esdis project.\224 http://esdis.eosdis.nasa.gov/index.html  M Esf andiari H Ramapriyan J Behnk e and E So\002nowski 223Evolution of the earth observing system eos data and information system eosdis\\224 Geoscience and Remote Sensing Symposium 2006 IGARSS 2006 IEEE International Conference on  pp 309\226312 31 2006Aug 4 2006  223Earth science mission operations esmo 224 http://eos.gsfc.nasa.gov/esmo  E Masuoka and M T eague 223Science in v estig ator led global processing for the modis instrument,\224 Geoscience and Remote Sensing Symposium 2001 IGARSS 01 IEEE 2001 International  vol 1 pp 384\226386 vol.1 2001  M Esf andiari H Ramapriyan J Behnk e and E So\002nowski 223Earth observing system eos data and information system eosdis 227 evolution update and future,\224 Geoscience and Remote Sensing Symposium 2007 IGARSS 2007 IEEE International  pp 4005\2264008 July 2007  D McAdam 223The e v olving role of tape in the data center,\224 The Clipper Group Explorer  December 2006  223Sun microsystems announces w orld s 002rst one terabyte tape storage drive.\224 http://www.sun.com/aboutsun/pr/200807/sun\003ash.20080714.2.xml July 2008  223P anasas 227 welcome 224 http://www panasas.com  R Domikis J Douglas and L Bisson 223Impacts of data format variability on environmental visual analysis systems.\224 http://ams.confex.com/ams/pdfpapers/119728.pdf  223Wh y did nasa choose hdf-eos as the format for data products from the earth observing system eos instruments?.\224 http://hdfeos.net/reference/Info docs/SESDA docs/NASA chooses HDFEOS.php July 2001  R E Ullman 223Status and plans for hdfeos nasa's format for eos standard products.\224 http://www.hdfeos.net/hdfeos status HDFEOSStatus.htm July 2001  223Hdf esdis project.\224 http://hdf.ncsa.uiuc.edu/projects/esdis/index.html August 2007  223W elcome to the ogc website 224 http://www.opengeospatial.org 2008  223Open gis Gis lounge geographic information systems.\224 http://gislounge.com/open-gis Christine M Hartzell received her B.S in Aerospace Engineering for Georgia Institute of Technology with Highest Honors in 2008 She is currently a PhD student at the University of Colorado at Boulder where she is researching the impact of solar radiation pressure on the dynamics of dust around asteroids She has spent two summers working at JPL on the data handling system for the HyspIRI mission with particular emphasis on the cloud detection algorithm development and instrument design Jennifer Carpena-Nunez received her B.S in physics in 2008 from the University of Puerto Rico where she is currently a PhD student in Chemical Physics Her research involves 002eld emission studies of nanostructures and she is currently developing a 002eld emission setup for further studies on nano\002eld emitters The summer of 2008 she worked at JPL on the HyspIRI mission There she was responsible for the science analysis of the data handling system speci\002cally de\002ning the data level and processing and determining potential mission collaborations Lindley C Graham is currently a junior at the Massachusetts Institute of Technology where she is working towards a B.S in Aerospace Engineering She spent last summer working at JPL on the data handling system for the HyspIRI mission focusing on developing a data storage and distribution strategy 20 


David M Racek is a senior working toward a B.S in Computer Engineering at Montana State University He works in the Montana State Space Science and Engineering Laboratory where he specializes in particle detector instruments and circuits He spent last summer working at JPL on compression algorithms for the HyspIRI mission Tony S Tao is currently a junior honor student at the Pennsylvania State University working towards a B.S in Aerospace Engineering and a Space Systems Engineering Certi\002cation Tony works in the PSU Student Space Programs Laboratory as the project manager of the OSIRIS Cube Satellite and as a systems engineer on the NittanySat nanosatellite both of which aim to study the ionosphere During his work at JPL in the summer of 2008 Tony worked on the communication and broadcast system of the HyspIRI satellite as well as a prototype Google Earth module for science product distribution Christianna E Taylor received her B.S from Boston University in 2005 and her M.S at Georgia Institute of Technology in 2008 She is currently pursing her PhD at the Georgia Institute of Technology and plans to pursue her MBA and Public Policy Certi\002cate in the near future She worked on the ground station selection for the HyspIRI mission during the summer of 2008 and looks forward to working at JPL in the coming year as a NASA GSRP fellow Hannah R Goldberg received her M.S.E.E and B.S.E from the Department of Electrical Engineering and Computer Science at the University of Michigan in 2004 and 2003 respectively She has been employed at the Jet Propulsion Laboratory California Institute of Technology since 2004 as a member of the technical staff in the Precision Motion Control and Celestial Sensors group Her research interests include the development of nano-class spacecraft and microsystems Charles D Norton is a Principal Member of Technical Staff at the Jet Propulsion Laboratory California Institute of Technology He received his Ph.D in Computer Science from Rensselaer and his B.S.E in Electrical Engineering and Computer Science from Princeton University Prior to joining JPL he was a National Research Council resident scientist His work covers advanced scienti\002c software for Earth and space science modeling with an emphasis on high performance computing and 002nite element adaptive methods Additionally he is leading efforts in development of smart payload instrument concepts He has given 32 national and international keynote/invited talks published in numerous journals conference proceedings and book chapters He is a member of the editorial board of the journal Scienti\002c Programming the IEEE Technical Committee on Scalable Computing a Senior Member of IEEE recipient of the JPL Lew Allen Award and a NASA Exceptional Service Medal 21 


this paper, we only generate the size-2 patterns in the BFS phase. It will be interesting to investigate the impact on the performance if the ?rst phase is stopped at a deeper level Also, the projection is a very ef?cient method for ?nding patterns, especially for parallel implementation of pattern mining algorithms [1]. We plan to adapt the projection ideas into our algorithm and design an ef?cient parallel algorithm for mining maximal hyperclique patterns References 1] R. Agarwal, C. Aggarwal, and V. Prasad. A Tree Projection Algorithm For Generation of Frequent Itemsets. pages 350 371, Feb 2001 2] R. Agrawal, T. Imielinski, and A. Swami. Mining Association Rules between Sets of Items in Large Databases. In Proc. of the ACM SIGMOD Conference on Management of Data, pages 207216,May 1993 3] R. Agrawal and R. Srikant. Fast Algorithms for Mining Association Rules. In Proc. of the 20th Intl Conference on Very LargeData Bases, 1994 4] R. Bayardo. Ef?ciently mining long patterns from databases In Proc. of the ACM SIGMOD Conference, 1998 5] R. Bayardo and R. Agrawal. Mining the Most Interesting Rules. In Proc. of the ACM SIGKDD Conference, 1999 6] D. Burdick, M. Calimlim, and J. Gehrke. Ma?a: AMaximal Frequent Itemset Algorithm for Transactional Databases. In Proc. of IEEE Conf. on Data Engineering, 2001 7] Y. Huang, H. Xiong, W. Wu, and Z. Zhang. A Hybrid Approach for Mining Maximal Hyperclique Patterns. In In Technical Report UTDCS-34-04, Department of computer science, University of Texas - Dallas, 2004 8] J.Han, J.Pei, and Y. Yin. Mining Frequent Patterns without Candidate Generation. In Proc. of the ACM SIGMOD International Conference on Management of Data, 2000 9] M.J.Zaki and C.Hsiao. ChARM: An ef?cient algorithm for closed itemset mining. In Proc. of 2nd SIAM International Conference on Data Mining, 2002 10] R.Rymon. Search through Systematic Set Enumeration. In Proc. Third Intl Conference on Principles of Knowledge Representation and Reasoning, 1992 11] H. Xiong, M. Steinbach, P.-N. Tan, and V. Kumar. HICAP: Hierarchial Clustering with Pattern Preservation. In Proc. of 2004 SIAM International Conference on Data Mining \(SDM 12] H. Xiong, P.-N. Tan, and V. Kumar. Mining Strong Af?nity Association Patterns in Data Set with Skewed Support. In Proc. of the Third IEEE International Conference on Data Mining \(ICDM Proceedings of the 16th IEEE International Conference on Tools with Artificial Intelligence \(ICTAI 2004 1082-3409/04 $20.00  2004 IEEE 





