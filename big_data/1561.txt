Group Based Epidemic Routing for Delay and Tolerant networks  Ruitao Zhou, Yuanda Cao, Jun Jin, Dongfeng Zhu Beijing Laboratory of Intelligent Information Technology School of Computer Science, Beijing Institute of Technology Beijing, China zrt@bit.edu.cn, ydcao@bit.edu.cn, flea.miss@gmail.com, heartzdf@163.com  Abstract 227Delay and Tolerant Networks \(DTNs\ have been proposed to address data communication challenges in network scenarios, where no instantaneous end-to-end path is guaranteed because of frequent and long duration network partitions Typical protocols forward a message to multiple nodes to 
improve message delivery rate. However, a large number of replications consume many system resources that are quite limited in such scenarios. Group Based Epidemic Routing \(GEpidemic\proposed in this paper to reduce the number of replications by limiting the range of message \223infection\224 of Epidemic. Nodes are divided into different groups, and the 223epidemic\224 only happens within certain groups. Simulation results show that G-Epidemic performs better than both Epidemic and PROPHET in the community scenario. It is able to deliver more messages, but the amount of replications drops in a big degree Keywords: DTN; Group based ro 
uting; probabilistic routing I   I NTRODUCTION  Delay and Tolerant Networks \(DTNs\ [1 i s a  ki n d o f  network focused on architectures and protocols that can operate in challenging network environments. There are often extremely limited resources including buffer size, network capacity, and power in such environments. Specifically there is no guarantee of instantaneous end-to-end path between the source and destination. Finding a path from a source to some destinations is one of the core functions in DTNs. However traditional protocols assume that there exits an end-to-end path 
between communicating nodes. When disconnections are detected, the protocols try to find an alternate path to replace the previous one. Thus, traditional techniques, including MANET routing protocols such as AODV [2 nd D S R [3  are not fit for handling frequent and arbitrarily long-period connectivity disruptions In DTNs, routing is performed over time to achieve final delivery by employing a store-and-forward strategy at intermediate nodes. Most protocols replicate the messages to several paths to increase the probabilities of successful delivery. That is, a node stores messages in its buffer, and replicates them to other nodes when it encounters them. The 
routing protocols are mainly classified into three classes  5   1\ flooding-based, 2\ history-based, and 3\ direct delivery protocols Flooding based routing protocols, such as Epidemic [6 7   are the first proposed to reliably deliver messages in intermittently connected networks. Each node forwards replications of the messages in its buffer whenever it meets with other nodes. History based protocols, such as PROPHET 8 t r y t o  r e d u c e t h e numb e r  o f  r e p l i c a t i o ns T h e y onl y forward the replications to the nodes with higher probabilities to encounter the destinations. In direct delivery routing protocols  n o re pl i c a t i o n i s  p e r f or m e d   a nd t h e s o u r c e n od e  
only delivers the messages to the destination nodes directly Hence, there is no replication in the network, but it is not guaranteed that a source node encounters the destinations Due to node mobility, it is necessary to keep proper amount of message replications to increase the probabilities of successful deliver. But too many replications will compete for the limited resources with the valid messages. In this proposal Group Based Epidemic Routing \(G-Epidemic\ is developed to reduce the number of message replications by limiting the range of message exchanging The rest of this paper is organized as follows: Section II reviews some related work. Our proposed G-Epidemic 
protocol is described in Section III. Section IV presents the evaluation environment, followed by performance evaluation results in Section V. Finally some concluding remarks with future work are given in Section VI II  R ELATED WORK  We are interested in Epidemic routing protocol, which can operate in various environments with different node mobility models. Generally, Epidemic can achieve better delivery ratio and shorter delay than other protocols, but with a heavy system overload because of redundant replications of original messages. In order to avoid the shortcomings of Epidemic PROPHET was proposed to select the next hop nodes using 
the history of encounters. In this paper, we use Epidemic and PROPHET routing protocols for performance comparison with G-Epidemic A  Epidemic Routing Epidemic routing extends the concept of flooding. Each node buffers messages and maintains a summary vector of them. When two nodes meet, they exchange the summary vectors. After the exchange, each node can determine whether 978-1-4244-3709-2/10/$25.00 \2512010 IEEE 


the other node has some messages it hasnt seen previously. In that case, it will send a request for the messages. In such a way the message will spread through the network like an epidemic If there are enough buffers, each node will finally have a copy of the original message To limit the utilization of resources, a hop-count field is set in each message. The hop-count will decrease by one at each forward. A message with a hop-count of one can only be delivered to the destination node. For example, node A has a message with a hop-count of n. when A encounters B, A will forward a copy of the message with a hop-count of n-1 to B The authors have shown that by selecting a proper maximum hop-count, Epidemic can achieve a high delivery ratio with lower resource utilization in the scenarios used in their evaluation [6  B  PROPHET Routing The concept of PROPEHT is that if two nodes encountered frequently in the past, there is a high probability for them to meet again in the future. Contact history is used to calculate the predictability of the encounter between two nodes. The predictability is defined as follows \(A and B represents two nodes P A,B P A,B 1- P A,B P init 1  Where P init  is a initialization constant between 0 and 1, and P A,B\d is the value of P A,B before the current update. We can learn from \(1\ that the more frequently A and B encounters the higher the predictability will be. Beside the direct contact the transitivity principle is used to calculate the predictability of a relay node P A,C P A,C 1- P A,C P A,B P B,C   2   is a non-zero constant between 0 and 1 that represents the prediction weight. The credibility will drop due to iterative calculations without relay nodes information. Hence, aging procedure is adopted to adjust the predictability P A,B P A,B  k  3 Where is aging constant between 0 and 1, and k is the number of time units that have elapsed since last aging time III  G ROUP B ASED E PIDEMIC R OUTING  It is quite often difficult to acquire the mobility pattern of DTN environment. Although Random Waypoint mobility model is commonly used for evaluating ad hoc and DTN protocols, it is not likely that nodes move in a completely random way in realistic scenarios. There are so many cases that the mobility of nodes has some potential regularity. Some nodes contact with each other more often than others just like the circle of friends. One can easily get in touch with anyone of the circle with the help of other members. We would like to make use of the power of the circle for routing in DTNs. We use the following definitions   Friend If node A encounters node B frequently, A and B are friends. If nodes A and B are friends, B and C are friends, and then A and C are also friends   Group Given a set of nodes Z, Z is a group if and only if any two nodes of Z are friends We can learn from above that, in a group there is a high probability for a node to deliver a message to another one with the aid of relay of their friends. Fig. 1 shows three groups of nodes, represented by Region I, II and III. Nodes within the same group connect with one another through dashed line Node A wants to send a message m to F. In Epidemic protocol m will be forwarded to B and C soon after its creation, and when B, carrying m, meets with D and H, it will forward m to both of them. Then, m will be delivered to F within Region II in the near future, but m will still be propagating in Region III Thus, the copies of m in Region III will consume extra system resources. The situation will be better in PROPHET. A will forward m to the nodes that have higher probabilities to deliver the message. So D, E and F are candidates for the next hop However, perhaps it will take a long period of time for A to meet with those nodes, if B does not have a higher probability than A for the delivery We propose Group Based Epidemic Routing \(G-Epidemic to take advantage of the group information. If a node has a message to deliver, it will get help from all its friends. Copies of the message will propagate to all the nodes of the same group by the means of Epidemic. If anyone of them encounters a node that is in the same group with the destination of the message, it will forward the message to that node. Then the message will be delivered to the destination within that group by the way of Epidemic From above, the forwarding strategy of G-Epidemic is as follows: when two nodes meet they exchange the summary vectors and group information. After this exchange, each node can determine whether there are some messages that the other node doesnt keep in its buffer. If the two nodes are in the same group, they exchange all the messages that the other node doesnt have at the movement. Otherwise, they check the messages and forward the ones, the destinations of which are in the same group with the other node   Re gi on I I I Regi on I A C B E F H G I D Regi on I I m Fig. 1 Three groups of nodes 


The operation of G-Epidemic relies on the group information. We can initialize the groups when distributing the DTN nodes, the groups can also be set up dynamically at runtime. For example, we can use the PROPHET protocol to calculate the probabilities of contacts. Nodes with high probabilities to encounter in the future will be set in the same group. In the evaluations in this paper, we have chosen a rather simple grouping strategy-if two nodes have high probabilities to appear in the same area, they are in the same group IV  S IMULATION S ETUP  It is vital that the models used in evaluation are realistic since the protocols choose the next hop depending on the mobility of nodes. Random Waypoint mobility model \(RW  ha s  b e e n co mm o n l y use d for e v a l ua t i ng ad h o c a n d D T N  routing protocols. In this model, nodes randomly choose a speed and a destination, move there, wait for a random period of time, and then continue the cycle. RW is an ideal model. In realistic scenarios, nodes do not move completely randomly Thus, we adopt a scenario, which is similar to the one used in PROPHET, called community model to better reflect the reality The scenario consists of a 3000 * 1500 m area as shown in Fig. 2. The area is divided into 12 subareas C1-C12, standing for 12 communities. Each node has one home community that is more likely to visit than other places. There are five nodes randomly placed in each community. The mobility in this scenario is that nodes select a destination and a speed between 5 and 20 m/s, move there, wait for a period time of 0120 seconds, and then select next destination. The destination selection strategy is that there is always a high probability for a node to choose a destination at its home community. Table 1 shows the probabilities of different destinations being chosen depending on the current location of a node The traffic in this scenario is that every 25-35 seconds two nodes are randomly selected, and one of them create a message with another as destination. The whole simulation lasts for 12 hours. At the start of the simulation before message generation there is a warm up period of 1000 seconds to initialize the environment  TABLE 1. Destination selection probabilities FROM \\ TO HOME ELSEWHERE HOME 0.7 0.3 ELSEWHERE 0.9 0.1 To investigate the performance improvement of GEpidemic, a simulation environment is developed using Opportunistic Network Environment simulator. In our evaluation of G-Epidemic, we have focused on the following metrics: First of all, we are interested in message delivery ratio  i.e. how many messages the protocol is able to deliver to their destinations. Secondly average delivery delay is introduced to measure how long the protocol will take to deliver a message That is the average time from creation of a message to its successful delivery. Finally, it is still of interest to consider the utilization of limited resource in DTN environment Overhead ratio  y is taken to reflect this respect, which is expressed as  y = \(N r N d N d 4 Where N r is the total number of relayed messages in the simulation, and N d is the number of delivered messages V  R ESULTS  In this section, we demonstrate the advantage of GEpidemic by simulations.  The parameters in each run of the simulations are the same except for the buffer size of the nodes The maximum hop-count of the message is set to 11. Such a bigger value will help to broadcast messages widely within the group. The communication rang is 20 m and 50 m. Each graph below contains three curves for G-Epidemic, Epidemic and PROPHET. On the x-axis is the buffer size of the nodes Fig. 3 shows the message delivery rate over different buffer sizes. It is easy to see that as the buffer size increases, so does the number of messages delivered to the destinations for all the three protocols. That is because bigger buffer size means more messages can be buffered, and the risk of dropping messages decreases. It is intuitive that G-Epidemic is able to deliver more messages than the other two Looking at the average delivery delay graph in Fig. 4 increasing the buffer size, also increases the delay in both Epidemic and PROPHET. Interesting to note is that there is a slight decrease of the delay in G-Epidemic when the buffer size is big enough.  With a smaller buffer size, PROPHET has a shorter average delay. While as the increase of the buffer size the delay in G-Epidemic will be much shorter than both Epidemic and PROPHET. From Fig. 3 and Fig. 4 we can see that with a bigger buffer size, G-Epidemic is able to achieve a high delivery ratio, while the average delay of delivery doesnt increase Finally, we are interested to investigate the overhead of the network in different protocols. It is desirable that the limited resources are utilized properly. Fig. 5 demonstrates the overhead ratio for the three protocols. It seems like that as the buffer size increases, the number of message replications will increase. However, there will also be more messages that are successfully delivered due to less risk of dropping buffered messages. Thus, the overhead ratio decreases in all of the three protocols as the increase of buffer size. Looking at the graph in Fig. 5, It is obvious that the overhead ratio in G-Epidemic is much less than the other two 1500 m 3000 m  C1 C2 C3 C4 C5 C6 C7 C8 C9 C10 C11 C12 Fig. 2 Community model 


When the maximum hop-count is 3, the simulation results show that G-Epidemic and PROPHET is able to deliver a slightly more messages than G-Epidemic. But the average delay and overhead ratio of G-Epidemic are still much less than those of both Epidemic and PROPHET    VI  C ONCLUSIONS  AND F UTURE WORK  We proposed Group Based Epidemic Routing protocol \(GEpidemic\ this paper, and have achieved two main goals: 1 reducing unnecessary message replications, and 2\eserving high message delivery ratio and short delivery delay in Epidemic routing. In G-Epidemic, a node relies on all its friends, a group of frequently encountered nodes, in message delivery. Simulations performed have shown that in a community based scenario, G-Epidemic gives rather better performance than both Epidemic and PROPHET Our work to date has revealed that some additional questions remain to be answered. As mentioned above, GEpidemic relies on group information for routing. However sometimes group information may not be easily acquired before the distribution of system. In addition, it is sure that the group size affects the performance of G-Epidemic. If the size of all the groups is one, G-Epidemic will operate in the way of direct delivery; and if all the nodes are in the same group, GEpidemic will become the same with Epidemic. Therefore, it is important to select proper parameters to define groups. We are interested in making use of history contact information to set up groups dynamically at runtime, and some research has already been underway R EFERENCES  1  Fall, Kevin, A Delay-Tolerant Network Architecture for Challenged Internets, Computer Communication Review, v33, n4, pp. 27-34 October 2003, Proceedings of ACM SIGCOMM 2003 Conference on Computer Communications 2  C.E. Perkins and E.M. Royer, Ad-hoc On Demand Distance Vector Routing, Proceedings of IEEE workshop on mobile computing systems and applications, pp. 90-100, Feb, 1999 3  D. Johnson and D. Maltz, Dynamic source routing in adhoc wireless networks, Mobile Computing, Kluwer Academic Publishers Dordrecht, The Netherlands, 1996 4  Y. Wang, S. Jain, M. Martonosi and K. Fall, Erasure-coding based routing for opportunistic networks, Proceedings of ACM SIGCOMM 2005 Workshops: Conference on Computer Communications, pp. 229236, 2005 5  T. Spyropoulos, K. Psounis and C. S. Raghavendra, Spray and wait An efficient routing scheme for intermittently connected mobile networks, Proceedings of ACM SIGCOMM 2005 Workshops Conference on Computer Communications, pp. 252-259, 2005 6  Werner Vogels, Robbert van Renesse, and Ken Birman, The power of epidemics: Robust communication for large-scale distributed systems Proceedings of First Workshop on Hot Topics in Networks \(HotNets-I pp. 28-29 October 2002 7  Amin Vahdat and David Becker, Epidemic routing for partially connected ad hoc networks, Technical Report CS-200006, Duke University, April 2000 8  A. Lindgren, A. Doria, and O. Schelen. Probabilistic routing in intermittently connected networks. In ACM SIGMOBILE Mobile Computing and Communications Review, vol. 7, number. 3, pp. 1920 July 2003 9  Thrasyvoulos Spyropoulos, Konstantinos Psounis, and Cauligi S Raghavendra., Single-copy routing in intermittently connected mobile networks, Proceedings of Sensor and Ad Hoc Communications and Networks SECON, pp. 235-244, October 2004   Tracy Camp, Jeff Boleng, and Vanessa Davies, A survey of mobility models for ad hoc network research, Wireless Communications Mobile Computing \(WCMC\: Special issue on Mobile Ad Hoc Networking: Research, Trends and Applications, vol. 2, no. 5, pp. 483 502, 2002 1 20 40 60 80 100 120 140 160 180 200 10 20 30 40 50 60 70 80 90 100 110 Over head r at i o Buf f er  si ze  m essages  GEpi dem i c  r ange 20m  Epi dem i c  r ange 20m  Pr oP H E T  r ange 20m  GEpi dem i c  r ange 50m  Epi dem i c  r ange 50m  Pr oP H E T  r ange 50m Fig. 5 Overhead ratio vs. buffer size 1 20 40 60 80 100 120 140 160 180 200 500 1000 1500 2000 2500 3000 3500 4000 4500 5000 5500 Aver age del i ver y del ay  seconds Buf f er  si ze  m essages  GEpi dem i c  r ange 20m  Epi dem i c  r ange 20m  Pr oP H E T  r ange 20m  GEpi dem i c  r ange 50m  Epi dem i c  r ange 50m  Pr oP H E T  r ange 50m  Fig.4 Average delay vs. buffer size  Fig.3 Delivered messages vs. buffer size 1 20 40 60 80 100 120 140 160 180 200 0 200 400 600 800 1000 1200 1400 Del i ver ed m essages Buf f er  si ze  m essages  GEpi dem i c  r ange 20m  Epi dem i c  r ange 20m  Pr oP H E T  r ange 20m  GEpi dem i c  r ange 50m  Epi dem i c  r ange 50m  Pr oP H E T  r ange 50m  Fig.3 Delivered messages vs. buffer size 


To understand and interpret the distribution of the samples in Fig. 4, it is instructive to examine the corresponding loading plot shown in Fig. 5. The loading plot gives an overall picture of the variable correlation structure [16   Fig. 4.The score plot in a global model   Fig. 5.The loading plot in a global model  The nine variables are grouped three clusters in Fig. 5 1696  The first cluster is related to temperature and humidity the second cluster is related to PM10 and PM2.5 on platform and last cluster is related to the ratio of PM2.5 and PM10, the concentration of PM10 at a tunnel The first group contains humidity and temperature that are more related each other than other pollutants Generally, saturated vapor is increased as the temperature is going up. Therefore, when the temperature is increased, the humidity is decreased, but in case of the subway, if the temperature is increased the humidity is increased because the increased quantity of current vapor by evaporation of sweat is bigger than the increased quantity of the saturated vapor. Therefore people in a subway may feel the corresponding displeasure in the summer period. The second group is made up of PM2.5 and PM10 of platform which are proportional to the quantity of dusts which is the ventilation result of outdoor air and the moving of passengers. Following the previous study, these variables are mostly affected by the moving of passengers [12, 17]. But, the concentration of PM on platform is more affected by the outside air quality than the number of passengers. This result could be confirmed by the degree of correlation as shown in Table 1  Table 1. The variables correlation in a global model O PM10 P/O PM10 Tem Hum Ws P- PM10 P PM2.5 PM2.5 PM10 Pass enger O PM10 1.00 -0.57 0.28 0.21 -0.26 0.59 0.68 0.34 -0.00 002 P/O PM10  1.00 0.12 0.11 -0.02 0.22 0.07 -0.37 -0.03 Tem  1.00 0.38 -0.21 0.44 0.43 0.08 0.02 Hum  1.00 -0.10 0.46 0.48 0.18 0.08 Ws  1.00 -0.41 -0.43 -0.18 -0.09 P 


PM10  1.00 0.95 0.08 0.03 P PM2.5  1.00 0.38 0.12 PM2.5 PM10  1.00 0.23 Pass enger  1.00  As the degree of correlation between PM10 at a tunnel and PM10, PM2.5 on platform are 0.59, 0.68 in Table 1 the value is higher than the degree of correlation with passengers. Therefore, it means that the outside air quality is more affected to PM concentration of platform than passengers. As shown in a previous score plot \(Fig 3 installation of PSD system. So, it is necessary to consider that each local model may be different from global model made by using a whole data  4.3. Local model by installation of PSD Each process followed the previous one. These models are made through a training data which is divided by installation of PSD. The model without PSD can explain 79.1% of the total variation of training data and the model with PSD can explain about 67.7% of variations in a training data. This means that it is a good summary of the each data as it represents more than two-thirds of the total variation For the interpretation of the air quality change by the installation of PSD in a subway system, it is represented the loading plot in Fig. 6. It can be explained the variable correlation structure a b Fig. 6. The loading plot of each seasonal model a b  In a case of without PSD, the nine variables are strongly grouped into three clusters, one is related to temperature and humidity and another is related to particle matter containing ratio. The other is the ratio of PM10 between tunnel and platform, wind-speed. The variable, Passengers, has a little effect to other variables Compared to the without PSD result, the distribution of variables is more broad. Only PM10 and PM2.5 have relationship each other. Hence, when it is showed the different results between without PSD and with PSD, it could be analogized that the PSD affect the change of air quality on platform. These results are explained more strongly by the degree of correlation as shown in Table 2, 3 In a without PSD case, the value between PM10 at a tunnel and PM10, PM2.5 on platform are 0.78, 0.82. But after setting up the PSD, the effect of PM10 at a tunnel is decreased and this results is reflected that the degree of correlation between PM of tunnel and platform  s PM is 1697 decreased. And the relationship is high between PM10 and PM2.5 on platform in a case of without PSD and with PSD  Table 2.The variables correlation of without PSD O 


O PM10 P/O PM10 Tem Hum Ws P- PM10 P PM2.5 PM2.5 PM10 Pass enger O PM10 1.00 -0.76 0.50 0.35 -0.47 0.78 0.82 0.76 0.12 P/O PM10  1.00 -0.3 -0.2 0.41 -0.3 -0.4 -0.45 0.02 Tem  1.00 0.57 -0.40 0.63 0.62 0.58 -0.14 Hum  1.00 -0.21 0.51 0.46 0.38 0.03 Ws  1.00 -0.43 -0.44 -0.44 -0.18 P PM10  1.00 0.96 0.80 0.20 P PM2.5  1.00 0.93 0.20 PM2.5 PM10  1.00 0.18 Pass enger  1.00  Table 3.The variables correlation with PSD O PM10 P/O PM10 Tem Hum Ws P- PM10 P PM2.5 PM2.5 PM10 Pass enger O PM10 1.00 -0.38 0.35 0.19 -0.21 0.66 0.70 0.14 -0.17 P/O PM10  1.00 0.04 0.31 -0.25 0.38 0.28 -0.23 0.10 Tem  1.00 0.23 0.03 0.31 0.30 -0.01 0.25 Hum  1.00 0.03 0.44 0.47 0.14 0.17 Ws  


 1.00 -0.39 -0.40 -0.13 -0.05 P PM10  1.00 0.95 -0.05 0.00 P PM2.5  1.00 0.23 0.11 PM2.5 PM10  1.00 0.25 Pass enger  1.00  4.4 Discussion These days, many people, especially commuters would stay in indoor space. The point which is focused on is that particular indoor space such as subway-station platform and so on is a limited closed space. The problem that the particular space has is that the pollutants is taken place at once, it is very hard to remove it without any managements. Since the pollutants are accumulated in platform, the stay-time longer and longer, the risk of diseases is increased Therefore, it is needed adequate management against the pollutants For interpretation of the air quality change by the installation of PSD, it is applied for PCA to each dataset which is divided by installation Of PSD. The model without PSD can explain 79.1% of the total variation of training data and the model with PSD can explain about 67.7% of variations in training data. And it is showed the different results between w/o PSD and with PSD on loading plot. Also, when it is compared the degree of correlation of variables, the value between PM10 at a tunnel and PM10, PM2.5 on platform are 0.78, 0.82 in a w/o PSD case. But, after setting up the PSD, the effect of PM10 at tunnel is decreased and this results is reflected that the degree of correlation between outside PM and platform PM is decreased. And the relationship is high between PM10 and PM2.5 on platform in a case of without PSD and with PSD Therefore, it could be analogized that the PSD affect the change of air quality on platform  5. CONCLUSION  This study shows the problem of univariate analysis and necessity of multivariate analysis for the interpretation on the air quality change in a subway station. And by using specific process knowledge with data analysis, a more useful interpretation of the indoor air quality can be obtained. It shows the multidimensional correlation between indoor and outdoor air quality and finds the change of the air quality before and after PSD system  ACKNOWLEDGEMENTS  This work was supported by BK21 project, the Korea Science and Engineering Foundation \(KOSEF funded by the Korea government \(MEST KRF-2009-0076129 Program \(CS070160  REFERENCE  


 1]. M. J. Nieuwenhuijsen  Levels of particulate air pollution, its elemental compositions determinants and health effects in metro systems  Atmospheric Environment, 41 pp.7995-8006, 2007 2]. N. D. Nevers, Air Pollution Control Engineering McGRAW-HILL, USA, 1995 3]. D. U. Park and K. C. Ha  Characteristics of PM10, PM2.5, CO2 and CO monitored in interiors and platforms of subway train in Seoul, Korea   Environment International, 34, pp.629-634, 2008 4]. S. N. Kang, H. J. Hwang, Y. M. Park, H. Y. Kim C. H. Ro  Chemical compositions of subway particles in Seoul, Korea determined by a quantitative single particle analysis  Environ Sci. Technol., 42\(24 5]. N. J. Kim, S. S. Lee, J. S. Jeon, J. H. Kim, M. Y Kim  Evaluation of Factors to affect PM-10 Concentration in Subway Station  P of KOSAE pp 571-573, 2006 6]. D. S. Kim, S.D. Kim, Y. S. Kim, .E. B. Shin and T. J. Lee  Quantitative determination of aerosol contribution in Seoul metropolitan subway stations  Jof KSEE, Vol. 16, No. 3, pp 309-319,1994 7]. A. J. Charlton, P. Robb, J. A. Donarski, J 1698  Godward  Non-targeted detection of chemical contamination in carbonated soft drinks using NMR spectroscopy, variable selection and chemometrics  Analytica Chimica Acta, 618 pp.196-203, 2008 8]. D. M. Markovic, D. A. Markovic, A. Jovanovic L. Lazic, Z. Mijic  Determination of O3, NO2 SO2, CO and PM10 measured in Belgrade urban area  Environ. Monit. Assess., 145, pp.349-359 2008 9]. J. C. M. Pires, S. I. V. Sousa, M. C. Pereira, M C. M. Alvim-Ferraz, F. G. Martins  Management of air quality monitoring using principal component and cluster analysis  part SO2 and PM10  Atmospheric Environment, 42 pp.1249-1260, 2008 10]. J. C. M. Pires, S. I. V. Sousa, M. C. Pereira, M C. M. Alvim-Ferraz, F. G. Martins  Management of air quality monitoring using principal component and cluster analysis  part CO, NO2 and O3  Atmospheric Environment, 42 pp.1261-1274, 2008 11]. F. J. G. Gallero, M. G. Vallejo, A. Umbria, J. G Baena  Multivariate statistical analysis of meteorological and air pollution data in the  Campo De Gibraltar  region, Spain  Environ Monit. Assess., 119, pp.405-423, 2006 12]. J. Lau, W. T. Hung, C. S. Cheung  Interpretation of air quality in relation to monitoring station  s surroundings  Atmospheric Environment, 43, pp.769-777, 2009 13]. L. Eriksson, E. Johansson, N. Kettaneh-Wold, J Trygg, C. Wikstrom, S. Wold, Multi and Megavariate Data Analysis: Principle and Applications, Umetircs AB, Umea, Sweden 14]. B. M. Wise, N. B. Gallagher, R. Bro, J. M Shaver, W. Windig, R. S. Koch, PLS_Toolbox 3.5, Eigenvector reaserch, inc 15]. R. K. Tomita, S. W. Park, O. A. Z. Sotomayor  Analysis of activated sludge process using 


 Analysis of activated sludge process using multivariate statistical tools- a PCA approach   Chemical Engineering Journal, 90, pp.283-290 2002 16]. L. H. Chiang, E.L. Russell, R.D. Braatz, Fault detection and diagnosis in industrial systems Springer, USA, 2001 17]. Y. H. Cheng, Y.L. Lin, C. C. Liu  Levels of PM10 and PM2.5 in Taipei rapid transit system   Atmospheric Environment, 42, pp.7242-7249 2008 pre></body></html 


  Picture 6 PCS layout with virtual infrastructure and SAN  The second very important step was the installation and commissioning of a Storage Area Network SAN\, because only a network storage enables to make use of virtualization infrastructure features such as failover. This is due to the fact that virtual machine disk files may not exist on a certain host, as in case of failure it would not be accessible and available any longer to be restarted on a different physical host  SANs are either based on Fibre Channel or iSCSI Technology. The idea of both technologies is to extend the \(usually\nal data lines between hard disk controllers and hard-disks to external devices Fibre Channel has been a proven technology for this type application for years. It has a slightly better performance, but is more expensive than iSCSI iSCSI stands for Internet Small Computer System Interface It  means encapsulation  of the SCSI protocol within TCP/IP packages. Today iSCSI delivers sufficient performance to build up SANs for process automation purposes at a cement works  In such an arrangement, from a failure point of view, the SAN is the most critical peace of hardware in virtualized computer architecture  Although SANs are built up internally fail safe \(redundant power supply, NICs, hard disk controllers,\205 and data sheets give impressive figures for availability, any concept for process control purposes should allow for setting up auto-synchronizing SANs at different spots  User interface VMs running on a host are comparable to applications running on a Terminal Server. In other words, VMs obviously need input and output devices to be handled. Fat clients \(PC\222s\o good choice if it is intended to simplify the maintenance of the process control system hardware. Moreover, they are costly and sometimes prone to error Another step forward -with limited risk only- was to replace some operator stations of a segment by Thin Clients without hard disk The connection between thin client and VM is either done by vendor specific client software, RDP or VNC  Obstacles Minor issues may occur while transferring physical control systems into virtual ones Most of the problems the reference plant encountered had to do with the hardware interfaces such as serial and parallel ports and multi-media features  


Unresolved points \(minor\are to date realizing failover with legacy interfaces and sound output with Windows NT guests   CONCLUSION  Virtualization is no new but a revitalized technol ogy. First virtualization solutions \(purely based on software\ell as computer emulation deliver poor results in terms of performance  Hardware supported virtualization and pure software virtualization are totally different approaches  Virtualization today is most powerful when it combines the strengths of the different technologies. CPU demanding applications are wasting less performance than memory-intense application. \(TLB miss costs  VMware ESX is a good example of this. ESX uses Para-virtualized drivers for the most critical I/O components \(but not for the CPU\, emulation for the le ss important I/O and Binary Translation in order to avoid the high "trap and emulate" performance penalty. In this way, virtualized applications perform quite well, in some cases almost as if th ere were no extra VMM layer involved  The user benefit of virtualization is manifold. Virtualization 225  decouples software from hardware \(provides availability for \223legacy platforms\224, enables software in a cloud 225  utilizes installed hardware more efficient 225  safes space, energy, and invest cost 225  eases system administration extensively  225  but requires additional know-how of system administrators  At this point in time we can say that virtualization has met all of our expectations and offered \226in particular with respect to system administration- even more. The number of plants that started using Virtualization is growing  The process automation staff is still on a learning curve with virtualization in order to take maximum benefit of this technology  Unexploited potential is likely to be found in the field of setting up systems, handling of back-ups and disaster recovery procedures     REFERENCES  200  K. Lawton, Running muliple operating systems concurrently on an IA32 PC using virtualization techniques,http://plex86.org/research/paper.txt 200 www.codinghorror.com/blog/archives/001029.html 200 it.anandtech.com 200 en.wikipedia.org/wiki/Platform_virtualization 200  Virtualization for dummies SUN and AMD special edition 200 www.intel.com/technology/virtualizatio n/technology.htm?iid=tech_vt+tech 200  2008 Automation Summit - ID#: 1474 - Dow Chemical R&D\222s Global Rollout of PCS7\256 Using VMWare\256, Chicago    200 en.wikipedia.org/wiki/Ring_\(computer_security 


  13 edge of the aperture.  The distance of the reflected beam from the center of the aperture is then used to calculate I  which varies from about -0.8\260 to +0.8\260 in the experiment Figures 24-28 show the change r I    found by taking the difference of the center of each spectral image and subtracting from its location when I and compared the modeled values over the same range of I Figure 23 illustrates that there is some amount of random error in these measurements, but overa ll the data is grouped around r 0 pixel difference between the measured and modeled values.  The 404.7nm source shows the most variation  Figure 23 \226 The difference in pixel displacement at the detector array between measurements from modeled and collected data as a function of I     Figure 24 \226 Measured and modeled r   p  for the 404.7nm spectral line   Figure 25 \226 Measured and modeled r   p  for the 435.8nm spectral line   Figure 26 \226 Measured and modeled r   p or the 546nm spectral line   Figure 27 \226 Measured and modeled r   p  for the 577.5nm spectral line   Figure 28 \226 Measured and modeled r   p  for the 635nm spectral line   Given that the model is able to predict the displacement of energy as a result of an error in p   due to incident angle data was collected similar to that with the tilted camera to examine the effect system atic error due to unknown I  caused by a misaligned prism Here, the prism was angled in the mount in two directions to create the angles x and y  between the prism face and the normal to the optical axis as shown in Fig. 10.  The mo unt itself was tilted in two directions to create the misalignment angles x and y as shown in Fig. 12.  The magnitudes of these angles were measured by a laser as described above.  The aperture was placed such that each mm of separation at the aperture equates to 0.25\260 of angle at th e prism.  Misalignment in the instrument was used that gave values x  0.5\260 y  0.5\260 x 0.75\260 and y  0.5\260 with the instrument design again limiting the amount of error that could be imparted  The r   p  expression from Equation 17 will be compared to see how the displacement of each of the 5 wavelengths as a function of rotation angle varies given the different I  due to misalignment as the prism rotates.  The estimation in 3 2 1 0 1 2 3 4 5 6 1.0 0.5 0.0 0.5 1.0 r from model \(pixels I degrees 404.7nm 435.8nm 546nm 578nm 635nm 400 390 380 370 360 350 0 90 180 270 360 r   p pixels p degrees 404 nm, measured 404 nm, modeled 258 255 252 249 246 243 240 237 234 231 0 90 180 270 360 r   p pixels p degrees 435 nm, measured 435 nm, modeled 0 1 2 3 4 5 6 7 8 9 0 90 180 270 360 r   p pixels p degrees 546 nm, measured 546 nm, modeled 28 30 32 34 36 38 40 0 90 180 270 360 r   p pixels p degrees 578 nm, measured 578 nm, modeled 76 78 80 82 84 86 88 90 0 90 180 270 360 r   p pixels p degrees 635 nm, measured 635 nm, modeled 


  14 error for angles and is +/-0.2\260 and is incorporated into the model prediction.  Results are shown in Figures 24-29  Here, the measured data match the overall trends of the model very well, with some slight offset of about 2 pixels in each of the r   p  comparisons.  This would lead to the assumption that the estimate of x is not accurate, but is likely not the case since the mean of the model is too high in the 404nm data, and too low in the 435nm data.  This indicates that there are other errors being observed, as again it is nearly impossible to lim it the measurement to error in the intended so urce.  Also, note the decrease in impact the rotation error has as wavelength increases.  This is due to the lowered bearing P has on p as shown in the previous section.  However, the error magnitudes are a ratio of the distance from the undeviated wavelength, and in this data set are large due the large fractional error of and   4  R ESULTS  The systematic errors in a CTI instrument affect the spectral and spatial resolutions and locations in the reconstructed hyperspectral data cube in similar ways that these errors would affect the results of a traditional prism spectrograph This would be expected since the 3-D data is constructed from 2-D projection data.  The CTI becomes much more sensitive to error dependent on how the error kernel in the reconstruction behaves as a function of the prism rotation angle p and degree of freedom not in a fixed element dispersion system.  Four type s of systematic error were examined in this study; those due to tilt in the detector array  between the det ector array and the lens L 3  d   error in knowledge of the angular prism dispersion p    and error in estimation of the prism rotation angle p   s that can be inse rted into the error kernel functions were developed for each to model the effects For reasonably large array tilts of up to 3\260 and error in distance of up to 2mm, only a slightly noticeable shift of less than a pixel in spatial location was observed, mostly dependent on the tilt angle.  A more substantial spectral peak shift resulted which was due to error in distance, with a 7nm shift seen at the longer wavelengths at d  2mm.  The spatial and spectral resolu tions remained virtually unchanged, indicating that an accurate construction occurs in a shifted location The dispersion angle can be in error due to faulty estimation of prism performance.  This w ill cause an apparent shift of spectral peaks as shown in Figu re 8.  A more complicated  is the result of its dependence on the incident angle to the prism face I This is caused by mi salignment of the prism in the mount, or misalignment of the mount itself.  Mount misalignment is similar to cons tant error in estimation of p   with a shift in spectral p eaks observed.  For the AFIT CTI, this shift is only a few nm per 1\260 of misalignment Mount misalignment produces a more complex error kernel as shift and loss of resolutio n occur for relatively smaller angular errors.  More impor tantly, the spectral peaks become split into two peaks for errors of total misalignment in both the x and y directions of 1\260.  The spectral resolution may be recovered if the entire spatial area of the image is integrated.  However, simila r to splitting of peaks, the spatial distribution is a donut shape in the bin of emission  Finally, the error in projection angle p was examined though in a more obligatory fa shion since it is a relative error \(i.e. not a systematic erro r necessarily, but an error in choice of the reference coordinate system\.  There is no shifting of spectral peaks or lo ss of spectral resolution however there is a circular displacement of the spatial image again causing donut shap es for large enough   Most importantly, the error mode l was verified by collecting measured data from the AFIT CTI instrument with systematic error intentionally created in the instrument to assess the effect.  While in some cases it was apparent that sources of error other than those being investigated were influencing the results, the data did match the model for the situations where th e studied error effect was dominant usually at higher angular dispersi on, or spectral resolution Further investigation of some error may be necessary, as our CTI system design could only support a certain degree of component alteration to assess er ror.  In some cases, due to sampling of the detector array w ith respect to the size of the PSF of the system, slight changes in performance caused by error could not be resolved  4  C ONCLUSIONS  The purpose of this study wa s to assess the effect of systematic error on the reconstr ucted data sets collected by a rotating prism CTI instrument While the results are specific to the AFIT CTI desi gn, it is intended that the relative magnitude of each error and result on the reconstructed data will apply to any set of data given the general nature of the equations describing the reconstruction and error kernel that is con volved with each spectral bin  The consequence of each systematic error was quantified by the shift in spectral and/or spatial location, and degradation of spectral and/or spatial reso lution.  Table 2 summarizes the contribution of each analy zed error to these quantities   Table 2 \226The effect of systematic error.  An \223x\224 indicates an effect exists, a \223-\223 indicates no effect is observed   


  15 The model of the system allows for a quick assessment of the error, and provides a more illustrative demonstration of the prism misalignment error an d how each spectral peak is affected differently.  Figure 29 shows how the spectral peak changes as the prism mount alignment is increased in both the x and y directions for the 400nm and the 450nm spectral peaks   Figure 29 \226 The 400nm and 450nm peak shapes with varying misalignment of the prism mount   Similarly, Figure 30 represents the situation where the prism mount misalignment is constant at x  y 0.5\260 but the misalignment of the prism in the mount is changing so that a constant shape is produced, but shifted as x increases   Figure 30\226 Shifting of the 400nm spectral peak as x  increases.  The shape remains the same as the misalignment of the mount is constant   Though presented independently, the obvious contribution of the errors of the system are cumulative and must be considered in total.  Given th e great number of variations possible, this was not attempted here, but can be done based on the mathematics  This study is intended to explore the effect of systematic error for the purpose of examining sensitivity of performance when designing th e instrument.  In practice the reconstruction of collected data is done using after calibration of the instrument to directly measure r  p   without regard for the sources of error.  While this measurement can be a diagnostic of the instrument, the fact that it is well known is enough to perform acceptable reconstructions.  If instrume nt components are accessible the diagnostics be used to correct for second order error created in the instrument.  For example, errors in distance to the focal plane or tilt also result in a defocus error which cannot be easily recovered in the reconstruction algorithm R EFERENCES  1  C G r o s s, G  P. Perram an d R. F. Tu ttle, \223Mo d el i n g  infrared spectral intensity data from bomb detonations\224 Proceedings of SPIE  5881 p. 100 \(2005  2 o oney, \223A ngu l arly Mu ltip lex ed  Sp ectral Im ag er\224 Proceedings of SPIE  2480 pp. 65\22677, 1995   a ster, \223De sign and M o del Verification of an Infrared Chromotomographic Imaging System.\224 AFIT Masters Thesis, 2004  4 bb ins D  J. Go dfrey 223D ig ital x-ray tomosynthesis: current state of the art and clinical potential\224 Phys Med. Biol 48, pp. R65-R106, 2003   R.A Br oo ks an d G Di Chi r o 223Pri nci p l e s o f Com p u t er Assisted Tomography \(CAT\n Radiographic and Radioisotopic Imaging\224 Phys. Med. Biol  21 No. 5, pp 689-732, 1976  6 R.L. Bostick, G.P. Perr am, \223Hyperspectral Imaging Using Chromotomography: A Fieldable Visible Instrument for Transient Events\224 International Journal of High Speed Electronics and Systems  18 no. 3, pp. 519\226529, 2008  7 Bo stick   G  P.Perram an d R.F.Tu tt le 223Characterization of spatial and spectral resolution of a rotating prism chromotomographic hyperspectral imager\224 Proceedings of the SPIE  Next-Generation Spectroscopic Technologies II Conference, April 2009  B IOGRAPHY  Randy Bostick is a part-time PhD student at AFIT developing a metrology for a rotating prism chromotomographic imaging system.  Mr. Bostick is employed full time at the National Air and Space Intelligence Center at Wright-Patterson Air Force Base as an intelligence analyst for national remote sensing assets  


http://www.w3.org/TR/wsci 36] The World Wide Web Consortium \(W3C vice Modeling Language \(WSML http://www.w3.org/Submission/WSML 37] The World Wide Web Consortium \(W3C vice Modeling Ontology \(WSMO http://www.w3.org/Submission/WSMO 38] J. Yang and M.P. Papazoglou, ?Web Component: A Substrate for Web Service Reuse and Composition?, Proc 14th Conf. Advanced Information Systems Eng. \(CAiSE 02 LNCS 2348, pp. 21?36, Springer-Verlag, 2002 39] Y.P. Yang, Q.P. Tan, and Y. Xiao, ?Verifying Web Services Composition Based on Hierarchical Colored Petri Nets?, IHIS?05, pp. 47-53, Bremen, Germany, 2005 40] Y.P. Yang, Q.P. Tan, Y. Xiao, J.S. Yu, and F. Liu, ?Exploiting Hierarchical CP-Nets to Increase the Reliability of Web Services Workflow?, Symposium on Applications and the Internet \(SAINT?06 41] X.C. Yi and K.J. Kochut, ?Process Composition of Web Services with Complex Conversation Protocols: a Colored Petri Nets Based Approach?, Conference on Design, Analysis, and Simulation of Distributed Systems, pp.141-148, 2004 42] D. Zhovtobryukh, ?A Petri Net-based Approach for Automated Goal-Driven Web Service Composition?, SIMULATION, Vol. 83, Issue 1, pp.33-63, January 2007 43] C. Zhou, L.T. Chia, and B.S. Lee, "Web Services Discovery with DAML-QoS Ontology", International Journal of Web Services Research, vol. 2: no. 2: pp. 43-66, 2005   Proceedings of the 42nd Hawaii International Conference on System Sciences - 2009 10 pre></body></html 


  17 Mission Phase Relevant Archit ecture Informat ion Purpose Funct ion Mat urit y Pr oduct s DODAF M odel Re f e r e nce N ot e s Preliminary System Design Integrated Risk List Cross  functional list of risks compiled across integrated product team PDR Delivery Consolidated Ri sk Li st FFP1A Operational Environment M atrix documenting how test requirements that have been levied are satisfied with test \(at both the component and system levels Identification of the method that w ill be used to verify the requirement Identification of any potential non-conformances  Initial Delivery Environmental Te st  Verification Matrix FFP7 This will show the capability of the SV to withstand various environments \(i.e. launch vehicles System Interface Control Documentation This will be a suite of documents, the mission plan s hould identify critical system boundaries that reuqire a formal interface control document M inimum Criteria:  SV - Ground and Payload to SV ICD initial drafts must be compl e t e Other pertinent ICDs:  LV - Spacecraft, Component interface ICD Initial Delivery Interface Control Documentation SV 1  SV 6 Schedule Program Driving Schedule Requirements Key schedule driven technical decisions Giver receiver relationships that span different program elements Li v i n g Document Intgrated Milestone Schedule PV2 System Sub-system Design Specifications Partial Preliminary understanding of system subsystem design Allocation of required system functions to configuration items Demonstration of how system requirements are satisfied by design Initial Delivery PDR De si gn  Presentation SV 5 Open System Trades Desription organized by susbsystem of open design trades and decsions that need to be completed Each trade should have an owner and assocaited due dates that are aligned with program constriants Li v i n g Document Trade  Decision tracking matrix FFP5 Technical Performance Measures Demonstrate design peformance to critical program requirements outlined within the requirements document Initial Delivery Technical performance budget SV 7 Values in the budget should be compared to industry standards for a given maturity in the devleopment De t ai l e d De si gn System  Design Specifications Detailed description of "to be"  system subsystem design Allocation of required system functions to configuration items Demonstration of how system requirements are satisfied by design Final Delivery CDR De si gn  Presentation SV 4  SV 5 Note: Reference Lesson 11 - Need to look at some views and diagrams that would be useful for every subsystem Integrated Risk List Cross  functional list of risks compiled across integrated product team CDR Delivery Consolidated Ri sk Li st FFP1A Operational Environment Matrix documenting how test requirements that have been levied are satisfied with test \(at both the component and system levels Identification of the method that w ill be used to verify the requirement Identification of any potential non-conformances  Final Delivery Environmental Te st  Verification Matrix FFP7 Note: previous delivery s houl d have defined how requirements would be satisfied for long lead components.  This delivery would address all remaiing compents and system levels System Interface Control Documentation This will be a suite of documents, the mission plan s hould identify critical system boundaries that reuqire a formal interface control document M inimum Criteria:  SV - Ground and Payload to SV ICD initial drafts must be compl e t e Other pertinent ICDs:  LV - Spacecraft, Component Interface ICD Final Delivery Interface Control Documentation SV 1  SV 6 Schedule Program Driving Schedule Requirements Key schedule driven technical decisions Giver receiver relationships that span different program elements CDR De l i v e r y Intgrated Milestone Schedule PV2 Integration Prodcution Plan List of all components under procurement and their expected and need dates List should include all piece parts, miscellaneous mat ls, connectors and required ground support equipment Initial Delivery Sy st e m Pa r t s  Li st  FFP6 Technical Performance Measures Demonstrate design peformance to critical program requirements outlined within the requirements document Final Delivery Technical performance budget SV 7 Values in the budget should be compared to industry standards for a given maturity in the devleopment Open System Trades Desription organized by susbsystem of open design trades and decsions that need to be completed Each trade should have an owner and assocaited due dates that are aligned with program constriants Li v i n g Document Trade  Decision tracking matrix FFP5   


 LNCRITIC 0.884 \(.005 0.362 352 0.593 053  CRPRO -0.007 \(.306 0.012 183 0.002 798  CRCON 0.010 \(.291 0.013 230 0.019 095  Model fit F p value 24.900 lt;.0001 11.110 lt;.0001 5.940 lt;.0001 Adjusted R2 0.559 0.553 0.320 p &lt; .10 p &lt; .05 Notes: p values are in parentheses  4.5. South Korean versus American market  In terms of the effect of WOM, we find no discernable difference in the motion picture markets of South Korea and the United States. Volume of WOM is positively correlated to the following week?s revenue in both markets, and valence of WOM is not significant The effect of critical reviews, however, did not concur While the literature on the American market data reports that positive critical reviews are positively related to box office revenue[21, 34], the results on the Korean market was different. There could be several reasons for this. First, South Korea and the United States have different sources for critical reviews, and the sources may have different impacts on moviegoers Second, the characteristics of critics might be different i.e., Korean critics may prefer movies that are considered less commercial or artistic than American critics  5. Conclusion  WOM and critical reviews both are important attributes that influence box office revenue in the motion picture industry. In this study, six hypotheses related to this issue were set up and tested. Data was collected on the motion picture industry of South Korea by using several websites that provide content and statistical data about movies. Finally, data on 118 movies was collected and the movies were categorized into two groups based on the distributors of the movies If the distributor of a movie was one of the major distributors in South Korea, that movie was categorized into mainstream movies, and if not then the movie was categorized into non-mainstream movies. As expected mainstream movies had much higher box office revenue and volume of WOM than non-mainstream Proceedings of the 42nd Hawaii International Conference on System Sciences - 2009 8 movies. In the case of the volume of critical reviews 


movies. In the case of the volume of critical reviews however, there was no big difference between mainstream and non-mainstream movies. WOM and critical reviews were usually positive H1 and H2 tested the relationship between WOM and weekly box office revenue, and the results supported the hypotheses. The volume of WOM was positively related to weekly box office revenue, while the valence of WOM had no significant effect. H3 H4a, and H4b tested the impact of critical reviews, and the results also supported the hypotheses except H4b The volume and valence of critical reviews had no consistent significances to weekly box office revenue H3 H4b. Table 7 showed that the number of critical reviews was statistically significant to aggregate box office revenue \(H4a for the attitude of critical reviews \(H4b the result more detail, an additional test was performed using only those factors related to critical reviews as independent variables. The result of the additional test supported H4, but the signs were reversed, i.e. positive critical reviews had minus signs, and negative critical reviews had plus signs. This reversed signs imply that the preference of critical reviewers is very similar to that of normal moviegoers. H5s and H6s tested the different effects of WOM and critical reviews on mainstream and non-mainstream movies. The result failed to determine that WOM give different impact on mainstream and non-mainstream movies, so H5a and H5b were rejected. H6, however, was supported, i.e the effects of critical reviews were different for mainstream and non-mainstream movies. There were no significant relationships between critical reviews and aggregate box office revenue in mainstream movies. For non-mainstream movies, however, the volume of critical reviews and the percentage of negative critical reviews were significant. Nonmainstream movies have fewer sources from which consumers can get information, and this might explain the results The above findings lead to several managerial implications. First, producers and distributors of movies could forecast weekly box office revenue by looking at previous weeks? volume of WOM. It does not matter what attitude people have when they spread WOM, the important factor is its volume. Therefore producers and distributors need to develop an appropriate strategy to manage WOM for their movies For example, the terms related to WOM marketing such as buzz and viral marketing are easily found Second, for the distributors who usually distribute less commercial and more artistic movies, and consequently have a smaller market compared to the major distributors, critical reviews can impact their movies box office revenues in a significant way. There are usually fewer sources for information for nonmainstream movies than mainstream movies, and so small efforts could leverage the outcomes. Finally, for those who are dealing with mainstream movies, the finding that the valence of WOM and critical reviews do not have significant relationship with box office revenue can have certain implications. Particularly, the attitude of critical reviews showed reversed effects Therefore, they may need to concentrate on other features rather than attitude of moviegoers or critical reviews, such as encouraging moviegoers to spread WOM This study contributes to the understanding of the motion picture industry, especially the relationship between box office revenue and WOM including critical reviews. There are existing studies that already 


critical reviews. There are existing studies that already dealt with similar issues, but this study has some differentiated features compare to prior studies. First the data used in this study was collected from South Korea, while most of the relevant studies usually focus on the North American market. This helps to provide the opportunity to understand the international market especially the Asian market, even though South Korea is a small part of it in terms of the motion picture industry. Second, movies were categorized to two groups, i.e. mainstream and non-mainstream and this study attempted to determine how WOM impacts these categories differently by testing several hypotheses In this study, there are also several limitations that could be dealt with in future research. First, using box office revenue as a dependent variable is more meaningful for distributers rather than producers. Due to there is close correlation between box office revenue and number of screens, one of producers? main concerns is how many screens their movies can be played on. Moreover, DVD sales are also important measurement for success of movies these days, and so it also could be a dependent variable. Therefore, it could be possible to give more fruitful managerial implications to various players in the motion picture industry by taking some other dependent variables Second, in this study, movies were categorized simply as mainstream and non-mainstream movies, but there could be further studies with diverse techniques of movie categorizations. For example, it would be possible to study the varying influence of WOM or critical reviews on different genres or movie budgets Third, an interesting finding of this study is that positive critical reviews could have negative relationship with box office revenue while negative critical reviews could have positive relationship. This study tried to provide a reasonable discussion on the issue, but more studies could be elaborate on it  Proceedings of the 42nd Hawaii International Conference on System Sciences - 2009 9 References  1] Dellarocas, C., The Digitization of Word of Mouth Promise and Challenges of Online Feedback Mechanisms Management Science, 2003. 49\(10 2] Bone, P.F., Word-of-mouth effects on short-term and long-term product judgments. Journal of Business Research 1995. 32\(3 3] Swanson, S.R. and S.W. Kelley, Service recovery attributions and word-of-mouth intentions. European Journal of Marketing, 2001. 35\(1 4] Hennig-Thurau, F., et al., Electronic word-of-mouth via consumer-opinion platforms: What motivates consumers to articulate themselves on the internet? Journal of Interactive Marketing, 2004. 18\(1 5] Fong, J. and S. Burton, Electronic Word-of-Mouth: A Comparison of Stated and Revealed Behavior on Electronic Discussion Boards. Journal of Interactive Advertising, 2006 6\(2 6] Gruen, T.W., T. Osmonbekov, and A.J. Czaplewski eWOM: The impact of customer-to-customer online knowhow exchange on customer value and loyalty. Journal of Business Research, 2006. 59\(4 7] Garbarino, E. and M. Strahilevitz, Gender differences in the perceived risk of buying online and the effects of receiving a site recommendation. Journal of Business Research, 2004. 57\(7 8] Ward, J.C. and A.L. Ostrom, The Internet as information minefield: An analysis of the source and content of brand information yielded by net searches. Journal of Business Research, 2003. 56\(11 


9] Goldsmith, R.E. and D. Horowitz, Measuring Motivations for Online Opinion Seeking. Journal of Interactive Advertising, 2006. 6\(2 10] Eliashberg, J., A. Elberse, and M. Leenders, The motion picture industry: critical issues in practice, current research amp; new research directions. HBS Working Paper, 2005 11] S&amp;P, Industry surveys: Movies and home entertainment 2004 12] KNSO, Revenue of Motion Picture Industry 2004 Ministry of Culture, Sports, and Tourism, 2004 13] Duan, W., B. Gu, and A.B. Whinston, Do Online Reviews Matter? - An Empirical Investigation of Panel Data 2005, UT Austin 14] Zhang, X., C. Dellarocas, and N.F. Awad, Estimating word-of-mouth for movies: The impact of online movie reviews on box office performance, in Workshop on Information Systems and Economics \(WISE Park, MD 15] Mahajan, V., E. Muller, and R.A. Kerin, Introduction Strategy For New Products With Positive And Negative Word-Of-Mouth. Management Science, 1984. 30\(12 1389-1404 16] Moul, C.C., Measuring Word of Mouth's Impact on Theatrical Movie Admissions. Journal of Economics &amp Management Strategy, 2007. 16\(4 17] Liu, Y., Word of Mouth for Movies: Its Dynamics and Impact on Box Office Revenue. Journal of Marketing, 2006 70\(3 18] Austin, B.A., Immediate Seating: A Look at Movie Audiences. 1989, Wadsworth Publishing Company 19] Bayus, B.L., Word of Mouth: The Indirect Effects of Marketing Efforts. Journal of Advertising Research, 1985 25\(3 20] Faber, R.J., Effect of Media Advertising and Other Sources on Movie Selection. Journalism Quarterly, 1984 61\(2 21] Eliashberg, J. and S.M. Shugan, Film critics: Influencers or predictors? Journal of Marketing, 1997. 61\(2 22] Reinstein, D.A. and C.M. Snyder, The Influence Of Expert Reviews On Consumer Demand For Experience Goods: A Case Study Of Movie Critics. Journal of Industrial Economics, 2005. 53\(1 23] Gemser, G., M. Van Oostrum, and M. Leenders, The impact of film reviews on the box office performance of art house versus mainstream motion pictures. Journal of Cultural Economics, 2007. 31\(1 24] Wijnberg, N.M. and G. Gemser, Adding Value to Innovation: Impressionism and the Transformation of the Selection System in Visual Arts. Organization Science, 2000 11\(3 25] De Vany, A. and W.D. Walls, Bose-Einstein Dynamics and Adaptive Contracting in the Motion Picture Industry Economic Journal, 1996. 106\(439 26] Bagella, M. and L. Becchetti, The Determinants of Motion Picture Box Office Performance: Evidence from Movies Produced in Italy. Journal of Cultural Economics 1999. 23\(4 27] Basuroy, S., K.K. Desai, and D. Talukdar, An Empirical Investigation of Signaling in the Motion Picture Industry Journal of Marketing Research \(JMR 2 295 28] Neelamegham, R. and D. Jain, Consumer Choice Process for Experience Goods: An Econometric Model and Analysis. Journal of Marketing Research \(JMR 3 p. 373-386 29] Lovell, G., Movies and manipulation: How studios punish critics. Columbia Journalism Review, 1997. 35\(5 30] Thompson, K., Film Art: An Introduction. 2001 McGraw Hill, New York 31] Zuckerman, E.W. and T.Y. Kim, The critical trade-off identity assignment and box-office success in the feature film industry. Industrial and Corporate Change, 2003. 12\(1 


industry. Industrial and Corporate Change, 2003. 12\(1 27-67 32] KOFIC, Annual Report of Film Industry in Korea 2006 Korean Film Council, 2006 33] Sutton, S., Predicting and Explaining Intentions and Behavior: How Well Are We Doing? Journal of Applied Social Psychology, 1998. 28\(15 34] Basuroy, S., S. Chatterjee, and S.A. Ravid, How Critical Are Critical Reviews? The Box Office Effects of Film Critics Star Power, and Budgets. Journal of Marketing, 2003. 67\(4 p. 103-117  Proceedings of the 42nd Hawaii International Conference on System Sciences - 2009 10 pre></body></html 





