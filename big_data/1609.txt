A Mining Algorithm For Emailís Relationships Based On Neural Networks   Hongjun Li Huazhong University of Science and Technology Wuhan University of Science and Engineering Wuhan, China Jiangang Zhang Wuhan University of Science and Engineering Wuhan, China  Haibo Wang  Wuhan University of Science and Engineering Wuhan, China  Shaoming Huang  Hubei Provincial Water Resources Research Institute Wuhan, China   Abstract The analysis of the vast storehouse of email content accumulated or produced by individual users has received relatively little attention other than for specific tasks such as relationship. Current email analysis in standard client applications consists of keyword based matching techniques for relationship of email files. We have implemented a tool, called the Email Mining Set \(EMS\r analyzing email archives which includes a graphical display to explore relationships between users and groups of email users. Our design goal is to embed the technology into standard email clients, such as foxmail and Outlook, revealing far more information about a userís relationship is otherwise now possible Keywords-email; relationship; data mining; neural networks I   I NTRODUCTION  Computer forensic technology has already become a focus attention of the law and computer science area since this year With status of the research and development of computer forensic technology, there are two problems of consummating Legal norm in computer forensic technology and process Frequency using email has already become an important communication way among members of crime organizing. The amounts of research about relations among people using email for communication testify human relations at a certain extent Dividing the relation by the research of the email information between users attracts more and more researchersí attention Meanwhile, the data amount is so much that deficiency in Database analyses the method. The large amount of email resource gaining through various channels is always no rule. It is difficult to discover the interrelation and information clue from known data, and it has no way to forecast the future development trend and analysis deathly[1,2 Data Mining means that extract out the unknown, valuable pattern from large amount of data  and it is widely be used among the field of industrial control, business management and science research, etc. there are much arithmetic for data mining, include: Fuzzy Set, Rough Set, Neural Network, etc The relation about Huge Data and Integrated Data are very complicated in reality, high Nonlinearity, noise data existence so it may restrict to apply some feasible algorithmic  Data mining means fetching unknown and valuable model from huge data set. An association rule is a rule which implies certain association relationships among a set of objects in a database. Since finding interesting association rules in databases may disclose some useful patterns for decision support, selective marketing, financial forecast, medical diagnosis, and many other applications, it has attracted a lot of attention in recent data mining research. Mining association rules may require scanning of large transaction or relational databases which is quite costly in processing. Therefore efficient mining of association rules in transaction and/or relational databases has been studied substantially The development of distributed algorithms for efficient mining of association rules has its unique importance, based on the following reasoning. Databases of data warehouses may store a huge amount of data. Mining association rules in such database may require substantial processing power, and distributed system is a possible solution. Many large databases are distributed in nature. This High flexibility, scalability, low cost performance ratio, and easy connectivity of a distributed system make it an ideal platform for mining association rules 4   The paper has told a data mining system carrying out relation specifically for the email date. According to the concept leading  into email address similar and active among clustering process, it reaches the effect carrying out clustering mail address having the similarity characteristic  providing a kind of new analysis method to the information processing email. Then, the computer forensic software function focuses on disc analysis; other work is dependent to be done by experts by hand, carrying to mislead the computer forensic software implement similar to disc analysis software. With the development of computer theory and the technology about crime forensic, it will be improved. From the researcher in the field, we can discover that not only the forensic technology is basal principle for analysis computer document and the data but also it can mine crime information among data system 
2008 International Conference on Computer Science and Software Engineering 978-0-7695-3336-0/08 $25.00 © 2008 IEEE DOI 10.1109/CSSE.2008.1537 1122 


information. Judging from the view of technology, data mining should be an effective technology for computer forensic technology. It is a hot spot in theory and applying for the current research computer science and technology, but many problems will be developed and improved. The paper tells how to use data mining technology to apply to computer crime forensic technology, and give a thought about fundamental data mining, through actual case analysis process to build an effective computer forensic method and way[4  II  T HE D ATA M INING  S F OUNDATION OF E MAIL R ELATIONSHIP  A  The Translation Rule and Format of Email There is a special way in sending email that the information is not sent to the destination directly, but transferred by several mail servers in a ístorage-transferí way. As shown in Fig. 1 ordinarily, an email is sent from the user, transferred to the SMTP server by mail client program, and then transferred by several mail servers, to the mail servers of recipients by pop3 server program with accounts and password The email format is defined by RFC822, sime-structure text file, including header and context. And the header has key information, such as FROM, SENDER, REPLY TO, TO, CC BCC, MESSAGE-ID, DATE, RECEIVED, RESENT SUBJECT, and COMMENTS. A common emailís header is shown as Figure 2 B  Ways Based on Data Mining Data Mining is a useful information and knowledge process that fetches from the large, incomplete, noisy, vague and random data. Computer Forensics Data Mining  is  the  concept 000\003  Figure 1. The transfer-flow of email  000\003 Figure 2. Common emailís header  of process with unascertained the discovery of crime information, analysis and production based-computer \(and the related system\Therefore, the way of Computer Forensics Data Mining is to establish the classification of the form of property crime, extraction the rules and the pattern found. Because a great deal, not complete, noise, vague and random data, in most cases it does not have a condition for data analysis, despite doing much in-depth research of mining model and algorithms in theory, but the results is still on ideals and formal. It can not achieve the purpose of data mining if only rely on incomplete data analysis, and statistical data being built in the way of experience and intuition based on a combination of data mining is a very useful way. According to data analysis having the generalized features, we call the generally data mining combination information mining  III  T ECHNIQUES FOR E MAIL RELATIONSHIP M INING  There is an important relationship between large itemsets and the sites in a distributed database: every globally large itemsets must be locally large at some sites. If an itemset A is both globally large and locally large at a S i A is called gl-large at site S i The set of gl-large itemsets at a site will form a basis for the site to generate its own candidate sets. Two monotonic properties can be easily observed from the local large and lglarge itemsets In order to study email flows between groups of users, we can compute a set of cliques based on the data present in an email archive. We seek to identify clusters or groups of related email accounts that participate with each other in common email communications. Conceptually, two broad types of cliques can be extracted from user email archives: user cliques and enclave cliques. In simple terms, user cliques can be inferred by looking at the email history of only a single user account, while enclave cliques are social groups that emerge as a result of analyzing traffic flows among a group of user accounts within an organization. The algorithm initially counts the number of emails exchanged between any two given users regardless of the direction of the traffic flow. This absolute number is compared to a threshold. If the count is above the threshold, then the link between the two underlying accounts is established and a graph begins to form. This is computed over all emails and all email accounts appearing in all messages whether sender or receiver of an email. At this point, we have a list of cliques of size 2, called dyads Features that made email so popular are the rapidity of communication, the minimum cost and the fact that it is remarkably easy to use. An advantage over Email communication is that it is asynchronous, meaning that there is no need for both sides of communication to be on-line or in front of a computer at the same time A decision tree is a structure similar to a flow chart. In order to classify an unknown sample, the attribute values of the sample are tested against the decision tree. A path is traced from the root to the leaf node that holds the class prediction for that sample. D Decision trees have been used in many application areas ranging from medicine to game theory and business. The basic algorithm used in decision tree induction is a greedy algorithm that constructs the trees in a top-down 
1123 


recursive, divide and conquer manner. The algorithm is a version of ID3, a well-known decision tree induction algorithm. The information gain measure is used to select the test attribute at each node in the tree. Such a measure is referred to an attribute selection measure or a measure of the goodness of split. For example, let S be a set consisting of s data samples. Suppose the class label attribute has m distinct values defining m distinct classes, C i for i=1, . . .,m\et s i be the number of samples of S in class C i The expected information needed to classify a given sample is given by 000    m i i i m p p s s s I 1 2 2 1   log     1 where pi is the probability that an arbitrary sample belongs to class C i and is estimated by s i s. Let attribute A have v distinct values, {a 1 a 2 a v Attribute A can be used to partition S into v subsets, {S 1 S 2 S v where Sj contains those samples in S that have value aj of A. Let s ij be the number of samples of class C i in a subset S j The entropy, or expected information based on the partitioning into subsets by A, is given by       1 1 1 mj j v j mj j s s I s s s A E 000     2 The term s s s mj j    1 acts as the weight of the jth subset and is the number of samples in the subset \(i.e., having value a j  of A\ divided by the total number of samples in S. The smaller the entropy value is, the greater the purity of the subset partitions. For a given subset S j  000    m i ij ij mj j j p p s s s I 1 2 2 1   log     3 where i ij ij s s p  and is the probability that a sample in S j  belongs to class C i The encoding information that would be gained by branching on A is         2 1 A E s s s I A Gain m   4 The algorithm computes the information gain of each attribute and the attribute with the highest information gain is chosen as the test attribute for the given set S. As a node is created and labeled with the attribute, branches are created for each value of the attribute, and the samples are partitioned accordingly Figure 3, which is called the User Panel, demonstrates the relationship between senders and their receivers. The blue nodes aligned as the left most column of the display are the indexed\ membership. The black nodes are the Email sender Each distinct black node corresponds to one distinct email address. They are placed in different columns depending upon the number of membership they belong to. For example, a sender who  belongs  to  only  one  membership  is  in  the  first  Figure 3. Visualization of membership  column immediately adjacent to the blue colored membership nodes. A sender who is part of two memberships is in the second column, and so forth. The senders aligned at the rightmost column are those who are members of the most membership, and may be regarded as very significant well connected individuals in an organization The edges in this graph represent the relationship of clique members. If there are two cliques with some common member EMS displays a link between the two cliques. We use different colors to represent the percentage of users that the two cliques share, indicating how similar the cliques are to each other. The color mapping is shown in Table 1. For example, cliques A and T ABLE I  T HE DEGREE OF SHARING USERS  Color Percentage Orange 10 Yello w 10 20 Red 20 30 Cyan 30 40 Blue 40 50 Magenta 50 60 Gree n 60 70 Gra y 70 80 Pin k 80 90 Blac k 90 
1124 


clique B share 30% of users, and hence they are linked with a red edge. When the user clicks on an edge, the common users appearing in both cliques is displayed In the SDK package, we can get the relationship from emailís information, such as FROM, SENDER, REPLY TO TO, CC, and BCC fields. The Figure 4 is given by the independent email system  Figure 4. Relationship of memberships The nucleus contacter: the people who provide information, technology and decision bagman: the people who contact different subgroups other people the information flow of the people in the relationnetwork IV  CONCLUSION Many email archives are currently being preserved with the intention that they will be a valuable resource in the future Governments preserve some email archives as public records businesses may keep their emails to comply with certain laws and some individuals save their personal email as a record of their life. In order for historians and social scientists to make use of these archives, they need powerful tools to navigate through a vast number of messages. In this paper, we present a new technique to allow email archive explorers the ability to identify discussions. By presenting visualizations that go beyond the threads of email, explorers can become aware of messages that would have otherwise been hidden. Our legible visualizations present relevant temporal and social data that provides explorers with an enhanced opportunity to understand discussions evidenced in email archives R EFERENCES  1  J.Heer, \(2005\, ìExploring enron: visual data mining http://www.cs.berkeley.edu/~jheer/anlp/final 2  D.W.Cheung, J.Han, V.Ng, and C.Y. wong, ìMaintenance of discovered association rules in large database: An incremental updating technique in Proceedings 1996 Internationl Conference on Data Engineering, New Orleans, Louisiana, February 1996 3  J.Han, Y.Cai, and N.Cercone, ìDatadriven discovery of quantitative rules in relational databases,î IEEE Transactions Knowledge and Data Engineering, 5: 30ñ41, 1993 4  A.Blum and T.Mitchell, \(1998\, ìCombining labeled and unlabelled data with co-training,î Paper presented at the Workshop on Computational Learning Theory 5  M. Girvan and M. Newman, ìCommunity structure in social and biological networks,î in Proceedings of National Academic Science USA 99, 7821C7826 2002   
1125 


a user-specified minimum support and confidence respectively, where X and Y are sensor readings from different sensors, s is the percentage of reading rounds that contain both X and Y, called support of the rule, and c is the percentage of reading rounds containing X that also contain Y, called the confidence of the rule. The task of mining association rules then is to find all the association rules among the sensors which satisfy both the user-specified minimum support and minimum confidence Experimental results show that WARM performs better than the average approach where the average reading reported by all sensors in the window is used for estimation. However WARM treats all sensor readings in the window to be of equal importance regardless of when the readings were obtained, i.e all the sensor readings would contribute equally to the estimation of a missing data value in the current round of readings.    This treatment does not reflect the temporal nature of sensor data in many data stream applications, such as those that use sensors to monitor environmental conditions.  In those applications, the more recent a sensor reading is, the more relevant it is in answering queries that are based on the current sensor data. For example, the temperature collected at 2 PM is more similar to that collected at 2:05 PM than the one reported at 10 PM.  So, to estimate the temperature that was missing i.e. did not get reported\t 2 PM due to a sensor data lateness/loss/corruption, the temperature reported at 2:05 PM should contribute more than the one reported at 10 PM. to the estimation To address the temporal sensor data problem, we have developed a new algorithm, called FARM \(Freshness Association Rule Mining\.  Here, we provide the key ideas and results of FARM; interested readers are referred to r more detailed descriptions.   FARM associates a freshness value, called round weight, to each round of sensor reading The more recent a round of sensor readings is, the higher round weight it has in computing the estimated value for the missing data in the current round. Like WARM, FARM also uses association rule mining to find the relationships between sensors; however, with the inclusion of round weights, the relationships discovered by FARM reflect the temporal correlations between sensors as the time element manifests itself in many data stream applications. After identifying the related sensors through data mining, FARM computes the estimated value of the missing sensor reading based on the weighted average of the current readings of the sensors related to the sensor with the missing reading To reduce space overhead, FARM implements a data structure that compacts raw stream data by means of round weights. Data held in that structure is the result of a formula that creates a mapping between a sequence of raw data and a resultant datum and thus requiring a much less space. Only compacted data is needed for estimation. This makes it possible to hold an efficient number of data rounds, which offers an advantage over the typical sliding window solution used in many data stream mining algorithms. Sliding window approaches typically suffer a tradeoff between a large space requirement and being able to store enough samples to recognize patterns given the chosen window size Additionally, limiting their amount of data stored makes them systematically unfit to answer data stream queries.  With the data compaction scheme, space overhead to compute association rules is reduced, which in turn, reduce access time to data needed to perform data estimation  To recapitulate, it is this duality between the data freshness  and the data compaction scheme as well as their positive implications on the space and time complexities that derive the motive of the FARM method  C. Missing Data Validation for the Attacked Mode Using a climate sensing data set [25 w h er e th e t e m p o r al characteristic of sensor data exists, we have performed experiments comparing FARM, WARM and existing data estimation algorithms: SPIRIT [26 T i n y D B  2 7  S imp le  Linear Regression \(SLR\, Multiple Linear Regression \(MLR Curve Regression \(CE\, and estimation by average \(Avg   The accuracy of the estimation is evaluated using the normalized root mean square error RMSE As shown in Table 1, FARM yields the best data estimation accuracy with 23.43% less error than the second best method \(WARM\ and 98.59% less error than the worst method \(CE  Method RMSEs for Climate Sensing data How many % the best approach is better FARM 0.00487 Best Approach WARM 0.00636  23.43  TinyDB 0.0085 42.71 SPIRIT 0.0116  58.02  Average 0.015  67.53  MLR 0.121  95.98  SLR 0.342  98.58  CE 0.346  98.59  Table 1 RMSEs for Climate Sensing Data Set  IV  C ONCLUSION AND P ERSPECTIVES  This paper proposed a new approach of modeling the collaboration of sensor system artifacts to address the security and survivability concerns of sensor networks. The model considered is composed of sensors, base and users. Sensors are nodes that acquire and process data. Base is the node that acquires and processes data from sensors and provides an interface to access and monitor the sensor network while Users monitor the system. The model proposed has been instantiated and validated using association rule mining to compensate for missing data in order to provide security and survivability to sensor networks. Future work will instantiate and validate other modes presented throughout the paper ACKNOWLEDGMENTS We thank our two collaborators, Dr. Johnson Thomas at Oklahoma State University and Dr. Sandip Sen at Tulsa University, for participating in many discussions of the proposed system model and instantiation 508 


R EFERENCES  1  B. H. Calhoun, D. C. Daly, N. Verma, D. Finchelstein, D D. Wentzloff, A. Wang, S.-H. Cho, and A. P Chandrakasan, çDesign Considerations for Ultra-low Energy Wireless Microsensor Nodes IEEE Transactions on Computers Vol 54\(6\ pp. 727-749, June 2005 2  L. Clare, G. Pottie, and J. Agre. çSelf-Organizing Distributed Sensor Networks SPJE Conference on Unattended Ground Sensor Technologies and Applications pp. 229-237, April 1999 3  T. Wong, T. Tsuchiya, and T. Kikuno, çA Self-organizing Technique for Sensor Placement in Wireless MicroSensor Networks,é in Proc. of 18th International Conference on Advanced Information Networking and Applications AINA\, pp. 78-83, March 2004, Fukuoka Japan, IEEE Computer Society 4  A. Ghosh and S. Sen, çAgent-Based Distributed Intrusion Alert System,é to appear in Proc. 61h International Workshop on Distributed Computing December 2004 5  R. Gopalakrishna and E. H. Spafford, çA Framework for Distributed Intrusion Detection using Interest Driven Cooperating Agents Web Proceedings of the Fourth International Workshop on Recent Advances in Intrusion Detection \(RAID 2001 6  Y. Fu, J. He, G. Li, çA Distributed Intrusion Detection Scheme for Mobile Ad Hoc Networks,é in Proc. of 31 st  Annual International Computer Software and Applications Conference COMPSAC\, Vol. 2,  pp. 7580, 2007 7  W. B. Heinzelman, A P. Chandrakasan, and H Balakrishnan, çAn Application-Specific Protocol Architecture for Wireless Microsensor Networks IEEE Transactions on Wireless Communications Vol. 1, No.4 2002 8  M.-Y. Huang and T. M. Wicks, çA Large-scale Distributed Intrusion Detection Framework Based on Attack Strategy Analysis,é in Web Proc. of the 1st International Workshop on Recent Advances in Intrusion Detection RAID\, 1998 9  A. Abraham, R. Jain, J. Thomas and S. Y. Han, çDSCIDS: Distributed soft computing intrusion detection system Journal of Network and Computer Applications  Vol. 30, pp. 81Ö98, 2007   C. Intanagonwiwat, R. Govindan and D. Estrin. çDirected Diffusion: A Scalable and Robust Communication Paradigm for Sensor Networks,é in Proc. of Annual International Conference on Mobile Computing and Networks MobiCOM\, August 2000   C. Karlof and D. Wagner, çSecure Routing in Wireless Sensor Networks: Attacks and Countermeasures,é Proc of 1st IEEE International Workshop on Sensor Network Protocols and Applications 2003   S. Meguerdichian, F. Koushanfar, M. Potkonjak, and M B. Srivastava, çCoverage Problems in Wireless Ad-hoc Sensor Networs IEEE Infocom Vol 3, pp. 1380-1387 April 2001   P. Papadimitratos and Z. J. Haas, çSecure routing for mobile ad hoc networks,é in SCS Communication Networks and Distributed Systems Modeling and Simulation Conference CNDS\ January 2002   A. Perrig, R. Szewczyk, V. Wen, D. Culler, and J. D Tygar, çSPINS: Security protocols for sensor networks in Proc. of Mobile Networking and Computing 2001   B. S. Snapp and G. D. et al., çDids \(distributed intrusion detection system\ motivation, architecture, and an early prototype,é In Fourteen National Computer Security Conference October 1991   T. Peng, C. Leckie and K. Ramamohanarao, çInformation sharing for distributed intrusion detection systems Journal of Network and Computer Applications Archive  Vol.  30\(3\, pp. 877-899, 2007   E. H. Spafford and D. Zamboni, çIntrusion detection using autonomous agents Computer Networks Vol 34\(4\ 2000   Y. Zhang and W. Lee. çIntrusion Detection in Wireless Ad-Hoc Networks,é in Proc. of the 6th Annual International Conference on Mobile Computing and Networking Mobicom\, 2000   B. Sun, K. Wu, Y. Xiao and R. Wang, çIntegration of mobility and intrusion detection for wireless ad hoc networks: Research Articles International Journal of Communication Systems archive Vol. 20\(6\, pp. 695-721 2007   L. Zhou and Z. Haas, çSecuring ad hoc networks IEEE Network Magazine vol. 13, no. 6, 1999   R. Agrawal, T. Imielinski, and A. N. Swami, çMining Assoc iation Rules between Sets of Items in Large Databases ACM SIGMOD Conference May 1993   M. Halatchev and  L. Gruenwald, çEstimating Missing Values in Related Sensor Data Streams,é in Proc. of Intl Conference on Management of Data January 2005   N. Jiang and L. Gruenwald: CFI-Stream: Mining Closed Frequent Itemsets in Data Streams; ACM SIGKDD international conference on knowledge discovery and data mining, August 2006   L. Gruenwald, H. Chok and M. Aboukhamis, çUsing Data Mining to Estimate Missing Data,é Proceedings of the 7th IEEE International Conference on Data Mining Workshop on Optimization-based Data Mining Techniques with Applications 2007   NASA/JPL Sensor Webs Project http://caupanga.huntington.org/swim/, a ccessed January 2006   S. Papadimitriou,  J. Sun, and C. Faloutsos, çPattern Discovery in Multiple Time-Series International Conference on Very Large Data Bases September 2005   S. Madden, M. Franklin,  J. Hellerstein, and W. Hong TinyDB: An Acquisitional Query Processing System for Sensor Networks ACM Transactions on Database Systems 2005   R. Little and D. Rubin, çStatistical Analysis with Missing Data New York: John Wiley & Sons 1987     509 


D j 222 38 
Return 
Figure 5 Algorithm for reassessing clusters composition for dynamic XML documents  6. Experimental results  To test our proposed method we used XML documents \(20kB and 50kB\xtracted from the   with an average number of levels of 4 Firstly, we clustered the documents to get the initial clusters composition \(Step 1 in framework in Section 3\, using minimum pair-wise distances; at this stage we also stored the distances between documents in the clustering solution together with the set of operations corresponding to each minimum distance. Then, in order to assess the efficiency of Step 2, we applied different percentages of changes to the documents in the clustered solution, in order to obtain new versions The purpose of the tests was to compare, after each set of changes, the time required to reassess the distance between documents using the same method as for the initial clustering \(i.e. full pair-wise comparison of the XML documents\ to the time of reassessing each distance using the method proposed in this paper and formulas in Definitions 5a, 5b and 5c  Figure 6 Test results for 50kB doc \(part 1  We show in Figures 6, 7, 8 and 9 some of the obtained results. They demonstrate clearly that our proposed technique to reassess the distances in dynamic XML clusters is much faster than performing a full pair-wise comparison on all new versions of the clustered documents. This can be explained by our technique: \(i\rforming only a minimum number of calculations and \(b\ reassessing distances only for those pairs of XML documents where at least one of them has changed Figure 8 Test results for 20kB doc \(part 1    Figure 9 Test results for 20kB doc \(part 2   Also, from Figures 6, 7, 8 and 9 it can be noticed that the difference between the full pair-wise and our proposed technique is more evident for higher number of documents modified or for higher percentages of changes applied                  V arious number of medium-sized documents \(50kB affected by 10% changes 0 20 40 60 80 100 51020 number of documents time\(second s    pair-w ise f ull comparison   proposed reassessing technique                50 small-sized documents \(20kB\ affected by various percentages of changes 0 50 100 150 10 20 50 percentage of change time\(second s    pair-w ise f ull comparison   proposed reassessing technique                  20 medium-sized documents \(50kB\ affected by various percentages of changes 0 50 100 150 3 5 10 25 percentage of change time\(second s    pair-w ise f ull comparison   proposed reassessing technique              V ar ious number of small documents \(20kB\ affected by 15% changes 0 10 20 30 40 50 60 51020 number of documents time\(second s    pair-w ise f ull comparison   proposed reassessing technique  
End if 
002 
37 prune edge D i 222 C\222={C 1 222,C 2 222,\205C n\222 222  ______________________________  
 Figure 7 Test results for 50kB doc \(part 2   
39 D i 222,D j 222 40 
 
Next 
455 
455 


 7. Conclusions  In this paper we have proposed an intelligent and efficient technique to reassess the distances between dynamic XML documents when one or all of the initially clustered documents have changed. After the changes, the initial clustering solution might become obsolete - the distances between clustered XML documents might have changed more or less depending on the degree of modifications \(insert update, delete\hich have been applied. Re-running full pair-wise comparisons on the entire set of modified documents is not a viable option, because of the large number of redundant operations involved Our proposed technique allows the user to reassess the pair-wise XML document distances, not by fully comparing each new pair of versions in the clustering solution, but by determining the effect of the temporal changes on the previously known distances between them. This approach is both time and I/O effective, as the number of operations involved in distance reassessing is greatly reduced  References  1  Beringer, J. and H\374llermeier, E., Online clustering of parallel data streams Data and Knowledge Engineering 58\(2\,  2006, 180-204 2  Catania, B. and Maddalena A., A Clustering Approach for XML Linked Documents, Proceedings of the 13th International Workshop on Database and Expert Systems Applications \(DEXA\22202\, IEEE 2002 3  Chen, M.S., Han, J. and Yu, P., Data Mining: An Overview from Database Perspective, IEEE Transactions on Knowledge and Data Engineering vol. 8, 1996, 866-883 4  Cormen, T., Leiserson, C. and Rivest, R Introduction to algorithms, MIT Press, 1990 5  Costa, G., Manco, G., Ortale, R. and Tagarelli, A., A tree-based Approach to Clustering XML documents by Structure, PAKDD 2004, LNAI 3202, 137-148 Springer 2004 6  Dalamagas, T., Cheng, T., Winkel, K.J. and Sellis, T 2004, Clustering XML documents by Structure SETN 2004, LNAI 3025, 112-121, Springer 2004 7  Ester, M., Kriegel, H.P., Sander, J., Wimmer,M. and Xu, X., Incremental Clustering for Mining in a Data Warehousing Environment, Proc.of the 24 th VLDB Conference, New York, USA, 1998 8  Garofalakis, M., Rastogi, R., Seshadri, S. And Shim K., Data Mining and the Web: Past, Present and Future Proceedings of WIDM 99 Kansas, US, ACM 1999 9  Mignet, L., Barbosa, D. and Veltri, P., The XML web : a first study, In Proceedings of the 12 th  International Conference on WWW, 500-510 2003   Nayak, R., Xu, S., XCLS: A Fast and Effective Clustering Algorithm for Heterogeneous XML Documents, In Proceedings of the 10 th Pacific-Asia Conference on Advances in Knowledge Discovery and Data Mining, Singapore, LNCS 3918, 2006   Rusu, L.I., Rahayu, W. and Taniar, D., A methodology for Building XML Data Warehouses International Journal of Data warehousing Mining, 1\(2 67-92, 2005   Rusu, L.I., Rahayu, W. and Taniar D.,  Maintaining Versions of Dynamic XML Documents, In Proceedings of the 6th International Conference on Web Information Systems Engineering, New York NY, USA, November 20-22, 2005, LNCS 3806   Rusu, L.I., Rahayu, W. and Taniar, D., Warehousing Dynamic XML Documents, In Proceedings of the 8 th  International Conference on Data Warehousing and Knowledge Discovery \(DaWaK 2006 LNCS 4081 Springer, 175-184, 2006   Shen, Y. and Wang, B., Clustering Schemaless XML documents, CoopIS / DOA/ODBASE 2003, LNCS 2888, 767-784, Springer 2003   Yoon, J. P., Raghavan, V., Chakilam, V., and Kerschberg, L., BitCube: A Three-Dimensional Bitmap Indexing for XML Documents J. Intel. Inf Syst 17, 2-3 \(Dec. 2001\, 241-254   XML data repository, online at http www.cs.washington.edu / research / projects / xmltk xmldata  
456 
456 


5 Related Work There exists extensive previous work on both the mining of software repositories and on the use of clustering algorithms in software engineering This discussion focuses on the most similar and recent work in the area of software evolution Mining Software Repositories Our technique was partially inspired by the work of Zimmermann et al and Y ing et al 17 on the mining of association rules in change history As described in Section 1 we sought to expand the technique to be able to recommend larger but less precise clusters of elements to guide program navigation Bouktif et al also investigated how to recommend cochanges in software development As opposed to the work cited above Bouktif et al used change patterns instead of association rules Also their approach does not attempt to reconstruct transactions and can consider associated 002les that were changed in different transactions ChangeDistiller is a tool to classify changes in a transaction into 002ne-grained operations e.g addition of a method declaration and determines how strongly the change impacts other source code entities Our approach uses similar repository analysis techniques but is focused on providing task-related information as opposed to an overall assessment of a system's evolution Finally repository mining can also be used to detect aspects in the code In this conte xt aspects are recurring sets of changed elements that exhibit a regular structure Aspects differ from the clusters we detect in the regular structure they exhibit which may not necessarily align with the code that is investigated as part of change tasks Clustering Analysis The classical application of clustering for reverse engineering involves grouping software entities based on an analysis of various relations between pairs of entities of a given version of the system Despite its long and rich history  e xperimentation with this approach continues to this day For example Andreopoulos et al combined static and dynamic information K uhn et al used a te xtual similarity measure as the clustering relation and Christl et al used clustering to assist iterative semi-automated reverse engineering The main dif ferences b e tween most clusteringbased reverse engineering techniques and the subject of our investigation is that the entities we cluster are transactions rather than software entities in a single version of a system For this reason our analysis is based strictly on the evolving parts of the system Both Kothari et al and V an ya et al 15 recently reported on their use of clustering to study the evolution of software systems The idea of using change clusters is the same in both works and ours but the purpose of the work is different Kothari et al use change clusters to uncover the types of changes that happened e.g feature addition maintenance etc during the history of a software system Vanya et al use change clusters which they call evolutionary clusters to guide the partitioning of a system that would increase the likelihood that the parts of the system would evolve independently In contrast we cluster transactions based on overlapping elements not 002les to recommend clusters to support program navigation as opposed to architectural-level assessment of the system Finally Hassan and Holt evaluated on 002ve open source systems the performance of several methods to indicate elements that should be modi\002ed together This study found that using historical co-change information as opposed to using simple static analysis or code layout offered the best results in terms of recall and precision The authors then tried to improve the results using 002ltering heuristics and found that keeping only the most frequently cochanged entities yielded the best results As opposed to our approach the evaluated 002ltering heuristics were only applied on entities recovered using association rules and not using clustering techniques The focus of their study was also more speci\002c as they recommend program elements that were strictly changed  as opposed to recommending elements that might be inspected by developers 6 Conclusion Developers often need to discover code that has been navigated in the past We investigated to what extent we can bene\002t from change clusters to guide program navigation We de\002ned change clusters as groups of elements that were part of transactions or change sets that had elements in common Our analysis of close to 12 years of software change data for a total of seven different open-source systems revealed that less than 12 of the changes we studied could have bene\002ted from change clusters We conclude that further efforts should thus focus on maximizing the quality of the match between the current task and past transactions rather than 002nding many potential matches Our study has already helped us in this goal by providing reliable evidence of the effectiveness of some 002ltering heuristics and useful insights for the development of additional heuristics Acknowledgments The authors thank Emily Hill and Jos  e Correa for their advice on the statistical tests and the anonymous reviewers for their helpful suggestions This work was supported by NSERC 
25 
25 
25 
25 
25 


References  B Andreopoulos A An V  Tzerpos and X W ang Multiple layer clustering of large software systems In Proc 12th Working Conf on Reverse Engineering  pages 79ñ88 2005  S Bouktif Y G Gu  eh  eneuc and G Antoniol Extracting change-patterns from cvs repositories In Proc 13th Working Conf on Reverse Engineering  pages 221ñ230 2006  S Breu and T  Zimmermann Mining aspects from v ersion history In Proc 21st IEEE/ACM Int'l Conf on Automated Software Engineering  pages 221ñ230 2006  A Christl R K oschk e and M.-A Store y  Equipping the re\003exion method with automated clustering In Proc 12th Working Conf on Reverse Engineering  pages 89ñ98 2005  D 020 Cubrani  c G C Murphy J Singer and K S Booth Hipikat A project memory for software development IEEE Transactions on Software Engineering  31\(6 465 2005  B Fluri and H C Gall Classifyi ng change types for qualifying change couplings In Proc 14th IEEE Int'l Conf on Program Comprehension  pages 35ñ45 2006  A E Hassan and R C Holt Replaying de v elopment history to assess the effectiveness of change propagation tools Empirical Software Engineering  11\(3 2006  D H Hutchens and V  R Basili System s tructure analysis Clustering with data bindings IEEE Transactions on Software Engineering  11\(8 1985  D Janzen and K De V older Na vig ating and querying code without getting lost In Proc 2nd Int'l Conf on AspectOriented Software Development  pages 178ñ187 2003  J K ot hari T  Denton A Shok ouf andeh S Mancoridis and A E Hassan Studying the evolution of software systems using change clusters In Proc 14th IEEE Int'l Conf on Program Comprehension  pages 46ñ55 2006  A K uhn S Ducasse and T  G  021rba Enriching reverse engineering with semantic clustering In Proc 12th Working Conf on Reverse Engineering  pages 133ñ142 2005  M P  Robillard T opology analysis of softw are dependencies ACM Transactions on Software Engineering and Methodology  2008 To appear  M P  Robillard and P  Mangg ala Reusing program in v estigation knowledge for code understanding In Proc 16th IEEE Int'l Conf on Program Comprehension  pages 202 211 2008  J Sillito G Murph y  and K De V older Questions programmers ask during software evolution tasks In Proc 14th ACM SIGSOFT Int'l Symposium on the Foundations of Software Engineering  pages 23ñ34 2006  A V an ya L Ho\003and S Klusener  P  v an de Laar and H van Vliet Assessing software archives with evolutionary clusters In Proc 16th IEEE Int'l Conf on Program Comprehension  pages 192ñ201 2008  N W ilde and M C Scully  Softw are reconnaissance Mapping program features to code Software Maintenance Research and Practice  7:49ñ62 1995  A T  Y ing G C Murph y  R Ng and M C Chu-Carroll Predicting source code changes by mining change history IEEE Transactions on Software Engineering  30\(9 586 2004  A Zeller  The future of programming en vironments Integration synergy and assistance In Proceedings of the 29th International Conference on Software Engineering The Future of Software Engineering  pages 316ñ325 2007  T  Zimmermann and P  W eiﬂgerber  Preprocessing C VS data for 002ne-grained analysis In Proc 1st Int'l Workshop on Mining Software Repositories  pages 2ñ6 May 2004  T  Zimmermann P  W eiﬂgerber  S Diehl and A Zeller  Mining version histories to guide software changes In Proc 26th ACM/IEEE Int'l Conf on Software Engineering  pages 563ñ572 2004 A Clustering Algorithm This algorithm is not sensitive to whether a given program element exists or not in a given version of a program For example if method m exists in one version it is considered a valid program element even if it is removed in a later version In the rest of this section we use the term program element to refer to the uniquely identifying representation of the element e.g a Java fully-quali\002ed name Let T be a transaction modeled as a set of program elements changed together during the history of a software system Let T be a sequence of transactions In this algorithm a cluster is also modeled as a set of elements 1 Input  T  A sequence of transactions 2 Parameter  M IN O VERLAP  A positive non-zero value indicating the minimum overlap between two transactions in a cluster 3 Var  C  A set of clusters initially empty 4 for all T i 2 T do 5 MaxOverlap  0 6 MaxIndex  000 1 7 for all C j 2 C do 8 if j C j  T i j  MaxOverlap then 9 MaxOverlap  j C j  T i j 10 MaxIndex  j 11 end if 12 end for 13 if MaxIndex   0  MaxOverlap 025 M IN O VERLAP  then 14 C MaxIndex   C MaxIndex  T i  15 else 16 NewCluster  T i 17 C  C  f NewCluster g 18 end if 19 end for 20 return C B Systems Analyzed System home pages last veri\002ed 7 May 2008 Ant ant.apache.org Azureus azureus.sourceforge.net Hibernate www.hibernate.org JDT-Core www.eclipse.org/jdt/core JDT-UI www.eclipse.org/jdt/ui Spring springframework.org Xerces xerces.apache.org 
26 
26 
26 
26 
26 


