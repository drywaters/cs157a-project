Intelligent Avionics with Advanced Clustering  John Meier Boeing Corporation Saint Louis MO 63166 USA Email:john.l.meier@boeing.com Todd Sproull and G Adam Covington and John W Lockwood Department of Computer Science and Engineering Washington University in Saint Louis St Louis MO 63130 USA f todd,gac1,lockwood g arl.wustl.edu Abstract In this paper we consider tracking targets using multiple distributed sensor platforms Rather than sendin g the tracks to a central location such as a command and control center where information is exchanged between platforms 
we consider a distributed solution While xed position single sensor tracking of a single target is considered straigh tforward multiple sensors on the different platforms with over lapping coverage is complex because duplicate tracking dat a is generated for the same targets Redundant information ge nerates network messages that in turn overload the network performance and may result in trafc congestion on limited avionic bandwidth wireless links that prevents time critic al data from reaching its destination In our approach we iden tify similar tracking data to be distributed and send only on e copy of the message In order to identify redundant data we use a clustering al 
gorithm to evaluate the large volumes of sensor information  Distributed multiple target tracking MTT combines track observations from different sensors to identify the same ta rget Massive computation and communication is required for distributed real time MTT In this paper the K-means cluste ring algorithm is used to aggregate redundant tracks Softwa re simulations using Matlab and emulation tests using Emulab show signicant improvement of the information quality by using clustering An MTT system was prototyped with FPGA hardware to cluster high volumes of data with low latency in real time at the network layer T ABLE OF 
C ONTENTS 1 I NTRODUCTION                                    1 2 C LUSTERING AND C LASSIFICATION              2 3 R ELATED W ORK                                   2 4 T RACK C LUSTERING A LGORITHM                3 5 ANALYSIS                                          4 6 E XPERIMENTATION                                6 7 H ARDWARE A RCHITECTURE                      8 8 H ARDWARE D ESIGN                               8 This work was funded by a research grant from the Boeing Corpo 
ration 1-4244-0525-4/07/$20.00 c r 2008 IEEE IEEEAC paper 1669 Version 4 Updated October 20 2007 9 C LUSTERING O BSERVATION D ATA                9 10H ARDWARE F ABRICATION                         10 11C ONCLUSIONS                                     10 12F UTURE W ORK                                    10 R EFERENCES                                      11 B IOGRAPHY                                        11 1 I NTRODUCTION Commercial and military aerospace use multiple sensors on a variety of platforms today to track targets Sensor data is 
partitioned into sets of observations or tracks that prov ide a time and distance history of target location Track data is then processed to identify the number of targets and identif y key metrics including velocity future predicted position  and target type Avionic networks interconnect numerous senso rs that generate a large volume of data Communication bandwidth is a valuable resource that must be used wisely to track targets effectively Multiple Target Tracking MTT must l ocate and identify targets quickly Existing MTT detection classication and tracking algorithms work well on a single platform Centralized data fu 
sion collects data from multiple sensors Rather than imple ment another centralized algorithm we consider technique s for distributed algorithms to regulate communication for d istributed track fusion Multiple platform sensor MTT systems need to gate and correlate a target's parameters position range rate veloci ty and acceleration 1  O u r a p p r o a c h u s e s c l u s t e r i n g t o a s s o c i a te MTT data for distributed tracking based on scenarios such as the one depicted in Figure 1 We evaluate the cost and benet of distributing track data between nodes with sensor s for improving situational assessment SA Track data ob 
servations are distributed using shared bandwidth betwee n platforms to improve SA Clustering improves SA by providing improved data association Clustering results in pr ioritization of network data conservation of bandwidth and lowering the track fusion latency Traditional methods to d istribute track observations often load the existing bandwid th beyond the channel capacity resulting in information laten cy and loss Figure 1 illustrates that multiple sensors report their 1 


observations of every target within range depicted as circ les Our scenario has multiple targets moving in dened patterns within range of multiple sensors to assess scalability Sensor 1 Sensor 2 Targets Pattern 2 1 3 4 Figure 1  Targets are simultaneously tracked by multiple sensors Real time SA requires improved dynamic exchange of sensor observations which often generates duplicate data for targ ets located in overlapping coverage which cause network overload It is critical to select only the best information to se nd over the limited bandwidth Lossless compression techniqu es are not effective in tting all the information within the li mited bandwidth for large scale systems Clustering intelli gently groups track messages autonomously in real-time to use available bandwidth with the highest priority track dat a Our goal is to reduce the number of tracks exchanged while retaining information quality The effectiveness of using our clustering algorithm operating in a distributed environme nt was proven using large-scale Emulab experiments 2 C LUSTERING AND C LASSIFICATION Clustering algorithms help to group data at discrete update points The measurement of the data to be clustered is dened as the distance metric We evaluated Manhattan Euclidian and Chebyshev distance algorithms for use with the K-means clustering algorithm Our distributed MTT cluster ing algorithm uses Manhattan distance with a modied Kmeans algorithm to nd centroids of the clusters of tracking data Classication of data identies which data is similar when prior information about a centroid is known A centroid is the representation of the target's predicted position base d on the density of targets The centroid is adjusted at discrete times to predict the target location Track data is sorted an d clustered for each target Target data is stored in a table as shown in Figure 2 as the track state for clustering Observations received at different times t1,t2 t3 are compa red to the projected centroid of each track or cluster stored Velo city and position data is used to associate the new observatio ns received with the appropriate track or clusters stored Our MTT track clustering algorithm calculates the distance s between tracks and projected target positions associated w ith the tracks centroid The algorithm identies whether the incoming track maps to an existing centroid then either update s the centroid or creates a new cluster for the incoming track Finally the algorithm then determines if the track should b e used only at a local node or sent to other nodes The traditional K means algorithm requires specifying the number of clusters Since we never know exactly the number of targets being tracked applying traditional cluster ing algorithms is impossible We evaluated multiple clusterin g and distance algorithms for improved track data associatio n and bandwidth matching using Matlab The thresholds were adjusted to match the MTT track gating The results provided clustering design and development constraints used in simu lation emulation and hardware evaluation To minimize the latency required to cluster data and to maximize throughput of the target tracking algorithm we implemented a clustering algorithm in Field Programmable Gate Array FPGA technology to parallelize the processing The main three hardware modules that were prototyped include Track Cluster Time Compare and Update The Track Cluster module calculates the Euclidian distance and maintains a list of current clusters/tracks The Time Compare module determines the priority and whether to send or aggregate the data The Update module computes the projection of the target centroid for clustering the track data and passes t he projection of the Track Cluster module to be stored The prototype modules are demonstrated using an open platform called the NetFPGA The NetFPGA processes real time MTT data as it is received in real time over a network Hardware achieved a signicant improvement over traditional softwa re processing methods Our parallel hardware design can perform 4 simultaneous distance metric measurements with up to 100 simultaneous tracks operating at a clock speed of 125 MHz The total time required for distance calculations assignment determination and updates requires 0.904  s for each incoming track which creates a real time throughput of approximately 1.1 million packets per second 3 R ELATED W ORK Target tracking includes data association and track lteri ng Data association receives observations and must assign the m to existing tracks Correct association is difcult becaus e the targets may be closely spaced together or located between tracks Sensor measurements of the targets may be imprecise due to measurement resolution noise and other error sources Many data association algorithms have been presented 2  3  f o r g r o u p c l u s t e r i n g a n d t a r g e t c l u s t e r i n g b u t few leverage recent advancements in data clustering tech2 


2 Cluster 1 Cluster 2 Cluster 3  Cluster n 6 1 3 Position Velocity x y vx vy 0 0 3 4 12 34 8 2     56 2 14 12 Cluster Table 0 0 3 4 0 0 3 4 56 4 3 4 56 4 3 4 11 31 2 1 11 31 2 1 Time t 1 Time t 2 Time t 3 Incoming Tracks Figure 2  Tracks mapped into L dimensional vectors are clustered into groups of current tr acks nology for improving bandwidth usage Older methods use Nearest Neighbor NN algorithms that make decisions as the data arrives while newer methods delay decisions by stor ing the data used in Multiple Hypothesis Tracking MHT Our clustering methods use NN algorithms for data association Modern radar systems often use the Suboptimal Nearest Neighbor SNN algorithm while the Global Nearest Neighbor GNN has recently been proposed Often multiple closely spaced aircraft are grouped together and mistaken f or a single target The GNN approach has demonstrated very reliable results for modern radar systems when contrasted wit h SNN Clustering has been used in two ways for tracking in the literature Target clustering groups similar data elements or observations together to form a track usually without prio r knowledge Group clustering typically computes a locatio n and velocity centroid of a large number of closely spaced tar gets moving in the same direction in order to reduce the track data transferred system loading and miscorrelation Tar get clustering is the application we are addressing Target clustering automates the target track gating and dis tribution of tracks Current radar monopulse tracking methods have trouble handling multiple unresolved targets within t he beamwidth which creates distortion by averaging the target measurements into a group centroid Proper setup of thresholds improves correct classication and sorting of data to reduce miscorrelation Clustering algorithms use similar ity measurements known as the distance The distance is computed from observations to centroids Normally centroids represent the average of grouped data elements however we project the last observation to the temporal-space for the d iscrete time interval needed to match the bandwidth available  Clustering applied to distributed fusion using avionic net works is a novel application Image and text based clusterin g was the basis which formed our current approach The two main forms of clustering are agglomerative bottom-up and divisive top-down Each approach utilizes a distance met ric that measures the difference between two elements Agglomerative clustering treats every data element as a separate c luster and merges clusters if they exhibit similar distance met rics Divisive clustering starts with all data elements in t he same cluster and partitions them into different clusters ba sed on the distance metric Both forms of clustering are describ ed in 4 a s i t a p p l i e s t o h i e r a r c h i c a l d o c u m e n t c l u s t e r i n g u s i ng the K-means algorithm The original K-means algorithm was described by Duba and Hart 5 a n d h a s b e e n u s e d b y E s t l i c k e t a l   6  a n d L e s s e r e t al 7 t o i m p l e m e n t a h a r d w a r e a p p r o a c h o f K m e a n s c l u s t e r ing for hypersectral images They 7 c o m p a r e d t h r e e d i f f e r ent distance metrics that included Manhattan Euclidean and Max distances They determined that the Manhattan distance would be the best t for their hardware Covington et al 8 showed the implementation of K-means mapped into integer arithmetic They utilized a Cosine Theta distance metric si nce this metric also known as the spherical distance provides a better distance in high dimensional sparse data Spectral Clustering is another algorithm that has been used to cluster data vectors This algorithm provides an effecti ve method to cluster sparse high dimensional data sets A spectral clustering algorithm described by Ng et al 9 c a l c u lates the top features or dimensions to cluster by calculati ng and selecting the top eigenvectors to cluster The heart of t he algorithm described used K-means to cluster the top eigenvectors 4 T RACK C LUSTERING A LGORITHM Most clustering algorithms operate on a xed set of data and are commonly iterative Every cycle a data element is selected and is moved to the cluster that is determined to be the best t by the distance metric The clustering algorithm use d to cluster track data differs from these cyclical algorithm s Since the clusters represent known tracks that could move the incoming track data can only be clustered once The track clustering also utilizes a cluster threshold to determine i f a track is close enough to be included in a cluster This is an important addition to the algorithm The cluster threshold allows the creation of new clusters when tracks are signicant ly distant from existing clusters The algorithm for track clustering operates as follows 3 


1 Calculate distances from incoming observation to centroids 2 Determine if there is a centroid C min close enough to have a distance below the cluster threshold a If C min exists assign track  t to centroid and update the position of C min based on the velocity b If C min does not exist add the track  t as a new track Although there are numerous distance metrics that can be used for clustering this work utilizes the Manhattan dista nce metric Manhattan Distance The Manhattan distance or city block distance provides th e absolute distance between two data elements In a two dimensional grid the calculation totals the absolute value of the difference between the vector elements Given the example shown in Figure 3 the Manhattan distance is nine 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 9 8 0 1 2 3 4 5 6 7 9 8 A B 3 6 Figure 3  Manhattan Distance calculation in two dimensions j A x B x j  j A y B y j  j 4 7 j  j 3 9 j  3  6  9 M anhattanDistance  X i 2 0 N  1 j  A i   B i j 1 5 ANALYSIS The major challenge faced by distributed multi-target trac k MTT fusion is choosing the right information to send at the right time over severely limited bandwidth links to construct a scalable unied picture that will enhance situatio nal awareness SA MTT employs one or more sensors together with computing resources to interpret the environment bas ed on a series of measurements MTT partitions sets of measurements observations or tracks for object representat ions in space and time Target prioritization missiles aircra ft trucks ships is critical to correctly assess the environm ent in real time This research creates a more intelligent inter face between the application fusion and the network distribu tion of observations to reduce latency while increasing the val ue of information transferred Fundamentally we reduce laten cy and preserve bandwidth by adding intelligence at the networ k layer that is able to make real time decisions The future SA technology trends use distributed fusion to in crease track accuracy and reduce latency in acquiring a common operating picture Today centralized fusion is usually accomplished at the application level and relies on the network to transfer all observations The fusion application h as very limited visibility into the network layer Operating a t the network layer more effectively is critical to distribut ing the many observations required for centralized fusion or di stributed fusion Distributed fusion runs multiple copies o f the fusion algorithms at local nodes near the edge of the network and relies on efcient transfer of the right data The problem is difcult due to the many constraints such as unreliable wireless transport limited processing power a t the edge and the use of multiple legacy wireless communication links with low throughput There are many solutions devised to overcome unreliable transport in wireless networks however the associated overhead and latency limit their effect iveness Limited edge processing makes running the fusion algo rithms at distributed nodes difcult Typical avionic wire less links offer less than 100 Kbps while the offered load for larg e distributed fusion is 100 Mbps or more Large packet latency or out of sequence packets often result in information delet ion by the fusion algorithms at the application layer Recognition of the inappropriate transfer of data will save bandwid th and result in less processing cycles wasted We hypothesize that better use of network resources can help to improve distributed fusion performance Theoretically each distributed node uses an identical fus ion engine to evaluate every track observation which should gen erate exactly the same SA picture We realize that it is impos sible for every node to be sent and process every track observation to develop exactly the same operation picture Reduc tion of data and preservation of the required processing cyc les is critical to developing a realistic solution for improvin g SA Two main types of distributed track fusion messages are used to initialize and update current tracks There is a time during initialization where multiple distributed nodes have s eparate identiers for new tracks detected however the goal is to quickly converge to a unique identier used by all sensors on different platforms tracking the same target Each track should be assigned a unique identication ID soon af ter initialization occurs Our solution does not depend on a unique identier assigned but will use it if provided Distributed track observations also contain position veloci ty and relative time of the measurement information There are scalability problems with distributing every tra ck observation to all nodes Recently the MTT application trie s to perform network layer functions at the application layer  This approach creates real time performance issues demand s 4 


signicant increases in processing presents optimal band width usage challenges limits key access to network management parameters and adds latency due to large queues buffering network packets Our novel research evaluates us ing clustering to reduce or eliminate these problems Traditional information theory was evaluated to help map th e track observations to queuing decisions for more efcient bandwidth allocation In our approach the goal is to identify similar tracking data to be distributed and send only on e copy of the message Shannon 10 d i s c u s s e d  G E O M E T RICAL REPRESENTATION OF MESSAGES to represent messages in multiple dimensions more efciently Eliminat ing message redundancy can happen by simply recognizing different information in the same message that is not necessary for recreation of the information being transferred S hannon proposes improved mapping of higher levels to lower levels of communication for more efcient transfers Intel ligent reconstruction by the source and receiver can provid e the improved mapping by eliminating messages or information normally sent In the case of distributed tracks the fu sion algorithms are insensitive to a certain amount of variation in distance known as tracking error 1  M e a n a n d v a r i a n c e o f the tracking error are used for calculating the dispersion m atrix variance and covariances of x,y positions of members for a group of track observations MTT uses variations of the dispersion matrix to identify the associated tracks estim ate the position of target We evaluate the impact of improvements to the lower level queuing using higher level geometri c methods similar to the example provided by Shannon 10  We evaluated changes relative to the true track path or shape generated relative to the track constructed from the data se nt over bandwidth limited links The challenge is to provide th e information required for accurate tracking while selectiv ely eliminating redundant or unnecessary information to match the bandwidth capacity available Our solution adds intell igence between the source and receiver to make difcult real time decisions at the network level to increase the value of information and improve network quality of service QoS Messages differing by only a slight variation of measurement to a limited extent represent nearly the same information and offer an opportunity to eliminate redundant information This may also reduce the number of dimensions in the current message space Track observations which are considered equivalent by the destinations receivers of tr ack observations can be grouped together and treated as one point or a reduced set of key observations Equivalency is evaluated by assessing the relative closeness of the observ ation to the projected centroid We propose that this grouping method requires fewer messages to specify one of these equivalence classes dened as we cluster the track observations rather than sending sequential non-prioritized obse rvations For example we use a two-dimensional space to indicate the value of this method by comparing normal tail drop network queuing with clustering Simulated targets a re controlled and y in a square pattern of known dimension to simplify assessing any perturbation observed The deviati on in target tracking shape represented by the series of obser vations are quantied relative to area differences of the sha pe We compare the known area generated by the simulation target ying in a square to the area constructed based on the limited observations sent Our clustering approach for distributed fusion uses both sp acial and temporal methods to evaluate equivalence We adjust clustering thresholds to prioritize the information s ent to other nodes Distance methods such as Manhattan or Euclidean distance compare the distance from the centroid to the observations If all observations are evenly spaced on a circle around the centroid they can be regarded as equivalent and theoretically can be reduced to a one-dimensional space or point We extend this specic example representing points track observations within the circle as key messag es to be sent at higher priority The radius of this circle is de ned by the clustering threshold We preserve state by storing ea ch target's most recent track observation sent for centroid pr ojection The spacial method described above clusters based on distance We rst project the centroid using information shown in Figure 2 and the following equation Centroid  stored  X Y  timeinc    currentvelocity  2 Second the distance from the observation to the projected centroid is calculated Third if the distance is less than t he clustering threshold the observation is sent Currently t he clustering threshold is set based on empirical data however dynamic methods are planned for future implementations Temporal methods simply evaluate velocity to prioritize th e observations and then select the correct update rates The three priority levels are high e.g missiles traveling at M ach 2 or higher medium e.g aircraft traveling between Mach an d Mach 2 and low e.g trucks ships traveling below Mach 1 We plan to use an adaptive weighting factor that will be adjusted relative to the proximity target turn radius a nd threat level represented by the target Based on experience  the update rates for the high priority is set at 6 hertz mediu m priority is set to 4 hertz and low priority is set to 2 hertz Our temporal algorithm compares the relative system time associated with last observations sent to decide whether th e current observation should be sent The update rate is varied based on the priority level of the target The observation won't be sent unless the update rate set for the target ha s been exceeded even if the observation is below the clusteri ng threshold close to the centroid Currently the spacial an d temporal algorithms operate independently but are sequentially dependent as indicated We evaluated a severely constrained bursty link with a small tail drop queue traditional network QoS contrasted with a zero length queue clustering to assess effectiveness Qu eue 5 


length helps to absorb variations in link bit rate but adds la tency Clustering adjusts the sending bit rate by using FPGA hardware to make real time decisions resulting in only very small hardware latency Figure 4 below shows projections based on Matlab simulations of the improved performance offered by intelligent clustering methods contrasted with tr aditional queuing methods using graphical evaluation techniq ues described above This illustrates that effective operatio n may occur with clustering at much lower bandwidths than traditional methods Figure 5 illustrates a modied target track ing pattern difference due to loss of critical data The area rep resented by the reduced data set has reduced area as expected Signicant area reductions occur depending on the randomness of the queue burstyness of the data and redundancy of the target pattern 0 20 40 60 80 100 0 10 20 30 40 50 60 70 80 90 100 Bandwidth \(percent Area \(percent   Clustering Queuing Figure 4  Value of information example 0 1 2 3 4 5 6 7 8 0 1 2 3 4 5 6 7 8 9 Distance in X dimension \(KM Distance in Y dimension \(KM   Received Target Observations Ideal Target Generation Figure 5  Area difference example representing information value The queuing solutions today are widely used Our Matlab simulations take into account the bursty nature of wireless links and the loss of critical updates for short periods of ti me as noted in Figure 5 The ideal target pattern shown as a square true representation is represented as a distorted parallelogram to illustrate the change in area The representa tion remains distorted until a large percentage of the bandwidth required is available as illustrated in Figure 4 The cluste ring solution is shown to provide increased information content with reduced bandwidth and latency 6 E XPERIMENTATION Software Clustering This section describes experiments to determine the latenc y related to available link capacity and use of software to clu ster the track observations The rst set of experiments inve stigated the amount of latency experienced by a single node receiving track data This experiment inserted a time stamp on packets leaving the sender The receiver then compares the packet time stamp against its current time The network time protocol NTP was used to synchronize clocks on all machines in the experiment Each node sent sensor track data to all other nodes in the network using IP Multicast A track generator application provided by Boeing created the tracks with the exibility to gen erate diverse patterns or shapes The software creates targ ets of interest and records their position as they change over ti me based on the pattern selected Modications were made to the track data generation software to provide simple X Y coordinates and X,Y velocities The track data also contained an identier eld describing the type of track data and packe t length Figure 7 contains the graph demonstrating an increased latency experienced at the gateway GW node for track data The gateway node has the ability to process the data at the network level between when it is received at the input port and routed to the output port As the networks grows from 10 to 68 nodes the amount of track data increases as well as the latency for a single track to be processed The maximum latency varied from 109 to 260ms as the number of nodes increased The average latency ranged only from 103 to 109ms Total Network Traffic 0 10000 20000 30000 40000 50000 60000 70000 80000 90000 100000 10 25 50 75 Number of Nodes Total Bandwidth \(MBytes JXTA Multicast JAVA IP Multicast JAVA IP Broadcast Figure 6  Bandwidth Costs for Distributing Track Data with Different Protocols In the next experiment clustering algorithms are proposed for both software and hardware.The nodes topologies consisted of 25 50 and 75 nodes each sending track data to all nodes in the network including a GW clustering node The GW 6 


Max Delay for a single track 0 50 100 150 200 250 300 10 25 50 68 Number of Nodes Max Delay \(ms Delay Figure 7  Maximum Latency to Receive a packet over a 100ms link clustering node uses a K-means clustering algorithm on each packet in order to identify similar track data Each packet t hat arrives at the GW node is clustered and compared to packets previously clustered If a packet is similar to a one previou sly clustered and recently forwarded to the neighboring networ k it is considered redundant and discarded Figure 8  10 node Emulab Experiment with a Gateway Cluster Node and Neighbor Link Packets sent in and out of Gateway Node 0 50000 100000 150000 200000 250000 300000 350000 400000 450000 500000 25 50 75 Number of Nodes Packets Packets received at Gatew ay Clustered Packets sent out Gatew ay Figure 9  Performance of Clustering Algorithm in Software Packets In Figure 8 the GW node connects to a neighboring network or node Our experiments next deployed a single node connected to the other end of the GW with a 1Mbit/sec link had a latency of 100ms Figure 9 illustrates the number of packets that the gateway node receives and clusters packets that are forwarded The amount of packets it forwards varies from  MBytes sent in and out of Gateway Node  0 10 20 30 40 50 60 70 80 90 100 25 50  75  Number of Nodes MByte  MBytes received at Gateway  MBytes of clustered packets sent  out Gateway  Figure 10  Performance of Clustering Algorithm in Software Mbytes Packet Loss At Gateway Node 0 50000 100000 150000 200000 250000 25 50 75 Number of Nodes Packets Packet sent to Gatew ay but not processed Figure 11  Packet Loss experienced at Gateway Cluster Node due to Software Clustering 1130 to 9400 packets This is a considerable reduction in the network load because the amount of packets it receives and clusters ranges from 187,000 to 435,000 packets Figure 10 displays the amount of bandwidth used in terms of megabytes processed in and out of the gateway node Again signicant reductions in bandwidth are demonstrated using clustering algorithms The incoming amount of data varies from 40 to 90Mbytes with the clustering gateway node reducing the traf c to 1.9 to 2.1 Mbytes This provides an 18 to 48x reduction in bandwidth before traversing to the low capacity neighbor ing link The last experiment performed investigates the amount of packet loss experienced by the software clustering impleme ntation The clustering program was developed in JAVA and executed on a 3 GHz Pentium 4 CPU using a Linux operating system The experiments utilized 100Mbit links with no additional link delay to provide the best case performance Packet loss is due to the slow sequential processing require d for the clustering algorithm Processing compares the clus tered hash value of each incoming packet against the know hash values of the packets in memory As bursts of packets arrived the CPU was unable to investigate all of the packets before buffers overowed Since the track data is assuming the use of an unreliable communication protocol no retrans mission is issued for track data and it is lost The hardware 7 


implementation of this clustering algorithm will not suffe r the same speed limitations of software Hardware maps the clustering algorithm onto an FPGA that allows for signicant parallelism The results of the packet loss at the gateway no de are presented in Figure 11 The number of packets that are unable to be clustered varies from 27,000 to 209,000 packets  Figure 9 illustrates the amount of trafc in and out of the gat eway node The average packet size received at the gateway is 217 bytes Each node generates 9,090 packets In the 75 node example 9090 x 75  681,750 packets are destined for the GW node The GW was only able to receive 434,995 packets and the others were dropped due to an overloaded CPU The total trafc received at the GW was 217  434,995  94,393,915 bytes or approximately 94 Mbytes Figure 6 depicts the amount of trafc generated in the network as the number of nodes increased from 10 to 75 From this gure the JXTA P2P Multicast protocol is the most expensive implementation to distribute trafc to all nodes U sing either IP Multicast or Ethernet Broadcast is signicant ly less expensive From these results the IP Multicast protocol was selected as the protocol to deploy in the software and hardware clustering applications These simulations help ed to demonstrate the problems of deploying the JXTA P2P at the Gateway Cluster Node This protocol would create additional CPU and network load to further degrade the performance of the clustering From Figure 6 the overhead associated with sending the same information using JXTA Multicast required 17 times the total bandwidth This overhead comes from the additional complexity of pushing multicast state information encapsulated with each message using overlays to the application layer Thus it is possible to predict 138,087,788  17  2,347,492,396 bytes or approximately 2.3 Gigabytes of trafc destined for the gateway node if P2P multicast is chosen as the distribution method The GW node would be able to process signicantly less if conventional hardware is used Testing conrms that even a 3 Ghz CPU could not keep up with receiving and clustering of the smaller multicast packets which necessitates the use of FPGA or ASIC technology 7 H ARDWARE A RCHITECTURE Advanced SA requires the use of high speed networks with increased bandwidth to implement centralized track fusion to improve tracking performance Distributed track fusion ca n process the data locally and only exchange key observations to improve SA It is critical to select the correct distance a nd clustering methods to ensure the right data arrives at the ri ght time to the distributed nodes Manhattan distance is used to calculate the distance to the projected target position or centroid This coarse gating  technique is responsible for the majority of the data reduct ion Track prediction is critical to setting the clustering thre shold Selecting the tracks to be clustered is a form of track-t otrack gating The time increment threshold selects the crit ical Figure 12  The NetFPGA platform used to implement Track Clustering points at which the distance clustering is accomplished As each track observation arrives the algorithms rst extr apolates each stored source track forward using the velocity a nd time increment Second the distance to each projected centroid is compared to correctly associate the data with the co rrect track or cluster If the distance calculated is less tha n the clustering threshold the new observation will be selected as critical data for fusion The update rate is also checked to ensure the most critical data is prioritized then sent Highly parallel state machine hardware implemented the algorithms above using the NetFPGA platform The NetFPGA is an open source project that allows researchers to develop network applications and systems 11  D e v e l o p e d p r o j e c t s include Secure Switches Ethane 12  R o u t e r s  a n d R a t e Control Protocol RCP 13  For the development of network solutions the NetFPGA contains a Xilinx Virtex-II Pro FPGA The board also contains a Double Data Rate DDR2 SDRAM device two SRAM devices two serial ATA SATA connectors and a quad-port physical-layer transceiver The NetFPGA library provides a Verilog template for design that interfaces to the memory de vices and the network interfaces 11  8 H ARDWARE D ESIGN The track clustering algorithm performs four primary opera tions 1 calculating the distances between observations a nd centroids 2 identifying if the incoming observation map s to an existing centroid 3 updating the centroid or creating a new cluster and 4 determining if the track should be dropped or sent based on the timetable The hardware implementation is comprised of three primary modules Track Cluster Time Compare and Update In addition to these modules control modules were needed to load and run the hardware clustering system Figure 13 shows the architectu re of the track clustering system Time Stamp As the track data enters the system it is provided with a time stamp The time compare module uses the 32-bit time stamp to determine if the track should dropped or sent based on the 8 


Update Control Processor Track Cluster Accept Time Compare Time Stamp Report Figure 13  Hardware Track Clustering Block Diagram dened update rates set by the time threshold Track Cluster A set of smaller modules comprise the track cluster function  The rst module calculates the distance and is designed in a modular fashion so that it can be replaced with diverse metrics implemented in hardware The Manhattan distance calculation is replicated in parallel to evaluate multiple dis tances simultaneously The second component is the cluster table The cluster table maintains a list of current clusters/tracks locally on the F PGA chip The centroids of the clusters represent the projected position of the track for prioritization This projected posi tion determines if an incoming track matches a cluster The calculated parallel distances are passed to the accept module t o make the critical decision to forward the data Accept The accept module compares all parallel distances to a clust er threshold If the distance is less than the cluster threshol d the module will assign the incoming track to the specied cluste r The module will not assign the incoming track if the distance s are greater than the cluster threshold If this occurs the s ystem currently decides the incoming track is a new cluster and will specify that a new entry needs to be added to the cluster table Update After the accept module determines if an assignment is accepted the update module then updates the cluster table Th e update is computed from the velocity information contained in the track data and determines the projected position of th e track The projected position is passed to the cluster table in the track cluster module for storage The accept module determines whether the track is a new track and needs to be added to the set of known clusters The update module will calculate the projection of the track and then send the infor mation to the cluster table to be stored Time Compare The time compare module determines if the track should be dropped or forwarded to downstream modules/systems The module is comprised of a timetable that maintains two time values the last time the cluster/track was reported and the last time a track message was received A time threshold determines if a track message should be sent or aggregated If the difference between the last sent time and the current time is greater than the threshold the data is sent from the node However if the difference is less than the time thresh old the data updates the cluster table however the data is not sent from the node The timetable also contains information regarding the velo city and the accuracy of the incoming track data This data is used in conjunction with the time data to determine whether the system sends or drops the data The velocity information is used to determine the three time categories or priorities of trafc high medium and low 9 C LUSTERING O BSERVATION D ATA The track data is part of the network trafc owing to and from each clustering node Each track observation has a current position and velocity in the xy dimension The clusteri ng system can be expanded into a larger dimensional space although the dimensionality is set to two currently The clustering nodes are interconnected using a network where multiple sensors on different platforms report the sa me track information but may have different accuracies These tracks are similar representations of the same information  but are received at multiple clustering nodes at different t imes due to network traversal The clustering nodes maintain information on the current clusters active tracks and clust er centroids In addition to the position of the track the system uses time stamps to determine the last time a cluster was reported The clustering system uses a modied algorithm similar to K-means In traditional K-means the number of clusters K is set to a specied number We allow the number of clusters to start from zero and expand as new tracks are found The algorithm utilizes two tables to achieve the desired fun ctionality The rst table the cluster table is comprised o f the current clusters that are projections of where the track sho uld be in the next track message As tracks are received they are compared to the clusters using the Manhattan distance If th e distance is less than a threshold cluster threshold the t rack message is assigned to the specied cluster The velocity of the track message updates the projection of the cluster Thi s projection update allows the system to account for tracks th at are not static If the distance from the input track is greate r than the threshold for all the current clusters a new cluste r is added The second table the track time table maintains two times for each cluster the last time a message was sent about that cluster and the last time a message was received about that cluster Since the track data is time stamped when the clus9 


tering system receives the track the system compares the ti me received to the time sent If this time is greater than the tim ing threshold the system will allow the message to pass and update the cluster received time in the table However if th e time is less than the time threshold the system updates the cluster received time and removes the message from the outgoing trafc 10 H ARDWARE F ABRICATION The implementation on the NetFPGA platform was able achieve a clock frequency of 125 MHz The hardware utilization of a track clustering algorithm with four parallel distance metrics is shown in Table 1 With a slice utilization of 44 the number of distance metrics can be increased This increase in parallel distance calculation reduces the late ncy to compare incoming tracks to all known clusters XC2VP50 Utilization Resources Utilization Percentage Slices 10533 out of 23616 44 4-input LUTS 14318 out of 47232 30 Flip Flops 12958 out of 47232 27 Block RAMs 82 out of 232 35 External IOBs 353 out of 692 51 Table 1  Device utilization for XC2VP50 Hardware Track Clustering with four concepts Given our implementation with four parallel distance metri cs with 100 total tracks in the cluster table at any one time we can estimate the total time for clustering an incoming track  The parallel distances can be calculated in four cycles The total number of cycles required to produce all 100 distances would be 100 Since the operation of the clustering circuits are pipelined the accept module would only require three cy cles for determining the correct action to perform The upda te module would require three cycles to perform an update or creation of a new cluster The time table compare takes three cycles Add in an additional four cycles for header processing and we have a total of 113 cycles Since we are running the hardware at 125 Mhz the total time required for distance calculations assignment determination and updates requ ires 0.904  s for each incoming track This gives us an approximate throughput of 1.1 million packets per second 11 C ONCLUSIONS The results show that the real time hardware using the Kmean algorithm for clustering can accurately locate redundant track data for aggregation identify new tracks and se lect the critical tracks to be forwarded to other distributed sen sor nodes for fusing Improvements in the information quality and latency for distributed track fusion were demonstrated using advanced clustering Track data distributed using multicast is shown to generate 2.3 Gigabytes of trafc for large scale 75 nodes fusion Experiments revealed state-of-the-art CPUs could not handle bursts of packets received which resulted in loss of pack ets due to network buffer overow The clustering gateway node was shown to provide an 18 to 48x reduction in bandwidth through eliminating redundant data The results were tested in a distributed environment called Emulab that used a software version of the clustering algorithms State-oftheart Emulab CPUs could not keep up with the track data resulting in network buffer overow and loss of packets This illustrates the need for our special processing solution us ing FPGA technology Real time clustering is implemented in the network layer OS I layer 3 to reduce the bandwidth intelligently while mainta ining high information content Our pipelined hardware desig n calculates four parallel distance metrics for 100 total tra cks in 100 cycles The total time required for distance calculations assignment determination and updates is only 0.904  s for each incoming track The hardware solution is prototyped using the Stanford NetFPGA in the Boeing Center for Intelligent Networked Systems CINS lab Our real time solution preserves Layer 7 resources and decreases latencies The ability to add real time hardware in t he network layer improves MTT performance in bandwidth limited environments ultimately preserving legacy avionic ne twork resources 12 F UTURE W ORK Novel methods to illustrate the increased value of information using clustering over normal queuing methods was constructed based on spatial methods Our use of clustering algorithms was fairly limited with K-means however there are plans to implement solutions based on N-means algorithms in the future We realize selection of the correct clusterin g thresholds must be dynamic based on the separation of target s and is highly dependent on accurately projecting the centro id The relationship between our temporal and spacial clusteri ng algorithms must be integrated into a single solution We pla n to develop dynamic clustering thresholds for more accurate prediction of target paths while selectively reducing the d istribution bandwidth Real time assessment of the information value allows us to dynamically adjust the thresholds fo r preserving the key observations We theorize that changing the update rates proportionally with the target velocity wi ll provide improved information value We also plan to add a weighting factor to take into account proximity sensor acc uracy and threat level will provide a more intelligent soluti on Interconnecting the time increment used in the projection o f the clustering centroid with the temporal target rate will s implify the algorithms and hardware Reliable transfer of data using wireless is available in sev eral avionic systems and will be evaluated as a separate test case Latency will denitely increase if all dropped packet s are transferred as required by reliable transport 10 


Information content is improved by identifying key target characteristics such as turning ratio threat level and mul titarget separation Increasing information content while d ecreasing bandwidth is the goal of the Boeing Intelligent Gat eway BIG being developed BIG is an intelligent gateway that uses a highly parallel state machine to implement a set o f distributed services such as intelligent data association for improving the quality of information with reduced bandwidth R EFERENCES 1 S  S  B l a c k m a n   M u l t i p l e t a r g e t t r a c k i n g w i t h r a d a r a p plications in Artech House  1986 pp 357–395 2 P  K  B  S  Y  C h u m m u n M  R   K i r u b a r a j a n T    F a s t data association using multidimensional assignment with clustering in IEEE trans On Aerospace and Electronic Systems  Vol 37 No 3 2001 pp 898–912 3 S  T  K  P  T c h a m o v a A   D e z e r t J    T a r g e t t r a c k i n g w i t h generalized data assocoation based on the general dsm rule of combinaton in Proceedings of Fusion 2004  Stockholm Sweden 4 M  L o o k s  A  L e v i n e  G  A  C o v i n g t o n  R  P  L o u i  J W Lockwood and Y H Cho Streaming hierarchical clustering for concept mining in Aerospace Conference AERO  Mar 2007 pp 1–12 5 R  D u d a a n d P  H a r t  Pattern Classication and Scene Analysis  John Wiley and Sons Mar 1973 6 M  E s t l i c k  M  L e e s e r  J  T h e i l e r  a n d J  J  S z y m a n s k i  Algorithmic transformations in the implementation of kmeans clustering on recongurable hardware in FPGA  2001 pp 103–110 Online  A v a i l a b l e  citeseer.ist.psu.edu/estlick01algorithmic.html 7 M  L e e s e r  J  T h e i l e r  M  E s t l i c k  N  K i t a r y e v a  and J Szymanski Effect of data truncation in an implementation of pixel clustering on a custom computing machine 2000 Online  A v a i l a b l e  citeseer.ist.psu.edu/leeser00effect.html 8 G  A  C o v i n g t o n  C  L  C o m s t o c k  A  A  L e v i n e  J  W  Lockwood and Y H Cho High speed document clustering in reconigurable hardware in 16th Annual Conference on Field Programmable Logic and Applications FPL  Madrid Spain Aug 2006 pp 411–417 9 A  N g  M  J o r d a n  a n d Y  W e i s s   O n s p e c t r a l clustering Analysis and an algorithm 2001 Online  Available citeseer.ist.psu.edu/ng01spectral.html 10 C  E  S H A N N O N   C o m m u n i c a t i o n i n t h e p r e s e n c e o f noise in PROCEEDINGS OF THE IEEE VOL 86 NO 2  1998 pp 447–457 11 J  W  L o c k w o o d  N  M c K e o w n  G  W a t s o n  G  G i b b  P Hartke J Naous R Raghuraman and J Luo Netfpga an open platform for gigabit-rate network switching and routing in International Conference on Microelectronic Systems Education  2007 12 J  L u o  J  P e t t i t  M  C a s a d o  J  L o c k w o o d  a n d N  M c K eown Prototyping fast simple secure switches for ethane in Hot Interconnects  Stanford CA Aug 2007 13 N  D u k k i p a t i  G  G i b b  N  M c K e o w n  a n d J  Z h u  Building a rcp rate control protocol test network in Hot Interconnects  Stanford CA Aug 2007 pp 91–98 B IOGRAPHY John Meier is a Boeing Technical Fellow in the Network Centric Thrust at Phantom Works NCO Thrust He has over 27 years of professional experience in avionic technology development specically working in the area of intelligent networking recongurable computing architectures and wireless network management At Boeing he is currently involved with several key technical activities including a major project on edge computing and intelligent distributed system management Mr Meier earned his BS from Southern Illinois University Carbondale SIU-C MS University of Missouri Rolla UMR and currently working on his PhD degrees from the Department Computer Science Engineering CSE at the Washington University in St Louis He is a member of IEEE and Tau Beta Pi Todd Sproull is a Doctoral Candidate pursuing his DSc in Computer Engineering at Washington University in Saint Louis He is a Research Assistant and member of the Recongurable Network Group RNG at Washington University His interests include peer-to-peer overlay networks recongurable computing and network security He has worked in the industry at Xilinx Research Labs Network Physics and IBM He earned a BS degree in Electrical Engineering at Southern Illinois Univ ersity in Edwardsville and an MS in Computer Engineering at Washington University He is a member of IEEE Tau Beta Pi and Eta Kappa Nu G Adam Covington is a Research Associate of the Recongurable Network Group RNG at Washington University in St Louis Adam's research interests include recongurable systems articial intelligence clustering and classication and applications of articial intelligence algorithms Upon completing a Bachelor of Science degree in Computer Engineering in 2003 Adam earned his Masters of Science degree in Computer Science and Engineering from Washington University in December of 2006 He is currently visiting Stanford to implement data clustering on the NetFPGA platform and help assemble NetFPGA test systems 11 


John W Lockwood designs and implements networking systems in recongurable hardware During 2007 he served as a Visiting Associate Professor at Stanford University to manage the Alpha and Beta releases of the NetFPGA Prior to working at Stanford he led the the Recongurable Network Group RNG at Washington University The RNG research group developed the Field programmable Port Extender FPX to enable rapid prototype of extensible network modules in Fie ld Programmable Gate Array FPGA technology As an Associate professor in the Department of Computer Science and Engineering at Washington University in Saint Louis He has published over 75 full-length papers in journals and major technical conferences that describe technologies for prov iding extensible network services in wireless LANs and in high speed networks Professor Lockwood has served as the principal investigator on grants from the National Science Foun dation Xilinx Altera Nortel Networks Rockwell Collins  and Boeing He has worked in industry for AT&T Bell Laboratories IBM Science Applications International Corpo ration SAIC and the National Center for Supercomputing Applications NCSA He served as a co-founder of Global Velocity a networking startup company focused on high-speed data security Dr Lockwood earned his MS BS and PhD degrees from the Department of Electrical and Computer Engineering at the University of Illinois He is a member of IEEE ACM Tau Beta Pi and Eta Kappa Nu 12 


assumes that around 20% of the attribute and text values are different from the template values Table 3 lists results from this experiment. The third column of the table shows the number of bytes transmitted for each sample document, while the 6 th column shows the time used to construct tokens from the compressed document. The table shows that, under above-described setup, the amount of data transmitted are reduced to 2.6% to 15.7% of the original size second column, listed in KB time is reduced to 5.4% to 11.3% of the Nature mode tokenization time, or 11.5% to 25% of the Swift mode tokenization time 5.5 Discussion Since in our implementations, we make changes to base systems \(KXML and XT changes are required to implement Structure Encoding performance differences demonstrated in this section are caused by differences in techniques rather than differences in implementations Our experiments clearly show that Structure Encoding can, potentially, greatly improve the efficiency of XML processing with relatively low penalty for worst cases. The worst case scenario happens when a receiver uses hash function to identify the structure of a document, only to find out that the document structure is not in cache. The penalty it pays for such worst case scenario, 11.1% for DOM-style parsing and 8.9% for transformation, can easily be compensated by future structure recurrence. Such cache-miss penalty is negligible when sender-assigning scheme is used Systems that are conscious of such client-side penalty can let the sender or anyone in the middle of the transmission path to assign ID without altering the semantics of the message or document Although we didn’t measure the impact of compression on parsing and transformation, it can be inferred from tables 2 and 3. For example, in the book case, with tokenization time reduced from 8.6ms Swift mode\s \(compressed\e will likely be further reduced from 8.8ms to around 1.3ms compared with 24.4ms for KDOM\Similarly transformation time may be further reduced from 11.5ms to around 4.0ms \(compared with 48.3ms for XT\Encoding based XML compression offers additi onal, significant performance improvements for XML parsing and transformation in mobile environments, where closelycoupled proxies commonly exists. With compression turned off, Structure Enc oding is fully compatible with Web specifications and can be used between any two Internet hosts, and it still offer very significant performance improvements when there is structure recurrence Without compression, for documents with recurrent structures, tokenization and structure hashing cost dominates the overall cost for parsing, and is the major part of the cost for transformation. Tokenization and structure hashing however are relatively simple operations that may be implemented in hardware with low cost. \(In fact, some mobile chipsets already have hardware implementation of hash functions such as MD5 for security purposes implementation can reduce tokenization and structure hashing cost to a fifth of the current cost, then there will be additional substantial improvement for the parsing and transformation of most of the documents used in our experiments In our system, a document havi ng a structure slightly different \(e.g., added a new element\from a previous structure will not be able to reuse the structure processing result of the previous structure. However our system pays off as long as this new, slightly different structure recurs in future documents 6 CONCLUSION, LIMITATIONS, AND FUTURE WORK In this paper we motivated exploiting structure recurrence to speedup XML processing in mobile environments, by reduci ng structure related transmission and processing costs. We presented the concept of Structure Encoding, and described approaches to quickly identifying recurring structures including one using collision-resistant hash function We explained in detail how to use structure encoding to speedup XML transmission, tokenization, treebuilding, and transformation. We described our implementation of st ructure encoding based tokenizer DOM parser \(based on kXML\processor \(based on XT\pression scheme. Our experiments conducted on a mobile test-bed demonstrated dramatic performance improvement in the presence of structure recurrence and low overhead otherwise. In ideal cases structure encoding offers speedups of up to 7 for parsing and over 38 for XSL transformation, and up to 97.4% in size reduction when 20% of the text and attribute values change Structure encoding, however, is not applicable to all XML applications. Rather, it is more applicable to data-centric XML processing than to document-centric XML processing. A user randomly browsing Web pages is not likely to have high structure recurrence probabilities 
323 


Our current implementa tion does not support documents with “variable-le ngth arrays” – lists of identically structured elements with non-fixed lengths Otherwise identically structured documents with different array lengths are currently considered as having different structure We are currently working on supporting “variablelength arrays” to extend the applicability of Structure Encoding. We are also looking at provide similar, but less aggressive, optimization support for schemaconforming documents REFERENCES  Nokia Web Services – Helping Operators Mobilize the Internet Http://www.projectliberty.org/resources/whitepapers/W S_Operators_A4_0408.pdf  The SAX Project. http://www.saxproject.org  XML Pull Parsing. http://www.xmlpull.org  W3C Document Object Model http://www.w3.org/DOM  WAP Binary XML Content Format http://www.w3.org/TR/wbxml  Efficiency Structured XML. http://www.esxml.org  VTD-XML. http://vtd-xml.sourceforge.net  XSLTC Documentation. http://xml.apache.org/xalanj/xsltc  kXML. http://www.kxml.org  Liefke, H. and D. Suciu. XMill: An Efficient Compressor for XML Data. In Proc. of the ACM SIGMOD Conference on Management of Data. May 2000  Liu, L., C. Pu, and W. Tang. WebCQ: Detecting and Delivering Information Changes on the Web" In the Proceedings of International Conference on Information and Knowledge Management \(CIKM  The XT XSLT processor http://www.blnz.com/xt/index.html  Sarvega,Inc. http://www.sarvega.com  DataPower Technology, Inc http://www.datapower.com  Rax Content Processor http://www.tarari.com/rax/index.html  The Sarvega XSLT Benchmark Study, Sarvega Inc http://www.sarvega.com/xslt-benchmark.php  XSLTMark http://www.datapower.com/xmldev/xsltmark.html  Eisenhauer, G. and L. K. Daley. Fast Heterogenous Binary Data Interchange. In Proceedings of the 9th Heterogeneous Computing Workshop \(HCW 2000 90-101  Bustamente, F., G. Eisenhauer, K.Schwan, and P Widener. Efficient Wire Formats for High Performance Computing. In Proceedings of High Performance Networking and Computing Conference, 2000 SC’2000  Toshiro Takase, Hisashi Miyashita, Toyotaro Suzumura, and Michiaki Tatsubori, An Adaptive, Fast and Safe XML Parser Based on Byte Sequence Memorization. In Proc. of WWW’2005  XML-RPC. http://www.xmlrpc.com  Open  Mobile Alliance http://www.openmobilealliance.org  RSS 2.0 Specification http://blogs.law.harvard.edu/tech/rss  Open Mobile Alliance http://www.openmobilealliance.org  M ogul, J., F. Douglis, A. Feldm an, and B Krishnamurthy. Potential benefits of deltaencoding and compression for HTTP In Proc SIGCOMM’97 1997  Spring, N. T., and D. W e therall. A protocolindependent technique for eliminating redundant network traffic In Proc. SIGCOMM’00 2000  Chiu, K., and W  Lu. A Com piler-Based Approach to Schema-Specific XML Parsing. In First Internati onal Workshop on High Performance XML Processing, May 2004  Matsa, M., E. Perkins, A. Heifets, M. G.aitatzes Kostoulas, D. Silva, N. Mendelsohn, M. Leger. A high-performance interpretive approach to schema-directed parsing. In Proceedings of the 16th International Conference on World Wide Web, 2007  Noga, M  L., Schott, S., and Löwe, W  2002. Lazy  XML processing. In Proceedings of the 2002 ACM Symposium on Document Engineering McLean, Virginia, USA, November 08 - 09 2002\02. ACM, New York, NY  Farfán, F., V. Hristidis and R. Rangaswam i Beyond Lazy XML Parsing. In Proceedings of the 18th International Conference \(DEXA 200 September 3-7, 2007  
324 


 15 Fourier transform spectrometers at the Internationa l Scientific Station of the Jungfraujoch Switzerland  for atmospheric measurements and at the Institute of Astrophysics in Liège for laboratory measurements He was hired by JPL in August 1990 as MkIV cognizant engin eer and participated in all the MkIV campaigns since th en \(one DC-8 campaign 19 balloon campaigns Dr J.-F Bla vier obtained his Ph.D in Physics from the University o f Liège in July 1998 Paula Pingree is a Senior Engineer in the Instruments and Science Data Systems Division at JPL She has been involved in the design integration test and operation of several JPL flight projects most recently Deep Impact DI She has worked on the Tunable Laser Spectrometer development for the 2009 Mars Rover and is presently the Electronics CogE for the Juno Mission s Microwave Radiometer She also enjoys research and technology development for Smart Payloads in her s pare time Paula has a Bachelor of Engineering degree i n Electrical Engineering from Stevens Institute of Te chnology in Hoboken, NJ, and an MSEE degree from California State University Northridge.  She is a member of IEEE 


 16  A High Capacity Solid Sate Recorder \(HC-SSR\is suggested using devices predicated to be available for each decade.   The design is robu st and easily implemented using conservative design and manufacturing techniques D EFINITIONS  rad radiation absorbed dose\:   the dose causing 0.01 joule of energy to be absorbed per kilogram of matter.   As the absorption is greatly affected by the molecular structure of the material, citations should al so indicate the material as a subscript to the term 223rad\224, as in rad Si indicating Silicon equivalency.  For the purposes of this paper, radiation equivalency always assumes Silicon For completeness, it should be noted that System International replaced the \223rad\224 with the unit Gr ay \(Gy\nd having an equivalency of 100 rads = 1 Gy [27 How e v e r   the use of rads, kilorads, megarads remains in the industry vernacular and is used in this document Moore\222s Law Named after Fairchild Semiconductor technologist Gordon Moore, Moore\222s law was derived from empirical data which shows that the dimensions of basic memory cells will shrink by approximately 50% of the previous value every 30 to 36 months.  It is Moore\222s Law more or less, that forms the backbone of the ITRS examinations for memory devices A DDITIONAL M ATERIAL  Standard Dose Rates for Various Orbits and Missions per year Earth    LEO  100 rad \(protons  MEO  100 krad \(protons electrons  GEO  1 krad \(electrons  Transfer Orbit  10 krad \(protons electrons Mars     Surface  2 krad \(electrons  Orbit  5 krad \(protons  Transit  5 krad \(protons Jovian     Transfer  100 Mrad \(protons electrons A CKNOWLEDGEMENT  The research described in this paper was carried out at the Jet Propulsion Laboratory, California Institute of Technology, under a contract with the National Aeronautics and Space Administration.   The Author thanks the many who guided the concept and offered support all along the way.   With special thanks to fellow-JPL\222ers Gary Noreen who provided funding\nd Taher Daud who provided editing ad-hoc extraordinaire  R EFERENCES    G M o o r e C r a m m i ng m o re C o m pone nt s o n t o  Integrated Circuits Electronics vol. 38, no. 8, April 1965 2 G M o ore, "No Expo n e n tial is Forev er: B u t 223Forever\224 Can Be Delayed Digest of Technical Papers, International Solid State Circuits Conference pp. 1.1-1 thru 1.1-19, 2003  S eagate Tec hnology Com p any. Seagate Tec hnical Corporation. [Onlin http://www.seagate.com/docs/pdf/marrketing/Article _Perpendicular_Recording.pdf   B l u R ay Di sc Ass o ci at i on  2 00 5 M a rc h B l u-R a y  Disc Technical Papers  J Vel e v K  D B e l a shche n ko  an d et _al   2 0 0 7  October\ MSREC - University of Nebraska Onlin http://www.mrsec.unl.edu/research/nuggets/nugget_2 6.shtml  6 R Katti, "Honeywell Rad i atio n Hard en ed  No nVolatile Memory \(MRAM\ Product Development in Proceedings, IEEE No n-Volatile Memory Technology Symposium Orlando, 2004, pp. L2:1-15 7 S aif u n  Sem ico n d u c tor  2 008 NV M Techno log y  Over http://www.saifun.com/content.asp?id=113  


 17    J. Ta usc h  S. T y son a n d T T a i r ba nks  Multigenerational Radiation Response Trends in SONOSb ased NROM Flash Memories with Neutron Latch-up Mitigation," in NSREC Radiation Effects Workshop Honolulu, 2007, pp. 189-193 9  Semico n du c to r In du str y A s sociatio n SIA  2 008   August\ Home. [Online  www.itrs.net  1  S. Ty s o n P ri v a t e C o m m uni que Tra n sEl  Semiconductor, Albuquerque, NM, 2008 1  T. M i k o l a ji c k  and C U Pi n n o w  2 00 8 N o vem b er Indo-German Winter Academy, 2008, Course 3 Onlin http://www.leb.eei.unierlangen.de/winterakadem ie/2008/courses/course3_ material/futureMemory/Mikolajick_TheFutureofNV M.pdf   BAE System s North Am erica, [Data Sheet Microcircuit, CMOS, 3.3V, NVRAM 8406746, April 28, 2008, Rev A 1  N Ha dda d a n d T Scot t  A da pt i n g C o m m erci al  Electronics to the Natura lly Occurring Radiation Environment," in IEEE Nuclear and Space Radiation Effects Conference Short Course Tucson, 1994, pp iv-14 1  D. R  R o t h a n d et _al S EU a n d TI D Test i n g of t h e Samsung 128 Mbit and the Toshiba 256 Mbit flash memory," in Radiation Effects Data Workshop  Reno, 2000 1  F. I r o m and D N guy e n  S i n gl e E v ent  Ef fe ct  Characterization of High Density Commercial NAND and NOR Nonvolatile Flash Memories Honolulu, 2007 1  C Ha fer M  L a hey a n d et _al R adi a t i o n H a rd ness  Characterization of a 130nm Technology," in Proceedings IEEE Nuclea r and Space Radiation Effects Conference Honolulu, 2007 17  T. R O l dh am J. Fr iend lich  an d et_ a l, "TID  an d SEE Response of an Advanced Samsung 4Gb NAND Flash Memory," , Honolulu, 2007  R. C. Lac o e C MOS Scaling, Desi gn Princi ples a n d Hardening-by-Design Methodologies," in Nuclear and Space Radiation Effects Conference Short Course Notebook Monterey, 1993, pp. II-1 thru II142 1 J. Pat t e rs o n a n d S  Gue rt i n   E m e rgi ng S E F I M o des and SEE Testing for Highly-Scaled NAND FLASH Devices," in Proceedings 2005 Non-Volatile Memory Technology Symposium vol. CD-ROM, Dallas, TX 2005, pp. G-3, Session G ; Paper 3 2 J. Ta usc h  S. T y son a n d T F a i rba nks  Mulitgenerational Radiation Response Trends in SONOSb ased NROM Flash Memories with Neutron Latch-up Mitigation," in Honolulu Radaition Effects Data Workshop, NSREC, 2007, pp. 189-193 2 M Janai  B Ei t a n A Sha p pi r I B l o o m and G  Cohen, "Data Retention Reliability Model of NROM Nonvolatile Memory Products IEEE Transactions on Device and Materials Reliability vol. 4, no. 3, pp 404-415, September 2004 2 D N g uy en a n d F I r o m Tot al Io ni zi n g  Do se \(T ID  Tests on Non-Volatile Memories: Flash and MRAM," in 2007 IEEE Radiation Effects Workshop  vol. 0, Honolulu, 2007, pp. 194-198  G. Noree n  a n d et_al L ow Cost Deep Space Hybrid Optical/RF Communications Architecture," , Big Sky, Montana, 2009, Pre-print 2 T. Sasa da a n d S. I c hi kawa  A p p l i cat i o n o f  Sol i d  State Recorders to Spacecraft," in Proceedings, 54th International Astronautical Cogress Bremen, 2003 2 H Ka nek o  E rr or C o nt r o l C odi ng f o r  Semiconductor Memory Systems in the Space Radiation Environment," in Proceedings, 20th IEEE International Symposium in Defect and Fault Tolerance in VLSI Systems, DFT2005 Monterey 2005 2 T. Sasa da a n d H Ka nek o  D evel o p m e nt an d Evaluation of Test Circuit for Spotty Byte Error Control Codes," in Proceedings, 57th International 


 18  Astronautical Congress Valencia, 2006 27  Bu reau  In tern atio n a l d e s Po ids et Mesures. \(2 008  August\SI Base Units. [On http://www.bipm.org/en/si/base_units   B IOGRAPHY  Author, Karl Strauss, has been employed by the Jet Propulsion Laboratory for over 22 years.  He has been in the Avionics Section from day One.  He is considered JPL\222s memory technology expert with projects ranging from hand-woven core memory \(for another employer\o high capacity solid state designs.  He managed the development of NASA\222s first Solid State Recorder, a DRAM-based 2 Gb design currently in use by the Cassini mission to Satu rn and the Chandra X-Ray observatory in Earth Orbit.  Karl was the founder, and seven-time chair of the IEEE NonVolatile Memory Technology Symposium, NVMTS, deciding that the various symposia conducted until then were too focused on one technology.  Karl is a Senior IEEE member and is active in the Nuclear and Plasma Scie nce Society, the Electron Device Society and the Aerospace Electronic Systems Society Karl is also an active member of SAE Karl thanks his wonderful wife of 28 years, Janet, for raising a spectacular family: three sons, Justin, Jeremy Jonathan.  Karl\222s passion is trains and is developing a model railroad based upon a four-day rail journey across Australia\222s Northern Outback   


 19 Bollobás, B. 2001. Random Graphs. Cambridge University Press; 2nd edition. 500pp  Cawley, G. C., B. L. C. Talbot, G. J. Janacek, and M. W Peck. 2006. Sparse Bayesian Ke rnel Survival Analysis for Modeling the Growth Domain of Microbial Pathogens  Chiang C. L. 1960. A stochastic study of life tables and its applications: I. Probability distribution of the biometric functions. Biometrics, 16:618-635  Cox,  D. R. 1972. Regression models and life tables J. R Stat. Soc. Ser. B 34:184-220  Cox, D. R. 1975.   Partial likelihood Biometrika 62:269276  Cox, D. R. & D. Oakes. 1984 Analysis of Survival Data  Chapman & Hall. London  Cressie, N. A. 1993 Statistics for Spatial Data John Wiley Sons. 900pp  Duchesne, T. 2005. Regression models for reliability given the usage accumulation history. In "Modern Statistical and Mathematical Methods in Reliability". Edited by A. Wilson N. Limnios, S. Kelly-McNulty Y. Armijo. pp.29-40. World Scientific, New Jersey  Eleuteri, A., R. Tagliaferri, L. Milano, G. Sansone, D D'Agostino, S. De Placido,  M. Laurentiis. 2003.  Survival analysis and neural networks. Proceedings of the International Joint Conference on Neural Networks, Vol. 4 20-24 July 2003 Page\(s\:2631 - 2636  Ellison, E., L. Linger, and M Longstaff. 1997.  Survivable Network Systems: An Emerging Discipline, Carnegie Mellon, SEI, Technical Report CMU/SEI-97-TR-013, 1997  Fleming, T. R. & D. P. Harrington. 1991. Counting process and survival analysis. John Wiley & Sons. 429pp  Graver, J. and M. Sobel 2005. You may rely on the Reliability Polynomial for much more than you might think Communications in Statistics: Theory and Methods  34\(6\1411-1422  Graves, T. and M. Hamada. 2005. Bayesian methods for assessing system reliability: models and computation. In Modern Statistical and Mathematical Methods in Reliability". Edited by A. Wilson, et al. pp.41-53  Grimmett, G. 2006 The Random-Cluster Model Springer  Grimmett, G. 1999 Percolation Springer  Hougaard, P. 2000. Analysis of Multivariate Survival Data Springer. 560pp  Ibrahim, J. G., M. H. Chen and D. Sinha. 2005. Bayesian Survival Analysis.  Springer. 481pp  Jin Z. 2005. Non-proportional semi-parametric regression models for censored data. In "Modern Statistical and Mathematical Methods in Reliability". Edited by A. Wilson N. Limnios, S. Kelly-McNulty, Y. Armijo. pp.279-292 World Scientific  Kalbfleisch, J. D. & R. L. Prentice. 1980 The Statistical Analysis of Failure Time Data John Wiley & Sons.  New York. 1980  Kalbfleisch, J. D. &  R. L. Prentice, 2002. The Statistical Analysis of Failure Time Data.  Wiley-InterScience, 2nd ed 462pp  Lisboa, P. J. G. and H. Wong. 2001. Are neural networks best used to help logistic regression? Proceedings of International Joint Conference on Neural Networks, IJCNN 01. Volume 4, 15-19,  July 2001. Page\(s\:2472 - 2477 vol.4  Kauffman, R. J. and B. Wang. 2002. Duration in the Digital Economy. Proceedings of th e 36th Hawaii International Conference on System Sciences \(HICSS’03\ Jan 2003  Kaplan, E. L. & P.  Meier.  1958.  Nonparametric estimation from incomplete observations J. Amer. Statist. Assoc  53:457-481  Klein, J. P. and P. K. Goel 1992. Survival Analysis: State of the Art.  Kluwer Academic Publishes. 450pp  Klein, J. P. and  M. L Moeschberger. 20 03. Survival analysis techniques for ce nsored and truncated data Springer  Krings, A. and Z. S. Ma. 2006.  "Fault-Models in Wireless Communication: Towards Survivable Ad Hoc Networks MILCOM 2006, Military Communications Conference, 2325 October, 7 pages, 2006  Krings, A. W. 2008.  Survivable Systems.  in Information Assurance: Dependability and Security in Networked Systems Yi Qian, James Joshi, David Tipper, and Prashant Krishnamurthy, Morgan Kaufmann Publishers. \(in press  Lawless, J. F. 1982. Statistical models and methods for lifetime data.  John Wiley & Sons. 579pp  Lawless, J. F. 2003. Statistical models and methods for lifetime data.  John Wiley & Sons. 2nd ed. 630pp  Li, M. and P. Vitanyi. 1997. Introduction to  Kolmogorov Complexity and Its Applications. 2nd ed, Springer  Ma, Z. S. 1997.  Survival analysis and demography of Russian wheat aphid populations.  Ph.D dissertation, 307pp University of Idaho Moscow, Idaho, USA 


 20 Ma, Z. S., and E. J. Bechinski. 2008.  Developmental and Phenological Modeling of Russian Wheat Aphid Annals of Entomological Soc. Am In press  Ma, Z. S. and A. W. Krings. 2008a. The Competing Risks Analysis Approach to Reliability Survivability, and Prognostics and Health Management.  The 2008 IEEEAIAA AeroSpace Conference. BigSky, Montana, March 18, 2008. \(In Press, in the same volume  Ma, Z. S. and A. W. Krings 2008b. Multivariate Survival Analysis \(I\e Shared Frailty Approaches to Reliability and Dependence Modeling. The 2008 IEEE-AIAA AeroSpace Conference. BigSky Montana, March 1-8, 2008 In Press, in the same volume  Ma, Z. S. and A. W. Krings. 2008c. Multivariate Survival Analysis \(II\ Multi-State Models in Biomedicine and Engineering Reliability. 2008 IEEE International Conference on Biomedical Engineering and Informatics BMEI 2008\27th-30th, 2008 Accepted   Mani, R., J. Drew, A. Betz, P. Datta. 1999. Statistics and Data Mining Techniques for Lifetime Value Modeling ACM Conf. on Knowledge Discovery and Data Mining  Mazzuchi, T. A., R Soyer., and R. V Spring. 1989. The proportional hazards model in reliability. IEEE Proceedings of Annual Reliability and Maintainability Symposium pp.252-256  Meeker, W. Q. and L. A. Escobar. 1998. Statistical Methods for Reliability Data. Wiley-Interscience  Munson, J. C. 2003. Software Engineering Measurement Auerbach Publications  Nelson, W. 1969. Hazard plotting for incomplete failure data J. Qual. Tech 1:27-52  Nakagawa, T. 2006.  Shock and Damage Models in Reliability Theory. Springer  Osborn, B. 2005. Leveraging remote diagnostics data for predictive maintenance.   In "Modern Statistical and Mathematical Methods in Reliability". Edited by A. Wilson N. Limnios, S. Kelly-McNulty, Y. Armijo. pp. 353-363  Pena, E. A. and E. H. Slate. 2005. Dynamic modeling in reliability and survival analysis. In "Modern Statistical and Mathematical Methods in Reliability". Edited by A. Wilson N. Limnios, S. Kelly-McNulty, Y. Armijo. pp.55-71  Reineke, D. M., E. A. Pohl, and W. P. Murdock. 1998 Survival analysis and maintenance policies for a series system, with highly censore d data.  1998 Proceedings Annual Reliability and Maintainability Symposium. pp 182-188  Schabenberger, O. and C. A. Gotway. 2005. Statistical Methods for Spatial Data Analysis.  Chapman & Hall/CRC  Severini, T. A. 2000. Likelihood methods in statistics Oxford University Press  Shooman, M. L. 2002. Reliability of Computer Systems and Networks: Fault Tolerance, Analysis and Design. John Wiley and Sons. 551pp  Stillman, R. H. and M. S. Mack isack, B. Sharp, and C. Lee 1995. Case studies in survival analysis of overhead line components. IEE Conferen ce of the Reliability and Distribution Equipment. March 29-31, 1995. Conference Publication No. 406. pp210-215  Therneau, T. and P. Grambsch. 2000 Modeling Survival Data: Extending the Cox Model Springer  Wilson, A.  N. Limnios, S Kelly-McNulty, Y. Armijo 2005. Modern Statistical and Mathematical Methods in Reliability. World Scientific, New Jersey  Xie, M. 1991. Software Reliability Modeling. World Scientific Press    B IOGRAPHY   Zhanshan \(Sam\ Ma holds a Ph.D. in Entomology and is a Ph.D. candidate in Computer Science at the University of Idaho. He has published approximately 30 journal and 30 conference papers, mainly in the former field.  Prior to his recent return to academia, he worked as senior network/software engineers in software industry.  His current research interests include reliability and survivability of wireless sensor networks, fault tolerance survival analysis, evolutionary game theory, evolutionary computation and bioinformatics  Axel W. Krings is a professor of Computer Science at the University of Idaho.  He received his Ph.D. \(1993\ and M.S 1991\ degrees in Computer Science from the University of Nebraska - Lincoln, and his M.S. \(1982\ in Electrical Engineering from the FH-Aachen, Germany.  Dr. Krings has published extensively in the area of Computer Network Survivability, Security, Fault-Tolerance and Realtime Scheduling. In 2004/2005 he was a visiting professor at the Institut d'Informatique et Mathématiques Appliquées de Grenoble, at the Institut National Polytechnique de Grenoble, France.  His work has been funded by DoE/INL DoT/NIATT, DoD/OST and NIST 


States\nWAb-3.4: NEW RESULTS IN THE ANALYSIS OF DECISION-FEEDBACK 2118\nEQUALIZERS\nAhmed Mehana, Samsung Electronics, Co Ltd., United States; Aria Nosratinia, University of Texas at \nDallas, United States\nWAb-5: TARGET TRACKING II\nWAb-5.1: POSTERIOR DISTRIBUTION PREPROCESSING FOR PASSIVE 2125\nDTV RADAR TRACKING: SIMULATED AND REAL DATA\nEvan Hanusa, Laura Vertatschitsch, David Krout, University of Washington, United States\nWAb-5.2: DEPTH-BASED PASSIVE TRACKING OF SUBMERGED SOURCES  ............................................2130\nIN THE DEEP OCEAN USING A VERTICAL LINE ARRAY\nLisa Zurk, John K. Boyle, Jordan Shibley, Portland State University, United States\nWAb-5.3: GENERALIZED LINEAR MINIMUM MEAN-SQUARE ERROR 2133\nESTIMATION WITH APPLICATION TO SPACE-OBJECT TRACKING\nYu Liu, X. Rong Li, Huimin Chen, University of New Orleans, United States\nWAb-5.4: FEATURE-AIDED INITIATION AND TRACKING VIA TREE SEARCH ..........................................2138\nHossein Roufarshbaf Jill Nelson, George Mason University, United States\nxxxiii\nWAb-6: DIRECTION OF ARRIVAL ESTIMATION\nWAb-6.1: A SELF-CALIBRATION TECHNIQUE FOR DIRECTION 2145\nESTIMATION WITH DIVERSELY POLARIZED ARRAYS\nBenjamin Friedlander, University of California, Santa Cruz, United States\nWAb-6.2: CRAMER-RAO PERFORMANCE BOUNDS FOR SIMULTANEOUS  ..............................................2150\nTARGET AND MULTIPATH POSITIONING\nLi Li, Jeff Krolik, Duke University, United States\nWAb-6.3: COPY CORRELATION DIRECTION-OF-ARRIVAL ESTIMATION  .................................................2155\nPERFORMANCE WITH A STOCHASTIC WEIGHT VECTOR\nChrist Richmond, Keith Forsythe, MIT Lincoln Laboratory, United States; Christopher Flynn, Stevens nInstitute of Technology, United States\nWAb-6.4: LOCATING CLOSELY SPACED COHERENT EMITTERS USING 2160\nTDOA TECHNIQUES\nJack Reale, Air Force Research Laboratory / Binghamton University, United States; Lauren Huie, Air \nForce Research Laboratory, United States Mark Fowler, State University of New York at Binghamton, \nUnited States\nWAb-7: ENERGY- AND RELIABILITY-AWARE DESIGN\nWAb-7.1: LOW-ENERGY ARCHITECTURES FOR SUPPORT VECTOR 2167\nMACHINE COMPUTATION\nManohar Ayinala, Keshab K Parhi, University of Minnesota, United States\nWAb-7.2: TRUNCATED MULTIPLIERS THROUGH POWER-GATING FOR 2172\nDEGRADING PRECISION ARITHMETIC\nPietro Albicocco, Gian Carlo Cardarilli, University of Rome Tor Vergata, Italy; Alberto Nannarelli, \nTechnical University of Denmark Denmark; Massimo Petricca, Politecnico di Torino, Italy; Marco Re, \nUniversity of Rome Tor Vergata Italy\nWAb-7.3: A LOGARITHMIC APPROACH TO ENERGY-EFFICIENT GPU 2177\nARITHMETIC FOR MOBILE DEVICES\nMiguel Lastras Behrooz Parhami, University of California, Santa Barbara, United States\nWAb-7.4: ON SEPARABLE ERROR DETECTION FOR ADDITION ..................................................................2181\nMichael Sullivan, Earl Swartzlander, University of Texas at Austin, United States\nWPb-1: PAPERS PRESENTED IN 2012\nWPb-1.1 DYNAMICALLY RECONFIGURABLE AVC DEBLOCKING FILTER  .............................................2189\nWITH POWER AND PERFORMANCE CONSTRAINTS\nYuebing Jiang, Marios Pattichis, University of New Mexico\nxxxiv\n 


on science teams for numerous planetary missions including Magellan, Mars Observer, Mars Global Surveyor and Rosetta. He was the US Project Scientist for the international Mars NetLander mission, for which he was also principal investigator of the Short-Period Seismometer experiment, and is currently the Project Scientist for the Mars Exploration Rovers. He led the Geophysics and Planetary Geology group at JPL from 1993-2005, and is the JPL Discipline Program Manager for Planetary Geosciences. He has held several visiting appointments at the Institut de Physique du Globe de Paris. He has a BS in physics and a PhD in geophysics from the University of Southern California  David Hansen is a member of the technical staff in the Communications Systems and Operations Group at the Jet Propulsion Laboratory. Current work includes the development of the telecom subsystem for the Juno project. David received a B.S. in Electrical Engineering from Cornell University and an M.S. in Electrical Engineering from Stanford University  Robert Miyake is a member of the technical staff in the Mission and Technology Development Group at the Jet Propulsion Laboratory. Current work includes the development of thermal control subsystems for interplanetary flagship missions to Jupiter and Saturn missions to Mars and the Earth Moon, and is the lead Thermal Chair for the Advanced Project Design Team Robert graduated with a B. S. from San Jose State University, with extensive graduate studies at UCLA University of Washington, and University of Santa Clara  Steve Kondos is a consultant to the Structures and Mechanisms group at the Jet Propulsion Laboratory. He currently is generating the mechanical concepts for small Lunar Landers and Lunar Science Instrument packages in support of various Lunar mission initiatives. He also provides conceptual design, mass and cost estimating support for various Team X studies as the lead for the Mechanical Subsystem Chair. Steve is also involved with various other studies and proposals and provides mentoring to several young mechanical and system engineers. He graduated with a B.S. in Mechanical Engineering from the University of California, Davis and has 28 years of experience in the aerospace field ranging from detail part design to system of systems architecture development. He has worked both in industry and in government in defense, intelligence commercial and civil activities that range from ocean and land based systems to airborne and space systems. Steve has received various NASA, Air Force, Department of Defense and other agency awards for his work on such projects as the NASA Solar Array Flight Experiment, Talon Gold, MILSTAR, Iridium, SBIRS, Mars Exploration Rovers ATFLIR, Glory Aerosol Polarimeter System and several Restricted Programs  Paul Timmerman is a senior member of technical staff in the Power Systems Group at the Jet Propulsion Laboratory Twenty-five years of experience in spacecraft design including 22 at JPL, over 250 studies in Team-X, and numerous proposals. Current assignments include a wide variety of planetary mission concepts, covering all targets within the solar system and all mission classes. Paul graduated from Loras College with a B.S. in Chemistry in 1983  Vincent Randolph is a senior engineer in the Advanced Computer Systems and 


the Advanced Computer Systems and Technologies Group at the Jet Propulsion Laboratory. Current work includes generating Command and Data Handling Subsystem conceptual designs for various proposals and Team X.  He also supports Articulation Control and Electronics design activities for the Advanced Mirror Development project. Vincent graduated from the University of California at Berkeley with a B.S. in Electrical Engineering 18  pre></body></html 


i models into time and covariate dependent dynamic counterparts  ii models and reliability analysis in a more realistic manner  iii level  whether or not functional components \(loyal generals diagnose correctly and take proper actions such as fault mask of failed components \(traitors asymmetric  iv survivability analysis. Evolutionary game modeling can derive sustainable or survivable strategies \(mapped from the ESS in EGT such as node failures such as security compromise level modeling in the so-called three-layer survivability analysis developed in Ma \(2008a this article  v offer an integrated architecture that unite reliability survivability, and fault tolerance, and the modeling approaches with survival analysis and evolutionary game theory implement this architecture. Finally, the dynamic hybrid fault models, when utilized to describe the survival of players in EGT, enhance the EGT's flexibility and power in modeling the survival and behaviors of the game players which should also be applicable to other problem domains where EGT is applicable  5. OPERATIONAL LEVEL MODELING AND DECISION-MAKING  5.1. Highlights of the Tactical and Strategic Levels  Let's first summarize what are obtainable at both tactical and strategic levels. The results at both tactical and strategic levels are precisely obtainable either via analytic or simulation optimization. With the term precisely, we mean that there is no need to assign subjective probabilities to UUUR events. This is possible because we try to assess the consequences of UUUR events \(tactical level ESS strategies \(strategic level time prediction of survivability. The following is a list of specific points. I use an assumed Wireless Sensor Network WSN  i of UUUR events: \(a actions which can be treated as censored events; \(b Cont' of Box 4.2 It can be shown that the replicator differential equations are equivalent to the classical population dynamics models such as Logistic differential equation and LotkaVolterra equation \(e.g., Kot 2001 Logistic equation, or the limited per capital growth rate is similar to the change rate of the fitness  xfxfi which can be represented with the hazard function or survivor functions introduced in the previous section on survival analysis.  This essentially connects the previous survival analysis modeling for lifetime and reliability with the EGT modeling. However, EGT provides additional modeling power beyond population dynamics or survival analysis approaches introduced in the previous section. The introduction of evolutionary theory makes the games played by a population evolvable. In other words, each player \(individual 


other words, each player \(individual agent and players interact with each other to evolve an optimized system Box 4.3. Additional Comments on DHF Models  The above introduced EGT models are very general given they are the system of ordinary differential equations. Furthermore, the choice of fitness function f\(x complexity to the differential equation system.  The system can easily be turned into system of nonlinear differential equations. The analytical solution to the models may be unobtainable when nonlinear differential equations are involved and simulation and/or numerical computation are often required  In the EGT modeling, Byzantine generals are the game players, and hybrid fault models are conveniently expressed as the strategies of players; the players may have different failure or communication behaviors Furthermore, players can be further divided into groups or subpopulations to formulate more complex network organizations. In the EGT modeling, reliability can be represented as the payoff \(fitness, the native term in EGT of the game. Because reliability function can be replaced by survivor function, survival analysis is seamlessly integrated into the EGT modeling. That is, let Byzantine generals play evolutionary games and their fitness reliability function  The evolutionary stable strategy \(ESS counterpart of Nash equilibrium in traditional games ESS corresponds to sustainable strategies, which are resistant to both internal mutations \(such as turning into treason generals or nodes such as security compromises represent survivable strategies and survivability in survivability analysis. Therefore, dynamic hybrid fault models, after the extension with EGT modeling, can be used to study both reliability and survivability 13 risks such as competing risks which can be described with CRA; \(c captured with the shard frailty.  We believe that these UUUR events are sufficiently general to capture the major factors/events in reliability, security and survivability whose occurrence probabilities are hard or impossible to obtain  Instead of trying to obtain the probabilities for these events which are infeasible in most occasions, we focus on analyzing the consequences of the events.  With survival analysis, it is possible to analyze the effects of these types of events on survivor functions. In addition, spatial frailty modeling can be utilized to capture the heterogeneity of risks in space, or the spatial distribution of risks \(Ma 2008a d UUUR events introduced previously. These approaches and models that deal with the effects of UUUR events form the core of tactical level modeling  To take advantage of the tactical level modeling approaches it is obviously necessary to stick to the survivor functions or hazard functions models. In other words, survival analysis can deal with UUUR events and offer every features reliability function provides, but reliability function cannot deal with UUUR events although survivor function and reliability function have the exactly same mathematical definition. This is the junction that survival analysis plays critical role in survivability analysis at tactical level. However, we 


recognize that it is infeasible to get a simple metric for survivability similar to reliability with tactical level modeling alone. Actually, up to this point, we are still vague for the measurement of survivability or a metric for survivability. We have not answered the question: what is our metric for survivability? We think that a precise or rigorous definition of survivability at tactical level is not feasible, due to the same reason we cited previously  the inability to determine the probabilities of UUUR events However, we consider it is very helpful to define a work definition for survivability at the tactical level  We therefore define the survivability at tactical level as a metric, Su\(t t function or reliability function with UUUR events considered. In the framework of three-layer survivability analysis, this metric is what we mean with the term survivability. The "metric" per se is not the focus of the three-layer survivability analysis. It is not very informative without the supports from the next two levels  strategic and operational models.  However, it is obvious that this metric sets a foundation to incorporate UUUR effects in the modeling at the next two levels  Due to the inadequacy of tactical level modeling, we proposed the next level approach  strategic level modeling for survivability. As expected, the tactical level is one foundation of strategic level modeling ii objectives: \(a affect survivability which survival analysis alone is not adequate to deal with; \(b survivability at tactical level is necessary but not sufficient for modeling survivability, we need to define what is meant with the term survivability at strategic level  With regard to \(a behaviors or modes which have very different consequences. These failure behaviors can be captured with hybrid fault models. However, the existing hybrid fault models in fault tolerance field are not adequate for applying to survivability analysis. There are two issues involved: one is the lack of real time notion in the constraints for hybrid fault models \(e.g., N&gt;3m+1 for Byzantine Generals problem synthesize the models after the real-time notions are introduced. The solution we proposed for the first issue is the dynamic hybrid fault models, which integrate survivor functions with traditional hybrid fault models. The solution we proposed for the second issue is the introduction of EGT modeling  With regard to \(b modeling our problem at strategic level, EGT modeling is essentially a powerful optimization algorithm.  One of the most important results from EGT modeling is the so-called evolutionary stable strategies \(ESS We map the ESS in EGT to survivable strategies in survivability analysis.   Therefore, at the strategic level, our work definition for survivability refers to the survivable strategies or sustainable strategies in the native term of EGT, which can be quantified with ESS  In addition to integrating dynamic hybrid fault models another advantage for introducing EGT modeling at strategic level is the flexibility for incorporating other node behaviors \(such as cooperative vs. non-cooperative those behaviors specified in standard hybrid fault models, as well as anthropocentric factors such as costs constraints  Without UUUR events, both tactical and strategic level 


Without UUUR events, both tactical and strategic level models default to regular reliability models. This implies that, in the absence of UUUR events, reliable strategies are sustainable or survivable.  This also implies that three-layer survivability analysis defaults to reliability analysis however, the three-layer approach does offer some significant advantages over traditional reliability analysis, as discussed in previous sections. Nevertheless, when UUUR events exist, reliable strategies and survivable strategies are different. This necessitates the next operational level modeling  5.2. Operational Level Modeling and Decision-Making  When UUUR events are involved, we cannot make real time predictions of survivability at tactical and strategic levels This implies that the implementations of survivable 14 strategies need additional measures that we develop in this section.  Box 5.1 explains the ideas involved with possibly the simplest example  Figure 4 is a diagram showing a simplified relationship between action threshold survivability \(TS survivability \(ES view since both TS and ES are multidimensional and dynamic in practice. Therefore, the sole purpose of the diagram is to illustrate the major concepts discussed above The blue curve is the survivability when survivable strategies specified by ESS are implemented at some point before time s.  The system is then guaranteed to hold survivability above ES. In contrary, if no ESS implemented before time s, then the system quickly falls below to the survivable level at around 40 time units  T i m e 0 1 0 2 0 3 0 4 0 5 0 6 0 7 0 8 0 9 0 1 0 0 Su rv iv ab ili ty M et ric S u t 0 . 0 0 . 1 0 . 2 0 . 3 0 . 4 0 . 5 0 . 6 0 . 7 0 . 8 0 . 9 1 . 0 E S S  i s  I m p lm e n t e d N o  E S S  is  I m p lm e n t e d ts E S T S  Figure 4. A Diagram Showing the Relationship Between TS and ES, as well as timing of s and t, with s &lt; t  6. SUMMARY  The previous sections discussed the major building blocks 


The previous sections discussed the major building blocks for the new life-system inspired PHM architecture. This section first identifies a few minor aspects that have not been discussed explicitly but are necessary for the implementation of the architecture, and then we summarize the major building blocks in a diagram  6.1. Missing Components and Links  Optimization Objectives  Lifetime, reliability, fault tolerance, and survivability, especially the latter two, are application dependent. Generally, the optimization of reliability and survivability are consistent; in that maximization of reliability also implies maximization of survivability. However, when application detail is considered, optimization of lifetime is not necessarily consistent with the optimization of reliability. Consider the case of the monitoring sensor network as an example. The network reliability is also dependent on connectivity coverage, etc, besides network lifetime. What may be further complicated is the time factor. All of the network metrics are time-dependent. A paradoxical situation between lifetime and reliability could be that nodes never 'sleep                                                   


          Box 5.1 Operational Level Modeling  Assuming that the ESS solution for a monitoring sensor network can be expressed with the following simple algebraic conditions: survivability metric at tactical level SU = 0.7, Router-Nodes in the WSN &gt; 10%, Selfish Nodes &lt; 40%. Even with this extremely simplified scenario, the ESS strategies cannot be implemented because we do not know when the actions should be taken to warrant a sustainable system.  These conditions lack a correlation with real time  The inability to implement ESS is rooted in our inability to assign definite probabilities to UUUR events, which implies that we cannot predict when something sufficiently bad will jeopardize the system survivability What we need at the operational level is a scheme to ensure ESS strategy is in place in advance  The fundamental idea we use to implement the ESS strategy is to hedge against the UUUR events. The similar idea has been used in financial engineering and also in integrated pest management in entomology. This can be implemented with the following scheme  Let us define a pair of survivability metrics: one is the expected survivability \(ES threshold survivability or simply threshold survivability \(TS ES is equivalent to the survivability metric at tactical level. ES corresponds to ESS at strategic level, but they are not equivalent since ESS is strategy and ES is survivability. TS is the survivability metric value \(at tactical level and TS can be obtained from strategic level models. For example, TS = SU\(s t condition for the implementation of ESS. In other words, the implementation of strategies that ensures TS at time s will guarantee the future ES level at time t.  To make the implementation more reliable and convenient multiple dynamic TSs can be computed at time s1, s2 sk, with si &lt; t for all i.  These TS at times s1, s2, ..., sk should be monitored by some evaluation systems  Unlike tactical and strategic levels, the operational level modeling is approximate. The term "approximate means that we cannot predict the real time survivability or we do not know the exact time an action should be taken. Instead, the action is triggered when the monitored survivability metric SU\(r survivability \(TS scheme of TS and ES, we ensure the ES by taking preventative actions \(prescribed by ESS and triggered by the TS consequences of UUUR events  Figure 4 is a diagram showing the above concepts and the decision-making process involved 15 This wakefulness \(never 'sleep short period but at the expense of network lifetime. Of course, when the network is running out of lifetime, network reliability ultimately crashes. This example reminds us that 


reliability ultimately crashes. This example reminds us that multi-objective optimization should be the norm rather than exception  Constraints and Extensions  Many application specific factors and constraints are ignored in this article. For example, we mentioned about spatial heterogeneity of environment, but never present a mathematical description The spatial heterogeneity can be modeled with the so-called spatial frailty in multivariate survival analysis \(Ma 2008a  Evolutionary Algorithm  Evolutionary game modeling when implemented in simulation, can be conveniently implemented with an algorithm similar to Genetic Algorithms \(GA ESS in the evolutionary game model with simulation is very similar to GA. Dynamic populations, in which population size varies from generation to generation \(Ma &amp; Krings 2008f of node failures. Another issue to be addressed is the synchronous vs. asynchronous updating when topology is considered in the simulation. This update scheme can have profound influences on the results of the simulation. Results from cellular automata computing should be very useful for getting insights on the update issue  6.2. Summary and Perspective  To recapture the major points of the article, let us revisit Figure 3, which summarizes the principal modules of the proposed life-system inspired PHM architecture. The main inspiration from life systems is the notion of individuals and their assemblage, the population. Population is an emergent entity at the next level and it has emergent properties which we are often more concerned with. Survival analysis, which has become a de facto standard in biomedicine, is particularly suitable for modeling population, although it is equally appropriate at individual level. Therefore, survival analysis \(including competing risks analysis and multivariate survival analysis comprehensively in the context of PHM in a series of four papers presented at IEEE AeroSpace 2008 \(Ma &amp; Krings 2008a, b, c, &amp; d proposed architecture. Survival analysis constitutes the major mathematical tools for analyzing lifetime and reliability, and also forms the tactical level of the three-layer survivability analysis  Besides lifetime and reliability, two other major modules in Figure 3 are fault tolerance and survivability. To integrate fault tolerance into the PHM system, Dynamic Hybrid Fault DHF 2008e, Ma 2008a make real-time prediction of reliability more realistic and make real-time prediction of fault tolerance level possible DHF models also unite lifetime, reliability and fault tolerance under a unified modeling framework that consists of survival analysis and evolutionary game theory modeling  DHG models also form the partial foundation, or strategic level, for the three-layer survivability analysis. At the strategic level, the Evolutionary Stable Strategies \(ESS which is mapped to survivable or sustainable strategies, can be obtained from the evolutionary game theory based DHF models. When there is not any UUUR event involved reliability and survivability are consistent, and reliable strategies are survivable. In this case, the strategic level modeling up to this point is sufficient for the whole PHM system modeling, and there is no need for the next level  operational level modeling  When there are UUUR events in a PHM system, the 


When there are UUUR events in a PHM system, the inability to determine the occurrence probabilities of UUUR events makes the operational level modeling necessary Then the principle of hedging must be utilized to deal with the "hanging" uncertainty from UUUR events. In this case reliability strategies are not necessarily survivable strategies At the operational level modeling, a duo of survivability metrics, expected survivability \(ES survivability \(TS the survivable strategies \(ESS level are promptly implemented based on the decisionmaking rules specified with the duo of survivability metrics then the PHM system should be able to endure the consequences of potentially catastrophic UUUR events. Of course, to endure such catastrophic events, the cost may be prohibitively high, but the PHM system will, at least, warn decision-makers for the potentially huge costs.  It might be cheap to just let it fail  Figure 3 also shows several other modules, such as security safety, application systems \(such as Automatic Logistics CBM+, RCM, Life cycle cost management, Real-time warning and alert systems architectures, but we do not discuss in this paper. Generally the new architecture should be fully compatible with existing ones in incorporating these additional modules. One point we stressed is that PHM system can be an ideal place to enforce security policies. Enforcing security policies can be mandatory for PHM systems that demand high security and safety such as weapon systems or nuclear plant facilities.  This is because maintenance, even without human-initiated security breaches, can break the security policies if the maintenance is not planned and performed properly  In perspective, although I did not discuss software issues in this paper, the introduced approaches and models should provide sufficient tools for modeling software reliability and survivability with some additional extension. Given the critical importance of software to modern PHM systems, we present the following discussion on the potential extension to software domain. Specifically, two points should be noted: \(1 architecture to software should be a metric which can 16 replace the time notion in software reliability; I suggest that the Kolmogorov complexity \(e.g., Li and Vitanyi 1997 be a promising candidate \(Ma 2008a change is because software does not wear and calendar time for software reliability usually does not make much sense 2 software reliability modeling.  Extending to general survivability analysis is not a problem either. In this article I implicitly assume that reliability and survivability are positively correlated, or reliability is the foundation of survivability. This positive correlation does not have to be the case. A simplified example that illustrates this point is the 'limit order' in online stock trading, in which limit order can be used in either direction: that stock price is rising or falling.  The solution to allow negative or uncorrelated relationships between reliability and survivability are very straightforward, and the solutions are already identified in previous discussions. Specifically, multiple G-functions and multi-stage G-functions by Vincent and Brown \(2005 very feasible solution, because lifetime, reliability and survivability may simply be represented with multiple Gfunctions. Another potential solution is the accommodation of the potential conflicts between reliability and survivability with multi-objective GA algorithms, which I previously suggested to be used as updating algorithms in the optimization of evolutionary games  


 The integration of dynamic hybrid fault models with evolutionary game modeling allows one to incorporate more realistic and detailed failure \(or survival individual players in an evolutionary game. This is because dynamic hybrid fault models are supported by survival analysis modeling, e.g., time and covariate dependent hazard or survivor functions for individual players. If necessary, more complex survival analysis modeling including competing risks analysis and multivariate survival analysis, can be introduced.  Therefore, any field to which evolutionary game theory is applicable may benefit from the increased flexibility in modeling individual players.  Two particularly interesting fields are system biology and ecological modeling.  In the former field, dynamic hybrid fault models may find important applications in the study of biological networks \(such as gene, molecular, and cell networks 2008g conjecture that explains the redundancy in the universal genetic code with Byzantine general algorithm. In addition they conducted a comparative analysis of bio-robustness with engineering fault tolerance, for example, the strong similarity between network survivability and ecological stability \(Ma &amp; Krings 2008g survivability analysis can be applied for the study of survivals or extinctions of biological species under global climate changes \(Ma 2008b  In this paper, I have to ignore much of the details related to the implementation issues to present the overall architecture and major approaches clearly and concisely. To deal with the potential devils in the implementation details, a well funded research and development team is necessary to take advantages of the ideas presented here. On the positive side I do see the great potential to build an enterprise PHM software product if there is sufficient resource to complete the implementation. Given the enormous complexity associated with the PHM practice in modern engineering fields, it is nearly impossible to realize or even demonstrate the benefits of the architecture without the software implementation. The critical importance of PHM to mission critical engineering fields such as aerospace engineering, in turn, dictates the great value of such kind software product  6.3. Beyond PHM  Finally, I would like to raise two questions that may be interested in by researchers and engineers beyond PHM community. The first question is: what can PHM offer to other engineering disciplines? The second question is: what kinds of engineering fields benefit most from PHM? Here, I use the term PHM with the definition proposed by IEEE which is quoted in the introduction section of the paper  As to the first question, I suggest software engineering and survivability analysis are two fields where PHM can play significant roles. With software engineering, I refer to applying PHM principles and approaches for dealing with software reliability, quality assurance, and even software process management, rather than building PHM software mentioned in the previous subsection. For survivability analysis, borrowing the procedures and practices of PHM should be particularly helpful for expanding its role beyond its originating domain \(network systems that control critical national infrastructures is a strong advocate for the expansion of survivability analysis to PHM. Therefore, the interaction between PHM and survivability analysis should be bidirectional. Indeed, I see the close relationships between PHM, software engineering, and survivability as well-justified because they all share some critical issues including reliability survivability, security, and dependability  


 The answer to the second question is much more elusive and I cannot present a full answer without comparative analysis of several engineering fields where PHM has been actively practiced. Of course, it is obvious that fields which demand mission critical reliability and dependability also demand better PHM solutions. One additional observation I would like to make is that PHM seems to play more crucial roles for engineering practices that depend on the systematic records of 'historical' data, such as reliability data in airplane engine manufacturing, rather than on the information from ad hoc events.  This may explain the critical importance of PHM in aerospace engineering particularly in commercial airplane design and manufacturing.  For example, comparing the tasks to design and build a space shuttle vs. to design and manufacture commercial jumbo jets, PHM should be more critical in the latter task  17    Figure 2. States of a monitoring sensor node and its failure modes \(after Ma &amp; Krings 2008e     Figure 3. Core Modules and their Relationships of the Life System Inspired PHM Architecture    REFERENCES  Adamides, E. D., Y. A. Stamboulis, A. G. Varelis. 2004 Model-Based Assessment of Military Aircraft Engine Maintenance Systems Model-Based Assessment of Military Aircraft Engine Maintenance Systems. Journal of the Operational Research Society, Vol. 55, No. 9:957-967  Anderson, R. 2001. Security Engineering. Wiley  Anderson, R. 2008. Security Engineering. 2nd ed. Wiley  Bird, J. W., Hess, A. 2007.   Propulsion System Prognostics R&amp;D Through the Technical Cooperation Program Aerospace Conference, 2007 IEEE, 3-10 March 2007, 8pp  Bock, J. R., Brotherton, T., W., Gass, D. 2005. Ontogenetic reasoning system for autonomic logistics. Aerospace Conference, 2005 IEEE 5-12 March 2005.Digital Object Identifier 10.1109/AERO.2005.1559677  Brotherton, T., P. Grabill, D. Wroblewski, R. Friend, B Sotomayer, and J. Berry. 2002. A Testbed for Data Fusion for Engine Diagnostics and Prognostics. Proceedings of the 2002 IEEE Aerospace Conference  Brotherton, T.; Grabill, P.; Friend, R.; Sotomayer, B.; Berry J. 2003. A testbed for data fusion for helicopter diagnostics and prognostics. Aerospace Conference, 2003. Proceedings 2003 IEEE  Brown, E. R., N. N. McCollom, E-E. Moore, A. Hess. 2007 Prognostics and Health Management A Data-Driven Approach to Supporting the F-35 Lightning II. 2007 IEEE AeroSpace Conference  Byington, C.S.; Watson, M.J.; Bharadwaj, S.P. 2008 Automated Health Management for Gas Turbine Engine Accessory System Components. Aerospace Conference 2008 IEEE, DOI:10.1109/AERO.2008.4526610 


2008 IEEE, DOI:10.1109/AERO.2008.4526610 Environment Covariates &amp; Spatial Frailty Applications: AL; Life Cycle Mgmt; Real-Time Alerts CBM+, RCM, TLCSM; Secret Sharing and Shared Control 18 Chen, Y. Q., S. Cheng. 2005. Semi-parametric regression analysis of mean residual life with censored survival data Biometrika \(2005  29  Commenges, D. 1999. Multi-state models in Epidemiology Lifetime Data Analysis. 5:315-327  Cook, J. 2004. Contrasting Approaches to the Validation of Helicopter HUMS  A Military User  s Perspective Aerospace Conference, 2004 IEEE  Cook, J. 2007. Reducing Military Helicopter Maintenance Through Prognostics. Aerospace Conference, 2007 IEEE Digital Object Identifier 10.1109/AERO.2007.352830  Cox, D. R. 1972. Regression models and life tables.  J. R Stat. Soc. Ser. B. 34:184-220  Crowder, M. J.  2001. Classical Competing Risks. Chapman amp; Hall. 200pp  David, H. A. &amp; M. L. Moeschberger. 1978. The theory of competing risks. Macmillan Publishing, 103pp  Ellison, E., L. Linger, and M. Longstaff. 1997.  Survivable Network Systems: An Emerging Discipline, Carnegie Mellon, SEI, Technical Report CMU/SEI-97-TR-013  Hanski, I. 1999. Metapopulation Ecology. Oxford University Press  Hallam, T. G. and S. A. Levin. 1986. Mathematical Ecology. Biomathematics. Volume 17. Springer. 457pp  Hess, A., Fila, L. 2002.  The Joint Strike Fighter \(JSF concept: Potential impact on aging aircraft problems Aerospace Conference Proceedings, 2002. IEEE. Digital Object Identifier: 10.1109/AERO.2002.1036144  Hess, A., Calvello, G., T. Dabney. 2004. PHM a Key Enabler for the JSF Autonomic Logistics Support Concept. Aerospace Conference Proceedings, 2004. IEEE  Hofbauer, J. and K. Sigmund. 1998. Evolutionary Games and Population Dynamics. Cambridge University Press 323pp  Hougaard, P. 2000. Analysis of Multivariate Survival Data Springer. 560pp  Huzurbazar, A. V. 2006. Flow-graph model for multi-state time-to-event data. Wiley InterScience  Ibrahim, J. G., M. H. Chen and D. Sinha. 2005. Bayesian Survival Analysis. Springer. 481pp  Kacprzynski, G. J., Roemer, M. J., Hess, A. J. 2002. Health management system design: Development, simulation and cost/benefit optimization. IEEE Aerospace Conference Proceedings, 2002. DOI:10.1109/AERO.2002.1036148  Kalbfleisch, J. D., and R. L. Prentice, 2002. The Statistical Analysis of Failure Time Data. Wiley-InterScience, 2nd ed  Kalgren, P. W., Byington, C. S.   Roemer, M. J.  2006 Defining PHM, A Lexical Evolution of Maintenance and Logistics. Systems Readiness Technology Conference 


Logistics. Systems Readiness Technology Conference IEEE. DOI: 10.1109/AUTEST.2006.283685  Keller, K.; Baldwin, A.; Ofsthun, S.; Swearingen, K.; Vian J.; Wilmering, T.; Williams, Z. 2007. Health Management Engineering Environment and Open Integration Platform Aerospace Conference, 2007 IEEE, Digital Object Identifier 10.1109/AERO.2007.352919  Keller, K.; Sheahan, J.; Roach, J.; Casey, L.; Davis, G Flynn, F.; Perkinson, J.; Prestero, M. 2008. Power Conversion Prognostic Controller Implementation for Aeronautical Motor Drives. Aerospace Conference, 2008 IEEE. DOI:10.1109/AERO.2008.4526630  Klein, J. P. and M. L. Moeschberger. 2003. Survival analysis techniques for censored and truncated data Springer  Kingsland, S. E. 1995. Modeling Nature: Episodes in the History of Population Ecology. 2nd ed., University of Chicago Press, 315pp  Kot, M. 2001. Elements of Mathematical Ecology Cambridge University Press. 453pp  Krings, A. W. and Z. S. Ma. 2006. Fault-Models in Wireless Communication: Towards Survivable Ad Hoc Networks Military Communications Conference, 23-25 October, 7 pages, 2006  Lamport, L., R. Shostak and M. Pease. 1982. The Byzantine Generals Problem. ACM Transactions on Programming Languages and Systems, 4\(3  Lawless, J. F. 2003. Statistical models and methods for lifetime data. John Wiley &amp; Sons. 2nd ed  Line, J. K., Iyer, A. 2007. Electronic Prognostics Through Advanced Modeling Techniques. Aerospace Conference 2007 IEEE. DOI:10.1109/AERO.2007.352906  Lisnianski, A., Levitin, G. 2003. Multi-State System Reliability: Assessment, Optimization and Applications World Scientific  Liu, Y., and K. S. Trivedi. 2006. Survivability Quantification: The Analytical Modeling Approach, Int. J of Performability Engineering, Vol. 2, No 1, pp. 29-44  19 Luchinsky, D.G.; Osipov, V.V.; Smelyanskiy, V.N Timucin, D.A.; Uckun, S. 2008. Model Based IVHM System for the Solid Rocket Booster. Aerospace Conference, 2008 IEEE.DOI:10.1109/AERO.2008.4526644  Lynch, N. 1997. Distributed Algorithms. Morgan Kaufmann Press  Ma, Z. S. 1997. Demography and survival analysis of Russian wheat aphid. Ph.D. dissertation, Univ. of Idaho 306pp  Ma, Z. S. 2008a. New Approaches to Reliability and Survivability with Survival Analysis, Dynamic Hybrid Fault Models, and Evolutionary  Game Theory. Ph.D. dissertation Univ. of Idaho. 177pp  Ma, Z. S. 2008b. Survivability Analysis of Biological Species under Global Climate Changes: A New Distributed and Agent-based Simulation Architecture with Survival Analysis and Evolutionary Game Theory. The Sixth 


International Conference on Ecological Informatics. Dec 25, 2008. Cancun, Mexico  Ma, Z. S. and E. J. Bechinski. 2008. A Survival-Analysis based  Simulation Model for Russian Wheat Aphid Population Dynamics. Ecological Modeling, 216\(2 332  Ma, Z. S. and A. W. Krings. 2008a.  Survival Analysis Approach to Reliability Analysis and Prognostics and Health Management \(PHM  AIAA AeroSpace Conference, March 1-8, 2008, Big Sky, MT, 20pp  Ma, Z. S. and A. W. Krings. 2008b. Competing Risks Analysis of Reliability, Survivability, and Prognostics and Health Management \(PHM  AIAA AeroSpace Conference, March 1-8, 2008.  Big Sky, MT. 20pp  Ma, Z. S. and A. W. Krings. 2008c. Multivariate Survival Analysis \(I Dependence Modeling", Proc. IEEE  AIAA AeroSpace Conference, March 1-8, 2008, Big Sky, MT. 21pp  Ma, Z. S. and A. W. Krings., R. E. Hiromoto. 2008d Multivariate Survival Analysis \(II State Models in Biomedicine and Engineering Reliability IEEE International Conference of Biomedical Engineering and Informatics, BMEI 2008.  6 Pages  Ma, Z. S. and A. W. Krings. 2008e. Dynamic Hybrid Fault Models and their Applications to Wireless Sensor Networks WSNs Modeling, Analysis and Simulation of Wireless and Mobile Systems. \(ACM MSWiM 2008 Vancouver, Canada  Ma, Z. S. &amp; A. W. Krings. 2008f. Dynamic Populations in Genetic Algorithms. SIGAPP, the 23rd Annual ACM Symposium on Applied Computing, Ceara, Brazil, March 16-20, 2008. 5 Pages  Ma, Z. S. &amp; A. W. Krings. 2008g. Bio-Robustness and Fault Tolerance: A New Perspective on Reliable, Survivable and Evolvable Network Systems, Proc. IEEE  AIAA AeroSpace Conference, March 1-8, Big Sky, MT, 2008. 20 Pages  Ma, Z. S.  and A. W. Krings. 2009. Insect Sensory Systems Inspired Computing and Communications.  Ad Hoc Networks 7\(4  MacConnell, J.H. 2008. Structural Health Management and Structural Design: An Unbridgeable Gap? 2008 IEEE Aerospace Conference, DOI:10.1109/AERO.2008.4526613  MacConnell, J.H. 2007. ISHM &amp; Design: A review of the benefits of the ideal ISHM system. Aerospace Conference 2007 IEEE. DOI:10.1109/AERO.2007.352834  Marshall A. W., I. Olkin. 1967. A Multivariate Exponential Distribution. Journal of the American Statistical Association, 62\(317 Mar., 1967  Martinussen, T. and T. H. Scheike. 2006. Dynamic Regression Models for Survival Data. Springer. 466pp  Mazzuchi, T. A., R. Soyer., and R. V. Spring. 1989. The proportional hazards model in reliability. IEEE Proceedings of Annual Reliability and Maintainability Symposium pp.252-256  Millar, R.C., Mazzuchi, T.A. &amp; Sarkani, S., 2007. A Survey of Advanced Methods for Analysis and Modeling of 


of Advanced Methods for Analysis and Modeling of Propulsion System", GT2007-27218, ASME Turbo Expo 2007, May 14-17, Montreal, Canada  Millar, Richard C., "Non-parametric Analysis of a Complex Propulsion System Data Base", Ph.D. Dissertation, George Washington University, June 2007  Millar, R. C. 2007. A Systems Engineering Approach to PHM for Military Aircraft Propulsion Systems. Aerospace Conference, 2007 IEEE. DOI:10.1109/AERO.2007.352840  Millar, R. C. 2008.  The Role of Reliability Data Bases in Deploying CBM+, RCM and PHM with TLCSM Aerospace Conference, 2008 IEEE, 1-8 March 2008. Digital Object Identifier: 10.1109/AERO.2008.4526633  Nowak, M. 2006. Evolutionary Dynamics: Exploring the Equations of Life. Harvard University Press. 363pp  Oakes, D. &amp; Dasu, T. 1990. A note on residual life Biometrika 77, 409  10  Pintilie, M. 2006. Competing Risks: A Practical Perspective.  Wiley. 224pp  20 Smith, M. J., C. S. Byington. 2006. Layered Classification for Improved Diagnostic Isolation in Drivetrain Components. 2006 IEEE AeroSpace Conference  Therneau, T. and P. Grambsch. 2000. Modeling Survival Data: Extending the Cox Model. Springer  Vincent, T. L. and J. L. Brown. 2005. Evolutionary Game Theory, Natural Selection and Darwinian Dynamics Cambridge University Press. 382pp  Wang. J., T. Yu, W. Wang. 2008. Research on Prognostic Health Management \(PHM on Flight Data. 2008 Int. Conf. on Condition Monitoring and Diagnosis, Beijing, China, April 21-24, 2008. 5pp  Zhang, S., R. Kang, X. He, and M. G. Pecht. 2008. China  s Efforts in Prognostics and Health Management. IEEE Trans. on Components and Packaging Technologies 31\(2             BIOGRAPHY  Zhanshan \(Sam scientist and earned the terminal degrees in both fields in 1997 and 2008, respectively. He has published more than 60 peer-refereed journal and conference papers, among which approximately 40 are journal papers and more than a third are in computer science.  Prior to his recent return to academia, he worked as senior network/software engineers in semiconductor and software industry. His current research interests include: reliability, dependability and fault tolerance of distributed and software systems behavioral and cognitive ecology inspired pervasive and 


behavioral and cognitive ecology inspired pervasive and resilient computing; evolutionary &amp; rendezvous search games; evolutionary computation &amp; machine learning bioinformatics &amp; ecoinformatics                 pre></body></html 


