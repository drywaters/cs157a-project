  1 Improved Verification for Aerospace Systems Mark A. Powell Attwater Consulting P.O. Box 57702 Webster, TX 77598-7702 208-521-2941 attwater@aol.com  Abstract 227Aerospace systems are subj ect to many stringent performance requirements that mu st be verified with low residual risk to the customer. This report investigates the improvements in verification planning and requirements validation made possible by using conditional approaches vice classical statistical pro cedures. The example used in this report to illustrate the results of these investigations is a 
proposed mission assurance requirement with its concomitant maximum acceptable verification risk for the NASA Constellation Program Orion Launch Abort System LAS This report demonstrates the following improvements possible through use of conditional approaches: 1 verification plans are more ach ievable and feasible than those developed using classical statistical methods; 2 historical surrogate data can be used to validate proposed performance requirements; and, 3\storical surrogate data may be incorporated in verification planning to produce even less costly and more reas onable verification plans. The procedures presented in this report may produce similar 
improvements and cost savings in validation and verification for any perform ance requirement for any aerospace system 1 2           1  1 978-1-4244-2622-5/09/$25.00 \2512009 IEEE  2 IEEEAC paper #1445, Version 4 Updated January 8, 2009  T ABLE OF C ONTENTS  1  I NTRODUCTION  1 
 2  M ETHODS  2  Comparison: Classical versus Conditional Approaches...2  Validation Considering Historical Data 5  Use of Historical Data in Verification Planning 7  3  E XAMPLE  7  Description of the Ori on Launch Abort System...............7 
 Historical Ground Test and Flight Data for Surrogate Systems Similar to the Orion LAS 8  4  R ESULTS  9  Comparison: Orion LAS Mission Assurance Verification Plans using Classical and Conditional Approaches 9  Orion LAS Mission Assurance Requirement Validation based on Histor ical Data 10  Conditional Orion LAS Verification Plan Using Historical Ground Test Data 11 
 5  C ONCLUSIONS  12  Verification Planning Using Conditional Approaches Reduces Numbers of Tests Required 12  Requirements Validation is Improved by Using Historical Data 12  Greater Verification Plan Achievability and Feasibility Results from Combining Conditional Approaches with Historical Data 12  Extensions to the Investigations.....................................12 
 R EFERENCES  13  B IOGRAPHY  13  1  I NTRODUCTION  Aerospace systems are subj ect to many stringent performance requirements. Verifi cation assures that the risk that the as-built system does not satisfy these requirements is below some level accepta ble to the customer. The customer upon accepting the ve rified aerospace system shoulders this residual risk Verification planning and 
execution for such requirements, to achieve low levels of residual risk, is often difficult and costly. For many performance requirements, verification planning that uses classical statistical methods becomes nearly impossible without many difficult to defend assumptions. The customer may be subsequently forced to accept a much higher level of residual risk than preferred, perhaps unknowingly These concerns were realized for a proposed mission assurance requirement for the NASA Constellation Program, specifically for the Orion Launch Abort System LAS 


  2 This report presents the following investigations using as an example a proposed Orion LAS mission assurance requirement with a required maximum acceptable verification risk: 1\he comparison of verification planning based on classical statistical methods with difficult to defend assumptions, and ve rification planning using conditional approaches avoidi ng indefensible assumptions 2\storical test and flight operations data from surrogate systems for valida tion of a mission assurance requirement; and, 3\use of historical test and flight operations data from surrogate systems in verification planning for a mission assurance requirement 2  M ETHODS  Verification planning is essentially an inverse hypothesis testing process. Hypothesis testing consists of three steps The first is to design and perform an experiment to obtain data about a hypothesis. The second is to process the observed data using a statistical procedure. The third is to decide, based on the results of statistical processing of the observed data from the experiment, whether to reject the hypothesis or retain it for further consideration In verification planning and execution, these steps are performed in a rather convoluted order. The first is to design an experiment to obtain data about a hypothesis for the verification plan \(to be performed later in actual verification execution\s to identify the desired outcome, rejection of the hypothesis or its retention. The third is then to determine which data sets observable from this planned experiment, that wh en subjected to a statistical procedure, would clearly lead to the decision that the desired outcome was achieved The hypotheses considered for verification planning always relate to whether or not an as-built system satisfies a requirement. The decision about the hypothesis becomes whether to accept the as-built sy stem or not. In verification planning, the objective is to find the data sets possible from the experiment, that when performed, will make this decision clear. These defined data sets establish the success criterion for the verification plan. In verification execution the experiment is performed. The data sets are then compared to those identified in the verification plan, and the decision is made based on the data actually observed Both for hypothesis testing and verification planning, the decision on the hypothesis is based on some specified acceptable level of risk of maki ng an incorrect decision. For verification planning, this is the risk of accepting the asbuilt system when the requirement is not truly satisfied even though the experiment produced the requisite data indicating successful verification. This is the residual risk that the customer shoulders with successful verification Another important factor in verification planning is the risk of the experiment failing to produce a data set defined for successful verification when the requirement is truly satisfied in the as-built system. Clearly, it is very desirable that the experiment be designed in verification planning such that this risk is very low. This is especially important for the contractor or supplier if verification results are used for contract fulfillment. Ideally, the probability of verification plan success when the as-built system truly satisfies the requirement \(the complement of this risk should exceed 90 The experiments or tests used in verification of a mission assurance requirement for an aerospace system exercise the system and observe whether the system accomplished its mission or not. The data then are a collection of Bernoulli trial results i e., num bers of observed successes and failures of the system to accomplish its mission in a testing scenario. The verification pl an for a mission assurance requirement thus defines the numbers of observed successes and failures of the mission that, when subjected to a statistical procedure, enab les the decision whether the mission assurance requirement is satisfied or not with less than some maximum acceptable residual risk In practice, a verification requirement for an aerospace system mission requirement may state the maximum acceptable verification risk in terms of a required confidence The complement of the confidence will be the maximum acceptable verification ri sk. The use of this term often leads to a misinterpretation that a confidence interval  procedure from classical statistics is required to be used in verification. As will be seen later in this report, this misinterpretation can be very costly Comparison: Classical versus Conditional Approaches Classical Statistical Procedures 227Classical statistical procedures operate on the principle of developing an experiment to produce evid ence that will support the falsity  of a hypothesis The concept i s si m p l e  i f t h e hy pot hesi s is truly false, then the data obtained from an experiment about the hypothesis, when processed by a statistical procedure or recipe, should indicate that the hypothesis is false. Falsification of a hypothesis is always possible if it is truly false, where proof that it is true when truly true may not be. If the results of the statistical processing of the data observed from the experiment do not support the falsity of the hypothesis, then the hypothesis remains under consideration as potentially being true. Classical statistical procedures never infer the truth of the hypothesis, only the falsity of the hypothesis, and the selection of the hypothesis for the procedure can be important in the design of the experiment. As a result, cla ssical statistical procedures inherently incorporate conservatism. Inability to falsify a hypothesis from a single experiment suggests nothing about whether it is true. Both classical hypothesis testing and the 


  3 equivalent confidence interval testing recipes adhere to these fundamental precepts A common misconception is that the confidence interval of classical statistics contains the probability that the hypothesis is true given the observed data C l assi cal  statistical recipes that pr oduce confidence intervals are based on a significance value, the complement of which is informally referred to as the confidence, most likely due to the name Karl Pearson gave to the interval. The probability contained in the confidence inte rval is always greater than the complement of the signifi cance value that is used to develop the confidence interval [4 e actu al p r o b ab ility contained in the classical confidence interval may be calculated from the observed data a veri fi cat i on pl an for a reliability requirement was developed based on a requirement that the verification provide 90% confidence that the requirement was satisfied. The 90% confidence interval \(based on a significance of 0.1 statistical test used to verify this requirement actually contained a 99.92% probability that the requirement was satisfied when the requisite data were observed. This resulted in an actual residual verification risk of 0.08%, far below the required 10% \(complement of the 90 confidence required\This unrequired and essentially invisible risk reduction more than doubled the cost of the verification. The inherent conservatism in using classical statistical procedures in verification planning always comes with a cost Conditional Approaches 227Conditional approaches operate on the principle of developing an experiment to obtain data to support the truth of the hypothesis. This is a much stronger proposition than the re tention of a hypothesis for consideration as true solely because data was not observed to indicate that it was false. Conditional statistical procedures infer from the data observed in the experiment the probability that the hypothesis is true. The residual risk of the hypothesis not being true for the data observed is the complement of this inferred probability Where classical statistical procedures include a host of recipes for different problems, conditional approaches are all based on one simple recipe, Bayes\222 Law  Equat i on 1 provides this simple recipe showing the uncertainty relationship between the observed data and a hypothesis h 0    00 0  Ph data Ldatah Ph 002 1 The term to the left of the proportion in equation 1 is called the posterior probability and is the probability that the hypothesis h 0 is true given the data. The hypothesis h 0  usually concerns the values of the parameters of a probability distribution model, from which the residual risk may be calculated. The first term to the right of the proportion is called the likelihood, the probability of obtaining the data or information actually observed given hypothetical values of the parameters of the probability distribution model. For data consisting solely of observed events, it is the same likelihood function used in calculating the maximum likelihood estimates. The likelihood may also include terms for probabilities of observing censored data which are not handled well if at all by classical statistical recipes. Events and observations about any phenomenon are generally independent. As such, the likelihood is usually a product of the probabilities of each event or observation given hypothetical values of the parameters. For data consisting of only actual observed events \(no censored data where the probability distribu tion model is a continuous model, the likelihood is a product of evaluations of the probability density function for the model given hypothetical values of the parameters The second term to the right of the proportion in equation 1 is called the prior probability, the joint probability for the probability distribution model parameters before processing the data. In general, selecting a model for the joint uncertainty for the parameters of any model for any phenomenon is problematic. For most probability distribution model parameters, there is no real physical meaning for these parameters, and hence no physics to govern any uncertainty about the joint relationship. The solution in this case is to use a joint model that actually reflects this lack of information about these parameters These models for the prior are called variously noninformative priors i gnorance pri o rs [3 Jeffrey 222 s pri o rs  m a xim u m entropy priors [6 and reference priors 7  As discussed in each referen ce, these uncertainty models provide the least possible information about the parameters in the inference, and thus provide maximum objectivity to the statistical inference of the posterior model provi des a list of these models for most of the commonly used probability distribution models. Using such a prior provides maximum objectivity in the inference, and indefensible assumptions are avoided Because of the linearity of th e derivative operator for real world verification problems, equation 1 can be formulated with the derivatives of the posterior and prior probabilities 5 i n g Bayes\222 Law in  term s o f  p r o b ab ility d en s ity functions as in equation 2  002 2 The posterior probability density function can always be integrated to produce probability values Verification is fundamentally used to make a decision whether or not to believe that the requirement is truly satisfied in the as-built system. Subsequently, for many aerospace systems, the decision for contract fulfillment is based on successful verification. Decision theory  exclusively uses conditiona l approaches. Verification  00 0  pd h data L data h pd h 


  4 planning seems then to be a natural application on which to apply conditional approaches A Useful Model for Mission Assurance Requirement Verification Planning 227Classical statistical procedures and conditional approaches both start by selecting a useful probability distribution model that could generate the observed data. The selection of this model should where possible be based on the physics or mathematics of the phenomenon that will generate th e data. For verification of Orion LAS mission assurance, the numbers of observed mission successes and failures form a set of Bernoulli trial results, the uncertainty for obtaining this set is naturally modeled using the binomial probability distribution model Equation 3 provides this binomial model where 361 s is the number of successes observed 361 f is the number of failures observed, and     003 is the mission assurance  003 the parameter of the binomial model. The kernel for the uncertainty model that provides the ultimate  1  1 11 f s sf n n sf sf nn Pn n nn 003\003 003 004 212 004+\004  3 Mission Assurance Requireme nt Verification Planning using Classical Statistical Procedures 227Verification planning that is based on classical statistical procedures uses the null hypothesis that the requirement is not satisfied in the as-built system Thus, the verification is considered successful if the experiment produces data that supports rejection of this null hypothesis; i.e., evidence is observed to infer that it is not true that the requirement is not  satisfied. Despite the double negative in the preceding statement, this is not equivalent to an experiment producing evidence that the requirement is in truth satisfied. If the alternate hypothesis were selected as the null hypothesis in verification planning using classical statistical procedures i.e. that the requirement is satisfied in the as-built system  then the verification would be considered successful if evidence were not observed to reject the hypothesis. In this case, failure to observe evid ence to reject the hypothesis that the requirement is satisfied in the as-built system is an even weaker proposition. Th ese subtleties escape many systems engineers in the aeros pace industry responsible for verification The classical statistical procedure suitable for use in verifying an aerospace sy stem mission assurance requirement, using as data the numbers of observed successes and failures of the mission, is the binomial test 2 e way to im p l em en t th e b i n o m ial test fo r v erificatio n  planning is to construct a one-sided confidence interval that ranges from the required mission assurance level to unity for a given significance level \(usually derived as the complement of a specified confidence level is traditionally set to the value of the maximum acceptable verification risk to be shouldered by the customer. An estimator for mission assurance is calculated from the data observed from the experiment, in this case the numbers of mission successes and failures. If this estimate of mission assurance produced by the binomial test recipe falls inside this confidence interval, the hypothesis that the required mission assurance has not been satisfied by the asbuilt system is rejected, and the verification is considered successful. The objective of verification planning using the binomial test is to determine the numbers of successes and failures that if observed would produce a mission assurance estimate that will indeed fall into this confidence interval Behind the binomial test recipe is an assumption that the central limit theorem is valid for the data and experiment This is apparent in the reci pe through the use of critical points selected from the standard normal distribution. The central limit theorem is based on some key assumptions as well. These assumptions are we ll documente  3   5     8  and are 1 h e dat a are al l i ndependent and identically distributed; 2\ these probability distributions have finite means and variances; and, 3\he data numbers approach infinity. For most verification planning, this compounding of assumptions upon assumptions may be difficult to defend, especially if the verification is very expensive. It may also be easily demonstrable that these assumptions are false. Seldom can experiments used for verification of aerospace sy stems producing very large numbers of data be cost feasible. Experiments are difficult to develop that produce data that are truly independent and identically distributed. And, it is not unusual for the physics of the phenomena producing the data to indicate that the probability distribution for the data has a mean or variance that is undefined, i.e., the data are Cauchy or Lorentz distributed. The inherent conser vatism in classical statistical procedures often compensates for the limited validity of these assumptions, but with a cost. Where verification cost is a programmatic issue for an aerospace system development, these assumptions may be difficult to defend Mission Assurance Requireme nt Verification Planning using Conditional Approaches 227The operant hypothesis for verification planning using conditional approaches is that the requirement is satisfied in the as-built system Using conditional approaches, if a ve rification plan, developed for a maximum acceptable verification risk of 5%, is successful, then there is a 95% probability that the requirement is truly satisfied in the as-built design, based on the test data. This information resonates particularly well with managers making decisions to accept an aerospace system and authorize cont ractor payment for it To develop a verification plan using conditional approaches, the posterior density model must be formed for the uncertainty about the hypothesis that the requirement is indeed satisfied in the as-built system. Equation 3, the binomial probability, directly provides the likelihood for verification of a mission assurance requirement. The binomial model provides the probability of obtaining the observed data 361 s and 361 f as a function of the mission assurance 


 1 1 2 2 1  11  22 003\003\003  7 Given the mission assurance requirement  6 The probability that the mission assurance requirement is satisfied, and hence the verification risk, given that 361 s and 361 f  are observed, are obtained from an integral of the posterior density model in equation 6. Equation 7 presents this integral to calculate the probability that the true mission assurance the mission assurance    1 1 2 2  1 s f n n sf pd n n   5 objectivity for the posterior based on using the binomial model i s present e d i n equat i on 4    003\003 003  R 1 1 1 2 2 1  1 11  22 002\212 4 Equation 5 presents the kernel of the posterior density model obtained via the product of equation 3 \(the likelihood\he maximum objectivity prior in equation 4  212 212 212 212 005 s f n n sf sf pd n n nn 212 212 212  003 exceed the required mission assurance 003 R with a maximum acceptable verification risk V R   005 s f n n R sf R sf Pnn dV nn 003 003\003 003\003 003 212 212 212 003 R and the maximum acceptable verification risk V R the verification plan developed using conditional approaches finds the limiting values of 361 s and 361 f that satisfy the inequality on the right of equation 7 Validation Considering Historical Data Quite often, several systems very similar to the aerospace system of interest have been designed, tested, and fielded These surrogate systems, if fielded and flown, were verified to satisfy their performance requirements within the maximum acceptable verification risk at acceptable costs for design, implementation, and verification. The mission assurance for these surrogate sy stems, as verified and as achieved in operations, establishes the bounds of validity for the mission assurance requi rement with the specified maximum acceptable verification risk for the aerospace system of interest It is not necessary to know what the mission assurance requirements were for these surr ogate systems, or what the maximum acceptable verificati on risks were. From the surrogate systems\222 test data the numbers of test successes and failures, statistical procedures may be used to establish the actual verified mission assurance parameterized as a function of maximum acceptabl e verification risk. This parametric relationship was achievable and cost feasible else these surrogate systems would not have been fielded whether verified or not The mission assurance actually achieved in the as-built surrogate system in operations may be different from the level that was verified or verifiable, usually higher. The same statistical procedures us ed to establish the verified mission assurance parameterized as a function of maximum acceptable verification risk may be used with the surrogate systems actual operations or flight data, the numbers of successful and failed flights. This establishes the achieved operational mission assurance parameterized as a function of bounding uncertainty levels. These levels of mission assurance performance were apparently achievable and cost feasible in design and manufacture, else these systems would have never been fielded and operated These parametric relationships for surrogate systems can be used to validate the achievability and feasibility of a proposed mission assurance requirement for an aerospace system of interest, both for verification planning and operations performance. Both cla ssical statistical procedures and conditional approaches ma y be used to analyze the surrogate test and flight data to establish these parametrics Validation based on Classical Statistical Procedures 227The classical statistical proce dure used to develop this parameterization again relies upon the binomial test, with its difficult to defend assumptions. For a given set of data, the achieved mission assurance for a given significance level using the binomial test recipe is just the lower limit of the confidence interval computed from the data. Typically in practice, this significance level is set to the specified maximum acceptable verification ri sk, or complement of the confidence if so specified For a range of hypothetical maximum acceptable verification risk levels between 0.001 and 0.5, Figure 1 shows the verified or verifiable mission assurance parametric resulting from using the binomial test for a hypothetical aerospace system with test data consisting of eight mission successes and one mission failure significance levels set to the risk levels 006 006\212 003\003 003 002\212 5 This posterior density model is immediately recognizable as the kernel of a beta probability density model, and is presented in its full form in equation 6 where B 267,\267  is the beta function   1 1 2 2 1 pd 


  6  Figure 1 \226 The classical binomial test can be used to parameterize verified mission assurance as a function of maximum acceptable verification risk level for a surrogate system The solid red line in Figure 1 represents the mission assurance requirement verified to be satisfied by the as-built surrogate system, at the verification risk level on the abscissa, when the test data were eight mission successes and one mission failure processed, using the classical binomial test. A point selected on the red solid line in Figure 1 at the abscissa value of 0.1 has the following properly stated interpretation the test data indicates that the as-built surrogate system did not satisfy a mission assurance requirement below 0.64 at a 0.1 significance  This properly stated interpretation might make a customer\222s decision to accept the as-built sy stem and pay the contractor somewhat difficult. Nota bene: the double negative in the previous statement does NOT equate to the interpretation that the as-built surrogate system does satisfy a mission assurance requirement of at least 0.64 with no more than 10% residual risk  Validation based on Conditional Approaches 227The conditional approach presented earlier in this report for verification planning without using any indefensible assumptions may also be used to parameterize achieved mission assurance performance at verification risk levels To do this, equation 7 is evaluated for a given mission assurance level 003 R with surrogate system mission successes 361 s with the allowed number of failures 361 f providing the maximum acceptable level of verification risk V R For a range of hypothetical maximu m acceptable verification risk levels between 0.001 and 0.5, Figure 2 shows the verified mission assurance thus obtained, compared with that obtained using the binomial test, for a hypothetical aerospace system with test data of eight mission successes and one mission failure  Figure 2 \226 Conditional approaches, without using indefensible assumptions, indicate levels of verified mission assurance superior to those obtained using the classical binomial test The surrogate system given its test data was verified to achieve at least the mission assurance level as indicated by the dashed blue line in Figure 2, at the verification risk on the abscissa when using conditional approaches. A point selected on the dashed blue lin e in Figure 2 at the abscissa value of 0.1 has the following properly stated interpretation there is a 90% certainty that the as-built surrogate system satisfied a mission assurance requirement of at least 0.7  based on the test data An equivalent interpretation at the same point is there is no more than a 10% risk that the asbuilt surrogate system did not satisfy a mission assurance requirement at least 0.7 based on the test data These statements do make the customer\222s decision to accept the as-built system and pay the contractor rather straightforward Note the conservatism inherent using the classical statistical procedures; everywhere in Figure 2, the verified mission assurance for the dashed blue line is higher than for the solid red line for all verification risk levels. This conservatism using the binomial test means that more than eight test successes would be needed using the binomial test to achieve the mission assurance level produced using conditional approaches for every verification risk level These additional tests mean additional costs 


005     7 Such investigations considering historical data for surrogate aerospace systems allow valida tion of the reasonableness feasibility, and achievability of a proposed mission assurance requirement at the maximum acceptable verification risk for the syst em of interest. The mission assurance parametrics for the fielded surrogate system in test and operations, calculable from the historical data, were achieved and verifiable; else it would not have been fielded The cost of the verification of the parametric performance must have been acceptable; el se the verification would not have been performed. This information on surrogate systems yields invaluable insight into the validity of the performance requirements and ve rification risk, as well as into the design and verification for the system of interest As will be seen later in this report, flight data quantities are usually much larger than test data quantities, and better mission assurance performance is usually achieved in actual mission flights than in testing at the same level of risk Actual flight mission assurance may be much more stringent than can be co st feasible to verify Use of Historical Data in Verification Planning Quite often, the similarities of surrogate aerospace systems to the system of interest extend to commonalities in design and manufacturing standards, and even to the manufacturers themselves. In these cases, it is reasonable to expect that the system of interest will exhibit similar properties and performance as the historical systems. While classical statistical procedures offer no means to take advantage of surrogate test data in verification planning, conditional approaches do If in equation 6 361 s and 361 f are the surrogate test data, then the left hand side represents a reasonable model of uncertainty for mission assurance for the aer ospace system of interest prior to its design and manufacture. Thus, rather than use a prior of maximum objectivity as in equation 4 to form the posterior density model for ve rification planning, equation 6 using the surrogate test data is used as the prior density model. Multiplying equation 6 with the likelihood of equation 3 with number of test successes n s with the allowed number of failures n f provides a posterior density model for a verification plan that takes advantage of the surrogate test data. The plan to verify a mission assurance 003 003\003 003\003 003 212 212 006  R 1 1 1 2 2   1 11  22 1 ss ff Rsfsf nn nn ss f f R Pnnnn d nn n n V 003 R requirement with a maximu m acceptable verification risk  V R that takes advantage of the surrogate test data 361 s and 361 f is obtained by solving equation 8 for n s and n f   212  006\212 8 The posterior density model t hus obtained using equation 6 as a prior for verification planning, taking advantage of the surrogate system test data 361 s and 361 f is the integrand in equation 8, another beta probability density model. As will be seen later in this report, the numbers of tests successes and failures allowed obtaine d from equation 8 can be considerably smaller than if the surrogate system test data are ignored A caveat for this process is appropriate at this point for using surrogate data for both validation and verification The determination of suitability of surrogate system test data, as representative of the system of interest, requires serious and thorough engineering analysis and judgment Inappropriate application of data always invalidates a statistical process 3  E XAMPLE  Description of the Orion Launch Abort System The Orion Launch Abort System \(LAS\is a rocket-based system mounted atop the Orion Crew Exploration Vehicle 9 e Orio n LAS will b e th e first su ch system  to  b e employed by NASA since the Apollo program The primary function of the Orion LAS is to provide crew survival should the Ares I launch vehicle explosively malfunction on the pad or during launch. The Orion LAS accomplishes this function by firi ng solid rockets that safely take the Orion capsule containing the astronauts away from the malfunctioning Ares I launch vehicle. The Orion crew is not expected to survive should the Orion LAS not function when needed. Successful operation of this system will be required on every Orion flight, regardless of whether the system is merely jettisoned, or used for pad or launch abort Therefore, the Orion LAS must be designed to achieve a high level of mission assurance performance, which must be verified with a low level of verification risk. As such, the Orion LAS will have a very stringent mission assurance requirement to assure crew survival should an Ares I launch vehicle malfunction Figure 3 shows the Orion LAS attached to the Orion capsule at the very top 


  8  Figure 3 \226 The Constellation Ares I stack, showing the Orion Launch Abort System atop the Orion Crew Exploration Vehicle Verification of this mission assurance requirement at a reasonable level of risk to be shouldered by NASA can be very expensive. A proposed mission assurance requirement considered initially for the Orion LAS was 0.9973 with a maximum acceptable verification risk of 10%, stated as a 90% confidence  3 These proposed requirements indicate that the maximum acceptable risk of Orion LAS mission failure is 0.0027, or 0.27%, and that the maximum acceptable risk of exceeding this value after successful testing is 10 Acceptance of the Orion LAS w ith a successful verification means that NASA accepts no more than a 10% risk that the 8  3 The term \223confidence\224 is subject to misinterpretation between managers and statisticians, and thus between ma nagers and verifica tion planners. For the Constellation program, NASA Associate Administrator Scott \223Doc\224 Horowitz defined the term as \223\205 a calculation of the probability of performing a certain task over a given time within a specific budget percent chance that a given project will cost an indicated amount or less  def i nition establishes for the Constellation Program relevant to verification of performance requirements is that a 22390% confidence\224 is defined as a 90 probability that the performance requirement is satisfied with a successful verification risk of loss of mission and crew due to failure of the Orion LAS exceeds 0.27 Historical Ground Test and Flight Data for Surrogate Systems Similar to the Orion LAS Forty-one different system were i d ent i f i e d as bei ng sufficiently similar to the proposed design for the Orion LAS to merit consideration for validation and verification planning for the Orion LAS. Appendi l i s t s t h ese surrogates with relevant descriptive data as well as ground test and flight mission assurance data. Appendix B of  describes in detail the in-depth engineering analysis involved in selecting these systems as suitable surrogates for the Orion LAS. All 41 of these surrogate systems were fielded. Numbers of successful and failed ground tests as well as numbers of successful and failed flights were provided. Table 1 lists the aggregation of the ground test and flight results data from these 41 surrogate systems Table 1: Aggregate Surrogate Data Considered for Validation and Verification Planning for the Orion LAS Data Type 361 s 361 f  Ground Tests 263 5 Flights 4381 8 Totals 5094 13  The numbers of successes in column two of Table 1 reflect the numbers of times that the surrogate systems successfully accomplished their intended function in the launch mission in ground test and/or flight. The numbers of failures in column three of Table 1 reflect the numbers of times the surrogate systems were fire d and did not accomplish their intended function in the launch mission in ground test and/or flight. The 41 surrogate systems averaged fewer than seven tests, with only nine using more than 10 tests, and with one using a maximum of 39 tests. Only eight of the surrogate systems had more than 100 flights, with one having 1,888 flights It is important to note that none of these surrogate systems had construction and performan ce characteristics identical to the proposed Orion LAS design. There indeed is a wide variety of surrogate systems\222 designs and performances listed in Appendi t h at broadl y  bracket  t h e current  design concepts for the Orion LAS. The engineering analysis concluded that design and manufacturing for solid rockets is a relatively mature art, conducted by a very small number of firms in the industry, and that the Orion LAS would be designed, manufactured, and tested, using 


  9 sufficiently similar standards a nd processes as used for the surrogate systems selected 4  R ESULTS  The methods discussed in section 2 of this report are employed for the proposed Orion LAS mission assurance requirement with the stated maximum acceptable verification risk. Verification plans developed with both classical and conditional approaches are compared Validation of the Orion LAS mission assurance requirement is performed using historical surrogate data. And, a costfeasible verification plan is developed for a valid Orion LAS mission assurance requirement by incorporating historical surrogate ground test data Comparison: Orion LAS Mission Assurance Verification Plans using Classical and Conditional Approaches Table 2 provides the minimum numbers of successes for the specified number of allowed failures that will define successful verification of the proposed Orion LAS mission assurance requirement as developed using classical statistical procedures. These data numbers will produce an estimate of mission assurance that will fall in the rejection region for a 90 confidence interval for the binomial test Table 2 also provides in co lumn three the associated probability of verification pl an success given that the mission assurance requirement is truly satisfied in the asbuilt design Table 2: Data Required fo r Successful Verification Based on the Binomial Test n s  n f  P V success  852 0 9.88 1439 1 14.90 1968 2 15.49 2470 3 15.63  To verify this proposed Orion LAS mission assurance requirement, with a 90 confidence interval the numbers of tests required in Table 1 would be prohibitively expensive, even allowing no failures. Recall that the largest number of tests among the surrogate systems was only 39 and the average number of surrogate tests was less than 7 Column three in Table 1 indicates that even if the proposed Orion LAS mission assurance requirement of 0.9973 were satisfied in the as-built design, the probability of obtaining the specified numbers of succe sses with no more than the allowed number of failures is terribly low. If contract fulfillment depends on successful verification of this requirement, then column three provides the probability that the contractor would get paid if they Orion LAS they designed and built satisfied the proposed mission assurance requirement. There is always a trade between verification cost and the values in column 3. Contractors supplying the Orion LAS to NASA will generally want much higher values than presented in column 3, especially if contract payment depends on successful verification Table 3 illustrates that improvements in test numbers result from verification planning using conditional approaches over using classical statistical procedures in numbers of tests required and probability of verification success Table 3: Comparison of Data Required for Successful Verification Obtained using Classical and Conditional Procedures in Verification Planning Classical from Table 2 Conditional n s  P V success  n s  P V success  n f  852 9.88% 501 25.81 0 1439 14.90% 1156 31.75 1 1968 15.49% 1707 36.57 2 2470 15.63% 2221 40.58 3  The improvements in verification planning using conditional methods as displayed in Table 3 are rather dramatic. However, too many tests are still required for the verification plan to be cost feasible, and the probabilities of verification plan success do not approach the desirable range above 90%. The expense of testing 501 Orion LAS is just not consistent with a system that may be used in fewer than 100 missions. Even if the expense were reasonable there is still an almost 75% probability that the verification plan would fail if the stringent 0.9973 mission assurance requirement were truly satisfied in every as-built Orion LAS from column four in Table 3 The conservatism of using cla ssical statistical procedures for verification plan development \(Table 3, comparing columns 1 and 3\s readily apparent, and significantly increases the expense of verification and reduces the probability of verification success 


  10 Orion LAS Mission Assurance Requirement Validation based on Historical Data The historical ground test and flight data for the 41 surrogate systems discussed in section 3 of this report were processed with the conditional procedure in section 2 to parameterize achieved mission assurance as a function of residual risk level \(verification risk in the case of the ground test data for each surrogate system the achieved risk levels at the proposed Orion LAS mission assurance requirement of 0.9973, calculated from both ground test data and flight data  Figure 4 \226 Achieved risk levels at a mission assurance level of 0.9973 for the 41 surrogate systems only fell below the 10% maximum acceptable level in one case and that from actual flight data In Figure 4, the vertical lines merely connect the achieved verification risk based on the ground test data with that based on the flight data for each surrogate system. None of these surrogate systems achieved mission assurance performance of 0.9973 verified within a 10% residual risk Only one of the surrogate systems achieved less than 10 risk for a mission assurance of 0.9973 with actual flights The lowest achieved verification risk for ground tests for the mission assurance of 0.9973 was more than 60%, hardly a level acceptable by most aerospace system customers. For most of these surrogate systems, there was more flight data than ground test data. There are 11 surrogate systems in Figure 4 for which the achieved risk using flight data was higher than that using ground test data. In five of these cases, there were fewer flights than ground tests, and higher achieved risk should be expected with fewer data. For the remaining six surrogate systems with higher flight than ground test achieved risk, all of the ground tests attempted were successful and there were one or more failures observed in actual flights, albeit with larger numbers of flights than tests. A single fa ilure in a set of successful Bernoulli trials can dramatically increase the achieved risk and again this should be expected. Tables 2 and 3 demonstrate this effect by virtue of the dramatically increased numbers of successes needed to assure the same level of verification risk when failures occur. Based on figure 4, the proposed Orion LAS mission assurance requirement of 0.9973 may not have been achieved widely in industry, and rarely verified at 10% residual risk Figure 5 illustrates for each surrogate system the achieved mission assurance at the proposed Orion LAS verification risk of 10%, calculated from both ground test data and flight data  Figure 5 \226 Achieved mission assurance for the 41 surrogate systems only exceeded 0.9973 at a 10 verification risk in one case, and that from actual flight data In Figure 5, the vertical lines merely connect the achieved mission assurance based on the ground test data with that based on the flight data for each surrogate system. While the scale of Figure 5 is too coarse to demonstrate this, none of these surrogate systems achieved a mission assurance of 0.9973 verified at a 10% risk level based on the ground test data. Only two surrogate systems achieved verification based on ground test data\a mission assurance level above 0.9 at 10% risk. While many of the surrogate systems achieved mission assurance levels above 0.9 at a 10% risk considering actual flight data, only one achieved a mission assurance above 0.9973 at a 10% risk. This surrogate system had 26 test successes out of 26 tests, and 1880 flight successes of 1888 flight attempts 


  11 Figures 4 and 5 overall may provide some significant insight into the state of th e art for rocket design and manufacture. While the 10% maximum acceptable verification risk level is not an unusual verification risk value, a mission assurance requirement of 0.9973 may be rare. Better than half of the 41 surrogate systems in figure 5 achieved mission assurance in ground tests better than 0.7 with no more than 10% verification risk, and only 15 exceeded an achieved mission assurance of 0.8 Considering the discussion in section 3 of this report concerning how these surrogate systems broadly bracketed the performance and design characteristics of the Orion LAS, it is illuminating to investigate the aggregate mission assurance performance. Table 4 provides the achieved verification risk for a mission assurance level of 0.9973 and the achieved mission assurance level for a 10% verification risk for the aggregated data in Table 1 Table 4: Achieved Mission Assurance and Verification Risk based on Aggregate Surrogate Systems Data Data Type 361 s 361 f  Achieved Risk for 0.9973 Mission Assurance Achieved Mission Assurance at 10 Risk  Ground Tests 263 5 99.97% 0.9680 Flights 4381 8 7.19 0.9974 Totals 5094 13 43.28 0.9964  The parameters in the rightmost two columns of Table 4, as calculated from the flight data, suggest that systems similar to the proposed Orion LAS generally perform in flight with mission assurance slightly better than the proposed required level of 0.9973, with a no more than a 10% risk. However the calculations using the aggregate ground test data suggest that surrogate systems were verified at lower mission assurance levels at 10% verification risk. Considering the aggregate data from these surroga te systems, it appears that if a mission assurance of 0.97 is verified at 10% risk, then better mission assurance performance, perhaps close to the proposed Orion LAS 0.9973 level, can be achieved in actual flight at less than a 10% risk. Thus, an ambitious yet valid mission assurance requirement to be verified at 10% risk to be considered for the Orion LAS then would be at 0.97. The remaining validation question is whether or not verification of a 0.97 mission assurance requirement is achievable and cost feasible Conditional Orion LAS Verifica tion Plan Using Historical Ground Test Data As discussed in section 2 of this report, a verification plan can be developed taking advantage of historical surrogate data. The historical surrogate data that is appropriate for verification of a mission assurance requirement for the Orion LAS is the aggregate ground test data in Table 1 Table 5 presents the plans developed using classical statistical procedures and using conditional approaches to verify a 0.97 mission assurance requirement for the Orion LAS with a 10% risk Table 5: Data Required for Successful Verification of 0.97 Mission Assurance with 10% Risk Using Classical Methods and Conditional Approaches taking Advantage of Surrogate Systems\222 Ground Test Data Classical Conditional n s  P V success  n s  P V success  n f  76 9.88% 18 57.80 0 128 14.90 59 67.00 1 174 15.49% 100 74.80 2 218 15.63% 140 81.5 3  The verification plans in the two leftmost columns of Table 5 are again developed using the binomial test, and cannot take advantage of the surrogate test data. The reduction of required test successes needed in column one of Table 5 vice in Table 2 is solely due to the relaxed mission assurance requirement to be verified As indicated in [11 o n e o f th e in itiato rs o f  th is investigation was a discussion about the numbers of tests needed to verify the proposed 0.9973 mission assurance requirement with no more than a 10% risk \(stated in  as a 90% confidence\The total number of tests being considered as cost feasible based on heuristics was 15, very close to the 18 required in Table 5 if no failures occur when conditional approaches are used in verification planning for the mission assurance requirement of 0.97. The probability of verification success given that the 0.97 mission assurance requirement is satisfied in the as-built Orion LAS does not reach the preferred level above 90%. However, there is a better than two-fold improvement over the original conditional verification plan and five-fold improvement over the classical verification plan 


  12 5  C ONCLUSIONS  The investigations in this report yield three important conclusions for improving valid ation and verification of aerospace systems\222 performance requirements, and suggest a number of investigatory extensions. The improvements should be extensible to validation and verification of any performance requirement for any aerospace system Verification Planning Usi ng Conditional Approaches Reduces Numbers of Tests Required Conditional approaches are used as the basis for applying decision theory. Veri fication for aerospace systems always supports the decision making process for acceptance of the system. Therefore, verification planning using conditional approaches is suitable and appropriate for aerospace systems As demonstrated in section 2 of this report, conditional approaches can be used with models of maximum objectivity to eliminate most, if not all, questionable assumptions. This is not possible when developing a verification plan using classical statistical methods. As observed with the Orion LAS mission assurance requirement example, the use of maximum objectivity models in verification planning did not introduce any unnecessary inherent conserva tism, producing verification plans using fewer numbers of tests, with higher probabilities of verification success than those developed using classical statistical methods. This results in more cost feasible verification plans due to the reduced numbers of tests that need to be performed Requirements Validation is Improved by Using Historical Data When considering verification planning for a stringent aerospace system requirement, hi storical surrogate systems data may be used with conditional methods to investigate actual achieved requirement performance levels in both verification and operations as a function of residual risk Surrogate systems that were fiel ded, were verified to satisfy their performance requirements at stated verification risk levels, and were cost feasible in design, manufacturing, and verification. Conditional approaches allow this validation process to be performed without any knowledge of the actual requirements levied on the surrogate systems, and without using any indefensible assumptions As was observed in this report for the proposed mission assurance requirement for the Orion LAS, 41 surrogate systems actually performed close to the Orion LAS requirement in operations considering the aggregated data However, none of these surrogate systems were verified to the level of the proposed Orion LAS mission assurance requirement with the stated residual verification risk. This suggests that the industry that produced the surrogates, and that will produce the Orion LAS, may indeed design and built such systems to perform at levels that cannot be verified at those levels at a feasible cost. Relaxing the stringency of the Orion LAS mission assurance requirement to the 0.97 level for verification purposes should be valid based on results from processing the aggregate surrogate systems data Further, consider that the Ares I rocket will be designed manufactured, and verified by the same industry that does so for the Orion LAS. A 0.97 mission assurance for the Ares I means that there is a 3% risk of failure. The Orion LAS with a mission assurance requirement of 0.97 has a 3 risk of failing, given that the Ares I fails. With these values for mission assurance requirements for both vehicles, the actual risk of loss of crew due to failure of the Orion LAS when the Ares I fails is the product of these two risks, a 0.09% risk When ground test and flight data from surrogate systems is available, conditional approaches may be used to validate both the level of required performance and required maximum acceptable verification risk for the system of interest Greater Verification Plan Achievability and Feasibility Results from Combining Conditional Approaches with Historical Data Beyond the improvements offered to verification planning when using conditional approaches, the cost feasibility can be further improved if historical surrogate system data are available. As seen for verification of the Orion LAS mission assurance requirement in Table 5, once relaxed to a validated level, a verification plan taking advantage of the historical surrogate systems\222 ground test data can be developed that can be cost feasible, with a greatly improved probability of verification success Extensions to the Investigations Conditional approaches may be used to predict future system performance based on observed data, i.e., test results 7 n s id erin g th at an ticip ated use of the Orion LAS may be limited to fewer than 100 flights, it is possible to predict the probabilities for number of failures of the Orion LAS among a fixed number of flights, given numbers of surrogate ground test and fli ght successes and failures and actual Orion LAS verification results. Factoring these results into verification planni ng, coupled with requirements validation based on processing surrogate data using conditional approaches, may yield further improvements in cost feasibility for verification of stringent requirements for aerospace systems  


  13 R EFERENCES  1 th o n y J. Hayter, Pro b ab ility an d Statistics fo r En g i n eers and Scientists, Third Edition, Belmont, CA, Duxbury 2007 2 C. J. Clo p p er  E S Pear son, \223The Use of Confidence or Fiducial Limits Illustrated in the Case of the Binomial,\224 Biometrika, 26, 404-413, 1934   Jam e s O. Berger, Statis tical Decision Theory and Bayesian Analysis, Second Edition. Springer-Verlag, New York, 1980 4 A. Po well, \223Op tim al an d  Ad ap tab l e Reliab ility Test Planning Using Conditional Methods,\224 Proceedings from the 14 th Annual International Symposium, International Council on Systems Engineering, Toulouse, FR, June 20\226 24, 2004  Harold Jeffreys, Theory of Probability. Oxford University Press, Oxford, 1939  Edward Jaynes, \223Prior Pr obabilities\224. IEEE Transactions Systems, Science and Cybernetics, 4, 227-291, 1968   Jose Bernardo and Adrian Smith, Bayesian Theory. John Wiley & Sons, LTD, New York, 1994   Howard Raifa and Robert Sc hlaifer, Applied Statistical Decision Theory. John Wiley & Sons, Inc. New York 1960 9 Brian Mu irh ead 223Co n stella tion Architecture and System Margins Strategy,\224 Proceedin gs from the International Astronautical Congress, Glasgo w, Scotland, September 29 226 October 3, 2008 10  Sco tt \223Do c\224 Ho ro witz, \223Cu rren t  Co n stellatio n  Planning,\224 presented to the House Science and Technology Committee Staff, March 13, 2007   M a rk A. Powell, Safety and M i ssion Assurance Special Assessments, CxP Orion LAS Verification Planning Evaluation Report, Repository Number: JS-2008-002 November 12, 2007      B IOGRAPHY  Mark Powell has practiced Systems Engineering for over 35 years in a wide range of technical environments including DoD, NASA, DOE, and commercial. More than 25 of those years have been in the aerospace arena. His roles in these environments have included project manager, engineering manager, chief systems engineer, and research scientist. He is currently an adjunct member of the Stevens Institute of Technology Syst ems Engineering Faculty, and of the University of Houston, Clear Lake Systems Engineering Faculty. Mr. Powell maintains an active engineering and management c onsulting practice \(currently in affiliation with SAIC\ North America, Europe, and Asia. Beyond consulting, he is sought frequently as a symposium and conference speaker and for training workshops, and tutorials on various topics in Systems Engineering, Project Management, and Risk Management Mr. Powell is an active member of AIAA, Sigma Xi, the International Society for Bayesian Analysis, and the International Council on Systems Engineering, where he serves as Assistant Direct or for Systems Engineering Processes  


  14  


2008, vol. 278/2008. Boston: Springer, July 2008, pp. 477  492 24] T. Neubauer, C. Stummer, and E. Weippl  Workshop-based Multiobjective Security Safeguard Selection  in Proceedings of the First International Conference on Availability, Reliability and Security ARES IEEE Computer Society, 2006, pp. 366  373 25] T. Neubauer and C. Stummer  Interactive Decision Support for multiobjective COTS Selection  in Proceedings of the 40th Annual Hawaii International Conference on System Sciences, no. 01, 2007 26    Extending Business Process Management to Determine Ef?cient IT Investments  in Proceedings of the 2007 ACM Symposium on Applied Computing, 2007, pp. 1250  1256 27] W3C  OWL - web ontology language  http://www.w3.org/TR/owlfeatures/, February 2004 28] J. Burtles, Principles and Practice of Business Continuity: Tools and Techniques. Rothstein Associates Inc., 2007 29] T. R. Peltier, Information Security Risk Analysis, 2nd ed. Auerbach Publications, 2005 30] S. Kairab and L. Kelly, A Practical Guide to Security Assessments Boston, MA, USA: Auerbach Publications, 2004 Proceedings of the 42nd Hawaii International Conference on System Sciences - 2009 10 pre></body></html 


well as from practitioners, is available, IL strategy including DWH/BI strategy IL strategies are addressed at all, either actual artifacts/documents are proposed without an integrating meta model/methodology, or the strategy making process is described without proposing specific and consistent result templates/structures Since it consumes a significant amount of resources and may constitute significant potentials for business, IL needs strategy. IL strategy must not be limited to hardware/software selection and architectural considerations, but should address the entire business scope of sourcing services, integrating acquired and self-made services into customer-oriented IL solutions, and delivering such solutions to create customer value Our survey of the state of IL strategy in practice reveals that IL sourcing, IL delivery and IL portfolio strategies are regarded as important strategy components. The larger companies are, the more international their focus is, and the more their IL is organized according to the CC model, the more components of a supply-chain oriented explicit IL strategy they are likely to have deployed The IIM model provides a suitable conceptual foundation for structuring such strategy components and also provides best practices from IT management which often can be easily adapted to IL. Regarding IL product/service development and maintenance certain functional oriented strategy sub-components are differentiated in our framework. These strategy components are adapted from an established data management functional framework in order to reflect IL specifics. While traditional, more technically oriented sub-components such as system and data architecture are covered in most companies, business oriented components like change management and project/business requirements management are covered less frequently. Additional research is necessary to develop appropriate solution components based on existing fragments and experiences Based on a more complete comprehension of IL strategy and its components, the strategy development and update process needs to be addressed in future research as well. Instead of developing and updating business strategies, IT strategies and IL strategies in independent processes, dependencies and cycles need to be addressed. A comprehensive understanding of IL strategy and respective processes may also serve as a foundation for establishing maturity models, reference models and best practices  References 1] Arnott, D. and G. Pervan, Eight key issues for the decision support systems discipline. Decision Support Systems 44\(3  2] Baum  l, U., Strategic Agility through Situational Method Construction. Proceedings of the European Academy of Management Annual Conference 2005, 2005  3] Burton, B., et al., Activity Cycle Overview: Business Intelligence and Information Management. Gartner Research G00138711, 2006  4] Chan, J.O., Optimizing Data Warehousing Strategies Communications of the IIMA, 5\(1  5] Earl, M., Management Strategies for Information Technology, Prentice Hall, New York et al., 1989  6] Eckerson, W.W., Data Quality and the Bottom Line 


6] Eckerson, W.W., Data Quality and the Bottom Line Achieving Business Success through a Commitment to High Quality Data. TDWI, Chatsworth, 2002  Proceedings of the 42nd Hawaii International Conference on System Sciences - 2009 9 7] Elliott, T., Implementing Business Intelligence Standards. BusinessObjects, 2004  8] English, L.P., Improving Data Warehouse and Business Information Quality: Methods for Reducing Costs and Increasing Profits, Wiley Computer, New York et al., 1999  9] Foshay, N., Best Practices in Business Intelligence Strategy. Blue Hammock, 2006  10] Friedman, T. and B. Hostmann, Management Update The Cornerstones of Business Intelligence Excellence Gartner Research G00120819, 2004  11] Gonzales, M., Creating a BI Stragey Document. DM Review, 2004\(November  12] Henderson, J.C. and N. Venkatraman, Strategic alignment: Leveraging information technology for transforming organizations. IBM Systems Journal, 32\(1  13] Hoffmann, O., Performance Management - Systeme und Implementierungsans  tze. 3 ed, Haupt, Bern et al 2002  14] Klesse, M. and R. Winter, Organizational Forms of Data Warehousing: An Explorative Analysis. in: IEEE Computer Society, Proceedings of the 40th Hawaii International Conference on System Sciences \(HICSS-40 Alamitos, 2007  15] Laudon, J. and K. Laudon, Management Information Systems: Managing the Digital Firm. 10 ed, Prentice Hall 2006  16] Losey, R., Enterprise Data Warehouse Strategy: Articulating the Vision. Dm Review, 2003\(January  17] Luftman, J.N. and R. Kempaiah, Key Issues For IT Executives 2007. MISQ Executive, 7\(2  18] MAIS and AIMS, A Business Intelligence Strategy Proposal for The University of Michigan. 2005  19] Melchert, F., Metadatenmanagement im Data Warehousing. Ergebnisse einer empirischen Studie. Institut f  r Wirtschaftsinformatik, Universit  t St. Gallen, 2004  20] Mosley, M., DAMA-DMBOK Functional Framework Version 3. DAMA International, 2008  21] Olszak, C.M. and E. Ziemba, Business Intelligence as a Key to Management of an Enterprise. in: Informing Science Institute, Informing Science + Information Technology Education, Pori, Finland, 2003  22] R  egg-St  rm, J., The New St. Gallen Management Model: Basic Categories of an Approach to Integrated Management, Palgrave Macmillan, Basingstoke, NY, 2005  23] Sommer, T., et al., Business Intelligence-Strategie bei der Volkswagen AG. in: Integrierte Informationslogistik B. Dinter and R. Winter, Editors, 2008, Springer, Berlin Heidelberg. pp. 261-284  


 24] Subramaniam, A., et al., Strategic planning for Data warehousing. Information &amp; Management, 33, 1997, pp 99-113  25] Totok, A., Entwicklung einer Business-IntelligenceStrategie. in: Analytische Informationssysteme - Business Intelligence-Technologien und -Anwendungen, P. Chamoni and P. Gluchowski, Editors, 2006, Springer, Berlin et al pp. 51-70  26] Vaduva, A. and T. Vetterli, Metadata Management for Data Warehousing: An Overview. International Journal of Cooperative Information Systems, 10\(3 298  27] Watson, H.J., D.L. Goodhue, and B.H. Wixom, The benefits of data warehousing: why some organizations realize exceptional payoffs. Information &amp; Management 39\(6  28] Watson, H.J., C. Fuller, and T. Ariyachandra, Data warehouse governance: best practices at Blue Cross and Blue Shield of North Carolina. Decision Support Systems 38\(3  29] Winter, R. and M. Meyer, Organization Of Data Warehousing In Large Service Companies: A Matrix Approach Based On Data Ownership and Competence Centers. Proceedings of the Seventh Americas Conference on Information Systems \(AMCIS 2001  30] Winter, R., Enterprise-wide Information Logistics Conceptual Foundations, Technology Enablers, and Management Challenges. ITI2008, 2008  31] Zarnekow, R., W. Brenner, and U. Pilgram, Integrated Information Management. Applying Successful Industrial Concepts in IT. 1 ed, Springer, Berlin, 2006  32] Zeid, A., Your BI Competency Center: A Blueprint for Successful Deployment. Business Intelligence Journal 11\(3    Proceedings of the 42nd Hawaii International Conference on System Sciences - 2009 10 pre></body></html 


The HyspIRI mission utilizes innovative techniques to both reduce the amount of data that must be transmitted to the ground and accommodate the required data volume on the ground The infrastructure and techniques developed by this mission will open the door to future high data volume science missions The designs presented here are the work of the authors and may differ from the current HyspIRI mission baseline A CKNOWLEDGMENTS This research was carried out at the Jet Propulsion Laboratory California Institute of Technology and was sponsored by the Space Grant program and the National Aeronautics and Space Administration R EFERENCES  K W ar\002eld T  V  Houten C Hee g V  Smith S Mobasser B Cox Y He R Jolly C Baker S Barry K Klassen A Nash M Vick S Kondos M Wallace J Wertz Chen R Cowley W Smythe S Klein L Cin-Young D Morabito M Pugh and R Miyake 223Hyspiri-tir mission study 2007-07 002nal report internal jpl document,\224 TeamX 923 Jet Propulsion Laboratory California Institute of Technology 4800 Oak Grove Drive Pasadena CA 91109 July 2007  R O Green 223Hyspiri summer 2008 o v ervie w  224 2008 Information exchanged during presentation  S Hook 2008 Information e xchanged during meeting discussion July 16th  R O Green 223Measuring the earth wi th imaging spectroscopy,\224 2008  223Moore s la w Made real by intel inno v ation 224 http://www.intel.com/technology/mooreslaw/index.htm  T  Doggett R Greele y  S Chein R Castano and B Cichy 223Autonomous detection of cryospheric change with hyperion on-board earth observing-1,\224 Remote Sensing of Environment  vol 101 pp 447\226462 2006  R Castano D Mazzoni N T ang and T  Dogget 223Learning classi\002ers for science event detection in remote sensing imagery,\224 in Proceedings of the ISAIRAS 2005 Conference  2005  S Shif fman 223Cloud detection from satellite imagery A comparison of expert-generated and autmatically-generated decision trees.\224 ti.arc.nasa.gov/m/pub/917/0917 Shiffman  M Griggin H Burk e D Mandl and J Miller  223Cloud cover detection algorithm for eo-1 hyperion imagery,\224 Geoscience and Remote Sensing Symposium 2003 IGARSS 03 Proceedings 2003 IEEE International  vol 1 pp 86\22689 July 2003  V  V apnik Advances in Kernel Methods Support Vector Learning  MIT Press 1999  C Bur ges 223 A tutorial on support v ector machines for pattern recognition,\224 Data Mining and Knowledge Discovery  vol 2 pp 121\226167 1998  M Klemish 223F ast lossless compression of multispectral imagery internal jpl document,\224 October 2007  F  Rizzo 223Lo w-comple xity lossless compression of h yperspectral imagery via linear prediction,\224 p 2 IEEE Signal Processing Letters IEEE 2005  R Roosta 223Nasa jpl Nasa electronic parts and packaging program.\224 http://nepp.nasa.gov/docuploads/3C8F70A32452-4336-B70CDF1C1B08F805/JPL%20RadTolerant%20FPGAs%20for%20Space%20Applications.pdf December 2004  I Xilinx 223Xilinx  Radiation-hardened virtex-4 qpro-v family overview.\224 http://www.xilinx.com/support/documentation data sheets/ds653.pdf March 2008  G S F  Center  223Tdrss o v ervie w  224 http://msp.gsfc.nasa.gov/tdrss/oview.html 7  H Hemmati 07 2008 Information e xchanged during meeting about LaserComm  223W orldvie w-1 224 http://www digitalglobe.com/inde x.php 86/WorldView-1 2008  223Sv albard ground station nor way.\224 http://www.aerospacetechnology.com/projects/svalbard 7 2008  223Satellite tracking ground station 224 http://www.asf.alaska.edu/stgs 2008  R Flaherty  223Sn/gn systems o v ervie w  224 tech rep Goddard Space Flight Center NASA 7 2002  223Geoe ye-1 f act sheet 224 http://launch.geoeye.com/launchsite/about/fact sheet.aspx 2008  L-3 Communications/Cincinnati Electronics Space Electronics 7500 Innovation Way Mason OH 45040 T-720 Transmitter  5 2007 PDF Spec Sheet for the T720 Ku-Band TDRSS Transmitter  L-3 Communications/Cincinnati Electronics Space Electronics 7500 Innovation Way Mason OH 45040 T-722 X-Band  7 2007 PDF Spec Sheet for the T-722  J Smith 07 2008 Information e xchanged during meeting about GDS  J Carpena-Nunez L Graham C Hartzell D Racek T Tao and C Taylor 223End-to-end data system design for hyspiri mission.\224 Jet Propulsion Laboratory Education Of\002ce 2008  J Behnk e T  W atts B K obler  D Lo we S F ox and R Meyer 223Eosdis petabyte archives Tenth anniversary,\224 Mass Storage Systems and Technologies 2005 Proceedings 22nd IEEE  13th NASA Goddard Conference on  pp 81\22693 April 2005 19 


 M Esf andiari H Ramapriyan J Behnk e and E So\002nowski 223Evolving a ten year old data system,\224 Space Mission Challenges for Information Technology 2006 SMC-IT 2006 Second IEEE International Conference on  pp 8 pp.\226 July 2006  S Marle y  M Moore and B Clark 223Building costeffective remote data storage capabilities for nasa's eosdis,\224 Mass Storage Systems and Technologies 2003 MSST 2003 Proceedings 20th IEEE/11th NASA Goddard Conference on  pp 28\22639 April 2003  223Earth science data and information system esdis project.\224 http://esdis.eosdis.nasa.gov/index.html  M Esf andiari H Ramapriyan J Behnk e and E So\002nowski 223Evolution of the earth observing system eos data and information system eosdis\\224 Geoscience and Remote Sensing Symposium 2006 IGARSS 2006 IEEE International Conference on  pp 309\226312 31 2006Aug 4 2006  223Earth science mission operations esmo 224 http://eos.gsfc.nasa.gov/esmo  E Masuoka and M T eague 223Science in v estig ator led global processing for the modis instrument,\224 Geoscience and Remote Sensing Symposium 2001 IGARSS 01 IEEE 2001 International  vol 1 pp 384\226386 vol.1 2001  M Esf andiari H Ramapriyan J Behnk e and E So\002nowski 223Earth observing system eos data and information system eosdis 227 evolution update and future,\224 Geoscience and Remote Sensing Symposium 2007 IGARSS 2007 IEEE International  pp 4005\2264008 July 2007  D McAdam 223The e v olving role of tape in the data center,\224 The Clipper Group Explorer  December 2006  223Sun microsystems announces w orld s 002rst one terabyte tape storage drive.\224 http://www.sun.com/aboutsun/pr/200807/sun\003ash.20080714.2.xml July 2008  223P anasas 227 welcome 224 http://www panasas.com  R Domikis J Douglas and L Bisson 223Impacts of data format variability on environmental visual analysis systems.\224 http://ams.confex.com/ams/pdfpapers/119728.pdf  223Wh y did nasa choose hdf-eos as the format for data products from the earth observing system eos instruments?.\224 http://hdfeos.net/reference/Info docs/SESDA docs/NASA chooses HDFEOS.php July 2001  R E Ullman 223Status and plans for hdfeos nasa's format for eos standard products.\224 http://www.hdfeos.net/hdfeos status HDFEOSStatus.htm July 2001  223Hdf esdis project.\224 http://hdf.ncsa.uiuc.edu/projects/esdis/index.html August 2007  223W elcome to the ogc website 224 http://www.opengeospatial.org 2008  223Open gis Gis lounge geographic information systems.\224 http://gislounge.com/open-gis Christine M Hartzell received her B.S in Aerospace Engineering for Georgia Institute of Technology with Highest Honors in 2008 She is currently a PhD student at the University of Colorado at Boulder where she is researching the impact of solar radiation pressure on the dynamics of dust around asteroids She has spent two summers working at JPL on the data handling system for the HyspIRI mission with particular emphasis on the cloud detection algorithm development and instrument design Jennifer Carpena-Nunez received her B.S in physics in 2008 from the University of Puerto Rico where she is currently a PhD student in Chemical Physics Her research involves 002eld emission studies of nanostructures and she is currently developing a 002eld emission setup for further studies on nano\002eld emitters The summer of 2008 she worked at JPL on the HyspIRI mission There she was responsible for the science analysis of the data handling system speci\002cally de\002ning the data level and processing and determining potential mission collaborations Lindley C Graham is currently a junior at the Massachusetts Institute of Technology where she is working towards a B.S in Aerospace Engineering She spent last summer working at JPL on the data handling system for the HyspIRI mission focusing on developing a data storage and distribution strategy 20 


David M Racek is a senior working toward a B.S in Computer Engineering at Montana State University He works in the Montana State Space Science and Engineering Laboratory where he specializes in particle detector instruments and circuits He spent last summer working at JPL on compression algorithms for the HyspIRI mission Tony S Tao is currently a junior honor student at the Pennsylvania State University working towards a B.S in Aerospace Engineering and a Space Systems Engineering Certi\002cation Tony works in the PSU Student Space Programs Laboratory as the project manager of the OSIRIS Cube Satellite and as a systems engineer on the NittanySat nanosatellite both of which aim to study the ionosphere During his work at JPL in the summer of 2008 Tony worked on the communication and broadcast system of the HyspIRI satellite as well as a prototype Google Earth module for science product distribution Christianna E Taylor received her B.S from Boston University in 2005 and her M.S at Georgia Institute of Technology in 2008 She is currently pursing her PhD at the Georgia Institute of Technology and plans to pursue her MBA and Public Policy Certi\002cate in the near future She worked on the ground station selection for the HyspIRI mission during the summer of 2008 and looks forward to working at JPL in the coming year as a NASA GSRP fellow Hannah R Goldberg received her M.S.E.E and B.S.E from the Department of Electrical Engineering and Computer Science at the University of Michigan in 2004 and 2003 respectively She has been employed at the Jet Propulsion Laboratory California Institute of Technology since 2004 as a member of the technical staff in the Precision Motion Control and Celestial Sensors group Her research interests include the development of nano-class spacecraft and microsystems Charles D Norton is a Principal Member of Technical Staff at the Jet Propulsion Laboratory California Institute of Technology He received his Ph.D in Computer Science from Rensselaer and his B.S.E in Electrical Engineering and Computer Science from Princeton University Prior to joining JPL he was a National Research Council resident scientist His work covers advanced scienti\002c software for Earth and space science modeling with an emphasis on high performance computing and 002nite element adaptive methods Additionally he is leading efforts in development of smart payload instrument concepts He has given 32 national and international keynote/invited talks published in numerous journals conference proceedings and book chapters He is a member of the editorial board of the journal Scienti\002c Programming the IEEE Technical Committee on Scalable Computing a Senior Member of IEEE recipient of the JPL Lew Allen Award and a NASA Exceptional Service Medal 21 


this paper, we only generate the size-2 patterns in the BFS phase. It will be interesting to investigate the impact on the performance if the ?rst phase is stopped at a deeper level Also, the projection is a very ef?cient method for ?nding patterns, especially for parallel implementation of pattern mining algorithms [1]. We plan to adapt the projection ideas into our algorithm and design an ef?cient parallel algorithm for mining maximal hyperclique patterns References 1] R. Agarwal, C. Aggarwal, and V. Prasad. A Tree Projection Algorithm For Generation of Frequent Itemsets. pages 350 371, Feb 2001 2] R. Agrawal, T. Imielinski, and A. Swami. Mining Association Rules between Sets of Items in Large Databases. In Proc. of the ACM SIGMOD Conference on Management of Data, pages 207216,May 1993 3] R. Agrawal and R. Srikant. Fast Algorithms for Mining Association Rules. In Proc. of the 20th Intl Conference on Very LargeData Bases, 1994 4] R. Bayardo. Ef?ciently mining long patterns from databases In Proc. of the ACM SIGMOD Conference, 1998 5] R. Bayardo and R. Agrawal. Mining the Most Interesting Rules. In Proc. of the ACM SIGKDD Conference, 1999 6] D. Burdick, M. Calimlim, and J. Gehrke. Ma?a: AMaximal Frequent Itemset Algorithm for Transactional Databases. In Proc. of IEEE Conf. on Data Engineering, 2001 7] Y. Huang, H. Xiong, W. Wu, and Z. Zhang. A Hybrid Approach for Mining Maximal Hyperclique Patterns. In In Technical Report UTDCS-34-04, Department of computer science, University of Texas - Dallas, 2004 8] J.Han, J.Pei, and Y. Yin. Mining Frequent Patterns without Candidate Generation. In Proc. of the ACM SIGMOD International Conference on Management of Data, 2000 9] M.J.Zaki and C.Hsiao. ChARM: An ef?cient algorithm for closed itemset mining. In Proc. of 2nd SIAM International Conference on Data Mining, 2002 10] R.Rymon. Search through Systematic Set Enumeration. In Proc. Third Intl Conference on Principles of Knowledge Representation and Reasoning, 1992 11] H. Xiong, M. Steinbach, P.-N. Tan, and V. Kumar. HICAP: Hierarchial Clustering with Pattern Preservation. In Proc. of 2004 SIAM International Conference on Data Mining \(SDM 12] H. Xiong, P.-N. Tan, and V. Kumar. Mining Strong Af?nity Association Patterns in Data Set with Skewed Support. In Proc. of the Third IEEE International Conference on Data Mining \(ICDM Proceedings of the 16th IEEE International Conference on Tools with Artificial Intelligence \(ICTAI 2004 1082-3409/04 $20.00  2004 IEEE 





