html><head></head><body><pre style="word-wrap: break-word; white-space: pre-wrap Abstract  Inter-cell interference \(ICI big challenge issue in cellular systems. In this work we propose an Enhanced Fractional Frequency Reuse \(EFFR with power allocation and an interference-aware reuse mechanism to achieve not only ICI limitation at cell edge but also enhancement of overall cell capacity in orthogonal frequency division multiple access \(OFDMA networks. The EFFR scheme divides the whole available bandwidth into a Primary Segment and a Secondary Segment The exclusive reuse-3 subchannels in the Primary Segment will be prior used by cell-edge users with higher transmission power whereas the remaining subchannels are all reuse-1 subchannels allowing to be used with lower power. In addition, the resources in the Secondary Segment will be occupied by means of signal-to-interference-ratio \(SINR proposed EFFR scheme in a system-level simulator and compare its performance with the well-known Soft Frequency Reuse \(SFR scheme and the classical reuse-1 scheme. In order to investigate the impact on the performance by power allocation, schemes are simulated with various power masks, and using a scenario with surrounding cells up to 2nd-tier. Simulation results show that the EFFR scheme is more flexible and robust than the SFR scheme and can gain substantial improvements in terms of both, the overall cell capacity as well as the cell-edge user performance  Index Terms  Cellular system, frequency reuse, inter-cell interference mitigation, LTE, OFDMA, WiMAX  I. INTRODUCTION HE expected convergence of fixed and mobile Internet services, the emergence of new applications and the growth of wireless subscribers will lead to an ever increasing demand for bandwidth in wireless access. With the Orthogonal frequency division multiple access \(OFDMA technique, great benefits in handling inter-symbol interference inter-carrier interference and high flexibility in the resource allocation can be reaped. Nevertheless, a big challenge issue with OFDMA still remained is co-channel interference \(CCI or so-called inter-cell interference \(ICI It is known that effective reuse of resources in a cellular system can highly enhance the system capacity. With a smaller frequency reuse factor \(FRF obtained by each cell. So, in this sense the classical FRF of 1 is desirable. However, with the usage of FRF-1, the most user  The authors are with the Chair of Communication Networks, Faculty 6 RWTH Aachen University, 52074 Aachen, Germany \(phone 49-241-8028576; fax: +49-241-8022242; e-mail: {tao|walke}@comnets rwth -aachen.de  terminals \(UTs especially near the cell edge. And that causes severe connect outages and consequently low system capacity. The conventional method to figure out this problem is through increasing the cluster-order, which can mitigate the ICI efficiently, nonetheless at the cost of a decrease on available bandwidth for each cell. This leads to restricted data transmissions and lower system spectrum efficiency To take aim at improving cell-edge performance while retaining system spectrum efficiency of reuse-1, several solutions [1]-[5] have been proposed recently. Among them the most representative approaches are the Soft Frequency Reuse \(SFR    Frequency Reuse \(IFR  concentrate on the high system spectrum efficiency with FRF-1 and efficient reduction of ICI \(especially near the cell edge simultaneously. However, the IFR scheme does not perform better than the classical reuse-1 scheme in full-load or overload situation. The performance with the usage of the SFR scheme might be advanced, compared to the classical reuse-1 system 


might be advanced, compared to the classical reuse-1 system but the resources are still underutilized. Based on a thorough analyzing of the SFR approach, in this paper we will put forward a new design referred as Enhanced Fractional Frequency Reuse \(EFFR goals, namely, to enhance the mean system capacity while restraining the ICI at cell edge. Moreover, since solutions with low system complexity and flexible spectrum usage are desirable, we will take systems with distributed radio resource management into account The remainder of this paper is organized as follows. In section II the noted SFR approach for ICI mitigation in cellular OFDMA networks is outlined. Based on a discussion of its advantages and limitations, a novel Enhanced Fractional Frequency Reuse \(EFFR which intends to further improve the overall cell capacity while retaining a better cell-edge performance with the usage of FRF of 3 to the cell-edge users. Then, in section IV, simulation results of three different frequency schemes with distinctive power masks are compared. Finally, the paper ends with some concluding remarks II. SOFT FREQUENCY REUSE The Soft Frequency Reuse \(SFR adopted in the 3GPP-LTE system [1]-[2], addresses the challenge by increasing FRF and transmission power for cell-edge users, so that the ICI from contiguous cells to those Enhanced Fractional Frequency Reuse to Increase Capacity of OFDMA Systems Zheng Xie, Bernhard Walke T 978-1-4244-6273-5/09/$26.00  2009 IEEE users can be alleviated, and thereby to improve their performance The basic idea of the SFR scheme is apply FRF of 1 to cell-centre users \(CCU CEU as illustrated in Fig. 1. Simply one third of the whole available bandwidth named Major Segment can be used by CEUs, yet on this Major Segment, packets are sent with higher power. To realize FRF of 3 for CEUs, Major Segments among directly neighboring cells should be orthogonal. In opposite to the CEUs, the CCUs can access the entire frequency resources however, with lower transmission power. The power allocation for each type of users can be calculated as 3 1 S p pP T S    1a CEU CCUP P?= ?             \(1b in which S, T stand for the total number of subchannels in a system and the available subchannels for the CEUs respectively. ? denotes the power ratio of a subchannel used by a CEU to which used by a CCU. p is used as a reference power which signifies the uniform transmit power used on each subchannel in a classical reuse-1 system. When ? equals 1 PCCU is equal to PCEU. The SFR system is a reuse-1 system When ? ? ?, PCCU, PCEU will converges at 0 and 3p respectively. The SFR system is now a reuse-3 system, but using a scheduling with Min-Throughput strategy Taking a view of the SFR design, some intrinsic limitations are exposed. For one thing, generally, there are more CEUs than CCUs in a cellular system, since the outer surface area is much larger than the inner part. However, with the SFR scheme CEUs have maximum one third of the entire bandwidth to utilize, which results in lower spectrum efficiency. Next, more CCI could happen even in a low traffic load situation, while there are still subchannels in idle and underutilized in the system. This is because the resource allocation of all cells via 


system. This is because the resource allocation of all cells via the SFR scheme starts always from the first subchannel up Lastly, in consequence of the inherent susceptibleness of the CEUs, they still will be grievously interfered by the CCU transmissions in the adjoining cells, in spite of using higher power III. ENHANCED FRACTIONAL FREQUENCY REUSE Aiming at the limitations of the SFR scheme mentioned above, we came up with a new design named the Enhanced Fractional Frequency Reuse \(EFFR retain the advantages of the SFR approach while avoiding its limitations, and seeks to further enhance the system capacity especially in overload situations A. Design Requirements The EFFR scheme is designed to meet the following requirements  Support flexibility with non-uniform user or traffic distribution  Support adaptation to time varying traffic conditions  Exploit possibility for self-setting up preferable reuse combinations  No need for the resource coordination among different base stations \(BS RNC the fixed resource allocation method  Applicable for high FRF systems  Low system complexity B. Concept of the Enhanced Fractional Frequency Reuse Scheme The objective of the proposed EFFR architecture is to improve system capacity while bettering spectrum efficiency at the cell edge. This can be achieved by basing on effectual mitigation of unwanted co-channel collisions for CEUs maximizing the opportunities for the other users to choose suitable resources \(time share and frequency share respectively 1 Just like the SFR scheme, the EFFR scheme defines 3 cell types for directly neighboring cells in a cellular system, and reserves for each cell-type a part of the whole frequency band named Primary Segment, which is indicated in the right part of Fig. 2 with thick border. The Primary Segments among different type cells should be orthogonal. Apart from the Primary Segment, the remaining subchannels constitute the Secondary Segment. The Primary Segment of a cell-type is at the same time a part of the Secondary Segments belonging to the other two cell-types. Each cell can occupy all subchannels of its Primary Segment at will, whereas only a part of subchannels in the Secondary Segment can be used by this cell in an interference-aware manner  Fig. 1. Concept of the SFR scheme in a cellular system based on FRF =3 for CEUs and FRF =1 for CCUs  Fig. 2. Concept of the EFFR scheme in a cellular system based on partition of exclusively reuse-3 subchannels and reuse-1 subchannels in the Primary Segment, as well as interference-aware reuse on the Secondary Segment The Primary Segment of each cell will be further divided into a reuse-3 part and reuse-1 part. The reuse-1 part can be reused by all types of cells in the system, whereas reuse-3 part can only be exclusively reused by other same type cells. To be precise the reuse-3 subchannels cannot be reused by directly neighboring cells, which attenuates the ICIs among them and therefore it is stipulated for the vulnerable CEUs to take priority of using these subchannels over CCUs 2 As we have the constant total power assumption, the power allocation on each type of subchannel can be calculated as  1_ ,3reuse subchannel S pP M N 


M N    2a  3 _ 1_reuse subchannel reuse subchannelsP P?? ?= ?     \(2b in which M, N stand for the number of available reuse-3 subchannels and reuse-1 subchannels in the Primary Segment respectively. ? denotes the power ratio employed on a reuse-3 subchannel to a reuse-1 subchannel. And p, S have the same meanings as in \(1a e.g., cell-type-A in Fig. 2 dedicated to the other two cell-types \(e.g., cell-type-B and -C in Fig. 2 equals 3 decreasing the Preuse-1_subchannel for other available reuse-1 subchannels. Otherwise, the Preuse-1_subchannel will vary with different values of the Preuse-3_subchannel. Note that with SFR, it is impossible that CEUs transmit or receive packets with power larger than 3 times of p, whereas using EFFR they can. Hence the EFFR scheme seems more flexible than the SFR to adapt to various wireless environments 3 SINR Since a cell acts on the Secondary Segment as a guest, and occupying secondary subchannels is actually reuse the primary subchannels belonging to the directly neighboring cells, thus reuse on the Secondary Segment by each cell should conform to two rules  monitor before use and  resource reuse based on SINR estimation Each cell listens on every secondary subchannel all the time And before occupation, it makes SINR evaluation according to the gathered channel quality information \(CQI resources with best estimation values for reuse. If all available secondary resources are either occupied or not good enough to a link, it will give up reusing for this link. This will not lead to a resource wasting, which means some resources maybe not reusable for this link, but can be reused by other links. And another thereby gained merit is that it will not generate excessive interferences for the neighboring cells which would degrade their performances. So, an upgrade of spectrum efficiency is expected by using the interference-aware-reuse mechanism on the Secondary Segment On the other hand, all above elucidation is based on a precise SINR estimation. However, an improper modulation and coding scheme \(PHY-mode estimation would cause to either higher packet loss rate or lower spectral efficiency, and thereupon wastes precious resources. Hence, to have a reliable SINR estimation is a crucial factor for maximizing system spectrum efficiency 4 The algorithm works as follows 1. The reuse-3 subchannels will be assigned to CEUs with the usage of the proportional faire scheduling strategy. If there are still resources remained after all CEUs are served, they will be continuing allotted to such CCUs with relatively poor SINR values 2. When the reuse-3 subchannels are exhausted, the remaining reuse-1 subchannels in the Primary Segment are allocated to residual unsatisfied users using maximum throughput strategy until demands of all users are met or the entire Primary Segment is occupied 3. If still resources are requested, available reuse-1 subchannels in the Secondary Segment will be scheduled to adequate users by applying interference-aware- operation C. Distinctions between the EFFR Scheme and the SFR Scheme The EFFR scheme owns mainly the following salient features, which are typically different to the SFR scheme  Since the users at cell edge are very weak at resisting 


 Since the users at cell edge are very weak at resisting ICIs, the reuse-3 subchannels in the Primary Segment for each cell are exclusively available for the users in the same type cell. This means real reuse-3 is applied on these subchannels, and for each cell not the whole bandwidth is available  In order to advance spectral efficiency, users which are allotted shares of the reuse-3 subchannels, should send packets with higher transmission power, whether they are CCUs or CEUs. In contrast, to reduce excessive interferences to the neighboring cells and avoid unwanted power wasting, packets will be sent on a reuse-1 subchannel in lower strength  Allocation of reuse-1 subchannels in the Secondary Segment is not blindly carried out, but in an interference-aware way according to the SINR estimation  In the Primary Segment unsatisfied users, whether they are CCUs or CEUs, have the same chance to get resources in the Secondary Segment, if they can find usable resource in accordance with the SINR estimation With the above introduced EFFR design, we can notice that several relevant factors play paramount roles in the realization and could influence the system performance severely, such as 1 3 threshold for reuse etc.. In what follows, we will focus on the effects on performances by using the EFFR scheme with varying ratios of M to N and different power ratios  IV. EVALUATION The Open Wireless Network Simulator \(OpenWNS framework for the implementation of event driven wireless network protocol simulators. It has been developed at the Chair of Communication Networks RWTH Aachen University, and is used for the implementation of several wireless network protocols like GSM, UMTS, IEEE 802.11, IEEE 802.16 [6 We have integrated the SFR scheme and the proposed EFFR scheme into the so-called WiMAC module, which is an implementation of the IEEE 802.16 standard in the OpenWNS With simulations we aim to demonstrate the effectiveness of the proposed EFFR scheme in terms of improvement of CEU throughput as well as mean cell capacity. We will compare the performance of the devised EFFR scheme with three M to N combinations \(8:2 | 7:3 | 6:4 scheme and the classical reuse-1 scheme. An OFDMA uplink cellular system in an omni-cell case for simulations is considered. UTs are uniformly distributed within each hexagonal cell. We assume the total system transmission power is kept constant, and each UT has a maximal transmission power of 200mW. Fig. 3 instantiates the corresponding used cell-specific power masks in response to diverse spectrum usage for studied approaches. The other main relevant parameters used in simulations are shown in Table I. And switching thresholds for the PHY-modes in [7] are adopted  TABLE   I SIMULATION PARAMETERS Parameter Value System bandwidth 20 MHz Center frequency 5470 MHz Subcarriers \(FFT size OFDMA symbol duration 102.858 ?s Number of subchannels 30 Frame length 10 ms DL-subframe : UL-subframe 1:1 Noise figure at [BS, UT] [5, 7] dB Cell radius 1100 m Range for CEUs 550 m - 1100 m Number of interfering cells 18 \(up to 2nd tier Pass loss exponent 2.9 


UT thermal noise density -174 dBm/Hz Traffic model symmetric, neg. exp IAT  Fig. 4 displays the average cell throughput as a function of the number of users in each cell. Both SFR scheme and EFFR scheme use a power ratio ? for high to low power level of 3 The results show that the EFFR scheme can provide a remarkable improvement on the overall cell capacity. And it outperforms the other two schemes in every situation regardless of with which M to N combination. Moreover, the EFFR with M:N = 8:2 combination performs better than it with other combinations till the number of users increases to 20 Then, with a further increase of the user numbers, the advantage of EFFR with M:N = 6:4 becomes significantly. In general, the EFFR with M:N = 6:4 is able to obtain around 30 gain over the SFR scheme Detailed observations in terms of mean throughput of a CEU and a CCU are presented in Fig. 5.  Fig. 5a shows that for the CCUs the SFR scheme has a close performance to the EFFR scheme, and performs significantly better than the classical reuse-1 scheme. However, Fig. 5b exposes that the SFR works much inferior to our proposed EFFR scheme for the CEUs although it can provide more available bandwidth to the CEUs than the EFFR scheme. This is mainly due to the facts that CEUs using the SFR scheme transmit packets with lower power than those using the EFFR scheme, and simultaneously they are interfered by the near CCUs in the directly neighboring cells The Bandwidth advantage of the SFR scheme cannot pay off the effects of these limitations The merit of the EFFR scheme compared to the other schemes can also be verified by Fig. 6, which shows the cell-edge outage probabilities of the three schemes. Again the performance of the EFFR scheme gains a noteworthy advantage over the SFR scheme and the conventional reuse-1 scheme To disclose the impact on the system performance by the power allocation, Fig. 7 exhibits the average cell capacity as a function of the offered traffic per user for different schemes with various power ratio values. 25 users are uniformly distributed in each cell in the system. From the results, we came to the following conclusions: Firstly, the EFFR scheme performs better the SFR and the classical reuse-1 scheme Secondly, both the EFFR scheme and the SFR scheme with a power ratio ? of 3 surpass which with other power ratios Lastly, the power masks have severe impacts on performances of the SFR scheme, whereas using the EFFR scheme the cell capacities are similar under different power ratios. With an   Fig. 4. Mean uplink cell capacity of three frequency reuse schemes as a function of the number of users in each cell, with 333 kbps offered traffic for each user and power ratio ? = 3 for the both SFR and EFFR schemes  a b  Fig. 3. Cell-specific power masks over system bandwidth for the SFR scheme and the EFFR scheme  inappropriate power allocation, the performance of the SFR scheme will be strongly deteriorated. As a consequence, the proposed EFFR design can gain more robustness than the SFR scheme V. CONCLUSION In this paper an enhanced frequency reuse scheme, the EFFR scheme, for ICI mitigation in OFDMA networks is developed and evaluated. It designs a resource allocation-and-reuse mechanism and can provide a considerable improvement with the help of the CQI estimation. In terms of the inherent vulnerability of CEUs, the EFFR scheme reserves resources for them with two emphasizes: 1 more flexible power allocation. Taking advantage of the geographic predominance of CCUs, the EFFR scheme allows 


geographic predominance of CCUs, the EFFR scheme allows them to occupy resources with FRF-1 and interference awareness A detailed performance evaluation by means of event driven stochastic simulations is presented, whereby the EFFR scheme is compared with the conventional reuse-1 scheme and the in the 3GPP-LTE system adopted SFR scheme. The presented results show that significant cell capacity gains and increases at cell edge can be achieved with the deployment of the proposed EFFR scheme. Furthermore, with respect to the power allocation, the EFFR scheme can provide more flexibility and robustness than the SFR scheme. In conclusion, with the usage of the EFFR scheme the medium is able to be more effectively utilized, and the performance of all users including both CEUs and CCUs are advanced REFERENCES 1] 3GPP; Technical Specification Group Radio Access Network  Physical channels and modulation \(release 8  TS-36.211, Jun. 2007, version 1.2.0 2] 3GPP; Huawei  Soft frequency reuse scheme for UTRAN LTE   R1-050507, May 2005 3] K. T. Kim, S. K. Oh  An Incremental Frequency Reuse Scheme for an OFDMA Cellular System and Its Performance  in Proc. of the 67th IEEE Vehicular Technology Conference \(VTC-Spring 08 4] M. Bohge, J. Gross, A. Wolisz  Optimal Power Masking in Soft Frequency Reuse based OFDMA Networks  in Proc. of the 15th European Wireless Conference 2009, pp. 162-166, Aalborg, Denmark May 2009 5] Y. Xiang, J. Luo  Inter-cell interference mitigation through flexible resource reuse in OFDMA based communication networks  in Proc. of the 13th European Wireless Conference 2007, pp. 1-7, Paris, France, April 2007 6] IEEE 802.16-2004  IEEE standard for local and metropolitan area networks-Part 16: Air interface for fixed broadband wireless access systems  Oct. 1, 2004 7] C. Hoymann  Analysis and performance evaluation of the OFDM-based metropolitan area network IEEE 802.16  in Computer Networks Volume 49 \(2005  a   b  Fig. 5. Mean uplink throughput of each type of users as a function of the number is users in each cell, having the same environment as in Fig. 4   Fig. 7. Mean uplink cell capacity of three frequency reuse schemes with different power ratios as a function of offered traffic per user, 25 users are uniformly distributed in each cell in the system    Fig. 6. Cell-edge average outage probability of three frequency reuse schemes as a function of the number of users in each cell, having the same environment as in Fig. 4 pre></body></html 


    3\012H\(\012\012\0122I2\012 012#3,\012\015\015 012,\015,,3\012\012\015\012,\012 012 012 3\015   012   2$3  012  012 0122  012    3\012\015#+%<3\012,\015 3  012     3 012\015 012  012##\012\012 A\015    012  012 2,#A#\012\015,3,2\012 0123<\015,<3\015,#,\012  012##\012  012<\015  1 012A F  012  012 3\015 012 015 012 015 A#,\015\012\015  0C	"X  012<\012F\012&\012\\012 012\0123\015 012\012\015\012\015 015\015 012 012 012\012  2  012    012 012  2 566G!EBG7J 012 566J!6B76@N  F   879 015 012\015  1\015\012 4 NN333+2\015\012 2566@+N#N4\012\015Y=,\012  859  R\015       015 015\012  0122\015  012\012  4 7MGJ 8@9 C    012   012 012\015 012\015 015 012 012  K 015 012   BL C\012,\015   X\015 C\012,\015&%,\012\012 \012 7MM7 8B9  1 3\012 012    0122\015  012\012 4+7MEE 8D9 C  012 F+4  015 015 015  012 015#<+4\012Z1\012+5665 8E9  4   012\015 C  3   012 012\015\015\012+M@K@L##+55@!5@7+\(566B 8G9   F   C     015\012\012    015\015 012 012,\015  012 3 012 015\015\012@BK7L##+5E\\@MK5666L 8J9 012#\012\012\015+'3\012\012'\012,D6 7D!@B5+7MJ6 8M9  012 4\012\012\015  012 012 015   012K+L%	,\012#\012\012\015\015#\012\012\015 7!5@+\012,3\012,/\(	\01232\012\012+7MME 8769  012 012 012\015 012 012 4\012 0153/\(4 \012+7MM6 8779 C    4  012 1 012  012    0  012   012  012 012\015 015 012<\015 015 012  012\012\0122,\015,\0123!\012,\015 0124,\015+77M##+@6@!@57+7MJD 8759 1 1\012 1 012 F R 015\015 C<#\012   0122\012\012\015+42+4+\012\(++K+L\012 012    012 015   7B7E  EEJ!EGG+%#\015!R\012\0157MMJ 87@9  C     2 012 4    012\015 012   012 A\012\012 R 012 012"#7MJB 87B9 C  012 F+4  012\015 015 X  012X#%<+4\012\0127MGD 87D9  F 4\015\012\015 015   K4%L 012\\012\012,#NN\012\0153++\012+N#\012N 87E9 1 1 F P  C Z 012,3  012A  012\01202$ \0122<,\015"\012	\015\012 7MDE 87G9 1\012\012\012\012\012,\012^#\012\012\012 NN333+\012\012+N5NA+#,#[#VY\012Z 012<VY3\012Z\015V5ZVD   1562 978-1-4244-6571-2/10/$26.00 2010 IEEE IEEE EDUCON Education Engineering 2010  The Future of Global Learning Engineering Education A pril 14-16, 2010, Madrid, SPAIN 


q 3 q 2 q 1 q 3 q 2 q 1 a\Graph c\aph 2 q 3 q 2 q 1 b\Graph 1 Fig 8 Answer Graph for Example 10 Finally G Q is computed by combining the set of path in PathTab   PathSet  b   We show how the algorithm works by the following example Example 9 Consider the graph in Figure 4 and two query nodes s and t Weset b 6 and after sorted PathSet   p 1 p 2 p 3 p 4 p 5 p 6 p 7  as given in Table I Table II gives the value of each Tab  x y  and the set of paths in each PathTab  x y   To save space we omit Columns 0-2 and Row 0 which are all 0s Recall that PathTab  x y   p i p j  can be regarded as a subgraph consisting of the set of paths  p i p j  where the number of distinct nodes in the subgraph is y  Thus we can construct PathTab 3     p 1 p 3  from PathTab 2     p 1   since all the nodes on p 3  except v 1  appear already on p 1 InRow5 PathTab 4     p 1 p 2  was replaced by PathTab 5     p 1 p 3 p 4 p 5  since Tab 5   is now greater than Tab 4   ForRow6,since p 6 consists of three new nodes and hence we need to update Tab 6   from Tab 5   However  Tab 5    0  006  Tab 5    thus p 6 is not added and Row 6 remains the same as Row 5 For Row 7 there is only one new node on p 7  thus we add p 7 to PathTab 6   to give PathTab 7     p 1 p 3 p 4 p 5 p 7   which is the nal answer 002 TABLE II V ALUES OF Tab AND PathTab IN E XAMPLE 9 3 4 5 6 1 0.267  p 1  0.267  p 1  0.267  p 1  0.267  p 1  2 0.267  p 1  0.267  p 1  0.267  p 1  0.299  p 1 p 2  3 0.267  p 1  0.281  p 1 p 3  0.281  p 1 p 3  0.299  p 1 p 2  4 0.267  p 1  0.281  p 1 p 3  0.295  p 1 p 3 p 4  0.299  p 1 p 2  5 0.267  p 1  0.281  p 1 p 3  0.306  p 1 p 3 p 4 p 5  0.306  p 1 p 3 p 4 p 5  6 0.267  p 1  0.281  p 1 p 3  0.306  p 1 p 3 p 4 p 5  0.306  p 1 p 3 p 4 p 5  7 0.267  p 1  0.281  p 1 p 3  0.306  p 1 p 3 p 4 p 5  0.311  p 1 p 3 p 4 p 5 p 7  Example 9 shows how to nd the answer graph of only two query nodes The following example further illustrates the case when the number of query nodes is more than two Example 10 Figure 8\(a shows a graph with three query nodes Assume that all paths have the same value If we set b  9  we can either output Figure 8\(b or Figure 8\(c Figure 8\(b shows strong pair-wise relationship between any pair of query nodes while Figure 8\(c shows strong relationship among all query nodes and pair-wise connection is included only because the budget still allows Our algorithm gives Figure 8\(c which reveals another advantage of our method that it values strong relationship among all or the majority of query nodes higher than pair-wise relationship 002 We now analyze the time complexity To compute each Tab  x y   we need to check  p x  number of  Tab  x  1 y    p x  z   entries For each entry we need to perform z intersections of PathSet  v  and PathTab  x  1 y    p x  z   Thus we need O   p x  2  PathSet   time to compute each Tab  x y   Note that we can terminate the intersection as soon as we nd one path in both sets Thus in many cases the intersection terminates earlier In total we need to compute b  PathSet  table entries and hence the total running time is O  b  p x  2  PathSet  2  In practice this running time is very small since  p x    PathSet  and b are all small The space required for PathSet and Tab is O  b  PathSet    We also keep PathTab  x  1 y    p x  z  with each Tab  x  1 y    p x  z   but only for the  x  1 th row and x th row of Tab  Thus the extra space needed is at most 2 b  PathSet    In most cases  PathTab  x  1 y    p x  z   is much smaller than  PathSet   However there is a potential problem in the DP solution that G Q may not be connected or may not contain all query nodes since the DP only picks up paths according to their values Since we select paths for all s t pairs 003 s t 004 Q we simply make G Q connected with all query nodes by adding the corresponding path\(s with the highest value Thus this process may output slightly more than b nodes but should not affect clear visualization VI I NTER C OMMUNITY C ONNECTION In Section V we discuss the intra-community connection between a set of query nodes that are in the same community In this section we discuss the inter-community connection for a query that contains nodes from different communities We give the algorithm for computing the inter-community connection between the query nodes in Algorithm 2 Algorithm 2 InterConnection Input H and the query Q  Output The answer graph G Q  1 Let C be the set of all communities that contain at least one query node 2 Let A be the common ancestor of all communities in C  3 Let E com be the set of all community edges of each virtual community on the path from each C i 012 C to A  4 Construct a graph G com  from E com  5 for each pair of communities C i and C j in C do 6 Compute the shortest path between C i and C j in G com  7 Let P be the set of all shortest paths obtained in Steps 5-6 8 Sort P in ascending order of the path length 9 for each path 002 C i C j 003\012 P do 10 if  C i and C j are not yet connected in G Q  11 Find the actual path between C i and C j andadditto G Q  12 if All query nodes in Q are connected 13 Return G Q  We describe Algorithm 2 as follows In Section IV-C we construct the community hierarchy tree H that shows the relationship between the communities For example if two communities are siblings in H  then they are the closest to each other since they are to be joined as one single 
864 
864 
 


community as measured by m odularity Algorithm 2 utilizes this relationship between two communities C i and C j to rst nd the connection between C i and C j at the community level Lines 2-6 then we nd the actual path in G that connects the query nodes in C i to those in C j Line 11 We rst discuss how we nd the connection between C i and C j at the community level Let p  005 C i C j 006 be the simple path that connects C i and C j in H i.e the path from C i to A and that from C j to A in Lines 2-3 of Algorithm 2 Since all nodes on p  except C i and C j  are virtual communities we need to rst convert p into a path of actual communities Recall from Section IV-C that at each virtual community in H  we keep a set of community edges Let E com be the union of the set of community edges at each virtual community on p  From E com  we can construct a graph G com  Note that G com must contain at least one path of actual communities from C i to C j  because C i and C j are reachable to each other in G  Thus the path that connects C i and C j at the community level can be computed as the shortest path from C i to C j in G com  It has been shown in  t h at s hort e s t pat h i s i n adequat e in capturing the relation between query nodes We also do not use shortest path to nd the relation between query nodes within a community However here the context in which we apply shortest path is differen t because the distance between two communities in the community hierarchy tree does show how close they are to each other For this reason the weight of each community edge in G com is dened as the level at which the community edge is kept in the hierarchy tree since the level of the hierarchy tree shows the time the communities are combined The higher the level the greater the edge weight the later are two communities combined and so the further away is their relationship We further illustrate the concept by the following example Example 11 Consider the graph in Figure 2 and the hierarchy tree in Figure 3 For clear illustration let us assume that we obtain the set of actual communities at Level 7 instead of Level 9 that is the set of actual communities is  C 1 C 2 C 6 C 7 C 8   The set of community edges at each virtual community is as follows we have   C 7 C 8   at Level 8   C 6 C 7    C 6 C 8  at Level 9   C 1 C 2   at Level 10 and   C 1 C 6    C 2 C 8   at Level 11 Suppose that the query nodes are in C 1 and C 7  We collect the community edges along the two paths from C 1 and C 7 to their ancestor C 5 and construct G com accordingly as shown in Figure 9 There are four simple paths connecting C 1 and C 7 but the shortest path is 005 C 1 C 6 C 7 006  It can also be seen from Figure 2 that this shortest path can indeed capture the relationship between the two communities 002 C 6 C 8 C 7 C 1 C 2 11 98 9 11 10 Fig 9 G com for Example 11 We now discuss how to nd the actual path to connect two communities C i and C j based on the discovered community path Line 11 of Algorithm 2 Let p  005 C i C x C y C j 006 be the shortest path between two communities C i and C j in G com  We utilize p to nd the actual path connecting the query nodes in C i and C j  A conceptual view of how we apply p is depicted in Figure 10 C i q i u C x v w  C y C j q j Fig 10 A Conceptual View of Inter-Community Connection Recall that each community edge is associated with a set of connecting edges Thus we start from C i and nd the highest-value path from a query node to some u where  u v  is a connecting edge We nd this highest-value path using the BFS strategy in Section V-C but we do not run dynamic programming since we only need to pick one path Then we nd the highest-value path from v to w in C x  This process goes on until we reach C j  where we connect a query node in C j with the highest-value path to a connecting edge from C y  In the same way we nd the actual path from C j to C i because the connection is directi on-aware We then select the path with higher overall value to connect the query nodes in C i and C j in the answer graph The overall connection between C i and C j is controlled by both interand intracommunity concepts As depicted in Figure 10 the quality of th e connection at the community level is ensured by the community hierarchy tree based on modularity When the connection goes inside a community we apply the concepts of information throughput of nodes and information ow of paths to compute the highest-value intra-community path Finally in Algorithm 2 we rst sort the shortest paths in Line 8 and terminate the process when all query nodes are connected in Lines 12-13 This is a greedy algorithm that computes a connected answer graph by selecting the best inter-community path at each step  Since the inter-community connection is at a much coarser l evel than the intra-community connection connecting all query nodes by the greedy strategy sufces though computing the connection between all communities in C is also possible and incurs only little overhead We now analyze the complexity of the inter-community connection First nding the shortest path in G com takes O   E com  log  V com   time and  O   E com    V com   space Since the sets of community edges kept by the virtual communities are disjoint and we only require the virtual communities on the simple path from C i to C j in H   E com  is small and so is  V com   In total we need to nd   C    C  1  2 shortest paths but  C 010|Q and in general a user does not ask a query with many query nodes Computing the actual path from the shortest path p  005 C i C j 006 takes 002 C k 004 p O   C k  2  where O   C k  2  is the time for computing the voltage and information throughput of the nodes in C k  Note that the time taken for the BFS path 
865 
865 
 


selection is dominated by O   C k  2   Finally the space requirement is O  MAX  C k  2    Since the size of a community is small both the time and space are also small VII E XPERIMENTAL R ESULTS We now evaluate the performance of our algorithm for object connection discovery We run all experiments on an AMD Opteron 248 with 1GB RAM running Linux 64-bit We use the DBLP co-authorship dataset modeled as a graph The graph has approximate ly 316K nodes and 1,834K edges where a node represents an author and the edge weight is the number of papers co-authored between two authors A Performance of Community Partition We rst evaluate the performance of community partition by our greedy algorithm We test three settings of c local 10 50 and 100 and four settings of c global 10 100 1000 10000 We also compare with Newmans algorithm 13 Figure 11\(a shows that our algorithm is about an order of magnitude faster than Newmans when c local 10 Theresult also shows that when c local increases the efciency decreases which demonstrates the effectiveness of Heuristic 1 10 100 1000 10000 10 2 10 3 10 4 c g lobal Running Time \(sec c local 10 c local 50 c local 100 Newman a Running Time 10 100 1000 10000 0 50 100 150 200 250 300 c g lobal Peak Memory Consumption \(MB c local 10 c local 50 c local 100 Newman b Memory Consumption Fig 11 Performance of Community Partition For the effect of Heuristic 2 i.e c global  the performance is the best when c global  1000 When c local 10  the running time is 682 613 570 and 667 seconds for c global  10 100 1000 and 10000 respectively The result can be explained as follows When c global is too small many items are not kept in the global max-heap and hen ce we need to rebuild the heap more often When c global is too large there are too many items in the heap and hence the update of the heap takes longer Figure 11\(b shows that the peak memory consumption of our algorithm increases when c local increases since the size of the local max-heaps increases when c local increases Increasing c global  i.e the size of the global heap from 10 to 10000 only increases the memory usage for less than 1 MB since we have only one global heap However in all cases our algorithm consumes considerably less memory than Newmans We also record that the value of the modularity of the optimal community partition obtained by the greedy algorithm is 0.71 note that all the algorithms compute the same partition According to Newman 13 a m odul ari t y v a l u e o f g reat er t h an 0.3 indicates a signicant comm unity structure Therefore 0.71 is a very high value of modularity and indicates a highquality community partition B Semantics of Answer Graph A Case Study We conduct a case study to compare our answer graph with the center-piece subgraph  CEPS  10 Thi s s t udy ai ms to rst provide a more intuitive view on the answer graphs obtained by our algorithm and CEPS Then we perform a more systematic comparison in the following subsection We use the query  Jim Gray  Jennifer Widom  Michael I Jordan  Geoffrey E Hinton   The four scholars are from two different communities Gray and Widom are from the database community while Jordan and Hinton are from the machine learning community This is clearly captured by our answer graph as shown in Figure 1 which is displayed in Section I Figure 12 shows the answer graph of CEPS which is very similar to our answer graph The similarity is because both our algorithm and CEPS nd nodes that are closely related to the query nodes in order to connect them Thus the result shows that both algorithms are able to capture important nodes and paths related to the query nodes However our method not only nds a good connection between all query nodes but also for query nodes that are in the same context we put more emphasis on their connection than the existing methods Compare Figure 1 with Figure 12 we clearly see a stronger connection between Gray and Widom through both Ceri and Hellerstein in our answer graph than CEPS Michael I Jordan Jim Gray Alexander Aiken 1 3 Jennifer Widom Michael Stonebraker Tommi Jaakkola Lawrence K. Saul 3 Zoubin Ghahramani 9 Geoffrey E. Hinton 7 1 2 5 11 2 1 9 1 1 5 3 Joseph M Hellerstein Fig 12 The Answer Graph of CEPS Although the quality of the answer graphs is comparable our algorithm signicantly outperforms CEPS we take only 0.33 seconds to compute our answer graph while the computation of the CEPS takes 925 seconds We further compare the two methods using more systematic measures as follows C Performance of Object Connection Discovery We compare the performance of our algorithm PCquery with CEPS 10  W e s et t h e b udget t o b e t w i ce of t h e query size We also verify that the answer graphs obtained by PCquery and CEPS are of roughly the same size Other settings of CEPS are as its default We generate two types of queries in-community queries and random queries  which are abbreviated as cq and rq in the gures For in-community queries the nodes in a query are randomly selected from a randomly selected community For random queries the nodes in a query are randomly selected from the set of all nodes in the dataset We generate 100 queries for each type and test the query size from 2 nodes to 20 nodes Figure 13\(a reports the average running time of nding the connection for a query The result shows that PCquery is more 
866 
866 
 


than three orders of magnitude faster than CEPS for both query types We nd that PCquery takes more time to process an incommunity query than a random query This is because the computation of the intra-community connection by dynamic programming is more costly than that of the inter-community connection by tracing the c ommunity hierarchy tree 2 4 8 12 16 20 10 2 10 0 10 2 10 4 Quer y Size \(number of nodes Average Response Time \(sec PCquery \(cq CEPS \(cq PCquery \(rq CEPS \(rq a Average Response Time 2 4 8 12 16 20 0 100 200 300 400 500 600 700 Quer y Size \(number of nodes Peak Memory Consumption \(MB PCquery \(cq CEPS \(cq PCquery \(rq CEPS \(rq b Memory Consumption Fig 13 Efciency of PCquery and CEPS Figure 13\(b reports the peak memory consumption during the entire running process The result shows that PCquery also consumes signicantly less memory than CEPS in all cases In addition to the comparison on efciency we also compare the quality of the answer graphs obtained by PCquery and CEPS For the fairness of comparison We use the quality metrics proposed in CEPS 10  NRatio and ERatio which indicate the percentage of important nodes and edges that are captured by an answer graph respectively We report the result in Figure 14 2 4 8 12 16 20 0 20 40 60 80 100 Quer y Size \(number of nodes NRatio PCquery \(cq CEPS \(cq PCquery \(rq CEPS \(rq a Average NRatio 2 4 8 12 16 20 0 20 40 60 80 100 Quer y Size \(number of nodes Eratio PCquery \(cq CEPS \(cq PCquery \(rq CEPS \(rq b Average ERatio Fig 14 Quality of Answer Graph Figure 14 shows that both PCquery and CEPS obtain high-quality answer graphs Both NRatio and ERatio of our answer graphs are comparable to those of CEPS although on average those of CEPS are slightly better Considering our algorithm is three orders of magnitude faster and also consumes signicantly less memory we can conclude that our method is both efcient and effective VIII C ONCLUSIONS We propose context-aware object connection discovery in a large graph We adopt a partition-and-conquer approach to achieve both high performance efciency and high quality results Our method rst partitions a large graph into a set of communities The concept of community not only naturally denes the context of the nodes but also signicantly improves the efciency of connection d iscovery since a community is much smaller than the original graph We compute the connection between query nodes rst at the intra-community level by maximizing the information throughput of the nodes and the information ow of the paths in the answer graph and then at the inter-community level by retaining the close relation between the commun ities as dened by modularity The quality of both the intraand intercommunity connection is thus controlled by the integration of information throughput/ow and modularity We verify by experiments that our community partition algorithm is efcient and the set of communities obtained has high quality We also show that our method obtains comparable high-quality answers as the state-of-the-art algorithm but is more than three orders of magnitude faster and consumes signicantly less memory Acknowledgement This work is partially supported by RGC GRF under grant number CUHK419008 and HKUST617808 We thank Mr Hanghang Tong and Prof Christos Faloutsos for providing us the source code of CEPS R EFERENCES  X  Y an P  S  Y u and J  H an  Graph i nde xing bas e d o n d is crim inati v e frequent structure analysis ACM TODS  vol 30 pp 960993 2005  J  C he ng Y  K e  W  N g a n d A  L u  F g-i nde x t o w a rds v e r i  c a t i on-fre e query processing on graph databases in SIGMOD  2007 pp 857872  P  Z hao J  X Y u  a nd P  S Y u   Graph i nde xing T r ee  d elta   graph in VLDB  2007 pp 938949 4 Y  K e J  Cheng and W  N g Cor r e lation s ear ch in gr aph d atabas es   in KDD  2007 pp 390399 5 Y  K e J  Cheng and W  N g E f  cient c or r e lation s ear ch f r o m g r a ph databases To appear in TKDE  2008  A  I nokuchi T  W as hio and H  M ot oda An apriori-based algorithm for mining frequent substruc tures from graph data in PKDD  2000 pp 1323  X  Y an and J  H an  Clos e g raph m i ni ng closed frequent graph patterns in KDD  2003 pp 286295  J  H uan W  W a ng J  Prins  and J  Y ang Spin mining maximal frequent subgraphs from graph databases in KDD  2004 pp 581586 9 C  F alouts o s  K  S  M c Cur l e y  a nd A  T o m k ins  F as t d is co v e r y of connection subgraphs in KDD  2004 pp 118127  H  T ong and C  F alouts o s  Center piece s ubgraphs  p roblem de n ition and fast solutions in KDD  2006 pp 404413  Y  K o ren S C North and C  V olins k y  Meas uring a nd e x tracting proximity in networks in KDD  2006 pp 245255  M E  J  Ne wm an and M  G irv a n Finding and e v a luating c om m unity structure in networks Physical Review E  vol 69 p 066113 2004  M E  J  Ne wm an  F a s t algorithm f or detecting c om m unity s t ructure i n networks Physical Review E  vol 69 p 066133 2004  F  W u and B  A  H uber m an  F i nding com m unities i n linear tim e a physics approach The European Physical Journal B Condensed Matter and Complex Systems  vol 38 no 2 pp 331338 2004  R K u m a r  P  Ragha v a n S Rajagopalan and A  T om kins   T r a w ling the web for emerging cyber-communities Comput Netw  vol 31 no 11-16 pp 14811493 1999  R K u m a r  P  Ragha v a n S Rajagopa lan and A Tomkins Extracting large-scale knowledge bases from the web in VLDB  1999 pp 639 650  R K u m a r  U Mahade v a n and D  S i v akum ar   A g raph-theoretic approach to extract storylines from search results in KDD  2004 pp 216225  D Gibs on R K u m a r  and A  T om kins   Dis c o v e ring lar g e d ens e subgraphs in massive graphs in VLDB  2005 pp 721732  Y  Douris boure F  Geraci a nd M Pe llegrini Extraction and classication of dense communities in the web in WWW  2007 pp 461470  A Claus e t M E  J  Ne wm an a nd C Moore Finding com m unity structure in very large networks Physical Review E  vol 70 p 066111 2004 
867 
867 
 


  13 false \(double\argets Figure 12 illustrates this situation. The conditional update correctly updates the tracker wh ich is tasked with following the target. However, the detector which is partially spatially coincident with the tracker also receives energy from the conditional update. This can lead the detector to initiate falsely\second target nearby the first target This effect can be countered a number of ways. First, we can adjust the speed at which the tracker re-centers itself The double initialization phenomenon occurs when the PDF peaks near the edge of the tracker grid. However, this method has the side effect of potentially allowing probability to fall off of the grid in low SNR environments causing track loss. Of course if the SNR is low enough or measurement outages occur tracks will be dropped. Second a guardband around the tracker that does not allow any detector sufficiently near the tracker to receive reinforcement via the conditional density can mitigate the double target problem. However, this has the side effect of preventing detection of closely spaced targets. Third increasing the spatial extent of the tracker has a similar effect as the using a guardband. It does require increased computation, but generates a better representation of the posterior There are several engineering tradeoffs. The first is that large tracker grids \(or large guard bands\ prevent falsely detecting new targets because of conditional probability spill over. However, if applied too aggressively, this will prevent correctly detecting cl osely spaced targets. Second quick tracker grid translation correctly centers the target mass, again preventing spillover into nearby detectors However, overly liberal trac ker repositioning may in fact move trackers to spurious energy locations and drop true targets off of the finite grid On Ambiguous Targets As discussed earlier, ambiguous targets will eventually move non-physically and this will cause the tracker to remove them via its natural prediction and update process Figure 13 illustrates this phenomenon. There are two real targets that create two persistent ambiguities. All four are detected and tracked automati cally. The ambiguous targets however, eventually move non-physically due to their reliance on the node bearing angles. The tracker automatically penalizes the non-physical motion and the targets\222 present hypothesis decrease quickly over time Ambiguous target removal is done automatically in the Bayesian framework as follows The PDF on target state is predicted forward in time according to the kinematic model True targets will have behavior consistent with the kinematic model \(note the kinematic model is a statistical model so it is predicting a range of possibilities for the future target state\biguous targets may behave consistently with this model for a period of time, but eventually they will appear to perform a non-physical maneuver \(these epochs typically come when the ambiguous target crosses a line of symmetry in the sensor\this point, the predicted target position will be in strong disagreement with the inco ming measurements on that target. This mismatch in predicted target position and measurements leads to a decr ease in the target present hypothesis as calculated in eq. \(4\long, only true targets remain   Figure 12 \226 Improper selection of grid resolution leads to multiple initializations on the same target. Left Measurement update of a Tracker \(red=highest likelih ood, blue=lowest\Right Measurement update of a detector which lies near the Tracker.  Since the track er size has been improperly chosen, some energy from the measurements of a single target leak s on to the detector. This can le ad to false double-initializations 


  14 8  C ONCLUSION  This paper has described a Bayesian approach to detecting and tracking multiple moving targets using acoustic data from multiple passive arrays In contrast to traditional undersea acoustic systems, which develop tracks at the single array level and require track association, our approach fuses data at the m easurement level and operates directly in the target state space We have detailed a well known nonlinear filtering approach to single target detection and tracking [1, 4 and desc ri be d our computationally efficient finite-grid approach to the required density estimation. We have furthermore extended this to the multiple target case by employing a bank of single target detector tracke rs and approximation methods that adjust for closely spaced targets. This approximate approach avoids fully treating the computationally complex joint multitarget problem Future work includes modified approaches to posterior estimation including dynamic grid extent, dynamic grid resolution, and particle filtering. It is anticipated that adaptive sampling of the posterior will lead to computational savings. Furthermore, future work includes more detailed modeling and estimation of closely spaced targets allowing a more accurate representation of the joint target density. Naively implemented, this implies exponential growth \(in the number of targets\r the probability state space being es timated. However, recent work in a related tracking domain on adaptive density factorization [5 c h a stic sa m p lin g  p article filtering    pr ovi de m e t h o d s t h at m i t i g at e t h i s com put at i o n gr owt h  when the full joint density is treated  A PPENDIX  This section discusses the details of how the single target probability density is time evolved on a discrete grid. This discussion is similar to that found elsewhere [15, 14, 13 We wish to compute the single target probability density at time      from the density at time     The relation between these two densities can be expressed using the law of total probability as                We expand     using a second order Taylor series as               where  is the vector of partial derivatives, i.e and is the matrix of second order partial derivatives Then the relation of \(23\ approximated as   Figure 13\226 Left: P h1 over time for four targets, two of which are real and two of which are ambiguous. Although the ambiguous intersections are persistent, eventually the false targets ha ve non-physical motion. The target present hypothesis quickly goes to zero for these targets and they are elimin ated. Right: the tracker estimate of target position and red circles indicating the removal point fo r the false targets 


  15             Where denotes the expectation with respect to the transition distribution    and the omitted terms involve similar terms involving and and cross terms between the and coordinates We use the nearly constant velocity \(NCV\model to specify the transition distribution    This assumption corresponds to one where the target moves at constant velocity except for random jump changes \(i.e nearly constant velocity\is is a plausible model when  is small as it is here Specifically, the NCV model assumes step changes in target velocity defined by the Ito Equations     This model implies  and likewise for  It is furthermore assumed that th e noise processes in each coordinate are independent Under this model, we can eval uate the required terms from 25\ as follows          And likewise for terms involving and Notice that all cross terms \(e.g  have expectation due to the assumption that the noise process is independent in the two coordinates This model simplifies \(25\ to         where the terms omitted are replicas involving the  coordinate Under the assumption that is small, this can be rewritten as    For implementation, this is approximated using an implicit Euler scheme wh ere      Where the indices  represent the discrete    locations where the probability mass is captured Likewise, using forward differencing      and          and similarly for the y coordinate system When substituted into \(28\is leads to a series of equations of the form                This series of equations defi ne the probability at each point at time  It can be efficiently solved via Thomas\222 algorithm \(rather than simply inverted\he matrix is tridiagonal     


  16 R EFERENCES    R o y E. Bet h el Benjam i n Shapo, C h r i st opher M   Kreucher, \223PDF Detection and Tracking\224, under review IEEE Transactions on Aerospace and Electronic Systems  2 y. E B eth e l an d G. J. Paras, \223A PDF Mu lt it arg et Tracker\224 IEEE Transactions on Aerospace and Electronic Systems vol. 30, no. 2, pp. 386-403, April 1994 3   R o y E  B e t h e l a n d G  J  P a r a s  223 A P D F M u l t i s e n s o r  Multitarget Tracker\224 IEEE Transactions on Aerospace and Electronic Systems vol. 34, no. 1, pp. 153-168 January 1998  L   D   Stone, C. A. Bar l ow, and T. L Corwin, \223Bayesian  Multiple Target Tracking\224  Boston: Artech House, 1999  l la and A. Hero, \223Multitarget Tracking using the Joint Multitarget Probability Density\224 IEEE Transactions on Aerosp ace and Electronic Systems  vol. 41, no. 4, pp. 1396-1414, October 2005  M  M o relande, C. Kreucher, K. Kastella, \223A Bay e sian  Approach to Multiple Target Detection and Tracking\224 IEEE Transactions on Signal Processing vol. 55, no. 5 pp. 1589-1604, May 2007  B  Shapo, and R  E B e t h el  223An Overvi ew of t h e Probability Density Function \(PDF\er\224 Oceans 2006 Boston, Sept. 2006  R oy L. St r e it 223M ult i s ensor M ul tit arget Int e nsit y Fil t er 224  International Conference on Information Fusion  Cologne, Germany July 2008  M  Ort on and W Fi t z geral d 223A B a y e si an approach t o  tracking multiple targets using sensor arrays and particle filters\224 IEEE Transactions on Signal Processing, vol. 50 no. 2, pages 216-223, Feb 2002  A. Doucet B Vo, C Andri e u, and M Davy 223Par t i c le filtering for multi-target tracking and sensor management\224, IEEE International Conference on Information Fusion, 2002  H Van T r ees, \223Det ecti o n Est i m a t i on, and M odul at i o n  Theory IV:  Optimum Array Processing\224  J. C St ri k w erda, Fi nit e  Di fference Sch e m e s and Partial Differential Equations, Ch apman & Hall, New York 1989   K. Kast el la and C Kreucher, \223M ult i p l e  M odel Nonl i n ear  Filtering for Low Signal Ground Target Applications\224 IEEE Transactions on Aerospace and Electronic Systems vol. 41, no. 2, April 2005, pp. 549-564  Z. Tang and \334. \326zg\374n er, \223Sensor Fu si on for Target Track Maintenance with Multiple UAVs based on Bayesian Filtering Method and Hospitability Map\224 Proceedings of the 42 nd IEEE Conference on Decision and Control pages 19-24, December 2003  K. Kast ell a 223Fi n it e di ff erence m e t hods for no nl i n ear filtering and automatic target recognition\224 MultitargetMultisensor Tracking: Applications and Advances vol III, pages 233-258, Artech House, 2000 B IOGRAPHY  Chris Kreucher received his Ph.D. in Electrical Engineering from the University of Michigan in 2005. He is currently a Senior Systems Engineer at Integrity Applications Incorporated in Ann Arbor, Michigan. From 1998 to 2007, he was a Staff Scientist at General Dynamics Advanced Information Systems' Michigan Research & Development Facility \(formerly ERIM\. His current research interests include nonlinear filtering \(specifically particle filtering Bayesian methods of multitarget tracking, self localization information theoretic sensor management, and distributed swarm management Ben Shapo earned his Ph.D. in El ectrical Engineering in 1996 from the University of Michigan.  He is currently a Senior Systems Engineer at Integrity Applications Incorporated in Ann Arbor, Michigan.  From 2003 to 2008 he was a Lead Engineer at General Dynamics, where he contributed to a number of RF and acoustics signal processing and tracking efforts.  Dr. Shapo has 12 years experience in the DoD research community in the areas of detection, tracking, and data fusion, with emphasis on highfidelity simulations and applying new methods to real data  Dr. Roy Bethel is currently employed at The MITRE Corporation in McLean, VA. He has been actively involved in development, testing, and evaluation of signal processing and detection and tracking systems. In particular, he has developed many systems that have been implemented on United States Navy airborne, surface, and submerged platforms. He is currently engaged in research and development of innovative approaches to multitarget detection and tracking  A CKNOWLEDGEMENTS  This work was partially funded by the Office of Naval Research contract N00014-08-C-0275. The authors would like to thank Dr. John Tague for his support, and Mr. Scott Spencer and Dr. Charles Choi for their assistance 


2 1 0 00                4 G ro w th 1  1 3 1 0 9 2 0 2 3 0 10  0 56                So ci ode m og ra ph ic c ha ra ct er is tic s 


s 5 A ge y ea rs   21 7 8 7 3 9 0 01 0 22  0 1 4 0 0 8              6 G en de r i s fe m al e2   0 2 4  0 0 6 0 0 2 0 00 0 0 3 0 10    


           7 C ur re nt ly n ot w or ki ng 2  0 0 5  0 0 8 0 04 0 04 0 0 1 0 16  0 16             8 C ur re nt ly in e du ca tio n2   0 6 


6 7  0 01 0 1 9 0 08  0 03 0 6 8 0 0 7 0 3 2           9 C ur re nt ly w or ki ng 2  0 2 8  0 03 0 18  0 1 1 0 0 3 0 64  0 00 0 1 4 0 8 9   


        10 E du ca tio n ac hi ev ed 3  3 5 7 1 5 2  0 04 0 02 0 2 1 0 1 2 0 16  0 02 0 1 6 0 13  0 0 6         11 D is pe ns ab le in co m e   


  21 0 9 2 72 7  0 14  0 0 1 0 09  0 08  0 2 0 0 00 0 0 4 0 18  0 1 6 0 0 1        In te rn et u sa ge                     


  12 A ct iv e in te rn et u sa ge 1  0 0 2 0 9 6 0 2 1 0 25  0 11  0 12  0 10  0 0 4 0 05  0 0 8 0 0 5 0 0 1 0 12        13 H ou rs o nl in e h ou rs 


rs   2 6 5 3 0 3  0 04 0 12  0 1 1 0 0 3 0 40  0 0 7 0 0 7 0 4 7 0 5 3 0 07  0 1 1 0 07       14 W illi ng ne ss to p ay 1  1 8 3 0 6 3  0 03 0 10 


10  0 07  0 08  0 0 2 0 0 4 0 0 1 0 01  0 00 0 0 5 0 14  0 04 0 05      G am e sp ec ifi c va ria bl es                      15 T en 


ur e w ee ks   2 8 2 3 5 2 0 2 6 0 31  0 0 9 0 01 0 12  0 0 4 0 02 0 0 9 0 0 9 0 07  0 02 0 13  0 08  0 0 4    16 C ro ss o ve r on o ffl in e 4  0 1 5 


5 1 1 1 0 1 9 0 11  0 13  0 18  0 2 0 0 1 4 0 0 7 0 14  0 1 1 0 0 4 0 08  0 15  0 0 5 0 01 0 07    17 S at is fa ct io n1   18 7 5 1 3 16  0 18  0 00 


00 0 44  0 52  0 1 4 0 0 3 0 02 0 07  0 0 9 0 1 4 0 10  0 08  0 0 6 0 09  0 0 1 0 13   18 C om m itm en t1  0 6 2 0 8 3 0 3 1 0 13  0 37  0 39  0 0 7 


7 0 0 6 0 02 0 03  0 0 4 0 1 3 0 14  0 17  0 0 5 0 09  0 07  0 19  0 58  S ou rc e O w n ca lc ul at io n N ot e N  1 3 89 o bs er va tio ns S ig ni fic an ce le ve ls 


ls  p  0 05 S D  S ta nd ar d de vi at io n 1 5 po in t L ik er t s ca le ra ng in g fro m 2 to 2  2 du m m y va ria bl e 3 o rd in al v ar ia bl e ra ng in g fro m v oc at io na l e du ca 


tio n to P h D 4 n um be r o f c on ta ct s   Proceedings of the 42nd Hawaii International Conference on System Sciences - 2009 10 pre></body></html 


