 
  Abstract 002 This paper presents a new approach for solving the paradoxical Blackman's Association Problem.  It utilizes the recently defined new class fusion rule based on fuzzy Tconorm/T-norm operators together with DezertSmarandache theory based, relative variations of generalized pignistic probabilities measure of correct associations defined from a partial ordering function of hyper-power set The ability of this approach to solve the problem against the classical Dempster-Shafer\222s method, proposed in the literature is proven. It is shown that the approach improves the separation power of the decision process for this association problem  Index Terms 
002 Attribute Data Fusion, Data Association Dezert-Smarandache Theory, Proportional Conflict Redistribution rules, Fuzzy operators I  I NTRODUCTION Data association with its goal to select the most probable and correct associations between sensors\222 measurements and target tracks, from a large set of possibilities, is a fundamental and important content for each radar surveillance system. In general case the focus of tracking algorithms has centered on kinematics state estimation However, targets\222 attribute information has the potential to not only estimate the identity/type information of the tracking targets, but it may also improve data association and kinematics tracking performance. Attribute data 
association can become a crucial and challenging problem in case when the sources of information are imprecise uncertain, even conflicting and paradoxical 
002 The specifics of the data association problem can vary according to both the different fusion methods and the criteria to estimate the correct associations. There are various methods for combining such information and the choice of method depends on the richness of abstraction and diversity of sensor data. The most used until now Dempster-Shafer Theory \(DST n d [4 r o po s e s a s ui t a b l e  mathematical framework for representation of uncertainty Although very appealing, DST presents some weaknesses and limitations, related with the law of the third excluded 
   This work is partially supported by the Bulgarian National Science Fund-grant MI-1506/05 Albena Tchamova is with the Institute for Parallel Processing Bulgarian Academy of Sciences , \221Acad. G. Bonchev\222 Str., Bl. 25-A 1113 Sofia, Bulgaria, \(telephone: +359 2 979 6620, E-mail tchamova@bas.bg  albena_tchamova@yahoo.com  Jean Dezert  is with ONERA,29 Av. de la  Division Leclerc, 92320 Chatillon, France, E-mail Jean.Dezert@onera.fr  Florentin Smarandache is with Department of Mathematics University of New Mexico, Gallup, NM 87301, U.S.A, Email:smarand@unm.edu 
 middle. The Dempster\222s rule of combination can give rise to some paradoxes/anomalies and can fail to provide the correct solution for some specific association problems This has been already pointed out by Samuel Blackman in 1  w h e r e th e f a m o u s  B l a ck m an A s s o ci a t i o n P r o b l em  BAP\s formulated In this paper we focus our attention on the ability of one new, alternative class fusion rule, interpreting the fusion in terms of fuzzy T-Conorm and T-Norm operators \(TCN rule\, to solve efficiently the paradoxical Blackman's Association Problem on the base of relative variations of generalized pignistics probabilities measure, defined within recently developed Dezert-Smarandache Theory DSmT\ of plausible and paradoxical reasoning a n d  
7   I t p r o p o s es a n ew g en er al ma th ema ti ca l f r am ew o r k  for solving fusion/association problems. This theory overcomes the practical limitations of DST, coming essentially from its inherent constraints, which are closely related with the acceptance of the law of the third excluded middle and can be interpreted as a general and direct extension of probability theory and the DST We first recall the BAP, then we browse the state of the art to find the correct solution through different approaches available in the literature. After a brief presentation of DSmT, DSmT based Proportional Redistribution Rule number 5 \(PCR5\, the new TCN combination rule and the DSmT based, relative variations of generalized pignistics probabilities measure, we provide 
a new solution of this problem, which is encountered in modern multisensor multitarget tracking and identification systems involved within defense applications. The last part of the paper provides a comparison of the performances of all the proposed approaches from Monte-Carlo simulation results II  T HE B LACKMAN A SSOCIATION P ROBLEM  The main purpose of information fusion/association is to produce reasonably aggregated, refined and/or completed granule of data obtained from a single or multiple sources of information with consequent adequate reasoning process. It means, that the main problem here consists not only in the way to aggregate correctly the 
sources of information, which in general are imprecise uncertain, or/and conflicting, but it is also important to dispose of proper criterion to estimate the correct association. Actually, there is no a single, unique rule to deal simultaneously with such kind of information peculiarities, but a huge number of possible combinational rules, appropriate for a particular only application conditions, as well as a number of  criterion to estimate the correct association A New Class Fusion Rule for solving Blackman's Association Problem Albena Tchamova, Jean Dezert and Florentin Smarandache 


  m.m 1 T Z   m.m 1 T Z  m 1 T and         A  Original Blackman Association Problem The well known association problem provided by Samuel Blackman considers a very simple frame of discernments according to only two target\222s attribute types  22 2 2 121 2  0.1 0.1 0.8 TT T T mm m m  m Z described within the same frame of discernments   m Z has some disagreement with the predicted bba of the second track  m Z with the predicted bba 003\005\003=\003=\003  It is evident here, the new observation perfectly fits with the predicted bba of the first track, i.e 003\003\003\003   005   m 2 T respectively   whereas  However, counter-intuitively, the solution, taken on the base of DST is just the opposite one   B. Second Blackman Association Problem In order to complete and compare all possible cases, we modify the first association problem into a second one with preserving the same predicted tracks\222 bbas  Because of perfect fitting, the correct decision here is apparently trivial 006  III  S TATE OF THE A RT TO FIND A C ORRECT S OLUTION  In [2 th e r e ar e d es cr i b ed  ex am in ed  an d d i s cu s s ed  several approaches to resolve the BAP. The first group includes approaches based on DST i a minimum conflict criterion ii a relative attribute likelihood function criterion, proposed by Blackman iii minimum distance criterion iiii Shubert\222s meta-conflict function criterion iiiii entropy-based approaches. The results obtained via Monte Carlo simulations indicate that there is no reliable approach to solve the assignment problem based on DST for both cases described above. The numerical computation of the conflict for BAP 1 yields an unexpected, non-adequate, counter-intuitive result. The fusion/association process actually assigns the lower degree of conflict to the incorrect solution 006 providing a larger discrepancy between observation\222s bba  Therefore, the search for the minimum conflict between sources cannot be taken as a reliable solution for the general assignment problem since at least one example exists for which the method fails. The meta-conflict approach, proposed by Shubert [6  d o e s n o t al lo w g e ttin g  t h e o p tima l e f f i c i e n cy  The Blackman\222s approach gives the same performance All entropy-based methods are less efficient than the minconflict approach. The min-distance approach is the least efficient one. According to the combination rule used, it has been already reported in [2   5    an d  6   th a t  th e u s e o f  DST must usually be done with extreme caution if one has to take a final and important decision from the result of the Dempter's rule of combination. Always there is a need to be added some ad-hoc or heuristic techniques to the association process, in order to manage or reduce the possibility of high degree of conflict between sources Otherwise, the fusion results lead to non-adequate conclusions, or cannot provide reliable results at all The second group approaches rely on the new DSmT of plausible and paradoxical reasoning. Its foundation is to allow imprecise/vague notions and concepts between elements of the frame of discernment. The main approaches to examine and estimate the correct data association within DSmT are based on the generalized pignistic transformation [2 m i n i mu m v ar i at io n o f  entropy-like measure, minimum variation of generalized pignistic entropy, minimum of relative variation of pignistic probabilities conditioned by the correct assignment The results obtained show that the method based on the relative variations of generalized pignistic probabilities conditioned by the correct assignment, yields adequate and proper decisions and outperforms all above approaches examined IV  D EZERT S MARANDACHE T HEORY  The DSmT of plausible and paradoxical reasoning proposes a new general mathematical framework for solving fusion problems and a formalism to describe analyze and combine all the available information allowing the possibility for conflicts and paradoxes between the elements of the frame of discernment. DSmT differs from DST because it is based on the free Dedekind lattice. It works for any model \(free DSm model and hybrid models - including Shafer\222s model as a special case\ which fits adequately with the true nature of the fusion problem under consideration, expressed in terms of belief functions, with static and dynamic fusion problematics. The DSmT includes the possibility to deal 003\003=\004 It corresponds to a single attribute observation and two estimated targets tracks 1 T and 2 T  associated with two predicted basic belief assignments bba  m 1 T than with the predicted bba  m 2 T nevertheless   11 2 1 121 2  0.5 0.5 0.0 TT T T mm m m         0.0 m;5.0m;5.0m.m 21Z 2Z 1Z Z          m 2 T It should lead to a categorical decision about the correct assignment 003\003 003\003   005  It should be mentioned that both sources of information are independent and share one and the same frame of hypotheses, on which their basic belief assignment are defined During the next time moment, a single new attribute observation is detected. It is characterized with an associated bba  21   m 1 T  and  m 2 T In the opposite of the first case, we consider the new attribute measurement to fit with the second track\222s bba, i.e   m.m 2 T Z   m.m 2 T Z   m.m 2 T Z   m.m 2 T Z   m.m 1 T Z 


 Am is called A\222s general basic belief assignment \(gbba\ or the general basic belief mass for A The belief and plausibility functions are defined for 003\003  003\003  003\003\003 005\013  The introduction of a given integrity constraint i 003\003 1  2 021 k independent bodies of evidence with gbbas  with evidences arising from different sources of information, which don't have access to absolute interpretation of the elements 003\003\003 1  be a set of n elements, which cannot be precisely defined and separated. A free-DSm model, denoted as 003 to be empty through the model 003\003 are truly impossible, i.e 003\003 are truly impossible i.e 003 f  The Shafer\222s model  004\007 is defined from the freeDSm model  004\007 f by introducing some integrity constraints on some elements i D  004\007 0 can be considered as the most constrained DSm hybrid model including all possible exclusivity constraints without non-existential constraint since all elements in the frame are forced to be mutually exclusive  C. Hyper-Power Set and Classical DSm Rule of Combination The hyper-power set  003 of  003 of n 004\007 f m by definition This rule is commutative and associative and requires no normalization procedure V  P ROPORTIONAL CONFLICT REDISTRIBUTION RULE NO   5 Instead of distributing equally the total conflicting mass onto elements of power set as within Dempster\222s rule through the normalization step, or transferring the partial conflicts onto partial uncertainties as within DSm hybrid rule, the idea behind the Proportional Conflict Redistribution rules is to transfer conflicting masses \(total or partial\ proportionally to non-empty sets involved in the model according to all integrity constraints. The general principle is to   1 m  n m and   003 007 t\n  There are several possible kinds of integrity constraints 003 007 t\n  implies the set of inner constraints 017\b  AB,DB BmABel n\020\013\b  AB,DB Bm APl 003 003 003 003 b\013\b\005\b\b\r  3. No other elements belong to  DBA,DBA,DB,DA   10 D:.m  003   003  The DSm classical rule of combination is based on the free-DSm model. For 2 003 004 b if there are some certain facts in accordance with the exact nature of the model related to the problem under consideration. An integrity constraint on i D 003 004 b consists in forcing i b  003 DA Am 1   The quantity 004 b\n D n    n  b\r   0  004\007 f consists in assuming that all elements n,...,i i 1  004\007 0  which requires the exclusivity and exhaustivity of all elements n,...,i i 1      m k over 022 013\013  004\007 004 b  AX...X DX...X k i ii k k f Xm Am 1 1   with 003 under consideration and can be interpreted as a general and direct extension of probability theory and the DST A. Free-DSm model Let 004 are not exclusive. The freeDSm model is an opposite to the Shafer\222s model 004  B. DSm hybrid Model A DSm hybrid model 200  exclusivity constraints \226 when some conjunctions of elements ki  n\t\013\013 007 k i  200  non-existential constraints \226 when some disjunctions of elements ki  n\t\005\005 007 k i  200  mixture of exclusivity and non-existential constraints, for example   kji n\t 007 B for all i B 003 D is defined as the set of all composite possibilities build from 003 with 005 and 013  operators such that 1 004 D except those obtained by using rules 1 or 2 From a general frame of discernment 003 with its freeDSm model, it is defined a map 003 DA 004 D   200  calculate the conjunctive rule of the belief masses of  sources 200  calculate the total or partial conflicting masses 200  redistribute the conflicting mass \(total or partial proportionally on non-empty sets involved in the model according to all integrity constraints The way the conflicting mass is redistributed yields to several versions of PCR rules [7  T h e s e P C R fu s i on  r ul e s  work both in DST and DSmT frameworks and for static or dynamical fusion problematic, for any degree of conflict in 0, 1 f o r an y D S m mo d e ls  S h a f e r 222 s mo d e l, f r e e D S m model or any hybrid DSm model\.  The most sophisticated rule among them is the proportional conflict redistribution rule no. 5 \(PCR5\ The PCR5 combination rule for only two sources of information is defined by  004\007 denoted as i 016 003  associated to a given source of evidence, which can support paradoxical, or conflicting information, as follows    0   2 m 205 


  5  0 PCR m 002 12 2  min    ij ij ij XXX XX mX m X m X n and for   XG    003\013\003 and the degree of association is as follows  002 c orresponds to the conjunctive consensus on X between the two sources and where all denominators are different from zero and  cX is the canonical form  of X  No matter how big or small is the conflicting mass PCR5 mathematically does a better redistribution of the conflicting mass than Dempster\222s rule and other rules since PCR5 goes backwards on the tracks of the conjunctive rule and redistributes the partial conflicting masses only to the sets involved in the conflict and proportionally to their masses put in the conflict considering the conjunctive normal form of the partial conflict. PCR5 is quasi-associative and preserves the neutral impact of the vacuous belief assignment VI  T HE TCONORM TNORM C OMBINATION R ULE  The TCN rule of combination [8 r ep r es en t s a  n ew  cl a s s  of combination rules based on specified fuzzy TConorm/T-Norm operators. This rule takes its source from the T-norm and T-conorm operators in fuzzy logics, where the AND logic operator corresponds in information fusion to the conjunctive rule and the OR logic operator corresponds to the disjunctive rule In this work we propose to interpret the fusion/association between the sources of information as a vague relation, characterized with the following two characteristics 002 51 2 22 12 21   1221             PCR YG X cX Y mXmX mX mY mX mY mX mY mX mY  m 1 and 003\003\003 003\003\003 003\003 003  005 005   m 2 is defined as ji X 003\005\003\003\005\003=\003\005\003   004 r\b by the equation            12 1 2 12 12 min  min  min  jji jij ij j mmm mm mm  Xm  12 represents the basic belief assignments after the fusion, associated with the given proposition X by using T-norm based conjunctive rule  The TCN combination rule in Dempster Shafer theory framework is defined for 2 X 003\003\003 003\003\003 003\003 003  005 005   004 is the DSmT hyper power set 12  mX 002  where G 002 Step 2 Distribution of the mass, assigned to the conflict In some degree it follows the distribution of conflicting mass in the most sophisticated DSmT based Proportional Conflict Redistribution rule number 5 \(PCR5\ proposed in 7  b u t t h e p r o ced u r e h er e r eli es o n f u z z y  o p er a t o r s  Th e  total conflicting mass is distributed to all non-empty sets proportionally with respect to the Maximum between the elements of corresponding mass matrix's columns associated with the given element X of the power set. It means the bigger mass is redistributed towards the element, involved in the conflict and contributing to the conflict with the maximum specified probability mass. The general procedure for fuzzy based conflict redistribution is as follows 004 r\b n   004 b 013=\n    200  The way of association between the possible propositions build on the base of the frame of discernment It is based on operations union and intersection, and their combinations. These sets\222 operations correspond to logic operations Conjunction and Disjunction and their combinations 200  The degree of association between the propositions It is obtained as a T-norm \(for conjunction or T-conorm \(for disjunction\ operators applied over the probability masses of corresponding focal elements. While the logic operators deal with degrees of truth and false, the fusion rules deal with degrees of belief of hypotheses Within this work, we focus only on the Minimum T-norm based Conjunctive rule. It yields results very closed to conjunctive rule, which is appropriate for identification problems, restricting the set of hypotheses we are looking for.  It has an adequate behavior in cases of total conflict presence. It is commutative and simply to apply The general principle of TCN rule consists in the following steps Step 1 Defining the min T-norm conjunctive consensus The min T-norm conjunctive consensus is based on the default min T-norm function. The way of association between the focal elements of the given two sources of information     j2i1 12 m,mminXm  004 013 b  200  Calculate all  partial conflict masses separately 200  If n=\003\013\003 ji then i   m\\(mmax j2i1   m\\(mmax i2j1 200  Finally, for the given above two sources, the minimum T-Norm conjunctive consensus yields  003 and j 003 and j 003\003   where 003 are involved in the conflict; redistribute the corresponding masses 0\\(m ji12 003\013\003 involved in the particular partial conflicts to the non-empty sets i 003 with respect to 003\003 and with respect to 003\003            12 1 2 12 12 min  min  min  iii iij ij i mmm mm mm         ji2ji1 ji12 m,mmin m  


           Step 3 The basic belief assignment, obtained as a result of the applied TCN rule becomes  003 023 derivation In the next section we will test its performance to resolve the BAP on the base of TCN rule and will compare it with the results, obtained by DST VIII  S IMULATION R ESULTS   In table 1 below the performance evaluation of several methods for solving the BAP are shown. We compare percentage of success in correct BAP resolving by the new TCN combination rule, DSmT based  Proportional Conflict Redistribution rule number 5 and Dempster\222s rule with the corresponding measure of correct association as follows  m\(.\m 2 T Z 004 b n\020  2X X 5PCR12 5PCR12 5PCR12 Xm  Xm  Xm    TCN combinational rule does not belong to the general Weighted Operator Class. The nice features of the new rule could be defined as: very easy to implement satisfying the impact of neutrality of Vacuous Belief Assignment; commutative, convergent to idempotence reflecting majority opinion, assuring an adequate data processing and interpretation in case of total conflict These main features make it appropriate for the needs of temporal data fusion VII  M EASURE OF E STIMATION BASED ON G ENERALIZED P IGNISTIC P ROBABILITIES    The minimum of relative variation of generalized pignistic probabilities within DSmT, conditioned by the correct assignment   P  i i i i i i TZ 210 P TZ 210 PZP P        12 12 5 12 2 12 12 1 12 min  max  min  max  ij PCR j j j ij ji j ji mm mmm mm mm m mm   m.m i T Z                 12 12 5 12 1 12 12 2 12 min  max  min  max  ij PCR i i i ij ji i ji mm mmm mm mm m mm 025 025\212\025 024 023 023 023 023   where  003\003 003\003\003 003\003 003\003 003 003\003 327 327  Step 4  Normalization of the result. The final step of the TCN fusion rule concerns the normalization procedure   m\(.\m 1 T Z  023 025 P i  by forcing the new measurement\222s bba to be equal to the given track\222s bba, i.e      023 025 P i  defines the relative variations of corresponding pignistic probabilities  jZT i P       for pignistic probabilities 006 or 006 Then we evaluate the percentage of right assignments for the given association criterion The evaluation of proposed here method for BAP\222s solving is performed on the base of the association criterion, proven to be the best among the investigated ones in  The results show that all the methods, applied as measures of correct data associations within DempsterShafer theory lead to non-adequate and non-reliable decisions. Dempster\222s rule of combination can give rise to some paradoxes /anomalies and can fail to provide the correct solution for some specific association problems Monte Carlo simulations show that only methods based on the new TCN combination rule and DSmT based PCR5 rule with the minimum relative variations of generalized pignistic probabilities measure outperform all methods examined in this work   003\003 003\003\003 003\003 003\003 003 003\003 327 327   m 1 T   m 2 T and the new observed bba  023 023 023 023 023 003 003\212\003\212\003 025 2 1j jT jTjZTjZT i i i i i P PPP P   The term 023 represents a generalized pignistic probability, according to a given proposition  m Z according  to a random assignment  023 024 P i is chosen as a measure of correct data association. It is defined from a partial ordering function of hyper-powerset, which is the base of DSmT It is proven that this measure outperforms all methods examined in [2 f o r co r r ect s o l v i n g o f B l a ck m an 222 s  association problem. Our goal is to estimate and compare the performance of TCN combination rule on the base of that best criterion   i i TZ 210 P 200  TCN combinational rule and the best criterion based on the relative variations of generalized pignistic probabilities build from the DSmT \(and the free DSm model 200  DSmT based Proportional Conflict Redistribution rule number 5 and the criterion  based on the relative variations of generalized pignistic probabilities build from the DSmT 200  Dempster\222s rule of combination and i  Dempster-Shafer theory based Blackman approach ii DST based Min Conflict approach iii\ DST based Meta conflict approach iiii\ DST based Min Entropy approach  The evaluation of  methods\222 performances/efficiency is estimated through Monte-Carlo simulations. They are based on 10.000 independent runs. A basic run consists in generating randomly the two predicted bba 025 023 is obtained as for 


  TABLE  I PERFORMANCE EVALUATION OF METHODS FOR SOLVING BLACKMAN 222 S ASSOCIATION PROBLEM   Rule and Approach for solving  BAP Percentage of success 200  DSmT based PCR5 rule 200  TCN rule 200  relative variations of generalized pignistic probabilities build from the DSmT \(and the free DSm model  100 200  relative variations of generalized pignistic probabilities build from the DSmT \(and the free DSm model  100 200  Dempster\222s rule 200  DST based Blackman approach 70.31 200  Dempster\222s rule 200  DST based Min Conflict approach 70.04 200  Dempster\222s rule 200  DST based Meta conflict approach 70.04 200  Dempster\222s rule 200  DST based Min Entropy approach 64.5  IX  C ONCLUSIONS  We focused our attention on the paradoxical Blackman\222s association problem and propose a new approach to outperform Blackman\222s solution. The proposed approach utilizes the recently defined new class fusion rule based on fuzzy T-conorm/ T-norm operators. It is applied and tested together with a Dezert-Smarandache theory based, relative variations of generalized pignistics probabilities measure of correct association, defined from a partial ordering function of hyper-powerset. The ability of this approach to solve the problem against the classical Dempster-Shafer\222s method, proposed in the literature, is proven. It is shown that it assures an adequate data processing in case of high conflict between sources of information, when Dempster's rule yields counter-intuitive fusion results and improves the separation power of the decision process for the considered association problem  R EFERENCES  1  S Blackman., \223Multiple-target tracking with radar applications\224 Norwood, MA,  Artech House 1986 2  F. Smarandache and J. Dezert \(Eds\, \223Advances and applications of DSmT\224 Vol.1  Rehoboth  USA American Research Press, 2004 3  A. Dempster Journal of the Royal Statistical Society,Series B  pp.205-247, 1968 4  G. Shafer, \223A mathematical theory of evidence\224, Princeton University Press, Princeton, New Jersey, 1976 5  J. Lowrance, T. Garvey, \223Evidential reasoning: an implementation for multisensor integration\224 Technical Note 307 Artificial Intelligence Center,  International, Menlo Park, CA, 1983 6  J. Schubert, \223Clustering belief functions based on attracting and conflictiing metalevel evidence\224 Proceedings of IPMU conf Annecy, France, 2002  7  F. Smarandache and J. Dezert \(Eds\, \223Advances and application of DSmT\224 Vol.2  Rehoboth  USA American Research Press, 2006 8  A. Tchamova, J. Dezert and F. Smarandache  \223A new class of fusion rules based on T-Conorm and T-Norm fuzzy operators\224 Information&Security, An International Journal, Vol. 20 2006    


Figure 5 Top The US Presidential election 2004 dataset Left 25 Presidential candidates are in red boxes and 50 states are in gray spheres Edges are concentrated on Bush and Kerry signifying that they are the two leading candidates Total number of votes thrown to Bush and Kerry are queried by clicking the respective nodes Right States such as California Florida Georgia Illinois and Michigan show very close support for Bush and Kerry The red edge between Kerry and California reveals that Kerry has the largest number of votes in the nation from California Next 2 rows A publication coauthorship dataset of 968 authors and 3,470 coauthorship relationships The impact of edge weight threshold  022  on the coauthorship data Middle left 3470 edges at 022 0 Middle right 384 edges at 022 2 Bottom left 10 edges at 022 6 Pruning by edge threshold helps to focus on statistically signi\002cant relationships quickly Bottom right Exploration of outstanding edges leads to the discovery of S K Card's coauthorship i.e 72 in total by clicking the S K Card node 
466 


is turned into a wire framed sphere all the connected edges to the node are highlighted in white and the detailed information on the node is displayed With this dataset the user interaction functionality performed smooth This dataset is also used to test interactive 002ltering of nodes and edges and reverting of the previous 002ltering The bottom 2 002gures in Figure 4 shows edge pruning at two different edge weight thresholds 17 and 23 With this pruning function we were able to discover 3-frequent itemsets such as f Pillsbury Cake Mix Pillsbury Biscuits Jiffy Muf\002n Mix g  quickly 2004 US presidential election dataset This dataset is obtained from FEDERAL ELECTIONS 2004 by Federal Election Commission This dataset is bipartite of two distinct object classes 25 presidential candidates and 50 voting states The objects of the presidential candidate class appear in red cubes and the states are rendered in gray spheres as shown in Figure 5 An edge weight represents the number of popular votes thrown to a candidate from a state The number of votes for Bush Kerry and all others by state are shown in Figure 3 The perspective of each histogram is different such that the left represents total popular votes by candidate whereas the right is by state These two perspectives are uni\002ed into one in Round3D shown in Figure 5 From the Round3D view we can visually and textually inspect the total number of votes thrown by each state to each candidate and the total number of votes received by each candidate from each state For example from the top left 002gure in Figure 5 we 002nd that Bush and Kerry are the two top runners From the top right 002gure it is clear that California threw the largest number of votes in the nation and Florida is the second It is also shown that California is in favor of Kerry more than Bush Co-authorship datasets small and large Two coauthorship datasets in scienti\002c publication are tested with Round3D One is from the InfoVis 2004 contest 968 authors and 3,470 coauthorship and the other dataset is from CiteSeer 19,898 authors and 8,294 coauthorship Both datasets were tested well The bottom 4 002gures in Figure 5 shows global summaries of the coauthorship as well as the details of individual author in which the degree of coauthorship of most authors is relatively low One outstanding example is S K Card shown in the 002gure This fact is well observed in Figure 5 as edges are pruned by increasing edge weight threshold With the larger co-authorship dataset we experienced noticeable lagging in user interaction 5 Conclusion and Future Work The preliminary results from the proposed Round3D were pleasant and promising as an in-memory tool They also expose shortcomings in our current approaches Our biggest concern is scalability for a massive dataset We plan to overcome this issue by two ways First we will make nodes and edges light by storing all the information other than their unique IDs in a high performing standalone database and access the details on demand With this approach we also plan to offer a versatile SQL query interface Second we consider to present meta-relationships at a high-level view 002rst and low-level views later as needed References  J Abello and J K orn MGV  A System for V isualizing Massive Multidigraphs  IEEE TVCG  8\(1 Jan-Mar 2002  L A Adamic and E Adar  Friends and Neighbors on the Web Social Networks  July 2003  M C F  de Oli v eira and H Le vk o witz From V isual Data Exploration to Visual Data Mining A Survey IEEE TVCG  9\(3 Jul-Sep 2003  W  H Hsu A L King M S R P aradesi T  Pydimarri and T Weninger Collaborative and Structural Recommendation of Friends using Weblog-based Social Network Analysis In Proc of AAAI Spring Symposia  pages 55ñ60 March 2006  T H Huang and M L Huang Analysis and V isualization of Co-authorship Networks for Understanding Academic Collaboration and Knowledge Domain of Individual Researchers In Proc of the 3rd CGIV  pages 18ñ23 2006  D A K eim Designing Pix el-Orient ed V isualization T echniques Theory and Applications IEEE TVCG  6\(1 Jan-Mar 2000  D A K eim C P anse M Sips and S C North V isual Data Mining in Large Geospatial Point Sets IEEE CG&A  24\(5 Sep-Oct 2004  R K umar  P  Ragha v an S Rajagopalan and A T omkins The Web and Social Networks IEEE Computer  35\(11 36 Nov 2002  Y  Matsuo and M Ishizuka K e yw ord Extraction from a Single Document using Word Co-occurrence Statistical Information Int'l J on AI Tools  13:157ñ169 2004  M E J Ne wman Coauthorship net w orks and patterns of scienti\002c collaboration Proc of the National Academy of Sciences of USA  101\(1 April 6 2004  J O'Madadhain D Fisher  P  Smyth S White and Y B Boey Analysis and Visualization of Network Data using JUNG J of Statistical Software  VV 2005  T  C Sprenger  R Brunella and M H Gross H-BLOB a hierarchical visual clustering method using implicit surfaces In Proc of the Conf on Visualization  pages 61ñ68 2000  E T ejada and R Minghim Impro v ed V isual Clustering of Large Multi-dimensional Data Sets In Proc of the 9th Int'l Conf on Info Visualisation  pages 818ñ825 July 2005  P  C W ong P  Whitne y  and J Thomas V isualizing Association Rules for Text Mining In Proc of IEEE InfoVis  pages 120ñ123 Oct 1999 
467 


5 Related Work There exists extensive previous work on both the mining of software repositories and on the use of clustering algorithms in software engineering This discussion focuses on the most similar and recent work in the area of software evolution Mining Software Repositories Our technique was partially inspired by the work of Zimmermann et al and Y ing et al 17 on the mining of association rules in change history As described in Section 1 we sought to expand the technique to be able to recommend larger but less precise clusters of elements to guide program navigation Bouktif et al also investigated how to recommend cochanges in software development As opposed to the work cited above Bouktif et al used change patterns instead of association rules Also their approach does not attempt to reconstruct transactions and can consider associated 002les that were changed in different transactions ChangeDistiller is a tool to classify changes in a transaction into 002ne-grained operations e.g addition of a method declaration and determines how strongly the change impacts other source code entities Our approach uses similar repository analysis techniques but is focused on providing task-related information as opposed to an overall assessment of a system's evolution Finally repository mining can also be used to detect aspects in the code In this conte xt aspects are recurring sets of changed elements that exhibit a regular structure Aspects differ from the clusters we detect in the regular structure they exhibit which may not necessarily align with the code that is investigated as part of change tasks Clustering Analysis The classical application of clustering for reverse engineering involves grouping software entities based on an analysis of various relations between pairs of entities of a given version of the system Despite its long and rich history  e xperimentation with this approach continues to this day For example Andreopoulos et al combined static and dynamic information K uhn et al used a te xtual similarity measure as the clustering relation and Christl et al used clustering to assist iterative semi-automated reverse engineering The main dif ferences b e tween most clusteringbased reverse engineering techniques and the subject of our investigation is that the entities we cluster are transactions rather than software entities in a single version of a system For this reason our analysis is based strictly on the evolving parts of the system Both Kothari et al and V an ya et al 15 recently reported on their use of clustering to study the evolution of software systems The idea of using change clusters is the same in both works and ours but the purpose of the work is different Kothari et al use change clusters to uncover the types of changes that happened e.g feature addition maintenance etc during the history of a software system Vanya et al use change clusters which they call evolutionary clusters to guide the partitioning of a system that would increase the likelihood that the parts of the system would evolve independently In contrast we cluster transactions based on overlapping elements not 002les to recommend clusters to support program navigation as opposed to architectural-level assessment of the system Finally Hassan and Holt evaluated on 002ve open source systems the performance of several methods to indicate elements that should be modi\002ed together This study found that using historical co-change information as opposed to using simple static analysis or code layout offered the best results in terms of recall and precision The authors then tried to improve the results using 002ltering heuristics and found that keeping only the most frequently cochanged entities yielded the best results As opposed to our approach the evaluated 002ltering heuristics were only applied on entities recovered using association rules and not using clustering techniques The focus of their study was also more speci\002c as they recommend program elements that were strictly changed  as opposed to recommending elements that might be inspected by developers 6 Conclusion Developers often need to discover code that has been navigated in the past We investigated to what extent we can bene\002t from change clusters to guide program navigation We de\002ned change clusters as groups of elements that were part of transactions or change sets that had elements in common Our analysis of close to 12 years of software change data for a total of seven different open-source systems revealed that less than 12 of the changes we studied could have bene\002ted from change clusters We conclude that further efforts should thus focus on maximizing the quality of the match between the current task and past transactions rather than 002nding many potential matches Our study has already helped us in this goal by providing reliable evidence of the effectiveness of some 002ltering heuristics and useful insights for the development of additional heuristics Acknowledgments The authors thank Emily Hill and Jos  e Correa for their advice on the statistical tests and the anonymous reviewers for their helpful suggestions This work was supported by NSERC 
25 
25 
25 
25 
25 


References  B Andreopoulos A An V  Tzerpos and X W ang Multiple layer clustering of large software systems In Proc 12th Working Conf on Reverse Engineering  pages 79ñ88 2005  S Bouktif Y G Gu  eh  eneuc and G Antoniol Extracting change-patterns from cvs repositories In Proc 13th Working Conf on Reverse Engineering  pages 221ñ230 2006  S Breu and T  Zimmermann Mining aspects from v ersion history In Proc 21st IEEE/ACM Int'l Conf on Automated Software Engineering  pages 221ñ230 2006  A Christl R K oschk e and M.-A Store y  Equipping the re\003exion method with automated clustering In Proc 12th Working Conf on Reverse Engineering  pages 89ñ98 2005  D 020 Cubrani  c G C Murphy J Singer and K S Booth Hipikat A project memory for software development IEEE Transactions on Software Engineering  31\(6 465 2005  B Fluri and H C Gall Classifyi ng change types for qualifying change couplings In Proc 14th IEEE Int'l Conf on Program Comprehension  pages 35ñ45 2006  A E Hassan and R C Holt Replaying de v elopment history to assess the effectiveness of change propagation tools Empirical Software Engineering  11\(3 2006  D H Hutchens and V  R Basili System s tructure analysis Clustering with data bindings IEEE Transactions on Software Engineering  11\(8 1985  D Janzen and K De V older Na vig ating and querying code without getting lost In Proc 2nd Int'l Conf on AspectOriented Software Development  pages 178ñ187 2003  J K ot hari T  Denton A Shok ouf andeh S Mancoridis and A E Hassan Studying the evolution of software systems using change clusters In Proc 14th IEEE Int'l Conf on Program Comprehension  pages 46ñ55 2006  A K uhn S Ducasse and T  G  021rba Enriching reverse engineering with semantic clustering In Proc 12th Working Conf on Reverse Engineering  pages 133ñ142 2005  M P  Robillard T opology analysis of softw are dependencies ACM Transactions on Software Engineering and Methodology  2008 To appear  M P  Robillard and P  Mangg ala Reusing program in v estigation knowledge for code understanding In Proc 16th IEEE Int'l Conf on Program Comprehension  pages 202 211 2008  J Sillito G Murph y  and K De V older Questions programmers ask during software evolution tasks In Proc 14th ACM SIGSOFT Int'l Symposium on the Foundations of Software Engineering  pages 23ñ34 2006  A V an ya L Ho\003and S Klusener  P  v an de Laar and H van Vliet Assessing software archives with evolutionary clusters In Proc 16th IEEE Int'l Conf on Program Comprehension  pages 192ñ201 2008  N W ilde and M C Scully  Softw are reconnaissance Mapping program features to code Software Maintenance Research and Practice  7:49ñ62 1995  A T  Y ing G C Murph y  R Ng and M C Chu-Carroll Predicting source code changes by mining change history IEEE Transactions on Software Engineering  30\(9 586 2004  A Zeller  The future of programming en vironments Integration synergy and assistance In Proceedings of the 29th International Conference on Software Engineering The Future of Software Engineering  pages 316ñ325 2007  T  Zimmermann and P  W eiﬂgerber  Preprocessing C VS data for 002ne-grained analysis In Proc 1st Int'l Workshop on Mining Software Repositories  pages 2ñ6 May 2004  T  Zimmermann P  W eiﬂgerber  S Diehl and A Zeller  Mining version histories to guide software changes In Proc 26th ACM/IEEE Int'l Conf on Software Engineering  pages 563ñ572 2004 A Clustering Algorithm This algorithm is not sensitive to whether a given program element exists or not in a given version of a program For example if method m exists in one version it is considered a valid program element even if it is removed in a later version In the rest of this section we use the term program element to refer to the uniquely identifying representation of the element e.g a Java fully-quali\002ed name Let T be a transaction modeled as a set of program elements changed together during the history of a software system Let T be a sequence of transactions In this algorithm a cluster is also modeled as a set of elements 1 Input  T  A sequence of transactions 2 Parameter  M IN O VERLAP  A positive non-zero value indicating the minimum overlap between two transactions in a cluster 3 Var  C  A set of clusters initially empty 4 for all T i 2 T do 5 MaxOverlap  0 6 MaxIndex  000 1 7 for all C j 2 C do 8 if j C j  T i j  MaxOverlap then 9 MaxOverlap  j C j  T i j 10 MaxIndex  j 11 end if 12 end for 13 if MaxIndex   0  MaxOverlap 025 M IN O VERLAP  then 14 C MaxIndex   C MaxIndex  T i  15 else 16 NewCluster  T i 17 C  C  f NewCluster g 18 end if 19 end for 20 return C B Systems Analyzed System home pages last veri\002ed 7 May 2008 Ant ant.apache.org Azureus azureus.sourceforge.net Hibernate www.hibernate.org JDT-Core www.eclipse.org/jdt/core JDT-UI www.eclipse.org/jdt/ui Spring springframework.org Xerces xerces.apache.org 
26 
26 
26 
26 
26 


