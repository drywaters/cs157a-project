  Proceedings of the Sev e nth Inter n ational Conference on Mac h ine Lear ning and Cyber n etics  K u nming,12-15 J u ly 2008 UAP-MINER A REAL-TIME RECOMMENDA TION ALGORITHM BASED ON USER ACCESS SEQUENCES HUA JIANG, DAN Z U O, X I N HU, YONG-X IN GE, BIN HAN C o l l e ge of C o m put er Sci e nce, Nort heast Norm al Uni v ersi t y C h angchun 130024, C h i n a E-M A IL ji angh289@nenu.edu.cn zuod539@nenu.edu.cn, gey x nenu edu.cn, hanb147@nenu.edu.cn Abstract Recommendation is an application of web mining Ho w e v e r  mos t of th e cu rr en t r ecomm en d a tion mech an is ms  n eed to gen erat e all as s o ciati o n ru les b e fore re commen d a tion s   This takes lots of time and c a n\222t pr ovide re al-time  recomm en d a tion s for on lin e u s ers I n th is p a p er  we p r op os e a n ovel algor ith m cal l ed U s er Acc e s s Pattern min i n g  UAP-min er  t o p 
r ovid e rea l time r ecomm e n d a tion s  b a s e d  u s er acc e s s p a ttern s  UAP-min er u s es a d a ta s t ru ctu re n a m e d  as Us er Ac ces s Patt ern t r e e  o r UAP-tr ee in  s h ort. Th e Us er Acces s Pat t ern  tree  can ef fic i e n tly s t ore l a rge n u m b er of u s e r  acces s  in format ion  Ac cord in g  to th e u s er ac ce s s p a ttern s  th e  UAP-min er s c an s relevan t s u b trees of th e Us er Acc e s s  Pattern tree to gen erate real-time recommen d a tion s   Keyw ords Web min i n g S e q u e n t ial p a ttern s min i n g UAP-tree  Real-time recommen d a tion s  1 Introducti on W e b m i ni ng 1  ap pl i e s t h e dat a m i 
ni ng t echn o l o gi es to hug e W e b data repo sitories W ith t h e ex p l o s iv e growth of dat a avai l a bl e on t h e W o rl d W i de W e b   W e b m i ni ng i s  becom i ng i m port a nt an d e v en necessa ry Fo r e x am pl e analyzing a nd disc ove ring user access be havior is helpful fo r  u n d e rst a ndi ng  what  onl i n e i n fo rm at i on u s ers i n qui re a n d ho w t h ey be h a ve T h e anal y zed res u l t c a n be  use d i n  in tellig en t on lin e app licatio n s refi n i ng web site m a p s  im proving sea r chi n g accurac y whe n seeki n g inform atio n and leadi n g decision m a kers to wards bett er decisions 
i n  changing m a rkets e.g., putti n g ad v e rtisemen ts in i d eal  places better custom er classifi cation, etc Resea r c h ers have pr op os ed vari ou s recom m endat i o n  t ech ni q u e s  Collaborative filtering [2] is a successful and wi dely used recomm endation technique Ho wev e r  pure co llab o rativ e filterin g appro a ch es require m a in tain in g p e rsisten t  i ndi vi dual  pr of i l e s, w h i c h ca n be  rest ri ct i v e  and i m pract i cal for a n onym ous users. C ons eque ntly som e recently pr o pose d rec o m m e ndat i o n s y st em s have  r e l i e d s o l e l y o n  W e b ac cess da t a i n st ead  of c ont e n t  or  user  pr ofi l e s  3    9  
  10  In ge ne ral, mining use r access patterns can be con s i d ere d as a speci al t y pe of seque nt i a l pat t e rns m i ni ng i n  t h e fi el d o f  web m i ni ng The m o st po pul a r seq u e n t i a l p a ttern s m i n i n g algorith m see m to b e th e Ap ri o r i algorit h m  4   w h i c h i s t h e fo u ndat i o n of m o st kn ow n al g o r i t h m s It  u s es a p r op erty statin g th at if a k-ite m s ets is freq u e n t all of i t s k 1  i t e m s et s m u st be f r e que nt  H o we ver  t h e  Ap ri o r i alg o rith m g e n e rates and tests candid a te ite 
m s et s lev e l-b y lev el. Th is m a y cau se iterativ e d a t a b a se scan and  hi gh com put at i onal cost  Han et al   5   t hus p r op ose d  t h e f r e que nt p at t e rn-t ree  FP t r ee st r u c t ure fo r e f fi ci e n t l y  m i ni ng fr eque nt i t e m s ets in transactio n a l d a tab a ses wi th ou t g e n e ratio n of can d i d a te ite m s ets. Th e FP-tree is used to co m p ress a d a tab a se in t o  a tree in wh ich stores on ly lar g e item s It allev i ates the m u l ti-scan  p r ob lem an d imp r ov es the can d i d a te item s e t  gene rat i o n Th e al g o ri t h m re qui res t w o sca n s o 
f t h e dat a s e t to bu ild th e t r ee and t h en m i n e s th is st ru ct u r e d i rectly Pei et al. [6 propose d a n ef ficient com p lete W e b access patterns mining al gorithm based on highly com p res s ed W e b acce s s  p a ttern s tree \(W AP-tree r to th e FP-tree W A P-tree was pr o pos ed  fo r m i ni ng se q u ent i a l  pat t e rn s we b l o g  T h e W A P-tree stores the se quent i al we b acce s s log in a tre e  structure. The authors of this algorithm report that t h eir alg o rith m is f a ster th an t h e A p r i or i-b a sed co un terp ar t fo r m i ning W e b access patterns In this paper  we prese n t a com p act struct ure  nam e d  User Access Pattern T r ee t o m odel the user access patterns Additionally  we apply the search m echanism 
calle d  UAP-m i ner to mine the Use r Acc e ss Patte rn T r ee, and t h e m i ni ng res u l t s are p r u n e d by use o f ass o ci at i on r u l e s. T h e associ at i o n k n o w l e d g e  ca n be use d t o  dy nam i cally recom m e nd t h e proper si t e s or pages for web users  The rem a i nder of t h i s  pa per i s or ga ni zed as fol l o ws In  Section 2, we defi ne releva nt term s used in user acces s p a ttern s m i n i ng  In Sectio n  3   we in trod u c e th e d e fin ition  an d con s tru c tio n of  U s er A ccess Pattern T r ee. Section 4 cont ai n s a de scri pt i o n o f t h e U A P m i ner al go ri t h m and    978-1-4244-2096-4/08/$25.00 \2512008 IEEE 356  


  Proceedings of the Sev e nth Inter n ational Conference on Mac h ine Lear ning and Cyber n etics  K u nming,12-15 J u ly 2008 Sect i on 5 draws t h e concl u si ons of t h i s st udy  2  Prelimina r ies In ge ner a l  a W e b l o g can be r e gar d e d as a se que nce o f  p a irs of u s er id en tifier an d ev en t. It reco rds all W e b access  inform ation W ith t h e data preprocessing techniques, t h e o r i g in al W e b lo g can  b e tran slated in to th e data ad ap tab l e to t h e m i ni ng al go ri t h m 1 1 T h e dat a p rep r ocessi n g  t echni q u es ca n be  ro u ghl y cl a ssi fied in to two categ ories 7  Th e f i rst ap pro ach m a p s t h e w e b log in t o t h e r e lationa l  d a tab a se, and th en ap p lies ad ap ted m i n i n g algo rith m s to  analyze it. The second m e thod adopts s p ecial pre p rocessi ng p r o cess to t r ansform th e lo g d a ta to fit m i n i n g algorith m s  Th e m a in d a ta-prepro cessing in cluded data cleaning use r  id en tificatio n, sessio n i d en tificatio n an d tran saction  id en tificatio n. Mo re d e tails ab ou t t h e d a ta-prepro cessing t echni ques of web m i ni ng can be found i n 8   No w we gi ve s o m e conce p t s  and  not at i o ns  Let E be a  set of ite m s The use r acce ss seque n ce S is an orde re d collection from E 12    m Se e e 001 001  1   The pattern P  is said a fre quent use r acces s pattern if P\222 s su ppo r t satisf i es a pr ed ef in ed m i n i m u m su p por t th r e sho l d     1 i eE i m  m m 12      n SDB S S S   Let  refe r to a user access se que nce in SDB   The user acces s pattern P re pres ents t h e browsing beha vior and is c h ara c terized as a se ries of item s The s u pport of a  user access pattern P is the num ber of se que ntial t r ansact i ons cont ai ni ng P i n SDB   1  i Si n 003 Ot herwise, i t is called a non-freque nt use r access  p a ttern  Gi ve n a se que nt i a l t r ansact i o n dat a base S D B  a use r  access pattern P  and a m i nimum support t h reshold 003 our ob ject i v e i s t o  recom m end t h e pr ope r i t e m to use r acc or di n g  to the user access pattern 3. UAP-tree construction In th is section  we in trodu ce t h e d e fi nitio n an d  construction of a User Access Pattern T r ee 3.1. Definiti on of UAP-tree A Use r Access  Patterns t r ee structure, or UAP-t r ee i n  short  can be defi ned as fol l o ws 1  It i s com posed of a r oot  no de a set o f i t e m  pre f i x  subt rees as t h e chi l d re n of t h e r o ot a n d a n i t e m  heade r  ta ble. Each node  in a UAP-t r ee re gisters two pieces of inform ation label a n d c o unt denot ed as l a bel  count  2   Th e roo t of th e UAP-tree consists o f three fi eld s   ite m _ n a m e ch ild _no d e _ link, an d to tal_ co un t whe r e i t e m _nam e represe n t t h e nam e of t h e ro ot  n o d e and is lab e led as \223n ull\224, ch ild_n ode_ lin k poi nt s t o a set  of t h e p r e f i x n ode s a n d t o t a l _ cou n t  regi st ers t h e num ber o f se que nt i a l t r ans act i ons stored in the UAP-tree 3   Each  no d e in th e item p r efix sub t ree con s ists o f  fo ur fi el ds i t e m _nam e coun t  chi l d _ n ode _ l i nk  an d n o d e _ lin k, in wh ich ite m _ n a m e reg i sters wh ich ite m n o d e rep r esen ts, co un t reg i sters th e num ber of  t r a n sact i on rep r ese n t e d by  t h e  p o r t i on of the porti o n of t h e path reachi n g this  node ch ild _no d e _ link po in ts t o a set o f t h e prefix no des  a n d n o d e_l i n k l i nks t o a set o f t h e ne xt  n o d e s in t h e UAP-tree carrying th e sa me  item _ n a m e  4   Each en t r y in th e item h ead er tab l e co n s ists of t h ree fi el ds i t e m _nam e ne xt _o b j ect _l i n k   head _ n o d e _ l i n k w h ere i t e m _nam e regi st ers wh ich ite m th is ob j ect represen ts next _o b j ect _l i n k l i n ks t o t h e ne xt  ob ject  i n t h e i t e m header t a bl e hea d _ n o d e _l i n k  poi nt s t o  fi rst  n o d e i n th e UAP-tree carryin g th e ite m_ n a m e   No tice th at each item _ n a m e  of t h e objects in the i t e m header t a bl e i s uni que 3.2 UAP-tree construction algorithm Based on  t h e ab ov e d e fin itio n o f  th e UAP-tree, we devel op t h e fol l o wi ng UAP-t ree const r uct i on al gori t h m   A l go r ith m 1 show s t h e UAP-tree co nstru c tion  alg o rith m  wh ich is b a sed  on t h e set o f sequ en ti al  tran sactio n th at is th e resu lt o f d a ta-p rep r o cessin g   Al gori t h m 1 UAP-t ree const r uct i on \(SDB   In p u t: A seq u e n tial tran sactio n d a tab a se, SDB Output: The UAP-tree T  and Headers M e t hod  1  C r eat e a root node for T   2 For each sequence S 004 SDB  denot ed as S  e 1 e 2 205 e m do a Increase t h e t o t a l _ count of T by 1   357 001\002 002  The l e ngt h of t h e se que nces S i s  A use r access sequ en ce with len g t h  is also called a seq uence  A  seq u e n tial tran sactio n d a tab a se is  S m 002\002 sup        ii i PP P P P S D B 


  Proceedings of the Sev e nth Inter n ational Conference on Mac h ine Lear ning and Cyber n etics  K u nming,12-15 J u ly 2008 b sub_T T c For each item e  S do d  If s u b_ T ha s a chi l d l a bel e d e i increa se the count of e i by  1 a nd m a ke su b_ T p o i n t t o e i  else create a ne w c h ild node e i 1  set sub_T  p o i n t to th e new ch ild  nod e an d in sert it in t o  the item header table 3 Return T  and Headers 3.3  Example of UAP-tree construction Now we gi ve an e x am ple to show a c o m p lete process  o f co nstructing a UAP-tree T a b l e 1 sh ows th e sequ en tial  t r ansact i on dat a base SDB i n our exam pl e  T a bl e 1 A sequent i a l t r ansact i on dat a base   The c o r r es po n d i n g UA P-t r ee i s sh ow n i n F i gu re 1  T o  con s t r uct t h i s  UA P-t r ee st art i ng fr om t h e r oot  n ode T  an d set th e item _ n a m e o f t h e roo t t o 223nu ll\224. Th en read i n g t h e  sequ en tial transactio n A, B   C, D fro m SDB, inserts t h em in to t h e tree, and i n creases to tal_ co un t si m u ltan e o u s ly  Each ite m bec o m e s a ne w child node of T   and eac h node  is  lab e led i n t h e fo rm lab el co un t e seco nd sequ en tial  transaction A B, D sha r es t h e com m on pre f i x  pat h  A  B>, w ith th e ex istin g  UA P-tr ee, th e co unt o f each node al on g t h e pre f i x i s i n crea sed by 1, a n d a ne w n o d e D  1   i s  created. For t h e third seque n tial tran sactio n <A, B, C   th ere is a p r efix  p a th A, B  C D and s h ares the same  ite m s with t h e th ird sequ en tial transaction T h ere f ore, it ca n increase t h e c o unt of the sha r ed pre f ix pat h  A, B  C At the sam e time it shares t h e com m on pre f i x pat h  A B   with th e secon d sequ en tial tran saction   Fo r t h e fou r t h  sequ en tial transactio n B, C, A>, it d o e s no t sh are an y p a rt  with t h e ex istin g UAP-tree so  we h a v e to create ano t h e r b r an ch  o f th e t r ee. Fin a lly  for t h e last sequ en tial tran saction  B A>, as sa me as a b ove, i t increa ses t h e  count of node  B wh ich in  p a th <B, C, A fo r t h e sh ared  p r efix  p a rt <B   The n it create s a ne w node A Whene v er a ne w node is in serted in t o  UAP-tree, t h e lin k ad ju sting p r o cess runs im m e di at el y  Com i ng wi t h t h e const r uct i o n o f U A P t r ee, a n  ite m h ead er tab l e is bu ilt in  wh ich each item p o i n t s t o its  occurre nce i n t h e tree via a he ad_node _link Nodes with t h e  sam e  i t e m _nam e are l i nked vi a n ode _l i n k  The U A P-t r e e  with its asso ci ated  n o d e _ lin k and ite m h ead tab l e is sh own i n Fi gure 1   Figure 1 The item header table and UAP-tree  Th e UAP-tree sho w s th e co m p lete in fo rmatio n fo r user access  pa ttern m i ning It avoids re pea t edly scanning th e sequ en tial tran saction  da tab a se. Fro m th e UAP-tree  co nstr u c tion pr o cess w e can see th at on e on ly scan s t h e  transaction dat a base SDB once to con s tru c t th e UAP-t r ee Thi s saves  l o t s of pr ocessi n g  t i m e t h at  c a n be used fo r  furthe r a n alys es. T h e c o st of inse rting a use r acce ss sequence S i n to the UAP-tree is O\(|S w h ere |S| is t h e n u m b e r o f item s  in S. Th e n e x t section in trodu ces the  algorithm for mining fre que nt use r acces s patterns via a UAP-tree 4 UAP-miner  In th is section  we d e scri be th e nov el UAP-m i n e r  algorithm for mining freque nt use r acce ss patterns  on t h e UAP-tree  It se arches for the best m a tching user access pat h  in the  UAP-t ree acc ording to a user 222 s curre nt acce ss sequence  W e rem ove the c u rrent user a c cess seque n ce\222 s  h ead i n g  rep e ated ly u n til we fin d a m a tc h i ng p a t h The  UAP-m i ner c o nsists of two pieces of al gorithm cooperating wi t h eac h ot h e r   The R eco m m e nd al g o ri t h m cont r o l s t h e  m i ni ng pr oces s an d m a nages t h e i n put  o ut p u t o f t h e Pr un e algorithm  Prune algori t h m can eliminates the  recom m endat i ons n o t sat i s fy i ng t h e m i ni m u m supp o r t t h reshol d 003  4 1  Descri pti o n of UAP-mi n er Al g o ri t h m 2 sh ows t h e R e c o m m e nd al g o ri t h m t o m i n e    358 


003  The al gorithm Reco mme nd invokes  the Prune al go ri t h m  The f unct i on P r u n e p r u n es t h e i n f r eq ue nt i t e m s  according to the count, a n d re turns the fre quent use r access  p a ttern s as reco mmen d a tions. Th e d e tail o f the Prune  al gori t h m i s gi ven as Al gori t h m 3 Al gori t h m 3 Prune \(R R   003  3   Delete th is item fro m RR 4  Retu rn  RR 4 2  E xampl e of UAP-mi n er Let\222 s co nsid er th e UAP-tree in  figu re 1. Su ppo se P=<D, B  C be the use r 222 s c u rrent acces s pattern 0.1 007 ca n r e f e r to th e co un t o f node A and  D   Th er efo r e, <B   C A confide n ce 1/3; a n d B C D   confide n ce 1/3. Our a p proa ch ca n provi de m o re precis e  recom m e ndat i ons for users 5 Concl u si ons  I n th is p a per   w e study th e g e n e r a tin g o f  recom m endat i ons  f o r  an o n l i n e user bas e d on t h e us er access pattern. W e propose a ne w data st ruct ure  nam e d UAP-tree to store use r ac ces s seque n ce W e ha ve use d t h e  UA P-t r ee i n  o u r  new al go ri t h m nam e d U A P-m i ner wi t h  whi c h real t i m e rec o m m endat i on can be d one W e b user    359 007 b  2   In th is ex am p l e, th e  can refer to the sum of the c o unt of node C, and  count   Proceedings of the Sev e nth Inter n ational Conference on Mac h ine Lear ning and Cyber n etics  K u nming,12-15 J u ly 2008 the freque nt us er access patte rn s on the UAP-tree. Its m a jor j o b is t o coo r din a te with t h e o t h e r algo rithm  to ach iev e th e m i ni ng t a sk Al gori t h m 2 R ecom m e nd \(Headers  P  003   Input   An item header table pointi ng to UAP-tree, Headers a current user access sequence, P t h e m i ni m u m support t h reshol d 003  an i ndex vari abl e t o i ndi cat e t h e i t e m i n P  i ndex Ou tp u t: reco m m e n d resu lts, RR M e t hod  1  In itialize RR  003   Input   A set of recom m e ndi ng nodes, R R   a m i ni m u m support t h reshol d 003  Ou tp u t The recom m endi ng res u l t s  sat i s fy su pp ort t h res h ol d 003 RR M e t hod  1 For each ite  2  003   be t h e m i nimum supp o r t t h resh ol d  It c o nsum es t h e fi r s t i t e m D i n P  an d fi nds t h e c o r r e sp on di n g  ob je ct D re gi st ere d  as ite m _ n a m e  in th e item h ead er tab l e Acco rd ing to  obj ec t  D 222 s h e ad_ node_ lin k, it can  f i nd two nod es lab e led as D   Because the  two nodes ha ve no c h ild node, we the n rem ove th e first item o f  P\227t h at is, P=<B, C W e  rep eat th e m a t c hi ng pr oc ess. N o w   we can fi nd t h e  m a t c hi ng pat h  B C in t h e UAP-t r ee, wh ich is m a rked as t h e bold, white no de T h ere a r e t w o m a t c hi ng pat h s a n d ea ch n ode C  has  ch ild  nod e D an d n o d e  A wh ich are m a rked as  gray node s  sho w n i n  Fi g u r e 2 N o de D  and  no de A a r e t h e u n p ru ne d  recomm ended results. T h e n  UAP-m i ner checks the s u pport threshold to prune of f the in frequent user access patterns     Figure 2 The UAP-m iner exam ple The m i nim u m supp ort c a n be cal c u l a t e d as  003  m u ltiplied by the num b er of  use r acces s patterns \(root no de 222 s t o t a l _ c o unt  n S D B   S o t h e m i nim u m su p p o r t i s  0 5 For eac h reco m m e nded res u l t  i t s count sh oul d sat i s fy t h e m i nim u m supp ort  N o de D a n d no de A sat i s f y t h e m i nim u m  sup p o rt t h res hol d 1 0  5  t h en we ob tain th e recom m ended resul t A  a n d D vi a t h e  U A P m i n er W e  c a n  prese n t t h e re commended result as ass o c i ation rule  B   C A and <B, C D>, the n  we can rank the  recom m e nded results by calculating confidence as      c ount c onfide n c e count 006 006    count 006 005 2 Let   m ean s th e first item in P 3 For each header_objec Headers do 4  If header t a bl e has a object nam e d e a If t h e no de l a bel e d e i n t h e U A P-t r ee has chi l d  no des  a n d t h e nam e of i t e m _nam e as the sam e as P[index] then b   in sert th e ch ild o f th ese ch ild n o d e s in t o RR  wi t h i t s count  c Else rem ove the first item from P 5 R e t u rn Prune\(R R   006\007 006 


  Proceedings of the Sev e nth Inter n ational Conference on Mac h ine Lear ning and Cyber n etics  K u nming,12-15 J u ly 2008 access pattern m i ning is a ne w resea r c h  field. It wi ll devel o p a n d  b e ap pl i e d wi de l y Fo r t h e c o m m e rce dem a nd increase day by day  t h ere are lo ts of p r ob le m s  n eed to be reso lv ed an d we will wo rk fu rth e r in th is field   References 1  Jiawei Han, Michelin e Kam b er, Dat a M i ni ng  Co n c ep ts an d Techn i qu e Secon d  Ed itio n, Ch i n a M achi n e Press, B e i j i ng, M a rch 2007 2  Breese. J, Hecherm a n D, Ka die. C 223Em p irical an alysis o f  Pred ictiv e Al g o rith m s fo r C o l l ab orativ e Filterin g 224 Pro ceed i ng o f  th e Con f eren ce on  Un certain t y in Artificial In t e llig en ce \(UAI\2229 8 pp  43-52, 1998 3  Zh ou B  H u i  S, C h a n g  K  223En h anci ng m obi l e web access using i n telligent rec o mmendations\224, Intelligent sy st em s, pp. 8-34, 2006 4   Agrawal. R, Srik an t. R, \223Min ing sequ en tial p a ttern s\224   In Pro c In ternatio n a l C o nf erence on Data E ngi neeri n g IEEE CS Press, pp. 3-14, 1995 5   Han. J Pei. J, Yin. Y 223Min in g freq u e n t p a tterns wi t hout candi dat e generat i on\224, SIGM OD, 2000 6  Pei. J, Ha n J, Mortazav i a s l. B, Z h u H, \223Mining access patterns efficiently fr om web l ogs\224  Proc 4t h Pacific-Asia Conf Knowledge Disc ove ry and Data  Min i n g  P AKD D 00  LNCS 180 5, Spr i ng er  p p  396-407, 2000 7  B o r g es. J  Le v e ne. M  223 D at a m i ni ng of user navi gat i o n  pat t e rns\224  P r oc eedi n g of  t h e WEB K D D 222 9 9 Wo r k sh o p  on  W e b Usa g e A n al y s i s an d User Pr o f i l i ng p p  3 1 3 6  1999  8  C ool ey R   M obs her  B  Sri v ast a va J, \223Dat a pre p arat i o n fo r m i ni ng wo r l d wi de we b br ow si n g  pattern\224  K n o w led g e a n d In fo rm ation Sy stem s 1  1    17-24, 1999 9  Tsen g  V  Li n K 223E ffi ci ent  m i ni ng a n d pr edi c t i o n o f  user  beha vi o r pat t e r n s i n m obi l e we b sy st em s\224 In fo rm ation and So ftwa re techn o lo gy  pp 3 5 7 3 6 9   2006 1 0  C h en T S Hs u S, \223M i n i n g f r eq ue nt t r ee-l i ke pat t e rns  in  larg e d a taset s 224, Data Kno w led g e  En g i neering  pp  65-83, 2007 1 1  Sri v ast a va J  C ool ey R  et  al 223 W e b Usa g e M i ni ng  Discovery a nd Applications  of Usa g e Patt erns fro m  W e b Dat a\224, SIGKDD Expl orat i ons, 2000    360 


Table 2 Comparison of C4.5 CBA CMAR and ACN on accuracy Dataset ACN CMAR CBA C4.5 diabetes 76.3 75.8 74.5 74.2 pima 75.1 75.1 72.9 75.5 tic-tac 99.7 99.2 99.6 99.4 iris 95.3 94 94.7 95.3 heart 82.2 82.2 81.9 80.8 lymph 83.1 83.1 77.8 73.5 glass 73.8 70.1 73.9 68.7 austra 85.5 86.1 84.9 84.7 led7 71.9 72.5 71.9 73.5 horse 83.7 82.6 82.1 82.6 sonar 79.8 79.4 77.5 70.2 hepati 83.2 80.5 81.8 80.6 crx 85.2 84.9 84.7 84.9 cleve 81.5 82.2 82.8 78.2 hypo 98.9 98.4 98.9 99.2 sick 97.3 97.5 97 98.5 Average 85.4 84.6 84.3 83.0 Table 3 Comparison of ACN and ARC-PAN on accuracy Dataset ACN ARC-PAN diabetes 76.3 74.9 pima 75.1 73.1 iris 95.3 94.0 heart 82.2 83.8 led7 71.9 71.1 breast 95.3 96.2 Average 82.68 82.18 For ARC-PAN we consider the results obtained when all rules both positive and negative are used for classi\002cation From table 3 we see that the win-loss-tie record of ACN against ARC-PAN is 4-2-0 5 Conclusions In this paper we proposed a novel classi\002cation algorithm ACN that mines both positive and negative class association rules and uses both sets for classi\002cation We showed that the number of generated negative rules is large and so using them in place of some weak positive rules can enhance classi\002cation accuracy Our experiments on UCI datasets show that ACN is consistent highly effective at classi\002cation of various kinds of databases and has better average classi\002cation accuracy compared to C4.5,CBA,CMAR and ARC-PAN References  R Agra w al and R Srikant F ast algorithms for mining association rules In VLDB  Chile September 1994  M Antonie and O R Za 250 021ne An Associative Classi\002er based on Positive and Negative Rules In DMKD  Paris France June 2004  M Antonie and O R Za 250 021ne Mining Positive and Negative Association Rules an Approach for Con\002ned Rules In Principles and Practice of Knowledge Discovery in Databases  2004  E Baralis and P  Garza A Lazy Approach to Pruning Classi\002cation Rules In ICDM  2002  C Blak e and C Merz UCI repository of m achine learning databases  R Duda and P  Hart Pattern Classi\002cation and Scene Analysis  John Wiley and Sons 1973  J Han J Pei and Y  Y i n Mining frequent patterns without candidate generation In SIGMOD  2000  G K undu S Munir  M F  Bari M M Islam and K Murase A Novel Algorithm for Associative Classi\002cation In International Conference on Neural Information Processing  Japan 2007  W  Li J Han and J Pei Accurate and ef 002cient classi\002cation based on multiple class association rules In ICDM  San Jose CA November 2001  T  Lim W  Loh and Y  Shi h A comparison of prediction accuracy complexity and training time of thirty-three old and new classi\002cation algorithms Machine Learning  39 2000  B Liu W  Hsu and Y  Ma Inte grating Classi\002cation and Association Rule Mining In KDD  New York August 1998  J Quinlan C4.5:Programs for Machine Learning  Morgan Kaufmann 1993  A Sa v asere E Omiecinski and S Na v athe Mining for Strong Negative Associations in a Large Database of Customer Transactions In ICDE  1998  S.Bri n R Motw ani and C.Silv erstein Be yond mark et baskets Generalizing association rules to correlations In ACM SIGMOD  1997  D Thiruv ady and G W ebb  Mining Ne g ati v e Association Rules using GRD In PAKDD  2004  X W u C Zhang and S Zhang Ef 002cient Mining of Both Positive and Negative Association Rules ACM Trans on Information Systems  22\(3 2004  P  Y an G Chen C Cornelis M D Cock and E K erre Mining Positive and Negative Fuzzy Association Rules In LNCS 3213  2004  X Y in and J Han CP AR Classi\002cation based on Predicti v e Association Rules In SDM  2003  X Y uan B P  Buckles Z Y uan and J Zhang Mining Ne gative Association Rules In Seventh International Symposium on Computers and Communications  Italy June 2002 


Table 10 Overview of different error classes in DC1 Algorithm All Features Multi-word features Single-word features False negatives False positives False negatives False positives None of the terms extracted Some of the terms extracted All extracted but not combined On-topic features Off-topic features Not extracted Extracted falsely as multi-word On-topic features Off-topic features Association Mining 594 14 62 25 23 0 45 39 260 259 Likelihood Test 594 138 1 0 1 0 295 3 29 0 002ed the algorithm in order to consider only the subsequence of the extracted feature which consists of nouns We refer to these two modi\002cations as Subsequence Similarity SsS An evaluation of these modi\002cations is shown in columns 5 and 6 of Table 7 We observe an average increase of recall by 2 and an increase of precision by 10 4.3.2 Analysis of the Association Mining Approach The precision of the Association Mining approach is fairly low since it returns any noun as a feature if it often occurs in the documents For example the term week is extracted as a frequent feature There is no distinction between dataset speci\002c terms and common vocabulary terms Setting the minimum-support threshold higher will not solve this problem as it would lead to decreased recall Note that in our evaluation Table 8 the infrequent features hardly affect the algorithm's results since they are only very seldomly extracted at all For example in the DC1 dataset of the 597 sentences only 12 contain an opinion word but no frequent feature Of those 12 cases the infrequent feature identi\002cation leads to 7 correct and 5 false features being extracted In some cases see Column 9 of Table 10 the association mining falsely attributes nouns occurring in a sentence to a single feature set For example in 4 recent price drops have made the g3 the best bargain in digital cameras currently available g3 is extracted as a feature set since the two terms occur together as one entity in multiple other sentences The compactness pruning will therefore not remove this feature set Sentences as 4 will hence result in an error during extraction The large amount of false positives in the single-word feature extraction see Table 10 Columns 6  7 is due to the fact that many sentences in the DC1 dataset consist of comparisons of the DC1 camera to other camera models The features of these other camera models are also mentioned in the reviews and therefore falsely extracted by the association mining since the algorithm is not capable of distinguishing between references to features of the DC1 camera and any other camera model 4.3.3 Comparison of the Approaches As outlined in Table 10 the two approaches have their strengths and weaknesses in different tasks If the Likelihood Ratio Test approach fails to extract a multi-word feature the tendency is that none of the feature terms are being extracted while this is not the case in the association mining approch This is due to the fact that the association mining algorithm will return any feature combination occurring in a given sentence while the Likelihood Ratio Test approach requires that a multi-word feature occurs in the same ordering in several sentences in order to achieve a high likelihood ratio and therefore be extracted The threshold of the Likelihood Ratio Test approach in combination with the Subsequence similarity calculation will therefore prevent that a subset of a multi-word feature is extracted instead the feature will not be extracted at all At the same time the association mining extracts several false multi-word features none of them belonging to the general vocabulary We observe similar results in the analysis of the single-word errors The Likelihood Ratio Test approach fails to extract many of the features which is again due to the threshold while the Association Mining approach extracts less false features but has the problem of wrongly extracting actual single-word features as a multi-word expression as analyzed in Section 4.3.2 The inability of the Association Mining approach to recognize whether a certain candidate feature is an attribute of the current topic as de\002ned in Section 2.1 is observable in Columns 10  11 of Table 10 The Association Mining approach extracts a large number of false features compared to the Likelihood Ratio Test approach The low number of falsely extracted on-topic features of the Likelihood Ratio Test approach could be attributed to the dBNP method Apparently if a candidate BNP is preceded by a de\002nite article an on-topic feature follows However the low number of false positives during the feature extraction re\003ects the tradeoff between recall and precision of this approach 5 Conclusions In this paper we provide a comprehensive analysis of two state-of-the-art algorithms for extracting features from product reviews based on the Likelihood Ratio Test and on 
159 
150 


association mining The Likelihood Ratio Test fails to extract features also belonging to common vocabulary and it makes the extraction dependent on the feature position in the sentence leading to low recall The dBNP and bBNP based methods yield low recall due to the fact that the product features do not occur with the article the in front of them very often The Association Mining approach returns all frequent nouns which decreases precision Our results suggest that the choice of algorithm to use depends on the targeted dataset If it consists of mainly on-topic content the results of Table 10 indicate that the Association Mining algorithm is better suited for this task due to its high recall If the dataset consists of a mixture of onand off-topic content our results suggest that the Likelihood Ratio Test based algorithm would perform better due to its ability to distinguish and 002lter out the off-topic features For future work we plan to extend the Likelihood Ratio Test methods especially the dBNP based approach by other determiners such as a or this  which should increase the recall of this method Another possibility which we will investigate regards the BNP patterns The current Likelihood Ratio Test approach is not capable of dealing with discontinuous feature phrases for example in 5 the quality of the pictures is great the feature would be picture quality  This problem could be addressed by introducing wildcards in the BNP patterns We will also investigate whether there are any methods in order to calculate an optimal threshold for the candidate feature extraction in order to increase the recall of the Likelihood Ratio Test based algorithm We plan to investigate whether a deeper linguistic analysis e.g with a dependency parser can improve the feature extraction Acknowledgements The project was funded by means of the German Federal Ministry of Economy and Technology under the promotional reference 01MQ07012 The authors take the responsibility for the contents The information in this document is proprietary to the following Theseus Texo consortium members Technische Universit  at Darmstadt The information in this document is provided as is and no guarantee or warranty is given that the information is 002t for any particular purpose The above referenced consortium members shall have no liability for damages of any kind including without limitation direct special indirect or consequential damages that may result from the use of these materials subject to any liability which is mandatory due to applicable law Copyright 2008 by Technische Universit  at Darmstadt References  R Agra w al and R Srikant F ast algorithms for mining association rules Proc 20th Int Conf Very Large Data Bases VLDB  1215:487–499 1994  K Bloom N Gar g and S Ar g amon Extracting a ppraisal expressions In HLT-NAACL 2007  pages 308–315 2007  R Bruce and J W iebe Recognizing subjecti vity a case study in manual tagging Natural Language Engineering  5\(02 1999  K Da v e S La wrence and D Pennock Mi ning the peanut gallery opinion extraction and semantic classi\002cation of product reviews In Proceedings of the 12th International Conference on World Wide Web  pages 519–528 New York NY USA 2003 ACM  T  Dunning Accurate methods for the statistics of surprise and coincidence Computational Linguistics  19\(1 1993  O Feiguina and G Lapalme Query-based summ arization of customer reviews In Canadian Conference on AI  pages 452–463 2007  C Fellbaum Wordnet An Electronic Lexical Database  MIT Press 1998  A Ferraresi Building a v ery lar ge corpus of english obtained by web crawling ukwac Master's thesis University of Bologna Italy 2007  M Gamon A Aue S Corston-Oli v er  and E Ringger  Pulse Mining customer opinions from free text In Proceedings of the 6th International Symposium on Intelligent Data Analysis IDA-2006  Springer-Verlag 2005  N Glance M Hurst K Nig am M Sie gler  R Stockton and T Tomokiyo Deriving marketing intelligence from online discussion In Proceedings of the 11th ACM SIGKDD International Conference on Knowledge Discovery in Data Mining  pages 419–428 New York USA 2005 ACM  M Hu and B Liu Mining opinion features in customer reviews In Proceedings of 9th National Conference on Arti\002cial Intelligence  2004  N K obayashi K Inui K T atei shi and T  Fukushima Collecting evaluative expressions for opinion extraction In Proceedings of IJCNLP 2004  pages 596–605 2004  S Morinag a K Y amanishi K T ateishi and T  Fukushima Mining product reputations on the Web In Proceedings of KDD-02 8th ACM International Conference on Knowledge Discovery and Data Mining  pages 341–349 Edmonton CA 2002 ACM Press  A.-M Popescu and O Etzioni Extracting product features and opinions from reviews In Proceedings of HLT-EMNLP-05 the Human Language Technology Conference/Conference on Empirical Methods in Natural Language Processing  pages 339–346 Vancouver CA 2005  H Schmid T reetagger a language independent part-ofspeech tagger Institut fur Maschinelle Sprachverarbeitung Universitat Stuttgart  1995  J W iebe R Bruce and T  O'Hara De v elopment and use of a gold-standard data set for subjectivity classi\002cations In Proceedings of the 37th annual meeting of the Association for Computational Linguistics on Computational Linguistics  pages 246–253 Association for Computational Linguistics Morristown NJ USA 1999  J Y i T  Nasuka w a R Bunescu and W  Niblack Sentiment analyzer Extracting sentiments about a given topic using natural language processing techniques In Proceeding of ICDM-03 the 3ird IEEE International Conference on Data Mining  pages 427–434 Melbourne US 2003 IEEE Computer Society 
160 
151 


Figure 4 Expected and real number of extracted patterns using two promoter sequence datasets Horizontal axis minimum support vertical axis number of patterns 
85 
85 


a frequency constraint and according to the structure of the dataset These proposals are all based on a global analytical model i.e an interesting approach that needs however to develop complex and speci\036c models As a result they cannot be easily extended to handle complex conjunctions of constraints to incorporate different symbol distributions or different semantics for pattern occurrences To the best of our knowledge no method has been proposed to estimate the number of patterns satisfying a constraint while avoiding to develop a global analytical model Our approach requires only to know how to compute for a given pattern its probability to satisfy the constraint this can be obtained in many situations and it remains ef\036cient in practice by adopting a pattern space sampling scheme 6 Conclusion Using constraints to specify subjective interestingness issues and to support actionable pattern discovery has become popular Constraint-based mining techniques are now well studied for many pattern domains but one of the bottlenecks for using them within Knowledge Discovery processes is the extraction parameter tuning This is especially true in the context of differential mining where domain knowledge is used to provide different datasets to support the search of truly interesting patterns From a user perspective a simple approach would be to get graphics that depict the extraction landscape i.e the number of extracted patterns for many points in the parameter space We developed an ef\036cient technique based on pattern space sampling that provides an estimate on the number of extracted patterns This has been applied to non trivial substring pattern mining tasks and we demonstrated by means of many experiments that the technique is effective It provides reasonable estimates given execution times that enable to probe a large number of points in the parameter space Notice that domain knowledge is also exploited here when selecting the distribution model Future directions of work include to adapt the approach to other pattern domains and to different constraints Another interesting aspect to investigate is the use of more sophisticated sampling schemes e.g that could b e incorporated in the approach when more complex syntactical constraints are handled e.g a grammar to specify the shape of the patterns Acknowledgments This work is partly funded by EU contract IQ FP6-516169 Inductive Queries for Mining Patterns and Models and by the French contract ANR-MDCO14 Bingo2 Knowledge Discovery For and By Inductive Queries We thank Dr Olivier Gandrillon from the Center for Molecular and Cellular Genetics CNRS UMR 5534 who provided the DNA promoter sequences References  J F  Boulicaut L De Raedt and H  M annila e ditors Constraint-Based Mining and Inductive Databases  volume 3848 of LNCS  Springer 2005  C  B resson C K e ime C F a ure Y  Letrillard M  B arbado S San\036lippo N Benhra O Gandrillon and S GoninGiraud Large-scale analysis by SAGE revealed new mechanisms of v-erba oncogene action BMC Genomics  8\(390 2007  L  C ao and C  Z hang Domain-dri v e n actionable kno wledge discovery in the real world In Proceedings PAKDDÕ06 volume 3918 of LNCS  pages 821–830 Springer 2006  G  D ong and J  L i Ef 036cient mining of emer ging patterns discovering trends and differences In Proceedings ACM SIGKDDÕ99  pages 43–52 1999  F  Geerts B  G oethals and J  V  d en Bussche T ight upper bounds on the number of candidate patterns ACM Trans on Database Systems  30\(2 2005  U  K eich and P  A  P e vzner  S ubtle motifs de\036ning the limits of motif 036nding algorithms Bioinformatics  18\(10 2002  S  K ramer  L De Raedt and C  Helma M olecular f eature mining in HIV data In Proceedings KDDÕ01  pages 136 143 2001  L  L hote F  Rioult and A  S oulet A v e rage number of frequent closed patterns in bernouilli and markovian databases In Proceedings IEEE ICDMÕ05  pages 713–716 2005  I  M itasiunaite a nd J.-F  B oulicaut Looking for monotonicity properties of a similarity constraint on sequences In Proceedings of ACM SACÕ06 Data Mining  pages 546–552 2006  I Mitasiunaite and J F  Boulicaut Introducing s oftness i nto inductive queries on string databases In Databases and Information Systems IV  pages 117–132 IOS Press 2007  I Mitasiunaite C Rigotti S Schicklin L  M e yniel J F  Boulicaut and O Gandrillon Extracting signature motifs from promoter sets of differentially expressed genes Technical report LIRIS CNRS UMR 5205 INSA Lyon France 2008 23 pages Submitted  G Ramesh W  M aniatty  a nd M J Zaki F easible itemset distributions in data mining theory and application In Proceedings ACM PODSÕ03  pages 284–295 2003  F  Zelezn  y Ef\036cient sampling in relational feature spaces In Proceedings ILPÕ05  volume 3625 of LNCS  pages 397 413 Springer 2005 
86 
86 


