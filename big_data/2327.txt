ARC-UI A Visualization Tool for Associative Classi\002ers David Chodos Osmar Za  021ane Department of Computing Science University of Alberta Canada chodos@cs.ualberta.ca zaiane@cs.ualberta.ca Abstract The classi\002cation of an unknown item based on a training data set is a key data mining task An important part of this process that is often overlooked is the user's comprehension of the classi\002er and the results it produces Associative classi\002ers begin to address this issue by using sets of simple rules to classify items However the size of these rule sets can be an obstacle to understandability In this work we present an interactive visualization system that allows the user to visualize various aspects of the classi\002er's decision process This system shows the rules that are relevant to the classi\002cation of an item the ways in which the item's characteristics relate to these rules and connections between the item and the classi\002er's training data set The system also contains a speculation component which allows the user to modify rules within the classi\002er and see the impact of these changes Thus this component allows the user to contribute domain expertise to the classi\002cation process consequently improving the accuracy of the classi\002er Keywords  visualization associative classi\002ers classi\002cation result analysis 1 Introduction The classi\002cation of items based on previously classi\002ed training data is an important area within data mining and has many real-world applications However one drawback to many classi\002cation techniques such as those based on neural networks or support vector machines SVM is that it is dif\002cult for the user to understand the reasoning behind a classi\002cation result or interpret the learned classi\002cation model This is particularly important in a context where an expert user could make use of domain knowledge to either con\002rm or correct a dubious classi\002cation result Rule-based classi\002ers address this shortcoming by using a collection of simple rules to perform classi\002cation Each rule is made up of one or more attribute/value pairs and a class and is thus quite easy to understand Most rule-based classi\002ers perform a heuristic search to discover classi\002cation rules often missing important ones Associative classi\002ers 12 on the other hand use association rule mining to perform an e xhausti v e search to 002nd classi\002cation rules However the set of rules generated by an associative classi\002er may contain hundreds of thousands of rules and thus it is dif\002cult for the user to ascertain which rules are relevant to the classi\002cation of an item and to what extent the relevant rules in\003uence a classi\002cation decision This paper presents ARC-UI a tool that allows the user to understand the reasoning behind an associative classi\002cation result via a graphical interactive interface Although other rule visualizers exist 6 ARC-UI is unique in that the user is able to modify the rules that are used and immediately see the results of this modi\002cation thus allowing the user to improve the accuracy of the classi\002er through the application of domain expertise This capability has the added bene\002t of increasing the user's con\002dence in the classi\002er 2 Related Work Research related to visualizing associative classi\002cation results can be divided into three areas visualizing classi\002cation results visualizing association rule sets and visual classi\002cation Each of these areas contributes important ideas and techniques to the aims of this research 2.1 Visualizing Classi\002cation Results One of the main goals of this research is to allow users to understand the result of classifying an item Poulin Szafron and others have investigated this issue of classi\002cation result analysis 13 Although their w ork focuses on additive rather than rule-based classi\002ers the concerns that are identi\002ed are equally applicable to this research An additive classi\002er uses a sum of terms to classify an item where each term represents the likelihood of an attribute belonging to a given class and the sum indicates the likelihood of the item belonging to that class Each term in the equation has a weight associated with it indicating its relevance to the classi\002cation decision Classi\002ers which fall into this category include Bayesian classi\002ers SVM-based classi\002ers and linear regression classi\002ers Their work is quite relevant in that they present a system which allows users to analyze classi\002cation results The 
12th International Conference Information Visualisation 1550-6037/08 $25.00 © 2008 IEEE DOI 10.1109/IV.2008.35 296 


authors propose 002ve desired areas for analysis  Classi\002cation Show the classi\002cation decision made by the classi\002er and show the alternatives  Decision evidence Show the evidence that was used by the classi\002er to arrive at its result  Decision speculation Show the effect of changing the item that is being classi\002ed  Ranks of evidence Show the relative importance of the evidence used by the classi\002er  Source of evidence Show the data that was used by the classi\002er to create the classi\002cation model The authors also present a system ExplainD which ful\002lls these requirements for additive classi\002ers For each of these classi\002ers the authors show how ExplainD implements the 002ve analysis areas described above This paper was followed by work by Szafron et al which applied the ideas of ExplainD to the problem of proteome analysis This system w as able to pro vide good prediction results in a variety of proteins and make every prediction transparent to its users through its explanatory features In their decision speculation component they only change the attribute value of the object being classi\002ed and do not edit any part of the learned model Although this system still relies on additive classi\002ers its success provides real-world evidence that classi\002cation result analysis is a useful capability and well worth pursuing 2.2 Visualizing Association Rule Sets A major drawback of associative classi\002ers is that they use very large rule sets to perform classi\002cation Thus understanding of the classi\002cation result is hampered by the need to make sense of sets of hundreds or thousands of rules This issue is particularly relevant to this research because of the decision evidence component which in an associative classi\002cation context relies on the visualization of the rules which are used in classifying an item Several researchers have addressed this issue in the context of association rule mining One method of dealing with large associative rule sets was developed recently by Tuzhilin and Adomavicius within the context of microarray data They developed post-processing techniques such as grouping and 002ltering which made the analysis of very large numbers of association rules a more manageable task As this w ork is focused more on processing methods than visualization it is not directly applicable to this research However the grouping techniques may be useful in implementing visualization techniques especially when considered along with the work of Couturier which is described below Another step in this direction was taken by Rahal et al  Their solution however focuses on querying this rule set in order to 002nd the subset of associations that are of interest in interacti v e mode 14 The idea of allo wing the user to interactively analyze association rules is similar in spirit to the visual classi\002cation work by Ankerst described in the following section However the need to iteratively re\002ne the rule set con\003icts with the need in the context of this research to quickly present the user with a summary of a large rule set Fukuda and Morimoto developed an interesting visualization technique for optimized two-dimensional rules Their work focuses on rules where the domains of the attributes form a planar region For these rules the authors represent the region as a pixel map where each pixel is assigned a colour and brightness level which convey information about that point in the plane This work is intriguing in its use of visual elements such as position brightness and colour to represent association rules However it is limited to rules of a particular form and thus is not practical for general-purpose analysis Couturier et al have also investigated visualizing large sets of association rules Rather than trying to represent each rule individually the authors propose clustering the rules and then using a 002sh-eye view FEV technique to view the details of a particular cluster while viewing coarse-grained representations of other clusters Leung et al  in developing a visualization system for frequent itemsets analyzed a couple of creative methods for visualizing association rules One of these A V iz uses a planar representation method similar to that developed by Fukuda and Morimoto The other by Yang uses a Bezier curve to represent a rule thus allowing multiple rules each represented by a Bezier curve to be shown on the same graph These techniques would not be effective for large rule sets but could be helpful for visualizing small subsets of association rules 2.3 Visual Classi\002cation Ankerst et al investigated the concept of having the user assist in the process of creating the classi\002er through visual inspection of the data and evaluation of the classi\002er as it is created This research is based on the idea that the user can contribute domain knowledge and pattern recognition abilities to the classi\002er creation process both of which are valuable contributions While the work focuses on decision tree-based classi\002ers the visualization techniques presented offer innovative ways of effectively presenting large quantities of data Furthermore the research emphasizes the importance of collaboration between the user and the classi\002cation system in creating an effective classi\002cation model which 
297 


Figure 1 Classi\002cation component Figure 2 Decision evidence component truncated echoes the goals of our research 3 System Features The initial development of the system was guided by the 002ve analysis components described by Poulin et al in their work on the ExplainD system Through testing and user feedback other requirements were identi\002ed which led to further development These components had already been implemented in a linear classi\002cation context but our focus on associative classi\002cation meant that some of the components had to be signi\002cantly revised The screenshots that follow were taken from system's use in the context of classifying mushrooms The wellknown mushroom data set downloaded from the UCI data repository contains over 8,000 mushrooms that have been classi\002ed as either poisionous or edible Each item in the data set contains twenty-two characteristics such as gills-attached colour and odor that help determine the item's classi\002cation The Weka data analysis tool  w as used to generate classi\002cation rules 1,275 in total which were then imported into the system Thus the screenshots show the system analyzing the classi\002cation of an unknown mushroom using these rules The classi\002cation component shows the result of classifying the item as well as all other possible classi\002cations as shown in Figure 1 This allows the user to compare the result with other possibilities and thus assess the likelihood of an alternative result The classi\002cation possibilities are listed in decreasing order of likelihood to facilitate comparison between the various possibilities The decision evidence component shows the rules that were used to classify an item This gives the user an initial understanding of the reasoning used by the classi\002er If the relevant rule set is small enough these rules are shown in a bar graph as in Figure 2 However if the rule set is too large for this to be feasible i.e more than a few dozen rules the bar graph is compressed in order to present the rule set characteristics in a meaningful visual manner Using this compressed format hundreds of rules may be viewed in a summarized form In either case the bar graph is colour-coded according to the class labels to facilitate comparison among the rules shown As well the component presents a summary of the rules in\003uencing each classi\002cation possibility This summary which is generated by sorting the relevant rules according to their classi\002cation labels includes the con\002dence value for each rules and the overall con\002dence for each class The overall con\002dence is calculated using either the best rule or a v erage rule method as speci\002ed by the user  The decision speculation component allows the user to modify the item being classi\002ed the method used to calculate the con\002dence for each class and the rules used in classi\002cation The user is shown a list of all relevant rules and can click on any rule to view a simple editing menu for that rule shown in Figure 3 This allows the user to deal with a large set of potentially relevant rules while providing 002ne-grained editing capabilities where they are needed After performing the desired modi\002cations the user is immediately shown the results of this modi\002cation This allows the user to experiment with the classi\002cation engine thus offering insight into the process behind item classi\002cation In selecting the con\002dence calculation method the user may choose between the best rule and a v erage rule methods When editing the rules used in classi\002cation the user can  edit the classi\002cation or con\002dence for a rule  add modify or delete clauses within a rule  remove a rule entirely causing it to be ignored  create a new rule Thus the user can draw on expert knowledge to edit the computationally-generated rule set Moreover the user is shown immediately whether this modi\002cation improved the accuracy of the classi\002er It should be noted that the speculative changes made by the user are not immediately made permanent However the user has the option of making the speculative changes permanent in the classi\002cation model once the results of these changes have been presented and accepted by the user Thus the tool offers the ability to interactively analyze and improve the classi\002er 
298 


Figure 3 Decision speculation component Figure 4 Ranks of evidence component The ranks of evidence component shows the relationships between characteristics association rules and classi\002cations This provides the user with further information about the way the classi\002er works independent of any particular item or rule set The system uses a colour-coded bar chart-based visualization scheme as shown in Figure 4 The length of each bar indicates the total number of times a characteristic appears in the rule set The colourcoded segments show the number of rules containing a given characteristic that result in a particular classi\002cation By moving the mouse over each segment the use is shown a more detailed summary of the rules that contain a given characteristic and result in the selected classi\002cation This approach is both visually appealing and scalable which is quite bene\002cial when dealing with very large rule sets In Figure 4 we see that the cap-shape characteristic appears in three rules two of which have the class poisonous and one with the class edible represented by green and red segments respectively By placing the mouse over the poisonous segment of the bar for the cap-shape characteristic we are shown more information about the rules containing the cap-shape characteristic where the class is poisonous Finally the source of evidence component allows the user to make connections between the item being classi\002ed and the entries in the data set that were used to generate the associative classi\002cation rules This may be useful when investigating a dubious classi\002cation result the user can check the data used in training the classi\002er to see if there were any anomalies in that original data Speci\002cally the component shows the entries in the training set in a colour-coded list using shades of red and green as shown in Figure 5 A green entry indicates that the entry has the same class as the item being analyzed while a red entry indicates that they have different classes The intensity of the colour indicates the proximity of the entry to the current item in terms of matching attribute-value pairs Finally the user is able to specify a variety of further analysis options to restrict the list of entries to those matching certain classi\002cation or characteristic criteria In particular when 002ltering by attribute the user is shown a chart of the distribution of that attribute among the possible classi\002cations divided by the possible attribute values Figure 6 shows the class breakdown for the possible values of the cap-shape attribute For example in 81 of the 535 items containing the cap-shape=convex attribute-value pair the class was edible The table also shows that there were no items which contained cap-shape=conical and thus this attribute-value pair had no impact on the classi\002cation model 4 Evaluation As described in the methodology section the system was evaluated by testing it with several real-world data sets and assessing the system's ability to analyze classi\002cation results deal with large sets of association rules and provide the user with interactive rule set editing capabilities Furthermore one of the goals of the system is to allow the user to use their expertise to interactively modify the rule set used by the classi\002er and thus improve the overall accuracy of the classi\002er Showing that this is indeed possible is another form of validation for the system as a whole To perform the 002rst part of the validation several data sets were obtained from the UCI machine learning repository mushroom car evaluation and nursery These data sets were then fed into Weka a data analysis program and the resulting rules were then pruned for relevance For a data set with n classes rules with a con\002dence value less than 1 n were pruned since they indicated less certainty than would be provided by random selection Finally the relevant rules along with the original data sets were loaded into our system The data sets had varying numbers of items and attributes and the rule sets were similarly varied thus providing a good test of the system's ca 
299 


Figure 5 Source of evidence component Figure 6 Source of evidence chart pabilities see Table 1 for details In order to test the utility of the interactive classi\002er modi\002cation component each data set was analyzed and iteratively improved using the decision speculation component In a scheme similar to the k-fold cross-validation method of classi\002er validation 90 of the items in each data set were used to train a classi\002er while the remaining 10 of the items were set aside for use with the ARCUI system For each of these items the ARC-UI system was used to classify the item and the result was compared to the correct class as recorded in the original data set The speculation component of the system was then used to modify the classi\002er and test the modi\002ed classi\002er with the aim of 002xing the errors made originally Finally after modi\002cations were made so that the incorrectly classi\002ed items were classi\002ed correctly all of the items were reclassi\002ed using the modi\002ed classi\002er to assess the overall impact of the modi\002cations and ensure that the changes had not adversely affected the accuracy of the classi\002er The results of classi\002cation using the initial and modi\002ed classi\002ers are presented in Table 2 As shown in this table the system was used to improve the accuracy of each classi\002er using the speculation and classi\002cation tools Furthermore it is worth noting that in each case the increased accuracy was caused by a very small change in the rule set This indicates that by identifying the appropriate rules to modify the user can improve the accuracy of the classi\002er with a minimal amount of time and effort 5 Future Work There are several promising areas for further work on this project Three of these are empirical validation rule set visualization and the improvement of the source of evidence component The validation for the system has thus far consisted of ensuring that the system met its functional requirements and offered users the ability to interactively improve the classi\002er they are working with However a key nonfunctional requirement of the system is that users from a broad range of backgrounds that is beyond computer science and data analysis should 002nd the system intuitive and easy to use To 002nd out whether this is in fact the case it would be bene\002cial to conduct a study to investigate the system's usability Participants could be drawn from a range of subject areas and thus the experiment could measure the system's applicability to speci\002c contexts as well as its general usability Effective rule set visualization becomes challenging when the size of the relevant rule set exceeds a few dozen rules Currently the system presents a compressed bar graph visualization if the rule set is larger than a certain threshold However it may be more effective to use a clustering approach similar to that proposed by Couturier et al  or a visualization scheme inspired by those presented by Ankerst et al  Thus se v eral visualization options could be implemented and then tested with users drawn from the participant pool described previously Currently the source of evidence helps the user identify anomalous entries in the original data set It would be even more bene\002cial if the user could after identifying such entries modify or even remove them entirely This along with an integrated classi\002cation rule generator would allow the user to interactively 002x errors in the training data The analysis techniques currently implemented are based on those developed for the linear classi\002er-oriented system by Poulin However there may be other analysis techniques which would be particularly useful for an associative classi\002cation context or other rule-based models Conclusions In this paper we present ARC-UI an interactive system for analyzing the results of an associative classi\002er Associative classi\002ers have the advantage of easily understandable classi\002cation rules but often use very large rule sets The system offers a variety of tools to help the user understand the classi\002cation engine's result including visualizations of relevant rule sets the relationships between characteristics rules and classes and connections between training data and the item being classi\002ed 
300 


Name Items Attrs All rules Pruned rules Car 1,728 6 1,057 28 Mushroom 8,124 22 1,275 71 Nursery 12,960 8 2,418 10 Table 1 Data set characteristics Car Mushroom Nursery Number of items 173 813 130 Rules modi\002ed 2 1 1 Accuracy before 80.9 93.5 70.4 Accuracy after 82.1 94.8 73.8 Table 2 Initial vs modi\002ed classi\002er accuracy Perhaps most important however is the speculation component which allows the user to modify the rules used to classify an item and then immediately see the results of classifying the item using the modi\002ed rule set Thus the user can contribute domain knowledge to the classi\002cation process improving the classi\002er's accuracy and increasing the user's con\002dence in the reasoning behind the classi\002er's decision-making process The system was validated by assessing its effectiveness with several data sets drawn from a variety of contexts and also by testing the utility of the speculation component described previously Thus it was shown that the system could be used to understand the results of classifying items in various real-world contexts and that the speculation tool could be used to improve the classi\002er's accuracy Acknowledgements This research has been funded by a grant from the Natural Sciences and Engineering Research Council of Canada References  R Agrawal T Imieli  nski and A Swami Mining association rules between sets of items in large databases SIGMOD Rec  22\(2 1993  M Ankerst M Ester and H Kriegel Towards an effective cooperation of the user and the computer for classi\002cation In KDD 2000  pages 179–188 2000  M Antonie and O Za  021ane Text document categorization by term association IEEE Data Mining ICDM  pages 19–26 2002  A Asuncion and D.J Newman UCI machine learning repository 2007  O Couturier T Hamrouni S Ben Yahia and E Mephu Nguifo A scalable association rule visualization towards displaying large amounts of knowledge In IV 07 Conf on Information Visualization  pages 657–663 2007  Usama Fayyad Georges G Grinstein and Andreas Wierse Information Visualization in Data Mining and Knowledge Discovery  Morgan Kaufmann 2002  T Fukuda Y Morimoto S Morishita and T Tokuyama Data mining with optimized twodimensional association rules ACM Trans Database Syst  26\(2 2001  J Han and M Kamber Data Mining Concepts and Techniques 2nd edition  Morgan Kaufmann 2006  TuBao Ho TrongDung Nguyen and DucDung Nguyen Visualization support for a user-centered kdd process In SIGKDD 02  pages 519–524 2002  C.K Leung and C Carmichael Frequent itemset visualization Technical report U of Manitoba 2007  W Li J Han and J Pei CMAR Accurate and ef\002cient classifcation based on multiple classassociation rules ICDM  pages 369–376 2001  B Liu W Hsu and Y Ma Integrating classi\002cation and association rule mining Proc of SIGKDD  pages 80–86 1998  B Poulin R Eisner D Szafron P Lu R Greiner D.S Wishart A Fyshe B Pearcy C MacDonnell and J Anvik Visual explanation of evidence in additive classi\002ers In Proc Conf on Innovative Applications of Arti\002cial Intelligence  pages 1–8 2006  I Rahal D Ren A Perera H Najadat W Perrizo R Rahhal and W Valdivia Incremental interactive mining of constrained association rules from biological annotation data with nominal features In SAC 05 ACM Symposium on Applied computing  2005  D Szafron P Lu R Greiner D Wishart Z Lu B Poulin R Eisner J Anvik and C MacDonnell Proteome analyst transparent high-throughput protein annotation Function localization and custom predictors Technical report U of Alberta 2003  A Tuzhilin and G Adomavicius Handling very large numbers of association rules in the analysis of microarray data In Proc ACM SIGKDD  2002  I.H Witten and E Frank Data Mining Practical machine learning tools and techniques  Morgan Kaufman 2nd edition edition 2005 
301 


Case 2:When CFI X become frequent in W/d-block we check for it’s closure If it is closed in W/d-block we retain it otherwise we delete it from LDIU tree for W we perform deletion operation step by step i.e updating LDIU tree for each transaction in d-block similar to  But for closure checking of a closed itemset we adopt a different method In the following part of this section we use the notations as follows  t An outgoing transaction in Window W and belonging to d-block  W/t Transactions in Window W excluding t After we perform deletion operation w.r.t t W:=W/t We perform the above operation until W=W/d-block  the y state t hat to determine if a c losed itemset in t is closed or not in W/t they 036nd all the proper supersets of that itemset in W/t that are closed in W/t They perform intersection of all those supersets If intersection is equal to itemset itself then they declare itemset to be closed in W/t They perform closure checking for itemsets based on precedence order of length in an outgoing transaction i.e closure checking for itemset of length i will be performed 036rst than for itemset of length j if i  j The reason for this precedence will be known in Lemma 7 But the above method requires searching for all proper supersets of that itemset in W/t that are closed in W/t So we propose the following lemma which advocates the determination of closedness of an itemset by searching only one proper superset of itemset in W/t that is closed in W/t Lemma 7 If Y is a closed itemset in W and Y is present in t then scan the LDIU tree for the 036rst proper superset of Y by traversing depth-\036rst from rightmost point of the tree If the 036rst proper superset obtained from LDIU tree has support same as that of Y in W/t then Y is not closed If the 036rst proper superset has support less than that of Y in W/t or if there is no proper superset present then Y is closed Proof If the 036rst proper superset obtained from LDIU tree has support same as that of Y in W/t then by closure de\036nition Y is not closed If there is no proper superset present then by closure de\036nition Y is closed Suppose the 036rst proper superset has support less than that of Y in W/t and there exist another proper superset of Y say Z in LDIU tree whose support is same as Y Then the 036rst proper superset is not closed since there will be presence of Z-Y items wherever 036rst proper superset is present in W/t But 036rst proper superset is closed in W/t by de\036nition of lemma 7 Therefore Z does not exist Hence the proof Transaction ID Items in transactions 1 abcf Table 5 Transaction 1 represent d-block Transaction ID Items in transactions 2 abcg 3 bcf 4 abcdg 5 bc Table 6 Transactions 2-5 represent W/dblock Since closure checking of itemset needs to obtain it’s proper superset the support or closedness of proper superset should be known prior to the closure checking of the given itemset This is the reason for precedence order of length for closure checking of itemsets To illustrate the above lemma consider d-block as shown in table 5 W/d-block in table 6 and the LDIU tree shown in 036gure 6 Taking S:=1 let us consider itemset a,b,c present in table 5 which is a CFI in W Now to check whether it is closed in W/d-block we 036nd 036rst proper superset of a,b,c i.e a,b,c,g by scanning from rightmost point of LDIU tree Since support of a,b,c is same as that of a,b,c,g i.e equal to 2 in W/d-block we conclude a,b,c is not closed in W/dblock and delete a,b,c in LDIU tree let us consider itemset b,c,f present in table 5 which is a CFI in W Now to check whether it is closed in W/d-block we 036nd 036rst proper superset of b,c,f by scanning from rightmost point of LDIU tree Since there is no proper superset of b,c,f in LDIU tree we conclude it is closed and just decrease it’s support by 1 let us consider itemset b,c present in table 5 which is a CFI in W Now to check whether it is closed in W/d-block we 036nd 036rst proper superset of b,c i.e b,c,f by scanning bc bcf abc abcdg abcf abcg 5 2 1 3 2 1 Figure 6 LDIU tree for d-block 007 W/d-block of table 5 and table 6 
522 
522 


from rightmost point of LDIU tree Since support of b,c,f is 1 which is less than support of b,c i.e 4 in W/d-block we conclude b,c is closed in W/d-block There cannot exist any proper superset of b,c in LDIU tree with support equal to 4 because if it exists then b,c,f will not be a closed itemset in LDIU tree We do not need to update\(increase the support of CFI’s in W/d-block w.r.t d 002 block because during pattern-growth on d 002 block  while intersecting the closures of an itemset X we check whether the intersection is same as closure of X in W/d-block If it is same we increase the support of CFI of X in W/d-block by the support of X in d 002 block So If CFI’s in W/d-block are present in d 002 block then they are updated during pattern-growth on d 002 block otherwise we do not need to update them We integrate all the optimization techniques mentioned above in to Stream-Close Algorithm development which will be discussed in next subsection 3.4 Stream-Close DESIGN AND IMPLEMENTATION In this section we formulate the Stream-Close algorithm which mines new CFI by FP-tree method Input W d LDIUW\(LDIU tree for W LDIUdelta\(LDIU tree for d 002 block d 002 block S:=1 IS//global parameters Output Set of CFI 002 in W 002 global parameters BEGIN 1 CFI 002  002  LDIU-delta 002  2 For every CFI in LDIUW update the support w.r.t d-block;//Applying optimization 7 so that resulting CFI’s support will be in accordance with W/d-block and CFI’s in W which become nonclosed in W/d-block are removed 3 Scan the items in d 002 block according to their support in W 002 w.r.t minsup S and create FP tree F on scanned d 002 block with support  1in d 002 block;//Since infrequent items in W 002 present in d 002 block don’t contribute to Set of CFI 002 in W 002  4:IS  002 global stack to keep itemsets 5 Stream-Close:Addition F Optimizations 1-6 6 CFI 002 CFI 002 007 setofallCFI’sinLDIUW END procedure Stream-Close:Addition F 1 For each item i in F.headtable push item into IS 2 Fetch the closure X of IS from LDIU-delta If X is NULL extract X by look ahead approach from IS’s conditional FP-tree\(w.r.t minimum support:=support of IS and insert X in to LDIU-delta.//Applying optimization 2 3 Fetch the closure Y of IS from LDIUW 3.1:if Y is NULL check for support of X 3.1.1:If support of X is 002 S then CFI 002 CFI 002 007 X and dynamically reorder the todo-set item’s of IS present in X and prune them later and Go to step 6 Applying optimization 6 and 1 3.1.2:If support of X is  S then pop item from IS and continue 4 If sum of support of X and Y  S then pop item from IS and continue 5 If sum of support of X and Y 002 S then perform Z:=Y 005 X 5.1:If Z contains done-set items of IS,then pop item from IS and continue.//Applying optimization 5 5.2:If Z 010 Y then CFI 002 CFI 002 007 Z and dynamically reorder the todo-set item’s of IS present in Z and prune them later and Go to step 6 Applying optimization 3 and 4 5.3:If Z 005 Y=Y and if Y’s support  S then CFI 002 CFI 002 007 Y update the support of Y by support of IS and dynamically reorder the todo-set item’s of IS present in Z and prune them later and Go to step 6 5.4:If Z 005 Y=Y and if Y’s support 002 S then update the support of Y by support of IS and dynamically reorder the todo-set item’s of IS present in Z and prune them later 6:construct IS’s conditional FP-tree F new w.r.t minimum support:=1 Stream-Close F new  pop item from IS Stream-Close algorithm illustrates how to 036nd CFI 002 in W 002 when we slide W by width d First we perform deletion operation w.r.t d-block and 036nd the set of CFI 002 in W/dblock as illustrated in line 2 of BEGIN block As shown in lines 3-5 of BEGIN block we perform insertion operation w.r.t d 002 block and scan the items in d 002 block according to their support in W 002 w.r.t minsup S and create FP tree F on scanned d 002 block to perform FP-growth routine IS is a global stack to keep track of itemsets generated during FPgrowth routine In procedure Stream-Close:Addition we perform FPgrowth routine to check for new CFI’s generated due to addition of d 002 block For each itemset generated during FPgrowth routine we extract the closure of IS in d 002 block say X from LDIU-delta If it is not present in LDIU-delta we extract from IS’s conditional fp-tree by merging items of same support as that of IS to form IS’s closure\(line 2 Next we fetch the closure of IS in W/d-block say Y from LDIUW tree maintained for W/d-block\(line 3 If Y is NULL we check for support of X and if support of X is 002 Sweadd X as a new CFI to the set CFI 002 and dynamically reorder the todo-set item’s of IS present in X and prune them later by 
523 
523 


applying optimization 2\(line 3.1 and 3.1.1 If Y is NULL and support of X is  S then any itemset which is a superset of IS has support  Sin W 002  therefore pop item from IS and continue to examine next itemset\(line 3.1.2 Similar is the case for line 4 If sum of support of X and Y\(i.e support of IS in W 002  is 002 S then we need to examine if their intersection say Z is a new CFI\(line 5 If Z contains done-set items then it should have been already examined earlier according to optimization 5 so all intersections of closures of supersets of IS contains done-set items Therefore pop item from IS and continue\(line 5.1 If Z is a subset of Y then Z is nonclosed in W/d-block but is closed in W 002 due to addition of d 002 block therefore add it as a new CFI to set CFI 002 and prune common todo-set items by dynamic reordering\(line 5.2 Suppose if Z  Y and support of Y is  S in W/d-block then Y\(already closed becomes frequent in W 002 due to addition of d 002 block therefore add it as a new CFI to set CFI 002 and prune common todo-set items by dynamic reordering\(line 5.3 If support of Y is 002 S in W/d-block then it is already present in LDIUW tree therefore just update it’s support by support of IS in d 002 block and prune common todo-set items by dynamic reordering\(line 5.4 Line 6 constructs IS’s conditional FP-tree F new w.r.t minimum support:=1 to explore further itemsets based on dynamic reordering and recursively calls the procedure Stream-Close on F new  Finally in line 6 of BEGIN block it merges CFI’s of CFI 002 and LDIUW tree to output the set of CFI 002 in W 002  Lemma 8 An itemset is a CFI in W 002 iff Stream-Close says Proof An itemset D is found as a CFI by Stream-Close when 1 D is frequent 2 there is no item which appears in every transaction in D-conditional database and 3 D is not a proper subset of any CFI already found To assert correctness of the lemma we show that there is no frequent closed itemset E which can be found later such that D is a subset of E Suppose we can 036nd such an itemset E then ED 011  0 must happen in every transaction of the D-conditional database This leads to a con\037ict with the fact that there is no item appearing in every transaction in the D-conditional database Thus we have the lemma The correctness of the algorithm has been reasoned stepby-step It generates the complete set of CFI’s in W 002 as shown in above lemmas 4 Empirical results We compare our algorithm with Moment w hich is the state-of-the-art algorithm to mine frequent closed item0 0.01 0.02 0.03 0.04 0.05 0.5 3 5.5 8 10.5 13 15.5 18 20.5  The Minimum Support Running time in Seconds   Moment Stream\025Close  Figure 7 Performance comparisons of Moment and Stream-close 0 0.01 0.02 0.03 0.04 0.05 0.4 0.9 1.4 1.9 2.4 2.9  The Minimum Support Memory usage in number of itemsets   Moment Stream\025Close  Figure 8 Memory usage results of Moment and Stream-close The order of number of itemsets is 10 7  sets in data streams For performance evaluation the synthetic dataset T10.I6.D100K is used The dataset is generated by the same procedure as described in where t he three numbers o f each dataset denote the average transaction size T the average maximal potential frequent itemset size I and the total number of transactions D respectively In our experiments the transactions of T10.I6.D100K dataset are looked up incrementally in blocks in sequence to simulate the environment of an online data stream In our experiments we keep sliding width parameter d  10 for Stream-Close window width:=1,00,000 for both Stream-Close and Moment and perform experiments over 100 sliding windows for Moment and 10 sliding windows for Stream-Close\(since d’:=10 and take the average processing time for every 10 transactions processed under different minimum supports for T10.I6.D100K data set as shown in 036gure 7 We can see from 036gure 7 that Stream-Close runs much faster than Moment when the support threshold is relatively low because the number of boundary nodes stored in the data structure of Moment increases when the support threshold decreases as the number of nodes to be processed 
524 
524 


and checked for node property increase execution time is increased When the support threshold is relatively high these two algorithms have comparable running time Moment runs a little bit faster than Stream-Close as the threshold increases This is because as the threshold is increased the number of the boundary nodes in Moment decreases while Stream-Close processes the same number of closed itemsets independent of support information This is advantageous when users have different speci\036ed support thresholds in their online queries Regarding memory usage Stream-Close maintains only CFI’s in LDIU-tree but whereas for Moment when the user de\036ned support threshold is small the number of nodes it maintains in the memory increases dramatically which consists of all the infrequent gateway nodes unpromising gateway nodes intermediate nodes and closed nodes as shown in 036gure 8 We performed all our experiments on 2 GB RAM 1.8 GHz AMD machine Our performance study shows that Stream-Close is very ef\036cient and the optimization techniques proposed in this paper are effective in improving the algorithm ef\036ciency 5 Conclusions In this paper we investigated the issues for cumulative mining of CFI’s in high speed data streams and addressed the inef\036ciency problem of mining the new window from scratch,sliding window by one transaction and also the problem associated with closedness checking of candidate itemsets in newly arrived block We proposed an algorithm Stream-Close by exploring several novel techniques to increase ef\036ciency and scalability It is a promising algorithm to mine CFI’s over high speed data streams In the future we plan to explore how to mine compressed top-k itemsets in datastreams and also how to adaptively vary sliding width according to speed of the data streams Also we plan to perform experiments on different datasets 6 Acknowledgements We thank Dr Yun Chi at the University of California for providing us the Moment algorithm source code References  J  Pei J  Han and R Mao Closet An e f 036cient algorithm for mining frequent closed itemsets ACM SIGMOD International Workshop on Data Mining and Knowledge Discovery May 2000  J  Pei J  Han and J W ang Closet Searching for the best strategies for mining frequent closed itemsets ACM SIGKDD Int’l Conf on Knowledge Discovery and Data Mining August 2003  M  J  Z aki and C J Hsiao Charm An ef 036cient algorithm for closed itemsets mining SIAM Int’l Conf on Data Mining April 2002  C  L ucchese S Orlando and R Pere go F a st and memory ef\036cient mining of frequent closed itemsets Knowledge and Data Engineering IEEE Transactions January 2006  J  H  Chang W  S Lee A Zhou Finding recent frequent itemsets adaptively over online data streams ACM SIGKDD Int’l Conf on Knowledge Discovery and Data Mining August 2003  S H L i S Lee and M Shan An ef 036cient algorithm for mining frequent itemsets over the entire history of data streams Int’l Workshop on Knowledge Discovery in Data Streams Sept 2004  G S  M anku R Motw ani Approximate frequenc y counts over data streams Int’l Conf on Very Large Databases 2002  J  H  Chang W  S Lee A s liding w indo w m ethod for 036nding recently frequent itemsets over online data streams Journal of Information Science and Engineering July 2004  C  Giannella J  Han J Pei X Y an P  S Y u  Mining frequent patterns in data streams at multiple time granularities Data Mining Next Generation Challenges and Future Directions AAAI/MIT 2003  C Lin D Chiu Y  W u A L P  Chen Mining frequent itemsets from data streams with a time-sensitive sliding window SIAM Int’l Conf on Data Mining April 2005  Y  Chi H W ang  P  S  Y u  R R Muntz Moment Maintaining closed frequent itemsets over a stream sliding window Int’l Conf on Data Mining November 2004  Nan J iang Le Gruenw ald CFI-Stream M ining Closed Frequent Itemsets in Data Streams KDD August 2006  Dong Xin Jia wei Han Xifeng Y a n and Hong Cheng On Compressing Frequent Patterns Knowledge and Data Engineering Special issue on Intelligent Data Mining 60\(1 5-29 2007  R Agra w a l R Srikant F ast a lgorithms for m ining association rules Int’l Conf on Very Large Databases September 1994  P  V a ltchef R  M issaoui and R Godin A F ramework for Incremental Generation of Frequent Closed ItemSets Proceedings of the 2nd SIAM Workshop on Data Mining Arlington VA April 2002  A v ailable a t h ttp://cl w eb csa.iisc.ernet.in/srirang a 
525 
525 


