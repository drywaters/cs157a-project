A Novel Approach to Find the Satisfaction Pattern of Customers in Hotel Management Lixia Du and Xu Xu and Yan Cao and Jiying Li Abstract  Nowadays many studies of the discovery of needs and feelings of the hotel customers are not only around before-booking period but also do not consider the privacy of customers completely While the best period of studies of this knowledge are after the booking took place there are two major problems for its unpopular one is personal privacy the other is not having a scientiìc and valuable approach In this paper we propose a novel approach to deal with the above existing problems We employ intuitionistic fuzzy set  cuts and Apriori algorithm to discovery the knowledge of needs and feelings of customers under an anonymous way The approach is 
expatiated under different  by an example And The yielded pattern and association rules have taken to the cooperative hotel more effects than before So the approach is provable and valuable I I NTRODUCTION D UE to the high costs that are typically involved with investments in the hotel industry a lot of stud    v e been made in these years to re v eal some useful information about customersêneeds and feelings But they are around before-booking period However they have many drawbacks for example when the customer neither is familiar with the decisions nor with the hotel chain Avoidance of some fault they will chose not to live in this hotel Even some of these studies nd some useful pattern about customers They often leak personal private data unin 
tentionally The best period to nd the interesting pattern of customers in hotel is after the booking took  b u t the discovery of needs and feelings of the customers after the booking took place has not been a major research issue so far There are two main problems for its unpopularity One is the personal data privacy to be concerned the other is not having a scientiìc and valuable approach to be used In this paper we propose a novel approach.We employ intuitionistic fuzzy set  cuts and Apriori algorithm under an anonymous way to settle the above problems and achieve the following purposes  The discovery of needs and feelings of the customers after the booking took place under an anonymous way  Avoiding the signals that sent by customers are noise and confusing by classiìcation 
 Pattern of customersêneeds and feelings means a strong competitive advantage for hotel management Lixia Du and Yan Cao and Jiying Li are with College of Electronic and Information Engineering Lanzhou Jiaotong University 88 west Anning Road Anning Lanzhou Xu Xu is with School of Economics and Management Tongji University 1239 Siping Road Yangpu Shanghai.Lixia Du and Xu Xu are coauthor correspondent email:dlx1228@mail.lzjtu.cn xuxusuccess5616@yahoo.com  The customers who belong to the different categories their choice and preferring are not the same The remainder of this paper is organized as follows Section II describes the prepared work to this approach and technique we employ Section III explicates the whole steps and approach by an example And reports the experiment results Section IV concludes our work and discusses future research II P 
REPARED W ORK A Intuitionistic Fuzzy Set Intuitionistic fuzzy set theory\(IFS for short is an e x tension of fuzzy set theory that deìes the claim that from the fact that an element x belongs to a given degree  A  x  to a fuzzy set A,naturally follows that x should not belong to A to the extent 1 A  x   an assertion implicit in the concept of a fuzzy set.On the contrary an IFS assigns to each element x of the universe both a degree of membership  A  x  and one of non-membership 
v A  x  such that  A  x  v A  x   1 1 thus relaxing the enforced duality  A  x   v A  x  from fuzzy set theory Obivously,when  A  x  v A  x  for all elements of universe the traditional fuzzy set concept is recovered B  cuts and Attributes 
We want to exhibit an element x  X that typically belongs to a fuzzy set A we may demand its membership value to be greater than some threshold    The ordinary set of each elements is the  cut A  of A A    x  X  A  x     2 The above equation is employed in this paper one also deìnes the strong  cut A    x  X  A  x 
   3 The membership function of a fuzzy set can be expressed in terms of the characteristic function of its  cuts according to the formula u A     1 if f x  A   0 otherwise 4 Customers proìling provides a basis for marketers and decision-makers to communicate with existing customers in order to offer them better services and retaining them According  and the characteristic of the customers 11 978-1-4244-1819-0/08/$25.00 c  2008 IEEE 


and the real condition of hotel,we construct the database using the attributes,which are shown in the following table LAN is Local Area Network for short TABLE I A TTRIBUTES  Attribute Attribute Internet service\(IS Wireless LAN WL Airport shuttle\(AS Fitness center\(FC Values for money VM Staff service SS Clean\(C Restaurant\(R We use the satisfaction and dissatisfaction degree to express this attributes separately Satisfaction and dissatisfaction are a multi-faceted concept It can be full or partial And it depends on the customers or depends on the purpose,etc Since satisfaction and dissatisfaction may be a matter of degree we use a number i between 0 and 1 to express the degree In our approach,0 corresponds to total absence of satisfaction.Roughly speaking the customers are completely dissatisìed Satisfaction and dissatisfaction degree do not have to sum up to 1 Omitting the restriction would result in allowing inconsistency As a result these are represented by an IFS.Here,we use IFS to reîect customersêneeds and feelings objectively,because customers may not experience all services the hotel provides So customers have no reason to be satisìed but also no reason to be dissatisìed C Data Mining and Privacy Preserving Data mining combines the statistic and artiìcial intelligence to nd out the rules that are contained in the data,letters,and gures and soon by sorting and analyz are man y methods of data mining including classiìcation,estimation,prediction,clustering,and afìnity grouping Among these,afìnity grouping can discover the high frequency pattern and discover which things appear frequently and simultaneously The central idea of data mining for customer relationship management is that data from the past that contains information that will be useful in the future It works because customer behaviors captured in corporate data are not random but reîect the differing needs preferences propensities and treatments of customers The goal of data mining is to nd patterns in historical data that shed light on those needs preferences and propensities The task is made difìcult by the fact that the patterns are not always strong and the signals sent by customers are noisy and Data mining techniques are used to nd patterns in large databases of information But sometimes these patterns can reveal sensitive information about the data holder or individuals whose information are the subject of the patterns The notion of privacy-preserving data mining is to identify and disallow such revelations as evident in the kinds of patterns learned using traditional data mining techniques In the paper we nd the interesting pattern under an anonymous way in order to protect the customers privacy effectively D Steps The steps of this approach  Divide he customers into different groups according to the different types of customers  Construct the database  Suppose  cuts to calculate the fuzzy degree of every attribute  Utilize  cuts to get the item sets,and calculate the appearing times of every item  Employ Apriori algorithm to nd the relative pattern and form the association rules III A N E XAMPLE In real application the customers are classiìed into six separate categories they are solo travelers young couples mature couples families with young children families with older children Groups Here we just take 10 records of young couples an example to explicate the whole approach and procedure and nd the satisfaction pattern under different   A Approach Explanation Step 1 We list the records according to the above.All the records are shown in below  S denotes the satisfaction degree,D denotes the dissatisfaction degree TABLE II R ECORDS IS WL AS FC VM SS C R S DS DS DS DS DS DS DS D 0.7 0.2 0.3 0.7 0.0 1.0 0.5 0.3 0.5 0.2 0.6 0.1 0.5 0.3 0.5 0.2 0.6 0.1 0.0 0.8 1.0 0.0 0.9 0.1 0.4 0.6 0.5 0.2 0.5 0.5 0.5 0.5 0.3 0.4 0.6 0.4 0.6 0.4 0.8 0.1 0.8 0.1 0.6 0.3 0.4 0.5 0.6 0.3 0.6 0.2 0.5 0.3 0.5 0.5 0.3 0.4 0.6 0.3 0.5 0.2 0.7 0.3 0.8 0.1 0.6 0.3 0.5 0.4 0.5 0.1 0.5 0.2 0.5 0.1 0.6 0.4 0.5 0.4 0.6 0.2 0.4 0.6 0.0 1.0 1.0 0.0 0.6 0.3 0.5 0.4 0.6 0.4 0.6 0.4 0.8 0.1 0.3 0.7 0.5 0.2 0.5 0.2 0.5 0.4 0.5 0.5 0.7 0.2 0.5 0.1 0.5 0.3 0.7 0.2 0.4 0.6 0.3 0.6 0.6 0.4 0.7 0.2 0.6 0.3 0.5 0.4 0.8 0.1 0.5 0.5 0.6 0.3 0.8 0.2 1.0 0.0 0.3 0.6 0.5 0.2 0.7 0.3 0.6 0.4 0.9 0.1 0.3 0.5 0.4 0.6 0.8 0.2 0.6 0.3 0.7 0.3 0.5 0.2 0.5 0.3 Step 2 Here we use  cuts to transform the above table,and here we suppose  0.5 0.8 separately.In the following tables A 1 denotes the satisfaction of IS A 2 denotes the dissatisfaction of IS and so on Step 3 Choosing the satisfaction attribute whose value is 1,then getting the transaction tables Step 4 Calculate the appearing times of satisfaction item when  0.5 0.8 And the appearing times of every item are shown later Step 5 We use Apriori algorithm to nd the frequent item sets Let the minimum support count be 8 It is obviously to nd the frequent item set existing when  0.5 There is no large item set when  0.8 The resulting set is denoted L,thus,we have L  D 1 F 1  D 1 H 1  F 1 H 1  D 1 F 1 H 1   and the minimum conìdence threshold is,say 95   Then 12 2008 IEEE International Conference on Fuzzy Systems FUZZ 2008 


the association rules are shown in the last table So we can get the following pattern from the above example  If the customers satisfy the Fitness center,then they will satisfy the Staff service  If the customers satisfy the Fitness center,then they will satisfy the Restaurant  If the customers satisfy the Restaurant,then they will satisfy the Staff service  If the customers satisfy the Fitness center and Restaurant,then they will satisfy the Staff service  If the customers satisfy the Fitness center and Staff service,then they will satisfy the Restaurant  If the customers satisfy the Fitness center,then they will satisfy the Staff service and Restaurant TABLE III T RANSFORMED TABLE UNDER  0.5  IS WL AS FC S A 1  D A 2  B 1  D B 2  C 1  D C 2  D 1  D D 2  1 00 10 11 0 1 00 11 01 0 0 01 01 01 0 1 01 00 00 0 1 00 01 01 0 0 10 11 01 0 0 11 01 00 0 1 00 10 11 0 0 01 01 01 0 1 00 00 11 0 VM SS C R S E 1  D E 2  F 1  D F 2  G 1  D G 2  H 1  D H 2  1 01 01 00 0 0 11 00 00 0 1 01 00 01 0 1 01 01 01 0 1 01 00 01 0 0 01 01 00 0 0 01 00 01 0 1 01 00 01 0 0 11 01 01 0 1 01 00 00 0 TABLE IV T RANSFORMED TABLE UNDER  0.8 IS WL AS FC S A 1  D A 2  B 1  D B 2  C 1  D C 2  D 1  D D 2  0 00 00 10 0 0 00 11 01 0 0 00 00 01 0 0 00 00 00 0 0 00 00 00 0 0 10 11 00 0 0 10 00 00 0 0 00 10 00 0 0 00 01 01 0 1 00 00 11 0 VM SS C R S E 1  D E 2  F 1  D F 2  G 1  D G 2  H 1  D H 2  0 00 01 00 0 0 00 00 00 0 1 00 00 00 0 0 00 00 01 0 0 00 00 00 0 0 00 00 01 0 0 00 00 00 0 0 00 00 01 0 0 00 00 00 0 0 00 00 00 0 TABLE V T RANSACTION TABLE UNDER  0.5 TID Items T 1 A 1 D 1 E 1 F 1 G 1 H 1 T 2 A 1 C 1 D 1 F 1 T 3 B 1 C 1 D 1 E 1 F 1 H 1 T 4 A 1 B 1 E 1 F 1 G 1 H 1 T 5 A 1 C 1 D 1 E 1 F 1 H 1 T 6 C 1 D 1 F 1 G 1 H 1 T 7 B 1 C 1 F 1 G 1 H 1 T 8 A 1 D 1 E 1 F 1 H 1 T 9 B 1 C 1 D 1 F 1 G 1 H 1 T 1 0 A 1 D 1 E 1 F 1 G 1 H 1 TABLE VI T RANSACTION TABLE UNDER  0.8 TID Items T 1 G 1 T 2 C 1 D 1 T 3 E 1 T 4 H 1 T 5 C 1 H 1 T 6 H 1 T 7 C 1 D 1 TABLE VII T HE APPEARING TIMES OF EVERY ITEM UNDER  0.5 Item Times Item Times Item Times Item Times A 1 6 B 1 4 C 1 6 D 1 8 E 1 6 F 1 10 G 1 6 H 1 9 2008 IEEE International Conference on Fuzzy Systems FUZZ 2008 13 


TABLE VIII T HE APPEARING TIMES OF EVERY ITEM UNDER  0.8  Item Times Item Times Item Times C 1 3 D 1 2 E 1 1 H 1 3 G 1 1 TABLE IX A SSOCIATION RULES  Association rules Conìdence D 1  F 1 100  F 1  D 1 80  D 1  H 1 100  H 1  D 1 89  H 1  F 1 100  F 1  H 1 90  D 1  H 1  F 1 100  D 1  F 1  H 1 100  H 1  F 1  D 1 89  F 1  D 1  H 1 80  H 1  D 1  F 1 89  D 1  F 1  H 1 100  B Experiments We have cooperated with a hotel to test our approach since 2006 and yielded some interesting and useful pattern and association rules From the experiment results even though to different categories under the same   the yielded association rules and pattern are different So the valuable information have important roles to the decision-makers of hotel After that these valuable pattern and yielded rules of customers have taken a strong competitive advantage for the hotel management IV C ONCLUSIONS We study the interesting pattern of customers in one hotel by proposing a novel approach,we employ IFS  cuts,and Apriori algorithm to discovery the knowledge of needs and feelings of customers after the booking took place under an anonymous way.Compared to    approach has successfully protected the customersêpersonal data privacy and achieved some gratifying results from the experiments.Certainly,the approach is not limited in hotel,we will study further in the long run to enlarge its application elds So the study is provable and valuable R EFERENCES  D.Dubois H.Prade,On the Representation,Measurement,and Disco v ery of Fuzzy Rules IEEE Transaction on Fuzzy Systems vol.2 pp.250262,2000  Barsk y J.D,Labagh,R.,A Strate gy for Customer Satisf action,The Cornell Hotel and Restaurant Administration Quarterly,vol.2 pp.32-40,1992  Gundersen,M.G.,Heide,M Oisson,U.H.,Hotel Guest Satisf action among Business Travellers,The Cornell Hotel and Restaurant Administration Quarterly vol.4 pp.72-81 1996  Dube,L Renghan,L.M.,Ho w Hotel Attrib utes Deli v e r the promised Beneìts,The Cornell Hotel and Restaurant Administration Quarterly,vol.1,pp.78-88,1999  Callan,R.J,Hotel classiìcation and grading schemes,a paradigm of utilisation and user characteristics,International Journal of Hospitality Mangement,vol 14,pp.271-284 1995  Callan,R,J,Attrib utional Analysis of CustomersêHotel Selection Criteria by U.K.Grading Scheme Categories Journal of Travel Research,vol.3,pp.20-34,1998  Callan,R,J,T ur geon,N.,K e y F actors in Guest Satisf action,The Cornell Hotel and Restaurant Administration Quarterly vol.2,pp.45-51,1998  Atanasso v K.T Intuitionistic Fuzzy sets,Fuzzy Sets and Systems,vol.20,pp.87-96,1986  Dider Dubois,Henri Prade,Fuzzy sets and System Theory and Applications,Academic Press Inc.,1985  L.A.Zadeh Fuzzy Sets Information and Control,1965  D.Dubois,H.Prade,What are Fuzzy rules and Ho w t o Use them Fuzzy Sets and Systems,vol.2 pp.168-186,1996  Jia wei Han Micheline Kamber Data Mining Concepts and T echniques  Morgan Kaufmann Publishers 2001  Berry Data Mining T echniques:for Mark eting,Sales and Customer Support John Wiley and Sons Inc 1997  Qingzhan Chen,Utilize Fuzzy Data Mining to Find the T r a v el P atten of Browsers IEEE the Fifth International Conference on Computer and Information Technology 2005  H.-J.Zimmermann Fuzzy Set Theory and its Applications  Kluwer Nijhoff Publishing 1985  M.-S.Chen,J.Han,P S.Y u Data Mining:An Ov ervie w from a Database Perspective IEEE Transactions on Knowledge and Data Engineering,vol.15,no.8,pp.866-880,1996  Ciobanu,Y A Data Mining Algorithm for T ransaction Data with Quantitative Values Intelligence Data Analysis,vol.3,no 5,pp.363-376,2003  Agra w al,R.Srikant,F ast Algorithm for Mining Association Rules In the conference on very large databases,vol.3,pp.487-499,1994  Franle y  W J.Piatetsk y-Shaprio Kno wledge Disco v ery in Databases:an Overview In the AAAI Workshop on Knowledge Discovery in Databases vol.3 pp.1-27 1993  Xu Xu,Zhongfu Zhang,Zhihong Feng,Applications of the Ev aluation of the Computer System Performance and Business Strategy Based on Fuzzy Mathematics,International Journal of Applied Mathematics,vol.9,pp.483-487 2006 14 2008 IEEE International Conference on Fuzzy Systems FUZZ 2008 


effective use into phase of constitution of the archaeology knowledge. The second level of validation will consist in automatically integrating the information extracted by the software chain we developed, then to appraise the quality of the results so obtained CONCLUSION AND FUTURE WORK  Knowledge and information extraction from archaeological texts requires the application of a complete process of text mining. Our text mining process is composed of the following steps: Standardization, PoS tagging, terminology extraction concept recognition, information extraction and knowledge discovery. The quality of each step depends strongly on the preceding steps The processing of specialized texts requires the cooperation of field experts and thus the use of convivial software allowing an effective work. The use of inductive methods is an important aspect in our text mining process. Indeed, for each step of the process, a specific inductive method is applied Within the framework of the e-archaeology project, we will continue to adapt and to improve the treatments carried out in each step For the standardization, we will develop an interactive software which would make it possible to the expert to apply standardization algorithms, to visualize their effects, and to insert easily correction rules For PoS tagging, the first task will be the acquisition of a specialized lexicon starting from the corpus and external resources. Then, the specialized rules will be acquired by using our tagging software ETIQ In our system, the concept instances may be terms or syntactic relationships. The extraction of syntactic relationships will be improved by using our PoS tagger results as input of the syntactic parser The process of concept categorization is a important subtask in information extraction. We will continue to improve our inductive, convivial and cooperative method to effectively include the expert in this process The validation of the data processing system can be done by the effective use of the information extracted from texts R EFERENCES  1  M. A. Hearst, ìUntangling Text Data Miningî,  37 th Annual Meeting of the Association for Computational Linguistics, University of Maryland June 20-26, 1999, pp. 3-10 2  A. Amrani, J. AzÈ, T. Heitz, Y. Kodratoff, and M. Roche, ìFrom the texts to the concepts they contain: a chain of linguistic treatmentsî, Text REtrieval Conference \(TREC'04\, National Institute of Standards and Technology, Gaithersburg Maryland USA, 2004, pp. 712-722 3  M. Roche, J. AzÈ, O. Matte-Tailliez, and Y. Kodratoff, ìMining texts by association rules discovery in a technical corpusî, Proceeding of IIS IIPWMí04 \(Intelligent Information Processing and Web Mining Springer Verlag series ìAdvances in soft Computingî, Poland, 2004, pp 89-98 4  Y. Kodratoff, A. Dimulescu, and A. Amrani. ìMan-Machine Cooperation in Retrieving Knowledge From Technical Textsî. AAAI 2005 Fall Symposium Series. Mixed-Initiative Problem Solving Assistants, 2005. Washington, USA, pp. 69-74 5  T. Heitz, ìModÈlisation du prÈtraitement des textesì, International Conference on Statistical Analysis of Textual Data, vol. 1, BesanÁon France,  pp. 499-506 6  J. Cussens, ìPart-of-speech tagging using Progolî, S. Dzeroski et N Lavrac, Eds., Proceedings of the 7 th International Workshop on ILP Vol.1297,  1997, pp. 93ñ108 7  E. Brill, ìSome Advances in Transformation-Based Part of Speech Taggingî, Proceedings of the twelfth national conference on Artificial intelligence, 1994, Washington, United States, pp. 722ñ727 8  L. Marquez and H. Rodriguez, ìPart-of-Speech Tagging Using Decision Treesî, Proceedings of the 10 th European Conference on Machine Learning, 1998, 25ñ36 9  A. Amrani, Y. Kodratoff, and O. Matte-Tailliez, ìA Semi-automatic System for Tagging Specialized Corporaî, 8 th Pacific-Asia Conference on Knowledge Discovery and Data Mining \(PAKDD 2004\, LNAI 3056 Springer-Verlag, may 2004, Sydney, Australia, pp. 670-681 10  A. Amrani, Y. Kodratoff, and O. Matte-Tailliez, ìInductive improvement of Part-of-Speech tagging and its effect on a terminology of molecular biologyî, In the 18 th Canadian Conference on Artificial Intelligence \(AIí2005\, May 2005, Victoria, Canada. Lecture Notes in Artificial Intelligence, Springer-Verlag, pp. 366-376 11  E. Frank and I. H. Witten, ìGenerating Accurate Rule Sets Without Global Optimizationî, Shavlik, J. Eds., Proceedings of the 15th International Conference on Machine Learning, Madison, Wisconsin 1998, pp. 144-151 12  W. Cohen, ìFast Effective Rule Inductionî, Proceedings of the 12 th  International Conference on Machine Learning \(ICML\, 1995, pp. 155123 13  A. Amrani, Y. Kodratoff, and O. Matte-Tailliez,  ìInduction de rËgles de correction pour líÈtiquetage morphosyntaxique de la littÈrature de biologie en utilisant líapprentissage actifì. TALN 2005 \(Traitement Automatique des Langues Naturelles\, Dourdan, France, 2005, pp. 385390 14  D. Lewis and J. Catlett, ìHeterogeneous Uncertainty Sampling for Supervised Learningî, 11 th International Conference on Machine Learning \(ICML\., pp. 148-156 15  A. McCallum and K. Nigam, ìEmploying EM and Pool-Based Active Learning for Text Classificationî. International Conference on Machine Learning, 1998, pp. 350-358 16  M. Roche, T. Heitz, O. Matte-tailliez, and Y. Kodratoff,  ìEXIT: un systËme itÈratif pour líextraction de la terminologie du domaine ‡ partir de corpus spÈcialisÈsî,  JournÈe Internationales díAnalyse Statistique des DonnÈes Textuelles \(JADTí04\, Volume 2, louvain-la-Neuve Belgique, 2004, pp. 946-956 17  L. Nerima, V. Seretan, E. Wehrli, ìCreating a multilingual collocations dictionary from large text corporaî, Proceedings of Conference of the European Chapter of the Association for Computational Linguistics EACL\,  2003, 131-134 18  T. E. Dunning, ìAccurate Methods for the Statistics of Surprise and Coincidenceî, Computational Linguistics, Volume 19 \(1\ , 1993, pp. 61 74 19  Y. Kodratoff, ìComparing Machine Learning and Knowledge Discovery in DataBases: An Application to Knowledge Discovery in Texts Machine Learning and Its Applications, 2001, pp. 1-21 20  Y. kodratoff, ìInduction Extentionnelle: dÈfinition et application líacquisition de concetps ‡ partir de textes", Extraction et gestion des connaissances \(EGC'04\, 2004, pp. 247-252 21  A. Amrani and O. Matte-Tailliez, ìInformation extraction on Crohnís disease from texts by interactive visualizationî, JournÈes Ouvertes de Biologie, Informatique et MathÈmatiques \(JOBIMí05\, Lyon, France, 68 July 2005 22  R. Agrawal, T. Imielinski, A. Swami, ìMining Association Rules between Sets of Items in Large Databasesî, International Conference on Management of Data  archive ACM SIGMOD, Washington, D.C United States, pp. 207-216  


In other words, an item would only appear at most one time in the i th row during a single round. In this way, we have few linked lists including n items if the hash function H is sufficiently uniform. The total memory required is again 000\013\000\014 On  In summary, the time an d space complexity of the candidate-generation process in our SERIT are asymptotically the same as BTHís 4. experiment results In this section, we report the results of testing our SERIT on several data sets. Compar ing with algorithm TAPER and BTH, SERIT is proved to be effective. Bounded with a small false-negative tolerance 000W as 0.005, SERIT can not only prune the uncorrelated pairs efficiently to generate a small candidate set and save computi ng resources; but also cover the shortcoming of BTH, still achieving small running time when 000T is relatively small The experiment bases on both synthetic and real data sets We choose the famous ìretailî data set, which contains data from a retail store and can be downloaded from FIMI website. The tool mentioned in [2 is also use d h e re  to generate three synthetic data sets S 1 S 2 and S 3 Table 3 lists the characteristics of these data sets. And table 4 shows the values of parameter k and t in algorithm SERIT and BTH for different 000T   T ABLE 3 THE CHARACTERISTICS OF DATA SETS  Data Set Num of Items Num of Records retail 16470 88163 S 1 20589 51316 S 2 33052 51292 S 3 42522 51337 All the experiments were performed on a personal computer, with a 2.0 GHz CPU and 512 Mbytes of memory running the windows XP operating system In section 5.1, we give th e executing time of the three algorithms, including candidate-generation running time and overall running time. We then show in section 5.2 the scalability of SERIT T ABLE 4   THE VALUES OF PARAMETER K AND T   Algorithm SERIT Algorithm BTH 000T  k t k t 0.8 7 8 2 10 0.7 11 6 2 18 0.6 14 6 2 38 0.5 17 6 2 47 0.4 28 4 2 204 0.3 30 4 2 370 0.2 110 4 2 2940 0.1 410 2 2 50000 4.1. The executing time  All the three algorith ms need two steps: 1\ generation of the candidate set 2\refinement. As a result, there are two types of executing time, candidate-generation running time and overall running time, which may present different properties. Although an algorithm executes efficiently during candidate-generation stage, it may produce a large candidate set inducing the incr ease of overall executing time The coefficient thresholds are sp lit to two parts with 0.4 as a dividing point. Figure 5 illust rates the candid ate-generation time, while Figure 6 shows the overall executin g time, both based on ìretailî data set The corresponding executing time on S 1 is presented in Figure 7 and 8. Note that when 0.1 000T 000  we find that the executing time including the two types\ of BTH is too long, much longer than that of other algorithms Moreover, it is also much longer than the time when 0.2 000T 000  For the rationality of experiment and brevity to present, we donít illustrate the execu ting time of BTH with 0.1 000T 000  From Figure 5~8\(a\s small executing time when 0.4 000T 000d And the advantage becomes more obvious when 000T  is smaller. Oppositely, the running time of BTH increases sharply with the decrease of 000T This is mainly due to the very large numbers of min-hash values caused by large t. Although BTH merely chooses two items in the same equivalence class to generate a candidate pair and the method in SERIT seem s a little complex, SERIT is still faster due to the r eason mentioned above When 0.5 000T 000t BTH computes less min-hash values, and consequentially it has smaller running time. SERIT is slightly slower than BTH in most cases, but always faster than TAPER. This is determin ed by the property of the probability function used in SERIT: With a big 000T the item pair whose correlation coefficient is smaller than 000T would be chosen into the candidate set in a relatively high probability \(compared with BTH\In this way, SERIT may have a slightly bigger candidate set than BTH From further analysis, the other two is much powerful than TAPER to remove pairs unwanted. As a result of the large candidate set generated in TAPER, in the refinement step more time is required. As shown in Figure 7 \(b\d 8 b\ the execution of TAPER can be one order of magnitude slower Moreover, comparing the experimental results on ìretail with S 1 we can conclude that the size of item set has greater influence on TAPER than on SERIT and BTH. The running time increases obviously with the growth of item set 
424 
418 


0.10 0.15 0.20 0.25 0.30 0.35 0.40 0 100 200 300 400 500 600 BTH TAPER SERIT Execution Time \(sec Threshold  Fig 5\(a\ candidate-generati on time on ìretailî with 0.4 000T 000d  0.50 0.55 0.60 0.65 0.70 0.75 0.80 5 10 15 20 25 30 Execution Time \(sec Threshold BTH TAPER SERIT  Fig 5\(b\ candidate-generati on time on ìretailî with 0.5 000T 000t  0.10 0.15 0.20 0.25 0.30 0.35 0.40 0 100 200 300 400 500 600 BTH TAPER SERIT Execution Time \(sec Threshold  Fig 6\(a\ overall executing time on ìretailî with 0.4 000T 000d  0.50 0.55 0.60 0.65 0.70 0.75 0.80 20 40 60 80 100 120 140 160 180 200 Execution Time \(sec Threshold BTH TAPER SERIT  Fig 6\(b\ overall executing time on ìretailî with 0.5 000T 000t  0.10 0.15 0.20 0.25 0.30 0.35 0.40 0 100 200 300 400 500 600 BTH TAPER SERIT Execution Time \(sec Threshold  Fig 7\(a\ candidate-generation time on S 1 with 0.4 000T 000d  0.50 0.55 0.60 0.65 0.70 0.75 0.80 5 10 15 20 25 30 35 40 45 Execution Time \(sec Threshold BTH TAPER SERIT  Fig 7\(b\ candidate-generation time on S 1 with 0.5 000T 000t  0.10 0.15 0.20 0.25 0.30 0.35 0.40 0 100 200 300 400 500 600 700 800 900 BTH TAPER SERIT Execution Time \(sec Threshold  Fig 8\(a\ overall executing time on S 1 with 0.4 000T 000d  0.50 0.55 0.60 0.65 0.70 0.75 0.80 50 100 150 200 250 300 350 400 450 Execution Time \(sec Threshold BTH TAPER SERIT  Fig 8\(b\ overall executing time on S 1 with 0.5 000T 000t  4.2. The scalability of algorithm SERIT We use synthesized data sets list in Table 3 to examine the scalability of SERIT from the vi ew point of ex ecution time They have different sizes of item set. Figure 9 shows that the execution time increases with the number of items. This conclusion is consistent with th e complexity analysis shown in section 3 
425 
419 


2.0 2.5 3.0 3.5 4.0 4.5 40 60 80 100 120 140 160 Execution Time \(sec Num of items              X 10 4 Thre0.1 Thre0.3 Thre0.5 Thre0.7  Fig 9. scalability of algorithm SERIT 5. Conclusion and future work In this paper, given a coefficient threshold, we design and implement the algorithm SERIT which can find the correlated item pairs through efficient pruning in a massive market-basket data set. The method proposed by Zhang et al   o re suitable when 000T is relatively big. Hence, a new problem is generated when 000T is small. Our SERIT introduces a new probability functio n to select candidate pairs Experimental results show that the space and time complexity are asymptotically the same as BTHís. In ad dition, with a relatively small 000T  0.4 000d eds a much smaller and more reasonable kt 000  than BTH. Theref ore, SERIT achieves much larger saving of computational resources  There are several potential dir ections in future research First, we will examine whether it is more efficient to combine SERIT and TAPER. However, the two different pruning methods need different pre-proces sings. In particular, we have to consider the trade-off between a more complex pre-processing and efficiency Second, we only considered pairs of items in this paper How about a correlated item set Also, there exist several other cr iterions to measure correlation association\, which may have peculiar properties  A CKNOWLEDGMENT  This work is supported by the National High-Tech Research and Development Plan of China \("863" plan\nder Grant No  2006AA01Z451 and No. 2007AA01Z474 6. References   Hui Xiong, Shashi Shekhar, P. N. Tan, and Vipin Kumar Exploiting a support-based upper bound of Pearsonís correlation coefficient for efficiently identi fying strongly correlated pairs KDDí04, pp. 334ñ343, August 22-25, 2004, USA   J i an Zh ang and J o an F e ig e nbaum, ìFindind highly correlated pairs efficiently with powerfu l pruningî, CIKMí06, pp. 152ñ161 November 5-11,2006, USA  Hui Xiong, Mark Brodie a nd Sheng Ma, ìTOP-COP: mining TOP-K strongly correlated pairs in large databaseî, ICDMí06, pp 1162ñ1166  R.Agrawal  T. Im i e linski   a nd A. S w am i   M ining associa tion rules between sets of items in large databases SIGMODí93, pp 207-216  C. Jerm aine, ì Th e com putational complexity of high-dimensional correlation s earchî, ICDMí01, pp. 249-256  C.Bucila, J Gehrke, D  Kif e r and W. M. White, ì Dualminer: a dual-pruning algorithm for itemsets with constrainsî, SIGKDDí02 pp. 241-272  E. Cohen   S ize-estim at i on fram e work with appl ic atio ns to transitive closure and reachability Journal of Computer and System Sciences, 1997, pp. 441-453  C. Jermaine, ìPlay i ng hide-a nd-seek with correlations SIGKDDí03, pp. 559-564  S  Brin R  M o tw ani and C S ilvers t ein   B e y ond m a rket bas k ets   Generalizing association rules to correlationsî, SIGMODí97, pp 265-276  Yu Li Miroslav, and  Kubat, ìSearching for high-su pport itemsets in itemset treesî, Intellig ent Data Analysis, , March, 2006 Volume 10, Issue 2, pp. 105-120  H. T. R e ynolds The an aly s is of cross-classificationsî, The Free Press, New York, 1977   Toon Cad e rs, B a rt Goeth a ls and S. Jaroszewicz, ìMining rank-correlated sets of numerical attributes KDDí06, August 20-23 2006, USA, pp. 96-105  C. K. S Leung, and Qu amru l l. Khan, ìEfficient mining of constrained frequent patterns fro m Streamsî, IDEASí06, pp. 61-68  Motwani  E Cohe n, M Da ta r, S. Fujiwa re A Gionis P Indyk, J. Ullman, and C.Yang, ìFinding interesting associations without support pruningî, IEEE Transactions on Knowledge and Data Engineering \(special issue  W. DuMouchel and D. Preg ibon Empirical bayes screening for multi-item associationsî, KDDí01, pp. 67-76  S  J a ros zew icz and D a n A  Simovici, ì Inte restingness of frequent itemsets using Bayesi an networks as background knowledgeî, SIGKDDí04, USA, pp. 178-186  
426 
420 


TESTS IN SECOND t INDICATES nl WAS LOWERED TO 2 Training BSTC Top-k RCBT 7 OC Holdout Validation Results RCBT outperforms BSTC on the single test it could finish by more then 7 although it should be kept in mind that RCBT's results for the 24 unfinished tests could vary widely Note that BSTC's mean accuracy increases monotonically with training set size as expected At 60 training BSTC's accuracy behaves almost identically to RCBT's 40 training accuracy see Figure 6 4 Ovarian Cancer OC Experiment For the Ovarian Cancer dataset which is the largest dataset in this collection the Top-k mining method that is used by RCBT also runs into long computational times Although Top-k is an exceptiounally fast CAR group upper bound miner it still depends on performing a pruned exponential search over the training sample subset space Thus as the number of training samples increases Top-k quickly becomes computationally challenging to tune/use Table VI contains four average classification test run times in seconds for each Ovarian Cancer\(OC training size As before the second column run times each give the average time required to build both class 0/1 BSTs and then use them to classify all test's samples with BSTC Note that BSTC was able to complete each OC classification test in about 1 minute In contrast RCBT again failed to complete processing most classification tests within 2 hours Table VI's third column gives the average times required for Top-k to mine the top 10 covering rule groups upper bouhnds for each training set test with the same 2 hour cutoff procedure as used for PC testing The fourth column gives the average run times of RCBT on the tests for which Topk finished mining rules also with a 2 hour cutoff Finally the  RCBT DNF column gives the number of tests that RCBT was unable to finish classifying in  2 hours each THE OC TESTS THAT RCBT FINISHED Training BSTC RCBT 40 92.05 97.66 60 95.75 96.73 80 94 12 98.04 1-133/077 9380 96.12 1070 cJ CZ C 0.95 0.9 0.85 0.8 0.75 0.7 0.65 0.6 0.55 0.5 BSTC RCBT d Median Median  Mean 260 Near outliers  Far outliers 40 Training 60 Training 0.90.80.70.6BSTC RCBT a 80 Training 1-52/0-50 Training 0.9DNFI 0.80.70.6BSTC RCBT b 1 u0.9DNFI 0.80.70.6BSTC RCBT  RCBT DNF 40 30.89 0.6186 273.37 0/25 60 61.28 41.21  5554.37 19/25 80 71.84  1421.80  7205.43 t 21/22 TIMES FOR THE OC 9 Mean 0 Near outliers  Far outliers 1.01 11 01 1.0 d Fig 6 PC Holdout Validation Results BSTC RCBT a Fig 0.80.8 0.8BSTC RCBT BSTC RCBT b c c i DNF cJ CZ C 40 Training 60 Training 80 Training 1-133/0-77 Training 0.95 DNF DNF DNF 0.9 0.90.90.90.85 0.8 BSTC RCBT TABLE VI AVERAGE RUN 1 133/0-77 70.38  1045.65  6362.86 t 20/23 over the number of tests for which Top-k finished Because RCBT couldn't finish any 80 or 1-133/0-77 tests within 2 hours with nl  20 we lowered nl to 2 Classification Accuracy Figure 7 contains boxplots for BSTC on all four OC classification test sets Boxplots were not generated for RCBT with 60 80 or 1-133/0-77 training since it was unable to finish all 25 tests for all these training set sizes in  2 hours each Table VII lists the mean accuracies of BSTC and RCBT over the tests on which RCBT was able to produce results Hence Table VII's 40 row consists of averages over 25 results Meanwhile Table VII's 60 row results are from 6 tests 80 contains a single test's result and 1-133/0-77 results from 3 tests RCBT has better mean accuracy on the 40 training size but the results are closer on the remaining sizes   4 difference over RCBT's completed tests Again RCBT's accuracy could vary widely on its uncompleted tests CAR Mining Parameter Tuning and Scalability We attempted to run Top-k to completion on the 3 OC 80 training and 2 OC 1-133/0-77 training tests However it could not finish mining rules within the 2 hour cutoff Top-k finished two of the three 80 training tests in 775 min 43.6 sec and 185 min 3.3 sec However the third test ran for over 16,000 mnm  11 days without finishing Likewise Top-k finished one of the two 1-133/0-77 tests in 126 min 45.2 sec but couldn't finish the other in 16,000 min  11 days After increasing Top-k's support cutoff from 0.7 to 0.9 it was able to finish the two unfinished 80 and 1-133/0-77 training tests in 5 min 13.8 sec and 35 min 36.9 sec respectively However RCBT with nl 2 then wasn't able to finish lower bound rule mining for either of these two tests within 1,500 min Clearly CAR-mining and parameter tuning on large training sets is TABLE VII MEAN AcCU1ACIES FOR 


support pruning gene expression classifier with an accurate and compact fuzzy rule base for microarray data analysis Biosystems vol 85 computationally challenging As training set sizes increase it is likely that these difficulties will also increase VI RELATED WORK While operating on a microarray dataset current CAR 1 2 3 4 and other pattern/rule 20 21 mining algorithms perform a pruned and/or compacted exponential search over either the space of gene subsets or the space of sample subsets Hence they are generally quite computationally expensive for datasets containing many training samples or genes as the case may be BSTC is explicitly related to CAR-based classifiers but requires no expensive CAR mining BSTC is also related to decision tree-based classifiers such as random forest 19 and C4.5 family 9 methods It is possible to represent any consistent set of boolean association rules as a decision tree and vice versa However it is generally unclear how the trees generated by current tree-based classifiers are related to high confidence/support CARs which are known to be particularly useful for microarray data 1 2 6 7 11 BSTC is explicitly related to and motivated by CAR-based methods To the best of our knowledge there is no previous work on mining/classifying with BARs of the form we consider here Perhaps the work closest to utilizing 100 BARs is the TOPRULES 22 miner TOP-RULES utilizes a data partitioning technique to compactly report itemlgene subsets which are unique to each class set Ci Hence TOP-RULES discovers all 100 confident CARs in a dataset However the method must utilize an emerging pattern mining algorithm such as MBD-LLBORDER 23 and so generally isn't polynomial time Also related to our BAR-based techniques are recent methods which mine gene expression training data for sets of fuzzy rules 24 25 Once obtained fuzzy rules can be used for classification in a manner analogous to CARs However the resulting fuzzy classifiers don't appear to be as accurate as standard classification methods such as SVM 25 VII CONCLUSIONS AND FUTURE WORK To address the computational difficulties involved with preclassification CAR mining see Tables IV and VI we developed a novel method which considers a larger subset of CAR-related boolean association rules BARs These rules can be compactly captured in a Boolean Structure Table BST which can then be used to produce a BST classifier called BSTC Comparison to the current leading CAR classifier RCBT on several benchmark microarray datasets shows that BSTC is competitive with RCBT's accuracy while avoiding the exponential costs incurred by CAR mining see Section VB Hence BSTC extends generalized CAR based methods to larger datasets then previously practical Furthermore unlike other association rule-based classifiers BSTC easily generalizes to multi-class gene expression datasets BSTC's worst case per-query classification time is worse then CAR-based methods after all exponential time CAR mining is completed O SlS CGl versus O Si CGi As future work we plan on investigating techniques to decrease this cost by carefully culling BST exclusion lists ACKNOWLEDGM[ENTS We thank Anthony K.H Tung and Xin Xu for sending us their discretized microarray data files and Top-k/RCBT executables This research was supported in part by NSF grant DMS-0510203 NIH grant I-U54-DA021519-OlAf and by the Michigan Technology Tri-Corridor grant GR687 Any opinions findings and conclusions or recommendations expressed in this material are those of the authors and do not necessarily reflect the views of the funding agencies REFERENCES 1 G Cong K L Tan A K H Tung and X Xu Mining top-k covering rule Mining SDM 2002 5 R Agrawal T Imielinski and A Swami Mining associations between sets of items Y Ma Integrating classification and association rule mining KDD 1998 11 T McIntosh and S Chawla On discovery of maximal confident rules without pp 43-52 1999 24 S Vinterbo E Kim and L Ohno-Machado Small fuzzy and interpretable pp 165-176 2006 1071 pp 207-216 1993 6 G Dong pp 273-297 t995 9 pp 5-32 2001 20 W Li J R Quinlan Bagging boosting and c4.5 AAAI vol 1 V Vapnik Support-vector networks the best strategies for mining frequent closed itemsets KDD 2003 4 M Zaki and C Hsiao Charm L Wong Identifying good diagnostic genes or gene expression data SIGMOD 2005 2 G Cong A K H Tung X Xu F Pan and J Yang Farmer Finding interesting rule gene expression data by using the gene expression based classifiers BioiiiJcrmatics vol 21 l and Inrelligent Systenis IFIS 1993 16 Available at http://sdmc.i2r.a-star.edu.sg/rp 17 The dprep package http:/cran r-project org/doclpackages dprep pdfI 18 C Chang and C Lin Libsvm a library for support vector machines 2007 Online Available www.csie.ntu.edu.tw cjlin/papers/libsvm.pdf 19 L Breiimnan Random forests Maclh Learn vol 45 no 1 M Chen and H L Huang Interpretable X Zhang 7 J Li and pp 725-734 2002 8 C Cortes and Mac hine Learming vol 20 no 3 in microarray data SIGKDD Worikshop on Dtra Mining in Bioinfrrnatics BIOKDD 2005 12 R Agrawal and R Srikant Fast algorithms for mining association rules VLDB pp 1964-1970 2005 25 L Wong and J Li Caep Classification by aggregating emerging patterns Proc 2nd Iat Coif Discovery Scieice DS 1999 gene groups from pp 487-499 t994 13 Available ot http://www-personal umich edu/o markiwen 14 R Motwani and P Raghavan Randomized Algoriitlms Caim-bridge University Press 1995 15 S Sudarsky Fuzzy satisfiability Intl Conf on Industrial Fuzzy Contri J Han and J Pei Cmar Accurate and efficient classification based on multiple class-association rules ICDM 2001 21 F Rioult J F Boulicaut B Cremilleux and J Besson Using groups for groups in microarray datasets SIGMOD 2004 3 concept of emerging patterns BioinformJotics vol 18 transposition for pattern discovery from microarray data DMKD pp 73-79 2003 22 J Li X Zhang G Dong K Ramamohanarao and Q Sun Efficient mining of high confidence association rules without S Y Ho C H Hsieh H pp 725-730 1996 10 B Liu W Hsu and support thresholds Principles f Drata Mining aind Knowledge Discovery PKDD pp 406 411 1999 23 G Dong and J Li Efficient mining of emerging patterns discovering trends and differences KDD J Wang J Han and J Pei Closet Searching for An efficient algorithm for closed association rule mining Proc oJ the 2nd SIAM Int Con on Data in large databases SIGMOD 


