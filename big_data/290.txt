An Algorithm of Association Rules Extracting Based on Granular Computing and Its Application Taorong Qiu Xiaoqing Chen Qing Liu Houkuan Huang Abstract-In this paper on the basis of the Apriori algorithm a granular computing-based algorithm for association rules extracting is presented The comparison of the running time between the presented algorithm and the Apriori algorithm is discussed  and its running procedure is illustrated by a real world example  By analyzing it is shown that the granular computing-based algorithm for association rules extracting reduces efficiently the number of candidate elements and avoids 
scanning repeatedly the information table Index Term--association rules data mining granular computing I INTRODUCTION D ATA mining technology has become a research hotspot nowadays It has a very widespread application prospect such as monitoring the quotations in the stock market timely comparing the price of the goods in each electrical-business website tracking the trends of friends and competitors collecting various information about the inside or the outside of a company Data mining has 5 models classification trend analysis clustering association rules and sequence patterns Association rules are simple and practical rules 
The model of the association rules is a kind of descriptive models and the algorithm of discovering association rules is a kind of unsupervised learning methods There are many association rules mining algorithms developed nowadays The Apriori algorithm presented by R.Agrawal is the most famous It has been applied in many fields But it has some disadvantages such as scanning repeatedly the transaction database each time when seeking for frequent item sets In this paper we discuss association rules mining from a perspective of information granules and granular computing On the basis of the 
Apriori algorithm we describe a new algorithm based on granular computing Compared with Apriori our algorithm can efficiently reduce the number of This study is supported by the Natural Science Foundation of China NSFC-#60173054 and the Natural Science Foundation of Jiangx province JXPNSF031 1 101 in China T.R.Oiu and X.Q.Chen are with the School of Computer and Information Technology Beijing Jiaotong University Beijing 100044,China and with the department of Computer Nanchang University Nanchang,Jiangxi 330029,China e-mail:qiutaorong@sina.com Q.Liu is with the department of Computer Nanchang University Nanchang,Jiangxi 330029,China H.K.Huang is with the School of Computer and 
Information Technology Beijing Jiaotong University Beijing 100044,China candidate elements and solve the bottleneck problem caused by repeatedly scanning the information table II INFORMATION GRANULES AND GRANULAR COMPUTING Since human's ability of solving problems is limited we usually divide enormous complex information into several simple blocks by its characteristics Each block can be viewed as an information granule That is an information granule is a set of entities with similar characteristics or similar functions or indistinguishability[1],[2],[5],[7  L.A.zadeh firstly presented the concept of information granularity and granulation after long-term research[5 Information granularity g 
is described in 5 by a proposition g=x is G is X in which x is a variable taking values in a universe of discourse U G is a fuzzy subset of U which is characterized by its membership RG  and qualifier denotes a fuzzy probability T.Y.Lin described information granules by view of domain[11 Let U be a crisp set  Let B c VXU be a binary relation For each object p e V we associate a binary subset BpcU where Bp={ul p B u that consists of all elements u that are related to p by B The 
map B V-Bp or the collection  Bp  is referred to as a binary neighborhood system Obviously whether Bp is clear or fuzzy depends on the characteristic of B In a nutshell granular computing is geared toward representing and processing information granules[l III AsSOCIATION RULES The association rule presented by R.Agrawal firstly is an very important subject in the data mining  It studies how to search for the frequent mode association relativity or cause and effect construction embedded in the association data transaction data or other information carriers and decides which will 
happen together through analyzing data or the relation between records Let I={ii,i2 im be an item set where ik\(k=1,2,...,m is an item it can be a sort of goods in the shopping basket and can also be a customer in a company and etc Assuming D is a transaction database each transaction T is a subset of item set i.e T cI  is identified by symbol TID\(Transaction Identifier If item set X CT then we say that transaction T includes item set X Association rule is a logical implicating formula as 0-7803-9017-2/05/$20.00 02005 IEEE 225 


XR Y among which X C T Y CT and Xn Y 0 If there are s transactions in the transaction database include X U Y then we say that the support of association rules is s its probability p\(X U Y can be written as support X  Y TI X U Y cT T ED I/IDI P\(X U Y If there are c transactions including X also include Y then we say that the confidence of association rules X  Y is c and the conditional probability P\(YIX can be written as confidence\(X=>Y I{TI XUY CT TED I/I{TI X5T T E D I=P\(YIX We call the rule that both satisfies minimum support\(min_sup and minimum confidence as strong rule The set of item are called item set The item set which contains K items is called K-item set The occurring frequency of item set is the number of transactions in which the item set is contained and it is also known as support count or count If the occurring frequency of item set is larger than or equal to the product of min sup and the number of transactions in D then the item set satisfies min-sup and it is called as frequent item set The set of frequent K-item set containing k items is generally denoted by Lk The task of mining association rules is to try to find all the association rules that satisfy min-sup and min_confidence in a transaction database D IV GRANULAR COMPUTING--BASED ALGORITHM FOR ASSOCIATION RULES EXTRACTING A Classic Frequent Item Set Method Apriori Algorithm In 1993,Agrawal presented an important method to mine association rules The design for association rules extracting algorithm can be divided into two sub-problems 1 Finding all the items whose support are larger than or equal to min_sup to generate a frequent item set 2 Using the frequent item set generated in step 1 to obtain expecting rules Step 2 is easy but it is difficult to do for step 1  Given a frequent item set Y=III2...Ik k.2 Ij EI 1<=j<=k our aim is to generate all the rules that include the items of set I 12 I Ik}only The right side of each such rules has only one item  i.e Y-Ij]=>Ij Vl.i<k Here we adopt the definition of strong rules Once these rules are generated only such rules that has support and confidence not less than those given by the user would be reserved We use iteration to generate all the frequent item sets The main idea of the Apriori algorithm is as follows 1 LI   Frequent 1-itemsets 2 for k=2 Lk-l k do begin 3 Ck=apriori-gen\(Lk-l new candidate item set 4 for all transactions teD do begin 5 Ct=subset\(Ck,t I/candidate item set that included in transaction T 6 for all candidates cE C do 7 c.count 8 end 9 Lk={ce CkIc.count.minsup 10 end 1 1 Answer=ukLk The procedure to generate new candidate item set is described as follows apriori-gen\(Lk-1 merging Insert into Ck Select p.item1 p.item2  p.itemk q.itemk I From Lk-l p Lk-l q Where p.iteml q iteml,p.item2=q.item2  p.itemk-2 q.itemk2 p.itemk_l q.itemk_I prunning For element c cE Ck do For all k-l s of c do if s 0 Lkl then delete c from Ck  In the Apriori algorithm frequent 1-itemset L is generated first then frequent 2-itemset L2 The algorithm won't stop until there exists a value r that makes Lr null In the Kth iteration the algorithm generates the set Ck of candidate K-item set first in which each element is generated by processing a connection between two elements in the frequent item set Lk-l The set Ck is the candidate item set used to generate a frequent item set Lk so the frequent item set Lk must be a subset of Ck The Lkl p and the Lkl q in the apriori-gen procedure are referred to element p and element q in the frequent item set Lk-l B Granular Computing--Based Frequent Item Set Algorithm First the information table\(i.e transaction database is described by information granules and information granules is represented by binary numeral string\(i.e bit representation So each element in Ck or Lk is an information granule Second on the basis of the Apriori algorithm we propose the granules computing based algorithm for association rules extracting The main steps of the algorithm are described as follows 1 Scanning the information table and generating the frequent item set LI the support of elements in LI satisfying min_sup  2 Generating candidate item set Ck k>=2 by the operation AND between the bit representation in Lk-l  3 In Ck the number of chars 1 of a element is the support of the element and the elements that their support satisfy the min_sup are put into the frequent item set Lk  4 If Lk is null then the algorithm stops else continue 2 5 Returning all frequent item set Lk obtained There are two attributes in the information granule One is the block number and another is the number of chars 1 in the bit representation We use symbol no and count to stand for the two attributes respectively The block number is the identifier  In Lk the information granules that have same attribute name or attribute combination are assigned same block number 226 


We still use iteration to generate all the frequent item sets The main idea of the algorithm is as follows 1 G1  gI,g2  g.1 gj.count>=minsup,l<=i<=m 2 for k=2 Gk l.4 k do begin 3 c p and ql p E Gk l,q E Gkl p.no<>q.no 4 Gk cl c.count>=minsup  5 end 6 Answer=-UkGk In this algorithm frequent 1-itemset G1 is generated first then frequent 2-itemset G2 The algorithm won't stop until there exists a value r that makes L null Here in the Kth iteration each element in Gk is generated by granular computing between the two information granules with different block numbers in GklI C Algorithm Analysis The Apriori algorithm has two main shortcomings one is that it may generate many redundant or meaningless candidate elements Another is that it repeatedly scans the information table  The Apriori algorithm scans the information table k times repeatedly Suppose that the number of elements in Lk is nk then the total number of comparisons in the step 3 r-I is C2 at most where r is the value when Lr is null From k=l step 4 to step 8 in Ck whether each element can be put into Lk it must be checked and the checking causes scanning information table Suppose that the number of elements in Ck is Mk then from step 4 to step 8 the number of compares r with the records of the information table is U E m k times k=2 at most When JUI or mk is much bigger the Agrawal algorithm may result in much load of I/O In order to reduce the size of Ck  Agrawal introduced a pruning technology Because of this when generating all frequent item set the performance of the algorithm can be improved effectively In addition suppose that the number of elements in Ck is Mk then r the total number of the comparisons in step 9 is M ik k=2 Compared with the Apriori algorithm the granular computing-based algorithm for association rules extracting is improved mainly in two aspects One is that redundant or meaningless candidate elements can be reduced effectively Another is that frequent item set Gk can be generated without scanning information table First in Gk elements  i.e information granules  are organized by blocks  So when generating elements in Gk+l within the blocks candidate elements that are redundant or meaningless are not generated Secondly by the operation and between elements with different block numbers in Gk elements in Gk+I are generated without scanning information table Thus it is obvious that the granular computing-based algorithm for association rules extracting can conquer the bottleneck phenomena caused in the Apriori algorithm Moreover Generally the number of blocks in G1 is fewer than the number of the item set I So the number of loops can be reduced greatly in the granular computing-based algorithm for association rules extracting v GRANULAR COMPUTING-BASED ALGORITHM APPLIED TO MINING WEB USER FAVORITE PATHS MODEL A Web Log The web log usually adopted the ECLM log model to record a data[lO Data structure is shown in figure 1 Time/Data field represents the time when web server receives the user's request URL field represents the URL location of web page that users visited Referer field represents the URL of cited page If a user input a the URL directly or uses bookmark to visit web pages then the referer field is null Agent field is the type of OS and browser IF Address Anth ID Time/Data lethod/1JDIIProtocol Status Size Referer Agent Fig 1 Web Log Data Structure B An Example We simply take three attributes in web log data structure to illustrate the thought of the granular computing-based algorithm for association rules extracting In addition the values of attributes are represented by using letters and digits Table 1 is the web log table that has been pre-processed In table 1 U={ul,u2,u3,u4,u5,u6,u7,u8,u9,ul0 is a universe Suppose that the min sup is s%=15 First we generate the frequent item set G1  The method is that each equivalence class is described by n bits  where n is the cardinal of U In a bit representation when the ith bit is 1 then the individual ui belongs to this information granule if it is 0 then the individual ui doesn't belong to this information granule The number of chars 1 in the bit representation is known as the size of the information granule i.e the size of the support In this example we use 10 bits to represent information granules If the number of chars 1 in bit TABLE 1 INFORMATION TABLE U User address Cited page Visited page ul 2 A VpC u2 1 C VpA u3 2 B VpB u4 3 D VpB u5 2 C VpB u6 3 C VpC u7 3 A VpC u8 2 D VpB u9 1 A VpC ulO 1 B VpA 227 


representation satisfies the min sup then this information granule is put into the frequent item set G1 Scanning the information table one time we can generate the frequent item set G1 In this example the result is G1={[1],[2],[3],[A],[B],[C],[D],[VpA],[VpB],[VpC As table 2 shows the elements in G1 belong to three different blocks TABLE 2 FREQUENT ITEM SET G information granules formed according to partitioning user's address in G1 block number 1 Name of Information The bit Support information granule representation granule of information granule 1 u2,u9,ulO 0100000011 3 2 ul,u3,u5,u8 1010100100 4 3 u4,u6,u7 0001011000 3 information granules formed according to partitioning cited page in G1 block number 2 Name of Information The bit Support information granule representation granule of information granule A ul,u7,u9 1000001010 3 B u3,uI0 0010000001 2 C u2,u5,u6 0100110000 3 D u4,u8 0001000100 2 information granule formed according to partitioning visited page in G1 block number=3 Name of Information The bit Support information granule representation granule of information granule VpA u2,ulO 0100000001 2 VpB u3,u4,u5,u8 0011100100 4 VpC ul,u6,u7,u9 1000011010 4 After generating G1 by operation and between two elements with different block numbers in G1 if the number of chars 1 in the computing result satisfies the condition i.e larger than or equal to the min sup the result is put into the frequent item set G2.The processing continues until none of pair of elements with different block numbers is processed At last G2 is generated through GI.The result is shown in table 3 Then G3 is generated according to G2 In this example because G3 is null G2 is returned at last In addition the maximal value of k is 3 according to the number of blocks Now we can extract association rules from G2 and we can also get this information user2 has a habit of visiting page VpB from cited page D This extracted association rule is the user favorite browsing paths that we hope to obtain When generating G1 the information table is scanned one time In order to generate G2 the total comparing number is 3*4+3*3+4*3=33 at most without scanning the information table If the Apriori algorithm is adopted when generating Lk the TABLE 3 FREQUENT ITEM SET G2 Attribute Information The bit Support combination granules representation of information granule block number 1 in G2 l]and[VpA u2,u10 0100000001 2 2]and[VpB u3,u5,u7 0010101000 3 block number 2 in G2 VpB]and[D u4,u8 0001000100 2 VpC]and[A ul,u7,u9 1000001010 3 information table is scanned 3 times in this example In step 3 it needs to compare C2 45 times to generate C2  and 10 C2 6 times to generate C3 In step 9 it needs comparing 45 times to generate L2 from C2 and 6 times to generate L3 from C3 From step 4 to step 8 the number of compares with the records of the information table is 10*51=510 times at most VI SUMMARY There are mainly two shortcomings in the classical Apriori algorithm In recent years many researchers present many methods to improve the classical Apriori algorithm This paper presents a granular computing-based algorithm for association rules extracting Compared with the classical Apriori algorithm  the algorithm can efficiently reduce the number of candidate elements and avoid the bottleneck phenomena caused in the Apriori algorithm REFERENCES 1 W Pedrycz Granular Computing An Introduction IEEE,2001 pp.1349-1354 2 L.A.zadeh Towards a Theory of Fuzzy Information granulation and Its Centrality in Human Reasoning and Fuzzy Logic Fuzzy Sets and Systems 1997,90\(2 11-127 3 T.Y.Lin and Eric Louie Modeling the Real World for Data Mining Granular Computing Approach IEEE,2001 pp.3044-3049 4 J Peters A Skowron and J Stepaniuk Information Granules in Spatial Reasoning IEEE,2001 pp.1355-1360 5 L.A.Zadeh Fuzzy Sets and Information Granularity In Advances in Fuzzy Sets Theory and Applications edited by M.Gupta,R.Ragade and R.Yager North Holland,Amsterdam,3-18,1979 6 Q.Liu Rough Sets and Rough Reasoning Science Press BeiJing,August 2003[2 7 Q Liu Information Granules and Approximate Reasoning Based on Granular Computing[R China 2004.10 8 F Jian Information Granules Technology Based on Rough Set and its Application The master degree thesis of NanChang University,JiangXi,China,2003.5 9 Z.Li S.H.Shao  Information Retrieval in Fuzzy Control System Based On Information Granulation and Computing with Words Joumal of China Textile University Vol.26 No.3 2000.6 pp..9-13 10 D.S.Xing,J.Y.Shen and Q.B.Song Discovering Preferred Browsing Paths from Web Logs Chinese Joumal of Computers Vol.26,No.11,2003.11 pp.1518-1523 11 T.Y Lin Granular Computing on Binary Relations II Rough Set Representations and Belief Functions In Rough Sets In Knowledge Discovery A Skowron and L Polkowski eds Physica Verlag 1998 121-140 228 


where is the number of observed/expected values \(this is always  in the case of CARM critical threshold value then it can be said that a relationship between the variables exists, otherwise there is no relationship. For CMAR a critical threshold value of was used \(this value has also been used in this paper 2.5. ACS or Specificity ordering In this paper it is proposed that a good alternative ordering to CSA \(as described above size of Antecedent, Con?dence and Support a similar manner to CSA \(see above tecedent placed ?rst. The intuition behind this ordering is that more speci?c rules should be ìtriggeredî before more general rules are attempted. For example we may have a classi?er, ordered using CSA, comprising two rules as follows Rule Conf 1 2  Given a case  this would be classi?ed, using ìbest rstî case satisfaction, as belonging to class  when intuitively class  would be more likely to be the correct class. ACS ordering thus ensures that speci?c rules have a higher precedence than more general rules so that in the above example the class  would be returned. It should be noted, however, that for ACS to work well a high con?dence threshold value should be used. An appropriate mechanism to prevent overfitting must also be incorporated Proceedings of the Fourth IEEE International Conference on Data Mining ICDMí04 0-7695-2142-8/04 $ 20.00 IEEE 3 Classification In the introduction to this paper three alternative case/record classi?cation mechanisms were identi?ed. Two of these, ìbest kî and ì testingî are brie?y discussed below so as to provide some necessary further detail \(ìbest rstî has the obvious interpretation 3.1. Best  Testing The intuition behind ìbest  testingî is that ëone cannot expect that any single rule can perfectly predict the class label for every example satisfying its bodyí [8]. Given a 


case  to be classi?ed the best  approach is as follows 1 2 for each class, or all rules if there are less than  rules for a particular class; \(3 average expected value to be maximised \(e.g. con?dence size of antecedent, Laplace accuracy,  value 4 the class associated with the best average. In [8] a value of was suggested as an appropriate value for 3.2. Weighted  Testing Weighted  Testing is used in a number of CARM algorithms, such as CMAR [6], to classify data by considering entire groups of rules that satisfy a given case. With respect to CMAR, given a case  to be classi?ed, the procedure commences by ?rst collecting all rules that satisfy . Then if the consequents of all rules are identical, or only one rule is found, classify case according to the consequents; otherwise group rules according to class and determine the combined effect of the rules in each group \(the class associated with the ìstrongest groupî is then selected a group is calculate using the WCS \(Weighted  Squared value. The class associated with the group of rules with the highest WCS value is then selected as the class to be allocated to the case 4. Apriori-TFPC The Apriori-TFPC classi?cation rule generation algorithm is founded on the Apriori-TFP \(Total From Partial ARM algorithm [4]1. This algorithm generates frequent sets that are placed as nodes in a set enumeration tree. To evaluate the above approaches a number of variations of the algorithm were created, each re?ecting one of the identi?ed approaches Uniquely, in Apriori-TFPC CRs are generated as part of the ìfrequent set identi?cation processî. As the tree is 1Apriori-TFP and Apriori-TFPC my be obtained from http://www.csc.liv.ac.uk/ frans/KDD/Software developed nodes in branches whose root represents a classi?er are tested for their appropriateness as classi?cation rules using a con?dence threshold \(to evaluate the different techniques considered in this paper this can equally well be achieved using a  threshold, Laplace accuracy or a WRA measure rule is placed in a list and the node not processed any further. Nodes are also pruned during the generation process according to a user supplied support threshold. This tree pruning is intended to prevent overfitting The different ordering and case satisfaction techniques considered in this paper can be combined into eleven different variations of Apriori-TFPC \(see Table 1 to ACS ordering, note that tree pruning is still carried out according to con?dence. In the case of experiments using 


best Kî techniques was set to 5. Evaluation Experiments were conducted using a range of data sets taken from the the UCI Machine Learning Repository [3 The chosen datasets were discretized using the LUCS-KDD DN software2, where appropriate continuous attributes were ranged using ?ve sub-ranges. The experiments were run on a 1.2 GHz Intel Celeron CPU with 512 Mbyte of RAM running under Red Hat Linux 7.3 The ?rst set of evaluations undertaken used a con?dence threshold value of % and a support threshold value of % \(as used in the published evaluations of CMAR 6] and CBA [7 where the best accuracy obtained for each of the data sets is highlighted in bold print. The row labels describe the key characteristics of each data set: for example, the label denotes the ìadultî data set which includes 48842 records in 2 classes, with attributes that for the experiments described here have been discretised into 131 binary categories It should be noted that the datasets were rearranged so that occurences of classes were distributed evenly throughout the datasets. This then allowed the datasets to be divided in half with the ?rst half used as the training set and the second half as the test set. Although a ìbetterî accuracy ?gure might have been obtained using Ten-Cross Validation, it is the relative accuracy that is of interest here and not the absolute accuracy From Table 1 it can be seen that with a % con?dence threshold the proposed ACS ordering worked reasonably well but not as well as was hoped. It is surmised that this is probably because many speci?c rules with relatively low con?dence were given a high precedence over higher con?dence but more general rules. The last four columns of 2The LUCS-KDD DN is available at http://www.csc.liv.ac.uk frans/KDD/Software/LUCS-KDD-DN Proceedings of the Fourth IEEE International Conference on Data Mining ICDMí04 0-7695-2142-8/04 $ 20.00 IEEE Table 1 show the results of a further set of experiments conducted using a con?dence threshold of %. In this case best results were obtained using ìbest ?rstî and ACS. ACS with ìbest ?rstî also produces the greatest number of best accuracies \(10 out of 22 that by reducing the overall number of rules \(by increasing the con?dence requirement orated 


 Data Set Best first Best  first All Best first Best  first CSA ACS WRA Lap.  CSA ACS WRA Lap.  WCS CSA ACS CSA ACS adult.D131.N48842.C2 76.1 76.1 65.2 76.1 32.8 76.0 76.3 57.8 76.1 33.7 76.1 80.7 76.1 80.9 76.4 anneal.D106.N798.C6 85.5 85.5 68.4 83.7 59.1 79.4 79.5 69.2 82.2 42.3 80.7 88.0 85.5 89.5 89.5 auto.D142.N205.C7 12.7 19.6 54.9 48.0 19.6 13.7 13.7 32.4 43.1 12.7 20.6 13.7 12.7 12.7 19.6 breast.D47.N699.C2 98.0 98.0 81.1 96.6 83.1 93.4 93.4 72.2 91.7 88.5 98.0 98.0 98.0 98.0 97.1 con4.D129.N67557.C3 65.8 65.8 37.3 65.8 61.1 65.8 65.8 62.4 65.8 65.9 65.8 65.8 65.8 65.9 65.9 glass.D52.N214.C7 49.5 38.3 34.6 46.7 13.1 42.1 42.1 26.2 43.0 13.1 13.1 32.7 36.4 46.7 45.8 heart.D53.N303.C5 49.7 54.3 57.6 55.0 55.0 53.0 53.0 56.3 55.0 55.0 55.0 43.0 54.3 29.8 29.8 hepatitis.D58.N155.C2 71.4 79.2 67.5 79.2 20.8 80.5 80.5 70.1 79.2 28.6 61.0 64.9 79.2 53.2 53.2 horseCol.D94.D368.C2 67.9 78.2 83.7 77.8 62.5 70.7 70.1 78.3 66.8 51.1 62.5 60.9 77.1 47.8 58.7 iono.D172.N351.C2 81.7 91.4 76.0 87.4 84.6 77.1 88.0 62.9 82.9 69.7 62.9 91.4 91.4 66.3 94.3 iris.D23.N150.C3 94.7 94.7 93.3 93.3 93.3 92.0 92.0 93.3 92.0 89.3 94.7 89.3 94.7 88.0 88.0 led7.D24.N3200.C10 67.1 57.2 32.9 66.6 26.0 66.2 66.3 31.9 66.8 19.1 73.8 63.4 64.6 64.1 64.1 letRec.D106.N20000.C26 44.2 34.9 16.9 42.4 28.1 41.0 41.2 8.1 41.3 25.6 38.1 28.6 29.1 28.5 28.4 mushrím.D127.N8124.C2 96.0 89.1 47.5 46.7 88.4 71.1 69.7 66.9 69.8 85.6 53.1 96.2 89.1 82.0 81.9 nursery.D32.N12960.C5 80.0 74.4 70.6 80.0 70.6 69.8 69.9 70.3 70.6 68.6 85.3 89.6 87.2 87.6 88.3 pageBlíks.D55.N5473.C5 89.8 89.8 79.6 89.8 3.4 89.8 89.8 68.5 89.8 5.4 2.0 89.8 89.8 89.8 89.8 penDig.D90.N10992.C10 79.5 40.6 33.1 78.1 49.9 54.4 54.8 35.2 55.0 46.8 70.8 83.0 79.3 71.0 71.2 pimaInd.D42.N768.C2 74.2 74.2 76.0 74.5 65.1 71.3 73.7 66.9 70.6 62.0 70.6 76.0 76.8 73.7 73.7 ticTacToe.D29.N958.C2 66.6 66.0 65.8 66.0 65.8 64.3 51.4 54.9 64.9 65.8 78.9 69.1 66.2 55.9 55.7 wave.D108.N5000.C3 66.2 61.1 62.5 66.4 62.5 57.8 58.3 60.0 58.7 60.0 77.6 76.4 67.8 66.0 66.8 wine.D68.N178.C3 70.8 82.0 86.5 92.1 92.1 67.4 67.4 71.9 80.9 84.3 91.0 70.8 83.1 27.0 28.1 zoo.D43.N101.C7 88.0 80.0 54.0 62.0 74.0 70.0 74.0 58.0 62.0 62.0 92.0 86.0 78.0 66.0 66.0 Average 71.6 69.6 61.1 71.6 55.0 66.7 66.9 57.9 68.6 51.6 64.7 70.8 71.9 63.2 65.1 Table 1 Classification accuracy 


6. Conclusion In this paper a number of alternative rule ordering and case satisfaction strategies have been considered. Four established ordering strategies were examined. In addition the authors proposed a ?fth strategy, ACS, where more speci?c rules are given a higher precedence than less speci?c rules but using con?dence as the most signi?cant factor for tree pruning during the generation process The principal ?ndings of the evaluation are as follows 1 used in the experiments, \(2 mechanism works better than ìbest î in all the data sets tested, \(3 that a relatively high con?dence threshold is used \(a threshold of % is suggested 4 olds \(% to a ìbest ?rstî case satisfaction produced good results References 1] Agrawal, R. and Srikant, R. \(1994 for mining association rules. Proc. VLDBí94, Morgan Kaufman, pp487-499 2] Bayardo, R.J. \(1997 Confidence Classification Rules. Proc. of 3rd Int. Conf on Knowledge Discovery and Data Mining, AAAI pp123-126 3] Blake, C.L. and Merz, C.J. \(1998 Repository of machine learning databases http://www.ics.uci.edu/ mlearn/MLRepository.html Irvine, CA: University of California 4] Coenen, F., Leng, P., Goulbourne, G. \(2004 Structures for Mining Association Rules. Jo. of Data Mining and Knowledge Discovery, 8\(1 5] Lavrac?, N., Flach, P. and Zupan, B. \(1999 Evaluation Measures: A Unifying View Proc. 9th Int Workshop on Inductive Logic Programming \(ILPí99 Springer-Verlag, pp174ñ185 6] Li W., Han, J. and Pei, J. \(2001 and Efficient Classification Based on Multiple ClassAssociation Rules. Proc ICDM 2001, pp369-376 7] Liu, B. Hsu, W. and Ma, Y \(1998 sification and Association Rule Mining. Proceedings KDD-98, AAAI, pp80-86 8] Yin, X. and Han, J. \(2003 on Predictive Association Rules. Proc. SIAM Int. Conf on Data Mining \(SDMí03 Proceedings of the Fourth IEEE International Conference on Data Mining ICDMí04 0-7695-2142-8/04 $ 20.00 IEEE 


to achieve a high degree of skewness Text documents arranged in a chronological order do appear to have a high degree of skewness and beneﬁt the PMIHP algorithm 4 Conclusions The proposed Parallel Multipass with Inverted Hashing and Pruning PMIHP algorithm is a parallel version of our Multipass with Inverted Hashing and Pruning MIHP algorithm and it is effective for mining frequent itemsets in large text databases The Multipass approach reduces the required memory space at each processor by partitioning the frequent items and pro cessing each partition separately Thus the number of candidate itemsets to be processed is limited at each instance The Inverted Hashing and Pruning is used to prune the local and global candidate itemsets at each processing node and it also allows each processing node to determine the other peer processing nodes to poll in order to collect the local support counts of each global candidate itemset PMIHP distributes the workload to multiple processing nodes to reduce the total mining time without incurring much parallelization overhead The average number of candidate itemsets to be counted at each processing node is much smaller than the case of sequential mining while the time for the synchronization between processing nodes to exchange the count information for the global candidate itemsets is very small compared to the total execution time PMIHP is able to exploit the natural skewed distribution of words in text databases and demonstrates a superlinear speedup as the number of processing nodes increases It has a much better performance than well-known parallel Count Distribution algorithm 2 becaus e the a v erage number of candidate itemsets to be counted at each processing node is much smaller especially when the minimum support level is low Overall the performance of PMIHP is quite scalable even when the size of the text database is large and the minimum support level is low which is the case of high workload References  R  A gra w al and R  S r i kant   Fast Al gori t h ms for M i n i n g A ssociation Rules Proc of the 20th VLDB Conf  1994 pp 487–499  R Agra w a l and J C S hafer  Paral l e l M i n i n g o f A ssoci at i o n Rules IEEE Trans on Knowledge and Data Engineering  Vol 8 No 6 1996 pp 962–969 3 M  S  C hen J Han and P  S  Y u   Dat a Mi ni ng An Overview from a Database Perspective IEEE Trans on Knowledge and Data Engineering  Vol 8 No 6 1996 pp 866–883 4 D  W  C heung S  D L ee and Y  Xi ao  E f f ect of Dat a S k e w ness and Workload Balance in Parallel Data Mining IEEE Trans on Knowledge and Data Engineering  Vol 14 No 3 2002 pp 498–514 5 S  M  C hung and J Y ang  A Par al l e l D i s t r i b ut i v e J oi n A l gorithm for Cube-Connected Multiprocessors IEEE Trans on Parallel and Distributed Systems  Vol 7 No 2 1996 pp 127–137  R  F e l dman and H Hi rsh F i ndi ng Associ at i ons i n Col l ections of Text Machine Learning and Data Mining Methods and Applications  R Michalski I Bratko and M Kubat editors John Wiley and Sons 1998 pp 223–240  R F e l dman I Dagen and H  H i rsh Mi ni ng T e xt Usi n g Keyword Distributions Journal of Intelligent Information Systems  Vol 10 No 3 1998 pp 281–300  C  Fox L e x i cal Anal ysi s and S t opl i s t s   Inforamtion Retrieval Data Structures and Algorithms W.FrakesandR Baeza-Yates editors Prentice Hall 1992 pp 102–130 9 M  G or don and S  Dumai s Usi ng L a t e nt S e mant i c I nde xi ng for Literature Based Discovery Journal of the Amer Soc of Info Science  Vol 49 No 8 1998 pp 674–685  J Han J P e i  and Y  Y i n Mi n i n g F r equent Pat t e r n s w i t hout Candidate Generation Proc of ACM SIGMOD Intêl Conf on Management of Data  2000 pp 1–12  J D Holt and S  M Chung Multipass Algorithms for Mining Association Rules in Text Databases Knowledge and Information Systems  Vol 3 No 2 Springer-Verlag 2001 pp 168–183  J D Hol t and S  M C hung Mi ni ng Associ at i o n R ul es Using Inverted Hashing and Pruning Information Processing Letters  Vol 83 No 4 Elsevier Science 2002 pp 211–220  J D Hol t and S  M C hung Mi ni ng associ at i o n R ul es i n Text Databases Using Multipass with Inverted Hashing and Pruning Proc of the 14th IEEE Intêl Conf on Tools with Artiìcial Intelligence  2002 pp 49–56  J S  Park M S  C hen and P  S  Y u   Usi n g a Hash-B a sed Method with Transaction Trimming for Mining Association Rules IEEE Trans on Knowledge and Data Engineering  Vol 9 No 5 1997 pp 813–825  G  S a l t on Automatic Text Processing The Transformation Analysis and Retrieval of Information by Computer  Addison-Wesley Publishing 1988  E  M V oorhees and D K Harmon edi t o rs The Fifth Text Retrieval Conference  National Institute of Standards and Technology 1997  O R  Z a i a ne and M L  Ant o i ne C l assi f y i n g T e x t D ocuments by Associating Terms with Text Categories Proc of the 13th Australian Database Conf  2002 0-7695-2132-0/04/$17.00 \(C Proceedings of the 18th International Parallel and Distributed Processing Symposium \(IPDPSê04 


  11 could be improved by a simple modification of the feed by adding a small tuning vane to th e feed. Therefore, it can be stated that some improvement can be expected by modification of the feeds, and adaptation of the test antenna in such a way that surrounding Ku-band element are closed   Figure 28 Reflection coefficient of Ku-band stacked patch antenna element in dual-frequency antenna stack  Figure 29 shows the influence of the L-band slots on the return loss of the Ku-band antenna element. To this end, the four connectors of the L-band elements were alternately open and terminated by means of 50 loads. The deviations were measured with respect to the set-up where all connectors were terminated Apparently, the deviations are acceptable  Figure 29 Influence of L-band termination on return loss of Ku-band antenna element, with and without termination Figure 30 and Figure 31 show the isolation between the Lband and Ku-band elements in L-band and Ku-band respectively. To this end the S21-parameters have been measured. These figures reveal that the mutual coupling between the L-band and Ku-band elements is sufficiently small  Figure 30 Measured isolation between L-band and Ku-band antennas in L-band frequencies  Figure 31 Measured isolation between L-band and Ku-band antennas in Ku-band frequencies From these measurements it can be concluded that opportunities should be considered to improve the design of the dual-frequency antenna \(by optimizing the feeds of the Ku-band elements antenna and the measurement set-up \(closure of surrounding Ku-band ports and use of appropriate connectors for the open Ku-band ports 7  M ODIFIED DUAL FREQUENCY ANTENNA  In order to benefit the str ong points of the two separate designs as discussed in section 4, an alternative antenna is proposed that exploits the properties of a \221best of both worlds\222 solution employing ideas from both designs. The modified antenna possesses an aperture fed L-band patch of a similar form to first design, but situated towards the bottom of the stack. Ku band el ements are located within the L-band perforations and para sitic patches are situated above a foam spacer \(see Figure 32 and Figure 33\A measurement campaign is underway to assess the behaviour of this modified test antenna 


  12  Figure 32 Bottom view of dual frequency antenna tile with perforated L-band patc h in lower layer with Kuband patches  Figure 33 Layer stack with perforated L-band patch in lower layer with Ku-band patches  8  B EAM FORMING N ETWORK  A major keystone for the su ccess of phased array antenna onboard aircraft is the capability of steering the main beam in the direction of the geosta tionary satellites. This requires the inclusion of a broadband beam forming network. Beam steering can be realized by adding RF-phase shifters and LNA\222s to the antenna elements of the array. However traditional phase shifters in ge neral have a narrow band, and hence do not yield the re quired broadband capability Alternative technologies for broadband beam forming are switched beam networks \(using Butler matrices innovative designs for RF-compone nts such as phase shifter LNA components in \(M\IC technology, or beam forming by using opti cal ring resonators  The German SME IMST is involved in several projects for development of electronica lly steerable phased array antennas for satellite communication. In the NATALIA project \(New Automotive Track ing Antenna for Low-cost Innovative Applications\ ESA, IMST is investigating the possibility of realizing a compact costeffective solution for a recei ve-only full electronically steerable antenna for cars in Ku-band. This antenna is a planar array composed of approximately 150 patches circularly polarised by using a 90\260 hybrid, and arranged in a hexagonal fashion. Each patc h is equipped with a MMIC corechip containing a phase sh ifting unit, LNA and digital steering logic  In the Netherlands, a consortiu m \(consisting of University of Twente, Lionix BV, National Aerospace Laboratory NLR and Cyner Substrates developing in the national FlySmart project technology for a broadband optical beam forming network. For the steering of the beam of the conformal phased array a squi nt-free, continuously tunable mechanism is proposed that is based on a fully integrated optical beam forming network \(OBFN optical ring resonators \(ORRs as tunable delay elements. A narrowband continuously tunabl e optical TTD device is realized as a recirculating wa veguide coupled to a straight waveguide. This straight wave guide can behave as a bandpass filter with a periodic, bell-shaped tunable group delay response. The maximum group delay occurs at a tunable resonance frequency. A larger delay-bandwidth product can be achieved by cascading multiple ORR sections. A complete OBFN can be obtaine d by grouping several delays and combining elements in one optical circuit. Such an OBFN can be realized on a si ngle-chip. Electrical/Optical E/O O E by means of filter based single-sideband modulation suppressing the carrier lanced coherent optical detection. Further details of the optical beamforming network have been presented in Re The proof-ofconcept has been shown by manufacturing a chip for an 8x1 OBFN. Essential components of the OBFN are the optical modulators, which are used to modulate the light in the ORR system 9  C ONCLUSIONS  For enhanced communicati on on board aircraft, novel antenna systems with broa dband satellite-based capabilities are required. So far, existi ng L-band satellite based systems for communications are used primarily for passenger application \(APC\i nistrative communications AAC and now data are tending to evolve towards broadband dig ital applications \(Voice over IP\any studies are going on worldwide to employ Kuband TV geostationary sate llites for communication with mobile terminals on aircraft The inbound traffic is about 5 times higher than the outbound The inbound traffic requires the availability of a broadband Ku-band antenna in receive mode only. The outbound traffic services can be supplied by the Inmarsat SBB link, whic h requires the installation of an L-band transmit antenna. In order to avoid both the installation of L-band antenna and Ku-band antenna, the concept of a hybrid dual frequency antenna operating L 


  13 band and Ku-band with low aerodynamic profile has been investigated in this paper. Keyaspects of this research are 200  Design and testing dual-fre quency antenna elements operating in both L-band and Ku-band 200  Conformal aspects of Ku-band phased array antennas 200  Beam forming algorithms for planar and conformal phased array antennas Two designs for dual-frequency antenna tiles consisting of 8x8 Ku-band antenna elements and one L-band element The designs have been analysed by means of computer simulations. Both designs show promising performance both in L-band and Ku-band. The design with slotted Lband antenna has a resonant fre quency in receive mode with a bandwidth of about 1 GHz. The Ku-band antenna is a stacked patch configuration where a parasitic element is placed above a lower patch separated by dedicated space filler. The manufactured protot ype antennas indicate that the bandwidth is sufficiently large In order to be able to communicate with geostationary satellites also at high latitudes e.g. during inter-continental flights\stem should have sufficient performance at low elevation angles. The antenna Ku-band system is required to have a small beamwidth \(to discriminate between the satellite signals\gain 30 dB angles. The effects of these requirements on the size and positioning of the antenna on the aircraft fuselage have been investigated. These requirements can be best satisfi ed by installing two planar phased array antennas on both side s of the fuselage with at least 1600 Ku-band elements. Each element has two feed lines, one for each polarization Every feed line has to be connected to the beam formi ng network. This means that the connections cannot be routed to one of the four sides of the antenna. Instead the concept of vertical feed lines \(by means of vias in a sufficiently thick substrate recommended. These vertical f eed lines connect the L-band and Ku-band antenna elements in the upper layer with feed networks in multiple lower laye rs. This vertical feed line system was not available so far due to manufacturing problems The performances of one dua l-frequency antenna design have been investigated by manufacturing two test antennas without vertical feed line syst em. The first antenna contains only a multilayer structure with L-band slots and 8x8 Kuband stacked patches. The performances of the L-band slots and Ku-band stacked patches c ould be measured separately It was concluded that opportun ities should be considered to improve the design of the dual-frequency antenna \(by optimizing the feeds of the Ku-b and elements the dual frequency test-antenna and the measurement set-up More important, however, is the realization of a mechanically stable vertical feed line system, so that the properties of L-band and Ku-band elements can be measured adequately The second test antenna contains only a multilayer structure with 8x8 Ku-band stacked patches and a feed network with 8 combiners, where each comb iner coherently sums 8 antenna elements. In combination with a prototype 8x1 OBFN, a Ku-band phased arra y antenna is obtained of which the beam can be steered in one direction. This second test antenna is used to analyze the broadband properties of the 8x8 Ku-band antenna array and 8x1 OBFN. The measured performances of this antenna are presented in Ref   A CKNOWLEDGMENT  This work was part of the EU 6 th Framework project ANASTASIA., and the FlySmart project, supported by the Dutch Ministry of Economic A ffairs, SenterNovem project numbers ISO53030 The FlySmart project is part of the Eureka PIDEA  project SMART Cyner Substrates is acknowle dged for technical assistance during the fabrication of the prototype antennas 


  14 R EFERENCES  1  P. Jorna, H. Schippers, J. Verpoorte, \223Beam Synthesis for Conformal Array Antennas with Efficient Tapering\224 Proceedings of 5 th European Workshop on Conformal Antennas, Bristol, September 11-12, 2007 2  The Radio Regulations, editi on of 2004, contain the complete texts of the Radio Regulations as adopted by the World Radio-communication Conference \(Geneva WRC-95 tly revised and adopted by the World Radio-communication Conference WRC-97\RadioWRC2000\and the World Radio-communication Conference WRC-03 Resolutions, Recommendations and ITU-R Recommendations incorporat ed by reference 3  RECOMMENDATION ITU-R M.1643, Technical and operational requirements for ai rcraft earth stations of aeronautical mobile-satellite service including those using fixed satellite service network transponders in the band 14-14.5 GHz \(Earth-to-space 4  ETSI EN 302 186 v1.1.1 \(2004-01 Stations and Systems \(SES\onised European Norms for satellite mobile Aircraft Earth Stations AESs\the 11 12/14 GHz frequency bands covering essential requirement s under article 3.2 of the R&TTE directive 5  EUROCAE ED-14E; Environmental Conditions and Test procedures for Airbor ne Equipment, March 2005 6  F. Croq and D. M. Pozar, \223Millimeter wave design of wide-band aperture-coupled stacked microstrip antennas,\224 IEEE Trans. Antennas Propagation, vol. 39 pp. 1770\2261776, Dec. 1991 7  S. D. Targonski, R. B. Waterhouse, D. M. Pozar Design of wide-band aperture stacked patch microstrip antennas ", IEEE Transactions on Antennas and Propagation, vol. 46, no. 9, Sep. 1998, pp. 1245-1251 8  R. B. Waterhouse, "Design of probe-fed stacked patches", IEEE Transactions on Antennas and Propagation, vol. 47, no. 12, Dec. 1999, pp. 1780-1784 9  D.M. Pozar, S. D. Targonski, \223A shared aperture dualband dual-polarised microstrip array\224, IEEE Transactions on Antennas and Propagation,Vol. 49 no. 2,Feb. 2001, pp. 150-157 10  http://www.ansoft.com 11  J-F. Z\374rcher, F.E. Gardiol, \223Broadband patch antennas\224 Artech House, \(1995\N 0-89006-777-5 12  H. Schippers, J. Verpoorte, P. Jorna, A. Hulzinga, A Meijerink, C. G. H. Roeloffzen, L. Zhuang, D. A. I Marpaung, W. van Etten, R. G. Heideman, A. Leinse, A Borreman, M. Hoekman M. Wintels, \223Broadband Conformal Phased array with Optical Beamforming for Airborne Satellite Communication\224, Proc. of the IEEE Aerospace Conference, March 2008, Big Sky, Montana US 13  H. Schippers, J. Verpoorte, P. Jorna, A. Hulzinga, L Zhuang, A. Meijerink, C. G. H. Roeloffzen, D. A. I Marpaung, W. van Etten, R. G. Heideman, A. Leinse M. Wintels, \223Broadband Op tical Beam Forming for Airborne Phased Array An tenna\224, Proc. of the IEEE Aerospace Conference, March 2009, Big Sky, Montana US 


  15  B IOGRAPHIES  Harmen Schippers is senior scientist at the National Aerospace Laboratory NLR. He received his Ph. D. degree in applied mathematics from the University of Technology Delft in 1982. Since 1981 he has been employed at the National Aerospace laboratory NLR. He has research experience in computational methods for aero-eleastics, aeroacoustic and electromagnetic problems. His current research activities are development of technology for integration of smart antennas in aircraft structures, and development of computational tools for installed antenna analysis on aircraft and spacecraft  Jaco Verpoorte has more than 10 years research experience on antennas and propagation Electromagnetic compatibility \(EMC and radar and satellite navigation He is head of the EMC-laboratory of NLR. He is project manager on several projects concerning EMCanalysis and development of advanced airborne antennas    Adriaan Hulzinga received his BEng degree in electronics from the hogeschool Windesheim in Zwolle Since 1996 he has been employed at the National Aerospace laboratory \(NLR as a senior application engineer. He is involved in projects concerning antennas and Electromagnetic compatibility \(EMC  Pieter Jorna received the M.Sc degree in applied mathematics from the University of Twente in 1999 From 1999 to 2005 he was with the Laboratory of Electromagnetic Research at the University of Technology Delft. In 2005 he received the Ph.D. degree for his research on numerical computation of electromagnetic fields in strongly inhomogeneous media Since 2005 he is with the National Aerospace Laboratory NLR\ in the Netherlands as R&D engineer   Andrew Thain is a research engineer in the field of electromagnetic modelling of antennas. He specialises in the use of surface integral methods for the calculation of coupling and radiation patterns and works closely with Airbus on the topic of antenna positioning. He has experience in the field of electromagnetic modelling  Gilles Peres is head of the Electromagnetics group of EADS-IW He has a wide experience in computational EM modelling particularly the use of FDTD, integral and asymptotic techniques for antenna structure interactions. He has contributed with Airbus experts to the certification campaign of the A340/500 and A340/600. Dr Peres holds a PhD thesis from University of Toulouse \(1998\ on impulsive Electromagnetic Propagation effects through plasma   Hans van Gemeren has a BEng degree in electronics. From the beginning of Cyner substrates he is involved in development and production of prototyping and nonconventional Printed Circuit boards Working mainly for design and research centers Cyner got involved in many high tech projects and from this developed a great expertise in the use of different \(RF materials. In the FlySmart project Hans and his colleagues are able to do what they like most: In close cooperation with designers, creatively working on substrate solutions 


  16  


NIMBUS NOAA 8 NOAA 15 NPOESS Preparatory Project Orbital Maneuvering Vehicle Orbcomm Orbiting Carbon Observatory Orbiting Solar Observatory-8 Orbview 2 Orion 1 P78 Pas 4 Phoenix Pioneer P-30 Pioneer Venus Bus/Orbiter Small Probe and Large Probe Pioneer-I 0 Polar QuikSCAT Radarsat Reuven High Energy Solar Spectroscopic Imager REX-II Rosetta Instruments Sage III SAMPEX Satcom C3 Satcom C4 SBS 5 SCATHA Seastar SMART-1 SNOE Solar Dynamics Observatory Solar Maximum Mission Solar Mesosphere Explorer Solar Radiation and Climate Experiment Solar Terrestrial Relations Observatory Space Interferometry Mission Space Test Program Small Secondary Satellite 3 Spitzer Space Telescope SPOT 5A Stardust  Sample Return Capsule STEPO STEPI STEP3 STEP4 STRV ID Submillimeter Wave Astronomy Satellite Surfsat Surveyor Swift Gamma Ray Burst Exporer Synchronous Meterological Satellite-I TACSAT TACSAT 2 TDRS F7 Tellura Terra Terriers Tethered Satellite System Thermosphere Ionosphere Mesosphere Energetics and Dynamics TIMED TIROS-M TIROS-N TOMS-EP Total Ozone Mapping Spectrometer TOPEX TRACE Triana Tropical Rain Measuring Mission TSX-5 UFO I UFO 4 UFO 9 Ulysses Upper Atmosphere Research Satellite Vegetation Canopy Lidar VELA-IV Viking Viking Lander Viking Orbiter Voyager Wilkinson Microwave Anisotropy Probe WIND WIRE XMM X-Ray Timing Explorer XTE XSS-iO XSS-ii APPENDIX B FIELDS COLLECTED Mission Mission Scenario Mission Type Launch Year Launch Vehicle Bus Model Bus Config Bus Diameter Location Expected Life Flight Profile Flight Focus Technical Orbit Currency Total Cost Including Launch Unit Sat Costs Average Sat Cost Production Costs Launch Costs Operations Cost Orbit Weight Wet Weight Dry Weight Max Power EOL Power BOL Power  of Batts 17 


Batt Power Batt Type Stabilization Type Propulsion Mechanism  of Solar Panels  of Solar Cells Manufacturing Qty Satellites in Constellation On-Orbit Spares Channels Number of Bands Data Storage Processing Power Source type Block Name Thermal Control Material Type Level of Technology Known Inheritance Propulsion station keeping Number of Axes Ground Based Spares Pointing Accuracy APPENDIX C EXISTING MODELS Numerous models are today in use for estimating spacecraft cost Two of the most common are the NASA/Air Force Cost Model and the Aerospace Small Satellite Cost Model Here is a description of the NAFCOM model The NASA/Air Force Cost Model NAFCOM is a parametric estimating toolfor space hardware It is based on historical NASA and Air Force space projects and is primarily used in the very early phases of a development project NAFCOM can be used at the subsystem or component levels The database currently includes 122 missions including 76 unmanned earth orbiting 24 unmanned planetary 11 launch vehicles 8 manned 3 engines It uses parametric relationships to estimate subsystem or component level costs for any aerospace hardware including earth orbital spacecraft manned spacecraft launch vehicle upper stages liquid rocket engines scientific instruments or planetary spacecraft 7 And for the Aerospace Small Satellite Cost Model SSCM employs a parametric methodology for estimation of program cost and is best suited to the early conceptual development phase of a spacecraft program during which time the design is likely to be less mature and when cost and performance trades can be easily performed SSCM consists of a collection of cost-estimating relationships or CERs which estimate the costs of developing andproducing a spacecraft system with the following subsystems  Attitude Determination and Control Subsystem ADCS  Propulsion  Power  Telemetry Tracking  Command TT&C  Command  Data Handling C&DH  Structure  Thermal CERs were also developed for integration assembly and test IA&T program management PM and systems engineering SE and launch and orbital operations support LOOS Individual subsystem cost estimates are statistically rolled up to yield a cost-risk distribution which provides the estimator with a range of cost estimates andpercentiles 8 The SSCM was calibrated from over 100 post-1990 Earth-orbiting andplanetary missions REFERENCES 1 Lack of Disciplined Cost-Estimating Processes Hinders Effective Program Management GAO study 04-642 2 Jilla Cyrus D and Miller David W Satellite Design Past Present and Future International Journal of Small Satellite Engineering 12 February 1997 3 Bearden David A A Complexity Based Risk Assessment of Low-Cost Planetary Missions:When Is A Mission Too Fast and Too Cheap Fourth IAA International Conference On Low-Cost Planetary Missions JHU/APL MAY 2-5 2000 4 Kellogg Mahr and Lobbia An Analogy-based Method for Estimating the Costs of Spacecraft IEEEAC paper 1371 Version 4 5 Hoeting Jennifer A Methodology for Bayesian Model Averaging An Update f 6]btp/ewiieiao iiAaos 7 Keith Smith NASA/Air Force Cost Model Science Applications International Corporation 8 18 


BIOGRAPHIES Lee Fischman served as Principle Investigator for this project Lee is Senior Director of Development at Galorath Incorporated where he directs much of the new product development and research at the firm He developed SEER for Software  Hardware Integrations with Microsoft Project the Comparison Sizing tool COTS Software model in addition to various data mining information extraction and expert systems Previously he was a software designerlprogrammer in the New York financial industry Lee earned a BA from the University of Chicago and an MA from UCLA both in economics Mike Kimel carried out statistical work on the project Mike is an Economist for Galorath Inc in addition to maintaining his own quantitative consulting practice He has also taught Economics and Advanced Statistics at the Graziadio School of Business and Management at Pepperdine University run the Competitive Strategy group for a Fortune 500 Telecom Company and worked as a Consultant at PriceWaterhouse LLC now PriceWaterhouse-Coopers He earned a Ph.D in Economicsfrom UCLA Troy Masters programmed analytic methods and is integrating the Far Out model into its parent product SEER for Hardware previously SEER-H Troy is a Software Engineer with Galorath Incorporated where he has been the primary developer for a range ofproducts He earned a BS in computer science from UCLA David J Pine was our subject matter expert helping us assemble data and gain insight into technical trends Dave is retired after a 34-year career with the National Aeronautics and Space Administration NASA currently is a consultant to various government and industry entities While at NASA his organizations in the Office of the Chief Financial Officer and later at the IPAO at Langley Research Center were responsible for the conduct of major NASA program analyses and evaluations for the NASA Administrator and Deputy Administrator From early 1988 through the end of 1990 he was the Deputy Program Manager for the Hubble Space Telescope Program specifically responsible for the telescope operations and science support aspects of the program He earned a BS in Aerospace Engineering from the Polytechnic Institute of Brooklyn and a Masters of Engineering Administration from the George Washington University 19 


  20 Angeles, where he also received a B.S. in Applied Mathematics  Eric Fetzer is a Senior Member of the Technical Staff at the Jet Propulsion Laboratory, Pasadena, California specializing in satellite observations of the atmosphere.  His scientific interests include planetary boundary layer processes, tropical phenomena, upper tropospheric variability, and climatologies of temperature, water vapor and clouds.  His technical interests include analysis of large data sets, and of multi-sensor observations. He has over 20 peer-reviewed publications and given numerous scientific presentations, public lectures and media interviews about climate science. Eric received a B.A. in Physics from the University of California Berkeley, and a Ph.D. in Astrophysical, Planetary and Atmospheric Sciences from the University of Colorado, Boulder   Amy Braverman is a Senior Statistician at the Jet Propulsion Laboratory, California Institute of Technology She holds a B.A. in Economics from Swarthmore College an M.A. in Mathematics from UCLA, and a Ph.D. in Statistics also from UCLA. Prior to her current position in JPL's Science Data Understanding Group, she was a Caltech Post-doctoral Scholar at the Jet Propulsion Laboratory, and a Scientist in the Flight Sciences Experiments Section of the Science Division. Dr Braverman conducts research on information-theoretic methods for the analysis of massive data sets and streams statistical data fusion, high-dimensional data analysis, and statistical analysis for climate model evaluation and diagnosis. She has published in both the statistics and geoscience literature, and is active in both communities She is a member of the Multi-angle Imaging SpectroRadiometer Science Team, and serves as a member of the Atmospheric Infrared Sounder Science Integration Team. Her responsibilities on both missions include designing data reduction algorithms for massive, remote sensing data sets. Dr. Braverman also holds an appointment in the Department of Statistics at UCLA as Adjunct Associate Professor, and is active in UCLA\222s Center for Environmental Statistics. She is member of the Committee on Applied and Theoretical Statistics of the US National Academy of Science. She has refereed for the Journal of the American Statistical Association, the Journal of Computational and Gr aphical Statistics, IEEE Transactions on Geoscience and Remote Sensing, and the Journal of Applied Meteorology and Climatology Seungwon Lee is a senior member of the High Capability Computing and Modeling Group at Jet Propulsion Laboratory. She is conducti ng research on comet gas dynamics, nonlinear dynamics control, climate model parameterization, Earth science data analysis, parallel computing, and advanced numerical algorithms. She received her Ph.D in Physics fr om the Ohio State University and her M.S. and B.S. in Physics from the Seoul National University, Korea  Matthew Henderson is software engineer in the High Capability Computing and Mode ling group at JPL. His current work includes Web Services and Instrument Data Level 2 subsetting. He received a B.S. Computer Science from CSU Pomona, and is currently pursuing M.S Computer Science  Steven J. Lewis is a member of the Information System and Computer Science staff member at the Jet Propulsion Laboratory.  He received a BS in Mathematics from the University of California, Los Angeles in June 2001, and the MS and Ph.D. Degree from Claremont Graduate University in May 2004 and May 2007, respectively.  He worked as a post doctoral fellow at Keck Graduate Institute from June 2007 until he joined JPL in March of 2008.  During his graduate and post doctoral work, his studies focused on applications of Bayesian methods to hidden Markov models with particular interest and application to protein sequencing.  His work at JPL has focused on integrating web services into various programming platforms for the purposes of accessing NASA satellite data, as well as developing object tracking so ftware and contributing to image enhancement and restoration efforts Van Dang is a member of the Science Data Understanding Group at the Jet Propulsion Laboratory. She was responsible for the NEWS Level 2 processing that generated the formal merged Level 2 data from multiple A-Train instruments  Manuel de la Torre is a Physicist from the Universidad Complutense at Madrid \(Spain\. After finishing his Ph.D work at the University of Bayreuth \(Germany\ on pattern formation in turbulent flows and a 7 1/2 year stunt as Ass and Assoc. Prof. at the Escuela T\351cnica Superior de Ingenieros Aeron\341uticos in Madrid \(Spain\, he came to the Jet Propulsion Laboratory on a 1-year Sabatical leave in 1997 wanting to apply fundamental concepts of nonlinear systems and geophysical fluid dynamics to something that might be directly useful to soci ety. He discovered the JPL as a great place to achieve that goal and extende d his stay a bit longer, becoming Technical staff and working on different aspects of remote sensing, validation of satellite instruments, and data analysis of atmospheric processes and climate  


