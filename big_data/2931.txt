A System for Mining Generalized Association Rules with Ontology Using Genetic Network Programming Guangfei Yang, Kaoru Shimada, Shingo Mabu, Kotaro Hirasawa and Jinglu Hu Graduate School of Information, Production and Systems, Waseda Universit\y yang@fuji.waseda.jp, k.shimada@aoni.waseda.jp, mabu@waseda.jp, hirasawa@\waseda.jp jinglu@waseda.jp Abstract In this paper, we propose a Genetic Network Programming based system to mine equalized association rules in multi c oncept layers of ontology There are three s in this system: Database Equalizer and GNP Miner. We first introduce ontology to facilitate building the multi concept layers in Database module and propose Dynamic Threshold Approach \(DTA\ to equalize the different layers in Equalizer. We make use of an evolutionary computation method Genetic Network Programming GNP\ to mine the rules and develop a new genetic operator to speed up searching the rule space 1. Introduction Association rules in multi concept layers, also known as generalized association rules, or multiplelevel association rules, could provide more information at mu  and Fu\222s method  a taxonom y should be first defined, and rules are discovered between concepts only within the same method does not have this limitation, which could find rules among all the concepts in every layer.  But these methods have some shortcomings 1 Hard to build a taxonomy: When a data mining expert wants to start mining the generalized association rules, he or she always should first build the taxonomy without any tool or methodology to help building and maintaining the taxonomy 2 Inequality among layers: If we mine rules among all the concept layers, most items in rules are picked up only from the upper concept layers 3 Wait for too many rules: The traditional methods usually could not give a single rule until finishing the whole calculation and result in too many rules after the whole calculation especially when dealing with large database In our system, we propose some new methods to solve these problems. There are three key features in our methods 1 Use ontology instead of taxonomy: We build and maintain our ontology instead of simple taxonomy by means with different data mining experts 2 Equalize layers: We propose a Dynamic Threshold Approach to select a certain percentage of classes in each layer for rules mining by using different minimum support thresholds in different layers 3 Use evolutionary method: Genetic Network Programming is applied to mine rules generation by generation 2. System Architecture In Figure 1, we demonstrate the main components of our system. Generally speaking, there are three parts Database, Equalizer and GNP Miner In Database, transaction records, ontology library and rule pool are stored. We fi rst build the ontology to describe the classes and relations in a specific domain In order to mine generalized association rules, the traditional plain transaction records should be transferred into Hierarchical Transaction. Protege accesses Database by JDBC API while other modules connect Database by ODBC API Because it is found that the classes in different layers have unequal chance to appear in the generalized association rules, we develop an Equalizer to equalize layers comparatively 0-7695-2882-1/07 $25.00 \2512007 IEEE 


Genetic Network Programming is introduced to mine the association rules and we employ a new genetic operator, named renewal, to explore the global rule space more efficiently 3. Ontology based Generalized Association Rules Generalized association rules, also known as multiple-level association rules, could provide more information at multiple concep t  of hierarchical taxonomy has been introduced into generalized association rules mining. In Han and Fuís method ong concept item s  only within the same layer of the hierarchy A ontology is a formal a nd explicit specification of shared conceptualization   In the field of association rule mining, we introduce ontology to describe and share the understanding of the concepts in the mining domain, and find numerical information behind the concepts The items in the traditional transaction are replaced by instances in ontology, but the instances are not used for mining rules directly. The traditional transactions should be transfered into Hierarchical Transaction. In Hierarchical Transaction, the elements of each transaction consist of the classes in ontology instead of the instances. Let T  t 1  t 2  t i  t m be a set of transactions, and S  s 1  s 2  s j  s n be the instance set in the ontology, where n is the number of instances Each transaction is a subset of S i.e t i  s i 1  s i 2  s ik  s ip where p is the number of goods in each transaction. Let the set of classes in the ontology be denoted by C  c 1  c 2  c l  c q where q is the number of classes. There are is a relations between instances and classes. That is, instance s j belongs to a class and the super classes of this class, and we define these classes as Ancestor Classes of s j denoted by Ance  j s  The Hierarchical Transaction is denoted by and each element of Hierarchical Transaction is denoted as whose element   12     im T tttt    12     iii ikip tss ss  ik s consists of the Ancestor Classes of the instance s ik that is   ik ik  equal i zati on transaction ontology hierarchical transaction initial generation mine rule crossover mutation of content mutation of conne ction renewal rule pool meaningfulness check re dundancy check store rule G N P  M i n e r end protege D a t a b a s e Modul e Informati on Fl ow Program Flow selection E q u a l i z e r Dataset J D B C O D B C Fig ure 1 System Architecture  s Ance s  4. Equalization of Classes from Different Layers If we mine rules among classes from all the layers most of the items in rules may be from the upper layers because the frequencies of the classes in the upper layers are much larger. We propose Dynamic Threshold Approach \(DTA from different layers in order to overcome the above problem First of all, some notations are defined to describe our method Definition 1: SUP min  l  SUP min  l inimum support value in layer l  When we check a candidate rule r if all the classes are from layer l the support value of r Support  r  should satisfy Support  r  SUP min  l want to store it into the rule pool If these classes are from different layers, there are three methods to get the minimum support value maximum method, minimum method and average method In order to calculate SUP min  l we define Candidate Class Rate \(CCR Definition 2: CCR l  Given a certain layer l CCR l  of the number of classes in layer l whose support value is bigger than SUP min  l  chance to be explored as the items in association rules while the other classes in this layer are deleted For example, there are ten classes with support 


values in layer l in Table 1. We first sort the support values in descending order. If CCR l is set at 0.5 C 4  C 8  C 2  C 5 would have the chance to appear in the association rules and the other five classes are excluded. SUPL l  5. GNP based Rules Miner 5.1. Genetic Network Programming Genetic Network Programming \(GNP extension of GP, which uses directed graphs as genes for evolutionary computa   structure of GNP has three kinds of nodes: a Start Node, some Judgment Nodes and some Processing Nodes. The start node is a special node, indicating the first position to be executed. Judgment nodes receive the information from the environment and determine the next node to be executed. Processing nodes represent some functional actions that could be taken GNP evolves the graph structure with the predetermined number of nodes, and reuses these judgment nodes and processing nodes during the execution. As a result, it could be quite compact and efficient and never cause the bloat When applying GNP to data mining, it is predigested into a kind of chain structure in Figure 2 Randomly Connected Chain \(RCC\s in RCC are not only selected random ly, but also connected randomly, which could have one next item and multiple previous items 5.2. Fitness Function There are two kinds of fitness functions defined in our method: Fitness of Individual \(FI\of Class \(FC\e first define One Step Reward \(OSR\to make use of the reward difference between the current generation and the previous generation Definition 3: OSR After executing the g 1\suppose M c  g 1 c are produced. Then after the g th generation, suppose M c  g  containing class c are produced. We call M c  g  M c  g  M c  g 1\Reward \(OSR\of class c  Table 1  Support values of classes C 1 C 2 C 3 C 4 C 5 C 6 C 7 C 8  0.30 0.57 0.12 0.88 0.53 0.40 0.37 0.59 without order Definition 4: FI FI is the fitness of individuals used for selection C 4 C 8 C 2 C 5 C 6 C 7 C 1 C 3 0.88 0.59 0.57 0.53 0.40 0.37 0.30 0.12  with order  We introduce two methods to calculate FI for individuals: Number Policy Method and OSR Policy Method. When applying Number Policy Method, the fitness value of individual i in the g th generation is described by Equation 1 FI i  g  N i  g  1 where N i  g ber of rules individual i produces in the g th generation When applying OSR Policy Method, FI of individual i is defined as If N max  g  N min  g  min max min arctan     1 FI        2 c i icC i Mg Ng N g g NgNg 2   1 1       1 cc c ii i c i Mg Mg g Mg Mg g  3 where N min  g  N max  g is the minimum and maximum number of rules individuals produce in the g th generation  c i M g is the number of rules including class c individual i produces in the g th generation, and C is the set of classes in the rules that individual i produces  c i M g is OSR value. It could be easily inferred that 0 FI i  g  C=1 B=1 E=1 A=1 D=1 F=1 1 P 2 P 4 P 5 P 3 P 6 P SP  Figure 2.  Randomly connected chain FI i  g ainly describes the potential ability of an individual to find new rul es. Considering the two major parts in FI i  g in Equation 2, the first part measures the potential ability contributed by the individual while the second part represents the potential ability contributed by the judgment items of the individual If N max  g  N min  g  i  g  N max  g  N min  g  0, FI i  g  Definition 5: FC FC is the fitness of classes used for the selection of classes. There are also two methods to calculate FC for classes: Number Policy Method and OSR Policy Method. When applying Number Policy Method, FC 


of class c in the g th generation is FC c  g  M c  g  4 where M c  g ber of rules containing class c produced in the g th generation When applying OSR Policy Method, the FC of class c in the g th generation is defined as If max  c M g min  c M g   min max min     arctan   1 FC        2 cc c c cc Mg M g Mg g MgMg 5   1 1       1 cc c c Mg Mg g Mg Mg g  6 where min  c M g  M  min cC c  g  max  c M g  M  max cC c  g  and C is the set of classes in the rules produced by all the individuals in generation g We could infer that 0 FC c  g  If max  c M g  min  c M g 0, FI c  g  If max  c M g  min  c M g 0, FI c  g  5.3. Genetic Operators There are four kinds of genetic operators in our method: crossover, mutati on of content, mutation of connection and renewal Crossover operation is shown in Figure 3, and here we use only one crossover point There are two kinds of mutation in GNP: mutation of content and mutation of connection shown in Figure 4 and Figure 5. We select classes randomly from class library to perform mutation of content Renewal operator selects classes from ontology class library according to their FC values to form the brand new individuals. This process is similar to the creation of the initial individuals, but renewal has considered the FC values of each class which could not be considered for the initial stage. The reason for introducing renewal operator is that we want to find useful individuals as many as possible. Renewal can let some individuals jump to the brand new search spaces more immediately than crossover and mutation 5.4. Meaningfulness Assurance When we say that a rule is meaningful, it means that this rule cannot be deduced di rectly by other rules. For example, if rule AB and B Ance  A  rule is not meaningful, because it can be simply deduced from B Ance  A  We ensure the meaningfulness by deleting the meaningless part of the rules when checking the candidate rules. For example, in Fig. 4, when checking the candidate rule \(A,B C of A, we can delete B from the candidate rule and check a new candidate rule \(A C frequency of the classes in this new candidate rule should be counted again 6. Conclusion In this paper, we propose a system to extend the generalized association rul es mining by ontology and introduce Dynamic Threshold Approach to equalize the different layers of ontol ogy. We also apply Genetic Network Programming to mine rules generation by generation and use a new genetic operator renewal to explore the global rule space more efficiently  C B A D J I H K J B A K C I H D Crossover Figure 3.  An example of crossover R EFERENCES  J. Han and Y Fu Discovery  of Multiple-Level Association Rules from Large Database Proceedings of the 21st International Conference on Very Large Data Bases  Zurich, Switzerland, pp. 420-431, 1995 C B A D H B A D Mutation of Content Figure 4.  An example of mutation of content   R Srikant and R. Agrawal, ìMining generalized association rules Proceedings of 21th International Conference on Very Large Data Bases Santiago, Chile, pp 407-419, 1995 C B A D C B A D Mutation of Connection Figure 5.  An example of mutation of connection  Protege. http://protege.stanford.edu 4 T. R. Gruber, ìTowards Principles for the Design of Ontologies Used for Knowledge Sharing International Journal of Human and Computer Studies 43\(5/6 928,1995  and J. Hu, ìA Graph-Based Evolutionary Algorithm: Genetic Network Programming GNP\Reinforcement Learning Evolutionary Computation MIT Press, to appear  K Shimada K. Hirasawa and J. Hu, ìGenetic Network Programming with Acquisition Mechanisms of Association Rules Journal of Advanced Computational Intelligence and Intelligent Informatics Vol. 10, No. 1, pp. 102-111 2006 


a user-specified minimum support and confidence respectively, where X and Y are sensor readings from different sensors, s is the percentage of reading rounds that contain both X and Y, called support of the rule, and c is the percentage of reading rounds containing X that also contain Y, called the confidence of the rule. The task of mining association rules then is to find all the association rules among the sensors which satisfy both the user-specified minimum support and minimum confidence Experimental results show that WARM performs better than the average approach where the average reading reported by all sensors in the window is used for estimation. However WARM treats all sensor readings in the window to be of equal importance regardless of when the readings were obtained, i.e all the sensor readings would contribute equally to the estimation of a missing data value in the current round of readings.    This treatment does not reflect the temporal nature of sensor data in many data stream applications, such as those that use sensors to monitor environmental conditions.  In those applications, the more recent a sensor reading is, the more relevant it is in answering queries that are based on the current sensor data. For example, the temperature collected at 2 PM is more similar to that collected at 2:05 PM than the one reported at 10 PM.  So, to estimate the temperature that was missing i.e. did not get reported\t 2 PM due to a sensor data lateness/loss/corruption, the temperature reported at 2:05 PM should contribute more than the one reported at 10 PM. to the estimation To address the temporal sensor data problem, we have developed a new algorithm, called FARM \(Freshness Association Rule Mining\.  Here, we provide the key ideas and results of FARM; interested readers are referred to r more detailed descriptions.   FARM associates a freshness value, called round weight, to each round of sensor reading The more recent a round of sensor readings is, the higher round weight it has in computing the estimated value for the missing data in the current round. Like WARM, FARM also uses association rule mining to find the relationships between sensors; however, with the inclusion of round weights, the relationships discovered by FARM reflect the temporal correlations between sensors as the time element manifests itself in many data stream applications. After identifying the related sensors through data mining, FARM computes the estimated value of the missing sensor reading based on the weighted average of the current readings of the sensors related to the sensor with the missing reading To reduce space overhead, FARM implements a data structure that compacts raw stream data by means of round weights. Data held in that structure is the result of a formula that creates a mapping between a sequence of raw data and a resultant datum and thus requiring a much less space. Only compacted data is needed for estimation. This makes it possible to hold an efficient number of data rounds, which offers an advantage over the typical sliding window solution used in many data stream mining algorithms. Sliding window approaches typically suffer a tradeoff between a large space requirement and being able to store enough samples to recognize patterns given the chosen window size Additionally, limiting their amount of data stored makes them systematically unfit to answer data stream queries.  With the data compaction scheme, space overhead to compute association rules is reduced, which in turn, reduce access time to data needed to perform data estimation  To recapitulate, it is this duality between the data freshness  and the data compaction scheme as well as their positive implications on the space and time complexities that derive the motive of the FARM method  C. Missing Data Validation for the Attacked Mode Using a climate sensing data set [25 w h er e th e t e m p o r al characteristic of sensor data exists, we have performed experiments comparing FARM, WARM and existing data estimation algorithms: SPIRIT [26 T i n y D B  2 7  S imp le  Linear Regression \(SLR\, Multiple Linear Regression \(MLR Curve Regression \(CE\, and estimation by average \(Avg   The accuracy of the estimation is evaluated using the normalized root mean square error RMSE As shown in Table 1, FARM yields the best data estimation accuracy with 23.43% less error than the second best method \(WARM\ and 98.59% less error than the worst method \(CE  Method RMSEs for Climate Sensing data How many % the best approach is better FARM 0.00487 Best Approach WARM 0.00636  23.43  TinyDB 0.0085 42.71 SPIRIT 0.0116  58.02  Average 0.015  67.53  MLR 0.121  95.98  SLR 0.342  98.58  CE 0.346  98.59  Table 1 RMSEs for Climate Sensing Data Set  IV  C ONCLUSION AND P ERSPECTIVES  This paper proposed a new approach of modeling the collaboration of sensor system artifacts to address the security and survivability concerns of sensor networks. The model considered is composed of sensors, base and users. Sensors are nodes that acquire and process data. Base is the node that acquires and processes data from sensors and provides an interface to access and monitor the sensor network while Users monitor the system. The model proposed has been instantiated and validated using association rule mining to compensate for missing data in order to provide security and survivability to sensor networks. Future work will instantiate and validate other modes presented throughout the paper ACKNOWLEDGMENTS We thank our two collaborators, Dr. Johnson Thomas at Oklahoma State University and Dr. Sandip Sen at Tulsa University, for participating in many discussions of the proposed system model and instantiation 508 


R EFERENCES  1  B. H. Calhoun, D. C. Daly, N. Verma, D. Finchelstein, D D. Wentzloff, A. Wang, S.-H. Cho, and A. P Chandrakasan, çDesign Considerations for Ultra-low Energy Wireless Microsensor Nodes IEEE Transactions on Computers Vol 54\(6\ pp. 727-749, June 2005 2  L. Clare, G. Pottie, and J. Agre. çSelf-Organizing Distributed Sensor Networks SPJE Conference on Unattended Ground Sensor Technologies and Applications pp. 229-237, April 1999 3  T. Wong, T. Tsuchiya, and T. Kikuno, çA Self-organizing Technique for Sensor Placement in Wireless MicroSensor Networks,é in Proc. of 18th International Conference on Advanced Information Networking and Applications AINA\, pp. 78-83, March 2004, Fukuoka Japan, IEEE Computer Society 4  A. Ghosh and S. Sen, çAgent-Based Distributed Intrusion Alert System,é to appear in Proc. 61h International Workshop on Distributed Computing December 2004 5  R. Gopalakrishna and E. H. Spafford, çA Framework for Distributed Intrusion Detection using Interest Driven Cooperating Agents Web Proceedings of the Fourth International Workshop on Recent Advances in Intrusion Detection \(RAID 2001 6  Y. Fu, J. He, G. Li, çA Distributed Intrusion Detection Scheme for Mobile Ad Hoc Networks,é in Proc. of 31 st  Annual International Computer Software and Applications Conference COMPSAC\, Vol. 2,  pp. 7580, 2007 7  W. B. Heinzelman, A P. Chandrakasan, and H Balakrishnan, çAn Application-Specific Protocol Architecture for Wireless Microsensor Networks IEEE Transactions on Wireless Communications Vol. 1, No.4 2002 8  M.-Y. Huang and T. M. Wicks, çA Large-scale Distributed Intrusion Detection Framework Based on Attack Strategy Analysis,é in Web Proc. of the 1st International Workshop on Recent Advances in Intrusion Detection RAID\, 1998 9  A. Abraham, R. Jain, J. Thomas and S. Y. Han, çDSCIDS: Distributed soft computing intrusion detection system Journal of Network and Computer Applications  Vol. 30, pp. 81Ö98, 2007   C. Intanagonwiwat, R. Govindan and D. Estrin. çDirected Diffusion: A Scalable and Robust Communication Paradigm for Sensor Networks,é in Proc. of Annual International Conference on Mobile Computing and Networks MobiCOM\, August 2000   C. Karlof and D. Wagner, çSecure Routing in Wireless Sensor Networks: Attacks and Countermeasures,é Proc of 1st IEEE International Workshop on Sensor Network Protocols and Applications 2003   S. Meguerdichian, F. Koushanfar, M. Potkonjak, and M B. Srivastava, çCoverage Problems in Wireless Ad-hoc Sensor Networs IEEE Infocom Vol 3, pp. 1380-1387 April 2001   P. Papadimitratos and Z. J. Haas, çSecure routing for mobile ad hoc networks,é in SCS Communication Networks and Distributed Systems Modeling and Simulation Conference CNDS\ January 2002   A. Perrig, R. Szewczyk, V. Wen, D. Culler, and J. D Tygar, çSPINS: Security protocols for sensor networks in Proc. of Mobile Networking and Computing 2001   B. S. Snapp and G. D. et al., çDids \(distributed intrusion detection system\ motivation, architecture, and an early prototype,é In Fourteen National Computer Security Conference October 1991   T. Peng, C. Leckie and K. Ramamohanarao, çInformation sharing for distributed intrusion detection systems Journal of Network and Computer Applications Archive  Vol.  30\(3\, pp. 877-899, 2007   E. H. Spafford and D. Zamboni, çIntrusion detection using autonomous agents Computer Networks Vol 34\(4\ 2000   Y. Zhang and W. Lee. çIntrusion Detection in Wireless Ad-Hoc Networks,é in Proc. of the 6th Annual International Conference on Mobile Computing and Networking Mobicom\, 2000   B. Sun, K. Wu, Y. Xiao and R. Wang, çIntegration of mobility and intrusion detection for wireless ad hoc networks: Research Articles International Journal of Communication Systems archive Vol. 20\(6\, pp. 695-721 2007   L. Zhou and Z. Haas, çSecuring ad hoc networks IEEE Network Magazine vol. 13, no. 6, 1999   R. Agrawal, T. Imielinski, and A. N. Swami, çMining Assoc iation Rules between Sets of Items in Large Databases ACM SIGMOD Conference May 1993   M. Halatchev and  L. Gruenwald, çEstimating Missing Values in Related Sensor Data Streams,é in Proc. of Intl Conference on Management of Data January 2005   N. Jiang and L. Gruenwald: CFI-Stream: Mining Closed Frequent Itemsets in Data Streams; ACM SIGKDD international conference on knowledge discovery and data mining, August 2006   L. Gruenwald, H. Chok and M. Aboukhamis, çUsing Data Mining to Estimate Missing Data,é Proceedings of the 7th IEEE International Conference on Data Mining Workshop on Optimization-based Data Mining Techniques with Applications 2007   NASA/JPL Sensor Webs Project http://caupanga.huntington.org/swim/, a ccessed January 2006   S. Papadimitriou,  J. Sun, and C. Faloutsos, çPattern Discovery in Multiple Time-Series International Conference on Very Large Data Bases September 2005   S. Madden, M. Franklin,  J. Hellerstein, and W. Hong TinyDB: An Acquisitional Query Processing System for Sensor Networks ACM Transactions on Database Systems 2005   R. Little and D. Rubin, çStatistical Analysis with Missing Data New York: John Wiley & Sons 1987     509 


D j 222 38 
Return 
Figure 5 Algorithm for reassessing clusters composition for dynamic XML documents  6. Experimental results  To test our proposed method we used XML documents \(20kB and 50kB\xtracted from the   with an average number of levels of 4 Firstly, we clustered the documents to get the initial clusters composition \(Step 1 in framework in Section 3\, using minimum pair-wise distances; at this stage we also stored the distances between documents in the clustering solution together with the set of operations corresponding to each minimum distance. Then, in order to assess the efficiency of Step 2, we applied different percentages of changes to the documents in the clustered solution, in order to obtain new versions The purpose of the tests was to compare, after each set of changes, the time required to reassess the distance between documents using the same method as for the initial clustering \(i.e. full pair-wise comparison of the XML documents\ to the time of reassessing each distance using the method proposed in this paper and formulas in Definitions 5a, 5b and 5c  Figure 6 Test results for 50kB doc \(part 1  We show in Figures 6, 7, 8 and 9 some of the obtained results. They demonstrate clearly that our proposed technique to reassess the distances in dynamic XML clusters is much faster than performing a full pair-wise comparison on all new versions of the clustered documents. This can be explained by our technique: \(i\rforming only a minimum number of calculations and \(b\ reassessing distances only for those pairs of XML documents where at least one of them has changed Figure 8 Test results for 20kB doc \(part 1    Figure 9 Test results for 20kB doc \(part 2   Also, from Figures 6, 7, 8 and 9 it can be noticed that the difference between the full pair-wise and our proposed technique is more evident for higher number of documents modified or for higher percentages of changes applied                  V arious number of medium-sized documents \(50kB affected by 10% changes 0 20 40 60 80 100 51020 number of documents time\(second s    pair-w ise f ull comparison   proposed reassessing technique                50 small-sized documents \(20kB\ affected by various percentages of changes 0 50 100 150 10 20 50 percentage of change time\(second s    pair-w ise f ull comparison   proposed reassessing technique                  20 medium-sized documents \(50kB\ affected by various percentages of changes 0 50 100 150 3 5 10 25 percentage of change time\(second s    pair-w ise f ull comparison   proposed reassessing technique              V ar ious number of small documents \(20kB\ affected by 15% changes 0 10 20 30 40 50 60 51020 number of documents time\(second s    pair-w ise f ull comparison   proposed reassessing technique  
End if 
002 
37 prune edge D i 222 C\222={C 1 222,C 2 222,\205C n\222 222  ______________________________  
 Figure 7 Test results for 50kB doc \(part 2   
39 D i 222,D j 222 40 
 
Next 
455 
455 


 7. Conclusions  In this paper we have proposed an intelligent and efficient technique to reassess the distances between dynamic XML documents when one or all of the initially clustered documents have changed. After the changes, the initial clustering solution might become obsolete - the distances between clustered XML documents might have changed more or less depending on the degree of modifications \(insert update, delete\hich have been applied. Re-running full pair-wise comparisons on the entire set of modified documents is not a viable option, because of the large number of redundant operations involved Our proposed technique allows the user to reassess the pair-wise XML document distances, not by fully comparing each new pair of versions in the clustering solution, but by determining the effect of the temporal changes on the previously known distances between them. This approach is both time and I/O effective, as the number of operations involved in distance reassessing is greatly reduced  References  1  Beringer, J. and H\374llermeier, E., Online clustering of parallel data streams Data and Knowledge Engineering 58\(2\,  2006, 180-204 2  Catania, B. and Maddalena A., A Clustering Approach for XML Linked Documents, Proceedings of the 13th International Workshop on Database and Expert Systems Applications \(DEXA\22202\, IEEE 2002 3  Chen, M.S., Han, J. and Yu, P., Data Mining: An Overview from Database Perspective, IEEE Transactions on Knowledge and Data Engineering vol. 8, 1996, 866-883 4  Cormen, T., Leiserson, C. and Rivest, R Introduction to algorithms, MIT Press, 1990 5  Costa, G., Manco, G., Ortale, R. and Tagarelli, A., A tree-based Approach to Clustering XML documents by Structure, PAKDD 2004, LNAI 3202, 137-148 Springer 2004 6  Dalamagas, T., Cheng, T., Winkel, K.J. and Sellis, T 2004, Clustering XML documents by Structure SETN 2004, LNAI 3025, 112-121, Springer 2004 7  Ester, M., Kriegel, H.P., Sander, J., Wimmer,M. and Xu, X., Incremental Clustering for Mining in a Data Warehousing Environment, Proc.of the 24 th VLDB Conference, New York, USA, 1998 8  Garofalakis, M., Rastogi, R., Seshadri, S. And Shim K., Data Mining and the Web: Past, Present and Future Proceedings of WIDM 99 Kansas, US, ACM 1999 9  Mignet, L., Barbosa, D. and Veltri, P., The XML web : a first study, In Proceedings of the 12 th  International Conference on WWW, 500-510 2003   Nayak, R., Xu, S., XCLS: A Fast and Effective Clustering Algorithm for Heterogeneous XML Documents, In Proceedings of the 10 th Pacific-Asia Conference on Advances in Knowledge Discovery and Data Mining, Singapore, LNCS 3918, 2006   Rusu, L.I., Rahayu, W. and Taniar, D., A methodology for Building XML Data Warehouses International Journal of Data warehousing Mining, 1\(2 67-92, 2005   Rusu, L.I., Rahayu, W. and Taniar D.,  Maintaining Versions of Dynamic XML Documents, In Proceedings of the 6th International Conference on Web Information Systems Engineering, New York NY, USA, November 20-22, 2005, LNCS 3806   Rusu, L.I., Rahayu, W. and Taniar, D., Warehousing Dynamic XML Documents, In Proceedings of the 8 th  International Conference on Data Warehousing and Knowledge Discovery \(DaWaK 2006 LNCS 4081 Springer, 175-184, 2006   Shen, Y. and Wang, B., Clustering Schemaless XML documents, CoopIS / DOA/ODBASE 2003, LNCS 2888, 767-784, Springer 2003   Yoon, J. P., Raghavan, V., Chakilam, V., and Kerschberg, L., BitCube: A Three-Dimensional Bitmap Indexing for XML Documents J. Intel. Inf Syst 17, 2-3 \(Dec. 2001\, 241-254   XML data repository, online at http www.cs.washington.edu / research / projects / xmltk xmldata  
456 
456 


5 Related Work There exists extensive previous work on both the mining of software repositories and on the use of clustering algorithms in software engineering This discussion focuses on the most similar and recent work in the area of software evolution Mining Software Repositories Our technique was partially inspired by the work of Zimmermann et al and Y ing et al 17 on the mining of association rules in change history As described in Section 1 we sought to expand the technique to be able to recommend larger but less precise clusters of elements to guide program navigation Bouktif et al also investigated how to recommend cochanges in software development As opposed to the work cited above Bouktif et al used change patterns instead of association rules Also their approach does not attempt to reconstruct transactions and can consider associated 002les that were changed in different transactions ChangeDistiller is a tool to classify changes in a transaction into 002ne-grained operations e.g addition of a method declaration and determines how strongly the change impacts other source code entities Our approach uses similar repository analysis techniques but is focused on providing task-related information as opposed to an overall assessment of a system's evolution Finally repository mining can also be used to detect aspects in the code In this conte xt aspects are recurring sets of changed elements that exhibit a regular structure Aspects differ from the clusters we detect in the regular structure they exhibit which may not necessarily align with the code that is investigated as part of change tasks Clustering Analysis The classical application of clustering for reverse engineering involves grouping software entities based on an analysis of various relations between pairs of entities of a given version of the system Despite its long and rich history  e xperimentation with this approach continues to this day For example Andreopoulos et al combined static and dynamic information K uhn et al used a te xtual similarity measure as the clustering relation and Christl et al used clustering to assist iterative semi-automated reverse engineering The main dif ferences b e tween most clusteringbased reverse engineering techniques and the subject of our investigation is that the entities we cluster are transactions rather than software entities in a single version of a system For this reason our analysis is based strictly on the evolving parts of the system Both Kothari et al and V an ya et al 15 recently reported on their use of clustering to study the evolution of software systems The idea of using change clusters is the same in both works and ours but the purpose of the work is different Kothari et al use change clusters to uncover the types of changes that happened e.g feature addition maintenance etc during the history of a software system Vanya et al use change clusters which they call evolutionary clusters to guide the partitioning of a system that would increase the likelihood that the parts of the system would evolve independently In contrast we cluster transactions based on overlapping elements not 002les to recommend clusters to support program navigation as opposed to architectural-level assessment of the system Finally Hassan and Holt evaluated on 002ve open source systems the performance of several methods to indicate elements that should be modi\002ed together This study found that using historical co-change information as opposed to using simple static analysis or code layout offered the best results in terms of recall and precision The authors then tried to improve the results using 002ltering heuristics and found that keeping only the most frequently cochanged entities yielded the best results As opposed to our approach the evaluated 002ltering heuristics were only applied on entities recovered using association rules and not using clustering techniques The focus of their study was also more speci\002c as they recommend program elements that were strictly changed  as opposed to recommending elements that might be inspected by developers 6 Conclusion Developers often need to discover code that has been navigated in the past We investigated to what extent we can bene\002t from change clusters to guide program navigation We de\002ned change clusters as groups of elements that were part of transactions or change sets that had elements in common Our analysis of close to 12 years of software change data for a total of seven different open-source systems revealed that less than 12 of the changes we studied could have bene\002ted from change clusters We conclude that further efforts should thus focus on maximizing the quality of the match between the current task and past transactions rather than 002nding many potential matches Our study has already helped us in this goal by providing reliable evidence of the effectiveness of some 002ltering heuristics and useful insights for the development of additional heuristics Acknowledgments The authors thank Emily Hill and Jos  e Correa for their advice on the statistical tests and the anonymous reviewers for their helpful suggestions This work was supported by NSERC 
25 
25 
25 
25 
25 


References  B Andreopoulos A An V  Tzerpos and X W ang Multiple layer clustering of large software systems In Proc 12th Working Conf on Reverse Engineering  pages 79ñ88 2005  S Bouktif Y G Gu  eh  eneuc and G Antoniol Extracting change-patterns from cvs repositories In Proc 13th Working Conf on Reverse Engineering  pages 221ñ230 2006  S Breu and T  Zimmermann Mining aspects from v ersion history In Proc 21st IEEE/ACM Int'l Conf on Automated Software Engineering  pages 221ñ230 2006  A Christl R K oschk e and M.-A Store y  Equipping the re\003exion method with automated clustering In Proc 12th Working Conf on Reverse Engineering  pages 89ñ98 2005  D 020 Cubrani  c G C Murphy J Singer and K S Booth Hipikat A project memory for software development IEEE Transactions on Software Engineering  31\(6 465 2005  B Fluri and H C Gall Classifyi ng change types for qualifying change couplings In Proc 14th IEEE Int'l Conf on Program Comprehension  pages 35ñ45 2006  A E Hassan and R C Holt Replaying de v elopment history to assess the effectiveness of change propagation tools Empirical Software Engineering  11\(3 2006  D H Hutchens and V  R Basili System s tructure analysis Clustering with data bindings IEEE Transactions on Software Engineering  11\(8 1985  D Janzen and K De V older Na vig ating and querying code without getting lost In Proc 2nd Int'l Conf on AspectOriented Software Development  pages 178ñ187 2003  J K ot hari T  Denton A Shok ouf andeh S Mancoridis and A E Hassan Studying the evolution of software systems using change clusters In Proc 14th IEEE Int'l Conf on Program Comprehension  pages 46ñ55 2006  A K uhn S Ducasse and T  G  021rba Enriching reverse engineering with semantic clustering In Proc 12th Working Conf on Reverse Engineering  pages 133ñ142 2005  M P  Robillard T opology analysis of softw are dependencies ACM Transactions on Software Engineering and Methodology  2008 To appear  M P  Robillard and P  Mangg ala Reusing program in v estigation knowledge for code understanding In Proc 16th IEEE Int'l Conf on Program Comprehension  pages 202 211 2008  J Sillito G Murph y  and K De V older Questions programmers ask during software evolution tasks In Proc 14th ACM SIGSOFT Int'l Symposium on the Foundations of Software Engineering  pages 23ñ34 2006  A V an ya L Ho\003and S Klusener  P  v an de Laar and H van Vliet Assessing software archives with evolutionary clusters In Proc 16th IEEE Int'l Conf on Program Comprehension  pages 192ñ201 2008  N W ilde and M C Scully  Softw are reconnaissance Mapping program features to code Software Maintenance Research and Practice  7:49ñ62 1995  A T  Y ing G C Murph y  R Ng and M C Chu-Carroll Predicting source code changes by mining change history IEEE Transactions on Software Engineering  30\(9 586 2004  A Zeller  The future of programming en vironments Integration synergy and assistance In Proceedings of the 29th International Conference on Software Engineering The Future of Software Engineering  pages 316ñ325 2007  T  Zimmermann and P  W eiﬂgerber  Preprocessing C VS data for 002ne-grained analysis In Proc 1st Int'l Workshop on Mining Software Repositories  pages 2ñ6 May 2004  T  Zimmermann P  W eiﬂgerber  S Diehl and A Zeller  Mining version histories to guide software changes In Proc 26th ACM/IEEE Int'l Conf on Software Engineering  pages 563ñ572 2004 A Clustering Algorithm This algorithm is not sensitive to whether a given program element exists or not in a given version of a program For example if method m exists in one version it is considered a valid program element even if it is removed in a later version In the rest of this section we use the term program element to refer to the uniquely identifying representation of the element e.g a Java fully-quali\002ed name Let T be a transaction modeled as a set of program elements changed together during the history of a software system Let T be a sequence of transactions In this algorithm a cluster is also modeled as a set of elements 1 Input  T  A sequence of transactions 2 Parameter  M IN O VERLAP  A positive non-zero value indicating the minimum overlap between two transactions in a cluster 3 Var  C  A set of clusters initially empty 4 for all T i 2 T do 5 MaxOverlap  0 6 MaxIndex  000 1 7 for all C j 2 C do 8 if j C j  T i j  MaxOverlap then 9 MaxOverlap  j C j  T i j 10 MaxIndex  j 11 end if 12 end for 13 if MaxIndex   0  MaxOverlap 025 M IN O VERLAP  then 14 C MaxIndex   C MaxIndex  T i  15 else 16 NewCluster  T i 17 C  C  f NewCluster g 18 end if 19 end for 20 return C B Systems Analyzed System home pages last veri\002ed 7 May 2008 Ant ant.apache.org Azureus azureus.sourceforge.net Hibernate www.hibernate.org JDT-Core www.eclipse.org/jdt/core JDT-UI www.eclipse.org/jdt/ui Spring springframework.org Xerces xerces.apache.org 
26 
26 
26 
26 
26 


