NEWER a NEuro fuzzy WEb Recommendation system Giovanna Castellano University of Bari 
Moro Department of Informatics CILAB Laboratory Italy castellano@dLuniba.it Anna Maria Fanelli University of Bari A Moro Department of Informatics CILAB Laboratory Italy fanelli di.uniba.it Maria Alessandra Torsello University of Bari A Moro Department of Informatics CILAB Laboratory Italy torsello  di uni ba.it Abstract 
A 
In this paper we present NEWER a neuro-fuzzy 
Web rec\255 ommendation system that dynamically suggests interesting pages to the current user NEWER employs a neuro-fuzzy approach in order to determine categories of users sharing similar interests and to extract a recommendation model in the form of fuzzy rules expressing associations between user categories and relevances of pages The derived model is used by an online recommendation module to dynami\255 cally suggest interesting links Comparative accuracy re\255 
sults show the effectiveness of NEWER 
1 Introduction In the era of the Web the problem of information over\255 load is continuously expanding When browsing the Web users are very often overhelmed by a huge amount of in\255 formation available online Indeed the ever more complex structure of sites combined with the heterogeneous nature of the Web make navigation activity difficult for ordinary users who often are faced with the challenging problem of finding the desired information in right 
time An important step in the direction of alleviating the problem of infonna\255 tion overload is represented by Web personalization Web personalization can be simply defined as the task of adapting the information or services provided by a Web site to the needs and interests of users exploiting the knowledge gained from the users navigational behavior and individual interests in combination with the content and the structure of the Web site 6 Recommendation systems are one of the major examples of Web 
personalization To develop a Web recommendation system two main problems have to be addressed how to discover knowledge about user interests from Web data and how to exploit this knowledge to deliver intelligent recommendations Both these tasks are characterized by uncertainty and vagueness A great deal of ambiguity pervades all stages of the user in978-1-4244-2624-9/08/$25.00 2512008 IEEE 162 teractions from the definition of the user navigational mod\255 els to the recommendation process Due to their character\255 istics Soft Computing techniques i.e fuzzy 
logic neural networks neurofuzzy systems etc reveal to be particu\255 larly appropriate to deal under these conditions 4 In this paper we present NEWER a neuro-fuzzy Web recommendation system able to support users during their navigational activity by dynamically suggesting links to pages that are retained interesting for them NEWER em\255 ploys a hybrid approach based on the combination of the fuzzy reasoning with a neural network in order to determine user categories encoding interests shared by groups of users and to extract a recommendation 
logliles 
to derive aggregate user cat\255 egories encoding the common interests of groups 
model expressed by a set of fuzzy rules useful to provide dynamical predictions about Web pages to be suggested to the current user according to the user categories previously identified 2 The NEWER system The NEWER system is designed to perform three se\255 quential steps 
225 Preprocessing 225 Knowledge discovery 
to identify user sessions and to create models of user navigational behavior 
of 
of users and to derive a recommendation model 
225 Recommendation 
an offline module an online module 
to dynamically suggest interesting pages to the current user by exploiting the previously discovered recommendation model As illustrated in Figure 1 these steps are organized into two main modules i 
that includes the first two steps to extract a recommendation model from Web usage data and ii that performs recom\255 mendations In the following subsections we describe in more detail each step involved in NEWER 


Web log OnllMMociule I which expresses the interest degree of each user for each page in a fuzzy way A very simple characterization of the matrix page 163 2.2 Knowledge discovery Two main activities are carried out in the knowledge discovery step categorization of user behaviors and discovery of the recommendation model In the following both these activities are detailed Categorization of user behaviors In order to identify user categories a fuzzy clustering process is applied to the behavior matrix Pik Nik Pk lij is the access time of the whole session Pi is the set of all pages with correspond\255 ing access information requested during the i-th session Namely with is the number of accesses to page is the number of the identified user sessions and m the number of different pages required in all the user sessions we model the naviga\255 tional behavior of a user is a maximum threshold of the interest degree b bim ILij  x m behavior matrix B  ti n a triple Si E 2 where Pi where through a vector i  1   nles i  IDmin,IDmax where where if page pjis accessed in session Si 1 otherwise where is the total access time to that page User sessions are used to create a model of the user behavior as follows Suppose that is the access frequency to the j-th page in the i-th session As a result the preprocessing step derives a is provided as follows if is a minimum threshold for the interest de\255 gree under which the interest for a page is considered null and represents the user identifier I D min D U 2.1 Preprocessing of log roes During the preprocessing task requests included in log files are structured into user sessions Starting from user sessions the behavior of each user is modeled by one vector which encodes the access pattern exhibited by the same user in that session To perform preprocessing of log files we applied the strategy described in 3 that identifies user sessions and models the user navigational behaviors Formally we de\255 fine a user session n b i2  b b b I Dmi'tt I D max Figure 1 Architecture of the NEWER system as  ill b ij  during the i-th session and where each component represents the interest degree of the i-th user for the E P b i B F  E  n   by means of CARD a fuzzy relational clustering algorithm that we proposed in 2 A key feature of CARD is its ability to automatically categorize the available data into an optimal number of clusters In fact it is able to derive always the same number of clusters independently on the initial ran\255 dom number provided in input to the algorithm CARD partitions the available data by working on rela\255 tional data Le data that quantify the relation between each pair of objects lYpically the relation expresses the similar\255 ity degree existing between two objects In NEWER to capture the similarity between two generic behavior vectors a fuzzy similarity measure is pro\255 posed within CARD Specifically each behavior vector is modeled as a fuzzy set and the similarity between two behavior vectors is expressed as the similarity between the corresponding fuzzy sets To do so the user behavior matrix B is converted into a matrix M  if Ui Ui ti tik Ui j-th ij ij ij max if 


where each component K Similarity values are mapped into the similarity matrix Sim for represent the significance in terms of rele\255 vance degree of a given page 3 4 1 describes the typical navigational behavior of a group of users with simi\255 lar interests Moreover CARD provides a partition matrix IF max calculated by using the fuzzy similarity mea\255 sure Starting from the similarity matrix the dissimilar\255 ity values are simply computed as m the online recommendation module Such model is expressed by a set of fuzzy rules which capture associations between behav\255 ior vectors and pages to be recommended in the following form IF IXcl j 1 i j j  1  V V M ij J-LbxJ J-LbyJ The values  225  L.Jj=1 is is LOW AND  the interest degree for is HIGH THEN recommend is derived where EbiEXc n C user category Summarizing CARD mines a collection of used Vcj is 164 c d U RL I m r mk A 1 U m U RL 1 U b ij 1   1   by have been computed the fuzzy membership valueszei are updated to optimize the clustering criterion resulting in a new fuzzy partition of be\255 havior vectors The process is iterated until the membership values stabilize Finally a crisp assignment of behavior vectors to the identified clusters is performed in order to derive a proto\255 type vector for each cluster representing a user category Precisely each behavior vector is crisply assigned to the closest cluster creating li,j=l  n representing the relation with relevance 0.3 AND  recommend with relevance 0.8 In NEWER the discovery of fuzzy recommendation rules is performed through the learning of a three layer feed\255 forward neuro-fuzzy network that encodes in its topology the structure of a Fuzzy Inference System The network consists of three layers Units in the first layer where j is is is the number of fuzzy rules after which the page is considered surely preferred by the user Of course other membership functions can be used to express the interest degree We explore these possibilities in our future research In this way the similarity of two generic users is intu\255 itively defined as the similarity between the corresponding fuzzy sets rows of F We measure the similarity between two fuzzy sets as the ratio of two quantities the cardinality of the intersection of the fuzzy sets and the cardinality of the union of the fuzzy sets The intersection of two fuzzy sets is defined by the minimum operator while the union of two fuzzy sets is defined by the maximum operator Fi\255 nally the cardinality of a fuzzy set also called a-count is computed by summing up all its membership values Sum\255 marizing the similarity between any two users b x and by is defined as follows  1   m are fuzzy singletons expressing the amount of recommendation relevance degree of the j-th URL The main advantage of using a fuzzy knowledge base for the recommendation system is readability of the extracted knowledge Actually fuzzy rules can be easily understood by human users since they can be expressed in a linguis\255 tic fashion by labeling fuzzy sets e  receive the degrees of interest for visited pages in a behavior vec\255 tor b Simij i,j ij Zci rjk Pj x Diss clusters 6 Recommendation model discovery In this activity both behavior vectors and discovered user categories are employed to extract a recommendation model that represents the knowledge base to Sim'ij]i j=l  the clusters from behavior data representing user categories Each category prototype AND  AND relevance of matrix R and for all implicit clusters and and evaluate the Gaussian membership Then for each cluster that describe the degree of belong\255 ingness of the i-th behavior vector in the c-th cluster Once the implicit distance values 5  1  m are fuzzy sets with Gaussian membership functions defined over the input variables implicit pro\255 totypes that summarize the data objects belonging to each cluster in the partition Specifically starting from the rela\255 tion matrix R the following implicit distances are computed at each iteration step of the algorithm for all behavior vectors c-th e THEN relevance of    be s n n Vern     min J-tbor-j J-tb1/j b m    1   AND  AND  1    1   micl where each entry represents the membership degree of the i-th user to the c-th category for where Ze is the membership vec\255 tor for the c-th cluster defined as on the basis of the fuzzy membership values G 0 b l b U RL k K b j U RL L 1 C n b2 Xc These are mapped in a  the interest degree for Vern m CARD implicitly partitions object data by denvlng the distances from the relational data to a set of a prototype vector c  n Diss ci Alk Arnk rlk Ajk jk RL RL m Vel V c 2,\267 Vej Vel V c 2 C ex\255 presses the simiiarity value between the user behaVIor vectors hi and b to the membership layer with linguistic terms such as LOW MEDIUM HIGH Hence a fuzzy rule in the web recommendation system can assume the following lin\255 guistic form 


receives the interest degree for the j-th page Then we identify the expresses the amount of URLs recommendation for the user related to the i-th behavior vector To com\255 pute the values in rd rule for are respectively the center and the width of the Gaussian function The second layer fuzzy recommendation rules the online module provides URL relevance degrees by means of the following fuzzy reasoning procedure 1 Calculate the matching degree of current session are hence calculated as units that compute the fulfillment degree of each rule In this layer no modifiable parameter is associated with the units The output is derived by computing the rule activation strength J.tk\(b\(D\273 as follows 7 where by means of the product operator as those with the highest membership values The num\255 ber K 1   1   mas 9 b b m  225\225\225  group contains 2 Calculate the relevance degree considered is experimentally established The values in the output vector rd 1   m 8 Recommendation groups one for each fuzzy rule The havior vectors and preferred URLs Precisely each training sample should describe the association between a behavior vector Le the vector of interest degrees for visited URLs during one session and the amount of recommendation rel\255 evance degree for each URL Thus the training set is a col\255 lection of input-output vectors 165 K output layer K L b j  A jk  k K b k l k-th contains units corresponding to the fuzzy sets which de\255 fine the premise part of the where some values are equal to zero corresponding to unexplored pages Each time the user requests a new page the vector is updated To maintain the active session a sliding window is used to capture the most recent user behavior Based on the set of top matching user categories Cl   10 1 1  2 k-th Cjk ajk j=1 rd i2   rd im  rd K L.Jk=1 JLk L..Jk=l k rjk provides the outputs of the network i.e the relevance values of the m URLs to be used for recommendation Each relevance value is obtained by inference of rules according to the following formula 1   functions representing fuzzy sets In this layer units are ar\255 ranged in rd the the retj 0;2 il  C K 0\(2 follows m 1   and 1  m 11 Once the training set has been constructed the neuro\255 fuzzy network can enter the learning phase to extract the knowledge embedded into the training set and represent it as a collection of fuzzy rules Firstly behavior data and extracted user categories are employed to initialize the structure and the involved param\255 eters of the neurofuzzy network In particular the number of fuzzy rules and the number of fuzzy sets used to partition data together with the parameters that define the premise and the consequence of each rule are established Successively the neural network enters in a learning phase to optimally adjust the premise and the consequent parameters of the derived fuzzy rule base Major details on the algorithms underlying the neuro-fuzzy learning strategy can be retrieved in 1 2.3 ij 12 j=1 in the partition matrix D D D D K 1 L 3 Vjcl 225  miq j==l  m where the input vector hi represents the i-th user behavior vector identified by the preprocessing phasc,and the output vector rd we exploit information embedded in the user categories extracted through fuzzy clustering Pre\255 cisely for each vector bi,we consider its membership to the clusters user categories expressed by membership values of top matching session categories which have to be The third layer k-th rdjkl-tk for the j-th URL n  1  m and computes its membership value to fuzzy set  1     mict VjCt b\(O\273 beD\273 13  0 In order to learn fuzzy rules for link suggestion the neuro-fuzzy network should be trained on a set of input\255 output samples describing the association between user rule layer rule In detail each unit of the layer i  267 j  m  j  i i  E J 1n    be\255 mic c=I  C j  h to the i II II The online module performs the ultimate task of rec\255 ommendation Le suggesting the URLs of the Web site that are judged relevant for the current user Specifically when a new user accesses the Web site this module matches the current partial session against the fuzzy rules currently available in the knowledge base and derives a vector of rel\255 evance degrees by means of a fuzzy inference process Formally when a new user accesses to the site an ac\255 tiv e user's curreo.t session  cf.eat.ed in the form of a vector L2 j.Ljk\(bjO\273 rdf Cl M h\(D j 


Profile used for different pages for pages which are not visited the white color is used Once user categories were identified the step of recom\255 mendation model discovery was applied Firstly a dataset of validation procedure was performed Among the 10 cre\255 ated models we choose max 225 KNN 8 In our experi\255 ments the values of final recommendation model the model having the lowest error on the test set The derived recommendation model is represented by a fuzzy rule base composed of Figure 2 illustrates a graphical representation of the identified user categories Here each row represents a user category and each column represents a page Different colors rules The last step of NEWER is to use the discovered rec\255 ommendation model to infer the relevance vector for a cur\255 rent user as described in section 2.3 Hence the pages not yet visited by the current user were ordered on the basis of the corresponding relevance values and the Figure 2 Graphical representation of the identified user categories  x 42 A 5 5 5 K NP based recommendation ap\255 proach 8 225 The pages with the highest values were recommended In order to evaluate the effectiveness of NEWER we per\255 formed an evaluation sequence organized as follows Web pages visited in each session of the test set were divided ran\255 domly into input set and measurement set The input set was treated as active session and it was given in input to our rec\255 ommendation process to determine the recommended pages or recommended set To measure the accuracy of the rec\255 ommendations provided by NEWER we used the mettics 11 units that com  pute the fulfillment degree of each rule In order to evaluate the quality of the recommendation model a 10fold cross166 Successively the infor\255 mation about the extracted user categories was used to ini\255 tialize the parameters of fuzzy rules and to derive an initial recommendation model Finally the neurofuzzy strategy was applied to learn the ultimate recommendation model  5 independently on the initial number of clusters fuzzyapF1 are o Then among unexplored pages only the first topN pages having the highest relevance de\255 gree are recommended to the user In practice a list of links is dynamically included in the page currently visited by the user 3 Experimental results NEWER was tested by carrying out a set of experiments on the log files from an Italian Web site of the Japanese movie Dragon Ball www.dragonballgt.it The choice of this site was due to its high daily number of accesses thou\255 sands of visits each day especially from younger people The considered log files contain user requests covering a time period of 12 hours from 10:00 a.m to 22:00 p.m for a total of 12,300 requests Firstly the NEWER preprocessing step was applied to identify user behavior vectors from log files Through this step the interest degrees of each user for each visited page were evaluated and these values were mapped into a 200 C max C C K Nearest Neighbors measure 5 Higher values of these measures indicate better recommendation accuracy During the simulation experiments for each behavior vector of the test set we considered all possible sub-vectors including a number of pages between 2 and 8 For each sub\255 vector representing the active session we determined the recommendations through the neurofuzzy inference pro\255 cess Hence the average values of the accuracy metrics were calculated To evaluate the goodness of the obtained values we compared NEWER with other three recommen\255 dation approaches proposed in literature 225 The Nearest behavior matrix Next categorization of user behaviors was executed We carried out several runs of CARD by setting different ini\255 tial number of clusters input-output samples was created in the way de\255 scribed in section 2.2 formula 10 Each sample of the dataset included 84 components 42 corresponding to the pages of each behavior vector and the remaining 42 calcu\255 lated by employing the fonnula neural network with 42 inputs corresponding to the compo\255 nents of the behavior vector and 42 outputs corresponding to the relevance values of the Web pages was considered The intemallayer of the network contains This inference process provides the relevance degree for all the considered m pages independently on the actual nav\255 igation of the current user In order to perform dynamic link suggestion the recommendation module firstly identi\255 fies URLs that have been not visited by the current user Le all pages such that  5 10 15 We observed that CARD provided data partitions with the same final number of clusters and and N are respectively fixed to 10 and 5 225 The recommendation approach based on the Precision Recall 200 


FARMM Meature  6 Sub.nctor size 0,9 0,8 0,7 0.6 recall b F1 c per sub-vector size be\255 tween NEWER and four other recommenda\255 tion approaches Expert Systems with Applications c 0,6 0,'\255 0,2 0,8 0.1 0,6 Comparison of average precision 0,2 0.3 pages 1433-1439 World Scientific Publishing Co Pte Ltd 2007 3 G Castellano A M Fanelli,C Menear and M A Torsello Log data preprocessing for mining web browsing patterns In pages 247-254 Atlanta Georgia October 2001 6 B Mobasher Web usage mining and personalization In M P Singh editor Kaohsiung Taiwan December 2007 4 E Frias-Martinez G Magoulas S Chen and R Macredie Modeling human behavior in user-adaptive systems recent advances using soft computing techniques a user to belong to several categories with different mem\255 bership degrees Recall a 4 5 6 This is the subject of our on-going research projects PYoposed NF NP 167 size 4 Conclusions In this paper we have presented NEWER a neuro-fuzzy Web recommendation system which is able to dynamically suggest interesting pages to the currently connected users Application of NEWER on a highly-visited Web site has shown its validity in extracting fuzzy models useful for rec\255 ommendation Comparative results highlight that the pro\255 posed NEWER system can be effective for recommenda\255 tion leading to a quality of the generated recommenda\255 tions comparable and often significantly better than those of other recommendation approaches The promising re\255 sults encourage the application of NEWER to a wider range of Web eRC Press 2005 7 O Nasraoui and C Petenes Combining web usage mining and fuzzy inference for website personalization In Precision In\255 formation Sciences 2007 _FARSP 149:187-207,2005 2 G Castellano A Fanelli and M A Torsello Web user pro\255 filing using relational fuzzy clustering In P Y.Cao H.Cheng D.Hung C Kahraman C.W.Ngo Y.Ohsawa M.G.Romay M.C.Su A Vasilakos D.Wang,and P Wang editors FAR proposed in 7 For this approach two variants were implemented considering two different combinations for the operators used for the t-normlintersection and t-conormlunion in the rec\255 ommendation inference procedure max-min FARSP and sum-product FARMM Figure 3 shows the comparative results It can be ob\255 served that recommendations generated by NEWER are better than those obtained with the other approaches es\255 pecially in correspondence to higher sub-vector sizes The better performance of NEWER for longer sub-vectors is due to the fact that longer vectors match more likely with dif\255 ferent user categories In this situation a neurofuzzy ap\255 proach is expected to be more effective because it enables 1 G Castellano C Castiello A Fanelli and C Menear Knowledge discovering by a neurofuzzy modelling frame\255 work Proceed\255 ings of WEBKDD 2003 Web mining as premise to effective Web applications 8 29 2 2005 5 G Karypis Evaluation of item-based top-n recommendation algorithms In Figure 3 Proceedings of the 8th Asian Pacific Industrial Engineer\255 ing And Management Systems Conference APIEMS 2007 Proceedings of the tenth International confer\255 ence on lnfomlation and knowledge management CIKM01 Proceedings of the WebKDD 2000Web Mining for E-Commerce Workshop at ACM SIGKDD 2000 0.1 Boston 2000 PJoposedNF NP Sub-vector KNN Sub..YedOr size b KNN F1 References proximate reasoning Fuzzy sets and Systems I I  260 Practical Handbook of Internet Comput\255 ing 0,5 1 0 0,3 02 0.1 o pages 37-46 2003 8 B M Sarwar G Karypis J A Konstan and J Riedl Appli\255 cation of dimensionality reduction in recommender system a case study In FARSP 1.2 0,8 


 Kluwer Academic Publishers Springer, New York 1st edition, 2001 14  S c h e f f e r   T   F i n d i n g  A s s o c i a t i o n  Ru l e s  t h a t  T r a de Support Optimally Against Confidence th The Elements of Statistical Learning self_care_guide/Urogenital/Postate%20Cancer.pdf  Accessed, 25 August, 2008 11  A g r a w a l   R  T   I m i e l i n s k i     A   S w a m i   M i n i n g  association rules between sets of items in large databases, In Proceedings of the 1993 ACM SIGMOD international conference on Management of data  The Netherlands 42 2001 61-95  Ordonez C Association rule discovery with the train and test approach for heart disease predictio n 207\226 216 12 001 13  H a s t i e   T    R  T i b s h i r a n i     J  H   F r i e d m a n   Proceedings of the 5th European Conference on Principles and Practice of Knowlege Discovery in Databases\(PKDD'01 IEEE Transactions on Information Technology in Biomedicine, 10\(2\, 2006. 334 \226 343 001 Freiburg, Germany : SpringerVerlag, 2001. 424-435 15  F l a c h   P  A     L a c h i c h e   N   Co n f i r m a t i o n g u i d e d  discovery of first-order rules with Tertius 10  P h a r m a c y   h t t p    w w w  p h a r m a c y  g o v  m y    


 7. Conclusions  In this paper we have proposed an intelligent and efficient technique to reassess the distances between dynamic XML documents when one or all of the initially clustered documents have changed. After the changes, the initial clustering solution might become obsolete - the distances between clustered XML documents might have changed more or less depending on the degree of modifications \(insert update, delete\hich have been applied. Re-running full pair-wise comparisons on the entire set of modified documents is not a viable option, because of the large number of redundant operations involved Our proposed technique allows the user to reassess the pair-wise XML document distances, not by fully comparing each new pair of versions in the clustering solution, but by determining the effect of the temporal changes on the previously known distances between them. This approach is both time and I/O effective, as the number of operations involved in distance reassessing is greatly reduced  References  1  Beringer, J. and H\374llermeier, E., Online clustering of parallel data streams Data and Knowledge Engineering 58\(2\,  2006, 180-204 2  Catania, B. and Maddalena A., A Clustering Approach for XML Linked Documents, Proceedings of the 13th International Workshop on Database and Expert Systems Applications \(DEXA\22202\, IEEE 2002 3  Chen, M.S., Han, J. and Yu, P., Data Mining: An Overview from Database Perspective, IEEE Transactions on Knowledge and Data Engineering vol. 8, 1996, 866-883 4  Cormen, T., Leiserson, C. and Rivest, R Introduction to algorithms, MIT Press, 1990 5  Costa, G., Manco, G., Ortale, R. and Tagarelli, A., A tree-based Approach to Clustering XML documents by Structure, PAKDD 2004, LNAI 3202, 137-148 Springer 2004 6  Dalamagas, T., Cheng, T., Winkel, K.J. and Sellis, T 2004, Clustering XML documents by Structure SETN 2004, LNAI 3025, 112-121, Springer 2004 7  Ester, M., Kriegel, H.P., Sander, J., Wimmer,M. and Xu, X., Incremental Clustering for Mining in a Data Warehousing Environment, Proc.of the 24 th VLDB Conference, New York, USA, 1998 8  Garofalakis, M., Rastogi, R., Seshadri, S. And Shim K., Data Mining and the Web: Past, Present and Future Proceedings of WIDM 99 Kansas, US, ACM 1999 9  Mignet, L., Barbosa, D. and Veltri, P., The XML web : a first study, In Proceedings of the 12 th  International Conference on WWW, 500-510 2003   Nayak, R., Xu, S., XCLS: A Fast and Effective Clustering Algorithm for Heterogeneous XML Documents, In Proceedings of the 10 th Pacific-Asia Conference on Advances in Knowledge Discovery and Data Mining, Singapore, LNCS 3918, 2006   Rusu, L.I., Rahayu, W. and Taniar, D., A methodology for Building XML Data Warehouses International Journal of Data warehousing Mining, 1\(2 67-92, 2005   Rusu, L.I., Rahayu, W. and Taniar D.,  Maintaining Versions of Dynamic XML Documents, In Proceedings of the 6th International Conference on Web Information Systems Engineering, New York NY, USA, November 20-22, 2005, LNCS 3806   Rusu, L.I., Rahayu, W. and Taniar, D., Warehousing Dynamic XML Documents, In Proceedings of the 8 th  International Conference on Data Warehousing and Knowledge Discovery \(DaWaK 2006 LNCS 4081 Springer, 175-184, 2006   Shen, Y. and Wang, B., Clustering Schemaless XML documents, CoopIS / DOA/ODBASE 2003, LNCS 2888, 767-784, Springer 2003   Yoon, J. P., Raghavan, V., Chakilam, V., and Kerschberg, L., BitCube: A Three-Dimensional Bitmap Indexing for XML Documents J. Intel. Inf Syst 17, 2-3 \(Dec. 2001\, 241-254   XML data repository, online at http www.cs.washington.edu / research / projects / xmltk xmldata  
456 
456 


5 Related Work There exists extensive previous work on both the mining of software repositories and on the use of clustering algorithms in software engineering This discussion focuses on the most similar and recent work in the area of software evolution Mining Software Repositories Our technique was partially inspired by the work of Zimmermann et al and Y ing et al 17 on the mining of association rules in change history As described in Section 1 we sought to expand the technique to be able to recommend larger but less precise clusters of elements to guide program navigation Bouktif et al also investigated how to recommend cochanges in software development As opposed to the work cited above Bouktif et al used change patterns instead of association rules Also their approach does not attempt to reconstruct transactions and can consider associated 002les that were changed in different transactions ChangeDistiller is a tool to classify changes in a transaction into 002ne-grained operations e.g addition of a method declaration and determines how strongly the change impacts other source code entities Our approach uses similar repository analysis techniques but is focused on providing task-related information as opposed to an overall assessment of a system's evolution Finally repository mining can also be used to detect aspects in the code In this conte xt aspects are recurring sets of changed elements that exhibit a regular structure Aspects differ from the clusters we detect in the regular structure they exhibit which may not necessarily align with the code that is investigated as part of change tasks Clustering Analysis The classical application of clustering for reverse engineering involves grouping software entities based on an analysis of various relations between pairs of entities of a given version of the system Despite its long and rich history  e xperimentation with this approach continues to this day For example Andreopoulos et al combined static and dynamic information K uhn et al used a te xtual similarity measure as the clustering relation and Christl et al used clustering to assist iterative semi-automated reverse engineering The main dif ferences b e tween most clusteringbased reverse engineering techniques and the subject of our investigation is that the entities we cluster are transactions rather than software entities in a single version of a system For this reason our analysis is based strictly on the evolving parts of the system Both Kothari et al and V an ya et al 15 recently reported on their use of clustering to study the evolution of software systems The idea of using change clusters is the same in both works and ours but the purpose of the work is different Kothari et al use change clusters to uncover the types of changes that happened e.g feature addition maintenance etc during the history of a software system Vanya et al use change clusters which they call evolutionary clusters to guide the partitioning of a system that would increase the likelihood that the parts of the system would evolve independently In contrast we cluster transactions based on overlapping elements not 002les to recommend clusters to support program navigation as opposed to architectural-level assessment of the system Finally Hassan and Holt evaluated on 002ve open source systems the performance of several methods to indicate elements that should be modi\002ed together This study found that using historical co-change information as opposed to using simple static analysis or code layout offered the best results in terms of recall and precision The authors then tried to improve the results using 002ltering heuristics and found that keeping only the most frequently cochanged entities yielded the best results As opposed to our approach the evaluated 002ltering heuristics were only applied on entities recovered using association rules and not using clustering techniques The focus of their study was also more speci\002c as they recommend program elements that were strictly changed  as opposed to recommending elements that might be inspected by developers 6 Conclusion Developers often need to discover code that has been navigated in the past We investigated to what extent we can bene\002t from change clusters to guide program navigation We de\002ned change clusters as groups of elements that were part of transactions or change sets that had elements in common Our analysis of close to 12 years of software change data for a total of seven different open-source systems revealed that less than 12 of the changes we studied could have bene\002ted from change clusters We conclude that further efforts should thus focus on maximizing the quality of the match between the current task and past transactions rather than 002nding many potential matches Our study has already helped us in this goal by providing reliable evidence of the effectiveness of some 002ltering heuristics and useful insights for the development of additional heuristics Acknowledgments The authors thank Emily Hill and Jos  e Correa for their advice on the statistical tests and the anonymous reviewers for their helpful suggestions This work was supported by NSERC 
25 
25 
25 
25 
25 


References  B Andreopoulos A An V  Tzerpos and X W ang Multiple layer clustering of large software systems In Proc 12th Working Conf on Reverse Engineering  pages 79ñ88 2005  S Bouktif Y G Gu  eh  eneuc and G Antoniol Extracting change-patterns from cvs repositories In Proc 13th Working Conf on Reverse Engineering  pages 221ñ230 2006  S Breu and T  Zimmermann Mining aspects from v ersion history In Proc 21st IEEE/ACM Int'l Conf on Automated Software Engineering  pages 221ñ230 2006  A Christl R K oschk e and M.-A Store y  Equipping the re\003exion method with automated clustering In Proc 12th Working Conf on Reverse Engineering  pages 89ñ98 2005  D 020 Cubrani  c G C Murphy J Singer and K S Booth Hipikat A project memory for software development IEEE Transactions on Software Engineering  31\(6 465 2005  B Fluri and H C Gall Classifyi ng change types for qualifying change couplings In Proc 14th IEEE Int'l Conf on Program Comprehension  pages 35ñ45 2006  A E Hassan and R C Holt Replaying de v elopment history to assess the effectiveness of change propagation tools Empirical Software Engineering  11\(3 2006  D H Hutchens and V  R Basili System s tructure analysis Clustering with data bindings IEEE Transactions on Software Engineering  11\(8 1985  D Janzen and K De V older Na vig ating and querying code without getting lost In Proc 2nd Int'l Conf on AspectOriented Software Development  pages 178ñ187 2003  J K ot hari T  Denton A Shok ouf andeh S Mancoridis and A E Hassan Studying the evolution of software systems using change clusters In Proc 14th IEEE Int'l Conf on Program Comprehension  pages 46ñ55 2006  A K uhn S Ducasse and T  G  021rba Enriching reverse engineering with semantic clustering In Proc 12th Working Conf on Reverse Engineering  pages 133ñ142 2005  M P  Robillard T opology analysis of softw are dependencies ACM Transactions on Software Engineering and Methodology  2008 To appear  M P  Robillard and P  Mangg ala Reusing program in v estigation knowledge for code understanding In Proc 16th IEEE Int'l Conf on Program Comprehension  pages 202 211 2008  J Sillito G Murph y  and K De V older Questions programmers ask during software evolution tasks In Proc 14th ACM SIGSOFT Int'l Symposium on the Foundations of Software Engineering  pages 23ñ34 2006  A V an ya L Ho\003and S Klusener  P  v an de Laar and H van Vliet Assessing software archives with evolutionary clusters In Proc 16th IEEE Int'l Conf on Program Comprehension  pages 192ñ201 2008  N W ilde and M C Scully  Softw are reconnaissance Mapping program features to code Software Maintenance Research and Practice  7:49ñ62 1995  A T  Y ing G C Murph y  R Ng and M C Chu-Carroll Predicting source code changes by mining change history IEEE Transactions on Software Engineering  30\(9 586 2004  A Zeller  The future of programming en vironments Integration synergy and assistance In Proceedings of the 29th International Conference on Software Engineering The Future of Software Engineering  pages 316ñ325 2007  T  Zimmermann and P  W eiﬂgerber  Preprocessing C VS data for 002ne-grained analysis In Proc 1st Int'l Workshop on Mining Software Repositories  pages 2ñ6 May 2004  T  Zimmermann P  W eiﬂgerber  S Diehl and A Zeller  Mining version histories to guide software changes In Proc 26th ACM/IEEE Int'l Conf on Software Engineering  pages 563ñ572 2004 A Clustering Algorithm This algorithm is not sensitive to whether a given program element exists or not in a given version of a program For example if method m exists in one version it is considered a valid program element even if it is removed in a later version In the rest of this section we use the term program element to refer to the uniquely identifying representation of the element e.g a Java fully-quali\002ed name Let T be a transaction modeled as a set of program elements changed together during the history of a software system Let T be a sequence of transactions In this algorithm a cluster is also modeled as a set of elements 1 Input  T  A sequence of transactions 2 Parameter  M IN O VERLAP  A positive non-zero value indicating the minimum overlap between two transactions in a cluster 3 Var  C  A set of clusters initially empty 4 for all T i 2 T do 5 MaxOverlap  0 6 MaxIndex  000 1 7 for all C j 2 C do 8 if j C j  T i j  MaxOverlap then 9 MaxOverlap  j C j  T i j 10 MaxIndex  j 11 end if 12 end for 13 if MaxIndex   0  MaxOverlap 025 M IN O VERLAP  then 14 C MaxIndex   C MaxIndex  T i  15 else 16 NewCluster  T i 17 C  C  f NewCluster g 18 end if 19 end for 20 return C B Systems Analyzed System home pages last veri\002ed 7 May 2008 Ant ant.apache.org Azureus azureus.sourceforge.net Hibernate www.hibernate.org JDT-Core www.eclipse.org/jdt/core JDT-UI www.eclipse.org/jdt/ui Spring springframework.org Xerces xerces.apache.org 
26 
26 
26 
26 
26 


