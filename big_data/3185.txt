An Effective Algorithm for Mining Positive and Negative Association Rules  Honglei Zhu School of Computer and Communication Lanzhou University of Technology, LUT GS, China z_honglei@126.com Zhigang Xu School of Computer and Communication Lanzhou University of Technology, LUT GS, China yangzij@lut.cn   Abstract Recently, mining negative association rules has received some attention and been proved to be useful in real world. This paper presents an efficient algorithm PNAR r mining both positive and negative association rules in databases The algorithm extends traditional association rules to include negative association rules. When mining negative association rules, we adopt another minimum support threshold to mine frequent negative itemsets. With a correlation coefficient measure and pruning strategies, the algorithm can find all valid association rules quickly and overcome some limitations of the previous mining methods. The experimental results demonstrate its effectiveness and efficiency Keywords-data mining; association rule; frequent itemset correlation coefficient; pruning strategy I   I NTRODUCTION  The research and application of data mining technology are a hot spot in database and artificial intelligence at recent years Association Rules Mining introduced by R. Agrawal [1 is an  important research topic among the various data mining problems. Association rules have been extensively studied in the literature for their usefulness in many application domains such as market basket analysis, recommender systems diagnosis decisions support, telecommunication, intrusion detection, and etc All the traditional association rule mining algorithms were developed to find positive associations between itemsets Several algorithms has been developed to cope with the popular and computationally expensive task of association rule mining, such as Apriori [1   A I S 2   D H P   3    Par titi o n   4    and etc With the increasing use and development of data mining techniques and tools, much work has recently focused on finding negative patterns, which can provide valuable information. However, mining negative association rules is a difficult task, due to the fact that there are essential differences between positive and negative association rule mining. We will attack two key problems in negative association rule mining 1\ How to effectively search for negative frequent itemsets 2\ How to effectively identify negative association rules Although some researchers pointed out the importance of negative associations, only some groups of researchers \([5 6   7 an d etc   p r o pos ed an  alg o r ith m to m i n e th es e ty pes  of  associations. This not only illustrates the novelty of negative association rules, but also the challenge in discovering them II  B ASIC K NOWLEDGE  A  Concepts and Definitions Let I  i 1  i 2  i n be a set of n distinct literals called items Let DB be a set of transactions, where each transaction T is a set of items, and each transaction is associated with a unique identifier called TID Let A called an itemset, be a set of items in I The number of items in an itemset is the length or the size of an itemset. Itemsets of length k are referred to as k itemsets. A transaction T is said to contain A if A 002 T An association rule is an implication of the form A 000 B where A 002 I  B 002 I and A 001 B  003 We call A the antecedent of the rule, and B the consequent of the rule The rule A 000 B has a support denoted as supp  s in DB if s of the transactions in DB contains A 001 B In other words the support of the rule is the probability that A and B hold together among all the possible presented cases. i.e supp  A 000 B  supp  A 001 B  P  A 001 B  1 The rule A 000 B has a measure of its strength called confidence denoted as conf  c if c of transactions in DB that contain A also contain B In other words, the confidence of the rule is the conditional probability that the consequent B is true under the condition of the antecedent A i.e conf  A 000 B  P  B  A  supp  A 001 B  supp  A  2  B  Classical Method The classical method is well known as the supportconfidence framework for association rule mining [1  I t ca n b e  decomposed into the following two issues 1\ Generate all frequent itemsets: All itemsets that have a support greater than or equal to user-specified minimum support  ms e generated 
2008 International Conference on Computer Science and Software Engineering 978-0-7695-3336-0/08 $25.00 © 2008 IEEE DOI 10.1109/CSSE.2008.1199 455 


2\ Generate all the rules that have a user-specified  minimum confidence  mc   in the following naive way: For every frequent itemset X and any B 002 X let A=X B If the rule A 000 B has the mc then it is a valid rule The generative rules are called interesting positive rules  A frequent itemset denoted as PL 8 is an it em set th a t  meets the user-specified ms Accordingly we define an infrequent itemset denoted as NL as an itemset that does not meet the user-specified ms  The second subproblem is straight forward and can be done efficiently in a reasonable time. However, the first subproblem is very tedious and computationally expensive for very large database and this is the case for many real life applications In order to generate the frequent itemsets, an iterative approach is used to first generate the set of frequent 1-itemsets L 1 then the set of frequent itemsets L 2 and so on until for some value of r the set L r is empty. At this stage the algorithm can be terminated. During the k th iteration of this procedure a set of candidates C k is generated by performing a k 2\join on the frequent itemsets L k 1 The itemsets in this set C k are candidates for frequent itemsets, and the final set of frequent itemsets L k  must be a subset of C k Each element of C k needs to be validated against the transaction database to see if it indeed belongs to L k  The validation of the candidate itemset C k against the transaction database seems to be bottleneck operation for the algorithm. In order to improve the algorithm efficiency, the apriori property is introduced that all subsets of a frequent itemset A in DB are also frequent in DB and all supersets of an infrequent itemset A in DB are also infrequent in DB  C  Negative Association Rules The negation of an itemset A is indicated by A which means the absence of the itemset A We call a rule of the form A 000 B a positive association rule and rules of the other forms  A 000  B  A 000 B and A 000  B  negative association rules  The support and confidence of the negative association rules can make use of those of the positive association rules [9   The support is given by the following formulas supp  A supp  A  3  supp  A 001  B  supp  A  supp  A 001 B  4  supp  A 001 B  supp  B  supp  A 001 B  5  supp  A 001  B supp  A  supp  B  supp  A 001 B  6  The confidence is given by the following formulas   sup   sup   sup   A p B A p A p B A conf 004    000  7    sup 1   sup   sup   A p B A p A p B A conf  004   000   8    sup 1   sup   sup   sup 1   A p B A p B p A p B A conf  004      000   9  The negative association rules discovery seeks rules of the three forms  with their support and confidence greater than, or equal to, user-specified ms and mc thresholds respectively These rules are referred to as an interesting negative association rule  III  P NAR A LGORITHM  A  Correlation Coefficient When mining positive and negative association rule at the same time, we will find that the mining rules are contradictory frequently. For example, the rules of the forms A 000  B and  A 000 B may be mined together, but the two rules are contradictory. In order to resolve these contradictions, we can judge the types of mining association rules by the correlation coefficient [10  L et  A and B for the two itemsets. The correlation coefficient \(denoted as corr A,B can show the relevance of the two itemsets.  As follows   sup   sup   sup  B p A p B A p corr B A 004   10  The value of correlation coefficient  exist the following three situations 1\ If corr A,B 1, then A and B are positive correlation. The more A occurs in a transaction the more B will likely also occur in the same transaction and vice versa 2 corr A,B 002 1, then A and B are independent. The B  occurs in a transaction, and it has no concern with whether the A occurs in the same transaction or not 3\ If corr A,B 1, then A and B are negative correlation. The more A occurs in a transaction the less B will likely also occur in the same transaction and vice versa By the definition of correlation coefficient, we can conclude the below lemmas Lemma 1: If the itemset A and B are positive correlation then the forms of A 000 B or A 000  B will be mined Lemma 2: If the itemset A and B are negative correlation then the forms of A 000  B or A 000 B will be mined B  Pruning Strategies As we have seen, there can be an exponential number of infrequent itemsets in a database, and only some of them are useful for mining interesting association rules. Therefore pruning strategy is critical to efficient search for interesting frequent negative itemsets. When mining negative association rules, we can adopt different minimum support  dms  minimum confidence  dmc threshold to improve the usability of the rules Through the experimental analysis, we found that the association rules of the forms A 000 B and A 000  B have considerable proportion when mining both positive and negative association rules. In particular, the number of the form  A 000  B is very large, and these rules including pure negative itemsets are usually of little use in real application. For 
456 


example, we assume that the database DB in a supermarket contain n transactions. Now we concern the sale of tea t and coffee c Suppose we mine the rule of the form t 000  c  which means customers not to buy tea and coffee in a transaction, the result is not useful to our market basket analysis. So we adopt a pruning strategy that we will not to consider the part negative association rules of the form  A 000  B to improve mining efficiency. The search space can be significantly reduced by the pruning strategy In addition, we are only interested in those absence itemsets whose positive counterparts are frequent for market basket analysis when mining negative association rules. For example the absence itemset A is not show if the itemset A is not frequent. The pruning strategy is more benefit to generate frequent 1-itemset. Because of reducing the number of frequent 1-itemset, the number of frequent and infrequent k itemset is reduced accordingly C  PNAR Algorithms As mentioned before, the process of mining both positive and negative association rules can be decomposed into the following three subproblems, in a similar way to mining positive rules only 1\enerate the set PL of frequent itemsets and the set NL of infrequent itemsets 2\ Extract positive rules of the form A 000  B in PL  3\ Extract negative rules of the forms A 000  B and  A 000 B in NL  Let DB be a database, and ms  mc  dms and dmc given by the user. Our algorithm for extracting both positive and negative association rules with a correlation coefficient measure and pruning strategies is designed as follows Algorithm 1  Positive and Negative Association Rules  PNAR   Input DB  ms  mc  dms  dmc respectively a set of transactions minimum support  minimum confidence  different minimum support  different minimum confidence    Output AR Positive and Negative Association Rules Generate the itemsets PL and NL  0 positiveA 0005 001\025 003   negativeAR 001\025 003  positive and negative AR itemsets 1 PL 001\025 003   NL 001\025 003  2\n the database and find the set of frequent 1-itemset  L 1  3 PL 0018 PL 001 L 1  4 for  k 2 L k\000\024 001 003 k   5 C k  L k\000\024\000\003 001\036\000\003 L k\000\024  6 for each  i 001\031 C k  7 s  supp  i  8 if s 000 ms then  9 L k 0018 L k 001  i    10 PL 0018 PL 001 L k 11 12 else    13 NL k 0018 NL k 001  i    14 NL 0018 NL 001 NL k 15 Generate positive association rules in PL  16 for each frequent itemset i in PL 17 for each expression   A 001 B  i and A 001 B  003   18 corr A,B supp\(A 001 B\/\( supp\(A\ * supp\(B  19 if corr A,B  1 then  20 if  conf  A 000 B  000 mc  then  21 positiveAR  001\025 positiveAR 001  A 000 B  22 Generate negative association rules in NL  23 for each infrequent itemset i in NL 24 for each expression   A 001 B  i and A 001 B  003  25 corr A,B supp\(A 001 B\/\( supp\(A\ * supp\(B 26 if  corr A,B  1 then  27 if  supp  A 001  B  000 dms and conf  A 000  B  000 dmc  then  28 negativeAR  001\025 negativeAR 001  A 000  B  29 if  supp  A 001 B  000 dms and conf  A 000 B  000 dmc  then  30 negativeAR  001\025 negativeAR 001    A 000 B  31 32  33  34 AR 001\025 positiveAR 001 negativeAR  35\ ruturn AR  PNAR generates not only all positive association rules in PL but also negative association rules in NL When mining negative association rules, we adopt different threshold to improve the usability of the frequent negative itemsets. With a correlation coefficient measure and pruning strategies, the algorithm can find all valid association rules quickly. An example of mining positive and negative itemsets is given below for illustrative purposes 
457 


D  Experimental Results For the convenience of comparison, we conducted our experiments on the synthetic dataset to study the behaviors of the algorithm Example Let us consider a small transactional table with 10 transactions and 6 items. In Table 1 a small transactional database is given TABLE I  A  T RANSAACTION D ATABASE TD TID Items 1 A,C,D 2 B,C 3 C 4 A,B,F 5 A,C,D TID Items 6 E 7 B,F 8 B,C,F 9 A,B,E 10 A,D  In the following tables L k is denoted as all frequent kitemset. Given that ms 0.3, all the positive and negative frequent itemsets can then be discovered in Table 2 by PNAR  algorithm if we adopt the same ms Given that dms 0.4, all the positive and negative frequent itemsets can then be discovered in Table 3 if we adopt the different ms And in Table 4, we compare three algorithms in the same TD  TABLE II  F REQUENT I TEMSETS G ENERATED F ROM T HE D ATABASE W ITH T HE S AME MS I N T ABLE 1 L 1 A B C D F Supp 0.5 0.5 0.5 0.3 0.3 L 2 AD BF A B A C A F Supp 0.3 0.3 0.3 0.3 0.4 B C B D C D 0.3 0.5 0.3 C F D F AB  AC 0.4 0.3 0.3 0.3  B C  B D  DF 0.3 0.3 0.3 L 3 AD¨F A BD B DF Supp 0.3 0.3 0.3 A B D  BD F 0.3 0.3  TABLE III  F REQUENT I TEMSETS G ENERATED F ROM T HE D ATABASE W ITH T HE D IFFERENT MS I N T ABLE 1 L 1 A B C D F Supp 0.5 0.5 0.5 0.3 0.3 L 2 AD BF A F B D C F Supp 0.3 0.3 0.4 0.5 0.4  From Table 4 we discover that the PNAR algorithm can reduce the number of the positive and negative frequent itemsets efficiently. Especially the number of frequent 2itemset is less than before in a certain extent. From Table 4 we can detect the number of frequent 2-itemset is less six itemsets than SRM algorithm [6 a n d t h e  num b e r o f  fr eq ue nt  2 i t e m se t  with the different ms is less ten itemsets than those with the same ms So the PNAR algorithm can reduce the search space efficiently and improve the efficiency, and can overcome some limitations of the previous mining methods TABLE IV  C OMPARISON O F T HE T HREE A LGORITHMS  L 1 Apriori 5 SRM 10 PNAR 5 L 2 21 15 L 3 0 10 5 L 4 0 1 0 2 PNAR 5 5 0 0 ms 0.3 0.3 0.3 0.3 dms 0.4  IV  C ONCLUSION  In this paper, we have designed a new algorithm for efficiently mining positive and negative association rules in databases. Our approach is novel and different from existing research. We have designed pruning strategies for reducing the search space and improving the usability of mining rules, and have used the correlation coefficient to judge which form association rule should be mined. It is shown by empirical studies that the proposed approach is effective, efficient and promising R EFERENCES  1  R. Agrawal, T. IMIELINSKI, and A. SWAMI, ìMining association rules between sets of items in massive databases,î In Proc. of the 1993 ACM SIGMOD International Conference on Management of Data ACM, Washington D.C., 1993, pp. 207-216 2  R. Agrawal, R. Srikant, ìFast Algorithms for Mining Association Rules,î In Proc. of the 20th Int. Conf. on Very Large Databases\(VLDB 94\, Santiago, Chile, 1994, pp. 487-499 3  J. S. Park, M. S. Chen, and P. S. Yu, ìAn Effective Hash-based Algorithm for Mining Association Rules,î In Proc. of the ACM SIGMOD Int. Conf. on Management of data \(ACM SIGMOD í95\, San Jose, California, 1995, pp. 175-186 4  A. Savasere, E. Omiecinski, and S. Navathe, ìAn efficient algorithm for mining association rules in large databases,î In Proc.1995 Int. Conf Very Large Database \(VLDBí95\, Zurich, Switzerland, 1995, pp. 1-24 5  A. Savasere, E. Omiecinski, and S. Navathe, ìMining for strong negative associations in a large database of customer transactions,î In Proc. of ICDE, 1998, pp. 494-502 6  W. Teng, M. Hsieh, and  M. Chen, ìOn the mining of substitution rules for statistically dependent items,î In Proc. of ICDM, 2002, pp. 442-449 7  X. Wu, C. Zhang, and S. Zhang, ìEfficient Mining of Both Positive and Negative Association Rules,î ACM Transactions on Information Systems, Vol. 22, No. 3, 2004, pp. 381ñ405 8  M. CHEN, J. HAN, and P. YU, ìData mining: An overview from a database perspective,î IEEE Transactions on Knowledge and Data Engineering, Vol. 8, No. 6, 1996, pp. 866-883 9  X. Dong, S. Wang, H. Song, and Y. Lu, ìStudy on Negative Association Rules,î Transactions of Beijing Institute of Technology, Vol. 24, No. 11 2004, pp. 978-981   S. Brin, R. Motwani, and C. Silverstenin, ìBeyond market baskets Generalizing association rules to correlations,î In Proc. of the 1997 ACM SIGMOD International Conference on Management of Data ACM, Tucson, Arizona, 1997, pp. 265ñ276 
458 


TABLE III D ATABASE WITH MEMBERSHIP VALUES  TID Age Salary Young M iddle Old Low Medium High 1 0.8 0.2 0 0.75 0.25 0 2 0.5 0.5 0 0 1 0 3 0.25 0.75 0 0.25 0.75 0 4 0 0.5 0.5 0 0.5 0.5 eter determining the degree of dependency on the iteration number In this paper  5 D GNP Structure for Association Ru l e Minin g GNP examines the attribute values of database tuples using judgment nodes and calculates the measurements of association rules using processing nodes 9 Attrib utes and their values correspond to judgment nodes and their judgments in GNP respectively Therefore the connections of judgment nodes are represented as association rules The measurements include support  conﬁdence and  2 value described in the next section Fig 7 shows an example of the connection of nodes in GNP for association rule mining P 1 is a processing node and is a starting point for calculating association rules Each processing node has an inherent numeric order  P 1  P 2   P s  and is connected to a judgment node Yes-side of the judgment node is connected to another judgment node Judgment nodes can be reused and shared with some other association rules because of GNP’s features No-side of the judgment node is connected to the next numbered processing node Fig 7 A connection of nodes in GNP for association rule mining In Fig 7 N is the number of total tuples and a  b  c and d are the numbers of tuples moving to Yes-side at each judgment node Once a GNP individual starts the searching for association rules the membership values are employed to determine the transition from one judgment node to another that is according to the membership value of the attribute A i described in section B the probability of selecting the judgment result Yes  No is calculated E Findin g Association Ru l es usin g GNP The number of kinds of the judgment node functions are equal to the number of attributes multiplied by the number of kinds of linguistic terms in a database For example supposing that we examine tuple 1  TID  in the judgment node of  A i is F iq  A i   a random number from the interval  is compared with the v alue calculated by F iq  A i   Then if the random number is smaller that the value the transition moves to Yes-side otherwise it moves to No-side If the examination of the connection from the starting point P s ends then GNP examines tuple 2  TID likewise Thus all tuples in the database will be examined The total number of tuples moving to Yes-side at each judgment node is calculated for every processing node which is a starting point for calculating association rules All GNP individuals are searched in parallel at the same time If Yes-side connection of judgment nodes continues and the number of the judgment nodes becomes a cutoff value maximum number of attributes in extracted association rules then Yes-side connection is transferred to the next processing node obligatorily F Measurements of the Association Ru l es usin g GNP Table IV shows the measurements such as support and conﬁdence of the association rules In Fig 7 and Table IV A 1 High,A 2 Low A 3 Mid and A 4 High are example of  A i is F iq  A i   where the membership functions have three kinds of linguistic terms such us Low Medium and High i.e  F i 1  Low  F i 2  Medium and F i 3  High  and A i is the fuzzy variable corresponding to attribute A i  The proposed method measures the signiﬁcance of associations via the  2 test for correlation used in classical statistics For example we are able to calculate the support of A 3 Mid and A 3 Mid  A 4 High  if we change the connection of P 1 node from A 1 High node to A 3 Mid node in Fig 7 We can repeat this like a chain operation in each generation Now we deﬁne important association rules by the ones which satisfy the following  2  2 min  5 support 012 sup min  6 Where  2 min and sup min are the minimum  2 and support values given by supervisors In this deﬁnition if the rule  X  Y  is important then X  Y  X  Y  X   Y Y  X Y  X  Y  X and  Y  X are also important rules If required we can also add conﬁdence to the deﬁnition The extracted association rules are stored in a pool all together through generations When an important rule is extracted by GNP the overlap of the attributes is checked and it is also checked whether an important rule is new or not i.e  whether it is already in the pool or not If the rule is new it is stored in the pool with its support  conﬁdence and  2  If the association rule is not new because the linguistic terms that describe the attributes are different from the ones of the association rule in the pool the association rule with higher  2 value is stored then the pool is updated in every generation and only important association rules with higher  2 values are stored See Fig 17 60 2008 I EEE Co n g r e ss o nE vol uti o nar yCo mputati o n C E C 2008 


TABLE IV S UPPORT AND CONFIDENCE OF ASSOCIATION RULES   association rules support conﬁdence A 1 High  A 2 Low b  N b  a A 1 High  A 2 Low  A 3 Mid c  N c  a A 1 High  A 2 Low  A 3 Mid  A 4 High d  N d  a A 1 High  A 2 Low  A 3 Mid c  N c  b A 1 High  A 2 Low  A 3 Mid  A 4 High d  N d  b A 1 High  A 2 Low  A 3 Mid  A 4 High d  N d  c Fig 8 The pool is updated generation by generation G Fitness of GNP Fitness of GNP is deﬁned by F   r  R   2  r   n ante  r   1  n con  r   1  new  r   7 The items are as follows R  set of sufﬁxes of extracted important association rules satisfying 5 and 6 in a GNP individual  2  r    2 value of the rule r  n ante  r   the number of attributes in the antecedent of the rule r  n con  r   the number of attributes in the consequent of the rule r   new  r   additional constant deﬁned by  new  r    new the rule r is new 0 the rule r has been already extracted 8  2  r   n ante  r   n con  r  and  new  r  are concerned with the importance complexity and novelty of the rule r  respectively H Genetic Operators of GNP The following genetic operators are executed to GNP individuals  Crossover Operator producing offspring from parents Uniform crossover is used Judgment nodes are selected as crossover nodes with the probability of P c  Two parents exchange the gene of the corresponding crossover nodes  Mutation-1 Operator that affects one individual The connection of the judgement nodes is changed by mutation rate of P m 1   Mutation-2 Operator that also affects one individual The function of the judgment nodes is changed by mutation rate P m 2  All GNP individuals in a population have the same number of judgment and processing nodes however the node with the same node number does not have the same function All the connections of the processing nodes are changed randomly in order to extract rules efﬁciently I Use of Acquired Information We can use the frequency of the attributes of all extracted rules or rules extracted in some of the latest generations when doing Mutation-2 We deﬁne the probability of selecting the attribute F iq  A i  for judgment nodes by the following P g iq  n g  F iq  A i   C  k  K  q  n g  F kq  A k   C   9 Where P g iq is the probability of selecting F iq  A i  using the information on the association rules extracted in the latest g generations n g  F iq  A i  is the frequency of the attribute F iq  A i  in the rules extracted in the latest g generations K is the set of sufﬁxes of attributes If no rules are extracted in the recent g generations then P g iq is equal to the inverse of the number of attributes C is a constant given by the supervisor Fig 9 shows the owchart of our proposed method VI S IMULATION R ESULTS The performance of the proposed method was evaluated by doing two simulations In simulation 1 the extraction of association rules is done by using xed parameters of the fuzzy membership functions that is they remain xed for all generations In simulation 2 the parameters of the fuzzy membership functions evolve by non uniform mutation in 2008 I EEE Co n g r e ss o nE vol uti o nar yCo mputati o n C E C 2008 17 6 1 


Fig 9 Flowchart of the GNP based data mining method order to get suitable parameters and increase the number of association rules stored in the pool All experiments were run on a real database that contains continuous attributes about VOCs Volatile Organic Compounds It consists of 10 attributes  A i  i 1  2  10  and 825 tuples In simulations the population size of GNP individuals is 120 The number of processing nodes and judgment nodes are 10 and 78 respectively We use 5   2 min  6.63 6  sup min 0  1  and 8   new  150  In addition the detailed conditions of extracting association rules in the simulations are as follows n ante  r  n con  r  012 6  n ante  r   5  n con  r   5  The probability of crossover and mutation are P c 15  78  P m 1 1  3 and P m 2 1  5 78 corresponds to the number of judgment nodes The number of changing the connections of the processing nodes at each generation is 5 The simulations were executed for 500 generations and 20 trials are studied here for all the experiments changing the random sequences All algorithms were coded in Java Experiments were done on a 1.50GHz Pentium M with 504MB RAM A Simu l ation 1 In this simulation when transforming each continuous attribute of the database into a fuzzy attribute the parameters    and  of the trapezoidal and triangular membership functions remain xed for all generations it means that for the transition from one judgment node to another in GNP individuals the xed membership functions are used for all generations As an illustration the original membership function for one attribute is shown in Fig 10 Fig 11 shows the number of association rules extracted in the pool It is shown from this gure that the number of rules increases gradually as the generation goes on However the performance is not so good compared with Simulation 2 where the membership functions are also evolved Fig 12 shows the average tness values of the GNP individuals They remain almost at the same level during all generations B Simu l ation 2 In this simulation the parameters    and  of the membership functions are evolved using non uniform mutation Fig 10 An example of the original fuzzy membership function Fig 11 Association rules stored in the pool when membership functions are xed Fig 12 Average tness value of GNP individuals when membership functions are xed it means that for the transition from one judgment node to another in GNP individuals evolved membership functions are used in every generation Fig 13 shows the number of association rules extracted in the pool while Fig 14 shows the average tness values of the GNP individuals It is found that both the number of rules extracted and the average tness value increased compared to Simulation 1 It shows that the evolution of the membership functions generation by generation is helpful for extracting many rules and for improving the performance of the GNP individuals’s tness value Fig 15 shows the evolved membership function of Fig 10 In this simulation the pool of the association rules is updated in every generation exchanging an association rule with lower  2 value for the same association rule with higher  2 value as a result association rules are stored with the parameters of the evolved membership functions 17 62 2008 I EEE Co n g r e ss o nE vol uti o nar yCo mputati o n C E C 2008 


Fig 13 Association rules stored in the pool when membership functions are evolved Fig 14 Average tness value of the GNP individuals when membership functions are evolved Fig 15 An example of the evolved fuzzy membership function VII C ONCLUSIONS AND F UTURE W ORK In this paper we have proposed an association rule mining algorithm based on Genetic Network Programming and Fuzzy Sets Theory to extract association rules from databases with continuous values Extracted association rules are stored in a pool all together through generations in order to nd new important rules The pool is also updated in every generation exchanging the same association rule with lower  2 value for higher  2 value These rules are reﬂected in genetic operators as acquired information Our method measures the signiﬁcance of association rules using conﬁdence support and  2 test We have performed experiments and estimated the performances of the proposed algorithm The results have shown that the proposed method extracts important association rules effectively in short time Adjusting the membership functions according to the frequency of the attributes stored in the pool in order to nd the most suitable parameters is our future work R EFERENCES  R Agra w al T  Imielinksi and A  S w ami Mining association rules between sets of items in large databases The 1993 ACM SIGMOD Conference pp 207-216 1993  R Agra w al T  Imielinksi and A  S w ami Database mining a p erfor mance perspective in The IEEE Transactions on Knowledge and Data Engineering Vol 5 No 6 pp 914-925 1993  I Graham and P  L  Jones Expert Systems Kno wledge Uncertainty and Decision Chapman and Computing Boston pp.117-158 1988  A Kandel Fuzzy Expert Systems CRC Press Boca Raton pp 8-19 1992  T  Eguchi K Hirasa w a  J  H u and N Ota  A study of Ev olutionary Multiagent Models Based on Symbiosis IEEE Trans on S y st Man and C y bernetics Part B  Vol.36 No.1 pp.179-193 2006  S Mab u  K  Hirasa w a and J Hu  A Graph-Based Ev olutionary Algorithm Genetic Network Programming and Its Extension Using Reinforcement Learning Evolutionary Computation MIT press Vol 15 No.3 2007  K Hirasa w a  M  Okubo H Katagiri J Hu and J Murata Comparison between Genetic Network Programming and Genetic Programming In Proc of Con g ress of E v o l utionar y Computation  pp.1276-1282 2001  K Shimada K Hirasa w a and J  Hu Genetic Netw ork Programming with Acquisition Mechanisms of Association Rules Journa l of Adv anced Computationa l Inte ll i g ence and Inte ll i g ent Informatics  Vol 10 No 1 pp.102-111 2006  K Shimada K Hirasa w a and J  Hu Class Association Rule Mining with Chi-Squared Test Using Genetic Network Programming In Proc of IEEE SMC 2006  pp.5338-5344 2006  C Zhang and S  Zhang Association Rule Mining models and algorithms Springer Sydney Australia 2002 pp 238  S Brin R Motw ani and C Silv erstein Be yond mark et bask ets generalizing association rules to correlations In Proc of the 1997 ACM SIGMOD Conf  pp.265-276 1997  R.J Miller and Y  Y ang Association rules o v er interv al data In Proc of ACM SIGMOD Conf Mana g ement of Data  1997  K Hirota and W  Pedrycz Linguistic data mining and fuzzy modelling Proc IEEE Internat Conf Fuzzy Systems Vol 1 1996  K.C.C Chan and W H Au An E f fecti v e Algorithm for Mining Interesting Quantitative Association Rules in Proc of the 12th ACM Symp on Applied Computing Feb 1997  K.C.C Chan and W H Au Mining Fuzzy Association Rules  i n Proc of the 6th ACM Int’l Conf on Information and Knowledge Management Las Vegas Nevada 1997  H Ishib uchi T  Nakashima T  Y a mamoto Fuzzy association rules for handling continuous attributes IEEE ISIE 2001  E Hullermeier and J Beringer  Mining implication-based fuzzy association rules in databases 2003 Elsevier  A Gyenesei Mining weighted association rules for fuzzy quantitati v e items TUCS Technical Report No 346 May 2000  A Gyenesei A fuzzy approach for mining quantitati v e association rules TUCS Technical Report March 2000  R Srikant and R  Agra w al Mining Quantitati v e Association Rules in Large Relational Tables Proc of ACM-SIGMOD Montreal Canada 1996  M Kaya and R Alhajj Genetic algorithm based frame w o rk for mining fuzzy association rules Elsevier 2004  T  P  Hong C H Chen Y  L W u and Y  C  Lee Mining membership functions and fuzzy association rules The 2003 Joint Conference on AI Fuzzy System and Grey System 2003  R Mendez F  V o znika A Freitas and J Nie v ola Disco v e ring Fuzzy Classiﬁcation Rules with Genetic Programming and Co-Evolution in Proc of the 5th European Conference on Principles of Data Mining and Knowledge Discovery PKDD 2001 LNAI 2168 pp 314-325 Springer Berlin 2001  M L y man and G  L e w ando wsk y  Genetic Programming for Association Rules on Card Sorting Data in Proc of the 2005 conference on Genetic and evolutionary computation GECCO 2005 pp 1551-1552 USA 2005  Z Michale wicz Genetic Algorithms  D ata Structures  E v olution Programs 3rd Edition Springer 1996 2008 I EEE Co n g r e ss o nE vol uti o nar yCo mputati o n C E C 2008 17 6 3 


5 Related Work There exists extensive previous work on both the mining of software repositories and on the use of clustering algorithms in software engineering This discussion focuses on the most similar and recent work in the area of software evolution Mining Software Repositories Our technique was partially inspired by the work of Zimmermann et al and Y ing et al 17 on the mining of association rules in change history As described in Section 1 we sought to expand the technique to be able to recommend larger but less precise clusters of elements to guide program navigation Bouktif et al also investigated how to recommend cochanges in software development As opposed to the work cited above Bouktif et al used change patterns instead of association rules Also their approach does not attempt to reconstruct transactions and can consider associated 002les that were changed in different transactions ChangeDistiller is a tool to classify changes in a transaction into 002ne-grained operations e.g addition of a method declaration and determines how strongly the change impacts other source code entities Our approach uses similar repository analysis techniques but is focused on providing task-related information as opposed to an overall assessment of a system's evolution Finally repository mining can also be used to detect aspects in the code In this conte xt aspects are recurring sets of changed elements that exhibit a regular structure Aspects differ from the clusters we detect in the regular structure they exhibit which may not necessarily align with the code that is investigated as part of change tasks Clustering Analysis The classical application of clustering for reverse engineering involves grouping software entities based on an analysis of various relations between pairs of entities of a given version of the system Despite its long and rich history  e xperimentation with this approach continues to this day For example Andreopoulos et al combined static and dynamic information K uhn et al used a te xtual similarity measure as the clustering relation and Christl et al used clustering to assist iterative semi-automated reverse engineering The main dif ferences b e tween most clusteringbased reverse engineering techniques and the subject of our investigation is that the entities we cluster are transactions rather than software entities in a single version of a system For this reason our analysis is based strictly on the evolving parts of the system Both Kothari et al and V an ya et al 15 recently reported on their use of clustering to study the evolution of software systems The idea of using change clusters is the same in both works and ours but the purpose of the work is different Kothari et al use change clusters to uncover the types of changes that happened e.g feature addition maintenance etc during the history of a software system Vanya et al use change clusters which they call evolutionary clusters to guide the partitioning of a system that would increase the likelihood that the parts of the system would evolve independently In contrast we cluster transactions based on overlapping elements not 002les to recommend clusters to support program navigation as opposed to architectural-level assessment of the system Finally Hassan and Holt evaluated on 002ve open source systems the performance of several methods to indicate elements that should be modi\002ed together This study found that using historical co-change information as opposed to using simple static analysis or code layout offered the best results in terms of recall and precision The authors then tried to improve the results using 002ltering heuristics and found that keeping only the most frequently cochanged entities yielded the best results As opposed to our approach the evaluated 002ltering heuristics were only applied on entities recovered using association rules and not using clustering techniques The focus of their study was also more speci\002c as they recommend program elements that were strictly changed  as opposed to recommending elements that might be inspected by developers 6 Conclusion Developers often need to discover code that has been navigated in the past We investigated to what extent we can bene\002t from change clusters to guide program navigation We de\002ned change clusters as groups of elements that were part of transactions or change sets that had elements in common Our analysis of close to 12 years of software change data for a total of seven different open-source systems revealed that less than 12 of the changes we studied could have bene\002ted from change clusters We conclude that further efforts should thus focus on maximizing the quality of the match between the current task and past transactions rather than 002nding many potential matches Our study has already helped us in this goal by providing reliable evidence of the effectiveness of some 002ltering heuristics and useful insights for the development of additional heuristics Acknowledgments The authors thank Emily Hill and Jos  e Correa for their advice on the statistical tests and the anonymous reviewers for their helpful suggestions This work was supported by NSERC 
25 
25 
25 
25 
25 


References  B Andreopoulos A An V  Tzerpos and X W ang Multiple layer clustering of large software systems In Proc 12th Working Conf on Reverse Engineering  pages 79ñ88 2005  S Bouktif Y G Gu  eh  eneuc and G Antoniol Extracting change-patterns from cvs repositories In Proc 13th Working Conf on Reverse Engineering  pages 221ñ230 2006  S Breu and T  Zimmermann Mining aspects from v ersion history In Proc 21st IEEE/ACM Int'l Conf on Automated Software Engineering  pages 221ñ230 2006  A Christl R K oschk e and M.-A Store y  Equipping the re\003exion method with automated clustering In Proc 12th Working Conf on Reverse Engineering  pages 89ñ98 2005  D 020 Cubrani  c G C Murphy J Singer and K S Booth Hipikat A project memory for software development IEEE Transactions on Software Engineering  31\(6 465 2005  B Fluri and H C Gall Classifyi ng change types for qualifying change couplings In Proc 14th IEEE Int'l Conf on Program Comprehension  pages 35ñ45 2006  A E Hassan and R C Holt Replaying de v elopment history to assess the effectiveness of change propagation tools Empirical Software Engineering  11\(3 2006  D H Hutchens and V  R Basili System s tructure analysis Clustering with data bindings IEEE Transactions on Software Engineering  11\(8 1985  D Janzen and K De V older Na vig ating and querying code without getting lost In Proc 2nd Int'l Conf on AspectOriented Software Development  pages 178ñ187 2003  J K ot hari T  Denton A Shok ouf andeh S Mancoridis and A E Hassan Studying the evolution of software systems using change clusters In Proc 14th IEEE Int'l Conf on Program Comprehension  pages 46ñ55 2006  A K uhn S Ducasse and T  G  021rba Enriching reverse engineering with semantic clustering In Proc 12th Working Conf on Reverse Engineering  pages 133ñ142 2005  M P  Robillard T opology analysis of softw are dependencies ACM Transactions on Software Engineering and Methodology  2008 To appear  M P  Robillard and P  Mangg ala Reusing program in v estigation knowledge for code understanding In Proc 16th IEEE Int'l Conf on Program Comprehension  pages 202 211 2008  J Sillito G Murph y  and K De V older Questions programmers ask during software evolution tasks In Proc 14th ACM SIGSOFT Int'l Symposium on the Foundations of Software Engineering  pages 23ñ34 2006  A V an ya L Ho\003and S Klusener  P  v an de Laar and H van Vliet Assessing software archives with evolutionary clusters In Proc 16th IEEE Int'l Conf on Program Comprehension  pages 192ñ201 2008  N W ilde and M C Scully  Softw are reconnaissance Mapping program features to code Software Maintenance Research and Practice  7:49ñ62 1995  A T  Y ing G C Murph y  R Ng and M C Chu-Carroll Predicting source code changes by mining change history IEEE Transactions on Software Engineering  30\(9 586 2004  A Zeller  The future of programming en vironments Integration synergy and assistance In Proceedings of the 29th International Conference on Software Engineering The Future of Software Engineering  pages 316ñ325 2007  T  Zimmermann and P  W eiﬂgerber  Preprocessing C VS data for 002ne-grained analysis In Proc 1st Int'l Workshop on Mining Software Repositories  pages 2ñ6 May 2004  T  Zimmermann P  W eiﬂgerber  S Diehl and A Zeller  Mining version histories to guide software changes In Proc 26th ACM/IEEE Int'l Conf on Software Engineering  pages 563ñ572 2004 A Clustering Algorithm This algorithm is not sensitive to whether a given program element exists or not in a given version of a program For example if method m exists in one version it is considered a valid program element even if it is removed in a later version In the rest of this section we use the term program element to refer to the uniquely identifying representation of the element e.g a Java fully-quali\002ed name Let T be a transaction modeled as a set of program elements changed together during the history of a software system Let T be a sequence of transactions In this algorithm a cluster is also modeled as a set of elements 1 Input  T  A sequence of transactions 2 Parameter  M IN O VERLAP  A positive non-zero value indicating the minimum overlap between two transactions in a cluster 3 Var  C  A set of clusters initially empty 4 for all T i 2 T do 5 MaxOverlap  0 6 MaxIndex  000 1 7 for all C j 2 C do 8 if j C j  T i j  MaxOverlap then 9 MaxOverlap  j C j  T i j 10 MaxIndex  j 11 end if 12 end for 13 if MaxIndex   0  MaxOverlap 025 M IN O VERLAP  then 14 C MaxIndex   C MaxIndex  T i  15 else 16 NewCluster  T i 17 C  C  f NewCluster g 18 end if 19 end for 20 return C B Systems Analyzed System home pages last veri\002ed 7 May 2008 Ant ant.apache.org Azureus azureus.sourceforge.net Hibernate www.hibernate.org JDT-Core www.eclipse.org/jdt/core JDT-UI www.eclipse.org/jdt/ui Spring springframework.org Xerces xerces.apache.org 
26 
26 
26 
26 
26 


