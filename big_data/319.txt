html><head></head><body><pre style="word-wrap: break-word; white-space: pre-wrap;">Proceedings  of 2005 International Symposium on Electrical Insulating Materials, June 5-9, 2005, Kitakyushu, Japan P2-35 Nano-interfacial polarization phenomena and pentacene FET characteristics T.Manaka, E.Lim, R.Tamura, and M, Iwamoto Department of Physical Electronics, Graduate School of Science and Engineering Tokyo Institute of Technology, 2- 12- I-S3-33 0-okayama, Meguro-ku, Tokyo 152-8552,Japan E-mail: iwamoto@pe.titech.ac.jp ABSTRACT Nano-interfacial polarization on drain and source electrodes directly influences on the FET performance because carrier injection from electrodes rules the camer transport of organic FETs. To clarify the details the effect of Wiozone treatment of source and drain electrodes was examined. Significant change of the FET threshold voltage was confirmed in association with the channel formation process that can be explained assuming the carrier injection from electrodes. Finally Maxwell -Wagner model is used to explain the FET characteristics 1. Introduction Organic FET has attracted much interest in electronics since the discovery of high-mobility organic materials. Pentacene is one of the most possible candidates that can be employed in organic FETs, and mobilities exceeding 1 cmZNs have been reported [l]. However the complexities at the metal-organic materials and ambiguities of organic semiconductor physics lead us to a difficulty in understanding the FET device operation, though carrier transport process and carrier injection process are two main factors. By adjusting effective work-function of electrodes to so-called Fermi level of organic films, the camer injection and contact reistance will be controlled [2]. Thus, it is important to understand the electrostatic phenomena at the interface between metallorganic materials in association with the carrier injection process. And this will be he lp l l  for a f d l  understanding of the FET device operation mechanism, including channel formation process, etc The study of electrostatic interfacial phenomena has been a continuous research topic since the discovery of contact electrification [3,4]. Applying the contact-charge exchange experiments to thick polymer films, it has been revealed that excess charges are injected from a metal into a film, and a space charge layer of p m  thichess is formed at the interface. On the other hand, with Kelvin probe surface potential measurement, we have focused our research on the space charge problem at the nanometer-thick organic fildmetal interfaces such as polyimide \(PI polyethylene \(FE Pc etc.[5,6,7]. As a r e d ,  it has been reveated that excess electrons or holes are injected from metal electrode into insulating PI and PE films within the region of several nanometers from the metal-film interface Similarly, the injection of excess electrons within the region of 20 nm from the fildmetal interface has been confirmed for semiconductor Pc films. Interestingly the charge injection was found to be a result of the alignment between Fermi-level of metal and the surface Fermi-level of organic material In our previous study [8,9], we revealed that the work function of the Au surface changes by the Wiozone treatment of the Au surface. Taking into account this, the effect of UViozone treatment of source and drain electrodes onto our pentacene FET characteristics has been investigated with relevance to the carrier injection from electrodes 2. Experiment Pentacene was purchased from Wako pure chemical 


Pentacene was purchased from Wako pure chemical CoLtd., and used as received. The pentacene was vacuum deposited at a process pressure less than 2 X Torr onto pre-patterned bottom contact FET substrate with interdigited Au electrodes that was fabricated on a 500 nm thickness silicon dioxide \(SOz layer of highly-doped Si substrate. The deposition rate was about 3 d m i n ,  and the thickness of the pentacene layer was 100 nm. Prior to the evaporation of pentacene, some FET substrates were exposed to Uvlozone for 30 min. The work-function of Au was 5.2 eV with ozone treatment, whereas it was 4.6 eV without ozone-treatment [8,9]. Channel length and width of the prepared FET were 50 ,um and 11 cm respectively FET characteristics were examined in-situ during the deposition of pentacene in a vacuum chamber without breaking vacuum. For the C-V measurement source and drain electrode was connected, and then capacitance between source-drain and gate was measured using an LCR meter. External bias was applied to the source-drain electrode with reference to the gate electrode 3. Results and Discussion Figure 1 shows the typical Id-Vd characteristics of a pentacene FET using untreated substrate with a thickness of pentacene layer was about 100 nm. This FET shows p-channel enhancement-type behavior, but no field-effect at low gate voltage region less than -30 V. On the other hand, significant drain current was observed at zero gate bias for the FET using UViozone treated substrate, where positive gate bias actually works to suppress drain current in a manner like a 665 depletion-type FET \(not shown here I I t h8 -4l amp;&amp;&amp;Is: i'$ I i Figure 1. The Id-Vd characteristics of a pentacene FET using untreated substrate Figure 2 shows the JId-Vg characteristics of these FETs, where threshold voltage, Vth, decreases with UV/ozone treatment. That is, threshold voltages for the UViozone-treated and untreated sample were about 41 V and -22 V, respectively. The mobilities of ozone-treated and untreated FETs were calculated to 2 X l o 3  and 2 X lo-' cm2Ns, respectively. The mobilities were small in comparison with typical values reported by other researchers. This is mainly due to the FET structure and the morphology of deposited pentacene. From microscopic observation our samples were found to be composed of a rich of small grains with a grain size less than 0.5 ,LL m leading to lower mobility. Of course, we suppose there are other factors resulting the lower mobilities, such as impurity, contact, etc vp ivj Figure 2. The transfer characteristics-\( a d  - Vg these FETs According to the Kelvin probe surface potential measurement, +340 mV and -260 mV of the surface potential was observed for the 60-nm thickness pentacene deposited on ozone-treated and the untreated Au surfaces, respectively. In the same way, the establishment of such surface potential was observed for pentacene with a thickness over 60 nm. The surface potential comes from the energy difference between the work function of the metal and the surface Fermi level" of the organic materials. Thus the surface potential difference in pentacene films deposited on the surface of UV-treated and untreated Au surfaces is in good agreement with the result 


Au surfaces is in good agreement with the result estimated from photoelectron spectroscopy measurement. The surface potential monotonously increases up to a film thickness of about 60 nm and then saturates, in a similar manner as observed for phthalocyanine, etc. This implies that the exchange of charges between organic materials and metal is confined within the nanometer interfacial region Solving the Poisson equation concerning interface space charge, we estimate that the amount of charges transferred fromito metal were about of 4.5 N O 3  C/m3 and -3.0 X lo3 C/m3 for pentacene deposited on UViozone-treated and untreated Au, respectively. This indicates that the holes are accumulated around the source and drain electrodes of WViozone treated substrate, whereas not around the electrodes of untreated ones. Since the carrier of pentacene FET is hole, holes accumulated around the source-drain electrode can easily contribute to the formation of channel. Thus, the threshold voltage decreases with a UViozone treatment m Figure 3: The C-V characteristics of a pentacene FET using \(a b Figure 3 shows the C-V characteristics of a pentacene FET using ozone-treated \(MI-square untreated substrate \(open-square frequency of the ozone-treated and untreated samples were 43 Hz and 1 kHz, respectively. Here the capacitance between source-drain and gate electrode 666 was measured The C-V characteristics of the substrate with no pentacene layer \(blank substrate measured before the deposition. There was no dependence on the bias voltage in the C-V characteristics. The geometrical capacitance of this electrode configuration was estimated as 5.7 nF whereas the measured capacitance of the blank substrate was about 5.2 nF. Taking into account this difference, the estimated capacitance formed between channel area and gate electrode is calculated as about 1.43 nF. As shown in Fig. 3, capacitance increased with the negative bias voltage. In this measurement source and drain electrodes were shorted and gate bias Vg was applied with reference to the source voltage Vs Vd can be discussed based on a model of metal-insulator semiconductor \(MIS according to our results, it is reasonable to consider that the channel area contributes to the capacitance increase for bottom-contact FET structure. Taking into account the p-type behavior of pentacene FETs, holes are injected from source and drain electrode into channel region under the condition of Vg &lt;. 0 Interestingly, only a small change was observed for untreated FET, whereas drastic change was observed for UV/ozone treated FET. These behaviors qualitatively coincide with the FET characteristics, i.e no field-effect at low gate voltage region less than -30 V, because the capacitance increase corresponds to the accumulation of carriers at the interfacial region of pentacene. According to the experimental limitation of our system, i.e., bias voltage for the C-V measurement can be changed between -40 V and 40 V, only a small change was observed for untreated FET. To understand the increase of the capacitance and the formation of channel due to bias voltage, Maxwell-Wagner model can be employed coupling with the equivalent circuit model, where we need to consider the presence of contact resistance, besides the accumulated charges based on a Maxwell-Wagner model f9]. The equivalent circuit model tells us that the cut-off frequency is 


circuit model tells us that the cut-off frequency is mainly dependent on the time constants defined as CliG1 and Cl/CO, where G1 and GO is the channel bulk conductance and interfacial electrode conductance and C1 is the capacitance between source-drain electrode and channel. Taking into these time constants we could reasonably explain the frequency dependence of the C-V characteristics, together with the FET device operation [9].  The detailed analysis proceeds and will be reported in near future 4. Conclusion The FET characteristics of the bottom contact pentacene FET are discussed based OR a camer accumulation around the electrode in the context o f  the UViozone treatment of the substrate. In addition, to investigate the channel formation process of this FET capacitance-voltage \(C-V was investigated. Significant change of the threshold voltage, i.e., the decrease of the Vth, by a UV/ozone treatment was observed and can be reasonably assigned to accumulated charges around source-drain electrode. Finally, it was suggested that these I-V characteristics were successfully explained based on a model by Maxwell-Wagner, taking into account the contact resistance related to injection and accumulated charge REFERENCES I ]  For example, recent progress in the research about organic transistor was reviewed in C. D Dimtrakopoulos and P. R. L. Malenfant, Adv. Matter 14 \(2002 21 Y. Y. Lin, D. J. Gundlach, S .  F. Nelson and T..N Jackson, IEEE Electron Device Lett. 18 \(1 997 3]J. Lowell and A. C .  Rose-Innes, Advances in Physics 29 \( 1  980 4] L. H. Lee, J. Electrostatics, 32 \(1994 eferences cited therein 151 E. Ito and M. Iwamoto, J. Appl. Phys. 81 \(1997 1190 6]T. Manaka, H. Ohta, M. Fukuzawa and M. Iwamoto Jpn. J. Appl. Phys. 42 \(2003 7] E. Itoh, H. Kokubo, S. Shouriki and M. Iwamoto, J Appl. Phys. 83 \(1998 8] Y. Suzue, T. Manaka and M. Iwamoto, Jpn. J. Appl Phys. 44 \(2005 9] T.Manaka, E.Lim, R.Tamura, and M. Iwamoto, Thin Solid Films, in the press \(2005 667 pre></body></html 


9 PEAK MIDDLE BIG HIGH 10 MIDDLE MIDDLE SMALL MIDDLE 11 MIDDLE MIDDLE BIG HIGH 12 MIDDLE Low BIG HIGH 13 PEAK HIGH SMALL HIGH 14 PEAK HIGH BIG HIGH 15 PEAK Low BIG HIGH 16 PEAK Low SMALL HIGH 17 MIDDLE Low SMALL HIGH 18 PEAK MIDDLE SMALL HIGH 4TABLE VI REDUCING ACCORDING TABLE5 RECORD MARKET LOADBID CAPABILITYNUMBER DEMAND RATE 1 * Low * HIGH 2 Low HIGH 3 BASE MIDDLE MIDDLE 4 BASE MIDDLE MIDDLE 5 BASE HIGH BIG MIDDLE 6 BASE HIGH SMALL Low 7 MIDDLE HIGH BIG HIGH 8 MIDDLE HIGH SMALL Low 9 PEAK HIGH 10 MIDDLE MIDDLE MIDDLE 11 MIDDLE MIDDLE * HIGH 12 Low HIGH 13 PEAK HIGH 14 PEAK HIGH 15 HIGH 16 * * * HIGH 17 Low HIGH 18 PEAK HIGH TABLE VII THE SET OF RULES RULE SET RULE IF BID=LOW THEN LOAD RATE=HIGH RULE IF MARKET DEMAND=BASE, BID=MIDDLE THEN LoAD 2 RATE=MIDDLE RULE IF MARKET DEMANDE=BASE, BID=HIGH, CAPABILITY=BIG 3 THEN LoAD RATE=MIDDLE RULE IF MARKET DEMAND=BASE, BID=HIGH 4 CAPABILITY=SMALL THEN LOAD RATE=Low RULE IF MARKET DEMAND=MIDDLE, BID=HIGH 5 CAPABILITY=BIG THEN LoAD RATE=HIGH RULE IF MARKET DEMAND=BASE, BID=HIGH 6 CAPABILITY=SMALL THEN LOAD RATE=Low RULE IF MARKER DEMAND=PEAK THEN LOAD RATE=HIGH 7 RULE IF MARKET DEMAND=MIDDLE, BID=MIDDLE THEN LoAD 8 RATE=MIDDLE From table VII, we can get some information as "If bid=low then load rate is high". At the different level of market demand, the affecting factors of unit's ability \(load rate When market demand is at peak load, the influence to load rate that is caused by level of unit bid and capability is slight. In this condition, the unit's bidding ability is strong That is to say, the load rate is high, which predicts market supply is less than market demand When marker demand is at base load, bidding ability is relevant of bid and unit capability If bid=high, capability= middle then load rate is middle If bid= high and capability= low then load rate is low. If bid= middle then load rate is middle When market demand is at middle load if bid= middle then load rate is middle If bid= high and capability= high then load rate is high As a conclusion, unit's bidding ability has stronger connection with market demand. When market demand is high the ability is always strong. When market demand falls down unit's bidding ability is relevant of bid and capability The advantage of adopting rough set is that it can consider problems from population to get rules. For instance, it can 


analyze the connection of unit capability, market demand level of bid and load rate as a whole, but needn't consider the relationship of load rate and market demand first, next considered load rate and level of bid, then load rate and unit capability's relationship, combines all of these relationships at last. Obviously, first classing then synthesis is not better than analyzing all the data as a whole. Rough set can discovery rules as a whole, so it can obtain more accurate result V. CONCLUSIONS A new method of assessing unit's bidding ability based on rough set is proposed in this paper. Through rough set, the minimum benefit rules are obtained, which are about the relationship of load rate and market demand, level of bid, unit ability. Better initial value of trade plan can be given by assessing unit's bidding ability. Supervisors can also improve their efficiency and research potential market risk and identify whether the illegal behave exist or not. The unit with different distinction can accord the knowledge to assemble competitive policy. And the knowledge is very sensible to Power Exchange-PX and Independent System Operator-ISO VI. REFERENCES Periodicals 1] Ma Rui et al. 'A new data-mining framework based on decision-tree for competitive bidding assessment in power market', Automation of electric power systems, 26\(15 2] Liao Zhingwei. 'Data Mining Technology And Its Application On Power System', Automation of electric power systemsIX25\(11 62-65 3] Diao Qinhua et al. 'Game Theory and Its Application in Power Systems Automation of electric power systems, 25\(1 4] Wang Xifan. 'Study On Framework Of Bidding System Model For Power Market In China', Electric Power, 2000, 33 \(11 5] Yu Erkeng et al. 'Bidding Model and Principle for Power Markets Automation of Electric Power Systems, 25 \(1 6] Pawlak Z, Busse J G, Slowinski R, et al. Rough sets [J].Communication of the ACM, 38\(11 VII. BIOGRAPHIES Li Ran was born in Baoding, Hebei province, China, on July 23 1965. She received the Bachelor's degree and Master's degree from North China Power System University in 1986 and 1990 respectively, both in Electrical Engineering. Now she is an associate professor at the Department of electrical Engineering of the North China Power System University. Her research interests are the application of artificial intelligence in power system, power system operation and management Li Jinghua was born in Yulin, Guangxi province, China, in 1982. She received the Bachelor's degree from North China Power System University in 2003. She is a master student of North China Power System University now Her research interests are the application of artificial intelligence in power system 4 pre></body></html 


a  i i i           017 017 017 212 212   017 001          b i j k b i j b i k n n b i j k b i q k k    2 3 4 4 4 3 4 3 3 4 y 1 1 1 1 i i i j a a a k a k a j                                   y 3 3 4 3 2 2 2 4 2 3 4 1 212 y  a a a n a a k k 4 4 3 4 3 4 3 1 3 4 3 2 2 2 2 2 etc and item below 212 1 1 for any j 325s itemset will already have been generated As well as being most space ef\336cient this is required to evaluate nontrivial y 212 004 1 p.depth 1  Conversely while there is still a child to create or test we cannot delete  Fact 6 will always apply in this case too eg we can also delete  Note also that because we need the itemvectors of the single items in memory we have not been able to use Fact 7 yet Similarly Fact 6 is also applied in l m o and p However note that in m o and p we also use Fact 7 to delete  k is the topmost sibling child Hence we can apply Fact 6 in h Note that by Fact 1 we calculate 15  This is because we only ever need at a time If and  then we can have completed all nodes corresponding to all subsets of of a node is created or we 336nd its itemset is not frequent and hence don\325t need to create it the itemvector corresponding to its can be deleted That is we have just created the topmost last immediate child of or when and as per Fact 1 Note we are also making use of Fact 3 320 and by Fact 5 It has no possible children because of the ordering of the sequences The same holds for as  and by Fact 3 We know already that the time complexity  This applies only when we can only ever onto the end We now present an example and the the root we only ever need to keep a single itemvector in memory for any child of only if siblings are in the pre\336x tree Hence we only try to expand nodes which have one or more siblings and for more thorough than Fact 3 pruning using the antimonotonic requirement This is what we call the 324bottom up\325 order of building the Pre\336x Tree 5 When a Pre\336xNode until we generate where may both greater then is not frequent Indeed we can write the result of 325s corresponding itemvector  on the topmost of our algorithm to illustrate some of these facts Suppose we have the items are siblings Once we have created the node for the root we will need to keep its children\325s itemvectors in memory the itemvectors  So if we use the depth 336rst procedure when a Pre\336xNode is created all Pre\336xNodes corresponding to subsets of or the topmost eg directly into the itemvector holding 15 By Fact 1 we cannot apply this to nodes with eg when all itemsets are frequent will correspond to  The reason behind this is that by using the bottom up method and the fact our itemsets are ordered we know that if we have in d we can delete  In l we deleted for two reasons Fact 6 and 7 it is a special case in Fact 6 Finally to better illustrate Fact 3 suppose is not frequent This means that will have no siblings anymore so we do not even need to consider 002  a i i i i  threshold is such that all itemsets are interesting frequent Figure 2 shows the target pre\336x tree and the steps in mining it This example serves to show how we manage the memory while avoiding any re-computations For now consider the frontier list in the 336gure as a list of Pre\336xNodes that have not been completed It should be clear that we use a bottom up and depth 336rst procedure to mine the itemsets as motivated by Facts 2 and 4 We complete all subtrees before moving to the next item In d we calculate p   i   i   i   i n n   n   i   i   i  p.depth p.depth  p.depth  minM easure minSup p.item p.item p.item    i 212 212 2 2 267 y  i i i i i i i i i i 1 i i i i i i i i i i i i j<q<k y k  If we have read in           1 1 y not parent branch i with with we will use  2 It also means we use least space if we perform a depth 336rst search Then for any depth  in f In g the node for it 4 Suppose the items are if is roughly linear in the number of frequent itemsets because we avoid re-computations of itemvectors So the question now is what is the maximum number of itemvectors that we have in memory at any time There are two main factors that in\337uence this First we need to keep the itemvectors for individual items in memory until we we have completed the node for the top-most item Fact 1 and 7 Hence the 324higher\325  we will at most have only one itemvector in memory at a time 3 We only ever check a new sequence by 324joining\325 siblings That is we check  we can delete the itemvector corresponding to the single item is the top-most item cannot have any children because it has no siblings by Fact 3 its itemvector will no longer be needed 6 When a topmost is child        y j>k 020 020 020   001  001 020 001 001 is the top-most unless it is the topmost node as they correspond to single items and are still needed 7 When we create a Pre\336xNode eg 1 1 k             b i j b i j k b i j b j b j k  y k>j p y I k y p p F p p p y y i b a y y p p p i y y y y y y y y sibling i i i i i i i i i i i i i i i  


k Step 10 n Step 13 c Step 2 e Step 4 i Step 8 value Shaded nodes have their corresponding itemvector in memory Dotted nodes have not been mined yet Solid lines are the parts of the tree that have been created b Step 1 f Step 5 h Step 7 j Step 9 m Step 12 o Step 14 p Step 15 a Complete Pre\336xTree d Step 3 g Step 6 l Step 11 Figure 2 Building the Pre\336xTree mining itemsets Example Nodes are labeled with their item 


 then we can additionally bound the space by  Furthermore since the frontier contains all uncompleted  and n n n  This is for the worst case when all itemsets are frequent Clearly a closer bound is if we let 1 2 2 1 1 2 1 2 2 1 itemvectors of space Furthermore 2    n n          b  212  b   The cardinality of both these sets equal to the number of nodes along the path is 942  001 001 001 001 be the largest itemset GLIMIT uses at most 001  007  100  n 1 1 1 1  t\212 n is even the last node is t   t t  b 3 1 t\212 l l l l step 006 n 2 n   n n n minSup 1 1  6 Experiments even or odd b 002 1 and up in the tree we are the more this contributes Secondly we need to keep itemvectors in memory until we complete their respective nodes That is check all their children Fact 6 or if they can\325t have children Fact 5 Now the further we are up in the tree or any subtree for that matter without completing the node the longer the sequence of incomplete nodes is and hence the the more itemvectors we need to keep Considering both these factors leads to the situation in Figure 3 320 that is we are up to the top item and the topmost path from that item so that no node along the path is completed If we have corresponding to the single items children of the root There are a further inclusive to the last coloured node these are the uncompleted nodes 16  Therefore the total space required is just is so that we do not double count the itemvector for  is low and in practice with non-pathological support thresholds we use far fewer than itemvectors If we know that the longest frequent itemset has size 16 When directly into As an aside note we could perform the transpose operation in memory before mining while still remaining within the worst case space complexity However on average and for practical levels of objects Algorithm 1 describes 17 the additional types we use such as items respectively To apply GLIMIT we 336rst transpose the dataset as a preprocessing step 19  We compared GLIMIT to a publicly available implementation of FP-Growth and Apriori We used the algorithms from ARtool 20 as it is written in 17 The pseudo-code in our algorithms is java-like and we assume a garbage collector which simpli\336es it Indentation de\336nes blocks and we ignore type casts 18 http://\336mi.cs.helsinki.\336/data 19 This is cheap especially for sparse matrices 320 precisely what the datasets in question typically are Our data was transposed in 8 and 15 seconds respectively using a naive Java implementation and without using sparse techniques 20 http://www.cs.umb.edu laur/ARtool It was not used via the supplied GUI The underlying classes were invoked directly itemvectors itemvectors along the path from node  We have sketched the proof of Lemma 2 Let  and shows the initialisation and the main loop 320 which calls methods used by We evaluated our algorithm on two publicly available datasets from the FIMI repository 18 320 T10I4D100K and T40I10D100K These datasets have  where the be the number of frequent items Hence we need space linear in the number of frequent items The multiplicative constant  method whereby a list priority queue of states each containing a node that has yet to be completely expanded is maintained The general construct is to retrieve the 336rst state evaluate it for the search criteria expand it create some child nodes and add states corresponding to the child nodes to the frontier Using different criteria and frontier orderings leads to different search techniques Our frontier contains any nodes that have not yet been completed wrapped in is odd it is  5     n y  1  3  5 n 212 3 n 212 1  items the worst case itemvector usage is just the number of coloured nodes in Figure 3 There are  n i  Note that in the even case the next step to that shown will use the same memory the itemvector for node t\212 2 y  1  3  5 n 212 3 n 212 1 n  frontier is no longer needed once we create  and when 3 5 3 5 3 5 5 3 n n 1 1 as we compute it so both need never be in memory at the same time nodes we know from the above that its upper bound is 3 It also describes the 3 step Figure 3 Maximum number of itemvectors Two cases   n   n   n   n 267 267 267 267 n 000 870 minM easure n be the number of frequent items Let b State State    n n n y n n n l n n be the number of items and n l calculateF  check 212 212 212   212 212 212 212  by Fact 6 and we write i eg  this would require more memory The algorithm is a depth 336rst traversal through the Pre\336xTree Any search can be implemented either recursively or using the frontier transactions and a realistic skewed histogram of items They have  n b  


Main Loop to join with  as we are creating    can write result directly into  pref ixT ree.getRoot y 002 003 004     004            1                         002                  boolean localT op F localT op localT op null localT op localT op localT op localT op m State State State State newState       if 001 001 001 001 001 001 001 001 001 001 001 001 001 001 001 001 001 Data-types initialisation main loop and methods  initialise i i i i i i i i  267 267 267 002   state.y state.y M minM easure state.itemvectors.next f f minM easure m p item   Iterator itemvectors boolean top P air newP air List buf f er  state.buf f er.iterator 002 localF rontier.removeF irst be the itemset corresponding to    nd P ref ixN ode M y y M M m m I I I I I I I I I I I I I I       P air p   f rontier.getF irst state.node p.item m 002             I I i i i i i i i i I i K K  Iterator is over   make use of anti-monotonic pruning property if   else   if   void y  hatwecreateif y y  P ref ixN ode node Item item double m  so we don\325t add it again  We need and and and becomes we create if   Fact 5 is not complete we  will add has been completed See and  1 Dataset  have already applied 2 Completed  containing all is the itemvector for in Fact 1 We keep reusing them through  is the itemvector corresponding to and in Fact 1  for the s created to hold the children of to make use of Fact 3 provides the as empty Create initial state objects Reads input one row at a time and annotates the itemvector with the item it corresponds to could also apply   while  is the parent of the new and is set so that is true only for a node that is along the  see end of method  and hence delete   the top child of in this step Fact 6  we are dealing with itemsets of length  Fact 6 or 7 No longer need as this is the last child we can create under  and it is not a single item other than perhaps the topmost  else  need to use additional memory for the child  don\325t need to calculate we know  if   Found an interesting itemset 320 create  there is potential to expand  Let is the itemset represented by a child of would be  This method calculates to look up the to get their values  Then it returns  details depend on  Check whether the itemset to check whether subsets of by Fact 3 exist details omitted Iterators any after              is used to create the may       P air P air   m   m inputF ile state.newP air state.newP air state.newP air p.item p.item pref ixT ree.createChildU nder p.item sequenceM ap.put state.buf f er.size state.newP air p.item P ref ixT ree pref ixT ree pref ixT ree p.y calculateF p.y check p.y p.y calculateF p.m p.M map map map map M   K  Remove y 002 y     006 006 002 002 002 002 002 002 002 002 002      001 001 m F-itemsets topmost branch  006 006 006 001 Itemvector y P ref ixN ode node Itemvector y itemvectors f rontier Iterator itemvectors f rontier.add  null itemvectors f alse null new LinkedList step nextT op State state null null state f rontier Itemvector y null boolean nextT op state.node.isRoot state.top nextT op nextT op state.top state.top state.node P ref ixN ode newN ode newN ode.item newN ode.M  nextT op new LinkedList state state.node node.item  Item item new AnnotatedItemvetorIterator new State state.node newN ode.M newN ode.top double m state.node state.node newN ode.m new State newN ode y f rontier.addF ront newState newState double boolean newN ode top top top newN ode newN ode newN ode node node node node node 002 267 267 267 f rontier.isEmpty 1 1 if  of the pre\336x tree  Algorithm 1 check such as  s else to so that      required subsets of from so  212\005 Input step Output Initialisation could be interesting by exploiting the anti-monotonic property of except  itemvectors 1 0  in transpose format   helps us do this  with its root Initialise     Perform one expansion  is true iff we are processing the top sibling of subtree   if    in the next   initialise  if  for it   add to front of frontier ie in front of if it\325s still present so depth 336rst search Fact 2  by using s corresponding to the 001  P ref ixN ode inputF ile  212 newP air    001 g f minM easure SequenceM ap item buf f er y buf f er buf f er y g state.buf f er.add state.itemvectors.hasN ext state.y I m state.node.getDepth  state.y y y y M M  minM easure  p state.buf f er item p item m F F 002 item 002 item item P ref ixN ode node Item item        calculateF  and corresponds to F use 


The fact that it is also fast when applied to traditional FIM is secondary sum 0 100 000 82  b Runtime and frequent itemsets T40I10D100K longer than 30 minutes for 267  To represent itemvectors for traditional FIM we used bit-vectors 21 so that each bit is set if the corresponding transaction contains the item\(set Therefore  0 001  5 5 step    n minSup 1 1  f  creates the bit-vector 21 We used the Lemma 2 the 336gure clearly shows this is never reached in our experiments Our maximum was approximately 24 over the calls to m    Java like our implementation and it has been available for some time In this section we really only want to show that GLIMIT is quite fast and ef\336cient when compared to existing algorithms on the traditional FIM problem Our contribution is the itemvector framework that allows operations that previously could not be considered and a 337exible and new class of algorithm that uses this framework to ef\336ciently mine data cast into different and useful spaces F m  n n b Colt Figure 4 Results g  Figure 4\(a shows the runtime 22 of FP-Growth GLIMIT and Apriori 23 on T10I4D100K as well   267 267 is larger much of the time and space is wasted GLIMIT uses time and space as needed so it does not waste as many resources making it fast The downside is that the operations on bit-vectors in our experiments of length times the number of items would be so small that the runtime would be unfeasibly large anyhow Furthermore the space a Runtime and frequent itemsets T10I4D100K Inset shows detail for low support  http://dsd.lbl.gov/\367hoschek/colt BitVector implementation 22 Pentium 4 2.4GHz with 1GB RAM running WindowsXP Pro 23 Apriori was not run for extremely low support as it takes as the number of frequent items The analogous graph for T40I10D100K is shown in Figure 4\(b 320 we did not run Apriori as it is too slow These graphs clearly show that when the support threshold is below a small value about 0.29 and 1.2 for the respective datasets FP-Growth is superior to GLIMIT However above this threshold GLIMIT outperforms FP-Growth signi\336cantly Figure 5\(a shows this more explicitly by presenting the runtime ratios for T40I10D100K FP-Growth takes at worst 19 times as long as GLIMIT We think it is clear that GLIMIT is superior above the threshold Furthermore this threshold is very small and practical applications usually mine with much larger thresholds than this GLIMIT scales roughly linearly in the number of frequent itemsets Figure 5\(b demonstrates this experimentally by showing the average time to mine a single frequent itemset The value for GLIMIT is quite stable rising slowly toward the end as there we still need to check itemsets but very few of these turn out to be frequent FP-Growth on the other hand clearly does not scale linearly The reason behind these differences is that FP-Growth 336rst builds an FP-tree This effectively stores the entire Dataset minus infrequent single items in memory The FPtree is also highly cross-referenced so that searches are fast The downside is that this takes signi\336cant time and a lot of space This pays off extremely well when the support threshold is very low as the frequent itemsets can read from the tree very quickly However when  can be time consuming when compared to the search on the FP-tree which is why GLIMIT cannot keep up when is very small Figure 5\(c shows the maximum and average 24 number of itemvectors our algorithm uses as a percentage of the number of items At worst this can be interpreted as the percentage of the dataset in memory Although the worst case space is  1 and  minSup minSup minSup  By the time it gets close to  AN D 


Proceedings of the Ninth ACM SIGKDD International Conference on Knowledge Discovery and Data Mining 7 Conclusion and Future Work References frontier  pages 487\320499 Morgan Kaufmann 1994  W orkshop on frequent itemset mining implementations 2003 http://\336mi.cs.helsinki.\336/\336mi03  W orkshop on frequent itemset mining implementations 2004 http://\336mi.cs.helsinki.\336/\336mi04  J  Han J  Pei and Y  Y in Mining frequent patterns without candidate generation In Proceedings of 20th International Conference on Very Large Data Bases VLDB VLDB Journal Very Large Data Bases Data Mining and Knowledge Discovery An International Journal Lecture Notes in Computer Science  2004  J W ang and G Karypis Harmon y Ef 336ciently mining the best rules for classi\336cation In The Tenth ACM SIGKDD International Conference on Knowledge Discovery and Data Mining KDD\32504 Symposium on Principles of Database Systems 2 b Average time taken per frequent itemset shown on two scales T10I4D100K is increased and hence the number of frequent items decreases Figure 5\(c also shows that the maximum frontier size is very small Finally we reiterate that we can avoid using the pre\336x tree and sequence map so the only space required are the itemvectors and the minSup SIAM International Conference on Data Mining required drops quite quickly as ACM SIGMOD Workshop on Research Issues in Data Mining and Knowledge Discovery 2000 ACM SIGMOD Intl Conference on Management of Data Figure 5 Results  8\(3\3204 2000  F  P an G C ong A T ung J Y ang and M Zaki Carpenter Finding closed patterns in long biological datasets In  2121:236 2001  M Steinbach P N T an H Xiong and V  K umar  Generalizing the notion of support In a Runtime ratios T10I4D100K c Number of Itemvectors needed and maximum frontier size T10I4D100K  pages 1\32012 ACM Press May 2000  F  K orn A Labrinidis Y  K otidis and C F aloutsos Quanti\336able data mining using ratio rules  Morgan Kaufmann 2003  J Pei J Han and L Lakshmanan Pushing convertible constraints in frequent itemset mining We showed interesting consequences of viewing transaction data as itemvectors in transactionspace and developed a framework for operating on itemvectors This abstraction gives great 337exibility in the measures used and opens up the potential for useful transformations on the data Our future work will focus on 336nding useful geometric measures and transformations for itemset mining One problem is to 336nd a way to use SVD prior to mining for itemsets larger than  pages 205\320215 2005  We also presented GLIMIT a novel algorithm that uses our framework and signi\336cantly departs from existing algorithms GLIMIT mines itemsets in one pass without candidate generation in linear space and time linear in the number of interesting itemsets Experiments showed that it beats FP-Growth above small support thresholds Most importantly it allows the use of transformations on the data that were previously impossible  That is the space required is truly linear  D Achlioptas Database-friendly random projections In  2001  R Agra w al and R Srikant F ast algorithms for mining association rules In  8:227\320252 May 2004  J Pei J Han and R Mao CLOSET An ef 336cient algorithm for mining frequent closed itemsets In  pages 21\32030 2000  S Shekhar and Y  Huang Disco v ering spatial colocation patterns A summary of results 


mator from sensor 1 also shown 6. CONCLUSIONS This paper derives a Bayesian procedure for track association that can solve a large scale distributed tracking problem where many sensors track many targets. When noninformative prior of the target state is assumed, the single target test becomes a chi-square test and it can be extended to the multiple target case by solving a multidimensional assignment problem. With the noninformative prior assumption, the optimal track fusion algorithm can be a biased one where the regularized estimate has smaller mean square estimation error. A regularized track fusion algorithm was presented which modifies the optimal linear unbiased fusion rule by a less-than-unity scalar. Simulation results indicate the effectiveness of the proposed track association and fusion algorithm through a three-sensor two-target tracking scenario 7. REFERENCES 1] Y. Bar-Shalom and W. D. Blair \(editors Tracking: Applications and Advances, vol. III, Artech House, 2000 2] Y. Bar-Shalom and H. Chen  Multisensor Track-to-Track Association for Tracks with Dependent Errors  Proc. IEEE Conf. on Decision and Control, Atlantis, Bahamas, Dec. 2004 3] Y. Bar-Shalom and X. R. Li, Multitarget-Multisensor Tracking Principles and Techniques, YBS Publishing, 1995 4] Y. Bar-Shalom, X. R. Li and T. Kirubarajan, Estimation with Applications to Tracking and Navigation: Algorithms and Software for Information Extraction, Wiley, 2001 5] S. Blackman, and R. Popoli  Design and Analysis of Modern Tracking Systems  Artech House, 1999 10 15 20 25 30 35 40 45 50 55 60 2 4 6 8 10 12 14 Time N o rm a li z e d e s ti m a ti o n e rr o r s q u a re d Target 1 Sensor 1 Centralized Est Track Fusion 10 15 20 25 30 35 40 45 50 55 60 0 2 


2 4 6 8 10 12 14 Time N o rm a li z e d e s ti m a ti o n e rr o r s q u a re d Target 2 Sensor 1 Centralized Est Track Fusion Fig. 7. Comparison of the NEES for centralized IMM estimator \(configuration \(i estimators \(configuration \(ii sensor 1 also shown 6] H. Chen, T. Kirubarajan, and Y. Bar-Shalom  Performance Limits of Track-to-Track Fusion vs. Centralized Estimation: Theory and Application  IEEE Trans. Aerospace and Electronic Systems 39\(2  400, April 2003 7] H. Chen, K. R. Pattipati, T. Kirubarajan and Y. Bar-Shalom  Data Association with Possibly Unresolved Measurements Using Linear Programming  Proc. 5th ONR/GTRI Workshop on Target Tracking Newport, RI, June 2002 8] Y. Eldar, and A. V. Oppenheim  Covariance Shaping Least-Square Estimation  IEEE Trans. Signal Processing, 51\(3 pp. 686-697 9] Y. Eldar  Minimum Variance in Biased Estimation: Bounds and Asymptotically Optimal Estimators  IEEE Trans. Signal Processing, 52\(7 10] Y. Eldar, A. Ben-Tal, and A. Nemirovski  Linear Minimax Regret Estimation of Deterministic Parameters with Bounded Data Uncertainties  IEEE Trans. Signal Processing, 52\(8 Aug. 2004 11] S. Kay  Conditional Model Order Estimation  IEEE Transactions on Signal Processing, 49\(9 12] X. R. Li, Y. Zhu, J. Wang, and C. Han  Optimal Linear Estimation Fusion  Part I: Unified Fusion Rules  IEEE Trans. Information Theory, 49\(9  2208, Sept. 2003 13] X. R. Li  Optimal Linear Estimation Fusion  Part VII: Dynamic Systems  in Proc. 2003 Int. Conf. Information Fusion, Cairns, Australia, pp. 455-462, July 2003 14] X. D. Lin, Y. Bar-Shalom and T. Kirubarajan  Multisensor Bias Estimation Using Local Tracks without A Priori Association  Proc SPIE Conf. Signal and Data Processing of Small Targets \(Vol 


SPIE Conf. Signal and Data Processing of Small Targets \(Vol 5204 15] R. Popp, K. R. Pattipati, and Y. Bar-Shalom  An M-best Multidimensional Data Association Algorithm for Multisensor Multitarget Tracking  IEEE Trans. Aerospace and Electronic Systems, 37\(1 pp. 22-39, January 2001 pre></body></html 


20 0  50  100  150  200  250  300 Pe rc en ta ge o f a dd iti on al tr af fic Cache size 200 clients using CMIP 200 clients using UIR c Figure 6. The percentage of additional traf?c the cache at every clock tick. A similar scheme has been proposed in [13], which uses fv, a function of the access rate of the data item only, to evaluate the value of each data item i that becomes available to the client on the channel If there exists a data item j in the client  s cache such that fv\(i j replaced with i A prefetch scheme based on the cache locality, called UIR scheme, was proposed in [7]. It assumes that a client has a large chance to access the invalidated cache items in the near future. It proposes to prefetch these data items if it is possible to increase the cache hit ratio. In [6], Cao improves the UIR scheme by reducing some unnecessary prefetches based on the prefetch access ratio \(PAR scheme, the client records how many times a cached data item has been accessed and prefetched, respectively. It then calculates the PAR, which is the number of prefetches divided by the number of accesses, for each data item. If the PAR is less than one, it means that the data item has been accessed a number of times and hence the prefetching is useful. The clients can mark data items as non-prefetching when PAR &gt; b, where b is a system tuning factor. The scheme proposes to change the value of b dynamically according to power consumption. This can make the prefetch scheme adaptable, but no clear methodology as to how and when b should be changed. Yin et al. [19] proposed a power-aware prefetch scheme, called value-based adaptive prefetch \(VAP the number of prefetches based on the current energy level to prolong the system running time. The VAP scheme de?nes a value function which can optimize the prefetch cost to achieve better performance These existing schemes have ignored the following characteristics of a mobile environment: \(1 query some data items frequently, \(2 during a period of time are related to each other, \(3 miss is not a isolated events; a cache miss is often followed by a series of cache misses, \(4 eral requests in one uplink request consumes little additional bandwidth but reduces the number of future uplink requests. In this paper, we addressed these issues using a cache-miss-initiated prefetch scheme, which is based on association rule mining technique. Association rule mining is a widely used technique in ?nding the relationships among data items. The problem of ?nding association rules among items is clearly de?ned by Agrawal et al. in [5]. However in the mobile environment, one cannot apply the existing association rule mining algorithm [4] directly because it is too complex and expensive to use This makes our algorithm different from that of [4] in 


This makes our algorithm different from that of [4] in twofold. First, we are interested in rules with only one data item in the antecedent and several data items in the consequent. Our motivation is to prefetch several data items which are highly related to the cache-miss data item within Proceedings of the 2004 IEEE International Conference on Mobile Data Management \(MDM  04 0-7695-2070-7/04 $20.00  2004 IEEE the cache-miss initiated uplink request. We want to generate rules where the antecedent is one data item, but the cache-missed data item and the consequent is a series of data items, which are highly related to the antecedent. If we have such rules, we can easily ?nd the data items which should also be piggybacked in the uplink request. Second in mobile environment, the client  s computation and power resources are limited. Thus, the rule-mining process should not be too complex and resource expensive. It should not take a long time to mine the rules. It should not have high computation overhead. However, most of the association rule mining algorithms [4, 5] have high computation requirements to generate such rules 5. Conclusions Client-side prefetching technique can be used to improve system performance in mobile environments. However, prefetching also consumes a large amount of system resources such as computation power and energy. Thus, it is very important to only prefetch the right data. In this paper, we proposed a cache-miss-initiated prefetch \(CMIP scheme to help the mobile clients prefetch the right data The CMIP scheme relies on two prefetch sets: the alwaysprefetch set and the miss-prefetch set. Novel association rule based algorithms were proposed to construct these prefetch sets. When a cache miss happens, instead of sending an uplink request to only ask for the cache-missed data item, the client requests several items, which are within the miss-prefetch set, to reduce future cache misses. Detailed experimental results veri?ed that the CMIP scheme can greatly improve the system performance in terms of increased cache hit ratio, reduced uplink requests and negligible additional traf?c References 1] S. Acharya, M. Franklin, and S. Zdonik. Prefetching From a Broadcast Disk. Proc. Int  l Conf. on Data Eng., pages 276  285, Feb. 1996 2] S. Acharya, M. Franklin, and S. Zdonik. Balancing Push and Pull for Data Broadcast. Proc. ACM SIGMOD, pages 183  194, May 1997 3] S. Acharya, R. Alonso, M. Franklin, and S. Zdonik. Broadcast disks: Data Management for Asymmetric Communication Environments. Proc. ACM SIGMOD, pages 199  210 May 1995 4] R. Agrawal and R. Srikant. Fast Algorithms for Mining Association Rules. In J. B. Bocca, M. Jarke, and C. Zaniolo editors, Proc. 20th Int. Conf. Very Large Data Bases, VLDB pages 487  499. Morgan Kaufmann, 12  15 1994 5] R. Agrawal, Tomasz Imielinski, and Arun Swami. Mining Association Rules Between Sets of Items in Large Databases. In Proc. of the ACM SIGMOD Conference on Management of Data, pages 207  216, Washington, D.C May 1993 6] G. Cao. Proactive Power-Aware Cache Management for Mobile Computing Systems. IEEE Transactions on Computers, 51\(6  621, June 2002 7] G. Cao. A Scalable Low-Latency Cache Invalidation Strategy for Mobile Environments. IEEE Transactions on Knowledge and Data Engineering, 15\(5 ber/October 2003 \(A preliminary version appeared in ACM MobiCom  00 8] K. Chinen and S. Yamaguchi. An Interactive Prefetching Proxy Server for Improvement of WWW Latency. In Proc INET 97, June 1997 9] E. Cohen and H. Kaplan. Prefetching the means for docu 


9] E. Cohen and H. Kaplan. Prefetching the means for document transfer: A new approach for reducing web latency. In Proceedings of IEEE INFOCOM, pages 854  863, 2000 10] R. Cooley, B. Mobasher, and J. Srivastava. Data preparation for mining world wide web browsing patterns. Knowledge and Information Systems, 1\(1  32, 1999 11] C. R. Cunha, Azer Bestavros, and Mark E. Crovella. Characteristics of WWW Client Based Traces. Technical Report TR-95-010, Boston University, CS Dept, Boston, MA 02215, July 1995 12] D. Duchamp. Prefetching hyperlinks. In USENIX Symposium on Internet Technologies and Systems \(USITS  99 1999 13] V. Grassi. Prefetching Policies for Energy Saving and Latency Reduction in a Wireless Broadcast Data Delivery System. In ACM MSWIM 2000, Boston MA, 2000 14] S. Hameed and N. Vaidya. Ef?cient Algorithms for Scheduling Data Broadcast. ACM/Baltzer Wireless Networks \(WINET  193, May 1999 15] Q. Hu and D. Lee. Cache Algorithms based on Adaptive Invalidation Reports for Mobile Environments. Cluster Computing, pages 39  48, Feb. 1998 16] Z. Jiang and L. Kleinrock. An Adaptive Network Prefetch Scheme. IEEE Journal on Selected Areas in Communications, 16\(3  11, April 1998 17] V. Padmanabhan and J. Mogul. Using Predictive Prefetching to Improve World Wide Web Latency. Computer Communication Review, pages 22  36, July 1996 18] N. Vaidya and S. Hameed. Scheduling Data Broadcast in Asymmetric Communication Environments. ACM/Baltzer Wireless Networks \(WINET  182, May 1999 19] L. Yin, G. Cao, C. Das, and A. Ashraf. Power-Aware Prefetch in Mobile Environments. IEEE International Conference on Distributed Computing Systems \(ICDCS 2002 Proceedings of the 2004 IEEE International Conference on Mobile Data Management \(MDM  04 0-7695-2070-7/04 $20.00  2004 IEEE pre></body></html 


um be r o f C he ck ed P at te rn s Support Threshold Mafia Min_Conf=0.5 Min_Conf=0.7 Min_Conf=0.9 Figure 6. The Number of Checked Patterns on the Pumsb Data Set 10 100 1000 10000 0.1 0.2 0.3 0.4 0.5 0.6 0.7 R un T im e s ec  Support Threshold Mafia Min_Conf=0.5 Min_Conf=0.7 Min_Conf=0.9 Figure 7. The RunTime Comparison on the Pumsb Data Set The runtime comparison of MHP and MAFIA on the Pumsb* data set is shown in Figure 5. In the ?gure, we can observe that the runtime of MHP can be signi?cantly reduced with the increase of h-con?dence thresholds. Also the runtime of MHP can be several orders of magnitude less than that of MAFIA even if the h-con?dence threshold is as low as 0.3. The reason is that the number of checked patterns of MHP is sign?cantly smaller than that of MAFIA Similar results are also obtained from the pumsb data set as shown in Figure 6 and Figure 7. For the pumsb data set the number of checked patterns of MHP is much smaller 


than that of MAFIA and the runtime of MHP can be significantly less than that of MAFIA 5.3. The Effect of the MHP Algorithm on Finding Maximal Hyperclique Patterns Figure 8 and Figure 9 show the number of maximal patterns identi?ed byMHP andMAFIA on Pumsb* and Pumsb data sets respectively. As can be seen, the number of maximal hyperclique patterns identi?ed by MHP can be orders of magnitude smaller than the number of maximal frequent patterns identi?ed by MAFIA. In other words, the number Proceedings of the 16th IEEE International Conference on Tools with Artificial Intelligence \(ICTAI 2004 1082-3409/04 $20.00  2004 IEEE 100 1000 10000 100000 1e+06 1e+07 1e+08 1e+09 0.02 0.025 0.03 0.035 0.04 0.045 0.05 0.055 0.06 N um be r o f C ou nt ed P at te rn s Support Threshold Mafia Min_Conf=0 Min_Conf=0.1 Min_Conf=0.3 Min_Conf=0.5 Min_Conf=0.7 Min_Conf=0.9 Figure 8. The Number of MFI/MHP Patterns in the Pumsb* Data Set 100 1000 10000 100000 1e+06 


1e+07 1e+08 0.1 0.2 0.3 0.4 0.5 0.6 0.7 N um be r o f C ou nt ed P at te rn s Support Threshold Mafia Min_Conf=0.5 Min_Conf=0.7 Min_Conf=0.9 Figure 9. The number of MFI/MHP Patterns in the Pumsb Data Set of maximal hyperclique patterns is much easier to manage than that of maximal frequent patterns. Indeed, in realworld applications, it is dif?cult to interpret several million maximal frequent patterns. However, it is possible to interpret the results of maximal hyperclique pattern mining In addition, due to the memory limitation, we cannot extract maximal frequent patterns with MAFIA on the Pumsb data set if the support threshold is less than 0.4, as shown in Figure 7. In contrast, MHP can identify maximal hyperclique patterns when the support threshold is 0.1, if we set the h-con?dence threshold to 0.5. In other words, MHP has the ability to identify patterns which can be dif?cult to identify for MAFIA. Hence, MHP can better explore the pattern space and ?nd interesting patterns at low levels of support 6. Conclusions and Future Work In this paper, we present a two-phase Maximal Hyperclique Pattern \(MHP best features of both the BFS strategy and the DFS strategy. More speci?cally, we adapted DFS pruning methods such as equivalence pruning, to an apriori-like approach In addition, we proved the correctness and completeness of the MHP algorithm. Finally, our experimental results show that the MHP algorithm can be several orders of magnitude faster than standard maximal frequent pattern mining algorithms and has the ability to identify patterns at extremely low levels of support in dense data sets There are several directions for future work. First, in 


this paper, we only generate the size-2 patterns in the BFS phase. It will be interesting to investigate the impact on the performance if the ?rst phase is stopped at a deeper level Also, the projection is a very ef?cient method for ?nding patterns, especially for parallel implementation of pattern mining algorithms [1]. We plan to adapt the projection ideas into our algorithm and design an ef?cient parallel algorithm for mining maximal hyperclique patterns References 1] R. Agarwal, C. Aggarwal, and V. Prasad. A Tree Projection Algorithm For Generation of Frequent Itemsets. pages 350 371, Feb 2001 2] R. Agrawal, T. Imielinski, and A. Swami. Mining Association Rules between Sets of Items in Large Databases. In Proc. of the ACM SIGMOD Conference on Management of Data, pages 207216,May 1993 3] R. Agrawal and R. Srikant. Fast Algorithms for Mining Association Rules. In Proc. of the 20th Intl Conference on Very LargeData Bases, 1994 4] R. Bayardo. Ef?ciently mining long patterns from databases In Proc. of the ACM SIGMOD Conference, 1998 5] R. Bayardo and R. Agrawal. Mining the Most Interesting Rules. In Proc. of the ACM SIGKDD Conference, 1999 6] D. Burdick, M. Calimlim, and J. Gehrke. Ma?a: AMaximal Frequent Itemset Algorithm for Transactional Databases. In Proc. of IEEE Conf. on Data Engineering, 2001 7] Y. Huang, H. Xiong, W. Wu, and Z. Zhang. A Hybrid Approach for Mining Maximal Hyperclique Patterns. In In Technical Report UTDCS-34-04, Department of computer science, University of Texas - Dallas, 2004 8] J.Han, J.Pei, and Y. Yin. Mining Frequent Patterns without Candidate Generation. In Proc. of the ACM SIGMOD International Conference on Management of Data, 2000 9] M.J.Zaki and C.Hsiao. ChARM: An ef?cient algorithm for closed itemset mining. In Proc. of 2nd SIAM International Conference on Data Mining, 2002 10] R.Rymon. Search through Systematic Set Enumeration. In Proc. Third Intl Conference on Principles of Knowledge Representation and Reasoning, 1992 11] H. Xiong, M. Steinbach, P.-N. Tan, and V. Kumar. HICAP: Hierarchial Clustering with Pattern Preservation. In Proc. of 2004 SIAM International Conference on Data Mining \(SDM 12] H. Xiong, P.-N. Tan, and V. Kumar. Mining Strong Af?nity Association Patterns in Data Set with Skewed Support. In Proc. of the Third IEEE International Conference on Data Mining \(ICDM Proceedings of the 16th IEEE International Conference on Tools with Artificial Intelligence \(ICTAI 2004 1082-3409/04 $20.00  2004 IEEE 





