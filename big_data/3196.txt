Abstract 
the depth-first method to find and update MFI. Finally, the algorithm was tested on the mushroom and T15I4D100K database, and UAMFI's performance 
Fast Updating Maximal Freq uent Itemsets Based On Full Merged Sorted FP-Tree GUO Yunkai , YANG Junrui , HUANG Yulei Dept. of Computer Science Xi'an University of Science & Technology Xi'an 710054, China 
204Because of the low efficiency of Maximal Frequent Itemsets\(MFI\ updating methods, the MFI's updating methods were analyzed. A new algorithm UAMFI based on Full Merged Sorted FP-Tree \(FMSFP-Tree\ was proposed. By merging the Sorted FP-Tree and then obtaining the FMSFP-Tree, UAMFI use  
were compared with Mafia. The experimental results indicate that UAMFI is an efficient algorithm for updating Maximal Frequent Itemsets 
Keywords- Data mining; Association rule; Maximal Frequent Itemsets; Sorted FP-Tree; Updating 
I I NTRODUCTION Frequent itemsets play an essential role in many data mining tasks that try to find interesting patterns from databases, such as association rules, correlations, sequences, episodes classifiers, clusters and many more of which the mining of association rules is one of the most popular problems Various of the proposed itemset mining algorithms are a variant of Apriori[1  w h i c h e m pl oy s a bot t om up  b r e a d t h  
first search that enumerates every single frequent itemset. In many applications with long frequent patterns enumerating all possible 2 m 2 subsets of a m length pattern is computationally unfeasible. Thus, there has been recent interest in mining maximal frequent patterns in these "hard" dense databases. As the maximal frequent itemsets \(MFI\ contains all the frequent itemsets , it is easy to analyze some interesting properties of the database, such as the longest pattern, etc. As a result, the maximal frequent pattern discovering plays an essential role in current research [3, 4, 8-1   In actual applications, users may adjust the minimum support dynamically to mine MFS which can meet the actual 
needs. Thus high efficiency algorithm for updating MFS need to be studied in order to maintain and manage the MFS mined MFS\220 updating has two situations: \(1\ how to update MFS when the database has changed and the minimum support hasn\220t changed. There are many algorithms to handle this problems, such as FUP[5 
IUA[6 
UMFIA[7   2  Ho w t o  update the MFS when the database does not change but the minimum support has changed. However, algorithms to handle this problem are rarely proposed. In this paper we focused on the MFS updating problems based on data transformation. We use a novel full merged Sorted FP-tree \(FMSFP-Tree\ to represent sub database containing all relevant frequency 
i 1 i 2 203,i m 
A Frequent pattern & Maximal frequent pattern 
information and with this data structure, our algorithm UAMFI Update Algorithm for mining Maximal Frequent Itemsets takes a new updating method to maintain the MFS This paper is organized as follows. In section II, we briefly review the MFI mining problems and introduce the related works. Section III gives the MFI updating algorithm, UAMFI which update MFI based on FMSFP-Tree. In section IV, we compare our algorithm with Mafia [10 F i n al l y   in s ecti o n  V  we give our conclusion II P RELIMINARIES be a set of different items, and D be a 
Let I 
database of transactions, where each transaction T is a set of items such that T 
I a pattern \(or an itemset\. The count of X is the number of transactions in D that contain X, which is labeled as count\(X\, and let supp\(X be the percentage of transactions in D that contain X Definition 1.Given a transaction database D and a minimum support threshold s\(or the minimum support count if supp\(X 
s \(or count\(X 
001 001 
we say that X is a frequent pattern, and we denote the set of all frequent patterns by FI 
I. The number of the transactions in D is denoted by |D|, associated with each transaction is a unique identifier, called its TID. We call X 
As the database D shown in table 1,with 
The frequent 1-itemset is called frequent itemset for short Definition 2.The 
b c 
of D is 1\(namely as a 
2\(b 3\(c 4\(g\nd 5\(e Definition 3. If X is frequent and no superset of X is 
is all the frequent itemsets in database D and sorted by its support count The 
is the L 1 numbered from 1 
 2,the L 1 of D is a 
frequent itemsets list L 1 
frequent item sequence list L 1 
g and e; the corresponding L 1 
Example 1 
frequent, we say that X is a maximal frequent pattern, and the sets of all maximal frequent patterns denoted by MFS 1 
B Sorted FP-Tree \(SFP-Tree 
We introduced a new data structure SFP-Tree to avoid the low efficiency of constructing and creating a number of subtrees, by investigating the relative article [2, 8,  9  
978-1-4244-2108-4/08/$25.00  \251 2008 IEEE 
Property 1 
Let L 1 be a list of all frequent items sorted by their frequency in descending order, and each of the maximal frequent pattern are made up of the item in L 1 


Algorithm 1 \(SFP-Tree construction count registers the number of transactions represented by the portion of the path reaching this node, first-child registers the node\220s first child and brother-link links to the next node in the SFP-Tree carrying the same parent, or null if there is none. The nodes in the brother-link are sorted by their node-no Based on this definition, we have the following FP-tree construction algorithm P\220s brother-link, make all the node-no in ascending order. If 2, Fig.1 shows the final SFP-Tree of D. Each node in Fig.1 has a section such as \(1:4\ the number in front of ": " is node\220s node-no, and the number after ": " is the count. The break-line indicates brother-link that the nodes are brothers and the real-line indicates the first-child that the parent is at the top and the child is on the bottom Let\220s take the database D shown in table 1 for example ,the sequence 2 3 4 with support count 2 is a MFI under Input Output is the first element and Create_tree C FMSFP-Tree n|N  T  If be [n|N w h e r e  and a minimum support and their supports. Sort in support descending order as node-no = n,count = 1,and link Q.node-no = n, if we find this node ,add it by 1, else create a database 4:2 Another path in S is [3 4 be c a u s e i n T 220 s 1 st level there is no node which has the same node-no equal to 3, so it creates a new node \(3:1\ and inserts  it into T\220s 1 st level, \(3:1\\220s subnode \(4:1\ is inserted into T\220s 2nd level as \(3:1\\220s sub-node O\(|trans In SFP-Tree, the same itemset may be separated in different sub-trees, and the support counts of itemset in sub-tree are all less than SFP-Tree into the SFP-Tree is When the SFP-Tree set its second constructs the SFP-Tree. The cost of inserting a 978-1-4244-2108-4/08/$25.00  \251 2008 IEEE 2 T here P and P.brother-link which L 1 L 1 2, but it distributed in two sub-trees, each itemset has the support count 1,when mining each sub-tree and just use the theorem 1 to examine the itemset whether is MFI, the MFI 2 3 4 is leaked. So merging strategy was proposed to solve the problem The merging strategy is described as follows: when dealing with the current node P, first make sure whether P\220s sub-tree S its parent is P\ contains the same nodes in P\220s brother-tree T the tree that P.brother-link point to\. If true, then it can merge that is adding S\220s node contained in T to T by node level. If the same node is contained in T at the same level \(the T\220s level is 1\, then add this node\220s count to the node contains in T otherwise it will insert the node into T using the SFP-Tree\220s construction method frequent item sequence list For database D in table 1 with in do the following Select and sort the frequent items in t to is finally constructed, each 3:3\. The node \(4:1\ is inserting into T\220s 3rd level and the node in T \(4:1  T ABLE I T RANSACTION D ATABASE D TID item Frequent Items t T ABLE II.L 1  n|N  T  is p e r f o r me d as  f o llo w s  A transaction database is the remaining list. Call link. All the nodes are in ascending order by their node-no count else search recursively Definition 4. A Sorted FP-Tree \(or SFP-Tree for short\ is a tree structure by improving the FP-Tree [2 t r u c t ur e d e s i gn e d  for maximal frequent pattern\220s storage and search. The structure of SFP-Tree is defined below 1. It consists of one root labeled as "root", a set of items prefix sub-trees as the children of the root 2. Each node in the item prefix sub-tree consists of four fields: node-no, count, first-child and brother-link where nodeno registers which item this node represents in the frequent item sequence list L1 once. Collect the set of frequent items 2\.Create the root of FP-tree sub-node, these nodes are brothers and linked by brotherLet the frequent item sequence list in t see that one needs exactly two scans of the transaction transaction according to the order of and then replace them by their location in The function the first collects the set of frequent items, and the is the number of frequent items in 220 first element is the root\220s Considering Fig.1,when dealing with the node P 1:4\, P\220s sub-tree S has a path [2 3 4  a s 2  2 o nt a i n e d  i n  P\220s brother-tree T, then the \(2:2\\220s level is 1 and the node \(2:2 should be inserted into T\220s 1 level, in T\220s 1 level, there is a node\(2:1\ has the same node-no, so node \(2:2\ count is added to the node \(2:1\, thus obtain the merging result \(2:3 The node \(3:2\ is also contained in T, as its parent contained in T, then the node \(3:2\\220s level is 2; it should insert into T\220s 2nd level and get the result \(3:1 the node Q in L 1 and the root only point to the node in the left and label it as "root".  For Then get the then create a new node  new node Q, set its node-no = n, count = 1, and insert Q into L 1 DB D  Example 3 L 1 DB DB The SFP-Tree is constructed in the following steps 1\.Scan the T.first-child rans rans Create_tree T.first-child = null trans trans trans trans F F L 1 L 1 rans n N  P P T.first-child N Method each transaction t Figure.1 SFP-Tree according to the D of Table 1 100 a,b,c,g a,b,c,g 1 2 3 4 200 a,b,c a,b,c 1 2 3 300 a,c,g a,c,g 1 3 4 400 a a 1 500 b,c,e,g b,c,e,g 2 3 4 5 600 e,g g,e 4 5 1 a Analysis. From the SFP-Tree construction process, we can 2 b 3 c 4 g 5 e Create_tree \(N; P Example 2 is not empty, call 


D Correlative property Property 2 Property 3 Property 4 Property 5 Proof Proof Property Example 4 from the Property 3 we can draw the conclusion that all N\220s sub-node has a count less than pTree.node-no add current node\220s node-no into CFS 4 exist   UAMFI for efficient MFI mining Input Output 13 exist 2,the updating process is described as follows then using depth-first strategy to deal with the path with pre-fix 1 2, the node \(3:2 has only one sub-node \(4:1\ with count = 1 if if if FMSFP-Tree is a novel data structure, in has its own attributes. We can draw a conclusion of such attributes by surveying FMSFP-Tree\220s structure and its construction MFS  else if s  s, then L 1 MFS   When the minimum support has changed, there are two conditions: s  s and s  s. If s = 0 and we constructed the corresponding FMSFP-Tree. After that, given any s  0, there exists MFS MFS  from theorem 2 we know that FMSFPTree contains all the MFS under s  so  we just need to use depth-first strategy  and directly traverse FMSFP-Tree, then we get the MFS  under s   Algorithm 2 MFS with MFS 14 MFS = MFS As  FMSFP-Tree constructed in example 1 given a minimum support count In FMSFP-Tree, each path\220s count indicate the item it represent  appeared in the database In FMSFP-Tree, the node\220s count declined from top to down. Given a node, its count is greater or equal to the sum of nodes in its sub-level In FMSFP-Tree, if we change each node\220s node-no into the path which from to this node, then the FMSFP-Tree w ill transform into set enumeration tree[11   the FMSFP-Tree construct under CFS 15 0 0 978-1-4244-2108-4/08/$25.00  \251 2008 IEEE 3 end if Figure.3   final FMSFP-Tree end while CFS =  NULL 3 CFS = CFS Finally, the merging result is shown in Fig.2. After handling all nodes, the final FMSFP-Tree is shown in Fig. 3 If the initial minimum support count is 0, then given any support, all the MFS under this support included are in the FMSFP-Tree 6: Assume D retain the same, if s  s, then L 1 is the minimum support count \, then neither count of  N\220s sub-node is greater than CFS then from theorem 1 we known {1 2 3} is a MFI and add it into MFS MFS ={{1 2 3}}. Then using the same method deal with the remain node recursively, and finally we obtain the MFS={{1 2 3},{1 3 4},{2 3 4}, {4 5 minimum support count exist deal with the node 2 and 3 respectively. When processing pre-fix path 12, node 2\220s first-child 3 with a count = 2 1\.MFS = CFS = NULL ; //CFS is the candidate set 2\.root.count = -1; //set the root\220s label 3\.call   DFMF \(root,CFS 4\return DFMF \(Current_Pointer,CFS\; // recursionly 10 Assume the database D retain the same, while the minimum support has changed. The minimum supports vary from s to s   The corresponding frequent item lists are L 1 and L 1  the maximal frequent sets are MFS and MFS   Each item in the database D has appeared in a path of FMSFP-Tree which means that all the sub-node is infrequent .Thus the path from root to current node N is a MFI or MFI\220s candidate If the node P which current node N\220s first-child points to has a count When dealing with the path with 1 as pre-fix, the node 1 has two sub-nodes 2 and 3 with count Figure.2 Merge example L 1   MFS    8  thus the path from root to current node N is a MFI or MFI\220s candidate 001 002    11\  Current_Pointer=Current_Pointer.brother-link 12 L 1   MFS then then else 001 002 002 003 true true When the initial support is 0, then the FMSFP-Tree contains the entire information of the database . From property 5, the paths in the FMSFP-Tree are the set numeration tree\220s value. Because of the set enumeration tree enumerates all the combinations of 1-item, so in any support all the MFS also contained in FMSFP-Tree III false pTree .count = = -1\ // pTree is the root 2    In FMSFP-Tree, we assume the current node N\220s first-child is P, if P.count Current_Pointer.count  Procedure DFMF \(pTree,CFS 1  9  Theorem 1 Theorem 2 UAMFI FOR EFFICIENT MFI UPDATING MFS call end assume there exist MFI 5\ Current_Pointer = pTree.first-child 6 while \(Current_Pointer != NULL 7 


All experiments were performed on 2.1G Hz AMD Athlon support then change s and use UAMFI for updating , in new support and compare the run-time with UAMFI greater than UAFMI \(in 30% runs 0.684s, Mafia runs 1.827s study shows that the method updating short and long patterns algorithm has good performance R EFERENCES 1 g ra w a l  R Im i e l i n s h i  T  S w a m i A M i n i n g  a s s o c i a t i o n  ru l e s b e t w e e n se t s  of items in large database. In: Proceedings of ACM SIGMOD Conference on Management of Data, Washton,DC,1993,pp.207-216 2 Ha n  J Ji a n P  Yi we n  Y M i n i n g f r e q u e n t p a t t e r n s  wi t h o u t c a n d i d a t e  generation. In: Proceedings of the 2000 ACM SIGMOD International Conference Management of Data, Dallas,2000,pp.1-12 3 a v a se r e  A  O m i e c i n s k i  E   Na v a t h e S M   A n e ffi c i e n t a l g o r i t h m  fo r  mining association rules. In:Proceedings of the 21st International Conference on VLDB.Zurich, 1995,pp. 432-444 4 T o iv o n e n H  Sa m p li n g la r g e  d a ta b a s e s  f o r a s s o c i a t i o n r u l e s  I n P r o c  o f t h e  22th Int'l Conf. on VLDB,Bombay,India,1996,pp.34 We have proposed a novel data structure, FMSFP-Tree, for storing the data contains all the information of MFS compressively, and developed a depth-first algorithm, UAMFI for efficient updating MFS in large databases 0, the FMSFP-Tree contained all the MFS with any support, the MFS with a given support are distributed in the tree, so it just needs to traverse the tree to find the MFS  at any given support Analysis. Reasons of high efficiency are:1\ base on FMSFPTree, it highly compressed the database and contained all the information of MFS; 2\.No need scan the database, directly mine the MFS on FMSFP-Tree and traverse some paths low, UAMFI has to process more traverses to find the MFS fewer studies related to this situation so far, so we compare Timings in the figures are based on total wall-clock time threshold is higher. To this dataset, Mafia\220s runtime is also V C ONCLUSIONS 4 E XPERIMENTAL RESULTS follows and the runtime is a little longer when the minimum support We have implemented UAMFI , studied its performance in g K of the two algorithms were complied using Visual C++ 6.0 We report experimental results on two datasets. The first one is mushroom downloaded from the Website [13 w h ic h  has 8124 transactions and 23 kinds of attributes. The second dataset T15I4D100K is a synthetic and sparse data set. It was generated from the application of  I t  ha s 1 00 000 transactions. The average transaction length is 15 and the average pattern length is 4 Figure. 4 The test results on database mushroom Fig.4 and 5 display the algorithms\220 performance in different and include all preprocessing costs .The test schemed as order to compare the performance, run Mafia again with the 0.Because, when UAMFI with Mafia, downloaded from FIMI [12   Th e co d es  Transfer node-no into the element it represented, then MFS ={{abc},{acg},{bcg},{ge IV Theoretic analyses and experimental results indicate this first use Mafia to mine the MFS with a given comparison with Mafia in large databases. Our performance 0. 187s, Mafia costs 1.98s For T15I4D100K, when the minimum support threshold is UAMFI is a high efficient algorithm for MFS updating while updating, it only use the FMSFP-Tree which constructed with  t t p    www a l m a d e n  i b m  c o m  c s  p r o j e c t s  i i s  minimum support threshold \(10~90%\.For mushroom   978-1-4244-2108-4/08/$25.00  \251 2008 IEEE 64 X2 with 896MB of memory, Windows XP SP2 . There are both efficiently. It outperforms Mafia s Fi UAMFI is faster than Mafia \(example: in 30%, UAMFI runs 45 5 C h e u n g D W  H a n J  M a i n t e n a nce of  d i s c ove r e d a s s o ci at i o n r u l e s i n l a r g e  database: An incremental updating technique [C  P r oc of t h e 12t h I n t  Conf on Data Engineering.New Orleans, Louisiana, 1996,pp.106-114 6 E NG Yu c a i  F E NG Ji a n l i n  I n c r e me n t a l  Up d a t i n g  Al g o ri t h ms  fo r  Mining Association Rules[J   J o ur n a l  of Sof t w ar e   1998 9 4  p p  301 306. \(in Chinese 7 ONG Yu Q i n g  Z H U Yu Q u a n  S U N Z h i Hu i  C h e n  Ge n g  A n  A l g o ri t h m and Its Updating Algorithm Based on  FP-Tree for Mining Maximum Frequent Itemsets [J  J o ur n a l of Sof t w ar e  2003 14 9  p p  15861592  in Chinese 8 R U A N Y o u l i n L I Q i ng h u a  L i u G a n Fa s t Mi ni n g a n d U p da t i n g  Algorithm for Maximum Frequent Patterns[J  C o mp ut e r  E n g i n e e r i ng and Applications,2005,\(24\ ,pp.23-26. \(in Chinese 9 QIN L i a n g x i  S H I Z h o n g z h i  S F P M a x A S o rt e d F P T r e e Ba se d  Algorithm for Maximal Frequent Patterns Mining[J  J o ur n a l of  Computer Research and Development, 2005,42\(02\,pp.217-223. \(in Chinese 10  D B u r di ck  M C a l i m l i m  J  G e hr k e  A Ma xi m a l Fr e q u e nt  I t e m s e t A l g o r i t h m  for Transactional Database[A  A non  P r o cee di ngs  of I n t e r n at i o n a l  Conference on Data Engineering 2001[C  H e i de l b e r g  G e r m a n y I E E E  Computer Society,2001,pp.443 452 1 R y mon R  S e ar ch t h r o ugh  s y s t e m a t i c  s e t  e n u m e r at i o n  C   I n P r ocee di n g  of Third International Conference on Principles of Knowledge Representation and Reasoning. 1992,pp.539- 550 12 h t tp    f i m i c s  h e ls in k i f i 13 h t t p    www i c s  u c i  e d u   m l e a r n  M L R e p o s i t o r y  h t m l  1 ure. 5 The test results on database T15I4D100 


662 rules were mined The association rules generated and the test images were submitted to the ACE algorithm which produced suggestions of diagnosis for each test image In a batch execution the test images were submitted to the IDEA system and the accuracy obtained considering the main parts of the diagnosis morphology and Bi-RADS were Morphology 91.3  BI-RADS value 96.7  Since BI-RADS categorization has a fuzzy separation among consecutive levels even for a human being we considered correct if the BI-RADS level suggested was the same or adjacent of the level annotated by the radiologist in the image report This result indicates that the employed features represent more the BI-RADS level of the lesion than the morphological properties of the images Table 2 shows the values of accuracy sensitivity and speci\002city achieved by IDEA in detecting the BI-RADS levels Table 2 Results achieved by IDEA in detecting the BI-RADS levels over the ROI dataset Accuracy 96.7 Sensitivity 91.3 Speci\002city 71.4 The system was also evaluated by two radiologists who demonstrated a high degree of acceptance for it They reported that the system had indicated lesions that they did not see in a 002rst analysis Figure 3 shows a screenshot of the system when analyzing the image on left of the screenshot The system shows the weight of each diagnosis keyword between parentheses The weight indicates the strength of the respective diagnosis part The higher the weight the higher the con\002dence that the keyword re\003ects the true diagnosis of the image Figure 3 Screenshot of the IDEA system 4.2 Experiment 2 the Mammogram Dataset The Mammogram dataset is composed of 1,080 mammograms collected in the Clinical Hospital of University of Sao Paulo at Ribeir  ao Preto The Mammogram dataset contains images classi\002ed in 4 levels of breast tissue density 1 mostly fatty 362 images 2 partly fatty 446 images 3 partly dense 200 images and 4 mostly dense 72 images Figure 4 illustrates examples of the images of this dataset Breast density is an important risk factor in the development of breast cancer In this experiment the images are represented by the feature set proposed in compounding a vector of 85 features including shape and size of the breast the conditions of the breast contour nipple position and the distribution of 002broglandular tissue level 1 level 2 level 3 level 4 Figure 4 Examples of images from the Mammogram dataset Images from left to right correspond respectively to mammograms of density levels 1 2 3 and 4 The visual analysis of mammograms by radiologists is a subjective task and suffers from a high degree of variability Thus it is a fair criterion to set as relevant not only the images of the same density class of the query image but also the images in the adjoining classes This is the approach used in this paper The same steps of the 002rst experiment were performed in this experiment In the training phase Omega algorithm reduced 34 of the feature vector size keeping only 56 of the original 85 features Apriori mined 30,996 association rules In the test phase the association rules and the features of test images were submitted to the ACE algorithm We measured the ability of IDEA in distinguishing a breast side  right breast or left breast  b type of the view medio-lateral oblique or cranio-caudal and c density level The values of accuracy obtained considering these parts of the diagnosis were Side 73.5  View 85.1  Density 94.8  Figure 5 shows a screenshot of the system when analyzing the image on the left of the screenshot Observe that the system suggests density 1 and 2 for the analyzed image However density=2 gets a higher value of weight than density=1 thus indicating that most likely the image is from 
270 
270 
270 
270 


density=2 which is the density of the image that is in the specialist's report The system can suggest more than one diagnosis hypotheses to the radiologists work on However the hypotheses with a higher value of weight should be 002rstly considered by them Figure 5 Screenshot of the IDEA system The results of the Experiments 1 and 2 are very promising because they show a very small error rate regarding the main part of the diagnosis BI-RADS and density level for Experiments 1 and 2 respectively making the system more reliable 5 Conclusions In this paper we presented the IDEA approach based on association rules to assist the specialists in the task of image diagnosing IDEA encompasses four main steps feature extraction feature selection and discretization association rule mining and generation of diagnosis suggestions Two new algorithms were developed to support the method Omega and ACE Omega executes two tasks in a single step feature selection and supervised discretization The ACE algorithm generates diagnosis suggestions by assigning multiple keywords to a test image The results of using real datasets show that the proposed method achieves high accuracy up to 96.7 being more sensitive than speci\002c what is desirable in medical domain The radiologists demonstrated acceptance for the IDEA system showing enormous interest in employing the system to aid them in their daily work The IDEA method has an important characteristic that makes it different from other CAD methods it can suggest multiple diagnosis hypotheses for the same image and employs a measure of quality to rank them The results indicate the proposed method is very suitable for the task of suggesting diagnosis of medical images enhancing and bringing more con\002dence to the diagnosing process Acknowledgment We thank the Brazilian funding agencies FAPESP CAPES and CNPq References  R Agra w al T  Imielinski and A  N Sw ami Mining association rules between sets of items in large databases In The ACM SIGMOD ICMD  1993  R Agra w al and R Srikant F ast algorithms for mining association rules In Intl Conf on VLDB  1994  M Al-Shalalf a and R Alhajj A ttracti v e feature reduction approach for colon data classi\002cation In 21st Intl Conf on Advanced Information Networking and Applications Workshops   M.-L Antonie O R Zaane and A Coman Associati v e classi\002ers for medical images In LNAI 2797 MMCD  pages 68–83 Springer-Verlag 2003  E.-L Chen P C Chung C.-L Chen H.-M T  A H.-M Tsai and C.-I C A C.-I Chang An automatic diagnostic system for ct liver image classi\002cation IEEE Transactions on Biomedical Engineering  45\(6 1998  K Do i and H Huangb  Computer aid ed diagnosis cad and image-guided decision support Computerized Medical Imaging and Graphics  31\(4-5 2007  S K Kinoshita P  M d Aze v edoMarques R R P  Jr  J A H Rodrigues and R M Rangayyan Contentbased retrieval of mammograms using visual features related to breast density patterns Journal of Digital Imaging  20\(2 2007  N Otsu A thresholding selection method from grayle v el histogram IEEE Transactions on Systems Man and Cybernetics  9:6266 1979  H P an J Li and Z W ei Mining interesting association rules in medical images In Advance Data Mining and Medical Applications   P  Perner  Image mining issu es frame w ork a gener ic tool and its application to medical-image diagnosis Engineering Applications of Arti\002cial Intelligence  15\(2 2002  S Quek C Thng J Khoo and W  K oh Radiologists detection of mammographic abnormalities with and without a computer-aided detection system Australasian Radiology  47\(3 2003  O T alak oub J Alirezaie and P  Babyn Lun g se gmentation in pulmonary ct images using wavelet transform In J Alirezaie editor Acoustics Speech and Signal Processing 2007 ICASSP 2007 IEEE Intl Conf on  volume 1 pages I–453–I–456 2007  X W ang M Smith and R Rang ayyan Mammograp hic information analysis through association-rule mining In IEEE CCGEI  pages 1495–1498 2004  J Y a o J Li and R Summers Ct colonograph y computer aided polyp detection using topographical height map In J Li editor IEEE Intl Conf on Image Processing  volume 5 pages V  21–V  24 2007  W L Zhang and X.-Z W ang Feature e x traction and classi\002cation for human brain ct images In X.-Z Wang editor Intl Conf on Machine Learning and Cybernetics  volume 2 pages 1155–1159 
271 
271 
271 
271 


IEEE Intelligent System 2004 Volume 23 \(8  Telford W.M Geldart, L.P. and Sheriff R.E. \215Applied Geophysics\216 1990\d 600-750   Chakraborty K Mubarak, Al H, Nimmagadda, S.L. and Ray, J 215Exploration Data Integration, an effective reengineering process for new petroleum plays in Gulf Offshore Basins\216, presented at the 2006 International Conference of 2004\, 47 \(7\, pp 77-80 1998\, 13\(1   Shanks, G. Tans ley  E W e ber R. \215Using Ontol ogy to validate conceptual models\216 2005 Australia   Nim m agadda, S.L, and Dreher, H. \215 M apping of Oil and Gas Business  Data Entities for Effective Operational Management\216, presented and published in the held in Phitsanulok 2008  Meers m an R.A 215Fou ndation s, implementations and applications of web semantics, parts 1, 2, 3\216 s, 14\(1\, \(1999\, pp. 27\20536   Jasper, R. and Uschold, M. A 215Framework for understanding and classifying ontology applications\216, published in the International Conference of IEEE in Industry Informatics Forum February, Tripoli, \(2007\, Libya   Nim m agadda, S L. and Dreher, H. Ontology based W a rehouse Tim e Depth Data Modelling Framework for Improved Seismic Interpretation in Onshore Producing Basins, a paper presented and published in the   Nim m agadda, S.L. and Dr eher H 215Ontolo gy of W e ster n Austr alian  petroleum exploration data for effective data warehouse design and data mining\216, presented and published in the 38 th Hawaii International Conference on Information System Sciences 2006   Nim m agadda, S.L., and Dreher H. \215Ontology based data warehouse modelling and mining of earthquake data: prediction analysis along Eurasian-Australian continental plates\216, a paper accepted for presentation in the w, \(1996\, 11\(2   Shanks, G. Tansley  E. and W e ber, R. \215Representing composites in conceptual modelling\216 AAPG 2007   Nim m agadda, S.L. and Dr eher H Ontology Based Data W a rehouse Modelling \205 a Methodology for Managing Petroleum Field Ecosystems, a paper presented and published in the on IT, \(2004   Rudra, A. and Ni mmagadda, S.L. \215 Roles of m u ltidi mensionality and granularity in data mining of war ehoused Australian resources data\216 presented at the Knowledge Engineering Review presented at the 7th international conference 2005\Hawaii, USA   Nim m agadda, S.L. and Dr eher, H. \215Ontology-Base Data warehousing and Mining Approaches in Petroleu m Industries\216: in Negro, H.O Cisaro, S.G., and Xodo D., \(Eds.\, Data Mining with Ontologies Implementation, Findings and Framework, a book published in 2007 by Idea Group Inc http://www.exa.unicen.edu.au/dmontolo  November, Perth, Australia  Chakraborty  K AlHajeri, M and Nimmagadda, S.L. \2153D Seismic Data Attributes Analysis for Predicting Wara reservoir qualities in the Al-Khafji Field, Middle East\216 proceedings of the International Petroleum Technology Conference IPTC Knowledge Engineering Revie communications of the ACM Curtin Business School, 2004   Valente, A., Russ, T., Ma cGrego r, R., and Swartout, W. \215Building and re\logy of air campaign planning\216 proceedings of the 3 rd international IEEE conference on Industrial Informatics proceedings of the IJCAI-99 ontology workshop proceedings of the 4 th International Conference of IEEE Industry Informatics proceedings of the 2 nd International Conference of IEEE-DEST 2007   Nim m agadda, S.L. and Ru dra A. \215Data sources and requirement analysis for multidimensional database modeling \205 an Australian Resources Industry scenario\216 Lecture Notes presented at School of Information Systems 1999\, p.1-20   Uschold, M.E. \215Knowledge level m odeling: concepts and terminology\216 2003\, 46\(10\, pp 85-89   Hoffer, J.A, Presscot, M.B and Mc Fadden, F.R. \215Modern Database Management\216, \(2005\, 7 th Edition, Prentice Hall   Pujari, A.K 215 D ata Mining Techni ques\216, Universities Press \(India  Private Limited, \(2002  Ozkarahan E 215Database Ma nagement, Concepts, Design and Practice\216, \(1990   Uschold, M. & Gr uninger M. Onto logies 215Principles m e thods and applications\216 VI CONCLUSIONS AND RECOMMENDATIONS 1 Ontology based design of data acquisition; data processing and interpretation are more effective in extracting knowledge on structural and petroleum geology domains. This is indeed a revolutionary concept in the fields of exploration and development of petroleum fields, which has more future scope of commercial research 2 Data instances from CDP, COP, CRP, CSP dimensions can easily be structured and integrated in a warehouse environment for the purpose of interpreting seismic signals and their attributes as required by geologists, well planners, reservoir and production engineers 3 Framing of business rules, constraints among usage of attributes within th e integration process and design of business rules have definite impact on correlation and mapping and thus on data mining 4 Ontology based data structuring has definite advantage, especially when attributes and their relationships are conceptualized using appropriate semantics and contexts 5 Integrating on tologically structured data in a warehousing environment has more flexibility and consistency in attribute mapping and interpretation during data mining stage 6 Structural data views taken from implemented warehoused metadata fo llow definite structure shapes, in terms of seismic high and low data instances, depicting geological knowledge 7 Integration of exploratio n data, modeled from different hierarchically derived multiple dimensions; facilitate the data mining process thus extracting knowledge of commercial petroleum plays. Issues of reuse and interoperability of denormalized fine-grained exploration data structures have also been emphasized in the context of implementing ontology based warehousing in petroleum exploration industries This research work addresses new methodologies, which have the potential to revolutionize the exploration and resources industries worldwide This is an on-going commercial research work at Curtin Business School Curtin University of Tech nology, Au stralia. Industry collaboration is accommodated through the University\220s commercialization arm \205 contact the second named author R EFERENCES   Beau m ont E.A and Foster, N.H. \215Exploring for Oil & Gas Traps  AAPG Publications of Millennium Edition\216, \(1999 2  Gilbert, R Liu Y. Abriel  W. an d Preece R. \215 R eservoir m odeling  integrating various data at appropriate scales\216 presented at the 2007 3 rd North African/Mediterranean Petroleum & Geoscience Conference Exhibition Communications of ACM Leading Edge 


TREC ONTO p-value Macro-FM 0.388 0.386 0.862 Micro-FM 0.356 0.355 0.896 MAP 0.290 0.284 0.484 Table 1 Other Experimental results downgrade For the average macroand microF 1 Measures also shown on Table 1 the TREC model only outperformed the ONTO model by 0.002 0.5 in macro F 1 and 0.001 0.2 in micro F 1  The two models achieved almost the same performance The evaluation result is promising The statistical test is also performed on the experimental results in order to analyze the evaluation's reliability As suggested by we use the Student's Paired T-Test for the signi\002cance test The null hypothesis in our T-Test is that no difference exists in two comparing models When two tests produce substantially low p-value usually  0.05 the null hypothesis can be rejected In contrast when two tests produce high p-value usually  0.1 there is not or just little practical difference between two models The T-Test results are also presented on Table 1 The pvalue s show that there is no evidence of signi\002cant difference between two experimental models as the produced pvalue s are quite high  p-value 0.484\(MAP 0.862\(macroFM and 0.896\(micro-FM far greater than 0.1 Thus we can conclude that in terms of statistics our proposed model has the same performance as the golden TREC model and the evaluation result is reliable The advantage of the TREC model is that the experimental topics and the training sets are generated by the same linguists manually They as users perfectly know their information needs and what they are looking for in the training sets Therefore it is reasonable that the TREC model performed better than the ONTO model as we cannot expect that a computational model could outperform a such perfect manual model However the knowledge contained in TREC model's training sets is well formed for human beings to understand but not for computers The contained knowledge is not mathematically formalized and speci\002ed The ONTO model on the other hand formally speci\002es the user background knowledge and the related semantic relations using the world knowledge base and local instance repositories The mathematic formalizations are ideal for computers to understand This leverages the performance of the ONTO model As a result as shown on Fig 2 and Table 1 the ONTO model achieved almost the same performance as that of the TREC model 6 Conclusions In this paper an ontology-based knowledge IR framework is proposed aiming to discover a user's background knowledge to improve IR performance The framework consists of a user's mental model a querying model a computer model and an ontology model A world knowledge base is used by the computer model to construct an ontology to simulate a user's mental model and the ontology is personalized by using the user's local instance repository The semantic relations of hypernym/hyponym holonym/meronym and synonym are speci\002ed in the ontology model The framework is successfully evaluated by comparing to a manual user model The ontology-based framework is a novel contribution to knowledge engineering and Web information retrieval References   C Buckley and E M Voorhees Evaluating evaluation measure stability In Proc of SIGIR 00  pages 33–40 2000   R M Colomb Information Spaces The Architecture of Cyberspace  Springer 2002   D Dou G Frishkoff J Rong R Frank A Malony and D Tucker Development of neuroelectromagnetic ontologies\(NEMO a framework for mining brainwave ontologies In Proc of KDD 07  pages 270–279 2007   S Gauch J Chaffee and A Pretschner Ontology-based personalized search and browsing Web Intelligence and Agent Systems  1\(3-4 2003   X Jiang and A.-H Tan Mining ontological knowledge from domain-speci\002c text documents In Proc of ICDM 05  pages 665–668 2005   J D King Y Li X Tao and R Nayak Mining World Knowledge for Analysis of Search Engine Content Web Intelligence and Agent Systems  5\(3 2007   D D Lewis Y Yang T G Rose and F Li RCV1 A new benchmark collection for text categorization research Journal of Machine Learning Research  5:361–397 2004   Y Li and N Zhong Mining Ontology for Automatically Acquiring Web User Information Needs IEEE Transactions on Knowledge and Data Engineering  18\(4 2006   H Liu and P Singh ConceptNet a practical commonsense reasoning toolkit BT Technology  22\(4 2004   A D Maedche Ontology Learning for the Semantic Web  Kluwer Academic Publisher 2002   S E Robertson and I Soboroff The TREC 2002 002ltering track report In Text REtrieval Conference  2002   M D Smucker J Allan and B Carterette A Comparison of Statistical Signi\002cance Tests for Information Retrieval Evaluation In Proc of CIKM'07  pages 623–632 2007   X Tao Y Li and R Nayak A knowledge retrieval model using ontology mining and user pro\002ling Integrated Computer-Aided Engineering  15\(4 2008   X Tao Y Li N Zhong and R Nayak Ontology mining for personalzied web information gathering In Proc of WI 07  pages 351–358 2007   T Tran P Cimiano S Rudolph and R Studer Ontologybased interpretation of keywords for semantic search In Proc of the 6th ICSW  pages 523–536 2007   Y Y Yao Y Zeng N Zhong and X Huang Knowedge retrieval KR In Proc of WI 07  pages 729–735 2007 
513 
517 


TESTS IN SECOND t INDICATES nl WAS LOWERED TO 2 Training BSTC Top-k RCBT 7 OC Holdout Validation Results RCBT outperforms BSTC on the single test it could finish by more then 7 although it should be kept in mind that RCBT's results for the 24 unfinished tests could vary widely Note that BSTC's mean accuracy increases monotonically with training set size as expected At 60 training BSTC's accuracy behaves almost identically to RCBT's 40 training accuracy see Figure 6 4 Ovarian Cancer OC Experiment For the Ovarian Cancer dataset which is the largest dataset in this collection the Top-k mining method that is used by RCBT also runs into long computational times Although Top-k is an exceptiounally fast CAR group upper bound miner it still depends on performing a pruned exponential search over the training sample subset space Thus as the number of training samples increases Top-k quickly becomes computationally challenging to tune/use Table VI contains four average classification test run times in seconds for each Ovarian Cancer\(OC training size As before the second column run times each give the average time required to build both class 0/1 BSTs and then use them to classify all test's samples with BSTC Note that BSTC was able to complete each OC classification test in about 1 minute In contrast RCBT again failed to complete processing most classification tests within 2 hours Table VI's third column gives the average times required for Top-k to mine the top 10 covering rule groups upper bouhnds for each training set test with the same 2 hour cutoff procedure as used for PC testing The fourth column gives the average run times of RCBT on the tests for which Topk finished mining rules also with a 2 hour cutoff Finally the  RCBT DNF column gives the number of tests that RCBT was unable to finish classifying in  2 hours each THE OC TESTS THAT RCBT FINISHED Training BSTC RCBT 40 92.05 97.66 60 95.75 96.73 80 94 12 98.04 1-133/077 9380 96.12 1070 cJ CZ C 0.95 0.9 0.85 0.8 0.75 0.7 0.65 0.6 0.55 0.5 BSTC RCBT d Median Median  Mean 260 Near outliers  Far outliers 40 Training 60 Training 0.90.80.70.6BSTC RCBT a 80 Training 1-52/0-50 Training 0.9DNFI 0.80.70.6BSTC RCBT b 1 u0.9DNFI 0.80.70.6BSTC RCBT  RCBT DNF 40 30.89 0.6186 273.37 0/25 60 61.28 41.21  5554.37 19/25 80 71.84  1421.80  7205.43 t 21/22 TIMES FOR THE OC 9 Mean 0 Near outliers  Far outliers 1.01 11 01 1.0 d Fig 6 PC Holdout Validation Results BSTC RCBT a Fig 0.80.8 0.8BSTC RCBT BSTC RCBT b c c i DNF cJ CZ C 40 Training 60 Training 80 Training 1-133/0-77 Training 0.95 DNF DNF DNF 0.9 0.90.90.90.85 0.8 BSTC RCBT TABLE VI AVERAGE RUN 1 133/0-77 70.38  1045.65  6362.86 t 20/23 over the number of tests for which Top-k finished Because RCBT couldn't finish any 80 or 1-133/0-77 tests within 2 hours with nl  20 we lowered nl to 2 Classification Accuracy Figure 7 contains boxplots for BSTC on all four OC classification test sets Boxplots were not generated for RCBT with 60 80 or 1-133/0-77 training since it was unable to finish all 25 tests for all these training set sizes in  2 hours each Table VII lists the mean accuracies of BSTC and RCBT over the tests on which RCBT was able to produce results Hence Table VII's 40 row consists of averages over 25 results Meanwhile Table VII's 60 row results are from 6 tests 80 contains a single test's result and 1-133/0-77 results from 3 tests RCBT has better mean accuracy on the 40 training size but the results are closer on the remaining sizes   4 difference over RCBT's completed tests Again RCBT's accuracy could vary widely on its uncompleted tests CAR Mining Parameter Tuning and Scalability We attempted to run Top-k to completion on the 3 OC 80 training and 2 OC 1-133/0-77 training tests However it could not finish mining rules within the 2 hour cutoff Top-k finished two of the three 80 training tests in 775 min 43.6 sec and 185 min 3.3 sec However the third test ran for over 16,000 mnm  11 days without finishing Likewise Top-k finished one of the two 1-133/0-77 tests in 126 min 45.2 sec but couldn't finish the other in 16,000 min  11 days After increasing Top-k's support cutoff from 0.7 to 0.9 it was able to finish the two unfinished 80 and 1-133/0-77 training tests in 5 min 13.8 sec and 35 min 36.9 sec respectively However RCBT with nl 2 then wasn't able to finish lower bound rule mining for either of these two tests within 1,500 min Clearly CAR-mining and parameter tuning on large training sets is TABLE VII MEAN AcCU1ACIES FOR 


support pruning gene expression classifier with an accurate and compact fuzzy rule base for microarray data analysis Biosystems vol 85 computationally challenging As training set sizes increase it is likely that these difficulties will also increase VI RELATED WORK While operating on a microarray dataset current CAR 1 2 3 4 and other pattern/rule 20 21 mining algorithms perform a pruned and/or compacted exponential search over either the space of gene subsets or the space of sample subsets Hence they are generally quite computationally expensive for datasets containing many training samples or genes as the case may be BSTC is explicitly related to CAR-based classifiers but requires no expensive CAR mining BSTC is also related to decision tree-based classifiers such as random forest 19 and C4.5 family 9 methods It is possible to represent any consistent set of boolean association rules as a decision tree and vice versa However it is generally unclear how the trees generated by current tree-based classifiers are related to high confidence/support CARs which are known to be particularly useful for microarray data 1 2 6 7 11 BSTC is explicitly related to and motivated by CAR-based methods To the best of our knowledge there is no previous work on mining/classifying with BARs of the form we consider here Perhaps the work closest to utilizing 100 BARs is the TOPRULES 22 miner TOP-RULES utilizes a data partitioning technique to compactly report itemlgene subsets which are unique to each class set Ci Hence TOP-RULES discovers all 100 confident CARs in a dataset However the method must utilize an emerging pattern mining algorithm such as MBD-LLBORDER 23 and so generally isn't polynomial time Also related to our BAR-based techniques are recent methods which mine gene expression training data for sets of fuzzy rules 24 25 Once obtained fuzzy rules can be used for classification in a manner analogous to CARs However the resulting fuzzy classifiers don't appear to be as accurate as standard classification methods such as SVM 25 VII CONCLUSIONS AND FUTURE WORK To address the computational difficulties involved with preclassification CAR mining see Tables IV and VI we developed a novel method which considers a larger subset of CAR-related boolean association rules BARs These rules can be compactly captured in a Boolean Structure Table BST which can then be used to produce a BST classifier called BSTC Comparison to the current leading CAR classifier RCBT on several benchmark microarray datasets shows that BSTC is competitive with RCBT's accuracy while avoiding the exponential costs incurred by CAR mining see Section VB Hence BSTC extends generalized CAR based methods to larger datasets then previously practical Furthermore unlike other association rule-based classifiers BSTC easily generalizes to multi-class gene expression datasets BSTC's worst case per-query classification time is worse then CAR-based methods after all exponential time CAR mining is completed O SlS CGl versus O Si CGi As future work we plan on investigating techniques to decrease this cost by carefully culling BST exclusion lists ACKNOWLEDGM[ENTS We thank Anthony K.H Tung and Xin Xu for sending us their discretized microarray data files and Top-k/RCBT executables This research was supported in part by NSF grant DMS-0510203 NIH grant I-U54-DA021519-OlAf and by the Michigan Technology Tri-Corridor grant GR687 Any opinions findings and conclusions or recommendations expressed in this material are those of the authors and do not necessarily reflect the views of the funding agencies REFERENCES 1 G Cong K L Tan A K H Tung and X Xu Mining top-k covering rule Mining SDM 2002 5 R Agrawal T Imielinski and A Swami Mining associations between sets of items Y Ma Integrating classification and association rule mining KDD 1998 11 T McIntosh and S Chawla On discovery of maximal confident rules without pp 43-52 1999 24 S Vinterbo E Kim and L Ohno-Machado Small fuzzy and interpretable pp 165-176 2006 1071 pp 207-216 1993 6 G Dong pp 273-297 t995 9 pp 5-32 2001 20 W Li J R Quinlan Bagging boosting and c4.5 AAAI vol 1 V Vapnik Support-vector networks the best strategies for mining frequent closed itemsets KDD 2003 4 M Zaki and C Hsiao Charm L Wong Identifying good diagnostic genes or gene expression data SIGMOD 2005 2 G Cong A K H Tung X Xu F Pan and J Yang Farmer Finding interesting rule gene expression data by using the gene expression based classifiers BioiiiJcrmatics vol 21 l and Inrelligent Systenis IFIS 1993 16 Available at http://sdmc.i2r.a-star.edu.sg/rp 17 The dprep package http:/cran r-project org/doclpackages dprep pdfI 18 C Chang and C Lin Libsvm a library for support vector machines 2007 Online Available www.csie.ntu.edu.tw cjlin/papers/libsvm.pdf 19 L Breiimnan Random forests Maclh Learn vol 45 no 1 M Chen and H L Huang Interpretable X Zhang 7 J Li and pp 725-734 2002 8 C Cortes and Mac hine Learming vol 20 no 3 in microarray data SIGKDD Worikshop on Dtra Mining in Bioinfrrnatics BIOKDD 2005 12 R Agrawal and R Srikant Fast algorithms for mining association rules VLDB pp 1964-1970 2005 25 L Wong and J Li Caep Classification by aggregating emerging patterns Proc 2nd Iat Coif Discovery Scieice DS 1999 gene groups from pp 487-499 t994 13 Available ot http://www-personal umich edu/o markiwen 14 R Motwani and P Raghavan Randomized Algoriitlms Caim-bridge University Press 1995 15 S Sudarsky Fuzzy satisfiability Intl Conf on Industrial Fuzzy Contri J Han and J Pei Cmar Accurate and efficient classification based on multiple class-association rules ICDM 2001 21 F Rioult J F Boulicaut B Cremilleux and J Besson Using groups for groups in microarray datasets SIGMOD 2004 3 concept of emerging patterns BioinformJotics vol 18 transposition for pattern discovery from microarray data DMKD pp 73-79 2003 22 J Li X Zhang G Dong K Ramamohanarao and Q Sun Efficient mining of high confidence association rules without S Y Ho C H Hsieh H pp 725-730 1996 10 B Liu W Hsu and support thresholds Principles f Drata Mining aind Knowledge Discovery PKDD pp 406 411 1999 23 G Dong and J Li Efficient mining of emerging patterns discovering trends and differences KDD J Wang J Han and J Pei Closet Searching for An efficient algorithm for closed association rule mining Proc oJ the 2nd SIAM Int Con on Data in large databases SIGMOD 


