An FUSP-Tree Maintenance Algorit hm for Record Modification   Chun-Wei Lin 1 Tzung-Pei Hong 2,3 Wen-Hsiang Lu 1 and Hsin-Yi Chen 4  1 Department of CSIE, National Ch eng Kung University, Taiwan 2 Department of CSIE, National University of Kaohsiung, Taiwan  3 Department of CSE, National Sun Yat-sen University, Taiwan  4 Advanced Master Business Administrati on, National Cheng Kung University, Taiwan   p7895122, whlu, rd696404}@mail.ncku.edu.tw, tphong@nuk.edu.tw   Abstract  There are several algorithms proposed for maintaining the sequential patterns as records are inserted. In addition to record insertion, the pattern maintenance for record modification is also very important in the real-applications. In the past, we have proposed the fast updated sequential pattern tree called FUSP tree\ structure for handling record insertion. In this paper, we attempt to handle the maintenance of sequential patterns for record modification. We do the task by maintaining the FUSP tree and then generate the patterns whenever necessary. An FUSP-tree maintenance algorithm for record modification is thus proposed for reducing the execution time in reconstructing the tree. The proposed approach is expected to achieve a good trade-off between execution time and tree complexity  1. Introduction  Data mining involves in applying specific algorithms to extract patterns or rules from databases It may provide great help to decision making Therefore, mining useful information and helpful knowledge from large databases has evolved into an important research   3 Am o n g t h e m   finding sequential patterns from temporal transaction databases is important since it allows modeling of customer behavior in business Mining sequential patterns was proposed by Agrawal et al. in 1995 [4 d i s a n o n t r i v i a l t a sk It  attempts to find customer purchase sequences and to predict whether there is a high probability that when customers buy some products, they will buy some other products in later transactions. Transactions may be modified due to some reasons such as errors, so effectively and efficiently maintaining the mined sequential patterns when reco rds are modified becomes an important task. An intuitive approach is to re-mine the entire modified database to get correct sequential patterns. However, when the database is massive in size, this will require considerable computation time In the past, Lin and Lee proposed the FASTUP algorithm [10 to  m a i n tai n seq u e n tial p a tter n s. It  mainly extended the FUP algorithm for association rules T h e appr oach  w o rk ed w e ll e x cept w h e n  newly coming sequences are not frequent \(large\ the original database. If this occurs frequently, the database has to be often rescanned and the performance of the FASTUP algorithm will correspondingly decrease Han et al. proposed the Frequent-Pattern-tree \(FPtree\tructure for efficiently mining association rules without generation of candidate itemsets [7 T h e y  showed the approach could have a better performance than the Apriori approach. Hong et al. then modified the FP-tree structure and designed the fast updated frequent pattern trees \(FUFP-trees ef f i cie n tl y handle newly inserted transactions for maintaining association rules based on the FUP con  Hong et al. proposed the pre-large concept to reduce the need of rescanning original databases for maintaining sequential patterns [8 Ch en g et al. f u rt h e r proposed the IncSpan \(Incremental mining of sequential patterns\gorithm [6 o r ef ficien tl y  maintaining sequential patterns in a tree structure IncSpan, however, only handled appended transactions in which the customer number was fixed. Lin et al thus proposed the FUSP-tree structure and maintenance algorithm for efficiently handling both appended transactions and new customers T h e advantage of the approach was when frequent items were not changed, the approach didnít need to rescan the original database, but can get the results from the tree In this paper, we propose a maintenance algorithm based on the FUSP tree for efficiently handling modification of records. A fast updated frequent updated sequential pattern tree \(FUSP-tree\cture is used, which will make the tree update become easier When records are modified from the database, the proposed algorithm will process them to maintain the 
2008 IEEE International Conference on Data Mining Workshops 978-0-7695-3503-6/08 $25.00 © 2008 IEEE DOI 10.1109/ICDM.Workshops.2008.110 649 
2008 IEEE International Conference on Data Mining Workshops 978-0-7695-3503-6/08 $25.00 © 2008 IEEE DOI 10.1109/ICDMW.2008.81 649 


FUSP tree and the Header_Table. The proposed maintenance algorithm first partitions the items in modified transactions into four parts according to whether they are large or small in the original database and whether their item difference is positive or negative \(including zero\ch part is then processed in its own way. The proposed approach can achieve a trade-off between execution time and tree complexity This approach may be especially efficient for mining the traversal paths from the web log since only one item exists in a large itemset. The structure is especially useful for this situation   2. Review of Related Works  2.1. The Frequent Pattern Tree  The Frequent-Pattern-tree structure \(FP-tree\was proposed by Han et al. for efficiently mining association rules without generation of candidate itemsets h e FP t ree m i ning alg o rit h m cons is ts of two phases. The first phase focuses on constructing the FP-tree from the database, and the second phase focuses on deriving frequent patterns from the FP-tree Three steps are involved in FP-tree construction The database is first scanned to find all items with their frequency. The items with their supports larger than a predefined minimum support are selected as large 1itemsets \(items\ Next, the large items are sorted in descending frequency. At last, the database is scanned again to construct the FP-t ree according to the sorted order of large items. The construction process is executed tuple by tuple, from the first transaction to the last one. After all transactions are processed, the FPtree is completely constructed  2.2. The Fast Updated Sequential Pattern Tree  Hong et al. proposed the FUSP-tree structure and incremental algorithms for handling appended or newly inserted transactions T h e con cepts of th e FUSP tree extended from both the FUFP tree [9 d  the IncSpan  FUSP  tree is s h o w n i n Fi gu re 1 where only the frequent 1-sequences \(with only one item\ are kept. Like the IncSpan algorithm [5 e lin k  between two connected nodes is marked by the symbol s representing the sequence relation\ if the sequence is only within the sequence relation in a sequence otherwise, the link is marked by the symbol i which indicates the sequence is within the itemset relation in a sequence. The sequence IDs are also kept in the last node of the corresponding branch which helps update the tree structure efficiently. In addition to the FUSP tree, the Header_Table is also kept to help find appropriate items or sequences in the tree. It sorts the frequent 1-sequences initially in a descending order  root b: 7 c: 1 e: 1 a: 1 c1 s s i s e: 1 a: 1 i: 1 c9 s s s i: 1 a: 1 c6 s i c: 4 e: 3 c3, c5 e: 1 c8 s i i a: 1 s a: 1 c7 c: 1 e: 1 s i i: 1 c: 1 c4 s s i: 1 c2 s null null null null null null null null Header_Table Sequence Frequency b                   7 c                   7 e                   6 a                   5 i                    5 s i: 1 c s Figure 1: A FUSP tree   The construction process is executed tuple by tuple from the first customer sequence to the last one. After all the customer sequences are processed, the FUSP tree is completely constructed By taking the characteristics of the FUFP tree, the size of a customer sequence is reduced since only the frequent items are kept. It thus makes the FUSP tree compact. Besides, the complete customer sequences are kept in the FUSP tree to avoid and reduce rescanning the original database. When frequent items are not changed, the approach doesnít need to rescan the original database, but can get the results from the tree. After the tree is maintained, the final frequent sequences can then be found by a recursive method from the tree. This approach may be especially efficient for mining the traversal paths from the web log since only one item exists in a large itemset. The structure is especially useful for this situation  3. The Proposed FUSP-tree Maintenance Approach for Record Modification  Assume an FUSP tree has been built in advance from the original database. Considering an original database and some records to be modified, the following four cases in Figure 2 may arise, where the difference means the count difference of an item after and before the modification Since the 1-itemsets in Case 1 are large in the original database and have positive count difference they will still be large after the database is updated Similarly, the 1-itemsets in Case 4 will still be small after the records are modified. Thus, Cases 1 and 4 will not affect the final large 1-itemsets. The 1-itemsets in Case 2 are large in the original database and have negative \(or zero\nt difference. Some existing large 1-itemsets may be removed after the database is modified. It is easily decided since the counts of the 
650 
650 


original large 1-itemsets are kept in the Header_Table At last, the 1-itemsets in Case 3 are small in the original database and have positive count difference Some large items may thus be added. The original database must be rescanned for finding the original counts of these 1-itemsets Positive Original database Large 1-itemset Small 1-itemset Case 1 Case 2 Case 3          Case 4 Negative \(zero difference difference Original database 1-itemset difference  Figure 2 Four cases when records are modified from an existing database   The maintenance algorithm for record modification is described below  The proposed FUSP-tree maintenance algorithm for record modification INPUT: An old database which contains d customer sequences, its corresponding Header_Table which sorts the frequent 1-itemsets initially in a descending order, its corresponding FUSP tree, a support threshold S and a set of t  modified records OUTPUT: A new FUSP tree for the updated database STEP 1: Find all the 1-itemsets in the t modified records. Donate them as the set of modified 1itemsets M  STEP 2: Find the count difference \(including zero each 1-itemset in M for the modified records STEP 3: Divide the 1-itemsets from M into four parts according to whether they are large or small in the original database and whether their count differences are positive or negative STEP 4: For each 1-itemset I in M which has positive count difference and is large in the original database \(appearing in the Header_Table\, do the following substeps Case 1  Substep 4-1: Set the new count S U  I  I in the entire updated database as S U  I  S D  I  S M  I  where S D  I e count of I in the Header_Table \(original database\d S M  I e count difference of I after and before record modification Substep 4-2: Update the count of I in the Header_Table as S U  I  Substep 4-3 Put I in both the sets of Increase_Seqs and Decrease_ Seqs which will be further processed in STEP 7 STEP 5: For each 1-itemset I in M which has negative or zero\ount difference and is large in the original database \(appearing in the Header_Table\ do the following substeps  Case 2  Substep 5-1: Set the new count S U  I  I in the entire updated database as S U  I  S D  I  S M  I  Substep 5-2 If S U  I    d  Sup  I will be large after the database is updated Update the count of I in the Header_Table as S U  I and add I  to both the sets of Increase_Seqs and Decrease_ Seqs  Substep 5-3 If S U  I  d  Sup  I will become small after the database is updated; Remove I from the Header_Table, connect each parent node of I directly to the corresponding child node of I and remove I from the FUSP tree STEP 6: For each 1-itemset I in M which has positive count difference and is small in the original database \(not appearing in the Header_Table do the following substeps Case 3  Substep 6-1: Rescan the original database to calculate the count S D  I the 1itemset I in the original database before modification Substep 6-2: Set the new count S U  I  I in the entire updated database as S U  I  S D  I  S M  I  Substep 6-3 If S U  I    d  Sup  I will be large after the database is updated Add the 1-itemset I in both the sets of Increase_Seqs and Rescan_Seqs  STEP 7: For an updated record before modification with an item J existing in the set of Decrease_Seqs find the corresponding branch of J in the FUSP tree for the record and subtract 1 from the count of the J node in the branch; if the count of the J node becomes zero after subtraction, remove node J from its corresponding branch and connect the parent node of J directly to the child node of J  STEP 8: Sort the 1-itemsets in the Rescan_Seqs in a decreasing order of their updated counts 
651 
651 


STEP 9: Insert the 1-itemsets in the Rescan_Seqs to the end of the Header_Table according to the descending order of their counts STEP 10: For each record in the unmodified records with a 1-itemset J existing in Rescan_Seqs if J has not been at the corresponding branch of the FUSP tree, insert J at the end of the branch and set its count as 1; Otherwise, add 1 to the count of the node J  STEP 11: For the updated records after modification with a 1-itemset J existing in the Increase_Seqs if J has not been at the corresponding branch of the FUSP tree, insert J at the end of the branch and set its counts as 1; Otherwise, add 1 to the count of the J node  Note that in STEP 7, a corresponding branch is the branch generated based on the frequent itemsets from a transaction and corresponding to the order of itemsets in the databases. After STEP 11, the final updated FUSP tree is formed by the maintenance algorithm for record modification. Based on the FUSP tree, the desired large sequences for the updated database can be determined by a recursive mining procedure, which is similar but much more complex than those proposed in    4. An Example  In this session, an example is given to illustrate the proposed algorithm for maintaining an FUSP tree when the records are modified. Table 1 shows a database to be used in the example. The database contains 10 transactions and 9 items, denoted a to i   Table 1   The original customer sequences  Cust_ID Customer sequences 1 a   bi   2 ac   ei   3 ac   df   4 b   cd   e   5 a   b   e   f   6 ac   i   7 a   b   d   ef   8 ac   e   fg   9 b   d   g   10 de   g   h    Assume the support threshold is set at 50%. The FUSP tree is then formed from the original customer sequences and the Header_Table. The results are shown in Figure 3   root b: 3 s a: 7 s c: 4 i e: 2 s d: 1 s b: 2 s c: 1 s d: 1 i e: 1 s e: 1 s d: 1 s e: 1 s d: 1 s d: 1 s e: 1 i null null null null null null null Header_Table 1-itemset Frequency a                        7 e                        6 b                        5 c                        5 d                        5  Figure 3 The Header_Table and the FUSP tree constructed   Assume the last three records \(with IDs 8 to 10\ in the original database are modified as shown in Table 2  Table 2 The three records after modification  Cust_ID Customer sequences 8 ac   e   f   9 bc   fg   i   10 ac   fg    The count difference of each 1-itemset in the modified records is calculated as shown in Table 3  Table 3 The count difference of each 1-itemset in M  1-itemset Count a 1 b 0 c 2 d 2 e 1 f 2 g 1 h 0 i 1  All the items in M are divided into four cases and are then processed in four individual ways. The final results are shown in Figure 4  5. Conclusions  In this paper, the maintenance algorithm for record modification is proposed to efficiently and effectively maintain the sequential patterns. A FUSP-tree structure is used to make the tree update process become easier  
652 
652 


Header_Table 1-itemset Frequency a                        8 e                        5 b                        5 c                        7 f                        6 root b: 3 s a: 8 s c: 5 i e: 2 s b: 2 s c: 1 s e: 1 s e: 2 s null null null null null c: 1 i f: 1 s f: 2 s f: 1 s f: 1 i Figure 4 The final result   When the records are modified, the proposed maintenance algorithm first partitions the 1-itemsets in the modified records into four parts according to whether they are large or small in the original database and have positive or negative count \(or zero\ difference Each part is then processed in its own way. The Header_Table and the FUSP tree are correspondingly updated whenever necessary. The obtained tree complexity may not be optimal because the frequency order of items may not be kept. The effect is expected small since large count difference seldom happens when the amount of modified records is not large. The execution time of the proposed approach can, however be greatly improved. The proposed approach can thus achieve a good trade-off between execution time and tree complexity  6. References  1 R. A g r a w a l T  I m ie link s i a n d A  Swa m i M ining  association rules between sets of items in large database The ACM SIGMOD Conference pp. 207-216 Washington DC, USA, 1993 2 R. A g ra w a l, T  I m ie link s i a n d A  Sw a m i D a t a b a s e  mining: a performance perspective IEEE Transactions on Knowledge and Data Engineering Vol. 5, No. 6, pp 914-925, 1993 3 R. A g ra wa l a nd R Srik a n t   F a s t a l g o rithm f o r m i ning  association rules The International Conference on Very Large Data Bases pp. 487-499, 1994 4 R. A g r a w a l a nd R. Srik a n t M in ing se que ntia l pa tte r n s  The Eleventh IEEE International Conference on Data Engineering pp. 3-14, 1995  D W  Ch eun g  J Han  V  T   Ng an d C Y W o n g   Maintenance of discovered association rules in large databases: An incremental updating approach The Twelfth IEEE International Conference on Data Engineering pp. 106-114, 1996  H Ch en g  X  Yan an d J Han  In c S p an  i n crem en t a l  mining of sequential patterns in large database The ACM SIGKDD international conference on Knowledge discovery and data mining pp.527-532, 2004 7  J  H a n, J  P e i a n d Y  Y i n M ining f r e que nt pa tte r n s  without candidate generation The 2000 ACM SIGMOD International Conference on Management of Data pp. 112, 2000 8  T  P  H ong C  Y  W a ng a nd S S. T s e n g   I nc r e m e nta l  data mining for sequential patterns using pre-large sequences The International Multiconference on Systemics, Cybernetics and Informatics Vol. 14, pp. 543548, 2001 9  T  P  H ong C  W  L i n a n d Y   L  W u  I nc r e m e nta l l y  fast updated frequent pattern trees Expert Systems with Applications Vol. 34, Issue 5, pp. 2424-2435, 2008 10  M. Y  L i n a nd S. Y  L e e   I nc r e m e nta l up da te on  sequential patterns in large databases The Tenth IEEE International Conference on Tools with Artificial Intelligence pp. 24-31, 1998  11  C  W  L i n, T   P  H o ng W e nH s ia ng L u a nd W e nY a ng  Lin, ìAn Incremental FUSP-Tree Maintenance Algorithm The Eighth International Conference on Intelligent System  Design and Application 2008  
653 
653 


1  Br e a s t h e a l t h   h t t p    w w w  b r e a s t h e a l t h  c o m  a u   statisticsresearch/index.html  Accessed on 12 August 2008 2  Co o k e   D    O r d o n e z  C   E r n e s t  V   G a r c i a   E   Omiecinski Elyzabeth Krawczynska Russell Folks Cesar Santana, Levien de Braal, and N. Ezquerra. Data  mining of large myocardial perfusion SPECT MPS databases to improve diagnostic decision making S.H Lee J.E and Park J.S Analysis on risk factors for cervical cancer using induction technique Expert Systems with Applications, 27\(1\.  2004, 97-105 6  V i n n a k o t a  S   a n d  L a m   N  S  N   S o c i o e c o n o m i c  inequality of cancer mortality in the United States  a spatial data mining approach Int J Health Geogr 2006,  5- 9 7  W i k i p e d i a   h t t p    e n  w i k i p e d i a  o r g  w i k i   Bladder_cancer Accessed 20 August 2008 8  Ca n c e r  o r g   h t t p    w w w  c a n c e r  o r g  d o c r o o t  CRI/content/CRI_2_4_1X_What_are_the_key_statisti cs_for_bladder_cancer_44.asp Accessed, 20 August 2008 9  H e r z o g   T  J   N e w  a p p r o a c h e s  f o r  t h e  m a n a g e m e n t  of cervical cancer   2003 S22\226S27 17  We therefore concluded a rule for each cancer dataset and summarized as below All the rules were shown highest confidence We found the breast and prostate cancer rules are very simple Whereas rest of the rules contained several significant risk factors to predict an appropriate cancer  Relation:   bladder  Rule work_esposure 307 work_leather_industry 307 work_rubber_industry 307 work_cable_industry 307 work_printing_industry 001 bladder_cancer  Relation:   breast  Rule  gender female 307  age\(>40 307  family_history 001 breast_cancer  Relation:   cervical  Rule  poor_hygienic_practices 307  low_socioeconomic_status 307  low_vegetables 307  sexually_transmitted_infections,smoking 001  cervical_cancer  Relation:    lung  Rule  chemical_exposure 307  smoking 307  previous_lung_disease 307  urban_residence 307  family_history 001 cervical_cancer  Relation:  prostrate  Rule family_history 307 age \(>50 001  prostrate_cancer  Relation:   skin  Rule weak_immune_system 307 fragile_skin 307  exposure_to_environmental_hazards 307  previous_skin_cancer 001 skin_cancer  All the generated rules demonstrated high confidence Thus we conclude that these rules are highly acceptable Comparatively breast and prostrate cancer showed shorter rules comparing other cancer This research argues to consider more risk factors to be considered in the experimental dataset for both breast and prostate cancer to extract most significant risk factors   6.0 Conclusions  This study has demonstrated the use of association rule mining to identify some specific risk factors for a particular cancer problem In this research we employed three types of association rule mining algorithms to extract significant risk factor for a specific cancer Finally we suggested in our research to use Apriori algorithm for such type of task All the generated rules were showing highest confidence level in our experiment  We aim to extend this research by considering more risk factors in the raw data-set for each cancer problem in order for association rule mining algorithm to extract more useful and significant risk factors for a particular type of cancer   References  Gynecologic Oncology 90  1999, 38\22649 4  P e n d h a r k a r   P  C   J  A   Ro d g e r   G  J   Y a v e r b a u m   N  Herman and M Benner Association statistical mathematical and neural approaches for mining breat  cancer patterns 40\(5\, 1999 3  O r d o n e z   C   a n d  O m i e c i n s k i   E   D i s c o v e r i n g  association rules based on image content In Expert Systems with Applications   1999, 223\226232 5  H o   S  H    J e e    th th Journal of Nuclear Medicine IEEE Advances in Digital Libraries Conference ADL\22299 


 Kluwer Academic Publishers Springer, New York 1st edition, 2001 14  S c h e f f e r   T   F i n d i n g  A s s o c i a t i o n  Ru l e s  t h a t  T r a de Support Optimally Against Confidence th The Elements of Statistical Learning self_care_guide/Urogenital/Postate%20Cancer.pdf  Accessed, 25 August, 2008 11  A g r a w a l   R  T   I m i e l i n s k i     A   S w a m i   M i n i n g  association rules between sets of items in large databases, In Proceedings of the 1993 ACM SIGMOD international conference on Management of data  The Netherlands 42 2001 61-95  Ordonez C Association rule discovery with the train and test approach for heart disease predictio n 207\226 216 12 001 13  H a s t i e   T    R  T i b s h i r a n i     J  H   F r i e d m a n   Proceedings of the 5th European Conference on Principles and Practice of Knowlege Discovery in Databases\(PKDD'01 IEEE Transactions on Information Technology in Biomedicine, 10\(2\, 2006. 334 \226 343 001 Freiburg, Germany : SpringerVerlag, 2001. 424-435 15  F l a c h   P  A     L a c h i c h e   N   Co n f i r m a t i o n g u i d e d  discovery of first-order rules with Tertius 10  P h a r m a c y   h t t p    w w w  p h a r m a c y  g o v  m y    


 7. Conclusions  In this paper we have proposed an intelligent and efficient technique to reassess the distances between dynamic XML documents when one or all of the initially clustered documents have changed. After the changes, the initial clustering solution might become obsolete - the distances between clustered XML documents might have changed more or less depending on the degree of modifications \(insert update, delete\hich have been applied. Re-running full pair-wise comparisons on the entire set of modified documents is not a viable option, because of the large number of redundant operations involved Our proposed technique allows the user to reassess the pair-wise XML document distances, not by fully comparing each new pair of versions in the clustering solution, but by determining the effect of the temporal changes on the previously known distances between them. This approach is both time and I/O effective, as the number of operations involved in distance reassessing is greatly reduced  References  1  Beringer, J. and H\374llermeier, E., Online clustering of parallel data streams Data and Knowledge Engineering 58\(2\,  2006, 180-204 2  Catania, B. and Maddalena A., A Clustering Approach for XML Linked Documents, Proceedings of the 13th International Workshop on Database and Expert Systems Applications \(DEXA\22202\, IEEE 2002 3  Chen, M.S., Han, J. and Yu, P., Data Mining: An Overview from Database Perspective, IEEE Transactions on Knowledge and Data Engineering vol. 8, 1996, 866-883 4  Cormen, T., Leiserson, C. and Rivest, R Introduction to algorithms, MIT Press, 1990 5  Costa, G., Manco, G., Ortale, R. and Tagarelli, A., A tree-based Approach to Clustering XML documents by Structure, PAKDD 2004, LNAI 3202, 137-148 Springer 2004 6  Dalamagas, T., Cheng, T., Winkel, K.J. and Sellis, T 2004, Clustering XML documents by Structure SETN 2004, LNAI 3025, 112-121, Springer 2004 7  Ester, M., Kriegel, H.P., Sander, J., Wimmer,M. and Xu, X., Incremental Clustering for Mining in a Data Warehousing Environment, Proc.of the 24 th VLDB Conference, New York, USA, 1998 8  Garofalakis, M., Rastogi, R., Seshadri, S. And Shim K., Data Mining and the Web: Past, Present and Future Proceedings of WIDM 99 Kansas, US, ACM 1999 9  Mignet, L., Barbosa, D. and Veltri, P., The XML web : a first study, In Proceedings of the 12 th  International Conference on WWW, 500-510 2003   Nayak, R., Xu, S., XCLS: A Fast and Effective Clustering Algorithm for Heterogeneous XML Documents, In Proceedings of the 10 th Pacific-Asia Conference on Advances in Knowledge Discovery and Data Mining, Singapore, LNCS 3918, 2006   Rusu, L.I., Rahayu, W. and Taniar, D., A methodology for Building XML Data Warehouses International Journal of Data warehousing Mining, 1\(2 67-92, 2005   Rusu, L.I., Rahayu, W. and Taniar D.,  Maintaining Versions of Dynamic XML Documents, In Proceedings of the 6th International Conference on Web Information Systems Engineering, New York NY, USA, November 20-22, 2005, LNCS 3806   Rusu, L.I., Rahayu, W. and Taniar, D., Warehousing Dynamic XML Documents, In Proceedings of the 8 th  International Conference on Data Warehousing and Knowledge Discovery \(DaWaK 2006 LNCS 4081 Springer, 175-184, 2006   Shen, Y. and Wang, B., Clustering Schemaless XML documents, CoopIS / DOA/ODBASE 2003, LNCS 2888, 767-784, Springer 2003   Yoon, J. P., Raghavan, V., Chakilam, V., and Kerschberg, L., BitCube: A Three-Dimensional Bitmap Indexing for XML Documents J. Intel. Inf Syst 17, 2-3 \(Dec. 2001\, 241-254   XML data repository, online at http www.cs.washington.edu / research / projects / xmltk xmldata  
456 
456 


5 Related Work There exists extensive previous work on both the mining of software repositories and on the use of clustering algorithms in software engineering This discussion focuses on the most similar and recent work in the area of software evolution Mining Software Repositories Our technique was partially inspired by the work of Zimmermann et al and Y ing et al 17 on the mining of association rules in change history As described in Section 1 we sought to expand the technique to be able to recommend larger but less precise clusters of elements to guide program navigation Bouktif et al also investigated how to recommend cochanges in software development As opposed to the work cited above Bouktif et al used change patterns instead of association rules Also their approach does not attempt to reconstruct transactions and can consider associated 002les that were changed in different transactions ChangeDistiller is a tool to classify changes in a transaction into 002ne-grained operations e.g addition of a method declaration and determines how strongly the change impacts other source code entities Our approach uses similar repository analysis techniques but is focused on providing task-related information as opposed to an overall assessment of a system's evolution Finally repository mining can also be used to detect aspects in the code In this conte xt aspects are recurring sets of changed elements that exhibit a regular structure Aspects differ from the clusters we detect in the regular structure they exhibit which may not necessarily align with the code that is investigated as part of change tasks Clustering Analysis The classical application of clustering for reverse engineering involves grouping software entities based on an analysis of various relations between pairs of entities of a given version of the system Despite its long and rich history  e xperimentation with this approach continues to this day For example Andreopoulos et al combined static and dynamic information K uhn et al used a te xtual similarity measure as the clustering relation and Christl et al used clustering to assist iterative semi-automated reverse engineering The main dif ferences b e tween most clusteringbased reverse engineering techniques and the subject of our investigation is that the entities we cluster are transactions rather than software entities in a single version of a system For this reason our analysis is based strictly on the evolving parts of the system Both Kothari et al and V an ya et al 15 recently reported on their use of clustering to study the evolution of software systems The idea of using change clusters is the same in both works and ours but the purpose of the work is different Kothari et al use change clusters to uncover the types of changes that happened e.g feature addition maintenance etc during the history of a software system Vanya et al use change clusters which they call evolutionary clusters to guide the partitioning of a system that would increase the likelihood that the parts of the system would evolve independently In contrast we cluster transactions based on overlapping elements not 002les to recommend clusters to support program navigation as opposed to architectural-level assessment of the system Finally Hassan and Holt evaluated on 002ve open source systems the performance of several methods to indicate elements that should be modi\002ed together This study found that using historical co-change information as opposed to using simple static analysis or code layout offered the best results in terms of recall and precision The authors then tried to improve the results using 002ltering heuristics and found that keeping only the most frequently cochanged entities yielded the best results As opposed to our approach the evaluated 002ltering heuristics were only applied on entities recovered using association rules and not using clustering techniques The focus of their study was also more speci\002c as they recommend program elements that were strictly changed  as opposed to recommending elements that might be inspected by developers 6 Conclusion Developers often need to discover code that has been navigated in the past We investigated to what extent we can bene\002t from change clusters to guide program navigation We de\002ned change clusters as groups of elements that were part of transactions or change sets that had elements in common Our analysis of close to 12 years of software change data for a total of seven different open-source systems revealed that less than 12 of the changes we studied could have bene\002ted from change clusters We conclude that further efforts should thus focus on maximizing the quality of the match between the current task and past transactions rather than 002nding many potential matches Our study has already helped us in this goal by providing reliable evidence of the effectiveness of some 002ltering heuristics and useful insights for the development of additional heuristics Acknowledgments The authors thank Emily Hill and Jos  e Correa for their advice on the statistical tests and the anonymous reviewers for their helpful suggestions This work was supported by NSERC 
25 
25 
25 
25 
25 


References  B Andreopoulos A An V  Tzerpos and X W ang Multiple layer clustering of large software systems In Proc 12th Working Conf on Reverse Engineering  pages 79ñ88 2005  S Bouktif Y G Gu  eh  eneuc and G Antoniol Extracting change-patterns from cvs repositories In Proc 13th Working Conf on Reverse Engineering  pages 221ñ230 2006  S Breu and T  Zimmermann Mining aspects from v ersion history In Proc 21st IEEE/ACM Int'l Conf on Automated Software Engineering  pages 221ñ230 2006  A Christl R K oschk e and M.-A Store y  Equipping the re\003exion method with automated clustering In Proc 12th Working Conf on Reverse Engineering  pages 89ñ98 2005  D 020 Cubrani  c G C Murphy J Singer and K S Booth Hipikat A project memory for software development IEEE Transactions on Software Engineering  31\(6 465 2005  B Fluri and H C Gall Classifyi ng change types for qualifying change couplings In Proc 14th IEEE Int'l Conf on Program Comprehension  pages 35ñ45 2006  A E Hassan and R C Holt Replaying de v elopment history to assess the effectiveness of change propagation tools Empirical Software Engineering  11\(3 2006  D H Hutchens and V  R Basili System s tructure analysis Clustering with data bindings IEEE Transactions on Software Engineering  11\(8 1985  D Janzen and K De V older Na vig ating and querying code without getting lost In Proc 2nd Int'l Conf on AspectOriented Software Development  pages 178ñ187 2003  J K ot hari T  Denton A Shok ouf andeh S Mancoridis and A E Hassan Studying the evolution of software systems using change clusters In Proc 14th IEEE Int'l Conf on Program Comprehension  pages 46ñ55 2006  A K uhn S Ducasse and T  G  021rba Enriching reverse engineering with semantic clustering In Proc 12th Working Conf on Reverse Engineering  pages 133ñ142 2005  M P  Robillard T opology analysis of softw are dependencies ACM Transactions on Software Engineering and Methodology  2008 To appear  M P  Robillard and P  Mangg ala Reusing program in v estigation knowledge for code understanding In Proc 16th IEEE Int'l Conf on Program Comprehension  pages 202 211 2008  J Sillito G Murph y  and K De V older Questions programmers ask during software evolution tasks In Proc 14th ACM SIGSOFT Int'l Symposium on the Foundations of Software Engineering  pages 23ñ34 2006  A V an ya L Ho\003and S Klusener  P  v an de Laar and H van Vliet Assessing software archives with evolutionary clusters In Proc 16th IEEE Int'l Conf on Program Comprehension  pages 192ñ201 2008  N W ilde and M C Scully  Softw are reconnaissance Mapping program features to code Software Maintenance Research and Practice  7:49ñ62 1995  A T  Y ing G C Murph y  R Ng and M C Chu-Carroll Predicting source code changes by mining change history IEEE Transactions on Software Engineering  30\(9 586 2004  A Zeller  The future of programming en vironments Integration synergy and assistance In Proceedings of the 29th International Conference on Software Engineering The Future of Software Engineering  pages 316ñ325 2007  T  Zimmermann and P  W eiﬂgerber  Preprocessing C VS data for 002ne-grained analysis In Proc 1st Int'l Workshop on Mining Software Repositories  pages 2ñ6 May 2004  T  Zimmermann P  W eiﬂgerber  S Diehl and A Zeller  Mining version histories to guide software changes In Proc 26th ACM/IEEE Int'l Conf on Software Engineering  pages 563ñ572 2004 A Clustering Algorithm This algorithm is not sensitive to whether a given program element exists or not in a given version of a program For example if method m exists in one version it is considered a valid program element even if it is removed in a later version In the rest of this section we use the term program element to refer to the uniquely identifying representation of the element e.g a Java fully-quali\002ed name Let T be a transaction modeled as a set of program elements changed together during the history of a software system Let T be a sequence of transactions In this algorithm a cluster is also modeled as a set of elements 1 Input  T  A sequence of transactions 2 Parameter  M IN O VERLAP  A positive non-zero value indicating the minimum overlap between two transactions in a cluster 3 Var  C  A set of clusters initially empty 4 for all T i 2 T do 5 MaxOverlap  0 6 MaxIndex  000 1 7 for all C j 2 C do 8 if j C j  T i j  MaxOverlap then 9 MaxOverlap  j C j  T i j 10 MaxIndex  j 11 end if 12 end for 13 if MaxIndex   0  MaxOverlap 025 M IN O VERLAP  then 14 C MaxIndex   C MaxIndex  T i  15 else 16 NewCluster  T i 17 C  C  f NewCluster g 18 end if 19 end for 20 return C B Systems Analyzed System home pages last veri\002ed 7 May 2008 Ant ant.apache.org Azureus azureus.sourceforge.net Hibernate www.hibernate.org JDT-Core www.eclipse.org/jdt/core JDT-UI www.eclipse.org/jdt/ui Spring springframework.org Xerces xerces.apache.org 
26 
26 
26 
26 
26 


