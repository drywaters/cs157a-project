Prediction and Early Warning Method for Flea Beetle Based on Semi-supervised Learning Algorithm  Ting Li 1 Jingfeng Yang 2 Xiaoqin Peng 3 Zhimin Chen 2 Chengyang Luo 4  1 Zhongshan Torch Polytechnic, Zhongshan, China  528436 2 South China Agricultural University, Guangzhou, China, 510642 3 Tianfu College of Southwestern University of Finance and Economics, Mianyang, China, 621000 4 Chung Tak Lighting Control Systems \(Guangzhou\ Ltd., Guangzhou, China, 511400 E-mail 002 li.tingzi@163.com  H T U yangvive@126.com U T H       Corresponding author. Email: zhiminchen@126.com  Abstract  The  prediction and early warning for vegetable crop diseases and insect pests commonly based on experts knowledge of plant protection while math modeling methods are used to analyze the associated data quantitatively scarcely. This paper takes advantage of labeled historical data to extract association rules as the supervised information, and combining with the use of the unsupervised learning method iterative self- organizing data analysis techniques algorithm \(ISODATA\ to establish the model semi-supervised learning algorithm for predicting and early warning vegetable pest flea beetle. Semi-supervised learning algorithm not only obtains a high accuracy of supervised learning method but also takes advantage of the flexibility of unsupervised learning method, which is si gnificative for both research and practice. The experimental results of Guangdong vegetable pest flea beetle show the prediction and early warning accuracy of semi-supervised learning method provides a higher accuracy rate than that of k-mean clustering, support vector machine and RBF neural network in the same condition Key words: Prediction and Early Warning; Flea Beetle Semi-supervised Learning; Association Rules; ISODATA  1. Introduction  In recent years, infection area of crop diseases and insect pests spread larger and larger, as well as the serious generation degree, which caused enormous economic losses to the peasants. The irrational use of chemical pesticides has caused a series of environmental and social issues that are difficult to resolve and avoid such as agricultural costs rising, declining quality, and environmental polluti  Therefore, effective prediction and early warning for crop diseases and insect pests is necessary, and it would provide the dependable basis for prevention and treatme nt at the same time. At present, computer information technology and GIS technology for crop diseases and insect pests prediction and early warning developed ra pidly, Hao and Chen used technology to establish a prediction GIS for pests of wheat in 1995; Wang etc desi gned and built GIS database for analyzing the Chilo suppressalis population spatiotemporal dynamics in  Li u et c devel oped wheat  and corn integrated pest control GIS in 2002 based on GIS technology, artificial in telligence technology plant protection knowledge,  occurrence regularity of crop diseases and insect pests, meteorological information. It could provide service including prediction, decisionmaking and consultation. Zhejiang agricultural expert system is jointly developed and designed by Chinese Academy of Sciences and Hangzhou Academy of Agricultural Sciences in 2005, including the information of fruits, vegetables and othe r crops in the diagnosis and treatment of crop diseases and insect pests The key technology of crop diseases and insect pest prediction system is prediction model and prediction algorithm. Various prediction algorithm proposed by researchers, Li and Peng developed a model for the classified prediction of ag ricultural crop diseases and insect pests using BP artificial neural network with factors related to agricultura l plant diseases and insect pests as input features of sample  Zhang and Zhu put  forward the idea of producing fuzzy rules by genetic algorithms based on Takagi-Sugeno Fuzzy Logic System and established the fuzzy model to forecast diseases and pests   Hu et c devel oped a B P neural net w ork prediction system concerning plant diseases and pests and the prediction system was used to predict the severity of wheat stripe rust in Hanzhong,Shaanxi provi   Xiong etc proposed a hybrid neural network based on parametric feed forward neural networks with fuzzy inputs configured by a genetic algorithm \(PFNNFG   Ren and Li improved and adjusted model of genetic programming based on traditional fitness function 
Fourth International Conference on Natural Computation 978-0-7695-3304-9/08 $25.00 © 2008 IEEE DOI 217 
Fourth International Conference on Natural Computation 978-0-7695-3304-9/08 $25.00 © 2008 IEEE DOI 217 
Fourth International Conference on Natural Computation 978-0-7695-3304-9/08 $25.00 © 2008 IEEE DOI 10.1109/ICNC.2008.371 217 
Fourth International Conference on Natural Computation 978-0-7695-3304-9/08 $25.00 © 2008 IEEE DOI 10.1109/ICNC.2008.371 217 


performance of accuracy in pest forecasting is improved by the algorithm   Previous prediction systems and the application of the algorithm have achieved certain effect. Growth cycle in different insect pests and crop diseases, morbidity in different characteristics, different pests and diseases should establish their own prediction model. However, in the past all kinds of crop diseases and insect pests prediction and early warning systems often use the same algorithm and model, which limits the accuracy of the prediction. Combining association rules with ISODATA vegetable crop diseases and insect pests of flea beetle early warning model is established in this paper, which has been the accession to the model-based early warning WebGIS crops biological disasters monitoring and early warning system  2. Fuzzy association rules  Apriori algorithm is one of most influential and classical algorithm that mine s Boolean association rules and frequent itemset However, t h i s associ at i on rules are single-dimension and single-layer Boolean association rules, the generation of which bases on such a reality: each item in the transaction is independent and simultaneous. Nevertheless, there exists such a case frequently: in one transaction, some items are independent, but some can not occur simultaneously. The case is relevant to multidimensional association rules mining, which is applied to extract classification association rules in the following text. Multidimensional association rules involve multi-attribute or multipredication rules. In mining process, different attributes in the same transaction is independent, and each value or range belonging to the same attribute must emerge, but not simultaneously If the form of multidimensional association rule is conditionset=>y, where conditionset denotes itemset, and y denotes class label, then this association rule is defined as classification association ru le. The attribute in database might be categorical attribute or quantitative attribute. If there are quantitative attributes in data samples, it is necessary to discretize the data samples. In nature, the classification association rules including quantitative attributes is fuzzy classi fication association rules Supposing an attribute set 12     n I II I  and a fuzzy transaction database 12    m DDD D  the discovered rules are of the form AB where 1  i Dim  is a transaction of D   A IB I    AB   and AB  do not contain any two items that are associated with the same attribute. The minimal Support and the minimal Confidence of fuzzy classification association rules could be defi    1   Support \(A B n i Ax By D    1   Confidence \(A B  n i Ax By Ax     Where D is the total number of transactions in D  which is equal m the number of transactions in the quantitative database D   Ax and  B y denote the degree of membership of the element x and y with respect to the fuzzy set A and B respectively  is a tnorm   3. ISODATA clustering algorithm  Iterative Self Organizing Data Analysis Techniques Algorithm\(ISODATA\atically agglomerate and divide the classes of the samples, then the reasonable number of the classes would be got through the process The calculation steps are Step 1: Giving n samples set 1 J  iterative times select c initial clustering centers  j Z J  1 2 jc   Step2: Calculate the distan ce between each sample with the clustering centers   kj Dx Z J If 1,2     min      1 2  kj kj jc DxZJ DxZJ k n   then ki x w  all the samples are compartmentalized into c sets, and j n denotes the number of samples for the subsets j X  Step 3:  If jn n    1 2 jc  then eliminate the subset j X 1 cc  calculate the distance again through the method in Step 2, where n  is the minimum number of samples of each cluster, if number of samples less than it that will not be able to be an independent cluster Step 4:  Calculate the ad justed clustering centers  1 1  j n j jk k j Z Jx n    1 2 jc   Calculate the mean distance j D between cluster centers 
218 
218 
218 
218 


  1 1  j n j jkj k j DDxZJ n   1 2 jc   Calculate the mean distance D among the samples of clusters 1 1 c jj j DnD n  012  Step 5: Distinguish agglomerative, divisive and iterative calculation If iterative calculation of the total number has reached I or the last iteration, set 0 c   go to Step 7, then end computing, where I is the maximum number of iterations c  is minimum distance between the two clustering centers, if less than it, agglomerate the two clusters If 2 cK  then go to Step 6, and divide the clustering centers, where K is the expected number of cluster centers Step 6: Divisive process Calculate standard devia tion vector of each sets 12     T jjj jd     The components 2 1  j ji i ji xX j x ZJ n     1 2 id   1 2 j c   where i x denotes the i th component of x  ji Z denotes the i th component of j Z  d is the dimension number Find largest standard deviation of the component max j   max 1,2 max   jji id     1 2 jc   If max jc   then divide the clustering center into two new clustering centers   jjj Z JZJr      jjj Z JZJr    Where jj rk   or max 0 0  0 T jj rk    01 k  Set 1 cc   1 JJ  go to Step 2 Step 7: Agglomerative process Calculate the distance ij D between every two clustering centers   ij i j DDZJZJ   1 2 1 ic   1 j ic   Compare ij D with c  sort ij D in ascending order by the distance of clustering centers less than c   11 2 2  i j i j iLjL DD D  where L denotes largest agglomerative number of cluster There are two homologous clustering centers iL Z and jL Z every iLjL D belongs to.  The agglomerative clustering center can be obtained by 1     LiLiLjLjL iL jL Z JnZJnZJ nn 012+\012   Set 1 cc   If JI  then 1 JJ   If parameters is needed to adjusting the, go to Step 1, if not, go to Step 2  4. Semi-supervised learning algorithm  The two categories algorithms of pattern classification are mainly supervised learning and unsupervised learning Training samples needed to be labeled in supervised learning algorithm. Supervised learning algorithm structures the optimal model so as to get the minimum error between the known knowledge. It's a process optimization with the single exact goal and high accuracy Supervised learning algorithms couldn't operate without training samples or labels. Unsupervised learning algorithms haven't got precise targets, in the condition of the samples without labeled, it could find out the significative model in accordan ce with the characteristics of their own targets, but accur acy is relatively low. Semisupervised learning method combines the virtue of supervised learning and unsupervised learning algorithms It can be flexible learni ng, and enhance accuracy under certain condition. Flea beetle prediction and early warning model is constructed by semi-supervised learning method based on the supervised learning information from association rules combining with unsupervised learning method ISODATA Specifically, flea beetle samples are provided with a number of different data attributes, homologous 
219 
219 
219 
219 


 Table 1 Vegetable pest in th e main classification criteria early warning classi fication I II III IV V number of insects per 100 vegetable 0-100 100-200 200-500 500-1000 1000  Table 2 Results of prediction and early warning samp les from 2007.1 to 2008.2 of flea beetle under different algorithms Algorithms Quantity of predicted and early warned accurately Accuracy rate of predicted and early warned accurately Support Vector Machine \(SVM 427 67.56 k-mean clustering 328 51.90 RBF Neural Network 381 60.28 Semi-supervised Learning Algorithm 483 76.42 multidimensional eigenvector which performs for a point at coordinates system. The shorter the distance between points eigenvector performs for, the corresponding model will be more similar, and the feasibility of corresponding model belong to the same class will be much more likely In a densely distributed region, the models are similar and then the same class could be formed by the polymerization. Set the points with labels mined by association rules as cluste ring centers, agglomerate or divide the association ru les by ISODATA, and then calculate the distance between unlabeled samples with agglomerative or divisive centers. Unlabeled samples with minimum distance to agglomerative or divisive centers will be labeled the same class. Assume the flea beetle pest databases of all the samples are independent and each is a subset of samples the calculation steps are as follows Step 1: Select a period of time of flea beetle as a training samples as the training samples, excavated association rules as the initial clustering centers Step 2: Agglomerate or divide the association rules by ISODATA, the new clustering centers are got Step 3: Compare with the clustering centers, find out the minimum distance. The warn ing class of unlabeled samples categorize to the corresponding clustering center  5. Experiment and result analysis 5.1 Experimental data  The data mainly from Guangdong Province vegetables crop diseases and insect pests flea beetle database According to Guangdong Province's climate and crop growth characteristics, five factors including types of vegetables, the growth phase of vegetables, the growth phase of flea beetle, and the weather conditions is selected. Flea beetle database contains data from 2004.1 to 2008.2, a total of 2,356 records. The data from 2004.1 to 2006.12 contains a total of 1,724 records. The data from 2007.1 to 2008.2 contains a total of 632 records  According to the "Vegetab le pests in the main  fl ea beetle prediction and early warning classification standards is shown as Table 1  5.2 Experiment result  Select the data from 2004 to 2006 as training samples of 1,724 records, 1, 2007 to February 29, 2008 record of 632 samples as prediction and early warning samples. In order to compare with the general supervised learning methods and unsupervised learning methods, Table 2 lists flea beetle results of the prediction and early warning using Support Vector Machine \(SVM k-mean clustering algorithms and RBF Neural Network.  In the second row of Table 2, "Quantity of predicted and early warned accurately" denotes the quantity of prediction and early warning samples from 2007.1 to 2008.2 of flea beetle data that predicted and early warned accurately Accuracy rate of predicted and early warned accurately denotes the accuracy rate of prediction and early warning samples from 2007.1 to 2008.2 of flea beetle data that predicted and early warned accurately. For instance while selecting algorithm is SVM, 433 prediction and early warning samples from 2007.1 to 2008.2 of flea beetle data predicted and early warned accurately, take 68.51% accuracy rate of total quantity As shown in Table 2, when the algorithms are Support Vector Machine \(SVM k-mean clustering, RBF Neural Network, 67.56%, 51.90%, 60.28%, accuracy rate of prediction and early warning samples from 2007.1 to 2008.2 of flea beetle data that predicted and early warned accurately, while 76.42% accuracy rate could be obtained by the Semi-supervised Learning Algorithm, which provided a higher precision w ith the accuracy improved by 8.86%, 24.52% and 16.14% in comparison with the results in the same condition. A satisfactory prediction and early warning accuracy c ould be obtained by semisupervised learning algorithm 
220 
220 
220 
220 


 Conclusion  This paper presents a semi-supervised learning algorithm based on the supervised learning information from association rules combining with unsupervised learning method ISODATA in prediction and early warning for flea beetle Semi-supervised learning algorithm takes advantage of virtue of supervised learning with high accuracy rate and unsupervised learning needn't training samples, according to past data successful predicted and early warned for vegetable crop diseases and insect pest flea beetle Semi-supervised learning algorithm can effectively improve the accuracy and effi ciency of prediction and early warning for vegetable crop diseases and insect pest flea beetle. Prediction and ear ly warning for flea beetle commonly depends on the knowledge of plant protection expert in previous. This paper constructed mathematical methods to establish prediction and early warning model have made certain signifi cance and a high accuracy for prediction and early warning Semi-supervised learning algorithm is effective, but the use of plant protection expert knowledge is also lacking In fact, the influential fact ors of the flea beetle number includes environmental factors, such as soil, but the quantitative research of flea beetle breeding environment is still in the rough, whose data including survival reproduction, and other environmental data of flea beetle is one of the research direc tion of the future research  Acknowledgements Project supported by the South China Agricultural University Principal Foundation Projects, China \(No 2007K017  References    Sun Hu. The St udy on B i ocont rol t o W h eat Takeall Disease and Resistance Assessment of Wheat Cultivars. Henan Agricultural University Master's degree thesis, 2004   W a ng Zhengjun, C h eng Ji aan, Li Di anm o  Desi gn and building of GIS database for Chilo suppressalis. Acta Entomologica Sinica, 2001, 44\(4\525-533    Li Zuoy ong, Peng Li hong. Predi c t i on m odel of agricultural plant diseases and insect pests based on artificial neural network and its verification.1999 19\(5\759-761   Zhang Ji anbi ng, Zhu Yepi ng. Di seases and pest  insects forecast by fuzzy rules. System Sciemces and Comprehensive Studies In Agriculture, 2000, 16\(4\283285   Hu Xi aopi ng Li ang C h enghua, Yang Zhi w ei et al  Development and application of the BP neural network prediction system on plantdiseases and pests. Journal of Northwest Sci-Tech University of Agriculture and Forestry, 2001 29\(2\73-76    Xi ong Xuem ei Ji C h angy i ng, C l audi o M o raga Parametric Fuzzy Neural Network Based on Genetic Algorithm Configured for Plant Disease Prediction Transactions of The Chines e Society of Agricultural Machinery, 2004, 35 \(6\110-114   R e n C hunfeng, Li M i ao. St udy  of fi t n ess funct i on in pest forecasting base d on genetic programming Computer Engineering and Applications, 2007 43\(6\197-243   Jiawei Han, Micheline Kam b er. Data Mining Concepts and Techniques. Morgan Kaufmann Pblishers.2001   B a o-Yi W a ng, Shao-M i n Zhang A M i ni ng Algorithm for Fuzzy Weighted Association Rules Proceedings of the Second International Conference on Machine Learning and Cybernetics. 2003, 11:2495-2499   Mohammadreza Kangavari Sattar Hashemi. Effect of Similar Behaving Attributes in Mining of Fuzzy Association Rules in the Large Databases. Lecture Notes in Computer Science, 2006 3980:1100-1109    R u an D.,Kerre E.E.. Fuzzy i m pl i cat i on operat o rs and generalized fuzzy method of cases. Fuzzy Sets and systems, 1993,54\(1\23-38   Veget a bl e pest s i n t h e m a i n cl assi fi cat i on criteria .2006, November, second edition  
221 
221 
221 
221 


  Proceedings of the Sev e nth Inter n ational Conference on Ma c h ine Lear ning and Cyber n etics  K u nming, 12-15 J u ly 2008          In fi g u re 1, t h e y ax is represen ts t h e tim e spen t in  readi ng i n a bat c h of st r e am const r uc t i ng i t s l o cal  DSC F C I t ree  up dat i n g t h e gl o b al DSC F C I-t ree  an d pr o duci n g f r e que nt cl o s ed i t e m s et s sati sfy i ng i t e m  constraints B The y axis i n figure 2 re presents the  me m o ry capacity used for storing the gl obal  DSCFCI-tree As ca n be see n fr om t h e t w o f i gu res whe n t h e val u e of s u pp o r t   i s fi xe d, t h e t i m e and space re qui rem e nt s of t h e algorithm grow as th e stream progre sses, but tend to sta b ilize. For e x am ple, the m e m o ry re qui red by the  global DSC F CI-tree with su ppo r t 0  00 15  in cr eases relativ ely q u i ck ly as th e first sev e n  b a tch e s o f st ream arriv e and tend s to stab ilize at ro ugh ly 3  8MB with sm a l l  bum ps. T h is is because the num b er of pote ntial fre que nt clo s ed item s e t s satisfyin g ite m co n s trai n t s g o es up  relativ ely q u i ck ly at first, and b e co m e s relativ ely stead y  later th ro ugh in tr odu cing p r un ing tech no log y Th e stab ility resu lts are qu ite n i ce as th ey p r o v id e ev id en ce th at th e algorith m can  h a n d l e lon g  d a ta strea m s. As t h e v a lu e o f suppo r t   dec r eases the e x ecution tim e in fig u re 1 a n d t h e m e m o ry requi red by  DS CFCI-tree in  figure 2 inc r ea ses quickly  This is because t h ere are m o re p ot ent i a l  f r e que nt cl ose d i t e m s et s sati sfy i ng i t e m  const r ai nt s wi t h sl ower support    s s Fi gu re 1 an d F i gu re 2 sh o w t h e e x peri m e nt al res u l t s  o f  d a ta sets T1 5I7 D 1 000k  Th e ex per i m e n t al r e su lts of  o t h e rs two d a ta sets are sim ilar to th ese fig u r es                           Fig u re 3 shows th e av erag e t i m e sp en t i n  up d a ting  t h e gl obal DS C F C I-t ree o n c e  with three dif f eren t ite m con s t r ai nt s c onst r ai nt  0 n o c onst r ai nt s co nst r ai nt  1  co nst r ai nt 2   e  can dra w a c o nclusi on that w ith t h e reinforcem en t o f th e constraints 222  degree the num b er of fre que nt close d  ite m s ets satis fyin g co rrespo nd ing item co n s t r ain t s d ecreases, and th e tim e sp en t i n  up d a ti ng  th e g l o b a l DSCFCI-tree dec r eases t o o. M o re ove r  the space  requirem ent of t h e global DSCFCI-tree go es d o wn  sim u l t a neousl y The r ef ore  i n t e g r at i ng i t e m const r ai nt s in to t h e m i n i n g algorith m can  reduce t h e e x ecution tim e  and space com p lexity of the algorithm    4 3   2 1  005 005 005 5.   Concl u si ons In this pa per   we propose a n ef ficient algorith m for m i ni ng fre q u e n t cl ose d i t e m s et s i n dat a st ream s. The co n t r i bu tio n s of ou r stud y in clu d e 1 pro posin g a no v e l  dat a  st r u ct ure  DSC F C I t re e, fo r st ori n g pot e n t i a l   fre que nt cl ose d i t e m s et s, and de vel o pi n g  a new m e t hod  for increm ental updating DSCFCI-t ree ef ficiently 2 appl y i n g a  pr u n i n g t e c hni que f o r ef fi ci ent  p r u n i n g gl obal  DSCFCI-tree  to reduce the s p ace re quire m e nt of t h e  DSCFCI-tree an d th e tim e sp en t in trav ersi n g the DSCFCI-tree dram atica l l y 3  teg r ating ite m con s t r ai nt s i n t o t h e m i ni ng a l go ri t h m and t hus  red u ci n g  furthe r t h e e x ecution tim e and sp ace co m p lex ity of th e const r ai nt 0 S=0.001 T ime\(s S=0.0015  const r ai nt 1 const r ai nt 2 S=0.002  N umber of data stream segments Fi gu re 3 c o m p ari s on of e x ecut i o n  t i m e wi t h di f f erent const r ai nt s\(s=0.0015 Figure 2.The m e m o ry usage of DSCFCI-tree   279 005 004 005 4 3 2 1 


  Proceedings of the Sev e nth Inter n ational Conference on Ma c h ine Lear ning and Cyber n etics  K u nming, 12-15 J u ly 2008  al gori t h m   Our performance st udy shows  that DSCFCI  algorithm is ef ficient and ef fective  Refer e nces 1] C Gia nnel l a, J Ha n, J  Pei, et al. Mi ning fre quent p a ttern s i n  d a t a stream s at mu ltip le tim e g r an u l arities  G]. In  H Kar g up ta, A Jo sh i, K Siv a ku m a r  et al, ed s Next  Ge nerat i on Dat a M i ni ng C a m b ri dg e, M a ss  M I T Press, 2003  2 G S Mank u, R Mo t w an i. App r ox im a t e f r e q u e n c y cou n t s ove r st ream i ng dat a  C    The 28 th Int 222 l Confere n ce on V e ry Lar g e Data Bases \(VL D B 2002 HongKong, 2002 3  Aras u A M a nk u G S  A p pr oxi m a t e co unt s a n d  q u a n tiles ov er slid in g wi n d o w s. In Pro c eed ing s  o f  th e 23 rd ACM S I G M OD SI G AC T S I G A R T  Sym posi u m on Pri n ci pl es o f  Dat a base Sy st e m s. Pari s France  AC M Press, 2004 4 Datar M, Gio n i s A, In d y k P   Mo t w an i  R. Main tain in g str eam stat is tics o v e r slid in g  w i ndow s In  Proceedi ngs of the 13 th A nnu al ACMSIA M  Sy m p o s iu m on  Discrete Al g o rith m s San Fran cisco   USA  AC M Press, 2002 5 N Pas quier  Y Bastide  R T a ouil, et al Discoveri n g freq u e n t clo s ed item s e t s fo r asso ciatio n ru les[C]. In   Beeri C, et al, eds  Proc of the 17 th I n t 222 l Co nf  on Dat a base Theory B e rl i n  Spri nger V e rl ag, 1999  6  W a n g Jian yon g. Clo s et sear ch ing fo r t h e b e st st rat e gi es f o r m i ni ng f r e que nt cl ose d i t e m s et s. In  Pr oc. N i n t h A C M SIGK DD In t\222 1 Co nf  on  K now ledg e D i scov er y an d  D a t a Min i n g  W a shi ngt on,DC Aug.2003    280 


association mining The Likelihood Ratio Test fails to extract features also belonging to common vocabulary and it makes the extraction dependent on the feature position in the sentence leading to low recall The dBNP and bBNP based methods yield low recall due to the fact that the product features do not occur with the article the in front of them very often The Association Mining approach returns all frequent nouns which decreases precision Our results suggest that the choice of algorithm to use depends on the targeted dataset If it consists of mainly on-topic content the results of Table 10 indicate that the Association Mining algorithm is better suited for this task due to its high recall If the dataset consists of a mixture of onand off-topic content our results suggest that the Likelihood Ratio Test based algorithm would perform better due to its ability to distinguish and 002lter out the off-topic features For future work we plan to extend the Likelihood Ratio Test methods especially the dBNP based approach by other determiners such as a or this  which should increase the recall of this method Another possibility which we will investigate regards the BNP patterns The current Likelihood Ratio Test approach is not capable of dealing with discontinuous feature phrases for example in 5 the quality of the pictures is great the feature would be picture quality  This problem could be addressed by introducing wildcards in the BNP patterns We will also investigate whether there are any methods in order to calculate an optimal threshold for the candidate feature extraction in order to increase the recall of the Likelihood Ratio Test based algorithm We plan to investigate whether a deeper linguistic analysis e.g with a dependency parser can improve the feature extraction Acknowledgements The project was funded by means of the German Federal Ministry of Economy and Technology under the promotional reference 01MQ07012 The authors take the responsibility for the contents The information in this document is proprietary to the following Theseus Texo consortium members Technische Universit  at Darmstadt The information in this document is provided as is and no guarantee or warranty is given that the information is 002t for any particular purpose The above referenced consortium members shall have no liability for damages of any kind including without limitation direct special indirect or consequential damages that may result from the use of these materials subject to any liability which is mandatory due to applicable law Copyright 2008 by Technische Universit  at Darmstadt References  R Agra w al and R Srikant F ast algorithms for mining association rules Proc 20th Int Conf Very Large Data Bases VLDB  1215:487–499 1994  K Bloom N Gar g and S Ar g amon Extracting a ppraisal expressions In HLT-NAACL 2007  pages 308–315 2007  R Bruce and J W iebe Recognizing subjecti vity a case study in manual tagging Natural Language Engineering  5\(02 1999  K Da v e S La wrence and D Pennock Mi ning the peanut gallery opinion extraction and semantic classi\002cation of product reviews In Proceedings of the 12th International Conference on World Wide Web  pages 519–528 New York NY USA 2003 ACM  T  Dunning Accurate methods for the statistics of surprise and coincidence Computational Linguistics  19\(1 1993  O Feiguina and G Lapalme Query-based summ arization of customer reviews In Canadian Conference on AI  pages 452–463 2007  C Fellbaum Wordnet An Electronic Lexical Database  MIT Press 1998  A Ferraresi Building a v ery lar ge corpus of english obtained by web crawling ukwac Master's thesis University of Bologna Italy 2007  M Gamon A Aue S Corston-Oli v er  and E Ringger  Pulse Mining customer opinions from free text In Proceedings of the 6th International Symposium on Intelligent Data Analysis IDA-2006  Springer-Verlag 2005  N Glance M Hurst K Nig am M Sie gler  R Stockton and T Tomokiyo Deriving marketing intelligence from online discussion In Proceedings of the 11th ACM SIGKDD International Conference on Knowledge Discovery in Data Mining  pages 419–428 New York USA 2005 ACM  M Hu and B Liu Mining opinion features in customer reviews In Proceedings of 9th National Conference on Arti\002cial Intelligence  2004  N K obayashi K Inui K T atei shi and T  Fukushima Collecting evaluative expressions for opinion extraction In Proceedings of IJCNLP 2004  pages 596–605 2004  S Morinag a K Y amanishi K T ateishi and T  Fukushima Mining product reputations on the Web In Proceedings of KDD-02 8th ACM International Conference on Knowledge Discovery and Data Mining  pages 341–349 Edmonton CA 2002 ACM Press  A.-M Popescu and O Etzioni Extracting product features and opinions from reviews In Proceedings of HLT-EMNLP-05 the Human Language Technology Conference/Conference on Empirical Methods in Natural Language Processing  pages 339–346 Vancouver CA 2005  H Schmid T reetagger a language independent part-ofspeech tagger Institut fur Maschinelle Sprachverarbeitung Universitat Stuttgart  1995  J W iebe R Bruce and T  O'Hara De v elopment and use of a gold-standard data set for subjectivity classi\002cations In Proceedings of the 37th annual meeting of the Association for Computational Linguistics on Computational Linguistics  pages 246–253 Association for Computational Linguistics Morristown NJ USA 1999  J Y i T  Nasuka w a R Bunescu and W  Niblack Sentiment analyzer Extracting sentiments about a given topic using natural language processing techniques In Proceeding of ICDM-03 the 3ird IEEE International Conference on Data Mining  pages 427–434 Melbourne US 2003 IEEE Computer Society 
160 
151 


Figure 4 Expected and real number of extracted patterns using two promoter sequence datasets Horizontal axis minimum support vertical axis number of patterns 
85 
85 


a frequency constraint and according to the structure of the dataset These proposals are all based on a global analytical model i.e an interesting approach that needs however to develop complex and speci\036c models As a result they cannot be easily extended to handle complex conjunctions of constraints to incorporate different symbol distributions or different semantics for pattern occurrences To the best of our knowledge no method has been proposed to estimate the number of patterns satisfying a constraint while avoiding to develop a global analytical model Our approach requires only to know how to compute for a given pattern its probability to satisfy the constraint this can be obtained in many situations and it remains ef\036cient in practice by adopting a pattern space sampling scheme 6 Conclusion Using constraints to specify subjective interestingness issues and to support actionable pattern discovery has become popular Constraint-based mining techniques are now well studied for many pattern domains but one of the bottlenecks for using them within Knowledge Discovery processes is the extraction parameter tuning This is especially true in the context of differential mining where domain knowledge is used to provide different datasets to support the search of truly interesting patterns From a user perspective a simple approach would be to get graphics that depict the extraction landscape i.e the number of extracted patterns for many points in the parameter space We developed an ef\036cient technique based on pattern space sampling that provides an estimate on the number of extracted patterns This has been applied to non trivial substring pattern mining tasks and we demonstrated by means of many experiments that the technique is effective It provides reasonable estimates given execution times that enable to probe a large number of points in the parameter space Notice that domain knowledge is also exploited here when selecting the distribution model Future directions of work include to adapt the approach to other pattern domains and to different constraints Another interesting aspect to investigate is the use of more sophisticated sampling schemes e.g that could b e incorporated in the approach when more complex syntactical constraints are handled e.g a grammar to specify the shape of the patterns Acknowledgments This work is partly funded by EU contract IQ FP6-516169 Inductive Queries for Mining Patterns and Models and by the French contract ANR-MDCO14 Bingo2 Knowledge Discovery For and By Inductive Queries We thank Dr Olivier Gandrillon from the Center for Molecular and Cellular Genetics CNRS UMR 5534 who provided the DNA promoter sequences References  J F  Boulicaut L De Raedt and H  M annila e ditors Constraint-Based Mining and Inductive Databases  volume 3848 of LNCS  Springer 2005  C  B resson C K e ime C F a ure Y  Letrillard M  B arbado S San\036lippo N Benhra O Gandrillon and S GoninGiraud Large-scale analysis by SAGE revealed new mechanisms of v-erba oncogene action BMC Genomics  8\(390 2007  L  C ao and C  Z hang Domain-dri v e n actionable kno wledge discovery in the real world In Proceedings PAKDDÕ06 volume 3918 of LNCS  pages 821–830 Springer 2006  G  D ong and J  L i Ef 036cient mining of emer ging patterns discovering trends and differences In Proceedings ACM SIGKDDÕ99  pages 43–52 1999  F  Geerts B  G oethals and J  V  d en Bussche T ight upper bounds on the number of candidate patterns ACM Trans on Database Systems  30\(2 2005  U  K eich and P  A  P e vzner  S ubtle motifs de\036ning the limits of motif 036nding algorithms Bioinformatics  18\(10 2002  S  K ramer  L De Raedt and C  Helma M olecular f eature mining in HIV data In Proceedings KDDÕ01  pages 136 143 2001  L  L hote F  Rioult and A  S oulet A v e rage number of frequent closed patterns in bernouilli and markovian databases In Proceedings IEEE ICDMÕ05  pages 713–716 2005  I  M itasiunaite a nd J.-F  B oulicaut Looking for monotonicity properties of a similarity constraint on sequences In Proceedings of ACM SACÕ06 Data Mining  pages 546–552 2006  I Mitasiunaite and J F  Boulicaut Introducing s oftness i nto inductive queries on string databases In Databases and Information Systems IV  pages 117–132 IOS Press 2007  I Mitasiunaite C Rigotti S Schicklin L  M e yniel J F  Boulicaut and O Gandrillon Extracting signature motifs from promoter sets of differentially expressed genes Technical report LIRIS CNRS UMR 5205 INSA Lyon France 2008 23 pages Submitted  G Ramesh W  M aniatty  a nd M J Zaki F easible itemset distributions in data mining theory and application In Proceedings ACM PODSÕ03  pages 284–295 2003  F  Zelezn  y Ef\036cient sampling in relational feature spaces In Proceedings ILPÕ05  volume 3625 of LNCS  pages 397 413 Springer 2005 
86 
86 


