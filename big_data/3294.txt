Intelligent Structuring of Association Rules in Data Structure Yan Wang Yuxia Lei Baoxiang Cao College of Computer Science QuFu Normal University Rizhao 276826 Shandong yx lei@126.com Abstract With the rapid development of society more and more universities are applying Intelligence Tutor System ITS As we know that the discovery of associate rules plays a very important role in a ITS In the paper we present a method for structuring associate rules among knowledge points in Data Structure which is based on Formal Concept Analysis FCA considered an important Arti\002cial Intelligence AI theory A teacher together with his  her students 002rst translates some related knowledge in Data Structure into a binary context and then the procedure can automatically generate a corresponding concept lattice from which many interesting associate rules with 100  con\002dence can be extracted The concept lattice and the associate rules provide the students with a vivid knowledge view which can make the students more easily understand the inherent connections among knowledge By using the method we obtained a well teaching quality 1 Introduction Intelligence Tutor System\(ITS is one of successful applications of Arti\002cial intelligence Nowadays more and more universities are applying the ITS to the teaching activities of some courses such as Data Structure Data Structure is of fundamental important in the 002eld of computer science as every area in computer science depends heavily on some kinds of methods for processing all kinds of data types Therefore most of colleges related to computer science are instructing this course One of the core tasks of teaching activities is to make the students more easily understand the knowledge and to improve the teaching quality Rules among knowledge points are exactly a valid tool for this task as they can provide the students with a research en In addition the disco v ery of associate rules plays a very important role in a ITS In the paper we present a method for structuring associate rules among knowledge points in Data Structure which is based on the theory of FCA FCA is a valid formal tool for data analysis and has already been applied to various 002elds such as Intelligent Tutor System\(ITS wledge interconnection  rules acquisition 5 In order to take advantage of the theory of FCA in the teaching activities we 002rstly must redescribe the knowledge in books in terms of the language of FCA Therefore our method mainly consists of two steps In the 002rst step we translate the knowledge into a binary context In the second step we obtain the corresponding concept lattice from which many associate rules with 100 con\002dence can be extracted In the paper we focus on the second step as the associate rules unfold some inherent connections among knowledge points For example the current rule  8 x  Act  Reverse  x   Act  S ize  x  means that if any instance x of some data type can be described by  Reverse  the same must be true for  S ize  The remainder of this paper is as follows Section 2 brie\003y introduces the notions of FCA Section 3 discusses how to intelligently extract associate rules in detail 2 Basic notions of formal concept analysis The following is a brief presentation of the theory of formal concept analysis FCA Details may be found in the Wille's book which provides an extensive introduction to FCA A binary context R is a triple  G  M  I   where G and M are sets and I is a binary relation The elements of G and M are called the objects and the attributes  respectively For an object g and an attribute a   g  a  2 I means that g has the attribute a  A small context can be easily represented by a cross table\(see 002gure 1 i.e by a rectangular table the rows of which are headed by the object names and the columns headed by the attribute names A cross in row g and column m means that the object g has the attribute m  A formal concept of such a context is a pair consisting of a set of objects the extent and a set of attributes the intent such that the intent consists of exactly those attributes that the objects in the extent have in common and the extent consists of exactly those objects that share all the attributes in the intent 
2008 International Symposium on Computational Intelligence and Design 978-0-7695-3311-7/08 $25.00 © 2008 IEEE DOI 10.1109/ISCID.2008.137 211 
2008 International Symposium on Computational Intelligence and Design 978-0-7695-3311-7/08 $25.00 © 2008 IEEE DOI 10.1109/ISCID.2008.137 211 


Formally a formal concept of a context  G  M  I  is de\002ned as a pair  X  Y  with X 022 G and Y 022 M such that  X  Y  is maximal with the X 002 Y 022 I  namely 013  X   Y and 014  Y   X  where 013  X   f a 2 M  8 r 2 X  r  a  2 I g and 014  Y   f r 2 G  8 a 2 Y  r  a  2 I  g  The hierarchical order of the concepts is formalized by  X 1  Y 1  026  X 2  Y 2   X 1 022 X 2   Y 2 022 Y 1  The set of all concepts of a context R together with the order 026 is always a complete lattice called the concept lattice of R and denoted by L  R  Table 1 A simple binary context student male female evenage oddage tall dedium short r 1    r 2    r 3    r 4    Table 1 consists of four student as its objects described by seven attributes such as male evenage and short The symbol    in row r 1 and column male means that the student r 1 is male h H H H H H H H H         h hh hh h hh h h         H H H H H H H H J J J J         J J J J            H H H H H H H H H H H l l l l l l            T T T T T r 1 r 3 r 4 r 2 male shortoddage evenage female tall medium Figure 1 The concept lattice of Table 1 Figure 1 visualizes the concept lattice of Table 1 by a line diagram  In the line diagram of its concept lattice the name of an object g is always attached to the circle representing the smallest concept with g in its extent dually the name of an attribute a is always attached to the circle representing the largest concept with a in its intent This allows us to read the map I from the diagram because an object g has an attribute a if and only if there is an ascending path from the circle labeled by g to the circle labeled by a  The extent of a concept consists of all objects whose labels are below in the diagram and the intent consists of all attributes attached to concepts above in the hierarchy For example the concept labeled by the attribute male has f r 1  r 3 g as extent and f male g as intent the concept labeled by the student r 4 has f r 4 g as extent and f female,evenage,short g as intent 3 Intelligent structuring of association rules In this section we present a method for extracting associate rules from knowledge points in detail Our method consists of two steps The 002rs is to translate some relevant knowledge points in Data Structure into a binary context and the second is to obtain the corresponding concept lattice and extract associate rules from the concept lattice We mainly discuss the second step Firstly we present two concept lattice construction algorithms F or a small context  G  M  I  we can use the 002rst algorithm to generate the corresponding concept lattice Algorithm 1 Input  a small context R  G,M,I where M  f m 1      m N g Output  the all concepts L  R  of R 1 T  G  003 T is a set of extents 003  2 For i  1 to n DO 3 For any T in T 4 T  T T 014  m i  5 L  R   f  T  013  T   T 2 T g The algorithm for the determination of concepts described above becomes awkward for larger contexts Therefore we can use the following theorem 1 namely algorithm 2 For simplicity we replace the 002nite set G consisting of n objects by the f 1  2      n g  Theorem 1  The small concept extent larger than a given set X 032 G is X 010 i  where i is the largest element of G with X 014 i X 010 i and X 010 i   014\013  X T f 1  2      i 000 1 g  S f i g  and X 014 i X 010 i  i 2  X 010 i 000 X  and X T f 1  2      i 000 1 g   X 010 i  T f 1  2      i 000 1 g  By using the above algorithms we can obtain a corresponding concept lattice L  R  of a context R   G  M  I  From the concept lattice we can extract some interesting rules The basic idea is as follows In L  R  if there is an ascending path from the circle labeled by a 1 to the circle labeled by a 2  then we can know that if an object g has the attribute a 1 the same is true for the attribute a 2  denoted by the following rule 8 g 2 G  g  a 1  2 I   g  a 2  2 I  In order to avoid the redundance we only consider such ascending paths with no other circles in them Because the  is transitive For example if there are the two rules 8 g 2 G  g  a 1  2 I   g  a 2  2 I  and 8 g 2 G  g  a 2  2 I   g  a 3  2 I  then we can obtain the rule 8 g 2 G  g  a 1  2 I   g  a 3  2 I  In addition we can extract such rules with existential quanti\002er For instance if there does not exist an ascending path from the circle labeled by a 1 to the circle labeled by a 2  then we can know that there must exist an object g which has the attribute a 1 but does not have the attribute a 2  denoted by the following rule 9 g 2 G  g  a 1  2 I   g  a 2   I  In order to illustrate our idea we take the following 
212 
212 


knowledge points in Data Structure into account We redescribe an example described in the paper Specifically we regard the six kinds of data types and the ten actions  operations as objects and attributes respectively that is G  f Set List Bag Map Tree and Relation g and M  f Reverse Size MemberOf Head Tail ElementAt NumOfOccur RemoveDups Root,and Leaves g  and de\002ne the binary I as a predicate Act  g  a  which is said to be true if and only if the action m 2 M applies to the instances of type g 2 G  and then we get a context as shown in Table 2 The corresponding concept lattice is shown in Figure 2 Table 2 A context about data types Reverse Size MemberOf Head Tail ElementAt NumOfOccur RemoveDups Root Leaves Set   List         Bag     Map   Tree      Relation   h h h h hh h h         H H H H H H H H J J J J          J J J J J      J J J J J J J J J J J J J J J J       Bag List T ree S et  Map Relation Size MemberOf NumOfOccur RemoveDups Reverse Head Tail ElementAt Root Leaves Figure 2 The concept lattice of Table 2 From the concept lattice in Figure 2 we can extract the following rules which either contains universal quanti\002er or contain existential quanti\002er The rules with universal quanti\002er are listed as follows 1 8 x  Act  RemoveDups  x   Act  S ize  x  2 8 x  Act  RemoveDups  x   Act  MemberO f  x  3 8 x  Act  NumO f Occur  x   Act  S ize  x  4 8 x  Act  NumO f Occur  x   Act  MemberO f  x  5 8 x  Act  Reverse  x   Act  S ize  x  6 8 x  Act  Reverse  x   Act  MemberO f  x  7 8 x  Act  ElementAt  x   Act  Reverse  x  8 8 x  Act  ElementAt  x   Act  NumO f Occur  x  9 8 x  Act  ElementAt  x   Act  RemoveDups  x  10 8 x  Act  T ail  x   Act  NumO f Occur  x  11 8 x  Act  T ail  x   Act  RemoveDups  x  12 8 x  Act  T ail  x   Act  Reverse  x  13 8 x  Act  Head  x   Act  NumO f Occur  x  14 8 x  Act  Head  x   Act  RemoveDups  x  15 8 x  Act  Head  x   Act  Reverse  x  16 8 x  Act  Leaves  x   Act  Reverse  x  17 8 x  Act  Root  x   Act  Reverse  x  These rules unfold the inherent connections among knowledge points in a 002xed context For instance rule 1 means that if the action RemoveDups can be applied to any instance x of a data type the same is true for the action S ize  These rules can be generalized the following rules 1 8 x  Act  NumO f Occur  x  _ App  RemoveDups  x   Act  S ize  x   Act  MemberO f  x  2 8 x  Act  Reverse  x   Act  MemberO f  x   Act  S ize  x  3 8 x  Act  ElementAt  x  _ Act  T ail  x  _ Act  Head  x    Act  NumO f Occur  x   Act  RemoveDups  x   Act  Reverse  x  4 8 x  Act  Leaves  x  _ Act  Root  x   Act  Reverse  x  The rules containing the 021 are listed as follows 1 8 x  Act  Head  x  021 Act  T ail  x  2 8 x  Act  Root  x  021 Act  Leaves  x  3 8 x  Act  NumO f Occur  x  021 Act  RemoveDups  x  4 8 x  Act  ElementAt  x  021 Act  T ail  x  5 8 x  Act  S ize  x  021 Act  MemberO f  x  The rules with existential quanti\002er are listed as follows 1 9 x  Act  S ize  x    Act  NumO f Occur  x  2 9 x  Act  MemberO f  x    Act  NumO f Occur  x  3 9 x  Act  S ize  x    Act  RemoveDups  x  4 9 x  Act  MemberO f  x    Act  RemoveDups  x  5 9 x  Act  S ize  x    Act  Reverse  x  6 9 x  Act  MemberO f  x    Act  Reverse  x  7 9 x  Act  NumO f Occur  x    Act  ElementAt  x  8 9 x  Act  NumO f Occur  x    Act  T ail  x  9 9 x  Act  NumO f Occur  x    Act  Head  x  10 9 x  Act  NumO f Occur  x    Act  Leaves  x  11 9 x  Act  NumO f Occur  x    Act  Root  x  12 9 x  Act  RemoveDups  x    Act  ElementAt  x  13 9 x  Act  RemoveDups  x    Act  T ail  x  14 9 x  Act  RemoveDups  x    Act  Head  x  15 9 x  Act  RemoveDups  x    Act  Leaves  x  16 9 x  Act  RemoveDups  x    Act  Root  x  17 9 x  Act  Reverse  x    Act  ElementAt  x  18 9 x  Act  Reverse  x    Act  T ail  x  19 9 x  Act  Reverse  x    Act  Head  x  20 9 x  Act  Reverse  x    Act  Leaves  x  21 9 x  Act  Reverse  x    Act  Root  x  
213 
213 


22 9 x  Act  Reverse  x    Act  NumO f Occur  x  23 9 x  Act  Reverse  x    Act  RemoveDups  x  24 9 x  Act  Leaves  x    Act  ElementAt  x  25 9 x  Act  Leaves  x    Act  T ail  x  26 9 x  Act  Leaves  x    Act  Head  x  The above rules explicitly represent the interesting connections among some revelent knowledge points in Data Structure When learning the course Data Structure the students can make full use of these rules Thus they can more easily understand the knowledge 4 Teaching quality analysis In order to verify the method we have preformed several experiments on three classes in College of Computer and Science In each class we arbitrarily chose the scores of 002fty students and computed their average score on each knowledge point Thus we can obtain the corresponding score rate on each knowledge point By contracting to the history analysis results we can 002nd that we obtained a more well teaching quality as shown in Table 3 Table 3 Teaching Quality Analysis\(Partly knowledge mass knowledge point score rate lined list stacks 96 queues 95 sort algorithm selection sort 98 insertion sort 96 bottom-up merge sorting 97 merge sort 96 quick sort 89 graph depth-\002rst search 96 backtracking 94 breadth-\002rst search 97 Dijkstra algorithm 86 Floyed algorithm 82 tree binary tree 98 rooted tree 96 Kruskai's algorithm 94 Prim's algorithm 91 5 Conclusion In this paper we mainly discuss how to apply the theory of FCA to our teaching schemes for instructing the course Data Structure Our idea is as follows we 002rstly translate some related knowledge points into a binary context and then extract the corresponding concept lattice of this context and last extract some interesting rules either with 8 or with 9  which can be used by the students to help them more easily understand the tuitionary knowledge in class These rules extracted from concept lattice have 100 con\002dence By using the method a teacher or together with his  her students should 002rstly accurately translate the related knowledge points into a binary context and rules acquisition can be automatically accomplish Therefore our method has nicer maneuverability Currently we have apply the theory of FCA to two courses such as Arti\002cial Intelligence and Data Structure Contract to traditional teaching methods the method has a more well teaching quality Acknowledgement This work is supported by Foundation of Teaching Reformation of Higher Education No.B05042 of ShanDong Province References  R Lindsay R Breen A Jenkins Academic Research and Teaching Quality the views of undergraduate and postgraduate students Studies in Higher Education Vol.27\(No.3 pp.309-27 2002  R Jane B Gillian Students experiences of learning in a research environment Higher Education Research Development Vol.25 No.3 215-229 2006  Yuxia Lei Design of Teaching Strategy of Tutor-AI System Based on Formal Concept Analysis Proceedings of the Second International Conference on Computer Sciences  Education ICCSE'2007 pp 1079-1082 2007  Yuxia Lei Yan Wang Baoxiang Cao and Jiguo Yu Concept Interconnection Based on Many-Valued Context Analysis Z.-H Zhou H Li and Q Yang Eds PAKDD 2007 LNAI 4426 pp 623-630 2007  G Stumme R Taouil Y Bastide et al Intelligent Structuring and Reducing of Association Rules with Formal Concept Analysis F.Baader G.Brewka and T.Eiter\(Eds KI2001 LNAI 2174 pp.335-350,2001  B Ganter R Wille Formal Concept Analysis Mathematical Foundations Springer 1999  Walid S Saba Language logic and ontology uncovering the structure of commonsense knowledge International Journal of Human-Computer Studies Vol.65\(No.7 pp.610-623 2007 
214 
214 


000\003 000\003 000\003 000\003 000\003 000\003 000\003 000\003 000\003 000\003 000\003 000\003 000\003 000\003 000\003 000\003 000\003 000\003 000\003 000\003 000\003 000\003 000\003 000\003 000\003 000\003 000\003 000\003 000\003 000\003 000\003 000\003 000\003 000\003 000\003 000\003 000\003 000\003 000\003 000\003 000\003 000\003 000\003 000\003 Start e 1 1, e 2 1, r 1 1, r 2 2 e 1 0010 L 002  e 2 0010 M 002  r 1 0010 N-l 002  r 2 0010 N 002   e 1 and r 1   and  e 2 and r 2  have the same name 002 e 1 e 2 r 1 r 2 entity integrity check Check passed 002 Call connective determination algorithm  e 1 and r 2   and  e 2 and r 1  have the same name 002 e 1 e 2 r 1 r 2 entity integrity check Check passed 002 Call connective determination algorithm r 2 r 2 1  End r 1 r 1 1 r 2 r 1 1  e 2 e 2 1 r 1 1  r 2 1  e 1 e 1 1 e 2 1  r 1 1 r 2 2  N N N N Y Y Y Y Y Y Y Y N N N N Fig.3  Attribute determination algorithm 
275 
275 


As to the database Fig. 1, when mining student\(Sno 010 1 course\(Cno 010 2 study\(Sno, Cno\he three tables the table determination algorithm determines are R=0, E 1 1, E 2 2 \(i.e. R equals Table 0, E 1 equals Table 1, E 2 equals Table 2 R=0, E 1 1, E 2 3 R=0, E 1 1, E 2 4 R=0, E 1 2, E 2 3 R=0, E 1 2, E 2 4 R=0, E 1 3, E 2 4 R=1, E 1 2, E 2 3  R=4, E 1 2, E 2 3  IV. ATTRIBUTE DETERMINATION ALGORITHM The attribute determination algorithm is shown in Fig. 3, where e 1 and e 2 are the serial numbers of the current attributes of Tables E 1 and E 2 respectively, r 1 and r 2 are the serial numbers of the first and the second attribute of the current attribute pair of Table R, L, M, N are the number of attributes of Tables E 1  E 2 and R respectively The attribute determination algorithm uses brutal force method, i.e. for every two pairs of attributes, it tries to find a double-connective association rule. If it finds that e 1 and r 1 have the same attribute name and e 2 and r 2 have the same attribute name or that e 1 and r 2 have the same attribute name and e 2 and r 1 have the same attribute name, then it goes on entity integrity check for each attribute. If the check passes, then these attributes indeed embrace a double-connective association rule For student\(Sno 010 1 course\(Cno 010 2 study\(Sno, Cno the first two pairs of attributes the algorithm determines embraces it  V. CONNECTIVE DETERMINATION ALGORITHM We take student\(Sno 010 1 course\(Cno 010 2 study\(Sno, Cno\ an example to study the connective determination algorithm. Let 010 1 and 010 2 be  004 1 or 003 1 respectively, and exchange the positions of student\(Sno 010 1 and course\(Cno 010 2 we obtain 8 double-connective association rules DCAR1: student\(Sno 003 1  course\(Cno 003 1  study\(Sno, Cno DCAR2: course\(Cno 004 1  student\(Sno 003 1  study\(Sno, Cno DCAR3: student\(Sno 003 1  course\(Cno 004 1  study\(Sno, Cno DCAR4: student\(Sno 004 1  course\(Cno 003 1  study\(Sno, Cno DCAR5: course\(Cno 003 1  student\(Sno 004 1  study\(Sno, Cno DCAR6: student\(Sno 004 1  course\(Cno 004 1  study\(Sno, Cno DCAR7: course\(Cno 003 1  student\(Sno 003 1  study\(Sno, Cno DCAR8: course\(Cno 004 1  student\(Sno 004 1  study\(Sno, Cno Because DCAR7  is equivalent with DCAR1, DCAR8  is equivalent with DCAR6, we only study DCAR1  through DCAR6 003 1 denotes “for all”. This requirement is too strong, we lower its requirement by setting certainty factors cf 1 and cf 2 they are percentages\ for 010 1 and 010 2 respectively. If the percentage is no less than the certainty factor, then 003 1 holds, denoting “for many If the percentage is less than the certainty factor but greater than 0, then 004 1 holds, denoting “there are some 
276 
276 


Since the attribute determination algorithm has determined that the attribute Sno in Table 0, the attribute Cno in Table 1, and the attributes <Sno Cno> in Table 2 embrace the double-connective association rule student\(Sno 010 1 course\(Cno 010 2 study\(Sno, Cno\he connective determination algorithm make the relational matrix shown in Fig. 4 according to the binary relationship table of Table 2   C1 C2 C3 C4 S1   T  T  F  F S2   T  F  T  F S3   T  F  F  F S4   F  T  F  F S5   T  F  F  T   Fig. 4 The relational matrix made from Table 2  Fig. 4 is made like this: Table 2 has the tuple S1, C1>, then at the cross of the row S1 and the column C1, a T is filled; Table 2 does not have tuple S1, C3>, then at the cross of the row S1 and the column C3, a F is filled Suppose the cardinality of student\(Sno\s M, in this example 5, i.e. S1 to S5; the cardinality of course\(Cno\n this example 4, i.e. C1 to C4 The algorithms for DCAR1 through DCAR6 are as follows The algorithm for DCAR1 If in Fig. 4 there is M*cf 1 rows, N*cf 2 columns submatrix, in which all elements are Ts, then DCAR1 holds The algorithm for DCAR2 If in Fig. 4 there is at least one column, in which there are at least M*cf 1 Ts, then DCAR2 holds The algorithm for DCAR3 If in Fig. 4 at least M*cf 1 rows have Ts, then DCAR3 holds The algorithm for DCAR4 If in Fig. 4 there is at least one row, in which there are at least N*cf 2 Ts, then DCAR4 holds The algorithm for DCAR5 If in Fig. 4 at least N*cf 2 columns have Ts, then DCAR5 holds The algorithm for DCAR6    DCAR6   DCAR3  DCAR5     DCAR2  DCAR4   DCAR1 Fig. 5 The complement lattice formed by DCAR1 through DCAR6 
277 
277 


000\003 000\\000L\000J\000\021\000\031\000\003\000\003\000&\000R\000Q\000Q\000H\000F\000W\000L\000Y\000H\000\003\000G\000H\000W\000H\000U\000P\000L\000Q\000D\000W\000L\000R\000Q\000\003\000D\000O\000J\000R\000U\000L\000W\000K\000P\000\003 Start Call DCAR1 000D\000O\000J\000R\000U\000L\000W\000K\000P  DCAR1 holds 002  Call DCAR2 000D\000O\000J\000R\000U\000L\000W\000K\000P  Output DCAR1,2,3,4,5,6 End DCAR2 holds 002  Output DCAR2,3,6 Call DCAR3 000D\000O\000J\000R\000U\000L\000W\000K\000P  DCAR3 holds 002  Output DCAR3,6 Call DCAR4 000D\000O\000J\000R\000U\000L\000W\000K\000P  DCAR4 holds 002  Call DCAR5 000D\000O\000J\000R\000U\000L\000W\000K\000P  Output DCAR4,5,6 End DCAR5 holds 002  Call DCAR6 000D\000O\000J\000R\000U\000L\000W\000K\000P  Output DCAR5,6 End DCAR6 holds 002  Output DCAR6 End Error Y N N Y Y N N Y Y N N Y 
278 
278 


If in Fig. 4 there is at least one T, then DCAR6 holds DCAR1 through DCAR6 forms a complement lattice shown in Fig. 5 In Fig. 5, the lower rule implies the upper rule That is, if DCARj is reachable from DCARi via an ascending path, and DCARi holds, then DCARj holds Because DCAR1 through DCAR6 satisfies Fig 5, their algorithms can be merged into one algorithm called connective determination algorithm, shown in Fig. 6 Suppose cf 1 80%, cf 2 75%. In Fig. 4, for the column of C1, there are M*cf 1 5*80%=4 elements whose values are T \(namely, S1, S2, S3, S5 Therefore, DCAR2: course\(Cno 004 1  student\(Sno 003 1  study\(Sno, Cno\olds. From Fig. 5, we know that DCAR3 and DCAR6 also hold. In Fig. 4, there are at least N*cf 2 4*75%=3 columns which have value T \(namely, in the column of C1 there is S1, in the column of C2 there is S1, in the column of C3 there is S2, in the column of C4 there is S5 therefore DCAR5: course\(Cno 003 1  student\(Sno 004 1  study\(Sno, Cno  VI. CONCLUDING REMARKS 1\ Double-connective association rule mining is different from single-connective association rule mining. The former mines the association among the primary keys of the two entity tables and the primary key of the binary relationship table. The latter mines the association between frequent item sets 2\. 4 is different from data cubes in data warehouses. The elements in Fig. 4 are T or F. The elements in the data cubes are data 3\The differences between double-connective association rule and database query are that, first, the query information in databases are predeterminate while the information to be mined by double-connective association rule is not predeterminate, it is implied. Secondly, database query needs to write SQL statements, while double-connective association rule mining is automatic. Thirdly, the information obtained by database query is quantitative, while the information obtained by double-connective association rule mining is qualitative such as “for many”, “there are some  REFERENCES 1 Ji a w ei H a n   M i ch eli n e K a m b er   D a t a  M i n i n g C onc ep t s  a nd Techniques, Higher Education Press, Beijing, 2001, Morgan Kaufmann Publishers, 2000 2 A  G  Ha m i lt on  L o gi c for M a th em a t i c ia ns R evi s ed E d i t i o n   Cambridge University Press, 1988, Tsinghua University Press Beijing, 2003 3 X unw e i Z h o u   Br ie f I ntr o du c t io n  to  Mu t u al l y I nve r s is tic Logic”, 1999 European Summer Meeting of the Association for Symbolic Logic, Utrecht, The Netherlands, August 1-6 1999 4 u n w ei Zh ou F i r s t leve l exp l i c i t m u lt ip le i ndu ct i v e composition”, 2005 Spring Meeting of the Association for Symbolic Logic, The Westin St. Francis Hotel, San Francisco CA. USA, March 25-26, 2005 5 A b rah a m S i lb ers c ha t z  Hen r y  F  Kort h  S S u da rs ha n Dat a b a s e  System Concepts \(Fourth Edition\, Higher Education Press Beijing, 2002, McGraw-Hill Companies, 2002  
279 
279 


support pruning gene expression classifier with an accurate and compact fuzzy rule base for microarray data analysis Biosystems vol 85 computationally challenging As training set sizes increase it is likely that these difficulties will also increase VI RELATED WORK While operating on a microarray dataset current CAR 1 2 3 4 and other pattern/rule 20 21 mining algorithms perform a pruned and/or compacted exponential search over either the space of gene subsets or the space of sample subsets Hence they are generally quite computationally expensive for datasets containing many training samples or genes as the case may be BSTC is explicitly related to CAR-based classifiers but requires no expensive CAR mining BSTC is also related to decision tree-based classifiers such as random forest 19 and C4.5 family 9 methods It is possible to represent any consistent set of boolean association rules as a decision tree and vice versa However it is generally unclear how the trees generated by current tree-based classifiers are related to high confidence/support CARs which are known to be particularly useful for microarray data 1 2 6 7 11 BSTC is explicitly related to and motivated by CAR-based methods To the best of our knowledge there is no previous work on mining/classifying with BARs of the form we consider here Perhaps the work closest to utilizing 100 BARs is the TOPRULES 22 miner TOP-RULES utilizes a data partitioning technique to compactly report itemlgene subsets which are unique to each class set Ci Hence TOP-RULES discovers all 100 confident CARs in a dataset However the method must utilize an emerging pattern mining algorithm such as MBD-LLBORDER 23 and so generally isn't polynomial time Also related to our BAR-based techniques are recent methods which mine gene expression training data for sets of fuzzy rules 24 25 Once obtained fuzzy rules can be used for classification in a manner analogous to CARs However the resulting fuzzy classifiers don't appear to be as accurate as standard classification methods such as SVM 25 VII CONCLUSIONS AND FUTURE WORK To address the computational difficulties involved with preclassification CAR mining see Tables IV and VI we developed a novel method which considers a larger subset of CAR-related boolean association rules BARs These rules can be compactly captured in a Boolean Structure Table BST which can then be used to produce a BST classifier called BSTC Comparison to the current leading CAR classifier RCBT on several benchmark microarray datasets shows that BSTC is competitive with RCBT's accuracy while avoiding the exponential costs incurred by CAR mining see Section VB Hence BSTC extends generalized CAR based methods to larger datasets then previously practical Furthermore unlike other association rule-based classifiers BSTC easily generalizes to multi-class gene expression datasets BSTC's worst case per-query classification time is worse then CAR-based methods after all exponential time CAR mining is completed O SlS CGl versus O Si CGi As future work we plan on investigating techniques to decrease this cost by carefully culling BST exclusion lists ACKNOWLEDGM[ENTS We thank Anthony K.H Tung and Xin Xu for sending us their discretized microarray data files and Top-k/RCBT executables This research was supported in part by NSF grant DMS-0510203 NIH grant I-U54-DA021519-OlAf and by the Michigan Technology Tri-Corridor grant GR687 Any opinions findings and conclusions or recommendations expressed in this material are those of the authors and do not necessarily reflect the views of the funding agencies REFERENCES 1 G Cong K L Tan A K H Tung and X Xu Mining top-k covering rule Mining SDM 2002 5 R Agrawal T Imielinski and A Swami Mining associations between sets of items Y Ma Integrating classification and association rule mining KDD 1998 11 T McIntosh and S Chawla On discovery of maximal confident rules without pp 43-52 1999 24 S Vinterbo E Kim and L Ohno-Machado Small fuzzy and interpretable pp 165-176 2006 1071 pp 207-216 1993 6 G Dong pp 273-297 t995 9 pp 5-32 2001 20 W Li J R Quinlan Bagging boosting and c4.5 AAAI vol 1 V Vapnik Support-vector networks the best strategies for mining frequent closed itemsets KDD 2003 4 M Zaki and C Hsiao Charm L Wong Identifying good diagnostic genes or gene expression data SIGMOD 2005 2 G Cong A K H Tung X Xu F Pan and J Yang Farmer Finding interesting rule gene expression data by using the gene expression based classifiers BioiiiJcrmatics vol 21 l and Inrelligent Systenis IFIS 1993 16 Available at http://sdmc.i2r.a-star.edu.sg/rp 17 The dprep package http:/cran r-project org/doclpackages dprep pdfI 18 C Chang and C Lin Libsvm a library for support vector machines 2007 Online Available www.csie.ntu.edu.tw cjlin/papers/libsvm.pdf 19 L Breiimnan Random forests Maclh Learn vol 45 no 1 M Chen and H L Huang Interpretable X Zhang 7 J Li and pp 725-734 2002 8 C Cortes and Mac hine Learming vol 20 no 3 in microarray data SIGKDD Worikshop on Dtra Mining in Bioinfrrnatics BIOKDD 2005 12 R Agrawal and R Srikant Fast algorithms for mining association rules VLDB pp 1964-1970 2005 25 L Wong and J Li Caep Classification by aggregating emerging patterns Proc 2nd Iat Coif Discovery Scieice DS 1999 gene groups from pp 487-499 t994 13 Available ot http://www-personal umich edu/o markiwen 14 R Motwani and P Raghavan Randomized Algoriitlms Caim-bridge University Press 1995 15 S Sudarsky Fuzzy satisfiability Intl Conf on Industrial Fuzzy Contri J Han and J Pei Cmar Accurate and efficient classification based on multiple class-association rules ICDM 2001 21 F Rioult J F Boulicaut B Cremilleux and J Besson Using groups for groups in microarray datasets SIGMOD 2004 3 concept of emerging patterns BioinformJotics vol 18 transposition for pattern discovery from microarray data DMKD pp 73-79 2003 22 J Li X Zhang G Dong K Ramamohanarao and Q Sun Efficient mining of high confidence association rules without S Y Ho C H Hsieh H pp 725-730 1996 10 B Liu W Hsu and support thresholds Principles f Drata Mining aind Knowledge Discovery PKDD pp 406 411 1999 23 G Dong and J Li Efficient mining of emerging patterns discovering trends and differences KDD J Wang J Han and J Pei Closet Searching for An efficient algorithm for closed association rule mining Proc oJ the 2nd SIAM Int Con on Data in large databases SIGMOD 


