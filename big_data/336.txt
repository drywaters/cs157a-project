Issues in Modeling for Data Mining Tsau Young T.Y Lin Department of Mathematics and Computer Science San Jose State University San Jose CA 95192 tylin@cs.sjsu.edu ABSTRACT Modeling in data mining has not been fully explored so data mining is often regarded as a set of added operations in database systems The consequence many notions are overloaded Some terms often have different semantics This paper continues previous effort to explore and reiterate some fundamental issues in data mining Keywords Modeling data mining equivalence relation 
lattice 1 Introduction A DBMS vender often offers a data mining service by adding a set of tools into its existing DBMS This practice has been translates into in academic world the following view:Dataminingisasetof added operations onto the classical data model So database terms are used without changes in data mining research This is a confusing in fact an incorrect view Some semantics of these terms can be very different between database and data mining Roughly database stores data according to its semantics 
While data mining is to discover what the data have expressed A set of data may not be able to fully expressed the given semantics 1.1 What is data mining A commonly quoted definition defines data mining as a non-trivial process of identifying valid novel potentially useful and ultimately understandable patterns from data  W e h a v e poin t ed ou t i n s ev eral occas ions th a t s o m e terms such as 223novel,\224 223useful,\224 and 223understandable\224 are subjective and can not be used as scientific criteria However they do point out one important requirement 
The discovered patterns should be relevant to the real world We call it a real-world-pattern We believe Real-world-patterns are the primary goal of data mining This leads us to examine the mathematical modeling of realworldforthepurposeofdatamining 1.2 Notations Let U be the set of the real world entities and A A 1 A 2  205 A n  be a set of attributes  A relation K will be viewed as a knowledge representation that assigns each entity or object a unique tuple 
K U 001 Dom\(A 1  002 Dom\(A 2  002  002 Dom\(A n  u 001 a 1 a 2 205,a n  where Dom is the active domain  the set of attribute values currently in use Traditionally the image of K is referred to as a relation For modeling it is more convenient to have the independent variables available for discussions so we will use the graph u K\(u and call it 
information table or simply table  2 Are the Given Attributes Adequate A tuple of degree n in a numerical relation of degree n can be regarded as a coordinate of a point in n 226 dimensional Euclidean space A coordinate system X 1  X 2 205,X n  of an Euclidean space is a set A 1 A 2 205,A n  of attribute names A point p x with coordinate x  x 1 
x 2  205 x n  is a tuple The set P  p x of points is a coordinate dependent concept it is a set of points real world objects While the set R of numerical tuples is a coordinate dependent concept it is merely a merely representation a 223matrix.\224 A pattern a statement about property of R may or may not be a real world event a statement about geometry A pattern with real world significance is then a geometric property of P 2.1 223Invisible\224 Association Rules 
Letusre-visittheexample[p T h e f i r s tc o l u m n i st h e l i s t of entities\(directed segments Attribute B is the Starting point of a direct segment the others are the D egree and Proceedings of the 26 th Annual International Computer Software and Applications Conference \(COMPSAC\22202 0730-3157/02 $17.00 \251 2002 IEEE 


L ength 223polar coordinates\224 This table only has one association rule of length 2 namely p 3 2.0\fthe ed support is 4 Segment S D L S 1 p 1 06.0 S 2 p 3 90 2.0 S 3 p 3 120 2.0 S 4 p 3 135 2.0 S 5 p 3 150 2.0 S 6 p 3 180 2.0 S 7 p 3 210 2.0 S 8 p 3 225 2.0 S 9 p 3 240 2.0 S 10 p 3 270 2.0 Table 1 10 directed segments in polar coordinates Segment B H V S 1 p 1 60 S 2 p 3 02 S 3 p 3 1 003 3 S 4 p 3 003 2 003 2 S 5 p 3 003 3 1 S 6 p 3 2 0 S 7 p 3 003 3 1 S 8 p 3 003 2\003 2 S 9 p 3 003 3 1 S 10 p 3 0-2 Table 2 10 directed segments in X,Y\coordinates Table 2 is transformed from Table 1 by switching to 223Cartesian coordinate system;\224 the two new attributes are H orizontal and V ertical length The only association rule disappears  In this geometric database the association rule is a real world phenomenon a geometric fact the same information should be still carried by Table 2 The estion is then How can such invisible association rules be discovered from Table 2 3 ning on ved Attributes To understand what is really reflected by attributes let us examine a simple example Table 3 is a numerical information table of 9 points in the Euclidean 3-space The first column is the names of the points the second columns and etc are Z-Xand Ycoordinates point X Y Z P1 200 0 0 P2 100 0 0 P3 173 100 1 P4 87 50 1 P5 44 25 1 P6 141 141 2 P7 71 71 2 P8 36 36 2 P9 0 200 3 Table 3 9 points with coordinate in Euclidean 3-space Next let us consider a transformation that rotates the Xand Yaxes around Z-axis Table 4 expands Table 3 by including new Xand Ycoordinates of various rotations The suffixes 20 30 52 and 79 represent the new coordinate axes attribute names that rotate 0.20 0.30 and etc radians Each new axis is a new derived attribute point Z X Y X20 Y20 X30 Y30 X52 Y52 X79 Y79 P1 0 200 0 196 40 191 59 174 99 141 142 P2 0 100 0 98 20 96 30 87 50 70 71 P3 1 173 100 189 64 195 44 200 0 193 53 P4 1 87 50 95 32 98 22 100 0 97 27 P5 1 44 25 48 16 49 11 51 0 49 14 P6 2 141 141 166 110 176 93 192 52 199 0 P7 2 71 71 84 55 89 47 97 26 100 0 P8 2 36 36 42 28 45 24 49 13 51 0 P9 3 0 200 40 196 59 191 99 174 142 141 Table 4 9 points with coordinate in various axes they rotate radians 0.2 0.3 0.53\(=30 o  0.79\(=45 o  Proceedings of the 26 th Annual International Computer Software and Applications Conference \(COMPSAC\22202 0730-3157/02 $17.00 \251 2002 IEEE 


The table seems indicate that there are at least as many new attributes as angles Even worse there are many non-linear transformations not listed in Table 4 Several questions arise 1 Are all these es stinct from data ng point of view 2 Could we find ALL derived attributes 3 Should data mining consider all of them We will answer the first and second one in next few sections For third question from scientific point of view we should consider all however from practical application point of view we may only want to select some from all This indicates that we should extend the common practices of feature selection to this full set not on the given set of attiutes 3 Is L abeling Concepts/Data Necessary 3.1 Isomorphic Attributes and Tables Definition 1  Attributes A i and A j areisomorphiciff there is a one-to-one and onto map s Dom\(A i  001 Dom\(A j  such that A j v s\(A i v 004 v 005 V.siscalled an isomorphism  Definition 2 Let K and H be two information tables with thesameuniverseV.LetA={A 1 A 2 205,A n andB B 1 B 2 205,B m  be the attributes of K and H respectively Then K and H are said to be isomorphic if every A i is isomorphic to some B j  and vice versa If n  m then it is said to be strict isomorphic Intuitively isomorphic is re-labeling The following theorem should be obvious Theorem 1 Let K and H be strictly isomorphic Then patterns such as association rules of K can be transformed to those of H by re-labeling the data Corollary Labeling the attribute values base concepts does not influence the results of data mining Now we apply the notion of isomorphism to Table 4 we find that X 006 X20 006 X30 006 X52 006 X79 006 Y20 006 Y30 where 006 means isomorphic So by dropping the isomorphic attributes Table 4 is reduced to Table 5 point Z X Y Y52 Y79 P1 1 200 0 99 142 P2 1 100 0 50 71 P3 1 173 100 0 53 P4 1 87 50 0 27 P5 1 44 25 0 14 P6 2 141 141 52 0 P7 2 71 71 26 0 P8 2 36 36 13 0 P9 3 0 200 174 141 Table 5 Simplified Table of 9 points The association rules are support 007 3 Z=1,Y52=0 Z 2,Y79=0 3.2 Isomorphic High Level Concepts One of the important data mining practices is the concept hierarchy attribute oriented generalization In the current state of arts human users supply the concept hierarchies  I n o th er w o r d s  th e n es ted s equ e n c e o f equivalence relations are labeled by human users The question is Is such a labeling necessary for data mining In other words will we get new rules if we rename all the nodes of a hierarchy By considering the table of high level concepts and results of Section 3.1 the answer is no re-labeling Table 6 will not change the high level association rules Theorem2 Isomorphic AOG have isomorphic high level association rules Corollary Given a nested sequence of partitions the generalized high level association rules are independent of labeling Corollary Labeling the high level and base concepts does not influence the results of data mining point Z X Y Proceedings of the 26 th Annual International Computer Software and Applications Conference \(COMPSAC\22202 0730-3157/02 $17.00 \251 2002 IEEE 


P1 Lz03={1 Lx00 200 100 Ly00={0 P2 Lz03={1 Lx00 200 100 Ly00={0 P3 Lz03={1 Lx30 173 87 44 Ly30 100 50,25 P4 Lz03={1 Lx30 173 87 44 Ly30 100 50,25 P5 Lz03={1 Lx30 173 87 44 Ly30 100 50,25 P6 Lz45={2 Lx45 141 71 36 Ly45 141 71,36 P7 Lz45={2 Lx45 141 71 36 Ly45 141 71,36 P8 Lz45={2 Lx45 141 71 36 Ly45 141 71,36 P9 3 0 200 Table 6 High Level Table granules are labeled 4 Granular Data Model In last section we have shown that labels are not essential So for data mining the underlying mathematical structures is important and we will use them to label the data 7,8 9 10  An attribute can be interpreted as the composition of K and the projection P j Dom\(A 1  002 Dom\(A 2  002  002 Dom\(A n  001 Dom\(A j  A j U 001 Dom\(A j  Each A j induces a partition on U By replacing attribute es a j with its inverse image A j  1 a i  the collection of these inverse images together forms a partition on U For example Pi p i  P12={p 1 p 2 and P345 p 3  p 4 p 5  P678 p 6 p 7 p 8  are equivalence classes One can label an equivalence class by itself called canonical names  So Pi Pij Pijk are labels canonical names of the respective equivalence classes Using these canonical names Table 4 is transformed to Table 9 such a table is called a unnamed relation  because each granule is not assigned a human oriented meaningful name they also have been called machine oriented model  E ach at t r i b u t e v al u e of T a bl e 4 i s a h um a n oriented meaningful name of the corresponding Pi in Table 9 This naming is an isomorphism that is Table 4 is isomorphic to e 9 e hat the e names say A are replaced by the induced equivalence relation E A  We hope we have convinced the readers the following theorem Theorem 3 Unnamed information table relation is isomorphic to the original table K hence their respective association rules are isomorphic The essential ingredients in an unnamed relations are U and E where E E 1 E 2 205,E n isthesetof equivalence relations induced by attributes We will call the pair U E={E 1 E 2 205,E n  a Granular Data Model GDM of K Pawlak called U E an approximation space if E has only one equivalence relation and in general a knowledge base knowledge base often has different meaning we will use Granular Data Model Summarize the discussions above we have Definition  Given an ordinary relation K then the information table relation obtained by using the induced equivalence relations as the names of attributes and equivalence classes as attribute values is called an unnamed table relation of K the Pair U E is called the granular data model of K point E Z E X E Y E X20 E Y20 E X30 E Y30 E X52 E Y52 E X79 E Y79 P1 P12 P1 P12 P1 P1 P1 P1 P1 P1 P1 P1 P2 P12 P2 P12 P2 P2 P2 P2 P2 P2 P2 P2 P3 P345 P3 P3 P3 P3 P3 P3 P3 P345 P3 P3 P4 P345 P4 P4 P4 P4 P4 P4 P4 P345 P4 P4 P5 P345 P5 P5 P5 P5 P5 P5 P5 P345 P5 P5 P6 P678 P6 P6 P6 P6 P6 P6 P6 P6 P6 P678 P7 P678 P7 P7 P7 P7 P7 P7 P7 P7 P7 P678 P8 P678 P8 P8 P8 P8 P8 P8 P8 P8 P8 P678 P9 P9 P9 P9 P9 P9 P9 P9 P9 P9 P9 P9 Table 9 Unnamed Relation attribute values are expressed by granules Proceedings of the 26 th Annual International Computer Software and Applications Conference \(COMPSAC\22202 0730-3157/02 $17.00 \251 2002 IEEE 


The uses of unnamed relations have some advantage over the traditional ones in machine processing ding data mining For ample we have shown in Table 4 that many attributes are isomorphic with efforts while in Table 9 isomorphic attributes are the identical columns So the simplification of Table 9 into Table 10 becomes effortless in unnamed relations point Z X Y Y52 Y79 P1 P12 P1 P12 P1 P1 P2 P12 P2 P12 P2 P2 P3 P345 P3 P3 P345 P3 P4 P345 P4 P4 P345 P4 P5 P345 P5 P5 P345 P5 P6 P678 P6 P6 P6 P678 P7 P678 P7 P7 P7 P678 P8 P678 P8 P8 P8 P678 P9 P9 P9 P9 P9 P9 Table 10 Simplified Unnamed Relation 5 The Features Completionthe Lattice in Partition In this section we will show how one can use granular data model/unnamed relation to find all derived attributes 5.1 Attribute Transformations By a new attribute Y we mean there is a subset denoted by Dom\(Y and an onto map U 001 Dom\(Y Let B={B 1  B 2 205,B k  be a subset of of A that is each B i is some A j i  Letusassumethereisamap f Dom\(B 1  002 Dom\(B 2  002  002 Dom\(B k  001 Dom\(Y such that f\(B 1 u B 2 u 205 B k u 004 u Then we said Y is an attribute transformed from B  B 1 B 2  205 B k  and denoted by Y f\(B 1 B 2 205,B k  The details of f are illustrated in Table 7 V 001 B 1 B 2 B k Y v 1 001 b 1 1 b 2 1  b k 1 f 1 f\(b 1 1 b 2 1 b k 1  v 2 001 b 1 2 b 2 2  b k 2 f 2 f\(b 1 2 b 2 2 b k 2  v 3 001 b 1 3 b 2 3  b k 3 f 3 f\(b 1 3 b 2 3 b k 3  001   v i 001 b 1 i b 2 i b k i f i f\(b 1 i b 2 i b k i  001   Table 7 Attribute feature Transformations In database theory we say Y is extension functionally depended on B The equivalence relation induced by Y is denoted by Y E  Theorem 4 Y is an attribute transformed from B B 1 B 2 205 B k iffY E is a coarsening of E B 1 b E B 2 b  b E B k where each E B i is the equivalence relation induced by B i  5.2 Lattices of Partitions induced by Attributes Let E be the set of equivalence relation induced by the attributes of K see the beginning of Section 4 The Boolean algebra 2 E is a lattice Let t U be the lattice of all partitions equivalence relations on U its join is the intersection of equivalence relations and the meet is the 223union\224 of equivalence relations where the 223union\224 is the smallest coarsening of its components T T Lee uses the map n 2 A 001\t U to summarize the fact that each attribute induces an equivalence relation on the universe U He observed that e map ly respects the meet but not the join 5  T h e image of n was called the relation lattice he observed then that the image is a subset of t U but not a sublattice This is the point of our departure Previously we have let L\(E  be the smallest sublattice that contains E and called it the generalized relation lattice 8 9  W e also have called the smallest sublattice that contains E and all its coarsening the lattice-in-partitions and denoted by L\(E Theorem 5 L\(E is a finite lattice and the feature completion of E This theorem says that the number of derived attributes is finite For data mining we may consider the following granular data model GDM for a given K 1 U E is the GDM of K 2 U L\(E  is a new GDM associated with K 3 U L\(E is a new GDM that contains feature completion 4 U G is a new GDM that contains essential attributes where G consists only of all join-irreducible equivalence relations in L\(E All possible generalized association canbe found here Proceedings of the 26 th Annual International Computer Software and Applications Conference \(COMPSAC\22202 0730-3157/02 $17.00 \251 2002 IEEE 


Let us consider a Table that collapses redundant tuples in Table 6 point Z X Y P12=u 1 Lz03 Lx00 Ly00 P345 u 2 Lz03 Lx30 Ly30 P678 u 3 Lz45 Lx45 Ly45 P9 u 4 3 0 200 Table 11 An Information Table K Reduced Table 6 It is clear X 006 Y so we drop Y and have an unnamed relation point E Z E X P12=u 1 u 1 u 2 u 1  P345 u 2 u 1 u 2 u 2  P678 u 3 u 3 u 3  P9 u 4 u 4 u 4  Table 12 Unnamed relation of K Since E Z b E X has 4 equivalence classes so the number of all possible derived attribute is the Bell number B 4 16 see  W e w i l l n o t d i s pl ay t h em  References  G  B irk h o f f an d S  M acLan e A S u r v e y o f M odern Algebra Macmillan 1977  R  B ru al di  I n t ro du ct ory C o m bi n a t o ri cs  P ren t i c e Hall 1992  F ay ad U  M  P i atets k y S j apir o G Sm y t h  P  From Data Mining to Knowledge Discovery An overview In Fayard Piatetsky-Sjapiro Smyth and Uthurusamy eds Knowledge Discovery in Databases  AAAI/MIT Press 1996 4  Had j im ic h ael H  H a m il to n  N Cer c o n e   Ex tr actin g Concept Hierarchies from Relational Databases in Proceedings FLAIRS-95 Florida AI Research Symposium Melbourne Beach Florida 1995  T  T  L ee 223A lg ebrai c T h eory of R e la tion a l Databases,\224 The Bell System Technical Journal Vol 62 No 10 December 1983 pp.3159-3204 6 T Y L in  223 Da ta Mo d e lin g f o r Data Min i n g 224 I n  Data Mining and Knowledge Discovery Theory Tools and Technology IV B Dasarathy ed Proceeding of SPIE Vol 4730 Orlando Fl April 15 2002 7 T  Y  L i n   D a t a M i ni n g  G r a nul a r Co m p ut i n g Approach In Methodologies for Knowledge Discovery and Data Mining Lecture Notes in Artificial Intelligence 1574 Third Pacific-Asia Conference Beijing April 26-28 1999 24-33  T Y L i n  223 F e a t u r e T ran s form at i o n s a n d S t r u c t u re of Attributes\224 In Data Mining d Knowledge Discovery Theory Tools and Technology IV Proceeding of SPIE\222s aeroSence 2002 1-5 April 2002 Orlando FL  T Y L in  223 T h e L att i ce Stru ct u r e o f D atabas e a n d Mining High Level Rules.\224 In Proceedings of Workshop on Data Mining and E-Organizations International Conference on Computer Software and Applications Chicago 2001 October 8-12 2001 Also in Bulletin of International Rough Set Society 10 T  Y  Li n   D a t a M i ni ng a n d M a c h i n e O r i e n t e d Modeling A Granular Computing  Journal of Applied Intelligence Kluwer Vol 13 No 2 September/October,2000 pp.113-124 Proceedings of the 26 th Annual International Computer Software and Applications Conference \(COMPSAC\22202 0730-3157/02 $17.00 \251 2002 IEEE 


tigated how data skewness affects parallel ef“ciency Figure 8 shows that the effect of data skewness are worse for the pure distributed implementations Although data skewness increases as we reduce the minimum support parallel ef“ciency increases for lower minimum support values since the asynchronous phase becomes more relevant  0  50  100  150  200  250  300  2  4  6  8  10  12  14  16   Execution time \(secs  Number of processors  WPortal - 0.01   Data Distribution \(Distributed   Candidate Distribution \(Distributed    Data Distribution \(Hierarchical    Candidate Distribution \(Hierarchical               0  50  100  150  200  250  300  350  400  450  500  2  4  6  8  10  12  14  16   Execution time \(secs  Number of processors  WPortal - 0.005   Data Distribution \(Distributed   Candidate Distribution \(Distributed    Data Distribution \(Hierarchical    Candidate Distribution \(Hierarchical              Figure 5 Total Execution Times as a function of number of processors SMP cluster The other series of experiments employed the two clusters but to make equal the computational power of both clusters we used only 4 dual nodes of the rst cluster Our objective is to evaluate our algorithms in terms of execution times and speedup We varied the number of processors and the minimum support value and in each parallel con“guration employed each cluster used the same number of processors i.e 2 processors mean that cluster 1 and cluster 2 used 1 processor Figure 9 shows the execution times obtained For    0.01 we observed a speedup number of 11/16 while for    0.005 the speedup number reached almost 14/16 These numbers shows that combining both Data and Distribution approaches in the inter-cluster parallel environment can be an ef“cient approach since it reduces communication among the clusters and reduces data skewness since there are only two logical partitions  1000  10000  100000  1e+06  1e+07  1e+08  1e+09  2  4  6  8  10  12  14  16   Communication \(bytes  Number of processors  WPortal - 0.01   Data Distribution \(Distributed   Candidate Distribution \(Distributed    Data Distribution \(Hierarchical    Candidate Distribution \(Hierarchical          Figure 6 Communication as a function of number of processors  0  0.05  0.1  0.15  0.2  0.25  0.3  2  4  6  8  10  12  14  16   Data Skewness  Number of processors  WPortal - Data Distribution   Distributed \(0.01   Hierarchical \(0.01    Distributed \(0.005    Hierarchical \(0.005            Figure 7 Data Skewness as a function of number of processors 5 Related Work Several algorithms for mining frequent itemsets were proposed in the literature 2 12 11 A PRIORI 2 w as the rst ef“cient algorithm and it forms the core of almost all current algorithms During the rst pass over  the support of each item is counted The frequent items are used to generated candidate 2-itemsets  is scanned again to obtain the support of all candidate 2-itemsets and the frequent ones are selected to generate candidate 3-itemsets This iterative process is repeated for   3,4 until there are no more frequent  itemsets to be found Clearly A PRI ORI needs  passes over   incurring in high I/O overhead In the parallel case A PRIORI based algorithms do a reduction operation at the end of each pass thus incurring also in high synchronization cost Three different parallel implementations of the A PRIORI algorithm on IBMSP2 a distributed-memory machine were presented in 1 In 10 t he aut hors s h o w ed t h e i mpact i n s ynchroni zat i o n Proceedings of the 15th Symposium on Computer Architecture and High Performance Computing \(SBAC-PAD03 0-7695-2046-4/03 $17.00 © 2003 IEEE 


 0.75  0.8  0.85  0.9  0.95  1  0  0.05  0.1  0.15  0.2  0.25   Parallel Efficiency  Data Skewness  WPortal - Data Distribution   Distributed \(0.01   Hierarchical \(0.01    Distributed \(0.005    Hierarchical \(0.005            Figure 8 Parallel Ef“ciency as a function of Data Skewness  0  50  100  150  200  250  300  350  400  450  500  2  4  6  8  10  12  14  16   Execution time \(secs  Number of processors  WPortal   0.01   0.005   Figure 9 Total Execution Times as a function of number of processors 2 clusters overhead due to ne-grained parallel approaches The parallel algorithms NPA SPA HPA and HPA-ELD proposed in 7 a r e sim ilar to th o s e i n  1   H P A E L D is th e b est among NPA SPA and HPA because it reduces communication by replicating candidates with high support on all processors E CLAT  an algorithm presented in 12 n eed s only two passes over  and decomposes the search-space for frequent itemsets in disjoint sub-spaces In 13 s e v eral E CLAT based parallel algorithms were presented Our basic algorithm need only one access to   In the parallel case our algorithms need only one communication round Also complementar experiments show that our basic algorithm generates a smaller number of candidates than both A PRIORI andE CLAT based algorithms 6 Conclusions The huge size of the available databases and their high dimension make data mining applications very computationally demanding to an extent that high performance parallel computing is fast becoming an essential component of the solution In fact data mining applications are poised to become the dominant consumers of supercomputing and high performance systems in the near future There is a practical necessity to develop effective and ef“cient parallel algorithms for data mining In this paper we presented several parallel algorithms for frequent itemset mining a fundamental data mining task Key issues such as load balancing communication reduction attention to data skewness improving cache locality and reducing false sharing were all addressed Our parallel algorithms need only one access to the disk-resident database and are based on a novel and ef“cient backtrack algorithm which was also presented in this paper Also our algorithms are the rst ones able to deal with both large size and high dimension problems The algorithms were evaluated on different parallel environments and showed to be very ef“cient We also presented a possible application mining large web logs to better understand web patterns We intend to continue our work by distributing the databases in a widely distributed scenario and developing proper algorithms to deal with the challenges imposed by this scenario References 1 R  A g r a w al an d J  S h a fer  P a rallel m in in g o f a sso ciatio n rules Transactions on Knowledge and Data Engineering  8\(6\:962…969 1996  R  A gra w al and R  S r i kant  F ast al gori t h ms for m i n i n g a ssociation rules In Proc 20  Int Conf Very Large Databases VLDB  pages 487…499 Morgan Kaufmann Dec 1994  R Bi anchi ni and T  L eBl anc S oft w are cachi ng on cachecoherent multiprocessors In Proc Symp on Parallel and Distributed Processing SPDP  pages 521…526 IEEE May 1992 4 D  W  L  C h eung and Y  Xi ao E f f ect of dat a d i s t r i b ut i o n in parallel mining of associations Data Mining and Knowledge Discovery  3\(3\:291…314 1999 5 J  G r a y a nd P  S h er no y  R u l e s o f t humb i n dat a engi neer i ng In Proc Int Conf on Data Engineering ICDE  pages 3…12 IEEE Ma y 2000  E  H Han G Karypi s and V  K umar  S cal abl e paral l e l d at a mining for association rules Transactions on Knowledge and Data Engineering  12\(3\:728…737 2000  M  J oshi  E  H Han G Karypi s and V  K umar  E f  ci ent par allel algorithms for mining associations Parallel and Distributed Systems  1759:418…429 2000  S  Part hasarat hy  M  Z aki  M  Ogi hara and W  L i  Paral lel data mining for association rules on shared-memory systems Knowledge and Information Systems  3\(1\:1…29 2001  A V e l oso W  Mei ra and M Bunt e Real w o rl d a ssoci at i o n mining Advances in Databases LNCS  2405:73…77 2002 Proceedings of the 15th Symposium on Computer Architecture and High Performance Computing \(SBAC-PAD03 0-7695-2046-4/03 $17.00 © 2003 IEEE 


 A V e l o so W  Mei r a M B unt e S  Par t hasar at hy  and M Zaki Parallel incrementa l and interactive frequent itemset mining In Proc Int Work on High Performance Data Mining HPDM  pages 81…90 SIAM May 2003  M Z a ki and S  Part hasarat hy  A l o cal i zed al gori t h m f or par allel association mining In Proc Symp on Parallel Algorithms and Applications SPAA  pages 120…128 ACM Aug 1997  M Z a ki  S  P ar t h asar at hy  M  O gi har a and W  L i  Ne w a l gorithms for mining association rules In Proc 2  Int Conf on Knowledge Discovery and Data Mining SIGKDD  pages 14…24 ACM Aug 1997  M Z a ki  S  P ar t h asar at hy  M  O gi har a and W  L i  Ne w par allel algorithms for fast discovery of association rules Data Mining and Knowledge Discovery An International Journal  1\(4\:343…373 1997 Proceedings of the 15th Symposium on Computer Architecture and High Performance Computing \(SBAC-PAD03 0-7695-2046-4/03 $17.00 © 2003 IEEE 


0 Figure 15 ROC map of associative keywords derived from a category 2 keyword 223perlor marrce\224 6 Conclusion The tcchniqiic OF data mining such as association algo rithm becnmcs to tie uscd widcly in variniis liclds H\(Iw cver it is tun h;ird to spccify tlic thrwhold for dcrivitig roles in nrdcr to rlcrivc mcaningful rulcs In Ibis paper wc tricd to cvaluatc thc perl\221ottunnce of ruics ilcrivcd by onc or mining icchnolugies brtscd 011 ihc cliar;icters riTROC prnplis cnnsirlchg the ROC coiivcx hull irieiliod and proposed the strelcgy to detcrruinc tho thrcsh old valucs in thc basic nlguritl~tns fot cxlcntlcd association rulcs Morcovcr wc pt-op~isctl thc visualization nielliotl hy the ROC map aid shnw how to fincl uid tlic rdntionship hc twccii n qiicry and ihc derived kcyworils In tbc fiiturc to ilerivc inorc optimal and iucnninghil rulcs wc have lo much inorc cxtciid basic and ROC nfgo rilhtns which arc prrjposed in this paper Ackaowledgrnent A par1 of this work is supportcd by hc grant of ScIeii tilic Research 10780259 OK244 103 from thc Ministry of Bducaticin Scicncc Sprk antl Culturc of Japan Wc arc gratehil to Nissho lwai Intocoin Co Lttl for thc sourcc prograins oftlic lull text seaixh sysicm 223OpetiTcxt\224 Referenccs 111 C Harbcr D Dobkin and 11 Hulidatipaii 221I\222hc quickhull algririlhin I\222or convex liull 221l\222cchnicnl Rcpurt CiCGSl Uni vcrsity 01\221 Miiiiicsotn 1903 z C 0 0,25 Figure 16 ROC map enlarged by the area of 0 5 FP  0.26 and 0 I Y\222P I 0.25 in Figure 13  2 LJ M I.\221;iyyed G Piatctsky-Sliapiro P Smytli and R Uthir rusamy Ailvirrices in Kmwludge Disucrveiy nd Dfim Miii hg AAAIIMIT l\222rcss 1996 131 J Han S Nishio H Kawano and W Wci Gcncralization hasccl datii mining in nhject-oricnied databascs wing in otrjcct cube mntlel 13a1u iind Knowledge EiiRirweririg 141 M Knwahrirn H Kawriio antl T Masegawn Evnluiilion 01\221 index had clustcring in spatial riawbasc Proceedings of Advcrmsrl I3rrrihcrsc S.ytnpo.viwn 22296 pngcs 79-X6 1 986 IS M Knwihara H Kawanu and T Hnsegawa Dah mining teclmologics fur hihliugraphic navigation systcm Tmiisrrc Iiott.r O~IIIE U\222S 39\(4 1998 161 M Knwnh;ire M Kawano atitl T 1 lmegawa lniplemcnta tion of bihliogfiiphic nnvigation system wiih tcxi data iniri ing Syskws Science 3\(24 101-1 IS 19N 71 H Kiiwano Moncluu Web search cnginc with tcxiual dm inini ng  Pro lP;Kk Puc$c Hiin C\221orference on Cotmtiirii whwi C~t~pirler rrrid Sigrid I\222ruuessing l>iips 402-405 1997 8 H Kiiwnno M Kawithsra and H T The strricturc cif text mining navigator Cor bibliographic sc;ircli Sy\222nrposriori OH fi$r,luRy IN I~XI~IES\221P pages 121-128 1998 191 E I\222rovtist and T Pawcclt Anidysis antl visualization ofclas silicr pcrfurmnncc Compririson iindcr imprccisc class and cost distributions In frocedirtgs rf3rd Irit\222I ConJerenctr MI Kiiowlerl,qe IXscnvwy mil Uri Mining KLID-97 pages 4348 1997 I IO R.Mldman Practical kxt mining In Sscortd Synqmviiri/1 on Principles of L1 Minirig arid Kti~~l~tlgc ljisorvrry PKDD-97 Nrintes Pmnce 1998 f I I R Srikant and K Agmwal Miniiig gcncralizcd association rulcs Plvceetlings oJ!h 21sr VLUA pagcs 407419 1995 25 199X 83 


It can also be added to cell CrossSales.3\(PC, printer one_year,\205 5  Distributed and Incremental Rule Mining There exist two ways to deal with association rules 267  Static that is, to extract a group of rules from a snapshot, or a history, of data and use "as is 267  Dynamic that is, to evolve rules from time to time using newly available data We mine association rules from an e-commerce data warehouse holding transaction data. The data flows in continuously and is processed daily Mining association rules dynamically has the following benefits 267  223Real-time\224 data mining, that is, the rules are drawn from the latest transactions for reflecting the current commercial trends 267  Multilevel knowledge abstraction, which requires summarizing multiple partial results. For example association rules on the month or year basis cannot be concluded from daily mining results. In fact multilevel mining is incremental in nature 267  For scalability, incremental and distributed mining has become a practical choice Figure 3: Distributed rule mining Incremental association rule mining requires combining partial results. It is easy to see that the confidence and support of multiple rules may not be combined directly. This is why we treat them as \223views\224 and only maintain the association cube, the population cube and the base cube that can be updated from each new copy of volume cube. Below, we discuss several cases to show how a GDOS can mine association rules by incorporating the partial results computed at LDOSs 267  The first case is to sum up volume-cubes generated at multiple LDOSs. Let C v,i be the volume-cube generated at LDOS i The volume-cube generated at the GDOS by combining the volume-cubes fed from these LDOSs is 345   n i i v v C C 1  The association rules are then generated at the GDOS from the centralized C v  214  The second case is to mine local rules with distinct bases at participating LDOSs, resulting in a local association cube C a,I a local population cube C p,I  and a local base cube C b,i at each LDOS. At the GDOS, multiple association cubes, population cubes and base cubes sent from the LDOSs are simply combined, resulting in a summarized association cube and a summarized population cube, as 345   n i i a a C C 1   345   n i i p p C C 1  and 345   n i i b b C C 1  The corresponding confidence cube and support cube can then be derived as described earlier. Cross-sale association rules generated from distinct customers belong to this case In general, it is inappropriate to directly combine association cubes that cover areas a 1 205, a k to cover a larger area a In the given example, this is because association cubes record counts of customers that satisfy   customer product merchant time area Doe TV Dept Store 98Q1 California Doe VCR Dept Store 98Q1 California customer product merchant time area Doe VCR Sears 5-Feb-98 San Francisco Joe PC OfficeMax 7-Feb-98 San Francisco customer product merchant time area Doe TV Fry's 3-Jan-98 San Jose Smith Radio Kmart 14-Jan-98 San Jose Association   population      base          confidence      support cube               cube                cube         cube                cube LDOS LDOS GDOS 


the association condition, and the sets of customers contained in a 1 205, a k are not mutually disjoint. This can be seen in the following examples 214  A customer who bought A and B in both San Jose and San Francisco which are covered by different LDOSs , contributes a count to the rule covering each city, but has only one count, not two, for the rule A  336  B covering California 214  A customer \(e.g. Doe in Figure 3\who bought a TV in San Jose, but a VCR in San Francisco, is not countable for the cross-sale association rule TV  336 VCR covering any of these cities, but countable for the rule covering California. This is illustrated in Figure 3 6  Conclusions In order to scale-up association rule mining in ecommerce, we have developed a distributed and cooperative data-warehouse/OLAP infrastructure. This infrastructure allows us to generate association rules with enhanced expressive power, by combining information of discrete commercial activities from different geographic areas, different merchants and over different time periods. In this paper we have introduced scoped association rules  association rules with conjoint items and functional association rules as useful extensions to association rules The proposed infrastructure has been designed and prototyped at HP Labs to support business intelligence applications in e-commerce. Our preliminary results validate the scalability and maintainability of this infrastructure, and the power of the enhanced multilevel and multidimensional association rules. In this paper we did not discuss privacy control in customer profiling However, we did address this issue in our design by incorporating support for the P3P protocol [1 i n  ou r data warehouse. We plan to integrate this framework with a commercial e-commerce system References 1  Sameet Agarwal, Rakesh Agrawal, Prasad Deshpande Ashish Gupta, Jeffrey F. Naughton, Raghu Ramakrishnan, Sunita Sarawagi, "On the Computation of Multidimensional Aggregates", 506-521, Proc. VLDB'96 1996 2  Surajit Chaudhuri and Umesh Dayal, \223An Overview of Data Warehousing and OLAP Technology\224, SIGMOD Record Vol \(26\ No \(1\ 1996 3  Qiming Chen, Umesh Dayal, Meichun Hsu 223 OLAPbased Scalable Profiling of Customer Behavior\224, Proc. Of 1 st International Conference on Data Warehousing and Knowledge Discovery \(DAWAK99\, 1999, Italy 4  Hector Garcia-Molina, Wilburt Labio, Jun Yang Expiring Data in a Warehouse", Proc. VLDB'98, 1998 5  J. Han, S. Chee, and J. Y. Chiang, "Issues for On-Line Analytical Mining of Data Warehouses", SIGMOD'98 Workshop on Research Issues on Data Mining and Knowledge Discovery \(DMKD'98\ , USA, 1998 6  J. Han, "OLAP Mining: An Integration of OLAP with Data Mining", Proc. IFIP Conference on Data Semantics DS-7\, Switzerland, 1997 7  Raymond T. Ng, Laks V.S. Lakshmanan, Jiawei Han Alex Pang, "Exploratory Mining and Pruning Optimizations of Constrained Associations Rules", Proc ACM-SIGMOD'98, 1998 8  Torben Bach Pedersen, Christian S. Jensen Multidimensional Data Modeling for Complex Data Proc. ICDE'99, 1999 9  Sunita Sarawagi, Shiby Thomas, Rakesh Agrawal Integrating Association Rule Mining with Relational Database Systems: Alternatives and Implications", Proc ACM-SIGMOD'98, 1998   Hannu Toivonen, "Sampling Large Databases for Association Rules", 134-145, Proc. VLDB'96, 1996   Dick Tsur, Jeffrey D. Ullman, Serge Abiteboul, Chris Clifton, Rajeev Motwani, Svetlozar Nestorov, Arnon Rosenthal, "Query Flocks: A Generalization of Association-Rule Mining" Proc. ACM-SIGMOD'98 1998   P3P Architecture Working Group, \223General Overview of the P3P Architecture\224, P3P-arch-971022 http://www.w3.org/TR/WD-P3P.arch.html 1997 


Plenary Panel Session 30 XML Databases   Moderator: Michael Carey, IBM Almaden Research Center USA Panelists Adam Bosworth, Microsoft Corporation USA David De Witt University of Wisconsin-Madison, USA Alon Levy University of Washington USA Bruce Lindsay IBM Almaden Research Center USA Jennifer Widom Stanford University USA Demo Session 1 Web Query Optimizer  661 V Zadorozhny L Bright L Raschid T Urhan and M Vidal ReQueSS: Relational Querying of Semi-structured Data  664 R Sunderraman The IDEAL Approach to Internet-Based Negotiation for E-Business  666 J Hammer C Huang Y Huang C Pluempitiwiriyawej M Lee H Li L Wang Y Liu and S Su READY A High Performance Event Notification Service  668 R Gruber B Krishnamurthy, and E Panagos A Multimedia Information Server with Mixed Workload Scheduling  670 G Nerjes DISIMA An Object-Oriented Approach to Developing an Image Database System  672 V Oria T Ozsu P Iglinski B Xu and L Cheng Demo Session 2 The Collaboration Management Infrastructure  677 H Schuster D Baker A Cichocki D Georgakopoulos and M Rusinkiewicz Assisting the Integration of Taxonomic Data The LITCHI Toolkit  679 I Sutherland J Robinson S Brandt A Jones S Embury W Gray R White and F Bisby TheaterLoc: Using Information Integration Technology to Rapidly Build Virtual Applications  681 G. Barish Y.4 Chen D Dipasquo, C Knoblock S Minton I Muslea and C Shahabi Lineage Tracing in a Data Warehousing System  683 Y Cui and J Widom xiii 


The Mentor-Lite Prototype A Light-Weight Workflow Management System  685 J Weissenfels M Gillmann 0 Roth, G Shegalov and W Wonner Location Prediction and Queries for Tracking Moving Objects  687 0 Wolfson B Xu and S Chamberlain Semiorder Database for Complex Activity Recognition in Multi-Sensory Environments  689 S Bhonsle A Gupta S Santini and R Jain Tutorial 1 Web Information Retrieval  693 M Henzinger Tutorial 2 Mobile and Wireless Database Access for Pervasive Computing  694 P Chrysanthis and E Pitoura Tutorial 3 Data Mining with Decision Trees  696 J Gehrke Tutorial 4 Directories Managing Data for Networked Applications  697 D Srivastava Tutorial 5 Indexing High-Dimensional Spaces Database Support for Next Decade\222s Applications  698 S Berchtold and D Keim xiv 


 T5.I2.D100K T10.I4.D100K T15.I4.D100K T10.I6.D400K T10.I6.D800K T10.I6.D1600K Optimizations across Databases 5 0 5 10 15 20 25 30 35 40 45 Improvement COMP TREE COMP-TREE 1 2 4 8 1 2 4 8 1 2 4 8 2 4 8 2 4 8 1 2 4 8 Processors Databases Figure 5 Effect of Computation and Hash Tree Balancing good as the COMP optimization The reason that the hash tree balancing is not suf\336cient to offset inherent load imbalance in the candidate generation in this case The most effective approach is to apply both optimizations at the same time COMP-TREE The combined effect is suf\336cient to push the improvements in the 40 range in the multiple-processor case On 1 processor only hash tree balancing is bene\336cial since computation balancing only adds extra cost 5.4 Short-circuited Subset Checking Figure 6 shows the improvement due to the short-circuited subset checking optimization with respect to the unoptimized version The unoptimized version is the Apriori algorithm due to Agrawal et al 5 The results are presented for dif ferent number of processors across dif ferent databases The results indicate that while there is some improvement for databases with small transaction sizes the optimization is most effective when the transaction size is large In this case we get improvements of around 25 r the unoptimized version To gain further insight into this optimization consider 336gure 7 It shows the percentage improvement obtained per iteration on applying this optimization on the T20.I6.D100K database It shows results only for the uni-processor case r similar results were obtained on more processors We observe that as the iteration k increases there is more opportunity for shortcircuiting the subset checking and we get increasing bene\336ts of up to 60 The improvements start to fall off t the high end where the number of candidates becomes small resulting in a small hash tree and less opportunity for short-circuiting It becomes clear that is an extremely effective 15 Proceedings of the 1996 ACM/IEEE Conference on Supercomputing \(SC\22296 0-89791-854-1/96 $ 10.00 ACM 


 T5.I2.D100K T10.I6.D800K T15.I4.D100K T20.I6.D100K procs across Databases 0 5 10 15 20 25 Improvement 1 2 4 8 Figure 6 Effect of Short-circuited Subset Checking 23456789101112 Iterations 0 10 20 30 40 50 60 improvement T20.I6.D100K Figure 7  Improvement per Iteration  proc   16 Proceedings of the 1996 ACM/IEEE Conference on Supercomputing \(SC\22296 0-89791-854-1/96 $ 10.00 ACM 


optimization for larger transaction sizes and in cases where there are large number of candidate k itemsets 6 Conclusions In this paper e presented a parallel implementation of the Apriori algorithm on the SGI Power Challenge shared memory multi-processor We also discussed a set of optimizations which include optimized join and pruning computation balancing for candidate generation hash tree balancing and short-circuited subset checking We then presented experimental results on each of these Improvements of more than 40 were obtained for the computation and hash tree balancing The short-circuiting optimization was found to be extremely effective for databases with large transaction sizes Finally we reported the parallel performance of the algorithm While we d good speed-up we observed a need for parallel I/O techniques for further performance gains References  R Agra wal T  Imielinski and A Swami Database mining A performance perspecti v e  I n IEEE Trans on Knowledge and Data Engg  pages 5\(6 1993  R Agra wal T  Imielinski and A Swami Mining association rules between sets of items in lar ge databases In Proc M SIGMOD Intl Conf Management of Data  May 1993  R Agra wal H Mannila R Srikant H T o i v onen and A I V erkamo F ast disco v ery of association rules In U F et al editor Advances in Knowledge Discovery and Data Mining  MIT Press 1996  R Agra wal and J Shafer  P arallel mining of association rules design implementation and e xperience Technical Report RJ10004 IBM Almaden Research Center San Jose CA 95120 Jan 1996  R Agra wal and R Srikant F ast algorithms for mining association rules In Proc 20th VLDB Conf  Sept 1994  M Cierniak W  Li and M J Zaki Loop scheduling for heterogeneity  I n 4th IEEE Intl Symposium on High-Performance Distributed Computing also as URCS-TR 540 CS Dept Univ f Rochester  Aug 1995  M Holsheimer  M  K ersten H Mannila and H T o i v onen A perspecti v e on databases and data mining In 1st Intl Conf Knowledge Discovery and Data Mining  Aug 1995  M Houtsma and A Swami Set-oriented mining of association rules In RJ 9567  IBM Almaden Oct 1993  H Mannila H T o i v onen and I V erkamo Ef 336cient algorithms for disco v ering association rules In AAAI Wkshp Knowledge Discovery in Databases  July 1994  J S P ark M Chen and P  S Y u  A n e f fecti v e hash based algorithm for mining association rules In Proc M SIGMOD Intl Conf Management of Data  May 1995 17 Proceedings of the 1996 ACM/IEEE Conference on Supercomputing \(SC\22296 0-89791-854-1/96 $ 10.00 ACM 


 J S P ark M Chen and P  S Y u  E f 336cient parallel data mining for association rules T echnical Report RC20156 IBM T J Watson Research Center Aug 1995  G Piatetsk y-Shapiro Disco v ery  presentation and analysis of strong rules In G P S et al editor  KDD  AAAI Press 1991  A Sa v asere E Omiecinski and S Na v athe An ef 336cient algorithm for mining association rules in large databases In Proc 21st VLDB Conf  1995  M J Zaki M Ogihara S P arthasarathy  and W  Li P arallel data mining for association rules on shared-memory multi-processors Technical Report 618 Department of Computer Science University of Rochester 618 1996 18 Proceedings of the 1996 ACM/IEEE Conference on Supercomputing \(SC\22296 0-89791-854-1/96 $ 10.00 ACM 


