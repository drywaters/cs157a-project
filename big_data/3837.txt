 153 A Multi-objective Scheme to Hide Sequential Patterns   Babak Rahbarinia Computer Engineering Department Islamic Azad University, Science and Research Branch Tehran, Iran babak.rhbrn@yahoo.com Hamid R. Arabnia Computer Science Department Georgia University Georgia, USA hra@cs.uga.edu Mir Mohsen Pedram Computer Engineering Department, Faculty of Eng Tarbiat Moallem University Karaj/Tehran, Iran pedram@tmu.ac.ir Zohreh Alavi Computer Engineering Department, Faculty of Eng Tarbiat Moallem University Karaj/Tehran, Iran zohreh.alavi@gmail.com   Abstract Notwithstanding the fact that data mining and particularly sequence mining have come to the help of database proprietors and experts in variety of fields by extracting the hidden knowledge in their raw data, they have provided an opportunity for adversaries to take advantage from this sensitive knowledge. So this work addresses the problem of sequential pattern hiding, and proposes an efficient and applicable algorithm which benefits from a multi-objective scheme to fulfill the requirements of the problem as well as maintaining database fidelity as much as possible Keywords-privacy preserving data mining; sequential pattern hiding; knowledge hiding I   I NTRODUCTION  Recent advancements in the data mining field have made opportunities to get access to the knowledge concealed in vast amount of data. Nonetheless, the divulged knowledge could also be considered adversely, inasmuch as every unauthorized person could elicit and use it to take advantage over database owners. To give a clear-cut example, consider a market which gathers its costumers' transactions, and by analyzing them extracts their purchase patterns, so by utilizing it could design promotions for other products. But it will lose its business situation over their competitors, if they get access to this sensitive knowledge, owing to the fact that this provides an opportunity for others to steal this market's business advantage. Clearly, an organization could neither keep its data hidden nor publish it thoroughly; a compromise should be made. Withholding others to take advantage of our data, and preserving our knowledge privacy are the main objectives of the knowledge hiding process and received conspicuous attention in recent years There are varieties of methods to achieve this, and majority of them try to alter the database, which to be published. The altered database is also called the sanitized database But majority of sanitization methods and algorithms have dealt with classic and simple forms of databases and knowledge so far, namely frequent itemsets and association rules. In [1  di s joi nt se n s it i v e as so ci a t i o n rules were hidden one at a time by reducing their support or confidence. The works in i n t r od uce d unknown values, and again aimed to reduce association rules' support or confidence. Author de f i ne d  a sanitization matrix  and used it to hide frequent patterns. The work by Oliveira et al con cer n ed wit h sharing t h e assoc i ation r u les an d hiding the sensitive ones rather than the data. An algorithm was introduced by Aggarwal et al. [8  f o r t h e proble m  of  protecting sensitive entries in a database. Authors of  presented a border-based approach to hide frequent itemsets A new form of practical knowledge, co-ocurring itemsets and approaches for hiding it were proposed by Abul and et al 11 But a relatively new and more structured form of data has been presented recently which is sequence mining [1 Incontrovertibly, knowledge preserving should be applied to this category of data, too, due to its more capability to cope with real world problems. Little research has been done in this field. Abul et al. [1 proble m i n t h eir work. So the aim of this paper is to propose a novel algorithm to surmount the problem of sequential pattern hiding in sequence databases in more expeditious ways than 13 This paper is organized as follows. In section II we present some background information and the notation used in the rest of the paper. In section III we introduce our approach to attack the sequential pattern hiding problem, an algorithm is presented, and enforcement of constraints is included, too. Section IV contains wide range of experiments and comparisons. Finally, we conclude the discussion in section V Volume 1  C 978-1-4244-5586-7/10/$26.00      2010 IEEE 


 154 II  P ROBLEM S TATEMENT  In this section, first some basic definitions of sequence data mining, which are based on e s tated, an d then  a  depth discussion about the problem of sequential pattern hiding will be followed A sequence is an ordered list S = s 1 s 2 s l where each s i 1 i  l is an itemset, and is called an element which is denoted as x 1 x 2 x m  such that each x k 1  k  m  and is a finite set of distinct items. A sequence a = a 1 a 2 a n is called a subsequence of another sequence b = b 1 b 2 b m and b a super-sequence of a if there exists integers 1  j 1 j 2  j n m such that a 1   b j1 a 2   b j2 a n   b jn In addition, a sequence database SDB contains a set of sequences. The support of a sequence a in a SDB is the number of sequences in SDB that are super-sequences of a  sup SDB S   SDB subsequence of S A sequence a is called a sequential pattern in SDB if sup SDB min-sup  Given a sequence S=s 1 s n and a subsequence S'=s 1 s m  a set of positions i 1 i 2 i m  is called an occurrence of S in S if 1  i 1 i m n and s k s ik for each 1  k  m  abd\bb\(cbd\ and S' = \(cd\bb Occurrences of S' in S are {4, 5, 6}, {4, 5, 7}, {4, 5, 8}, {4, 6 7}, {4, 6, 8}, and {4, 7, 8}, which occurrences' indices correspond to element numbers Given a sequence database and a minimum support threshold, the sequential pattern mining problem is to find the complete set of sequential patterns in the database Definition \(related occurrence set of an item in a sequence given a sequence S a sequential pattern SP and an item x which is the i th item from SP the related occurrence set of x from SP in S encircles item numbers in S  which correspond to item x from SP and is denoted as ros sps x:i  cbd\, and SP cd\the related occurrence set of 3 th item from SP i.e b  in S is ros cd\bbs b:3\{7, 9, 10  Definition \(Sensitive Patterns Sensitive patterns are sequential patterns which are determined sensitive by field experts, and must be hidden. In addition, we refer to items in sensitive patterns as sensitive items Problem definition Given a sequence database SDB a sensitive pattern set SPS and a hiding threshold  the goal is to minimally alter the SDB to hide all of sensitive patterns in it by reducing their support to   There are four important issues in the definition. First the database's sequences should be altered. This will be done by replacing some of their element's items by unknown value We refer to the number of item changes as distortions  Second, the term "minimally" im poses that disto rtions should be as few as possible, due to the fact that distortions decline data's quality. Then, the support of sensitive patterns must reduce to exactly  because excessive support declining diminishes database's quality, but in th e aut ho r s requ ir e  that sensitive patterns' support must not be more than  so they permit excessive support declining in their algorithm Next, in our work we cope with complex sequential patterns rather than the simple form. Simple sequences, which are the subject of conta i n a s ingle ite m  a s  the i r  ele m e nt s instead of itemsets III  T HE P ROPOSED A PPROACH  The proposed approach and its comparison h e  presentation of the hiding algorithm, and handling constraints are discussed in this section A  Overview of the Proposed Hiding Approach The definition of the problem is very generic that needs further clarification in every aspect of it.  Firstly, we need to explain how a sequential pattern vanishes from a sequence to do this all the occurrences of the sequential pattern must be cleared from the sequence, such that the sequential pattern no longer is supported by the sequence. Again, consider the abd\bb\(cbd\ and the sequential pattern SP = \(cd\hide SP it is adequate to select one of its items, for instance, item c from first element of SP i.e. the item number 1, and to replace all items in S with "?" which are included in ros cd\s c:1\{4 So the sanitized abd\bb\(cbd\. Note that the other item c in the S, the 11 th item, remains intact Other alterations are plausible. For example, the sanitized c?d\ by choosing item number 3 from SP and by replacing "?" with its related occurrences. Distinctly, this would not be a good solution owing to its imposed distortions. Now, consider a case which cbd\mprises more than one sensitive pattern: ac\(ad\ and \(cd\tized S bab\(?d\\(abd\\(cbd\gained by solely one distortion because ros ac\(ad\s c:2\ros cd\s c:1\ = {4 As a result the sequence should be sanitized with fewer distortions as possible. It is worth mentioning that optimal sanitization which is hiding all occurrences of sensitive patterns in a sequence is NP-Hard [13  To clarify the sanitization process take into account our sample database in table I, the hiding threshold 1 and a sensitive pattern set cd\be which sup\(ac\(ad\\2  sup\(\(cd\bb\ = 3 and sup\(ebe\ = 2 So the patterns in SPS should be hidden by reducing their supports to   We introduce a multi-objective sequence selection framework to surmount the sensitive patterns hiding problem which first analyzes each sequence of the database and finds the best candidate solution to sanitize it, and then by comparing all best candidates in the database, it selects the winner sequence, i.e. the best overall candidate, and applies it to the corresponding sequence, so the support of some sensitive patterns will reduce by one unit. This process will iterate until all sensitive patterns' supports ascend to the exact value of   TABLE I  S AMPLE D ATABASE  Sequence ID \(s-id Sequence abd\bb\(bcd 2 \(cd\ac\(ad\b\(ad 3 \(cd\b\(cd\bebe  Volume 1 


 155 The candidate solution selection process should consider the following factors 1  Number of sensitive patterns SP hich their supports will be reduced one unit by the solution 2  Number of distortions D the candidate solution 3  Number of non-sensitive patterns which their supports will reduce by one unit by the solution  NSP  Factor SP holds positive effect and should be maximized while the effects of D and NSP is negative and need to be minimized. Thus, the problem of hiding all sequences s  SPS  in sequential data base SDB is defined as to find s' as a subsequence of s to be hidden and changing SDB into SDB  so that     Max SP\(s'\, Min D\(s'\ NSP\(s 1  s.t. s' subsequence of s, for all s  SPS  sup SDB s\ , for all s  SPS  To solve the above multi-objective optimization problem a weighted summation of the above objectives is introduced  s'\NSP\(s  SP\(s    D\(s  NSP\(s  2   and  0    The sequence analysis process, which results in the best solution, is conducted by constructing a candidate tree The candidate tree is composed of all possible solutions to sanitize a sequence in such a way that each of its nodes is a solution, so each of them encircles the following information 1\ the sensitive items involved, and 2\ the associated objective functions or a 3-tuple, i.e SP, D, NSP Fig. 1 depicts the candidate tree for the sequence with s-id = 3 in table I. This sequence comprises two sensitive patterns cd\. For the sake of simplicity the effect of NSP  is ignored 0 The number of items in a sensitive pattern is included in the repeated items to help distinguish them from each other An important point about the candidate tree is that first it examines solutions which are composed of a single sensitive item. These solutions could be seen in the first level of the candidate tree in Fig. 1, and then pairs of solutions with a sensitive item are amalgamated, and the result will be the solutions with couple of sensitive items, but as it is clear in the candidate tree of Fig. 1, none of the sensitive items from a same sensitive pattern are coalesced; there is no need to hide a sensitive patterns by hiding more than one of its items in the sequence. As a result, to avoid this, some amalgamation criteria are considered: solutions which construct the i th level of the candidate tree must incorporate the combination of i items from i distinct sensitive patterns so   To yield solutions with two sensitive items all the solutions which contain one item and are compatible with the above criteria will participate   Solutions with three or more sensitive items are produced in a similar fashion So if a candidate tree is merely constructed on a single sensitive pattern, no combination will be necessary Therefore, by using this bunch of rules when constructing a candidate tree a huge number of unnecessary and useless solutions will be pruned beforehand So far the sequence with s-id = 3 is analyzed by constructing its candidate tree. Now, based on the objective function F the best solution will be determined. In aggregation, there are four combinations of SP, D in the candidate tree in Fig. 1: \(1, 2\, \(2, 3\, \(1, 1\d \(2, 2 assume 0.5, 	 = 1 and F\(1,2  1.5, F\(2,3  2, F\(1,1   0.5 and F\(2,2  1 so the third solution will be the winner. To exhibit the significance of the weighted F to decide the winner, consider another example with 1 0.5 The winner solution in this case is the fourth solution with F\(2,2\1 The winner solutions in both cases are circumscribed in Fig. 1. Moreover, it worth mentioning that if two or more solutions with the same value for the F  function have the highest value among other solutions, the winner is selected based on a preconceived preference. For instance, one may prefer fewer distortions In Fig. 1 distortions number for solutions is calculated based on the related occurrence sets. For instance, for the node b:4,b\(2,2 which is equivalent to one of the winners ros cd\(bb\id:3 b:4  ros ebes-id:3 b:2\ = {6,8  8} = {6,8  which means two distortions are required Candidate trees of other two sequences in the sample database in table I will be constructed, and the overall winner will be pointed out and applied to the corresponding sequence. Assuming 0.5, 	 = 1 table II shows overall winners and their results on the database and supports of sensitive patterns. As a result, by only two distortions the sample database is sanitized, and, furthermore, this approach does not obtrude any extra distortions by reducing the support of some sensitive patterns below the  In the proposed approach in [1 the auth ors fi r st sort t h e  database's sequences in ascending order according to the number of sensitive pattern occurrences in them, second select the first SDB   sequences, where SDB is the size of the database, then sanitize them by hiding all the occurrences of sensitive patterns in them. So this method necessitates that when a sequence is selected for sanitization all the sensitive patterns must be deleted from it, while it is not necessary; we should consider the entire database for sanitization not just a single sequence at a time; in addition by sanitizing all the sensitive patterns from the selected sequence, we might lose the opportunity to sanitize the database with fewer distortions. In the table II in the second iteration the sequence with s-id = 2 is selected as the overall winner, but after altering it, it still contains the sensitive pattern ac\(ad  Moreover, by selecting top SDB   sorted sequences, some sensitive patterns' supports might descend below the  which will cause unnecessary distortions. For instance, the sequences in table I contain 7, 5, and 4 occurrences of sensitive patterns respectively, so according to the method of [1 e s equences wit h s-id = 3 and s-id 2 will be sanitized in order with 2 and 3 distortions respectively. So with 5 distortions the database is sanitized Furthermore, after the sanitization sup\(ebe\ = 0 but our approach imposes neither excessive distortions, nor excessive support declination Volume 1 


 156   cd\(bb\                                                                                                         ebe  c\(1,2\                      d\(1,2\                             b:3\(1,2\                         b:4\(2,2\                      e 1\(1,1\                 b\(1,1\                e:3\(1,1     c,e:1\(2,3\     c,b\(2,3\     c,e:3\(2,3\     d,e:1\(2,3\     d,b\(2,3\    d,e:3\(2,3\    b:3,e:1\(2,3\     b:3,b\(2,3\     b:3,e:3\(2 3\    b:4,e:1\(2,3\     b:4,b\(2,2\  b:4,e:3\(2,3   Figure 1  Candidate tree for the sequence with s-id = 3 in table I TABLE II  S ANITIZATION P ROCESS FOR S AMPLE D ATABASE IN T ABLE I Iteration Data base Winner \(s-id Replace location Supports ac\(ad cd\bb ebe 1 abd\\(cbd cd\ac\(ad\b\(ad cd\b\(cd 1 4 1 2 2 2 abd\\(cbd cd\ac\(ad\?\(ad cd\b\(cd 2 10 1 1 1 B  The Proposed Algorithm The novel hiding algorithm MOSS \(Multi-objective Sequence Selection\ented in Fig. 2, and summarizes our hiding framework. In this algorithm DBSeqsToCheck  which at first holds the s-id of all sequences  is used to determine which SDB sequences should be checked in the next iteration. The algorithm iterates until all sensitive patterns become hidden. In the first step it finds the best candidate solution for each sequence, and then finds the best solution for the entire SDB This solution is applied to the corresponding sequence, and as a result of that supports of sensitive patterns in that sequence will be reduced by one unit. In this point those sensitive patterns which are successfully hidden are deleted from the SPS  One of the features of our algorithm is that after the first iteration, which in it all sequences in SDB are checked it solely rechecks the updated sequence as well as those sequences which contain the hidden sensitive patterns given the fact that their candidate tree will not include the hidden sensitive patterns anymore. Other sequences candidate trees will remain intact. Therefore, a small number of sequences are checked in each iteration  Algorithm: MOSS INPUTS SDB, SPS  OUTPUT  sanitized SDB \(SDB  DBSeqsToCheck \012 all s-ids While |SPS| > 0 1  For each s-id in DBSeqsToCheck 1.1  Generate solutions whic h consider one sensitive item for deletion 1.2  Combine solutions to generate solution tree 1.3  Compute rank of each solution 1.4  bestSolutions \012 highest ranked solution in the solution tree 2  Find best overall solution 3  Apply best overall solution and update SDB 4  Decrease support of affected sensitive patterns 5  For each sp in SPS 5.1  If sup\(sp\=  then remove sp from SPS 6  Empty DBSeqsToCheck 7  DBSeqsToCheck \012 updated sequence's s-id 8  DBSeqsToCheck \012 s-id of sequences which contain removed sensitive patterns 9  For each s-id in DBSeqsToCheck 9.1 Delete the corresponding bestSolution  Figure 2  MOSS algorithm C  Handling Constraints The two types of constraints namely max/min gap and max/min distance could conveniently be enforced to the hiding algorithm; no change is required in the algorithm in Fig. 2, and a solitary part that needs reconsideration is the definition of the related occurrence set. If a sequence S contains a subsequence SP then a max/min gap constraint demands that the number of elements in S which are between every two elements of SP be less than max + 1   and more than min Ö 1 ed occurrence set is denoted as gapros SPS x:i, min, max Moreover, a max/min distance constraint obliges that the number of elements in S which are between the first and the last elements of SP be in the interval [min, ma I n thi s case  the related occurrence set is denoted as disros SPS x:i, min max The following corollaries are obvious about the related occurrence sets   gapros SPS x:i, min, max   ros SPS x:i  3   disros SPS x:i, min, max   ros SPS x:i  4   So to generate the newly introduced related occurrence sets, the ros SPS x:i is computed at first, and then those item numbers which cannot satisfy the constraints will be excluded from it. For the sequence with s-id = 1 in table I gapros ac\(ad\s-id=1 a:3, 1, 2\ = {10  ros ac\(ad\s-id=1 a:3 5, 10 In another example disros ac\(ad\s-id=1 a:3, 0, 1  In addition, these constraints could be forced into the hiding approach simultaneously IV  E XPERIMENTAL R ESULTS  We evaluate our algorithm with three datasets. The first dataset is a randomly generated dataset over the alphabet {a, b, c, d} which contains 10000 complex sequences \(sequences which are compatible with the definition of a sequence in section 2\The second dataset is the Molecular Biology dataset [15  wi t h 106 DNA  Volume 1 


 157 sequences of length 57. The MSNBC.com Anonymous Web dataset [16 is our t h i r d d a taset wh i c h in co r p o r ates 989818 sequences over integers from 1 to 17 as its items Each sequence is page views of a user during a 24-hour period, and the first 5000 sequences have been considered in the experiments. We denote these datasets as Random  DNA and WEB respectively We compared our algorithm with the other sequence hiding approac whic h we r e f er to i t as OSH Number of distortions is one of our measurements, and the other one is infidelity measure which encompasses those nonsensitive patterns which their support fall below the support threshold after sanitization Randomly selected sensitive patterns and other information regarding the datasets are shown in table III Throughout the tests we use a certain notation to refer to the algorithm and other information which is <algorithmname, \(,,\>. The second and third elements are optional. Because the algorithm in [13 can not dea l with complex sequences, we adopt it to accept them In the figures the x-axis is always the hiding threshold i.e. , and the y-axis is either the distortion or infidelity Fig. 3.a, 3.b, and 3.c depict the number of distortions in Random, DNA, and WEB datasets respectively. The gradual entry in <MOSS-\(1,gradual,0\> in Fig. 3.a indicates that  gradually increases from 0.1 to 1 as ascends. To further discuss the impact of objective function the MOSS results are presented with different settings of the 3-tuple \(,,\. As it is clear in Fig. 3.a, 3.b and 3.c the MOSS with/without constraint surpasses the OSH with/without constraint Fig. 4.a, 4.b, and 4.c show the infidelity measure in datasets, and prove the better results of MOSS Furthermore, the effect of , which aims to preserve nonsensitive patterns according to the objective function, is eminent in the figures, but we have to say that this often has a negative effect on distortions, which is clear in Fig 3.a when comparing <MOSS, \(1,1,1\> with <OSH>, but on the other hand, the infidelity measure decreases dramatically when comparing the results with the effect of with those that ignore it TABLE III  D ATASETS I NFORMATION  Dataset Support threshold Patterns Sensitive patterns Random 1000 837 ab DNA 106 35628 caatttgcaa, ggcggac WEB 100 109 1 6 6, 2 2 1 V  C ONCLUSION  In this paper we addressed the problem of hiding sequential patterns. The main contributions of this work over the other algorithm in the literature [1  cou ld  be summarized in dealing with complex form of sequences rather than simple sequences, and presenting a more efficient algorithm which hides sensitive patterns from a sequence database with fewer distortions, so data quality is preserved. Furthermore, we presented a highly flexible weighted objective function to find best solution among all candidate solutions to sanitize sequences. Moreover handling constraints was another topic of discusstion Experimental evaluations carried out on three datasets with distinct characteristics to prove the promised functions of both the algorithm and the objective function. The results indicated that the proposed algorithm surpasses the existing one significantly   Random dataset 3.a 0 2000 4000 6000 8000 10000 12000 0 100 200 300 400 500 600 700 800 900 hiding threshold distortion MOSS, \(1,gradual,0 MOSS, \(1,1,1 MOSS, \(1,1,0\ gap2,5 MOSS, \(1,1,0\is6,9 OSH OSH, gap2,5    DNA dataset 3.b 0 100 200 300 400 500 600 700 0 102030405060708090100 hiding threshold distortion MOSS, \(1,gradual,0 MOSS, \(1,1,0 MOSS, \(1,0.1,0 MOSS, \(1,1,0\gap4,9 MOSS, \(1,1,0\ dis15,22 OSH OSH, gap4,9    WEB dataset 3.c 0 100 200 300 400 500 600 700 0 102030405060708090 hiding threshold distortion MOSS, \(1,1,0 MOSS, \(1,1,1 OSH  Figure 3  Distortions in Random, DNA, and WEB datasets  Volume 1 


 158  Random dataset 4.a 150 170 190 210 230 250 270 290 310 330 350 0 100 200 300 400 500 600 700 800 900 hiding threshold infidelity MOSS, \(1,gradual,0 MOSS, \(1,1,1 OSH  DNA dataset 4.b 0 5000 10000 15000 20000 25000 30000 35000 40000 0 10 203040 5060 708090100 hiding threshold infidelity M OSS, \(1,gradual,0 M OSS, \(1,1,0  M OSS, \(1,0 1,0 OSH WEB dataset 4.c 0 2 4 6 8 10 12 0 102030405060708090 hiding threshold infidelity MOSS, \(1,1,0 MOSS, \(1,1,1 OSH  Figure 4  Infidelities in Random, DNA, and WEB datasets    R EFERENCES  1  E. Dasseni, V. S. Verykios, A. K. Elmagarmid, and E. Bertino Hiding Association Rules by Using Confidence and Support Proc. 4th International Workshop on Information Hiding, SpringerVerlag, 2001, pp. 369-383 2  V. S. Verykios, A. K. Elmagarmid, E. Bertino, Y. Saygin, and E Dasseni, çAssociation rule hiding,é IEEE Transactions on Knowledge and Data Engineering, vol. 16, issue 4, 2004, pp. 434447, doi: 10.1109/TKDE.2004.1269668 3  Y. Saygin, V. S. Verykios, and A. K. Elmagarmid, çPrivacy Preserving Association Rule Mining,é Proc. 12th International Workshop on Research Issues in Data Engineering: Engineering ECommerce/E-Business Systems \(RIDE'02\omputer Society, 2002, p. 151 4  Y. Saygin, V. S. Verykios, and C. Clifton, çUsing Unknowns to Prevent Discovery of Association Rules,é ACM SIGMOD Record vol. 30, issue 4, 2001, pp. 45-54 5  E. D. Pontikakis, Y. Theodoridis, A. A. Tsitsonis, L.  Chang, and V S. Verykios, çA Quantitative and Qualitative Analysis of Blocking in Association Rule Hiding,é Proc. ACM workshop on Privacy in the electronic society \(WPES'04 6  G. Lee, C. Chang, and A. L. P. Chen, çHiding Sensitive Patterns in Association Rule Mining,é Proc. 28th Annual International Computer Software and Applications Conference \(COMPSAC'04 IEEE Computer Society, 2004, pp. 424-429 7  S. R. M. Oliveira, O. R. Zaiane, and Y. Saygin, çSecure Association Rule Sharing,é Proc. 8th Pacific-Asia Conference Advances in Knowledge Discovery and Data Mining \(PAKDD'04 Springer, 2004, pp. 74-85 8  C. C. Aggarwal, J. Pei, and B Zhang, çOn Privacy Preservation Against Adversarial Data Mining,é Proc. 12th ACM SIGKDD international conference on Know ledge discovery and data mining ACM, 2006, pp. 510-516 9  X. Sun and P. S. Yu, çA Border-based Approach for Hiding Sensitive Frequent Itemsets,é Proc. 5th IEEE International Conference on Data Mining \(ICDM'05\EEE Computer Society 2005, pp. 426-433, doi: 10.1109/ICDM.2005.2 10  G. V. Moustakides and V. S. Verykios, çA Max Min Approach for Hiding Frequent Itemsets Data & Knowledge Engineering Elsevier Science Publishers B. V vol. 65, issue 1, 2008, pp. 75-89 doi: 10.1016/j.datak.2007.06.012 11  O. Abul. çHiding Co-Occurring Frequent Itemsets,é Proc. 2nd International Workshop on Privacy and Anonymity in the Information Society \(PAISê09\, in conjunction with ICDT/EDBT'09, 2009 12  R. Agrawal and R. Srikant, çMining Sequential Patterns,é Proc 11th International Conference on Data Engineering \(ICDE95 IEEE Computer Society, 1995, pp. 3-14 13  O. Abul, M. Atzori, F. Bonchi, and F. Giannotti, çHiding Sequences,é Proc. IEEE 23rd International Conference on Data Engineering Workshop \(ICDEW 2007\EEE Computer Society 2007, pp. 147-156, doi: 10.1109/ICDEW.2007.4400985 14  G. Dong and J. Pei, Sequence Data Mining, 1st ed., Springer, 2007 15  C. Harley, R. Reynolds, UCI Machine Learning Repository http://archive.ics.uci.edu/ml/datasets/Molecular+Biology+\(Promot er+Gene+Sequences 16  David Heckerman, UCI Machine Learning Repository http://archive.ics.uci.edu/ml/datasets/MSNBC.com+Anonymous Web+Data    Volume 1 


 F  To check the validity of association rules  E quatio n  1  is use d  as  it is done i n  th e  last column of  Figur e  7   G  Select one  of th e  rules which have Improvement  value more than   1     H  In case if there is another job asking to get the files  and the s e files are available in the same sites then  choose another rule to serve the new request  Otherwise  apply  Aprior i  algorithm for recent STTs  of  new replicas sites    VI I   I NTERPRETING THE  R ESULT S    This section means to explain how the association  rul e s work better than the traditional and random methods  As it is shown in  Figure 7 after applying  Aprior i  algorithm  we get  602  different rules which can be used to select the  best combination of replica sites   Let us explain Figure 7  in details    Rule #1: if Site\(s S 4  S 7  are selected then this implies  that site\(s S 3  can also be selected at the same time. This  rule has 100% confidence    In other words, it means if site  S 4   and  S 7  are selected to  work together to transfer the requested files, t h en this  implies site\(s  S 3  can also be selected to share the work at  the same time. This rule has confidence  100  This  particular rule has  confidence  of  100  meaning that  S 4  S 7   and  S 3  can be selected as a best set of replicas by  Replica  Manage r  to ge t  requested files. To compute the correlation  of this rule and see how far it is better than choosing the site  randomly, we use an Improvement equation     indicates that it has support of  26  transactions, meaning that in transaction  Single Trip  Time  Table  there are  2 6  concurrent uncongested trips of  S 4  S 7   i.e. these sites have similar network conditions in particular  time      indicates the total number of transactions  involving uncongested trips of  S 3   in  Rule 1  is equal to  174    This is a piece of a side information; it is not involved  in calculating the confidence or support for the rule itself       is the number of transactions where   S 4   S 7 as well as   S 3 has uncongested trips. In  Rule 1  it is equal  to  2 6       or   indicates how much  more likely we are to encounter  S 4  and  S 6  transaction if we  consider just those transactions where  S 3  S 5 and  S 8  have  uncongested trips. As compared to the entire population of  the transactions, it's t h e  confidenc e  divided by  support \(c   where the latter is expressed as a percentage   For  Rule 1 the  confidenc e is  100   support \(c  in  percentage   174/194\*100 = 89.6 9 So, th e    Lift ratio = 100/89.69.1 = 1.1   As it is clearly shown in  Figure 7  some r u les with  an improvement value less than one means this is an  unreliable rule. Whereas the rule with a value more than one  means this rule is better than random replica selection with  number of time equal to improvement value as it is shown in  Figure 8                   When improvement value is more than 1 it is better to use  EST to select replica sites, because it selects the sites able to  work simultaneously    I n  Figure  9  we sho w  the  comparison between EST and  traditional model using highest bandwidth a s  a criterion to  select the best replica. As we can observe our technique has  a better performance most of the times because it selects the  sites which have the stable links. In traditional method the  site which has the highest bandwidth does not always me a n  to be the best because sometimes this highest bandwidth  link can be congeste d   Let us declare more by the following  scenario  o f  Figure 1 0 suppose   S 0   be the computing site  and let   S 1  S 3   S 1 4   be replica sites  Red stars referring to  congested router s   Using traditional selection method the  file will be got from S14 since it has less number of Hops  routers\ and highest and also has highest bandwidth link         Figure 8. Improvement ratio for different rule s  Figure 9. Traditional selection strategy and ES T    
193 


               Using  ES T the replica   S 3    is selected as a best replica  because the link b etween  C S  and  R S  is uncongested     VII I   C ONCLUSIO N  In this paper we presented a dynamic replica  selection strategy that aims to adapt at ru n time its criteria to  flexible QoS binding contracts specified by the service  provider and/or the client. The adapta b ility feature  addressed by our replica selection strategy is inferred from  the observation that the basic metrics, which influence the  QoS that the user perceives when accessing a replica  depend directly on the application being replicated and on  the cli e nts\222 preferences. To reach this objective that, we  used   the concept of association rules of data mining  approach to the most stable links sites in order to reduce the  searching space the response time and network resources  consumed    A CKNOWLEDGEMENT S  Au t hors wish to express their sincere thanks to  Prof. Arun Agarwal, from GridLabs Department of  Computer and Information Sciences, University of  Hyderabad, India for providing all the infrastructural and  computational support required to carry out this work  His  academic suggestions to improve the quality of the work are  also highly appreciated and acknowledged   R EFERENCE S     M  Rashedur Rahma n   Ken Barke r   Reda Alhaj j    Replica  selection in grid environment:a dat a mining approac h    Distributed systems and grid computing \(DSGC\,pp: 695  226  700  2005    J. Gwertzman and M. Seltzer    The case for geographical  push  cashing  In Proceeding of the 5th Workshop on Hot ZTopic in  Operating Systems, 1995     R. Kavitha, I. Foster   Design and evaluation of replication  strategies for a high performance data gri d  in, Proceedings of  Computing and High Energy and, Nuclear P h ysics, 2001   S. Vazhkudai, J. Schopf, I. Foster   Predicting the performance of  wid e area data transfer s  in: 16th International PDPS, 2002   S. Vazhkudai, J. Schopf   Using regression techniques to predict  large data transfer s  in: Computing: Infrastru c ture and  Applications, The International Journal of High Performance  Computing Applications, IJHPCA , August, 2003   A. Abbas, Grid Computing    A Practical Guide to Technology  and  A PPLICATION S    2006   http://goc.pragm a grid.net/wiki/index.php/UoHy d   S. Vazhkudai, S Tuecke, I. Foster   Replica selection in the  globus data gri d  in: First IEEE/ACM International Conference  on Cluster Computing and the Grid, CCGrid 2001   J. Guyton and M. Schwartz   L o cating nearby copies of replicated  internet server s    In Proceeding of ACM SIGCOM M 222  95, 1995   A. Tirumala, J. Ferguson, Iperf 1.2   The TCP/UDP Bandwidth  Measurement Tool, 2002   R. Wolski, Dynamically forecasting network performance using  the Network Weat h er Service, Cluster Computing \(1998   Yunhong Gu, Robert L. Grossman   UDT: UD P based data  transfer for hig h speed wide area network s  Computer  Networks, Volume 51, Issue 7, 16 May  2007, Pages 1777 1799  Elsevier   R.M. Rahman, K. Barker, R. Alhajj   Predicting the performance  of GridFTP transfer s  in: Proceedings of IEEE Symposium of  Parallel and Distributed Systems, 2004, New Mexico, USA, p  238a   J. F. Kurose, K.W. Ross   Compute r  Networking A To p Down  Approach Featuring the Interne t 3rd edition   S. Venugopal, . R. Buyya,"The Gridbus Toolkit for Service  Oriented Grid and Utility Computing: An Overview and Status  Report"2004   R   Agrawal  T  Imielinski  A.Swami    Mining associatio n  rules  between sets of items in large database s  In: Proc. ACM  SIGMOD Intl. Conf. Management Data, 199 3  R  M Rahman, K Barker and R Alhajj   Replica selection  strategies in data gri d    Jou r nal of Parallel and Distributed  Computin g   Volume 68, Issue 1 2 Pages 156 1 1574, December  2008   A. Jaradat, R. Salleh and A. Abid   Imitating K Means to  Enhance Data Selectio n  Journal of Applied Sciences 9 \(19  356 9 3574, 2009, ISSN 181 2 5654, Asian Ne t work for Scientific  Informatio n 2009   S. Venugopal, . R. Buyya, K. Ramamohanarao, "A taxonomy of  Data Grids for distributed data sharing, management, and  processing". ACM Comput. Surv. 38, 1 \(Jun. 2006  AC M   New  York, NY, US A  http://www.resample.com/xlminer/help/Index.ht m  A   K Pujar i    Data mining technique s    Hyderabad : Universities  Press, 2002   G. Williams, M. Hegland and S. Roberts   A Data Mining  Tutoria l  IASTED International Conference on Parallel and  Distributed Computing and Networks P DCN\22298\ 14 December  199 8   T  Ceryen, and M. Kevin, 2005   Performance characterization of  decentralized algorithms for replica selection in dstributed object  system s  Proceedngs of 5th International Workshop on Software  and Performance, July 11  14, Palm a de Mallorca, Spain, pp  25 7 262    F  Corina, and M. Mesaac, 2003  A scalable replica selection  strategy based on flexible contract s  Proceedings of the 3rd  IEEE Workshop on Internet Applications, June 2 3 24, IEEE  Computer Society Washington, DC, USA p p: 9 5 99   R. M. almuttari, R. Wankar, A. Negi, C.R. Rao   Intelligent  Replica Selection Strategy for Data Gri d    In proceeding of the  1 0 t h  International conference on Parallel an d  Distributed  Proceedin g  Techniques and Applications  IEEE Computer  Society W a shington, DC  WorldComp2010, GCA2010   LasVega s   USA  Volume3  pp: 9 5 100  July 1 2 1 5 201 0   Cisco Distributed Director  http://www.cisco.com/warp/public/cc/pd/cxsr/dd/index.shtm l  M   Sayal, Y. Breitbart, P. Scheuermann, R  Vingralek   Selection  algorithms for replicated web server s  In Proceeding of the  Workshop on Internet Server Performance,1998   E. Zegura, M. Ammar, Z. Fei, and S. Bhattacharjee   Applicatio n layer anycasting: a se r ver selection architecture and  use in a replicated web servic e  IEEE/ACM Transactions on  Networking, vol. 8, no. 4, pp. 45 5 226 466, Aug. 2000     Figur e  10   Data Grid and their associated network geometr y   
194 


Application of Chaotic Particle Swarm Optimization Algorithm in Chinese Documents Classification 763 Dekun Tan Qualitative Simulation Based on Ranked Hyperreals 767 Shusaku Tsumoto Association Action Rules and Action Paths Triggered by Meta-actions 772 Angelina A. Tzacheva and Zbigniew W. Ras Research and Prediction on Nonlinear Network Flow of Mobile Short Message Based on Neural Network 777 Nianhong Wan, Jiyi Wang, and Xuerong Wang Pattern Matching with Flexible Wildcards and Recurring Characters 782 Haiping Wang, Fei Xie, Xuegang Hu, Peipei Li, and Xindong Wu Supplier Selection Based on Rough Sets and Analytic Hierarchy Process 787 Lei Wang, Jun Ye, and Tianrui Li The Covering Upper Approximation by Subcovering 791 Shiping Wang, William Zhu, and Peiyong Zhu Stochastic Synchronization of Non-identical Genetic Networks with Time Delay 794 Zhengxia Wang and Guodong Liu An Extensible Workflow Modeling Model Based on Ontology 798 Zhenwu Wang Interval Type-2 Fuzzy PI Controllers: Why They are More Robust 802 Dongrui Wu and Woei Wan Tan Improved K-Modes Clustering Method Based on Chi-square Statistics 808 Runxiu Wu Decision Rule Acquisition Algorithm Based on Association-Characteristic Information Granular Computing 812 JianFeng Xu, Lan Liu, GuangZuo Zheng, and Yao Zhang Constructing a Fast Algorithm for Multi-label Classification with Support Vector Data Description 817 Jianhua Xu Knowledge Operations in Neighborhood System 822 Xibei Yang and Tsau Young Lin An Evaluation Method Based on Combinatorial Judgement Matrix 826 Jun Ye and Lei Wang Generating Algorithm of Approximate Decision Rules and its Applications 830 Wang Yun and Wu-Zhi Qiang Parameter Selection of Support Vector Regression Based on Particle Swarm Optimization 834 Hu Zhang, Min Wang, and Xin-han Huang T-type Pseudo-BCI Algebras and T-type Pseudo-BCI Filters 839 Xiaohong Zhang, Yinfeng Lu, and Xiaoyan Mao A Vehicle License Plate Recognition Method Based on Neural Network 845 Xing-Wang Zhang, Xian-gui Liu, and Jia Zhao Author Index 849 
xiii 


   C4.2 Open GL has excellent documentation that could help the developer learn the platform with ease C4.3 Developer has very little ex perience in working with Open GL platform  For our case study, alternative B i.e. Adobe Director was the most favorable alternative amongst all the three. It catered to the reusability criteria quite well and aimed at meeting most of the desired operational requirements for the system   6. CONCLUSION & FUTURE WORK  The main contribution of this paper is to develop an approach for evaluating performance scores in MultiCriteria decision making using an intelligent computational argumentation network. The evaluation process requires us to identify performance scores in multi criteria decision making which are not obtained objectively and quantify the same by providing a strong rationale. In this way, deeper analysis can be achieved in reducing the uncertainty problem involved in Multi Criteria decision paradigm. As a part of our future work we plan on conducting a large scale empirical analysis of the argumentation system to validate its effectiveness   REFERENCES  1  L  P Am g o u d  U sin g  A r g u men ts f o r mak i n g an d  ex p lain in g  decisions Artificial Intelligence 173 413-436, \(2009 2 A  Boch m a n   C ollectiv e A r g u men tatio n    Proceedings of the Workshop on Non-Monotonic Reasoning 2002 3 G  R Bu y u k o zk an  Ev alu a tio n o f sof tware d e v e lo p m en t  projects using a fuzzy multi-criteria decision approach Mathematics and Computers in Simualtion 77 464-475, \(2008 4 M T  Chen   F u zzy MCD M A p p r o ach t o Selec t Serv ice  Provider The IEEE International Conference on Fuzzy 2003 5 J. Con k li n  an d  M. Beg e m a n   gIBIS: A Hypertext Tool for Exploratory Policy Discussion Transactions on Office Information Systems 6\(4\: 303  331, \(1988 6 B P  Duarte D e v elo p in g a p r o jec ts ev alu a tio n sy ste m based on multiple attribute value theroy Computer Operations Research 33 1488-1504, \(2006 7 E G  Fo rm an  T h e  A n a l y t ic Hier a rch y P r o cess A n  Exposition OR CHRONICLE 1999 8 M. L ease  an d J L  L i v e l y  Using an Issue Based Hypertext System to Capture Software LifeCycle Process Hypermedia  2\(1\, pp. 34  45, \(1990 9  P e id e L i u   E valu a tio n Mo d e l o f Custo m e r Satis f a c tio n o f  B2CE Commerce Based on Combin ation of Linguistic Variables and Fuzzy Triangular Numbers Eight ACIS International Conference on Software Engin eering, Artificial Intelligence Networking and Parallel Distributed Computing, \(pp 450-454 2007  10  X  F L i u   M an ag e m en t o f an In tellig e n t A r g u m e n tatio n  Network for a Web-Based Collaborative Engineering Design Environment Proceedings of the 2007 IEEE International Symposium on Collaborative Technologies and Systems,\(CTS 2007\, Orlando, Florida May 21-25, 2007 11 X. F L i u   A n In ternet Ba se d In tellig e n t A r g u m e n tatio n  System for Collaborative Engineering Design Proceedings of the 2006 IEEE International Symposium on Collaborative Technologies and Systems pp. 318-325\. Las Vegas, Nevada 2006 12 T  M A sub jec tiv e assess m e n t o f altern ativ e m ission  architectures for the human exploration of Mars at NASA using multicriteria decision making Computer and Operations Research 1147-1164, \(June 2004 13 A  N Mo n ireh  F u zzy De cisio n Ma k i n g b a se d o n  Relationship Analysis between Criteria Annual Meeting of the North American Fuzzy Information Processing Society 2005 14 N  P a p a d ias HERMES Su p p o rti n g A r g u m e n tative  Discourse in Multi Agent Decision Making Proceedings of the 15th National Conference on Artifical Intelligence \(AAAI-98  pp. 827-832\dison, WI: AAAI/MIT Press,  \(1998a 15  E. B T riantaph y llo u   T h e Im p act o f  Ag g r e g atin g Ben e f i t  and Cost Criteria in Four MCDA Methods IEEE Transactions on Engineering Management, Vol 52, No 2 May 2005 16 S  H T s a u r T h e Ev alu a tio n o f airlin e se rv ice q u a lity b y  fuzzy MCDM Tourism Management 107-115, \(2002 1 T  D W a n g  Develo p in g a f u zz y  T O P S IS app r o ach  b a sed  on subjective weights and objective weights Expert Systems with Applications 8980-8985, \(2009 18 L  A  Zadeh  F u z z y Sets   Information and Control 8  338-353, \(1965  152 


                        





