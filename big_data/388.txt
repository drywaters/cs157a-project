Efficient Progressive Sampling for Association Rules  Srinivasan Parthasarathy Computer and Information Science Ohio State University Columbus OH 43235 srini@cis.ohio-state.edu Abstract In data mining sampling has ojien been suggested as an effective tool to reduce the size of the dataset operated at some cost to accuracy Howevez this loss to accuracy is ojien difjicult to measure and characterize since the exact nature of the learning curve accumcy vs sample size\is parameter and data dependent i.e we do not know apriori what sample size is needed fo achieve 
a desired accuracy on a particular dataset for a particular set of parameters In this article we propose the use ofprogressive sampling to determine the required sample size for association rule min ing We first show that a naive application of progressive sampling is not very effrcientfor association de mining We then present a refinement based on equivalence classes that seems to work extremely well in practice and is able to converge to the desired sample size very quickly and very accurately An additional noveliy of our approach 
is the definition of a suppon-sensitive interactive measure of ac curacy across progressive samples 1 Introduction viability of using to reduce the dataset size While such methods have shown quite a lot of promise it has been observed by several researchers[l4 15 201 that it is often very difficult to quantify, apriori the quality of the re sults obtained for a given sample size Recently to addresg this problem some researchers have proposed and evaluated progressive  for select data mining tasks Pro gressive sampling starts with a small 
sample and uses pro gressively larger ones until model accuracy no longer im proves beyond a user specified threshold In this paper we study progressive sampling methods as they apply to asso ciation rule mining, a key data mining task Realizing an efficient method to progressively sample a dataset for asso ciation rule mining poses several challenges First and foremost one needs to define a notion of model accuracy. In other words for a particular dataset how does one define how good the sample is? This goodness cri terion should be sensitive to relevant interaction parameters e.g 
support confidence important items to the user as well as the inherent properties of the dataset in question A naive approach could be to compare the set of associations generated by the sample with the set of associations gener ated on theentire dataset Obviously this is self-defeating and does not take into account aspects of user interaction As our ability to collect store and distribute huge mounts of data increases with advancine technnloev             discovering the knowledge hidden in these ever-growing databases has become 
a pressing problem mis problem re femed to as data-mining, an effort 10 derive interesting con clusions from large bodies of data is an interactive process In fact interactivitv is often the kev to facilitating effective Second while defining a notion of model accuracy is im portant one must also be able to compute it efficiently, Zaki et ai[201 have observed that at low sample sizes, there is a tendency to detect a large number of false positives This Property can limit the effectivenessof progressive sampling 
 data understanding and knowledge discovery In such an environment response time is crucial However extracting knowledge from these massive databases is a compute and VO intensive process which makes the task of guaranteeing quick response times difficult In order to to minimize the YO traffic involved in such data-intensive applications researchers have evaluated the This work was panially supported by an Amentech Faculty Fellow ShiR 0-7695-1754-4/02 17.00 0 2002 IEEE Third as noted by Provost and Kolluri 1151 
most discus sions on sampling assume that producing random samples efficiently from large datasets is not difficult This is simply not true In fact most implementations require O\(N time where N represents the size of dataset and not the sample size S Naive implementations often may be much worse Note, that one cannot afford to spend O\(N time to generate IFor example a user may be interested in associations pertaining to a specific item say diapers 354 


each progressive sample We address these three problems in the context of pro gressively sampling for association rules Specifically our contributions are A novel measure of model accuracy for progressively sampling association rules The measure is designed in such a way to be sensitive to user parameters and interactions while not requiring execution on the entire dataset An efficient technique for identifying the optimal sam ple size This key result is based on the identification and tracking of a representative set of frequent itemsets a small subset of the entire set of frequent itemsets Essentially the computational element \(computing the associations for a given sample size is reduced sig nificantly enabling faster convergence to the optimal sample size This technique also addresses the high false-positive problem for low support values An efficient technique based on asynchronous U0 op erations and a novel application of a well known sam pling methodology to improve the efficiency of gener ating a random sample as perceived by the processor The rest of this article is organized as follows In Section 2 we provide some background on progressive sampling and association rules In Section 3 we present our progressive sampling approach We empirically evaluate the proposed approach on synthetic and real datasets in Section 4 Finally we conclude with directions for future work in section 5 2 Background Discovery of association rules is an important problem in database mining The prototypical application is the analy sis of sales or basket data 31 although more recently it has been adopted in the domains of scientific computing bioin formatics and performance modeling. The problem can he formally stated as Let Z  il i2   am be a set of rn distinct attributes also called items Each transaction T in the database 2 of transactions has a unique identifier and contains a set of items such that T Z An association rule is an expression A  B where A B C Z are sets of items called itemsets and An B  0 Each itemset is said to have a support S if S of the transactions in D contain the itemset The association rule is said to have confrdence G if C of the transactions that contain A also contain B i.e C  S\(A U B A i.e the conditional probahil ity that transactions contain the itemset B given that they contain itemset A Data mining of association rules fmm such darabases consists offrnding the set of all rules which meer rhe user specifred minimum confidence and support values Database Layoul There are two possible layouts of the database for association mining. The horizontal layout con sists of a list of transactions where each transaction has an identifier followed by a list of items The vertical layout consists of a list of items where each item contains a list of transactions that transacted on that particular item Ap proaches based on the horizontal format include the popular Apriori and its variants The Apriori algorithm uses the downward closure property of itemset support to prune the itemset lattice  the property that all subsets of a frequent itemset must themselves be frequent Thus the frequent k-itemsets are used to construct candidate k+l itemsets A pass over the data is made to identify which of the candidate ktl are actually frequent This process is repeated till there are no more frequent sets The vertical format has the advantage that the support for candidate k-itemset can be computed by simple tid-list intersections The tid-lists cluster relevant transactions and avoid scanning the whole databases to compute support and the larger the itemset the shorter the tid-lists resulting in faster  An additionaloptimization of com pressing the vertical lists results in additional gains due to lower memory and YO traffic[4 171 Note that sampling in the vertical format will be inefficient Essentially sampling in the vertical context will necessarily have to keep track of which transactions are in the sample and which are out and one would need to to scan through each lid-list and mark the transactions in the sample and chose out of it. One can of course sample in the horizontal format and then convert to the vertical format on the By Equivalence Class Partitioning One way to improve the vertical approach is to use it in conjunction with equiv alence class partitioning Let the set of large two-itemsets L2 he {AB AC AD AE BC BD, BE CD DE Equiva lence class partitioning partitions these itemsets by their \(k 1 length where k 2 in the above example prefixes result ing in the following four partitions:Sa  A  AB AC AD AE SB  B  BC, BD BE Sc  C  CD and SD  D  DE The same partitioning scheme can be recursively repeated to find all the associations For in stance in the above example, partition B yields candidates BCD,BCE,BDE Assuming that all of the candidates are deemed frequent then the level 3 partitions for B are SBC  BC  BCD,BCE and SBD  BD  BDE The advantage of this approach is that the algorithm can process an entire equivalence class partition before proceeding to the next partition This improves memory locality and min imizes U0 traffic in the ECLAT  an approach based on the above equivalence class partitioning Note that past work has not considered using the equiv alence class idea within the context of sampling For the present work it is important to define a notion of an equiv alence superclass Informally an equivalence superclass 355 


is defined as the set of all frequent itemsets that can re cursively be enumerated from a given partition From the above example the equivalence superclass from partition SB denoted as ESB  BC,BD,BE,BCD,BCE.BDE Sampling for Associations While several authors have proposed various strategies on the use of sampling for KDD[8 14 111 and database tasks[l2 we limit the dis cussion in this section to those relevant to association min ing Toivonen I81 presents an association rule mining al gorithm using sampling The approach can be divided into two phases. During phase 1 a sample of the database is ob tained and all associations in the sample are found These results are then validated against the entire database To maximize the effectiveness of the overall approach the au thor makes use of lowered minimum support on the sample Since the approach is probabilistic i.e dependent on the sample containing all the relevant associations\not all the rules may be found in this first pass Those associations that were deemed not frequent in the sample but were actually frequent in the entire dataset are used to construct the com plete set of associations in phase 2 A detailed theoretical analysis of sampling using Chernoff bounds for associa tion des was presented by 7aki er a1  Chernoff bounds provide information on how close is the actual occurrence of an itemset in the sample as compared to the expected count in the sample Based on itemset frequencies, using Chernoff bounds one can obtain a sample size[20 How ever the sample size is independent of the original dataset size and can be quite large sometimes larger than the orig inal dataset Empirical evidence in the same paper also showed that Chernoff bounds may be too pessimistic for association mining It was also shown that sampling can be effective for association mining if the sample size were known apriori for the corresponding dataset and input pa rameters However determining the optimal sample size was left as an open problem Note that determining the optimal sample size efficiently can significantly improve on the overall performance of Toivenen\222s approach[l81 since with a good estimate one could minimize the computational and YO aspects of the second pass Progressive Sampling In order to quickly estimate the optimal sample size researchers have recently turned to progressive sampling Before we detail this procedure we first define the notion of a learning curve A learning curve is a mapping between sample size and model accuracy Typ ically a learning curve is depicted with the vertical axis rep resenting the accuracy of the model and the horizontal axis representing the sample size Most learning curves typi cally have steeply sloping portion early in the curve and a plateaulate in the curve[l4,5 The cost-performancetrade off is best at the knee of the curve Such curves exhibit the property that the slope of the curve is monotonically non increasing with n excepting for small local variance\Most learning curves exhibit the above behavior but some curves can misbehave especially at small sample sizes[lO The goal of progressive sampling is to start with small samples and progressively increase them as long as model accuracy improves sufficiently. Using such a technique one can identify the knee of the learning curve using basic slope characterization across recently evaluated samples One problem in the association rule mining context is how does one quantify model accuracy A simple metric would he to compare the set of associations found for a given sample size with the set of associations found for the entire dataset However to obtain the latter we would have to run the al gorithm on the entire dataset The efficiency of progressive sampling is governed by the average case execution time performance of the algo rithm and by the sampling schedule In the case of associ ation rule mining algorithms while the worst case complex ity is exponential the average case behavior typically tends to be linear or in some cases quadratic The issue of de termining an optimal sampling schedule was addressed by Provost et a1[14 where the authors show that a simple geo metric sampling schedule is efficient in an asymptotic sense for most induction algorithms with a run time complexity of O\(n or worse as long as the maximum sample size is n 12 However, the above result is not useful if the desired ac curacy is met only at a a sample size of 70 for a linear time algorithm This reduction \(from 100 may still re sult in significant performance benefits Another problem with the above theoretical model is that sampling overheads are ignored Efficiently obtaining a sample from a large dataset is often ignored by most researchers as pointed out by Provost and Kolluri[lS If one were to account for this the benefits of progressive sampling would decrease An other overhead, induced within the context of association rules is the avalanche effect of detecting false positives at very small sample sizes see Zaki et al We address these issues in the next section 3 Methodology In this section we present our approach for efficient pro gressive sampling of association rules We first describe our measure of model accuracy which is based on the notion of self-similarity of associations across progressive samples A novelty of the proposed measure is that it is functionally dependent on user input parameters support constraints etc We then identify a representative subset of frequent itemsets such that the behavior of our measure of model accuracy on this representative subset mimics the behavior of our measure on the entire set of associations The final problem we address relates to that of sampling overhead Model Accuracy Absolute model accuracy for a given sample is difficult to measure without running the algorithm on the entire dataset Since this is not possible to do due to 356 


efficiency constraints we define a measure of accuracy that is based on the following key intuitions For progressive samples dl and dz where size\(d2  size the self-similarity between the set of associations generated under the two samples is likely to be low during the growth phase and is likely to be much higher during the 223plateau\224 phase. Therefore identification of the knee of the curve can be done by measuring the self-similarity between progressive samples We now define the our notion of interactive self similarity: Let A and B respectively be a the set of frequent itemsets for a database sample dl and that for a database sample dz For an element E A respectively in B let supd z respectively supd,\(z be the frequency of z in dl respectively in 4 Our metric is where a is a scaling parameter The parameter a has a de fault value of l and can be modified to reflect the signifi cance the user attaches to variations in supports. For a  0 the similarity measure is identical to w i.e support variance carries no significance Sin1 values are bounded and lie in O,l Sim also has the properly of relative or dinality i.e if Sim\(X Y  Sim\(X Z then X is more similar to Y than it is to Z Note, that while the above for mulation does not explicitly consider correlations between itemsets e.g two itemsets \(ABEK AEFK that have many items in common are not treated differently\they are ac counted for implicitly as all itemsets that can he formed hy the common items A,E,K are part of the summation An important point raised by Das Manilla and  while evaluating the similarity between two attributes was that using a different set of external probes to measure similarity could potentially yield a different simi larity measure In our case the action of modifying the ex ternal probe set corresponds to modifying the association sets evaluated over different samples of the input database This is achieved either by modifying the minimum sup port or by restricting the search for associations to those that satisfy certain conditions \(Boolean properties over at tributes Z Note that the optimal sample size the knee of the curve\can vary for a different set of parameter values Picking a Representative Set The above metric sug gests using the entire association set from consecutive sam ples to measure the self-similarity between progressive samples. However as observed earlier computing complete association sets for each sample may eventually defeat the purpose of sampling since evaluating each sample has vari ous overheads associated with it To overcome this problem what we need is a representative class of itemsets which has a behavior similar to the self-similarity CUN of the original set of associations Moreover this representative class of itemsets should satisfy the criterion that it should be efficient to compute Given the above requirement we evaluated three possible options for a representative set a random sample of the set of frequent itemsets a level-wise horizontal-i.e all k-itemsets for a given k split of the fre quent itemset lattice an equivalence-superclass \(vertical split of the frequent itemset lattice The first option for a representative class is infeasible A truly random sample of the set of frequent itemsets while ideal from a statistical perspective is impossible to gen erate without first generating the set of frequent itemsets and therefore self-defeating The second option is imprac tical for higher order splits the set of all k-itemsets where k is large as again one has to compute pretty much all the frequent itemsets before reaching the higher order split in question We found empirically that using lower order splits tends to result in an unreliable over-estimation i.e pre mature convergence\of the similarity between subsequent samples and was therefore not useful Detailed analysis of these options was considered and the reader is refered to an extended version of this article for Our proposed approach is to use equivalence super classes vertical splits generated from the most frequent item\(s as representative sets We considered using ran domly selected equivalence superclasses as the represen tative class of itemsets but realized that these could suffer from the same problem as the horizontal split approaches The key intuition behind using the most frequent item is that such an equivalence super-class in all likelihood most completely captures the entire set of frequent itemsets and the distribution of associated supports across all levels of frequent itemsets 131 As we shall see from the empiri cal results in the next section this representative class based approach yields a very good predictor of the self similarity measure. The other nice feature of this representative class is that it can be quickly computed with some straightfor ward modifications current-day vertical-set approaches[l31 Note no changes are required to the self-similarity mea sure we are just replacing the base association set with the representative set as determined by the first few\equiva lence class partition\(s However, the representative class selection is somewhat dependent on the similarity measure For instance if the similarity metric as discussed earlier were restricted to those itemsets including a particular item say A then the hest equivalence super-class to choose might be the equivalence super-class generated by that par ticularitem A Also while we have argued intuitively[l3 that equivalence super-classes based on the most frequent item\(s\are likely to he good representative sets in general other splits based on the constraints imposed on the sim ilarity measure may be better and are being investigated Efficient Sampling Methodology Provost and  point out that most sampling algorithms 357 


require O\(N or greater time to execute where N is the size of the database and that researchers rarely account for this overhead For generating samples of the database we use the Method A algorithm presented by Vitter\(l91 A simple algorithm for sampling generates an independent uniform random variate for each record to determine whether that record should be chosen for the sample If m records have been chosen from the first t records then the next record will be chosen with probability n-m This algorithm generates N random variates Method A significantly speeds up the sampling process by efficiently determining the number of records to be skipped before the next one is chosen It generates exactly n random variates With appropriate support for database indexing the method A scheme allows the sampling procedure to take O\(n time2 Note that even with direct indexing creating a sample still creates some level of overhead This overhead can be split into two components computational overhead deter mining which transactions are in the sample and WO over head reading in said transactions The YO component can be overcome with suitable systems support in the form of asynchronous VO a technique which allows WO opera tions to overlap with useful computation Essentially one can overlap the WO required for the next progressive sam ple with the computation required for processing the cur rent sample In other words while we compute the asso ciation set for the current sample one can do the WO for the next sample size in the sampling schedule With ac tive disk-like approaches[l 161 one can move the compu tational overhead associated with sampling off the critical path as well This approach lends itself to accessing data over the network as well since even that can be effectively overlapped with useful computation Algorithm Details The basic steps to the progressive sampling approach are highlighted in Figure 1 We present two approaches, one based on estimating self-similarity be tween the current sample and the subsequent sample in the schedule RC-SS and the other based on estimating self similarity between the current sample and the entire dataset using the first k equivalence super-classes RC-S Step 0 for the RC-S algorithm computes the representa tive set on the entire dataset Step 1 for the RC-SS algo rithm computes the representative set on the lowest sam ple size in the schedule Step 2 is an iterative for loop Each iteration of this for loop first computes the next sam ple Step3\in the schedule Then the representative set for this sample is constructed \(Step4 After this the self similarity measure is computed For the RC-SS algorithm we compute the self similarity between this representative set and the previous one For the RC-S algorithm we com pute the self similarity between this representative set and Nole lhal if each transaction in the database is directly indexable prov ing this bund for the worst-case is trivial Step 0 Compute representative set on entire dataset \(RC-S only Step 1 Compute initial sample and representative set on sample RC-SS only Step 2 For each sample size in the schedule Step 3 Compute sample Step 4 Compute representative set Step 5 Is convergence criteria met Step 6 If yes set effective sample size ESS and break Step 7 If no continue Step 8 Compute the rest of the entire set of associations for the ESS Figure 1 Proposed Approach the one pre-computed in Step 0 If the similarity met ric is above a user-specified threshold then convergence is achieved Step 5 For RC-SS we modified the conver gence criteria slightly after viewing empirical results We found that the self-similarity curve for RC-SS is not always well behaved is non-monotonic For this algorithm we declared convergence only if the similarity metric is above the user-specified threshold for two consecutive iterations This avoids premature convergence due to local variances and also protects against the possible misbehavior of self similarity curves found mainly at small sample sizes If the convergence criteria is met we break out of the for loop Step 6 else we continue \(Step 7 In Step 8 we compute the overall association set for the determined sample size 4 Experimental Methodology In this section we empirically evaluate the proposed methodology on several synthetic and real datasets We first describe the experimental setup machine configura tion, dataset properties etc We then evaluate the proposed measure of model accuracy self similarity between consec utive samples; and the impact on this measure when using the first equivalence superclass as a representative set We then quantify the performance gains from using this repre sentative class as opposed to the entire set of associations At the end of this section we quantify the gains from our sampling methodology Experimental Setup We used three synthetic datasets generated from the IBM dataset generator program[3 These datasets mimic the transactions in a retailing environ ment The properties of the synthetic datasets are inherent in the names The number following the T refers to the av erage transaction length the number following the I refers to the average maximal potentially frequent itemset size, the alpha-numeric-code following the D refers to the total num ber of transactions IM means 1 Million We also used two real datasets for our experiments The first real dataset is the Gazelle dataset which formed a part of the KDD Cup 1999 competition The properties of these three datasets are de scribed in Table 2 The second real dataset is the nook 358 


dataset which is a dataset from a prominent online book store retailer in South America Database I numT I Sim T1014D5M I 5000000 I 260MB T815D25M 25000000 1.25GB 1 Gazelle I 59602 I 1.35MB 1 Vbwk 136809 4.3MB Figure 2 Database properties All experiments unless otherwise noted, were performed on a dual pentium node machine lGHz Pentium III having 512 MB RAM and running Linux 2.4 For all the experi ments we used a geometric sampling schedule up to 40 of the original dataset and an arithmetic progressive schedule from that point on if required Impact of Representative Set on Self Similarity The self similarity plots for all the datasets are described in Fig ure 3 In each graph the Y-axis corresponds to the self sim ilarity and the X-axis corresponds to the sample size In each graph there are four plots the RC-S and RC-SS plots have already been explained in the previous section The A S plots in bold is the learning curve that we are trying to estimate They represent the naive impractical approach of comparing the entire set of associations generated by the sample with the set of associations generated by the entire dataset The A-SS plots mirror the procedure described for R-SS the only difference being that the self-similarity mea sure is computed on the entire set of associations On viewing the plots for the real datasets Figures 3a and 3b one can observe that the plots for the represeuta tive set prefix RC closely follow the plots for the entire set of associations prefix A for the corresponding support values considered For the gazelle dataset note that if we required a self similarity cut off of 0.9 for 0.1 support we would never obtain this value even if we went the dis tance whereas at 0.25 support not shown see[l3 for details this could be achieved at a 50 sample size This highlights the fact that the user-specified parameters has an important role to play in determining whether sampling is useful or not and if so at what level Overall both plots fol low the expected pattern of low self similarity at smaller samples and higher self similarity at larger samples The phase transition from lower self-similarities to higher self similarities coincide with the knee of the learning curve The results for the synthetic datasets are better \(see Fig ures 3c-d The shape of the self similarity plots for the representative class almost exactly mirror the self similarity plots for the entire set of associations Unlike the plots for the real datasets the self similarities are quite high even at low sample sizes This is mainly due to the fact that the syn thetic datasets are much larger than the real datasets there fore the absolute number of transactions for a given sample size \(expressed as percentage of the original is much larger Overall the RC-S plots most closely mirrors A-S plots Another interesting trend that is observed across both real and synthetic datasets is that there seems to be a relatively consistent overestimation or underestimation of the self similarity across RC and A graphs For example in Fig ure 3a the RC curves consistently underestimate their A curve counterparts This would seem to indicate that the curve we want to estimate A-S can be best estimated by using the RC-S curve and a translation factor that can be de rived from the translations computed from the RC-SS and A-SS curves This strategy is currently being evaluated Impact of Representative Set on Performance In this section we highlight the performance gains from using the representative class of itemsets to compute self similarities over using the entire set of associations Figure 4 plots the cumulative execution time for different sample sizes for the datasets under consideration The cumulative execution time is the execution time of the algorithm RC-S or RC-SS when the convergence criteria is satisfied at the correspond ing sample size The Baseline Execution lime corresponds to the execution time of the association mining algorithm on the entire dataset Essentially the break even point for progressive sampling when computing on the entire set of associations represented by the prefix A at 0.5 support is when the cumulative execution time intersects with this baseline For the VBook dataset the break even point when using the entire set of associations is reached at a sample size of around 10 for this dataset at this value of support The poor performance here can be traced to the fact that for this support value at low sample sizes the basic association mining algorithm detects a large number of false positives However for the representative class approach after deter mining the effective sample size the algorithm still has to be completely executed on that sample size \(sans the rep resentative class For this dataset if the effective sample size determined was 50 corresponding to a value of 0.9 in the RC-SS \(RC-S\plot from Figure 3b\then the total ex ecution time is equal to 1.1s 1.15s for RC-S which is still below the baseline of 1.5s This result is especially encour aging and shows that even for a small dataset the approach presented can be quite effective As can be observed from Figures 4b-c the results on the synthetic datasets are even better For T1014DSM for a self similarity cut off of 0.95 or higher the optimal sample size is 50 this can be seen from Figure 3c The RC-SS ap proach required a total of 448 \(496 for RC-S seconds to compute the results see Figure 4b The approach using the entire association set requires 1037 seconds which is above the baseline of 950s to compute the same result This results in a factor of improvment of 2.4 2.1 over the base line For TSISD25M Figure 4c for a self similarity cut off of 0.95 or higher the optimal sample size is 10 from Fig ure 3d The representative class approach requires a total 359 


Comparielon of Seif-Similarity CUNOS Gazallt 0 10 20 30 40 50 BO 70 80 Sample size a Gazelle Camperision Ot Sell-Similarity Curves T1014D5M s 0.8 E 0.75 I 0.7 0.55 0.55  0.1 RC-S  0.6 O.l%A-S  O.l%A-SS  r 0.1 RC.SS 0 10 20 30 40 50 BO 70 80 Sample size b VBwk Cornparision 01 Self-Similatity Curves: TBISDZSM 0.05 RC-S  0.05 A-S  0.05 A-SS D  0.75 0.7 0.65 0.05 RC-SS  0 10 20 30 40 50 BO 70 80 Sample Sire tc T1014D5M  I 0.75 0.08 RC-S  0.08 A-S  0.08 A.SS 0  0.6 0.55 0.5 0.08 RC-SS   0 10 20 30 40 50 BO 70 Bo Sample size d TBI5D25M Figure 3 Evaluation of Proposed Method Similarity plots PerbmanceCawkkn RCn A VT!d P&manceCanpamlon UCn A:T815025M IC f F s 9 Y if E 5 0.1  C 9  0.1XA  k _ o.l%Rcs  wm 0.lXRCSS  0.IXRC-S  I  IO M B U M MI 70 80 WIW 0 10 M 30 10 M MI 70 80 90100 saw IO sanp1e sa0 Sam sa a VBook b T1014D5M c T815D25M Figure 4 Impact of Representative Set on Performance Sampling MethOdolcgy Performance T1014D5M:0.05 sup SBrnpling Melhodobgy Breakdown T1014D5M:0.05 0 10 20 30 40 50 80 70 80 90 1W 0 10 20 30 40 50 60 70 80 90 100 Sample Sue Sample Size a Overall Performance b Breakdown Figure 5 Sampling Methodology on Performance Breakdown 360 


of 73.17 125 for RC-SS seconds to compute the results The approach using the entire association set requires 140 seconds to compute the same result When compared with the baseline execution time \(1730s the representative class approach\222s improvement factor is around 25 Impact of Sampling Methodology In Figure 5 we con sider the performance of the sampling methodology pre sented in Section 3 Figure 5a compares the cumulative execution time performance of our the approach using the representative class to identify the ideal sample size while overlapping the sampling and U0 operations of the next stage with the computation of the current stage In Figure 5a we compare the performance of ideal situation where there is no sampling overhead TC-ideal with the actual perfor mance with overlapping \(TC-overlap and without overlap ping \(TC-nooverlap For the overlapping computation we used two scenarios, one where the processor handling the WO and sampling was a 300Mhz Pentium 113 i.e a more realistic scenario for active disks with a much slower pro cessor than the compute processor\and the other where the U0 processor was lGHz ideal baseline On viewing the graphs it is clear that the TC-ideal graph and the TC-overlap \(1GHz\are almost identical, reflecting the fact that almost all of the sampling overhead is over lapped with useful computation \(computing the association set for the previous sample size On relaxing the assump tion and allowing for the fact that the processor doing the sampling and WO is often much slower 300 Mhz we ob serve a marginal drop in performance \(slightly under 4 so still most of the sampling overhead is overlapped with useful computation Note that if we did not overlap the sampling overhead with computation then we perform 10 12% worse than the ideal \(comparing the TC-Ideal and TC noverlap graphs This experiment assumes the best pos sible sampling algorithm the Sample A algorithm We further broke down the performance of the sampling over heads in Figure 5b for the two configurations \(1GHz and 300Mhz The performance of the naive algorithm \(see Sec tion 3 is much worse than the Sample A algorithm 5 Conclusions and Future Work We have presented an efficient method to progressively sample for association rules Our approach relies on a novel measure of model accuracy \(self-similarity of associations across progressive samples\the identification of a represen tative class of frequent itemsets that mimic extremely accu rately\the self-similarity values across the entire set of asso ciations and an efficient sampling methodology that hides 3We did not have a dual processor system where one processor was fast and the other was slow We timed the sampling overheads for each of the different sample sizes for his dataset on the slower machine and we used these times by precomputing the samples and busy waiting for the necessary amount of time while evaluating the performance on this configuration the overhead of obtaining progressive samples by overlap ping it with useful computation We evaluated the results on a set of real and synthetic datasets We extensively benchmarked each aspect of our algorithm and obtained uniformly good performance several factor-fold execution time improvements across both real and synthetic datasets In the current work we have considered each sample to be independent of the other We would like to see if the pro posed method can be improved by using adaptive sampling techniques[S Other directions of future work have been outlined already in the text References I Anurag Acharya et 01 Active disks Programming model algorithms and evaluation In ASPLOS 1998 2 C Aggawal and P Yu Online generation of association rules In ICDE 1998 3 R Agrawal and R Srikant Fast algorithms for mining asso ciation rules In 20th VLDB Conf September 1994 4l Doug Burdick Manuel Calimlim and 1 E. Gehrke Mafia A maximal frequent itemset algorithm for transactional databases In ICDE 2001  5 Jason Catlett Megainduction A test flight In Machine Learning pages 59k599 1991 61 W G Cochran Sampling Techniques I Wiley  Sons-1977 171 G Das H Mannila and P Ronkainen Similarity of at tributes by external probes In KDD 1998 SI Carlos Doming0 and Osamu Watanabe Scaling up a boosting-based learner via adaptive sampling In PAKDD 2wO 9 1 Han and 1 Pei Yiwen yin Mining frequent patterns with out candidate generation In SIGMOD 2ooO IO Haussler Kearns Seung and Tishby Rigorous leaming curve bounds from statistical mechanics In COLT 1994 1 I George H John and Pat Langley Static versus dynamic sam pling for data mining In KDD 1996 I21 F Olken and D. Rotem Random sampling from database files  a survey In 5th Intl Conf Staristical and Scientific Dorubose Manugement April 1990 I31 S Parthasarathy Efficient progressive sampling for associ ation rules OSU CIS Technical Repon Number TR-OSU CISRC-5/02-TR13 November 2001 revised March 2002 I41 Foster 1 Provost David lensen and Tim Oates Efficient progressive sampling In KDD 1999 I51 Foster 1 Provost and Venkateswarlu Kolluri A survey of methods for scaling up inductive algorithms Duta Mining and Knowledge Discovery 3\(2 1999 I61 E Riedel G Gibson and C Faloutsos Active storage for large-scale data mining and multimedia In VLDB 1998 I71 Pradeep Shenoy et al Turbo-charging vertical mining of large databases In SIGMOD pages 22-33.2wO 1181 H Toivonen Samding large databases for association rules  In 22nd VLDB c 1996 1191 I S Vitter An efficient algorithm for sequential random sampling In ACM Trans Mathematical Siftware volume 13\(1 pages 58-67 March 87 ZO M I Zaki S Parthasarathy er al Evaluation of sampling for data mining of association rules In RIDE 1997 211 M 1 Zaki S Parthasarathy et al New algorithms for fast discovery of association rules In 3rd Inrl Conf on Knowl edge Discovery and Dora Mining August 1997 361 


  9 operation. In actuality the control of the hardware elements extends even further back to the TSX-5 and STEP heritage busses. These have over a dozen years more on-orbit success for the Air Force. Figure 9 shows several of these heritage satellites   The Glory hardware draws its heritage from the same series of satellites, namely the Defense Systems Inc. \(DSI CTA Space Systems \(CTASS\P bus architecture. TSX5 was an evolution from the STEP heritage, upgrading the electronics for radiation hardness. The TSX-5 mission is flying in a highly elliptical orbit that passes through the Van Allen belts. It has been flying for over 4 years in this environment. ACRIMSAT, OV-3 and VCL made only minor improvements to the TSX-5 designs  The reaction wheels are built by Orbital and are flying on the OV-3 satellite. The propulsion system was assembled and tested by Orbital and is identical to the OV-3 system More than 75% of the bus co mponents were built by Orbital at either the Dulles campus, or previously at the McLean or Germantown facilities. Orbital also manufactured the bus structure elements, including the aluminum honeycomb decks. The same methods were used on the extremely successful ACRIMSAT structure  In terms of the purchased components, most also have flight heritage. The GPS receivers have more than 100 years of combined on-orbit satellite years of operations on the Orbcomm constellation alone. The LN-200S is flying on the TSX-5 mission, and flew briefly on QuikToms \(launch vehicle problem\ RF transmitters and receivers are from L3-Conic and have significant flight heritage on both Orbital satellites and others across the industry. The Orbital-built antennas have extensive flight heritage. The torque rods are the industry standard units from Ithaco. The Solar Array Drive Assemblies SADAs\re the standard Type 2 gimbals from Moog. Orbital has flown these same drives on our geo-synchronous satellites    Figure 9 - ACRIMSAT, STEP-0 and VCL Satellites  The arrays are populated with single junction GaAs cells from Emcore, which was Tecstar when the cells were made and laid down on the panels. These cells are of the same vintage as those flying on the Orbcomm and GALEX satellites. The NiH2 battery is an SPV from Eagle-Picher. It is the same technology, although a smaller capacity, as the batteries flying on the Iridium constellation. The baseline star trackers are the ESA flight heritage Advanced Stellar Compass from the Danish Technical University \(DTU This unit has more than 5 years on orbit with the Oersted satellite, and has flown on more than 8 missions to date with no known failures  The Taurus launch vehicle has had 6 successful flights in various configurations. ACRIMSAT was successfully 


  10 launched on the same 2110 Taurus vehicle configuration in 1999 with the KOMPSAT satellite  Orbital has flown numerous missions from the Mission Operations Center \(MOC\lles using the MAESTRO ground software for command and telemetry. The MOC is shown below in Figure 10. This software is hosted on Sun workstations running the Solaris operating system. The most recent missions are OV-3 and GALEX. Both programs are running smoothly and operating as planned. ACRIMSAT has recently converted over to using the MAESTRO system for operations as well. USN is supporting the GALEX mission, including X-band pass services at Hawaii and Australia. Glory will follow this proven path. USN has also supported most of Orbital’s geo-synchronous satellite launches and on orbit checkouts    Figure 10 – Orbital’s Mission Operations Center  6  S UMMARY   In the case of the Glory program, it is concluded that reuse of many components from the VCL program not only significantly reduces the cost of the Glory mission but helps to make something of what could be shelved for an indeterminate amount of time.  By employing existing resources and knowledge from a program that was very mature, the Glory program is doing its part to contribute to cost saving measures and maximizing benefit to NASA. The Glory program provides savings of nearly $15M over a ground-up bus design effort, while mitigating significant risk on the bus portion of the mission  Glory is an ideal mission for ear th sciences in the realm of climate change research. It draws from significant flight heritage elements in both th e instruments and the spacecraft bus. It uses an existing NASA asset with minor refurbishment to save significant development costs. It uses a LV that has flown several NASA and DOD missions to date. The ground system employs flight proven hardware and software with a robust plan for backup coverage   7  R EFERENCES   NASA Facts Aerosols June 1999   NASA Godda rd Space Flight Center Glory Program Science and Mission Requirements Document  Greenbelt, Maryland, February 2, 2004  8  B IOGRAPHIES   Darcie A. Durham is an Engineer in the Advanced Programs Group at Orbital Sciences Corporation in Dulles, Virginia.  Currently she is supporting the Glory program in the Systems Engineering Division as well as supporting the Concept Exploration and Refinement Program.  Her experience is both on hardware and paper study programs ranging from Crew Preference Items for Lockheed Martin to Crew Exploration Vehicle Design for Orbital Sciences Corporation.  She graduated with a B.S. in Aerospace Engineering from Texas A&M University.  Past experience includes flight certification of ISS hardware at Johnson Space Center in Houston and work with the Advanced Missions Architecture Group at the Jet Propulsion Laboratory in Pasadena, California   Thomas J. Itchkawich is a Program Director working for the VP of Science and Technology Programs in the Space Systems Group at Orbital Sciences Corporation in Dulles Virginia. Tom is currently managing the operations support for ACRIMSAT managing the Glory program at Orbital, and managing an internal ERP conversion in his spare time. He has successfully launched the Mighty Sat I satellite on the Shuttle Endeavour, and the ACRIMSAT satellite on Taurus. He has supported numerous other programs at both CTA Space Systems and Orbital Sciences. In a previous incarnation he was the lead engineer for the Pegasus payload fairing from inception through design, fabrication, qualification testing and the first four flights. A true Fighting Blue Hen, Tom graduated with a Bachelor’s of Mechanical Engineering from the University of Delaware. The first ten years of his career were spent at Hercules Aerospace working on composite rocket motor cases, including Titan IVB, Delta GEM strap-ons, and Filament Wound Case Shuttle boosters. Tom was part of the Pegasus Team that was awarded the National Medal of Technology, and the MightySat team that was awarded the Program of the Quarter by AFRL. He has several other published papers on composite structures and low-cost satellite missions  


11  251 2002 Tim Menzies, Gary D. Boetticher Page  SEW-27 Tutorials '02  data bindings domain-specific metric for assessing module interrelationship  interface errors errors arising out of interfacing software modules  Porter90 Predicting software  faults 251 2002 Tim Menzies, Gary D. Boetticher Page  SEW-27 Tutorials '02 From decision trees to association rules  Classifiers  223this and this\224 goes with that \223class\224  conclusions \(RHS\ limited to one class attribute  target very well defined  Association rules  223this and this\224 goes with \223that and that\224  conclusions \(RHS\ may be any number of attributes  But no overlap LHS and RHS  target wide open  Treatment learning  223this and this\224 goes with \223less bad and more good\224  223less\224,  \223more\224: compared to baseline  223bad\224, \223good\224: weighted classes Proceedings of the 27th Annual NASA Goddard Software Engineering Workshop \226 Tutorial Notes \(SEW\22202 0-7695-1854-0/02 $17.00 \251 2002 IEEE 


12  251 2002 Tim Menzies, Gary D. Boetticher Page  SEW-27 Tutorials '02 Association rule learning  www.amazon.com  Customers who bought this book also bought  The Naked Sun by Isaac Asimov  The Caves of Steel by Isaac Asimov  I, Robot by Isaac Asimov  Robots and Empire by Isaac Asimov 251 2002 Tim Menzies, Gary D. Boetticher Page  SEW-27 Tutorials '02 Support and confidence  Examples = D , containing items I  1: Bread, Milk 2: Beer Diaper Bread, Eggs 3: Beer Coke, Diaper Milk 4: Beer Bread, Diaper Milk 5: Coke, Bread, Diaper Milk  LHS  RHS = {Diaper,Milk  Beer  Support       =   | LHS U RHS|  / | D |       = 2/5 = 0.4  Confidence  =   | LHS U RHS |  / | LHS |    = 2/3 = 0.66  Support-based pruningreject rules with s < mins  Check support before checking confidence Proceedings of the 27th Annual NASA Goddard Software Engineering Workshop \226 Tutorial Notes \(SEW\22202 0-7695-1854-0/02 $17.00 \251 2002 IEEE 


13  251 2002 Tim Menzies, Gary D. Boetticher Page  SEW-27 Tutorials '02 Example of supportbased pruning 4 Bread 1 Eggs 4 Diaper 3 Beer 4 Milk 2 Coke Count 1Item 3 Beer,Diaper 3 Milk, Diaper 2 Milk,Beer 3 Bread, Diaper 2 Bread,Beer 3 Bread,Milk Count 2Item 2 Milk, Diaper Beer 3 Bread,Milk Diaper Count 3Item Support-based pruning 225 Min support =3 Ignore subsets of items of size N 225 only if N-1 support > min-support Without pruning 6 C 1  6 C 2  6 C 3 41 With pruning: 6 + 6 + 2 = 14 251 2002 Tim Menzies, Gary D. Boetticher Page  SEW-27 Tutorials '02 Classifiers versus Association rules \(again  Classifiers  Assume entire example set can fit into RAM  Association rule learners  can handle very big data sets  Agraw  t he APRIORI alg o r i t h m   very large data sets  10,000,000 examples  843MB Proceedings of the 27th Annual NASA Goddard Software Engineering Workshop \226 Tutorial Notes \(SEW\22202 0-7695-1854-0/02 $17.00 \251 2002 IEEE 


14  251 2002 Tim Menzies, Gary D. Boetticher Page  SEW-27 Tutorials '02 The Data Mining Desiderata Bradley  Require one scan \(or less\ of the database if possible  On-line \223anytime\224 behavior  223best\224 is always available, with status information on progress, expected remaining time, etc. provided  Suspendable, stoppable, resumable  incremental  progress saved to resume a stopped job  Ability to incrementally incorporate additional data with existing models efficiently  Work within confines of a given limited RAM buffer  Ooops, good-bye traditional classifiers e.g. C4.5  Argued against by some  223Memory is cheap\224: [W A R2 251 2002 Tim Menzies, Gary D. Boetticher Page  SEW-27 Tutorials '02 Conf1  outlo o k overc a s t   1 0   82  40    84  40   4 0 0  Treatment learning sunny, 85 86 false none \(2 1 2 sunny, 80 90 true none sunny, 72 95 false none rain 65 70 true,          none rain, 71 96 true none rain 70  false some \(2 2 4 rain, 68 80 false,  some rain, 75 80 false some sunny,      69 70 false lots    \(2 3 8 sunny,      75 70 true lots overcast,     83  false lots overcast,     64  true lots overcast,     72  true lots overcast,     81 75 false lots outlook temp humidity wind hours on course A good attribute range 225 More frequent in good that bad 225 Weighted by 223distance\224good to bad 225 Normalized by total count 225 Summed for all good/bad class pairs Lots  none Lots  some Proceedings of the 27th Annual NASA Goddard Software Engineering Workshop \226 Tutorial Notes \(SEW\22202 0-7695-1854-0/02 $17.00 \251 2002 IEEE 


15  251 2002 Tim Menzies, Gary D. Boetticher Page  SEW-27 Tutorials '02 sunny, 85 86 false none \(2 1 2 sunny, 80 90 true none sunny, 72 95 false none rain 65 70 true,           none rain, 71 96 true none rain 70  false some \(2 2 4 rain, 68 80 false,  some rain, 75 80 false some sunny,      69 70 false lots    \(2 3 8 sunny,      75 70 true lots overcast,     83  false lots overcast,     64  true lots overcast,     72  true lots overcast,     81 75 false lots 0 1 2 3 attribute ranges with deltaf 4-2024681 conf1 225 treatments 002 attribute.range.conf1 > X 225 treatments|=N 225TAR2 = O\(2 N  225 fails for large N outlook temp humidity wind hours on course Conf1  outlo o k overc a s t   1 0   82  40    84  40   4 0 0  Lots  none Lots  some 251 2002 Tim Menzies, Gary D. Boetticher Page  SEW-27 Tutorials '02 Treatments for golf 0 1 2 3 4 none some lots I f outl ook o verc as t Th en l o t s o f go l f  4 4  0 Least monitor watch the humidityalert if rising over 90 Least change pick a vacation location with overcast weather I f h u m i d i t y  90  97 Th en l o t s o f go l f  1 4  0 1 2 3 none some lots 0 1 2 3 4 5 6 none some lots If n o ch an ge Th en l o t s o f go l f  6 6 3 5  3  Proceedings of the 27th Annual NASA Goddard Software Engineering Workshop \226 Tutorial Notes \(SEW\22202 0-7695-1854-0/02 $17.00 \251 2002 IEEE 


16  251 2002 Tim Menzies, Gary D. Boetticher Page  SEW-27 Tutorials '02 6.7 <= RM < 9.8 And 12.6 <= Ptratio 15.9 BEST ACTION 0.6 <= NOX < 1.9 and 17.16 <= LSTAT < 39 WORST ACTION BASELINE 500 examples  of bad--, bad, ok, good Stop staring at the scenery and tell me where to steer or what to dodge 251 2002 Tim Menzies, Gary D. Boetticher Page  SEW-27 Tutorials '02 Require overall require2 require3 require5 require4     action1 action1, action2, action3,  \205   Cost,    Benefit 1 Y              Y             N,        \205   23200,  250 2           N              N             Y ,       \205   11400,  150 205..       \205             \205            \205        \205   \205         \205 action2 fault2 fault3 fault1 JPL requirements Feather&Menzie Proceedings of the 27th Annual NASA Goddard Software Engineering Workshop \226 Tutorial Notes \(SEW\22202 0-7695-1854-0/02 $17.00 \251 2002 IEEE 


17  251 2002 Tim Menzies, Gary D. Boetticher Page  SEW-27 Tutorials '02 Case study 99 proposed actions for deep space satellite design; 2 99 10 30 options Each row is one project plan action1, action2, action3,  \205   Cost,    Benefit 1 Y              Y             N,        \205   23200,  250 2           N              N             Y ,       \205   11400,  150 205..       \205             \205            \205        \205   \205         \205 Learnt 225 Do 16 225 Don\222t do 14 225 Ignore 66 options 225 c.f. genetic algorithms Each dot  is one randomly generated project plan 251 2002 Tim Menzies, Gary D. Boetticher Page  SEW-27 Tutorials '02 Pr of tampering 0.02 Pr of fire 0.01 Pr of smoke  given [fi  0.90 Pr of smoke  given [fi  0.01 Pr of report given [exodus=ye 0.75 Pr of report given [exodus=no 0.01 Pr of exodus given [alarm=yes 0.88 Pr of exodus given [alarm=no 0.001 etc tampering fire alarm smoke exodus run away report hello, operator I want to report a fire 0.02 0.01 Use Bayesian analysis to update probabilities given new information Use Bayesian analysis to update probabilities given new information Bayesian Tuning Proceedings of the 27th Annual NASA Goddard Software Engineering Workshop \226 Tutorial Notes \(SEW\22202 0-7695-1854-0/02 $17.00 \251 2002 IEEE 


18  251 2002 Tim Menzies, Gary D. Boetticher Page  SEW-27 Tutorials '02 tampering fire alarm smoke NO exodus report YES 0.50 was 0.02 0.03 was 0.01 Q1: What if there is a report, but no smoke Q1: What if there is a report, but no smoke Q2: What if there is a report, and smoke Q2: What if there is a report, and smoke tampering fire alarm smoke YES exodus 0.03 was 0.02 0.97 was 0.01 report YES Example from : [Poole98   p37 1 Source = http:// www.swi.psy.uva.nl/projects/SWI-Prolog/download.html http://www.cs.ubc.ca/spider/poole/ci/code.tar.gz Files    = code/acp/bnet.pl code/acp/bnet_t1.pl Bayesian Tuning 251 2002 Tim Menzies, Gary D. Boetticher Page  SEW-27 Tutorials '02 Non-na\357ve model bayesian network Proceedings of the 27th Annual NASA Goddard Software Engineering Workshop \226 Tutorial Notes \(SEW\22202 0-7695-1854-0/02 $17.00 \251 2002 IEEE 


19  251 2002 Tim Menzies, Gary D. Boetticher Page  SEW-27 Tutorials '02 Low testing effort EXPLAINS 1\ some observed operational defects  and 2\ low pre-release defects 251 2002 Tim Menzies, Gary D. Boetticher Page  SEW-27 Tutorials '02  Ancestors  ancestor\(X,Y\:-parent\(X,Y  ancestor\(X,Y\:-parent\(X,Z\ancestor\(Z,Y  Lists  member\(X,[X|Z   member\(X,[Y|Z me mb er X Z   append X X   append\([X|X Y s X Z s  a ppe nd X s Ys Z s  Example Example action action hypothesis hypothesis p\(b,[b add clause p\(X,Y   specialize p\(X,[V p\(x,[a specialize p\(X,[X p\(b,[a add clause p\(X,[X p\(X,[V p\(X W Inductive Logic Programming Proceedings of the 27th Annual NASA Goddard Software Engineering Workshop \226 Tutorial Notes \(SEW\22202 0-7695-1854-0/02 $17.00 \251 2002 IEEE 


20  251 2002 Tim Menzies, Gary D. Boetticher Page  SEW-27 Tutorials '02 East-West trains 1. TRAINS GOING EAST 2. TRAINS GOING WEST 1 2 3 4 5 1 2 3 4 5 1. TRAINS GOING EAST 2. TRAINS GOING WEST 1 2 3 4 5 1 2 3 4 5 251 2002 Tim Menzies, Gary D. Boetticher Page  SEW-27 Tutorials '02 ILP representation  Example eastbound\(t1  Background theory car\(t1,c1\      car\(t1,c2\       car\(t1,c3\.      car\(t1,c4 rectangle\(c1\  rectangle\(c2\     rectangle\(c3\.   rectangle\(c4 short\(c1\      long\(c2\.          short\(c3\       long\(c4 none\(c1\.        none\(c2\.          peaked\(c3\.      none\(c4 two_wheels\(c1\  three_wheels\(c2\two_wheels\(c3\two_wheels\(c4 load\(c1,l1\.     load\(c2,l2\       load\(c3,l3\    load\(c4,l4 circle\(l1\      hexagon\(l2\       triangle\(l3\    rectangle\(l4 one_load\(l1\  one_load\(l2\.      one_load\(l3\    three_loads\(l4  Output ne\(C Proceedings of the 27th Annual NASA Goddard Software Engineering Workshop \226 Tutorial Notes \(SEW\22202 0-7695-1854-0/02 $17.00 \251 2002 IEEE 


21  251 2002 Tim Menzies, Gary D. Boetticher Page  SEW-27 Tutorials '02 Predicting Correctness Almei NewID CN2 C4.5 C4.5_rule FOIL Accuracy 52 54 66 68 73 251 2002 Tim Menzies, Gary D. Boetticher Page  SEW-27 Tutorials '02 FOIL\222s best rule high\(A executable\(A,B maximum_statement_nesting_depth\(A,C lines_of_comments\(A,B commentsdivsize\(A,E n1\(A,F n2\(A,G less_or_equal\(E,F not less_or_equal\(B,G C <> 4 C <> 43 less_or_equal\(C,D High faults when comment density <= #operators and executable statements > #operators and max nesting <= number of lines of comments and max nesting is not 4 or 43 High faults when comment density <= #operators and executable statements > #operators and max nesting <= number of lines of comments and max nesting is not 4 or 43 Proceedings of the 27th Annual NASA Goddard Software Engineering Workshop \226 Tutorial Notes \(SEW\22202 0-7695-1854-0/02 $17.00 \251 2002 IEEE 


22  251 2002 Tim Menzies, Gary D. Boetticher Page  SEW-27 Tutorials '02 Inside  some learners  neural nets  genetic algorithms  decision tree learners  association rule learners  treatment learners  bayesian tuning  inductive logic programming 225 sub-symbolic locally guided descent symbolic, global search 225 recursive diversity reduction 225 this goes with that CLASS 225 this goes with that 225 asses 225 a little model goes a long way 225 Horn clauses  251 2002 Tim Menzies, Gary D. Boetticher Page  SEW-27 Tutorials '02 Case studies predicting effort \(45 predicting faults \(51 model-based ML \(54 early lifecycle project planning \(60 Proceedings of the 27th Annual NASA Goddard Software Engineering Workshop \226 Tutorial Notes \(SEW\22202 0-7695-1854-0/02 $17.00 \251 2002 IEEE 


23  251 2002 Tim Menzies, Gary D. Boetticher Page  SEW-27 Tutorials '02 Case study How can we estimate earlier in the life cycle  251 2002 Tim Menzies, Gary D. Boetticher Page  SEW-27 Tutorials '02 Predicting development times in months\Srinivasan95 Proceedings of the 27th Annual NASA Goddard Software Engineering Workshop \226 Tutorial Notes \(SEW\22202 0-7695-1854-0/02 $17.00 \251 2002 IEEE 


24  251 2002 Tim Menzies, Gary D. Boetticher Page  SEW-27 Tutorials '02 Bayes for effort Chulani99  The COCOMO-II project  Open-source software cost estimation  Reuse vs effort XH : multiple product lines VH : across product lines H : across program N : across project L  : none  Regression over data from 83 software projects  Regression conflicted with \223Delphi values\224  Tune regression values using Delphi expectations 0.8 0.9 1 1.1 1.2 1.3 1.4 1.5 1.6 Low N H VH XH Delphi Regression Adjusted Da ta   reus e low e rs effo r t Ex pe ct e d  reus e incre a se  effo r t    251 2002 Tim Menzies, Gary D. Boetticher Page  SEW-27 Tutorials '02 COCOMO-II \(1998\COCOMO-II \(1997 Pred\(30 Pred\(25 Pred\(20 Pred\(X 52 49 46 83 projects 63 59 54 161 projects 7561 68 55 63 48 161 projectsbased on Bayesian 161 projectsbased on Delphi Percentage of estimated effort within X of actual Conclusion data + delphi tuning\a Proceedings of the 27th Annual NASA Goddard Software Engineering Workshop \226 Tutorial Notes \(SEW\22202 0-7695-1854-0/02 $17.00 \251 2002 IEEE 


25  251 2002 Tim Menzies, Gary D. Boetticher Page  SEW-27 Tutorials '02 Neural Network Count the wi dge ts in the I n te r f ace to es ti m a te e f f o r t  Labels Edit Boxes Grid Boxes Check Boxes Buttons 251 2002 Tim Menzies, Gary D. Boetticher Page  SEW-27 Tutorials '02 Neural Network Subsystem Pred\(25 MARE Buyer Admin 80 17.6 Buyer Client 80 14.6 Distribution Server 20 96.7 Supplier Client 90 12.2  12 Different Widgets Counted and associated with effort Proceedings of the 27th Annual NASA Goddard Software Engineering Workshop \226 Tutorial Notes \(SEW\22202 0-7695-1854-0/02 $17.00 \251 2002 IEEE 


26  251 2002 Tim Menzies, Gary D. Boetticher Page  SEW-27 Tutorials '02 Case study: Predicting software 251 2002 Tim Menzies, Gary D. Boetticher Page  SEW-27 Tutorials '02 Predicting software  faults Khoshgoftaar99 Whi c h d o g s di d not ba r k  225 42 attri b ute s  in dat a s e t 225 Only 6 in the l e arnt th e o ry Diffe re nt attri b ute s than b e fore 225 223c au se s f a u l t 224  do m a in s pec i f i c 225 Me thod for fin d ing fa ult s  gen e r a l Whi c h d o g s di d not ba r k  225 42 attri b ute s  in dat a s e t 225 Only 6 in the l e arnt th e o ry Diffe re nt attri b ute s than b e fore 225 223c au se s f a u l t 224  do m a in s pec i f i c 225 Me thod for fin d ing fa ult s  gen e r a l Proceedings of the 27th Annual NASA Goddard Software Engineering Workshop \226 Tutorial Notes \(SEW\22202 0-7695-1854-0/02 $17.00 \251 2002 IEEE 


27  251 2002 Tim Menzies, Gary D. Boetticher Page  SEW-27 Tutorials '02 Issue of generality  Specific conclusions may not apply to general projects  Proposal one  Intra-project learning  Lessons should generalize across the same developer methodology, application and tool set  Proposal two  Inter-project learning  Need larger training set  COCOMOII uses 161 projects  Note: two = N * one Khoshgoft good bad Tia bad good  251 2002 Tim Menzies, Gary D. Boetticher Page  SEW-27 Tutorials '02 Model-based ML Bratko89,Pearc Proceedings of the 27th Annual NASA Goddard Software Engineering Workshop \226 Tutorial Notes \(SEW\22202 0-7695-1854-0/02 $17.00 \251 2002 IEEE 


28  251 2002 Tim Menzies, Gary D. Boetticher Page  SEW-27 Tutorials '02 Model-based ML simple e.g sum\(X,  Y Z sum   sum   sum\(0 0 0 sum 0  sum 0  sum\(0   sum\(0   sum  Any sum  Any if X >0 X\222=      if X < 0 0 if X= 0  switch\(State,Volts,Amps switch\(on,       0,     Any switch\(off,      Any,   0 blub\(Mode,Light,Volts,Amps bulb\(blown,dark, Any 0 bulb\(ok,     light   bulb\(ok,    light   bulb\(ok,    dark 0 0 251 2002 Tim Menzies, Gary D. Boetticher Page  SEW-27 Tutorials '02 A qualitative circuit go  :tell\('circ.data'\ go1, told go1 :functor\(X,circuit,9\ forall\(X, example\(X example\(circuit\(Sw1,Sw2,Sw3,B1,B2,B3,L1,L2,L3\classification\(B1,B2,B3,Class format\('~a,~a,~a,~a,~a,~a,~a~n Sw1,Sw2,Sw3,L1,L2,L3,Class  classification\(B1, B2, B3,Class needs 2 our of three bulbs working classification\( ok, ok, B3,   good classification\( ok, B2, ok,   good classification\( B1, ok, ok,   good classification\( B1, B2, B3,   bad Proceedings of the 27th Annual NASA Goddard Software Engineering Workshop \226 Tutorial Notes \(SEW\22202 0-7695-1854-0/02 $17.00 \251 2002 IEEE 


29  251 2002 Tim Menzies, Gary D. Boetticher Page  SEW-27 Tutorials '02 Results from > 700 examples circ.names good,bad switch1: on, off switch2: on, off switch3: on, off bulb1: light, dark bulb2: light, dark bulb3: light, dark Command line c4.5 -f circ -m 2 W a t c hing bulb1 tells us th e rest Insight f ul  Or dull W a t c hing bulb1 tells us th e rest Insight f ul  Or dull 251 2002 Tim Menzies, Gary D. Boetticher Page  SEW-27 Tutorials '02 More Model-based ML Proceedings of the 27th Annual NASA Goddard Software Engineering Workshop \226 Tutorial Notes \(SEW\22202 0-7695-1854-0/02 $17.00 \251 2002 IEEE 


30  251 2002 Tim Menzies, Gary D. Boetticher Page  SEW-27 Tutorials '02 ca n we r e v i s i t thos e warranti e s   Run 1 35,000 tions  Learn 1  Run 2 if Sw2c=off then 3264 tions  Learn 2  Run 2 if Sw2c=off n then 648 tions  Learn 3 Ca n\222t clos e  Sw3c warranty issu es No b u d g e t  for e x p e ns i v e ha rd wa r e 251 2002 Tim Menzies, Gary D. Boetticher Page  SEW-27 Tutorials '02 3 \223tunings\224 5 SLOC guesstimates 150,000 runs Treatments for software projects Proceedings of the 27th Annual NASA Goddard Software Engineering Workshop \226 Tutorial Notes \(SEW\22202 0-7695-1854-0/02 $17.00 \251 2002 IEEE 


31  251 2002 Tim Menzies, Gary D. Boetticher Page  SEW-27 Tutorials '02 flex=1 pmat=3 sced=2 rest anything from kc1 150,000 runs 150,000 runs Treatments for software projects \(ii 251 2002 Tim Menzies, Gary D. Boetticher Page  SEW-27 Tutorials '02 pmat=2 acap=2 sced=2 rest anything from kc1 30,000 runs 30,000 runs Treatments for software projects \(iii Proceedings of the 27th Annual NASA Goddard Software Engineering Workshop \226 Tutorial Notes \(SEW\22202 0-7695-1854-0/02 $17.00 \251 2002 IEEE 


32  251 2002 Tim Menzies, Gary D. Boetticher Page  SEW-27 Tutorials '02 ons discussion \(64 downloads \(69 further reading \(71 references \(72 251 2002 Tim Menzies, Gary D. Boetticher Page  SEW-27 Tutorials '02 Will you try ML  Have we motivated you  Will you rush home and do ML on your data  Clearly  ML algorithms work  Caution  you may find it harder than you think Proceedings of the 27th Annual NASA Goddard Software Engineering Workshop \226 Tutorial Notes \(SEW\22202 0-7695-1854-0/02 $17.00 \251 2002 IEEE 


33  251 2002 Tim Menzies, Gary D. Boetticher Page  SEW-27 Tutorials '02 Many ways to learn numerous case studies but there is still a problem Theme Learning is a solved problem \(sort of Data collecting and modeling is not 251 2002 Tim Menzies, Gary D. Boetticher Page  SEW-27 Tutorials '02 Be warned match your ML goals to your software process level Project metrics coarse-grain conclusions Product metrics product learning Process metrics process learning Proceedings of the 27th Annual NASA Goddard Software Engineering Workshop \226 Tutorial Notes \(SEW\22202 0-7695-1854-0/02 $17.00 \251 2002 IEEE 


34  251 2002 Tim Menzies, Gary D. Boetticher Page  SEW-27 Tutorials '02 Also, match your tool to task Task ML Tool Assembly line robot deciding what to reject Decision tree learner Repair robot trying to do the least to fix the rejected parts Treatment learner Predicting the life of a robot Neural Network Optimizing the assembly line Genetic Algorithm If clustering when no classes iation rule learning If simple background knowledge Bayesian If complex relational background knowledge ILP 251 2002 Tim Menzies, Gary D. Boetticher Page  SEW-27 Tutorials '02 Have we learnt enough  Not yet  But wait Proceedings of the 27th Annual NASA Goddard Software Engineering Workshop \226 Tutorial Notes \(SEW\22202 0-7695-1854-0/02 $17.00 \251 2002 IEEE 


35  251 2002 Tim Menzies, Gary D. Boetticher Page  SEW-27 Tutorials '02 Cost = $0  WEKA  E.g. http://www.cs.waikato.ac.nz/~ml/weka/: ML in JAVA 003 decision tree inducers,rule learners, naive Bayes, decision tables locally weighted regression  GDB_Net  http://nas.cl.uh.edu/boetticher/gdb_net.zip  TAR2  http://www.ece.ubc.ca/twiki/bin/view/Softeng/TreatmentLearner  APRIORI  http://fuzzy.cs.uni-magd eburg.de/~borgelt/apriori/apriori.html#download  And many others  E.g. ML  A public domain \223C\224 library of common algorithms  Naive Bayes, ID3, MC4 , Decision Tables ,   Holte's OneR CN2,\205  http://www.sgi.com/tech/mlc/utils.html 251 2002 Tim Menzies, Gary D. Boetticher Page  SEW-27 Tutorials '02 Cost > $0  C4.5  Comes with the book Quinlan  C5.0  http://www.rulequest.com/download.html  Microsoft SQL SERVER 2000\231  Comes with numerous machine learning tools  Proprietary algorithms  Etc  223data mining\224 \223commercial software\224 in Google  3,340 links  223data mining consultancy\224 in Google  850 links Proceedings of the 27th Annual NASA Goddard Software Engineering Workshop \226 Tutorial Notes \(SEW\22202 0-7695-1854-0/02 $17.00 \251 2002 IEEE 


36  251 2002 Tim Menzies, Gary D. Boetticher Page  SEW-27 Tutorials '02 Further reading  Mendonca  great rev i e w art i cl e on ML  Large list of available tools  All the things you can do with a decision tree [Menzies0  Treatment learning: [Menzies01a  Michalski\222s excellent survey of ML types [Michalski  Neural nets: [Boetticher01  Special issue SEKE journal, knowledge discovery Morasca99  Inductive logic programming [Bergadano95,Cohen95  Come by IJCAI 2011 and I\222ll tell you all about it\222s applications  Genetic algorithms: [Goldberg8  Bayesian learning [Cheeseman88 251 2002 Tim Menzies, Gary D. Boetticher Page  SEW-27 Tutorials '02 References  Agrawal  Agrawal, R., and T.Imeilinski and A.Swami \223Mining Association Rules between Sets of Items in Large Databases,\224 Proceedings of the 1993 ACM SIGMOD Conference Washington DC, USA  Bergadan  Bergadano, F., and D.Gunetti Inductive Logic Programming: From Machine Learning to Software Engineering The MIT Press, 1995  B  Berry, M. J. A., and G., Linoff Data Mining For Marketing, Sales, and Customer Support John Wiley Sons, Inc., New York, 1997  Boetticher01  Boetticher, G., "An Assessment of Metric Contribution in the Construction of a Neural Network-Based Effort Estimator Second International Workshop on Soft Computing Applied to Software Engineering  Enschade, NL, 2001 Available from http://nas.cl.uh.edu/boetticher/publications.html  Boetticher01  Boetticher, G., "Using Machine Learning to Predict Project Effort: Empirical Case Studies in Data-Starved Domains First International Workshop on Model-based Requirements Engineering San Diego, 2001 Available from http://nas.cl.uh.edu/boetticher/publications.html  Bradley  Bradley, P., U. Fayyad, and C. Reina. \223Scaling clustering algorithms to large databases\224. In KDD'98  B  Bratko, I., I. Mozetic, and N. Lavrac KARDIO: a Study in Deep and Qualitative Knowledge for Expert Systems MIT Press, 1989  Breim  Breiman, L., J. Friedman, R. Olshen, C. Stone, \223Classification and Regression Trees,\224 Wadsworth International Group, 1984 Proceedings of the 27th Annual NASA Goddard Software Engineering Workshop \226 Tutorial Notes \(SEW\22202 0-7695-1854-0/02 $17.00 \251 2002 IEEE 


37  251 2002 Tim Menzies, Gary D. Boetticher Page  SEW-27 Tutorials '02 References  Burgess  Burgess, C.J., and Martin Lefley. \223Can genetic programming improve software effort estimation? A comparative evaluation,\224 Information and Software Technology er 2001  Cheesem  P. Cheeseman, D. Freeman, J. Kelly, M. Self, J. Stutz, and W. Taylor. \223Autoclass: a bayesian classification system,\224 In Proceedings of the Fifth International Conference on Machine Learning  Morgan Kaufman, 1988  Chulani  S.Chulani,  B. Boehm, and B. Steece 223Bayesian analysis of empirical software engineering cost models,\224 IEEE Transaction on Software Engineering 25\(4\ly/August  1999  Cohe  W. W. Cohen, \223Inductive specification recovery: Understanding software by learning  from example behaviors,\224 Automated Software Engineering 2:107-129, 1995  DeJon  DeJong, K.A., and Spears, W.M. "An Analysis of the Interacting Roles of Population Size and Crossover in Genetic Algorithms Proc. First Workshop Parallel Problem Solving from Nature  Springer-Verlag, Berlin, 1990  Dietteric  Dietterich, T. G., \223Machine Learning  Research: Four Current Directions,\224 AI Magazine 18 \(4\97 Pp. 97-136. Available from ftp://ftp.cs.orst.edu/pub/tgd/papers/aimag-survey.ps.gz  s  Feather, M.S., and T. Menzies: \223Converging on the Optimal Attainment of Requirements IEEE Joint Conference On Requirements Engineering  ICRE'02 and  RE'02 9-13th September, University of Essen, Germany, 2002. Available from http://tim.menzies.com/pdf/02re02.pdf 251 2002 Tim Menzies, Gary D. Boetticher Page  SEW-27 Tutorials '02 References  Fenton00  Fenton, N., and  M. Neil \223Software Metrics: A Roadmap,\224 International Conference on Software Engineering, 2000. Available from http://www.dcs.qmul.ac.uk/~norman/papers/metrics_roadmap.pdf  Goldberg  Goldberg, D.E Genetic Algorithms in Search, Optimization, and Machine Learning Addison-Wesley Reading, Massachusetts, 1989  Khoshgoftaar  Khoshgoftaar, T.M., and E.B. Allen. \223Model software quality with classification trees,\224 in H. Pham, editor 223Recent Advances in Reliability and Quality  Engineering\224, World Scientific, 1999  Mendonc  Mendonca, M., and N.L. Sunderhaft, \223Mining Software Engineering Data: A Survey,\224 A DACS State-ofthe-Art Report September 1999. Available from http://www.dacs.dtic.mil/techs/datamining  Menzie  Menzies, T., \223Practical Machine Learning for Software Engineering and Knowledge Engineering,\224 ftware Engineering and Knowledge Engineering volume 1, 2001\vailable from http://tim.menzies.com/pdf/00ml.pdf  Menzies01a  Menzies, T., and Y. Hu, \223Reusing models for requirements engineering,\224 First International Workshop on Model-based Requirements Engineering 2001. Available from http://tim.menzies.com/pdf/01reusere.pdf  Menzies01b  Menzies, T., and Y. Hu, \223Constraining discussions in requirements engineering,\224 First International Workshop on Model-based Requirements Engineering San Diego, 2001. Available from http://tim.menzies.com/pdf/01lesstalk.pdf  Menzie  Menzies. T., and J. Kiper, \223Better reasoning about software engineering activities,\224 Automated Software Engineering 2001. Available from http://tim.menzies.com/pdf/01ml4re.pdf Proceedings of the 27th Annual NASA Goddard Software Engineering Workshop \226 Tutorial Notes \(SEW\22202 0-7695-1854-0/02 $17.00 \251 2002 IEEE 


38  251 2002 Tim Menzies, Gary D. Boetticher Page  SEW-27 Tutorials '02  Michalski90   Michalski, R.S., \223Toward a unified theory of learning,\224  In B.G. Buchanan and D.C. Wilkins, editors 223Reading in Knowledge  Acquisition and Learning\224, pages 7--38. Morgan Kaufmann, 1993  Mitchell  Mitchell, T Machine Learning McGraw-Hill, 1997  Morasca99  Morasca, S., and Gunther Ruhe, Guest editors' introduction of the Special issue on \223Knowledge Discovery from Software Engineering Data,\224 International Journal of Software Engineering and Knowledge Engineering October, 1999  Pearce  Pearce, D., \223The induction of fault diagnosis systems from qualitative models,\224 in Proc. AAAI-88 1988  Poole9  Poole, D. L.,  A. K. Mackworth, and R. G. Goebel Computational Intelligence: A Logical Approach  Oxford University Press, New York, 1998  Porter9  Porter, A.A., and R.W. Selby  \223Empirically guided software development using metric-based classification trees,\224 IEEE Software Pp. 46-54, March 1990  Quinla  Quinlan, R C4.5: Programs for Machine Learning Morgan Kaufman, 1992  Srinivasa  Srinivasan, K., and D. Fisher,  \223Machine learning approaches to estimating software development effort,\224 IEEE Transactions on Software Engi neering Pp. 126-137, February 1995  Tian9  Tian, J., and M.V. Zelkowitz 223Complexity measure evaluation and selection,\224 IEEE Transactions on Software Engineering 21\(8\p. 641-649,  August 1995  Webb0  Webb, G., \223Efficient search for association rules,\224 Proceeding of KDD-2000 Boston, MA,  2000  Zhang0  Zhang, Du, \223Applying Machine Learning Algorithms in Software Development,\224 Modelling Software System Structures in a fastly moving scenario Santa Margherita Ligure, Italy, 2000 References Proceedings of the 27th Annual NASA Goddard Software Engineering Workshop \226 Tutorial Notes \(SEW\22202 0-7695-1854-0/02 $17.00 \251 2002 IEEE 


