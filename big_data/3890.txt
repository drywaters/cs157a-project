Parallel Algorithm for Mining Fuzzy Association Rules  000h Baowen Xu 1 2 Jianjiang Lu 1 2,3 Yingzhou Zhang 1,2 Lei Xu 1,2 Huowang Chen 4 Hongji Yang 5 1 Department of Computer Science and Engineering, Southeast University, Na\njing, 210096, China 2 Jiangsu Institute of Software Quality, Nanjing, 210096, China 3 
PLA University of Science and Technology, Nanjing, 210007, China 4 School of Computer Science, National University of Defense Technology, C\hangsha,410073, China 5 School of Computing, De Montfort University, Leicester, LE1 9BH, England 000h\000\003 This work was supported in part by the National Natural Science Foundation of China \(NSFC  60073012\ent al Research 973 Program of China \(2002CB312000 Research Foundation for the Doctoral Program of Higher Education of China, Natura l Science Foundation of Jiangsu Province, China \(BK2001004\tate Key Laboratory of Software Engineering in Wuhan 
University, and Opening Foundation of Jiangsu Key Laboratory of Computer Information Processing Technology in Soochow University Correspondence to:  Baowen Xu, Dept. of Computer Science and Engineering, Southeast University, Nanjing 210096, China.. E-mail bwxu@seu.edu.cn Abstract The principle and steps of the algorithm for mining fuzzy association rul es is studied, and the parallel algorithm for mining fuzzy association rules is presented. In this parallel mining algorithm quantitative attributes are partitioned into several fuzzy sets by the parallel fuzzy c-means algorithm, and fuzzy sets are applied to soften the partition boundary of the attributes. Then the parallel algorithm for mining Boolean association 
rules is improved to discover frequent fuzzy attributes. Last, the fuzzy association rules with at lea st fuzzy confidence are generated on all processors. The parallel mining algorithm is implemented on the distributed linked PC/workstation. The experiment results show that the parallel mining algorithm has fine scaleup, sizeup and speedup Keywords data mining; fuzzy association rules parallel; fuzzy clustering 1. Introduction The mining of association rules is one of the most important issues in the fiel d of data mining. The problem of mining Boolean association 
rules over basket data is introduced in There are m a ny known algorithm s for mining Boolean associati on rules, such as Apriori 2  DHP 3 etc. As the database size becomes larger and larger, a better way is to mine association rules in parallel Some parallel association rule mining algorithms have   Recently, people have got interested in quantitative attributes. The problem of mining quantitative association rules is introduced in [6]. Th e algorithm finds association rules by partitioning the attribute domain combining adjacent partitions, and then transforming the 
problem into binary one. Although this mining algorithm of quantitative association ru le can solve problems introduced by quantitative attributes, it introduces some other problems. The first probl em is that equi-depth partitioning cannot embody the actual distribution of the data On the one hand, it may not work very well on highly skewed data and tends to split adjacent values with high support into separate in tervals though their behavior would typically be similar On the other hand, it is not easy to distinguish the degree of membership. For instance, age of 50 and age of 70 will both be classified into the old. However, we intuitively know that age of 70 is much older than age of 50. The second problem is 
caused by the sharp boundary between intervals. The algorithm either ignores or over-emphasizes the elements near the boundary of the intervals in the mining process Ref uses fuzzy set to soften partition boundary of the domains, and presents the concept of fuzzy association rules, but it does not present partitioning algorithm which can embody the actual dist ribution of the data and does not present the mining al gorithm for fuzzy association rules which relational fuzzy c means algorithm to partition the quantitative attributes into sev eral fuzzy sets, then the problem of mining fuzzy associa tion rules is introduced 
by combining fuzzy sets. The relational fuzzy c means algorithm can embody the actual distribution of the data Furthermore, fuzzy sets can soften partition boundary But combining fuzzy sets can obtain excessive fuzzy association rules, so the mining algorithm cannot fit for large database. The improved algorithm for mining fuzzy association rules, which fits for large database, is presented in This m i ning algorithm consists of three parts Proceedings of the 2003 International Conference on Cyberworlds \(CW\22203 0-7695-1922-9/03 $ 17.00 \251 2003 IEEE 


1 Quantitative attributes are partitioned into several fuzzy sets by the fuzzy c means \(FCM 2 Discovering frequent fuzzy attributes 3 Generating fuzzy association rules with at least a minimum confidence from frequent fuzzy attributes In this paper, the parallel algorithm for mining fuzzy association rules is discussed. In this parallel mining algorithm, quantitative attributes are first partitioned into several fuzzy sets by the parallel fuzzy c means algorithm. Secondly, the parallel algorithm for mining Boolean association rules is improved to discover frequent fuzzy attributes. Last, the fuzzy association rules with at least fuzzy confidence are generated on all processors. The parallel algorith m is implemented on the distributed linked PC/worksta tion. The experiment results show that the parallel mining algorithm has fine scaleup sizeup and speedup 2.The algorithm for mining fuzzy association rules Let  21 n tttT  000 be a relational database j t represents the j th record in T let  21 m iiiI  000 be the attribute set where j i denotes a boolean, categorical or quantitative attribute   kj it represents value of the j th record in attribute k i Values of the record in attribute need to be partitioned into several fuzzy sets for mining fuzzy association rules Let 1 A and 2 A be two values of the record in boolean attribute, then two values can be partitioned into two fuzzy sets 1 A and 2 A  2 1 1 0 1  Ax Ax xA 000 000 000 1 2 2 0 1  Ax Ax xA 000 000 000 Categorical attribute with fewer values can be partitioned into several fuzzy sets with the same method Each quantitative attribute is pa rtitioned into several fuzzy sets by FCM algorithm   For example, the process of using FCM algorithm to partition quantitative attribute k i into c fuzzy sets is given below. Put the values taken by attribute k i together as a set of samples X Let  ijij vxd 000\020\000  m 2, matrix norm is the maximum element of the matrix. After clustering with the FCM algorithm, partition matrix U and c centers i v are obtained In order to mine fuzzy association rules, we first construct a new database through original database T In this new database, attributes are fuzzy sets; values of the record in attributes are obtained as follows: Let 1 k i be a fuzzy set of attribute k i  1 k i is an attribute in new database Value of the j th record in attribute 1 k i is    1 kjk iti     1 kjk iti is membership value of   kj it with respect to fuzzy set 1 k i In this new database, because attributes are fuzzy sets, we call attributes fuzzy attributes next. Let I still be the fuzzy attribute set, let  kj yt represent value of the j th record in fuzzy attribute k y   kj yt  Let IyyyX p 000\215\000  21  IyyyY qppp 000\215\000 000\016\000\016\000\016  21  Y X 000\210  000\207 An association rule is an implication of the form YX 000\237 Because attributes in X and Y are fuzzy attributes YX 000\237 is called fuzzy association rule. The fuzzy support and fuzzy confid ence of fuzzy association rule are defined as follows 9  Definition 1 Let fuzzy attribute set IyyyX p 000\215\000  21  the fuzzy support of X is defined as follows n yt XFSup n j p m mj 000\246 000\226 000 000 000 1 1   where 000\246 000\226 000 000 n j p m mj yt 1 1  is called as the fuzzy support count Fuzzy attribute sets with at least a minimum fuzzy support are called frequent fuzzy attribute sets Definition 2  The fuzzy support of YX 000\237 is defined as follows n yt FSup n j qp m mj 000\246 000\226 000 000\016 000 000 1 1  Definition 3  The fuzzy confidence of YX 000\237 is defined as follows  XSup Sup FConf 000 Because  kj yt  subsets of a frequent fuzzy attri bute set must also be frequent according to definition 1. So it is easy to modify Apriori algorithm 2 to mine fuzzy association rules. The   3. Partition the quantitative attributes Quantitative attributes are partiti oned into several fuzzy sets by the FCM algorithm in section 2. As the database Proceedings of the 2003 International Conference on Cyberworlds \(CW\22203 0-7695-1922-9/03 $ 17.00 \251 2003 IEEE 


size becomes larger and larger, FCM algorithm requires lots of computation power, main memory and disk I/O Lamehamedi H. presents the parallel fuzzy c means PFCM  The PFCM algorithm is developed following a master/sla ve approach. The computation is iterative and consists of s slaves controlled by the master In order to implement th e parallel algorithm for mining fuzzy association rules on the distributed linked PC/workstation, we improve the master/slave approach to the single program/multi da ta approach. Indeed, the PFCM algorithm is shown in Algorithm 1 Algorithm 1.  PFCM algorithm PFCM1 The values taken by each attribute are regarded as the initial set of patterns. Partition the initial set of patterns among the processes. Each process will get n/s patterns. Where n is the number of patterns and s is the number of the processes launched sProcess2Process1Process  1\(/21\/\(/21 nsnssnsnsn xxxxxxx  000\016\000\020\000\016 PFCM2 Initialize the civ i 2,1  000 on the root process, and broadcast them to all processes PFCM3 Each process receives civ i 2,1  000 and computes the membership values of the patterns it holds. Each process j operates separately on its subset of data 1/\1 sjnsnjkx k  000\016\000\020\000 this step is the end of the initialization part kivxvxu c j m AjkAikik         1 1 1\(2 0,0,0 000\005\000\020\000\020\000 000\020 000 000\020 000\246 For t 1 to T PFCM4 Each process computes 000\246 000 000\020 000 xsize k k m tikji xu 1 1  000D 000\246 000 000\020 000 xsize k m tikji u 1 1  000E where snxsize  000 is the number of patterns receive by each process PFCM5 Each process j sends these results ji  000D and ji  000E  the root process, which then aggregates to compute ti v  and broadcasts to all processes civ s j ji s j jiti 2,1 1  1   000 \000 000\246\000\246 000 \000 000E 000D PFCM6 Each process receives the value of the cluster centers and computes the membership values of the patterns Each process operates separately on its subset of data kivxvxu xsize j m AtjkAtiktik         1 1 1\(2  000\005\000\020\000\020\000 000\020 000 000\020 000\246 PFCM7 Each process computes the error. The portion of error at each process j is computed and then sent to the root process 000\246\000\246 000 \000 000\020 000 \000\020\000 xsize k c i tiktikj sjforuuerror 11 2 1 2,1  PFCM8 The errors are aggregated at the root process 2/1 1  000\246 000 000 s j jt errorE if 000H 000\037 t E then stop Algorithm 2.  PMFAR algorithm Inp ut Subset of data i D 2,1 si  000  minFsup  minFconf  Output Fuzzy association rules \(FARs Parameter: nproc \(the number of process\yid \(process label\ysize \(data size of the subset\pPMat \(partial partial fuzzy association rules  Methods  MPI_Init \(&argc,&argv Get the number of process MPI_Comm_size \(MPI_COMM_WORLD, &nproc Get the process label MPI_Comm_rank \(MPI_COMM_WORLD, &myid Read in the subset of data i D  Data_input D i  The processes are synchronous MPI_Barrier \(MPI_COMM_WORLD If \(myid==0 startwtime=MPI_Wtime for \(cl=0; cl<COLUMN; cl Clustering by PFCM PFCM D i mysize, cl, pPMa  Construct a new database Transform \(pPMat istree=ist_create \(m, minFsupp, minFconf Discover frequent fuzzy attributes do for \(i=0;i<mysize;i ist_count \(istree, pPMat, mysize, i extract_count \(istree, LCntArr MPI_Reduce_scatter \(LCntArr, PartGCntArr PartSize, MPI_SUM, MPI_COMM_WORLD MPI_Allgatherv \(PartGCntArr, PartSize[my  GCntArr, PartSize, disp, MPI_COMM_WORLD Writeback_count \(GCntArr, istree l=ist_addlvl \(istree while \(l==0 Parallel generating fuzzy association rules Gen_rule \(istree, pFARs If \(myid==0 MPI_Gather \(pFARs FARs, MPI_COMM_WORLD endwtime = MPI_Wtime printf \("wall clock time = %f\\n",endwtime-startwtime  MPI_Finalize If \(myid==0  Proceedings of the 2003 International Conference on Cyberworlds \(CW\22203 0-7695-1922-9/03 $ 17.00 \251 2003 IEEE 


4. Parallel mining fuzzy association rules Parallel mining Boolean association rules is introduced in Two parallel algorithm s Count Distribution and Data Distribution are proposed The Count Distribution algorithm scales linearly and has excellent speedup and sizeup behavior with respect to the number of transactions. In this paper, we adopt the similar idea of the Count Distribution algorith m to design parallel algorithm for mining fuzzy association rules \(PMFAR The key step for generating frequent fuzzy attribute sets is obtaining the whole fuzzy support count by exchanging the local fuzzy support count of the candidate fuzzy attribute sets. First, each process obtains local fuzzy support count of the candidate fuzzy attribute sets from hash tree asynchronously and put into the array LcntArr Second, each process aggregates to compute components of the array by function MPI_Reduce_Scatter \(\and broadcasts them to each process, which only receives the whole fuzzy support count with respect to its partition Third, each process gathers the whole fuzzy support count of the candidate fuzzy attribute sets to the array GcntArr by function MPI_AllGatherv based on the message passing interface \(MPI Algorithm 2 5. Experimental results We implemented our parallel algorithm for mining fuzzy association rules on the distributed linked PC/workstation. This workst ation consists of six computers with 128,000 KB of real memory, which are interconnected via a 10M/100M hub. We use the parallel message passing software MPICH1.2.4 The experiment is implement ed on an abalone dataset from UCI machine learning. We first copy abalone dataset 32 times, and obtain a 5.72MB dataset with 133,664 records, which is regarde d as the initial dataset. The performance of scaleup, sizeup and speedup are analyzed To see how well our parallel algorithm handles large dataset when more computers are available, we perform scaleup experiments where the dataset is copied from the initial dataset in direct proportion to the number of the computers in the workstation. The number of maximal processors is set to 6.  In the experiment, attributes are partitioned into three fuzzy sets by PFCM algorithm. Let minimum fuzzy support be 0.01, let minimum fuzzy confidence be 0.1. The performance results of scaleup are shown in figure 1 We fix the size of the computers at 4 in the workstation, while growing th e dataset from 1.5MB per computer to 9MB.  Figure 2 shows the performance results of sizeup. The results show subliner performance for our parallel algorithm. Our parallel algorithm is actually more efficient as the dataset size is increased since increasing the size of the dataset simply makes the non-communication portion of the code take more time due to more I/O and more transaction processing. This has the result of reducing the percentage of the overall time spent in communication  0 500 1000 1500 2000 2500 3000 3500 4000 02468 The number of processes Response timme sec 0 500 1000 1500 2000 2500 3000 3500 4000 0246810 Data size per process MB Response timme\(sec  0 500 1000 1500 2000 2500 3000 02468 The number of process Response timme\(sec  We perform Speedup experiments where we keep the dataset constant and vary the number of computers. We Figure 1.  Scaleup Figure 2.  Sizeup Figure 3.  Speedup Proceedings of the 2003 International Conference on Cyberworlds \(CW\22203 0-7695-1922-9/03 $ 17.00 \251 2003 IEEE 


use the initial dataset \(5.72MB\ber of maximal processors is set to 6. Figure 3 shows the performance results of Speedup 6. Related works  introduces the problem of m a intaining Boolean association rules and gives the FUP algorithm that can maintain Boolean association rules when new transactions add into more general algorithm, FUP2, which can maintain Boolean association rules when some records are inserted deleted uses negative borders to maintain rules Ref. [15] introduces the problem of mining Boolean association rules with weighted items introduces the problem  of mining Boolean association rules and fuzzy association rules with weighted items. Liu, Hsu and Ma propose classification based on associa tions \(CBA iterative method to find the frequent and accurate possible rule set and then uses method of elicitation to build classification system  But it is important to note that the intervals involved in quantitative association rules may not be concise and meaningful A fuzzy approach that can be used for mining interesting rul es for classification with degree of membership in  This approach represents the revealed regularities and exceptions using linguistic terms. The use of linguistic terms allows human users to better understand the discovered rules because of the affinity with the human knowledge representation Furthermore, this approach is capable of finding interesting relationships among attributes without any subjective input required of the users. Some results show that the classification me have good accuracy and interpretability than C4.5 and CBA 7. Conclusions We discuss the parallel algorithm for mining fuzzy association rules. In this parallel mining algorithm quantitative attributes are first partitioned into several fuzzy sets by the parallel fuzzy c means algorithm Secondly, the parallel algorithm for mining Boolean association rules is improved to discover frequent fuzzy attributes. Last, the fuzzy association rules with at least fuzzy confidence are generated on all processors. The parallel algorithm is implemented on the distributed linked PC/workstation. The experi ment results show that the parallel mining algorithm based on the MPI has fine scaleup, sizeup and speedup. Our parallel algorithm considers the number of the records mainly. In our parallel algorithm, the real memory of every computer must save all candidates fuzzy attribute sets. When the number of quantitative attributes is increasing, our parallel algorithm may be in effective. How to mine the fuzzy association rules in the database with lots of quantitative attributes is a further work References   R. Agrawal, T. Imieliski, and A. Swami, \215Mining association rules between sets of items in large databases\216 Proceedings of ACM SIGMOD Conference on Management of Data Washington DC, 1993, pp.207-216   R. Agrawal, R. Srikant, \215Fast algorithms for mining association rules\216 Proceedings of the 1994 International C onference on Very Large Databases  Santiago, Chile, 1994, pp.487-499   J.S. Park, M.S. Chen, and P.S. Yu, \215An effective hash-based algorithm for mining association rules\216 Proceedings of the 1995 ACM-SIGMOD International Conf erence on Management of Data  San Jose, CA, 1995, pp.175-186   R. Agrawal, J. C. Shafer, \215Parallel mining of association rules: design, implementation and experience\216 Special Issue on Data Mining, IEEE Transactions on Knowle dge and Data Engineering 1996,8\(6   E. H. Han, G. Karypis, V. Kumar, \215Scalable parallel data mining for association rules\216 Proc. ACM Conf Management of Data ACM Press, New York, 1997 pp. 277-288   R. Srikant, R. Agrawal, \215Mining quantitative association rules in large relational tables\216 Proceedings of the ACM -SIGMOD Conference on Management of Data Montreal, Canada, 1996, pp.112   M.K. Chan, F. Ada, and H.W. Man, \215Mining fuzzy association rules in database\216 Proceedings of the ACM Sixth International Conference on Information and Knowledge Management Las Vegas, Neveda 1997, pp.10-14   Lu Jianjiang, Song Zilin, Qian Zouping, \215Mining linguistic valued association rules\216 Journal of Software 2001,12\(4 in Chinese   Zou Xiaofeng, Lu Jianjiang, Song Zilin, \215Mining linguistic valued association rules\216 Journal of System Simulation 2002,14\(9\\(in Chinese   R.J. Hathaway, J.W. Davenport, and J.C. Bezdek 215Relational dual of the c means algorithms\216 Pattern Recognition 1989,22\(2   H. Lamehamedi, A. D. Bensaid, and E-G. Kebbal 215Adaptive programming: Application to a semisupervised point prototype clustering algorithm\216 International Conference on Parallel and Distributed Processing Techniques Las Vegas Nevada, USA, 1999, pp. 2753-2759 Proceedings of the 2003 International Conference on Cyberworlds \(CW\22203 0-7695-1922-9/03 $ 17.00 \251 2003 IEEE 


  D.W.L. Cheng, J. Han, V.T. Ng, \215Maintenance of discovered association rules in large databases: An incremental update technique\216 Proc. of the 12th ICDE. New Orleans, Louisiana 1996, pp.106-114   D.W.L. Cheng, S.D.Lee, B. Kao, \215A general incremental technique for maintaining discovered association rules\216 Proc. of the Fifth International Conference on Database Systems for Advanced Applications Melbourne, Australia, 1997, pp.185-194   S. Thomas, S. Bodagala, K. Alsabti, et al, \215An efficient algorithm for th e incremental updation of association rules in large databases\216 Proc. KDD'97  Newport Beach, California, USA, 1997, pp.263-266   Cai C H, Fu Ada W C, Cheng C H. et al 215 Mining association rules with weighted items\216 Proc of IEEE International Database Engineering and Applications Symposium Cardiff, Wales, U.K 1998, pp 68-77   Lu Jianjiang, \215Research on algorithms of mining association rules with weighted items\216 Journal of Computer Research and Development 2002,39\(10 pp.1281-1286 \(in Chinese   B. Liu, W. Hsu, Y. Ma 215Integrating classification and association rule mining\216 Proceedings of the International Conf erence on Knowledge Discovery and Data Mining New York, 1998, pp.80-86   W.H. Au, K.C.C. Chan, \215Classification with degree of membership: A fuzzy approach\216 Proc. of the 1st IEEE Int'l Conf. on Data Mining San Jose, CA 2001, pp.35-42   Zou Xiaofeng, Lu Jianjiang, Song Zilin 215Classification system based on fuzzy class association rules\216 Journal of Computer Research and Development 2003, 40\(5 Proceedings of the 2003 International Conference on Cyberworlds \(CW\22203 0-7695-1922-9/03 $ 17.00 \251 2003 IEEE 


2          f o r  a l l  c a t e g o r i c a l              let          3          f o r  a l l  c a t e g o r i c a l              let           4   G i v e n  a n  m d i  o f       f o r  a l l  n u m e r i c       let           Given                   a n d                r       f o r  e a c h  c a t e g o r i c a l       a n d        o r       f o r  e a c h  c a t e g o r i c a l       from \(1 3 4 t h e  d e n s e n e s s  b e i n g  a  M I N T  m e a s u r e         f o r  e a c h  n u m e r i c       a n d        f o r  e a c h  n u m e r i c       Accordi n g l y         a n d         a n d  t h e  j o i n            g i v e s the upper bounds of       m a y  n o t  b e  u n i q u e   s i n c e  m u l tiple mdrs  s  c a n  b e  d e r i v e d   A l s o    m a y  n o t  e x i s t   s i n c e      c a n  b e  o b t a i n e d  i n   1    o r  t h e  m d r   can not exist, i.e      i n   4    F i g u r e  1  d e p i c t s  t h e s e  c a s e s   I n Figure 1. Derivation of  by join a  o f  t h e  c o m b i n e d  i t e m s e t    i s  m u l t i p l e  d u e  t o  t h e  l a c k of uniformity of     even if  and  of the original itemsets are unique respectively. In \(b  


nal itemsets are unique respectively. In \(b  does not exist due to the low denseness of       A c c o r d i n g l y    rived via       i s  a  f a m i l y  o f  s e t s  i n  g e n e r a l   T h e n  w e  o b t a i n  t h e  j o i n  o p e r a t i o n         b y  E q   2    F r o m  t h e  a b o v e d i s c u s s i o n                      a n d  t h u s       i l a r l y          T h i s  i n d i c a t e s  t h a t  t h e  j o i n      g i v e s  t h e upper bound of    a n d  a n  u p p e r  s e m i l a t t i c e    Based on this de?nition of join operation on families of sets with denseness and the de?nitions of support and con?dence, the most of the standard algorithms of the Basket Analysis whose complexity is       c a n  b e  a p p l i e d  t o  d e rive generic QARs from data 3.2. Implementation To assess the basic features of QARMINT, we used the standard Apriori-TID algorithm [1], since it is principally an algorithm running on memory, and its computational features are well known. Instead of hash tables, the trie data structure as depicted in Fig. 2 was used under lexicographically ordered itemsets. If any subsets of the joined s e t                a r e  n o t  f r e q u e n t  a c c o r d i n g  t o  a  g i v e n      i s  p r u n e d  b e f o r e  i t s  m d r   is computed. Moreover, after computing the mdr      i s  p r u n e d  i f    i s  n o t frequent. The pruning by these checks are indicated by the slashed itemsets in Fig. 2. A difference from the original Apriori-TID algorithm is that the join of two itemsets    within a family depicted by a solid box is not allowed, and t h e  i t e m s e t s   s  o b t a i n e d  f r o m  a  p a i r  o f  f a m i l i e s    l o n g  t o  a n  i d e n t i c a l  f a m i l y     A n o t h e r  d i f f e r e n c e  i s  t h a t  a join of     c a n  g e n e r a t e  m u l t i p l e  i t e m s e t s   s  a s  d e p i c t e d  i n a dashed box The most expensive process in QARMINT is to derive the mdr  s  o f  j o i n e d  i t e m s e t     W e  i n t r o d u c e  a n  i t e r a t i v e approach to reduce the required computation time. Given                     r s t   a l l  t r a n s a c t i o n s  i n  are sorted for each attribute   i n     T h i s  i s           T h e n  the mdis on the number line of  


are computed from the transactions without taking into account the other attributes When multiple mdis are obtained, one of them is focused and the transactions in the mdi is retained. Next, the identiProceedings of the The 2005 Symposium on Applications and the Internet Workshops \(SAINT-W  05 0-7695-2263-7/05 $20.00  2005 IEEE Figure 2. Trie data structure Figure 3. Time complexity cal process is applied to   and this recursively continues in depth ?rst search \(DFS   is computed, the process continues again from  until the mdi of every              c o n v e r g e s   T h e  m d i s  a l w a y s  c o n v e r g e to these of the mdr  because the denseness is a MINT measure. After the convergence, the search is backtracked to the next mdr  The computation of mdis in each step requires       t i m e  a t  m o s t   I n  t h e  w o r s t  c a s e   o n l y  o n e t r a n s a c t i o n  i s  d r o p p e d  i n  e a c h  s t e p   a n d    s t e p s  r e q u i r e d until the mdis converge. Thus         H o w e v e r   t h i s  d o e s not likely occur. Practically, only a portion of the transact i o n s  a r e  r e t a i n e d  i n  e a c h  s t e p   L e t          b e  a n  e x pected rate of transactions retained in each step the required steps for convergence. The process to search an mdr stops at the latest when the number of retained transa c t i o n s     b e c o m e s  l e s s  t h a n   By solving the equation       w i t h   is        A c cordingly, the expected time complexity of this most expensive process is         4. Performance Evaluation The performance of QARMINT has been evaluated through both arti?cial data and real bench mark data Sets of arti?cial data have been generated under various conditions. The characteristics of the computation time is simlilar to the conventional Basket Analysis except for       T h e  t i m e  m o d e r a t e l y  i n c r e a s e s  w h e n s of all attributes are increased. This is because wider permissible ranges increases the number of mdrs. Figure 3 shows the dependency of the computation time on the n u m b e r  o f  t r a n s a c t i o n      T h e  c u r v e  a l m o s t  f o l l o w s  t h e  r e lation         The real bench mark data  Labor relations Database  in UCI Machine Learning Repository [3] was analyzed by QARMINT. It contains 57 instances, 8 numeric attributes and 8 categorical attributes and many missing values. We ignored the attributes of missing values in each instance and transformed the data into transactions. Though the size 


and transformed the data into transactions. Though the size of this data is quite small, we found many interesting QARs associated with the labor conditions under      and      w h i c h  i s  1 0   o f  t h e  m a x i m u m  a n d  m i n i mum values of each  in the data. The following two are examples                                                                                                                  These rules indicate that the workers having longer durat i o n  c o n t r a c t s  a n d  e v a l u a t i n g  t h e i r  l a b o r  c o n d i t i o n  a s   admit longer working times and less wage increase. These evaluations indicate the suf?cient tractability and the practical applicability of QARMINT 5. Conclusion The mathematical characterization and the extension of the Basket Analysis presented in this paper are expected to provide variety of new approaches of data mining. Their potential has demonstrated by a novel approach called QARMINT for complete mining of generic QARs within a low time complexity. We are implementing QARMINT in a more ef?cient algorithm and evaluating its performance in near future Acknowledgement This research has conducted under the support of JSPS Kiban Kenkyuu \(B 2 References 1] R. Agrawal and R. Srikant. Fast algorithms for mining association rules. Proc. of 20th Int. Conf. on Very Large Data Bases VLDB  499, 1994 2] R. Srikant and R. Agrawal. Mining quantitative association rules in large relational tables. Proc. of 1996 ACM SIGMOD Int. Conf. on Management of Data, pages 1  12, 1996 3] U. C. I. \(UCI http://www.ics.uci.edu/ mlearn/MLRepository.html, 2004 4] J. Wijsen and R. Meersman. On the complexity of mining quantitative association rules. Data Mining and Knowledge Discovery, 2\(3  281, September 1998 Proceedings of the The 2005 Symposium on Applications and the Internet Workshops \(SAINT-W  05 0-7695-2263-7/05 $20.00  2005 IEEE 


0-7695-2263-7/05 $20.00  2005 IEEE pre></body></html 


n M L N n t n t n t n t L M L t L t L tt L t kkkk kkkk kkk kkkk kkkkkkkkP VK VK VK VK PP       kkP t 31 where L  s the error covariance associated with the state estimate t i    kkLX  tt kkk P1  00 0  0                     s s sss s s sss s s sssss N n t n t n 


n t n N n t n t n t n N n t n t n t n t n t n c t L kkkkkk kkkkk kP VKVK VKVK  32 4. Simulations One has run simulations comparing the sequential implementations of MSJPDA algorithm and the new algorithm here. A typical multisensor multitarget tracking environment is assumed in the simulations. According to article [1,3], One known that the performance of sequential MSJPDA is better than the performance of parallel MSJPDA. Therefore, the performance of parallel MSJPDA algorithm will not be compared here There are three sensors, which are fixed in three platforms. Regarding the 2nd sensor as fusion centre situation of the other sensors are: =?-500m?-500m 0m??N =?-500m? 500m?0m??The distance error of each sensor is: =300m, =200m, =100m?The bear error of each sensor is 0.03rad, =0.02rad, =0.01rad?The of sample is T=1s?The nonparametric model of clutter is used in the simulations, and expected number of false measurement is m=1.8 1 sN 3 s 1r 2 2r 3 3r 1 Simulations have been run for racking two targets. The true initialization state of the targets is X1?[-29500m,400m/s,34500m,-400m/s X ?[-26250m,296m/s,34500m,-400m/s]'? 2 The two targets will cross above 31seconds later. To evaluate tracking performance, 50 Monte Carlo runs were performed for three case of the target detection probability Pd=0.97 ? Pd=0.76 ? Pd=0.58. In every run, the total simulation time is 140 steps 


simulation time is 140 steps            Figure 1  RMS position error in case of Pd=0.97          Figure 2  RMS velocity error in case of Pd=0.97       Figure 3  RMS position error in case of Pd=0.76 567 Proceedings of  the Fourth International Conference on Machine Learning and Cybernetics  Guangzhou, 18-21 August 2005         Figure 4  RMS velocity error in case of Pd=0.76         Figure 5  RMS position error in case of Pd=0.58          Figure 6  RMS velocity error in case of Pd=0.58  Table 1 The emanative times comparison for sequential MSJPDA and SD-CMSJPDA algorithm  Pd N A  0.97 0. 76 0.58 Sequential MSJPDA 2 11 17 SD-CMSJPDA 0 3 5 Pd denotes detection probability, N denotes emanative 


Pd denotes detection probability, N denotes emanative times, A denotes the kind of algorithm Table 1 shows the summation of emanative times for sequential MSJPDA and SD-CMSJPDA algorithm in 50 Monte Carlo simulations. From table 1 , it is shown that the stability of SD-CMSJPDA is better than that of sequential MSJPDA as the detection probability varied Figure 1,2 show the RMS errors for position and velocity in case of Pd=0. 97, respectively; Figure 3,4 show the RMS errors for position and velocity in case of Pd=0.76 respectively; Figure 3,4 show the RMS errors for position and velocity in case of Pd=0.58, respectively. From the figures we can see that the average RMS position error is lower for the SD-CMS JPDA algorithm. We also see that the state estimation precision of sequential MSJPDA get worse as the detection probability decreases The reasons for these simulation results lies:1 state estimation precision will get worse when the detection probability decrease;2 algorithm is to process measurement from each sensor using single sensor JPDA algorithm sequentially. Therefore the estimation error from each sensor will be accumulated Moreover, the sequential MSJPDA algorithm can  t improve the joint detection probability of the multisensor system The estimation error of the SD- CMSJPDA  algorithm will not be accumulated for it processes the measurement from each sensor directly in the mean time .What  s more the new method can greatly improve the joint detection probability of the multisensor system. Therefore, the tracking performance of SD-CMSJPDA algorithm is better than that of sequential MSJPDA. Algorithm All of the simulations are run in the personal computer with a 2.0G CPU and a 256M memory. The average cost time per step is 0.0251 in the sequential implementations of MSJPDA algorithm. And the average cost time per step is 0.0282 in the sequential implementations of MSJPDA algorithm. According to the results we can see that there is few difference in real time between the new method and the sequential   MSJPDA when there is not so many sensors and targets 568 Proceedings of  the Fourth International Conference on Machine Learning and Cybernetics  Guangzhou, 18-21 August 2005  5. Conclusion In order to solve the problem of multisensor multi target tracking, a new centralized multisensor  joint probabilistic data association  algorithm is proposed in this paper. The simulation results shows that the tracking performance of the new algorithm is better than that of the sequential MSJPDA algorithm The computational complexity of the new method will increase as the number of sensors and targets grow Therefore, how to improve the real time of SD- CMSJPDA algorithm will be pay attention References 1] He You, Wang Guohong, Lu Dajin, Peng Yingning Multisensor Information Fusion With Application[M Publishion House of Electronics Industry. 2000, Beijing.  [11] B..Zhou and N.K.Bose Multitarget  Tracking in Clutter:Faste Algorithms for Data Association .IEEE Transaction on Aerospace and Electronic Systems 1993,29\(2 2] Bar-shalom,Y\(Ed Applications and Advances,2: Norwood,MA Artech  House, 1992 3] L.Y. Pao, C.W.Frei. A Comparison of Parallel and Sequential Implementation of a Multisensor Multitarget Tracking Algorithm. Proc. 1995 American Control Conf. Seattie, Washington,June 1995 1683~1687 


4] K. Chang, C. Chong, Bar-Shalom, Joint Probabilistic Data Association in Distributed Sensor Networks IEEE Transactions on Automatic Control, AC-31\(10 octobre 1986 5] Bar-shalom, Multitarget Multisensor Tracking Advanced Application ,:YBS Publishing, 1990 6] Bar-shalom, Multitarget Multisensor Tracking Principles and Techenices ,:YBS Publishing, 1995 7] Hu Wenlong, Mao shiyi, Multisensor Data Association Based on Combinatorial Optimization[J]. Journal of Systems Engineering and Electronics . 1997 NO.1,1~9 8] Pattipati K R, Passive Multisensor Data Association Using a New Relaxation Algorithm.In Multitarget-Multisensor Tracking: Advanced and Applications,Y.Barshalom,Norwood,MA:Aretech,199 0 9] Deb S,et al, An S-Dimentional Assignment Algorithm for Track Initiation ,Proc. Of the IEEE Int. Conf Systems Engineering, Kobe, Japan,Sept 1992 527~530 10] Deb S,et al, A Multisensor-Multitarget Data Association Algorithm for Heterogeneous Sensors[J].IEEE Trans. on AES 1993 ,29 \(2 560~568 12] Bar-shalom,Y.,and Fortmann,T.E  Tracking and Data Association  New York:Academic press,1988 13] J,A,Roecher and G.L.Phillis,Suboptimal Joint Probabilistic Data Association .IEEE Transaction on Aerospace Electronic Systems.1993,29\(2 14] J,A,Roecker,A Class of Near Optimal JPDA Algorithm IEEE Transaction on Aerospace and Electronic Systems,1994,30\(2 15] Han Yanfei, Analysis and Improvement of Multisensor Multitarget Probabbilistic Data Association Filting Algorithm[J].  Journal of Systems Engineering and Electronics, 2002, Vol.24, 36~38  569 pre></body></html 


dense data sets for evaluating pattern mining algorithms These two data sets are obtained from IBM Almaden at http://www.almaden.ibm.com/cs/quest/demos.html. Recently, theMAFIA algorithm [6] was proposed to ef?ciently discover maximal frequent patterns. As shown in their paper, MAFIA can be several orders better than some alternatives, such as DepthProject, for mining maximal frequent patterns. Hence, we chose MAFIA as the base line for our performance evaluation. Finally, please note that only the size-2 patterns are generated in the ?rst BFS phase Experimental Platform We implemented the MHP algorithms using C++ and all experiments were performed Proceedings of the 16th IEEE International Conference on Tools with Artificial Intelligence \(ICTAI 2004 1082-3409/04 $20.00 © 2004 IEEE on a Pentium III    MHz PC machine with    megabytes main memory, running Linux Redhat 6.1 operating system 5.2. A Performance Comparison 100 1000 10000 100000 1e+06 1e+07 1e+08 1e+09 1e+10 1e+11 0.02 0.025 0.03 0.035 0.04 0.045 0.05 0.055 0.06 N um be r o f C he ck ed P at te rn s Support threshold Mafia Min_Conf=0 Min_Conf=0.1 Min_Conf=0.3 Min_Conf=0.5 Min_Conf=0.7 Min_Conf=0.9 


Figure 4. The Number of Checked Patterns on the Pumsb* Data Set 10 100 1000 10000 100000 0.02 0.025 0.03 0.035 0.04 0.045 0.05 0.055 0.06 R un T im e s ec  Support Threshold Mafia Min_Conf=0 Min_Conf=0.1 Min_Conf=0.3 Min_Conf=0.5 Min_Conf=0.7 Min_Conf=0.9 Figure 5. The RunTime Comparison on the Pumsb* Data Set Figure 4 shows the number of patterns that MHP and MAFIA have to check during the pattern mining process on the pumsb* data set. As can be seen, for MHP, the number of checked patterns is increased with the decrease of the h-con?dence threshold. However, the number of checked patterns of MHP can be signi?cantly smaller than that of MAFIA even if a low h-con?dence threshold is speci?ed To check a pattern, we need to count the support of the patterns. Counting the support of a pattern is the most timeconsuming task during the pattern mining process, since we need to retrieve all the transactions which include one of its sub-pattern, or for Ma?a, retrieve all the bit of the bitmap of this pattern [6]. Therefore, an algorithm is more ef?cient if smaller number of patterns need to be checked 100 1000 10000 100000 1e+06 1e+07 1e+08 1e+09 0.1 0.2 0.3 0.4 0.5 0.6 0.7 N 


um be r o f C he ck ed P at te rn s Support Threshold Mafia Min_Conf=0.5 Min_Conf=0.7 Min_Conf=0.9 Figure 6. The Number of Checked Patterns on the Pumsb Data Set 10 100 1000 10000 0.1 0.2 0.3 0.4 0.5 0.6 0.7 R un T im e s ec  Support Threshold Mafia Min_Conf=0.5 Min_Conf=0.7 Min_Conf=0.9 Figure 7. The RunTime Comparison on the Pumsb Data Set The runtime comparison of MHP and MAFIA on the Pumsb* data set is shown in Figure 5. In the ?gure, we can observe that the runtime of MHP can be signi?cantly reduced with the increase of h-con?dence thresholds. Also the runtime of MHP can be several orders of magnitude less than that of MAFIA even if the h-con?dence threshold is as low as 0.3. The reason is that the number of checked patterns of MHP is sign?cantly smaller than that of MAFIA Similar results are also obtained from the pumsb data set as shown in Figure 6 and Figure 7. For the pumsb data set the number of checked patterns of MHP is much smaller 


than that of MAFIA and the runtime of MHP can be significantly less than that of MAFIA 5.3. The Effect of the MHP Algorithm on Finding Maximal Hyperclique Patterns Figure 8 and Figure 9 show the number of maximal patterns identi?ed byMHP andMAFIA on Pumsb* and Pumsb data sets respectively. As can be seen, the number of maximal hyperclique patterns identi?ed by MHP can be orders of magnitude smaller than the number of maximal frequent patterns identi?ed by MAFIA. In other words, the number Proceedings of the 16th IEEE International Conference on Tools with Artificial Intelligence \(ICTAI 2004 1082-3409/04 $20.00 © 2004 IEEE 100 1000 10000 100000 1e+06 1e+07 1e+08 1e+09 0.02 0.025 0.03 0.035 0.04 0.045 0.05 0.055 0.06 N um be r o f C ou nt ed P at te rn s Support Threshold Mafia Min_Conf=0 Min_Conf=0.1 Min_Conf=0.3 Min_Conf=0.5 Min_Conf=0.7 Min_Conf=0.9 Figure 8. The Number of MFI/MHP Patterns in the Pumsb* Data Set 100 1000 10000 100000 1e+06 


1e+07 1e+08 0.1 0.2 0.3 0.4 0.5 0.6 0.7 N um be r o f C ou nt ed P at te rn s Support Threshold Mafia Min_Conf=0.5 Min_Conf=0.7 Min_Conf=0.9 Figure 9. The number of MFI/MHP Patterns in the Pumsb Data Set of maximal hyperclique patterns is much easier to manage than that of maximal frequent patterns. Indeed, in realworld applications, it is dif?cult to interpret several million maximal frequent patterns. However, it is possible to interpret the results of maximal hyperclique pattern mining In addition, due to the memory limitation, we cannot extract maximal frequent patterns with MAFIA on the Pumsb data set if the support threshold is less than 0.4, as shown in Figure 7. In contrast, MHP can identify maximal hyperclique patterns when the support threshold is 0.1, if we set the h-con?dence threshold to 0.5. In other words, MHP has the ability to identify patterns which can be dif?cult to identify for MAFIA. Hence, MHP can better explore the pattern space and ?nd interesting patterns at low levels of support 6. Conclusions and Future Work In this paper, we present a two-phase Maximal Hyperclique Pattern \(MHP best features of both the BFS strategy and the DFS strategy. More speci?cally, we adapted DFS pruning methods such as equivalence pruning, to an apriori-like approach In addition, we proved the correctness and completeness of the MHP algorithm. Finally, our experimental results show that the MHP algorithm can be several orders of magnitude faster than standard maximal frequent pattern mining algorithms and has the ability to identify patterns at extremely low levels of support in dense data sets There are several directions for future work. First, in 


this paper, we only generate the size-2 patterns in the BFS phase. It will be interesting to investigate the impact on the performance if the ?rst phase is stopped at a deeper level Also, the projection is a very ef?cient method for ?nding patterns, especially for parallel implementation of pattern mining algorithms [1]. We plan to adapt the projection ideas into our algorithm and design an ef?cient parallel algorithm for mining maximal hyperclique patterns References 1] R. Agarwal, C. Aggarwal, and V. Prasad. A Tree Projection Algorithm For Generation of Frequent Itemsets. pages 350 371, Feb 2001 2] R. Agrawal, T. Imielinski, and A. Swami. Mining Association Rules between Sets of Items in Large Databases. In Proc. of the ACM SIGMOD Conference on Management of Data, pages 207–216,May 1993 3] R. Agrawal and R. Srikant. Fast Algorithms for Mining Association Rules. In Proc. of the 20th Int’l Conference on Very LargeData Bases, 1994 4] R. Bayardo. Ef?ciently mining long patterns from databases In Proc. of the ACM SIGMOD Conference, 1998 5] R. Bayardo and R. Agrawal. Mining the Most Interesting Rules. In Proc. of the ACM SIGKDD Conference, 1999 6] D. Burdick, M. Calimlim, and J. Gehrke. Ma?a: AMaximal Frequent Itemset Algorithm for Transactional Databases. In Proc. of IEEE Conf. on Data Engineering, 2001 7] Y. Huang, H. Xiong, W. Wu, and Z. Zhang. A Hybrid Approach for Mining Maximal Hyperclique Patterns. In In Technical Report UTDCS-34-04, Department of computer science, University of Texas - Dallas, 2004 8] J.Han, J.Pei, and Y. Yin. Mining Frequent Patterns without Candidate Generation. In Proc. of the ACM SIGMOD International Conference on Management of Data, 2000 9] M.J.Zaki and C.Hsiao. ChARM: An ef?cient algorithm for closed itemset mining. In Proc. of 2nd SIAM International Conference on Data Mining, 2002 10] R.Rymon. Search through Systematic Set Enumeration. In Proc. Third Int’l Conference on Principles of Knowledge Representation and Reasoning, 1992 11] H. Xiong, M. Steinbach, P.-N. Tan, and V. Kumar. HICAP: Hierarchial Clustering with Pattern Preservation. In Proc. of 2004 SIAM International Conference on Data Mining \(SDM 12] H. Xiong, P.-N. Tan, and V. Kumar. Mining Strong Af?nity Association Patterns in Data Set with Skewed Support. In Proc. of the Third IEEE International Conference on Data Mining \(ICDM Proceedings of the 16th IEEE International Conference on Tools with Artificial Intelligence \(ICTAI 2004 1082-3409/04 $20.00 © 2004 IEEE 





