Application Research of Association Analysis with Clementine Yu-Chen Song, Yi-Feng Fang Center for Inner Mongolia Industry Informationization and Innovation Department of Mining Info rmation System, Laborator y for Data Engineering Inner Mongolia University of Science and Technology, Baotou, China. 014010 songyuchen@imust.edu.cn,  qdfyf@163.com   Abstract After introduce briefly about the basic concept and methods of association rules in data mining, we take borrowing records in library as example to describe the whole process of how to find association with the application of Apriori algorithm in Clementine.The mining outc ome shows that some books and books have stronger associat ion strength. According to the association between books, we can do book recommendation That is to say, when reader borrows a book, the library can recommend the book which has strong association strength with it to the reader; we can rearr ange the distribution of books in library by putting books with strong association strength close to each other to save time for read ers in choosing books Keywords-data mining; association rules; borrowing record apriori  algorithm I  I NTRODUCTION  The association rules in data mining attach importance to the association among different areas of data and finding out the dependant relation am ong different areas in given conditions. The prospect of applica tion of association rules is extremely bright. Retail trade analysts use association rule to analyze a great amount of sales figures. They find out customer purchasing pattern and trend to improve their service quality Association rules are also widely a pplied in risk analysis in insurance industry, mark et predicting in fin ancial investment and relevant areas about teleco mmunication industry Nowadays, the prevalent mining tools in the market are Enterprise Miner developed by SAS, Intelligent Miner developed by IBM and Clementine developed by SPSS. This paper takes Clementine12.0 as example to introduce the application of data mining II A SSOCIATION R ULES M INING T HEORY AND A LGORITHM S TUDY  Association rule is the most active research method in data mining. It was firstly put forw ard in 1993 by Agrawal, etc. The original motivation of pu tting forward it aimed at market basket analysis and the goal is to find out the association rules among different merchandise in trading database. These rules describe consumer buying behavi or model and they can be used to instruct merchant to arrange scientifically about purchases, inventory and desi gning of goods shelf, etc A The Definition of Asso ciation Rules and Associative Processes Association Rules refer to rules that describe the potential association among data items  attribute, variable mining techniques of Association Rules  we can find out a large amount of unkno wn dependant relation s among data We define Association Rules as follows: Let I={i 1 i 2  i m be the set of all items in a market basket data and T={t 1  t 2 t n be the set of all transactions. Each transaction t i  contains a subset of itemset. If an itemset contains k items, it is called a k-itemset. A transaction t j is said to contain an itemset X if X is a subset of tj. An association rule is an implication expression of the form X=>Y, where X and Y are disjoint itemsets, and X  Y =. The Strength of an association rule can be measured in terms of its support and confidence. The formal definitions of these metrics are   N Y X Support     1  X Y X Confidence      2 We assume that minsup is the mi nimum support and minconf is the minimum confidence. If the rule satisfies both minsup and minconf, it is the strong association rule Mining for Association Rules has two steps The first step is to find out the group of the frequent itemset According to the definition, the frequency of appearance of these itemsets is at least the same with the number of the pre-defined minsup The second step is to generate the strong association rules from the frequent itemset. According to the definition, these rules must satisfy both minsup and minconf B The Ccategory  of Association Rules According to the type of the attribute value in dealing with the rule, Association Rules can be divided into Boolean association rule and Quantitative association rule Identify applicable sponsor/s here sponsors 445 


Boolean association rule concerns the association about whether the classification attribute value exists or not For example we get a rule by market basket analysis buys\("beer"\>buys\("Diapers conf  The classical algorithm Apriori algorithm, is the most influential algorithm in mining for frequent itemset of Boolean association rule The main idea is using the method of layerby-layer search to find out the frequently appeared itemsets in database. The main processes of the algorithm are as follows The first step is to generate frequent itemset L 1 then scan the database D, each database appearing in D forms an candidate itemset C 1 and count the frequency of each data item's appearance, the set in which the frequency is bigger than the minsup is the frequent itemset L 1 the step k is to generate the frequent itemset L k using the frequent ite mset generated by the previous step associated with itself to generate the candidate itemset C k then scan the databa se transaction set, count the frequency of each member of C k delete the candidate item which is smaller than the minsup, then the frequent itemset k comes out at last Quantitative association rule describes the association among the quantitative attributes. For example age\(30,35\e\(12k,14 k\[sup=20%,conf  Quantitative association rule separates the quantitative attributes according to the data distribution and then use the classical algorithm to mine. E.g., in come attribute is divided into equal districts as "0k...20k", "21k...30k", "31k...40k", etc Then substitute the value of the original attribute, sto ck it in the relation table. Then revise Apriori algorithm to find out all frequent predicate \(i.e. to search all the relevant attributes, not only one attribute as "buys"\ At last, generate the association rule which satisfies both minsup and minconf C Brief Introduction of Clementine Association There is much of software of data mining, the paper focuses on the usage of Clementine association. Clementine is a platform for data mining tool s developed by ISL \(Integral Solutions Limited\ acquired ISL in 1999. They reintegrated and developed the production of Clementine Clementine is widely used special software in data mining at present, and it integrates different kinds of data mining techniques as cluster, decisi on tree, neural network and association rules, etc to a intuitional visible graphical interface The association module is very useful in protecting different outcomes. As for the association which can be found out by manual movement, Association rule algorithm can find it automatically through visible technique \(e.g the Web node The advantage of Association rule algorithm over decision tree algorithm is that it can find out the association among all the attributes. Decision trees algor ithm only use mono-conclusion to construct rules while Associati on rule algorithm tries to find out more rules and each rule has different conclusion Clementine offers 3 kinds of Association rule algorithms Apriori, GRI and CARMA algorith m. We study the Apriori algorithm III T HE APPLICATION OF C LEMENTINE A SSOCIATION M INING  College library generates a large amount of books currency data. These data record reader's personal information and are used to do the regular service data statistics. The potential value of using these data has not been mined and used reasonably. Using cluster technique of data mining to mine for the relevant data in library through designing and testing CADD cluster algorithm, we make a cluster application of library data and get a good outcome. The problem of whether the Association rule mining method can be applied to the analysis of books currency dat a to mine and discover the implied rules in the borrow be havior of readers to instruct the work of the library deserves study We study the data of the lib rary borrowing system, using Clementine to mine for the association among books to offer service for recommendation and library shelf arrangement Readers have similarity in borrowing books, i.e., they borrow another book soon after borrowing one book. For example, after borrowing Ad vanced Mathematics, we usually will borrow Exercises on Advanced Mathematics A Data Preparation We use borrowing data \(2006.9-2008.9\ of library system to mine for association of books. Our college library uses General Library Integrated System \(GLIS8.0\which is an application system for library network At first, we study the partic ular borrowing details and select the top 50 books according to the number of borrowing times to do experiment about association. The statistics attributes include: control number \(book's MAC\author, publishing house, publishing data and borro wing times. We check the particular borrowing details by looking for the bar code according to the control number. In the experiment, we select 15 books as analyzing objects. These books are <<Mechanical Parts Design Manual>>, <<Cherry tree>>, << Peking University Students Meiwen>>, <<Spicy Lovers Amber tears>>, <<Legal Report: China's legal Lunch >>, << Even Ling >>, <<Elapsed beauty>>and <<The story of Zhou Enlai>>, etc. The relevant information about these books is showed as TABLE I  446 


TABLE I THE T OP 15  B OOKS   According to the analysis of the borrowing records, 488 readers have borrowed these books. Then we refer to the borrowing records of these readers, deleting each reader's repetition borrowing record of each book, and then we get a Transaction database for discovering association rules as TABLE II. ID refers to the number of transactions; the actual data refer to the reader's certificate number; ITEM refers to the itemset of transaction and its actual meaning is the set of the reader's borrowing books. The com bining meaning of the letters and numbers is call number of books TABLE II T RANSACTION DATABASE  ID ITEM 0610127114 O13-44/2,O13/43,Z 228/8,I247.5/38,TP312C/146 0710100331 78.213/5090,TH13-39/6 2003041212 TP312C/73,78.213/5090 I247.57/88,I545.73/2 2003041235A K827=52/8,H316/5,I 207.411-53/1,C913.2/22 2003041540 TB301-43/2,TB301/19,71.221/1249,TB301/16 2003041644 TG506/3,78.29/11 11,X734.201/3,X756.03/1    B The Processes of Clementine Data Mining 1 Creating the data stream The data mining processes are described by stream in Clementine. Stream is a set of Nodes and it represents the processes of data moving from Source Node to Processing Node and then to the Output Node. User can edit the stream in steam editor. To create stream as follows: select çFileé from Menu", then click "New Stream 2 Adding and editing the data source node Editing stream in stream edito r, we firstly should add data source node and then attach it to the data for mining. In Clementine, Database, Fixed File, SPSS File, SAS File, Excel User Input are data source nodes Data used in this paper are stored in Excel. Therefore, we select Sources tab, double click Excel node in node module, adding Excel node to stream editor window. Then we edit it in ed itor window and select the data file we need 3 Importing Data Double click Type node, click Read value in a pop-up dialog box to import data 4 Adding data mining model node Clementine offers algorithm models as nerve network decision tree, cluster, sequence, regression, association, etc. As this thesis describing the application processes of association we should construct associa tion data mining model Clementine offers association models as GRI, Apriori, Carma Sequence, etc. This thesis uses the Apriori model so we add stream by selecting Apriori in model tab 5 Executing the mining model After model setup, we set the pre-piece and the post-piece and click "Execute". After execution a new icon will appear in manager. We can see the execution ou tcome by right clicking the icon and clicking "Browse 6 Making mining outcome visible If you want to make the final mining outcome visible, you can add a certain graphic node to data stream and execute it An integrated data stream is showed as Fig. 1   Figure 1 Data Stream  C The Description of Data MiningRresult We can get different mining outcomes by selecting different minsup and minconf as is showed in TABLE III ID Control Num ber Title Author Publisher Publication Date Borrowed Times 1 zyk0 0358 63 Mechanical Parts Design Manual Northeastern University of Technology Metallurgy Industry Press 1980 748 2 zyk0 0689 08 Cherry tree Japan Watana be Culture and Arts Publishing House 2005 442 3 zyk0 0706 47 Spicy Lovers Amber tears Mu Mao New World Press 2005 422        44 7 


TABLE III A SSOCIATION R ESULT  Result Minsup\(%\ Minconf\(%\Rules Result 1 4 50 48 Result 2 5 50 16 Result 3 6 55 4  In TABLE III, there are 48 association rules in the first outcome where minsup is 4% and minconf is 50%; there are 16 association rules in the second outcome where minsup is 5 and minconf is 50%; there are 4 association rules in the third outcome where minsup is 6% and minconf is 55%. Then let's see the differences among mining outcomes when minsup and minconf have different values In the first outcome, there are 48 association rules where minsup is 4% and minconf is 50%. Among these 48 rules, the minsup is 4.098%; the maxsup is 7.992%; the minconf is 50 the maxconf is 84.615%. So me Association rules strength among books are showed in Fig. 2   Figure 2 Association Rules Strength Among Books I  In Fig. 2, the thick er the line between th e two books is, the stronger the association strength of the two books is. The thinner the line is, the weak er the association strength is. Link refers to the number of times of the appearance of the pre-piece and the post-piece at the same time. As is showed in Fig. 2 there are 28 links between 1247.5 6/9 and 1247.56 6, i.e. 28 readers borrow the two bo oks at the same time. We define it as a strong link when there are more than 30 links between 2 books; a medium link when the number is between 15 and 30 a weak link when the number is under 15. The Fig. 2 is an outcome after deleting some weak link. The aim is to see clearly that which 2 books have stronger association strength i.e., after borrowing one book the reader tends to borrow another book We change the graph to data showed in TABLE IV. As is showed in TABLE IV, when readers borrow I247.56/6 Ghost Inn Peak Reasoning 118\(<<Latent grass Rapids 12.45/2\(<<Honey-moon Cry>>\84/2\(<<Lauraês Secret>>\56/8\(<< Sad Fi nd Murderer 114\(<<Elapsed Beaut y>>\I247.55/6\(<<Adventures in urban demon>>\row  I247.56/9\(<<Even Ling>>\55/5\(<<FLS Legend \(Part One\hey usually also borro w  I247.56/4\(<<Love War KGB>>\borrows I247.57/105\(<< Sparrow Revolute rrow I247.57/78 \(<<Spicy Lovers Amber tears>>\ borrow I247.55/1\(<<Soul Wars>>\hey oft en also borrow I247.55/6 Adventures in urban demon There are 16 association rules in the second outcome where minsup is 5% and minconf is 50%. Compared with the first outcome, it has deleted the rules with sup under 5%. Among these 16 rules, minsup is 5.123%, maxsup is 7.992%, minconf is 50%, maxconf is 84.615%. The association strength is showed in Fig. 3 The association strength is showed in detail in Fig. 4. As is showed in Figure IV, I247.56 9 and I247.7/13 have the strongest association strengt h, I247.56/9 and I247.45/29 come second, and then I247.57/78 and I2 47.57/78, I247.56/  and I247.55/6  at last TABLE IV A SSOCIATION R ULES S TRENGTH A MONG B OOKS I Post-piece Pre-piece Support Confidence I247.56/9 = T I247.57/119 T 5.328 84.615 I247.56/9 = T I247.56/8 T 5.943 75.862 I247.55/6 = T I247.55/1 T 4.918 75.0 I247.56/9 = T I247.57/1 16 = T 4.098 70.0 I247.56/9 = T I712.45/29 T 6.762 66.667 I247.56/9 = T I247.56/6 T 7.992 64.103 I247.55/4 = T I247.55/5 T 4.303 61.905 I247.55/3 = T I247.55/5 T 4.303 61.905     Figure 3 Association Rules Strength Among Books II 448 


 Figure 4 Association Rules Strength Among Books III  We change graph to data showed in TABLE V TABLE V A SSOCIATION R ULES S TRENGTH A MONG B OOKS II  As is showed in TABLE V  There are 6.672% of readers borrow I247.45/29 Even Ling>>\of the readers who borrow I247.45/29\(<<Honeymoon Cry>>\will borrow I247.56/9 \(<< Even Ling  7.992% of readers borrow I247.56/6\(<<Ghost Inn and I247.56/9 \(<<Even Ling readers who borrow I247.56 6\(<<Ghost Inn borrow I247.56/9 \(<< Even Ling  There are 7.172% of readers borrow I247.7/13 Peak Reasoning Even Ling>>\of the readers who borrow I247.7/13 \(<<Peak Reasoning I247.56/9 \(<< Even Ling  6.557% of readers borr ow I247.7/43\(<<Sky Blue and I247.57/78\(<<Spicy Lovers Amber tears 56.25% of the readers who borrow I247.7/43\(<<Sky Blue>>\I 247.57/78\(<<Spicy Lovers Amber tears IV C ONCLUSOION  The paper starts with the basic concept of Association rules describing the whole processes of how to find association rules by using Clementine through th e study of borrowing records about the books association. The mining outcome shows that Even Ling>> and <<Peak Reasoning>>, << Even Ling >>and <<Honeymoon Cr y>>, <<Sky Blue>> and Spicy Lovers Amber tears>>, << Even Ling >> and Adventures in urban demon>> have stronger association strength. According to the association between books, we can do book recommendation. That is to say, when reader borrows a book, the library can recommend the book which has strong association strength with it to the reader; we can rearrange the distribution of books in library by putting books with strong association strength close to each other to save time for readers in choosing books Clementine has other association algorithms. As for the length of the paper, we only study the Apriori algorithm. We can use different algorithms of Clementine in a broader area Post-piece Pre-piece Support\(%\Confidence I247.56/9 = T I247.45/29 T 6.672 66.667 I247.56/9 = T I247.56/6 T 7.992 64.103 I247.56/9 = T I247.7/13 T 7.172 57.143 I247.57/78 = T I247.7/43 T 6.557 56.25 A CKNOWLEDGMENT   The material is based on work supported by National Natural Science Foundation of China under Grant No 40764002  The material is based on work supported by National Social Science Foundation of China under Grant No 06XTQ011  R EFERENCES    Yan Wang. Association rules algorithm  in data mining. Journal of Chengdu University of Information Technology,2004,19\(2  R Agrawal,T l m i e lisk,A Swa m i Mining Association Rules Betwee n Sets of Items in Large Database  In Proceedings of ACM SIGMOD International Conference on Manageme nt of Data\(SIGMODê93 1993:207-216  Jiawei Han,Miche line Ka m b er.Data Mining:Concept and Techniques  Beijing:China Machine Press,2001  YuChen Song. Dy nam ic and I n cr em ental Clustering Based on Density Reachable . IEEE Publishers, Aug-2009  Yu-Chen Song, Grady M J O Hare G M P O. Applications of Attributes Weighting in Data Mining. In pr oceedings of IEEE Cybernetic Systems Conference,IEEE Publishers,2007: 41-45  Yu-Chen Song, Hai-Dong Meng Clustering Algorithms for Arbitrary Data Se yclopedia of Artificial Intelligence  Idea Group Inc Information Science Reference  Yu-Chen Song,Yi-F eng Fang,Wei Wang,et al. Data Analysis of College Library Reading-room Based on Clusteri ng Algorithm ation  Technology Application Institute, 2008  Yu-Chen Song Hai-Dong Meng Feiyan Song. Study on Arbitrary Distribution in Cluster Analysis. IEEE Publishers, Sep-2009  44 9 


method widely used in recommender systems. In this paper starting from general neighborhood problem, various methods are proposed and a complete collaborative filtering method system is build. Also, various methods are compared empirically each other. Although experiments elementally support our ideas, it is still need more experiments to verify them with more dataset in the future. More research need to be made to enhance CFC by other methods, such as ontology A CKNOWLEDGMENT  This research was partly supported by National Science Foundation of China under grants No.70871115, \(Renmin University of China\C Publishing Plan for International Journal under grants No.10XNK090. Special thank is given to the System Research Center of Digital Equipment Corporation for providing Each-Movie database available for research. We also like to thank anonymous reviewers for their valuable comments R EFERENCES  1  Resnick and Varian.\(1997\Recommender systems. Communications of the ACM, 40\(3\®C58, 1997 2  Sarwar, B. M., Karypis, G., Konstan, J. A., and Riedl, J. \(2000 Analysis of Recommendation Algorithms for E-Commerce. In Proceedings of the ACM ECê00 Conference. Minneapolis, MN. pp. 158167 3  Schafer, J. B., Konstan, J. and Riedl, J. \(1999\, èRecommender Systems in E-Commerceê. In: EC ê99: Proceedings of the First ACM Conference on Electronic Commerce, Denver, CO, pp. 158-166 4  Jiyong Zhang, Pearl Pu \(2007\, A Recursive Prediction Algorithm for Collaborative Filtering Recommender Systems, RecSysê07, October 19 20, 2007, Minneapolis, Minnesota, USA 5  Ailin Deng, YangYong Zhu, BaiLe Shi \(2003\, A Collaborative Filtering Recommendation Algorithm Based on Item Rating Prediction Journal of Software, Vol.14, No.9 6  Badrul M. Sarwar, George Karypis, Joseph A. Konstan, John T. Riedl 2000\,Application of Dimensionality Reduction in Recommender System -- A Case Study,WEBKDDD2000 7  Gyenesei A and Teuhola J \(2001\nterestingness Measures for Fuzzy Association Rules. In Proceedings of the Fifth European Conference on Principles of Data Mining and Knowledge Discovery, September 3-5 Freiburg, Germany, pp 152-164 8  Cane Wing-ki Leung, Stephen Chi-fai Chan, Fu-Lai Chung \(2006\, A collaborative filtering framework based on fuzzy association rules and multiple-level similarity. Knowledge and Information Systems \(KAIS Volume 10, Issue 3, October 2006, 357Ö 381 9  Feng-Hsu Wang, Hsiu-Mei Shao 2004 Effective Personalized Recommendation Based on Time-Framed Navigation Clustering and Association Mining Expert Systems with Applications 27 \(2004\ 365 377   Lin W, Alvarez SA and Ruiz C \(2002\fficient Adaptive-Support Association Rule Mining for Recommender Systems. Data Mining and Knowledge Discovery, 6\(1\: 83-105   Li Yu, Who is True Neighborhood, Community Neighborhood or General Neighborhood? Submitted to ACM SIGIR 2008   John s. Breese, David Heckerman, and Carl Kadie \(1998\. Empirical analysis of predictive algorithms for collaborative filtering. In Proceedings of the 14th conference on Uncertaintly in Artificial Intelligence, pages 43®C52, 1998   Herlocker, J. A. Konstan, and J. Riedl. An empirical analysis of design choices in neighborhood-based collaborative filtering algorithms Information Retrieval, 5\(4\:287 310, 2002   J. Wang, A. P. de Vries, and M. J. Reinders. Unifying user-based and item-based collaborative filtering approaches by similarity fusion. In Proc. of SIGIR, 2006   G.-R. Xue, C. Lin, Q. Yang, W. Xi, H.-J. Zeng, Y. Yu, and Z. Chen Scalable collaborative filtering using cluster-based smoothing. In Proc of SIGIR, 2005   Kim C and Kim J \(2003\ A Recommendation Algorithm Using Multilevel Association Rules. In Proceeding of the IEEE/WIC International Conference on Web Intelligence, October 13-17, Halifax, Canada, pp 524-527   Fu X, Budzik J and Hammond KJ \(2000\ Mining Navigation History for Recommendation. In Proceedings of the 2000 International Conference on Intelligent User Interfaces, January 9-12, New Orleans, LA, USA, pp 106-112   Mei-Ling Shyu \(2006\ Collaborative Filtering by Mining Association Rules from User Access Sequences 2005 International Workshop on Challenges in Web Information Retrieval and Integration \(WIRIê05   Rashmi S, Kirsten S, Comparing Recommendations Made by Online Systems and Friends[R SI M S  Un i v ers i t y of C a l i forn i a 2 001  20  McJones, P. \(1997\. EachMovie collaborative filtering data set. DEC Systems Research Center http://www.research.digital.com/SRC/eachmovie   Resnick, P., Iacovou, N., Suchak, M., Bergstrom, P. and Riedl, J.\(1994 GroupLens: An Open Architecture for Collaborative Filtering of Netnewsê. In: Proceedings of the Conference on Computer Supported Cooperative Work, Chapel Hill, NC, pp. 175-186   Yiyang Zhang,  Jianxin \(Roger\ Jiao \(2006\, An Associative Classification-Based Recommendation System for Personalization in B2C E-Commerce Applications Expert Systems with Applications 2006   Hao Ma,  Haixuan Yang,  Irwin King,  Michael R. Lyu, Seminonnegative matrix factorization with global statistical consistency for collaborative filtering,CIKM2009, P767-776   Benjamin Van Roy,  Xiang Yan, Manipulation-resistant collaborative filtering systems, 2009 Proceedings of the third ACM conference on Recommender systems, P165-172   Asela Gunawardana,  Christopher Meek, A unified approach to building hybrid recommender systems, 2009  Proceedings of the third ACM conference on Recommender systems, P117-224                         


    Figs. 7 and 8 show the average rank for the training data accuracy and the test data accuracy. We can observe almost all of the same effects of candidate rule addition and lateral tuning as in the case of 0.0  Pareto EC ECW Pareto EC ECW  0.00 0.01 0.05 0.10 0 2 4 6 Average rank  Fig. 7.  Average rank for the training data accuracy over all the data sets A smaller rank is better Pareto EC ECW Pareto EC ECW  0.00 0.01 0.05 0.10 0 2 4 6 Average rank  Fig. 8.  Average rank for the test data accuracy over all the data sets A smaller rank is better  C  Comparison between Low and High Imbalanced Data We divided the data sets used in our experiments into two subsets: Low imbalance data sets \(IR < 3.0\gh imbalanced data sets \(IR > 3.0\gs. 9 and 10 show the average rank for the test data accuracy over the low imbalanced data sets and the high imbalance data sets respectively. We can see that the positive effect of genetic lateral tuning became weaker as became larger for the low imbalance data sets. On the other hand, the approaches with candidate rule addition and ge netic lateral tuning \(i.e., EC and ECW*\kept good ranking in almost all cases. This observation may indicate that the proposed extensions are effective especially for the high imbalanced data sets V   C ONCLUSION  In this paper, we proposed two extensions of our genetic fuzzy rule selection for designi ng more accurate classifiers One extension is to add compatible rules with misclassified patterns into candidate rules for genetic fuzzy rule selection The other extension is to tune membership functions by genetic lateral tuning after genetic fuzzy rule selection Experimental results showed that the candidate rule addition can improve the training data accuracy. This is because the possibility that the misclassified training patterns are classified by additional rules becomes high. Experimental results also showed that the genetic lateral tuning can improve the test data accuracy as well as the training data accuracy, since fuzzy membersh ip functions are properly adjusted according to the pattern distributions. The combination of the proposed two extensions would be the best choice As a future study, we will examine the effects of the proposed extensions using a large number of data sets TABLE  VI A DJUSTED P VALUES OBTAINED BY N EMENYI 222 S T EST   H OLM 222 S T EST   S HAFFER 222 S T EST  AND B ERGMANN H OMMEL P ROCEDURE FOR THE T EST D ATA A CCURACY OBTAINED IN OUR C OMPUTATIONAL E XPERIMENTS  i Hypothesis Unadjusted p  p Neme  p Holm  p Shaf  p Berg  1 Pareto vs. ECW 3.1 x 10 10 4.8 x 10 9 4.8 x 10 9 4.8 x 10 9 4.9 x 10 9  2 Pareto vs. EC 1.6 x 10 7 2.4 x 10 6 2.2 x 10 6 1.6 x 10 6 1.6 x 10 6  3 EC vs. ECW 1.6 x 10 4 0.0024 0.0021 0.0016 0.0016 4 Pareto vs. ECW 8.0 x 10 4 0.0119 0.0095 0.0080 0.0056 5 Pareto* vs. ECW 0.0012 0.0173 0 0127 0.0116 0.0081 6 Pareto vs. Pareto 0.0024 0.0355 0 0237 0.0237 0.0142 7 ECW vs. ECW 0 0033 0.0500 0.0300 0.0237 0.0142 8 EC vs. EC 0.0064 0.0963 0.0514 0.0449 0.0385 9 Pareto vs. EC 0 0119 0.1781 0.0831 0.0831 0.0475 10 Pareto* vs. EC 0 0277 0.4156 0.1662 0.1662 0.0831 11 ECW vs. EC 0.0592 0.8876 0.2959 0.2367 0.1183 12 EC* vs. ECW 0 2945 1.0000 1.0000 1.0000 1.0000 13 EC vs. ECW 0.4017 1.0000 1.0000 1.0000 1.0000 14 EC vs. Pareto 0 6002 1.0000 1.0000 1.0000 1.0000 15 ECW vs. Pareto 0 7532 1.0000 1.0000 1.0000 1.0000 


   including data sets with more than two classes. We also have to compare the proposed method with other learning algorithms. There are still a lot of things we have to improve in the proposed extensions, es pecially the search space and genetic operations in the lateral tuning. The discussion on the tradeoff relation among accuracy, complexity, and interpretability is also another important future research issue  Pareto EC ECW Pareto EC ECW  0.00 0.01 0.05 0.10 0 2 4 6 Average rank  Fig. 9.  Average rank for the test data accuracy over low imbalanced data sets A smaller rank is better Pareto EC ECW Pareto EC ECW  0.00 0.01 0.05 0.10 0 2 4 6 Average rank  Fig. 10.  Average rank for the test da ta accuracy over high imbalanced data sets. A smaller rank is better R EFERENCES  1  R. J. Bayardo Jr. and R. Agrawal 223Mining the most interesting rules,\224 Proc. of the 5th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining ACM Press, New York, NY USA, pp. 145-154, 1999 2  B. Liu, W. Hsu, and Y. Ma, \223Integ rating classification and association rule mining,\224 Proc. of 4th International Conference on Knowledge Discovery and Data Mining New York, AAAI Press, August 27-31 1998, pp. 80-86 3  X. Yin and J. Han, \223CPAR: Cl assification based on predictive association rules,\224 Proc. of SIAM International Conference on Data Mining, San Francisco CA, May 2003, pp. 331-335 4  H. Ishibuchi, K. Nozaki, N. Yamamoto, and H. Tanaka, \223Selecting fuzzy if-then rules for classi fication problems using genetic algorithms,\224 IEEE Trans. on Fuzzy Systems vol. 3, no. 3, pp. 260-270 1995 5  H. Ishibuchi, T. Murata, and I B. Turksen, \223Single-objective and two-objective genetic algorithms for selecting linguistic rules for pattern classification problems,\224 Fuzzy Sets and Systems vol. 89, no. 2 pp. 135-150, 1997 6  H. Ishibuchi, T. Nakashima, and T Murata, \223Three-objective genetics based machine learning for linguistic rule extraction,\224 Information Sciences vol. 136, no. 1-4, pp. 109-133, 2001 7  H. Ishibuchi and T. Yamamoto, \223F uzzy rule selection by multi objective genetic local search algorith ms and rule evaluation measures in data mining,\224 Fuzzy Sets and Systems vol. 141, no. 1, pp. 59-88 2004 8  H. Ishibuchi, I. Kuwajima, and Y Nojima, \223Prescreening of candidate rules using association rule mining a nd Pareto-optimality in genetic rule selection,\224 Proc. of 11th International Conference on Knowledge Based and Intelligent Informa tion and Engineering Systems pp 509-516, 2007 9  I. Kuwajima, Y. Nojima, and H. Ishibuchi, \223Obtaining accurate classifiers with Pareto-optimal and near Pareto-optimal rules,\224 Proc. of 11th International Symposium on Artificial Life and Robotics pp 195-198, Beppu, Japan, January 31-February 2, 2008 10  H. Ishibuchi and T. Nakashima, \223E ffect of rule weights in fuzzy rule-based classification systems,\224 IEEE Trans. Fuzzy Systems vol. 9 no. 4, pp. 506-515, August 2001 11  H. Ishibuchi and T. Yamamoto, \223Rule weight specification in fuzzy rule-based classification systems,\224 IEEE Trans. on Fuzzy Systems vol 13, no. 4, pp 428-435, August 2005 12  J. M. Alonso and L. Magdalena, \223A n interpretability-guided modeling process for learning comprehensible fuzzy rule-based classifiers,\224 Proc of 9th International Conference on Intelligent Systems Design and Applications pp. 432-437, 2009 13  K. Deb, A. Pratap, S. Agarwal, a nd T. Meyarivan, \223A fast and elitist multiobjective genetic algorithm: NSGA-II,\224 IEEE Trans. on Evolutionary Computation vol. 6, no. 2, pp. 182-197, April 2002 14  R. Alcal\341, J. Alcal\341-Fdez, and F Herrera, \223A proposal for the genetic lateral tuning of linguistic fuzzy syst ems and its interaction with rule selection,\224 IEEE Trans. on Fuzzy Systems vol. 15, no. 4, pp. 616-635 2007 15  J. Alcal\341-Fdez, R. Alcal\341, M. J. Gacto, and F. Herrera, \223Learning the membership function contexts for mining fuzzy association rules by using genetic algorithms,\224 Fuzzy Sets and Systems vol. 160, pp 905-921, 2009 16  M. Kaya and R. Alhaji, \223Utilizi ng genetic algorithms to optimize membership functions for fuzzy weighted association rules mining,\224 Applied Intelligence vol. 24, no. 1, pp. 7-15, February 2006 17  W. Wang and S. M. Bridges, \223G enetic algorithm optimization of membership functions for mining fuzzy association rules,\224 Proc. of the 7th International Conference on Fuzzy Theory & Technology  pp.131-134, Atlantic City, NJ February 27-March 3, 2000 18  J. Dem\232ar, \223Statistical comparisons of classifiers over multiple data sets,\224 Journal of Machine Learning Research vol. 7, pp. 1-30, 2006 19  M. Friedman, \223The use of ranks to avoid the assumption of normality implicit in the analysis of variance,\224 Journal of the American Statistical Association vol. 32, pp. 675-701, 1937 20  P. B. Nemenyi Distribution-free Multiple Comparisons PhD thesis Princeton University, 1963 21  S. Holm, \223A simple sequentially re jective multiple test procedure,\224 Scandinavian Journal of Statistics vol. 6, pp. 65-70, 1979 22  J. P. Shaffer, \223Modified seque ntially rejective multiple test procedures,\224 Journal of the American Statistical Association vol. 81 pp. 826-831, 1986 23  G. Bergmann and G. Hommel, \223Impr ovements of general multiple test procedures for redundant systems of hypotheses,\224 In Bauer, Hommel and Sonnemann, eds  Multiple Hypotheses Testing Springer, Berlin, pp 100-115, 1988 24  S. Garc\355a and F. Herrera, \223An exte nsion on \221Statistical comparisons of classifiers over multiple data sets\222 for all pairwise comparisons,\224 Journal of Machine Learning Research vol. 9, pp. 2677-2694 December 2008 The source code is available at http sci2s.ugr.es/keel/multipleTest.zip   


Application of Chaotic Particle Swarm Optimization Algorithm in Chinese Documents Classification 763 Dekun Tan Qualitative Simulation Based on Ranked Hyperreals 767 Shusaku Tsumoto Association Action Rules and Action Paths Triggered by Meta-actions 772 Angelina A. Tzacheva and Zbigniew W. Ras Research and Prediction on Nonlinear Network Flow of Mobile Short Message Based on Neural Network 777 Nianhong Wan, Jiyi Wang, and Xuerong Wang Pattern Matching with Flexible Wildcards and Recurring Characters 782 Haiping Wang, Fei Xie, Xuegang Hu, Peipei Li, and Xindong Wu Supplier Selection Based on Rough Sets and Analytic Hierarchy Process 787 Lei Wang, Jun Ye, and Tianrui Li The Covering Upper Approximation by Subcovering 791 Shiping Wang, William Zhu, and Peiyong Zhu Stochastic Synchronization of Non-identical Genetic Networks with Time Delay 794 Zhengxia Wang and Guodong Liu An Extensible Workflow Modeling Model Based on Ontology 798 Zhenwu Wang Interval Type-2 Fuzzy PI Controllers: Why They are More Robust 802 Dongrui Wu and Woei Wan Tan Improved K-Modes Clustering Method Based on Chi-square Statistics 808 Runxiu Wu Decision Rule Acquisition Algorithm Based on Association-Characteristic Information Granular Computing 812 JianFeng Xu, Lan Liu, GuangZuo Zheng, and Yao Zhang Constructing a Fast Algorithm for Multi-label Classification with Support Vector Data Description 817 Jianhua Xu Knowledge Operations in Neighborhood System 822 Xibei Yang and Tsau Young Lin An Evaluation Method Based on Combinatorial Judgement Matrix 826 Jun Ye and Lei Wang Generating Algorithm of Approximate Decision Rules and its Applications 830 Wang Yun and Wu-Zhi Qiang Parameter Selection of Support Vector Regression Based on Particle Swarm Optimization 834 Hu Zhang, Min Wang, and Xin-han Huang T-type Pseudo-BCI Algebras and T-type Pseudo-BCI Filters 839 Xiaohong Zhang, Yinfeng Lu, and Xiaoyan Mao A Vehicle License Plate Recognition Method Based on Neural Network 845 Xing-Wang Zhang, Xian-gui Liu, and Jia Zhao Author Index 849 
xiii 


   C4.2 Open GL has excellent documentation that could help the developer learn the platform with ease C4.3 Developer has very little ex perience in working with Open GL platform  For our case study, alternative B i.e. Adobe Director was the most favorable alternative amongst all the three. It catered to the reusability criteria quite well and aimed at meeting most of the desired operational requirements for the system   6. CONCLUSION & FUTURE WORK  The main contribution of this paper is to develop an approach for evaluating performance scores in MultiCriteria decision making using an intelligent computational argumentation network. The evaluation process requires us to identify performance scores in multi criteria decision making which are not obtained objectively and quantify the same by providing a strong rationale. In this way, deeper analysis can be achieved in reducing the uncertainty problem involved in Multi Criteria decision paradigm. As a part of our future work we plan on conducting a large scale empirical analysis of the argumentation system to validate its effectiveness   REFERENCES  1  L  P Am g o u d  U sin g  A r g u men ts f o r mak i n g an d  ex p lain in g  decisions Artificial Intelligence 173 413-436, \(2009 2 A  Boch m a n   C ollectiv e A r g u men tatio n    Proceedings of the Workshop on Non-Monotonic Reasoning 2002 3 G  R Bu y u k o zk an  Ev alu a tio n o f sof tware d e v e lo p m en t  projects using a fuzzy multi-criteria decision approach Mathematics and Computers in Simualtion 77 464-475, \(2008 4 M T  Chen   F u zzy MCD M A p p r o ach t o Selec t Serv ice  Provider The IEEE International Conference on Fuzzy 2003 5 J. Con k li n  an d  M. Beg e m a n   gIBIS: A Hypertext Tool for Exploratory Policy Discussion Transactions on Office Information Systems 6\(4\: 303  331, \(1988 6 B P  Duarte D e v elo p in g a p r o jec ts ev alu a tio n sy ste m based on multiple attribute value theroy Computer Operations Research 33 1488-1504, \(2006 7 E G  Fo rm an  T h e  A n a l y t ic Hier a rch y P r o cess A n  Exposition OR CHRONICLE 1999 8 M. L ease  an d J L  L i v e l y  Using an Issue Based Hypertext System to Capture Software LifeCycle Process Hypermedia  2\(1\, pp. 34  45, \(1990 9  P e id e L i u   E valu a tio n Mo d e l o f Custo m e r Satis f a c tio n o f  B2CE Commerce Based on Combin ation of Linguistic Variables and Fuzzy Triangular Numbers Eight ACIS International Conference on Software Engin eering, Artificial Intelligence Networking and Parallel Distributed Computing, \(pp 450-454 2007  10  X  F L i u   M an ag e m en t o f an In tellig e n t A r g u m e n tatio n  Network for a Web-Based Collaborative Engineering Design Environment Proceedings of the 2007 IEEE International Symposium on Collaborative Technologies and Systems,\(CTS 2007\, Orlando, Florida May 21-25, 2007 11 X. F L i u   A n In ternet Ba se d In tellig e n t A r g u m e n tatio n  System for Collaborative Engineering Design Proceedings of the 2006 IEEE International Symposium on Collaborative Technologies and Systems pp. 318-325\. Las Vegas, Nevada 2006 12 T  M A sub jec tiv e assess m e n t o f altern ativ e m ission  architectures for the human exploration of Mars at NASA using multicriteria decision making Computer and Operations Research 1147-1164, \(June 2004 13 A  N Mo n ireh  F u zzy De cisio n Ma k i n g b a se d o n  Relationship Analysis between Criteria Annual Meeting of the North American Fuzzy Information Processing Society 2005 14 N  P a p a d ias HERMES Su p p o rti n g A r g u m e n tative  Discourse in Multi Agent Decision Making Proceedings of the 15th National Conference on Artifical Intelligence \(AAAI-98  pp. 827-832\dison, WI: AAAI/MIT Press,  \(1998a 15  E. B T riantaph y llo u   T h e Im p act o f  Ag g r e g atin g Ben e f i t  and Cost Criteria in Four MCDA Methods IEEE Transactions on Engineering Management, Vol 52, No 2 May 2005 16 S  H T s a u r T h e Ev alu a tio n o f airlin e se rv ice q u a lity b y  fuzzy MCDM Tourism Management 107-115, \(2002 1 T  D W a n g  Develo p in g a f u zz y  T O P S IS app r o ach  b a sed  on subjective weights and objective weights Expert Systems with Applications 8980-8985, \(2009 18 L  A  Zadeh  F u z z y Sets   Information and Control 8  338-353, \(1965  152 


                        





