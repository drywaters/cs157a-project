002 002 
Practical Parallel Lempel-Ziv Factorization Julian Shun 
Carnegie Mellon University jshun@cs.cmu.edu Fuyao Zhao Carnegie Mellon University fuyaoz@cs.cmu.edu 
Abstract 
In the age of big data the need for efìcient data compression algorithms has grown A widely used data compression method is the Lempel-Ziv-77 LZ77 
method being a subroutine in popular compression packages such as gzip and PKZIP There has been a lot of recent effort on developing practical sequential algorithms for Lempel-Ziv factorization equivalent to LZ77 compression but research in practical parallel implementations has been less satisfactory In this work we present a simple work-efìcient parallel algorithm for Lempel-Ziv factorization We show theoretically that our algorithm requires linear work and runs in 
O 
time randomized for constant alphabets and time   for integer alphabets We present experimental results showing that our algorithm is efìcient and achieves good speedup with 
n O n 002 
log    1 
2 
002 
respect to the best sequential implementations of Lempel-Ziv factorization 
1 Introduction 
lossless 
As data sizes increase compression techniques which reduce the storage requirements of such data become more important Data compression techniques are widely studied in computer science and fall into two categoriesÑlossless and lossy For methods e.g Lempel-Ziv 31 arithmetic coding 26 Huf fman coding 15 and Burro wsWheeler no information is lost when the data is compressed while compression with 
lossy 
methods e.g JPEG and MPEG can result in some information loss Lempel-Ziv-77 LZ77 and Lempel-Zi v-78 LZ78 32 form the basis for the f amily of Lempel-Ziv methods They are dictionary coders meaning that the encoder searches a dictionary for matches of substrings of the text and returns a pointer to the substringês location in the dictionary In LZ77 the encoder uses a sliding window implicit dictionary over the text to search for previous occurrences of substrings Lempel-Ziv-Storer 
Szymanski LZSS is a v ariant of LZ77 that returns a pointer to the dictionary only if the matched substring is long enough LZ78 stores an explicit dictionary containing substrings previously seen and in each iteration searches this dictionary to nd the longest substring that exists in the dictionary and then inserts a new entry into the dictionary Lempel-Ziv-Welch is a v ariant of LZ78 that uses a pre-initialized dictionary  As we are interested in parallel implementations we focus on LZ77 in this work rather 
than LZ78 since LZ77 admits efìcient parallel solutions whereas LZ78 was shown to be P-complete unlikely to have an efìcient parallel solution 10 LZ77 is a lossless dynamic compression method that has been popular due to its simplicity and computational efìciency It is a component of the DEFLATE algorithm which is used in software packages such as gzip and PKZIP The LZ77 algorithm consists of a compression stage which computes the Lempel-Ziv factorization LZ-factorization of 
the input string and a decompression stage which recovers the original string from the Joint rst author Part of this work was done while author was an undergraduate student at Central South University 
002  
2013 Data Compression Conference 1068-0314/13 $26.00 © 2013 IEEE DOI 10.1109/DCC.2013.20 123 


S S 
 
n O n O n n O n O n O n O n n 002 002 002 
m 
log   log  log    log  log  0   
2 0 1 1 
 
2 Lempel-Ziv Factorization Preliminaries 
compressed string The LZ-factorization can be computed sequentially in linear time with a sufìx tree and decompression can be done sequentially in linear time with a scan The rst parallel algorithms for LZ-factorization were described independently by Noar and Crochemore and Rytter 9 F or a string of length  their algorithms require time and work on the PRAM making them not work-efìcient Farach and Muthukrishnan gi v e the rst linear w ork algorithms for both LZ-f actorization and decompression each requiring time on the PRAM These parallel algorithms all make use of parallel sufìx trees LZ77 decompression is much simpler and faster than LZ-factorization so we focus on the latter There has been much research done in designing practical sequential algorithms for computing the LZ-factorization Recently researchers have proposed the use of sufìx arrays instead of sufìx trees to obtain faster and more space-efìcient algorithms for LZfactorization 8 6 5 7 Since suf x arrays can be computed in linear time 17 these LZ-factorization algorithms are also able to run in linear time The aforementioned sequential algorithms have been shown to perform well in practice To the best of our knowledge the only parallel implementations of LZ-factorization described in the literature are those of Klein and Wiseman using CPUs and Ozso y and Swany using GPUs Both implementations in v olv e splitting the input string among processors and having each processor independently compute the factorization of its substring Because in these implementations the processors do not necessarily have access to the entire input string they do not always compute the same LZ-factorization as would be computed sequentially and thus can produce larger compressed les Furthermore the corresponding papers 19 do not pro vide an y comple xity bounds on w ork and time Previous work on parallel algorithms for computing the same LZ-factorization as would be computed sequentially do not include any implementations or experiments 13 22 The linear w ork algorithm of F arach and Muthukrishnan 13 does not lead to a practical implementation as it involves complicated parallel methods for tree contraction least common ancestors and Euler tours In this work we present a simple linear-work parallel algorithm for LZ-factorization and practical implementations of it Our algorithm computes the same factorization as would be computed sequentially The algorithm is based on parallel sufìx arrays nding all nearest smaller values and uses simple parallel routines such as preìx sums and list ranking Theoretically  our algorithm requires work and time randomized due to the use of sufìx arrays so does not achieve the time bound of Farach and Muthukrishnan b ut lends itself to a practical implementation W e sho w experimentally that on 40 cores we achieve speedups between 6.7 and 21.2 compared to running the algorithm on a single core We also implement a sequential algorithm for LZfactorization that is faster than previous algorithms 1  and our parallel algorithm achieves a 4.8Ö15.5 fold speedup on 40 cores over this sequential algorithm  The LZ-factorization of a string is  1 Very recently a slightly faster sequential algorithm was independently described by Kempa and Puglisi  
124 


factor sufìx array longest common preìx longest previous factor previous occurrence array all nearest smaller values ANSV 
m n i<m 002 i 002 002 002 002 002 abbaabbbaaabab 002 002 002 a 002 b 002 b 002 a 002 abb 002 baa 002 ab 002 ab 002  002 002 i n abbaabbbaaabab a  b             m i i n n n  s s s s n i i  i  j<i i i i abbaabbbaaabab abbaabbbaaabab 
SA SA SA SA SA 
S S start prev start S prev S start prev prev start start prev start start LZ LZ start prev suf S S S SA SA suf suf suf LCP LCP LCP suf suf S suf suf LPF LPF prevOcc prevOcc suf S SA LCP LPF prevOcc LZ SA LCP LPF prevOcc LZ S 
    
003 003      004 004 004 004 
0              0  1  2 1 3 0 4 0 7 2 10 0 12 10   0  0 1 lcp    0 0    lcp  lcp       
0 a 80 aaabab 23 0 1 b 92 aabab 33 1 2 b 33 aabbbaaabab 10 2 3 a 12 1 ab 210 3 4 a 10 2 abab 20 4 5 b 02 abbaabbbaaabab 0-1 7 6 b 43 abbbaaabab 30 10 7 b 13 0 b 17 12 8 a 71 baaabab 32  9 a 23 baabbbaaabab 11  10 a 11 2 bab 22  11 b 61 bbaaabab 41  12 a 14 bbaabbbaaabab 01  13 b 52 bbbaaabab 21  Figure 1 
i i i m i i i i i i i i i i i i i m i i i n i j i j i i i j i 
0 1 1 0 7 0 1 2 3 4 5 6 7 1 0         
where and for each  called the th of the string is either a single character which does not appear in or is the longest preìx of that also appears starting at a position to the left of in  In the example given by Crochemore et al the string has the factorization where       and  To achieve compression the values are not explicitly returned LZ77 returns a sequence of pairs where indicates the starting position of in and indicates the position of s left match in if it exists coded and otherwise stores the character at position uncoded For decompression each pair can reconstruct its factor by looking at and either directly copying if it is a character or copying characters starting at the position stored in we consider the value of to be 0 and to be  The sequence of pairs returned for the string is  Throughout our discussion we denote the LZ-factorization by an array of size where stores only the value of the pair To obtain the LZ77 representation the value of the pair can easily be computed given the previous occurrence array deìned later in this section This can easily be modiìed to return the LZSS representation We denote of string to be the sufìx of starting at position  The  of a string is an array of length such that is a permutation of the integers and  where means lexicographically less than We use to denote the length of the longest common preìx lcp between strings and  The array is an array of length such that and for   The of an index in  is equal to the maximum value of  for all  We denote to be the longest previous factor array where stores the longest previous factor of index 0 if none We use to denote the  where stores the starting location of the longest previous factor of in 1 if none Figure 1 shows the    and arrays for the string  i S  i  SA  i  LCP  i  suf i LPF  SA  i  prevOcc  SA  i  LZ  i     and for  The problem is deìned as follows for each element 
125 


n i i n i i  i i i 
LN RN LN RN LPF LPF LZ LPF LPF next next LPF next next LZ start LPF SA LCP SA LCP SA SA LCP SA LCP LPF SA LCP suf SA    LN RN SA  Then LPF suf SA  suf SA  LN  suf SA  suf SA  RN  
LPF LZ LZ LZ LZ LPF LZ LZ 
       1    min max   1     1    log    log    log 2      1     and   be the left and right nearest smaller neighbors of element    max\(lcp  lcp     log log  0 003 
LPFtoLZ while do return 
Algorithm LPFtoLZ Lemma 2.1 Let 
i i i W T P O T n i i i  n i<n n O n O n O n O n O n O n O n O n 003 i i i i in i    O n O n i<j<n 
   1 2 3 4 5 6 
0 0    1    a x  1     1 
W P 002 i  i  i  i  
work time 
in a sequence of elements from a total ordering nd the closest smaller element to the left and the closest smaller element to the right of it if there is no smaller element then report it An algorithm for ANSV returns two arrays and where   contains the index of the nearest smaller element to the left right of element 1 if none Throughout this paper we will use the parallel random-access machine PRAM model of parallel computation where refers to the number of operations performed by an algorithm and refers to the number of time steps required by an algorithm We will assume that the model supports concurrent reads and concurrent writes CRCW PRAM If the number of processors available is  then by Brentês work-time scheduling principle the total running time will be proportional to   Our parallel algorithm is based on the sequential algorithm described by Crochemore Ilie and Smyth henceforth CIS which rst computes the array Computing the LZ-factorization can then be computed with a single pass over the array The psuedocode for computing from is shown below We rst describe Farach and Muthukrishnanês method of parallelizing given the array as an input Their method creates a size array of pointers  where for and  Following the indices pointers starting at until reaching a value of 1 is sufìcient to determine the indices in  Using a parallel list ranking algorithm with the v alue at inde x 0 set to 1 and the remaining values set to 0 the result is an array of ags indicating which indices are in the LZ-factorization This can be done in work and time A preìx sums is then done on the array of ags to get the values for the elements in the LZ-factorization and this can also be done in work and time Now what remains is to show how to compute the array As done in CIS the sufìx array is rst computed While CIS computes the array after computing  we compute while computing  Using the algorithm of Karkkainen and Sanders  both and can be computed in parallel using work and time randomized for constant-sized alphabets and work and for on integer alphabets on the CRCW PRAM After computing and  we apply the following lemma due to Crochemore et al which states that an y can be computed using an ANSV computation and range minima queries on and  To deal with boundary cases we assume evaluates to the empty string and therefore has an lcp of 0 with any other string Berkman Schieber and Vishkin sho w that ANSVs can be computed in work and time on the CRCW PRAM It can be shown that for any  
126 


 k i i i O O n O n baaabab baaabab i n O n O i i O n O n O n O n i i O n O n O n O n O n O n O n O n O n 
 so using range minima queries we can compute the lcp values and hence the values is set to if has a longer lcp with  and otherwise Range minima queries can be performed in work and time and requires work and time for preprocessing In the example shown in Figure 1 to determine and corresponding to sufìx  we look at its left nearest smaller value in  which is  and its right nearest smaller value which is  and then select the one corresponding to the sufìx with a larger lcp with  which is of length  Therefore and  We now describe two variants of our algorithm differing only in how is computed Our rst variant PLZ1 uses Lemma 2.1 directly It builds a range minima query table on the array for constant-time queries and then in parallel does range minima queries to compute each  The queries require a total of work and time Our second variant PLZ2 uses as a component the sequential algorithm of Crochemore et al which tak es the ANSVs as input and does a single pass o v er the string to compute the array Their crucial observation is that  and using this dependence they derive a linear-work algorithm for computing  Unlike PLZ1 PLZ2 does not build a range minima query table for constant-time queries but instead builds a segment tree on the array an idea which was also investigated by Canovas and Navarro The se gment tree is a binary tree whose lea v es store the elements of and internal nodes store the minimum value of its children It requires work and time to construct Range minima queries can be answered by traversing the levels of the tree hence requiring work and time PLZ2 then divides the input into blocks and computes the values of each block The longest previous factor of the rst element is computed using a range minima query on the segment tree described above and since only depends on  we can then run the sequential algorithm of Crochemore et al to compute the remaining longest pre vious factors of each block Since we perform in parallel one query for each of the blocks this leads to a cost of work and time Running the linear-work sequential algorithm per block in parallel takes a total of work and time since the size of each block is  Our motivation for designing PLZ2 was that constructing the segment tree is simpler than constructing the table for constant-time queries and since we only perform queries on a subset of the elements we found experimentally that the decreased construction time more than makes up for the increased query times The steps for LZ-factorization are summarized below PLZ1 and PLZ2 differ only in the computation of step 3 From the above discussion we see that all the steps require work and the time is dominated by the sufìx array construction We have the following lemma 
SA SA SA LN SA 
suf suf LCP LPF prevOcc LN suf suf RN LPF prevOcc SA LPF prevOcc LPF LCP LPF LPF LPF LPF LPF LCP LCP LPF LPF LPF 
005    
Lemma 2.2 Our parallel algorithm for computing the Lempel-Ziv factorization requires 
 S  n  1 Compute the sufìx array SA  and longest common preìx array LCP  for S  2 Compute the left and right smaller neighbor arrays LN and RN on SA using an ANSV algorithm 3 Compute the LPF and prevOcc arrays 4 
         log log 2 
ComputeLZ return LPFtoLZ LPF  n  
i j i<k j i i n n n n 
002 
lcp   min         1   log    4 2 3   3   2     1     1   log  log  log        log    log  log      work and log  time randomized for constant-sized alphabets and   work 
127 


3 Implementations Parallel LPFtoLZ Sequential 4 Experiments 
O n 003 O n O n 003 O n n O n O n n O n O n 
8196 
  1 log    1  log  log   log  log    
002 002 n 
LCP LCP LCP LCP LCP LPF SA LPF 
Except for the sufìx array and lcp computation our algorithm takes time for arbitrary alphabets so improvements to the bounds for sufìx array and lcp computation can improve our overall bounds as well Our algorithm is amenable to implementation as we describe in the next section  We implemented PLZ1 PLZ2 and a simple variant of PLZ2 that avoids computing the array For sufìx arrays we used the linear-work and time for some constant  implementation from the Problem Based Benchmark Suite There are faster sequential sufìx array codes when running on one core but most of them do not compute the array see e.g W e implemented an optimized v ersion of the work and time ANSV algorithm of Berkman et al instead of their much more complicated work-optimal version For  we implemented a random sampling-based list ranking algorithm and used the parallel sequence routines from the Problem Based Benchmark Suite F or the range minima query table used for computing the array inside the sufìx array algorithm we used an work time construction for constant-time range minima queries For PLZ1 we built a range minima table on the resulting array using the same construction For PLZ2 we set the number of blocks to in our experiments which we found to give the best results We implemented the sequential algorithm of Crochemore et al which is used in each block Our variant of PLZ2 which we call PLZ3 does not compute the array but instead computes the lcp values of the rst element of each block with its nearest smaller neighbors using naive string comparison and uses this to compute its value The rest of each block is computed in the same way as in PLZ2  Here we describe a simple sequential algorithm for LZ-factorization which we use in our experiments in Section 4 Our sequential algorithm LZ-ANSV rst computes the sufìx array without lcps and then computes the ANSVs on the sufìx array sequentially using the stack-based algorithm of Gabow et al It then loops through the sufìxes in their original order and for the positions appearing in the LZ-factorization it computes the longest previous factor with the sufìxes corresponding to the positions of their left and right smaller neighbors in using naive string comparison By incrementing the index of the loop by the length of the longest previous factor after computing it for an element it bypasses the computation for the elements not appearing in the LZfactorization LZ-ANSV requires work We experimentally compare the performance of the different implementations of our parallel LZ-factorization algorithm We are not aware of any existing parallel implementations for computing the same LZ-factorization as would be computed sequentially Previous parallel algorithms for doing so 13 22 use parallel suf x trees and are relati v ely complicated no implementations are available We show that the best publicly available parallel sufìx tree algorithm is slo wer than that of our entire LZ-f actorization algorithm on most strings hence it is unlikely that a parallel implementation of LZ-factorization that uses sufìx trees will outperform our implementation 
and   for integer alphabets on the CRCW PRAM 
128 


icpc O2 g O2 http://people.unipmn it/manzini/lightweight/corpus http://pizzachili.dcc.uchile cl/texts.html 
LCP LPF LPF LCP LPF 
Experimental Setup Experimental Results 
4 2 4 10 10 
 006 
7 7 40 1 1 40 
 T T T T 
We compare our parallel code with our sequential LZ-ANSV code and the sequential algorithm of Ohlebusch and Gog which the y sho wed to be f aster than other sequential algorithms note that as mentioned in Footnote 1 very recently a faster algorithm was published by Kempa and Puglisi W e obtained the code from Ohleb usch and Gog and refer to it as LZ-OG All of the implementations in our experiments compute pairs containing the starting position and previous occurrence for each factor in the LZ-factorization For fair comparison all of the implementations used the same sufìx array code  We performed experiments on a 40-core Intel machine with hyper-threading with GHz Intel 10-core E7-8870 Xeon processors a 1066MHz bus and 256GB of main memory The parallel programs were compiled with Intelês compiler version 12.1.0 using CilkPlus with the ag The sequential programs were compiled using 4.4.1 with the ag We used a variety of real-world strings available online  and  XML code from Wikipedia samples wikisamp*.xml and artiìcial inputs Our artiìcial inputs are of size and include an all identical string 10Midentical a random string with an alphabet size of 10 10Mrandom and a string with an alphabet size of 2 where every th position contains the rst character and all other positions contain the second character 10Msqrtn  We rst compared the three variants of our PLZ algorithm and found that PLZ3 gives the best absolute performance across the board both in parallel and sequentially This is due to the fact that PLZ3 does not need to compute the array which takes about one-third of the time of the sufìx array code and this more than makes up for the extra time spent in performing naive string comparisons for the rst element of each block The parallel running times on 40 cores with hyper-threading   for all three variants are shown in Table 1 We compared PLZ3 to the two sequential algorithms LZ-ANSV and LZ-OG and Table 1 shows a comparison of running times on the input strings is the time in seconds for running PLZ3 on a single core and the speedup is computed as  The results show that our sequential algorithm LZ-ANSV outperforms LZ-OG for all of the input strings Note that however LZ-ANSV does not compute the entire array whereas LZ-OG does so for applications where the entire array is required LZ-ANSV will not sufìce On a single core PLZ3 is 1.3Ö1.6 times slower than LZ-ANSV On 40 cores with hyper-threading PLZ3 achieves 6.7Ö21.2 times speedup with respect to running the algorithm on one core It achieves a 4.8Ö15.5 times speedup with respect to LZ-ANSV The running times of PLZ3 and LZ-ANSV as a function of the number of processors for the 10Mrandom and wikisamp8.xml les are shown in Figures 2\(a and 2\(b respectively PLZ3 achieves good speedup and outperforms LZ-ANSV with just 2 or more processors Figure 3 shows the running time of PLZ3 on 40 cores as a function of the input size random characters We see that PLZ3 scales gracefully with the size of the input Figure 4 shows the breakdown of the running time of PLZ3 on several input strings We note that the sufìx array takes about 80 of the time If the lcps are also computed as in PLZ1 and PLZ2 then the sufìx array time becomes about 1.5 times slower which explains why PLZ3 improves over PLZ1 and PLZ2 by not computing the array The computation takes 
129 


 
 We note that for most strings the parallel suf\223x tree code alone takes as much time or more time than our entire LZ-factorization algorithm and since a suf\223x tree-based LZ-factorization algorithm involves many other procedures e.g tree contraction least common ancestors and Euler tours it is unlikely that such an algorithm will have a better overall performance We have presented a simple parallel algorithm for Lempel-Ziv factorization which requires 
time  
n n n 
O 
 for integer alphabets We showed that a practical implementation of our algorithm is fast for a wide variety of input strings and achieves good speedup on 
003 
Text Size LZ-ANSV LZ-OG PLZ3 PLZ3 PLZ3 PLZ1 PLZ2 PST MB 
0.1 
1 
LPF 
O 
PST 
002 
log 
1 
O 
T T T 
T T 
n 
10 1.68 1.74 2.35 0.347 6.772 0.553 0.515 0.377 10Mrandom 10 3.97 4.67 6.2 0.437 14.18 0.521 0.55 0.286 10Msqrtn 10 2.14 2.44 3.36 0.401 8.379 0.618 0.611 0.439 chr22.dna 34.6 19.4 22.0 28.9 1.57 18.40 1.9 2.02 1.56 etext99 105 69.9 75.2 99.0 4.8 20.62 5.69 6.18 5.33 howto.txt 39.4 24.0 25.5 33.4 1.82 18.35 2.24 2.36 1.93 jdk13c 69.7 40.4 41.4 54.1 2.86 18.91 3.89 3.95 3.45 pitches 55.8 31.8 34.3 43 2.27 18.94 2.79 2.89 2.47 proteins 210 147 172 203 9.79 20.74 11.6 12.5 11.4 rctail96 115 70.0 72.9 96.5 4.77 20.23 6.19 6.57 5.83 rfc 116 72.8 76.6 100 4.83 20.70 6.19 6.5 5.77 sources 211 140 163 186 9.17 20.28 11.7 12.1 11.4 sprot34.dat 110 69.0 72.2 93.7 4.6 20.36 5.9 6.31 5.57 w3c2 104 63.1 64.7 84.1 4.42 19.02 5.96 6.11 5.5 wikisamp8.xml 100 59.9 61.4 81.2 4.03 20.14 5.51 5.54 4.96 wikisamp9.xml 1000 653 670 894 42.1 21.23 55.1 56.2 59.9 Table 1 Comparison of running times seconds of parallel and sequential algorithms on different inputs on a 40-core machine with hyper-threading a 10Mrandom b wikisamp8.xml Figure 2 Log-log plots of running times on a 40-core machine with hyper-threading less than 20 of the overall time and the ANSV computation and conversion from 
work and time randomized for constant-sized alphabets and work and 
LZ 
O 
LZ-ANSV   LZ-ANSV   
   
2 
Speedup 10Midentical to take very little time The suf\223x array portion of the code achieves the lowest speedup so improvements in parallel suf\223x array code will likely improve our LZ-factorization code In Table 1 we also include the 40-core times for a modi\223ed version of the best publicly available parallel suf\223x tree code of Blelloch and Shun labeled 
40 40 40 40 
1 10 1 2 4 8 16 32 40 1 10 100 1 2 4 8 16 32 40 
5 Conclusion 
Running time \(seconds Number of processors Comparison of running times for 10Mrandom PLZ3 Running time \(seconds Number of processors Comparison of running times for wiki8 PLZ3 
   
130 


Acknowledgments References 
0 1 2 3 4 5 etext99 rctail96 rfc w3c2 wikisamp8 Running time \(seconds Text file Breakdown of running times for PLZ3 SA ANSV       LPF       LZ       
0 5 10 15 20 25 30 35 40 200 400 600 800 1000 Running time \(seconds File size \(MB Running times versus file size \(random characters 
Figure 3 Running time versus input size of PLZ3 on 40 cores Figure 4 Breakdown of running time of PLZ3 on 40 cores a 40-core machine even relative to the best sequential implementations Opportunities for future work include integrating our algorithm into popular compression packages and developing practical parallel implementations of other methods in the Lempel-Ziv family We thank Guy Blelloch and the anonymous reviewers for their helpful comments This work is partially supported by the National Science Foundation under grant number CCF-1018188 and by Intel Labs Academic Research Ofìce for the Parallel Algorithms for Non-Numeric Computing Program  O Berkman B Schieber  and U V ishkin Optimal doubly logarithmic parallel algorithms based on nding all nearest smaller values  1993  G E Blelloch and J Shun A simple parallel cartesian tree algorithm and its application to sufìx tree construction In  2011  M Burro ws and D J Wheeler  A block-sorting lossless data compression algorithm Technical report HP Labs 1994  R C  anovas and G Navarro Practical compressed sufìx trees In  2010  G Chen S Puglisi and W  Smyth Lempel-Zi v f actorization using less time  space  1 2008  M Crochemore and L Ilie Computing longest pre vious f actor in linear time and applications  2008  M Crochemore L Ilie C S Iliopoulos M K ubica W  Rytter  and T  W ale  n LPF 
J Algorithms ALENEX SEA Mathematics in Computer Science Inf Process Lett 
131 


Combinatorial Algorithms Data Compression Conference Inf Process Lett Theor Comp Sci Data Compression Communications and Processing Computational Geometry Algorithms and Applications SPAA STOC Proceedings of the IRE Introduction to Parallel Algorithms ICALP ALENEX Discrete Appl Math SODA J ACM ICALP CPM IEEE International Conference on Cluster Computing ACM Computing Surveys IBM J Res Dev J ACM SPAA J ACM Computer IEEE Transactions on Information Theory IEEE Transactions on Information Theory 
computation revisited In  2009  M Crochemore L Ilie and W  Smyth A simple algorithm for computing the Lempel-Ziv factorization In  2008  M Crochemore and W  Rytter  Ef cient parallel algorithms to test square-freeness and factorize strings  1991  S De Agostino P-complete problems in data compression  1994  S De Agostino Lempel-Zi v data compression on parallel and distrib uted systems In  2011  M de Ber g O Cheong M v an Kre v eld and M Ov ermars  Springer-Verlag 2008  M F arach and S Muthukrishnan Optimal parallel dictionary matching and compression extended abstract In  1995  H Gabo w  J Bentle y  and R T arjan Scaling and related techniques for geometry problems In  1984  D Huf fman A method for the construction of minimum-redundanc y codes  1952  J Jaja  Addison-Wesley Professional 1992  J Karkkainen and P  Sanders Simple linear w ork suf x array construction In  2003  D K empa and S J Puglisi Lempel-Zi v f actorization Simple f a st practical In  2013  S T  Klein and Y  W iseman P arallel Lempel Zi v coding  2005  U Manber and G Myers Suf x arrays A ne w method for on-line string searches In  1990  E M McCreight A space-economical suf x tree construction algorithm  1976  M Naor  String matching with preprocessing of te xt and pattern In  1991  E Ohleb usch and S Gog Lempel-Zi v f actorization re visited In  2011  A Ozso y and M Sw an y  CULZSS LZSS lossless data compression on CUD A In  2011  S Puglisi W  F  Smyth and A H T urpin A taxonomy of suf x array construction algorithms  2007  J Rissanen and G G Langdon Arithmetic coding  1979  M Rodeh V  R Pratt and S Ev en Linear algorithm for data compression via string matching  1981  J Shun G E Blelloch J T  Fineman P  B Gibbons A K yrola H V  Simhadri and K Tangwongsan Brief announcement the Problem Based Benchmark Suite In  2012  J A Storer and T  G Szymanski Data compression via te xtual substitution  1982  T  W elch A technique for high-performance data compression  June 1984  J Zi v and A Lempel A uni v ersal algorithm for sequential data compression  1977  J Zi v and A Lempel Compression of indi vidual sequences via v ariable-rate coding  1978 
132 


A Global Solution COVERAGE North and South America EMEA and Asia White lines are flights in the masFlight platform from February 8, 2013 Yellow pins are weather stations feeding hour ly data to our platform Maps from Google Earth / masFlight masFlight tracks flights, airports and weather around the world  Global daily flight information capture  82,000 flights  350 airlines  1700 airports  Integrated weather data for 6,000 stations  Match weather to delays  Validate block forecasts at granular level  Add weather analytics to IRROPS review and scenario planning 


Example 1: Proposed FAA Tower Closures masFlight used big-data to link airport operations across three large data sets  Current and historical airline schedules  Raw Aircraft Situation Display to Industry \(ASDI\AA  Enhanced Traffic Management System Counts \(ETMS\Airport operations counts by type \(commercial, freight, etc TOWER CLOSINGS Dots indicate closures; Red dots have scheduled service Based on scheduled service March 1 7, 20 13; scheduled service includes scheduled charter flights, cargo flig hts, and passenger flights Dots  indicate  closures  Red  dots  have  scheduled  service Bas ed  o n sc h edu l ed  se rvi ce  M a r c h 1  7, 2013; scheduled se rvi ce includ es scheduled c harter fli g hts car g o fli g hts a nd passen g er fli g hts Findings: Proposed Tower Closings  From schedules database: 55 airports with scheduled passenger airline service  14 EAS Airports  From ASDI & ETMS: 10,600 weekly flights on a flight plan \(ex. VFR and local traffic  6,500 Part 91/125 weekly flights  4,100 Part 135/121 weekly flights  


Example 1: Big-Data Analytics Applied to ASDI and ETMS To Analyze Operations TOWER CLOSINGS  26 44 24 23 11 10 6 2 1 2 Up to 5 5-10 10-15 15-20 20-25 25-30 30-35 35-40 40-45 45 Count of Airports Average Number of Daily Operations with a Flight Plan Filed Distribution of Airports By Average Number of ìDailyî Impacted Flights Airports Affected by Tower Closures Source: ASDI radar data ñ Part 91 151 flying and Part 135/121 flying March 1-7, 2013; masFlight analysis Note: Average ìdailyì operations based on 5-day week 


Example 2: Aviation Safety Causal Factor For example, consider the following ASRS report \(ACN 1031837 Departing IAH in a 737-800 at about 17,000 FT, 11 m iles behind a 737-900 on the Junction departure over CUZZZ Intersection. Smooth air with wind on the nose bearing 275 degrees at 18 KTS We were suddenly in moderate chop which lasted 4 or 5 seconds then stopped and then resumed for another 4 or 5 seconds with a significant amount of ri ght rollingÖ I selected a max rate climb mode in the FMC in order to climb above the wake and flight path of the leading -900 We asked ATC for the type ahead of us and reported the wake encounter. The 900 was about 3,300 FT higher than we were  Synopsis  B737-800 First Officer reported wake encounter from preceding B737-900 with resultant roll and moderate chop What causal factors can be identified from this narrative that could be applied to future predictive applications CAUSAL FACTORS Data-mining algorithms can mine the text of safety reports to obtain specific data that can be used to analyze causal factors  


Example 2: Identifying Causal Factors CAUSAL FACTORS  Indicators ñ Data Element Methods ñ Identifying Context and Causes  Time of day  Date range \(month day  Aircraft type  Fix or coordinates  Originating airport  Destination airport  Weather notes We pinpoint the sequencing of flights on the IAH Junction Seven departure \(at CUZZZ\the specified wind conditions to find cases wher e a B737-900 at 20,000 feet precedes by 11 miles a B737-800 at 17,000 feet  Search related data sets including ASDI flight tracks, local traffic and congestion  Weather conditions for alter native causes \(winds aloft shear and convecti ve activity  Airline specific informati on \(repeated occurrence of event in aircraft type Big data gives us visibility into contextual factors even if specific data points are missing such as a specific date or route Big-data analytics gives us insight into unreported factors as well 


Example 3: Correlating Utilization and Delays  60 65 70 75 80 85 90 95 100 7 9 11 13 ONTIME DEPARTURE PERFORMANCE HOURS OF DAILY UTILIZATION 60.0 70.0 80.0 90.0 100.0 7.0 9.0 11.0 13.0 Narrowbodies By Day of Week 60.0 70.0 80.0 90.0 100.0 7.0 9.0 11.0 13.0 Widebodies by Day of Week Daily Utilization vs. On-time Departures January 2013 System Operations Correlation Coefficient -0.53 Includes AA, AC, AS B6 F9, FL, NK, UA, US VX and WN SOURCE masFlight \(masflight.com COMPARING OTP AND UTILIZATION 


 6.2 6.0 5.8 5.8 5.2 4.9 LGB JFK BOS MCO DCA FLL JetBlue Focus Average Daily Deps per Gate Used UTILIZATION BY HUB Example 4: Daily Utilization of Gates, by Hub Big-data analysis of different carriers daily departures per gate used SOURCE masFlight \(masflight.com June 1 through August 31, 2012 Gates with minimum 1x daily use 7.7 7.4 7.2 6.2 6.1 5.8 3.8 3.6 ORD LAX SFO EWR DEN IAH IAD CLE United Airlines Hubs Average Daily Deps per Gate Used 7.8 6.4 5.5 5.4 5.3 4.4 4.3 4.0 SEA SAN PDX ANC SFO GEG LAX SJC Alaska Airlines Hubs Average Daily Deps per Gate Used 7.2 6.9 6.8 6.4 5.0 2.7 ORD DFW LAX LGA MIA JFK American Hubs Average Daily Deps per Gate Used 7.2 6.9 6.6 4.9 4.2 CLT DCA PHL PHX BOS US Airways Hubs Average Daily Deps per Gate Used 6.6 5.9 5.5 4.7 MCO BWI ATL MKE AirTran Hubs Average Daily Deps per Gate Used ne pe 


Conclusions for Big Data in Aviation  Big-data transforms operational and commercial problems that were practically unsolvable using discrete data and on-premises hardware  Big data offers new insight into existing data by centralizing data acquisition and consolidation in the cloud and mining data sets efficiently  There is a rich portfolio of information that can feed aviation data analytics  Flight position, schedules, airport/gate, weather and government data sets offer incredible insight into the underlying causes of aviation inefficiency  Excessive size of each set forces analysts to consider cloud based architectures to store, link and mine the underlying information  When structured, validated and linked these data sources become significantly more compelling for applied research than they are individually  Todayís cloud based technologies offer a solution CONCLUSIONS 


Conclusions:  Our Approach  masFlightís data warehouse and analysis methods provide a valuable example for others attempting to solve cloud based analytics of aviation data sets  masFlightís hybrid architecture, consolidating secure data feeds in on-premises server installations and feeding structured data into the cloud for distribution, addresses the unique format, security and scale requirements of the industry  masFlightís method is well suited for airline performance review competitive benchmarking, airport operations and schedule design and has demonstrated value in addressing real-world problems in airline and airport operations as well as government applications CONCLUSIONS 





