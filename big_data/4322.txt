Modeling of System of Systems via Data Analytics \226 Case for \223Big Data\224 in SoS 1   Barnabas K. Tannahill Aerospace Electronics and Information Technology Division Southwest Research Institute San Antonio, TX, USA barney.tannahill@swri.org  Co-Authors C. E. Maute, Y. Yetis, M. N. Ezell A. Jaimes, R. Rosas, A. Motaghi, H. Kaplan, and Mo Jamshidi, Fellow IEEE Department of Electrical and Computer Engineering University of Texas at San Antonio San Antonio, TX, USA  Abstract  
Large data has been accumulating in all aspects of our lives for quite some time. Advances in sensor technology, the Internet, wireless communication, and inexpensive memory have all cont ributed to an explosion of 223Big Data\224. System of Systems \(SoS\ integrate independently operating, non-homogeneous systems to achieve a higher goal than the sum of the parts. Today\222s SoS are also contributing to the existence of unmanageable 223Big Data\224. Recen t efforts have developed a promising approach, called \223Data Analytics\224, which uses statistical and computational intelligence \(C I\ tools such as principal component analysis \(PCA\, clustering, fuzzy logic, neurocomputing, evolutionary computation, Bayesian networks 
etc. to reduce the size of \223Big Data\224 to a manageable size and apply these tools to a\ract information, b\ build a knowledge base using the derived data, and c\ eventually develop a non-parametric model for the \223Big Data\224. This paper attempts to construct a bridge between SoS and Data Analytics to develop reliable models for such systems.  A photovoltaic energy forecasting problem of a micro grid SoS will be offered here for a case study of this modeling relation Keywords Data Analytics, Big Data, Solar Energy Clustering, Micro-Grid, Neural Networks, Fuzzy Inference Systems, Fuzzy C-Means, PCA 1  Introduction  System of Systems \(SoS\tegrated 
independently operating systems working in a cooperative mode to achieve a higher performance. A detailed literature survey on definitions to applications of SoS can be found in recent texts by Jams pplication areas of  SoS  are vast indeed. They are software systems like the Internet cloud computing, health care, and cyber-physical systems all the way to such hardware dominated cases like military energy, transportation, etc. Data analytics and its statistical and intelligent tools including clustering, fuzzy logic neuro-computing, data mining, pattern recognition and post-processing such as evolutionary computations have 
their own applications in forecasting, marketing, politics and all domains of SoS  A typical example of SoS is the future Smart Grid destined to replace conventiona l electric grid. A small-scale version of this SoS is a micro-grid designed to provide electric power to a local community. A Micro-Grid is an aggregation of multiple distributed generators \(DGs\uch as renewable energy sources, conventional generators, in association with energy storage units which work together as a power supply networked in order to provide both electric power and thermal energy for small communities which may vary from one common building to a smart 
house or even a set of comp licated loads co nsisting of a mixture of different structures such as buildings, factories   T y picall y a m i cro g r id ope rates s y n c h r on ous l y i n  parallel with the main grid. However, there are cases in which a Micro-Grid operates in islanded mode, or in a disconnected st ccu rate predictions of received solar power can reduce operating costs by influencing decisions regarding buying or selling power from the main grid or utilizing non-renewable energy generation sources  The object of this paper is to use a massive amount of data on solar irradiance as an integral system of the micro 
grid SoS to extract relevant information for available solar energy in an attempt to derive an unconventional model  Section II first describes the micro-grid that will be used as the SoS of interest for this paper. Section III then describes the set of environmental data to be used in this paper as the input to the different data analytics tools Section IV then discusses the application and effectiveness of different data analytics tools in the generation of models and relations that could be leveraged to better optimize the operation of the micro-grid.  Finally, Section V summarizes the exercises discussed in this paper and draws conclusions 
based on their findings 2  System Model  The micro-grid SoS is shown in Figure 1.  Shown here are solar array, battery storage, DC-AC inverter, load 1 This work is partially funded by Lutcher Brown Endowed Chair, ACE Laboratory, University of Texas at San Antonio 
978-1-4673-5597-1/13/$31.00 \2512013 IEEE Proc. of the 2013 8th International Conference on System of Systems Engi\neering, Maui, Hawaii, USA - June 2-6, 2013 177 


and a controller to manage the entire system. Ultimately we want to forecast received solar power as a model based on real-time environmental measurements to be used in an energy management system [3 t o m i ni mi z e o p e r a t i n g costs This micro-grid represents a facility scale Cyber-Physical System \(CPS\r a SoS consisting of a building with 200  A fixed \(or with tracking system\olar photovoltaic system 200  A load demand in the form of overall energy consumption, HVAC and lighting, with bidirectional communications \(e.g. bi-directional inverter 200  A reconfigurable control and acquisition system i.e. with open I/O modules, embedded controller for communication, processing and a userprogrammable FPGA 200  A local, off-site or cloud-based computing infrastructure for simulation/computational analysis  Figure 1.  A PV Forecasting System as a constituent member of  3  PV Data Description  To ensure the Photovoltaic \(PV\put data for the different data analysis tools is comprehensive, data from different sources was combined to form the full dataset This was possible because of the solar research projects occurring in Golden, CO, where the National Renewable Energy Laboratory \(NREL\ is conducting long term research and data recording to support the growing renewable energy industry  The first source was the data recorded by the Solar Radiation Research Laboratory \(SRRL\which employs over 70 instruments to measure solar conditions and environmental parameters A l s o t h is data s e t i n cl u d es 180\260 images of the sky that are used to determine current cloud conditions directly.  An example of this is shown in Figure 2  Figure 2. Sample Sky Image  The second source of data was the SOLPOS data made available by the Measurement and Instrumentation Data Center \(MIDC\, which has stations throughout North America to capture information on solar position and available solar energy u ck il y  th e MIDC  h as a s t atio n near NREL, so their data can be used in conjunction with the SRRL data  The final set of data originates from the Iowa Environmental Mesonet \(IEM h eir Au to m a ted Surface Observing System \(ASOS station near the Golden CO site was also included to have current weather data in the set  Data from the month of October 2012 was combined from the different sources of data.  This final set includes one sample for each minute of the month and incorporates measured values for approximately 250 different variables at each data point. The data set was sanitized to only include data points containing valid sensor data prior to the analysis 4  Data Analytics of PV Data  In this section, the analysis steps are described, and the results from the different techniques are compared.  The goal is to use data analytics tools to generate a useful model from the dataset without needing to resort to parametric analysis and the use of subject matter experts 4.1  Objective Identification  Since the micro-grid would benefit from predicted values of solar irradiance, it was decided that the output of the data analytics should be 60 minute predicted values of three key irradiance parameters \(Global Horizontal Irradiance \(GHI zontal Irradiance \(DHI\nd Direct Normal Irradiance \(DNI 178 


4.2  Input Variable Downselection  The input variables were down selected from the full data set to only include cloud levels, humidity, temperature wind speed, and current irradiance levels.  If this exercise was conducted using \223Cloud\224 computing, the number of variables might not need to be down-selected; however since this effort took place on a single PC, the number of variables was reduced 4.3  Cleanup of the Raw Dataset  Next, the data set was further reduced by removing data points in which GHI, DHI, and DNI levels were very low.  The primary reason for this second step was to reduce the amount of time and memory necessary for analysis Figure 3 is a graph containing the measurements of GHI DHI, and DNI over one day in the cleaned dataset  Figure 3. Three Key Irradiance Parameter Plot for a Clear Day 4.4  Non-Parametric Model Generation Tools  After cleaning took place, the data could be fed into either of the two non-parametric model generating tools the Fuzzy Inference System Generator and BackPropagation Neural Network training tools included in the Matlab Fuzzy Logic Toolbox and the Neural Network Toolbox 4.4.1  Non-Parametric Model Generation Tools  The Fuzzy Logic Toolbox function used in this exercise genfis3 uses Fuzzy C-Means clustering to cluster values for each variable which produces fuzzy membership functions for each of the variables in the input matrix and output matrix.  It then determines the rules necessary to map each of the fuzzy inputs to the outputs to best match the training data set.  These membership functions and rules can be viewed using the Matlab FIS GUI tools such as ruleview When run with default parameters, the genfis3  function ran significantly slower and performed worse than Matlab\222s Neural Network fitting function  Figure 4. Data Generated Using GENFIS3 Based on 13 Input Variables  Note in Figure 4, differences in the observed and predicted data points generally corresponds to the presence of clouds or other anomalies that could not be predicted an hour in advance using the variables input to the function 4.4.2  Neural Network Fitting Tool  The second model generating method was the Matlab Neural Network Training tool.  By default, this tool uses the Levenberg-Marquardt back propagation method to train the network to minimize its mean squared error performance.  Results from training one sample set are shown in Figure 5, Figure 6, and Figure 7  Figure 5. Back-propagation Performance Curve 179 


 Figure 6. Post Training Network Regression Performance  Figure 7. Data Generated Using NFTOOL Based on 13 Input Variables and 10 Hidden Neurons 4.5  Additional Pre-Processing Discussion  Once the initial performance of these two tools was evaluated, it was decided that further effort should go into including a greater number of original input variables and including additional preprocessed parameters in the training data in an effort to enhance the performance of the derived model.  This effort took three paths, the calculation of nonlinear input parameters, the inclusion of a greater number of input parameters, and the reduction of input data dimension when necessary in order to support the execution requirements of the two model generation tools 4.5.1  Nonlinear Data Set Expansion  In an effort to derive additional useful input parameters from the existing dataset, each variable included in the dataset generated several additional variables based on nonlinear functions and past values of the variable itself.  Inclusion of these parameters in the training data set greatly improved the performance of the training tools.  A subject matter expert would be useful in this step to identify useful derived parameters such as these to add to the training data set 4.5.2  Large Data Sets and Principal Component Analysis  Models were generated using different sets of input variables to try to assess the impact of incorporating increasing numbers of variables in the training data set.  In general, the trained model performed better when more variables were included in the training data set; however, as the number of variables increased, the training execution time became excessive and out-of-memory errors occurred when the data sets became too large  In order to combat this issue, the dimension of the training data set was reduced to a manageable size using PCA.  PCA can be used to compress the information from a large number of variables to a smaller dataset while minimizing the information lost during this process [8   This can be performed directly on a dataset using the princomp function in Matlab  The columns of the SCORE matrix returned by the princomp function represent the columns of the input data transformed to place the majority of the information in the data set in the first few principal components.  The information distribution among the principal components is illustrated in Figure 8.  The higher eigenvalues represent the principal components with the most information Incorporating principal components past 10 provides minimal additional information  Figure 8. Principal Component Information Graph  Figure 9 below shows the quality of information recovery if transforming back to the original basis using only information from the first 50 principal components 180 


 Figure 9. Data Recovery Demonstration Using First 50 Principal Components  In this application PCA was primarily useful because it allowed the reduction of very high dimension data sets to smaller, more manageable data sets that could be used as training inputs to the model generation tools 4.6  Results  In order to generate the best non-parametric model possible, different combinations of data inputs to the GENFIS3 and NFTOOL were considered.  Different implementations of the options discussed above were evaluated during this analysis  The best performing NFTOOL generated model used all 244 original variables, which were then expanded the dimension to 1945 using the nonlinear variable derivation calculations.  Next, the dimension of the data was shrunk to 150 so that the training function had sufficient memory to train the network.  The resulting network was the best of all the generated models  The best performing GENFIS3 generated model evaluated during this effort used the same input data set as mentioned in the paragraph above with the exception that the dimension was shrunk down to 50 using PCA.  It was observed during this effort that effectiveness of the GENFIS3 tool appears to be less tolerant of high dimension training data sets than the NFTOOL   Figure 10. Best Neural Network Linear Regression Performance  Figure 11. Best Neural Network GHI Error  Figure 12. Best Neural Network DHI Error 181 


 Figure 13. Best Neural Network DNI Error  Table 1 and 2 describe the performance of the models generated using these tools.  Note that these performance numbers should be compared qualitatively since the different input parameter configurations can yield different numbers of training data points Table 1. Performance Comparison of the Generated NonParametric Models \(GENFIS3  Table 2. Performance Comparison of the Generated NonParametric Models \(NN10   A sub-optimal predictor was constructed in order to show its performance relative to that of the non-parametric models.  This predictor was based on the average GHI DHI, and DNI values for each time bin in the data set Table 3 shows the improvement of the non-parametric models when compared to this sub-optimal predictor named \223Time Bin Mean\224 in the table below Table 3. Performance of Best Non-Parametric to Mean Time Bin Sub-Optimal Predictor   During this analysis, the aspect of the scalability of the GENFIS3 and NFTOOL tools was evaluated.  The model generation time for NFTOOL was always shorter than GENFIS3 for the same data sets.  The relationship of NFTOOL execution time to dataset length and dimension was generally linear for the test cases evaluated.  The relationship of GENFIS3 execution time to dataset length was also linear; however, its relationship between dataset dimension and execution time was a function of the dataset dimension squared.  This is shown in Figure 14 and Figure 15  Figure 14. Model Generation Execution Time Relationship with Dataset Dimension  182 


 Figure 15. Model Generation Execution Time Relationship with Dataset Length 5  Conclusion  This paper presents a high level look at some of the tools available in the Matlab toolset that enable the user to extract information from \223Big Data\224 sources in order to draw useful conclusions.  As described in Section II, the specific application discussed in this paper is the prediction of the amount of solar power generated by a micro-grid Section III then discusses the data that was gathered to support this exercise.  Section IV discusses the steps and techniques considered while trying to generate the best solar irradiance prediction model.  Techniques discussed included dataset sanitation, training input parameter selection, model generation via Fuzzy C-Means Clustering and Rule Inference GENFIS3 Neural Network training using back propagation NFTOOL Pre-Processing nonlinear variables to add to the training data set, and the use of PCA to reduce the dimension of the training data while maximizing the information retained in the data set  It was observed in the results presented in Section IV that the best model predicting solar irradiance was one utilizing the maximum number of original and preprocessed variables, which was then reduced to a manageable dimension using PCA prior to use in training the model.  The results in this section also showed that the non-parametric model generation methods discussed in this paper performed significantly better than a sub-optimal predictor.  Finally, the results describing the model generation times for the two techniques showed that NFTOOL provides significantly better training times especially when the dimension of the dataset is high  Future work on this topic is planned to address the benefits of using Genetic Programming to optimally reduce the dimension of the dataset, the use of cloud computing to generate models for larger data sets, and the design and evaluation of a controller to buy or sell money from the grid based on demand and predictions of received solar energy References 1  M. Jamshidi \(ed.\, Systems of Systems Engineering \226 Principles and Applications, CRC \226 Taylor & Francis Publishers, London, UK, 2008 2  M. Jamshidi \(ed.\, System of Systems Engineering \226 Innovations for the 21st Century, John Wiley & Sons Publishers, New York, NY, 2009 3  Y. S. Manjili, A. Rajaee, M. Jamshidi, B. Kelley 223Fuzzy Control of Electricity Storage Unit for Energy Management of Micro-Grids1\224, World Automation Congress \(WAC\co, 2012 4  Texas Sustainable Energy Research Institute Proposal to National Science Foundation on PV Forecasting and Energy Management, M. Jamshidi PI February 2013, San Antonio, Texas 5  National Renewable Energy Laboratory. \(2012 Current Irradiance and Meteorological Conditions Data Set Retrieved from http://www.nrel.gov/midc/srrl_bms 6  National Renewable Energy Laboratory. \(2012 SOLPOS Data Set. Retrieved from http://www.nrel.gov/midc/solpos/ solpos.html 7  Iowa Environmental Mesonet. \(2012\. Automated Surface Observing System Data Set. Retrieved from http://mesonet.agron.iastate.edu/ASOS 8  L. I. Smith. \(2002, Feb. 26\\223A Tutorial on Principal Components Analysis\224, [Onlin ailable   http://www.cs.otago.ac.nz/cosc453/student_tutorials/princi pal_components.pdf 9  J. Shlens. \(2009, Apr. 22\A Tutorial on Principal Component Analysis\224 Version 3.01, [Onlin A v ailab l e  http://www.snl.salk.edu/~shlens/pca.pdf 183 


  Z. Jia et al. “The Implications of Diverse Applications and Scalable Data Sets in Benchmarking Big Data Systems”. Second workshop of big data benchmarking \(WBDB 2012 India\ & Lecture Note in Computer Science \(LNCS   Y. Chen et al, “We Don’t Know Enough to make a Big Data Benchmark suite”. Workshop on Big Data Benchmarking. 2012   J. Zhan et al, “High volume computing: Identify and characterizing throught oriented workloads in data centers”. In Parallel and Distributed processing Symposium Workshops & PhD Forum IPDPSW\, 2012 IEEE 26 th International pages 1712-1721. IEEE 2012   http://en.wikipedia.org/wiki/Principal_component_analysis   http://en.wikipedia.org/wiki/K-means_clustering   125 


overhead of job initialization in Hadoop is much larger than cNeural VIII C ONCLUSION AND F UTURE W ORK The past several years have witnessed an ever-increasing growth speed of data To address large scale neural network training problems in this paper we proposed a customized parallel computing platform called cNeural Different from many previous studies cNeural is designed and built on perspective of the whole architecture from the distributed storage system at the bottom level to the parallel computing framework and algorithm on the top level Experimental results show that cNeural is able to train neural networks over millions of samples and around 50 times faster than Hadoop with dozens of machines In the future we plan to develop and add more neural network algorithms such as deep belief networks into cNeural in order to make further support training large scale neural networks for various problems Finally with more technical work such as GUI done we would like to make it as a toolbox and open source it A CKNOWLEDGMENT This work is funded in part by China NSF Grants No 61223003 the National High Technology Research and Development Program of China 863 No 2011AA01A202 and the USA Intel Labs University Research Program R EFERENCES  C Bishop Neural networks for pattern recognition  Clarendon press Oxford 1995  J Collins Sailing on an ocean of 0s and 1s  Science  vol 327 no 5972 pp 1455…1456 2010  S Haykin Neural networks and learning machines  Englewood Cliffs NJ Prentice Hall 2009  R Hecht-Nielsen Theory of the backpropagation neural network in Proc Int Joint Conf on Neural Networks,IJCNN IEEE 1989 pp 593…605  Y  Loukas  Arti“cial neural netw orks in liquid chromatography Ef“cient and improved quantitative structure-retention relationship models Journal of Chromatography A  vol 904 pp 119…129 2000  N Serbedzija Simulating arti“cial neural netw orks on parallel architectures Computer  vol 29 no 3 pp 56…63 1996  M Pethick M Liddle P  W erstein and Z Huang P arallelization of a backpropagation neural network on a cluster computer in Proc Int Conf on parallel and distributed computing and systems PDCS  2003  K Ganeshamoorthy and D Ranasinghe On the performance of parallel neural network implementations on distributed memory architectures in Proc Int Symp on Cluster Computing and the Grid CCGRID  IEEE 2008 pp 90…97  S Suresh S Omkar  and V  Mani P arallel implementation of back-propagation algorithm in networks of workstations IEEE Trans Parallel and Distributed Systems  vol 16 no 1 pp 24…34 2005  Z Liu H Li and G Miao Mapreduce-based backpropagation neural network over large scale mobile data in Proc Int Conf on Natural Computation ICNC  vol 4 IEEE 2010 pp 1726…1730  M Glesner and W  P  ochm  uller Neurocomputers an overview of neural networks in VLSI  CRC Press 1994  Y  Bo and W  Xun Research on the performance of grid computing for distributed neural networks International Journal of Computer Science and Netwrok Security  vol 6 no 4 pp 179…187 2006  C Chu S Kim Y  Lin Y  Y u  G  Bradski A Ng and K Olukotun Map-reduce for machine learning on multicore Advances in neural information processing systems  vol 19 pp 281…288 2007  U Seif fert  Arti“cial neural netw orks on massi v ely parallel computer hardware Neurocomputing  vol 57 pp 135…150 2004  D Calv ert and J Guan Distrib uted arti“cial neural netw ork architectures in Proc Int Symp on High Performance Computing Systems and Applications  IEEE 2005 pp 2…10  H Kharbanda and R Campbell F ast neural netw ork training on general purpose computers in Proc Int Conf on High Performance Computing HiPC  IEEE 2011  U Lotri  c and e a Dobnikar A Parallel implementations of feed-forward neural network using mpi and c on  net platform in Proc Int Conf on Adaptive and Natural Computing Algorithms  Coimbra 2005 pp 534…537  Q V  Le R Monga and M e a De vin Building high-le v e l features using large scale unsupervised learning in Proc Int Conf on Machine Learning ICML  ACM 2012 pp 2…16  J Ekanayak e and H e a Li T wister a runtime for iterati v e mapreduce in Proc of the 19th ACM International Symposium on High Performance Distributed Computing  ACM 2010 pp 810…818  Y  Bu B Ho we M Balazinska and M D Ernst Haloop Ef“cient iterative data processing on large clusters Proc of the VLDB Endowment  vol 3 no 1-2 pp 285…296 2010  M Zaharia M Cho wdhury  T  Das A Da v e  J  Ma M McCauley M Franklin S Shenker and I Stoica Resilient distributed datasets A fault-tolerant abstraction for in-memory cluster computing in Proc USENIX Conf on Networked Systems Design and Implementation  USENIX Association 2012 pp 2…16 384 


Figure 15  3D model of the patio test site Figure 16  Model of the patio test site combining 2D map data with 3D model data a Largest explored area b Smallest explored area Figure 14  Maps built by a pair of 2D mapping robots Yellow indicates area seen by both robots Magenta indicates area seen by one robot and Cyan represents area seen by the other a 3D point cloud built of the patio environment Figure 16 shows a model built combining 2D map data with 3D model data A four-robot mission scenario experiment was conducted at the mock-cave test site This included two 2D mapping robots a 3D modeling robot and a science sampling robot There was no time limit on the run Figure 17 shows a 3D model of the tunnel at the mock cave Figure 18 shows a model built combining 2D map data with 3D model data 7 C ONCLUSIONS  F UTURE W ORK The multi-robot coordination framework presented in this paper has been demonstrated to work for planetary cave mission scenarios where robots must explore model and take science samples Toward that end two coordination strategies have been implemented centralized and distributed Further a core communication framework has been outlined to enable a distributed heterogenous team of robots to actively communicate with each other and the base station and provide an online map of the explored region An operator interface has been designed to give the scientist enhanced situational awareness collating and merging information from all the different robots Finally techniques have been developed for post processing data to build 2  3-D models of the world that give a more accurate description of the explored space Fifteen 2D mapping runs with 2 robots were conducted The average coverage over all runs was 67 of total explorable area Maps from multiple robots have been merged and combined with 3D models for two test sites Despite these encouraging results several aspects have been identi\002ed that can be enhanced Given the short mission durations and small team of robots in the experiments conducted a simple path-to-goal costing metric was suf\002cient To use this system for more complex exploration and sampling missions there is a need for learning-based costing metrics Additional costing parameters have already been identi\002ed and analyzed for future implementation over the course of this study One of the allocation mechanisms in this study was a distributed system however task generation remained centralized through the operator interface In an ideal system robots would have the capability to generate and auction tasks based on interesting features they encounter Lastly the N P complete scheduling problem was approximated during task generation However better results could potentially 10 


Figure 17  3D model of the tunnel in the mock cave test site Figure 18  Model of the mock cave test site combining 2D map data with 3D model data be obtained by releasing this responsibility to the individual robots A CKNOWLEDGMENTS The authors thank the NASA STTR program for funding this project They would also like to thank Paul Scerri and the rCommerceLab at Carnegie Mellon University for lending hardware and robots for this research R EFERENCES  J C W erk er  S M W elch S L Thompson B Sprungman V Hildreth-Werker and R D Frederick 223Extraterrestrial caves Science habitat and resources a niac phase i study\\224 NASA Innovative Advanced Concepts NIAC Tech Rep 2003  G Cushing T  T itus and E Maclennan 223Orbital obser vations of Martian cave-entrance candidates,\224 in First Intl Planetary Caves Workshop  Carlsbad NM 2011  J W  Ashle y  M S Robinson B R Ha wk e A K Boyd R V Wagner E J Speyerer H Hiesinger and C H van der Bogert 223Lunar caves in mare deposits imaged by the LROC narrow angle camera,\224 in First Intl Planetary Caves Workshop  Carlsbad NM 2011  J W  Ashle y  A K Bo yd H Hiesinger  M S Robinson T Tran C H van der Bogert and LROC Science Team 223Lunar pits Sublunarean voids and the nature of mare emplacement,\224 in LPSC  The Woodlands,TX 2011  S Dubo wsk y  K Iagnemma and P  J Boston 223Microbots for large-scale planetary surface and subsurface exploration niac phase i.\224 NASA Innovative Advanced Concepts NIAC Tech Rep 2006  S Dubo wsk y  J Plante and P  Boston 223Lo w cost micro exploration robots for search and rescue in rough terrain,\224 in IEEE International Workshop on Safety Security and Rescue Robotics Gaithersburg MD  2006  S B K esner  223Mobility feasibility study of fuel cell powered hopping robots for space exploration,\224 Master's thesis Massachusetts Institute of Technology 2007  M T ambe D Pynadath and N Chauv at 223Building dynamic agent organizations in cyberspace,\224 IEEE Internet Computing  vol 4 no 2 pp 65\22673 March 2000  W  Sheng Q Y ang J T an and N Xi 223Distrib uted multi-robot coordination in area exploration,\224 Robot Auton Syst  vol 54 no 12 pp 945\226955 Dec 2006  A v ailable http://dx.doi.or g/10.1016/j.robot 2006.06.003  B Bro wning J Bruce M Bo wling and M M V eloso 223Stp Skills tactics and plays for multi-robot control in adversarial environments,\224 IEEE Journal of Control and Systems Engineering  2004  B P  Gerk e y and M J Mataric 223 A formal analysis and taxonomy of task allocation in multi-robot systems,\224 The International Journal of Robotics Research  vol 23 no 9 pp 939\226954 September 2004  M K oes I Nourbakhsh and K Sycara 223Heterogeneous multirobot coordination with spatial and temporal constraints,\224 in Proceedings of the Twentieth National Conference on Arti\002cial Intelligence AAAI  AAAI Press June 2005 pp 1292\2261297  M K oes K Sycara and I Nourbakhsh 223 A constraint optimization framework for fractured robot teams,\224 in AAMAS 06 Proceedings of the 002fth international joint conference on Autonomous agents and multiagent sys11 


tems  New York NY USA ACM 2006 pp 491\226493  M B Dias B Ghanem and A Stentz 223Impro ving cost estimation in market-based coordination of a distributed sensing task.\224 in IROS  IEEE 2005 pp 3972\2263977  M B Dias B Bro wning M M V eloso and A Stentz 223Dynamic heterogeneous robot teams engaged in adversarial tasks,\224 Tech Rep CMU-RI-TR-05-14 2005 technical report CMU-RI-05-14  S Thrun W  Bur g ard and D F ox Probabilistic Robotics Intelligent Robotics and Autonomous Agents  The MIT Press 2005 ch 9 pp 222\226236  H Mora v ec and A E Elfes 223High resolution maps from wide angle sonar,\224 in Proceedings of the 1985 IEEE International Conference on Robotics and Automation  March 1985  M Yguel O A ycard and C Laugier  223Update polic y of dense maps Ef\002cient algorithms and sparse representation,\224 in Intl Conf on Field and Service Robotics  2007  J.-P  Laumond 223T rajectories for mobile robots with kinematic and environment constraints.\224 in Proceedings International Conference on Intelligent Autonomous Systems  1986 pp 346\226354  T  Kanungo D Mount N Netan yahu C Piatk o R Silverman and A Wu 223An ef\002cient k-means clustering algorithm analysis and implementation,\224 IEEE Transactions on Pattern Analysis and Machine Intelligence  vol 24 2002  D J Rosenkrantz R E Stearns and P  M Le wis 223 An analysis of several heuristics for the traveling salesman problem,\224 SIAM Journal on Computing  Sept 1977  P  Scerri A F arinelli S Okamoto and M T ambe 223T oken approach for role allocation in extreme teams analysis and experimental evaluation,\224 in Enabling Technologies Infrastructure for Collaborative Enterprises  2004  M B Dias D Goldber g and A T  Stentz 223Mark etbased multirobot coordination for complex space applications,\224 in The 7th International Symposium on Arti\002cial Intelligence Robotics and Automation in Space  May 2003  G Grisetti C Stachniss and W  Bur g ard 223Impro ving grid-based slam with rao-blackwellized particle 002lters by adaptive proposals and selective resampling,\224 in Proceedings of the IEEE International Conference on Robotics and Automation  2005  227\227 223Impro v ed techniques for grid mapping with raoblackwellized particle 002lters,\224 IEEE Transactions on Robotics  2006  A Geiger  P  Lenz and R Urtasun 223 Are we ready for autonomous driving the kitti vision benchmark suite,\224 in Computer Vision and Pattern Recognition CVPR  Providence USA June 2012  A N 250 uchter H Surmann K Lingemann J Hertzberg and S Thrun 2236d slam with an application to autonomous mine mapping,\224 in Proceedings of the IEEE International Conference on Robotics and Automation  2004 pp 1998\2262003  D Simon M Hebert and T  Kanade 223Real-time 3-d pose estimation using a high-speed range sensor,\224 in Proceedings of the IEEE International Conference on Robotics and Automation  1994 pp 2235\2262241 B IOGRAPHY  Ammar Husain received his B.S in Mechanical Engineering Robotics from the University of Illinois at Urbana-Champaign He is pursuing an M.S in Robotic Systems Development at Carnegie Mellon University He has previously worked on the guidance and control of autonomous aerial vehicles His research interests lie in the 002eld of perception-based planning Heather Jones received her B.S in Engineering and B.A in Computer Science from Swarthmore College in 2006 She analyzed operations for the Canadian robotic arm on the International Space Station while working at the NASA Johnson Space Center She is pursuing a PhD in Robotics at Carnegie Mellon University where she researches reconnaissance exploration and modeling of planetary caves Balajee Kannan received a B.E in Computer Science from the University of Madras and a B.E in Computer Engineering from the Sathyabama Institute of Science and technology He earned his PhD from the University of TennesseeKnoxville He served as a Project Scientist at Carnegie Mellon University and is currently working at GE as a Senior Cyber Physical Systems Architect Uland Wong received a B.S and M.S in Electrical and Computer Engineering and an M.S and PhD in Robotics all from Carnegie Mellon University He currently works at Carnegie Mellon as a Project Scientist His research lies at the intersection of physics-based vision and 002eld robotics Tiago Pimentel Tiago Pimentel is pursuing a B.E in Mechatronics at Universidade de Braslia Brazil As a summer scholar at Carnegie Mellon Universitys Robotics Institute he researched on multi-robots exploration His research interests lie in decision making and mobile robots Sarah Tang is currently a senior pursuing a B.S degree in Mechanical and Aerospace Engineering at Princeton University As a summer scholar at Carnegie Mellon University's Robotics Institute she researched multi-robot coordination Her research interests are in control and coordination for robot teams 12 


Shreyansh Daftry is pursuing a B.E in Electronics and Communication from Manipal Institute of Technology India As a summer scholar at Robotics Institute Carnegie Mellon University he researched on sensor fusion and 3D modeling of sub-surface planetary caves His research interests lie at the intersection of Field Robotics and Computer Vision Steven Huber received a B.S in Mechanical Engineering and an M.S in Robotics from Carnegie Mellon University He is curently Director of Structures and Mechanisms and Director of Business Development at Astrobotic Technology where he leads several NASA contracts William 223Red\224 L Whittaker received his B.S from Princeton University and his M.S and PhD from Carnegie Mellon University He is a University Professor and Director of the Field Robotics Center at Carnegie Mellon Red is a member of the National Academy of Engineering and a Fellow of the American Association for Arti\002cial Intelligence 13 


