corresponding author 978-1-4673-5311-3/13/$31.00 2512013 IEEE of units to avoid attacks from enemy's force 2 In the fog-of-war conditions the vision allows the player to see only the limited area around the scouting unit Because other areas are invisible to the player it has high uncertainty to infer the current states of place visited or non-visited In case that the prediction of strategy is successful there is risk to make decision on the change of build orders For expert players they have common sense on the choice of build orders when they recognize the opponent's strategy with uncertainty Usually the knowledge is not formalized to be used in the AI bots The decision should be related to the accuracy of the prediction and the winning ratio of specific build orders Although there are some works on the design of the scouting unit control mechanism it is still under developed to be used in the competition The scouting unit should survive in the enemy's area for long time and navigate the area continuously to update information In addition they need to be defensive to the attack of enemy For human players the controlling of scouting unit is one of the key factors to win the game The design of the strategy recognizer and the change of build order is not a trivial problem It is necessary to automate the design process with the help of huge amount of data from the web The replays on the web are important resource to learn the recognizer and the build order change For example Weber INTRODUCTION In StarCraft each player comes with a strategy usually represented as a build order given to the game map and opponents When the game starts each player follows the prepared build orders At the same time they plan to send a scouting unit to the opponent's area Although the operation of the scouting is optional it is nearly mandatory in human games If the unit arrived in opponent's area successfully it can give limited vision around him to the player There are a lot of difficulties to recognize opponent's strategy 1 The amount of information from the scouting unit is proportional to the survival time and active movement in the enemy's territory However it requires a careful control This work was supported by the National Research Foundation of Korea NRF grant funded by the Korea government MSIP 2013-016589 2010-0018950 I  Replay-based Strategy Prediction and Build Order Adaptation for StarCraft AI Bots Ho-Chul Cho Dept of Computer Science and Engineering Sejong University Seoul South Korea chc2212@naver.com Kyung-Joong Kim Dept of Computer Science and Engineering Sejong University Seoul South Korea kimkj@sejong.ac.kr Sung-Bae Cho Dept of Computer Science Yonsei University Seoul South Korea sbcho@cs.yonsei.ac.kr Keywords-Strategy Prediction StarCraft Build Order Adaptation Decision Tree Feature Expansion et ale Abstract-StarCraft is a real-time strategy RTS game and the choice of strategy has big impact on the final results of the game For human players the most important thing in the game is to select the strategy in the early stage of the game Also it is important to recognize the opponent's strategy as quickly as possible Because of the fog-of-war in the game the player should send a scouting unit to opponent's hidden territory and the player predicts the types of strategy from the partially observed information Usually expert players are familiar with the relationships between two build orders and they can change the current build order if his choice is not strong to the opponent's strategy However players in AI competitions show quite different behaviors compared to the human leagues For example they usually have a pre-selected build order and rarely change their order during the game In fact the computer players have little interest in recognizing opponent's strategy and scouting units are used in a limited manner The reason is that the implementation of scouting behavior and the change of build order from the scouting vision is not a trivial problem In this paper we propose to use replays to predict the strategy of players and make decision on the change of build orders Experimental results on the public replay files show that the proposed method predicts opponent's strategy accurately and increases the chance of winning in the game run machine learning algorithms on the data extracted from replays of high-level players Although the results are promising their extractor ignores the fog-of-war and the data file contains all of the opponent's information usually not visible to the player In this work we propose to use the replays to design strategy predictor and change build orders In the strategy prediction we found that the best learning algorithms for the prediction is different on the stage of the game Based on the observation we combine machine learning algorithms with feature-expanded decision trees usually perform well in the later parts of the game From the replays it is possible to get statistical data on the relationships among build orders If build order A is effective on the build order B the winning ratio from the replays could be saved to make decisions Finally we extract the information from the replays 


   considering the \223fog-of-war.\224 It allows the extracted information should be limited to the visible to players. The realistic settings could give practical insight on the use of replays for the design of AI in the competition II  B ACKGROUNDS  A  StarCraft Strategy StarCraft is a popular real-time strategy game where players collect resources \(minerals and gas\, construct buildings and produce units to attack other players. The goal of the game is to eliminate all the buildings of opponents. However, when the player gives up the game, it stops although there are buildings remaining for the player. There are three races Protoss, Terran, and Zerg. Each race has different units buildings, and upgrade options For each race, there are a lot of different ways to determine building orders \(a sequence of building construction\ and unit production schedule. Because players have limited resource and time for the construction and production, it is desirable to select one strategy and optimize their actions to the choice. In fact, there is no golden strategy that beats all other strategies Each strategy has strong and weak points to other strategies and experienced players have knowledge on the relationships among them It is possible to prepare strong build orders but its value is highly dependent on the opponent\222s strategy in the game. It is important to collect information on the enemy\222s territory and guess the strategy. If the prepared choice is risky in the context of opponent\222s choice, the player should change the current build order. The decision making on the build order is not easy because the information on the opponent is imperfect Each player has limited vision around alliance units and the scouting unit is not guaranteed to survive for long time  B  StarCraft AI Competition StarCraft AI competition has been held as special events in game AI conferences \(IEEE CIG and AIIDE\ the competition, each participant submits an AI program and each program plays multiple games against other entries Because each entry has different styles of playing, it is difficult to get general goodness over the diversity of strategy Unlike human leagues, the bots usually not change their build orders and pay small attention on the scouting In human games, players usually change their strategy in the next game with the same opponent. However, bots usually have no mechanism to change their build order when they lose game to the opponent. If the build order programmed is not working to the opponent, there chance to lose all the games with the player. It is not yet common to prepare multiple build orders and adaptively change \(not randomly its choice during the game. It requires \223strategy prediction,\224 223scouting\224 and \223build order adaptation\224 mechanisms From the list of entries of the competitions, we investigate sixteen bots from their source code and replays to check the existence of scouting. Table 1 summarizes the entries show the scouting behavior \(31% of the Bots\owever, their main function is not observation but disturbance to the construction and production of opponents  Table 1. Scouting in StarCraft AI Competitions AI Players Race Scouting Behavior Nova Terran Disturbance Skynet Protoss Disturbance UalbertaBot Protoss Disturbance ItalyUndermind Zerg Disturbance SPAR Protoss Observation  We have developed Xelnaga for the StarCraft AI competition since 2011. Like other entries in the early days our submission has only one \223build order\224 specialized in the use of \223Dark Templar.\224 As expected, the strategy is successful to beat players but fail to beat all entries. In the version, we have no mechanism to scout the opponent\222s region. The focus is to follow the predefined build order until we have enough attack units. This is a kind of all-or-nothing strategy. It is weak to the very early attack or \223observer\224 production strategy In 2012, we add a function to scout the opponent\222s are using probe \(a resource collecting unit in PROTOSS\m the observation, we count the assimilator and the gateway in the enemy\222s territory. If the number of gateway \(attack unit production building\ is more than three and no assimilator gas extractor\we recognize it as \223very fast attack\224. If the number of gateway is two, the strategy is \223fast attack\224 Although we use very simple rules, they\222re helpful to recognize the early attack and change our strategy. However it is a still big problem to recognize a variety of strategies and handle them properly by changing our build orders. However it is a still big problem to recognize a variety of strategies and handle them properly by changing our build orders  C  StarCraft Replay Mining Game mining is an interdisciplinary research to extract useful knowledge from game-related data sources with data mining techniques [3   T he kno w l e d ge c a n b e use d t o b ui l d  better games and artificial intelligence for the games [4    There are several sources of information originated from games: transcripts, logs, text chats, social networks, and so on It can be used to mine the behavior of gamers to improve the design of the games      Since gamers have played the StarCraft for more than ten years, their replays have been archived in game-related portals. AI researchers analyze the replays to build a 223strategy\224 prediction model using CBR [9 4 8  k NN, NN g e  2 a n d B a y e si a n ne t w o r k 1 0   A l so  i t he l p s t o fi nd t h e go a l  of players d rel a t i o n s h i ps a m ong bu i l dorders s t r on g or weak  Because the previous works are dependent on some replay programs without \223fog-of-war\224 options, they pose unrealistic assumption that players have full vision to the opponent Recently Park et al tried to predict that opponent\222s strategy with fog-of-w In th e ex perim e n t s  th e y  u s e th e i r ag en t s  


   bots\o records realistic \(with fog-of-war\ervation during the game. Although it is successful to collect realistic logs but it should play the games against other agents to get the data. So, the approach is not useful to analyze the replays In our 2013 version, we develop a technique to collect realistic logs from replays with an \223observer\224 role agent. The software simulates each game from replay in a fastest mode and the observer records all the relevant game events considering the \223fog-of-war.\224 Hostetler et al infer the strategy in fog-of-w  Th eir f o cus is to in f e r th e cu rren t  opponent\222s unobserved information from observed data III  P ROPOSED M ETHODS  In this paper, we propose a framework to exploit the replays to predict strategy of opponent and making decision on the change of build orders. Fig. 1 shows the overview of the proposed framework    Fig. 1. Overview of the proposed method \(FOW = Fog of War The replays are available from famous internet game portals However, there is no information on the strategy used in the replay. The strategy \223labeling\224 can be done by human experts The labeled replays can be used as a training data for the supervised learning in the next step. It is necessary to automate the \223labeling\224 by modeling the human experts. The replays record all the gaming events \(mouse click, the production of units, the construction of buildings and upgrades\ a binary format The Extractor converts the raw replay files into human readable text files. Because the Blizzard, the creator of the StarCraft, does not support the conversion, the extraction is dependent on some software personally developed by experts They\222re Lord Martin Replay Browser and BWChart. Because the extraction software is built without support from the game creator, it has several limitations. For example, it has limited support on the multiplayer games and no option to reflect the 223fog-of-war\224 in the games  The next step is to build a feature vector from the raw text files. Because the replays store all the events necessary to recover the games again, it has large amount of useless information to predict the \223strategy.\224  In this step, expert knowledge is required to the choice of features. Although it records all the information on the units, buildings and user commands but most of them are not useful. Simply, it is possible to set filters to delete useless information. Because the raw data is too coarse, additional preprocessing techniques \(averaging, counting and so on\ be applied In previous works machine learning algorithms are successful to predict the strategy of opponents in the early stage of the games [1   Ho w e v e r, th e y 222 r e n o t in terp retab l e to human experts who design the build orders of the bots Also, it is not easy to maintain high accuracy throughout the games \(early, middle and end stages\As a solution, we propose to use a decision tree to predict the strategy. Because the model is interpretable to human experts, it is straightforward to convert them into a build order. To enhance the performance of decision tree, we expand a feature set for the model by incorporating new features based on time comparison. Because single machine learning algorithm fails to cover all the stage of the games, we propose to assign different machine learning models for each stage Based on the prediction, the player should make decision on the change of the build order. There are big uncertainties in the decision. In this architecture, we automatically get the statistics on the winning ratio of strategy against others. For example, it stores the winning ratio if strategy A plays against strategy B The final decision is based on the prediction accuracy and the winning ratio for the predicted strategy and the player\222s current strategy  A  Replay Preprocessing Although replays are stored in a binary format, it is possible to convert them to game logs using Lord Martin Replay Browser 2 or BWAPI 3 They extract types of buildings, units upgrade and their making time from replays. The extracted raw data is encoded as a feature vector, containing temporal features. If units or buildings are produced or constructed multiple times during the game, each feature describes the time when they\222re made first. For example, the PROTOSS player constructs multiple Gateways \(buildings for the attack unit production\ during the game. But in the feature vector the feature \223Gateway\224 stores only the time that the first Gateway is constructed  P x P x t xf P by  produced \(yet\not   was0 by  produced first  is  when time    where x is a unit type, build type or unit upgrade. A subset of an example feature vector for a Terran player is shown in Table 2. In the game, second gas was not yet produced by the player   Table 2. A subset of an example feature vector \(from a Terran player\222s feature vector for a Protoss vs. Terran match Attribute Game Time Pylon 1:20  2 http://lmrb.net 3 http://code.google.com/p/bwapi 


   Gateway 2:05 Gas 2:40 Expansion 11:00 Second Expansion 15:11 Third Expansion 18:45 Fourth Expansion 0:00 Second Gas 0:00  B  Strategy Prediction In the strategy prediction, we propose to use feature expanded decision tree. The only difference with the standard decision tree is that it incorporates a lot of new features into the original vector. In StarCraft, the order of game events action A prior to action B is one of important factors to identify the strategy. Fig. 2 shows an example of feature-expanded decision tree for the StarCraft a\ Standard decision tree    b\ Feature-expanded decision tree  Fig. 2  An example of standard and feature-expanded decision tree \(C, S and F stand for \223Citadel,\224 \223Stargate,\224 and \223First Expansion,\224 respectively  The number of features in the vector is N There are 1\(5.0 003 004 327 212+\327   1  Approach Ensemble Approach Ensemble Accuracy Accuracy  IV  E XPERIMENTAL R ESULTS  A  Experimental Setup In this paper, we collect StarCraft replays from YGOSU.com. The number of replays is 570 and all the games are PROTOSS vs. PROTOSS. Because we can extract text logs in the perspective of each player of the game, the number of samples is 1140. Also, we repeat the extraction two times by controlling the \223fog-of-war\224 options. As a result, we have two sets of data samples \(\223with fog-of-war\224 and \223without fog-of-war\224\he number of features in the vector is 56 212\327\327 NN comparisons among the features \(only, \221>\222 operation is considered\ The new feature has one of \223true\224 and \223false\224 value. Because the number of new features is large, feature selection is adopted. The percentage of \223true\224 value for each strategy \(class\ calculated. For example x1>x2 is true for all the replays labeled as \223Fast DT\224 strategy The comparison is worth to be considered. If a feature shows 100% for at least one strategy \(class\, it is selected   a\ Feature expansion  b\ Feature selection  Fig. 3. Feature expansion and the selection for the decision tree  Also, we propose to use an ensemble approach where different machine learning models take charge of different stage of games. The separation of game stage is done by experts. Usually, the game can be divided into early, middle and end stages. In case that the expert knowledge is not available, it is possible to assign machine learning models that perform the best on the training samples at the given time For example, we can use \223Random Committee\224 models from the game start to 9 minutes and \223Feature-Expanded DT\224 after the time  C  Build Order Change From the replays, it is possible to get statistics on the relatinoships among strategies. In sum, the winning ratio when strategy A plays against strategy B From the training samples, it is possible to get prediction accuracy \(0~1\ the trained models is the maximum winning ratio if the player changes the current build order into new one \(from the statistics is 0.5 


   Also, we use the data 4 from Weber et al 2 B ecau s e th e y  already preprocessed the raw replay files, it is easy to use for the experiments. Also, they have data for games among all races \(PvP, PvT, PvZ, TvT, TvZ, and ZvZ\. For example, PvP represents PROTOSS versus PROTOSS. The number of samples for each type of games is ranging from 542 to 1150 In total, they have 5493 samples. However, they do not consider the \223fog-of-war\224 in th e log extraction. Also, the raw replay files are not available for the data. It makes difficult to know the player who wins the game for the replay. The number of features for PROTOSS, TERRAN, and ZERG is 56, 51, and 48, respectively  P = PROTOSS, T TERRAN, Z = ZERG Types FOW Raw Replays Samples YGOSU.com P vs. P O O 1140 P vs. P  O 1140 Weber et al  P vs. P   542 P vs. T   1139 P vs. Z   1024 T vs. T   628 T vs. Z   1150 Z vs. Z   1010  Table 3 summarizes the details of data used. The number of strategies for each race is seven. For example, the PROTOSS has \223Fast Dark Templar,\224 \223Fast Observer,\224 \223Fast Expansion,\224 223Fast Legs,\224 \223Reaver Drop,\224 \223Carrier,\224 and \223Unknown.\224 Ten-fold cross validation is used for all experiments. The machine learning algorithms are implemented with the WEKA API  T h e m a c h i n e learn i ng alg o rit h m s are evaluated at different time steps throughout the game. The overall performance is defined as the average accuracy during the game N is the number of sampling points during the game in this paper N 31, Game Time = 15 min   GameTime t Classifier t Accuracy N Acc Avg 0  1 _  B  Feature-Expanded Decision Tree  Table 4. Comparison of standard DT and the feature-expanded DT in terms of accuracy and the size of model \(the number of leaves and the size of the tree\ \(W =Weber dataset, Y=YGOSU.com  Race Source Standard DT Feature-Expanded DT  Accuracy  Size Accuracy  Size P \(Y 89.49 157, 313 99.73 15, 29 P \(W 89.68 125, 249 99.77 14, 27 T \(W 91.05 122, 243 99.96 11, 21 Z \(W 95.76 72 , 143 100.0 10, 19 Average 91.50 119, 237 99.87 13, 24  4 http://eis.ucsc.edu/StarCraft_Data_Mining The purpose of the \223feature-expanded\224 decision tree FBDT\ is to build machine learning models interpretable to humans and easily converted into programming codes \(as a build order categorization\. The algorithm is applied to the replays from each race. For comparison, the standard DT without feature expansion\ is used. It shows that the FBDT is accurate compared to the standard DT and the size of the model is relatively small. Also, the result from our YGOSU.com data is similar to the Weber\222s dataset. Fig. 4 shows an example of conversion from the FBDT into a programming code  IF FirstExpansion <= Stargate  IF RoboBay <= FirstExpansion  IF Citadel <= RoboBay  IF Legs <= Archives  IF FourthExpansion <= Legs 223Unknown\224   ELSE  223Fast Legs\224    ELSE  223Fast DT\224    ELSE   IF RoboSupport <= Observory  IF SecondExpansion <= RoboSupport 223Unknown\224   ELSE  223Reaver Drop\224    ELSE  223FastObs\224     ELSE   IF FirstExpansion <= Citadel 223Fast Expand\224   ELSE   IF Legs <= Archives 223Fast Legs\224   ELSE  223Fast DT\224     ELSE   IF Citadel <= Stargate  IF Legs <= Archives 223Fast Legs\224   ELSE  223Fast DT\224    ELSE   IF RoboBay <= Stargate  IF RoboSupport <= FirstExpansion 223Reaver Drop\224   ELSE 223Fast Obs\224   ELSE  223 C arrier\224    Fig. 4. Conversion of feature-expanded decision tree into a programming code  C  223Strategy Prediction\224 during the Game  Table 5 summarizes the prediction accuracy of machine learning algorithms on PROTOSS vs. PROTOSS games. It shows that the results from Weber dataset are similar to the one from YGOSU.com. As expected, the introduction of 223fog-of-war\224 decreases the prediction accuracy. It is interesting that the FBDT outperforms other classifiers in the later parts of the games. However, it is very poor in the early 


   stage of the games. Other machine learning algorithms perform well in the early stage of the game but not the best in the later part of the game. From this observation, it is meaningful to use more than one classifier during the game For example, Rotation Forest is used in the early stage of the game but the FBDT in the later part of the game \(Fig. 5  Table 5. The comparison of \223strategy prediction\224 accuracy \(bold means the best accuracy  a\ P \(Weber Data   5 min 10 min 15 min Avg_Acc NNGE 49.6 80.6 76.0 60.3 KNN 47.4 80.4 74.5 60.1 J48 [18  43 9 81 9 85 4  62 1  FBDT 26.0 89.7 99.6 59.7 Bagging [17  50 0 85 2 86 9  63 1  Random Committee 50.2 85.1 85.0 64.0 Random Forest  49.8 83.2 83.4 63.7 Rotation Forest  50.4 85.8 89.1 65.3  b\ P \(YGOSU.com   5 min 10 min 15 min Avg_Acc NNGE 41.1 81.0 77.5 59.6 KNN 40.4 78.3 67.6 56.0 J48 38.6 85.5 85.0 62.8 FBDT 9.4 89.1 98.5 51.0 Bagging 47.9 87.2 89.4 65.7 Random Committee 44.6 84.7 86.0 63.7 Random Forest 45.4 84.7 86.3 63.5 Rotation Forest 47.5 87.4 90.6 66.0  with fog-of-war   5 min 10 min 15 min Avg_Acc NNGE 38.0 61.3 68.0 46.0 KNN 35.3 57.0 58.8 43.0 J48 37.2 61.5 72.5 50.2 FBDT 11.9 57.4 83.2 37.1 Bagging 40.9 63.9 75.3 53.0 Random Committee 39.5 62.5 70.1 51.4 Random Forest 40.2 61.6 70.7 51.3 Rotation Forest 41.6 64.8 76.0 53.5     a\ P \(YGOSU.com   with fog-of-war  Fig. 5. The introduction of \223fog-of-war\224 and the prediction accuracy during the game  D  Build Order Change We analyze the 570 replays from YGOSU.com. It shows that the number of replays categorized into \223Fast Legs\224 and 223Carrier\224 is too small compared to other strategies. In the calculation of the winning ratio, we only consider the five strategies except the low-percentage strategies. Table 6 summarizes the winning ratio from the replays. It means that the Fast DT strategy wins 59% against the Fast Observer strategy  Table 6. Winning ratio from the replay files \(YGOSU.com  a\ The number replays for each strategy in YGOSU.com data Fast Legs Fast DT Fast Obs Reaver Drop Carrier Fast Expand Unknown 15 162 424 200 0 265 74  b\inning ratio of each strategy \(0~1 Player Opponent Fast DT Fast Obs Reaver Drop Fast Expand Unknow n FastDT  0.50 0.59 0.67 0.64 0.00 FastObs 0.41 0.50 0.52 0.49 0.29 Reaver Drop 0.33 0.48 0.50 0.52 0.71 Fast Expand 0.36 0.51 0.48 0.50 0.31 Unknown 1.00 0.71 0.29 0.69 0.50  


   Fig. 6 shows the change of the E[Wi d u r i ng t h e  ga m e  T h e  value is calculated using the prediction accuracy of the combined models \(Random Forest and FBDT\ and the winning ratio in Table 6. In the early stage of the game, the prediction accuracy is not high and it is not beneficial to change the build order. In 6~7 minutes of the game, the prediction accuracy is relatively high and the E[win beco m e s  the maximum. After the time, the prediction accuracy increases but the possibility of the build order change goes down \223\(almost buildings are constructed\he player can make a decision on the change of build orders based on the E[win du ring t h e g a m e    Fig. 6. Expected win \(0~1\ the prediction accuracy \(Rotation Forest FBDT\nd the winning ratio of each strategy \(P vs. P, YGOSU.com data V  C ONCLUSIONS AND F UTURE W ORKS  In this paper, we propose a framework to use the replays on the automatic design of strategy prediction and the build order adaptation. For the replay mining, we develop a new customized tool for the extraction of information from the replays considering the \223Fog-of-War.\224 For the strategy prediction, we propose to use the \223feature expansion\224 for the decision tree learning. It returns human-interpretable accurate models to predict the strategy of the game. Because the model is not good in the early stage, it is desirable to hybrid it with other machine learning algorithms \(for example, rotation forest\or the build order change, we propose an equation to get the E[Win  v a l u es  f r o m  t h e prediction acc u r ac y a n d t h e  winning ratio from the replays Experimental results show that the proposed FBDT is promising to build a small-size human-interpretable tree models. However, its accuracy is not good in the early stage of the game. The rotation forest is successful to predict the strategy in the early stage of the game. The combination of the two models outperforms other candidates in the strategy prediction problems. The introduction of the \223Fog-of-War\224 in the game reduces the prediction accuracy as expected. But there is a learning algorithm robust to the uncertainty. The build order change experiments show that the 6~7 minutes are the best timing to change the build order Although we can build strategy prediction models with the 223Fog-of-War\224 from the human replay files, there is difference between human and bots games. In the human replays, the players control the \223scouting unit\224 effectively and acquire useful information to predict the strategy. However, in the bots, it is still under development to implement the \223scouting unit\224 management. The success of the strategy prediction is highly dependent on the use of the \223scouting unit\224 in the presence of the \223Fog-of-War.\224 R EFERENCES  1  H.-S. Park, H.-C. Cho, K.-Y. Lee, and K.-J. Kim, "Prediction of early stage opponents strategy for StarCraft AI using scouting and machine learning In Proceedings of the Workshop at SIGGRAPH Asia \(WASA 2012 pp. 7-12, 2012 2  B. Weber, and M. Mateas, \223A data mining approach to strategy prediction,\224 IEEE Symposium on Computational Intelligence and Games pp.140-147, 2009 3  A. Tveit, \223Game usage mining: Information gathering for knowledge discovery in massive multiplayer games,\224 Proceedings of the International Conference on Internet Computing pp. 636-642, 2002 4  D. Kennerly, \223Better game design through data mining,\224 Gamasutra  2003 5  K.S.Y. Chiu, and K.C.C. Chan, \223Game engine design using data mining,\224 Proceedings of the 26 th IASTED International Conference on Artificial Intelligence and Applications pp. 352-357, 2008 6  C. Thurau, and C. Bauckhage, \223Analyzing the evolution of social groups in World of Warcraft,\224 IEEE Conference on Computational Intelligence and Games pp. 170-177, 2010 7  T. Mahlmann, A. Drachen, J. Togelius, A. Canossa, and G. N Yanakakis, \223Predicting player behavior in Tomb Raider: Underworld,\224 IEEE Conference on Computati onal Intelligence and Games pp 178-185, 2010 8  K.-J. Shim, and J. Srivastava, \223Behavioral profiles of character types in EverQuest II,\224 IEEE Conference on Computational Intelligence and Games pp. 186-194, 2010 9  J.-L. Hsieh, and C.-T. Sun, \223Building a player strategy model by analyzing replays of real-time strategy games,\224 IEEE International Joint Conference on Neural Networks pp. 3106-3111, 2008   G. Synnaeve and P. Bessiere, \223A Bayesian model for opening prediction in RTS games with application to StarCraft,\224 in Proceedings of 2011 IEEE CIG Seoul, South Korea, pp. 281-288, Sep. 2011   B. Weber, and S. Ontanon, \223Using automated replay annotation for case-based planning in games,\224 International Conference on Case-based Reasoning Workshop on CBR for Computer Games pp 15-24, 2010   J. K. Kim, K.-H. Yoon, T. Yoon, and J.-H. Lee, \223Cooperative learning by replay files in real-time strategy game,\224 Lecture Notes in Computer Science vol. 6240, pp. 47-51, 2010   J. Hostetler, E. W. Dereszynski, T. G. Dietterich, and A. Fern Inferring Strategies from Limited Reconnaissance in Real-time Strategy Games Proceedings of the Twenty-Eighth Conference on Uncertainty in Artificial Intelligence \(UAI2012 pp. 367-376, 2012   I. H. Witten, E. Frank and M. A. Hall Data Mining: Practical Machine Learning Tools and Techniques Morgan Kaufmann, 2011   J. J. Rodriguez, L. I. Kuncheva, and C. J. Alonso, \223Rotation forest: A new classifier ensemble method,\224 IEEE Transactions on Pattern Analysis and Machine Intelligence vol. 28, no. 10, pp. 1619-1630 2006   L. Breiman, \223Random forests,\224 Machine Learning vol. 45, no. 1, pp 5-32, 2001   L. Breiman, \223Bagging predictors,\224 Machine Learning vol. 24, no. 2, pp 123-140, 1996   R. Quinlan C4.5: Programs for Machine Learning Morgan Kaufmann 1993 


http  wethedata.org  2013  02  04  a-new-deal-forpersonal-information-assets  Accessed: 17-Feb2013   2 P  W a u g h an d A Stri ng e r   M y  N Z Open Data    Digital Government Adventure,” 2013. [Online   Available: http  pipka.org  2012  12  18  my-nz-opendata-and-digital-government-adventure  Accessed 17-Marc   2 W Mi chener  F i v e New P a r a di g m s f o r S c ience  and an Introduction to DataONE E ducause vol 47, no. 2, pp. 50–51, 2012 2 K  Ekholm and P   K a rh ula S l eep w a lkin g t o w a r d a control society: Ten Must-Know Trends www.ifla.org pp. 1-15, 2012 2 D ata P r o t ect i o n  D i rect i v e: Eur op ean  Union  2012. [Onli   A v ai l a bl e http  en.wikipedia.org  wiki  Directive_95  46  EC_o n_the_protection_of_personal_data. [Accessed: 1May       5 8 20 1 3 IEEE I n ter na t i o nal S ymp o sium o n Tech n o l o gy and S oc i et y IS TA S 


Copyright © 2009 Boeing. All rights reserved  Architecture Server-1 Server-2 DB2 SURVDB XML Shredder WebSphere Message Broker Ext.4 H Ext.3 G Ext.2 F Ext.1 E C WebSphere MQ TCP/IP Live ASDI Stream IBM Cognos Server-3 IBM SPSS Modeler SPSS Collaboration Deployment Services 


Copyright © 2009 Boeing. All rights reserved  Database Modeling Schemas for correlated ASDI messages translated into equivalent relational schemas  Database tables generated based on classes created from schema definitions  Nine main, eleven supporting tables  Each main table contains FLIGHT_KEY 


Copyright © 2009 Boeing. All rights reserved  Database Modeling 


Copyright © 2009 Boeing. All rights reserved  Correlation Process To archive received ASDI data  Track messages must be correlated with flight plan messages FLIGHT_KEY assigned Uncorrelated data tagged Approx 30 minutes to correlate one day of data 


Copyright © 2009 Boeing. All rights reserved  Historical Data Processing To load correlated data  Uncompress, unmarshall  Create a list of files containing the correlated data  Write data to warehouse 


Copyright © 2009 Boeing. All rights reserved  Live Data Processing Processed using IBM MQ IBM Message Broker and a technique called XML Shredding Message Broker Compute Nodes  Uncompress Node  Extract correlated messages  Shred Node adds to DB Stored Procedure “shreds XML docs and adds to tables 


Copyright © 2009 Boeing. All rights reserved  Issues and Observations Initial load of one day of data ~ 7 hours Optimizations  Write data in batches  Use a mutable data structure to create data strings  Deploy a higher performance machine  Use load instead of insert  Use DB2 Range-Partitioned tables  Database tunings Time reduced from 7 hours to approx 30 minutes 


Copyright © 2009 Boeing. All rights reserved  Optimizations Use a mutable data structure to create data strings  Original application created the SQL statement by appending elements to a Java String  It was taking five hours \(of the seven hours Strings  Instead Java StringBuilder used  Java Strings immutable  Time savings of 71.4 


Copyright © 2009 Boeing. All rights reserved  Optimizations Deployed on a higher-performance machine  Application ported from IBM Blade Center HS21 \(4GB of RAM and 64-bit dual-core Xeon 5130 processor to Dell M4500 computer \(4GB of RAM and 64-bit of quad-core Intel Core i7 processor  Reduced the time to thirty minutes Bulk loading instead of insert  Application was modified to write CSV files for each table  Entire day worth of data bulk loaded  Reduced the time to fifteen minutes 


Copyright © 2009 Boeing. All rights reserved  Optimizations Range-Partitioned tables \(RPT  To limit the size of tables, the original code created multiple tables per table type  This puts burden on the application to query multiple tables when a range crosses several tables  With RPT, user is not required to make multiple queries when a range crosses a table boundary  Increased the time to thirty minutes  Additional fifteen minute cost per day of partitioning enabled time savings during queries 


Copyright © 2009 Boeing. All rights reserved  Optimizations Database tunings  Range periods changed from a week to a month  Automatic table space resizing changed from 32MB to 512KB  Buffer pool size decreased  Decreased the time to twenty minutes Overall, total time savings of 95.2 


Copyright © 2009 Boeing. All rights reserved  20 IBM Confidential Analytics Landscape Degree of Complexity Competitive Advantage Standard Reporting Ad hoc reporting Query/drill down Alerts Simulation Forecasting Predictive modeling Optimization What exactly is the problem What will happen next if What if these trends continue What could happen What actions are needed How many, how often, where What happened Stochastic Optimization Based on: Competing on Analytics, Davenport and Harris, 2007 Descriptive Prescriptive Predictive How can we achieve the best outcome How can we achieve the best outcome including the effects of variability Used with permission of IBM 


Copyright © 2009 Boeing. All rights reserved Initial Analysis Activities Flights departing or arriving on a date Flights departing or arriving within a date and time range Flights between city pair A,B Flights between a list of city pairs Flights passing through a volume on a date. \(sector, center, etc boundary Flights passing through a volume within a date and time range Flights passing through an airspace volume in n-minute intervals All x-type aircraft departing or arriving on a date Flights departing or arriving on a date between city pair A,B Flights departing or arriving on a date between a list of city pairs Flights passing through a named fix, airway, center, or sector Filed Flight plans for any of the above Actual departure, arrival times and actual track reports for any of the above 


Copyright © 2009 Boeing. All rights reserved  Initial SPSS Applications Show all tracks by call sign 


Copyright © 2009 Boeing. All rights reserved  Predictive / Prescriptive Analytics Use-Case For a given Airspace Volume of Interest \(AVOI compute distinct traffic volume at some point in the future  Aim to alert on congestion due to flow control areas or weather if certain thresholds are exceeded  Prescribe solution \(if certain thresholds are exceeded Propose alternate flight paths  Use pre-built predictive model  SPSS Modeler performs data processing Counts relevant records in the database \(pattern discovery Computes traffic volume using statistical models on descriptive pattern Returns prediction with likelihood 


Copyright © 2009 Boeing. All rights reserved  Predictive / Prescriptive Analytics Use-Case Advanced Arrival Procedures with Active Abatement Potentials   9/23/10  24 Pulls in the TRACKINFO table of MAIN using SQL Limits the data to database entries which fall inside the AVOI Combines the SOURCE_DATE and SOURCE_TIME to a timestamp that can be understood by modeler Computes which time interval the database entry falls in. The time interval is 15 minutes Defines the target and input fields needed for creating the model Handles the creation of the model Produces a graph based off of the model results Final prediction 


Copyright © 2009 Boeing. All rights reserved  Initial Cognos BI Applications IBM Cognos Report Studio  Web application for creating reports  Can be tailored by date range, aircraft id, departure/arrival airport etc  Reports are available with links to visuals IBM Framework Manager  Used to create the data package  Meta-data modeling tool  Users can define data sources, and relationships among them Models can be exported to a package for use with Report Studio 


Copyright © 2009 Boeing. All rights reserved  Flights Departing Las Vegas on Jan 1, 2012 1 of 3 Report shows the departure date, departure and arrival locations and hyperlinks to Google Map images DeparturePosition and ArrivalPosition are calculated data items formatted for use with Google Maps Map hyperlinks are also calculated based on the type of fix 


Copyright © 2009 Boeing. All rights reserved  Flights Departing Las Vegas on Jan 1, 2012 2 of 3 DeparturePosition, Departure Map, ArrivalPosition and Arrival Map are calculated data items \(see departure items below DepartureLatitude DepartureLongitude DeparturePosition Departure Map 


Copyright © 2009 Boeing. All rights reserved  Flights Departing Las Vegas on Jan 1, 2012 3 of 3 


Copyright © 2009 Boeing. All rights reserved  Conclusion and Next Steps Current archive is 50 billion records and growing  Approximately 34 million elements per day  1GB/day Sheer volume of raw surveillance data makes analytics process very difficult The raw data runs through a series of processes before it can be used for analytics Next Steps  Continue application of predictive and prescriptive analytics  Big data visualization 


Copyright © 2009 Boeing. All rights reserved  Questions and Comments Paul Comitz Boeing Research & Technology Chantilly, VA, 20151 office Paul.Comitz@boeing.com 


Copyright © 2009 Boeing. All rights reserved Advanced Arrival Procedures with Active Abatement Potentials   9/23/10  31 


Copyright © 2009 Boeing. All rights reserved Advanced Arrival Procedures with Active Abatement Potentials   9/23/10  32 Backup Slides 


Copyright © 2009 Boeing. All rights reserved  Initial Approach Initial Investigations  Apache Solr/Lucene  Data Warehouse Evaluate Hadoop in the future 


Copyright © 2009 Boeing. All rights reserved  Using SOLR Uncompress Track Information Messages To use with Solr  Transforming track messages from their  original schema to Solr required building a “key, value” list using an XSTL  Queries made against this list of “key, value” pairs Transformation Process  One day of data ~ 4.5 hours Once transformation complete search/query performance very good Geo spatial queries using  unique query language 


Copyright © 2009 Boeing. All rights reserved  Representation Aviation data is frequently represented in more than one form 


