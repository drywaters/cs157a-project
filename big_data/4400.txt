2009 IEEE International Advance Computing Conference IACC 2009 Patiala India 6-7 March 2009 Parallel Privacy Preserving Association rule mining on pc Clusters B.Janaki Ramaiah Dr A Rama Mohan Reddy M.Kamala Kumari Associate.Profissor Dept of CSE Professor Dept of CSE Associate.Profissor Dept of CSE DVR  Dr HS MIC College of Tech Sri Venkateswara University Adikavi Nannaya University Vijayawada A.P India Tirupati,A.P India Rajahmundry A.P India Abstract Association rules discovered by association includes a large number of transactions Different from rule mining may contain some sensitive rules which data modification data reconstruction 7 is a new may cause potential 
threats towards privacy and promising method in dealing with the association rule security In this paper we address the problem of hiding problem This approach is based on knowledge privacy preserving association rule mining by sanitization Specifically it hides the rules by sanitizing proposing a Knowledge Sanitization to prevent the itemset lattice called a knowledge base rather than disclosure of sensitive rules We also present parallel sanitizing original dataset Then a reconstruction approach to generate a non-sensitive and sensitive rule procedure reconstructs a new released dataset from the mining Our proposed solution key issue is to 
provide a sanitized itemset lattice In this way data reconstruction high degree of parallelism for privacy to the data gives user a knowledge level window to control the owner availability of rules handily and control the hiding 1 Introduction effects directly Our approach is based on knowledge sanitization Association rule mining extracts novel hidden and useful patterns from huge repositories of data 2 Formulate the problem These patterns are useful for an effective analysis and decision making in corporation marketing business Given a database D to be released with medical analysis website linkages financial 
minimum support threshold and minimum confidence transactions health-care records and other applications threshold a set of rules R mined from D and a set of The sharing of association rules can bring a lot of sensitive rules Rh C R to be hided we need to advantages in industry research and business construct a new data set D such that the rules in Rh collaboration At the same time a huge repository of cannot be mined from D while the rules in R-Rh can data contains private data and sensitive rules that must still be mined as many as possible be 
protected before sharing On demand to various Two problems are addressed here one is the mismatched requirements of data sharing privacy protection of private data another is the protection of preserving and knowledge discovery privacy sensitive rules contained in the data The former settles preserving data mining has become a research hotspot how to get normal mining results when private data in data mining Simply the association rule-hiding cannot be accessed accurately the latter settles how to problem is to hide secret sensitive association rules protect sensitive rules contained in 
the data from being contained in data from being discovered while without discovered while non-sensitive rules can still be mined losing non-sensitive at the same time This problem normally motivated different authors 5 6 7 who proposed a number of algorithms to this problem There have been 3 Proposed Framework two broad approaches Data modification approaches and data reconstruction approaches Data modification The framework is depicted in Figure 1 The 4 methods hide sensitive association rules by directly whole approach is divided into three phases The first modifying original data According to different phase is to use Fast Frequent Set Mining 
FFSM modification means it can be further classified into the algorithm to generate all frequent itemsets with their two subcategories Data Distortion techniques and Data supports and support counts from original database D Blocking techniques Data Distortion[3 is implemented This gives the set of association rules R In the second by deleting or adding items to reduce the support or phase we perform sanitization algorithm over R and get confidence of the sensitive rules while data-blocking the sanitized frequent itemsets FFSM In the best case is implemented by replacing certain items with a from FFSM ensured from sanitization algorithm we question mark  to make the 
support and confidence get exactly the set of non-sensitive rules R-Rh with no of the sensitive rules uncertain As a traditional method normal rules lost and no ghost rules generated The data modification can operate simply However they third phase is to generate released database D from suffer from the weakness of providing a way of fineFFSM by using inverse frequent set mining algorithm tuning the generation of the released database which The fast frequent itemset mining algorithm and inverse makes that they cannot control the hiding effects frequent set mining algorithm are parallelized by using directly and clearly Data sanitization can produce a lot Linux cluster environment Of I/O operations especially when the original database 978-1T-42441888-6/08/f$25.OO Q 2008 IEEE 1538 


r T   a required to complete the calculations A cluster of _ FFSM _ machines was built to use as a parallel processing D Fig 1 Proposed Framework I_nernect NlsagIrg Protocol lntrco onneck Hardiare N5Cs Swlteha and Cble|s 4 Procedure Cluster Nodes Begin Fig 2 Layers in a typical Cluster Step 1 A cluster of n machines was built to use as a parallel processing platform 5.1 Fast Frequent set Mining algorithm Step 2 Use Fast Frequent set Mining algorithm to We introduce a new parallel algorithm PFPT generate itemset with supports over original Parallel Frequent Pattern Tree for parallel mining of dataset D D 4 FFSM 4 R frequent patterns based on FP-growth mining[2 that Step 3 Find all frequent itemsets from Database and uses only two full I/O scans of the database eliminating generate corresponding association rules R the need for generating the candidate items and Step 4 Identify sensitive frequent itemsets and select distributing the work fairly among processors We have the hiding strategy devised partitioning strategies at different stages of the Step 5 Perform sanitization algorithm mining process to achieve near optimal balancing Step 6 Next generate exactly the set of non-sensitive between processors The PFPT approach we proposed rules R-Rh from sanitization algorithm consists of two main stages Stage one is the Sanitization i R-Rh construction of the parallel frequent pattern trees one Step 7 Reconstructed database D based on inverse for each processor and stage two is the actual mining frequent set mining algorithm of these data structures much like the FP-growth R-Rh  FFSM o D algorithm End 2009 IEEE Inxternational Advanxce Computing Conference IACC 2009 1539 and Devekp preznt Tcls  Ile Prograrnm mi ng Lib ra ry D:-Original Data Base 5 Parallel data mining in Linux Clusters FFSM Fast Frequent Set Mining algorithm R Set of Association rules sensitive  Non sensitive Challenging problems in engineering and Rh Set of Sensitive Association rules information sciences typically require a lot computing FFSM':-Inverse Fast Frequent set Mining algorithm power and Linux clusters are one of the solutions R-Rh:-only non sensitive rules Linux clusters are less expensive and are scalable Data D Reconstructed Data Base mining applications require processing huge collections of data and are computationally intensive Hence these applications can be parallelized to reduce the time P_  R platform Applications can be parallelized to reduce the time required to complete the calculations Parallelism can affect the execution time of data mining applications Benefits of clusters are Lower cost Scalability Vendor independence Adaptability Reliability Availability and Serviceability and Faster Linux cluster nodes technology innovation Clusters are becoming increasingly popular as computational resources both in research and Knowledge Sanitization commercial organizations These organizations are favoring clusters over single large servers for a wide variety of problems Super computers being highly expensive and being less scalable The increasing popularity of the Linux operating system is adding fuel  FFSM  1 to this Linux provides a very cost effective and open D'v R-Rh environment to build a cluster The main motivation factor is usually faster computation very simple idea that n computers operating simultaneously can achieve the result n times faster Other motivation factors are fault tolerance larger amount of memory available etc Linux cluster nodes U __rAppiator Pou ll 


5.2 Knowledge Sanitization algorithm Each processor finds the local counts of each data item Data item A has 2 references item 3 has 1 Choosing hiding strategy We would decrease three references say for example The local counts of support of sensitive rule from current support so that it each processor on each data item are shown in Table 3 will not be mined from dataset with a minimal support threshold value Counters 2 Configuring support values We will find all the Item P P1 P2 subsets of sensitive rule Then subtract their support finding all supersets of sensitive rule and then modify A 2 the support After finding all subsets of superset B 3 3 2 excluding subsets of sensitive rule their supports are C 1 0 0 modified accordingly D 3 3 After completion of Knowledge sanitization use B 0 parallel frequent set mining algorithm to generate F 3 exactly the set of non-sensitive rules R-Rh G 2 3 1 5.2 Example H 0 1 1 K 0 0 1 Table 1 represents a transaction database D having  nine transactions with 11 different items Tid Items Bought Table 3 Local Counts 1 A,B,C,D,E 2 F,B,D,E,G These local counts of each data item are 3 B,D,A,E,G summed which gives global count of each processor A,B,F,G,D Item A has a total of 7 references overall which gives A,B,F,D,G,H the global count of it We find Global count of all data 6 A,B,F,G,D items similarly This is shown in Table 4 8 A,F,,A,DJ Proc  Item Global counter 9 A,B,F,I,J A 7 Table 1 Original transaction database D D In order to enumerate the frequent items E 3 efficiently we divide the datasets among the available P1 F 6 processors We consider three processor for example G 6 Each processor is given an approximately equal number H 2 of transactions to read and analyze In this original data K I base is horizontally partitioned into three parts and each P2 2 part is assigned to corresponding processors shown in 2 Table 2 So each processor is having three itemsets Table 4 Global count which performs the given tasks similarly and parallely on pc clusters Let us assume the Minimum Support threshold value is 6 Items which are below the threshold value Tid Items Bought Processor are removed and which are equal to or above the Number threshold value are retained This levies A B D F and t A.B C E G to retain in the frequent items 2 F,B,D,E,G PO Item Global counter 4 A,B,F,G,D A 7 5 B,F,D,G,H P1 B 8 6 A,B,F,G,D D 7 7 AXBFJ GJ Q,,,,U f_'_1 A TN IDi F 6 Table 2 Divide the datasets Table 5 Frequent Items Frequent Item sets FS 11540 2009 IEEE Internactionalz Advance Computing Conference IACC 2009 


From Table 5 to find all possible Frequent Now after the sanitization we have the Item sets FS frequent itemsets set FS from which we get the set of non sensitive association rules R-Rh shown in this Items Support Count Table 9 7_ B 8 Rules Confidence  Support  D 7 B D 87 77 F 6 B F 75 66 G 6 B G 75 66 A,B 6 D=>G 75 66 B,D 7 Table 9 Association Rules R-Rh B,F 6 B,G 6 Applying Inverse frequent set mining D,G 6 algorithm to find released database D from this database D we can not find sensitive rules shown in Table 6 Frequent Item sets FS this Table 10 From the frequent itemsets FS we get six TID Items association rules shown in this table 7 1 B,D,F,G 2 G,F,D,B Rules Confidence  Support 4 B,DG A=>B 75 66 5 F,D,B,G B=>D 87 77 6 F,D,B,G B F 75 66 7 G,B,D,F B G 75 66 Table 10 Released Database D LD=>G 75 66 5.4 Inverse frequent set mining algorithm Table 7 Association Rules R Use parallel Inverse frequent set mining algorithm Now let us suppose the first rule A=>B is a to reconstruct new database D from the sanitized sensitive rule that needs hiding So Applying frequent itemsets First we try to guess a FP-tree that Knowledge Sanitization algorithms to remove the satisfies the set of non-sensitive rules R-Rh The whole A=>B rule we find the Frequent Itemsets FS shown process of the proposed method is the reverse process in this table 8 of the FP-tree-based frequent itemsets mining If we apply mining process on D it generates the set of nonRules Support Count sensitive rules R-Rh B 7 Inverse frequent set D 7 Mining algorithm FFSM F 6 G 6 BID 7 B,F 6 


Han J Pei Y Yin and R Mao Mining frequent patterns without candidate generation A frequent-pattern tree approach Data Mining and Knowledge Discovery Datta S Wang Q and Sivakumar K 2003 613-616 5 J Vaidya and On the Privacy Preserving Properties of Random Data Perturbation Techniques In Proceedings of the 3rd IEEE International Conference on Data Mining ICDM'03 Melbourne Florida USA November 2003 pp 6 Experimental Results Experiments used 64 Linux cluster nodes of Intel Pentium dual core with 2.80GHz and 2 GB of RAM my institution laboratory environment to conduct the experiments The sizes of the input databases vary from 1 GB transactions to 50 GB Each of these transactions has at least 2 items preceded by a unique transactional ID The largest dataset is in the order of 512 bytes Frequent Set Mining Result 3000  2500 z 2000 w 1500 z 0 D 1000 U w x w 500 2 4 g 16 32 64 NO OF pages 146-157 2006 7 Yuhong Guo Reconstruction-Based Association Rule Hiding Pzroceedings of SIGMOD2007 Ph.D Workshop on Beijing China 154 2009 ICMEEE International Advalnce Computing Conference IACC 2009 A Evfimievski and R Srikant Information sharing across private databases In SIGMOD 2003 2 J 2003 3 99-106 4 Oliveira S.R.M and Zaiane O.R Protecting sensitive knowledge by data sanitization In Proc of the 3rd IEEE Int'l Conf on Data Mining ICDM'03 IEEE Computer Society USA 2002 6 Z.Wang B Liu,W.Wang H Zhou and B Shi An effective approach for hiding sensitive knowledge in data publishing In WAIM Innovative Database Research 2007\(IDAR2007 June 10 2007 Kargupta H PROCESSORS Fig 4 Execution time 7 Conclusion In this paper a Framework has been implemented for Fast and Scalable Privacy-Preserving Association Rule Mining We have introduced an efficient parallel implementation of an FP-Tree-based association nule mining Algorithm on Linux clusters to achieve fast scalability and preserve a high degree of accuracy in the mining results Sanitization algorithm provides a high degree of privacy to the user Our further research will focus on the optimal Knowledge Sanitization to improve degree of privacy 8 References 1 R Agrawal C Clifton Privacy preserving association rule mining in vertically partitioned data In SIGKDD 


composed by 5000 samples, in order to illustrate the algorithm clearly, we extract 20 samples from the datasets randomly and suppose that 20 samples are distributed 3 different local computing nodes T ABLE 1 DATA  IN NODE 1 TID List of item_IDs 1 I1 I5 I12 4 I2 I8 I12 5 I2 I8 I11 9 I2 I6 I10 13 I3 I7 I12 18 I3 I7 I12 T ABLE 2 DATA IN NODE 2 TID List of item_IDs 3 I1 I6 I14 8 I2 I8 I11 10 I2 I8 I11 12 I3 I6 I10 15 I3 I7 I12 17 I4 I9 I13 20 I3 I7 I12 T ABLE 3 DATA IN NODE 3 TID List of item_IDs 2 I1 I6 I13 6 I2 I8 I11 7 I2 I8 I11 11 I2 I8 I13 14 I3 I7 I12 16 I3 I7 I11 19 I3 I7 I12 We can obtain as follows by scanning the database  1 614 10001000000100 01000001000100 01000001001000 01000100010000 00100010000100 00100010000100 A             2 714 10000100000001 01000001001000 01000001001000 00100100010000 00100010000100 00010000100010 00100010000100 A               3 714 10000100000010 01000001001000 01000001001000 01000001000010 00100010000100 00100010001000 00100010000100 A               1 2 3 A AA A        validate whether the equation 11 22 33 TT T T AA AA AA AA  is tenable or not  calculate with MATLAB software, apparently the equation 11 22 33 TT T T AA AA AA AA  is tenable    Fig.2  Global association transaction matrix For example: denoted as figure 2 T AA is a global association transaction matrix find out leading diagonal elements 3,8,8,1,1,4,7,7,1,2,6,9,3,1 ii t   min_ sup 20 25 5   if the value of leading diagonal element is smaller than 5, we can confirm that it isnêt to satisfy minimum support threshold, that is to say  it is impossible to generate frequent itemsets in the current row. So, we only scan these rows which the elements  22 33 77 88 1111 1212   ttttt t located for the 2,3,7,8,11,12 th th th th th th row in matrix the vectors that satisfy minimum support are respectively  23 7 2,8,11 3  3 7,12 3  3 7,12 3     81112 2,8,11,3  2,8,11,3  3,7,12,3    So frequent 3-itemsets       337122811    L iii iii   we can get frequent 2-itemsets 2 L with the same method, in addition, we discover that frequent 221 7 


itemsets 2 L can be gained from frequent 3itemsets 3 L directly 6.2 Experiment 2 The hardware environment for experiment in local area network include: 4 personal computer ,where one is used to be as global computing node, the others are used to be as local computing node which distributed in geography for data mining. This experiment data comes from the customer information database in 2007 of insurance company in yangzhou city, Jiangsu province. Experiment data is composed with 5000 samples,  it is tested in two ways 5000 samples approximate in average\( node 1: 1666, node 2:  1667 node 3: 1667 \tributed 3 different local computing nodes 5000 samples are centralized in the global node. where DARBM\(Distributed Association Rules Based on Matrix, DARBM\,FDMAR\(Fast Distributed Matrix Association Rules DARB-M and FDMAR adopt mode appriori and im_appriori\(improved appriori\dopt mode the results for the experiment as follows  Fig.3 Comparison for the experiment 7. Conclusion  Association rule mining is a very important problem in the field of data mining. This paper puts forward a new distributed mining algorithm for matrix association rules WEKA4WS-Based in grid environment , and embed it in WeKa4WS frame. It is excellent that it can reduce the times of accessing database and need not to generate candidate item sets based on Boolean matrix for Apriori algorithm need to generate plenty of candidate itemsets 12 The new algorithm need to scan the database only once and as the structure of the Boolean matrix is simple, it can be understood easily, and it is easy to compute without generating plenty of candidate item sets. It is specially important that this paper combines the grid with web service technology, builds the distributed data mining system under the grid environment, and also proves the validity of algorithms and feasibility of system. It has upper veracity and better effect for distributed association rules mining 8. References  I an F o st er T h e au t o n o m y o f  t h e G r i d  20 06  1 0 24   2 L i  Ze ng L i da  X u  Zh ong z h i S h i Ma og ua ng W a ng  Wenjuan Wu,çDistribued Computing Environment Approaches and Applicationsé,IEEE, \(2004\pp.3240-3244 3 J. Cha ttra tic ha t, J. Da rli ng to n, Y. G uo, S. He dv a ll, M  Kohler, and J.Syed, çAn Architecture for Distributed Enterprise Data Miningé. \(2002 4 Ha im onti D u tta   E m pow e r i n g Sc ie ntif ic Disc ov e r y b y  Distributed Data Mining on the Grid Infrastructureé. \(2007 5 Ma rio Ca n n a t a r o, A ndre a  P u g lie s e D o m e n ic o T a lia P a ol  Trunfio,çDistributed Data Mining on Grids: Services,Tools and Applica tionsé.IEEE Transactions on Systems, Man, and 2004\pp.2451-2465 6 OA SIS W e b Se rv ic e Re sourc e Fra m e w ork W SRF C   http://www.oasisopen.org/committees/tc_home.php?w g_abbrev=wsrf,\(2004 7 T h e G l obus T oolk it htt p://w w w g lobus org to olk it   Czaj ko w s ki K et al  T h e W S Reso u r ce F r am e w o r k Version 1.0.http://www-106.ibm.com/developerworks library/ws-resource/ws-wsrf.pdf .15 May , 2006 9 Sha ik h A li A  R a na O F T a y l or IJ  W e b  Se r v ic e s  Composition for Distributed Data Mining. Workshop onWeb and Grid Services for Scientific Data Analysis 2005 10 E u g e nio Ce s a rio. D i s t ri bu t e d D a ta Mining M ode l a s  Services on the Grid[C  20 08 IE EE Inte r n a tio na l Co nf e r e n c e  on  Data Mining Workshops,2008 11 L i u Sa x i ng T a n L i qiu  X i ong Y o ng jun A Stu dy on Association RulesnMining Algorithm and Its Application[J Engineering and Computer Science, 2007 12 Ia n H.W itte n, E i be Fra n k  Da ta Mining pra c tic a l  Machine Learning Tools and Techniques [M  B e ij ing C h i n a  Machine press,2006    218 


        


9 Appendix Fig 6: Forest Cover Types of the U.S. \(Source. USGS National Atlas of US Summary of Forest Cover Type Data Type Multivariate Abstract The forest cover type for 30 x 30 meter cells obtai ned from US Forest Service \(USFS\ Region 2 Resource Information System RIS\ data Data Characteristics The actual forest cover type for a given observatio n \(30 x 30 meter cell\ was determined from US Fores t Service \(USFS\ Region 2 Resource Information System RIS data Independe nt variables were derived from data originally obta ined from US Geological Survey \(USGS\ and USFS data. Data is in raw form \(not scaled\ and contains binary \(0 or 1 columns of data for qualitative independent variables \(wilderness areas and soil types Summary Statistics Number of instances observations 581012 Number of Attributes 54 Attribute breakdown 12 measures, but 54 columns of data \(10 quantitativ e variables, 4 binary wilderness areas and 40 binary soil type variables Missing Attribute Values None 43 


   C4.2 Open GL has excellent documentation that could help the developer learn the platform with ease C4.3 Developer has very little ex perience in working with Open GL platform  For our case study, alternative B i.e. Adobe Director was the most favorable alternative amongst all the three. It catered to the reusability criteria quite well and aimed at meeting most of the desired operational requirements for the system   6. CONCLUSION & FUTURE WORK  The main contribution of this paper is to develop an approach for evaluating performance scores in MultiCriteria decision making using an intelligent computational argumentation network. The evaluation process requires us to identify performance scores in multi criteria decision making which are not obtained objectively and quantify the same by providing a strong rationale. In this way, deeper analysis can be achieved in reducing the uncertainty problem involved in Multi Criteria decision paradigm. As a part of our future work we plan on conducting a large scale empirical analysis of the argumentation system to validate its effectiveness   REFERENCES  1  L  P Am g o u d  U sin g  A r g u men ts f o r mak i n g an d  ex p lain in g  decisions Artificial Intelligence 173 413-436, \(2009 2 A  Boch m a n   C ollectiv e A r g u men tatio n    Proceedings of the Workshop on Non-Monotonic Reasoning 2002 3 G  R Bu y u k o zk an  Ev alu a tio n o f sof tware d e v e lo p m en t  projects using a fuzzy multi-criteria decision approach Mathematics and Computers in Simualtion 77 464-475, \(2008 4 M T  Chen   F u zzy MCD M A p p r o ach t o Selec t Serv ice  Provider The IEEE International Conference on Fuzzy 2003 5 J. Con k li n  an d  M. Beg e m a n   gIBIS: A Hypertext Tool for Exploratory Policy Discussion Transactions on Office Information Systems 6\(4\: 303  331, \(1988 6 B P  Duarte D e v elo p in g a p r o jec ts ev alu a tio n sy ste m based on multiple attribute value theroy Computer Operations Research 33 1488-1504, \(2006 7 E G  Fo rm an  T h e  A n a l y t ic Hier a rch y P r o cess A n  Exposition OR CHRONICLE 1999 8 M. L ease  an d J L  L i v e l y  Using an Issue Based Hypertext System to Capture Software LifeCycle Process Hypermedia  2\(1\, pp. 34  45, \(1990 9  P e id e L i u   E valu a tio n Mo d e l o f Custo m e r Satis f a c tio n o f  B2CE Commerce Based on Combin ation of Linguistic Variables and Fuzzy Triangular Numbers Eight ACIS International Conference on Software Engin eering, Artificial Intelligence Networking and Parallel Distributed Computing, \(pp 450-454 2007  10  X  F L i u   M an ag e m en t o f an In tellig e n t A r g u m e n tatio n  Network for a Web-Based Collaborative Engineering Design Environment Proceedings of the 2007 IEEE International Symposium on Collaborative Technologies and Systems,\(CTS 2007\, Orlando, Florida May 21-25, 2007 11 X. F L i u   A n In ternet Ba se d In tellig e n t A r g u m e n tatio n  System for Collaborative Engineering Design Proceedings of the 2006 IEEE International Symposium on Collaborative Technologies and Systems pp. 318-325\. Las Vegas, Nevada 2006 12 T  M A sub jec tiv e assess m e n t o f altern ativ e m ission  architectures for the human exploration of Mars at NASA using multicriteria decision making Computer and Operations Research 1147-1164, \(June 2004 13 A  N Mo n ireh  F u zzy De cisio n Ma k i n g b a se d o n  Relationship Analysis between Criteria Annual Meeting of the North American Fuzzy Information Processing Society 2005 14 N  P a p a d ias HERMES Su p p o rti n g A r g u m e n tative  Discourse in Multi Agent Decision Making Proceedings of the 15th National Conference on Artifical Intelligence \(AAAI-98  pp. 827-832\dison, WI: AAAI/MIT Press,  \(1998a 15  E. B T riantaph y llo u   T h e Im p act o f  Ag g r e g atin g Ben e f i t  and Cost Criteria in Four MCDA Methods IEEE Transactions on Engineering Management, Vol 52, No 2 May 2005 16 S  H T s a u r T h e Ev alu a tio n o f airlin e se rv ice q u a lity b y  fuzzy MCDM Tourism Management 107-115, \(2002 1 T  D W a n g  Develo p in g a f u zz y  T O P S IS app r o ach  b a sed  on subjective weights and objective weights Expert Systems with Applications 8980-8985, \(2009 18 L  A  Zadeh  F u z z y Sets   Information and Control 8  338-353, \(1965  152 


                        





