Efficiently Using Matrix in Mining  Maximum Frequent Itemset Liu Zhen-yu  School of Traffic and Transportation Beijing Jiaotong University Beijing , China 08114207@bjtu.edu.cn  Xu Wei-xiang School of Traffic and Transportation Beijing Jiaotong University Beijing, china xu_weixiang@163.com Liu Xumin School of Information Engineering Capital Normal University Beijing, china liuxumin@126.com   Abstract an efficient way to discover the maximum frequent itemset can be very useful for mining association rules, correlations, episodes patterns, etc. Most existing work focuses on the technique for mining candidate maximal 
frequent itemset and ignores the technique for MFI checking. However the efficient of a MFS mining algorithm lies on these two parts. In this paper, a new MFI checking method is presented based on the optimizing of the former called MaxMatrix and an additional constraint for association rules generating is discussed to save mining time In order to understand the process of MaxMatrix easily, an example is provided in detail Keywords-maximum Frequent itemset; MFI checking MaxMatrix; Association Rules I   I NTRODUCTION  Frequent itemset mining has been recognized as a fundamental and essential problem in many data mining tasks including association rules mining, sequential 
patterns mining, correlations, and multi-dimensional patterns et al. A frequent itemset is a set of items appearing together in a number of database records meeting a userspecified threshold Starting with the pioneering work in [1,2 it em set mining algorithm has been studied extensively by researchers. Many of the proposed itemset mining algorithms are a variant of Apriori, which employs a bottom-up level-wise search in the itemset lattice that enumerates every possible single frequent itemset. This implies candidate k 1-itemsets are generated only after all k itemsets have been generated. For each level, all candidate itemsets are tested for frequency by scanning the database 
The drawback of mining all frequent itemsets is that in order to produce a frequent itemset of length l, all l 2 of its subsets must be enumerated, which is computationally unfeasible. Thus there has been recent interest in exacting only the maximal frequent itemset, because the set of all maximum frequent itemsets is orders of magnitude smaller than the set of all frequent itemsets. An itemset is maximal frequent if it has no superset that is frequent. Wherever there are very long patterns \(pattern contains many items are presented in the data, it is often impractical to generate the entire set of frequent itemsets [3 A l so  in so m e  situations it is sufficient to mine the maximal frequent itemsets rather than all the frequent itemsets. We will use 
MFS to denote the set of the maximal frequent itemsets and MFI to denote one maximal frequent itemset Therefore, many algorithms [3,4,5,6,7 ve b e e n  proposed for generating MFS directly instead of all the frequent itemsets to ìshortcutî the process. In general, a MFS mining algorithm includes two main parts. The first is the techniques to find candidate maximal frequent itemset efficiently, and the second is the methods used to perform fast MFI checking to eliminate non-maximal itemsets. However, the second part MFI checking hasnít drawn adequate attention. This paper is written with the primary aim of developing a method for fast maximality checking In this paper a new method is proposed called MaxMatrix which uses the pseudo-projection matrix of the 
MFS matrix to do MFI checking. It can not only test fast but also significantly save resources. Because only logical operation is used to delete the related ranks of the matrix for testing the candidate MFI in algorithm MaxMatrix, it does not need to allocate new memory space for pseudoprojection matrix. An all-confidence constraint is also used to facilitate the further generation of association rules from MFS if necessary A  Related Work There are considerable researches on methods for generating the set of maximal frequent itemsets Lin and Kedem r op o s e d a n a l gor i t hm  c a l l e d Pincer-search for mining maximal frequent itemsets. It combines both the bottom-up like Apriori and top-down 
directions to maintain and update the maximal frequent candidate set which do not contain any known infrequent itemset. This method can help in reducing the number of database scans by eliminating non-maximal set early. But the overhead of maintaining the candidate maximal frequent set can be very high MaxMiner [3 a l so m i n e s o n ly m a x i m a l elem en ts  It  abandons a strict bottom-up traversal of the search space and instead always attempts to ìlook aheadî in order to quickly identify maximal frequent itemsets. i.e., if a node with all its extensions can be determined to be frequent there is no need to further process that node. It also employs item order based on support instead of the lexicographic order to keep the search space as small as 
possible. Though these strategies reduce the search time dramatically, MaxMiner still needs many passes over datasets to get all maximal frequent itemsets DepthProject fi n d s l o ng p a t t er ns b y usi ng d e p t hfirst search on a lexicographic tree of itemsets. It uses bitvector and hierarchical projections to make the process of support counting more efficient. A bitvector contains the information about transactions which contain the itemset for a node as a subset. By using hierarchical projections, it can reuse the information from counting k itemset to count k 1\itemsets. It also uses an effective 
2010 Third International Conference on Knowledge Discovery and Data Mining 978-0-7695-3923-2/10 $26.00 © 2010 IEEE DOI 10.1109/WKDD.2010.27 50 


lookahead strategy in order to avoid creation of those subtrees of the lexicographic tree which contain only nonmaximal itemsets MAFIA l s o use s t h e de pt h-fi r s t s e ar c h st r a t e gy fo r mining maximal frequent itemsets from transactional database like DepthProject. It integrates a variety of old and new algorithmic ideas to improve performance, such as three type of pruning ideas to trim the tree including PEP, FHUT\(also used in MaxMiner and DepthProject\ and HUTMFI, dynamic reordering the children of each node and a compression form of vertical bitmap representation for the database In general, these methods are all trying to improve the performance for mining maximal frequent itemset and have varying performance depending on the database characteristics mainly the distribution of maximal frequent patterns by length. While they all maintain a superset of the MFI and would require post-pruning, it is not clear how these algorithm would do maximality checking efficiently GenMax [7  u s es a n o v e l te ch n i qu e cal le d p r og res s iv e  focusing to perform maximality checking and diffset propagation to perform fast frequency computation in the process of mining to mining exact MFI. But it needs to construct a list of local maximal frequent itemsets which is most relevant superset of candidates. G.Grahne and J.Zhu proposed a MFI-tree in [8,9 to s t o r e al l MF I, w h ich is constructed like FP-tree [10  an d retu rn s al l an d on ly th e maximal frequent itemsets. However, for large datasets the MFI-tree will be quite large, so one itemset may need thousands of comparisons for subset testing In this paper, the algorithm MaxMatrix will integrates pruning of non-maximal itemsets in the process of mining using matrix of MFS to maintain an exact set of maximal frequent itemset, which is proved to be an efficient method B  Overview The organization of the rest of the paper is as follows Section 2 discusses the conceptual ideas of the MFS mining problem and the principle of MFI checking of MaxMtrix. In section 3, we provide a pseudo-code description of MaxMatrix and implementation details about how it uses pruning techniques to restrict the search space. Section 4 discusses the integration of all-confidence constrains into the generation of association rules from MFS. The algorithm is illustrated with an example in section 5. Section 6 discusses the conclusions and summary II  P RELIMINARIES  A  Terminology Defining Let  m i i i I    2 1 000  be a set of m distinct items. A database D is a set of transactions that are sets over item domain I Each transaction is associated with a unique identifier, called TID A set of items is more succinctly called an itemset. An itemset with k items are referred as k itemset. The support of an itemset I X 002 denoted  sup X is the fraction of the transactions in D that contains all items of X An itemset is frequent if its support is above or equal to the minimum support minsup  predefined by the user. Otherwise, it is infrequent We will use generic set-enumeration tree search framework [3 t o s e a r ch ea ch MF I  T h e id ea is t o  ex p a n d  sets over an ordered and finite item domain as illustrated in figure1, where five items  E D C B A     are denoted by their position in the ordering. We assume that a lexical ordering exists among the items in the database. The itemname is replaced with item-number in order to facilitate the construction and pseudo mapping of MFS-matrix defined in section 2.3\. MaxMatrix constructs the set enumeration tree mainly in depth-first order for finding the exact MFI. Figure1 also shows the itemset frequency testing order in the process of MFS mining by the number on the top-right side of the itemset   A candidate group 2 g is employed to represent each node in the set-enumeration tree like [3 at th e in it ial ste p  of algorithm MaxMatrix. A candidate group 2 g consists of head   2 g h and tail   2 g t    2 g h represents the itemset enumerated by the node and   2 g t is an lexical ordered set containing all items not in   2 g h which can potentially appear in   2 g h s sub-node B  Initialization Figure 1 shows the tree does not grow in pure depthfirst order. A hash technique of the DHP [11,12 s used t o  initialize the step of group. A direct-addressing hash table H 2 and hash function 000        1 1 1        x i x y i N y x h are illustrated in figure2 N is the amount of the item and 5  N in figure 2  item name A B C D E item number 1 2 3 4 5 itemset 2 H hash address 1,2 0 1,3 1 000  000 3,5 8 4,5 9  Figure2. Example of H 2  generation C  MFS Checking Based Matrix First we need to construct a MFS-matrix, each row of which represents a frequent item ordered according to lexical sequence. Every determined MFI will be added in the matrix as a new column, of which the element corresponding to item included in MFI will be set to 1 and 000      1 1      x i i N y x h   1     x y   0  1 1 2 1 3 1  4 1  1  2 1 1  3 1 1  4 1 2  3 1 2  4 1 3  4 1  1  2  3 2 1  2  4 2 1  3  4 6 1  3  5 6  1,2,3,4 3  Figure 1  set enumeration tree for searching 5 1 1  5 1 2  5 1 3  5 1  1  2  5 2 1  4  5 8  2  3  4 9 2  4  5 11 3  4  5 12 4  5 1 1,2,3,5 3 1,2,4,5 5 1,3,4,5 7 2,3,4,5 10  1,2,3,4,5 4 2  3  5 9   
51 


others set to 0, so each column represents a MFI. For each candidate MFI X pseudo projection is operated on MFSmatrix to check whether it has a superset in MFS-matrix. If item X i 003 the columns of MFS-matrix is shielded, of which the i th element equal to 0. Iterating the shield process from the last item to the first one of X a pseudo projection matrix 004 of the original MFS-matrix will be obtained. If 004  005 it verifies there is not a superset of X  and if X is frequent then X is a MFI X will be added to the original MFS-matrix; otherwise X is not a MFI, the iteration will be continued until no candidate MFI is produced Since the mapping is based on the designated ranks, it does not require new memory space to storage new matrix It just needs to establish a vector to shield the corresponding ranks in MaxMatrix, which can save memory greatly III  P SEUDO CODE FOR M AXMTRIX  MaxMatrix consists of four parts as follows 1  In the first round, scan the database D to count the support of all 1-item sets and build a hash table H2 2  Generate L 1 and L 2  3  Geberate first-level and second-level nodes of search tree 4  MFS-searching algorithm and MFI checking The pseudo-code of MaxMatrix algorithm is given below  MaxMatrix Algorithm Begin generate the initial candidate node 2 g  1 for each itemset 2 F x x j i 003 generate a new candidate group 2 g  2    let j i x x g h    2  3    2 g t   2 F x x k k i 003 k follows j in the ordering invoke as MFI-search 2   2 2 C I current node 2 I  4 for each 2 g x 003  5  Let    2 x h x I      2 x t x P   6 2 C Tail-gen 2 2  P I  7  MFI-search l C I l l    function MFI-search l C I l l   ntil 005  l C  8 MFI-search l C I l l    9 for each l C x 003  10   1 x I I l l 000    11   1 x y and C y y P l l  003    12    While flag=0 do 13   {If 1 1   l l P I 000 has a superset in MFS-marix 14         return// all subsequent branches pruned 15   1 l C Tail-gen 1 1    l l P I  16           if 1  C and flag=1 17               {put 1 1   l l C I 000 in MFI 18                  let 005  l C  19           if 1  C and flag=0 20           if 1 1   l l C I 000 has a superset in MFS-matrix 21                 return// all subsequent branches pruned 22            put 1 1   l l C I 000 in MFS-matrix 23                    return// all subsequent branches pruned 24           if 0  C  25            if 1  l I has no superset in MFS put 1  l I in MFS-matrix 26        else MFI-search 1   1 1    l C I l l  can 1  l I joint with other item in l C  27 Tail-gen 1 1    l l P I  28 005  C  0  C flag=1 29  for each 1  003 l P y  30     if sup   1 y I l 000   006 minsup  31        if sup   1 y I l 000  sup 1  l I  32   1 1 y I I l l 000     33        else y C C 000   34 1   C C  35     else flag=0 End  MaxMatrix employs PEP \(lines 30-32\ and HUTMFI lines 12-14\uning strategies. PEP has the biggest effect of the pruning method on the performance gains proved in 6  HU TMF I p r op os ed  als o i n  6  d e t e rm in es w h eth e r a  superset of the HUT is in the MFS, and thus it ensures the exact MFI generated without post-pruning and can prune some branches early to reduce search space. If a superset does exist, then the HUT must be frequent and the subtree rooted at the node can be pruned away Many algorithms adopt support increasing order to dynamically reorder the children of each node, such as MaxMiner, MAFIA, GenMax etc. There are also algorithms adopting support descending order [9,1 While ordering strategy isnít always an effective means of cutting down the search space, since the effect of item ordering is very much dependent upon the characteristics of the data sets. Here, MaxMatrix constructs search tree based on lexical order in order to facilitate the MFI checking with MFS-matrix To avoid redundancy generated during each recursive superset checking, itemsí count C of 1  l C and a status flag are used. If flag is true, it implies no items are deleted from 1  l P That is l l P I 000 of current node is the same as 1 1   l l P I 000 so superset checking do not needed to operate again \(lines 12-14\. If flag is true and C 1, we can inset 1 1   l l C I 000 into MFS directly and end current l I s extension lines 16-18\. If flag is false and C 1 1 1   l l P I 000 will be performed superset checking subsequently without the need to return to MFI-search\(\ \(lines 19-23 IV  F URTHER C ONSTRAINT FOR A SSOCIATION R ULE M INING  Though the frequent patterns themselves are often of interest to the decision maker, they often need to be transformed further before being presented for understanding. The problem of mining association rules is to generate all rules that have support and confidence greater than some user specified minimum support and  
52 


minimum confidence thresholds respectively. The confidence of a rule Y X 000 is defined as the ratio  sup  sup X Y X 007 So in order to find those association rules with high confidence, another database pass is required after finding all maximal frequent itemsets to obtain the supports of all frequent itemsets for producing association rules. If some frequent itemsets are long, this step will be very costly [3  To s o lv e th is  problem, we incorporate an additional constraint called all_confidence into MaxMatrix for association rules searching from MFS. This constraint is quite powerful since all_confidence ensures a lower bound on confidence for any rule of an itemset by which we can further reduce the number of subset of MFI to be counted All_confidence is defined as the minimum confidence of all the association rules that can be derived from the itemset X which is formulated as follows    max{sup  sup   X i i X X allconf j j 003 010  1 A pattern that has all_confidence of no less than a given minimum confidence threshold 011 indicates a high correlation among all the items in the pattern. This is because all association rules derived from the pattern have confidence of no less than 011 as implied by \(1  All_confidence has a desirable property for the efficient mining of all association rules from MFS. The property called the downward closure property c a n b e  directly adapted as effective pruning tools for mining association rules, which is formally stated as follows Property1. \(Downward closure property of all_confidence Given two itemsets X and Y if Y X 012  then     Y allconf X allconf 006  By property 1, we are able to perform the following pruning: if a pattern X has an all_confidence value no less than 011 then the all-confidence of all its subset will greater than 011 so we can get the association rules directly without counting the supports of these subset V  E XAMPLE  The process of MaxMatrix is given in figure3 with minsup 2 011 0.5 and initial MFS-matrix 005 The fist time scanning of D returns 1 C and 2 H Comparing 1 C and 2 H with minsup  1 F and 2 F can be determined. Based on the items in 2 F itemgroup 2 g can be acquired. Then the MFS search tree for the database D is constructed like figure 1, in which itemsets painted with sloping line are MFIs and itemset below dashed line are infrequent itemsets. MFS searching starts from the second level. For example, when  2 I 1,2 and  2 P 3,4,5, through the Tailgen 5  4  3 2  C Though the first calling of the function   MFS-search 3  2  1 3  I and 5  4 3  P is produced 5  4  3  2  1 3 3  P I 000 is checked subsequently whether it has a superset in MFS. As MFS-matrix 005  5  4  3  2  1 3 3  P I 000 doesnít have a superset in MFS and 5 3  C from Tail-gen 3 3  P I In this phase  C 1 and flag=0, so 5  3  2  1 3 3  C I 000 will be checked whether it has a superset in MFS. Similarly, it doesnít have a superset in MFS 5  3  2  1 3 3  C I 000 will be added in MFS-matrix as a Figure3   the mining process of MaxMatrix 
53 


MFI. The node 3  2  1 3  I extension is finished. Then the function MFS-search l C I l l   ill be called repeatedly until all the nodes are checked or 005  l C  The checking process with MFS-matrix is showed in figure4 when 5  3  2 3 3  P I 000 First, starting from the last item 5 of 3 3 P I 000 the column of the original matrix figure4\(a\ith the fifth element equal to 0 is shielded then the matrix figure4\(b\is obtained. Second, to the second item 3 from back to front of 3 3 P I 000 the column with the third element equal to 0 is shielded and matrix figure4\(c\ is generated. Third, to the last item from back to front, the column is shielded with the second element equal to 0 and matrix figure4\(d\ is produced, which is the final pseudo projection matrix 004 Because 004 005 013  5  3  2 3 3  P I 000 is not a MFI   000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 0 1 1 1 0 1 1 0 1 1 1 0 1 1 1 5 4 3 2 1  5 3 2  000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 1 1 0 1 1 1 0 1 1 1 5 4 3 2 1  5 3 2  000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 1 0 1 1 1 5 4 3 2 1  5 3 2  000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 1 0 1 1 1 5 4 3 2 1  5 3 2  a                         b                    c                      d  Figure4  MFS-matrix pseudo projection based 5  3  2 3 3  P I 000   Through the iteration calling of the function MFSsearch\(\ and MFI checking with MFS-matrix, MaxMatrix can get all the exact MFI without post-pruning. In this example MFS is   4  3  2  5  4  2  1  5  3  2  1   If we need to get all the association rules of the database D we could compute all_confidence of every MFI in MFS firstly. For example 33  0  5  3  2  1   allconf  50  0  5  4  2  1   allconf and 33  0  4  3  2   allconf from the formula \(1\ Since 50  0  5  4  2  1   allconf 006 011 all the association rules exacted from the pattern are interesting and it does not need to count the supports of its subset VI  C ONCLUSION  This paper present an efficient MFI mining algorithm MaxMatrix based on the analysis of the previous work which mainly relies on a depth-first search technique to construct the lexical set enumeration tree of itemsets. The algorithm is optimum through hash technique at initial stage, node pruning with PEP and HUTMFI and some means avoiding redundancy. At the same time, it uses MFS-matrix to do superset and MFI checking during the hole searching process efficiently. An additional constraint for discovering association rules from MFS is also discussed, which can save a lot of time for counting the support of the subset of MFI. MaxMatrix can reduce both the time the exact MFI is generated and the number of subset considered for association rule mining A CKNOWLEDGMENT  The authors gratefully acknowledge the editor and anonymous reviewers for their valuable comments and constructive suggestions. This research was supported by the Beijing Municipal Science & Technology Commission key project \(Z090506006309011\ and the Beijing Educational Committee science and technology develop plan key project \(KZ200710028014\. It was partially supported by the MOE key Laboratory for Transportation Complex Systems Theory and Technology School of Traffic and Transportation Beijing Jiaotong University R EFERENCES  1  R. Agrawal, T. Imielinski, A. Swami. Mining Association Rules between Sets if Items in Very Large Database. ACM SIGMOD Conference Proceedings, pages 207-216, 1993 2  R. Agrawal, R. Srikant. Fast Algorithms for Mining Association Rules. VLDB Conference Proceedings, pages 487-499, 1994 3  R. J. Bayardo. Efficiently Mining Long Patterns from Databases ACM SIGMOD Conference Proceedings, pages 85-93, 1998 4  D. Lin, Z. M. Kedem. Pincer-search: A New Algorithm for Discovering the Maximum Frequent set. The Six European Conference Proceedings on Extending Database Technology, Mar 1998 5  R. Agrawal, C. Aggarwal, and V. Prasad. Depth First Generation of Long Patterns. ACM SIGKDD Conference Proceedings, Aug 2000 6  D. Burdick, M. Calimlim, and J. Gehrke. MAFIA: A Maximal Frequent Itemset Algorithm for Transactional Databases. In Intl Conf. on Data Engineering, Apr. 2001 7  K. Gouda, M.J. Zaki. Efficiently Mining Maximal Frequent Itemsets. In 1st IEEE International Conference on Data Mining\(ICDM\, pages 163-170, San Jose, Nov. 2001 8  G. Grahne and J. Zhu. High Performance Mining of Maximal frequent itemsets. In SIAMí03 Workshop on High Performance Data Mining: Pervasive and Data Stream Mining, May 2003 9  G. Grahne and J. Zhu. Efficiently Using Prefix-trees in Mining Frequent Itemsets. First workshop on Frequent Itemset Mining Implementation \(FIMIí03\, Melbourne ,FL,2003   J. Han, J. Pei, and Y. Yin. Ming Frequent Patterns without Candidate Generation. In Proceeding of Special Interest Group on Management of Data, pages 1-12, Dallas, TX, May 2000   J. S. Park, M. S. Chen, and P. S. Yu. Using a Hash-based Method with Transaxtion Trimming for Mining Association Rules. IEEE Trans on Knowledge and Data Engineering, pages 813-825, 1997 9\(5   Zhang Min-cong, Yan Cun-liang, and Zhu Kai-yu. A New Hybrid Algorithm for Association Rule Mining. Journal of Donghua University, Vol. 24, No. 5, 2007   E. R. Omiecinski. Alternative Interest Measures for Mining Associations in Databases. IEEE Trans on Knowledge and Data Engineering, pages 57-69, 2003, 15\(1  
54 


 T ABLE II  R EGIONS P ATTERNS OF IMAGES OF A CERTAIN  CATEGOY   ID  Region Patterns  1 R\(a,b,c,-\R\(a,b,-,d\R\(aí,bí,cí,dí\ R\(aí,bí,cí,-\ R\(-,bí,cí,d  2 R\(a,b,c,-\,R\(a,b,-,-\,R\(aí,bí,cí,dí\, R\(aí,bí,cí,-\, R\(-,bí,cí,d  3 R\(a,b,c,-\  R\(a,b,-,-\  R\(aí,bí,cí,-\ R\(-,bí,c  4 R\(a,b,c,-\ R\(a,b,-,-\R\(aí,bí,cí,-\ R\(-,bí,c  5 R\(a,b,-,d\,R\(a,b,-,-\ R\(-,bí,cí,dí\ R\(-,bí,c  The category of an image  is determined by the following semantic association rules R\(a,b,c,-\ and R\(aí,bí,cí,-\>category R\(a,b,c,-\ and R\(a,b,-,-\->category R\(aí,bí,cí,-\ and R\(a,b,-,-\ ->category R\(a,b,-,-\ and R\(-,bí,cí,-\ ->category R\(a,b,c,-\ and R\(aí,bí,cí,-\d R\(a,b,-,-\ ->category The rules are represented in Prolog as facts of the form PatternRule\(Category, Score, ListofRegionPatterns The patterns from ListofRegionPatterns are terms of the form: regionPattern\(ListofPatternDescriptors The patterns from the descriptors list specify the set of possible values for a certain descriptor name. The form of this term is descriptorPattern\(descriptorName,ValueList One of the semantic pattern rules used to identify the cliff category is illustrated bellow. This semantic pattern rule has the score \(confidence\al to 100 PatternRule \(cliff,100 regionPattern descriptorPattern\(colour,[dark-brown descriptorPattern\(horizontal-position,[center,left right  descriptorPattern\(vertical-position,[center,bottom descriptorPattern\(dimension,[big descriptorPattern\(eccentricity-shape,[sma descriptorPattern\(texture-probability, [medium  descriptorPattern\(texture-inversedifference medium descriptorPattern \(texture-entropy,[big descriptorPattern\(texture-energy,[big descriptorPattern \(texture-contrast,[big descriptorPattern \(texture-correlation, [big  regionPattern descriptorPattern\(colour,[medium-brown  descriptorPattern\(horizontal-position,[center,left right descriptorPattern\(vertical-position,[center, bottom descriptorPattern\(dimension,[smal descriptorPattern\(eccentricity-shape,[sma descriptorPattern \(texture-probability,[big descriptorPattern\(texture-inversedifference,[big descriptorPattern\(texture-entropy,[medium descriptorPattern \(texture-energy, [big  descriptorPattern \(texture-contrast,[medium descriptorPattern \(texture- correlation,[big  B  Semantic pattern rules elimination The number of semantic pattern rules that could be generated is usually big. In this case two problems exist: the first one is that the set of rules can contain noise information and affect the classification time. Another problem is the big number of rules that can also affect the classification time This is an important problem in the real applications, which necessitate rapid response. On the other side, the elimination of rules can affect the classification accuracy. The elimination methods are the following elimination of  specific rules and keeping the rules with big confidence elimination of rules that can introduce errors in the classification process The following definitions introduce some notions used in this section [11   Definition 1   Given two rules R 1 C and R 2 C, the first rule is called general if R 1  R 2 The second one is called specific Definition 2  Given two rules R 1 and R 2 R 1 is called stronger than R 2 or R 2 is weaker than R 1  1\ R 1 has confidence greater than R 2  2\If the confidences are equal, but the support\(R 1  greater than support\(R 2  3\ the supports are equal, support\(R 1 upport\(R 2  and confidences confidence\(R 1 fidence\(R 2  equal, but R 1 has fewer attributes than R 2   The elimination of weak and specific semantic pattern rules is described in pseudo-code Algorithm IV.3  Elimination of weak and specific rules Input  set of semantic pattern rules, S generated for each category, C   Output  the set of rules which will be used for classification Method Sort the rules for C category in conformity to Definition 1 foreach rule in S do begin Find the most specific rules Eliminate the rules with  smallest confidence end C  Semantic image classification The classifier represents the set of semantic pattern rules used to predict the category of images from the test database. Being given a new image, the classification process searches in the rules set for finding the most appropriate category. Images are processed and are represented by means of semantic indicators as Prolog facts The semantic pattern rules are applied to the set of images facts, using the Prolog inference engine A semantic pattern rule matches an image, if all characteristics which appear in the body of the rule also appear in the image characteristics The algorithm for image categorization is described in pseudo-code 
129 


Algorithm IV.4  Semantic classification of an image Input new unclassified image and the set of semantic pattern rules; each pattern rule has the confidence R i conf Output the classified image, and the score of matching Method  S = null foreach rule R in PatternRules do begin if R matches I then Keep R and add R in S I.score = R.conf  Divide S into subsets one foreach category: S 1 S n   foreach subset S k from S do Add the confidences of all rules from S k  Add I image in the category identified by the rules from S k with the greatest confidence I.score = max 000 S k conf end end  end In the experiments realized through this study, two databases are used for testing the learning process. The database used for learning contains 200 images from different nature categories and is used to learn the correlations between images and semantic concepts. All the images from the database have JPEG format and are of different dimensions. The database used in the learning process is categorized into 50 semantic concepts. The system learns each concept by submitting appreciatively 20 images per category. The testing database contains 500 unclassified images The results of the semantic image retrieval after the sunriseî category are observed in the figure 6. These images from the test database are correctly classified by the algorithm The results of the semantic image retrieval after the mountainî category are observed in the figure 7. Two images from the test database are incorrectly classified since they represent ìclouds The performance metrics, precision and average normalized modified retrieval rate \(ANMRR\, are computed to evaluate the efficiency and accuracy of the semantic pattern rule generation and annotation methods The precision is defined as the ratio between the number of images correctly classified by system, and the total number of classified images. The precision is in the range of 0 an d g r eater v a lu es repres en t a better retriev a l performance. Averaged Normalized Modified Retrieval Rate \(ANMRR\ is an overall performance calculated by averaging the result from each query h e A N M R R is in the range of d s m a ller v a lu e s repres en t a better retrieval performance These parameters are computed as average for each image category as in the table III    Figure 6. The results of semantic image retrieval after the ìsunrise category  Figure 7. The results of semantic image retrieval after the ìmountains category  
130 


T ABLE III  T HE PRECISION AND ANMRR COMPUTED FOR EACH IMAGE CATEGORY  Category Precision ANMRR Fire 0.77 0.39 Iceberg 0.71 0.34 Tree 0.65 0.45 Sunset 0.89 0.14 Cliff 0.93 0.11 Desert 0.89 0.11 Red Rose 0.75 0.20 Elephant 0.65 0.43 Mountain 0.85 0.16 See 0.91 0.09 Flower 0.77 0.31  Also, for each category from the database, the percent of images correctly classified by the system is computed as in Figure 8 As it can be observed from the experiments, the results are strongly influenced by th e complexity of each image category. Actually, the results of experiments are very promising, because they show a small average normalized modified retrieval rate and a good precision for the majority of the database categories, making the system more reliable V  CONCLUSION  In this study we propose methods for semantic image annotation based on visual content. For establishing correlations with semantic categories, we experimented and selected some low-level visual characteristics of images. So each category is translated in visual computable characteristics and in terms of objects that have the great probability to appear in an image category  Figure 8. Category vs. percent of images correctly classified   The algorithm that generates the semantic pattern rules selects the image characteristics with the greatest probability of apparition, offering a better generality By comparison to other image annotation methods, our proposed and developed methods have some advantages: the entire process is automated, and a great number of semantic concepts can be defined; these methods can be easily extended to any domain, because the visual features semantic indicators remain unchanged, and the semantic pattern rules are generated based on the set of example labeled images used for learning semantic concepts; the spatial information is taken into account and it offers rich semantic information about the relationships of the image colour regions \(left, right, center, bottom, and upper The proposed methods have the limitation that they canít learn every semantic concept, due to the fact that the segmentation algorithm is not capable to segment images in real objects. Improvements can be brought using a segmentation method with greater semantic accuracy R EFERENCES  1  A  Be r s o n S  J  S m it h, D a ta W a r e ho us i n g  D a ta Mi ni ng a n d O L A P  McGraw-Hill. New York, 1997 2 G  C a rn e i ro A  C h a n  P  M o re n o a n d N Va s c on c e los  S u p e rvi s e d  learning of semantic classes for image annotation and retrieval IEEE Pattern Analysis Machine Intelligence, vol. 29\(3\, 2007, pp 394ñ410 3  A  H o og s  J  Ri tts c he r  G  S t e i n  a n d  J  S c hm ie de r e r   V ide o co nte n t  annotation using visual analysis and a large semantic knowledge base,î Proceedings of the IEEE Computer Society Conference on Computer Vision and Pattern Recognition, 2003, pp. 327 ñ 334 4  W  J. F r aw l e y   G  P i ate t sky S h apir o  an d C  J Mat h e u s  K n o w le dg e Discovery in Databases, chapter Knowledge Discovery in Databases  An Overview, MIT Press, 1991 5  A   W  S m e u l d e r s  M  W o r r i n g  S   S a n t i n i  A  G u p t a  a n d R  J a i n   Content-Based Image Retrieval at the End of the Early Years IEEE Trans. Pattern Analysis and Machine Intelligence, vol. 22\(12 2000, pp. 1349ñ1380 6  J  R  S m it h S  F C h a n g   V is ual S E E k a f u l l y auto m a te d co nte n tbased image query system,î The Fourth ACM International Multimedia Conference and Exhibition, Boston, MA, USA, 1996 7  V  Me z a r i s   I   K o m p ats i ar is  an d M G  S t r i ntz   R e g io nbas e d I m age Retrieval using an Object Ontology and Relevance Feedback EURASIP JASP, 2004 8  B. S   Ma nj u n a t h  P  S a l e m b ie r  a nd T  S i ko r a I n tr o duc tio n to MP E G 7: Multimedia Content Description Standard, Wiley, New York 2001 9  O  Mar q ue s  N  B a r m a n  S e m iau t o m a ti c S e m a n t i c A nno ta tio n o f  Images Using Machine Learning Techniques,î D. Fensel, K. Sycara and J. Mylopoulos, editors, Proceedings of the International Semantic Web Conference, 2003, pp. 550ñ565, Florida 10 N. R a si w a si a  P. J. Moreno  N  Vasconcelos  Bridging the Gap Query by Semantic Example,î IEEE Transactions On Multimedia vol. 9\(5\, 2007, pp. 923-938   O   R Z a ian e  M L  A n t o ni e  A   C o m a n A pp l i cati o n o f D a ta   Minin g  Techniques for Medical Image Classificationî, Proceedings of Workshop on Multimedia Data Mining \(MDM/KDDí2002\, San Francisco, USA, 2002 
131 


     Figure 9. Argumentation Tree For Open GL  A1 The current system in flash does not have the functionality of dynamic allocation of particles like mine or clutter. It places them randomly  A1.1 That is not of much importance because it still gives a new position to mine and clutter particles A2 Current system in flash has faster response time as compared to system in Adobe Director A3 The current system doesnêt satisfy many of the features required for the new system like database A4 Adobe Flash cannot communicate with database A4.1 Flash doesnêt support database but database support is very important and critical A4.1.1 The system should be able to generate evaluation reports for trainee based on pr evious records stored in the database A5 Flash doesnêt create sound clips  A5.1 We donêt need sound creating features as the sys tem has to generate sound. We can play externally recorded sound files using Adobe Flash A6 Flash can provide good visual effects as compared to Adobe Director A7 The developer has good knowledge in development using Flash so the system can be developed quickly B1 We could reuse the system already developed for sound generation, as it is developed using Adobe Audition for analysis which is somehow related to Adobe Director B1.1 The current system is better synthesized in terms of sound production and the sound produced is also instantaneous rather than discrete B1.2 That current system has certain performance issues like slow response time B1.3 The current system in Adobe Director has the feature of producing dynamic coloring scheme on approaching a mine. This kind of scheme is highly preferable and is not present in Adobe Flash system B2 Adobe Director can provide more functionality as compared to the current flash system. E.g. Multiple sounds while detecting mines   B2.1 Adobe Director can provide better visual effects as compared to flash e.g. in case of GUIês   B2.2 A modified version of the current system in flash can also provide the same functionality B2.2.1 We cannot integrate code developed in other platforms with Flash, but Flash can be integrated in Adobe Director B3 The interface provided by flash is not professional enough. It is too simple and straight forward for doing more things in future   B4 Easily available plug-ins can help integrate the tracking system developed in C# with Adobe Director  B4.1 Code developed in Open GL/AL can also be integrated using Adobe Director using suitable stubs   B5 A new sound recognition algorithm is being developed in Adobe Audition which can be integrated with Adobe Director but not with Open GL or Flash Evidence supported B6 If the current system is reused; the project deadline can be met easily B7 The developer has very little experience in development using Adobe Director   B7.1 The developer can take help from the already developed system in Adobe Director C1 The tracking software already developed is coded in C#/NX5. We could reuse that and develop our system in Open GL/AL C1.1 Open GL has C# libraries which can be used to develop the system C2 Because the platform used is for high end application development, it can provide good GUI and database support C2.1 Open GL/AL can help us generate dynamic surfaces for mine detection and training which the original system in flash does not have C4 Open GL does not support connectivity with Adobe Audition. Adobe Audition is required for creating sound recognition algorithm C3 Open GL does not support connectivity with Adobe Audition. Adobe Audition is required for creating sound recognition algorithm C4 The time taken for developing the project using open GL will be comparatively more as the whole system would have to be developed from scratch C4.1 If Open GL has support for C# libraries, and then the system could be develope d faster as developer is quite familiar with programming languages like C 151 


   C4.2 Open GL has excellent documentation that could help the developer learn the platform with ease C4.3 Developer has very little ex perience in working with Open GL platform  For our case study, alternative B i.e. Adobe Director was the most favorable alternative amongst all the three. It catered to the reusability criteria quite well and aimed at meeting most of the desired operational requirements for the system   6. CONCLUSION & FUTURE WORK  The main contribution of this paper is to develop an approach for evaluating performance scores in MultiCriteria decision making using an intelligent computational argumentation network. The evaluation process requires us to identify performance scores in multi criteria decision making which are not obtained objectively and quantify the same by providing a strong rationale. In this way, deeper analysis can be achieved in reducing the uncertainty problem involved in Multi Criteria decision paradigm. As a part of our future work we plan on conducting a large scale empirical analysis of the argumentation system to validate its effectiveness   REFERENCES  1  L  P Am g o u d  U sin g  A r g u men ts f o r mak i n g an d  ex p lain in g  decisions Artificial Intelligence 173 413-436, \(2009 2 A  Boch m a n   C ollectiv e A r g u men tatio n    Proceedings of the Workshop on Non-Monotonic Reasoning 2002 3 G  R Bu y u k o zk an  Ev alu a tio n o f sof tware d e v e lo p m en t  projects using a fuzzy multi-criteria decision approach Mathematics and Computers in Simualtion 77 464-475, \(2008 4 M T  Chen   F u zzy MCD M A p p r o ach t o Selec t Serv ice  Provider The IEEE International Conference on Fuzzy 2003 5 J. Con k li n  an d  M. Beg e m a n   gIBIS: A Hypertext Tool for Exploratory Policy Discussion Transactions on Office Information Systems 6\(4\: 303  331, \(1988 6 B P  Duarte D e v elo p in g a p r o jec ts ev alu a tio n sy ste m based on multiple attribute value theroy Computer Operations Research 33 1488-1504, \(2006 7 E G  Fo rm an  T h e  A n a l y t ic Hier a rch y P r o cess A n  Exposition OR CHRONICLE 1999 8 M. L ease  an d J L  L i v e l y  Using an Issue Based Hypertext System to Capture Software LifeCycle Process Hypermedia  2\(1\, pp. 34  45, \(1990 9  P e id e L i u   E valu a tio n Mo d e l o f Custo m e r Satis f a c tio n o f  B2CE Commerce Based on Combin ation of Linguistic Variables and Fuzzy Triangular Numbers Eight ACIS International Conference on Software Engin eering, Artificial Intelligence Networking and Parallel Distributed Computing, \(pp 450-454 2007  10  X  F L i u   M an ag e m en t o f an In tellig e n t A r g u m e n tatio n  Network for a Web-Based Collaborative Engineering Design Environment Proceedings of the 2007 IEEE International Symposium on Collaborative Technologies and Systems,\(CTS 2007\, Orlando, Florida May 21-25, 2007 11 X. F L i u   A n In ternet Ba se d In tellig e n t A r g u m e n tatio n  System for Collaborative Engineering Design Proceedings of the 2006 IEEE International Symposium on Collaborative Technologies and Systems pp. 318-325\. Las Vegas, Nevada 2006 12 T  M A sub jec tiv e assess m e n t o f altern ativ e m ission  architectures for the human exploration of Mars at NASA using multicriteria decision making Computer and Operations Research 1147-1164, \(June 2004 13 A  N Mo n ireh  F u zzy De cisio n Ma k i n g b a se d o n  Relationship Analysis between Criteria Annual Meeting of the North American Fuzzy Information Processing Society 2005 14 N  P a p a d ias HERMES Su p p o rti n g A r g u m e n tative  Discourse in Multi Agent Decision Making Proceedings of the 15th National Conference on Artifical Intelligence \(AAAI-98  pp. 827-832\dison, WI: AAAI/MIT Press,  \(1998a 15  E. B T riantaph y llo u   T h e Im p act o f  Ag g r e g atin g Ben e f i t  and Cost Criteria in Four MCDA Methods IEEE Transactions on Engineering Management, Vol 52, No 2 May 2005 16 S  H T s a u r T h e Ev alu a tio n o f airlin e se rv ice q u a lity b y  fuzzy MCDM Tourism Management 107-115, \(2002 1 T  D W a n g  Develo p in g a f u zz y  T O P S IS app r o ach  b a sed  on subjective weights and objective weights Expert Systems with Applications 8980-8985, \(2009 18 L  A  Zadeh  F u z z y Sets   Information and Control 8  338-353, \(1965  152 


                        





