Intelligent Data Prefetching for Hybrid Flash-Disk Storage Using Sequential Pattern Mining Technique  Un-Keun Yoon       Han-joon Kim   School of Electrical and Computer Engineering The University of Seoul Seoul, Korea khj, ds5eqe}@uos.ac.kr Jae-young Chang Department of Computer Engineering Hansung University Seoul, Korea jychang@hansung.ac.kr  Abstract This paper presents an intelligent prefetching technique that significantly improves hybrid flash-disk storage a combination of hard disk and flash memory. As a prefetching strategy, we adopt the sequential pattern mining, a variant of 
association rule mining. Our goal is to minimize overall I/O processing time of hybrid storage systems with using the Fully Associated Sector Translation \(F AST\ technique that is known to be the best mapping method in managing flash memory. It is very significant to further enhance the system performance of the hybrid storage when applying FAST to it. In our work, the hybrid storage uses the flash memory as a cache space to improve system performance. With this memory architecture the proposed method is to prefetch objects onto ‘prefetching blocks in the level of both file and block in hybrid storage systems. Through extensive experiments using real UCC data 
and synthetic data, we show that the proposed prefetching method outperforms conventional ones Keywords- flash-disk storage; prefetching; sequential pattern mining; fully-associative sector translation I   I NTRODUCTION  The hybrid flash-disk storage is a new type of storage that includes flash memory storage space in addition to the usual magnetic disk storage [1 N o r m a l l y  fl a s h m e m o r y  embedded in the hybrid storage acts as a storage ‘cache space, holding frequently accessed data. For example, a hybrid storage HM12HII/DOM made by SAMSUNG company has 256Mbytes of flash memory space with 
120Gbytes of HDD. Flash memory has prospective features useful to a storage system which enable it to provide much better performance than hard disks. Flash memory is nonvolatile solid-state memory with a number of powerful features; recently, its density and I/O performance have improved to a level at which it can be used as a mass storage in general computing systems. It is as fast as DRAM in reading operations and much faster than a hard disk in writing 1 Also, flash memory is more scalable than DRAM due to its simple cell structure and insensitivity to cell failure. These features enable the creation of a large memory space. However, since the flash memory still costs much 
    Corresponding author 1 It has been reported that read operations in NAND-type flash memory takes about 15  s and write operations take about 200  s per sector typically, 512bytes higher than HDD in terms of price 2 it is now hard for flash memory to replace conventional HDD. Hence, the hybrid flash-disk storage device that combines relatively smaller space of flash memory with HDD has been suggested [1, 2   Due to the numerous advantages of flash memory, the hybrid 
storage has a great possibility to replace conventional hard disks [3  In order for the hybrid storage to be used as a mass storage, it is necessary to develop high-level management skills fit for the storage [4, 5  Fo r th e ef f i cien t m a n a g e m e n t  of the hybrid storage, we assume that the hybrid storage system uses the ‘Fully Associative Sector Translation FAST\ technique [6 th at is k n o w n to  b e th e b e st m a p p in g  method in managing flash memory as a kind of Flash Translation Layer \(FTL\ Here, flash memory space consists of ‘data’ blocks and ‘log’ blocks. The FAST technique can effectively handle sequential accesses while highly utilizing log’ block space because sequential access is inherently 
frequent in flash memory space. Thus, to enhance the FASTbased hybrid storage systems, we utilize the sequential pattern mining [7  a var i a n t o f  a ssoc i a t i o n r u l e m i ni ng  which is to extract sequential patterns with time information from large-scale sequence data. The sequential patterns can contribute to greatly improving I/O speed of hybrid storage systems through prefetching operations In our work, we assume that the hybrid storage considers the flash memory space as a cache space including prefetching area under the FAST scheme. We propose a new way of ‘two-level’ prefetching technique that is to prefetch some objects to be accessed in the future onto ‘prefetching 
area at both file- and block-levels according to sequential access patterns. We have found that there exist significant sequential patterns for file references as well as block references after analyzing real UCC \(User Created Contents trace data. This observation implies that we can predict future access patterns almost perfectly, and can achieve successful prefetching    2 The flash memory costs $8~9 for 1Gbyte and in contrast the HDD costs 0.16 for 1Gbyte in 2008 
9th IEEE/ACIS International Conference on Computer and Information Science 978-0-7695-4147-1/10 $26.00 © 2010 IEEE DOI 10.1109/ICIS.2010.19 280 


II  P RELIMINARIES  A  Fully associative sector translation  FAST   In our work, to implement a file system with the hybrid flash-disk storage, we use the ‘fully associative sector translation’ \(FAST\ technique [6 T h i s t e c hni q u e ca n r e d u ce the number of erase operations due to a lot of write operations, and it assumes that flash memory space is composed of ‘data’ blocks and ‘log’ blocks. The log blocks are divided into two areas: one is used for ‘sequential’ writes and the other for ‘random’ writes. This technique uses a combination of sector mapping and block mapping. That is the FAST technique keeps a block-level mapping table and it also performs ‘sector’ mapping within a particular block 3  This technique enables overwrite operations to be minimized compared to other methods When an overwrite operation occurs, FAST determines whether it is a sequential or random overwrite. In case of sequential overwrite operations, FAST allocates one sequential log block and performs the write operation on the block. This block is managed by fully associative sector mapping; one log block contains a pre-defined number of sectors. Several write operations for the same logical sector number \(LSN\n be done in one log block if it has enough free space. Conversely, when all sectors within sequential log block are already used, FAST needs to conduct a socalled ‘switch’ operation in the sequential log block; FAST exchanges it with its data block, erases the data block, and returns the erased data block to a pool of free blocks Secondly, in case of random overwrite operations, FAST allocates random log blocks and performs write operation on the blocks. The switch operation for random log blocks is the same as sequential overwrite operation. In our work, to enhance the FAST scheme in the hybrid flash-disk storage the sequential log block is used to save the prefetched data which is thus called ‘prefetch log block’. However, although we have modified the internal memory architecture of the FAST technique, the procedure of basic I/O operations is the same to that of the original FAST B  Sequential pattern mining The sequential pattern mining \(SPM\is a variant of association rule mining that finds co-occurrence relationships, called association, among data items purchased. The SPM finds frequently occurring events called sequences, with considering the order of events from large-scale sequence data, in applications where orderings are significant [7 F o r ex a m ple, in m a rk et bas k et an aly s is   it is significant to recognize that people buy particular items in sequence, e.g., buying a ‘CANON digital camera’ first and then buying a ‘SAMSUNG color printer’ some time later A sequence is an ordered list of non-empty set of items during a given time interval. We denote a sequence s by <e 1  e 2 e 3 e n where e i is a set of items. For example, the sequence <{i 1 i 2 i 3 i 4 i 5 means that the events    3  Flash memory cannot be updated in situ; its contents must be erased before new data can be stored. The erase operations are executed in a block’ unit: usually, one block consists of 32 sectors  corresponding to the set of items {i 1 i 2 i 3 and {i 4 i 5  happen sequentially in this order. Given a set of sequence data, the problem of sequential pattern mining is to find a set of significant sequential patterns with high support. Here, the support’ for a sequence means the number of records that contain the pattern in a given sequence database. By using such frequently occurring patterns, we can predict which event\(s\ will happen next after a particular event occurs. That is, the SPM technique is used to extract significant sequential patterns from a sequence database of file references for the purpose of prefetching files or blocks before they are actually requested For example, suppose that the file access sequence of Table 1 is given, then from this database, we can discover a frequent sequence F 5 F 4 F 1 where F i represents that an event of accessing a file object F i occurs. In our work, an event is assumed to contain a single access for files or blocks. The pattern F 5 F 4 F 1 means that files F 5 F 4 and F 1 are referenced in the order with high probability \(or support\. Hence, when F 5 is accessed, fetching F 4 and F 1  beforehand onto flash memory space can contribute to speeding up I/O operations. Similarly, from the block access sequence of Table 1, we can discover a frequent sequence  B 2 B 1 where B i represents that an event of accessing a block B i occurs within the same file. Suppose there is a pattern B 2 B 1 then when B 2 is accessed, we can pre-fetch B 1 onto flash memory space Generally, a sequence database of file access trace is very large, particularly in multimedia service server such as UCC User Created Contents\r. Thus, there may be an excessive number of sequential patterns from the large database, even if we try to properly adjust a threshold of minimum support to reduce the number of patterns. As we intend to prefetch file \(or block\objects included in discovered patterns, too many patterns results in degrading I/O performance of the system due to excessive prefetching operations. Hence, in our work, to prefetch an appropriate number of objects onto flash memory, we isolate frequent event pairs \(i.e., a sub-sequence of access pattern\ from discovered patterns. For this, we represent sequential patterns as a graph structure whose edge has its weight information that means the degree occurrence of related subsequence pattern. Eventually, we achieve to minimize overall file I/O processing time by prefetching files \(or blocks 4 to be accessed in the future into a ‘cache’ of flash memory TABLE I  E XAMPLE OF SEQUENCE DATABASE 5  SID File Access Sequence SID Block Access Sequence S 1  S 2  S 3 S 4 S 5  F 5 000S F 4 000S F 3 000S F 1   F 2 000S F 5 000S F 10 000S F 4 000S F 15 000S F 4 000S F 15 000S F 1   F 5 000S F 10 000S F 4 000S F 1   F 2 000S F 5 000S F 5 000S F 4 000S F 2 000S F 1   F 2 000S F 5 000S F 6 000S F 4 000S F 9 000S F 1  S F5 1 S F5 2 S F5 3 S F5 4 S F5 5   B 2 000S B 1 000S B 3   B 2 000S B 1 000S B 3 000S B 4   B 2 000S B 3   B 1 000S B 2 000S B 1 000S B 4   B 1 000S B 2 000S B 3 000S B 1 000S B 5 000S B 1     4  Throughout the paper, we shall call the files or blocks to be prefetched simply ‘objects  5  The files belonging to a sequential pattern are denoted in boldface S F5 1   S F5 5 denote the sequence ID of the blocks accessed within the file F 5   
281 


III  M ANAGEMENT OF HYBRID FLASH DISK STORAGE  A  System architecture 000G Figure 1  The proposed system architecture The hybrid storage system proposed in this paper is illustrated in Fig. 1. This figure shows the process in which the object requested by an application is loaded in main memory; firstly, the application submits a request signal to the hybrid storage manager, which determines whether the requested object exists in prefetch log block with the help of FTL \(or FAST\. If the requested file exists in sequential log block, then it will be loaded in the main memory without referencing hard disk. After the signal is forwarded to the file system, the hybrid storage manager locates files that will be accessed in the near future by looking up sequential patterns discovered. Lastly, promising files are fetched in advance onto prefetch log block in idle times by FTL The hybrid storage manager allows external applications to regard the hybrid storage as the conventional disk storage and it tries to improve I/O performance through prefetching operations. The module is composed of three major components: sequential pattern miner, prefetching controller and file map handler. The sequential pattern miner is responsible for generating the sequential pattern from the past sequences of file reference. The prefetching controller is responsible for fetching selected files onto flash memory space by using sequential patterns before the files are requested afterwards. Lastly, the file map handler is responsible for deciding and managing the number of sector to save the prefetched objects onto prefetch log blocks. Note that files to be prefetched should be stored in the prefetch log blocks against sequential access B  Modification to the FAST scheme for intelligent twolevel prefetching This section describes the modified memory architecture of the FAST scheme, and how objects to be prefetched are actually uploaded onto prefetch log blocks. As shown in Fig 2, to prefetch file objects, the file map handler manages the used-LSN table and the file map table. The file map table contains meta-data information such as file name, size, and LSN information to the memory architecture of the FAST 000G Figure 2  Modification to internal memory architecture of FAST As mentioned before, the prefetch log blocks correspond to the sequential log blocks in conventional FAST technique We assume that the size of page is 10Kbytes. Thus, as seen in Fig. 2, ‘File5.avi’ of 10Kbytes and ‘File4.avi’ of 28Kbytes have one LSN and three LSNs, respectively. When the application requests write operation for the file F 5  referred to as ‘File5.avi’ in the figure\ given the sequential pattern <F 5 F 4 F 1 extracted from Table 1, then the hybrid storage manager interprets the sequential pattern to determine which file objects are prefetched from hard disk According the sequential patterns, the file F 4 referred to as File4.avi’\will be prefetched onto prefetch log block. To prefetch it, FAST would obtain three LSNs such as ‘LSN 8 LSN 7’ and ‘LSN 6’, which are saved in used-LSN table, as seen in Fig. 2. Next, before processing write operations for LSNs 8, 7 and 6, FAST needs to locate physical blocks by referring the block-level mapping table, and then FAST examines whether these LSNs can be stored in prefetch log block. In case of Fig. 2, since all sectors of prefetch log block are currently empty, FAST can write the data for all requested LSNs onto pre-fetch log block. Specifically, since LSN 6 corresponds to prefetched data, LBN is computed by dividing LSN by the number of prefetch log blocks; that is 000 6/3 000 2. And, a sector number is obtained by computing LSN % \(number of prefetch log blocks\, that is 6%3=0. As a result, the data for LSN 6 is saved in the 0th block of prefetch log block area C  Generating sequential patterns In order to locate the files or blocks to be prefetched from hard disks, we use the information of sequential patterns extracted beforehand. The sequential pattern miner extracts time-sequential patterns from a given sequence data of file or block\ references. Given the input data of Table 1, the module can extract a set of sequential patterns such as  F 5 F 4 F 1  Here, we need to clarify which files \(or blocks\ould be prefetched onto flash memory with the extracted sequential 
282 


patterns. It is because a sequential pattern can be utilized with different ways of prefetching. For example, if the sequential pattern F 5 F 4 F 1 is captured, then when F 5 is accessed, both F 4 and F 1 can be prefetched, or when F 5 and F 4 are accessed F 1 is made to be prefetched. Here, we have two considerations. One is that it is necessary to avoid excessive prefetching operations due to many sequential patterns. The other is that checking whether the past sequence of files accessed is matched to all patterns is a big overhead to the prefetching controller. Therefore, our system assumes that accessing an object allows to prefetch only its next object; in other words, for a sequential pattern F i  F i+1 accessing the file F i leads to prefetching only its subsequent file F i+1  According to such a policy for pattern extraction, the final sequential patterns are generated which are submitted to the prefetching controller. Here, to isolate highly significant patterns, we need to carefully adjust a threshold of minimum support; in general, to obtain a best minimum support, we perform the mining activities repeatedly with various values of minimum support D  Prefetching objects from disk using pattern weights The prefetching controller utilizes sequential patterns generated by the sequential pattern miner to determine which objects are prefetched from hard disk. This module keeps a simple data structure to internally process sequential patterns. A set of sequential patterns is represented by a 2dimension array corresponding to its directed graph; since a sequential pattern expresses a sequence of time-orderly events, it can be represented as a directed graph. Each edge of the graph contains the weight of frequency with which its related pair of objects occurs in the set of sequential patterns The weight information is used to choose more significant patterns Note that excessive amount of prefetching can cause too frequent page faults due to limited space of flash memory Such frequent page faults \(or replacements\can be avoided by adjusting the threshold value of pattern weight. We set the threshold of weight to an appropriate value so that frequently accessed objects can reside in the flash space before the request for them and cannot incur page faults. In our empirical results, the optimal threshold value of pattern weight is empirically found to be 2 or 3 TABLE II  P ROCEDURE OF T WO LEVEL P REFETCHING  Procedure  two-level Prefetching  Input: a file f and a set of its blocks B to be requested 1  begin  2  if Size of the requested file 002  then  3  Search the file-level sequential patterns related to the file f  4  Identify a set of file objects F to be prefetched 5   foreach  f  003  F  6  Search the block-level sequential patterns related to the blocks belonging to the file f  7  Identify a set of block objects B to be prefetched 8   if  B is not empty then  9  Prefetch the blocks B onto the prefetch log blocks 10   else Prefetch the file f onto the prefetch log blocks 11   12  End  As mentioned before, we propose the ‘two-level prefetching technique that considers both file-level and block-level with sequential access patterns when prefetching The proposed method proceeds as shown in Table I. When an application requests a particular file, the system first examines whether its size is more than 002 e.g., 1024Kbytes Since the flash memory space is limited in size, too big files are not excluded in prefetching operation. Then, the system searches for a set of pairs of \(file\objects related to the file f  in the set of file-level sequential patterns, and it identifies a set of file objects to be prefetched. Next, we investigate whether there are block-level sequential patterns for each of the candidate files or not. Thus, the system searches for a set of pairs of \(block\ects related to the blocks belonging to the file f in the set of block-level sequential patterns. If such patterns do exist, then the related blocks existing in the sequential patterns will be prefetched onto the prefetch log blocks. Otherwise, the requested file f will be prefetched wholly IV  P ERFORMANCE A NALYSIS  A  Simulator and experiment data As a main measurement in our work, we have used processing time’, which means the time during which the system provides file \(or block\bjects corresponding to I/O requests of applications. As a baseline for performance measurement, we have used the FAST technique combined with Top-N prefetching method, which is denoted as FAST+Top-N. The Top-N prefetching is a simple way of prefetching top-N popular file objects periodically [9  Additionally, we have compared our method with the prefetching method considering only file-level, which is denoted as FAST+File-level. Our proposed method is denoted as FAST+2-level To evaluate our proposed method, we have built a simulator of FAST-based hybrid storage manager with 512Mbytes of flash memory space. The details pertaining to flash memory and FAST technique are described in Table 3 To build the sequential pattern miner, we have chosen PLWAP algorithm [10  t h a t  i s e v a l uat e d t o p e r f or m  b e s t  among various sequential pattern mining algorithms For reliable performance evaluation, we have used two types of data: UCC data and synthetic data. The UCC data have click stream information for one month, in which about two million users requests more than six million files. The size of UCC data is between 4Kbytes and 2Mbytes. The data contains 6 elements: the used date, duration, size, UCC file path name, host IP \(server\ address, and guest IP \(user address. Because many users access only a few files in the UCC data, we have used part of the UCC data in which some users access a large number of files. As another test data, we have synthetically generated a set of various workloads denoted as SYN data\at are characterized by frequent request to diverse files. The size of files is between 1Kbyte and 10Mbytes. The synthetic workloads exhibit certain amounts of locality of file reference. In this paper, to denote the degree of locality, we use the notation similar to that of 11  th at is  y  x This means that x of access requests 
283 


TABLE III  S IMULATION P ARAMETERS  Parameters for Flash Memory Space  Parameters for Modified FAST scheme  NAND Flash Memory Size 512 Mbytes Space for data blocks 192 ~ 414 MB Page Size 512 bytes Space for random log blocks 64 MB Writing speed 210.5 011  Space for prefetch sequential\ log blocks 64 ~ 128 MB Reading speed 200 011  Erasing speed 1.2 sec go to y of the data, and the other \(100x go to \(100y  of the data and thus ‘50:50’ means no locality. Moreover we have conformed to the Zipf’s law to generate the block reference within a particular file. The Zipf's law states that the product of rank number and frequency make up a constant; that is, while only a few blocks within a file are used very often, many or most are used rarely B  Experimental results In our experiment, we have evaluated our proposed method in three aspects. First, it is necessary to determine optimal amounts of training data to develop sequential patterns. Second, in case of using synthetic data, we will investigate how much the locality of reference affects the system performance. Lastly, we need to check the effect which results from adjusting the threshold of pattern weight In principle, we need to check effect which results from changing the size of data block, where the data block means a unit of data transfer; a file consists of a set of data blocks In case of MPEG data, a data block corresponds to GOP Group of Pictures\, whose size is not fixed. However, we have found that the processing time is not greatly dependent upon the size of data block, which implies that our proposed method does not need to have any regard for some special issues depending upon a particular file format 1  Effect of changes in the size of training data We expect that extracted patterns can get more salient as the size of training data get larger. For example, given an extracted pattern F 2 001\027 F 1 for 2,000 training files, one of its related patterns may be F 2 001\027 F 3 001\027 F 5 001\027 F 1 for 3,000 training files This section describes how much the size of training data can affect on performance of prefetching. In general, when developing a prediction model with machine learning algorithms, a larger training data always does not result in developing a better model [6  Fig. 3 shows changes in the processing time as the training data gets larger in size in case of using SYN and UCC data. In this figure, we can see that in order for prefetching to reduce the overall process time, the size of training data had better be greater than some threshold, but excessive amounts of training data causes an increase in process time; this is because excessive amounts of many training data cause pattern over-fitting which leads to prefetch too many files onto flash memory space. In our experiment, the optimal size of training data is 3,500 and 40,000 I/O requests for SYN and UCC data, respectively 2  Effect of changes in locality with the synthetic data This section describes how much the degree of reference of locality can influence on performance of prefetching for SYN data. In our experiment, we have generated the SYN data with three kinds of locality of reference; 2:8, 3:7, 4:6 Fig. 4 shows the processing time according to changes in reference of locality, it shows that our proposed method outperforms the conventional one for all types of locality and 2:8 of locality shows the best performance. On the whole, the processing time decreases as the degree of locality increases  3  Effect of changes in threshold of pattern weight As stated before, lower \(or higher\ threshold value of pattern weight can incur excessive prefetching operations. It is thus important to find the optimal threshold for the best performance   a\In case of SYN data  b\In case of SYN data Figure 3.Changes of processing time from varying the size of training data   Figure 4. Changes of processing time from varying reference of localit y 
284 


Fig. 5 shows the execution time according to changes in the threshold value of weight when using SYN and UCC data. From this figure, we can see that the execution time is greatly influenced by the threshold values. In contrast, in case of file-level prefetching, the change in threshold value of weight does not give a great effect on the execution time For both SYN and UCC data, when the threshold value is set to 2, the proposed method shows the shortest execution time In case of less than 3 \(i.e., prefetching all \(or most of\e objects belonging to the generated sequential patterns excessive prefetching causes a big increase in the execution time. Conversely, as the threshold value becomes higher than the optimal value, the favorable effect from prefetching decreases gradually V  S UMMARY  In this paper, we have proposed an intelligent two-level prefetching method in which sequential pattern mining is incorporated into the FAST-aware hybrid flash-disk storage system. In our work, the hybrid storage uses the flash memory as a cache space, and we focus on prefetching file or block\objects onto prefetch \(or sequential\og blocks to be accessed in the near future through sequential pattern mining. To achieve the best performance, it is very important to determine optimal values in terms of threshold of pattern weight and the size of training data. To be noted is that the proposed method works at the level of file and block objects   b\In case of SYN data   b\In case of SYN data Figure 5: Effect of changes in weight threshold In contrast, previous studies focused on prefetching block-level objects [1 i t h si m p l e he u r i s t i c s e v e n t h o ugh they cannot be applied to hybrid storage systems. On the whole, the proposed two-level prefetching is more effective than file-level prefetching in UCC and the synthetic data Empirical results show that in terms of the execution time the proposed method improves the I/O performance of hybrid storage by about 16% and 18% for UCC and SYN data, respectively, compared to the Top-N prefetching under the FAST scheme. We submit that two-level prefetching can help to significantly enhance the future commercial hybrid storage products. In the future, we plan to study a way of semi-automatically adjusting several parameters such as the weight threshold and the size of training data for sequential pattern mining A CKNOWLEDGMENT  This work was supported by the Basic Research Program through the Korea Science and Engineering Foundation funded by the Ministry of Education, Science and Technology \(Grant Number: R01-2007-000-206490  R EFERENCES  1  Hybrid drive: Wikipedia, http://en.wikipedia.org/wiki/Hybrid_drive 2  S. L. Min and E. H Nam, “Current trends in flash memory technology: invited paper”, Proceedings of the 2006 conference on Asia South Pacific design automation, 2006, pp. 332-333 3  Y.H. Bae, “Design Technique of High Performance Flash Memory SSD \(Solid State Disk\, Journal of Korean Institute of Information Scientists and Engineers, Vol. 25, No. 6, 2007, pp.18-28 4  E. Gal and S. Toledo, “Algorithms and Data Structures for Flash Memories”, ACM Computing Surveys, Vol. 37, No. 2,  2005, pp.138 163 5  H.J. Kim, and S.G. Lee, “An Effective Flash Memory Manager for Reliable Flash Memory Management”, IEICE Transactions on Information and Systems, Vol. 85, No. 6, 2002, pp.950-964 6  S. W. Lee, D. J. Park, T. S. Ching, D. H. Lee, S. W. Park, and H. J Song, “A Log Buffer-Based Flash Translation Layer Using FullyAssociative Sector Translation”, ACM Transactions on Embedded Computing Systems, Vol. 6, No. 3, 2007, pp.18-44 7  R. Agrawal, R. Srikant, “Mining sequential patterns”, Proceedings of the 11th International Conference on Data Engineering \(ICDE'95 1995, pp.3-14 8  P.N. Tan, M. Steinbach, and V. Kumar, Introduction to Data Mining Addison-Wesley, 2006 9  E.P. Markatos and C. Chronaki, A Top-10 Approach to Prefetching on the Web, Proceedings of the INET 98 Conference, 1998   C.I. Ezeife, Y. Lu, and Y. Liu, “PLWAP sequential mining: open source code”, Proceedings of the 1st international workshop on open source data mining \(OSDM’05\, 2005, pp.26-35   M.L. Chiang, Paul C.H. Lee, and R.C. Chang, “Using data clustering to improve cleaning performance for flash memory”, Software Practice and Experience, Vol.29, No.3, 1999, pp.267-290   Z. Li, Z. Chen, S. M. Srinivasan and Y. Zhou, “C-Miner: Mining Block Correlations in Storage Systems”, Proceedings of the 3rd USENIX Conference on File and Storage Technology \(FAST’04 2004, pp.173-186  
285 


composition debugging model, are discussed in details. After the decision table is constru cted through collecting WSDL interface information, composition process specification, and testing execution information rule extraction algorithm in rough set reasoning is used to find the rules associated with system or service failures. In a ddition, the feasibility and effectiveness of our approach are validated by two examples and experiments. At present, we onl y consider the debugging problem for the common Web service system, the fault location for semantic Web services should be further explored in the on-going research A CKNOWLEDGMENT  This work was supported in part by the National Natural Science Foundation of China \(NSFC\under Grant No 60803046, China Postdoctoral Science Foundation under Grant No.2007041 0946, the Science Fo undation of Jiangxi Educational Committee under Grant No. GJJ10433, and the Youth Foundation of Jiangxi University of Finance and Economics. The author is grateful to Qiong Zhang for her warm-heart help, and thanks the anonymous reviewers for their insightful comments R EFERENCES  1 W. Han  Integrating Peer-to-Peer into Web Services Master thesis University of Saskatchewan, 2006  W3C Web S e rvi ces Activit y avai lable fro m  http://www w3.org 2002/ws/, accessed on July 2010  W o rld W i de W e b Cons ortiu m  W3C Web Services Description Language \(WSDL\ Version 1.1 March, 2001. Available at http://www. w3.org/TR/wsdl  W o r l d W i de W e b Consor tiu m  W 3C  Simple Object Access Protocol Version 1.2 April 2007, available at http://www.w3.org/TR/soap12  OASIS WSBP EL Technical Co mm i ttee  Web Services Business Process Execution Language, Version 2.0 available at http://docs oasis-open.org/wsbpel/2.0 /wsbpelv2.0.pdf  M. Aoya m a S Wee rawa rana, H Maruya m a and et al W eb  Services Engineering: Promises and Challenges Proc. of ICSE’02  ACM Press, New York 2002, pp. 647-648  C. Liu L. Fei X Yan, and et al., Statistical Debuggin g: A Hypothesis Testing-Based Approach IEEE Transactions on Software Engineering 2006, vol. 32, no. 10, pp.1-17  W  Dickinson, D. Leon, and A Podgurski, Finding Failures by Cluster Analysis of Execution Profiles Proc. of ICSE’01 2001, pp 339-348  Z. Li and Y Zhou, PRM iner: Automatically Extracting Implicit Programming Rules and Detecting Violations in Large Software Code Proc. of ESEC/ FSE’05 2005, pp. 306-315  M. Renieris, and S. P Reiss, Fault LocalizationWith Nearest Neighbor Queries Proc. of ASE’03 2003, pp. 30-39  C. Liu, Z Lian and J. Han, How Bayesians Debug Proc. of ICDM’06 2006, pp.382-393  G. D. F a tta, S   Leue, and E. St e g antova D iscri m inative Pattern Mining in Software Fault Detection Proc. of SOQUA’06 2006 pp.62-69  M. J Harrold, G. Rotherm e l, K Sayre, and et al., An Empirical Investigation of the Relationship Between Fault-revealing Test Behavior and Differences in Program Spectra Journal of Software Testing Verification and Reliability 2000, vol. 10, no.3, pp. 171-194  D. Jeffrey, N. Gup ta, and R. Gupta Fault Localizatio n Using Value Replacement Proc. of ISSTA’08 2008, pp. 167-178  IBM W e b Services: Taking e-Busi ness to the Next Level White Paper, 2000, available from: http://www.ibm.com/developerworks/cn websphere/ download/pdf/e-businessj.pdf  S. Noikajana, and T. Suwannasart, W eb Service Test Case Generation Based on Decision Table Proc. of the 8th International Conference on Quality Software \(QSIC’08 2008, pp. 321-326  C M a o Per form ing Co m b inator ial Testing on W e b Ser viceBased  Software Proc. of Int’l Conf. on Computer Science and Software Engineering \(CSSE’08 2008, vol.2, pp.755-758  T  Y Chen F.C  Kuo T  H T s e and et al  M eta m or phic T e sting and Beyond Proc. of the 11th International Workshop on Software Technology and Engineering Practice \(STEP’03 2003, pp.94-100  Business Process Managem e nt Initiative Business Process Modeling Language \(BPML November, 2002  W 3 C  OWL-S: Semantic Markup for Web Services Nov. 22, 2004 available from: http://www.w3.org/ Submission/OWL-S  Z. Pawlak, Roug h Set Int’l Journal of Information and Computer Science vol. 11, 1982, pp. 341-356  Jianhua Dai Research on Rough Set Theory and Its Applications in Knowledge Discovery \(Ph. D. Dissertation Library of Wuhan University, 2003, pp. 97104.   \(in Chinese  M Kry szkiewicz, Rou gh Set Approach to Inco m p l e t e Inform ation Systems Information Sciences 1998, vol. 112, pp. 39-49  C  M a o, Slicing W e b Ser vicebased Softwar e Proc. of IEEE International Conference on Service-Oriented Computing and Applications \(SOCA’09 Taipei, Taiwan, December 14-15, 2009, pp 91-98  C M a o X Hu and Y L u  T owards a Softwar e Diagnosis M e tho d  Based on Rough Set Reasoning Proc. of the IEEE 8th International Conference on Computer and Information Technology \(CIT’08  Sydney, Australia, July 811, 2008, pp. 718-723  I   Gr osclaude  M odelbased M o nitor ing of Co m ponentbased Software Systems Proc. of the 15th International Workshop on Principles of Diagnosis 2004, pp. 155-160  L  Ar dissono L  Console A Go y  and et al Enhancing W e b  Services with Diagnostic Capabilities Proc. of the 3rd IEEE European Conference on Web Services 2005, pp. 182-191  X Fu P Z ou  Z   Shang and et al   Fault Diagnosis f o r W e b Ser vice Composition Based on Bayesian NetworkŽ, Computer Applications 2008, vol.28, no. 5, pp. 1095-1097.   \(in Chinese   
299 


        


9 Appendix Fig 6: Forest Cover Types of the U.S. \(Source. USGS National Atlas of US Summary of Forest Cover Type Data Type Multivariate Abstract The forest cover type for 30 x 30 meter cells obtai ned from US Forest Service \(USFS\ Region 2 Resource Information System RIS\ data Data Characteristics The actual forest cover type for a given observatio n \(30 x 30 meter cell\ was determined from US Fores t Service \(USFS\ Region 2 Resource Information System RIS data Independe nt variables were derived from data originally obta ined from US Geological Survey \(USGS\ and USFS data. Data is in raw form \(not scaled\ and contains binary \(0 or 1 columns of data for qualitative independent variables \(wilderness areas and soil types Summary Statistics Number of instances observations 581012 Number of Attributes 54 Attribute breakdown 12 measures, but 54 columns of data \(10 quantitativ e variables, 4 binary wilderness areas and 40 binary soil type variables Missing Attribute Values None 43 


   C4.2 Open GL has excellent documentation that could help the developer learn the platform with ease C4.3 Developer has very little ex perience in working with Open GL platform  For our case study, alternative B i.e. Adobe Director was the most favorable alternative amongst all the three. It catered to the reusability criteria quite well and aimed at meeting most of the desired operational requirements for the system   6. CONCLUSION & FUTURE WORK  The main contribution of this paper is to develop an approach for evaluating performance scores in MultiCriteria decision making using an intelligent computational argumentation network. The evaluation process requires us to identify performance scores in multi criteria decision making which are not obtained objectively and quantify the same by providing a strong rationale. In this way, deeper analysis can be achieved in reducing the uncertainty problem involved in Multi Criteria decision paradigm. As a part of our future work we plan on conducting a large scale empirical analysis of the argumentation system to validate its effectiveness   REFERENCES  1  L  P Am g o u d  U sin g  A r g u men ts f o r mak i n g an d  ex p lain in g  decisions Artificial Intelligence 173 413-436, \(2009 2 A  Boch m a n   C ollectiv e A r g u men tatio n    Proceedings of the Workshop on Non-Monotonic Reasoning 2002 3 G  R Bu y u k o zk an  Ev alu a tio n o f sof tware d e v e lo p m en t  projects using a fuzzy multi-criteria decision approach Mathematics and Computers in Simualtion 77 464-475, \(2008 4 M T  Chen   F u zzy MCD M A p p r o ach t o Selec t Serv ice  Provider The IEEE International Conference on Fuzzy 2003 5 J. Con k li n  an d  M. Beg e m a n   gIBIS: A Hypertext Tool for Exploratory Policy Discussion Transactions on Office Information Systems 6\(4\: 303  331, \(1988 6 B P  Duarte D e v elo p in g a p r o jec ts ev alu a tio n sy ste m based on multiple attribute value theroy Computer Operations Research 33 1488-1504, \(2006 7 E G  Fo rm an  T h e  A n a l y t ic Hier a rch y P r o cess A n  Exposition OR CHRONICLE 1999 8 M. L ease  an d J L  L i v e l y  Using an Issue Based Hypertext System to Capture Software LifeCycle Process Hypermedia  2\(1\, pp. 34  45, \(1990 9  P e id e L i u   E valu a tio n Mo d e l o f Custo m e r Satis f a c tio n o f  B2CE Commerce Based on Combin ation of Linguistic Variables and Fuzzy Triangular Numbers Eight ACIS International Conference on Software Engin eering, Artificial Intelligence Networking and Parallel Distributed Computing, \(pp 450-454 2007  10  X  F L i u   M an ag e m en t o f an In tellig e n t A r g u m e n tatio n  Network for a Web-Based Collaborative Engineering Design Environment Proceedings of the 2007 IEEE International Symposium on Collaborative Technologies and Systems,\(CTS 2007\, Orlando, Florida May 21-25, 2007 11 X. F L i u   A n In ternet Ba se d In tellig e n t A r g u m e n tatio n  System for Collaborative Engineering Design Proceedings of the 2006 IEEE International Symposium on Collaborative Technologies and Systems pp. 318-325\. Las Vegas, Nevada 2006 12 T  M A sub jec tiv e assess m e n t o f altern ativ e m ission  architectures for the human exploration of Mars at NASA using multicriteria decision making Computer and Operations Research 1147-1164, \(June 2004 13 A  N Mo n ireh  F u zzy De cisio n Ma k i n g b a se d o n  Relationship Analysis between Criteria Annual Meeting of the North American Fuzzy Information Processing Society 2005 14 N  P a p a d ias HERMES Su p p o rti n g A r g u m e n tative  Discourse in Multi Agent Decision Making Proceedings of the 15th National Conference on Artifical Intelligence \(AAAI-98  pp. 827-832\dison, WI: AAAI/MIT Press,  \(1998a 15  E. B T riantaph y llo u   T h e Im p act o f  Ag g r e g atin g Ben e f i t  and Cost Criteria in Four MCDA Methods IEEE Transactions on Engineering Management, Vol 52, No 2 May 2005 16 S  H T s a u r T h e Ev alu a tio n o f airlin e se rv ice q u a lity b y  fuzzy MCDM Tourism Management 107-115, \(2002 1 T  D W a n g  Develo p in g a f u zz y  T O P S IS app r o ach  b a sed  on subjective weights and objective weights Expert Systems with Applications 8980-8985, \(2009 18 L  A  Zadeh  F u z z y Sets   Information and Control 8  338-353, \(1965  152 


                        





