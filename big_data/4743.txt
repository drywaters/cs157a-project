Cloud based Big Data Analytics for Smart Future Cities Zaheer Khan University of the West of England Bristol Email Zaheer2.Khan@uwe.ac.uk Ashiq Anjum University of Derby Derby UK Email A.Anjum@derby.ac.uk Saad Liaquat Kiani University of the West of England Bristol Email Saad2.Liaquat@uwe.ac.uk 
Abstract 
ICT is becoming increasingly pervasive to urban environments and providing the necessary basis for sustainability and resilience of the smart future cities Often ICT tools for a smart city deal with different application domains e.g land use transport energy and rarely provide an integrated information 
perspective to deal with sustainability and socioeconomic growth of the city Smart cities can beneìt from such information using Big and often real-time cross-thematic data collection processing integration and sharing through inter-operable services deployed in a Cloud environment However such information utilisation requires appropriate software tools services and technologies to collect store analyse and visualise large amounts of data from the city environment citizens and various departments and agencies at city scale This paper presents a theoretical perspective on the smart cities focused Big data processing and analysis by proposing a Cloud-based analysis service that can be further developed to generate information intelligence and 
support decision-making in smart future cities context 
I I NTRODUCTION With the rapid increase in the presence of Internet of Things IoT and future internet  technologies in the smart cities context   a lar ge amount of data a.k.a Big data is generated which needs to be properly managed and analysed for various applications using a structured and integrated ICT approach The structured approach can be based on a generic process identifying the necessary steps to be followed by using different techniques tools and services These steps may consist of collection storage harmonisation processing visualisation analysis and generation of smart city application speciìc information and knowledge for decision 
making using Cloud-based storage and analysis services Today approximately 75 of the European population lives in urban areas and the urbanisation of the European population is expected to increase over 80 by 2020 A continuous increase in urban population strains the limited resources of a city affects its resilience to the increasing demands on resources and urban governance faces ever increasing challenges Furthermore sustainable urban development economic growth and management of natural resources such as energy and water require better planning and collaborative decision making at the local level In this regard the innovation in ICT can provide integrated information intelligence for better urban management and governance sustainable socioeconomic 
growth and policy development using participatory processes In order to mitigate the above challenges a shift from classical models of top-down governance to new bottom-up approach using ICT support is needed to capture multi-dimensional expert opinions Such an ICT driven urban management can be considered as a step towards transforming cities into smart cities which are deìned as a city which invests in ICT enhanced governance and participatory processes to deìne appropriate public service and transportation investments that can ensure sustainable socio-economic development enhanced quality-of-life and intelligent management of natural resources  
ICT brings a signiìcant change in smart cities governance particularly in terms of improved communication and information services as well as offering the potential to provide citizens with the necessary information to better manage and utilise their surroundings and city resources Similarly these innovative tools provide the urban planners with the necessary intelligence for decision making needed to actively manage the urban environment However the realisation of the requisite knowledge and tools depends on the availability of the underlying data and facilities to process such data Appropriate mechanisms are needed to manage data acquisition using different methods such as remote sensing RFIDs sensor networks smart phones city databases satellite imagery open 
data from governments initiatives Furthermore processing and integration of cross-disciplinary data is needed to get knowledge and intelligence for the sustainability resilience and governance of a city This would also provide the necessary context-aware information services for general public such as public transport services air quality of surrounding environment etc In addition citizens can also participate in information collection such as pertaining to trafìc gridlock detection i.e via crowd sourcing building or household energy usage and environmental sensing related to bio-diversity and green infrastructures Such public participation empowers the general public and raises awareness about their environment and health which can result in behavioural changes for green 
and sustainable healthy city-wide initiatives Smart cities use a v ariety of ICT solutions to deal with real life urban challenges Some of these challenges include environmental sustainability socioeconomic innovation participatory governance better public services planning and collaborative decision-making In addition to creating a sustainable futuristic smart infrastructure overcoming these challenges can empower the citizens in terms of having a personal stake in the well-being and betterment of their civic life Consequently city administrations can provide better urban governance and management by applying these ICT solutions Such ICT enabled 
2013 IEEE/ACM 6th International Conference on Utility and Cloud Computing 978-0-7695-5152-4/13 $26.00 © 2013 IEEE DOI 10.1109/UCC.2013.77 381 
2013 IEEE/ACM 6th International Conference on Utility and Cloud Computing CFP13UCC-USB/13 $26.00 © 2013 IEEE DOI 10.1109/UCC.2013.77 381 
2013 IEEE/ACM 6th International Conference on Utility and Cloud Computing CFP13UCC-USB/13 $26.00 © 2013 IEEE DOI 10.1109/UCC.2013.77 381 


solutions thus enable efìcient transport planning better water management improved waste management new constructions and structural methods for health of buildings and effective environment and risk management policies for the citizens Moreover other important aspects of the urban life such as public security air quality and pollution public health urban sprawl and bio-diversity loss and energy efìciency can also beneìt from these ICT solutions ICT as prime enabler for smart cities transforms application speciìc data into a useful information and knowledge From the ICT perspective the possibility of realisation of smart cities is being enabled by smarter hardware smart phones sensor nets smart household appliances etc which can organise in an Internet of Things IoT and thus become a major source of user and environment speciìc data With the passage of time the volume of data generated from these IoTs is bound to increase exponentially and classiìed as Big data In addition cities already possess land use transport census and environmental monitoring data which is collected from various local often not interconnected sources and used by application speciìc systems but is rarely used as collective source of information i.e system of systems for urban go v ernance and planning decisions Many local governments are making such data available for public use as open data Managing such large amount of data and analysing for various applications e.g future city models visualisation simulations provision of quality public services and information to citizens and decision making becomes challenging without applying appropriate tools and techniques 
OTHERS e.g Waste & water management 
Key Some Possible City Applications Main Pillars of a Smart City Cloud infrastructure and application services Information Flow 
Smart Governance Smart People Smart Mobility Smart Economy Smart Environment Data acquisition and storage Information processing and decision making Informed People Public participation City Management Economic development Transport and CO2 Emission Energy Efficiency Public Health Security Emergency services 
Fig 1 Cross-thematic data management and analysis for variety of smart city applications in Cloud environment In the above context recent emergence of Cloud computing promises solutions to such challenges by facilitating Big data storage and delivering the capacity to process visualise and analyse city data Such an infrastructure level solution can also facilitate the decision makers in meeting the QoS requirements by providing an integrated information processing infrastructure for variety of smart cities applications to support decision making and urban governance Figure 1 depicts our view of the main thematic pillars of smart cities smart people smart economy smart environment smart governance and smart mobility which contribute towards the sustainability of resources and resilience against increasing urban demands The main motive towards developing such a view is to consider a holistic approach for smart cities by providing data acquisition integration processing and analysis mechanisms to synthesize the needed information that can help in enhancing resilience and sustainability of a city Managing data for these thematic domains in a Cloud environment provides the opportunity to integrate data acquired from various sources and process it in acceptable time-frames However it is not straightforward to adopt Cloud computing to deal with smart city applications due to a number of challenges and requirements Our aim here is to discuss a theoretical perspective on how these challenges can be addressed in part by using ICT tools and software services to intelligently analyse and manage the complex Big data of smart cities and by incorporating a suitable Cloud architecture such as the one proposed by 11 12 The remainder of this paper is structured as Section II provides a simple use case of smart cities identifying needs of information processing and knowledge generation A service architecture and design for analytical processing of Big data for smart cities in Cloud environment is presented in Section III In Section IV we conclude our discussion and present future research directions II A N E XAMPLE U SE C ASE S MART T OWN C ENTRE Consider the use case of a city that decides to transform its urban environment by interrelating peoples processes places and technologies There can be number of different scenarios in this context e.g related to urban management water management waste management public administration urban planning policy development citizens engagement environmental sustainability business development and economy energy efìciency transport management public security and health Naphade et al highlight the need of inno v ation in planning management and operation to transform a smart city They argued for a system of systems based approach using a uniìed information model that makes it possible to acquire a complete picture of urban complexity and processes They also present several smart cities application examples and opportunities of using innovative ICT solutions and associated development challenges Similarly Libelium lists 50 sensors-based applications for a smarter world which contribute towards development of a smart future city We will build upon such use cases and brieîy present one hypothetical smart future city use case In most urban settings the town centre can be considered as the core of major socio-economic activities including tourism social business shopping work travelling hubs bus or train stations education colleges/universities and often has residential places as well Typically a number of people commute to the town centre at different times on weekdays mostly for work and over weekends shopping work leisure etc and act as a stimulus to the socioeconomic development These activities also create an environmental footprint that requires enhanced information intelligence to manage and mitigate any negative effects on these town centres For such an urban 
382 
382 
382 


setting to be transformed into a  there is a core requirement of pervasive interconnected communication infrastructure and access to contextual information of its citizens and physical spaces by data sensing processing and generating useful information for different stakeholders for consumption and decision making Amongst many other technologies environmental sensors and smart phones are major source of Big data points in a city environment as these technologies assist in determining presence and location of the objects and in case of smart phones provide a means of information dissemination and consumption as well In order to utilise sensor based information in a more effective way additional digital data including that of city maps road networks pedestrian/cycling tracks cadastre buildings populations census utility services digital elevation model etc are often needed from various city databases to process and utilise the needed information For instance a common scenario can be locating empty parking spaces during peak hours using smart phones For example Libelium smart parking sensors for parking management system http://www.libelium.com/smart parking can provide real time information to motorists in town centres thus saving fuel costs and reduced CO emissions Another scenario can be based on a smart phone application with an interactive and navigable map of the town centre that allows end users e.g citizens or tourists to nd the nearest attraction bank or pharmacy etc Such a smart phone application can also support a feedback mechanism allowing end users to leave comments/annotations e.g complaint fault reporting experience details appreciation etc by clicking on a speciìc point of a map or auto-detected current location using GPS which can be dealt by city government staff A new scenario relies on the information about number of vehicles available on speciìc roads of town centre which can be detected by speciìc counting sensors and/or vehicle tted with GPS devices This information helps in route optimisation by providing a trafìc congestion map in real-time to the citizens who are planning to visit/leave town centre and assist their decision making towards their mode of transport private public and route planning In an alternative scenario a similar kind of information can be collected by processing mobile phone activity data available to mobile service providers to determine sojourn population distribution and mobility patterns which can help transport agencies to tune the frequency of public transport dynamically on speciìc routes of the town centre City councils can also use this information for public consultation by visualising overall socio-economic and environmental impact using web and/or smart phone platforms and engage the public on the development of new policies e.g regarding restricted trafìc zones congestion charges etc and collaborative decision making All the above scenarios indicate that there are numerous possibilities for the development of smart solutions for the smart town centre use case The Cloud-based Big data collection processing and visualisation play a major role in dealing with the scalability issues of data processing power and increasing number of users i.e new scenarios novel use cases size and population of the city etc which can ultimately contribute towards better management decision making and governance In the following section we propose an architecture for Cloud-based Big data analytics focused towards the smart city use cases III D EVELOPING AN A NALYTICAL P ROCESSING S ERVICE This section discusses two elements pertinent to the development of a generic Cloud service for smart city related Big data analysis i design of the Cloud service and ii reusability of existing tools and techniques Such a Cloud-based analysis service can be exploited as model Our guiding design principle for the Cloud-based analysis service is to reuse existing well-tested tools and techniques Therefore we use some architectural concepts from our previous work on Cloud architecture for information intelligence in urban systems 4 
smart town centre Analytics as a Service A Architectural Design of the Cloud Based Big Data Analysis 
Data\002and\002 Metadata\002\(RDF\002 Storage Data\002Acquisition,\002Analysis\002and\002Filtering\002Layer Resource\002data\002mapping\002and\002linking\002Layer Interactive\002Explorer\002Layer Data\002Source\002 Classification CA Data\002Cleansing Intelligent\002Engine Linked\002Data Data\002Browser 
Fig 2 Proposed Architectural Design The system architecture as shown in Figure 2 is divided into three tiers to enable the development of a uniìed knowledge base Each layer represents the potential functionality that we need to meet our objectives The rst requirement in the bottom-up approach of our design is data collection however it is likely that collected data will be in a number of different formats due to heterogeneous data sources Data from heterogeneous sources can be exposed through uniìed service interfaces if its meta-data is known and processed The lowest layer in our architecture deals with this requirement The lowest layer in the architecture consists of distributed and heterogeneous repositories that are subscribed to the system There are two ways data can be retrieved from these repositories First if APIs and services have been implemented by these data providers then data access and retrieval process becomes simple because either an API or a web service can be invoked to retrieve the meta-data and populate the meta-data repository e.g Open Geospatial Consortium OGC compliant web services Alternatively if an API or web service has not been provided by a data provider suitable extractors can be implemented to extract meta-data from these distributed repositories to access the databases when this is needed Apart from these data repositories a major source of data will be connected things or sensor networks that will sense city environment in real-time and provide large data volumes which would also need to be analysed ltered and processed into meaningful information In this respect Nathalie et al 
2 
383 
383 
383 


 introduce the concept of Cloud of things by combining sensor networks in a Cloud environment They abstract the heterogeneity of variety of sensors using semantics and OGC standards such as Sensor Web Enablement SWE Sensor Observation Service SOS SensorML etc and provide useful insights to integrate sensor data in a smart city context Once the meta-data of heterogeneous data sources has been populated into meta-data stores mappings are established between the resources links are generated and the data is made semantically relevant and browse-able The data is then mapped using standardised resource description semantics e.g via an RDF store which has all the necessary links established between artefacts and resources In case of linked services higher level services and mashups can be composed to browse and make use of this data for interesting scenarios The smart links layer nds new scenarios and supports workîows to develop relations that were not possible in the isolated data repositories In the case of linked data databases can be browsed to serve queries and nd events of interest that were not possible without the availability of linked data An intelligent engine top layer will process the data returned from Open APIs available in the linked data and services layers The engine uniìes the data that is available in the linked data and services stores and helps users in submitting queries algorithms and workîows to nd information from the repositories The analysis engine will process the data that is retrieved through the respective Open API implementations once these are invoked by the Explorer Users or third-party services will be able to apply stochastic rules and criteria to generate non-obvious relations and associations based on the content of the linked databases The third layer in the architecture is an interactive Explorer The Explorer will provide a scalable and semantics-aware browsing platform to the meta-data and distributed databases This provides the interactivity and interfaces that users need to browse the information based on their topics of interest submit queries and get access to uniìed resources User can reìne their queries after interpreting the results so that query and analysis algorithm evolution and execution become an interactive process The Explorer will also interact with the intelligent engine to support users in their stochastic analysis and data mining operations to derive and produce new links and relations The system architecture is also based on the following design principles  The information linking browsing and analytics processes will be scalable The aim is to use technologies such as Hadoop MapReduce to scale the analytics engine Machine learning algorithms will be transformed as MapReduce scripts to parallelize the analysis and search processes Similarly stochastic aspects will be converted into MapReduce scripts to scale and optimize the processing activity The system will be capable of both batch and stream mode of data processing to cater for real-time data streams being made available by environment sensor networks and other data services  The architecture will support the low latency and better quality of service goals to give users a great browsing and analysis experience To enable this in-memory storage and analytics approaches will be exploited A high level in-memory storage and Cloud-based processing cluster will be created that will exploit the low latency resources in clustered memories to cut down latencies provide quick results and increase user experience on a distributed system of heterogeneous repositories From system hardware point of view GPU based scheduling resource allocation and optimisation approaches will be used to optimise the data interrogation stochastic processing and browsing operations Overall aim here is not to rely on a particular hardware and to make the system hardware independent  The architecture will exploit open APIs and standards-based technologies First of all this will avoid lock-ins The use of open standards will make the system open so that new tools and technologies which have better functionality and performance can be integrated on demand provided they are standards compliant Secondly the system can be extended to link and integrate new databases The use of open standards will encourage data providers and user communities to join the system resulting in an ecosystem of repositories and planners leading to unprecedented discoveries and interesting scenarios  The system will implement two data acquisition mechanisms depending on whether both an open data schema and its associated API are available from the data provider or not If both data schema and API are accessible deterministic queries can be made to the provider for data acquisition purposes In addition to this a stochastic engine will also play an important role in extracting data from sources by helping the users to nd data sets that may add value to the analysis process This may lead planners or end users to come up with ad-hoc or stochastic queries that are sent to the data sources for a batch like data querying process to assist planners in their quest for knowledge production  The system will process raw data to establish both casual associations and semantic links amongst multiple data sources Analyses will be performed both in batch mode and based on interactive input The latter will be accessed through the Explorer which will be implemented as an open publicly-available web tool The batch mode will be realised by implementing stochastic operations on a Hadoop-based analytic platform A number of data mining and machine learning algorithms will be experimented to produce the stochastic functionality in order to nd events of interests to planners There exists several tools and approaches for large scale data management 17 18 19 and analytics 20 21 in Cloud environment 23 24 25 26 and number of issues in this domain have been identiìed 28 Belo w we 
     
System scalability Low latency Open system principle Data acquisition and management Processing Analysis and Use B Existing Tools and techniques 
384 
384 
384 


Future Gener Comput Syst Wirel Pers Commun Proceedings of the 26th Annual AESOP Congress ITAAC Workshop 2012 Utility and Cloud Computing UCC 2012 IEEE Fifth International Conference on Control Systems and Computer Science CSCS 2013 19th International Conference on Urban sprawl in Europe  The ingored challenge 
 vol 29 no 7 pp 1645Ö1660 Sep 2013  A v ailable http://dx.doi.or g/10.1016/j.future.2013.01.010  D Bandyopadhyay and J Sen Internet of things Applications and challenges in technology and standardization  vol 58 no 1 pp 49Ö69 May 2011 A v ailable http://dx.doi.org/10.1007/s11277-011-0288-5  D Ludlo w and Z Khan P articipatory democrac y and the go v ernance of smart cities in  Ankara Turkey July 2012  Z Khan and S Kiani  A cloud-based architecture for citizen services in smart cities in  2012 pp 315 320  G Suciu A V ulpe S Halunga O Fratu G T odoran and V  Suciu Smart cities built on resilient cloud computing and secure internet of things in  2013 pp 513Ö518  European En vironment Agenc y  Ofìce for Ofìcial Publications of the European Communities 2006 iSBN 92-9167-887-2 
 002 002  002 002 002  002   
OpenStack Apache Cassandra Apache Solr Lynx w3m RapidMiner Data and Meta-data Formats Processing Objects 
represent some well-known tools and techniques which provide necessary foundation for the above architecture System and Database Management http://www.openstack.org will be used to create a scalable and standards compliant cloud infrastructure This will lead to a standard and scalable open source Cloud operating system enabling the system to create and offer Cloud computing services running on standard hardware NoSQL Database will be used as a datastore to elastically organise linked meta-data in the system Linear scalability and proven fault-tolerance on Cloud infrastructure makes Cassandra a viable platform for organising critical data Cassandraês data model offers column oriented schema and powerful built-in caching that will help planners end users in getting the quality of service in exploiting the data in the system Web Resources Extraction http://lucene.apache.org/solr will be used for searching the databases Solr is a standalone enterprise search server with a REST-like API The operations such as full-text search faceted search near realtime indexing dynamic clustering database integration rich document handling and geo-spatial search can be supported through Apache Solr Conìgurable browsers http://lynx.isc org or w3m.sourceforge.net can be used to support the stochastic search engine of the system REST base web service interfaces will be provided to access the meta-data applications interactive and batch as well as the source repositories Data Analysis Tools  Open source data mining toolkit supporting both analytics and visualisation and  which is a functional language adopted by the statistics research community will be exploited for analysis To scale the analyses process Hadoop MapReduce http://hadoop apache.org will be integrated with R and RapidMiner to interrogate and mine the data at scale  Existing metadata formats such as the European Data Model Talis Aspire the Open Library and DBLP as Linked Data will be used to describe and store meta-data extracted from different sources Similar to Ontologies common meta-data format will be deìned using eXtensible Markup Language XML conforming to the Resource Description Framework RDF speciìcation The extensible nature of mark-up language allows new vocabularies to be added as newly discovered associations emerge SPARQL an RDF query language will be used to retrieve and manipulate data stored in Resource Description Framework format  REST XML and JSON will form the foundation of the access and interaction APIs APIês will return data in the following formats i Extensible Markup Language XML and ii JavaScript Object Notation JSON XML and JSON representations of Open APIês will be exploited to make available the data metadata as well the tools for interrogating and visualising the data Open APIês initiatives such as mingle https://mingle.io Bloombergês open market data initiative http://www.openbloomberg.com 2013/02/06/open-api-blpapi-v3-6-x-released and the Guardian Open Platform http://www.theguardian com/open-platform will be evaluated for reuse IV D ISCUSSION AND C ONCLUSION Smart cities provide an opportunity to connect people and places using innovative technologies that helps in better city planning and management At the core of smart cities is the collection management analysis and visualisation of huge amount of data that is generated every minute in an urban environment due to socioeconomic or other activities Smart cities data can be collected directly from variety of sensors smart phones citizens and integrated or linked with city data repositories to perform analytical reasoning and generate required information for decision-making for better urban governance However this requires carefully prepared uniform and integrated information model of cross thematic data in a Cloud environment that will provide the beneìt of developing variety of information services for different city applications Cloud computing provides a great opportunity to manage analyse and process the Big data generated by cities but needs new tools and services to process and analyse city data effectively Our future research work is to develop a prototype in order to identify technical implications and limitations and suggest viable solutions R EFERENCES  J Gubbi R Buyya S Marusic and M P alanisw ami Internet of things iot A vision architectural elements and future directions 
R 
385 
385 
385 


 Open Kno wledge F oundation Open go v ernment data  http opengovernmentdata.org Last Accessed 11 October 2012  IBM P  Zik opoulos and C Eaton  1st ed McGrawHill Osborne Media 2011  M Naphade G Bana v ar  C Harrison J P araszczak and R Morris Smarter cities and their innovation challenges  vol 44 no 6 pp 32Ö39 2011  W  M da Silv a A Alv aro G H R P  T omas R A Afonso K L Dias and V C Garcia Smart cities software architectures a survey in  ser SAC 13 New York NY USA ACM 2013 pp 1722 1727 A v ailable http://doi.acm.or g/10.1145/2480362.2480688  Z Khan D Ludlo w  R McClatche y  and A Anjum  An architecture for integrated intelligence in urban management using cloud computing  vol 1 no 1 2012  M Nathalie P  Symeon P  Antonio and T  Kishor  Combining cloud and sensors in a smart city environment  p 247 2012  Libelium 50 sensor applications for a smarter w orld Get inspired http://www.libelium.com/top 50 iot sensor applications ranking Last accessed 15 Aug 2013  W  Loibl and J Peters-Anders Mobile phone data as source to disco v er spatial activity and motion patterns in  2012  R T olosana-Calasanz J Angel Baares C Pham and O Rana Endto-end qos on shared clouds for highly dynamic large-scale sensing data streams in  2012 pp 904Ö911  S Sakr  A Liu D Batista and M Alomari  A surv e y of lar ge scale data management approaches in cloud environments  vol 13 no 3 pp 311Ö336 2011  N Tcholtche v  L F arid F  Marienfeld I Schieferdeck er  B Dittw ald and E Lapi On the interplay of open data cloud services and network providers towards electric mobility in smart cities in  2012 pp 860Ö867  S De y  A Chakraborty  S Naskar  and P  Misra Smart city surv eillance Leveraging beneìts of cloud data stores in  2012 pp 868Ö876  Oracle Corporation Big data analytics Adv anced analytics in oracle database http://www.oracle.com/technetwork/database/options advanced-analytics/bigdataanalyticswpoaa-1930891.pdf Last accessed 25th Aug 2013  J Y in I Gorton and S Poorv a T o w ard real time data analysis for smart grids in  IEEE 2012 pp 827Ö832  G P an G Qi W  Zhang S Li Z W u and L Y ang T race analysis and mining for smart cities issues methods and applications  vol 51 no 6 pp  2013  Y  Chen S Alspaugh and R Katz Interacti v e analytical processing in big data systems a cross-industry study of mapreduce workloads  vol 5 no 12 pp 1802Ö1813 2012  J Bughin M Chui and J Man yika Clouds big data and smart assets Ten tech-enabled business trends to watch  vol 56 no 1 pp 75Ö86 2010  Rightscale Big data analytics in cloud  http://www rightscale.com solutions/cloud-computing-uses/big-data.php Last accessed 26 Aug 2013  Intel Corporation Big data in cloud con v er ging technologies http://www.intel.com/content/www/us/en/big-data big-data-cloud-technologies-brief.html Last accessed 23 Aug 2013  S S Rajan Cloud analytics four of ferings  http://cloudcomputing sys-con.com/node/1770824 Last accessed 22 Aug 2013  D Agra w a l S Das and A El Abbadi Big data and cloud computing current state and future opportunities in  ACM 2011 pp 530Ö533   Big data and cloud computing ne w wine or just ne w bottles  vol 3 no 1-2 pp 1647Ö1648 2010 
Understanding Big Data Analytics for Enterprise Class Hadoop and Streaming Data Computer Proceedings of the 28th Annual ACM Symposium on Applied Computing Jounral of Cloud Computing Applications Advances Systems and Applications EURASIP Journal on Wireless Communications and Networking Proceedings fo GI Forum Cluster Cloud and Grid Computing CCGrid 2012 12th IEEE/ACM International Symposium on Communications Surveys Tutorials IEEE Local Computer Networks Workshops LCN Workshops 2012 IEEE 37th Conference on Local Computer Networks Workshops LCN Workshops 2012 IEEE 37th Conference on High Performance Computing Networking Storage and Analysis SCC 2012 SC Companion Communications Magazine IEEE Proceedings of the VLDB Endowment McKinsey Quarterly Proceedings of the 14th International Conference on Extending Database Technology Proceedings of the VLDB Endowment 
386 
386 
386 


      012 015    012  012 015    015 015                   012     012       012 012 015 015    012             012     012       012 012 015     012             012     012  015 "\015     012 012    015 015      012 015\012 015 D   012  012      012    015    015 015 015     012 015\012 015  015\015    015 015     012     012  015  015 012     16  2  128  log 2 128  128   015    L symbol  D          012    015    015    012      015\012 015 012\012   015 015    8  128    015   015   015     012  012  012 015    015    012    012\015   012    012   012    012   015       L symbol  L mark   D  log 2 D  D  012 L symbol    015    015 012    8  8  128  log 2 128  128      L symbol  2 L mark  2  D    16+8  128    015   015        012     015 015\015   015 015  015\015  015   012   015 012   012  012  012  012 012\015        012\012  015 015		\015 015   012\012     015   012 012\012 015   0 012  012   012 1	\012   015- \015      015     015  015 015 015  015 2 012 012\015  015  015 2         015\012  012 012\015   012    015  012 0122  2   015 \015 015      015   012 015 \015    015 012\015   015 3    012\012  012 0120 0,	0 012 100 4  015   012\015\012  012 2           015 5  012 015\012  015 6 015\012 \0157   67'\(658&9'+95   015   015  015 012 015        2   9 2  015\012    2    015 015 015\012  012   012 2 \012  012     012   015  015 012  0152     015     015 015  2 015\0122  012\012 0152 015 2  012\0152 012\015 2      015   015 015  015 015\012 012  015  012    012 2 \012  015\012 2\012 015     015   015  015 015\012  015     015   012  015 \015 2 012  10   015\012  012  0  012 015  015 015 012\015  012    012\012   015		\015  015       015 015  015 \015 015 015\012   012 015 012\012 012 015   012\015      015  012    012\012     015       0122    015    012 015     015    012 015 015 015 015 \015 012\015  015 015   012\015   012/2\012\015 2   015\012 2 015 \015 015\012\015 \012 015   015  015\015  015\012\012\0152 015  015   012  0121	\012  012  012    015  012  015  015\015  015		2 012    015 3     015	\012   012      012 015 \015 2\012\015 015    012  015    2=\015 \015   015 015  015 \015   012 012   015 012\012 015    015 \015    2\012\015       015   012 015  015    015 012   015\012 015\012 2    012 0152\012  015        015  015 015  2     015 \015   015 015\012 012\015  015\015.2  012   015  015\015   015  015 015 \015  2  015 2 2    015    92 


  012 015\015 	\015\015 015 012  012  012 015  012\015  012  012 015  012 012 012 015\015 012 012   012 015 012 \012 012 012 012 012 012\015 012 012   012 015  012   012 012  012\015 012  012  012 012\015    012    012 012 012 012 012  012 012 \012\015 015 012 015 012 012    015 012 015 015	\012\015      012 015\012 012  012 012 012\015 012 015 012 015\012   012 012    012 015 012 015     015  012\015    015\012 012 012 015 012 012 012 \012  012  015\015  015 012 015 012  012\015 012  012     015 012   015 012 015 012    012 012 \012  012 015   015 012 015\012  012              0123445201264478  015    012\015    012  015  012       015         012  015  012     012   015   015     015  015     015  015   0  015  1  012  012'\012  2 015  012 015   015  015    3 1  24 012455 5666$-,6   7   1 8#\015  1    012  9  015          015        6  015     9   2 015          015   015  015   6    012\015  012  015  012 015   015  015   6     015  1\015    015  012      012  2      015    012     015 015    0   012\015  1 0129  012\012   015   015   015  015  6\015 6 6      012  015  2 4           015          015   015            A   015 A 012  012   9"	4 1   012#\015   015   1A56+6\015 66   8  1   015 3  2  015   012    015   015  015      1 1   8\015 3   2   B 2	\015    015  015      2	\015  C    012	\015               015 6,6\015  6   015 1 015    D  015 012     B  B 015    012      015*\015     012 015   3 1 E 012\012\015  1\015 F14   A  1 012#"	\015    3 1  24 012455 5""&#GH   015  015    015 F     015    012   012   015*\015     012 015   3 1 E   A  1 012#"	\015 015     8 015  I2 2  015     015  93 


006\003\006 006\003\007 006\003\011 006\003\013 006\003\015 002\003\006 002\003\007 032\033\025\020+\033\034 017\020\021\022\023\024\024\025\026\020 017\020\021\022 023\024\024\025\026\020 032\\032#\(\017\020\021\022 023\024\024\025\026\020 032\033\025\020+\033\034,#\(\027\030\031\022 032\033\031\020\034\031\035 027\030\031\022 032\033\031\020\034\031\035 032\\032#\(\027\030\031\022 032\033\031\020\034\031\035 004%\020\027!\031\030\024\034#&\030'\020#>\024"'\033\026\0309\0201#\031\024#;\033\0353\0201#\032\033"\031\030\031\030\024\034\030\034\025 033\0353\030\034\025 0\004 020\033'\030\034\025 032\020"$\024"'\033\034\027\020#\024$#;\033\0353\030\034\025 
Figure 8 
heuristic to execute BC on just 4 workers in roughly two-thirds the time as the baseline using 8 workers providing users with cost-performance tradeoffs in a pay-as-you-go cloud environment. The automation offered by the adaptive heuristic to the end user also eliminates the guesswork of picking a static baseline or any potential non-uniformity in sampling using the sampling heuristic C  Given the need to run computation as a series of smaller \(optimally sized\at hs, is important to decide when we initiate the next swath. Our initiation heuristics attempt to overlap execution of multiple swaths to flatten the resource \(memory, network, CPU\ usage variations causes by different supersteps within a single swath. In BC and APSP, we observe a triangle waveform with a central peak; this heuristic is not relevant for applications like PageRank with uniform resource usage. Besides improving resource utilization, overlapping consecutive swath iterations also reduce the cumulative supersteps required and thus reduces the total overhead spent on synchronization between supersteps Figure 6 compares the relative performance of our initiation heuristics for the BC application normalized to a baseline approach that runs strictly  non-overlapping iterations. These run on 8 workers Figure 7 shows the corresponding messages transferred between supersteps over time, spanning swath iterations. The initiates a new swath every supersteps while the  performs initiation when it detects a peak in the number of messages exchanged. Static-Nês performance depends on the graph and the value of that is chosen.  If the average shorte st path is greater than  we will be initiating new heur istics before the previous swath has hit its peak, thereby exacerbating the resource demand. If the average shortest path length is well distributed or is \(just\ shorter than it leads to better performance. So 4 for the larger CP graph actually works best. Our dynamic he uristic eliminates this guesswork as it picks the initiation point at runtime without user input or graph preprocessing. Using this dynamic initiation heuristic we achieve up to 24 speedup vs. sequential initiation for the WG graph. The message transfer plot in Figure 7 corroborates this While sequential shows the message transfers peak and fall to zero \(thus showing more variability and poorer utilization\, Static-6 \(which is optimal but handselected\ maintains a higher message rate while dynamic is a bit more conservative, but automated VII E VALUATING I MPACT OF G RAPH P ARTITIONING ON P REGEL NET Our Pregel.NET framework is agnostic to how the graphs are partitioned and assigned to workers. The default mode performs a simple hash over the vertex ID to determine the target worker partition. Several works have shown that intelligent graph partitioning can improve the performance of distributed graph algorithms [19  26 a nd i t is relevant to examine if these benefits carry over to the Pregel/BSP model also METIS is a commonly used strategy that provides good quality in-place partitioning that minimizes edge-cuts across partition  Rec e n t w o rk o n a p pr o x im ate partitioning using a single graph scan offers an alternative for partitioning online as the graph is read from storage P a ge R a nk is o f t e n used in l iter a tur e  to validate the effectiven ess of these partitioning strategies. However, as we have seen, PageRank implemented using Pregel/BSP has a uniform message profile while BC and APSP have a triangle waveform message profile. We analyze the consequence of this on the performance gains from intelligent graph partitioning Clearly, the benefit of partitioning comes in reduced communication time since messages to remote vertices incur additional delay due to serialization and network I/O when compared to in-memory messages sent to local vertices. Since many distributed graph algorithms are dominated by communication rather than computation, partitioning can improve overall performance However, the barrier synchronization model in Pregel/BSP means that the total time spent in a superstep is determined by the slowest worker in the superstep. Hence, the balance of work amongst workers in a superstep is as import ant as the cumulative number of remote messages generated in a superstep. Since vertices communicate with their neighbors along edges in the Pregel/BSP model and partitioning seeks to collocate a majority vertex neighbors in the same partition, there may arise çlocal maximasé in specific partitions where more vertices are active during the course of execution of a graph application. This difference in workload can cause underutilization of workers that wait for over utilized workers at the superstep barrier  
Relative time taken by PageRank, APSP and BC to run on WG and CP graphs partitioned using METIS and Streaming, normalized to Hashing approach. Smaller is better  
  
sequentially Static-N heuristic Dynamic heuristic 
Swath Initiation Heuristics N N N N N  
211 


006 002\006 007\006 010\006 011\006 012\006 013\006 014\006 015\006 016\006 002\006\006 006 012\006\006 002\006\006\006 002\012\006\006 007\006\006\006 007\012\006\006 010\006\006\006 010\012\006\006 011\006\006\006 033\0353\0201 0\004 031"\020\033'\030\034\025 0#8\031\030\026\0309\033\031\030\024\034 004%\020\027!\031\030\024\034#&\030'\020#\(\035\020\027\003 024'2!\031\020\005:AB 033""\030\020"#5\033\030\031 8\031\030\026 006 006\003\012 002 002\003\012 007 007\003\012 010 010\003\012 011 011\003\012 012 0202#\014 0202#\015 031\0202#\016 031\0202#\002\006 0\020\035\035\033\025\020\035#\\020\034\031#-7#\004\033\0273#5\024",\020 0\030\026\026\030\024\034\035 017\020\021\022\023\024\024\025\026\020#;\033\0353\0201#\032\033"\031\030\031\030\024\034\030\034\025 5\006 5\002 5\007 5\010 5\011 5\012 5\013 5\014 006 006\003\012 002 002\003\012 007 007\003\012 010 010\003\012 011 011\003\012 012 0202#\014 0202#\015 0202#\016 0202#\002\006 0\020\035\035\033\025\020\035 020\034\031#-7#\004\033\0273#5\024",\020 0\030\026\026\030\024\034\035 017\020\021\022\023\024\024\025\026\020#0\004&:\#\032\033"\031\030\031\030\024\034\030\034\025 5\006 5\002 5\007 5\010 5\011 5\012 5\013 5\014 006 002\006 007\006 010\006 011\006 012\006 013\006 014\006 015\006 016\006 002\006\006 006 012\006\006 002\006\006\006 002\012\006\006 007\006\006\006 007\012\006\006 033\0353\0201 0\004 031"\020\033'\030\034\025 0#8\031\030\026\0309\033\031\030\024\034 004%\020\027!\031\030\024\034#&\030'\020#\(\035\020\027\003 024'2!\031\020\005:AB 033""\030\020"#5\033\030\031 8\031\030\026 006 006\003\012 002 002\003\012 007 007\003\012 010 010\003\012 011 011\003\012 012 0202#\016 031\0202#\002\006 031\0202#\002\002 031\0202#\002\007 0\020\035\035\033\025\020\035#\\020\034\031#-7#\004\033\0273#5\024",\020 0\030\026\026\030\024\034\035 027\030\031\022\032\033\031\020\034\031\035#;\033\0353\0201#\032\033"\031\030\031\030\024\034\030\034 025 5\006 5\002 5\007 5\010 5\011 5\012 5\013 5\014 006 006\003\012 002 002\003\012 007 007\003\012 010 010\003\012 011 011\003\012 012 031\0202#\016 031\0202#\002\006 031\0202#\002\002 031\0202#\002\007 0\020\035\035\033\025\020\035#\\020\034\031#-7#\004\033\0273#5\024",\020 0\030\026\026\030\024\034\035 027\030\031\022\032\033\031\020\034\031\035#0\004&:\#\032\033"\031\030\031\030\024\034\030\034\025 5\006 5\002 5\007 5\010 5\011 5\012 5\013 5\014 
We evaluate the impact of graph partitioning using the best-in-class METIS partitioner as well as the best heuristic \(linear-wei ghted deterministic, greedy approach partitioner from [26 an d com p a r e  them against a baseline that uses simple of vertices by their IDs. We run PageRank, BC and APSP over the WG and CP graphs on 8 workers for this evaluation. Hash, METIS, and Streaming produce 8 partitions whose percentage of remote edges are 87 18% and 35% for the WG graph and 86%, 17% and 65% for the CP graph; smaller this number, lower the edge cuts across partitions, and METIS proves a low edge cut for both graphs. Given the large sizes of the graphs, we run these experiments on the same set of vertices as our other experiments \(50 vertices for CP and 75 vertices for WG\. We report these results when using Pregel.NET without our swath heuristics however, the trends we observe are consistent even with heuristics turned on, though the absolute performance is uniformly better Figure 8 shows the relative time taken when using the METIS and streaming partitioning normalized to hashing for PageRank, BC and APSP running on WG and CP. We see that the WG graph sees a relative improvement of nearly 42-50% for METIS for the three applications, while this improvement drops to 24-35 for the streaming partitioning. When running Pregel.NET with heuristics turn ed on, we see a best case improvement of 5x in relative time taken by METIS for BC on WG compared to hashing \(graph not shown These are consistent with results reported in  However, we also see that the CP graph does not show such a marked improvement in performance due to better partitioning, despite its edge cut ratios from different partitioning being similar to WG. In fact hashing is faster than METIS and Streaming for APSP on this graph. It is worthwhile to investigate this consistent lack of improvement for the CP graph as opposed to WG. Figure 9 shows the runtime for BC broken into compute+I/O time and the synchronization barrier wait time components for the WG graph and Figure 12 does the same for CP. The plots also show the VM utilization %, calcul ated as the time spent in compute and I/O communication against the total time including barrier wait time\ on the secondary Y-axis We see that the VM utilization % for hashing is higher though the total time taken is also higher, for both WG and CP. METIS shows the inverse property, having lower utilization but also lower total time. This is explained by looking at the number of messages emitted by workers in a supe rstep for both hashing and METIS, shown in Figures 10 and 11 for WG, and in Figures 13 and 14 for CP. We expect that a hashed assignment of vertices to a partition would spread communication roughly evenly over all workers, while also increasing the number of remote communications required. The latter contributes to the increased total time while the former leads to a uniform number of    
Figure 9 Figure 10 Figure 11 Figure 12 Figure 13 Figure 14 
 taken for BC on a subset of with  shows the ratio of Compute+I/O time to total time   transferred by each worker in the peak supersteps of BC performed over using    transferred by each worker in the peak supersteps of BC performed over       taken for BC on a subset of with  shows the ratio of Compute+I/O time to total time   transferred by each worker in the peak supersteps of BC performed over using    transferred by each worker in the peak supersteps of BC performed over   
in-place streaming hashing 
Total time WG graph different partitioning Utilization Number of messages WG graph Hash partitioning Number of messages WG graph using METIS partitioning Total time CP graph different partitioning Utilization Number of messages CP graph Hash partitioning Number of messages CP graph using METIS partitioning 
212 


Bottom Top A B 
Figure 15 Figure 16 
messages seen for all workers in a superstep \(Figures 10 and 13\. When looking at the messages sent by workers in a superstep for METIS, we see that there are message load imbalances within work ers in a superstep, caused due to concentration of vertices being traversed in that superstep in certain partitions This variability is much more pronounced in CP as compared to WG \(Figures 11 and 14\ E.g. in superstep 9 for CP, twice as many messages \(4M\ are generated by a worker compared to another \(2M\.  For Pregel BSP, the time taken in a superstep is determined by the slowest worker in that superstep. Hence increase d variability in CP causes even çgoodé partitioning strategies to cause an increase in total execution time wh en using the Pregel/BSP model VIII A NALYSIS OF E LASTIC C LOUD S CALING  Cloud environments offer elasticity Ö the ability to scale-out or scale-in VMs on-demand and only pay for what one uses [28   On th e f l i p s i de  on e en ds u p  paying for VMs that are acquired even if they are underutilized. We have already shown the high variation in compute/memory resources used by algorithms like BC and APSP across different supersteps. While our earlier swath initiation heuristics attempt to flatten these out by overlapping swath executions, one can consider leveraging the cloudês elasticity to, instead, scale up and down the concurrent workers \(and graph partitions\ allocated in each superstep The peak and trough nature of resource utilization combined with Pregel/BSPês synchronous barrier between supersteps offers a window for dynamic scaleout and Öin at superstep boundaries. Peak supersteps can greatly benefit from additional workers, while those same workers will contribute to added synchronization overhead for trough supersteps We offer an analysis of the potential benefits of elastic scaling by extrapolating from observed results for running BC on WG and CP graphs, using four and eight workers.  To provide a fair and focused comparison, we turned off swath heuristics in favor of fixed swath sizes and initiation intervals Figure 15 \(Bottom\ plots the speedup of BC running on eight workers when normalized to BC running on four workers, at corresponding supersteps.  The number of workers does not impact the number of supersteps We also plot the number of active vertices \(i.e. vertices still computing for a given swath\these supersteps which is a measure of how much work is required \(Fig 15 \(Top\. We find that we occasionally get superlinear speedup spikes \(i.e. >2x\ that shows a strong correlation with the peaks of active messages, for both WG and CP graphs. At other times, the sp eedup is sublinear or even a speed-down \(i.e. <1\responding to inactive vertices.  The superlinear speedup is attributable to the lower contention and reduced memory pressure for 8 workers when the active vertices peak \(similar to what we observed for the swath initiation heuristics Similarly, the below par speedup during periods of low activity is contributed by the increased overhead of barrier synchronization across 8 workers. Intuitively, by dynamically scaling up the number of workers for supersteps with peaking active vertices and scaling them down otherwise, we can leverage the superlinear speedup and get more value per worker Using a threshold of 50% active vertices as the threshold condition for between 4 and 8 workers in a superstep, we extrapolate the time per superstep and compared this to the fixed 4 and 8 worker runtimes. We also compute the best-case run time using an çoracleé approach to i.e. for each superstep, we pick the minimum of the 4 or 8 workerês time.  Note that these projections do not yet consider the overheads of scaling, but are rather used to estimate the potential upside if we had an ideal or an automated heuristic for scaling. The total time estimates for running BC on WG and CP graphs, normalized to  
 plot shows speedup of 8 workers relative to 4 workers, for each superstep, when running BC on WG and CP graphs plot shows the number of vertices active in that superstep Estimated time for BC using elastic scaling, normalized to time taken for 4 workers. Normalized cost is shown on secondary Y axis WG graph shown on left CP graph shown on right. Smaller is better 
022\011 022\010 022\007 022\002 006 002 007 006 002 007 010 011 012 013 014 015 006 006\003\002 006\003\007 006\003\010 006\003\011 006\003\012 006\003\013 006\003\014 006\003\015 006\003\016 002 027\031\030\037\020#@\020"\031\030\027\020\035 0201!2#\024$#\015#5\024",\020"#\017\003"\003\031\003#\011#5\024",\020"\035 024"'\033\026\0309\0201#\\031\020 2 035#\032\020"#+!\034 017\020\021\022\023\024\024\025\026\020 027\030\031\022\032\033\031\020\034\031\035 017\020\021\022\023\024\024\025\026\020#?#/\027\031\030\037\020#@\020"\031\030\027\020\035 027\030\031\022\032\033\031\020\034\031\035#?#/\027\031\030\037\020#@\020"\031\030\027\020\035 036\030\034\020\033"#\\0201!2 006 006\003\007 006\003\011 006\003\013 006\003\015 002 002\003\007 006 006\003\002 006\003\007 006\003\010 006\003\011 006\003\012 006\003\013 006\003\014 006\003\015 006\003\016 002 011#5\024",\020 B\034\0267 015#5\024",\020 B\034\0267 1\0332\031\030\037\020 030\034\025 1\0332\031\030\037\020 036\024\017\020 024!\0341 024\035\031#>\024"'\033\026\0309\0201#\031\024#\011#5\024",\020"#.\024\035\031 017\020\021\022\023\024\024\025\026\020#+!\034\022&\030'\020#>\024"'\033\026\0309\0201#\031\024#\011#5\024",\020"#&\030'\020 011#5\024",\020"#&\030'\020 015#5\024",\020"#&\030'\020 024\035\031 006 006\003\007 006\003\011 006\003\013 006\003\015 002 002\003\007 002\003\011 002\003\013 006 006\003\002 006\003\007 006\003\010 006\003\011 006\003\012 006\003\013 006\003\014 006\003\015 006\003\016 002 011#5\024",\020 B\034\0267 015#5\024",\020 B\034\0267 1\0332\031\030\037\020 033\026\030\034\025 1\0332\031\030\037\020 036\024\017\020 024!\0341 024\035\031#>\024"'\033\026\0309\0201#\031\024#\011#5\024",\020"#.\024\035\031 027\030\031\022\032\033\031\020\034\031\035#+!\034\022&\030'\020#>\024"'\033\026\0309\0201#\031\024#\011#5\024",\020"#&\030'\020 011#5\024",\020"#&\030'\020 015#5\024",\020"#&\030'\020 024\035 031 
 
dynamically scaling ideal scaling 
Our hypothesis is that an intelligent adaptive scaling of workers can achieve a similar performance as a large, fixed number of workers, but with reduced cost 
213 


Nature Nature Ecological Applications Nature ACM International Conference on Management of Data \(SIGMOD In Parallel Object-Oriented Scientic Computing \(POOSC Science Communications of the ACM ACM Workshop on Mining and Learning with Graphs Communications of the ACM HotCloud Proceedings of the 19th ACM International Symposium on High PErformance Distributed Computing HPDC Knowledge and Information Systems KAIS International Conference on Computational Science IEEE International Conference on Cloud Computing Technology and Science ACM/IEEE Conference on Advances in Social Network Analysis and Mining \(ASONAM IEEE International Parallel and Distributed Processing Symposium \(IPDPS International Conference on Distributed Computing and Networking Journal of Mathematical Sociology International Conference on Parallel Processing Communications of the ACM 
 
observed time taken using 4 workers, are plotted in Figures 16\(A\ and 16\(B We see that our dynamic scaling heuristic using the percentage of active vertices achieves nearly the same CP\ or better \(WG\ performance as a fixed 8 worker approach. Clearly there is benefit of using fewer workers for low utilization su persteps to eliminate the barrier synchronization overhead. Also, the dynamic scaling heuristic performs almost as well as the ideal scaling. Finally, when we consider the monetary cost of the proposed approaches, assuming a pro-rata normalized cost per VM-second plotted on the secondary Y axis, we see that dynamic scaling is comparable \(CP\ or cheaper \(WG\ than a 4 worker scenario while offering the performance of an 8 worker deployment IX C ONCLUSION  In conclusion, we introduce optimization and heuristics for controlling memory utilization and show they are critical to performance.  By breaking computation into swaths of vertices and using our sizing heuristics we achieve up to 3.5x speedup over the maximum swath size that does not cause the a failure.  In addition overlapping swath executions can provide a 24% gain with automated heuristics and even greater speedup when a priori knowledge of the network characteristics is applied This evaluation offers help to eScience users to make framework selection and cost-performancescalability trade-offs. Our he uristics are generalizable and can be leveraged by other BSP and distributed graph frameworks, and for graph applications beyond BC. Our work uncovered an unexpected impact of partitioning and it would be worthwhile, in future, to examine the ability to pred ict, given certain graph properties, a suitable partitioning model for Pregel/BSP It may also be useful to perform such evaluations on larger graphs and more numbers of VMs. At the same time, it is also worth considering if non-linear graph algorithms are tractable in pr actice for large graphs in a distributed environment B IBLIOGRAPHY  1  F  L i lj er os C   Ed l i n g L  A m a r a l H  S t an ley   and Y    berg The web of human sexual contacts 
vol. 411, pp. 907908, 2001   H Je o n g  S   Ma so n A  L   B a ra b s i  a nd Z   Oltva i  L e t ha l i t y  and centrality in protein networks vol. 411, pp. 41-42 2001   O. B o din and E   E s t r ada    U s i n g n e t w ork c e nt r a l i t y  m e a s ures t o  manage landscape connectivity vol 18, no. 7, pp. 1810-1825, October 2008   D. W a ts s  and S  S t r ogat z  C olle c t i v e  d y nam i cs of  s m a ll-w orl d   networks vol. 393, no. 6684, pp. 440Ö442, June 1998   G  Ma lew i c z   M A u s t er n A   Bik  J   Dehn er t I  Hor n   N. L e i s er and G. Czajkowski, "Pregel: A system for large-scale graph processing," in 2010   D. G r egor  and A  L u m s dain e  T h e  pa r a llel  B G L  A gen e r i c  library for distributed graph computations," in 2005   B. S h a o  H. W a n g  and Y  L i T he T r init y G r aph E n g i n e    Microsoft Research, Technical Report MSR-TR-2012-30, 2012   A  F ox  C lo ud c o m putin g w h at  s  in it for m e  as  a  s c i e n tis t     vol. 331, pp. 406-407, 2011   S. G h e m a w a t  and J  De an   Map re duc e s i m p lifi e d data  processing on large clusters vol 51, no. 3, pp. 107-113, 2008   J  L i n and M. S c hat z   Des i g n  patt er n s  for eff i ci ent gr aph algorithms in MapReduce," in 2010   L   Va l i ant   A b r id g i n g m o d e l f or pa r a llel com putati o n  vol. 33, no. 8, pp. 103-111, 1990 12 a c h e  Ha ma    O n l i n e    http://hama.apache.org   13 Ap a c h e  Ha d o op    O n l i n e    http://hadoop.apache.org     M Z a h a r i a, M. Ch ow dhu ry M F r ank l in S  S h e n k e r, and I   Stoica, "Spark: Cluster Computing with Working Sets," in 2010   J  Ekana y ak e e t a l     T w i st er A  r untim e f o r it er ati v e  MapReduce," in Chicago, 2010, pp. 810-818   U. K a n g  C  T s o u rakakis   and C. F a l outs o s  Peg a s us   Minin g  Peta-scale Graphs," in 2010   M. P a c e  B S P vs  MapR e duc e    in vol. 103.2081, 2012   S. Seo  E  Yoo n, J  K i m  S  J i n  J-S. K i m   and S   Ma e n g HAMA: An Efficient matrix computation with the MapReduce framework," in 2010, pp. 721-726   S. S a l i h ogl u  and J  W i d o m  G PS A G r a ph P r oc e s s i n g Sy s t em    Stanford University, Technical Report 2011   R L i cht e n w a l t e r and N   Cha w la D is Ne t  A fr am ew ork for  distributed graph computation," in  2011   K  Maddu r i  D. E d i g er K   J i an g  D. Bad e r  and D  Cha v a r riaMiranda, "A faster parallel algorithm and efficient multithreaded implementations for evaluating betweenness centrality on massive datasets," in 2009   E  K r e p s k a, T  K i el m a nn, W  F o kkink, H   Ba l, "A  hi g h level framework for distributed processing of large-scale graphs," in 2011, pp. 155-166   L   Pa ge  S  B r in R. M o t w ani and T  W i nogr ad  T h e P a geRank citation ranking: Bringing order to the web," Stanford InfoLab Technical Report 1999-66, 1999   U  Brand  s  A f a s t er  a l gor ith m for  b e t w eenn e s s c e nt r a l i t y    vol. 25, no. 2, pp. 163-177 2001   Stan fo r d  Net w or k A na l y s is Pro j e c t  O n l in e    http://snap.stanford.edu    I  S t ant o n and G  K l i o t, "S t r e a m i n g G r aph P a rtiti o n in g  for L a rge Distributed Graphs," Microsoft Corp., Technical Report MSRTR-2011-121, 2011   G   K a ry pis and V   K um a r A fas t and hi g h qua l i t y m u l t i l evel scheme for partitioning irregular graphs," in 1995, pp. 113-122   M. A r m b r u s t e t  a l   A v i ew of  c l o u d  c o m putin g    vol. 53, no. 0001-0782, pp. 50-58 April 2010  
214 


  13  or gani c  c he m i s t r y  i n our  Sol ar  Sy s t e m       Xi a n g  L i r e c e i v e d h i s B  S   m is tr y  fr o m  th e  P e k in g  U n iv e r s ity  C h in a  in  2 0 0 3  and P h D   i n P hy s i c al  C he m i s t r y  f r om  t he  J ohns  H opk i ns  Un i v e r s i t y  i n  2 0 0 9   He  h a s  b e e n  a  R e s e a r c h  A s s o c i a t e  wi t h  a  j o i n t  a p p o i n t m e n t  a t  t h e  U n i v e r s i t y  o f  M a r y l a n d   Ba l t i m o r e  C o u n t y  a n d  N AS A G o d d a r d  S p a c e  Fl i  Ce n t e r  s i n c e  2 0 1 1   H i s  r e s e a r c h  f o c u s e s  o n  t h e  d e t e c t i o n  of  t r ac e  e l e m e nt  and as t r obi ol ogi c al l y  r e l e v ant  or gani c  mo l e c u l e s  i n  p l a n e t a r y  s y s t e ms   l i k e  M a r s   He  i s  es p eci a l l y i n t er es t ed  i n  t h e d evel o p m en t  o f  T i m e of  and I on T r ap m as s  s pe c t r om e t e r s w i t h v a r i o u s i o n i z a t i o n  ng te c h n iq u e s   Wi l l  B r i n c k e r h o f f  sp a c e  sc i e n t i st  i n  t h e  Pl a n e t a r y  En v i r o n m e n t s  La b  a t  N A S A  s  G o d d a r d  Spac e  F l i ght  C e nt e r  i n Gr e e n b e l t   M D w i t h  pr i m ar y  r e s pons i bi l i t y  f or  th e  d e v e lo p m e n t o f th e  L D TO F  m a s s  s p e c t r o  th is  p r o je c t H e  h a s  fo c u s e d  re c e n t l y  o n  t h e  d e v e l o p m e n t  o f  m i n i a t u re  l a se r d ma s s  s p e c t r o me t e r s  f o r  f u t u r e  p l a n e t a r y  mi s s i o n s  a l o n g  wi t h  b a s i c  e x p e r i m e n t a l  r e s e a r c h  i n  a s t r o b i o l o g y  a n d  p r e bi ot i c  s y nt he s i s   D r   B r i nc k e r hof f  i s  i nv ol v e d i n t he  de v e l opm e nt  of  m as s  s pe c t r om e t e r  f or  bot h t he  2011 Ma r s  S c i e n c e  L a b o r a t o r y  a n d  t h e  2 0 1 8  E x o Ma r s  mi s s i o n s   


  14   


Copyright © 2009 Boeing. All rights reserved  Issues and Observations Initial load of one day of data ~ 7 hours Optimizations  Write data in batches  Use a mutable data structure to create data strings  Deploy a higher performance machine  Use load instead of insert  Use DB2 Range-Partitioned tables  Database tunings Time reduced from 7 hours to approx 30 minutes 


Copyright © 2009 Boeing. All rights reserved  Optimizations Use a mutable data structure to create data strings  Original application created the SQL statement by appending elements to a Java String  It was taking five hours \(of the seven hours Strings  Instead Java StringBuilder used  Java Strings immutable  Time savings of 71.4 


Copyright © 2009 Boeing. All rights reserved  Optimizations Deployed on a higher-performance machine  Application ported from IBM Blade Center HS21 \(4GB of RAM and 64-bit dual-core Xeon 5130 processor to Dell M4500 computer \(4GB of RAM and 64-bit of quad-core Intel Core i7 processor  Reduced the time to thirty minutes Bulk loading instead of insert  Application was modified to write CSV files for each table  Entire day worth of data bulk loaded  Reduced the time to fifteen minutes 


Copyright © 2009 Boeing. All rights reserved  Optimizations Range-Partitioned tables \(RPT  To limit the size of tables, the original code created multiple tables per table type  This puts burden on the application to query multiple tables when a range crosses several tables  With RPT, user is not required to make multiple queries when a range crosses a table boundary  Increased the time to thirty minutes  Additional fifteen minute cost per day of partitioning enabled time savings during queries 


Copyright © 2009 Boeing. All rights reserved  Optimizations Database tunings  Range periods changed from a week to a month  Automatic table space resizing changed from 32MB to 512KB  Buffer pool size decreased  Decreased the time to twenty minutes Overall, total time savings of 95.2 


Copyright © 2009 Boeing. All rights reserved  20 IBM Confidential Analytics Landscape Degree of Complexity Competitive Advantage Standard Reporting Ad hoc reporting Query/drill down Alerts Simulation Forecasting Predictive modeling Optimization What exactly is the problem What will happen next if What if these trends continue What could happen What actions are needed How many, how often, where What happened Stochastic Optimization Based on: Competing on Analytics, Davenport and Harris, 2007 Descriptive Prescriptive Predictive How can we achieve the best outcome How can we achieve the best outcome including the effects of variability Used with permission of IBM 


Copyright © 2009 Boeing. All rights reserved Initial Analysis Activities Flights departing or arriving on a date Flights departing or arriving within a date and time range Flights between city pair A,B Flights between a list of city pairs Flights passing through a volume on a date. \(sector, center, etc boundary Flights passing through a volume within a date and time range Flights passing through an airspace volume in n-minute intervals All x-type aircraft departing or arriving on a date Flights departing or arriving on a date between city pair A,B Flights departing or arriving on a date between a list of city pairs Flights passing through a named fix, airway, center, or sector Filed Flight plans for any of the above Actual departure, arrival times and actual track reports for any of the above 


Copyright © 2009 Boeing. All rights reserved  Initial SPSS Applications Show all tracks by call sign 


Copyright © 2009 Boeing. All rights reserved  Predictive / Prescriptive Analytics Use-Case For a given Airspace Volume of Interest \(AVOI compute distinct traffic volume at some point in the future  Aim to alert on congestion due to flow control areas or weather if certain thresholds are exceeded  Prescribe solution \(if certain thresholds are exceeded Propose alternate flight paths  Use pre-built predictive model  SPSS Modeler performs data processing Counts relevant records in the database \(pattern discovery Computes traffic volume using statistical models on descriptive pattern Returns prediction with likelihood 


Copyright © 2009 Boeing. All rights reserved  Predictive / Prescriptive Analytics Use-Case Advanced Arrival Procedures with Active Abatement Potentials   9/23/10  24 Pulls in the TRACKINFO table of MAIN using SQL Limits the data to database entries which fall inside the AVOI Combines the SOURCE_DATE and SOURCE_TIME to a timestamp that can be understood by modeler Computes which time interval the database entry falls in. The time interval is 15 minutes Defines the target and input fields needed for creating the model Handles the creation of the model Produces a graph based off of the model results Final prediction 


Copyright © 2009 Boeing. All rights reserved  Initial Cognos BI Applications IBM Cognos Report Studio  Web application for creating reports  Can be tailored by date range, aircraft id, departure/arrival airport etc  Reports are available with links to visuals IBM Framework Manager  Used to create the data package  Meta-data modeling tool  Users can define data sources, and relationships among them Models can be exported to a package for use with Report Studio 


Copyright © 2009 Boeing. All rights reserved  Flights Departing Las Vegas on Jan 1, 2012 1 of 3 Report shows the departure date, departure and arrival locations and hyperlinks to Google Map images DeparturePosition and ArrivalPosition are calculated data items formatted for use with Google Maps Map hyperlinks are also calculated based on the type of fix 


Copyright © 2009 Boeing. All rights reserved  Flights Departing Las Vegas on Jan 1, 2012 2 of 3 DeparturePosition, Departure Map, ArrivalPosition and Arrival Map are calculated data items \(see departure items below DepartureLatitude DepartureLongitude DeparturePosition Departure Map 


Copyright © 2009 Boeing. All rights reserved  Flights Departing Las Vegas on Jan 1, 2012 3 of 3 


Copyright © 2009 Boeing. All rights reserved  Conclusion and Next Steps Current archive is 50 billion records and growing  Approximately 34 million elements per day  1GB/day Sheer volume of raw surveillance data makes analytics process very difficult The raw data runs through a series of processes before it can be used for analytics Next Steps  Continue application of predictive and prescriptive analytics  Big data visualization 


Copyright © 2009 Boeing. All rights reserved  Questions and Comments Paul Comitz Boeing Research & Technology Chantilly, VA, 20151 office Paul.Comitz@boeing.com 


Copyright © 2009 Boeing. All rights reserved Advanced Arrival Procedures with Active Abatement Potentials   9/23/10  31 


Copyright © 2009 Boeing. All rights reserved Advanced Arrival Procedures with Active Abatement Potentials   9/23/10  32 Backup Slides 


Copyright © 2009 Boeing. All rights reserved  Initial Approach Initial Investigations  Apache Solr/Lucene  Data Warehouse Evaluate Hadoop in the future 


Copyright © 2009 Boeing. All rights reserved  Using SOLR Uncompress Track Information Messages To use with Solr  Transforming track messages from their  original schema to Solr required building a ìkey, valueî list using an XSTL  Queries made against this list of ìkey, valueî pairs Transformation Process  One day of data ~ 4.5 hours Once transformation complete search/query performance very good Geo spatial queries using  unique query language 


Copyright © 2009 Boeing. All rights reserved  Representation Aviation data is frequently represented in more than one form 


