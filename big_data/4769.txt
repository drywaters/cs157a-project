Mining Trafìc Patterns from Public Transportation GPS Data Florin Lipan and Adrian Groza Technical University of Cluj-Napoca Department of Computer Science Baritiu 28 RO-400391 Cluj-Napoca Romania Email orin.lipan@student.utcluj.ro adrian.groza@cs.utcluj.ro Abstract Bus schedules submitted by public transportation companies often lack accuracy Generally this relates to trafìc being inconsistent over most parts of the road network We set on nding a model for predicting these speed variations over GPS monitored bus routes by using association rules and then apply it on the local bus network of Cluj-Napoca Romania Index Terms public transportation GPS eet monitoring association rules trafìc patterns 
I P ROBLEM S TATEMENT One aspect of public transportation that makes up a good premises for data mining is regularity  buses run in cycles laps along the same track attending every station according to a xed schedule or at a given frequency Therefore with every performed cycle this feature will enable us to collect a large amount of information on terrain layout or trafìc If we were to take into account only road features length speed restrictions terrain geometry etc and the daily cycle of buses predicting the schedule of a public transportation system should be possible But often the variations in trafìc make it very difìcult to determine an acceptable approximation to the arrival and departure times Rush hours weekends or holidays 
are common exceptions to the trafìc ow that may be a source of unpredictable behaviour Moreover some features along a bus route like trafìc lights and pedestrian crossings represent for the driver elements of randomness which can be foreseen only with a certain probability Hence a reliable integrated prediction system is needed one that should take into account both the relationship between trafìc events and date  time information as well as the probability of random events like stopping at the trafìc lights The current paper sets on nding a model for speed variations of buses using data mining techniques on collected GPS information from public transportation The goal of this research is to investigate correlations between road features date  time information passenger count etc and speed II T ECHNICAL 
I NSTRUMENTATION The NMEA format is a standard interface developed by the National Marine Electronics Association in the U.S for communications between marine electronic equipment including GPS receivers GPS GGA Global Positioning System Fix Data sentences contain the following information i UTC timestamp in hhmmss.sss format hh hours mm minutes ss seconds sss miliseconds ii and longitude in Dm,H format D degrees m minutes with 4 decimals precision H hemisphere iii GPS quality information 0 for invalid 1 for GPS x or 2 for DGPS x iv number of satellites being tracked v horizontal dilution of the position a measure of GPS accuracy based on the geometry of tracked satellites this attribute assumes a numerical value between 1 and 20 where 1 equals to the highest possible conìdence 
level vi altitude followed by its unit of measure The Haversine formula is used for calculating geographical distances or more explicitly to compute the shortest path between two geographical coordinates on the surface of the globe measured in degrees or radians Let   s  s  and   f  f  be the latitude longitude pair of two points s and f  measured in radians Then the spherical angular distance of the two will be   2 arcsin 
   sin 2    2  cos s cos f sin 2    2  1 where     f   s and     f   s 
 The distance d or arc length for a sphere of radius r and   becomes d  r    III D ATA A CQUISITION Initially GPS devices are mounted on one or several vehicles along the examined bus route The movement of a vehicle is going to be sampled by the GPS receiver at a given time rate thus associating every piece of geographical information latitude longitude altitude with a timestamp The devices should also offer the possibility to communicate with a remote server task usually accomplished by GPRS 3G or radio connections As the GPS device records geographical information it is sent via the remote connection to a central 
processing unit which accomplishes storing prepossessing and analyzing the data Also by the means of this connection the GPS device can be used not only for data mining but also for real time monitoring of the bus eet How long and how often we keep monitoring the activity on a certain bus line is a question of what kind of results we are actually expecting Trafìc generally varies from workdays to weekends and also according to the time of the day e.g rush hours and to seasons e.g snow-days in northern Europe or Monsoon season in India For the latter case our analysis will have to cover the whole year on a regular basis monitoring 978-1-4244-8230-6/10/$26.00 ©2010 IEEE 123 


Fig 1 Cluj-Napoca GPS log over the rst six bus stops of line 35 a couple of days per week for the whole year Both for limited studies as well as in the case of year long surveys the following rules should be considered i the analysis should preferably cover the entire daily schedule on the given route otherwise omitted time periods will be assigned to nearest available data and results for these gaps might be unreliable ii there should be a balance between the number of samples taken on workdays and weekends iii whether we provide GPS coverage for only one bus on the track or for all of them at the end of the survey there should be enough data available to minimize the effect of outliers and technical errors horizontal dilution can be used to lter unreliable information Our experiment focused on the Nokia LD-3W a low-cost Bluetooth GPS device which can be paired up with any Bluetooth  GPRS enabled Java MIDP 2.1 mobile phone We used the popular Nokia 2700 phone For establishing a communication line between the LD-3W module and the mobile device we developed a Java midlet The application accomplishes four main tasks 1 creates and manages a Bluetooth connection between the mobile phone and any GPS device within signal range 2 receives NMEA strings from the GPS device at a given sampling rate between 0.5 seconds and 2 minutes parses this information latitude longitude altitude timestamp signal quality horizontal dilution number of available satellites and appends it to a log le 3 whenever running in LOG MODE at the end of the transmission the midlet converts the log to KML and stores it on the phoneês memory the data is exploited later by the processing unit for data mining purposes 4 whenever running in LIVE MODE every parsed piece of information from the GPS module is sent in real time to a remote server the processing unit  via the GPRS Internet connection of the mobile device IV S YSTEM A RCHITECTURE Fig 2 depicts the architecture of our system On the left side we have the data acquisition system  described on the previous section The processing unit coordinates all data mining activities and is responsible for drawing the actual Fig 2 Top view system architecture TABLE I R AW GPS I NFORMATION   ID Date  Time Latitude Longitude Altitude Dilution 1 2010-03-18 09:10:22 46.755738 23.593575 431.2 2.0 2 2010-03-18 09:10:27 46.755780 23.593848 437.7 2.0 3 2010-03-18 09:10:32 46.755833 23.594278 445.6 2.0 conclusions rules out of the knowledge base It implements RapidMiner methods through the RapidMiner API A Feature Selection and Combination Data acquisition offered us valuable knowledge on the geographical coordinates  latitude  longitude  altitude  of the monitored vehicles associating them to date  time references We can also assess data reliability using the horizontal dilution attribute Table I shows a sample of the initial state of our knowledge base as acquired from KML logs The nality of this research should be nding correlations rules between road features time information bus load etc and the speed variations that actually stop us from assuming a xed bus schedule We shall combine the current knowledge in order to assess new features that would better explain the speed variations By applying the Haversine formula on every two consecutive points we can obtain distance  Correlating this feature with the timestamp reference of consecutive points leads us to speed  which is a determinant attribute to our system Data information can be processed to obtain the day of the week or the season of the year  Altitude difference of two consecutive points could also be of help as speed usually increases over the descent and drops when driving uphill Another interesting feature that can be obtained from the raw GPS data sets is bus station interest  This feature automatically assesses passenger ow at bus stops and is deduced mainly from the time spent by buses loading and unloading passengers in every station The more time a vehicle spends waiting at a particular station the higher the passenger ow  in and out  and subsequently the higher the interest for this station at the given timestamp Just think about the crowding in downtown bus stops at rush hours compared to the ow in suburban stations on weekends In order to automatically label a geographical point as being part of a bus stop we 124 


Fig 3 Labeled clusters resulted from road partioning via k-Means must assume a consistent volume of GPS information For every log we process speed is always going to drop to 0 around bus stations Of course this is also the case of road sections with trafìc lights pedestrian crossings trafìc jams etc However given a consistent knowledge base we are able to make the following observation whilst speed always levels to 0 around bus stops given all stations are mandatory for the bus driver for all other situations this will happen only by a certain probability e.g trafìc lights and pedestrian crossings will generally have random effects trafìc jams only take place at rush hours Thus points which maintain a constant speed of 0 over all GPS logs will be labelled as bus stations and we may calculate their interest feature B Feature Discretization Initially coordinates have been converted to decimal degrees with a 6 decimals precision every 0.000001 decimal degree provides a 0.111 meters accuracy We would like to maintain this precision on every new feature that derives from geographical coordinates like for example speed  Because some data mining algorithms e.g FP-Growth can not process continuous datasets the features need to be discretized First we attend the set of geographical coordinates we want to partition the whole length of the monitored bus route into smaller clusters Each cluster should preferably cover up a road section of 25 50 meters as we would like to approximate speed to this interval rather than to every couple of points The size of the bins will have to vary according to the number of available example sets use smaller bins with higher precision for a large number of examples or use wider bins for less data and consequently less accurate conclusions The clustering operation can be accomplished with k-Means where k will be a function of road length and the number of available example sets  Fig 3 depicts the outcome of clustering the geographical coordinates space using k-Means over 25 bins Other features will be discretized by frequency speed  altitude difference  time of the day  This operation takes as an input the continuous set of data and the number of bins to create which is a function of the number of examples  the feature type and the expected result accuracy  Areas with high TABLE II D ISCRETIZED D ERIVED F EATURES   ID WD/WE Minute  Day Speed Road Cluster 1 wd range3 543 range5 7.35 16 2 wd range3 543 range6 12.46 16 3 wd range3 543 range7 18.39 18 information density will contain narrower more accurate bins whilst sections with less data available will have wider bins If there are large amounts of data available to us we can afford a high number of bins otherwise precision will have to suffer Attributes like day of the week and season of the year can be discretized by speciìcation For example days can be divided into workdays and weekends A sample of such discretized features is depicted in Table II where wd stands for work day Note that this information is deduced from the raw data presented in Table I Road clusters relate to g 3 C Finding Association Rules We have selected and discretized the features that best relate to the speed variations on our track Now we want to be able to draw some conclusions out of this information We are going to use association rules  The FP-Growth algorithm will help us identify frequent itemsets Minimum support value for FP-Growth needs to be adjusted according to the number of available example sets but also to the size of the bins generated through discretization and to the data reliability degree we are aiming for We suggest using the following formula in order to estimate the minimum support minsup  N  f 1  f  bins f  2 where N is the number of selected features and  bins f  is the number of bins partitions created for feature f  Variable  f depicts the degree at which examples are equally distributed within the bins of feature f  It takes values between 1 the highest degree of equal distribution and  bins f  the lowest degree If we strive to balance the number of examples among all time intervals and all road clusters  time and  road should be closer to 1  However there are other features to which this kind of approach would be nonsense For example itês highly impossible that we are going to get an equal distribution of all ranges of speeds over the same road section Variable  speed will probably be closer to  bins speed  in this case After having generated frequent itemsets they are fed to the association rules operator which takes the minimum rule conìdence as an argument The result of this operation is a set of rules based on frequent itemsets Because our initial goal was to infer the causes of speed variations we are only interested in rules that take speed as a conclusion V R ESULTS Fig 1 shows the rst six bus stops of bus line 35 based on satellite imagery of Cluj-Napoca Romania 42 GPS logs have been acquired on this track corresponding to 42 different 125 


Fig 4 Knowledge representation for 42 GPS logs TABLE III A SSOCIATION R ULES INFERRED OVER LINE 35  No Premises Conclusion Support Conìdence 1 road cluster  10 speed  0.047 0.351 2 road cluster  1 day  wd time  speed  0.001 0.238 3 road cluster  1 day  wd time  speed  0.001 0.352 4 road cluster  6 day  wd speed  0.014 0.779 5 road cluster  23 day  wd speed  0.016 0.338 6 road cluster  16 time  speed  0.004 0.221 bus rides All 4747 points contained within these logs have been plotted on g 4 bus stops are labeled using numbers and speed is represented over the Z-axis as well as in colours This graph conìrms our observations on speed variations One of the rides has also been depicted with g 1 every coloured point represents one piece of GPS information sampled from the GPS receiver at the frequency of 5 seconds Because the time interval between two consecutive points is a constant value it is possible to assess speed only from point densities However in order to make this interpretation easier weêve also added a reference to speed which is shown in colours The current knowledge base is not consistent enough to make complex assumptions over trafìc patterns Therefore our analysis is going to use only a limited number of attributes road partition road cluster speed  time of the day and day of the week  Feature discretization will produce 25 road clusters 12 speed clusters and 5 time intervals By applying Formula 2 we round up the minimum support to the value of 0  001  conìdence will be leveled to 0  2  Table III shows a sample of rules identiìed by our system Only rules that take speed as a conclusion have been retained Road clusters correspond to labels on g 3 Rule no 1 takes the most general form only the road segment in the premises and speed in the conclusion It has successfully identiìed bus station 5  where speed can be approximated to 0 Rule no 6 states that speed will drop to 13-18 km/h within cluster 23 around workdays this is valid because the road partition corresponds to a major intersection where trafìc jams often occur However the most important form of inferred rules are the ones pointed out with rule 2 and 3 both rules correspond to the same road cluster but referr to different time periods and different conclusions these are the speed variations we have been looking for Both point to cluster 1 which is right next to clusters 15 and 3 important sources of trafìc disruption around rush hours Finally rule no 4 states that high speeds can be attained with cluster 6 this is also expected because the segment corresponds to a straight four lane descent VI D ISCUSSION AND R ELATED W ORK Provided that a sufìcient volume of information exists the presented system should be able to assess a set of reliable rules for predicting trafìc behaviour Until now we were interested in associations that led to speed variations but other valuable rules might also be inferred out of the knowledge base For example we could determine the relationship between date  time values and passenger ow or bus station interest  Potential beneìts include 1 achieve a better coordination of the bus eet by knowing the correlations between the time of the day and the speed over each road section buses running on the same route wonêt overlap their schedules any more 2 offer a reliable bus schedule to both passengers and crew the inferred rules could help put up a dynamic schedule on the companyês website 3 improve quality of service by determining high interest bus stations aiming better coverage at critical hours 4 balance fuel consumption and enable better duty scheduling and duty rostering  uses smart-card information to determine the variability of public transit use  by the means of data mining techniques Results describe the correlations between fare category and day of usage or boarding hours and frequently used bus stops With the authors suggest a GPS data management system for GPS monitored buses by deriving travel time patterns from historical data and apply these patterns on real-time situations with the corresponding adjustments The authors focus on time values whilst our system is based on time derived features like speed  providing more knowledge than raw GPS data VII C ONCLUSION Variations in trafìc might prevent us from assuming a xed schedule over a certain bus line but the current paper has demonstrated that trafìc generally follows patterns and that these patterns can lead to accurate predictions of bus arrival times On going work regards the combination of the above results with the activity theory to identify solutions for encouraging people to use public transportation A CKNOWLEDGMENT This work was supported by CNCSIS-UEFICSU project number PNII-Idei 170/2009 R EFERENCES  A Sch  obel H W Hamacher A Liebers and D Wagner The continuous stop location problem in public transportation networks APJOR  vol 26 no 1 pp 13Ö30 2009  R Bornd  orfer Discrete optimization in public transportation in 1st Indo-US Symp on Adv in Mass Transit and Travel Behaviour Research   B A Catherine Morenc y  M T repaniera Measuring transit use v ariability with smart-card data Transport Policy  vol 14 pp 193Ö203 2007  C S Jensen and D T i e  syt  e TransDB GPS data management with applications in collective transport in Proc of the 5th Int Conf on Mobile and Ubiquitous Systems  Brussels Belgium 2008 pp 1Ö6  M.-P  K w a n and I Casas Gabriel Gis acti vity-based tra v e l simulator  activity scheduling in the presence of real-time information GeoInformatica  vol 10 no 4 pp 469Ö493 2006 126 


the following procedures 022  filter rules not including class type on the right side rules  2\ filter rule not including rules of TIP and Port on the left side rules    Some satisfying rules are achieved by taking above steps, shown as follows  left side rules  right side rules  support count 0169\017  confidence count 0169\017  192 8 168 8 1 8 12 80 sf normal          9.8           100 192 8 168 8 1 8 168 25 passive exter normal         16.5           100 192 8 168 8 88 8 217 80 active normal         25.2           100 192 8 168 8 114 8 48 tcp 25 sf normal         37.1          100 192 8 168 8 118 8 63 80 active normal         19.7           100 003     Conclusion  The safety of third-party logistics information involves many factors, and there are also multi - methods to ensure the safety. The paper discusses the content and safety of third-party logistics information management and constructs a third-party logistics information safety detection model based on data mining which applies data mining technique to information detection and analyze in order to judge whether the information management model is attacked or not. The paper suggests a useful method to further solve third-party information technique safety problem   REFERENCES 1 Zh en g 2 006   Network and Information Safety Qinghua University Press,11-23  ZHAO Wentao 010 YANG Jing 8  Information Management Model of Coal Mine Safety Data 8 Industry and Automation 010@"A\007 36-39 8\003  002 Security Model and Application of Logistics Information Management in the Environment of Networks  8 Logistics Technology 010 035\036 111-113 8  I=#FJK\0031%.\(LEK\003@.M.\036+\007 2006  Research on Information Management in the Third Party Logistics and Information Cooperation Model 007 Logistics Sci- Tech Oct.98-100 002  H U Jia n 010 YIN Xi. \(2007\The System Planning and Analysis of MIS for Third Party Logistics on The Perspective of SCM   China Business and Market 003@\035\036 10-13 6 Jiawei 010 KAMBR M 8 2001 Data Mining Concepts and Techniques 8 Higher Education Press, 227 N 236 8   Known Attack  Unknown Attack packet sniffer data preprocessing newdon analyzer  announciator Rule Bank Rules Builder Fig 2 Third-Party Logistics information safety detection model based on data mining  
131 


Moreover we can say that F C is comparable to E C and the modi\002ed version of E C i.e vE C  is correct and effective  The combinations of F C  E C  and vE C with 006 conf improve slightly F C  E C  vE C  and 006 conf  We can say that the sum of con\002dences is an important measure and these combined measures are useful in particular in the context where the accuracies of the classi\002cation by the sum of con\002dence by F C  and by E C are almost very good For conclusions 002rstly the adapted weight of evidence is a good class membership measure built on the gain of information F C  a measure built on the revisited 037 2 test provides another view of information gain It is comparable to the adapted weight of evidence The sum of con\002dence is a simple and natural measure with the good performance The combinations of the sum of con\002dence with the previous measures are interesting and useful to improve their performance Next based on the average accuracy values of different measures we recommend to use the combined measures because the average accuracy values of the combined measures are in general better than that of the non-combined measures Finally through the results on each dataset between the combined measures based on 037 2 and the weight of evidence we suggest the following propositions 017 For the 13 small datasets though the average accuracy value of cE C is slightly better than that of cF C  we can observe that cF C is much often wins cE C  Indeed cE C wins cF C on only 3 datasets while cF C wins cE C on 6 datasets Hence we can recommend cF C for the small datasets 017 For the 10 large datasets the average accuracy value of cvE C is slightly better than that of cF C  and cvE C wins cF C on 4 datasets and cF C wins cvE C 3 datasets Hence we can recommend cvE C for large datasets References  B Lent A Sw ami and J W idom Clustering association rules Proc Intl Conf on Data Engineering ICDE'97 IEEE Computer Society 1997 pp 220-231  W  Li J Han and J Pei CMAR Accurate and Ef 002cient Classi\002cation based on multiple class-association rules Proc IEEE Intl Conf on Data Mining ICDM'01 San Jose CA IEEE Computer Society 2001 pp 369-376  B Liu W  Hsu and Y  Ma Inte grating Classi\002cation and Association Rule Mining Proc 4th Intl Conf on Knowledge Discovery and Data Mining KDD'98 AAAI Press 1998 pp 80-86  Y  Sun Y  W ang and A.K.C W ong Boosting an Association Classi\002er in IEEE Transactions on Knowledge and Data Engineering vol 18 no 7 IEEE Computer Society 2006 pp 988-992  J W ang and G Karypis HARMONY  Ef 002ciently Mining the Best Rules for Classi\002cation Proc SIAM Intl Conf on Data Mining SDM'05 2005 pp 205-216  J W ang and G Karypis On Mining Instance-Centric Classi\002cation Rules in IEEE Transactions on Knowledge and Data Engineering vol 18 no 11 2006 pp 1497-1511  Y  W ang and A.K.C W ong From Association to Classi\002cation Inference using Weight of Evidence in IEEE Transactions on Knowledge and Data Engineering vol 15 no 3 2003 pp 764-767  F  Coenen The LUCS-KDD Implementations of the FOIL PRM and CPAR algorithms http://www.csc.liv.ac.uk frans/KDD/Software/FOIL PRM CPAR/foilPrmCpar.html Computer Science Department University of Liverpool UK 2004  Y  Basti de R T aouil N P asquier  G Stumme and L Lakhal Mining Frequent Patterns with Counting Inferences in ACM SIGMOD Explorations vol 2 no 2 2000 pp 66-75  R Agra w al and R Srikant F ast algorithms for mining association rules Proc 20th Intl Conf on Very Large Databases VLDB'94 Santiago Chile 1994 pp 487-499  V  Phan-Luong and R Messouci Building Classi\002ers with Association Rules based on Small Key Itemsets Proc 2nd IEEE International Conf on Digital Information Management ICDIM'07 France 2007 pp 200-205  J Quinlan and R Cameron-Jones FOIL A Midterm Report Proc European Conf on Machine Learning ECML'93 1993 pp 3-20  X Y in and J Han CP AR Classi\002cation based on Predicti v e Association Rules Proc 3rd SIAM Intl Conf on Data Mining SDM'03 San Francisco CA SIAM 2003 pp 369-376  C Cortes and V  V apnik Support-V ector Netw orks  in Machine Learning vol 20 no 3 1995 pp 273-297 
690 


Figure 3 Precision-recall curve in ROI-250 image dataset 5.3 Experiment 3 Mammograms-1080 image dataset This experiment employed a dataset composed by 1080 mammograms images collected in the Clinical Hospital of University of Sao Paulo at Ribeiro Preto The dataset was previously classi\002ed into 4 levels of breast tissue density 0501\051 mostly fatty 050362 images\051 0502\051 partly fatty 050446 images\051 0503\051 partly dense 050200 images\051 and 0504\051 mostly dense 05072 images\051 Figure 4 Precision-recall curve in Mammography-1080 image dataset Breast density is an important risk factor in the development of breast cancer In this experiment the images are represented by the feature set proposed in b uilding a vector of 85 features including shape and size of the breast the conditions of the breast contour nipple position and the distribution of 002broglandular tissue This dataset was divided in training set and test set The training set is composed of 720 images and test set is composed of 360 images Figure 4 shows the P&R curves over test dataset and also the number of features selected in each method Again the proposed methods reached the highest values of precision and select the smallest number of features 050a\051 050b\051 050c\051 050d\051 Figure 5 Queries in Mammography dataset 050a\051 226 is the query image 050b\051 using the features selected through 002tness function F cB  050c\051 using the features selected through classi\002cation error of C4.5 and 050d\051 using the all features extracted Results for the retrieval of the 5 most similar images from a query image are also provided in this experiment as illustrated in Figure 5 The image 5.\050a\051 is the query image taken from the mostly fatty image class Images shown in 5.\050b\051 are the 5 most similar images retrieved for the proposed 002tness function F cB  The row 050c\051 shows the results for C 4  5 classi\002er whereas 050d\051 illustrate the images resulting from all features 050no selection applied\051 In Figure 5 the images surrounded by dashed lines are false positives 050not relevant images\051 For this query the proposed method achieved the highest precision 050100%\051 when compared the results of C4.5 and the original feature vector 050precision of 40%\051 


6 Conclusions This work proposed a novel genetic feature selection framework for CBIRs It employs a wrapper strategy that searches for the best reduced feature set while optimizing 050or preserving\051 the quality of the solution From a ranking evaluation function three new 002tness functions namely F cA  F cB and F c have been proposed and evaluated in three experiments The proposed genetic feature selection approach which encompasses F cA  F cB and F c  has been compared with 050a\051 traditional methods found in the literature 050b\051 the StARMiner feature selector and 050c\051 the whole feature vector and signi\002cantly outperformed them The proposed approach has been able to optimize the accuracy of similarity queries while selecting a signi\002catively reduced number of features Additionally the proposal of combining the quality of the query results with the criterion of minimizing the number of selected features F cA and F cB  led to high accurate query answers while reducing the number of features more than the 002tness function F c  Therefore the 002nal processing cost of the queries is also reduced References  P  M d Aze v edo-Marques N A Rosa A J M T raina C Traina-Jr S K Kinoshita and R M Rangayyan Reducing the semantic gap in content-based image retrieval in mammography with relevance feedback and inclusion of expert knowledge International Journal of Computer Assisted Radiology and Surgery  3\0501-2\051:123\226130 June 2008  R Baeza-Y ates and B Ribeiro-Neto Modern Information Retrieval  Addison-Wesley Essex UK 1999  B Bartell G Cottrell and R Bele w  Optimizing similar ity using multi-query relevance Journal of the American Society for Information Science  49:742\226761 1998  O Cord 264 on E Herrera-Viedma C L 264 opez-Puljalte M Luque and C Zarco A review on the application of evolutionary computation to information retrieval International Journal of Approximate Reasoning  34:241\226264 July 2003  J G Dy  C E Brodle y  A Kak L S Broderick and A M Aisen Unsupervised feature selection applied to content-based retrieval of lung images IEEE Transactions on Pattern Analysis and Machine Intelligence  25\0503\051:373\226 378 March 2003  W  F an E A F ox P  P athak and H W u The ef fects of 002tness functions on genetic programming-based ranking discovery for web search Journal of the American Society for Information Science and Technology  55\0507\051:628\226636 2004  W  F an P  P athak and M Zhou Genet ic-based approaches in ranking function discovery and optimization in information retrieval a framework Decision Support Systems  2009  D E Golber g Genetic algorithms in search optimization and machine learning  Addison Wesley 1989  R L Haupt and S E Haupt Practical Genetic Algorithms  John Wiley  Sons New Jersey United States second edition edition 2004  J Horng and C Y eh Applying genetic algorit hms to query optimization in document retrieval Information Processing  Management  36:737\226759 2000  S K Kinoshita P  M d Aze v edo-Ma rques R R PereiraJr J A H Rodrigues and R M Rangayyan Contentbased retrieval of mammograms using visual features related to breast density patterns Journal of Digital Imaging  20\0502\051:172\226190 June 2007  F  K orn B P agel and C F aloutsos On the  dimensionality curse and the self-similarity blessing IEEE Trans on Knowledge and Data Engineering  13\0501\051:96\226111 2001  H Liu and L Y u T o w ard inte grating feature select ion algorithms for classi\002cation and clustering IEEE Transactions on Knowledge and Data Enginnering  17\0504\051:491\226502 April 2005  M X Ribeiro A J M T raina C T raina-Jr  and P  M Azevedo-Marques An association rule-based method to support medical image diagnosis with ef\002ciency IEEE Transactions on Multimedia  10\0502\051:277\226285 2008  U S Cancer Statistics W orking Group United states cancer statistics 1999-2005 incidence and mortality webbased report atlanta 050ga\051 Department of health and human services centers for disease control and prevention and national cancer institute 2009 Available in http://apps.nccd.cdc.gov/uscs   L T amine C C and M Boughanem Multiple query evaluation based on an enhanced geneticnext term algorithm Information Processing  Management  39\0502\051:215\226 231 2003  R S T orres A X  F alc 230 ao M A Gonc\270alves J P Papa Z B W Fan and E A Fox A genetic programming framework for content-based image retrieval Journal of the American Society for Information Science and Technology  42\0502\051:283\226292 2009  A Tsymbal P  Cunningham M P echenizkiy  and S Puuronen Search strategies for ensemble feature selection in medical diagnostics In Proceedings of the 16th IEEE Symposium on Computer-Based Medical Systems  pages 124\226 129 June 2003  A Tsymbal M Pechenizkiy  and P  Cunningham Sequential genetic search for ensemble feature selection In Proceedings of the International Joint Conferences on Arti\002cial Intelligence  pages 877\226882 August 2005  C.-M W ang a and Y F  Huang Ev olutionary-based feature selection approaches with new criteria for data mining A case study of credit approval data Expert Systems with Applications  36\0503 Part 2\051:5900\2265908 2009  H Y an J Zheng Y  Jiang C Peng and S Xiao Selecting critical clinical features for heart diseases diagnosis with a real-coded genetic algorithm Applied Soft Computing  8:1105\2261111 2008  T  Zhao J Lu Y  Zhang and Q Xiao Feature selection based on genetic algorithm for cbir In IEEE Congress on Image and Signal Processing  volume 2 pages 495\226499 2008 


     Figure 9. Argumentation Tree For Open GL  A1 The current system in flash does not have the functionality of dynamic allocation of particles like mine or clutter. It places them randomly  A1.1 That is not of much importance because it still gives a new position to mine and clutter particles A2 Current system in flash has faster response time as compared to system in Adobe Director A3 The current system doesnêt satisfy many of the features required for the new system like database A4 Adobe Flash cannot communicate with database A4.1 Flash doesnêt support database but database support is very important and critical A4.1.1 The system should be able to generate evaluation reports for trainee based on pr evious records stored in the database A5 Flash doesnêt create sound clips  A5.1 We donêt need sound creating features as the sys tem has to generate sound. We can play externally recorded sound files using Adobe Flash A6 Flash can provide good visual effects as compared to Adobe Director A7 The developer has good knowledge in development using Flash so the system can be developed quickly B1 We could reuse the system already developed for sound generation, as it is developed using Adobe Audition for analysis which is somehow related to Adobe Director B1.1 The current system is better synthesized in terms of sound production and the sound produced is also instantaneous rather than discrete B1.2 That current system has certain performance issues like slow response time B1.3 The current system in Adobe Director has the feature of producing dynamic coloring scheme on approaching a mine. This kind of scheme is highly preferable and is not present in Adobe Flash system B2 Adobe Director can provide more functionality as compared to the current flash system. E.g. Multiple sounds while detecting mines   B2.1 Adobe Director can provide better visual effects as compared to flash e.g. in case of GUIês   B2.2 A modified version of the current system in flash can also provide the same functionality B2.2.1 We cannot integrate code developed in other platforms with Flash, but Flash can be integrated in Adobe Director B3 The interface provided by flash is not professional enough. It is too simple and straight forward for doing more things in future   B4 Easily available plug-ins can help integrate the tracking system developed in C# with Adobe Director  B4.1 Code developed in Open GL/AL can also be integrated using Adobe Director using suitable stubs   B5 A new sound recognition algorithm is being developed in Adobe Audition which can be integrated with Adobe Director but not with Open GL or Flash Evidence supported B6 If the current system is reused; the project deadline can be met easily B7 The developer has very little experience in development using Adobe Director   B7.1 The developer can take help from the already developed system in Adobe Director C1 The tracking software already developed is coded in C#/NX5. We could reuse that and develop our system in Open GL/AL C1.1 Open GL has C# libraries which can be used to develop the system C2 Because the platform used is for high end application development, it can provide good GUI and database support C2.1 Open GL/AL can help us generate dynamic surfaces for mine detection and training which the original system in flash does not have C4 Open GL does not support connectivity with Adobe Audition. Adobe Audition is required for creating sound recognition algorithm C3 Open GL does not support connectivity with Adobe Audition. Adobe Audition is required for creating sound recognition algorithm C4 The time taken for developing the project using open GL will be comparatively more as the whole system would have to be developed from scratch C4.1 If Open GL has support for C# libraries, and then the system could be develope d faster as developer is quite familiar with programming languages like C 151 


   C4.2 Open GL has excellent documentation that could help the developer learn the platform with ease C4.3 Developer has very little ex perience in working with Open GL platform  For our case study, alternative B i.e. Adobe Director was the most favorable alternative amongst all the three. It catered to the reusability criteria quite well and aimed at meeting most of the desired operational requirements for the system   6. CONCLUSION & FUTURE WORK  The main contribution of this paper is to develop an approach for evaluating performance scores in MultiCriteria decision making using an intelligent computational argumentation network. The evaluation process requires us to identify performance scores in multi criteria decision making which are not obtained objectively and quantify the same by providing a strong rationale. In this way, deeper analysis can be achieved in reducing the uncertainty problem involved in Multi Criteria decision paradigm. As a part of our future work we plan on conducting a large scale empirical analysis of the argumentation system to validate its effectiveness   REFERENCES  1  L  P Am g o u d  U sin g  A r g u men ts f o r mak i n g an d  ex p lain in g  decisions Artificial Intelligence 173 413-436, \(2009 2 A  Boch m a n   C ollectiv e A r g u men tatio n    Proceedings of the Workshop on Non-Monotonic Reasoning 2002 3 G  R Bu y u k o zk an  Ev alu a tio n o f sof tware d e v e lo p m en t  projects using a fuzzy multi-criteria decision approach Mathematics and Computers in Simualtion 77 464-475, \(2008 4 M T  Chen   F u zzy MCD M A p p r o ach t o Selec t Serv ice  Provider The IEEE International Conference on Fuzzy 2003 5 J. Con k li n  an d  M. Beg e m a n   gIBIS: A Hypertext Tool for Exploratory Policy Discussion Transactions on Office Information Systems 6\(4\: 303  331, \(1988 6 B P  Duarte D e v elo p in g a p r o jec ts ev alu a tio n sy ste m based on multiple attribute value theroy Computer Operations Research 33 1488-1504, \(2006 7 E G  Fo rm an  T h e  A n a l y t ic Hier a rch y P r o cess A n  Exposition OR CHRONICLE 1999 8 M. L ease  an d J L  L i v e l y  Using an Issue Based Hypertext System to Capture Software LifeCycle Process Hypermedia  2\(1\, pp. 34  45, \(1990 9  P e id e L i u   E valu a tio n Mo d e l o f Custo m e r Satis f a c tio n o f  B2CE Commerce Based on Combin ation of Linguistic Variables and Fuzzy Triangular Numbers Eight ACIS International Conference on Software Engin eering, Artificial Intelligence Networking and Parallel Distributed Computing, \(pp 450-454 2007  10  X  F L i u   M an ag e m en t o f an In tellig e n t A r g u m e n tatio n  Network for a Web-Based Collaborative Engineering Design Environment Proceedings of the 2007 IEEE International Symposium on Collaborative Technologies and Systems,\(CTS 2007\, Orlando, Florida May 21-25, 2007 11 X. F L i u   A n In ternet Ba se d In tellig e n t A r g u m e n tatio n  System for Collaborative Engineering Design Proceedings of the 2006 IEEE International Symposium on Collaborative Technologies and Systems pp. 318-325\. Las Vegas, Nevada 2006 12 T  M A sub jec tiv e assess m e n t o f altern ativ e m ission  architectures for the human exploration of Mars at NASA using multicriteria decision making Computer and Operations Research 1147-1164, \(June 2004 13 A  N Mo n ireh  F u zzy De cisio n Ma k i n g b a se d o n  Relationship Analysis between Criteria Annual Meeting of the North American Fuzzy Information Processing Society 2005 14 N  P a p a d ias HERMES Su p p o rti n g A r g u m e n tative  Discourse in Multi Agent Decision Making Proceedings of the 15th National Conference on Artifical Intelligence \(AAAI-98  pp. 827-832\dison, WI: AAAI/MIT Press,  \(1998a 15  E. B T riantaph y llo u   T h e Im p act o f  Ag g r e g atin g Ben e f i t  and Cost Criteria in Four MCDA Methods IEEE Transactions on Engineering Management, Vol 52, No 2 May 2005 16 S  H T s a u r T h e Ev alu a tio n o f airlin e se rv ice q u a lity b y  fuzzy MCDM Tourism Management 107-115, \(2002 1 T  D W a n g  Develo p in g a f u zz y  T O P S IS app r o ach  b a sed  on subjective weights and objective weights Expert Systems with Applications 8980-8985, \(2009 18 L  A  Zadeh  F u z z y Sets   Information and Control 8  338-353, \(1965  152 


                        





