Influence Of Discrete Granularity On Using Association Rules To Complete Missing Values Yue-an ZHU information science and technology school Jinan University Guangzhou China iwillgoon@126.com Jian-hua WU Zhuhai Campus Jinan University Zhuhai China tjhwu@jnu.edu.cn Abstract 227this paper investigates the impacts of different discrete granularities of continuous attribute on the algorithms which employ association rules to complete missing value. The Chi2 algorithm is used to discrete the continuous attributes. By using three different discrete granularities, the impacts of the algorithm on completing missing value are explored Experimental results show that different discrete granularity has 
negligible impacts on using association rules to complete missing value. However, the completing accuracy has an inclination to decrease with the decrease of the discrete granularity Keywords missing value; association rule; discrete granularity Chi2 algorithm I   I NTRODUCTION  Missing values is very common in all kinds of science research. Incomplete data set brings great difficulty in data using and analysis and it is one of the main reasons for indefinite information system. Reference [1 u m m arizes s o m e  definition of missing value as follows: error occurring in transferring or collecting data, null value, exceeding the range value that can\222t meet the standard and so on. There are many 
reasons for missing value, but the main causes are probably as follows: some information is unavailable at the moment; some information is omitting; some attributes of the object can\222t be used; some information is viewed as unimportant; the cost to obtain those information is high; the system requires high realtime, i.e., decision must be made quickly before the information is available etc. Researcher propounded many methods to solve the missing value which base on different theory and are applied in different occasion. Generally, those methods are divided into such kinds: deleting the records where missing value exists and then obtaining complete data set, completing the missing value manually, treating Missing values as special values like [12  ut i l i z i ng t he st a t i s t i c s m e t hod 
conducting data mining or inference in those data sets etc. In recent years, there comes up with the method using association rules to complete missing values\(ARMV\, see [4, 5, 9 an d  it  achieves good performance compared with other methods used to complete missing values such as Robust Bayesian Estimator RBE S o far  r e s e ar c h  o f ARM V i s m a i n l y o n d i s c re t e  data set. This paper investigates how the discrete granularity of continuous attribute in non-discrete data set affects the performance of ARMV. We say some continuous attribute has discrete granularity 2, we mean using 2 intervals to represent the value of that attribute. The greater granularity is, the fewer intervals are used to represent the original data The rest of this paper is organized as follows: Section 2 
introduces ARMV. Section 3 introduces the data discretization algorithm. Section 4 provides experimental results and evaluates the influence of discrete granularity of continuous attributes on ARMV. Finally, conclusions are drawn in section 5 II  ARMV A  association rules In 1993, R.Agrawal put forward the concept of association rules first time. Combined with the transaction database R.Agrawal gave its formal description as follows [9, 10  L e t I  i 1 i 2 i n be a set of n distinct literals, called item set. Let DB be a transaction database, where each transaction Ti 
002 I is a set of items, which has a unique identifier associated with it called TID If a set of items X that fulfills the relationship \223X 002 T\224, we say T contains X. An association rule is an implication which has the form \223X Y\224, where X 002 I, Y 002 I and X Y An association rule has two attributes support  and confidence whose values must be no less than the userspecified minimum support minSup and minimum confidence  minConf values respectively. The rule \223 X 
Y\224 that has a support value s means the percentage of transactions containing X Y in the transaction database, denoted as XY Sup\(X Y DB DB  
 where XY DB 
003 003 is the transaction set containing X Y. The rule \223X Y\224 that has a confidence value c means the conditional probability, i.e., Pr Y|X\= Pr \(X Y\ / Pr \(X\o, it means c of transactions in database containing X also contains Y. In fact, association rule is an approximate dependency relationship in database, using 
support and confidence to evaluate this relationship The task of mining association rule in transaction database is to find all association rules whose support and confidence are no less than minsup and minconf respectively. The primary concept behind most association rule algorithms is a two phase procedure [10  In th e f i rst  p h a se al l f r e q u en t item sets a r e  found. An item set is said to be frequent if it satisfies a user978-1-4244-7941-2/10/$26.00 \2512010 IEEE 


defined minimum support requirement. The second phase uses these frequent item sets to generate all the rules which satisfy the user-specified minimum confidence The first phase discovering all frequent item sets dominates the performance of the mining association rules process. Algorithms to discover all frequent item set can be divided into two categories: one is producing the candidate set and the other is not producing the candidate set. The Apriori algorithm, a multiple-passes and producing candidate set algorithm, is a typical and famous technique to identify frequent item sets [10   B  Applying ARMV on incomplete transaction database Association rule has the form of imputation ìX 004\010 Yî, where X 001 Y 000 X is called antecedent and Y is called consequent Let us see an example how to apply association rules to complete missing value, where the Zoo database is obtained from UCI machine learning repository Given data: aquatic = y, tail = y, hairs = n, legs =?, fins Supposed minsup 0.8 and minconf 0.15, we used association rules r1 ìaquatic = y, hairs = n 004\010 legs = 0î to obtain the new data: aquatic = y, tail = y, hairs = n, legs = 0 fins = ?. Again, we used association rules r2  ìtail = y, legs = 0 004\010 fins = yî to obtain the complete records: aquatic = y, tail = y hairs = n, legs =0, fins = y. But how to select the association rules to complete missing values need more complicated procedure. In the following, we will introduce methods converting the relation database to transaction database and give our algorithm of selecting association rules to complete missing values 1  Transforming the relation database to transaction database We use the method like [7 to t r an sf o r m th e  rel a ti o n  database to transaction database D is dataset defined over n  attributes 1  n AA and contains m cases 1  m cc  Let i c  1 im 004\004 be transaction ID and cases of attributes 1  n AA  1  n aa be corresponding items, we can get transaction dataset TD That is, let 1 iij ij I SAai a  005 is a case of i A  is an item set eliminating the missing values. After transforming, a transaction of TD looks like 11    ii ijnnj cA a A a   Then given a minsup we utilize the Apriori algorithm to mine the large item sets of TD denoted as 1  g L L  1 g 005 Then for each element uv e of u L  1,1 ugv 004\004 \005 we compute the confidence   uv uvw uvw ed d 006 for  each element 1 uvw dw 005 of uv e If the confidence is no less than the userspecific threshold minconf the element of association rule is add to the set of association rules. Now, letís see an example below    TABLE I   A  DATASET OF 5 CASES 002 B 002 TRANSACTION FORM OF DATASET  Case A1 A2 A3  TID Items c1 2 1 002  t1 A1=2, A2=1 c2 2 1 2 t2 A1=2,A2=1,A3=2 c3 2 1 2 t3 A1=2, A2=1,A3=2 c4 002  2 1 t4 A2=2,A3=1 c5 1 002  1 t5 A1=1, A3=1 TABLE II  T HE  ASSOCIATION RULES PRODUCING BY TABLE 1 WHERE MINSUP   0.3 MINCONF   0.6 ID Asscotiaon rules sup conf r1 A1=2 000 A2 =1 60% 100 r2 A2=1 000 A1=2 60% 100 r3 A1=2 000 A3=2 40% 66.7 r4 A3=2 000 A1=2 40% 100 r5 A1=2, A2=1 000 A3=2 40% 66.7 r6 A1=2, A3=2 000 A2=1 40% 100 r7 A2=1, A3=2 000 A1=2 40% 100  There are 5 cases and 3 attributes in table 1\(a\, where represents the missing value. Table 1\(b\s the transaction form of Table 1\(a\ in which the missing values is eliminated. Then given the specific threshold minsup 0.6 and minconf 0.3 we applied the Apriori algorithm on Table 1\(b\ to find large item set and obtained the association rules 2  Selecting the association rules to complete missing values Firstly, we score the each association rules based on the following function S \(length support  confidence ength + 0.5 000h confidence  0.25 000h support 1 And sort them based on the score of rule by decreasing order Referen a v e a g ood h e u r i s t i c fun c t i o n t o s e l ect t h e association rule to complete missing value. Here, the methods to select the rule will not affect our research. So, we adopt a simple method to select the rule. Here, length is equal to the number of element of antecedent in association rule. For example, the antecedent of the rule ìaquatic = y, hairs = n 004\010  legs = 0î has two components, so the ìlengthî of the rule is two. Then, for each case of test data set, we scan the rules one by one and identify which rulesí antecedent is implicated in the case. These identified rules form the matching rules set called Rm. If Rm is not null, we select the first rule where the consequent of the rule is missing value. If Rm is null, we use the value that appears most frequent in that attribute as the missing value. The following is algorithmic description of missing data completing          


 Figure 1  algorithmic description of missing data completing III  DATA DISCRETE ALGORITHM INTRODUCTIONS  Data discretization technique can be used to reduce the number of values for a given continuous attribute by dividing the range of the attribute into several intervals. Interval labels can then be used to replace the actual data values. Replacing numerous values of a continuous attribute by a small number of interval labels can thereby reduce and simply the original data 6 S e ver a l m e t hod s h a ve be en pro p o s e d t o  d i scr e t i z e  da t a  as a preprocessing step for the data mining process. Roughly, we can divide the approaches into two classes [5    Unsupervised methods. "Blind" methods, where we have no classification information available for the object being considered. These methods rely on assumptions of the distribution of the attribute values   Supervised methods. Classification information is available, and this information can be taken into consideration when discretizing the data. A common denominator can be used to minimize the number of objects from different decision classes into the same discretization class In 1992, Kerber put forward heuristic algorithm ChiMerge to discrete the continuous attribute which based on 2 007 statistics. Different from the conventional top-down splitting strategy, ChiMerge algorithm begins with initialization, adopts bottom-up strategy and consists of a series of merging step. It continues to merge the intervals until a stop condition is satisfied. The stop condition depends on an important parameter 010 which is decided artificially. The ChiMerge algorithm have been widely used and referred in machine learning papers, and adopting this method came as a natural choice. The algorithm has been refined into a modified Chi2 versio   I n t h i s  pa pe r w e  use Chi2 algorithm to discrete data. The more details about Chi2 algorithm see [4 IV  EXPERIMENT RESULTS  Chi2 algorithm is implemented with C language and visual C++ is used as programming platform. The experiment is conducted in such environment: windows XP SP2 operating system, Intel\(R\ Pentium\(R 003 2.40GHz CPU, 768M memory The three medical data sets used in this experiment are gotten from UCI machine learning repository. The first data set named bupa.data about liver function disordered, has six attributes. The second data set, named diabetes.data about diabetes, has five attributes. The third data set, named newthyroid.data about thyroid, has eight attributes. 20% missing values are introduced in those data sets. The association rules is produced on those data sets under the condition minsup 0.2 and minconf 0.5 repectively. We are interested to find that some discrete granularity of all attributes canít be the same on the same granularity. For example, in Table 1, in D1, A1, A2 A3, A4, A5, A6 has granularities as following: 2, 2, 2, 2, 2, 1 respectively. Why not the same? Because those two intervals used to represent the data of A6 are so ìsimilarî and the Chi2 algorithm will combines them. Fig.1 shows that different data discrete granularity has little effect on ARMV, but as the data discrete granularity decreases, accuracy of ARMV inclines to decrease TABLE III  THREE DATA DISCRETIZATION OF BUPA  DATA   A1 A2 A3 A4 A5 A6 CA DD1 2 2 2 2 2 1 DD2 3 4 3 4 3 3 DD3 7 6 6 8 6 7 Remark: A = attribute, DD = data discrete granularity, CA = categorical atrribute. the ab. in following is the same as this TABLE IV  THREE DATA DISCRETIZATION OF NEW THYROID  DATA   A1 A 2 A 3 A 4 A 5 CA DD1 2 2 2 2 2 DD2 4 4 4 3 4 DD3 6 6 8 8 6  TABLE V  THREE DATA DISCRETIZATION OF DIABETES  DATA   A1 A2 A3 A4 A5 A6 A7 A8 CA DD1 2 2 1 1 1 2 1 2  DD2 4 4 4 4 3 3 4 4  DD3 6 6 8 6 7 6 7 7     1\ Algorithm SelectARToCompleteMV 2\ Begin 3 011  4\or each case Ti 012 the test data set do finding matching rules set Rm 5\or each rule 012 Rules set do 6\    if antecedent\(rule\ implicated Ti then 7\          Rm= Rm 003 rule; //adding the rule to Rm 8\     endif 9\dfor select the most priority rule 10  if Rm 000 null then 11  Ri=First\(Rm 12  endif 13  Imputation data=consequent\(Ri 14  endfor 15\d 


000\024\000\023\000\010 000\026\000\023\000\010 000\030\000\023\000\010 000\032\000\023\000\010 000\034\000\023\000\010 000'\000'\000\024 000'\000'\000\025 000'\000'\000\026  000D\000F\000F\000X\000U\000D\000F\000\\\000\003\000U\000D\000W\000H 000E\000X\000S\000D 0001\000H\000Z\000\020\000W\000K\000\\\000U\000R\000L\000G 000G\000L\000D\000E\000H\000W\000H\000V  Figure 2  accuracy change under different data discretization V  CONCLUSIONS  Association rules are approximate functional dependency. It plays an important role in supermarket basket analysis. In recent years, the research on ARMV has been on the upgrade seeing [2 C o m p a r ed w i t h RB E   R o b u st  B a y e si a n  Estimator\ [11  A R MV  ach iev e s  a b e tt e r p e rf o r m a n c e in  completing missing values and has a good applicative perspective. But most of researches are on discrete data sets This paper investigates influence of the different data discretization of continuous attribute on using ARMV Experimental results show that data discretization granularity of continuous attribute has no great effect on ARMV, but as the data discretization granularity decreases, the accuracy of ARMV has the trend to decrease. The result has some guide meaning for future research of ARMV on non-discrete data set Future research is conducting more jobs on more data set  R EFERENCES   1  Jukka Parviainen. Tik-61.181 Special Course in Information Technology EB/OL t t p    w w w cis hu t f i/O pi nno t/T 61.6010/s99/presentations/oct27_JP.ppt 2  A. Ragel and B. Cremilleux, MVC ñ a preprocessing method to deal with missing values, Knowledge-Based Systems, 12\(5ñ6\, 285ñ291 1999 3  Jau-Ji Shen, Chin-Chen Chang, Yu-Chiang Li: Combined association rules for dealing with missing values.Journal of Information Science 2007, 1~13 4  H. Liu, R. Setiono. Discretization of Ordinal Attributes and Feature Selection. In Proceedings of the 7th International Conference on Tools with Artificial Intelligence, Washington D.C., Nov 1995. pp. 388-391 5  Kerber R. ChiMerge: Discretization of numeric attributes. In Proceedings of Tenth Nat. conference on artificial Intelligence, MIT Press, 1992: 123~128 6  J. Han, M. Kamber, Data Mining : Concepts and Techniques, Morgan Kaufmann, August 2000 7  Wu, C., Wun, C., Chou, H.: Using association rules for completing missing data.In: Proceedings of 4th International Conference on Hybrid Intelligent Systems \(HIS 2004\, Kitakyushu, Japan, 5-8 December 2004 pp. 236ñ241. IEEE Computer Society Press, Los Alamitos \(2004 8  R. Agrawal, T. Imielinski and A. Swami, Mining association rules between sets of items in large database.In: P.Buneman and S. Jajodia eds\ Proceedings of the 1993 ACM SIGMOD International Conference on Management of Data, Washington, D.C., May 1993 \(ACM Press New York, 1993\207ñ216 9  R. Agrawal and R. Srikant, Fast algorithms for mining association rules in large databases. In: J.B. Bocca, M. Jarke and C. Zaniolo \(eds Proceedings of the 20th International Conference on Very Large Data Bases, Santiago, Chile, September 1994 \(Morgan Kaufmann, San Francisco, CA, 1994\ 487ñ499   Ramesh C, etc. A Tree Projection Algorithm for Generation of Frequent Item Sets. Journal of Parallel and Distributed Computing, 61, 350ñ371 2001   Ramoni, M., and Sebastiani, P. \(2001\, ìRobust Learning with Missing Data,î Machine Learning, vol. 45, no. 2, pp. 147-170   Frick, J.R., and Grabka, M.M. \(2003\, ìMissing Income  Information in Panel Data: Incidence, Imputation and its Impact on the Income distribution,î in the Proceedings of the Workshop on Item-Non-response and Data Quality in Large Social Surveys, October 9-11   


the following procedures 022  filter rules not including class type on the right side rules  2\ filter rule not including rules of TIP and Port on the left side rules    Some satisfying rules are achieved by taking above steps, shown as follows  left side rules  right side rules  support count 0169\017  confidence count 0169\017  192 8 168 8 1 8 12 80 sf normal          9.8           100 192 8 168 8 1 8 168 25 passive exter normal         16.5           100 192 8 168 8 88 8 217 80 active normal         25.2           100 192 8 168 8 114 8 48 tcp 25 sf normal         37.1          100 192 8 168 8 118 8 63 80 active normal         19.7           100 003     Conclusion  The safety of third-party logistics information involves many factors, and there are also multi - methods to ensure the safety. The paper discusses the content and safety of third-party logistics information management and constructs a third-party logistics information safety detection model based on data mining which applies data mining technique to information detection and analyze in order to judge whether the information management model is attacked or not. The paper suggests a useful method to further solve third-party information technique safety problem   REFERENCES 1 Zh en g 2 006   Network and Information Safety Qinghua University Press,11-23  ZHAO Wentao 010 YANG Jing 8  Information Management Model of Coal Mine Safety Data 8 Industry and Automation 010@"A\007 36-39 8\003  002 Security Model and Application of Logistics Information Management in the Environment of Networks  8 Logistics Technology 010 035\036 111-113 8  I=#FJK\0031%.\(LEK\003@.M.\036+\007 2006  Research on Information Management in the Third Party Logistics and Information Cooperation Model 007 Logistics Sci- Tech Oct.98-100 002  H U Jia n 010 YIN Xi. \(2007\The System Planning and Analysis of MIS for Third Party Logistics on The Perspective of SCM   China Business and Market 003@\035\036 10-13 6 Jiawei 010 KAMBR M 8 2001 Data Mining Concepts and Techniques 8 Higher Education Press, 227 N 236 8   Known Attack  Unknown Attack packet sniffer data preprocessing newdon analyzer  announciator Rule Bank Rules Builder Fig 2 Third-Party Logistics information safety detection model based on data mining  
131 


Moreover we can say that F C is comparable to E C and the modi\002ed version of E C i.e vE C  is correct and effective  The combinations of F C  E C  and vE C with 006 conf improve slightly F C  E C  vE C  and 006 conf  We can say that the sum of con\002dences is an important measure and these combined measures are useful in particular in the context where the accuracies of the classi\002cation by the sum of con\002dence by F C  and by E C are almost very good For conclusions 002rstly the adapted weight of evidence is a good class membership measure built on the gain of information F C  a measure built on the revisited 037 2 test provides another view of information gain It is comparable to the adapted weight of evidence The sum of con\002dence is a simple and natural measure with the good performance The combinations of the sum of con\002dence with the previous measures are interesting and useful to improve their performance Next based on the average accuracy values of different measures we recommend to use the combined measures because the average accuracy values of the combined measures are in general better than that of the non-combined measures Finally through the results on each dataset between the combined measures based on 037 2 and the weight of evidence we suggest the following propositions 017 For the 13 small datasets though the average accuracy value of cE C is slightly better than that of cF C  we can observe that cF C is much often wins cE C  Indeed cE C wins cF C on only 3 datasets while cF C wins cE C on 6 datasets Hence we can recommend cF C for the small datasets 017 For the 10 large datasets the average accuracy value of cvE C is slightly better than that of cF C  and cvE C wins cF C on 4 datasets and cF C wins cvE C 3 datasets Hence we can recommend cvE C for large datasets References  B Lent A Sw ami and J W idom Clustering association rules Proc Intl Conf on Data Engineering ICDE'97 IEEE Computer Society 1997 pp 220-231  W  Li J Han and J Pei CMAR Accurate and Ef 002cient Classi\002cation based on multiple class-association rules Proc IEEE Intl Conf on Data Mining ICDM'01 San Jose CA IEEE Computer Society 2001 pp 369-376  B Liu W  Hsu and Y  Ma Inte grating Classi\002cation and Association Rule Mining Proc 4th Intl Conf on Knowledge Discovery and Data Mining KDD'98 AAAI Press 1998 pp 80-86  Y  Sun Y  W ang and A.K.C W ong Boosting an Association Classi\002er in IEEE Transactions on Knowledge and Data Engineering vol 18 no 7 IEEE Computer Society 2006 pp 988-992  J W ang and G Karypis HARMONY  Ef 002ciently Mining the Best Rules for Classi\002cation Proc SIAM Intl Conf on Data Mining SDM'05 2005 pp 205-216  J W ang and G Karypis On Mining Instance-Centric Classi\002cation Rules in IEEE Transactions on Knowledge and Data Engineering vol 18 no 11 2006 pp 1497-1511  Y  W ang and A.K.C W ong From Association to Classi\002cation Inference using Weight of Evidence in IEEE Transactions on Knowledge and Data Engineering vol 15 no 3 2003 pp 764-767  F  Coenen The LUCS-KDD Implementations of the FOIL PRM and CPAR algorithms http://www.csc.liv.ac.uk frans/KDD/Software/FOIL PRM CPAR/foilPrmCpar.html Computer Science Department University of Liverpool UK 2004  Y  Basti de R T aouil N P asquier  G Stumme and L Lakhal Mining Frequent Patterns with Counting Inferences in ACM SIGMOD Explorations vol 2 no 2 2000 pp 66-75  R Agra w al and R Srikant F ast algorithms for mining association rules Proc 20th Intl Conf on Very Large Databases VLDB'94 Santiago Chile 1994 pp 487-499  V  Phan-Luong and R Messouci Building Classi\002ers with Association Rules based on Small Key Itemsets Proc 2nd IEEE International Conf on Digital Information Management ICDIM'07 France 2007 pp 200-205  J Quinlan and R Cameron-Jones FOIL A Midterm Report Proc European Conf on Machine Learning ECML'93 1993 pp 3-20  X Y in and J Han CP AR Classi\002cation based on Predicti v e Association Rules Proc 3rd SIAM Intl Conf on Data Mining SDM'03 San Francisco CA SIAM 2003 pp 369-376  C Cortes and V  V apnik Support-V ector Netw orks  in Machine Learning vol 20 no 3 1995 pp 273-297 
690 


Figure 3 Precision-recall curve in ROI-250 image dataset 5.3 Experiment 3 Mammograms-1080 image dataset This experiment employed a dataset composed by 1080 mammograms images collected in the Clinical Hospital of University of Sao Paulo at Ribeiro Preto The dataset was previously classi\002ed into 4 levels of breast tissue density 0501\051 mostly fatty 050362 images\051 0502\051 partly fatty 050446 images\051 0503\051 partly dense 050200 images\051 and 0504\051 mostly dense 05072 images\051 Figure 4 Precision-recall curve in Mammography-1080 image dataset Breast density is an important risk factor in the development of breast cancer In this experiment the images are represented by the feature set proposed in b uilding a vector of 85 features including shape and size of the breast the conditions of the breast contour nipple position and the distribution of 002broglandular tissue This dataset was divided in training set and test set The training set is composed of 720 images and test set is composed of 360 images Figure 4 shows the P&R curves over test dataset and also the number of features selected in each method Again the proposed methods reached the highest values of precision and select the smallest number of features 050a\051 050b\051 050c\051 050d\051 Figure 5 Queries in Mammography dataset 050a\051 226 is the query image 050b\051 using the features selected through 002tness function F cB  050c\051 using the features selected through classi\002cation error of C4.5 and 050d\051 using the all features extracted Results for the retrieval of the 5 most similar images from a query image are also provided in this experiment as illustrated in Figure 5 The image 5.\050a\051 is the query image taken from the mostly fatty image class Images shown in 5.\050b\051 are the 5 most similar images retrieved for the proposed 002tness function F cB  The row 050c\051 shows the results for C 4  5 classi\002er whereas 050d\051 illustrate the images resulting from all features 050no selection applied\051 In Figure 5 the images surrounded by dashed lines are false positives 050not relevant images\051 For this query the proposed method achieved the highest precision 050100%\051 when compared the results of C4.5 and the original feature vector 050precision of 40%\051 


6 Conclusions This work proposed a novel genetic feature selection framework for CBIRs It employs a wrapper strategy that searches for the best reduced feature set while optimizing 050or preserving\051 the quality of the solution From a ranking evaluation function three new 002tness functions namely F cA  F cB and F c have been proposed and evaluated in three experiments The proposed genetic feature selection approach which encompasses F cA  F cB and F c  has been compared with 050a\051 traditional methods found in the literature 050b\051 the StARMiner feature selector and 050c\051 the whole feature vector and signi\002cantly outperformed them The proposed approach has been able to optimize the accuracy of similarity queries while selecting a signi\002catively reduced number of features Additionally the proposal of combining the quality of the query results with the criterion of minimizing the number of selected features F cA and F cB  led to high accurate query answers while reducing the number of features more than the 002tness function F c  Therefore the 002nal processing cost of the queries is also reduced References  P  M d Aze v edo-Marques N A Rosa A J M T raina C Traina-Jr S K Kinoshita and R M Rangayyan Reducing the semantic gap in content-based image retrieval in mammography with relevance feedback and inclusion of expert knowledge International Journal of Computer Assisted Radiology and Surgery  3\0501-2\051:123\226130 June 2008  R Baeza-Y ates and B Ribeiro-Neto Modern Information Retrieval  Addison-Wesley Essex UK 1999  B Bartell G Cottrell and R Bele w  Optimizing similar ity using multi-query relevance Journal of the American Society for Information Science  49:742\226761 1998  O Cord 264 on E Herrera-Viedma C L 264 opez-Puljalte M Luque and C Zarco A review on the application of evolutionary computation to information retrieval International Journal of Approximate Reasoning  34:241\226264 July 2003  J G Dy  C E Brodle y  A Kak L S Broderick and A M Aisen Unsupervised feature selection applied to content-based retrieval of lung images IEEE Transactions on Pattern Analysis and Machine Intelligence  25\0503\051:373\226 378 March 2003  W  F an E A F ox P  P athak and H W u The ef fects of 002tness functions on genetic programming-based ranking discovery for web search Journal of the American Society for Information Science and Technology  55\0507\051:628\226636 2004  W  F an P  P athak and M Zhou Genet ic-based approaches in ranking function discovery and optimization in information retrieval a framework Decision Support Systems  2009  D E Golber g Genetic algorithms in search optimization and machine learning  Addison Wesley 1989  R L Haupt and S E Haupt Practical Genetic Algorithms  John Wiley  Sons New Jersey United States second edition edition 2004  J Horng and C Y eh Applying genetic algorit hms to query optimization in document retrieval Information Processing  Management  36:737\226759 2000  S K Kinoshita P  M d Aze v edo-Ma rques R R PereiraJr J A H Rodrigues and R M Rangayyan Contentbased retrieval of mammograms using visual features related to breast density patterns Journal of Digital Imaging  20\0502\051:172\226190 June 2007  F  K orn B P agel and C F aloutsos On the  dimensionality curse and the self-similarity blessing IEEE Trans on Knowledge and Data Engineering  13\0501\051:96\226111 2001  H Liu and L Y u T o w ard inte grating feature select ion algorithms for classi\002cation and clustering IEEE Transactions on Knowledge and Data Enginnering  17\0504\051:491\226502 April 2005  M X Ribeiro A J M T raina C T raina-Jr  and P  M Azevedo-Marques An association rule-based method to support medical image diagnosis with ef\002ciency IEEE Transactions on Multimedia  10\0502\051:277\226285 2008  U S Cancer Statistics W orking Group United states cancer statistics 1999-2005 incidence and mortality webbased report atlanta 050ga\051 Department of health and human services centers for disease control and prevention and national cancer institute 2009 Available in http://apps.nccd.cdc.gov/uscs   L T amine C C and M Boughanem Multiple query evaluation based on an enhanced geneticnext term algorithm Information Processing  Management  39\0502\051:215\226 231 2003  R S T orres A X  F alc 230 ao M A Gonc\270alves J P Papa Z B W Fan and E A Fox A genetic programming framework for content-based image retrieval Journal of the American Society for Information Science and Technology  42\0502\051:283\226292 2009  A Tsymbal P  Cunningham M P echenizkiy  and S Puuronen Search strategies for ensemble feature selection in medical diagnostics In Proceedings of the 16th IEEE Symposium on Computer-Based Medical Systems  pages 124\226 129 June 2003  A Tsymbal M Pechenizkiy  and P  Cunningham Sequential genetic search for ensemble feature selection In Proceedings of the International Joint Conferences on Arti\002cial Intelligence  pages 877\226882 August 2005  C.-M W ang a and Y F  Huang Ev olutionary-based feature selection approaches with new criteria for data mining A case study of credit approval data Expert Systems with Applications  36\0503 Part 2\051:5900\2265908 2009  H Y an J Zheng Y  Jiang C Peng and S Xiao Selecting critical clinical features for heart diseases diagnosis with a real-coded genetic algorithm Applied Soft Computing  8:1105\2261111 2008  T  Zhao J Lu Y  Zhang and Q Xiao Feature selection based on genetic algorithm for cbir In IEEE Congress on Image and Signal Processing  volume 2 pages 495\226499 2008 


     Figure 9. Argumentation Tree For Open GL  A1 The current system in flash does not have the functionality of dynamic allocation of particles like mine or clutter. It places them randomly  A1.1 That is not of much importance because it still gives a new position to mine and clutter particles A2 Current system in flash has faster response time as compared to system in Adobe Director A3 The current system doesnêt satisfy many of the features required for the new system like database A4 Adobe Flash cannot communicate with database A4.1 Flash doesnêt support database but database support is very important and critical A4.1.1 The system should be able to generate evaluation reports for trainee based on pr evious records stored in the database A5 Flash doesnêt create sound clips  A5.1 We donêt need sound creating features as the sys tem has to generate sound. We can play externally recorded sound files using Adobe Flash A6 Flash can provide good visual effects as compared to Adobe Director A7 The developer has good knowledge in development using Flash so the system can be developed quickly B1 We could reuse the system already developed for sound generation, as it is developed using Adobe Audition for analysis which is somehow related to Adobe Director B1.1 The current system is better synthesized in terms of sound production and the sound produced is also instantaneous rather than discrete B1.2 That current system has certain performance issues like slow response time B1.3 The current system in Adobe Director has the feature of producing dynamic coloring scheme on approaching a mine. This kind of scheme is highly preferable and is not present in Adobe Flash system B2 Adobe Director can provide more functionality as compared to the current flash system. E.g. Multiple sounds while detecting mines   B2.1 Adobe Director can provide better visual effects as compared to flash e.g. in case of GUIês   B2.2 A modified version of the current system in flash can also provide the same functionality B2.2.1 We cannot integrate code developed in other platforms with Flash, but Flash can be integrated in Adobe Director B3 The interface provided by flash is not professional enough. It is too simple and straight forward for doing more things in future   B4 Easily available plug-ins can help integrate the tracking system developed in C# with Adobe Director  B4.1 Code developed in Open GL/AL can also be integrated using Adobe Director using suitable stubs   B5 A new sound recognition algorithm is being developed in Adobe Audition which can be integrated with Adobe Director but not with Open GL or Flash Evidence supported B6 If the current system is reused; the project deadline can be met easily B7 The developer has very little experience in development using Adobe Director   B7.1 The developer can take help from the already developed system in Adobe Director C1 The tracking software already developed is coded in C#/NX5. We could reuse that and develop our system in Open GL/AL C1.1 Open GL has C# libraries which can be used to develop the system C2 Because the platform used is for high end application development, it can provide good GUI and database support C2.1 Open GL/AL can help us generate dynamic surfaces for mine detection and training which the original system in flash does not have C4 Open GL does not support connectivity with Adobe Audition. Adobe Audition is required for creating sound recognition algorithm C3 Open GL does not support connectivity with Adobe Audition. Adobe Audition is required for creating sound recognition algorithm C4 The time taken for developing the project using open GL will be comparatively more as the whole system would have to be developed from scratch C4.1 If Open GL has support for C# libraries, and then the system could be develope d faster as developer is quite familiar with programming languages like C 151 


   C4.2 Open GL has excellent documentation that could help the developer learn the platform with ease C4.3 Developer has very little ex perience in working with Open GL platform  For our case study, alternative B i.e. Adobe Director was the most favorable alternative amongst all the three. It catered to the reusability criteria quite well and aimed at meeting most of the desired operational requirements for the system   6. CONCLUSION & FUTURE WORK  The main contribution of this paper is to develop an approach for evaluating performance scores in MultiCriteria decision making using an intelligent computational argumentation network. The evaluation process requires us to identify performance scores in multi criteria decision making which are not obtained objectively and quantify the same by providing a strong rationale. In this way, deeper analysis can be achieved in reducing the uncertainty problem involved in Multi Criteria decision paradigm. As a part of our future work we plan on conducting a large scale empirical analysis of the argumentation system to validate its effectiveness   REFERENCES  1  L  P Am g o u d  U sin g  A r g u men ts f o r mak i n g an d  ex p lain in g  decisions Artificial Intelligence 173 413-436, \(2009 2 A  Boch m a n   C ollectiv e A r g u men tatio n    Proceedings of the Workshop on Non-Monotonic Reasoning 2002 3 G  R Bu y u k o zk an  Ev alu a tio n o f sof tware d e v e lo p m en t  projects using a fuzzy multi-criteria decision approach Mathematics and Computers in Simualtion 77 464-475, \(2008 4 M T  Chen   F u zzy MCD M A p p r o ach t o Selec t Serv ice  Provider The IEEE International Conference on Fuzzy 2003 5 J. Con k li n  an d  M. Beg e m a n   gIBIS: A Hypertext Tool for Exploratory Policy Discussion Transactions on Office Information Systems 6\(4\: 303  331, \(1988 6 B P  Duarte D e v elo p in g a p r o jec ts ev alu a tio n sy ste m based on multiple attribute value theroy Computer Operations Research 33 1488-1504, \(2006 7 E G  Fo rm an  T h e  A n a l y t ic Hier a rch y P r o cess A n  Exposition OR CHRONICLE 1999 8 M. L ease  an d J L  L i v e l y  Using an Issue Based Hypertext System to Capture Software LifeCycle Process Hypermedia  2\(1\, pp. 34  45, \(1990 9  P e id e L i u   E valu a tio n Mo d e l o f Custo m e r Satis f a c tio n o f  B2CE Commerce Based on Combin ation of Linguistic Variables and Fuzzy Triangular Numbers Eight ACIS International Conference on Software Engin eering, Artificial Intelligence Networking and Parallel Distributed Computing, \(pp 450-454 2007  10  X  F L i u   M an ag e m en t o f an In tellig e n t A r g u m e n tatio n  Network for a Web-Based Collaborative Engineering Design Environment Proceedings of the 2007 IEEE International Symposium on Collaborative Technologies and Systems,\(CTS 2007\, Orlando, Florida May 21-25, 2007 11 X. F L i u   A n In ternet Ba se d In tellig e n t A r g u m e n tatio n  System for Collaborative Engineering Design Proceedings of the 2006 IEEE International Symposium on Collaborative Technologies and Systems pp. 318-325\. Las Vegas, Nevada 2006 12 T  M A sub jec tiv e assess m e n t o f altern ativ e m ission  architectures for the human exploration of Mars at NASA using multicriteria decision making Computer and Operations Research 1147-1164, \(June 2004 13 A  N Mo n ireh  F u zzy De cisio n Ma k i n g b a se d o n  Relationship Analysis between Criteria Annual Meeting of the North American Fuzzy Information Processing Society 2005 14 N  P a p a d ias HERMES Su p p o rti n g A r g u m e n tative  Discourse in Multi Agent Decision Making Proceedings of the 15th National Conference on Artifical Intelligence \(AAAI-98  pp. 827-832\dison, WI: AAAI/MIT Press,  \(1998a 15  E. B T riantaph y llo u   T h e Im p act o f  Ag g r e g atin g Ben e f i t  and Cost Criteria in Four MCDA Methods IEEE Transactions on Engineering Management, Vol 52, No 2 May 2005 16 S  H T s a u r T h e Ev alu a tio n o f airlin e se rv ice q u a lity b y  fuzzy MCDM Tourism Management 107-115, \(2002 1 T  D W a n g  Develo p in g a f u zz y  T O P S IS app r o ach  b a sed  on subjective weights and objective weights Expert Systems with Applications 8980-8985, \(2009 18 L  A  Zadeh  F u z z y Sets   Information and Control 8  338-353, \(1965  152 


                        





