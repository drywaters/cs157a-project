978-1-4673-1813-6/13/$31.00 \2512013 IEEE  1 IMU/Vision/Lidar Integrated Navigation System in GNSS Denied Environments Sukchang Yun, Young Jae Lee and Sangkyung Sung Konkuk University Department of  Aerospa ce Information Engineering Seoul, Korea 82-2-458-0164 amerisan@konkuk.ac.kr  Abstract 227This paper aims to develop IMU/Vision/Lidar integrated navigation system which can provide accurate relative navigation information in GNSS denied environments The developed integrated navigation system consists of an IMU, a vision sensor and a Lidar sensor. In order to overcome 
limitation of low accuracy of MEMS inertial navigation solution when GNSS signal cannot be used, 2-dimensional optical flow vector from vision sensor and Lidar range information between the system and ground surface are used Two aided sensor data are complementarily employed in the system integration. Basically, by using the optical flow vector and relative height between vision sensor and ground surface accuracy of the horizontal position estimates is improved. At the same time, by using compensated Lidar measurement accurate vertical position can be estimated. The overall integrated navigation filter is constructed based on Extended 
Kalman Filter approach. Feasibility of the navigation filter is proven via simulation results. Finally, with real hardware system, an outdoor test is carried out for analyzing performance of the proposed integrated navigation system T ABLE OF C ONTENTS  1  I NTRODUCTION 1  2  S YSTEM A RCHITECTURE 3 3  I NTEGRATED N AVIGATION S YSTEM 3 4  S IMULATIONS 4 5  E XPERIMENTS 
5 6  C ONCLUSIONS 7 R EFERENCES 7  B IOGRAPHY 9   1  I NTRODUCTION  One of the most important technologies for operating autonomous vehicles is to figure out their pose and attitude information. There are a number of navigation systems used for various autonomous platforms such as military reconnaissance and surveillance UAV \(Unmanned Aerial vehicle\, a guided missile, or an autonomous ground vehicle for land exploration. Among navigation sensors, GNSS 
Global Navigation Satellite System\most essential system as it can provide absolute position information within a certain error boundary as well as velocity and time information. Nevertheless, the information accuracy of GNSS system is greatly affected by satellite observation environments. For example, when a vehicle is surrounded by skyscrapers and forestry, or blocked by indoor objects or a jamming signal, it cannot provide reliable navigation information. This availability problem is an inherent and inevitable drawback to the GNSS based navigation system GPS/INS integrated navigation system is a representative navigation system based on GNSS. This system has been widely used in ground and aerial application for several 
decades. This integrated system provides INS \(Inertial Navigation System\ navigation solution when GPS \(Global Positioning System\gnal cannot be used. In such case, the accuracy of the navigation solution relies heavily on that of inertial measurements. Thus, for providing reliable navigation information, INS necessarily requires a high performance IMU \(Inertial Measurement Unit\with a tactical or inertial grade for its construction. For this reason a number of researches on GPS-free navigation method have been widely carried out. Among these, researches on sensor fusion of IMU and vision sensor are noticeable [1-3  These researches were generally performed using SLAM Simultaneous Localization and Mapping\echnology based on feature points [4-8 h e perf orm a n ce of t h i s f e a t u re  
point based system largely relies on the estimation accuracy of the position of the feature points. In order to do that continuous tracking performance is required. However since it is difficult to track points continuously in unconstructed outdoor environments, the feature point based system is limited in outdoor application Meanwhile, development of another vision-aided navigation system is attempted by using optical flow in image sequences l o w  is ins ect i ns pired f l o w  v ector that is, an approximation of the local image motion based upon local derivatives in a given sequence of images. That is, in 2D it specifies how much each image pixel moves between adjacent images [9 tical f l o w  h a s b een  u tilized  in a number of vision based ground and aerial navigation 
system [11 [11], by  appl y i ng opt i cal  f l o w t o road navigation, forward velocity and heading angular rate are estimated to detect a moving car. Optical flow has been also used in the field of aerial autonomous vehicle. Using optical flow, UAV autonomously performs path planning in clutter environments d i t c a n be al s o u s ed t o es t i m a t e  angular rate and aerodynamic angle of the aircraft  Additionally, this flow vector is used for autonomous control of the MAV \(Micro Aerial Vehicle\n indoor corridor environments d au t o n o m ous t a ke off/hovering/landing of the UAV i des  t w o opt i cal  chips in a mouse are used to estimate ground depth by using 


  2 high speed optical flow. But, the system has low depth resolution due to limited total pixel and cannot avoid a divergence problem in estimating horizontal positions because of lack of observability [17   However, it is rarely reported optical flow is adopted for estimating 6DOF \(Degree of Freedom\ navigation solution In i n or der t o  ov erco m e deg radat i o n of n a v i g a t i o n performance of GPS/INS system in GPS denied environments, optical flow rate measurement is applied to EKF fusion process. But, they could not avoid rapid divergence of navigation solution after 20 seconds With the various vision based integrated navigation system Lidar sensor based navigation system has been developed in GPS denied environments. The development of localization and mapping system for a mobile robot and a quadrotor has been mainly carried out.  In s can  m a tc h i n g bas e d t w o  dimensional SLAM and INS were integrated by using loosely coupled EKF approach and real hardware system was developed to apply to various applications such as UAV, USV \(Unmanned Surface Vehicle\d small handheld embedded systems.  Additionally, Lidar measurement was applied to Graph-based SLAM for autonomous navigation of small quadrotor [19 a nd laser/IMU odometry was developed based on correlative scan matching method H o w e v e r t h es e sy s t e m s  ca n not  be used in unstructured outdoor environments since obstacles are out of sensor detection range in outdoor environments Several researches presented a fusion system of vision and Lidar sensors. Although IR scanner, vision sensors and encoders were integrated based on a particle filter for localization of mobile robot, this system had previously required map information. And in addition to research on detecting moving car and pedestrians, research on UAV\222s indoor path planning was developed [23o f a r, n o  published result practically touches an investigation of vision sensor and Lidar sensor integrated navigation system that can operate in unstructured outdoor environments In this paper, we developed IMU/Vision/Lidar integrated navigation system that can operate in GPS denied environments. In order to cope with the problem of the divergence characteristics in estimating velocity and position using INS system, consecutive downward optical flow measurement and range information from Lidar sensor are complementarily employed. Therefore, this system can provide a reliable and robust navigation solution in those limited environments. For this propose, integrated navigation filter is constructed based on EKF approach. In this system, horizontal velocity estimated of INS is compensated by using optical flow measurement at the same time while the vertical position of INS is compensated by using range measurement. Operational limit height is restricted within measuring range of the Lidar sensor. Thus this system can be applicable to low altitude UAV system The feasibility of the proposed system is proved via simulation results by comparing INS only case and IMU/DualVision integrated system that uses dual optical flow as measurements. On the basis of the simulation results the performance of the proposed integrated navigation system was verified via outdoor test with a real sensor system The rest of the paper is organized as follows: section 2 describes concept of proposed integrated navigation and operational environments. And after, INS error model sensor model and integration method are presented. Section 3 provides simulation results to verify its feasibility in GPS denied environments. On the basis of the simulation results outdoor experimental result is presented in section 4 Section 5 concludes the paper with a discussion on our current research 2  S YSTEM A RCHITECTURE   Figure 1 \226 System concept of integrated navigation 


 _ xfull xx y xx Pix FL OF V t t HPixSize FOV  ie in en in   3 Proposed integrated navigation system can operate in limited environments, in which GPS signal cannot be used This system solves inevitable INS divergence problem that velocity error gradually increase as time goes on. Thus, it can provide reliable and robust navigation solution System concept and coordinate system Optical axis of the vision sensor is parallel to down axis of the vehicle. And also, detection plane of the Lidar sensor is heading for down axis of the vehicle, and scan direction is in x-z plane. The performance of estimating horizontal velocity based on optical flow depends on accuracy of attitude of the vehicle and relative altitude between system and ground. Therefore, this system can estimate accurate altitude using range information from Lidar sensor at the same time while it can estimate corrected horizontal velocity. In this process, we assumed that ground surface is flat and its height is zero meters, and vehicle motion has low dynamics Figure 1 describes system concept and operational environments. IMU/Vision/Lidar integrated navigation system can provide reliable and robust navigation solution without map information in the limited environments which GPS signal cannot be used. In this system, body frame follows right handed IMU coordinate system. X-axis of the frame is equal to forward direction of the vehicle and y-axis looks right direction. Lidar coordinate system is represented using measured range \(r\measured angle x-z plane of the body frame. In this system, we assume that the three sensor coordinate system has same origin. Sensor coordinate system is depicted in figure 2  a\amera             \(b\idar Figure 2 \226 Sensor coordinate system INS error model Psi angle approach is used as an INS error model. The psi angle error model is the most widely adopted approach and has been implemented in many tightly coupled integration systems Ps i an g l e err o r m odel i s  s h o w n i n equ a t i o n  1 002\003\003\002\002 002\003\002\002 002\003\002\004 212  327 212 327 005 212 327  212 327  vv f rrv 1 where    cos cos LiDAR NE H H  002 r  002 v  002 Velocity, position, attitude error vectors ie 003 Earth rate vector in 003 Angular rate vector of the true coordinate system w.r.t the inertial frame en 003 Angular rate vector of the true coordinate system w.r.t the Earth frame 005 Accelerometer error vector 004 Gyro drift vector f Specific force vector Sensor model Direction of the optical flow vector in consecutive image frame is opposite to the vehicle motion. With this principle optical flow vector is generated by translational velocity and 3 represent a relationship between optical flow vector translational velocity and rotational angular rate based on pinhole camera model. In this equation, optical flow is a mount of pixel movements that has pixel units 003 327\212\327 006+\327\212\327 006 327 2 003 327 212\327 006+\327\327 006 327 3 where  x OF  y OF Optical flow measurements [pix  x V  y V  Translational velocity w.r.t. the body  x 003  y 007\007  4  3  I NTEGRATED N AVIGATION S YSTEM  Integrated navigation filter is constructed using INS error model and sensor model presented in the previous section State vector consists of position error, velocity error attitude error in INS error model. And additionally acceleration and gyroscope bias error vectors are augmented Equation \(5\presents 15-order state vector and system model. Detail expression is shown in APPENDIX A. All         _ yfull yyx yy Pix FL OF V t t HPixSize FOV 003 Rotational angular rate w.r.t. the body frame [rad/s H Ground height [m F L Camera focal length [m x PixSize  y P ixSize Magnitude of the 1 pixel [m x F OV  y F OV Field of view _ x full Pix  _ yfull Pix Number of the total pixels t 006 Interval time [s A relationship between ground height and Lidar range measurement is shown in equation \(4\. Ground height is calculated using Lidar range measurement by compensating roll, pitch angle 


East \(m     cos sin sin cos x DDN y DDE V V V V  007\007 007\007   4 process noises are modeled as zero-mean gaussian white noises 11 12 13 22 33  00 00 T nav acc gyro nav nav nav acc acc acc g yro gyro gyro FFF F F 40     xx x x xx w xx w xx w 5 4 Since three sensors have the same origin point, translational velocity in equation \(2\, \(3\ can be obtained using global velocity and heading angle as shown in equation \(6  _ yfull zz y yy Pix FL OF V t t PixSize FOV 0 0  212 6 3\re perturbed, error model of the optical flow measurements can be obtained. Observation vector consists of optical flow error model and height difference between INS derived height and corrected height measurement from Lidar sensor as shown in equation \(7 T INS Lidar x y HH OF OF 002 002 212  z 7 Figure 3 describes IMU/Vision/Lidar integrated navigation filter structure. In this structure, integrated navigation solution is obtained by compensating INS error estimated in EKF correction step  Figure 3 \226 Integrated filter structure For the comparison of the navigation performance IMU/DualVision system is additionally used. This system uses three dimensional optical flow vectors from the forward and downward vision sensors. Observation model of this system consists of three error models of the optical flow measurement as shown in equation \(9\tical flow vector in forward image is a function of vertical velocity and pitch angular rate as shown in equation \(8\ this equation, we assume that the object in the forward image is far enough from vision sensor 003 327\327\006+\327\212\327\006 8 T x y z OF OF OF 002 002 002 40 60 80 100 120 20 50 60 70 20 40    North \(m Up \(m start  end   z 9  4  S IMULATIONS  The feasibility of the proposed IMU/Vision/Lidar integrated navigation filter in the previous section was verified via simulation by comparing navigation performance of the proposed system with that of INS and that of IMU/DualVision system when GPS signal outage is occurred Simulation environments Navigation scenario is that vehicle makes a level flight with GPS/INS navigation system at first, and then navigation mode is changed to GPS-free navigation systems as soon as GPS outage input is applied at 15 seconds and vehicle navigates with integrated mode to the end. Flight trajectory contains three flight modes such as level, ascending, turning mode. Figure 4 shows reference trajectory of the vehicle  Figure 4 \226 Reference flight trajectory Simulation results After GPS outage has occurred, navigation performance of the three GPS-free system was compared. Figure 5 shows horizontal position estimate results. Estimate error of the INS system diverges as time goes on in this graph. However other two navigation systems suppress error divergence And, IMU/Vison/Lidar system well tracks the reference trajectory than IMU/DualVision system                             


INS INS 15   5  Figure 5 \226 Horizontal position estimate results Figure 6 shows altitude estimate results. In this graph, INS only system diverges as time goes on. On the other hand other two integrated systems well track the reference altitude. But, the IMU/DualVision system has significant error bound of meter level. It originates from the assumption that distance between vision sensor and forward object in image is infinite. Thus, estimate accuracy is degraded because noise of the forward optical flow measurement is amplified  Figure 6 \226 Vertical posi tion estimate results  Figure 7 shows velocity estimate results. Performance of the IMU/Vision/Lidar integrated system is the most accurate in the three navigation methods like the previous position estimate results   Figure 7 \226 Velocity estimate results   5  E XPERIMENTS  On the basis of the simulation results presented in the previous section, with a real sensor system the performance of the proposed integrated navigation system was verified via outdoor test by comparing navigation performance of the proposed system with that of INS. In this test IMU/DualVision system does not considered due to experimental complexity Experimental environments For this test we constructed a multi sensor data acquisition system and performance analysis of our system was fulfilled with the hardware system installed on a moving cart as shown in figure 8   Figure 8 \226 Sensor system and installation                              20 5 East \(m North \(m  10 IMU/DualVision 10 IMU/DualVision 20 100 20 Time \(s  Up \(m   5 15 20 25 30 35 40 25 30 35 40 45 50 55 60 65 70 IMU/Vision/Lidar                             5 15 20 25 30 35 40 10 5 IMU/Vision/Lidar                             10 20 30 10 10 20 30 40 60 80 40 20 40 15 25 35 15 25 35 5 60 120 20 IMU/Vision/Lidar                                       Time \(s  V D m Ref IMU/DualVision 0 0 0 0 0 V N m Time \(s  0 0 V E m Time \(s                          0 0   INS Ref Ref 5 40 10 20 5 40 5 


East \(m North \(m   INS 10 0   6 Sensor system consists of an IMU, a vision sensor, a Lidar sensor. Specifications of these sensors are shown in table 1  Table 1. Sensor specifications Sensor Model Manufacturer  Main feature IMU ADIS16385 Analog Devices  Gyro. bias stability z-axis: 6 \260/h[1  x, y-axis: 21 \260/h[1  Acc. bias stability 50 g [1  Vision sensor LifeCam Studio Microsoft  Resolution 640 x 480 Type Color Lidar UTM-30LX Hokuyo  Scan Angle 270 \260 Detection range 0.1~30 m A wall is set up on a flat ground using office partitions. And the cart moves along a certain two dimensional trajectory in front of the wall surface over making vision sensor and Lidar sensor look at the wall surface. If it is assumed that the wall surface is the ground surface, the motion is in effect equivalent to flight trajectory of an aerial vehicle, which includes level, ascending and descending flight mode without lateral motion. Reference trajectory of the moving cart is depicted in Figure 9  Figure 9 \226 Reference moving trajectory Figure 10 shows experimental environments. Due to the assumption that the wall surface is a ground surface, the moving trajectory can be regarded as the vehicle initially levels off at 3 meters and then is ascending to 6 meters and descending to 3 meters, lastly levels off at 3 meters In this test, combined local-global \(CLG\method is used to calculate the optical flow vector which is robust under gaussian noise while giving dense flow fields     Figure 10\226 Experimental environments Experimental results With the acquired raw sensor data, navigation performance analysis of the proposed system was conducted Figure 11 shows horizontal position estimate results. In the case of the horizontal position, estimate error of the INS gets lager after passing by a first curve point and finally diverges as time goes on, whereas position of the IMU/Vision/Lidar integrated system well tracks reference trajectory as compared with INS only system   Figure 11 \226 Horizontal posi tion estimate results Figure 12 shows velocity estimate results. In the case of the INS, errors gradually get lager in view of the fact that the moving cart stops at the end                                      0 2 4 6 8 12 8 7 6 5 4 3 2 1 1 IMU/Vision/Lidar Reference 9 


INS 5 20 25 1 1 2 5 20 25 1 1 2 5 20 25 1 1 2 15 15 15 2 2 2 0 0 V N m Time \(s                        0 0 V E m Time \(s                        0 0 V D m     7  Figure 12 \226 Velocity estimate results   6  C ONCLUSIONS  In this paper, we developed IMU/Vision/Lidar navigation system which can operate in GNSS denied environments This system consists of an IMU, a vision sensor and a Lidar sensor. In order to cope with the problem of the divergence characteristics in estimating velocity and position using INS system, downward optical flow and range information are complementarily employed in the integrated navigation Basically, by using the optical flow vector and ground height, accuracy of the horizontal velocity estimates is improved. At the same time, by using compensated Lidar measurement, accurate vertical position can be estimated The overall integrated navigation filter is constructed based on EKF approach Feasibility of the navigation filter is proven via simulation results. When GPS outage occurs, proposed navigation system provides more accurate navigation solution than INS and INS/DualVision system. On the basis of the simulation results, we constructed real hardware system that consists of practical sensors. With this system, an outdoor test is carried out for analyzing performance of the proposed integrated navigation system. As a result, IMU/Lidar integrated system provides more reliable and robust navigation solution than INS in real world outdoor environments. We are now analyzing quantitatively the performance of the IMU/Vision/Lidar integrated navigation system. And also based on this research, development of advanced navigation system that can estimate height variation of ground surface is now under way  A CKNOWLEDGEMENT  This research was supported by Basic Science Research Program through the National Research Foundation of Korea \(NRF\unded by the MEST \(20120003952 R EFERENCES  1  G  Cr a i g B e c ke r   R e l i a b l e  N a vi ga t i o n U s i n g La nd ma r ks   Proceedings of IEEE International Conference on Robotics and Automation, pp. 401-406, 1995 2 Co ur t ne y S S ha r p   A  V i s i o n S ys t e m  fo r  La nd i ng a n  Unmanned Aerial Vehicle," Proceedings of the IEEE International Conference on Robotics and Automation pp. 1720-1727, Vol. 2, 2001 3 L S  Co e l ho   P o s e E s t i m a t i o n o f  A u t o no mo us D i r i gi b l e s  Using Artificial Landmarks Proceedings of IEEE International Conference on Robotics and Automation  pp.  2584-2589, Vol. 4, May 1999  rra n t W hy t e a n d T  Bai l e y   S i m ul t a n e o u s Localization and Mapping: Part- I, II IEEE Robotics Automation Magazine pp. 99-108, Vol.13, Issue2, June 2006  i m J. an d Sukk ari e h  S    R eal t i m e I m p l e m e n t a t i on of Airborne Inertial-SLAM Robotics and Autonomous Systems pp. 62\22671, Volume 55, Issues 1, Jan 2007  A h re ns S  Levi n e D  A ndre w s G  H o w  J V i s i onba s e d guidance and control of a hovering vehicle in unknown GPS-denied environments IEEE international conference on robotics and automation pp. 2643-2648, 2009 7 Kai s er N R  Ga n s W  E Di x o n   V is io n B a sed  Estimation for Guidance, Navigation, and Control of an Aerial Vehicle IEEE TRANSACTIONS ON AEROSPACE AND ELECTRONIC SYSTEMS pp. 10641077, VOL. 46, NO. 3, July 2010   Y u n  B L ee Y  J  L e e a n d S   S ung R eal T i m e Performance Test of an Vision-based Inertial SLAM The International Conference on Control, Automation and Systems 2010 Gyeonggi-do, Korea, 2010   J. L an d T h ack er N. A T u t o ri al   C o m p u t i n g 2D  and 3D Optical Flow. Tech. Rep. 012, Tina Memo, 2004  o rn al l  T Eg an G  O p t i c  f l o w  m e t h ods appl i e d t o  unmanned air vehicles, Academic Research Forum, Dept Elect. And Computer Systems Engineering, Monash University, Feb, 2003                       10 10 10 IMU/Vision/Lidar Time s  


  8 11 A  G i ac h e t ti, M Ca m p a n i a n d  V. T o r r e T h e Use o f  Optical Flow for Road Navigation IEEE Trans. Robotics and Automation vol. 14, no. 1, pp. 34-48, 1998  oderick  A  Ke h o e, J an d L i n d R  V i s io nBas e d  Navigation using Multi-Rate Feedback from Optic Flow and Scene Reconstruction Proceedings of the 2005 AIAA Guidance, Navigation, and Control Conference  San Francisco, CA, August 2005  o e, J Watk i n s  A Caus e y R a n d L i n d R  S ta te  Estimation using Optical Flow from Parallax-Weighted Feature Tracking Proceedings of the 2006 AIAA Guidance, Navigation, and Control Conference  Keystone, CO, August 2006   Z i ngg D  S cara m uzz a S  Wei s s  a n d R  S i e g w a rt  MAV Navigation through Indoor Corridors Using Optical Flow," in ICRA, 2010  dou l, F., F a ntoni, I Non a m i K O ptic Flo w Based Vision System for Autonomous 3D Localization and Control of Small Aerial Vehicles Robotics and Autonomous Systems 57, pp. 591-602., 2009  J Wang S Ha n  A  Al m a g b ile M A G a rratt  A. Lambert, and J. J. Wang, "Adding Optical Flow into the GPS/INS Integration for UAV navigation in IGNSS Symposium 2009 Surfers Paradise, Qld, Australia, 2009 17 J  Ki m a n d G B r a m b l e y  D u a l Op tic f lo w I n te g r at e d  Navigation for Small-scale Flying Robots in Proc. of Australasian Conference on Robotics and Automation  Brisbane, Australia, Dec 2007 18 S K o hl b r e c he r  J  M e y e r   O  vo n St r y k  a n d U  K l i n ga uf  A Flexible and Scalable SLAM System with Full 3D Motion Estimation," in International Symposium on Safety, Security, and Rescue Robotics IEEE, Nov 2011   G r zonk a, G  G r i s e t t i an d W. Bu r g ard A Ful l y Autonomous Indoor Quadrotor IEEE Transactions on Robotics vol. 28, no. 1, pp. 90-100, Feb 2012  l a w o m i r G G   G i orgi o an d B. Wol f ra m   Autonomous Indoors Navigation using a Small-Size Quadrotor International Conference on Simulation Modeling and Programming for Autonomous Robots pp 455-463, 2008 21 D Ellis, T B r ad y  I Ol so n   Y Li Au t o n o m o u s Q u ad r o to r  for the 2012 International Aerial Robotics Competition 2012 Third Symposium on Indoor Flight Issues International Aerial Robotics Competition, 2012   J Lee, B.-D Y i m  a n d J.B S o ng  M obi l e  R obot  Localization based on Effective Combination of Vision and Range Sensors Int\222l J. of Control, Automation, and Systems vol. 7, no. 1, pp. 97-104, 2009  r em ebida, C   Ludwig, O and Nunes, U  LIDAR and Vision-Based Pedestrian Detection System Journal of Field Robotics vol. 26, no. 9, pp. 696-711, 2009   H u a n g an d M. Bart h  T i g ht l y C o u pl ed L ID A R a n d  Computer Vision Integration for Vehicle Detection," in Proc. IEEE Intelligent Vehicles Symposium pp. 604-609 Jun 2009  h ada m W S  Wi j e s o m a a n d J. F  D o ng  Improving Path Planning and Mapping Based on Stereo Vision and Lidar," In Proceedings of the International Conference on Control, Automation, Robotics and Vision  2008  i ng W O pt i m a l Int e g rat i o n o f G P S  w i t h Inert i a l  Sensors: Modelling and Implementation," Ph.D. thesis University of New South Wales, Sydney, 2008  Bru h n  A  We ic k e rt J  Sc hn 366rr, C    Lu c a s  K a n ade  meets Horn/Schunck: combining local and global optic flow methods International Journal of Computer Vision  vol. 61, no. 3, pp. 211-231, 2005 


  9 Biographies Sukchang Yun received the M.S degree in aerospace engineering from Konkuk University, Seoul Korea, in 2009, where currently he is working toward the Ph.D. degree in the Department of Aerospace Information Engineering. His recent research interests include INS/GPS integration, Simultaneous Localization and Mapping, heterogeneous sensor fusion and avionics hardware instrumentation Young Jae Lee received his Ph.D degree in Aerospace Engineering from the University of Texas at Austin in 1990. He is a Professor in the Department of Aerospace Information Engineering at Konkuk University, Korea. His research interests include integrity monitoring of GNSS signal, GBAS RTK, attitude determination, orbit determination, and GNSS-related engineering problems Sankyung Sung received his B.S and Ph.D. degrees in Electrical Engineering from Seoul National University, Seoul, Korea, in 1996 and 2003, respectively. From March 1996 to February 2003, he worked for the Automatic Control Research Center in Seoul National University. Currently, he is an Associate Professor of the Department of Aerospace Information Engineering, Konkuk University. His research interests include avionic system hardware and IT fusion technology, inertial sensors, integrated navigation, and application to unmanned systems 


212\212        11 0 100000 0010000 0001000 00 0 2 0 002 02 0 002 2 0 0 000 0 0 0 0 000 0 0 0 0 000 0 0 0 0 ei e D E ei e i e D N ei e E N ie ie ie ie sL L sL cL LcL gR sL L f f gR sL cL f f F gR L cL f f sL L s Lc L Lc L 327\327   327\212   where  L   10 APPENDIX A  Detailed expression for 11 F of the system matrix from equation \(5  212\212 212 212 212 212  12 12 22 33 0\(3 3 0\(3 3 0\(33 000 0\(3 3 n b n b FCF FFdiag C 212  212  b b\b b 003\b 003\b 003\b 003\b 003\b 003\b 003\b 003\b 003 Earth rate vector  N f  E f  D f specific force w.r.t. navigation frame s L sin L  L cos L   212\212 212 b the longitude and latitude g: gravity  e R Earth radius  ie 327   212 


  11   Fi g u r e  17  e re n c e  i n  D S S 43 a nd D S S S P c N o   Af t e r  E DL   E v e n t  R e c o r d s   E VR s   t h a t  l o g g e d  e a c h  t o n e  is s u e d  d u r in g  E D L  w e r e  obt a i ne d f r om  M S L   Th e s e  l o g s  we r e  c o m p a r e d  wi t h  t h e  r e a l tim e  r e s u lts  p r o v id e d  b y  th e  ED A  t o  d e t e r m i n e  p e r f o r m a n c e    Th e  D TE c o m m u n i c a t i o n s  sy st e m  r e c e i v e d  a n d  c o r r e c t l y  i d e n t i f i e d  1 0 0   o f  ra d i a t e d   i n r e a l tim e  d u r in g  M S L  E D L   Th e s e  r e s u l t s  a r e  co n s i s t en t  w i t h  t h e t h eo r et i cal  pr oba bi l i t i e s  of  c a r r i e r  acq u i s i t i o n  t r ack i n g  an d  d at a t o n e d et ect i o n  co m p u t ed  i n  Se c t i o n  3   5   C ON   Th e  D i r e c t to Ea r t h  X ba nd c om m uni c a t i ons  s ys t e m  ut i l i z e d dur i ng M S L  E D L  s uc c e s s f ul l y de t e c t e d a l l  ra d i a t e d   de s pi t e  c ha l l e ngi ng s i gna l  dyna m i cs  w i t h  l ar g e u n k n o w n  ch an g es  i n  D o p p l er  f r eq u en cy   r at e  an d  accel er at i o n   Fu t u r e  m i s s i o n s  w i t h  p e r i o d s  o f  r a p i d  a n d  u n k n o w n  s i g n a l  dyna m i c s  s uc h a s  Ma r s  o r  i c y  m o o n  la n d e r s  can  l ev er ag e fr o m  t h e  M S L  de s i gn f or  D T E  c om m uni c a t i ons    6   A CK NO W L E DG E M E NT S   T he  a ut hor s  w oul d l i ke  t o a c know l e dge  t he  c ont r i but i on s   Ja n  T a r sa l a   te s tin g  o f  th e  E D A  p r io r  to  M S L  E D L  us i ng a  P R S R  a nd M S L  t e s t be d    Th e  a u t h o r s  w o u l d   th a n k  J e r e m y  S r  fo r  p r o v i d i n g  6 D O F  s i m u l a t i o n  d a t a  th a t w a s  v a lu a b le  in  c o n f ig u r in g  th e  E D A   Th e  a u t h o r s  wo u l d  a l s o  l i k e  t o  t h a n k  t h e  C DS C C  s t a t i o n  p e r s o n n e l  f o r  th e ir  e x c e lle n t s u p p o r t a n d  ope r a t i ons  of  t he  D S N  eq u i p m en t  an d  t h e F u l l  S p ect r u m  P r o ces s o r  A r r ay  i n  u   Th i s  r e s e a r c h  w a s  c a r r i e d  o u t  a t  t h e  J e t  P r o p u l s i o n  La b o r a t o r y   C a l i f o r n i a  I n s t i t u t e  o f  Te c h n o l o g y    Co p y r i g h t  2012 C a l i f or ni a  I ns t i t ut e  of  T e c hnol ogy  Go v e r n m e n t  sp o n so r sh i p  a c k n o w l e d g e d     


  12  R EF ER EN C ES   1  E  S a t o r i u s   P   Es t a b r o o k   J   W i l s o n   D   F o rt    D i re c t to  Ea r t h  c o m m u n i c a t i o n s  a n d  s i g n a l  p r o c e s s i n g  f o r  M a r s  ex p l o r at i o n  r o v er  en t r y   d es cen t  an d  l an d i n g   T h e In t e rp l a n e t a ry  N e t w o rk  P ro g re s s  R e p o rt   IP N  P ro g re s s  Re p o r t  4 2 2003  2 A n d re  J o n g e l i n g  an d  S u s an  F i n l ey     M ar s  S ci en ce La b o r a t o r y  Te l e c o m  S y s t e m  En g i n e e r i n g  P r e  Re v i e w   E D L  D a t a  A n a l y s i s  S i m u l a t i o n s  Re s u l t s     A p r i l  24  2007   3 W   J   H u rd   P   E s t a b ro o k   C   S   R a c h o   a n d  E   S a t o ri u s   C r i t i cal  sp acecr af t to ear t h  co m m u n i cat i o n s   ex p l o r at i o n  r o v er   M E R   en t r y   d es cen t  an d  l an d i n g   Pr o c   I E E E  A e r o s p a c e  C o n f e r e n c e   v o l  3   p p   1 2 8 3  MT   Ma r c h  2 0 0 2    4 M  S o r i a n o   S   F i n l e y   A   J o n g e l i n g   D   F o r t   C   G o o d h a r t   D  R o g s t a d   R   Na v a r r o    Sp a c e c r a f t to Ea r t h  Co m m u n i c a t i o n s  fo r J u n o  a n d  M a rs  S c i e n c e  L a b o ra t o ry  Cr i t i c a l  E v e n t s   P r o c  I E E E  A e r o sp a c e  C o n f e r e n c e   M T   2   5 A   M a k o v s k y   P   Il l o t t   J   T a y l o r    M a rs  S c i e n c e  La b o r a t o r y  Te l e c o m m u n i c a t i o n s  S y s t e m  D e s i g n    D e e p  Sp a c e  C o m m u n i c a t i o n s  a n d  N a v i g a t i o n  Sy s t e m s  C e  of  E xc e l l e nc e  D e s i gn a nd P e r f or m a nc e  S um m a r y S e r i e s   No v e m b e r  2 0 0 9   6 M   S o ri a n o  a n d  P   E s t a b ro o k    M S L  E D L  S i m u l a t i o n s   i n t e rn a l  d o c u m e n t   J e t  P ro p u l s i o n  L a b o ra t o ry   P a s a d e n a   CA   M a y  7   2 0 1 2   7  Sa t o r i u s  R e v i s e d  T h r e s h o l d s  f o r  E D L    i n t e r n  doc um e nt    J e t  P r opul s i on L a bor a t or y  P a s a de na   C A   Ja n u a r y  1 4   2 0 0 3   8 A   K w o k     M o d u l e  2 0 6  Te l e m e t r y  G e n e r a l  In fo rm a t i o n    i n DS N  T e l e c o mmu n i c a t i o n s  L i n k  De s i g n  k B   D S N  N o  8 1 0 005   P a s a de na  Ca l i f o r n i a   J P L   Oc t o b e r  3 1   2 0 0 9  ht t p   e i s  j pl  na s a g o v d e e p s p a c e d s n d o c s 8 1 0 005     


  13  M el i s s a  S o r i a n o  ff f tw a r e  e n g in e e r  in  th e  T r a c k in g  Sy s t e m s  and A ppl i c at i ons  Se c t i on at  t he  J e t  P r opul s i on L abor at or y    She  has  de v e l ope d r e al  so f t w a re  f o r t To  co m m u n i ca t i o n s  w i t h  M a r s  Sc i e nc e  L abor at or y  dur i ng E nt r y   De s c e n t   a n d  L a n d i n g   th e  L o n g  W a v e le n g th  Ar r a y   N AS A s  Br e a d b o a r d  Ar r a y   a n d  t h e  W i d e b a n d  VL BI  S c i e n c e  Re c e i v e r  u s e d  i n  t h e  D e e p  S p a c e  N e t w o r k   Me l i s s a  i s  a l s o  cu r r en t l y t h e s o f t w a r e co g n i z a n t  en g i n eer  f o r  t h e D S C C  Do w n l i n k  A r r a y   She  has  a B  S   fr o m  C a lte c h  d o u b le  m a jo r  in  E le c tr ic a l a n d  C o m p ut e r  E ngi ne e r i ng and B us i ne s s  Ec o n o m i c s  a n d  M a n a g e m e n t    S h e  a l s o  h a s  a n  M  S    Co m p u t e r  S c i e n c e  fr o m G e o r g e M a so n  U n i v e rsi t y   Sus a n F i nl e y  is  a  k e y  s ta ff me mb e r  i n  t h e  P r o c e s s o r  S y s t e ms  De v e l o p me n t  Gr o u p  a t  J P L     is  th e  s u b s y s te m  e n g in e e r  fo r  th e  Fu ll S p e c tr u m  P r o c e s s o r  su b sy st e m  d e p l o y e d  i n  N A S A  s De e p  S p a c e  N e t w o r k     exp er i en ce i n cl u d es  t h e o p er a t i o n  of  t he  E D A  f or  bot h of  t he  M E R  l andi ngs  on M ar s  as  w e l l  as  th e  o p e r a tio n  o f th e  R a d io  S c ie n c e  R e c e iv e r  fo r  th e  la n d in g  o f th e  H u y g e n s  P r o b e  o n  T it an and f or  t he  P hoe ni x  l andi ng on s    Da v i d  t  re c e i v e d  a  B  A  S c  i n  En g i n e e r i n g  Ph y s i c s  a n d  M  S c  i n  As t r o n o m y  f r o m  t h e  U n i v e r s i t y  o f  To r o n t o  a n d  a n  M S c   a n d  P h  D   i n  Ra d i o  As t r o n o m y  f r o m  t h e  U n i v e r s i t y  of  M anc he s t e r    H e  j oi ne d N R C  C a n a d a  i n  1 9 7 2  a n d  w o r k e d  o n  a l l  as pe c t s  of  V L B I  unt i l  1987   H e  su b se q u e n t l y  j o i n e d  J P L  i n  se c t i o n  3 3 5  a n d  w o rk e d  o n  a  num be r  of  har dw ar e  and s of t w ar e  pr oj e c t s  f or  t he   be c am e  s upe r v i s or  of  t he  P r oc e s s or  Sy s t e m s  de v e l opm e nt  Gr o u p  f o r  t h e  t w o  y e a r s  p r i o r  t o  r e t u r n i n g  t o  N R C  i n  2 0 0 2   Un t i l  h i s  r e t i r e me n t  i n  2 0 1 0  h e  w o r k e d  o n   Co r r e l a t o r  P r o j e c t    No w a   G u e s t  W o r k e r    h e  h e l p s  o u t  wi t h  t h e  E V L A  a s  i t  b e c o m e s f u l l y  o p e ra t i o n a l  a n d  w i t h  oc c as i onal  que s t i ons  f r om  J P L    Br i a n  S c h r a t z  is  th e  le a d  e n g in e e r  fo r  th e  E D L  te le c o m m u n ic a tio n s  o n  th e  Ma r s  S c i e n c e  L a b o r a t o r y  m i s s i o n  a n d  a m e m be r  of  J P L  s  C om m uni c at i ons  Sy s t e m s  and O pe r at i ons  gr oup      jo in e d  J P L  th r e e  y e a r s  a g o   B S  E E  a n d  M  S  E E   Pe nns y l v ani a St at e  U ni v e r s i t y    Pe t e r  I l o t t  is  th e  te le c o m m u n ic a tio n s  sy st e m  l e a d  f o r t h e  M S L  m i ssi o n   H e  has  w or k e d on s pac e c r af t  te le c o m m u n ic a tio n s  s y s te m  d e s ig n  fo r  2 5  y e a r s  1 1  y e a r s  o n  c o m m e r c ia l sp a c e c ra f t   a n d  si n c e  2 0 0 0  a t  J P L    wo r k e d  o n  M E R   P h o e a te le c o m m u n ic a tio n s  s y s te m  e n g in e e r  Pe t e r  w o r k e d  o n  a l l  t h e  M a r s  ED L   e n t r y  and la n d in g   e ffo r ts  s in c e  M E R  a n d  in  b e tw e e n  M a r s  m is s io n s  he l pe d out  on t he  D e e p I m pac t  and C l oudat  mi s s i o n s  a t  J P L   He  c u r r e n t l y  s u p p o r t s  t h e  M S L  s u r f a c e  mi s s i o n  p h a s e   a n d  i s  th e  te le c o m m u n ic a tio n s  le a d  fo r  th e  E u r o p a  m is s io n  cu r r en t l y u n d er  s t u d y  I l o t t  h o l d s  B S c  M S c  a n d  P h D  de gr e e s  i n phy s i c s  and e l e c t r i c al  en g i n eer i n g  f r o m  M cG i l l  i st y  o f  M o n t re a l    i  re c e i v e d  t h e  B  S  E  E   and t he  M  S E  E   i n 1997 and t he  Ph  D   i n  El e c t r i c a l  En g i n e e r i n g  i n  2003  al l  f r om  U C L A    He  h a s  b e e n  em p l o yed  a t  t h e Jet  P r o p u l s i o n  La b o r a t o r y  a s  a  Te l e c o m m u n i c  en g i n eer  s i n ce 1 9 9 9  a n d  h a s  s er ved  on t he  M ar s  E x pl or at i on R ov e r   DA W N   C a s s i n i   J u n o   a n d  M a r s  Sc i e nc e  L abor at or y  pr oj e c t s     Po l l y  E s t a b r o o k  is  th e  d e p u ty  ma n a g e r  o f  t h e  C o mmu n i c a t i o n  Ar c h i t e c t u r e s  a n d  Re s e a r c h  S e c t i o n  at  J P L     She  i s  a m e m be r  o f N A S A  s  Spac e  C om m uni c at i on and Na v i g a t i o n  P r o g r a m  s u p p o r t i n g  t h e  de f i ni t i on of  t he  N A SA  s  f ut ur e  In t e g r a t e d  C o m m u n i c a t i o n  a n d  Na v i g a t i o n  Ne t wo r k  a n d  i s  a  m e m b e r  o f  t h e  I n t e g r a t e d  Sy s t e m  E ngi ne e r i ng t e am  f or  t he  M ar s  Sc i e nc e  L abor at or y  r   Fr o m  2 0 0 5  t o 2010  s he  l e d s e v e r al  c om m uni c at i on sy st e m  d e si g n  t e a m s w i t h  t h e  g o a l  o f  d e f i n i n g  t h e  mo d i f i c a t i o n s  t o  N A S A  s  S p a c e  C o mmu n i c a t i o n  a n d  Na v i g a t i o n  i n f r a s t r u c t u r e  n e e d e d  t o  s u p p o r t  t h e  p l a n n e d  hum an m i s s i ons  t o t he  M oon and M ar s   F r om  2000 t o 2004 sh e  w a s t he  l e ad t e l e c om  s y s t e m  e ngi ne e r  f or  t he  M ar s  Ex p l o r a t i o n  Pr o j e c t   r e s p o n s i b l e  f o r  t h e  p e r f o r m a n c e  o f  t h e  en t r y d es cen t  a n d  l a n d i n g  t el eco m m u n i ca t i o n s  s ys t em  a n d  fo r  th e  o v e r a ll d e s ig n  a n d  p e r fo r m a n c e  o f th e  D ir e c t to  Ea r t h  a n d  r e l a y  c o m m u n i c a t i o n s  s y s t e m s   In  2 0 0 4   D r   Es t a b r o o k  r e c e i v e d  t h e  N AS A Ex c e p t i o n a l  Ac h i e v e m e n t  Me d a l  f o r  h e r  w o r k  o n  t h e  Ma r s  E x p l o r a t i o n  R o v e r  T e l e c o m  Sy s t e m   She  has  w r i t t e n ov e r  35 t e c hni c al  pape r s  and ch a i r ed  n u m er o u s  I E E E  a n d  A I A A  co n f er en ce S es s i o n s    Po l l y  Es t a b r o o k  r e c e i v e d  h e r B  A   i n  e n g i n e e ri n g  p h y si c s fr o m  th e  U n iv e r s ity  o f C a lifo r n ia  B e r k e le y  a n d  M S  a n d  Ph  D   d e g r e e s  i n  e l e c t r i c a l  e n g i n e e r i n g  f r o m  S t a n f o r d  Un i v e r s i t y   S t a n f o r d   C A      


  14  Ka m a l  O u d r h i r i  is  a  s e n io r  r  in  th e  R a d io  S c ie n c e  Sy s t e m s  G r oup at  NA S A  s  J e t  Pr o p u l s i o n  L a b o r a t o r y   As  a co n t r a ct  t ech n i ca l  m a n a g er   Ou d r h i r i  lti di s c i pl i nar y  te a m s  th r o u g h  th e  de s i gn  im p le m e n ta tio n  a n d  d e liv e r y  of  flig h t h a r d w ar e  t o t he  r adi o sc i e n c e  c o m m u n i t y   Ov e r  t h e  l a s t  d e c a d e   Ou d r h i r i  se rv e d  i n  key r o l es  o n  m u l t i p l e N A S A  mi s s i o n s   T h e  M a r s  E x p l o r a t i o n  s  M E R   t h e  In t e r n a t i o n a l  C a s s i n i  m i s s i o n  t o  Sat ur n T he  GR A I L  l u n a r  mi s s i o n  a n d  T h e  M a r s  S c i e n c e  La b o r a t o r y     Da n i e l  K a h a n  is  a s e ni or  m e m be r  of  S ci en ce S ys t em s  G r o u p  at  NA S A  s  J e t  Pr o p u l s i o n  La b o r a t o r y   Ov e r  t h e  l a s t  ei g h t  yea r s   h e h a s  pr ov i de d e ngi ne e r i ng s uppor t  f or  t he  i o s c i e nc e  c om m uni t y   NA S A  m i s s i o n s   i n c l u d i n g  M a r s  G l o b a l  Sur v e y or   M ar s  R e c onnai s s anc e  Or b i t e r   th e  G R A I L  lu n a r  m is s io n  th e  In t e r n a t i o n a l  C a s s i n i  mi s s i o n  t o  S a t u r n   a n d  Ma r s  S c i e n c e  La b o r a t o r y   Ed g a r  H   S a t o r i u s  is  a  p r in c ip a l me mb e r  o f  t h e  t e c h n i c a l  s t a f f  i n  th e  F lig h t C o m m u n ic a tio n s  Sy s t e m s  Se c t i on of  t he  J e t  Pr o p u l s i o n  L a b   H e  p e r f o r m s  sy st e m s a n a l y si s i n   de v e l opm e nt  of  di gi t al  s i gnal  e ssi n g  a n d  c o m m u n i c a t i o n s sy st e m s w i t h  sp e c i f i c  a p p l i c a t i o n s t o  b l i n d  d e m o d u l a t i o n   di gi t al  di r e c t i on f i ndi ng and di gi t al  r e c e i v e r s   H e  has  publ i s he d ov e r  90 ar t i c l e s  and hol ds  t w o pat e nt s  i n t he  f i e l d of  di gi t al  s i gnal  pr oc e s s i ng and i t s  appl i c at i ons   I n a ddi t i on  he  i s  an A dj unc t  A s s oc i at e  P r of e s s or  at  t he  U ni v e r s i t y  of  Sout he r n C al i f or ni a w he r e  he  t e ac he s  di gi t al  s i gnal  pr oc e s s i ng c our s e s   H e  r e c e i v e d hi s  B  Sc   i n e ngi ne e r i ng fr o m  th e  U n iv e r s ity  o f C a lifo r n ia  L o s  A n g e le s  a n d  th e  M S  and P h D   de gr e e s  i n  el ect r i ca l  en g i n eer i n g  f r o m  t h e Ca l i f o r n i a  I n s t i t u t e  o f  T e c h n o l o g y   P a s a d e n a   Ca l i f o r n i a   


Example 2: Identifying Causal Factors CAUSAL FACTORS  Indicators – Data Element Methods – Identifying Context and Causes  Time of day  Date range \(month day  Aircraft type  Fix or coordinates  Originating airport  Destination airport  Weather notes We pinpoint the sequencing of flights on the IAH Junction Seven departure \(at CUZZZ\the specified wind conditions to find cases wher e a B737-900 at 20,000 feet precedes by 11 miles a B737-800 at 17,000 feet  Search related data sets including ASDI flight tracks, local traffic and congestion  Weather conditions for alter native causes \(winds aloft shear and convecti ve activity  Airline specific informati on \(repeated occurrence of event in aircraft type Big data gives us visibility into contextual factors even if specific data points are missing such as a specific date or route Big-data analytics gives us insight into unreported factors as well 


Example 3: Correlating Utilization and Delays  60 65 70 75 80 85 90 95 100 7 9 11 13 ONTIME DEPARTURE PERFORMANCE HOURS OF DAILY UTILIZATION 60.0 70.0 80.0 90.0 100.0 7.0 9.0 11.0 13.0 Narrowbodies By Day of Week 60.0 70.0 80.0 90.0 100.0 7.0 9.0 11.0 13.0 Widebodies by Day of Week Daily Utilization vs. On-time Departures January 2013 System Operations Correlation Coefficient -0.53 Includes AA, AC, AS B6 F9, FL, NK, UA, US VX and WN SOURCE masFlight \(masflight.com COMPARING OTP AND UTILIZATION 


 6.2 6.0 5.8 5.8 5.2 4.9 LGB JFK BOS MCO DCA FLL JetBlue Focus Average Daily Deps per Gate Used UTILIZATION BY HUB Example 4: Daily Utilization of Gates, by Hub Big-data analysis of different carriers daily departures per gate used SOURCE masFlight \(masflight.com June 1 through August 31, 2012 Gates with minimum 1x daily use 7.7 7.4 7.2 6.2 6.1 5.8 3.8 3.6 ORD LAX SFO EWR DEN IAH IAD CLE United Airlines Hubs Average Daily Deps per Gate Used 7.8 6.4 5.5 5.4 5.3 4.4 4.3 4.0 SEA SAN PDX ANC SFO GEG LAX SJC Alaska Airlines Hubs Average Daily Deps per Gate Used 7.2 6.9 6.8 6.4 5.0 2.7 ORD DFW LAX LGA MIA JFK American Hubs Average Daily Deps per Gate Used 7.2 6.9 6.6 4.9 4.2 CLT DCA PHL PHX BOS US Airways Hubs Average Daily Deps per Gate Used 6.6 5.9 5.5 4.7 MCO BWI ATL MKE AirTran Hubs Average Daily Deps per Gate Used ne pe 


Conclusions for Big Data in Aviation  Big-data transforms operational and commercial problems that were practically unsolvable using discrete data and on-premises hardware  Big data offers new insight into existing data by centralizing data acquisition and consolidation in the cloud and mining data sets efficiently  There is a rich portfolio of information that can feed aviation data analytics  Flight position, schedules, airport/gate, weather and government data sets offer incredible insight into the underlying causes of aviation inefficiency  Excessive size of each set forces analysts to consider cloud based architectures to store, link and mine the underlying information  When structured, validated and linked these data sources become significantly more compelling for applied research than they are individually  Today’s cloud based technologies offer a solution CONCLUSIONS 


Conclusions:  Our Approach  masFlight’s data warehouse and analysis methods provide a valuable example for others attempting to solve cloud based analytics of aviation data sets  masFlight’s hybrid architecture, consolidating secure data feeds in on-premises server installations and feeding structured data into the cloud for distribution, addresses the unique format, security and scale requirements of the industry  masFlight’s method is well suited for airline performance review competitive benchmarking, airport operations and schedule design and has demonstrated value in addressing real-world problems in airline and airport operations as well as government applications CONCLUSIONS 





