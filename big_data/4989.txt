CTS 2013 PREFACE  Welcome to the 2013 International Conference on Colla boration Technologies and Systems \(CTS 2013\.  During the conference, attendees will see and interact with a broad spectrum of methodologies and technologies that relate to cooperation, coordination, communication, a nd collaboration at both the c lient and backend \(cloud levels.  This year\222s conference presents a wide array of papers, posters, workshops 
panels, demonstrations exhibits, presentations, and tutorials addressing a broad ra nge of topics including sensors, robots, people, and social networks, big data, biology knowledgebase, groupware, citizen science, crowd sourcing, human-computer interaction, visualization, virtual environments, user interfaces, gaming, e-learning, e-business, e-health emergency response, knowledge management, decision ma king using clouds, global grids, P2P, multi-agent systems, mobile clients, wearable devices, Web 2.0 with resilience, trust and security, and related human and 
socio-technical collaboration issues  Today\222s computer and information technologies see dram atic progress in both lightweight clients and megascale backend systems \(clouds\ supporting them. This s upports seamless and borderless information delivery and services for anyone, anywhere, and anytime. The interna tional free flow of information is having huge sociopolitical impacts on countries where stri ct censorship and limits on informat ion and news exchange had been 
traditionally  and culturally accepted World-wide, people expect unlimited access to information within and across cultures.  Social networking continues to expand even at the enterprise level, and businesses are struggling to devise policies on the appropriate use of applications such as Facebook, Twitter, blogs, and texting. The desire for mobile and pervasive connectivity is pushing expansion of an ever gr owing wired and wireless high speed backbone that globally combines computing, sensing, a nd communication technologies. Annually, new classes of 
mobile devices are added to the traditional desktop, note book computers, tablet PCs, and netbooks.  Most recently multi-modal touch screen devices, pioneered by Apple\222s iPhone \231 and iPad \231 with comparable importance of Android-based systems, have significantly improved the eas e of use of personal collaboration instruments.  The new mobile devices provide immediate access to people, em ail, entertainment and knowledge and have created a marketplace for hundreds of thousands of new applica tions.  The Internet of Things captures the growing 
importance of sensor swarms; often attached to one\222s sm artphone or wristwatch. These applications are enabled by backend clouds but their utility depends on their value to people  Underlying infrastructure such as cloud computing, servi ce oriented architectures, and smart networks and grids offer the vision of resources \(networks, computational ser vers, storage, etc.\as a service with greater ease to collaborate and while also lowering cost. At the same time, there are increasing challenges for privacy and 
security as we attempt to understand how to handle trust in complex systems and how to measure trustworthiness in human to human, human to machine, machine to human, and machine to machine collaboration  CTS is the premier international research conference in the major areas related to collaboration, communication and their underlying technologies.  It offers an exceptiona l opportunity to interact with world class researchers in collaboration and related arenas and discuss the results of 
the best research in the dom ain.  The conference gives us insight into what collaboration is today and what 21st century collaboration will be based on technologies now in research and development.  We hope you enjoy and l earn from the tremendous exchange of ideas and concepts that will be presented in this year\222s conference sessions  Geoffrey Fox and Waleed W. Smari CTS 2013 Conference Co-Chairs Bloomington, Indiana and Dayton, Ohio, USA April 2013 


CTS 2013 PROGRAM MESSAGE   On behalf of the Organizing and International Technical Program Committees, we are delighted to present these proceedings of the 2013 International Conference on Collaboration Technologies and Systems \(CTS 2013 program.  This year is the 14 th anniversary of the CTS conferences.  We are pleased to have this milestone and look forward to continuous contributions to the commun ity and bringing the state-of-the-art in research and development in this domain  The conference this year is held May 20-24, in San Di ego, California, USA.  The meeting provides a dynamic forum to address, explore, and exchange informati on, knowledge, and experiences in the state-of-the-art collaborative enterprises, their modeling and simulation, d esign and use, and impact.  The goal of CTS meetings is to bring together researchers, sc ientists, engineers, practitioners, educat ors, and students from many nations and backgrounds to share and exchange their insights, br eakthroughs, and research results about various aspects of collaboration systems and technologies; to discuss challeng es encountered in government, industry, and academe and to seek new and innovative solutions.  Additionally we hope that the Conference will provide opportunities for many open technical interchanges in individual and group settings on key technology issues.  It is our hope that the Conference will provide opportunities for future collaborations among the participants  This year, and despite the continuation of the challengi ng times, the CTS Conference is run with parallel sessions over a period of four days, including one full day of parallel tutorials.  For the fifth year, we have full day parallel sessions on all days of the conference to accommodate the nu mber of presentations we have this year.  As in previous years\222 successful meetings, the Conference conti nues to enjoy excellent growth and a diverse program The Proceedings contains papers on many timely a nd emerging topics.  We received a good number of submissions and the quality of the ov erall manuscripts pool was excellent There was a total of 153 paper submissions to main and all other tracks from 37 countries.  The top five countries with most submissions were the USA with about 36%, followed by Italy \(9.6%\ France 7.4%\ \(4.8%\, and Saudi Arabia \(4%\.  In the main track, each manuscript unde rwent a minimum of four rigorous reviews plus two independent evaluations.  It was a challenge to select papers for incl usion in the proceedings.  The acceptance rate this year was about 34.21% \(26 papers were accepted in the main track out of 76 submitted\y-one manuscripts were accepted in the symposia, workshops and special sessions 8 invited talks, 4 poster pa pers, 3 doctoral dissertation colloquium abstracts, and 6 research posters abstracts The Conference had ten symposia, workshops and special sessions, all with rigorously reviewed papers \(a minimum of three reviews per manuscript\ch of the symposia, workshops and special sessions handled their pa pers separately but maintained similar standards for paper evaluation and acceptance as much as possible.  Th ese proceedings include a total of 104 contributions regular papers, short papers, poster papers, extended abstracts, etc.\om the submissions.  The program\222s technical papers represen t works from academia, research laboratories, government practitioners, and industry  The five-day final program is strong and diverse.  It consists of an opening remarks session, four keynote speeches, a plenary session, four tutori al sessions, three demo sessions, twenty-five technical sessions, a posters session, three panel sessions, a Doctoral Dissertation Co lloquium \(DDC\ session, a conference reception, a luncheon and a banquet dinner, three meet & greet sessions nine short breaks, exhibits, and three other social events, including full-day excursions to Balboa Park, the San Diego Zoo, and the San Diego Safari Park.  For the fourth time, we have three doctoral dissertation presentati ons as part of the DD Colloquium.  We hope that the DDC will provide a useful mentoring opportunity to our future researchers and leaders. Throughout the program students continue to be involved in various activities  We would like to thank first all the participants a nd authors who submitted works and papers to the CTS Conference this year.  The program is built from their hard work and contributions.  We also wish to thank the many people who helped make this Conference happe n successfully: our Keynote Speakers Loren Terveen Gerhard Fischer, Victoria Bellotti, and Cindy Pickeri ng; our Plenary Speaker Robert Neches; our Invited 


Speakers: Rachid Alami, Yunana Chen, Cory Knobel, Pe ter M. Kogge, Jeffrey W. Nic hols, Milind Tabe, and Eric R Wade; our Symposia, Workshops and Special Sessions Organizers: Marc Smith, Flavio Villanustre, Trish McCall, Geoffrey Fox, Eli Blevis  Muhammad Anan, Syed Misbahuddin, Musa Ayyash, Goce Trajcevski, Wei Chen, Edmund Durfee, Myriam Abramson, Robert Neches, Selma \212abanovi Cindy L. Bethel, Adriana Tapus Eric Meisner, Connie White, Tammy Karlgaard, Murray E Jennex, Joel Aud, James C. Hagen, Antonio Navarro Mart\355n, Alex Mu-Hsing Kuo, Danilo Pani, Haibin Zhu  Joan Reynaud, Marc Pasquet, Bechir Hamdaoui, Ammar Rayes, Sergiu Dascalu, Francesco Be llotti, C. Shaun Longstreet, Carolina Islas Sedano, Bill Kapralos, Claudia Diamantini, Domenico Potena, J. Cecil, Sanjay Kuma r Madria, and Mark Linderman our Tutorials presenters Marc A. Smith, Michele Missikoff, Matthew J. Bietz Cory Knobel, Katie Pine, and Sanjay Kumar Madria; our Demo Sessions presenters: Mary Galvin, Lutz Gerick e, and John Hamilton; Pane l Sessions moderators and panelists:  Aditya Sehgal, Jacob Spoelstra, Nikolaos Vasiloglou, Radhika Subramanian, Mary Czerwinski Gerhard Fischer, Loren Terveen, Kathl een A. Kramer, Christopher Clarke, Shelley Y. Hawkins, Gordon K. Lee Rex E. Gantenbein; and last but not least our Doctoral Dissertation Colloquium contributors: Charalampos Chelmis, Rabia Noor Enam, and Laura Genga  We also wish to recognize the contributions of our A dvisory Committee members who provided us with excellent suggestions and advice whenever needed.  Our superb co llection of papers and presentations was possible through the diligent work of the International Technical Pr ogram Committees.  The ITPC co-chairs, members and reviewers did an exceptional job and we are grateful for their help in reviewing and evaluating the paper submissions.  We also recognize the contribution and s upport of the CTS 2013 exhibitors and sponsors who made many of the Conference\222s activities possible.  Last but not least, we wish to thank all members of the Organizing Committee and student assistants without whom this conference would not have been possible  On behalf of the organizers, the ITPC and all those w ho made CTS 2013 a reality, we hope you find this volume of value, thought provoking a nd interesting, as have been the case in the past years  Thank you and we look forward to seeing all of you at our CTS 2014 conference   Waleed W. Smari and Geoffrey C. Fox CTS 2013 Organizing Committee Co-Chairs Dayton, Ohio, and Bloomington, Indiana, USA April 2013   


2 Optimization w.r.t   j   Let y j   y ij  i I j  We can update  j with the learned w 0 and W  P   j  w j  w 0  X  y j   P  y j  X  w j  j   P  w j  w 0  j   P   j        i I j exp k j  y ij    w T j x i  2  2   exp  j  w j  w 0  2 2      1 j exp   j    D  I j  2    1 j  exp      w j  w 0  2  k  i I j  y ij    w T j x i  2 2   j   Hence p   j  w j  w 0  X  y j  G      where      D  I j  2       1 2   w j  w 0  2  k  i I j  y ij    w T j x i  2   where D is the dimensionality of instances and I j  denotes the number of elements in the set I j  The expectation of  j is   j  E   j       2   D  I j  2    w j  w 0  2  k  i I j  y ij    w T j x i  2  15 We can get some intuition from 15  w j  w 0  2 measures the difference from the parameter of the j th personal classiìer to the parameter of nal classiìer learned groundtruth classiìer and  i I j  y ij    w T j x i  2 denotes the error of the personal classiìer on the training data The larger these differences errors are the smaller the corresponding  j will be Thus  j reîects the expertise score ability of the annotator j  which can be automatically learned from the training data By combining 15 with 12 we can get an algorithm which can automatically learn an expertise score for each worker Based on these learned scores our RPC model can learn a nal classiìer contributed more from good workers but less from poor workers or spammers This is more reasonable than PC model with equal weights for all workers 3 Summarization We summarize the algorithm for RPC model in Algorithm 1 During the learning of RPC we can eliminate the spammers in each iteration after we have found them The performance of the learned classiìer in the following iterations can be expected to improve due to the reduced noise spammer In Algorithm 2 we present the variant of the PRC algorithm called RPC2 that iteratively eliminates spammers in each iteration Algorithm 1 Robust personal classiìer RPC Input features  x i  M i 1 labels y ij  0  1  i 1 M j 1 N indicator matrix I max iter while iter num  max iter do update w 0 based on 12 update each w j based on 14 update each  j based on 15 end while Output w 0  W    j  N j 1 Algorithm 2 Robust personal classiìer with spammer elimination RPC2 Input features  x i  M i 1 labels y ij  0  1  i 1 M j 1 N indicator matrix I max iter spammer num while remove num  spammer num do while iter num  max iter do update w 0 based on 12 update each w j based on 14 update each  j based on 15 sort   j  N j 1  and remove z workers with the lowest values of  j remove num  remove num  z end while end while Output w 0  W    j  N j 1 IV E XPERIMENTS In this section we compare our model with some baseline methods including state-of-the-art methods on CL We validate the proposed algorithms on both simulated datasets and UCI benchmark datasets k is set to 1 in our experiments A Baseline Methods We compare our RPC model with two baseline methods majority voting MV and PC model to evaluate the effectiveness of RPC model MV is a commonly used heuristic method in CL tasks and PC model is the most related one Furthermore PC model has achieved the state-of-the-art performance according to the experiments in 1 Majority Voting In MV all the annotators contribute equally and a training instance is assigned the label which gets the most vote This method is very simple but strong in practice We train a logistic regression classiìer on the consensus labels MV can be adapted to measure the expertise of each annotator worker We compute the similarity between the labels given by each worker and the majority voted labels The similarity is treated as a measure of workerês expertise based on the fact that high-quality workers usually give similar labels as the ground-truth labels 341 


2 Personal Classiìer PC Model The PC model in can learn a classiìer for the underlying ground-truth labels So we can measure its area under the curve AUC on the testing data However the PC model does not provide a direct mechanism to measure the ability expertise of each worker so we only compare RPC with MV in terms of discriminating good workers from spammers in the experiment B Simulated Data We rst validate our algorithm on simulated data We assume there exist two types of annotators The rst type is called good annotators Due to worker ability and understanding bias for the labeling task the good annotators are assumed to give correct labels at a certain probability which ranges from 0.65 to 0.85 in the experiment The second type of annotators is spammers Spammers are assumed to give labels randomly regardless of the features The dimensionality of the feature vectors is 30 and each dimension is generated from a uniform distribution U   0  5  0  5  The parameter of the base model w 0 is generated from a Gaussian distribution with zero mean and identity covariance matrix The ground truth labels are calculated from the logistic function in 8 The noisy labels given by each worker are then generated according to whether they are good annotators or spammers For all the experiments we run the experiments 10 times and report the average results Let M denote the number of training instances For all the experiments we generate 10 M instances as the testing set Let R denote the number of good annotators and S denote the total number of annotators So the number of spammers is S  R  We use two metrics to evaluate our algorithms against baseline methods As the ground truth labels are known we compute the AUC for all the classiìers Another evaluation metric is the ability to detect good annotators We rank the expertise scores and fetch top n workers Among them we compute the precision of good annotators The n is set to R in our experiment if there are R good annotators in the training set 1 Classiìcation Accuracy We report the AUC on some datasets with different M  R and S in Table I TABLE I AUC PERFORMANCE  Data Set Parameters MV PC RPC Random Data 1 M 100 R 5 S 50 0.6014 0.6608 0.6718 Random Data 2 M 200 R 5 S 50 0.7544 0.8233 0.9032 Random Data 3 M 400 R 5 S 50 0.7760 0.8559 0.9520 Random Data 4 M 300 R 5 S 10 0.8838 0.9278 0.9695 Random Data 5 M 300 R 5 S 50 0.7153 0.8077 0.9091 Random Data 6 M 300 R 5 S 90 0.6641 0.7240 0.8346 We can see from Table I that RPC outperforms PC model and MV method on all the datasets 2 Ability to Discriminate Good Annotators from Spammers We evaluate the ability of the proposed RPC model to discriminate good annotators from spammers We generate 5 good annotators in this experiment We rank the expertise scores and check the ratio of the 5 highest scores to be truly good annotators we call this metric precision at top 5 Table II shows that RPC model can detect good annotators more accurately than MV method TABLE II P RECISION OF DETECTING GOOD ANNOTATORS AT TOP 5 Data Set Parameters MV RPC Random Data 1 M 100 R 5 S 50 0.3200 0.5000 Random Data 2 M 200 R 5 S 50 0.4200 0.7600 Random Data 3 M 400 R 5 S 50 0.7400 0.9400 Random Data 4 M 300 R 5 S 10 0.9600 1.0000 Random Data 5 M 300 R 5 S 50 0.4800 0.7200 Random Data 6 M 300 R 5 S 90 0.3000 0.7600 3 Effect of the Number of Spammers We are also interested in the sensitivity of performance when the number of spammers ranges from small to very large Fig 2 shows the AUC performance and the precision to detect good annotators in the top 5 positions with increasing number of spammers The number of good annotators in the training set is 5 We can nd that all the results degrade as more spammers are added RPC model still performs better than PC model and MV method 10 20 30 40 50 60 70 80 90 100 0.65 0.7 0.75 0.8 0.85 0.9 0.95 1    number of spammers Average AUC MV PC  RPC  RPC2  10 20 30 40 50 60 70 80 90 100 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1  number of spammers precision of good annotators MV RPC  a AUC b precision Fig 2 AUC and precision of good annotators detected on simulated data We vary the number of spammers from 10 to 100 by steps of 10 4 Effect of Missing Labels It is not practical for each worker to annotate all the instances in the dataset We test our model in this scenario Fig 3 gives the AUC performance and the precision to detect good annotators in the top 5 positions with increasing number of spammers when each instance is labeled by 30 of the annotators All the results drop signiìcantly compared with those of complete labels but the proposed RPC models still work better than the baselines C UCI Benchmark Data We use the breast cancer dataset from the UCI machine learning repository for e v aluation The cancer dataset contains 683 instances and each instance has 10 features dimensions In our experiments 400 instances are used for training and the rest is for testing We simulate the noisy labels with the same strategy as that in the previous section We generate 5 good annotators and vary the number of spammers 342 


  10  20  30  40  50  60  70  80  90  100  0.55  0.6  0.65  0.7  0.75  0.8  0.85  0.9  0.95          number of spammers Average AUC   MV  PC   RPC   RPC2     10  20  30  40  50  60  70  80  90  100  0  0.1  0.2  0.3  0.4  0.5  0.6  0.7  0.8      number of spammers precision of good annotators   MV  RPC   a AUC b precision Fig 3 AUC and precision of good annotators detected on simulated data with missing labels We vary the number of spammers from 10 to 100 by steps of 10 The AUC and precision of detecting good annotators are shown in Fig 4 We can nd that the proposed RPC can outperform both PC model and MV in terms of AUC and RPC model does much better than MV in detecting good annotators Moreover the RPC2 can further improve the performance of PRC by eliminating the spammers during the learning procedure   10  20  30  40  50  60  70  80  90  100  0.76  0.78  0.8  0.82  0.84  0.86  0.88  0.9  0.92  0.94  0.96          number of spammers average AUC   MV  PC   RPC   RPC2     10  20  30  40  50  60  70  80  90  100  0.2  0.3  0.4  0.5  0.6  0.7  0.8  0.9  1      number of spammers precision of good annotators   MV  RPC   a AUC b precision Fig 4 AUC and precision of good annotators detected on UCI dataset We vary the number of spammers from 10 to 100 by steps of 10 V C ONCLUSION A key problem in crowdsourced learning CL is about how to estimate accurate labels from noisy labels To deal with this problem we need to estimate the expertise level of each annotator worker and to eliminate the spammers who give random labels In this paper we propose a novel model called robust personal classiìer RPC model to discriminate high-quality annotators from spammers Extensive experimental results on several datasets have successfully veriìed the effectiveness of our model Future work will focus on empirical comparison between our model and other models such as those in on more real-world applications VI A CKNOWLEDGEMENTS This work is supported by the NSFC No 61100125 the 863 Program of China No 2012AA011003 and the Program for Changjiang Scholars and Innovative Research Team in University of China IRT1158 PCSIRT R EFERENCES  A J Quinn and B B Bederson Human computation a surv e y and taxonomy of a growing eld in Proceedings of the 2011 annual conference on Human factors in computing systems  ACM 2011 pp 1403Ö1412  L V o n Ahn Human computation  i n Design Automation Conference 2009 DACê09 46th ACM/IEEE  IEEE 2009 pp 418Ö419  J Deng W  Dong R Socher  L.-J Li K Li and L Fei-Fei ImageNet A Large-Scale Hierarchical Image Database in CVPR  2009  A P  Da wid and A M Sk ene Maximum lik elihood estimation of observer error-rates using the em algorithm Journal of the Royal Statistical Society Series C Applied Statistics  vol 28 no 1 pp 20 28 1979  P  Smyth U M F ayyad M C Burl P  Perona and P  Baldi Inferring ground truth from subjective labelling of venus images in NIPS  1994 pp 1085Ö1092  V  C Raykar  S  Y u L H Zhao G H V aladez C Florin L Bogoni and L Moy Learning from crowds Journal of Machine Learning Research  vol 11 pp 1297Ö1322 2010  Y  Y an R Rosales G Fung and J G Dy  Modeling multiple annotator expertise in the semi-supervised learning scenario in UAI  2010 pp 674Ö682    Acti v e learning from cro wds  i n ICML  2011 pp 1161Ö1168  J Y i  R  Jin A K Jain S Jain and T  Y ang Semi-cro wdsourced clustering Generalizing crowd labeling by robust distance metric learning in NIPS  2012 pp 1781Ö1789  H Kajino Y  Tsuboi and H Kashima  A con v e x formulation for learning from crowds in AAAI  2012  V  C Raykar and S Y u  Eliminating spammers and ranking annotators for crowdsourced labeling tasks Journal of Machine Learning Research  vol 13 pp 491Ö518 2012  Y  Baba and H Kashima Statistical quality estimation for general crowdsourcing tasks in KDD  2013  H Kajino Y  Tsuboi and H Kashima Clustering cro wds  i n AAAI  2013  S Oyama Y  Baba Y  Sakurai and H Kashima  Accurate inte gration of crowdsourced labels using workers self-reported conìdence scores in IJCAI  2013  K Mo E Zhong and Q Y ang Cross-task cro wdsourcing  i n KDD  2013  R Sno w  B OêConnor  D  Jurafsk y  and A Y  Ng Cheap and f ast but is it good evaluating non-expert annotations for natural language tasks in EMNLP  2008 pp 254Ö263  A Sorokin and D F orsyth Utility data annotation with Amazon Mechanical Turk in Computer Vision and Pattern Recognition Workshops 2008 CVPRWê08 IEEE 2008 pp 1Ö8  V  S Sheng F  J Pro v ost and P  G Ipeirotis Get another label improving data quality and data mining using multiple noisy labelers in KDD  2008 pp 614Ö622  J Whitehill P  Ruv olo T  W u  J  Ber gsma and J R Mo v ellan Whose vote should count more Optimal integration of labels from labelers of unknown expertise in NIPS  2009 pp 2035Ö2043  P  W elinder  S  Branson S Belongie and P  Perona The multidimensional wisdom of crowds in NIPS  2010 pp 2424Ö2432  Y  T ian and J Zhu Learning from cro wds in the presence of schools of thought in KDD  2012 pp 226Ö234  D Zhou J C Platt S Basu and Y  Mao Learning from the wisdom of crowds by minimax entropy in NIPS  2012 pp 2204Ö2212  V  C Raykar and S Y u  Ranking annotators for cro wdsourced labeling tasks in NIPS  2011 pp 1809Ö1817  K Lange D R Hunter  and I Y ang Optimization transfer using surrogate objective functions Journal of Computational and Graphical Statistics  vol 9 no 1 pp 1Ö20 2000  W  H W olber g and O L Mangasarian Multisurf ace method of pattern separation for medical diagnosis applied to breast cytology Proceedings of the National Academy of Sciences  vol 87 no 23 pp 9193Ö9196 1990  K Bache and M Lichman UCI machine learning repository   2013  A v ailable http://archi v e.ics.uci.edu/ml 343 


  7  Lorenz, R  D., Experi m e n t s i n Timel a pse C a m e r a  Observations of Dust Devil Activity at El Dorado Playa Nevada, Abstract #1573, 42nd Lunar and Planetary Science Conference, Lunar and Planetary Institute Houston, TX, 2011  Lorenz R  D., B  Jackson and J. B a rnes, Inexpensi v e Timelapse Digital Cameras for Studying Transient Meteorological Phenomena : Dust Devils and Playa Flooding, Journal of At mospheric and Oceanic Technology, 27, 246-256, 2010  C a st ano, A., A. F ukanag a J. B i esadecki, L. Neakrase, P Whelley, R. Greeley, M. Lemmon, R. Castano, S. Chien Automatic detection of dust devils and clouds on Mars Machine Vision and Applications, 19, 467-482, 2008  Lorenz R  D. and A Val d ez, Var i abl e W i nd R i p p l e  Migration at Great Sand Dunes National Park, Observed by Timelapse Imagery, Geomorphology, 133, 1-10, 2011 19 B a l m e  M. R A  Pa th a r e, S.M Me tzg e r  M C. To w n er  S.R. Lewis, A. Spiga, L.K. Fenton, N.O. Renno, H.M Elliott, F.A. Saca, T.I. Michae ls, P. Russell, J. Verdasca Field measurements of horizontal forward motion velocities of terrestrial dust devils: Towards a proxy for ambient winds on Mars and Earth, Icarus, 221, 632ñ645 2012  Koch, W  On B a y e si an Tracki ng and Dat a Fusi on  A Tutorial Introduction with Examples, IEEE Aerospace and Electronics Systems, 25, 29-51, 2010  Biographies Ralph Lorenz is a planetary scientist at the Johns Hopkins University Applied Physics Laboratory, with interests in atmospheres surfaces and their interactions, especially on Titan and Mars.  He worked for the European Space Agency on Phase B of the development of the Huygens probe to Titan, and subsequently built part of the instrumentation of the probeís Surface Science Package SSP\. Prior to joining APL in 2006, he spent 12 years in various positions at the Lunar and Planetary Laboratory at the University of Arizona, where he led observation planning for the Cassini RADAR investigation, and served on the science team of the New Millennium DS-2 mission to Mars. He is th e author of several books including ëSpinning Flightí, ëTitan Unveiledí, and ëSpace Systems Failures. He has a B.Eng in Aerospace Systems Engineering from the University of Southampton \(UK and a Ph.D. in Physics from the University of Kent at Canterbury \(UK\. He is the recipient of 5 NASA Group Achievement Awards   


  8  


Virtual Social Networks Analysis in Computational Social Network Analysis  ser Computer Communications and Networks A Abraham A.-E Hassanien and V Sn  ael Eds London Springer London 2010 ch 1 pp 3Ö25  J K orner  Fredman-k olmo s bounds and information theory   SIAM J Algebraic Discrete Methods  vol 7 no 4 pp 560Ö570 Oct 1986  T  Leighton and S Rao Multicommodity max-îo w min-cut theorems and their use in designing approximation algorithms J ACM  vol 46 no 6 pp 787Ö832 Nov 1999  M Bastian S He ymann and M Jacomy  Gephi An open source software for exploring and manipulating networks 2009  A.-L Barabasi and R Albert Emer gence of scaling in random networks Science  vol 286 no 5439 pp 509Ö512 1999 


application or middleware platform to collect request ows Thus it is much easier to deploy FChain in large-scale IaaS clouds Blacksheep correl a t e s t he change poi nt of s y s t em-l e v el metrics e.g cpu usage with the change in count of Hadoop application states i.e events extracted from logs of DataNodes and TaskTrackers to detect and diagnose the anomalies in a Hadoop cluster Kahuna-BB correl a t e s b l ack-box dat a system-level metrics and white-box data Hadoop console logs across different nodes of a MapReduce cluster to identify faulty nodes In comparison FChain is a black-box fault localization system which is application-agnostic without requiring any knowledge about the application internals We believe that FChain is more practical and attractive for IaaS cloud systems than previous white-box or gray-box techniques V C ONCLUSION In this paper we have presented FChain a robust blackbox online fault localization system for IaaS cloud computing infrastructures FChain can quickly pinpoint faulty components immediately after the performance anomaly is detected FChain provides a novel predictability-based abnormal change point selection scheme that can accurately identify the onset time of the abnormal behaviors at different components processing dynamic workloads FChain combines both the abnormal change propagation knowledge and the inter-component dependency information to achieve robust fault localization FChain can further remove false alarms by performing online validation We have implemented FChain on top of the Xen platform and conducted extensive experimental evaluation using IBM System S data stream processing system Hadoop and RUBiS online auction benchmark Our experimental results show that FC hain can achieve much higher accuracy i.e up to 90 higher precision and up to 20 higher recall than existing schemes FChain is light-weight and non-intrusive which makes it practical for large-scale IaaS cloud computing infrastructures A CKNOWLEDGMENT This work was sponsored in part by NSF CNS0915567 grant NSF CNS0915861 grant NSF CAREER Award CNS1149445 U.S Army Research Ofìce ARO under grant W911NF-10-1-0273 IBM Faculty Awards and Google Research Awards Any opinions expressed in this paper are those of the authors and do not necessarily reîect the views of NSF ARO or U.S Government The authors would like to thank the anonymous reviewers for their insightful comments R EFERENCES   A m azon E las tic Com pute Cloud  h ttp://a w s  a m azon com ec2   V i rtual c om puting lab  http://vcl ncs u  e du  P  Barham  A  D onnelly  R I s aacs  a nd R M o rtier   U s ing m agpie f or request extraction and workload modelling in 
 2004  M  Y  Chen A  A ccardi E  K icim an J  L lo yd D  P atters on A  F ox and E Brewer Path-based failure and evolution management in  2004  R F ons eca G  P o rter  R H  K atz S  S h enk e r  and I  S toica X T race A pervasive network tracing framework in  2007  I  Cohen M  G o lds z m i dt T  K elly  J  S ym ons  a nd J  S  Chas e Correlating Instrumentation Data to System States A Building Block for Automated Diagnosis and Control in  2004  I  C ohen S  Z h ang M  G o lds z m i dt J  S ym ons  T  K elly  a nd A  F ox Capturing indexing clustering and retrieving system history in  2005  S  D uan S  Bab u  a nd K  M unagala F a A s ys tem for a utom ating failure diagnosis in  2009  S  K andula R Mahajan P  V erkaik S  A garw al J  P a dhye a nd V  Bahl Detailed diagnosis in computer networks in  2009  A  J  O liner  A  V  K ulkarni and A  A ik en  U s ing c orrelated s u rpris e to infer shared inîuence in  2010  P  Bahl R Chandra A  G r eenber g  S  K andula D  A  M altz and M Zhang Towards highly reliable enterprise network services via inference of multi-level dependencies in  2007  Z  G ong X  G u  a nd J  W ilk es   P RE S S  P Redicti v e E las tic ReS ource Scaling for Cloud Systems in  2010  H  N guyen Y  T a n and X  G u P A L  P ropagation-a w are a nom aly localization for cloud hosted distributed applications in  2011  B Gedik H Andrade K L  W u P  S  Y u and M  D oo SP ADE  t he system s declarative stream processing engine in  2008  A pache H adoop S y s tem   http://hadoop apache  or g/co re   Rice uni v e rs ity bidding s y s tem   http://rubis  objectw eb  o r g   M Ben-Y e huda D  B reitgand M F actor  H  K o lodner  V  K r a v ts o v  and D Pelleg NAP a building blo ck for remediating performance bottlenecks via black box network analysis in  2009  Y  T a n X  G u  a nd H  W a ng  A dapti v e s ys tem anom aly prediction f or large-scale hosting infrastructures in  2010  D  L  M ills   A b rief his t ory o f N T P tim e m e m o irs o f a n i nternet timekeeper  2003  Y  T a n H  N guyen Z  S h en X  G u C V e nkatram ani and D  R ajan PREPARE Predictive Performance Anomaly Prevention for Virtualized Cloud Systems in  2012  M  Bas s e ville and I  V  N ikiforo v   Prentice-Hall Inc 1993  L  Cherkaso v a  K  O zonat N Mi J  S ym ons a nd E  Sm irni  Anom aly application change or workload change towards automated detection of application performance anomaly and change in  2008  P  Barham and e t al   X e n a nd the a rt of virtualization  i n  2003  T he ircache p roject  h ttp://www.ircache.net  H ttperf  h ttp://code google com  p htt p er f  S  K u llback  T h e ku llback-leibler distance  1987  X  Chen M  Z hang Z  M  M a o and P  B ahl  A utom ating n etw ork application dependency discovery experiences limitations and new solutions in  2008  M Y u  A  G reenber g  D  M altz J  Re xford L  Y u an S  K andula and C Kim Proìling network performance for multi-tier data center applications in  2011  M K  A guilera J  Mogul J  W iener  P  R e ynolds  a nd A  Muthitacharoen Performance debugging for distributed systems of black boxes in  2003  S  A g arw ala F  A l e g re K  S chw a n and J  M ehalingham  E 2E P r of A utomated end-to-end performance management for enterprise systems in  2007  P  Re ynolds  J  L  W iener  J  C M ogul M  K  A guilera and A  V ahdat  WAP5 black-box performance debugging for wide-area systems in  2006  R Apte L  Hu K  S chw a n and A  G hosh L ook W ho s T alking Discovering dependencies between virtual machines using cpu utilization in  2010  G Khanna I  L aguna F  A rshad an d S Bagchi Distr ibuted diagnosis of failures in a three tier e-commerce system in  2007  R R S a m b as i v an A  X  Z heng M  D e Ros a  E  K re v at S  W h itm an M Stroucken W Wang L Xu and G R Ganger Diagnosing performance changes by com paring request ows in  2011  J  T a n a nd P  N a ras i m h an  RA M S and B lackS h eep I nferring w h ite-box application behavior using black-box techniques CMU Tech Rep 2008  J  T a n X  P a n E  Marinelli S  K a vulya R  G andhi a nd P  N a ras i m h an Kahuna Problem diagnosis for mapreduce-based cloud computing environments in  2010 
OSDI NSDI NSDI OSDI SOSP ICDE SIGCOMM DSN SIGCOMM CNSM SLAML SIGMOD ICAC PODC Computer Communication Review ICDCS Detection of abrupt changes theory and application DSN SOSP The American Statistician OSDI NSDI SOSP DSN WWW HotCloud SRDS NSDI NOMS 
207 
30 
30 


A Global Solution COVERAGE North and South America EMEA and Asia White lines are flights in the masFlight platform from February 8, 2013 Yellow pins are weather stations feeding hour ly data to our platform Maps from Google Earth / masFlight masFlight tracks flights, airports and weather around the world  Global daily flight information capture  82,000 flights  350 airlines  1700 airports  Integrated weather data for 6,000 stations  Match weather to delays  Validate block forecasts at granular level  Add weather analytics to IRROPS review and scenario planning 


Example 1: Proposed FAA Tower Closures masFlight used big-data to link airport operations across three large data sets  Current and historical airline schedules  Raw Aircraft Situation Display to Industry \(ASDI\AA  Enhanced Traffic Management System Counts \(ETMS\Airport operations counts by type \(commercial, freight, etc TOWER CLOSINGS Dots indicate closures; Red dots have scheduled service Based on scheduled service March 1 7, 20 13; scheduled service includes scheduled charter flights, cargo flig hts, and passenger flights Dots  indicate  closures  Red  dots  have  scheduled  service Bas ed  o n sc h edu l ed  se rvi ce  M a r c h 1  7, 2013; scheduled se rvi ce includ es scheduled c harter fli g hts car g o fli g hts a nd passen g er fli g hts Findings: Proposed Tower Closings  From schedules database: 55 airports with scheduled passenger airline service  14 EAS Airports  From ASDI & ETMS: 10,600 weekly flights on a flight plan \(ex. VFR and local traffic  6,500 Part 91/125 weekly flights  4,100 Part 135/121 weekly flights  


Example 1: Big-Data Analytics Applied to ASDI and ETMS To Analyze Operations TOWER CLOSINGS  26 44 24 23 11 10 6 2 1 2 Up to 5 5-10 10-15 15-20 20-25 25-30 30-35 35-40 40-45 45 Count of Airports Average Number of Daily Operations with a Flight Plan Filed Distribution of Airports By Average Number of ìDailyî Impacted Flights Airports Affected by Tower Closures Source: ASDI radar data ñ Part 91 151 flying and Part 135/121 flying March 1-7, 2013; masFlight analysis Note: Average ìdailyì operations based on 5-day week 


Example 2: Aviation Safety Causal Factor For example, consider the following ASRS report \(ACN 1031837 Departing IAH in a 737-800 at about 17,000 FT, 11 m iles behind a 737-900 on the Junction departure over CUZZZ Intersection. Smooth air with wind on the nose bearing 275 degrees at 18 KTS We were suddenly in moderate chop which lasted 4 or 5 seconds then stopped and then resumed for another 4 or 5 seconds with a significant amount of ri ght rollingÖ I selected a max rate climb mode in the FMC in order to climb above the wake and flight path of the leading -900 We asked ATC for the type ahead of us and reported the wake encounter. The 900 was about 3,300 FT higher than we were  Synopsis  B737-800 First Officer reported wake encounter from preceding B737-900 with resultant roll and moderate chop What causal factors can be identified from this narrative that could be applied to future predictive applications CAUSAL FACTORS Data-mining algorithms can mine the text of safety reports to obtain specific data that can be used to analyze causal factors  


Example 2: Identifying Causal Factors CAUSAL FACTORS  Indicators ñ Data Element Methods ñ Identifying Context and Causes  Time of day  Date range \(month day  Aircraft type  Fix or coordinates  Originating airport  Destination airport  Weather notes We pinpoint the sequencing of flights on the IAH Junction Seven departure \(at CUZZZ\the specified wind conditions to find cases wher e a B737-900 at 20,000 feet precedes by 11 miles a B737-800 at 17,000 feet  Search related data sets including ASDI flight tracks, local traffic and congestion  Weather conditions for alter native causes \(winds aloft shear and convecti ve activity  Airline specific informati on \(repeated occurrence of event in aircraft type Big data gives us visibility into contextual factors even if specific data points are missing such as a specific date or route Big-data analytics gives us insight into unreported factors as well 


Example 3: Correlating Utilization and Delays  60 65 70 75 80 85 90 95 100 7 9 11 13 ONTIME DEPARTURE PERFORMANCE HOURS OF DAILY UTILIZATION 60.0 70.0 80.0 90.0 100.0 7.0 9.0 11.0 13.0 Narrowbodies By Day of Week 60.0 70.0 80.0 90.0 100.0 7.0 9.0 11.0 13.0 Widebodies by Day of Week Daily Utilization vs. On-time Departures January 2013 System Operations Correlation Coefficient -0.53 Includes AA, AC, AS B6 F9, FL, NK, UA, US VX and WN SOURCE masFlight \(masflight.com COMPARING OTP AND UTILIZATION 


 6.2 6.0 5.8 5.8 5.2 4.9 LGB JFK BOS MCO DCA FLL JetBlue Focus Average Daily Deps per Gate Used UTILIZATION BY HUB Example 4: Daily Utilization of Gates, by Hub Big-data analysis of different carriers daily departures per gate used SOURCE masFlight \(masflight.com June 1 through August 31, 2012 Gates with minimum 1x daily use 7.7 7.4 7.2 6.2 6.1 5.8 3.8 3.6 ORD LAX SFO EWR DEN IAH IAD CLE United Airlines Hubs Average Daily Deps per Gate Used 7.8 6.4 5.5 5.4 5.3 4.4 4.3 4.0 SEA SAN PDX ANC SFO GEG LAX SJC Alaska Airlines Hubs Average Daily Deps per Gate Used 7.2 6.9 6.8 6.4 5.0 2.7 ORD DFW LAX LGA MIA JFK American Hubs Average Daily Deps per Gate Used 7.2 6.9 6.6 4.9 4.2 CLT DCA PHL PHX BOS US Airways Hubs Average Daily Deps per Gate Used 6.6 5.9 5.5 4.7 MCO BWI ATL MKE AirTran Hubs Average Daily Deps per Gate Used ne pe 


Conclusions for Big Data in Aviation  Big-data transforms operational and commercial problems that were practically unsolvable using discrete data and on-premises hardware  Big data offers new insight into existing data by centralizing data acquisition and consolidation in the cloud and mining data sets efficiently  There is a rich portfolio of information that can feed aviation data analytics  Flight position, schedules, airport/gate, weather and government data sets offer incredible insight into the underlying causes of aviation inefficiency  Excessive size of each set forces analysts to consider cloud based architectures to store, link and mine the underlying information  When structured, validated and linked these data sources become significantly more compelling for applied research than they are individually  Todayís cloud based technologies offer a solution CONCLUSIONS 


Conclusions:  Our Approach  masFlightís data warehouse and analysis methods provide a valuable example for others attempting to solve cloud based analytics of aviation data sets  masFlightís hybrid architecture, consolidating secure data feeds in on-premises server installations and feeding structured data into the cloud for distribution, addresses the unique format, security and scale requirements of the industry  masFlightís method is well suited for airline performance review competitive benchmarking, airport operations and schedule design and has demonstrated value in addressing real-world problems in airline and airport operations as well as government applications CONCLUSIONS 





