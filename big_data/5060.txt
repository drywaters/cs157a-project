  An Improved Apriori Algorithm Based on Pruning Optimization and Transaction Reduction  Zhuang Chen College of Computer Science and Engineering Chongqing University of Technology ChongQing,China zhuang.ch@gmail.com Shibang Cai,  Qiulin Song and Chonglai Zhu College of Computer Science and Engineering Chongqing University of Technology ChongQing,China caishibang@sina.com   Abstract 227The paper analyzes the basic ideas and the shortcomin gs of Apriori algorithm, studies the current major improvement strategies of it. In order to solve the low performance and efficie 
ncy of the algorithm caused by its generating lots of candidate sets and scanning the transaction database repeatedly, it studies the pruning optimization and transaction reduction strategies and on this basis, the improved Apriori algorithm based on pruning optimization and transaction reduction is put forward According to the performance comparison in the simulation experiment, by using the improved algorithm, the number of frequent item sets is much less and the running time is significantly shortened as well as the performance is enhanced then finally the algorithm is improved 
Keywords- Apriori;   frequent itemsets;   pruning optimization transaction reduction I   I NTRODUCTION  Association rules mining is an important research content in the field of data mining. It helps to find the association relationship among the large number of database items and its most typical application is to find the new useful rules in the sales transaction database, which reflects the customer purchasing behavior patterns, such as the impact on the other goods after buying a certain kind of goods. These rules can be used in many fields, such as customer shopping analysis additional sales, goods shelves design, storage planning and classifying the users according to the buying patterns, etc 
Apriori algorithm is the most classical basic one of the algorithms in realizing the association rules mining. The algorithm has its unique advantages in looking for frequent itemsets, however, it is with the low performance and efficiency caused by generating lots of candidate sets and scanning the transaction database repeatedly in the execution process, which is the main disadvantage of Apriori algorithm The continuous research and improvement on the Aprior algorithm will promote the algorithm of association rules mining more mature and more efficient, push forward the association rules mining\222s successful application in commercial fields and its broader prospect II  BASIC 
 CONTENT  AND  ANALYSIS  OF  APRIORI A  Basic Content of Apriori Apriori is a classic algorithm for learning association rules in data mining, proposed by R.Agrawal and R.Srikant in 1994 t her e ar e t w o pr ope rt i e s 223a l l n o ne m p t y sub s e t  o f  a frequent itemset must also be frequent; all superset of nonfrequent itemset must also be non-frequent\224 ,the properties[2 is used in Apriori algorithm to scanning the database , resulting in Boolean association rules frequent itemsets 
Specifically ,Apriori uses an iterative search method layer by layer, where k-dimensional itemsets are used to explore k+1\dimensional itemsets. First ,the set of frequent 1dimensional itemsets is found and denoted L1, Next,L1 is used to find L2,the set of L2 frequent 2-itemsets ,which is used to find L3,and so on ,until no more frequent k-dimensional itemsets can be found .Finally, getting the rules from large set of data items. how Li-1 is used to find  Li is consisting of twostep process ,join and prune actions as followed 1  The join step Join Lk-1 with itself ,than combine the 
same extension item appeared to generate a possible candidate k-dimensional itemsets ,this set of candidates is denoted Ck Ck 
002 Lk 2  The prune step Scan the database to determine the count of each candidate in Ck. When the count is less than the minimum support count, it should be delete from the candidate itemsets. meanwhile ,if any \(k-1\dimensional subset of a candidate k-dimensional itemsets is not in Lk-1,the the candidate cannot be frequent either ,after this we can get the kdimensional itemsets ,which is denoted Lk B  Algorithm  Analysis Apriori algorithm is a well-known association rules 
algorithm and it has its unique advantages in mining frequent itemsets, has been used for most commercial products ,but at the same time, as the classical association rule extraction algorithm ,Apriori also has its shortcomings 1 Algorithm will spend a large overhead to deal with large candidate set ,the generation from Lk-1 to Ck is exponential growth , so if judge the frequent itemsets before the generation 1908 978-1-4577-0536-6/11/$26.00 \2512011 IEEE 


  of the candidate frequent itemsets Ck, we can avoid creating an invalid candidate itemsets, reducing the scan database time 2 Many repeat comparison of itemset in join step ,and the join may result a large set of candidates, if it can avoid repeating the comparison ,excluding the possibility of invalid candidate, the efficiency of the algorithm can be improved 3 Repeatedly scanning the transaction database requires a lot of I/O load. After generating candidate frequent items it also go back and scan the database to determine whether these candidates are frequent itemsets. in the process of scanning ,the length of some items is small can not support the generation of frequent itemsets, but still repeat scan , so there is room for improvement III  THE MAINLY IMPROVED STRATEGIES OF A PRIORI  Since the Apriori algorithm was proposed , many researchers make a in-depth research and  present some effective improvement methods A  Data Partitioning Method In order to reduce the number of database scans , Savasere proposed the division method based on partition[3  t h e database id divided into many segments, the core idea is :the frequent itemsets on the database at least one segment in the database is frequent ,then the union set of fenquent itemsets of each segment is the set of potential frequent itemsets the algorithm consists of two steps 1 The algorithm subdivides the transactions into many nonoverlapping partitions, small partitions can be completely loaded into memory, so you can call any sort of frequent itemsets mining algorithm to exploit the frequent itemsets in each partition. this requires scanning a trip to the database 2 Together the frequent item set of each segment ,the result is generate a giant candidate sets on the entire database this requires re-scan the database to verify whether each candidate is a real set of frequent itemsets therefore, using the data partitioning method ,the whole process only scan the database twice B  Hash-based Technique The DHP algorithm on behalf of  hash-based optimization method proposed by Park[4 a i n l y  can be u s e d t o  r e du ce  t h e  size of the candidate k-dimensional itemsets, Ck, for k>1 The basic idea is :when scanning each transaction in the database to generate the frequent k-itemsets from the candidate k-dimensional itemsets ,at the same time ,produce \(k+1 itemsets for each transaction ,then hush them to the different hash buckets of a hash table structure, and increase the corresponding bucket counts ,so that when produce the candidate \(k+1\dimensional itemsets can exclude some meaningless candidate set according to the minimum support threshold C  Sampling Sampling-based approach was first proposed by Mannila et al, to further improve by Toivonen et al[5   The basic idea of the sampling method is to pick a random sample S of the given data D, and then search for frequent itemsets in S instead of D. Because we are searching for frequent itemsets in S rather than in D, it is possible that we will miss some of the global frequent itemsets. To lessen this possibility, we use a lower support threshold than minimum support to find the frequent itemsets local to S This method suitable for requirements for higher efficiency of mini ut no t  t oo hi gh a c c ur a c y o f m i ni ng environments IV  A N I MPROVED A LGORITHM B ASED ON P RUNING O PTIMIZATION AND T RANSACTION R EDUCTION  A  Pruned Optimization Strategy Property 1: In K-dimension frequent itemset X = {i1 i2 003\003\003 ik} ,  if there is a item named ij which can meet the Count \(ij\-1, then X is not a frequent itemset.Among them, j < k, and Count \(ij\ means the number of itemsets containing the item ij in the collection of k-1-dimension frequent itemsets named Lk-1 Proof: Suppose X is a K-dimensional frequent  itemset then all the K K-1-dimensional subsets of X are in  Lk-1, and every item of X named ij will exit in k-1 subsets of X.It means that the number of itemsets containing item ij is k-1,so every item named ij of X could make the value of Count ij to be no less than k-1 because the collection named Lk-1 includes all subsets of X, but This contradicts with the condition, so the assumption does not hold, so X is not a frequent itemset Pruned optimization strategy: In generating Kdimensional candidate itemsets, on the basis of the existing \(K1\-dimensional frequent itemsets, we can use a temporary table to count the frenquency of the items all in the frequent itemsets,if the frenquency of an item is less than K-1, this item can not be used to generate the k-dimensional itemsets, so we can delete all the frequent itemsets containing the item in Lk-1 this can effectively reduce the scale of Lk-1 and generate Ck more efficient For example, make association rules mining in a simple transaction database, as below  Figure 1  Execution process map  after adding a temporary table In the above example, if we use  Apriori algorithm directly, it means the lack of the temporary table T1 in TID T1 T2 T3 T4 Items 1,3,4 2,3,5 1,2,3,5 2,5 Scanning D IS 1 2 3 4 SUP 2 3 3 1 5 3 D:SUPPORT=2      IS ---ItemSets Compare with support IS 1 2 3 5 SUP 2 3 3 3 C1 L1 Generate C2 IS 1,2 1,3 1,5 2,3 SUP 1 2 1 2 2,5 3,5 3 2 Compare with support IS 1,3 2,3 2,5 3,5 SUP 2 2 3 2 Count Item 1 2 3 5 Frequency 1 2 3 2 C2 L2 C1 IS 2,3 2,5 3,5 SUP 2 3 2 L2 IS 2,3,5 SUP 2 Delete the itemsets containing item 1 Compare with support IS 2,3,5 SUP 2 C3 L3 1 2 3 1909 


  step \(2\ ,so the set of 2-dimensional frequent itemsets is 1,3},{2,3},{2,5},-{3,5}}, therefore, all the possible  3dimensional  candidate set is {{1,2,3 1,2,5 1,3,5 2,3 ,5} },Then  scan  the  transaction database  D  and  compare the frenquency of candidate itemsets with the mini\227support, finally, obtain the conclusion that  3dimensional frequent itemsets is {2,3,5};In another way, if we use the Pruned optimization strategy for Apriori , the process will like this :we have added a temporary table T1 to count the frenquency of the items all in the 2-dimensional  frequent itemsets,then we can see the frenquency of the item named 1 is less than two, so we can delete all the itemsets containing the item named 1,delete itemset {1,3}in fact, there are {2,3},{2,5 and {3,5} remained,then generate the only  3-dimensional candidate itemset {2,3,5} ,through the scanning databases and comparative support, get the final 3-dimensional frequent itemsets  {2,3,5}. Therefore, it can be found that using pruned optimization strategy can filter out  non-frequent candidate itemsets {1,2,3}, {1,2,5} and {1,3,5}, Thus avoid a lot of  scanning the database and compar- ison to determine and   eliminate   non-frequent candidate itemsets reduce unnecessary time cost[7  T h is e ffe c t w ill be  more clearly reflected in a large transaction database B  Transaction Reduction Strategy Property 2: For generating K-dimensional  frequent item sets, if the length of a transaction is less than k, thetransaction is not necessary to scan Proof: generating K-dimensional frequent itemsets must scan the transaction database to calculate the frequency of frequent itemsets,if the length of a transaction is less then K, it means the number of items it contains is no more than K, it indicates that the transaction can not contains the Kdimensional frequent  itemsets[9   s o th e r e is n o n ee d  t o  s can  this transaction Property 3:Recorded Sk is the set of all items which  Kdimensional frequent itemsets contains,when scan the database for generating  K+1-dimensional frequent itemsets , any item named a including in \(Sk-1 - Sk\ is not necessary to scan in all transactions Proof: For any item named a including in \(Sk-1 \226 Sk\, a is not exist in  K-dimensional frequent itemsets, furthermore,a is not exist in  K+1-dimensional frequent itemsets certainly,so a can not support the generation of K+1-dimensional frequent itemsets, there is no need to scan the item a So, according to property 2 and property 3 ,we can design the following optimization strategy Transaction Reduction strategy:When scan the database for generating  K+1-dimensional frequent itemsets, calculate the length of all transactions, delete the transaction whose length is less than K+1 directly, for the remaining transactions, delete the items including in \(Sk-1\226Sk\,and re-calculate the length of every transaction, if a transaction\222s length is less than K+1, delete the transaction in order to compress the transaction and reduce the scale of the database Therefore, when generate  the new K-dimensional frequent itemsets, take the Transaction Reduction strategy firstly.It will compress the size of the transaction and reduce the scale of the database in the next database scanning. Especially, when the  value of K  is large, taking the transaction reduction strategy before scanning database will reduce the scale of transaction database constantly,and avoid a lot of repetitions scanning of short transactions, greatly reduce the time spent on the scanning of database,and finally improve the efficiency of the Apriori algorithm significantly C  The  Improved  Algorithm The improved algorithm is based on the classic Apriori algorithm,and take Pruned optimization strategy to optimize the process of pruning in order to reduce the  generation of frequent itemsets, and meanwhile, take Transaction Reduction strategy to compress the transaction of database in order to reduce the scale of the transaction database tobe scanned.All of these will effectively decrease the system overhead and reduce the running time, improve the efficiency of Apriori algorithm significantly Here is the improved  algorithm named BE - Apriori BE - Apriori Algorithm Input: transactiondatabase D, minimum support  min_sup Output: all the frequent itemsets denoted L of D The algorithm 1 L1={ 1-dimensional frequent itemsets 2 for\(k=2;Lk-1 004 k 3  if\(k!=2 4  Count the frequency named |Lk-1\(a\| of every item named a Exists in Lk-1 5  If \(|Lk-1\(a\ <k-1\ete all the itemsets contained a in Lk-1 and update Lk-1 6   7 for each l1 005 Lk-1, for each l2 005 Lk-1 8  9  if  1  006 003\003\003 006 l1[k 006 l1[k  10  c=l1 007 l2  11  for each k-1 subset s of c 12  If\( s b  Lk-1 13  delete c ;}     Break 14  15  Ck=Ck t C 16 for each t 005 D 17 If Coun delete t 18 Else{ delete the items of t  including in \(Sk-1 \226 Sk\d recalculate the length of t 19 If Coun delete t 20  Ct=subset \(Ct, t 21 for each c 005 Ct   c.count 22  23 Lk={c 005 Ck |c.count > min_sup 24 return L=L1 t L2 t 003\003\003 t Lk  V  P ERFORMANCE C OMPARISON  In order to confirm the optimization for Apriori ,we have taken some comparison tests between Apriori and the improved 1910 


  algorithm named BE - Apriori. Experimental  environment CPU ,Pentium \(R\Dual-CoreT4300, RAM 2.0G. Operating system ,Windows ;  programming language, C; development platform , VC6.0.Choose the data set named retail as the Experimental test data which come from the frequent itemsets mining library of FIMI \(Frequent Itemset Mining Implementations\ provided by a Belgian supermarket anonymously ,and contains 88163 consumption records of 5133 customers.We use the first 3000 records  for the experiment We have done several tests about the retail data set used the classical  Apriori and  the improved BE-Apriori separately The results obtained are as follows The numbers of frequent itemsets generated under different support are shown as below        Figure 2  The comparison of the number of frequent itemsets generated under different support According to the above results,it can be seen that the number of frequent itemsets generated by  the improved   BEApriori is less than the number generated by the pure Apriori algorithm. Furthermore, with the  value of the support selected is increasing, the effect of resulting reduction in the number of frequent itemsets  generated has become obvious increasingly The comparison of the running time of two algorithms  is shown as below             Figure 3  The comparison of the running time of two algorithms under different support According to the above results,it can be seen that the running time of  the improved   BE-Apriori is less than the the running time of  the pure Apriori under different support When the support increases from 10 to 12,15,20 the running time of  the improved BE-Apriori is reduce rapidly relative to the Apriori algorithm.When the  support is 20, the running time of the improved BE-Apriori is less than half of the pure Apriori algorithm Therefore, we find that, compared with the pure Apriori algorithm, the improved BE-Apriori algorithm an significantly reduce the number of frequent itemsets generated, the running time was obviously shortened,the efficiency of the improved BE-Apriori is higher than Apriori VI  CONCLUSION  This paper briefly reviews the topic  of association rules mining, analyzes the ideas and the shortcomings of Apriori algorithm, and compare several different styles of the major improvement strategies.Then studies the pruning optimization and transaction reduction strategy, finally put forward the improved Apriori algorithm based on pruning optimization and transaction reduction.The experiments about data set retail show that ,compared with the pure Apriori algorithm, the improved  algorithm named BE-Apriori has decreased the number of frequent itemsets generated, reduced the running time obviously. The improved  algorithm have a good advantage of low system overhead and good operating performance,  its efficiency is significantly higher than the Apriori algorithm.With the expansion of the scale of data, this advantage will become obvious increasingly R EFERENCES  1  R Agrawal T Imielinski A Swami. Mining Association Rules between Sets of Items in Large Database[C  I n  P r o cee ding s o f t h e  ACM SIGMOD Conference on Management of Data 1993:207~216 2  Yuan Chang-an, Deng Song. Principles of Data Mining and SPSS Clementine Application Collection [M Be ij ing  e l e c tr o n ic in d u s tr y  press 2009 3  Savasere A,Omiecinski E,Navathe S.An efficient algorithm for mining association rules in large databases Ne w York  A C M  199 5  432 443 4  Park J S,Chen M S,Yu P S.Efficient parallel data mining of association rules[C N e w Y o r k A CM,1 9 95 3 1 3 6  5  Toivonen H.Sampling large databases for association rules   India:[s.n    199 6  1 34 145 6  Gao Fei. The data mining algorithm for association rules[D Master thesis of Xi'an University of Electronic Science and Technology 2006 7  Xu Zhang-yan Liu Mei-ling and Zhang Shi-chao. Three kind of Optimizations of Apriori Algorithm [J   C om put er E n gin eeri n g an d Applications 2004 36 190~192 8  Hu Ji-ming Xian Xue-feng. The Research and Improvement of Apriori  for  association rules mining [J Co m p ute r T e chno l o g y and Development 2006 16\(4 99~104 9  Xu Jun-li Yu Guo-ping. The Research and application algorithm for Association rule mining [J   Mi cr o co m p u t e r i n f o r m atio n 2009 4\(3 193~194 1911 


Figure 4 A sequence of queries may differ for each issued query indeed we are supposing that the values of the dynamic data e.g the occupation of a classroom may be updated at each user request As the example highlights in the worst case the set V 026 r 033 contains a view for each query formulated by the user However in our case study we suppose that updates of the sensor tables are not continuous but triggered by a certain sampling policy e.g a sample every thirty minutes Moreover during the frequency computation it is not necessary to recompute from scratch all the views associated with the queries referring to Fig 4 we may compute the views associated with the instants t 1  t 4 and t 7  and derive the needed ones only by modifying the values of the sensor attributes that can be retrieved by querying the temporal relations Example 2 Score computation Consider the server log in Fig 3 The rule situation=alone  occupation=[0,50 is mined with con\002dence 3 4  with the contribution of the contexts C 1 021 situation=alone and C 2 021 situation=alone  interest topic=classrooms  The log rows related to C 1 are associated with two time instants t 1 and t 3  connected with different views According to the tables in Fig 2 the frequency of the value 0  50 in the view of C 1 at instant t 1 is 3/4 while at instant t 3 is 1/2 Suppose that the frequency in the view related to context C 2 at instant t 2 is 1/3 Applying 2 we obtain f 026 r 033  1 4 001 3 4  1 2 001 1 2  1 4 001 1 3  0  52  Finally choosing 015  2  we can compute the preference score by 1  2 001  3 4 000 0  52  0  46  The inferred preferences will be used to customize the contextual views and their computation requires a periodic aging step not described here 6 Conclusions and Future Work This paper has informally described a methodology exploiting data mining for the automatic extraction of contextual preferences on relational and sensor data The described techniques have been implemented in a Java tool so far managing only standard relational data We have evaluated the approach on a movie-related case study exploiting a real video-on-demand log 002le achieving encouraging results in terms of recall in more detail in our experimental setting our approach gains 8.3 recall w.r.t a naive algorithm based on item popularity reaching 38.8 against 30.5 We have also used our techniques to mine non-contextual preferences 002nding that in our case study context can bring 3.3 recall increase In the future we plan to add to our prototype the ability of managing sensor data too Moreover currently preference mining relies only on the user past querying activity we are now investigating the possibility to combine our proposal with other techniques coming from recommendation systems in order to propose other kinds of suggestion e.g unexpected serendipitous data References  R Agra w al R Rantzau and E T erzi Conte xt-sensiti v e ranking In Proc of SIGMOD  pages 383ñ394 2006  R Agra w al and R Srikant F ast algorithms for mining association rules in large databases In Proc of VLDB  pages 487ñ499 1994  M Baldauf S Dustdar  and F  Rosenber g A surv e y on context-aware systems Int Journal of Ad Hoc and Ubiquitous Computing  2\(4 2007  C Bolchini C Curino E Quintarelli F  A Schreiber  and L Tanca A data-oriented survey of context models SIGMOD Record  36\(4 2007  C Bolchini C A Curino E Quintarelli F  A Schreiber  and L Tanca Context information for knowledge reshaping Intl Journ Web Eng Technology  5\(1 2009  C Bolchini E Quintarelli and R Rossato Relational data tailoring through view composition In Proc of ER  pages 149ñ164 2007  M M Gaber  A B Zasla vsk y  and S Krishnasw amy  Mining data streams a review SIGMOD Record  34\(2 2005  S Holland M Ester  and W  Kieﬂling Preference mining A novel approach on mining user preferences for personalized applications In Proc of PKDD  pages 204ñ216 2003  E Jembere M O Adigun and S S Xulu Mining conte xtbased user preferences for m-services applications In Proc of WI  pages 757ñ763 2007  S Jung J Hong and T  Kim A statistical model for user preference IEEE TKDE  17\(6 2005  A Miele E Qui ntarelli and L T anca A methodology for preference-based personalization of contextual data In Proc of EDBT  pages 287ñ298 2009  B Mozaf ari H Thakka r  and C Zaniolo V erifying and mining frequent patterns from large windows over data streams In Proc of ICDE  pages 179ñ188 2008  K Stef anidis E Pitoura and P  V assiliadis Adding conte xt to preferences In Proc of ICDE  pages 846ñ855 2007  A H v an Bunningen L Feng and P  M G Apers A context-aware preference model for database querying in an ambient intelligent environment In Proc of DEXA  pages 33ñ43 2006  K Xu M Zhu D Zhang and T  Gu Conte xt-a w are content 002ltering  presentation for pervasive  mobile information systems In Proc of Ambi-Sys  pages 1ñ8 2008  J  Xu Y u Z Chong H Lu and A Zhou F alse positi v e or false negative Mining frequent itemsets from high speed transactional data streams In Proc of VLDB  pages 204ñ215 2004  L Y ang and M San v er  Mining short association rules with one database scan In Proc of IKE  pages 392ñ398 2004 
120 


 Figure 7\(c MRD values for Top-15   At the same time, we also observed the average feedback times as shown in Fig. 8\(a\ and the average precision as shown in Fig. 8\(b\, among these 10 testers. As shown in Fig. 8\(a\, for most cases, the more Top-N was the more the feedback times were. Besides, as shown in Fig. 8\(b\, the precision of different Top-N was a little diverse among 10 testers. Nevertheless, they almost reached more than 90% precision, especially two of third reaching the most satisfied level \(i.e., 100  Figure 8\(a\. Feedback times for different Top-N     Figure 8\(b\. Precision for different Top-N   IV  C ONCLUSION  In this paper, we proposed a feedback-based recommendation system. First, data generalization consisting of the movie clustering and the neighborhood aggregation was done. Next, after doing normalization on these data, we used the personal normalized data to mine association rules based on customer preferences, and stored them in the rule base. Finally, rule information aided a preliminary recommendation; afterward, the relevance feedback mechanism improved further recommendations based on the explicit interaction from customers A CKNOWLEDGMENT  This work was supported by National Science Council of R.O.C under Grant NSC99-2220-E-224-005 R EFERENCES  1  Cane Wing-Ki Leung, Stephen Chi-fai Chan, and Fu-lai Chung  A collaborative filtering framework based on fuzzy association rules and multiple-level similarity   Knowledge and Information Systems, Vol. 10, No. 3, pp 357-381, 2006 2  S. Aciar, D. Zhang, S. Simoff, and J. Debenham  Informed recommender: basing recommendations on consumer product reviews  Proc. the IEEE/WIC International Conference on Web Intelligence, pp. 39-47, 2007 3  Dan Melamed, Bracha Shapira, and Yuval Elovici MarCol a market-based recommender system  IEEE Intelligent Systems, Vol. 22, No. 3, pp. 74-78, 2007 4  En Cheng, Feng Jing, Mingjing Li, Weiying Ma, and Hal Jin  Using implicit relevance feedback to advance web image search  Proc. the IEEE International Conference on Multimedia and Expo, pp. 1773-1776, 2006 5  Jiawei Han and Micheline Kamber Data Mining Concepts and Techniques 2nd edition, Morgan Kaufmann Publishers 2007 6  Choonho Kim and Juntae Kim A recommendation algorithm using multi-lev el association rules  Proc IEEE/WIC International Conference on Web Intelligence pp. 524-527, 2003 7  G. Linden, B. Smith, and J York, çAmazon.com recommendations: item-to-item collaborative filtering   IEEE Internet Computing, Vol. 7, No. 1, pp. 76-80, 2003 8  Badrul Sarwar, George Karypis, Joseph Konstan, and John Riedl  Analysis of recommendation algorithms for ecommerce  Proc. the 2nd ACM Conference on Electronic Commerce, pp. 158-167, 2000 9  Cyrus Shahabi and Yi-Shin Chen An adaptive recommendation system without explicit acquisition of user relevance feedback  Distributed and Parallel Databases Vol. 14, No. 2, pp. 173-192, 2003 10  T. Kohonen Self-Organizing Maps 3 rd edition, Springer 2001 11  Li-Tung Weng, Yue Xu, Yuefeng Li, and Richi Nayak An improvement to collaborative filtering for recommender systems  Proc. the International Conference on Computational Intelligence for Modelling, Control and Automation, pp. 792-795, 2005 12  Yuefeng Li, Wanzhong Yang, and Yue Xu  Multi-tier granule mining for representations of multidimensional association rules  Proc. the 6th International Conference on Data Mining, pp. 953-958, 2006 13  Qinbao Song, Martin Shepperd, Michelle Cartwright, and Carolyn Mair Software defect association mining and defect correction effort prediction  IEEE Transactions on Software Engineering, Vol. 32, No. 2, pp. 69-82, 2006 14  Bo Yang, Tao Mei, Xian-Sheng Hua, Linjun Yang, ShiQiang Yang, and Mingjing Li  Online video recommendation based on multimodal fusion and relevance feedback  Proc. the 6th ACM International Conference on Image and Video Retrieval, pp. 73-80, 2007  
417 


30 1 3 5 6 9 12 15 19 20 21 23 25 27 29 31 32 7 22 33 34 10 24 35 36 26 37 38 16 28 39 40 41 42 43 44 45 46 47 48 49 50 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 75 76 0 2 4 8 11 14 17 18 51 2 5 8 29 31 33 42 46 48 52 3 28 30 35 39 45 49 53 54 13 36 41 55 11 19 32 40 56 15 37 57 58 16 17 38 43 59 12 34 44 60 61 62 63 64 65 24 47 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 0 98 1 99 100 101 4 102 103 6 104 7 105 106 9 107 10 108 109 110 111 14 112 113 115 18 20 21 22 23 25 123 26 27 111 100 101 300 305 205 a Cluster similarity graph b Outlier similarity graph  c Anomaly similarity graph Fig 3 Cluster similarity graph and outlier similarity gra ph for destination aggregated data Anomalies are easily id entied through cliques TABLE II S IGNATURES OF ANOMALIES FOUND  Anomaly type Source trafc Destination trafc Source signature Destination signature segment indice segment indice Few ICMP pkts 111 305 nSrcs  1  nICMP  nPkts   1 nSrcs  1  nICMP  nPkts   2 Few ICMP pkts 112 309 nSrcs  1  nICMP  nPkts   1 nSrcs  1  nICMP  nPkts   2 Network scan 100 205 nSrcs  1  nDsts   1  nSYN  nPkts   2 nSrcs  1  nDsts   3  nSYN  nPkts   4   0 50 100 150 200 250 300 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 nDsts nSYN/nPkts    Cluster 1 Cluster 2 Cluster 3 Anomalous flows Outliers relative filtering rule absolute filtering rule   0 200 400 600 800 1000 1200 1400 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 nSrcs nSYN/nPkts    Cluster 1 Cluster 2 Anomalous flows Outliers absolute filtering rule relative filtering rule Fig 4 Filtering rules for characterization of the found ne twork scan in MAWI Table II details each anomaly with its type the segment indices extracted from ICLA and IOA and the two signatures detected from both source and destination aggregated data The terms Few ICMP packets actually means that these two anomalies were containing just a few harmless ICMP packets Both of these anomalies could have easily been discarded by an impact estimation based on nPkts/second Figures 4.\(a,b depicts the results of the characterizatio n phase for a network scan anomaly Each sub-gure represents a partition P n for which ltering rules were found They involve the number of IP sources and destinations and the fraction of SYN packets Combining them produces a signature that can be expressed as nSrcs  1  nDsts   1   nSYN  nPkts   2   where  1 and  2 are two thresholds obtained by separating normal and anomalous clusters at hal f distance This signature makes perfect sense the network s can uses SYN packets from a single attacking host to a large number of victims The main advantage of the unsupervised approach relies on the fact that this new signature has been produced without any previous information about the attack or the baseline trafc VIII C ONCLUSIONS The completely unsupervised anomaly detection algorithm we have presented has many interesting advantages w.r.t previous proposals in the eld It uses exclusively unlabel led data to detect and characterize network anomalies without assuming any kind of signature particular model or canoni cal data distribution This allows to detect new previously uns een anomalies even without using statistical-learning or hum an analysis or decision making Despite using ordinary cluste ring techniques the algorithm avoids the lack of robustness of general clustering approaches by combining the notions of Sub-Space Clustering/Sub-Space Clustering Inter-Clust er Association  Anomaly Correlation for Unsupervised Network Anomaly Detection and Anomaly Correlation The characterization approach permits the construction of easy-to-inte rpretand-to-visualize results providing insights and explana tions about the detected anomalies to the network operator We have evaluated the computational time of our algorithm Results conrm that the use of the algorithm for on-line unsupervised detection and characterization is possible a nd easy to achieve for the volumes of trafc that we have analysed Even more they show that if run in a parallel archi tecture the algorithm can reasonably scale-up to run in hig hspeed networks using more trafc descriptors to character ize network attacks We have veried the effectiveness of our proposal to detect and isolate distributed network anomalies on real trafc i n a completely blind fashion without assuming any particula r trafc model signicant clustering parameters or even cl usters structure beyond a basic denition of what an anomaly is This provides a strong evidence of the accuracy of the 


SSC-ICLA/IOA-Anomaly Correlation-based method to detect network anomalies We think that this approach constitute a great step toward an autonomous network anomaly detection that will allow networks to self-diagnose themselves and th us faster reactions and lower operational costs A CKNOWLEDGMENTS This work has been done in the framework of the ECODE project funded by the European commission under grant FP7ICT-2007-2/223936 R EFERENCES 1 J  M a z e l  P  C a s a s  a n d P  O w e z a r s k i   S u b s p a c e c l u s t e r ing  evidence accumulation for unsupervised network anomaly detection  ser TMA 11 2011 2 K  C h o  K  M i t s u y a  a n d A  K a t o   T r a f  c d a t a r e p o s i t o r y a t the wide project ser ATEC 00 pp 263ñ270 Online  A v a i l a ble http://portal.acm.org/citation.cfm?id=1267724.12677 75 3 P  B a r f o r d  J  K l i n e  D  P l o n k a  a n d A  R o n   A s i g n a l a n a l ysis of network trafc anomalies ser IMW 02 Online  A v a i l able http://doi.acm.org/10.1145/637201.637210 4 J  D  B r u t l a g   A b e r r a n t b e h a v i o r d e t e c t i o n i n t i m e s e r i es for network monitoring in Proceedings of the 14th USENIX conference on System administration  2000 pp 139ñ146 Online  A v a i l a b l e  http://portal.acm.org/citation.cfm?id=1045502.10455 30 5 A  L a k h i n a  M  C r o v e l l a  a n d C  D i o t   D i a g n o s i n g n e t w o r k-wide trafc anomalies ser SIGCOMM 04 pp 219ñ230 Online  A v a i l able http://doi.acm.org/10.1145/1015467.1015492 6     M i n i n g a n o m a l i e s u s i n g t r a f  c f e a t u r e d i s t r i b u t i o ns ser SIGCOMM 05 pp 217ñ228 Online  A v a i l a b l e  h t t p    d o i acm.org 10.1145/1080091.1080118 7 A  S o u l e  K  S a l a m a t i a n  a n d N  T a f t   C o m b i n i n g  l t e r i n g and statistical methods for anomaly detection ser IMC 05  Online  Available http://portal.acm.org/citation.cfm?id=125 1086.1251117 8 B  K r i s h n a m u r t h y  S  S e n  Y  Z h a n g  a n d Y  C h e n   S k e t c h based change detection methods evaluation and applications ser I MC 03 pp 234 247 Online  A v a i l a b l e  h t t p    d o i  a c m  o r g  1 0  1 1 4 5  9 48205.948236 9 G  D e w a e l e  K  F u k u d a  P  B o r g n a t  P  A b r y  a n d K  C h o   E x tracting hidden anomalies using sketch and non gaussian multiresolu tion statistical detection procedures ser LSAD 07 pp 145 152 Online  Available http://doi.acm.org/10.1145/1352664.135267 5 10 F  S i l v e i r a a n d C  D i o t   U r c a  P u l l i n g o u t a n o m a l i e s b y their root causes ser INFOCOM 10 pp 1ñ9 11 L  P o r t n o y  E  E s k i n  a n d S  S t o l f o   I n t r u s i o n d e t e c t i on with unlabeled data using clustering ser DMSA-2001 pp 5ñ8 12 E  E s k i n  A  A r n o l d  M  P r e r a u  L  P o r t n o y  a n d S  S t o l f o  A geometric framework for unsupervised anomaly detection Detecting i ntrusions in unlabeled data in Applications of Data Mining in Computer Security  2002 13 K  L e u n g a n d C  L e c k i e   U n s u p e r v i s e d a n o m a l y d e t e c t i o n in network intrusion detection using clusters ser ACSC 05  pp 333 342 Online  A v a i l a b l e  h t t p    p o r t a l  a c m  o r g  c i t a t i on.cfm?id=1082161 1082198 14 L  P a r s o n s  E  H a q u e  a n d H  L i u   S u b s p a c e c l u s t e r i n g f or high dimensional data a review SIGKDD Explor Newsl  vol 6 pp 90ñ105 June 2004 Online  A v a i l a b l e  h t t p    d o i  a c m  o rg/10.1145 1007730.1007731 15 A  L  N  F r e d a n d A  K  J a i n   C o m b i n i n g m u l t i p l e c l u s t e r ings using evidence accumulation IEEE Trans Pattern Anal Mach Intell  vol 27 pp 835ñ850 June 2005 Online  A v a i l a b l e  http://dx.doi.org/10.1109/TPAMI.2005.113 16 G  C o r m o d e a n d S  M u t h u k r i s h n a n   W h a t  s n e w   n d i n g s i gnicant differences in network data streams Networking IEEE/ACM Transactions on  vol 13 pp 1219  1232 2005 17 G  F e r n a n d e s a n d P  O w e z a r s k i   A u t o m a t e d c l a s s i  c a t i on of network trafc anomalies in Proceedings SecurComm'09  2009 18 A  K  J a i n   D a t a c l u s t e r i n g  5 0 y e a r s b e y o n d k m e a n s   Pattern Recognition Letters  vol 31 pp 651ñ666 Online  A v a i l a b l e  http://linkinghub.elsevier.com/retrieve/pii/S016786 5509002323 19 A  S t r e h l a n d J  G h o s h   C l u s t e r e n s e m b l e s  a k n o w l e d g e reuse framework for combining multiple partitions J Mach Learn Res  vol 3 pp 583ñ617 March 2003 Online  A v a i l a b l e  http://dx.doi.org/10.1162/153244303321897735 20 R  A g r a w a l  J  G e h r k e  D  G u n o p u l o s  a n d P  R a g h a v a n   A utomatic subspace clustering of high dimensional data for data minin g applications ser SIGMOD 98 pp 94ñ105 Online  A v a i lable http://doi.acm.org/10.1145/276304.276314 21 R  F o n t u g n e  P  B o r g n a t  P  A b r y  a n d K  F u k u d a   M a w i l a b combining diverse anomaly detectors for automated anomaly labeling a nd performance benchmarking ser Co-NEXT 10 pp 1ñ12 


moments. Signal Processing : Image Communication, 16 :95100, 2000 


And put forward that we could use confidence, category homoplasy and relevancy strength to improve the quality of feature extension modes. We also verified that confidence category homoplasy and relevancy strength are effective through our experiments. In the same time we have drawn the following conclusions: \(1 relationships for short-text can improve their classification performance; \(2 effectiveness of information in the feature extension mode library we should choose the suitable thresholds; \(3 information is too small to meet the demand of short-text feature extension. So we should find out a perfect method which can increase information coverage in the feature extension mode library for short-text classification; \(4 extension library for short-text extension effectively, i.e., choosing a perfect feature extension strategy is also our further work ACKNOWLEDGMENT The research is supported in part by the National Natural Science Foundation of China under grant number 60703010 the Nature Science Foundation of Chongqing province in China under grant number CSTC, 2009BB2079, and the Scientific Research Foundation for the Returned Overseas Chinese Scholars of Ministry of Education of China under grant number [2007] 1109 REFERENCES 1] Fabrizio Sebastiani.Machine Learning in Automated Text Categorization, A.ACM Computing Surveys, C.2002.34\(1 2] Fan Xing-hua,Wang peng. Chinese Short-Text Classification in TwoStep, J.Journal of DaLian Maritime Universtiy, 2008,11\(2 3] Zelikovitz S. and Hirsh H. Improving Short Text Classification Using Unlabeled Background Knowledge to Assess Document Similarity C. In: Proceedings of ICML-2002, 2002, 1183-1190 4] Wang Xi-wei,Fan Xing-hua and Zhao Jun. A Method for Chinese Short Text Classification Based on Feature Extension, J.Journal of Computer Applications,2009,29\(3 5] JIAWEI HAN,JIAN PEI ,YIWEN YIN, BUNYING MAO.Ming Frequent Patterns without Candidate Generation:A Frequent-Pattern Tree.Data Mining and Knowledge Discovery,2004,8:53-87 6] Liu Fei. Huang Xuan-qing and Wu Li-de.Approach for Extracting Thematic Terms Based on Association Rule, J.Computer Engineering,2008\(4 7] Xinhua Fan, Jianyun Nie. Link Distribution Dependency Model for 


Document Retrieval, C.Journal of Information and Computational Science6:3\(2009  90 


shows that proposed post mining of association rule mining technique for missing sensor data estimation is an area worth to explore REFERENCES 1] Agrawal, R., & Imielinski, T., & Swami, A., "Mining association rules between sets of items in massive databases", International Conference on Management of Data, 1993 2] Austin, F. I., "Austin Freeway ITS Data Archive", Retrieved January 2003 from http://austindata.tamu.eduidefauIt.asp 3] Bastide, Y., & Pasquier, N., & Taouil, R, & Stumme, G., & Lakhal L., "Mining minimal non-redundant association rules using frequent closed itemsets", First International Conference on Computational Logic, 2000 4] Cool, A. L., "A review of methods for dealing with missing data The Annual Meeting of the Southwest Educational Research Association, 2000 5] Deshpande, A., & Guestrin C., & Madden, S., "Using probabilistic models for data management in acquisitional environments", The Conference on Innovative Data Systems Research, 2005 6] Halatchev, M., & Gruenwald, L., "Estimating missing values in related sensor data streams", International Conference on Management of Data, 2005 7] Iannacchione, V. G., "Weighted sequential hot deck imputation macros", Proceedings of the SAS Users Group International Conference, 1982 8] Nan Jiang, "Discovering Association Rules in Data Streams Based On Closed Pattern Mining", SIGMOD Ph.D. Workshop on Innovative Database Research, 2007 9] Li, Y., & Liu, Z. T., & Chen, L., & Cheng, W., & Xie, C.H Extracting minimal non-redundant association rules from QCIL The 4th International Conference on Computer and Information Technology, 2004 10] Little, R 1. A., & Rubin, D. B., "Statistical analysis with missing data", New York: John Wiley and Sons, 1987 II] McLachlan, G., & Thriyambakam, K., "The EM algorithm and extensions", New York: John Wiley & Sons, 1997 12] Mitchell, T., "Machine Learning", McGraw Hill, 1997 13] Papadimitriou, S., & Sun, 1., & Faloutsos, C., "Streaming pattern discovery in multiple time-series", The International Conference on Very Large Databases, 2005 14] Rubin, D., "Multiple imputations for nonresponce in surveys", New York: John Wiley & Sons, 1987 


15] Shafer, 1., "Model-Based Imputations of Census Short-Form Items In Proceedings of the Annual Research Conference, 1995 16] Taouil, R., & Pasquier, N., & Bastide, Y., & Lakhal, L., "Mining bases for association rules using closed sets", International Conference on Data Engineering, 2000 17] Wilkinson & The AP A Task Force on Statistical Inference, 1999 18] Zaki, M. 1., Hsiao, C. 1., "Efficient algorithms for mining closed itemsets and their lattice structure", IEEE Transactions on Knowledge and Data Engineering, 2005 V5-106 


General Chair f!!\f  Organizing Chairs  f!!\f  f$% \f!!\f  Organizing Co-chairs f    f  f\f   f\f\f   f*!\f!\f.\f  f f  Program Committee Chairs  f\f\f   f!!\f  Publication Chair 0   


200 250 300  The size of dataset/10,000 R es po ns e tim e S    a 0 50 100 150 200  The size of dataset/10,000 R es po ns e tim e S    b 0 10 20 30 40 50 


60  The size of dataset/30,000 R es po ns e tim e S    c Fig. 9 The scalability of our algorithm compared with FP-growth  Paper [12] proposed a way to reduce times of scanning transaction database to reduce the cost of I/O IV. CONCLUSIONS AND FUTURE WORK This paper first discusses the theory of foundations and association rules and presents an association rules mining algorithm, namely, FP-growth algorithm. And then we propose an improved algorithm IFP-growth based on many association rules mining algorithms. At last we implement the algorithm we propose and compare it with algorithm FPgrowth algorithm. The experimental evaluation demonstrates its scalability is much better than algorithm FP-growth 177 Now, lets forecast something we want to do someday Firstly, we would parallelize our algorithm, because data mining needs massive computation, and a parallelable environment could high improve the performance of the algorithm; Secondly, we would apply our algorithm on much more datasets and study the run performance; At last, we would study the performance when the algorithm deal with other kinds of association rules  REFERENCES 1] S. Sumathi and S. N. Sivanandam. Introduction to Data Mining and its Applications, Springer, 2006 2] V. J. Hodge, J. Austin, A survey of outlier detection 


methodologies, Artificial Intelligence Review, 2004, 22 85-126 3] Han, J. and M. Kamber. Data Mining: Concepts and Techniques. Morgan Kaufmann, San. Francisco, 2000 4] Jianchao Han, Mohsen Beheshti. Discovering Both Positive and Negative Fuzzy Association Rules in Large Transaction Databases, Journal of Advanced Computational Intelligence and Intelligent Informatics 2006, 10\(3 5] Jiuyong Li, Hong Shen, Rodney Topor. Mining Informative Rule Set for Prediction. Journal of Intelligent Information Systems, 2004, 22\(2 6] Jianchao Han, and Mohsen Beheshti. Discovering Both Positive and Negative Fuzzy Association Rules in Large Transaction Databases. Journal of Advanced Computational Intelligence, 2006, 10\(3 7] Doug Burdick, Manuel Calimlim, Jason Flannick Johannes Gehrke, Tomi Yiu. MAFIA: A Maximal Frequent Itemset Algorithm. IEEE Transactions on Knowledge and Data Engineering, 2005, 17\(11 1504 8] Assaf Schuster, Ran Wolff, Dan Trock. A highperformance distributed algorithm for mining association rules. Knowledge and Information Systems, 2005, 7\(4 458-475 9] Mohammed J. Zaki. Mining Non-Redundant Association Rules. 2004, 9\(3 10] J.Han, J.Pei, Y.Yin, Mining frequent patterns without candidate generation, Proceedings ACM SIGMOD 2000 Dallas, TX, May 2000: 1-12 11] P.Viola, M.Jones. Rapid Object Detection Using A Boosted Cascade of Simple Features. Proc. IEEE Conf. on Computer Vision and Pattern Recognition, 2001 12] Anthony K. H. Tung, Hongjun Lu, Jiawei Han, Ling FengJan. Efficient Mining of Intertransaction Association Rules. 2003, 154\(1 178 


For each vertex b in g form j forests body\(a, g, i s.t. bodyAnt\(a, g, i a, g, i with itemsets Ant\(b b and each subset of itemsets Ant\(b b in P\(a, g, j Assign to each leaf l of trees bodyAnt\(a, g, i bodyCons\(a, g, i a fresh variable Vm,M, m, M = size\(itemset\(l Assign to each leaf l of tree headAnt\(a, g, j the variable assigned to itemset l in some leaf of some tree bodyCons\(a, g, i TABLE II.  EXPERIMENTAL DATA Conf. #rules #pruned #dftrs PtC 0.5 6604 2985 1114 0.6 2697 2081 25 0.75 1867 1606 10 0.8 1266 1176 0 0.95 892 866 1 0.98 705 699 1 DSP 0.5 2473 1168 268 0.6 1696 869 64 0.75 1509 844 89 0.8 1290 1030 29 0.95 1032 889 15 0.98 759 723 1 Arry 0.5 770 492 82 0.6 520 353 60 0.75 472 327 39 0.8 408 287 22 0.95 361 255 25 0.98 314 243 30  Our induction algorithm has been launched for each combination of thresholds. Our scheme eliminates all redundant rules in the sense of [25, 31], i.e. those association rules that are not in the covers. All the meta-rule deductive schemes implicitly included in [25] and [31] are induced by our method. The percentage of pruning, thus, outperforms [25 


The results produced for k=3, support 0.25 and confidences between 0.7 and 0.99 are shown in Fig. 3, in terms of pruning percentage \(vertical axis when applied to low confidences \(from 0.7 to 0.9 The percentage of pruning achieved diminishes as the confidence is superior to 0.9. Nevertheless, the pruning is effective with confidence of 0.99 in the majority of cases Pruning at Support = 0.25 0,00 5,00 10,00 15,00 20,00 25,00 30,00 35,00 40,00 45,00 50,00 0,7 0,8 0,9 0,95 0,99 Confidence P ru n in g L e v e l Case 1 Case 2 Case 3  Figure 3.  Pruning experiences at support 0.25  V. DISCUSSION AND CHALLENGES It is important to discuss the technique presented here with focus on the purpose the technique pursues:  to produce semantic recommendation The reader should have noticed that the algorithm presented 


relies strongly on "choice". For instance, the algorithm chooses ears in the graph to form an order for elimination, and the choice is arbitrary. This strategy is essential to maintain low complexity \(polynomial practical. Nevertheless, a warned reader may conclude that this arbitrary choice implies that there are many compactions to produce and therefore the approach as a whole does not show to produce an optimal solution. And the reader is right in this conclusion. Since the goal is compaction, the search for an optimal solution can be bypassed provided a substantial level of pruning is achieved To complete the whole view, we describe how web service descriptions are complemented with the association rules as recommendations. In effect, under our scheme, the document describing the web service is augmented with a set of OWL/RDF/S triples that only incorporate the non-pruned rules with the format of Example 1, that is, the set ARmin of the compaction program obtained by our algorithm, together with the thresholds applied to the mining process and a registered URI of a registered description service. The assumptions and defeaters are not added to the web service description. If the associations encoded in the triples are not sufficient for the client \(a search engine, for instance widening of the response to the description service identified by the given URI, and then the assumptions and defeaters are produced. The reasoning task required for deriving all the implicitly published rules is client responsibility Notice that, under this scheme, the actual rules that appear as members of the set initial ARmin set are irrelevant; the only important issue is the size of the set The developed scheme also supports an extension of the algorithm that admits the assignment of priorities to rules and to itemsets, in order to allow the user to produce a more controlled program as output. Nonetheless, the importance of the extension has not been already tested, and therefore it is beyond the subject of the present paper It would be also interesting to design a scheme that supports queries where the client provides an itemset class and values for support and confidence and the engine produces a maximal class of inferred associated itemsets as a response. This scheme is also under development, so we have not discussed this aspect here 


VI. CONCLUSION In this paper, we have presented a defeasible logic framework for managing associations that helps in reducing the number of rules found in a set of discovered associations. We have presented an induction algorithm for inducing programs in our logic, made of assumption schemas, a reduced set of association rules and a set of counter-arguments to conclusions called defeaters, guaranteeing that every pruned rule can be effectively inferred from the output. Our approach outperform those of [17], because all reduction compactions presented there can be expressed and induced in our framework, and several other patterns, particular to the given datasets, can also be found. In addition, since a set of definite clauses can be obtained from the induced programs, the knowledge obtained can be modularly inserted in a richer inference engine Abduction can be also attempted, asking for justifications that explain the presence of certain association in the dataset The framework presented can be extended in several ways Admitting defeaters to appear in the head of assumption, to define user interest Admitting arithmetic expressions within assumptions for adjustment in pruning Admitting set formation patterns as itemset constants Extending the scope, to cover temporal association rules REFERENCES 1]  R. Agrawal, and R. Srikant: Fast algorithms for mining association rules In Proc. Intl Conf. Very Large Databases. \(1994 2]  A. V. Aho, J. E. Hopcroft, J. Ullman. The design and analysis of computer algorithms, Addison-Wesley, 1974 3]  G. Antoniou, D. Billington, G. Governatori, M. J. Maher, A. Rock: A Family of Defeasible Reasoning Logics and its Implementation. ECAI 2000: 459-463 4]  G. Antoniou, D. Billington, G. Governatori, M. J. Maher: Representation results for defeasible logic. ACM Trans. Comput. Log. 2\(2 2001 5]  A. Basel, A. Mahafzah, M. Al-Badarneh: A new sampling technique for association rule mining, Journal of Information Science, Vol. 35, No. 3 358-376 \(2009 6]  R. Bayardo and R. Agrawal: Mining the Most Interesting Rules. In Proc of the Fifth ACMSIGKDD Intl Conf. on Knowledge Discovery and Data Mining, 145-154, \(1999 


7]  R. Bayardo, R. Agrawal, and D. Gunopulos: Constraint-based Rule Mining in Large, Dense Databases. Data Mining and Knowledge Discovery Journal, Vol. 4, Num-bers 2/3, 217-240. \(2000 8]  A. Berrado, G. Runger: Using metarules to organize and group discovered association rules. Data Mining and Knowledge Discovery Vol 14, Issue 3. \(2007 9]  S. Brin, R. Motwani, J. Ullman, and S. Tsur: Dynamic itemset counting and implication rules for market basket analysis. In Proc. ACMSIGMOD Intl Conf. Management of Data. \(1997 10] L. Cristofor and D.Simovici: Generating an nformative Cover for Association Rules. In ICDM 2002, Maebashi City, Japan. \(2002 11] Y. Fu and J. Han: Meta-rule Guided Mining of association rules in relational databases. In Proc. Intl Workshop on Knowledge Discovery and Deductive and Object-Oriented Databases. \(1995 12] B. Goethals, E. Hoekx, J. Van den Bussche: Mining tree queries in a graph. KDD: 61-69. \(2005 13] G. Governatori, D. H. Pham, S. Raboczi, A. Newman and S. Takur: On Extending RuleML for Modal Defeasible Logic. RuleML, LNCS 5321 89-103. \(2008  14] G. Governatori and A. Stranieri. Towards the application of association rules for defeasible rules discovery In Legal Knowledge and Information Systems, JURIX, IOS Press, 63-75. \(2001 15] J. Han, J. Pei and Y. Yin: Mining frequent patterns without candidate generation. In Proc. ACM-SIGMOD Intl Conf. Management of Data 2000 16] C. Hbert, B. Crmilleux: Optimized Rule Mining Through a Unified Framework for Interestingness Measures. DaWaK: LNCS 4081, 238247. \(2006 17] E. Hoekx, J. Van den Bussche: Mining for Tree-Query Associations in a Graph. ICDM 2006: 254-264 18] R. Huebner: Diversity-Based Interestingness Measures For Association Rule Mining. Proceedings of ASBBS Volume 16 Number 1, \(2009 19] B. Johnston, Guido Governatori: An algorithm for the induction of defeasible logic theories from databases. Proceedings of the 14th Australasian Database Conference, 75-83. \(2003 20] P. Kazienko: Mining Indirect Association Rules For Web Recommendation. Int. J. Appl. Math. Comput. Sci., Vol. 19, No. 1, 165 186. \(2009 21] M. Klemettinen, H. Mannila, P. Ronkainen, H. Toivonen, and A Verkamo: Finding interesting rules from large sets of discovered association rules. In Proc. 3rd Intl Conf. on Information and Knowledge 


Management. \(1994 22] M. J. Maher, A. Rock, G. Antoniou, D. Billington, T. Miller: Efficient Defeasible Reasoning Systems. International Journal on Artificial Intelligence Tools 10\(4 2001 23] C. Marinica, F. Guillet, and H. Briand: Post-Processing of Discovered Association Rules Using Ontologies. The Second International Workshop on Domain Driven Data Mining, Pisa, Italy \(2008 24] N. Pasquier, Y. Bastide, R. Taouil, and L. Lakhal: Closed sets based discovery of small covers for association rules. In Proc. BDA'99 Conference, 361-381 \(1999 25] N. Pasquier, R. Taouil, I. Bastide, G. Stume, and  L. Lakhal: Generating a Condensed Representation for Association Rules. In Journal of Intelligent Information Systems, 24:1, 29-60 \(2005 26] P. Pothipruk, G. Governatori: ALE Defeasible Description Logic Australian Conference on Artificial Intelligence.  110-119 \(2006 27] J. Sandvig, B. Mobasher Robustness of collaborative recommendation based on association rule mining, Proceedings of the ACM Conference on Recommender Systems \(2007 28] W. Shen, K. Ong, B. Mitbander, and C. Zaniolo: Metaqueries for data mining. In Fayaad, U. et al. Eds. Advances in Knowledge Discovery and Data Mining. \(1996 29] I. Song, G. Governatori: Nested Rules in Defeasible Logic. RuleML LNCS 3791, 204-208 \(2005 30] H. Toivonen, M. Klemettinen, P. Ronkainer, K. Hatonen, and H Mannila: Pruning and grouping discovered association rules. In ECML Workshop on Statistics, Machine Learning and KDD. \(1995 31] M. Zaki: Generating Non-Redundant Association Rules. In Proc. of the Sixth ACMSIGKDD Intl Conf. on Knowledge Discovery and Data Mining, 34-43, \(2000 32] w3c. OWL Ontology Web Language Reference. In http://www.w3.org/TR/2004/REC-owl-ref-20040210 33] w3c. RDF/XML Syntax Specification. In: http://www.w3.org/TR/rdfsyntax-grammar 34] w3c. RDF Schema. In: http://www.w3.org/TR/rdf-schema      


 8   2  3\f            8  D    F  \b 1 8 & #J      b 1  1  4    2  


4 1    9  E 1  2 4 1    9 1   4      8 2  8 1  D 1        1 1  b 


     b b b b b  K            8          2 D 9   F  \b 1 8 ,+J  9 


     b 1     1 2  9 1  12 L 1   9  8       1  2      2   


     b b b b b  K            2  0 \b f  b\f      9       


  8 2   E 1   1     M13 31L 1    b  8E 1   1 #3\b?### 1  1     E 1   1 \b?###3        


1   1   b 1  2 2 18 2     8              1    2 \b 1    2  


    2          2   1 L 2 1   1   L 2 2    2 1  2        


    8  2H D \b A             2  2H D \b A 2 \f 3%\f  f   4%\f f !  , \f\b  C    2    2 


 6    3 1      253 6   1 L 2    6   1         f\b3\f       


               1     1     8 2    E       2  1   


     2 8    b 4      1 8             1 2     1  8 2  


1 9    8      2 1       1     2    8    2 3\f        


     8 D 4 9  F  \b 1 8 #J 9 1     2 1   2 #-@ 1   2 9  E 1   1   2 9      6  


    8  8   1  D 1         1 F  \b0         2 D    F  \b 1 8  9  


  1 9  1   E 1  2 9     1 1 F  \b       1    18   F   1    1 #-$+  \b  2 2  


1 D     1 #-$+.B- 0/:% .0             9 1      18    1 6     1 2  1  1  


1   6      2    1 2 E 8 D 1      1 2   1   1 #-4  #-@E     2  1  1  1       


 8     1          2 F    6   F  2   8    2 C<CC/C N\bO 5      


CD    b$44NO F P Q 6   2 b$$$ ,=\b\bA  A N,O 2 C C  b$$4N  92 2   f  9-\b$$4 B N?O  !-    91  2 1 HH111-18-N+O    -1 :3%   2     0-4 


     b N4O 2   2- \f  C b$@$ \b# >\b\b$3\b$N@O  f :.% 9 /9 \f    1  6  f 2  4   A254 


Advantages of Our M ethod Advantages of Our M ethod Exploit the memory v ertical data format utilizes slidin g windows to g form a much larger database to analyze  Flexibility in Choosing what to choose  Choosing what to choose to build the rules Computational and memory efficiency We have a team working only on this aspect 45 Associative IDS for NextGen Frameworks Dr S Dua LA Tech 45 


Preliminary Results Intra transaction Relations Data rate simulator NH-134 Mb HOP PATH update \(Y/N Inference 11.5 Y Y 2 0.120 N N      Y   n 0.345 N NH134 Y/N   Inf 1 0.150 N N 2 0 120 Y N Inter transaction Relations 2 0  120 Y N       5 5.55 0.456 Y Relations  n 0.345 N N Nmap on DMRL nmap.org 


Anticipated Outcome Anticipated Outcome Develop algorithm capable of learning from a given heterogeneous diverse Develop algorithm capable of learning from a given heterogeneous diverse data ff Dynamic algorithmic f ramework designed to shi f t modalities and sampling rates based on complex logic Flexibility of integration into the Snort intrusion detection system 47 Associative IDS for NextGen Frameworks Dr S Dua LA Tech 47 


References References Aircraft Cockpit Image courtesy USAF http://www.faa.gov htt p   www.faa g ov  air traffic  technolo gy  p g  _ gy  Acharya R Dua S Du X Sree V Chua C K Automated Diagnosis of Glaucoma Using Texture and Higher Order Spectra Features To appear in IEEE Transactions on Information Technology in Biomedicine  Du X Dua S 2011 Cancer Prognosis Using Support Vector Regression in Imaging  Modality World Journal of Clinical Oncology 2  1   44 49 Du X Dua S 2010 Salient Frame Extraction Using Support Vector Regression and Motion Features pp 5 Proc of the National Aerospace and Electronics Conference July 14 16 2010 D M P D S 2010 Di i i ti Ft d Cl ifi ti Mthd f D essaue r  M  P  D ua S  2010  Di scr i m i na ti ve F ea t ures an d Cl ass ifi ca ti on M e th o d s f or Accurate Classification 1st ed vol 7704 pp 14 Bellingham WA Proceedings of SPIE Dessauer M P Dua S 2010 Low Resolution Vehicle Tracking using Dense and Reduced Local Gradient Features Maps 1st ed vol 7694 pp 8 Bellingham WA Proceedings of SPIE SPIE 


Acknowledgements Acknowledgements Fundin g A g encies  US 4 1 Million direct fundin g g g 4 g LA BoR NIH NSF AFRL AFOSR and NASA Research Team Samuel Kasimalla Brandy McKnight Dr Pradeep Chowriappa Connor Johnson Vasanth Nair Mihir Chowriappa  Connor Johnson  Vasanth Nair  Mihir Karnik Mohit Jain and Swadheen Songmen Associative IDS for NextGen Frameworks Dr S Dua LA Tech 49 All the respective Logos belong to their owners 


Rf d Rdi R e f erence d R ea di ngs Copyright of cover pages held by respective publishers 


Thank You Questions Thank You  Questions Dr Sumeet Dua E mail sdua@latech.edu Web http://dmrl.latech.edu Associative IDS for NextGen Frameworks Frameworks Dr S Dua LA Tech 51 Image Source roadtrafficsigns.com 


