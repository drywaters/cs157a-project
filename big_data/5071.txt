Web Structure Optimization Apprai sal Plan Based on Visiting Thing Furong Jing 1 Fahui Gu 2 Luyan Lai 3  1 Branch School of Information Engineering, JiangXi University of Science and Technology, JiangXi GanZhou 2 Department of Information Engineering, JiangXi Applied Technology Vocational College,  JiangXi GanZhou, China 3 Branch School of Management Engineering,  Jiangxi Environmental Engineering Vocational College,  JiangXi GanZhou 13576675850@139.com Abstract The optimization and appraisal of Web structure is a significant hard problem. In this paper, using the association rule to discover the effective link, using the false association rule to discover invalid link, and the definition of the false association rule is given n. An evaluation function of the Web site optimization is proposed by combination between maximal forward reference path and reference length, which makes the transaction more accurate to optimize the Web structure, and the related experiment is given, the experimental result verifies the credibility of the appraisal plan, the result of the study is a good reference for related research Keywords Web Structure Optimization  False Association rule  Maximal Forward Reference Path  Reference Time Length   Appraisal Function I  I NTRODUCTION  Along with Internet rapid development, the Websites have already become main places where people gain the resources and communicate now and in the future. However the Web link structures of Website also become more complex, which causes the users hard to search the need information. In order to help users to fast search the useful information, it is necessary to carry on the optimization to the Web structure, which achieves the initiative recommendation of the information. Nowadays, many people study the optimization of the Web structure, for example, using the mining of Web logs to realize the optimization of the Web structure, but few people study the appraise of the result of Web structure optimization. In fact it is very significant to appraise the result of Web structure optimization, because the appraisal goal is for optimizing well In this paper, an evaluation function of the Web site optimization is proposed by combination between maximal forward reference path and reference length, which make the transaction more accurate to optimize the Web structure, and verified through the experimental data II  W EB STRUCTURE OPTIMIZATION PROCESS AND SIGNIFICANCE  The Web structure optimization mainly carries on the optimization to the Web page link structure, its optimized goal is for increasing the valid link, and enhancing the search result place, which will be advantageous for the users to find need information quickly The Web link structure may divide into the basic link structure and the additional link structure, once when the Web structure gets down fixedly, we cannot change the basic structure at will, because changing the structure will cause the customers hard to find the page which they have visited before, thus it will cause the outflow of the customers. The Web structure optimization is generally through mining and analysis the Web logs files which the users stay on the server when they glance over Web to realize To optimize the website, two aspects must be analyzed not only to discover the association pages, but also to discover the unreasonable ultra link. This article mainly aims at the Web link structure, resting on the result of mining Web logs files, using the association rule and the false association rule to analysis, dynamic to optimize the Web structure Based on the association rule analysis, many associated patterns can be found, but with business change and time pass, these patterns are often also no longer established. We need one method to confirm these patterns, the false association rule can be available to discover the kind of obsolete and unreasonable pattern, and the definition of false association rule are as follows To suppose    E V G  to express the oriented graph which is composed by an item of collection and during the items of collection association rule, in which V expresses an item of collection set l V j 002 we call it a k item of collection set k  j V  l expresses all of item set E  expresses association rule set, namely E Y X 002 000  If 003 is a real number, called it the most doubting recorded it s uspec t ma x then there is 003 004 000   Y X confidence  Now we carry on the confirmation to each by the association rule E Y X 002 000 to distinguish whether it was still established or not. If the support or the confidence level of association rule is lower than the threshold value which assigns separately, then we call this rule false association rule, with Y X 005 expression Y X 000 is existence , if the expression port Y X port sup min   sup 004 000 or suspect Y X confidence max   004 000 is established, we call Y X 000 association rule and record it Y X 005  Speaking of the false association rule, it should be to discover he association rule which has been discovered which support is smaller than port sup min or confidence level is smaller than s uspec t ma x In here the significance of the support and confidence level of false association rule and association rule is same. No matter the support is association ruleís or the false association ruleís, the incidence relation first should be satisfied; The smallest support of the false 
2009 First International Workshop on Education Technology and Computer Science 978-0-7695-3557-9/09 $25.00 © 2009 IEEE DOI 10.1109/ETCS.2009.131 551 
2009 First International Workshop on Education Technology and Computer Science 978-0-7695-3557-9/09 $25.00 © 2009 IEEE DOI 10.1109/ETCS.2009.131 551 
2009 First International Workshop on Education Technology and Computer Science 978-0-7695-3557-9/09 $25.00 © 2009 IEEE DOI 10.1109/ETCS.2009.131 551 
2009 First International Workshop on Education Technology and Computer Science 978-0-7695-3557-9/09 $25.00 © 2009 IEEE DOI 10.1109/ETCS.2009.131 551 


association rule is equal to the association ruleís; The confidence level has reflected the rule strong or weak, when the confidence level is lower than the smallest confidence level of the association rule slightly, which is insufficient to explain that the rule is untenable, only when the belief level is enough small, namely which is smaller than the most doubting, we can explain that the rule has been untenable We should see the false association rule is compared to the association rule weaker   III  A PPRAISAL PLAN OF W EB STRUCTURE OPTIMIZATION BASED ON VISITING THING  A  Appraisal of Web structure optimization based on average of maximal forward reference path  When a user visits a content Web page, it is often not because of the content of this page, but through the other navigation page. In order to appraise the optimized degree of the Web structure, we give the following several definitions The definition of maximal forward reference path   m l l l mfp  2  1  l is the reference page   length l time l url l l      When the user visits the Web page, the page visited with difficulty locates at the deep level generally, moreover takes the big storage space. To visit deep level page is essential to pass many intermediate level page, and all of the users on each intermediate level page have the possibility to change to visit other pages, therefore it will cause the possibility of he users visiting the page to reduce. Obviously, if two pages have not the ultra link to be connected but the incidence relation, the corresponding maximal forward reference path will be very long, thus it will take to the user to be inconvenient. Therefore, appraisal of Web structure optimization based on average of maximal forward reference path is reasonable, if average of maximal forward reference path of the website is shorter equally, the degree of optimization will be higher Generally speaking, one web log database contains tow nodes \(source node i s goal node i d of a browsing patch. The start source node of a new browsing is empty. As follows is the algorithm of maximal forward reference path Step 1: i=1, Y=null, F=1// to initialize variables and suppose that user is glancing over page forward Step 2: A i s B i d If A=null then Begin If Y<>null then Output Y to database DF Y=B Go to Step 5 End Step 3:  If B  Y then Begin If F=1 then Output Y to database DF Delete m j Y Y   F=0 Go to Step 5 End Step 4: Append B to Y //to append B to Y If F=0 then F=1 Step 5: i=i+1 For DF mfpi    m l l l  2  1 do j=1 for k=\(1Öm\ do Begin If time length l k min    Insert k j l l  into database MFP//MFP is improved thing database j=k+1 End B  Appraisal of Web structure optimization based on length of reference time User continues take the page as the navigation page to visit other pages, after the user glances over a content page which will increase length of maximal forward reference path. Theoretically, the action of visiting can be divided into two or more things, but from the viewpoint of maximal forward reference, it is actually one thing The length of reference time is based on the kind of supposition: The total time of user glancing over a page and the page whether is the navigation page or the content page is related. Generally speaking, the time of user spending on navigation page is always short, but it spending on the content page is longer. Therefore, we can judge that the page is navigation page or content page through expenditure of time which the user spends in glancing over on the Web page Now we redefine the thing as follows           1 1 1 length l time l url l uidtrl trl ip trl rl rl rl t t t           length l time l url l rl rl rl t m t m t m  In which m k   1  L l rl t k   iptrl ip l rl t k    uidtrl uid l rl t k   L  expresses the set of logs L I  which contains ip l  uid l  URL time l  and length l  If the page is a content page there is time length l trl m min    ime M int average time of visiting the page, is the smallest time value for discrimination of navigation page and content page. The definition is as follows  n length l time n i t i rl  min 1    C  statement of Web logical structure optimization appraisal objective function According to above analysis, we can judge the page whether is navigation page or content page through the 
552 
552 
552 
552 


average time of reference. If the reference length is shorter equally, then we can think the degree of the Web page optimization is higher In the ordinary circumstance, user always hope to find the page which one wants to visit as soon as possible whether a Web link structure is reasonable or not, we can judge it through the maximal forward reference path when user visits the content page. Facing the circumstance that the different user visits different page, we can appraise the optimization of Web structure through the computation of maximal forward reference path. Obviously, when a user visits the identical content page, the page number which the user must pass through is smaller, the web link structure optimization is better Therefore, we should consider the factor of the maximal forward reference path and threshold value hypothesis of the average reference time length equally to appraise the optimization of Web structure. The hypothesis of appraisal objective function is as follows  t t i t s t f   1   In which t expresses the total number of things t s  expresses the total page number of each thing   t f  expresses the average value of reference length  In the database of MFP, the total page of each visiting thing is recorded. We can discover the total page number of each visiting thing. It is easy to calculate the total page number P of all the things and the total number t of all things. The result of p/t is the average value of reference length. Whenever the page is carried on an optimization to the website, the result of p/t should be as far as possible small, such optimization will be significance. It is worth of emphasizing, the result of p/t will tend to be smaller with optimization of the Web structure successfully and continually, if the page is carried on very big changing, the optimization value will not be comparative as last time Supposing that the log data has been already processed for the form of user conversation, we can describe the algorithm of the thing of reference length as follows For all sessions do For all pages of session do Begin p If time length l trl m min    t End Result = p/t IV  E XPERIMENT  To test the Web structure optimization appraisal plan mentioned above, here provides the following experiment system, experiment process and its result aiming at a high school website to optimize and appraisal the logic structure A  Experiment system framework The design of experiment system is based on Windows Java and Mysql. Its function can be approximately divided into log preconditioning, algorithm implementation optimization analysis. The main task of system is to control the operation process of whole system, to call all other functional patterns. It includes data cleaning, user conversation identification, thing identification, association rule analysis, false association rule analysis, website optimization appraisal and so on. Among them the objective function will be used to appraise the optimization for website optimization appraisal pattern B  Log cleaning In log processing stage, the logs of pages ended with mpga, .gif, .css, .js ect, need to be cleaned, and other logs of pages ended with .jsp, .html, .asp,.php ect.need to be kept As figure 1 shows the cleaned log records storing in the Mysql database  Figure 1  cleaned log records After log cleaned, the conversation and thing analysis is to be carried on. User maybe visits the same website for many times in Web server log of the wide spanning time section. The target of conversation analysis is to divide the visit record into single conversation. A conversation is composed of several things. Here we take 30 minutes as once conversation time, while taking average page visit time min  as once thing time. The log conversation and the result of thing processed are as figure 2 shows  Figure 2  the log conversation and the result of thing processed C  Algorithm implementation The experiment system mainly uses algorithm of association rule and algorithm of false association rule to analyze the Web hyperlink. The following is the result of 
553 
553 
553 
553 


website log of a high school worked out by association rule and false association rule The process of association rule analysis: put the entire hyperlink pattern found by association rule into a database then test every hyperlink pattern on the website. If the hyperlink exists, it will be deleted from the database otherwise, keep it. Finally, hyperlink in the database will be man-analyzed to make sure whether it can be used to optimize the website or not, just as figure 3 shows  Figure 3  the result of association rule analysis of Web page The process of false association rule analysis: Firstly, put the web hyperlink into database by web spider, then, in the cleaned log records, calculate its support and doubting to determine whether the hyperlink is still suitable or not one by one. If the hyperlink is suitable, it will be deleted from database, otherwise not. At last, hyperlink pattern in the database will be man-analyzed to make sure whether it is suitable to website optimization or not. Figure 4 is result of rule kuandai.htm and xgxx.htm carried on  Figure 4  the result of false associated rule analysis D  Optimization appraisal analysis The procedure reads thing database firstly, then works out average reference length value according to website optimization appraisal algorithm based on average reference length thing. The following is the result of appraisal of the website before optimized and after optimized, as figure 5 figure 6  Figure 5  the result of the first Web structure optimization appraisal  Figure 6  the result of  the second Web structure optimization appraisal From the figure 5 and figure 6 we can know, the value of second website optimization is 5.43, less than 5.58. That is to say, the web structure has been improved. It is necessary to remark that the web structure appraisal always refers to comparison of two optimization values now and last. If the website structure has been carried on a large-scale adjustment, the comparison does not have the significance V  C ONCLUDING REMARK   The failed link of website is not only to reduce the authority of website, but also to affect the corporation business or the sale of products. Web structure optimization can provide the effective server to users and enhance the visit quantity of website, while, to avoid obsolete and invalid hyperlink, it requests urgently us to dynamic appraise its optimization R EFERENCES  1  Han, J., Pei, J. and Yin, Y. Mining frequent patterns without candidate generation. In ACM-SIGMOD Int. Conf. on Management of Data \(SIGMODí00\. \(2000\. Dallas, TX 2  Baoyao Zhou, Jinlin Chen, Jin Shi, Hongjiang Zhang, and Qiufeng Wu.  Website link structure evaluation and improvement based on user visiting patterns . In HYPERTEXTí2001: Proceedings of the twelfth ACM conference on Hypertext and Hypermedia, pages 241 244, 2001 3  Quinlan JR Simplifying decision trees International Journal of Man Machine Studies, 1987, 27\(3\: 221-234 4  Pawalk Z. Rough sets  . International Journal of Computer and Information Science ,1982 ,11\(5\ : 341 356 5  Srikant R, Agrawal R. Mining generalized association rule. In: Proc of the 21st Int'l Confon Very Large DataBase. Zurich, Switzerland 1995.407 419 6  Cooley R, Mobasher B, Srivastava J  Data preparation for mining world wide Web browsing patterns  Knowledge and Information Systems l\(1\:5~32 1999 7  Usama M Fayyad, Gregory Piatetsky-Shapiro et al. Advances in knowledge discovery and data mining. California: AAAI/MIT Press 1996 8  Ming-Syan Chen, Jiawei Han and Philip S. Yu. Data Mining: An Overview from a Database Perspective, IEEE Transactions on Knowledge and Data Engineering, Vol. 8, No.6, pp. 866-883,1996 9  Bollobas B Modern graph theory. Beijin Science Press 2001   R. Ng, J. Han. Efficient and effective clustering method for spatial data mining. In: Proc. 20th VLDB Conference, Santiago, Chile, 1994 pp. 451-463   Bharati P., P. Tarasewich. Global perceptions of Journals publishing E-Commerce. Research  Communications of the ACM 2002,45\(5\:21-26   Ngai E. W. T., F.K.T. Wat. A Literature Review and Classification of Electronic Commerce Research.  Information & Management. 2002 39: 415-429 
554 
554 
554 
554 


  Nakayama T., H. Kato and Y. Yamane, Discovering the gap between Web site designersí expectations and usersí behavior, Computer Networks, 2000, 33: 823-825  Acknowledgment: Our research gets financial aid from Jiangxi educational department \(Science and technology foundation project GJJ08285       
555 
555 
555 
555 


Moreover we can say that F C is comparable to E C and the modi\002ed version of E C i.e vE C  is correct and effective  The combinations of F C  E C  and vE C with 006 conf improve slightly F C  E C  vE C  and 006 conf  We can say that the sum of con\002dences is an important measure and these combined measures are useful in particular in the context where the accuracies of the classi\002cation by the sum of con\002dence by F C  and by E C are almost very good For conclusions 002rstly the adapted weight of evidence is a good class membership measure built on the gain of information F C  a measure built on the revisited 037 2 test provides another view of information gain It is comparable to the adapted weight of evidence The sum of con\002dence is a simple and natural measure with the good performance The combinations of the sum of con\002dence with the previous measures are interesting and useful to improve their performance Next based on the average accuracy values of different measures we recommend to use the combined measures because the average accuracy values of the combined measures are in general better than that of the non-combined measures Finally through the results on each dataset between the combined measures based on 037 2 and the weight of evidence we suggest the following propositions 017 For the 13 small datasets though the average accuracy value of cE C is slightly better than that of cF C  we can observe that cF C is much often wins cE C  Indeed cE C wins cF C on only 3 datasets while cF C wins cE C on 6 datasets Hence we can recommend cF C for the small datasets 017 For the 10 large datasets the average accuracy value of cvE C is slightly better than that of cF C  and cvE C wins cF C on 4 datasets and cF C wins cvE C 3 datasets Hence we can recommend cvE C for large datasets References  B Lent A Sw ami and J W idom Clustering association rules Proc Intl Conf on Data Engineering ICDE'97 IEEE Computer Society 1997 pp 220-231  W  Li J Han and J Pei CMAR Accurate and Ef 002cient Classi\002cation based on multiple class-association rules Proc IEEE Intl Conf on Data Mining ICDM'01 San Jose CA IEEE Computer Society 2001 pp 369-376  B Liu W  Hsu and Y  Ma Inte grating Classi\002cation and Association Rule Mining Proc 4th Intl Conf on Knowledge Discovery and Data Mining KDD'98 AAAI Press 1998 pp 80-86  Y  Sun Y  W ang and A.K.C W ong Boosting an Association Classi\002er in IEEE Transactions on Knowledge and Data Engineering vol 18 no 7 IEEE Computer Society 2006 pp 988-992  J W ang and G Karypis HARMONY  Ef 002ciently Mining the Best Rules for Classi\002cation Proc SIAM Intl Conf on Data Mining SDM'05 2005 pp 205-216  J W ang and G Karypis On Mining Instance-Centric Classi\002cation Rules in IEEE Transactions on Knowledge and Data Engineering vol 18 no 11 2006 pp 1497-1511  Y  W ang and A.K.C W ong From Association to Classi\002cation Inference using Weight of Evidence in IEEE Transactions on Knowledge and Data Engineering vol 15 no 3 2003 pp 764-767  F  Coenen The LUCS-KDD Implementations of the FOIL PRM and CPAR algorithms http://www.csc.liv.ac.uk frans/KDD/Software/FOIL PRM CPAR/foilPrmCpar.html Computer Science Department University of Liverpool UK 2004  Y  Basti de R T aouil N P asquier  G Stumme and L Lakhal Mining Frequent Patterns with Counting Inferences in ACM SIGMOD Explorations vol 2 no 2 2000 pp 66-75  R Agra w al and R Srikant F ast algorithms for mining association rules Proc 20th Intl Conf on Very Large Databases VLDB'94 Santiago Chile 1994 pp 487-499  V  Phan-Luong and R Messouci Building Classi\002ers with Association Rules based on Small Key Itemsets Proc 2nd IEEE International Conf on Digital Information Management ICDIM'07 France 2007 pp 200-205  J Quinlan and R Cameron-Jones FOIL A Midterm Report Proc European Conf on Machine Learning ECML'93 1993 pp 3-20  X Y in and J Han CP AR Classi\002cation based on Predicti v e Association Rules Proc 3rd SIAM Intl Conf on Data Mining SDM'03 San Francisco CA SIAM 2003 pp 369-376  C Cortes and V  V apnik Support-V ector Netw orks  in Machine Learning vol 20 no 3 1995 pp 273-297 
690 


Figure 3 Precision-recall curve in ROI-250 image dataset 5.3 Experiment 3 Mammograms-1080 image dataset This experiment employed a dataset composed by 1080 mammograms images collected in the Clinical Hospital of University of Sao Paulo at Ribeiro Preto The dataset was previously classi\002ed into 4 levels of breast tissue density 0501\051 mostly fatty 050362 images\051 0502\051 partly fatty 050446 images\051 0503\051 partly dense 050200 images\051 and 0504\051 mostly dense 05072 images\051 Figure 4 Precision-recall curve in Mammography-1080 image dataset Breast density is an important risk factor in the development of breast cancer In this experiment the images are represented by the feature set proposed in b uilding a vector of 85 features including shape and size of the breast the conditions of the breast contour nipple position and the distribution of 002broglandular tissue This dataset was divided in training set and test set The training set is composed of 720 images and test set is composed of 360 images Figure 4 shows the P&R curves over test dataset and also the number of features selected in each method Again the proposed methods reached the highest values of precision and select the smallest number of features 050a\051 050b\051 050c\051 050d\051 Figure 5 Queries in Mammography dataset 050a\051 226 is the query image 050b\051 using the features selected through 002tness function F cB  050c\051 using the features selected through classi\002cation error of C4.5 and 050d\051 using the all features extracted Results for the retrieval of the 5 most similar images from a query image are also provided in this experiment as illustrated in Figure 5 The image 5.\050a\051 is the query image taken from the mostly fatty image class Images shown in 5.\050b\051 are the 5 most similar images retrieved for the proposed 002tness function F cB  The row 050c\051 shows the results for C 4  5 classi\002er whereas 050d\051 illustrate the images resulting from all features 050no selection applied\051 In Figure 5 the images surrounded by dashed lines are false positives 050not relevant images\051 For this query the proposed method achieved the highest precision 050100%\051 when compared the results of C4.5 and the original feature vector 050precision of 40%\051 


6 Conclusions This work proposed a novel genetic feature selection framework for CBIRs It employs a wrapper strategy that searches for the best reduced feature set while optimizing 050or preserving\051 the quality of the solution From a ranking evaluation function three new 002tness functions namely F cA  F cB and F c have been proposed and evaluated in three experiments The proposed genetic feature selection approach which encompasses F cA  F cB and F c  has been compared with 050a\051 traditional methods found in the literature 050b\051 the StARMiner feature selector and 050c\051 the whole feature vector and signi\002cantly outperformed them The proposed approach has been able to optimize the accuracy of similarity queries while selecting a signi\002catively reduced number of features Additionally the proposal of combining the quality of the query results with the criterion of minimizing the number of selected features F cA and F cB  led to high accurate query answers while reducing the number of features more than the 002tness function F c  Therefore the 002nal processing cost of the queries is also reduced References  P  M d Aze v edo-Marques N A Rosa A J M T raina C Traina-Jr S K Kinoshita and R M Rangayyan Reducing the semantic gap in content-based image retrieval in mammography with relevance feedback and inclusion of expert knowledge International Journal of Computer Assisted Radiology and Surgery  3\0501-2\051:123\226130 June 2008  R Baeza-Y ates and B Ribeiro-Neto Modern Information Retrieval  Addison-Wesley Essex UK 1999  B Bartell G Cottrell and R Bele w  Optimizing similar ity using multi-query relevance Journal of the American Society for Information Science  49:742\226761 1998  O Cord 264 on E Herrera-Viedma C L 264 opez-Puljalte M Luque and C Zarco A review on the application of evolutionary computation to information retrieval International Journal of Approximate Reasoning  34:241\226264 July 2003  J G Dy  C E Brodle y  A Kak L S Broderick and A M Aisen Unsupervised feature selection applied to content-based retrieval of lung images IEEE Transactions on Pattern Analysis and Machine Intelligence  25\0503\051:373\226 378 March 2003  W  F an E A F ox P  P athak and H W u The ef fects of 002tness functions on genetic programming-based ranking discovery for web search Journal of the American Society for Information Science and Technology  55\0507\051:628\226636 2004  W  F an P  P athak and M Zhou Genet ic-based approaches in ranking function discovery and optimization in information retrieval a framework Decision Support Systems  2009  D E Golber g Genetic algorithms in search optimization and machine learning  Addison Wesley 1989  R L Haupt and S E Haupt Practical Genetic Algorithms  John Wiley  Sons New Jersey United States second edition edition 2004  J Horng and C Y eh Applying genetic algorit hms to query optimization in document retrieval Information Processing  Management  36:737\226759 2000  S K Kinoshita P  M d Aze v edo-Ma rques R R PereiraJr J A H Rodrigues and R M Rangayyan Contentbased retrieval of mammograms using visual features related to breast density patterns Journal of Digital Imaging  20\0502\051:172\226190 June 2007  F  K orn B P agel and C F aloutsos On the  dimensionality curse and the self-similarity blessing IEEE Trans on Knowledge and Data Engineering  13\0501\051:96\226111 2001  H Liu and L Y u T o w ard inte grating feature select ion algorithms for classi\002cation and clustering IEEE Transactions on Knowledge and Data Enginnering  17\0504\051:491\226502 April 2005  M X Ribeiro A J M T raina C T raina-Jr  and P  M Azevedo-Marques An association rule-based method to support medical image diagnosis with ef\002ciency IEEE Transactions on Multimedia  10\0502\051:277\226285 2008  U S Cancer Statistics W orking Group United states cancer statistics 1999-2005 incidence and mortality webbased report atlanta 050ga\051 Department of health and human services centers for disease control and prevention and national cancer institute 2009 Available in http://apps.nccd.cdc.gov/uscs   L T amine C C and M Boughanem Multiple query evaluation based on an enhanced geneticnext term algorithm Information Processing  Management  39\0502\051:215\226 231 2003  R S T orres A X  F alc 230 ao M A Gonc\270alves J P Papa Z B W Fan and E A Fox A genetic programming framework for content-based image retrieval Journal of the American Society for Information Science and Technology  42\0502\051:283\226292 2009  A Tsymbal P  Cunningham M P echenizkiy  and S Puuronen Search strategies for ensemble feature selection in medical diagnostics In Proceedings of the 16th IEEE Symposium on Computer-Based Medical Systems  pages 124\226 129 June 2003  A Tsymbal M Pechenizkiy  and P  Cunningham Sequential genetic search for ensemble feature selection In Proceedings of the International Joint Conferences on Arti\002cial Intelligence  pages 877\226882 August 2005  C.-M W ang a and Y F  Huang Ev olutionary-based feature selection approaches with new criteria for data mining A case study of credit approval data Expert Systems with Applications  36\0503 Part 2\051:5900\2265908 2009  H Y an J Zheng Y  Jiang C Peng and S Xiao Selecting critical clinical features for heart diseases diagnosis with a real-coded genetic algorithm Applied Soft Computing  8:1105\2261111 2008  T  Zhao J Lu Y  Zhang and Q Xiao Feature selection based on genetic algorithm for cbir In IEEE Congress on Image and Signal Processing  volume 2 pages 495\226499 2008 


     Figure 9. Argumentation Tree For Open GL  A1 The current system in flash does not have the functionality of dynamic allocation of particles like mine or clutter. It places them randomly  A1.1 That is not of much importance because it still gives a new position to mine and clutter particles A2 Current system in flash has faster response time as compared to system in Adobe Director A3 The current system doesnêt satisfy many of the features required for the new system like database A4 Adobe Flash cannot communicate with database A4.1 Flash doesnêt support database but database support is very important and critical A4.1.1 The system should be able to generate evaluation reports for trainee based on pr evious records stored in the database A5 Flash doesnêt create sound clips  A5.1 We donêt need sound creating features as the sys tem has to generate sound. We can play externally recorded sound files using Adobe Flash A6 Flash can provide good visual effects as compared to Adobe Director A7 The developer has good knowledge in development using Flash so the system can be developed quickly B1 We could reuse the system already developed for sound generation, as it is developed using Adobe Audition for analysis which is somehow related to Adobe Director B1.1 The current system is better synthesized in terms of sound production and the sound produced is also instantaneous rather than discrete B1.2 That current system has certain performance issues like slow response time B1.3 The current system in Adobe Director has the feature of producing dynamic coloring scheme on approaching a mine. This kind of scheme is highly preferable and is not present in Adobe Flash system B2 Adobe Director can provide more functionality as compared to the current flash system. E.g. Multiple sounds while detecting mines   B2.1 Adobe Director can provide better visual effects as compared to flash e.g. in case of GUIês   B2.2 A modified version of the current system in flash can also provide the same functionality B2.2.1 We cannot integrate code developed in other platforms with Flash, but Flash can be integrated in Adobe Director B3 The interface provided by flash is not professional enough. It is too simple and straight forward for doing more things in future   B4 Easily available plug-ins can help integrate the tracking system developed in C# with Adobe Director  B4.1 Code developed in Open GL/AL can also be integrated using Adobe Director using suitable stubs   B5 A new sound recognition algorithm is being developed in Adobe Audition which can be integrated with Adobe Director but not with Open GL or Flash Evidence supported B6 If the current system is reused; the project deadline can be met easily B7 The developer has very little experience in development using Adobe Director   B7.1 The developer can take help from the already developed system in Adobe Director C1 The tracking software already developed is coded in C#/NX5. We could reuse that and develop our system in Open GL/AL C1.1 Open GL has C# libraries which can be used to develop the system C2 Because the platform used is for high end application development, it can provide good GUI and database support C2.1 Open GL/AL can help us generate dynamic surfaces for mine detection and training which the original system in flash does not have C4 Open GL does not support connectivity with Adobe Audition. Adobe Audition is required for creating sound recognition algorithm C3 Open GL does not support connectivity with Adobe Audition. Adobe Audition is required for creating sound recognition algorithm C4 The time taken for developing the project using open GL will be comparatively more as the whole system would have to be developed from scratch C4.1 If Open GL has support for C# libraries, and then the system could be develope d faster as developer is quite familiar with programming languages like C 151 


   C4.2 Open GL has excellent documentation that could help the developer learn the platform with ease C4.3 Developer has very little ex perience in working with Open GL platform  For our case study, alternative B i.e. Adobe Director was the most favorable alternative amongst all the three. It catered to the reusability criteria quite well and aimed at meeting most of the desired operational requirements for the system   6. CONCLUSION & FUTURE WORK  The main contribution of this paper is to develop an approach for evaluating performance scores in MultiCriteria decision making using an intelligent computational argumentation network. The evaluation process requires us to identify performance scores in multi criteria decision making which are not obtained objectively and quantify the same by providing a strong rationale. In this way, deeper analysis can be achieved in reducing the uncertainty problem involved in Multi Criteria decision paradigm. As a part of our future work we plan on conducting a large scale empirical analysis of the argumentation system to validate its effectiveness   REFERENCES  1  L  P Am g o u d  U sin g  A r g u men ts f o r mak i n g an d  ex p lain in g  decisions Artificial Intelligence 173 413-436, \(2009 2 A  Boch m a n   C ollectiv e A r g u men tatio n    Proceedings of the Workshop on Non-Monotonic Reasoning 2002 3 G  R Bu y u k o zk an  Ev alu a tio n o f sof tware d e v e lo p m en t  projects using a fuzzy multi-criteria decision approach Mathematics and Computers in Simualtion 77 464-475, \(2008 4 M T  Chen   F u zzy MCD M A p p r o ach t o Selec t Serv ice  Provider The IEEE International Conference on Fuzzy 2003 5 J. Con k li n  an d  M. Beg e m a n   gIBIS: A Hypertext Tool for Exploratory Policy Discussion Transactions on Office Information Systems 6\(4\: 303  331, \(1988 6 B P  Duarte D e v elo p in g a p r o jec ts ev alu a tio n sy ste m based on multiple attribute value theroy Computer Operations Research 33 1488-1504, \(2006 7 E G  Fo rm an  T h e  A n a l y t ic Hier a rch y P r o cess A n  Exposition OR CHRONICLE 1999 8 M. L ease  an d J L  L i v e l y  Using an Issue Based Hypertext System to Capture Software LifeCycle Process Hypermedia  2\(1\, pp. 34  45, \(1990 9  P e id e L i u   E valu a tio n Mo d e l o f Custo m e r Satis f a c tio n o f  B2CE Commerce Based on Combin ation of Linguistic Variables and Fuzzy Triangular Numbers Eight ACIS International Conference on Software Engin eering, Artificial Intelligence Networking and Parallel Distributed Computing, \(pp 450-454 2007  10  X  F L i u   M an ag e m en t o f an In tellig e n t A r g u m e n tatio n  Network for a Web-Based Collaborative Engineering Design Environment Proceedings of the 2007 IEEE International Symposium on Collaborative Technologies and Systems,\(CTS 2007\, Orlando, Florida May 21-25, 2007 11 X. F L i u   A n In ternet Ba se d In tellig e n t A r g u m e n tatio n  System for Collaborative Engineering Design Proceedings of the 2006 IEEE International Symposium on Collaborative Technologies and Systems pp. 318-325\. Las Vegas, Nevada 2006 12 T  M A sub jec tiv e assess m e n t o f altern ativ e m ission  architectures for the human exploration of Mars at NASA using multicriteria decision making Computer and Operations Research 1147-1164, \(June 2004 13 A  N Mo n ireh  F u zzy De cisio n Ma k i n g b a se d o n  Relationship Analysis between Criteria Annual Meeting of the North American Fuzzy Information Processing Society 2005 14 N  P a p a d ias HERMES Su p p o rti n g A r g u m e n tative  Discourse in Multi Agent Decision Making Proceedings of the 15th National Conference on Artifical Intelligence \(AAAI-98  pp. 827-832\dison, WI: AAAI/MIT Press,  \(1998a 15  E. B T riantaph y llo u   T h e Im p act o f  Ag g r e g atin g Ben e f i t  and Cost Criteria in Four MCDA Methods IEEE Transactions on Engineering Management, Vol 52, No 2 May 2005 16 S  H T s a u r T h e Ev alu a tio n o f airlin e se rv ice q u a lity b y  fuzzy MCDM Tourism Management 107-115, \(2002 1 T  D W a n g  Develo p in g a f u zz y  T O P S IS app r o ach  b a sed  on subjective weights and objective weights Expert Systems with Applications 8980-8985, \(2009 18 L  A  Zadeh  F u z z y Sets   Information and Control 8  338-353, \(1965  152 


                        





