Managing Unstructured Data With Structured Legacy Systems David A Maluf david.a.maluf\(nasa.gov Peter B Tran peter.b.tran\(nasa.gov NASA Ames Research Center Intelligent Systems Division Mail Stop 269-4 Moffett Field CA 94035 Abstract In this paper we describe an approach and system for managing and joining enterprise semi-structured data in a high-throughput nimble and scalable systems with traditional relational database management systems RDBMS This paper presents the second release of NASA's NETMARK system 
NETMARK is an Enterprise Information Integration ElI framework based on a modem schema-less concept approach NETMARK schemaless information integration reinvents the way of managing semi-structured documents within traditional RDBMS We describe in particular detail the unique underlying data storage approach and efficient query processing mechanisms given the new proposed storage system upgrade We present an extensive evaluation of the virtual union between NETMARK with the persistent schemas similar to commercial off-the-self products such 
as Systems Applications and Products SAP currently utilized for NASA's Financial System through well validated applications At the heart of the approach is the philosophy of a well-defined and focused approach on most common data management requirements in the enterprise and not burdening users and application developers with unnecessary complexity and formal data integration processes This paper presents the details of achieving the integration between two incompatible systems 1 2 
TABLE OF CONTENTS 1 INTRODUCTION 1 2 NETMARK AS AN EXTENSIBLE DATABASE 2 3 A LEAN APPROACH  2 4 NETMARK 3 5 APPLICATION 4 6 CONCLUSIONS 5 REFERENCES  5 BIOGRAPHIES  5 1 1-4244-1488-1/08/$25.00 
C 2008 IEEE 2 IEEEAC paper 1360 Version 2 Updated November 08 2007 1 INTRODUCTION The Problem of Heavy Middleware The 1990's witnessed a significant amount of activities towards the 
development of ElI Enterprise Information Integration technologies that were aimed at addressing the ubiquitous problem of providing data integration across multiple distributed and possibly heterogeneous data sources in the enterprise Software vendors that included both start-up companies as well as larger players such as International Business Machine IBM were offering software based upon a middleware architecture The idea behind this particular architecture was that the middleware would provide an integrated access 
layer across the various data sources being integrated This is integration as opposed to the data warehousing approach in which all data is loaded and centralized at a single place for further analysis Towards the late 90's eXtensible Markup Language XML gained prevalence simultaneously addressing the problem of syntactic heterogeneity but not semantic heterogeneity across different information sources The functional key issue with the middleware architecture approach to seamless data integration is the significant amount of effort 
and resources required for managing and reconciling heterogeneous data schemas Schemas describing data in the individual information sources as well as specifying linkages across multiple schemas to form an integrated view of the information The amount of time and resources required for schema management becomes a key impediment to ElI technology being scalable and cost-effective for large applications Indeed as observed in an ElI technology review 1 A connected thread to this key 
impediments for EII is to address modeling and metadata management which is the highest cost item in the first place The original vision of intelligent information integration to nimble data management for an integrated access to information sources on-demand went awry We trace this to some tacit incorrect assumptions regarding how enterprise data should be managed and integrated These assumptions along with our alternative approach to addressing these issues are 1 


1 Data must always be stored and managed in DBMS systems Actually the requirements of applications vary greatly ranging from simple data that can be stored in simple document-oriented formats e.g spreadsheets and/or flat text files to complex large data objects e.g binary image files that does indeed require DBMS storage 2 The database must always provide for and manage the structure and semantics of the data through formal schemas Alternatively the database can be nothing more than intelligent storage Data could be stored generically and imposition of structure and semantics schema may be done by clients as needed 3 Managing multiple schemas from several independent data sources and their interrelationships between them is inevitable and unavoidable thus produces schemachaos  Alternatively any imposition of schema can be done by the clients only as when needed by applications 2 NETMARK AS AN EXTENSIBLE DATABASE Middleware technology should be a cost-effective solution and not become part of the problem as it is now At the NASA Ames Research Center we have designed and developed a data management and integration system called NETMARK that achieves data integration across multiple structured and unstructured data sources in a highly scalable and cost efficient manner The querying and integration of originally unstructured data such as various formatted reports in Microsoft Word Adobe Portable Document Format PDF Excel spreadsheets and PowerPoint presentations is a key focus given that the bulk of enterprise data is indeed unstructured A new paradigm we introduce is that of context-sensitive querying and search Let us illustrate this with some examples Consider a document report in Microsoft Word format see Figure 1 The document comprises of several text fragments e.g sections and sub-sections such as the section titled Abstract Project Summary Background etc A spreadsheet in Excel can also be fragmented into various rows columns cells tables and workbooks or sets thereof Similarly a PowerPoint slide comprises typically of a slide title and some slide content Each such sections or sub-sections are considered as topic headings to a particular context For instance in the Word report we have a Background context in the example PowerPoint slide we may have a Constellation Spirals context as a heading etc The actual document content then becomes the text graphics or other material within the document fragment that is then referred to as content For instance the text in the Background paragraph heading is the content associated with that particular context Figure 1 Fragments in unstructured data Users pose queries in terms of context and content where they are able to search and retrieve particular textual fragments of interest For instance a query such as Context=Procurement 3 would return all fragments from a collection of documents where the context contains the word Procurement case insensitive Similarly the query Context=Procurement  Content=Contract will return all fragments which contains the keyword word contract within the context of Procurement 3 A LEAN APPROACH NETMARK supports such context and content oriented queries over a collection of unstructured data of literally any common types found in the enterprise This has proven to be a powerful and effective paradigm for information retrieval in real-world applications In addition to data management and integration we have also considered other key issues in the enterprise information lifecycle Providing data to an integrated application should be an easy process requiring minimal effort from the user In fact many existing ElI technologies require that any data to be integrated should be massaged parsed or marked to be a certain format or wrapped for translation NETMARK provides a capability where data can simply be provided as-is Providers simply drag and drop their data e.g a folder with several reports spreadsheets etc sitting on the user desktop into a NETMARK-enabled server While maintaining the simple concept of the folder on their desktop the NETMARK system than formats and structures it appropriately for seamless integration At the data consumer end we further provide capabilities for quickly composing reports and presentations over the integrated data Finally the NETMARK system incorporates and interoperates with open and widely used data representation and exchange standards and protocols All data is ultimately represented 3 We illustrate using an informal query syntax here 2 


and stored in XML formats using open protocols such as the Web Distributed Authoring and Versioning WebDAV are used for client-server communications WebDAV is a W3C World Wide Web Consortium Internet Engineering Task Force IETF Request for Comments RFC standard that provides a set of extensions in the forms of methods headers and content-type ancillaries to the HTTP/1.1 protocol for resource management namespace manipulation and locking mechanisms for collaboratively sharing and editing documents remotely from web-enabled HTTP servers Originally RFC25 18 was established in February 1999 and has been superseded by RFC4918 as of June 2007 The implementation however is purely relational meeting the ultimate objective of integration with legacy RDBMS systems 4 NETMARK The NETMARK architecture is illustrated in Figure 2 MAtlllEE3  INETMARK 1 L7U4 E D M5 Figure 3 Data storage in NETMARK Data storage in NETMARK as shown in Figure 3 has two the relational tables e.g DOC and XML which map objects to relations A document could then be joined by a primary PK and foreign key FK pair named DOC ID The XML table is recursively nested on physical row identifiers called a ROWID A ROWID is a pseudo-column within the relational tables that allow the fastest single block read access to the tabular record The DOC table contains the document metadata fields such as file name type date and size etc The schema-less concept demonstrates the ability to articulate context independently from content reflecting on structures such as tags or attributes of an XML entry but in a dynamic fashion The context and content oriented manner in which all data is modeled leads to a very efficient mechanism for storing the data coupled with efficient retrieval The data storage cycle is as follows Unstructured data is provided to NETMARK by placing the data in a NETMARK folder NETMARK then automatically structures the data and converts it to XML This conversion is done based on heuristics that takes into account the document format e.g titles headings etc to fragment the document Each document gets marked up as context and content blocks of XML fragments Each block is then represented as a node in a hierarchical document tree-like data structure We will not go into the details of a node later but a node is essentially the fundamental unit that captures the information in each context and content 3 June 2007 httSM swww.ietforn/rfc/rfc49 18.txt 5SGML specification IS08879 XML data store The data store is a relational DBMS that has been optimized to handle any data structure using a schema-less paradigm concept k 77 DOIO 2V4 WDEID 102 NODEN A#h MARENTROf SBtN I EAM I NE MAS rEN BL I E Figure 2 NETMARK Architecture Various clients such as data producers and providers and data consumers or both access NETMARK through a web interface We will provide some illustrations of this interface on both context and content querying The NETMARK daemon processes the incoming client requests and the Standard Generalized Markup Language SGML parser provides functionality for loading data e.g documents into NETMARK The SGML parser hands the superset of conventional Hyper Text Markup Language HTML web pages and XML data formats SGML is the precursor and superset of markup language known as International Standards Organization ISO 8879 standard specification on Information Processing for Text and Office Systems published in 1986 The NETMARK daemon is a continual process that reads in any new documents inserted into a NETMARK folder via drag and drop features and then invokes the customizable SGML parser for structuring it and loading it into the NETMARK WebDAV RFC2518 specifications as of February 1999 http://www.webPdav.oNrg/specs/rfc2518.htmI WEBDAV RFC4918 specifications as of 


The nodes are stored in a relational table called XML The information or metadata about the document is also stored and maintained as well in the second table called DOC Note that with this data representation strategy the information in any document is ultimately stored in the same two relational tables XML and DOC This representation is independent of any schema associated with the document and is thus termed to be schema-less 5 APPLICATION A key feature of the NETMARK storage system is the simplicity by which applications and users can manage data and retrieve data efficiently unlike X-Path and X-Search based systems which relies on complex query languages The challenges for new developers and non-technical users to adopt this system are not well-suited to ad-hoc queries of information in a semi-structured data store such as NETMARK NETMARK provides the ease of use of a fulltext search engine with the capabilities of a semi-structured data store for information retrieval and analysis NETMARK has been deployed in several applications in the NASA enterprise It serves as the integration engine for other more expansive systems for information and process management With NETMARK we have been able to assemble new integration applications very quickly with minimal software development effort zero in many cases and typically requiring just about 2 man days for system setup and application assembly One such application is the analysis of mishap reports for Aviation Safety within NASA Such analysis reports are typically text-based reports describing the analysis of a range of accidents involving government both NASA and other agencies and commercial aircrafts Using NETMARK we are able to select particular sections and sub-sections from multiple reports and further load this information to data analysis and visualization tools seamlessly The integrated access and analysis capabilities over integrated data have proved invaluable to Aviation Safety Analysts at NASA Also the assembly of the application was done with minimal development effort and time NETMARK success has many industry spillovers leading to commercialization and collaboration efforts For example the NASA-Xerox NX system is the result of a strategic collaboration between NASA and XEROX Corporation where NETMARK has been integrated with many XEROX DocuShare6 enterprise content management systems with capabilities for text and document management NX offers a suite of capabilities in 1 Content management including capabilities for document management and collaborative sharing tool 6 XEROX DocuShare is a registered trademark of XEROX Corporation 2 Content process management for business process activities and management BPM such as action item tracking workflow activities and compliance NASA has implemented the NX technology at several NASA centers and in various NASA missions and programs including the following 1 The NASA International Space Station ISS uses NX to mine information for historical decisions and safety assurance information 2 NASA Program Analysis and Evaluation PA&E adopted the commercial version of NX in 2005 which led to adoption by the NASA's Strategic Management Council SMC 3 Most NASA centers use the NX platform including Ames Research Center ARC Langley Research Center LaRC Dryden Flight Research Center DFRC Jet Propulsion Laboratory JPL Johnson Space Center JSC and NASA Headquarters HQ The ability of integrating information is well demonstrated with a complete turn-key application known as the Program Management Tool PMT PMT is a custom-built business intelligence solution for NASA to successfully manage large programs and projects PMT integrates over nine distinct data sources with periodical data updates NETMARK is the underlying data management and integration engine for PMT PMT generates financial data and integrates with the eminent data streams from NASA's Business Warehouse BW SAP-based system PMT enables program project and task managers to communicate successfully any critical information on the status and progress of all program levels in an efficient and update-to-date manner PMT keeps track of program and project goals risks milestones and deliverables and assists the proper allocation of financial material and human resources It is well integrated with other agency-wide information systems such as BW PMT supports all essential program and project management activities and corresponding documents such as the creation and monitoring of annual task plans monthly reporting of technical schedule management budget status tracking budget phasing plans analyzing program risks and mitigation strategies It will assist in reporting and evaluating project life cycle costs accessing convenient aggregated views and automatically creating Earned Value Management EVM assessments Quad-Charts and other analytical reports PMT also provides integrated access to multiple distributed resources across the NASA agency Some the NASA agency-wide information systems PMT has interfaced with are namely the ERASMUS reporting system ERASMUS is an executive reporting system and project performance dashboard that includes performance metrics of all NASA centers programs projects and safety All other trademarks are of their respective companies 


and health activities the NASA Technology Inventory Database an inventory of technologies developed by or under development at NASA and the Integrated Financial Management System IFMP is an agency-wide information system supporting NASA financial management activities thereby significantly reducing cost and time for entering the same data multiple times into different systems This overall reduces data redundancies in multiple information systems NETMARK has received the Best Practices in Storage Award by Computer World and Storage Networking World magazine publication 6 CONCLUSIONS While NETMARK exists for government and commercial use for few years the NETMARK development team's intention to release the NETMARK system with an open source initiative for limited availability sometimes in the near future The type of open source license for NETMARK and its capabilities policies and processes for receiving the software has yet to be determined but NASA Ames Research Center has a history of releasing software into the open source community and we expect that the NETMARK system will be released in this manner also Interested individuals and/or groups may contact Dr David A Maluf at for additional information Also additional information about the NASA's Program Management Tool PMT including system overview demonstrations and documentations can be obtained at the following website h t REFERENCES 1 A Halevy N Ashish D Bitton M Carey D Draper J Pollock A Rosenthal and V Sikka Enterprise information integration Successes challenges and controversies  in ACMSIGMOD 2005 2 D Maluf D Bell N Ashish C Knight and P Tran Semi-structured data management in the enterprise A nimble high-throughput and scalable approach in International Database Engineering and Applications Symposium IDEAS 2005 3 Maluf A David Bell David Ashish Naveen Lean Middleware  Proceedings of the 2005 ACM SIGMOD international conference on Management of data 2005 pp 788-791 ISBN:159593-060-4 2005 4 Maluf A David Bell David NASA Program Management Tool Project Management Challenge University of Maryland 2005 5 Maluf A David Bell David Towards G2G Systems of Technology Database Systems  IEEE Aerospace Conference Montana 2005 6 Maluf David A Gawdiak Yuri Bell David On Space Exploration and Human Error A Paper on Reliability and Safety Proceedings of the ThirtyEighth Annual Hawaii International Conference on System Sciences 2005 7 Maluf David A Tran Peter B NETMARK A Schemal-Less Extension for Relational Databases for Managing Semi-Structured Data Dynamically International Symposium on Methodologies for Intelligent Systems Lecture Notes in Computer Science Springer Verlag 2003 8 Maluf David A Tran Peter B NETMARK Adding Hierarchical Object to Relational Databases with Schema-less Extensions  Intelligent Systems Design and Applications ISDA Tulsa Oklahoma Conference Proceedings 2003 9 Maluf A David Bell G David Knight Chris Tran Peter La Tracy Lin Jenessa McDermott Bill Pell Barney,"NASA-XDB-IPG Extensible Database Information Grid Global Grid Forum 8 2003 BIOGRAPHIES David A Maluf received his Ph.D from McGill University in 1995 and his postdoctoral from Stanford University He has been involved in Intelligent Information Integration and databases since David was also Director of Software Development at Incyte Before NASA David founded and operated Science Gate as CTO The company was successfully acquired At NASA David was the Project Manager for Knowledge Engineering under the Engineering for Complex Systems program David was the CIO for the program In conjunction with the FAA David has been leading from its inception the development and operation of large government information grid projects connecting US government centers nation wide David is the inventor on many NASA patents including Netmark tool suites which were commercialized leading to products such as NX and PMT David is the recipient of many NASA Awards Best Technology Commercialization Turning Goals into Reality and Space Act Awards Peter B Tran is currently a Senior IT Software Architect for NASA Ames Research Center working on data integration and information management projects for the NASA's Constellation Program Previously Peter worked as a software consultant architect technical lead and software engineer at several technology companies including QSS Group Inc BEA Systems XUMA Computer Sciences Corporation and Recom Technologies Peter has a degree in electrical engineering and computer sciences from the University of California at Davis and has taken graduate-level coursework at Stanford University majoring in Computer Science 5 


test between the variables representing AA complexity and the variables representing causes and impacts. The results match closely in terms of significance of category differences and correlation i.e. for those variables where groups exhibited significant differences, we also observed medium correlation strength \(in terms of rho values between 0.3 and 0.5\with significance at the .01 level reinforcing that the categorization did not have a distorting impact on the data \(with the exception of the complexity-impact relation of overlap/redundancy, as this exhibited a non-linear relation that cannot be measured using the Spearman correlation; see Section 4  4. Results  For better readability, we summarize the results of the analyses described above. The appendix contains a detailed description. Table 3 depicts the results with respect to the support found for the propositions derived in Section 2 5   Table 3: Summary of results   Overall, we found support for all propositions \(13\ly for interdependency-related AA complexity Other types of AA complexity did not fully behave as proposed   5 Legend: "+" highly significant \(.01 level\upport of proposition that higher value of 'causes' coincide with higher value IT complexity \(e.g. older applications have higher level of interdependency\ or higher value of IT complexity leads to higher impact \(e.g. higher level of interdependency of applications also leads to higher maintenance cost\. "\(+\" significant \(.05 level support of proposition that that higher value of 'causes' coincide with higher value IT complexity \(e.g. applications covering more products also exhibit a higher level of interdependence significant \(.05 level\ inversion of propositions \(e.g. older applications exhibit lower level of deviation from standard OS\. "\(+\" significant \(.05 level\hape inversion of propositions \(e.g medium level of overlap/redundancy of applications leads to lower operations cost than applications with low or high level overlap/redundancy. "-+" ditto with highly significant \(.01 level N/A" not applicable as overlap is computed from the two variables process and products coverage. "" \(empty cell proposition not supported More specifically, the results for interdependency-related AA complexity show that groups of applications with more interfaces record a higher median score in terms of age \(P1.1\ well as in terms of user departments involved. The same is true at a lower significance level for the number of IB products and processes: the groups of applications with more interfaces also cover more investment banking products and processes \(P2.1\en it comes to complexity impacts, we also found a statistically significant difference in operations cost as well as maintenance cost across the three different interdepency-groups of applications. The more interdependent group \(i.e. applications with 3-7 or more than 8 interfaces\ recorded a higher median of operations and maintenance costs than the less interdependent group \(less than 3 interfaces applications \(hence supporting proposition P3.1  For diversity-related AA complexity  we got different results: almost none of the propositions found support. Although 8 different operating systems \(OS\ were used in total by the 273 applications 6 our tests revealed no significant difference neither in the age nor in the number of user departments involved, number of IB products or processes covered for applications using one versus applications using more than one OS. Hence propositions P1.2 and P2.2 cannot be supported \(at least not when measuring OS-related diversity We see similar results when measuring diversitycomplexity in terms of the number of DBMS used by an application \(overall, we identified 6 different DBMS used by the 273 applications 7 he only significant difference is for the age of applications Applications with more than one DBMS were also older on average than applications with only one DBMS, in support of proposition P1.2 \(in terms of DBMS\lower significance level, we see a significant difference in terms of the amount of user departments involved for those applications with one versus those with more than one DBMS: the former group involves less user departments than the latter This supports P2.2 stating that the more complex business requirements, the more diverse the applications get \(in terms of DBMS\e do not find support for this proposition when looking at the   6 The OS used were: Windows XP/2003 \(used by 28% of applications\, SunOS \(24%\, Solaris \(23%\, zOS \(13%\, AIX 5%\, Linux \(4%\, VMS \(1%\, Other Unix \(1%\; an application can use multiple OS, e.g. if the front-end of a multi-tier application runs on Windows and the back-end runs on AIX 7 The DBMS used were: Sybase \(used by 38% of applications Oracle \(24%\, DB2 \(18%\, MS SQL \(13%\, IMS \(4%\, proprietary DBMS \(3 Proceedings of the 42nd Hawaii International Conference on System Sciences - 2009 6 


number of products or processes covered by the application, though We also found no significance with regards to cost impacts of diversity-related complexity \(neither for DBMS nor for OS\ce, propositions P3.2 could not be supported  Turning to deviation-related AA complexity we found significant differences in terms of the products covered and at a lower significance level in terms of age and processes covered between those applications that do not deviate and those that deviate from the standard OS. Non-standard-compliant applications cover more products and also more processes. However, compliant applications are slightly older \(median: 3.2 years\ than non-compliant ones \(median: 2.2 years\hese results lend support to proposition P2.3 \(when measuring compliance to OS standards\terestingly, the results also indicate that the relation between age and deviation from proposition P1.3\ reverse to the proposition: older applications are more standard compliant Measuring the deviation of applications from the standard DBMS provides a somewhat different picture: significant differences only exist for the number of user departments involved in the application. Here, we find again a surprising result the standard-conformant applications have more userdepartments involved \(median: 3\an non-compliant ones \(median: 1 department; overall median: 2 departments\. This is inverse to the original proposition. We do not find support for propositions stating that with an increase in either age \(P1.3\r business requirements complexity \(P2.3 applications also increase in their deviation from standard technology \(in terms of DBMS As far as deviation-related impacts are concerned we found only one significant result: the group of applications that did not comply to DBMS standards exhibit lower maintenance cost than the compliant applications. In contrast to the original proposition 3.3, for DBMS-standard deviation, we observe significantly lower maintenance cost for noncompliant than for compliant applications  With regards to overlap-/redundancy-related AA complexity we found some support for proposition P2.4 stating that involvement of more users leads to more overlap of applications 8 No significant differences are found regarding the age of the applications, hence, the proposition that older   8 The variables for the coverage of products and processes were not included in this test as the overlap was computed using these two variables \(implying that there is a significant relation between the respective variables applications also exhibit a higher degree of overlap was not supported \(P1.4 However, interesting results were found for the impacts of overlap-redundancy-related AA complexity: it is striking to see that the applications with a medium level of overlaps have a lower median in operations cost than those with a low or high-level of overlap, implying a non-linear, U-shaped relation between overlap and operations cost. Interestingly the same holds true for maintenance cost. Hence, the original proposition \(P3.4\that applications with higher overlap also exhibit higher IT cost is not supported  5. Discussion  Up to now, the \(practical and academic discussion of AA complexity has lacked differentiation. Various kinds of AA complexity have been lumped together with little attempt to distinguish between them. The implicit propositions underlying the respective statements and recommendations have been that all these kinds of AA complexity increase with age and business complexity, and in turn cause higher IT costs In our case, however, the result \(Table 3\dicate that only interdependency-related AA complexity behaves as assumed by consultants and researchers with respect to causes and impact: older applications and those with more complex business requirements also exhibit more interfaces \(i.e. a higher degree of interdependency\; at the same time, more interdependent applications incur higher IT costs than less interdependent applications. An explanation for this is the intuitive assumption underlying the abovementioned propositions: on the one hand, when a business grows over time, applications are added, and these have to be connected to ever more applications In former times, more point-to-point interfaces might have been used, while newer applications try to reduce interfaces e.g. by relying on central middleware. On the other hand, it might also be more difficult to maintain and operate applications with many connections because it is not easy to keep track of all the interdependencies: changing one application means that all of the other applications connected to it have to be changed, as well, thus leading to higher costs for those interdependent applications. The advice of "doing more with less seems to hold true here. In this case, consultants would probably be right in advising their clients to either maintain the growth of or reduce the number of interfaces \(e.g. by introducing Enterprise Application Integration \(EAI\yers to eliminate point-to-point interfaces Proceedings of the 42nd Hawaii International Conference on System Sciences - 2009 7 


However, the other types of AA complexity diversity, deviation, and overlap\ot act according to the general propositions of researchers and consultants in our case. In the following paragraphs, we would like to discuss the deviations from the propositions stated in the introduction The diversity of applications with respect to OS does not seem to be related to any of the causes or impacts we looked at in our case. Concerning DBMS diversity seems to increase with age and the number of involved users. However, no relation to causes is found for DBMS-diversity either. There are multiple possible explanations for this. Firstly, looking at the data, we do not find many applications using multiple OS or DBMS in the company we chose for our case study \(e.g. there were only 20 applications using more than one DBMS\nce, the company might have already worked on the diversity issue Nevertheless, we would have expected some difference even among these few applications in the case of a strong relation. Secondly, we find differences in the support for the propositions depending on which level of the "technology stack we look at. If we think of the different types of technologies as being organized in a layered stack with the specificity of technologies increasing towards the top, OS would probably be on a low level and DBMS would be on a higher level \(because a DBMS is less 'general purpose', i.e. more constrained in what it can be used for\e might find the propositions supported only for 'more specific technologies, which we did not test for \(such as middleware, e.g. application servers, directory services, etc.\rther research might extend the proposition to include a broader coverage of the technology stack". Thirdly, it might well be that diversity \(i.e. the sheer number of technologies used by an application\ is indeed not an important complexity criterion on the level of applications However, it might still be important on more aggregate levels, such as application landscapes: If a business product \(such as derivatives\ makes use of applications that together employ a large number of different technologies on each layer of the technology stack, this combined diversity might very well have an impact on costs. Hence, we would have to look at higher levels of the IT architecture and could formulate the respective proposition for these levels even though they are not supported on the level of applications. Comparing complexity as well as its causes and impacts on different levels of IT architecture \(e.g. applications vs. application landscapes\would enable dissecting the impact that the combination of application has in contrast to single applications \(i.e. answer what the formation of a landscape is really contributing to the overall complexity\ch research could serve to further disentangle AA complexity by not only differentiating different types of AA complexity interdependency, diversity, deviation, and overlap but also by distinguishing different levels of AA complexity \(e.g. applications vs. application landscapes Regarding deviation, we again see differences depending on which level of the technology stack we look at: applications deviating from the standard OS also cover more investment banking products and processes. The reason for this might be that different investment products and processes were historically supported by applications on different platforms Hence applications that have been extended to also cover these products and processes had to be made compatible. This would also provide an explanation for why younger applications deviate more from the standard OS than older ones: introducing more connector" applications serving multiple products and processes will bear out this observation. This explanation makes us aware of the fact that the propositions would benefit from taking into account the previous complexity management activities conducted by the bank. A mediating construct of Complexity management activities and abilities might hence improve the conceptual model for future research. For this purpose, variables would have to be identified to measure the level of activities that address the respective AA complexity type \(e.g integration measures addressing interdependency standardization efforts addressing deviation, and consolidation efforts addressing overlap/redundancy Complexity management activities might mediate both the causes-complexity relation as well as the complexity-impact relation \(see Figure 2 for a refined conceptual model   Causes of IT complexity Age Business requirements  IT complexity Interdependency Diversity of technologies Deviation from technology standards Overlap/redundancy  Impact of IT complexity Cost Agility  Complexity management activities  Figure 2: Refined Conceptual Model  Regarding DBMS-related deviation, we observed two surprising relationships in our case: those applications that deviated more from the standard DBMS involved fewer user departments and also incurred less maintenance costs. The propositions suggested the inverse relationship. An explanation might be that the IT department refused to maintain the applications that were not standard-compliant Proceedings of the 42nd Hawaii International Conference on System Sciences - 2009 8 


These applications might hence generate "hidden" IT costs somewhere else. These costs might then not be reported as IT cost, but e.g. as marketing cost in the case of a non-compliant marketing information system. This explanation would hint at a problem with allowing exceptions to standards if the user department itself takes care of the non-compliant application. In this case, official indicators might underestimate the costs incurred by non-compliance unless the decentralized cost is being tracked as well We cannot think of an intrinsic argument that might warrant the introduction of non-compliant technologies with the aim of decreasing maintenance costs. It should be noted that this might not be the case for other impact variables \(such as agility short-term agility might very well improve if applications with non-standard technologies are added, because it would allow business requirements to be fulfilled more quickly in the short-term However, as we did not include agility as a dependent variable in our study, this claim remains conjectural Concerning overlap/redundancy of applications we only see the proposition on increased user department involvement influencing a higher degree of overlap among applications. Interestingly, the degree of overlap among applications exhibited a Ushaped relation to both operations and maintenance costs, with medium-level overlapping applications incurring the least cost. The explanation for this might be that applications need to have some level of overlap in order to be integrated and should not only serve as silos that consume even more resources to keep them connected with other applications [4, p  th e oth e r e x tre m e, t hos e application s  w i t h a  very high overlap might be so redundant that they incur double work, which increases costs as well This explanation was confirmed when we discussed the results with the bank itself. It follows that at least in this case, reducing overlap is not always warranted, as there might be an optimal level of overlap that does not necessarily coincide with the lowest level of overlap. This reminds us that not all relationships have to be linear when it comes to complexity. Especially in relation to agility, for some types of complexity, a certain amount might be essential and even beneficial, but too much might again be detrimental. While this has been investigated to some degree in non-IT-related areas 1, 2 it h a s rem a i n ed on l y a clai m s o f a r i n th e field of IT complexity \(e.g ilit y i s  hy pot h e sized to  decrease at the extreme ends of the vague construct IT complexity", hence leaving ample room for future research  6. Conclusions  We have shown that the propositions underlying current research and \(consulting\ practice do not hold true for all types of AA complexity. We disentangled the rather broad and vague AA complexity concept by proposing four types of AA complexity interdependency-, diversity, deviation- and overlap/redundancy-related AA complexity. We would recommend against referring broadly to "AA complexity" without further differentiation in future research; we advise specifying which type of AA complexity \(interdependency, diversity, deviation or overlap\ really meant. Being more precise will enable us to add further to the body of knowledge in this highly relevant area of IS research. This proved to hold especially true as we found that the general propositions were only valid for interdependencyrelated AA complexity and not for the other types of AA complexity. Future research should clearly be based on multiple case studies rather than just on a single case study in order to allow for generalization As we found support for the propositions for interdependency-related AA complexity, we propose honing in on this type of AA complexity further, e.g by differentiating the degree or type of interdependency between applications \(see footnote 1\or example, a question of interest could be whether batch-oriented interfaces are more costly to maintain than online interfaces or interfaces facilitated by middleware We also pointed to potential differences for similar types of IT complexity on different architectural levels \(such as for deviation and diversity on the level of applications vs. deviation and diversity on the level of application landscapes which might warrant further research Based on the interpretation of our research findings, we also proposed several adjustments to the current propositions by referring to the technologystack levels for diversity and deviation, and by introducing AA complexity management activities as a mediating construct We hope that this research will serve as a foundation for future research in this area, which has so far in its entangled form been marked by assumptions rather than the subject of actual research       Proceedings of the 42nd Hawaii International Conference on System Sciences - 2009 9 


7. References  1 A s hk e n a s R Simplicity-Minded Management Harvard Business Review, 2007 85 12\: p. 101-109 2 G o ttf re ds on, M. a nd K  A s pina ll Innovation vs Complexity Harvard Business Review, 2005 83 11\6271  S can t l e b u r y  S   et al    From IT Complexity to Commonality: Making Your Business More Nimble in Opportunities for Action in Information Technology 2004 The Boston Consulting Group 4 Ross J.W  P. W e ill, a n d D  C. Ro be rtso n Enterprise Architecture As Strategy 2006, Boston, MA: Harvard Business Scholl Press 5 Ma tte rn F S  Sc h nw  l de r, a n d W  Ste i n  Fighting Complexity in IT McKinsey Quarterly, 2003\(1\. 57-65 6 Child J  Parkinson's Progress: Accounting for the Number of Specialists in Organizations Administrative Science Quarterly, 1973 18 3\: p. 328 7 G e ll-Ma nn, M What is complexity Complexity, 1995 1 1\: p. 16-19 8 P a rk  R.E   Software size measurement: a framework for coutning source statements 1992, Software Engineering Institute, Pittsburg 9 Mc Ca be T  A complexity measure in Proceedings of Int'l Conf. Sofrware Engineering 1976 10  Mc Ca be T  a n d D   Sha r o n  Cyclomatic Complexity and the Year 2000 IEEE Software, 1996 13 3\ p. 115 1 Halstead  M  H   Elements of Software Science 1977 New York: Elsevier 12 r te ta B.M. a n d R  E. G i a c h e tti A measure of agility as the complexity of the enterprise system Robotics and Computer-Integrated Manufacturing, 2004 20 p. 495-503 1 S h p i l b erg D  et al    Avoiding the Alignment Trap in Information Technology. \(Cover story MIT Sloan Management Review, 2007 49 1\: p. 51-58 14 Bo h, W  F. a nd D. Y e llin Using Enterprise Architecture Standards in Managing Information Technology Journal of Management Information Systems 2007 23 3\: p. 163-207 15 Chil d P  e t a l  SMR Forum: The Management of Complexity Sloan Management Review, 1991 33 1\ p 73-80 16 K a is le r, S.H F  A r m our, a nd M. Va l i v u lla h  Enterprise Architecting: Critical Problems in Proceedings of the 38th Annual Hawaii International Conference on System Sciences \(HICSS'05 2005: Hawaii 17 X i a   F  Module Coupling: A Design Metric in AsiaPacific Software Engineering Conference \(APSEC'96  1996 18 K u bic e k H  The Organization Gap in Large-scale EDI systems in Scientific Research on EDI 1992: Alphen aan den Rijn 1 Hi tz M  and B  M o n t azeri  Measuring Coupling and Cohesion in Object-Oriented Systems in Proc. Int Symposium on Applied Corporate Computing 1995 2 Z ach m a n  J A    A framework for information systems architecture IBM Systems Journal, 1987 26 3\: p. 276292 2 J o hn so n G    Researchers on Complexity Ponder What It's All About in New York Times 1997. p. B4 22 Si ng h, K  The impact of technological complexity and interfirm cooperation on business survival Academy of Management Journal, 1997 40 2\: p. 339 23 A x e l rod, R  a nd M.D  C ohe n Harnessing Complexity organizational implications of a scientific frontier 2000 New York: Basic Books 24 Ke lly S. a nd M.A   A llison The Complexity Advantage 1999, New York: McGraw-Hill 25 S h e r m a n, H  a nd R Sc hultz  Open Boundaries creating business innovation through complexity 1998 New York: Perseus Books 26 Ca m pbe ll, D  J  Task Complexity: A Review and Analysis Academy of Management Review, 1988 13 1 p. 40-52 2 L e e O K  et al   IT-Enabled Organizational Agility and Firms' Sustainable Competitive Advantage in Proceedings of the Twenty Eighth International Conference on Information Systems 2007. Montral 28 r h out M  v E W a a r ts, a nd J.v   Hille g e rsbe rg   Change factors requiring agility and implications for IT  European Journal of Information Systems, 2006 15 p 132-145 29 W e bs te r, J  a n d R.T  W a ts on Analyzing the Past to Prepare for the Future: Writing a Literature Review MIS Quarterly, 2002 26 2\ p. xiii-xxiii 30 A I S MIS Journal Rankings 2007  [cited 2007 18 April 2007 v a ila ble  f r o m  http://www.isworld.org/csaunders/rankings.htm  31 Pruit t  S  Gartner issues 10 CIO resolutions for 2005  in InfoWorld 2004 32  Po rter M.E  an d  V  E  Mi lla r How information gives you competitive advantage Harvard Business Review 1985 63 4\: p. 149-160 33 T a ba c hnik  B.G  a nd L  S. Fide ll Using multivariate statistics 5th ed. 2007, Boston: Pearson 34 Marten so n s   A  Producing and Consuming Agility in Agile Information Systems - Conceptualization Construction, and Management K.C. DeSouza, Editor 2006, Butterworth-Heinemann. p. 41-51   Proceedings of the 42nd Hawaii International Conference on System Sciences - 2009 10 


Appendix: Detailed description of results  We structured the results of the analyses described in Section 3 according to the two different types of propositions, namely those related to the causes and those related to the impacts of AA complexity  A.1. Results from analyzing causes of AA complexity  Causes of interdependency-related AA complexity The Kruskal-Wallis test revealed a statistically significant difference in the age and number of user departments covered for the three different interdependency groups of applications \(see Table 4 for n and p values\he groups of applications with more interfaces record a higher median score in terms of age as well in terms of user departments involved \(see also  Table 4\The same is true at a lower significance level \(0.05 level\or the number of IB products and processes: the groups of applications with more interfaces also cover more products and processes \(see Table 4 for for n and p values\ce, we do find support for proposition P1.1, which states that the older an application, the higher its interdependency-complexity it is. We also find support for proposition P2.1, which asserts that the higher the complexity of business requirements the higher the interdependency-complexity of applications is  Causes of diversity-related AA complexity The Mann-Whitney U test revealed no significant difference in either the age or the number of user departments involved, or in the number of IB products or processes covered for applications with one OS versus applications with more than one OS see Table 5\. Hence, we do not find support for propositions P1.2 and P2.2, which state that \(OSrelated\ersity complexity is caused by age or business requirements-complexity We obtained similar results when measuring diversity-complexity in terms of the number of DBMS used by an application. The only significant difference at the .01 level was in the age of applications: The group of applications with more than one DBMS was also older on average than those applications with only one DBMS. This supports proposition P1.2, which states that the older the applications get, the more diverse they become \(in terms of DBMS\At a lower significance level \(.05 we see a significant difference in terms of the amount of user departments involved for those applications with one DBMS versus those with more than one DBMS: the former group was found to involve fewer user departments than the latter. This supports P2.2 which asserts that the more complex the business requirements are, the more diverse the applications become \(in terms of DBMS\. However, we do not find support for this proposition when looking at the number of products or processes covered by the application, though. See Table 5 for the detailed results of the analyses  Causes of deviation-related AA complexity A Mann-Whitney U Test \(Table 6\ealed significant differences in terms of the products covered and at a lower significance level in terms of age and processes covered between those applications that do not deviate from the standard OS and those that do. Nonstandard applications cover more products and also more processes \(median: 1 vs. 2\wever, standardcompliant applications at this firm are slightly older median: 3.2 years\ than the non-compliant applications \(median: 2.2 years\hese results lend support to proposition P2.3, which states that the higher the complexity of the business requirements in terms of product and process coverage\is, the more deviation from the standard \(in terms OS\s found in applications. Interestingly, the results also indicate that the relation between age and deviation from standard technology \(in terms of OS proposition P1.3\tradicts the proposition: older applications are more standard compliant Measuring the deviation of an application from the standard DBMS provides a somewhat different picture. A Mann-Whitney U test \(Table 6\ealed significant differences only for the number of user departments involved in the application \(at .05 level of significance\ain we find a surprising result in that the standard-conformant applications involve more user-departments \(median: 3\han the non-compliant ones \(median: 1 department; overall median: 2 departments\. We do not find support for the propositions stating that an increase in either age P1.3\siness requirements complexity \(P2.3 causes an increase in applications' deviation from standard technology \(in terms of DBMS\e see indications for an inverse relationship between the number of user departments involved and the deviation of applications from standards in terms of DBMS technology  Causes of overlap-/redundancy-related AA complexity A Kruskal-Wallis \(Table 7\ealed significant differences in terms of the number of user departments involved for those applications that have a low to medium overlap and those with a significant overlap \(the first two groups involve one user department and the last group involved 2.5 user Proceedings of the 42nd Hawaii International Conference on System Sciences - 2009 11 


departments on average\ignificant differences were found regarding the age of the applications. The variables for the coverage of the products and processes were not included in this test because the overlap was computed using these two variables implying that there is a significant relation between the respective variables\his lends some support to proposition P2.4 stating that involvement of more users leads to greater overlap of applications. The proposition that older applications also exhibit a higher degree of overlap was not supported \(P1.4  A.2. Results from analyzing impacts of AA complexity  Impacts of interdependency-related AA complexity A Kruskal-Wallis test \(Table 4\ealed a statistically significant difference in operations cost as well as maintenance cost across the three different interdependency-groups of applications. The more interdependent group \(i.e. applications with 3-7 or with 8 or more interfaces\igher median of operations \(Md=119,000 and 363,000 EUR respectively\ and maintenance costs \(Md=326,000 and 506,000 EUR respectively\ than the less interdependent group \(fewer than 3 interfaces applications \(Md=52,000 EUR operations costs and 64,000 EUR maintenance costs\. This supports the proposition \(P3.1\ that more interdependent applications also incur higher IT \(operations and maintenance\ts  Impacts of diversity-related AA complexity   Regarding OS-related diversity, a Mann-Whitney U test \(Table 5\howed no significant difference between the operations costs of more \(Md=93,890 n=105\d less diverse applications \(Md=131,540 n=27\09.5, z=-1.174, p=.24. The same holds for maintenance costs \(Md=166,400; n=121 vs Md=116,900; n =31\782, z=-.43; p=.668 To measure DBMS-related diversity, a MannWhitney U test was conducted \(Table 5\d revealed no significance difference in operations costs of more Md=129,985; n=85\d less diverse applications Md=154,777; n=16\5, z=-.237, p=.813. The same holds for maintenance costs \(Md=210,500 n=98 vs. Md=245,700; n=19\36, z=-.704 p=.481. Hence, the proposition \(P3.2\ that diversityrelated AA complexity leads to higher IT costs is not supported  Impacts of deviation-related AA complexity   Regarding deviation from the standard OS, a MannWhitney U test \(Table 6\revealed no significant difference between the maintenance costs and operations costs for standard-compliant \(Md=83,581 n=94 for operations cost and Md=148,300; n=113 for maintenance cost\nd non-compliant applications Md=180,147; n=38 for operations cost and Md=166,400; n=39 for maintenance cost z=-1.921, p=.055 for operations cost and U=2116 z=-.371, p=.711 for maintenance cost Concerning deviation from the standard DBMS, a Mann-Whitney U test \(Table 6\ealed a significant difference between maintenance costs for standardcompliant \(Md=373,100; n=59\d non-standardcompliant applications \(Md=170,200; n=58 U=1303, z=-2.231, p=.026. It is remarkable that the non-compliant applications had lower maintenance costs than the compliant applications. The difference between operations costs for compliant Md=109,978; n=51\d non-compliant applications Md=180,147; n=50\s not significant, U=1196.5 z=-.533, p=.594 Thus, the proposition \(P3.3\at application that deviate from technology standards incur higher IT costs is not supported. In contrast, for DBMSstandard deviation, we observed significantly lower maintenance cost for non-compliant than for compliant applications  Impacts of overlap/redundancy-related AA complexity a Kruskal-Wallis test \(Table 7\ showed significant differences in operations costs across the applications with a low \(less than 34 overlaps Md=90,442; n=37\edium \(35-79 overlaps Md=55,770; n=56\ and high level of overlap/redundancy \(more than 80 overlaps Md=129,985; n=61 6.862, p=.032. It is striking to see that the applications with medium overlaps have a lower median operations cost than those with a low or high-level of overlap, implying a non-linear U-shape relation between overlap and operations cost. Interestingly, the same holds true for maintenance cost. Applications with a low degree of overlap exhibited a median maintenance cost of 96,600 \(n=59\, those with a medium level of overlap incurred a median of 81,300 \(n=58\d highly overlapping applications a median of 248,700 \(n=67 9.791, p=.007. Hence, the proposition \(P3.4\at applications with a greater degree of overlap also exhibit higher IT costs is not supported  Proceedings of the 42nd Hawaii International Conference on System Sciences - 2009 12 


Interdependency Number of interfaces \(gp3_y4_sum_intf  2 22 2 22 Df 047 000 000 016 000 000 Asymp. Sig 6.134 22.298 20.875 8.331 17.018 18.917 N Median 46 45 43 46 27 37 41 41 41 41 36 38 2 intf 8 intf 1.0000 2.2000 1.0000 1.0000 52.3020 64.4000 2.0000 7.8000 4.0000 2.0000 363.9885 506.3500 2 intf 8 intf Mean rank 55.89 47.03 44.13 56.13 33.67 37.77 2 intf 73.46 83.40 76.61 76.21 60.89 68.89 8 intf 40 39 33 40 30 34 3 7 intf 1.0000 3.2000 2.0000 1.0000 119.3940 326.2000 3 7 intf 63.63 59.97 56.50 60.54 42.33 58.22 3 7 intf  Business requirements Causes of complexity Impacts of complexity  No. of IB products covered y24_#_IB_ bankprod Application age y14_age No. of user departments y19_#_ user_dpts No. of IB process covered \(y26_ IB_bankproc Operations cost \(y36_ ops_cost Maintenance cost \(y37_ Maint_cost 2  Table 4: Results of Kruskal-Wallis test for causes and impacts of interdependency-related AA complexity    Diversity Number of OS/DBMS used by an application Operating systems \(gp2_y7a_OS DBMS \(gp2_y8a_DBMS 2,726.500 18,302.500 1.503 133 1,087.500 1,318.500 1.362 173 3,308.000 902 367 543.000 7,446.000 3.925 000 2,642.000 2,536.000 3,202.000 855 392 757.500 7,198.500 2.187 029 2,884.500 18,460.500 965 335 1,216.500 1,447.500 583 560 1,209.500 6,774.500 1,174 240 654.500 790.500 237 813 1,782.000 9,163.000 430 668 836.000 5,687.000 704 481 Wilcoxon W Z Asymp. Sig N Median Mean rank Mann-Whitney U Wilcoxon W Z Asymp. Sig Mann-Whitney U 21 1.0000 125 1.0000 75.30 62.79 20 8.0500 117 2.2000 63.64 100.35 19 3.0000 113 1.0000 63.70 83.13 21 1.0000 125 1.0000 74.27 68.93 16 154.7770 85 129.9850 51.30 49.41 19 245.7000 98 210.5000 58.03 64.00 N Median 1 DBMS 2 DBMS 1 DBMS 2 DBMS Mean rank 1 DBMS 2 DBMS Data not shown as no significance found  Business requirements Causes of complexity Impacts of complexity  No. of IB products covered \(y24_#_ IB_bankprod Application age y14_age No. of user departments y19_#_user_dpts No. of IB process covered \(y26_#_ IB_bankproc Operations cost \(y36_ ops_cost Maintenance cost \(y37_ Maint_cost  Table 5: Results of Mann-Whitney test for causes and impacts of diversity-related AA complexity  Proceedings of the 42nd Hawaii International Conference on System Sciences - 2009 13 


 Deviation degree of deviation from standard OS/DBMS Operating systems \(gp2_y7b_OS_Dev DBMS \(gp2_y8b_DBMS_Dev 2,780.000 16,146.000 3.681 000 163 49 1.0000 2.0000 99.06 131.27 2,611.000 5,312.000 227 820 73 1.0000 73 1.0000 72.77 74.23 3,970.500 2.107 035 151 47 3.2000 2.2000 104.18 84.48 2,102.000 4,587.000 1.074 283 70 2.2000 67 3.5000 72.63 2,842.500 65.53 2,902.000 4,030.000 1.509 131 143 47 2.0000 1.0000 98.71 85.74 1,551.500 3,829.500 3.041 002 67 1.0000 65 3.0000 76.13 57.16 3,103.500 16,469.500 2.698 007 163 49 1.0000 2.0000 101.04 124.66 2,610.000 5,311.000 232 816 73 1.0000 73 1.0000 72.75 74.25 1,404.000 5,869.000 1.921 055 94 38 83.5815 180.1470 62.44 76.55 1,196.500 2,522.500 533 594 50 180.1470 51 109.9780 49.46 52.57 2,116.000 8,557.000 371 711 113 39 148.3000 166.4000 75.73 78.74 1,303.000 3,014.000 2.231 026 58 170.2000 59 373.1000 65.92 51.97  Wilcoxon W Z Asymp. Sig N Median No deviation \(1.0 Deviation 1.1 No deviation \(1.0 Deviation 1.1 Mean rank Mann-Whitney U No deviation \(1.0 Deviation 1.1 Wilcoxon W Z Asymp. Sig N Median No deviation \(1.0 Deviation \(>1.0 No deviation \(1.0 Deviation \(>1.0 Mean rank Mann-Whitney U No deviation \(1.0 Deviation \(>1.0  Business requirements Causes of complexity Impacts of complexity  No. of IB products covered \(y24_#_ IB_bankprod Application age y14_age No. of user departments y19_#_user_dpts No. of IB process covered \(y26_#_ IB_bankproc Operations cost \(y36_ ops_cost Maintenance cost \(y37_ Maint_cost  Table 6: Results of Mann-Whitney test for cause s and impacts of deviation-related AA complexity  Overlap/redundancy \(gp3_overlap_count 22 22 Df 216 001 032 007 Asymp. Sig 3.066 13.139 6.862 9.791 2 N Median 90 81 37 59 79 78 61 67 34 80 2.2000 1.0000 90.4420 96.6000 2.6000 2.5000 129.9850 248.7000 34 80 Mean rank 129.29 113.80 82.76 87.25 34 137.18 144.50 85.66 108.10 80 86 85 56 58 35 79 2.2000 1.0000 55.7705 81.3000 35 79 118.22 110.61 65.14 79.82 35 79  Not applicable Not applicable Business requirements Causes of complexity Impacts of complexity  No. of IB products covered \(y24_ _IB_bankprod Application age y14_age No. of user departments y19_#_ user_dpts No. of IB process covered \(y26_ _IB_bankproc Operations cost \(y36_ ops_cost Maintenance cost \(y37_ Maint_cost  Table 7: Results of Kruskal-Wallis test for causes and impacts of overlap-/redundancy-related AA complexity Proceedings of the 42nd Hawaii International Conference on System Sciences - 2009 14 


  15 R EFERENCES    http://www.w3.org/XML/Schema   eb Orchestration with BPEL\224 http://www.idealliance.org/pa pers/dx_xml03 papers/0406-01/04-06-01.html  Hi bernat e hom e page www.hibernate.org   Al l a rd, Dan and Hut c herson, Joe, \223C om m uni cat i ons Across Complex Space Networks\224, IEEE Aerospace Conference, March 1-8, 2008  W e b Servi ce Defi ni t i on Language http://www.w3.org/TR/wsdl   B a uer, C h ri st i a n and Ki ng Javi n Java Persi s t e nce for Hibernate, New York: Manning Publications, 2007 7] \223Software Agents An Overview\224 http://www.sce.carleton.ca/netm anage/docs/AgentsOverview ao.html  e thodology.org  http://www.riaspot.com artic les/entry/What-is-Ajax  http://www.json.org 11 h ttp to m cat.ap ach e.o r g   12] http://java.sun com/products/servlet  http://www.w3.org/Sty le/CSS    B IOGRAPHY  Dan Allard has worked as a software engineer at the Jet Propulsion Laboratory for the past 17 years.   He currently leads the development of core JPL accountability systems applications and infrastructure Other recent work includes the development of a message-based ground data system for the Mars Science Laboratory as well as research and development of ontologybased distributed communications     Dr. Charles D \(Chad\ards, Jr received his A.B degree in Physics from Princeton University in 1979 and his Ph.D. in Physics from the Calif ornia Institute of Technology in 1984.  Since then he has worked at NASA\222s Jet Propulsion Laboratory, where he currently serves as Manager of the Mars Network Office and as Chief Telecommunications Engineer for the Mars Exploration Program, leading the development of a dedicated orbiting infrastructure at Mars providing essential telecommunications and navi gation capabilities in support of Mars exploration.  Prior to that he managed the Telecommunications and Mission Operations Technology Office, overseeing a broad program of research and technology development in support of NASA\222s unique capabilities in deep space communications and mission operations.  Earlier in his career, Dr. Edwards worked in the Tracking Systems and Applications section at JPL where he carried out research on novel new radio tracking techniques in support of deep space navigation, planetary science, and radio astronomy  


  16  


Thank you Questions 


 18  Astronautical Congress Valencia, 2006 27  Bu reau  In tern atio n a l d e s Po ids et Mesures. \(2 008  August\SI Base Units. [On http://www.bipm.org/en/si/base_units   B IOGRAPHY  Author, Karl Strauss, has been employed by the Jet Propulsion Laboratory for over 22 years.  He has been in the Avionics Section from day One.  He is considered JPL\222s memory technology expert with projects ranging from hand-woven core memory \(for another employer\o high capacity solid state designs.  He managed the development of NASA\222s first Solid State Recorder, a DRAM-based 2 Gb design currently in use by the Cassini mission to Satu rn and the Chandra X-Ray observatory in Earth Orbit.  Karl was the founder, and seven-time chair of the IEEE NonVolatile Memory Technology Symposium, NVMTS, deciding that the various symposia conducted until then were too focused on one technology.  Karl is a Senior IEEE member and is active in the Nuclear and Plasma Scie nce Society, the Electron Device Society and the Aerospace Electronic Systems Society Karl is also an active member of SAE Karl thanks his wonderful wife of 28 years, Janet, for raising a spectacular family: three sons, Justin, Jeremy Jonathan.  Karl\222s passion is trains and is developing a model railroad based upon a four-day rail journey across Australia\222s Northern Outback   


 19 Bollobs, B. 2001. Random Graphs. Cambridge University Press; 2nd edition. 500pp  Cawley, G. C., B. L. C. Talbot, G. J. Janacek, and M. W Peck. 2006. Sparse Bayesian Ke rnel Survival Analysis for Modeling the Growth Domain of Microbial Pathogens  Chiang C. L. 1960. A stochastic study of life tables and its applications: I. Probability distribution of the biometric functions. Biometrics, 16:618-635  Cox,  D. R. 1972. Regression models and life tables J. R Stat. Soc. Ser. B 34:184-220  Cox, D. R. 1975.   Partial likelihood Biometrika 62:269276  Cox, D. R. & D. Oakes. 1984 Analysis of Survival Data  Chapman & Hall. London  Cressie, N. A. 1993 Statistics for Spatial Data John Wiley Sons. 900pp  Duchesne, T. 2005. Regression models for reliability given the usage accumulation history. In "Modern Statistical and Mathematical Methods in Reliability". Edited by A. Wilson N. Limnios, S. Kelly-McNulty Y. Armijo. pp.29-40. World Scientific, New Jersey  Eleuteri, A., R. Tagliaferri, L. Milano, G. Sansone, D D'Agostino, S. De Placido,  M. Laurentiis. 2003.  Survival analysis and neural networks. Proceedings of the International Joint Conference on Neural Networks, Vol. 4 20-24 July 2003 Page\(s\:2631 - 2636  Ellison, E., L. Linger, and M Longstaff. 1997.  Survivable Network Systems: An Emerging Discipline, Carnegie Mellon, SEI, Technical Report CMU/SEI-97-TR-013, 1997  Fleming, T. R. & D. P. Harrington. 1991. Counting process and survival analysis. John Wiley & Sons. 429pp  Graver, J. and M. Sobel 2005. You may rely on the Reliability Polynomial for much more than you might think Communications in Statistics: Theory and Methods  34\(6\1411-1422  Graves, T. and M. Hamada. 2005. Bayesian methods for assessing system reliability: models and computation. In Modern Statistical and Mathematical Methods in Reliability". Edited by A. Wilson, et al. pp.41-53  Grimmett, G. 2006 The Random-Cluster Model Springer  Grimmett, G. 1999 Percolation Springer  Hougaard, P. 2000. Analysis of Multivariate Survival Data Springer. 560pp  Ibrahim, J. G., M. H. Chen and D. Sinha. 2005. Bayesian Survival Analysis.  Springer. 481pp  Jin Z. 2005. Non-proportional semi-parametric regression models for censored data. In "Modern Statistical and Mathematical Methods in Reliability". Edited by A. Wilson N. Limnios, S. Kelly-McNulty, Y. Armijo. pp.279-292 World Scientific  Kalbfleisch, J. D. & R. L. Prentice. 1980 The Statistical Analysis of Failure Time Data John Wiley & Sons.  New York. 1980  Kalbfleisch, J. D. &  R. L. Prentice, 2002. The Statistical Analysis of Failure Time Data.  Wiley-InterScience, 2nd ed 462pp  Lisboa, P. J. G. and H. Wong. 2001. Are neural networks best used to help logistic regression? Proceedings of International Joint Conference on Neural Networks, IJCNN 01. Volume 4, 15-19,  July 2001. Page\(s\:2472 - 2477 vol.4  Kauffman, R. J. and B. Wang. 2002. Duration in the Digital Economy. Proceedings of th e 36th Hawaii International Conference on System Sciences \(HICSS03\ Jan 2003  Kaplan, E. L. & P.  Meier.  1958.  Nonparametric estimation from incomplete observations J. Amer. Statist. Assoc  53:457-481  Klein, J. P. and P. K. Goel 1992. Survival Analysis: State of the Art.  Kluwer Academic Publishes. 450pp  Klein, J. P. and  M. L Moeschberger. 20 03. Survival analysis techniques for ce nsored and truncated data Springer  Krings, A. and Z. S. Ma. 2006.  "Fault-Models in Wireless Communication: Towards Survivable Ad Hoc Networks MILCOM 2006, Military Communications Conference, 2325 October, 7 pages, 2006  Krings, A. W. 2008.  Survivable Systems.  in Information Assurance: Dependability and Security in Networked Systems Yi Qian, James Joshi, David Tipper, and Prashant Krishnamurthy, Morgan Kaufmann Publishers. \(in press  Lawless, J. F. 1982. Statistical models and methods for lifetime data.  John Wiley & Sons. 579pp  Lawless, J. F. 2003. Statistical models and methods for lifetime data.  John Wiley & Sons. 2nd ed. 630pp  Li, M. and P. Vitanyi. 1997. Introduction to  Kolmogorov Complexity and Its Applications. 2nd ed, Springer  Ma, Z. S. 1997.  Survival analysis and demography of Russian wheat aphid populations.  Ph.D dissertation, 307pp University of Idaho Moscow, Idaho, USA 


 20 Ma, Z. S., and E. J. Bechinski. 2008.  Developmental and Phenological Modeling of Russian Wheat Aphid Annals of Entomological Soc. Am In press  Ma, Z. S. and A. W. Krings. 2008a. The Competing Risks Analysis Approach to Reliability Survivability, and Prognostics and Health Management.  The 2008 IEEEAIAA AeroSpace Conference. BigSky, Montana, March 18, 2008. \(In Press, in the same volume  Ma, Z. S. and A. W. Krings 2008b. Multivariate Survival Analysis \(I\e Shared Frailty Approaches to Reliability and Dependence Modeling. The 2008 IEEE-AIAA AeroSpace Conference. BigSky Montana, March 1-8, 2008 In Press, in the same volume  Ma, Z. S. and A. W. Krings. 2008c. Multivariate Survival Analysis \(II\ Multi-State Models in Biomedicine and Engineering Reliability. 2008 IEEE International Conference on Biomedical Engineering and Informatics BMEI 2008\27th-30th, 2008 Accepted   Mani, R., J. Drew, A. Betz, P. Datta. 1999. Statistics and Data Mining Techniques for Lifetime Value Modeling ACM Conf. on Knowledge Discovery and Data Mining  Mazzuchi, T. A., R Soyer., and R. V Spring. 1989. The proportional hazards model in reliability. IEEE Proceedings of Annual Reliability and Maintainability Symposium pp.252-256  Meeker, W. Q. and L. A. Escobar. 1998. Statistical Methods for Reliability Data. Wiley-Interscience  Munson, J. C. 2003. Software Engineering Measurement Auerbach Publications  Nelson, W. 1969. Hazard plotting for incomplete failure data J. Qual. Tech 1:27-52  Nakagawa, T. 2006.  Shock and Damage Models in Reliability Theory. Springer  Osborn, B. 2005. Leveraging remote diagnostics data for predictive maintenance.   In "Modern Statistical and Mathematical Methods in Reliability". Edited by A. Wilson N. Limnios, S. Kelly-McNulty, Y. Armijo. pp. 353-363  Pena, E. A. and E. H. Slate. 2005. Dynamic modeling in reliability and survival analysis. In "Modern Statistical and Mathematical Methods in Reliability". Edited by A. Wilson N. Limnios, S. Kelly-McNulty, Y. Armijo. pp.55-71  Reineke, D. M., E. A. Pohl, and W. P. Murdock. 1998 Survival analysis and maintenance policies for a series system, with highly censore d data.  1998 Proceedings Annual Reliability and Maintainability Symposium. pp 182-188  Schabenberger, O. and C. A. Gotway. 2005. Statistical Methods for Spatial Data Analysis.  Chapman & Hall/CRC  Severini, T. A. 2000. Likelihood methods in statistics Oxford University Press  Shooman, M. L. 2002. Reliability of Computer Systems and Networks: Fault Tolerance, Analysis and Design. John Wiley and Sons. 551pp  Stillman, R. H. and M. S. Mack isack, B. Sharp, and C. Lee 1995. Case studies in survival analysis of overhead line components. IEE Conferen ce of the Reliability and Distribution Equipment. March 29-31, 1995. Conference Publication No. 406. pp210-215  Therneau, T. and P. Grambsch. 2000 Modeling Survival Data: Extending the Cox Model Springer  Wilson, A.  N. Limnios, S Kelly-McNulty, Y. Armijo 2005. Modern Statistical and Mathematical Methods in Reliability. World Scientific, New Jersey  Xie, M. 1991. Software Reliability Modeling. World Scientific Press    B IOGRAPHY   Zhanshan \(Sam\ Ma holds a Ph.D. in Entomology and is a Ph.D. candidate in Computer Science at the University of Idaho. He has published approximately 30 journal and 30 conference papers, mainly in the former field.  Prior to his recent return to academia, he worked as senior network/software engineers in software industry.  His current research interests include reliability and survivability of wireless sensor networks, fault tolerance survival analysis, evolutionary game theory, evolutionary computation and bioinformatics  Axel W. Krings is a professor of Computer Science at the University of Idaho.  He received his Ph.D. \(1993\ and M.S 1991\ degrees in Computer Science from the University of Nebraska - Lincoln, and his M.S. \(1982\ in Electrical Engineering from the FH-Aachen, Germany.  Dr. Krings has published extensively in the area of Computer Network Survivability, Security, Fault-Tolerance and Realtime Scheduling. In 2004/2005 he was a visiting professor at the Institut d'Informatique et Mathmatiques Appliques de Grenoble, at the Institut National Polytechnique de Grenoble, France.  His work has been funded by DoE/INL DoT/NIATT, DoD/OST and NIST 


