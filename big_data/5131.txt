   Searching and Clustering on Social Tagging Sites Ying Zhou School of Information Technologies The University of Sydney, Australia Email zhouy@it.usyd.edu.au   Abstract  Social Tagging Site has increasingly become a main avenue for people to share resources online. Users can use simple tools to publish everything from bookmarks to video clips on those sites. However, effective querying of resources in such sites is still a challenging question in industry and academic research. This paper reports a novel algorithm of presenting the web resources query result on the social tagging sites. It adopts a two step clustering approach to organize an 
d rank resources based on their relative similarities with each other. Initial term similarities are computed using user and tag information of the resource. The query results are then organized as a group of concepts represented by a few semantically related terms The resources that are related with each concept are rank with respect to the concept. In addition concepts are also ranked by representing terms and the number of resources associated Keywords Social Tagging, Asso ciation Rule Mining Clustering I  INTRODUCTION The Web 2.0 era brings along various tools that enable Internet users to publish all sort s of objects on the Web. It is very easy for any user with Internet connection to publish 
photos, videos and other non te xtual object on the web with the help of such tools. Once a photo or video is published users can make it either private or public. Public resources rely on description text to make them retrievable by other users.  Instead of providing a lengthy description, many users choose to tag their resource with a few keywords. The keywords based tagging activ ity has gained popularity in websites like flickr, citeULike youTube and many other sites The key feature contributing to its popularity is the uncontrolled vocabulary.  Users may choose any number of terms from any language to describe the object that becomes public or private resource on the we b. This feature, on the one 
hand, encourages people to upload and tag their objects; on the other hand, it presents lots of new challenges for the searching services. Such challe nges cannot be addressed by traditional information retrieval techniques for the following reasons.  First, the query target is usually a non-textual web resource.  This is different from a textual webpage containing complete or partial informati on of a particular query term Second, the textual information about the target is highly condensed and limited to, in ma ny cases, only a few terms Third, there is no explicit relationship such as hyperlink between resources that can be used for ranking purpose. The traditional relevance/popularity ranking algorithms do not work very well under these three constraints. Currently, many websites provide alternative 
ranking mechanisms such as rank by date or rank by subjective measures like interestedness  used in flickr. This paper pre sents a novel way of organizing the object search result on social tagging sites. It adopts a two step clustering approach to group and rank resources based on their relative similarities with each other. The query results are associated with a group of concepts represented by a few semantically related terms Resources are ranked by their similarities with respect to thos e concepts.  In particular, the paper makes the following contributions It uses the association rule mining algorithm to obtain an initial similarity measure betw een popular terms appearing in 
a result set. The association ru le based measure can effectively remove noises generated during the tagging process. Typical noises include relationship ge nerated by single user or nonstandard terms used by single user. The set of rules is used to establish a relation graph between terms It proposes a two step clustering algorithm to associate resources with related concepts. The algorithm first clusters the terms into semantically related concepts based on the initial similarity measures and term relation graph. It then filters resources into groups associated with particular concepts. Resources are also ranked inside each group It proposes new ways to measure resource-cluster similarity, to rank resources in a cluster and to rank clusters in 
a query result set The rest of the paper is organized as follows. Section 2 describes several important rela ted works. Section 3 describes the algorithm of obtaining initial similarity and the design of cluster based measure and the clustering algorithms.  We show the experiments and results in section 4. Section 5 concludes the paper II  RELATED WORK Fonseca et query  log t o build c oncept based on association rule mining technique Each query is mapped to an item and a set of consecutive queries issued by a same user in a small predefined time frame is mapped to a transaction  After applying standard association rule mining algorithm, a 
directed graph is built with each node representing a query and each edge representing a rule between a pair of queries Concepts are identified as the minimal cycles in the graph 2009 Fifth International Conference on Semantics, Knowledge and Grid 978-0-7695-3810-5/09 $26.00 © 2009 IEEE DOI 10.1109/SKG.2009.72 99 2009 Fifth International Conference on Semantics, Knowledge and Grid 978-0-7695-3810-5/09 $26.00 © 2009 IEEE DOI 10.1109/SKG.2009.72 99 


    Dong et nts a n  as sociation rule/clustering based approach to find concepts in a set of web services. The document is the parameter names of input/output functions of web service operations, such as  LocalTimeByZipCodeResult  The terms correspond to words in the parameter names, such as  Time  and  Zip  The problem can be seen as findi ng term relations in very short documents with no grammatical constraints, which is similar to folksonomy. It adopts the simple  occurrences as support   approach Nie et. Al an object ranking model PopRank to extend the popular PageRank algorithm to object level PopRank focuses on building relation between various types of objects and estimating th e popularity propagation factor from a predefined partial ranking list. The algorithm is implemented in an academic paper search engine Libra PopRank deals with a complex graph consisting of various objects and relationship. Such complexity adds valuable information for computing ranks. The need of a predefined partial ranking list makes PopRa nk less flexible and reduces its general applicability. On the contrary, our algorithm treats objects of various types as retrievable resources. The minimal requirement is that each resource should have some tags as description. Our algorithm tries to rank resources by examining shared tags among them. It does not require a predefined initial ranking. It can be applied to rank objects of different types as long as they are described by tags III  DESIGN Our ranking algorithm uses a two step approach. We first derive concepts from tags appear ing in the result space. Each concept is labeled by its highest ranking tags. All resources are then associated with the concepts and ranked in each cluster. Although tag clusters are mutually exclusive, one resource may appear in multiple clusters. Clusters are also ranked by its internal cohesion an d the number of resources it represents I  Tag Clustering In any social tagging system, a tag is defined as a word or a phrase used to describe a uniquely addressed resource on the Internet. The resource could be a webpage, an academic paper, a photo or a video clip. A resource may have more than one tag, for instance Australian Open and Melbourne to describe it. Such co-occurrence is an important indicator of possible semantic relationship be tween tags a ny  social tagging sites provide tag based query engine to facilitate resource query. The si mplest form of such engine would return all resources containing the query term As co-occurrence may happen for various reasons, it is a necessary but not sufficient condition on the existence of semantic relation. Our observation made on several sites shows that a pair of co-occurring tags usually has one of the following five relations Inclusive relationship For example Australia and Sydney  Expressing one concept in conjunction For example Social and Network  Synonyms, hypernyms and hyponyms For example cat  and gatto the Italian word for cat  Expressing different aspects of the resource For example AustralianOpen and 2009  Non-relevant There are tags assigne d purely for personal use such as toread or mystuff These tags almost occur uniformly in the tag space; they may co-occur with any other tags We consider the first three as valid and strong relations The fourth one may be valid but weak relation in certain cases. This is especially true when all tags involved are popular ones. For instance party and 2006 may happen to cooccur a lot even though the re lation is quite weak A good similarity measure stronger than co-occurrence should be able to identify and filter out the weak and nonrelevant relation. We propose using association rule to compute the relation between a tag pair. Each resource is considered as a transaction and tags used to describe the resource are considered as items Each association rule has two numbers support and confidence to describe the popularity and strength of a pa rticular rule. Following the traditional asocial rule mini ng approach n c ount  support as the number of co-occurrence in the whole transaction space. This equals the number of resources having all the tags in a rule. However in systems like Flickr or Youtube, it is possible and qu ite often for a user to use a similar set of tags over and over again to describe a collection of pictures or videos. There is hi gh possibility for any pair in that set to become a rule with co-occurrence support measure The rule set may include the fourth and fifth relations we described above. We propose using user count instead to measure the support of tag pairs.  Any user may assign a pair of tags multiple times to diff erent resources. The support of that pair is increased by 1 in that case  Confidence computed from user count support can offset the effect of general tags that may be associated with all sorts of other tags. It also provides a normalized measure on the strength of each rule We use confidence to measure the strength of tag relation Table 1 Comparing two approaches on support Candidate Rule Co-occurrence User Count  Supp Conf Supp Conf WashingtonDC  panthera 216 0.6 1 0.02 Bangkok 2004 80 0.75 1 0.06 Taronga zoo 34 0.92 26 0.9 Deutschland  Germany 28 0.97 1 1 0.92  Table 1 shows the outcome of the two approaches on a flickr data set. The co-occurre nce approach considers all tag pairs in the table as highly relevant. However, the first two pairs are weakly related. The high co-occurrence numbers are contributed by one user using the pair on hundreds of pictures The user count approach with appropriate thresholds can 100 100 


    easily filter these noises out. Spam and non-relevant tags such as toread  mystuff n also be filtered out Tags and their relations is then expressed in a graph. It is straight forward to generate th e tag relation graph from a set of association rules. The tag relation graph     W E N G consists of nodes N directed edges E and a weight matrix W Each node of the graph corresponds to a tag in an association rule If we have two tags p and q and an association rule q p  there is an edge from node p to node q in the graph. The weight of the edge W pq equals the confidence of the association rule We take the agglomerative hier archical clustering approach to organize tags \(nodes\nto cohesive clusters. The algorithm starts with N clusters each containing an individual node List 1 shows an algorithm CutAvg for tag clustering. It runs iteratively by merging the two clus ters that are closest to each other in each iteration until the stop condition is met Hierarchical clustering algorithms may use different stop conditions. We adopt the simple and straightforward similarity threshold approach that is, the algorithm will stop when the highest similarity computed between clusters in a current iteration is lower than a predefined threshold. To achieve this, we need to measure and compute the similarity of clusters List 1 Tag Graph Clustering Algorithm method CutAvg Collection clusters each node in its own cluster Cluster cx,cy the two clusters to be merged at a stage  maxSim 0 highest similarity so far  for each cluster pair c1, c2 in clusters  do   double similarity  calSimilarity  c1, c2    if  similarity  maxSim   maxSim  similarity  cx  c1  cy  c2     end if  end for  if  maxSim simThreshold  merge  cx, cy  merge the two clusters  end if  end method   The similarity between two nodes p and q equals W pq in the tag graph. Similarity between clusters is computed based on node similarity. Our aim is to develop a non-local measure for cluster similarity. In graph theory, all edges across two subcomponents \(clusters\re called “cut edges”, where “cut refers to the partition of these two clusters. Previous work on spectral graph partition ggests that the optimal result occur where the cut of two clusters is minimal, and the cohesion within each cluster is maximized. Intuitively, we may define the cut size of two possible clusters as the sum of weights of all cut edges between them.  At each iteration, the algorithm could always merge the two clusters with the maximum cut size. Cut size defined as such is a local measure. It only includes the edges across two clusters in the computation. It does not consider the size of each cluster or other edges in the clusters.  To make the measure non-local we propose to use the size of clusters to normalize the cut between them. The similarity of cluster A and B is thus defined as               B B A cut A B A cut B A Sim    1     where |A| represents the numb er of nodes in cluster A and cut\(A,B is the cut size of cluster A and B defined as B v A u uv W B A cut         2  II  Parameter Setting  In our algorithm, support and confidence thresholds are used to control the number of ta gs and relations in the tag graph. Some initial experiment results indicate that the major clusters and popular tags are always preserved for any threshold values in a reas onable range. We run a test on apple  query data with support varying from 5 to 20 and confidence varying from 0.5 to 0.8. The result shows that high support threshold only misses a few less frequent tags and concepts the clustering result is othe rwise quite similar with low support threshold case. High co nfidence value has a slightly bigger impact as it would  cut  the tag relation graph into many small pieces. The values we choose for the following experiment are: 5 \(users\ minimum support threshold, and 0.5 as minimum confidence threshold Similarity threshold as the guard for stop condition is another important parameter that may affect the final results Similarity threshold is bounded by confidence threshold Similarity value between any two nodes is in a range between  min_conf   T h e C u tAv g  sim i larity value obtaine d by formula \(1\n the ra Formula \(1\nsures that for any one node cluster, there will be another cluster with whom the similarity is larger than the confidence threshold. We use a simple example to illustrate this feature.  Suppose we are at an iteration with clusters a  b,c,d and e,f The definition of the tag graph guarantees that each node in the graph would have at least an edge with another node. Suppose a has an edge connecting with b The similarity between a and b,c,d would be 3  b a b a Conf Conf Regardless of the actual values of the confidence of rule b a  the calculated cluster similarity would always be greater than the confidence threshold. If the similarity threshold is set to equal the confidence threshold single node cluster a would eventually be merged with  b,c,d to become a big cluster Error! Reference source not found clearly illustrates such feature in some example datasets from queries tiger  apple  bridge and Australia The number of clusters grows rapidly when similarity threshold is greater than 0.5 \(the confidence threshold\. The observed increase consists largely of single node clusters. On the other side of 0.5 the number of clusters grows much slower with the increase of similarity threshold. This  knee  or turning point 101 101 


    of a curve is also considered as good choice of number of clusters 6 Hence we take the confidence threshold as similarity bound  Figure 1 Effects of Similarity Threshold III  Associating Resources with Concepts The tag clusters obtained can be viewed as semantically related concepts expressed as a set of tags. The next step is to associate the resources described by a set of tags in the result set with those concepts. There are two simple and intuitive observations we follow to dete rmine the membership and rank of a resource with respect to concepts. They are First, any resource whose tags overlap with a concept’s tag set should be considered as a member of that concept Second, the strength of the re lationship between a resource and a tag cluster concept depends on the portion of tags they share Table 2 Simple Example Data, As sociation Rules and Clusters Resource Tags r 1 t 1 t 2 t 3  r 2  t 3 t 4 t 5  r 3  t 5 t 6 t 7  r 4  t 1 t 2 t 4  r 5  t 1 t 2 t 5  r 6  t 6 t 7  r 7  t 1 t 3  r 8  t 5 t 6  2.a   Resources and Tags       The first observation deals with the membership problem while the second one deals with the rank of resources. Both are quite intuitive and easy to understand Table 2 shows a simple example of a set of resources and their tags. We assume each resource belongs to a different user and that user assigns all tags for a resource Under this assumption, the user count is the same as co-occurrence count. Table 2.a shows the resources and their tags. Table 2.b shows rules generated with support threshold set to 2 and confidence threshold set to 0.5 Table 2.c shows concept obtained using the clustering techniques described in section 3.2. It also shows the important tags in each cluster. We first examine a few typical pairs of resources where the concept membership and the rank are obvious. One good exam is the pair r 1 and r 3 They are fully represented by concept C 1 and C 2 respectively Moreover, r 1 s tags do not overlap with tags of all other concepts at all. r 3 has the same feature.  We can define a similarity function    C r Sim between a resource and a concept to calculate a similarity value in the Ideally we should have 1    1 1 C r Sim  0    2 1 C r Sim  0    1 2 C r Sim and 1    2 2 C r Sim  The second example contains the pair r 1 and r 7 both of which are clearly members of C 1 However, r 7 only contains a subset of the C 1 s tags. Intuitively, we should have       1 7 1 1 C r Sim C r Sim A less straight forward case is the pair  r 4 and r 7 each of which has two tags overlapping with the tags of concept C 1 While r 7 has all its tags included in C 1 tag set r 4 only has two third of them in it. The similarity measure should give       7 4 1 7 C r Sim C r Sim  Based on the above observation of pairs and orderings, we develop a naive object-cluster similarity metric as             C C r r C r C r Sim   3    Where   C r represents the number of overlapping tags between resource r and concept C  r represents the number of tags resource r has and C represents the number of tags a concept C has. For the above example, the simple measure will compute 3  2     9  4     1    1 7 1 4 1 1 C r Sim C r Sim C r Sim  which satisfies our observation. Several trial experiments with small data sets show that the simple metric performs well for concepts with only a few tags. However, for concepts containing a large number of tags, it is likely that most resources overlap with a small portion of the concept tags. In that case, the naïve similarity measure cannot avoid certain randomness in ordering. Several resources may end up with a same similarity measure even if they cover different portion of the concept tag set. For instance, in concept C 2 resource r 6 and r 8 would have the same similarity value as 2/3. Without other evidence, r 6 and r 8 can only be ranked randomly. Such randomness exists because the naive similarity metric treats all tags belonging to a concep t as equally representing the concept. Again, it is not a bi g issue in concepts with a few tags. Yet it is ineffective fo r general concepts with large number of tags. A more refined measure will first calculate the concept-tag weight and adjust the overlapping portion with Rule Confidence t 1 t 2  0.75 t 2 t 1  1 t 1 t 3  0.5 t 3 t 1  0.67 t 5 t 6  0.5 t 6 t 5  0.67 t 6 t 7  0.67 t 7 t 6  1 2.b Association rules Concept Tags C 1  t 1 t 2 t 3  C 2  t 5 t 6 t 7  2.c Clusters                     0 50 100 150 200 250 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 Similarity Threshod Number of Clusters   apple  tiger   australia  bridge  102 102 


    the respective weightings of tags. This ensures that a resource overlapping with important tags of a concept be ranked higher than a resource overlapping with less important ones. The concept-tag weight denoted as w\(t,C is defined as C t if Coup Inv cohesion C t if C t weight   0       4  C v v t W cohesion      5  C u u t W Coup Inv  2      6  The cohesion measures the strength of connectivity of a tag with other tags in the same concept, the Inv.Coup inverse coupling\easures the strength of connectivity of a tag with other tags not in the same concept. This tag-concept similarity measure is developed based on the classic TFIDF measure in IR lots of internal links should rank higher in this concept than another ta g with only a few internal links but many external ones. With the concept-tag weight information, the similarity between a resource and a concept is adjusted to  r t C t C r t r t w C t w C t w C r Sim               2     7    The resource-concept similarity value is also in the range  w\(t,r denotes the weight of tags in each resource. It is determined by its weight in the concept it joins. If a tag does not belong to any cluster, its resour ce-tag weight will be zero  C t C t C t w r t w  0           8  Once resources are associated and ranked in concepts, it is worthwhile to rank the concepts itself. Intuitively, concepts representing large number of resources in the result set should have higher rank. However, we should also evaluate the quality of such big concept. Concepts are ranked by its internal cohesion and the number of resources it represents Average tag weight in a concept is a simple way of measuring the quality of internal cohesion of a concept. Formally the ConceptRank is defined as   N N C C t w R c C t c         9  where N denotes the total number of resources in the result set and N C denotes the number of resources in concept C The first part of formula \(9\omputes the average tag weight in the concept. The second part normalizes the number of resources in the concept by total result number Table 3 shows the tag-concept weight, resour ce-concept similarity and ConceptRank values for the simple example in Table 2 The new metrics preserve most of the observed orders we described. However, there are a few exceptions. For instance resource r 4 is ranked higher in co ncept C1 than resource r 7  Such discrepancy is a result of applying tag weights. In this particular example t 2 has higher weight in C1 than t 3 has indicating that r 4 is better represented by C 1 than r 7 is.  In addition, the new metrics is able to precisely rank resources such as r 6  and r 8 in concept C 2  r 6 is ranked higher because it overlaps with more important tags in C 2  Table 3 Similarity measure C 1  C 2  weight\(t 1 C 1 2.92 weight\(t 2 C 1 1 75 weight\(t 3 C 1 1.17 weight\(t 5 C 2 1.17 weight\(t 6 C 2  2.84 weight\(t 7 C 2 1.67 Sim\(r 1 C 1 1.00 Sim\(r 2 C 1 0.10  Sim\(r 4 C 1   Sim\(r 5 C 1 0.64  Sim\(r 7 C 1 0.70 Sim\(r 2 C 2 0.10 Sim\(r 3 C 2 1 00 Sim\(r 5 C 2 0.0 4 Sim\(r 6 C 2  0.79 Sim\(r 8 C 2 0.71 ConceptRank = 1.22 ConceptRank = 1.83 IV  EXPERIMENT AND RESULTS  The proposed algorithms are evaluated on several data sets obtained from CiteULike www.citeulike.org  an online bibliography organize r. It allows users to save bibliographic information about published research papers online. Users can tag those papers with keywords. A paper can be retrieved through all tags collectively assigned by various users. We collected several data sets using query terms including algorithm”, “software”, “web” and so on  Table 4 shows the clustering results on the data set obtained by query term “web We only show the top concepts whose ConceptRank values are greater than 0.1. For each concept, we list the represe nting tags in decreasing order of their weights in the concept We also show the top 5 papers based on resource-concept simila rity values. The result clearly distinguishes several research areas related with keyword web”. The first and the third concepts are in the area of web information retrieval with differ ent focuses. The first concept has a focus on query log analysis and user behavior study while the third one represents more traditional approach based on hyperlink analysis. The second concept has a focus on semantic web and web service s research. The fourth has a focus on more recent research on web 2.0 and social web   103 103 


    Table 4 web” query re sult Concept Members R: 0.92 t: 20 r:96   search \(24.21\, query_log_analysis \(14.47\, queries\(14.47 web_search \(13.15\ \(12.81\, search_behaviour \(12.47  6 Searching the Web: the public and their queries \(0.79 Vox Populi: the public searching of the Web \(0.79  U.S. versus European web searching trends \(0.79  Analysis of a very large web search engine query log\(0.77  An analysis of web searching by E uropean AlltheWeb.com users \(0.72 R: 0.73 t: 9  r: 153  service \(8.21\, semantic \(6.01\ ,com position \(5.14\y\(4 coordination \(3\y \(2.73\, matching 2.22\, discovery \(1.71\, rdf \(1.6 Composition-oriented Service Discovery \(0.69 Automated Composition of Semantic Web Services into Executable Processes 0.69  A software framework for matchmaking base d on semantic web technology \(0.69 Combining RDF and OWL with SOAP for Semantic Web Services \(0.67  An ontology driven framework for data tr ansformation in scientif ic workflows 0.63 R: 0.28 t: 5  r: 92 information-retrieval \(3.0\, prodei \(1.67 1.0 SALSA: the stochastic approach for link-structure analysis 1 What is this page known for? Com puting Web page reputations \(0.92  Enhanced hypertext categoriz ation using hyperlinks \(0.92  Measuring index quality using random walks on the Web 0.92 Efficient crawling through URL ordering \(0.79 R: 0.17 t:7  r: 57  3.83 Eni \(3.33\ksonomies \(2 1\ \(1 Collaborative tagging as a tr ipartite network \(0.82 Social bookmarking in the enterprise \(0.71  Referral Web: Combining Social Networks and Collaborative Filtering \(0.61  The Tipping Point: How Little Things Can Make a Big Difference \(0.55 Collaborative thesaurus taggi ng the Wikipedia way \(0.53  Table 5 shows the clustering re sult on dataset obtained using query term algorithm”. This dataset overlaps partially  with the web dataset. They both have papers in the web information retrieval research area. Interestingly, because our algorithm dynamically clusters query results, the papers in the shared part are put into slightly different concepts with relations to the query and to ot her results. The first concept in algorithm result has similar focus with the third concept in “web” data set.  Both have   informationretrieval”, “web and “algorithm” as keywords. The complete sets of keywords are different which reflect slightly different focuses of the groups. The first concept in “algorithm” data set has “google” and “pagerank” as keywords The original PageRank paper by S.Brin and L Page is ranked fourth in that concept. This paper has a large number of tags assigned by different users which dilutes the focus and makes it ranked lower than a few other papers with less tags. The third concept in “web” data set does not include specific words like “google” or “pageRank” as its keywords and it focuses on general theme on link based web ranking. The Brin&Page paper belongs to the concept. It is not one of the top 5 results though. The rest of the concepts in “algorithm datasets are about gene analysis, graphic algorithm and social network analysis V  CONCLUSION This paper reported a novel algorithm for presenting the web resource search result on the social tagging sites. It adopts a two step clustering approach to organize and rank resources based on their relative similarities with each other Initial similarities are co mputed using user and tag information. The query results are then organized as a group of concepts represented by a few semantically related terms The resources that are related with each concept are rank within the concept. In additi on, concepts are also ranked by its representing terms and the number of resources they represent. We run experiment on data sets obtained from an online bibliography organizing sites allowing people to share their favorite academic papers. The results show that our algorithm can effectively disti nguish various research areas in query results and associate papers in those areas   104 104 


    Table 5 algorithm” result  Concept Members R: 0.44 t: 9  r: 64 5.41\ch \(5.04 information retrieval \(4.83\, web \(3.94 informationretrieval \(3.89 pagerank \(3.05\, information \(1 Inside PageRank \(0.88 The anatomy of a large scale hypertextual Web search engine \(0.84 Authoritative sources in a hyperlinked environment \(0.65  The PageRank Citation Ranking Bringing Order to the Web 0.57 Understanding Search Engines: Mathematic al Modeling and Text Retrieval \(Software Environments, Tools\on 0.48 R:0.34 t:9  r:55  ica \(11.2\, brain \(6.2 3.69\, fmri \(2 eog \(2\, erp \(2\, statistics  \(1.11 Recovering EEG brain signals: Artifact suppression with wavelet enhanced independent component analysis  0.92  Temporally constrained ICA: an application to artifact rejection in electromagnetic brain signal analysis. \(0.89 R:0.33 t:9  r:51  Microarray \(8.34\Expression \(5.49\gene _set_analysis \(4.74\, comparison \(2.50 functional_annotation \(4.58 gene_list_analysis \(1.43 Group testing for pathway analysis improves comp arability of different microarray data sets. \(0.90  GenePattern 2.0 0.85  Significance analysis of functional categorie s in gene expression studies: a structured permutation approach \(0.85 R:0.28 t:8  r: 74 social_networks \(4.77\-net works \(3.77\etworks \(3.70 2.55 1 Finding community structure in very large networks 0.77 Finding and evaluating community structur e in networks 0.71 Fast algorithm for detecting community structure in networks 0.62 The Small World Phenomenon: An Algorithmic Perspective 0.62 A measure of betweenness centrality based on random walks 0.60 R: 0.22 t: 6  r: 44  3.5\ank \(2\, graph \(1.88 Ordering by weighted number of wins gi ves a good ranking for weighted tournaments 1.0  Ranking Tournaments \(1.0  Aggregating inconsistent information ranking and clustering \(0.75  A Min-Max Theorem on Feedback Vertex Sets \(0.71 A CKNOWLEDGMENT  This research is supported by MSRA ISAR Research Grant REFERENCE 1  Agrawal, R., Imieli ski, T., and Swami, A., Mining association rules between sets of items in large databases. In Proceedings of the 1993 ACM SIGMOD Washington, D.C., USA 2  Cai, D., et al. Hierarchical clustering of WWW image search results using visual, textu al and link information. In Proceedings of the 12th annual ACM international conference on Multimedia New York, NY, USA, 2004\ 952-959 3  Ding, C., et al. A minmax cut algorithm for graph partitioning and data clustering. In Proceedings of IEEE Internal Conference on. Data Mining San Jose, CA, USA, 2001\7-114 4  Dong, X., et al. Similarity search for web services. In Proceedings of the 30th VLDB Conference Toronto, Canada 2004 5  Fonseca, B. M., et al. Concept-based interactive query expansion. In Proceedings of the 14th ACM international Conference on information and Knowledge Management Bremen, Germany, 2005\. CIKM '05. ACM Press, 696-703 6  Nie, Z., et al., Object-level ranking: bringing order to Web objects, in Proceedings of the 14th international conference on World Wide Web. 2005, ACM Press: Chiba, Japan 7  Qiu, Y. and Frei, H. 1993. Concept based query expansion. In Proceedings of the 16th Ann ual international ACM SIGIR Conference on Research and Development in information Retrifeval Pittsburgh, PA, USA, 1993\93., 160-169 8  Salton, G., Wong, A. and Yang C.S., A vector space model for automatic indexing Communications of the ACM Vol. 18, No 11 \(November 1975 9  Sanderson, M. and Croft, B. Deriving concept hierarchies from text. In Proceedings of the Annual international 22nd ACM SIGIR Conference in Information Retrieval Berkeley, CA USA. 1999\ Press, 206 213 10 Tibshirani, R., Walther, G. and Hastie,T. Estimating the number of clusters in a dataset via the gap statistic. Journal of the Royal Statistical Society: Series B \(Statistical methodology\. \(2001 63\(2  11 Xu, J. and Croft, W.B.  Query ex pansion using local and global document analysis. In Proceedings of the 19th annual international ACM SIGIR conference on Research and development in information retrieval Zurich, Switzerland 1996 11  105 105 


026\027\201\231\026\027\245\202\231\027\233\235\235\301<\027 255\233\210\256 023\027 252\031\021\031 031\020\031\022\034\017\026\027 f\231\021\027 226\037\037\023\032\023\017\021\022\027 231\030{\024\016\023\022\034\\\027 037\024\016\027 205\023\021\023\021{\027 231##\024\032\023\031\022\023\024\021\027 030\017#\027 023\021\027 251\031\016{\017\027 212\031\022\031 232\024\032\034\017\021\027 223\023 016\023\024\016\023\027 037\024\016\027 231##\024\032\023\031\022\023\024\021\027 030\017\027 205\023\021\023\021{\027 226\037\037\023\032\023\017\021\032\035\025\026\027 226!\016\024 231#\034\024  255\264\256 016\023#\034\021\031\021\027\202\016\023 222\222<\027 202 016\023\021{\017\016\246\303\017\016\030\031{\026\027\227\017\016\030\023\021\026\027\273\017\016\\\031\021\035\027\217\206\207\233\207\211<\027 255\233\301\256 031\\\031 031\\\031 205<\027 241\031 031 031\021\022\026\027=\031 031\021\022\027 031#\017\025\026\027 263\016\024\032\017\017\033\023\021{\027 024\037\027 022\034\017\027 206\233 022 027 303\251\212\227\027 201\024\021\037\017\016\017\021\032\017\026\027 273\024\017\022\034\031\030#\026\027\227<\027\031\021\033\027\303\031\021\027\033\017\021\027\227!##\032\034\017\026\027\232<\027 233\235\235\235<\027\231\027\263\016\023\024\016\023\027\303\017\016#!#\027\231\027 263\024#\022\017\016\023\024\016\023\027 023\030\022\017\016\023\021{\027 024\037\027 231##\024\032\023\031\022\023\024\021\027 030\017#<\027 253\021\027 263\016\024\032\017\017\033\023\021{<\027 024\037\027 022\034\017\027 233\235\235\235\026\027 231\201\205\027 202\253\273\205\240\212\027 261\024\016 034\017\023\224\031\033\017\034\026\027 f\231\030{\024\016\023\022\034\\#\027\037\024\016\027\231##\024\032\023\031\022\023\024\021\027=!\030\017\027\205\023\021\023\021{\027 023\026\027 202\034\031 022 027 255\302\256 022\023\\\023\224\017\033\027 231##\024\032\023\031\022\023\024\021\027=!\030\017#\234\027\202\032\034\017\\\017\026\027\231\030{\024\016\023\022\034\\#\026\027\031\021\033\027\303\023#!\031\030\023\224\031\022\023\024\021<\027\253\021\027 263\016\024\032\017\017\033\023\021{<\027 024\037\027 022\034\017\027 233\235\235\210\027 231\201\205\027 246\027 202\253\273\205\240\212\027 253\021\022\017\016\021\031\022\023\024\021\031\030\027 201\024\021\037\017\016\017\021\032\017\027\024\021\027\022\034\017\027\205\031\021\031{\017\\\017\021\022\027\024\037\027\212\031\022\031\026\027 273<\253<\027 261\017 034\024 205\031#\031\031 024\026\027 205\031#\031\037!\\\023\027 223\031{\023\036\031\016\031\026\027 311\202 031#\017\025\026\027\027\205\240\212\027 206\207\207\026\027\212\031\030\030\031#\026\027|\242\027 245\202\231<\027 255\233\222\256 030\017\027\231\030{\024\016\023\022\034\\#\027\037\024\016\027\016\017\254!\017\021\022\027\253\022\017\\\027\202\017\022\027 205\023\021\023\021{\025\026\027\202 202<\263\016\031 027 227\031\036\031\026\027 212\017\020\031\020\016\031\022\027 202\034\031\034\026\027 f|!\016 027 212\023#\032\024\020\017\016\023\021{\027 202\023{\021\023\037\023\032\031\021\022\027 263\031\022\022\017\016\021#<\027 205\031\032\034\023\021\017\027 251\017\031\016\021\023\021{\027 210\302\217\233\211\234\233 027\231\027\273\017\021\017\016\031\030\027\202!\016\020\017\035\027 031\021\033\027\201\024 003 003 003 003 003 003 003 003 003 003 003 003 003 003 027\264\222\206\246\264\264\264\026\027\241!\016\023\032\034\026\027\202\036\023\224\017\016\030\031\021\033\026\027\233\235\235\262<\027\027 027 255\301\256 031#\034\026\027 205<\202<\263\031\016\020\031\022\034\023\027 026\f\231\021\027 226\021\034\031\021\032\017\033\027 202\032\031\030\023\021{\027 231 263\016\017\033\017\017 027 024\021\027 017#\017\031\016\032\034\027 253##!\017#\027 023\021\027 212\031\022\031\027\205\023\021\023\021{\027\031\021\033\027\252\021\024\036\030\017\033{\017\027\212\023#\032\024\020\017\016\035\026\027 016\023#\034\021\031\021\027\202\016\023 024<\206\027\217\206\207\233\207\211\026\027 017\031\021\027 232\024!\016\021\031\030\027 024\037\027\202\032\023\017\021\022\023\037\023\032\027=\017#\017\031\016\032\034\026\027\253\202\202 035\031\\\031\026\027|<\027 233\235\235\210<\027 212\031\022\031\027 205\023\021\023\021{\027 023\021{\027 036\024\246\212\023\\\017\021#\023\024\021\031\030\027 240 026\027 245\030\016\023\032\034\027 273!\021\022\224\017\016\026\027 273\034\024\030\031\\\016\017\224\031\027 027 202\031\020\031#\017\016\017\026\027 226\033\036\031\016\033\027 240\\\023\017\032\023\021 245\033\024\\\027 237\031\023\032\034\016\024\017\021\026\027 f\231 017\017\033\246 030\023\017\033\027 227\024\024\030\017\031\021\027 027 231\030{\017 206\235\210<\027 231\231\231\253\027 263\016\017##\026\027 205\017\021\030\024\027\263\031\016 005\005 005\005 005\005 005\005 002\002 005\005 027\233\264\262\207\246\206\233\210\242\027\303\024\030<\222\235\027 016\031\025\026\027 233\235\302\235\026\027 227\031\021 026\027|\034\031\023\030\031\021\033 027 255\210\256 027 202\034\017\021\024\035\026\027 232\031\035\031\021\022\027 027 223\031\016\023#\022\031\026\027 202<\027 202!\033\031\016#\034\031\021\026\027 273\031!\016\031\020\027 227\034\031\030\024\022\023\031\026\027 205\031\035\031\021 005 003 201\034\016\023#\022\023\031\021\027\227\024\016{\017\030\022\026\027\f\202\023 024  027 017\032\034\021\023\254!\017\027 037\024\016\027 231##\024\032\023\031\022\023\024\021\027 030\017\027 205\023\021\023\021{\027 227\031#\017\033\027 024\021\027 031\021\027 231\016\022\023\037\023\032\023\031\030\027 251\023\037\017\027 231\030{\024\016\023\022\034\\\311\027 207\246\301\210\235\262\246\222\207\222\206\246\242\274\207\301\027 027 206\207\207\301\027 253\226\226\226\027 212\240\253\027\233\207<\233\233\207\235\274\273\016\201<\206\207\207\301<\233\207\222<\217\206\207\207\301\211\027 255\233\264\256 024\246\032\034\031\021{\023\021{\027 303\017\016\022\023\032\031\030\027\205\023\021\023\021{\027\024\037\027\251\031\016{\017\027\212\031\022\031 027\233\222\246\206\222 027 255\235\256 206\262\301\246\206\210\264<\027 027 222 \003 003 003 005 002 003 003 003 003 004 002 005 003 003 005 003 005 005 004 007 005 003 003 003 002 005 003 002 002 003 003 005 005 007 005 004 003 004 004 005 007 003 005 005 003 005 005 004 004 030\017#\025\026\027 202\253\273\205\240\212\027 233\235\235\210\026\027\205\024\021\022\016\017\031\030\026\027\201\031\021\021\031\033\031 027 027 027 027 027 027 027 027 027 027 027 027 027 027 027 027 027 027 027 027 027 027 027 027 027 027 027 027 027 027 027 027 027 027 255\233\206\256 017\016\027\222<\027 255\233\207\256 017#\034\027\231{\031\036\031\030\026\027\f\205\023\021\023\021{\027\273\017\021\017\016\031\030\023\224\017\033\027 231##\024\032\023\031\022\023\024\021\027 030\017#\025\026\027 016\023\021{\017\016\026\027 231\\#\022\017\016\033\031\\\026\027 017\022\034\017\016\030\031\021\033#\027 217\206\207\207\301\211<\027 255\233\262\256 017\036\027 311\231\030{\024\016\023\022\034\\#\027\037\024\016\027\031#\022\027\212\023#\032\024\020\017\016\035\027\024\037\027\231##\024\032\023\031\022\023\024\021\027=!\030\017#\311<\027\263\016\024\032<\027 222\016\033\027 253\021\022<\027 201\024\021\037<\027 024\021\027 252\021\024\036\030\017\033{\017\027 212\023#\032\024\020\017\016\035\027 031\021\033\027 212\031\022\031\026\027 205\023\021\023\021{\027 217\252\212\212^\235\301\026\027 017\036 024\016\022\027 227\017\031\032\034\026\027 201\231\211\026\027 206\302\222 031\016\023#\024\021\025\026\027\231\201\205\027\202\253\273\252\212\212\027\232!\030\035\027\206\207\207\207<\027 255\233\233\256 023\026\027 202<\027 263\031\016\022\034\031#\031\016\031\022\034\035\026\027 205<\027 240{\023\034\031\016\031\026\027 031\021\033\027 261<\027 251\023<\027 033\031\026\027 260\027 205\024\016\023\\\024\022\024\026\027 237<\260\027 205\024\016\023#\034\023\022\031\026\027 202<\260\027 031\021\033\027 024 031\021\022\026\027=\031 031 205<\223<\205\031\016{\031\034\021\035\027 031\021\033\027 231<\231<\205\023\022\036\031\030\035\026\027 f\031#\022\027 231\030{\024\016\023\022\034\\\027 037\024\016\027 205\023\021\023\021{\027 231##\023\032\023\031\022\023\024\021\027 030\017#\025\026\027 231\253\205\251\027 207\262\027 201\024\021\037\017\016\017\021\032\017\026\027 201\031\023\016\024\026\027 226{\035 016\024\032\017\017\033\023\021{\027 024\037\027 206\233\022\034\027 303\251\212\227\027 201\024\021\037\017\016\017\021\032\017\026\027 241!\016\023\032\034\026\027\202\036\023\224\017\016\030\031\021\033\026\027\233\235\235\262 027 255\262\256 002 003 017#\034\027\231{\016\031\036\031\030\026\027\205\023\021\023\021{\027\270!\031\021\035\023\022\031\022\023\020\017\027 f\231##\024\032\023\031\022\023\024\021\027 030\017#\027 023\021\027 251\031\016{\017\027 017\030\031\022\023\024\021\031\030\027 031 


              


   


                        





