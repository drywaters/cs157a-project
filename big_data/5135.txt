Evolutionary Computational Methods for the Design of Spectral Instruments Richard J Terrile Seungwon Lee Giovanna Tinetti Wolfgang Fink Paul von Allmen and Terrance L Huntsberger Jet Propulsion Laboratory European Space Agency 4800 Oak Grove Drive University College London Pasadena CA 91109 Gower Street London WC 1E6BT UK 818 354-6158 44 0 rich.terrilegjpl.nasa.gov g.tinettigucl.ac.uk Abstract We have developed a technique based on Evolutionary Computational Methods ECM that allows for the automated optimization of complex computationally modeled systems We have demonstrated that complex engineering and 
science models can be automatically inverted by incorporating them into evolutionary frameworks and that these inversions have advantages over conventional searches by not requiring expert starting guesses designs and by running on large cluster computers with less overall computational time than conventional approaches We have applied these techniques to the automated retrieval of atmospheric and surface spectral signatures from Earthshine observational data We have demonstrated that in addition to automated spectral retrieval ECM can also be used to evaluate the discriminability 
of scientific results as a function of requirements placed on the spectral model An important application of this technique is for the optimization of design parameters for spectral instruments 12 TABLE OF CONTENTS 1 INTRODUCTION 1 2 EARTHSHINE SPECTRAL DATA 2 3 TECHNICAL APPROACH AND METHODOLOGY 3 4 ECM SPECTRAL RETRIEVAL STUDIES 4 5 RESULTS 5 6 DISCUSSION 6 7 CONCLUSIONS 6 ACKNOWLEDGEMENTS 6 REFERENCES  7 BIOGRAPHY  8 
1 INTRODUCTION We have developed a technique based on Evolutionary Computational Methods ECM that allows for the automated optimization of complex computationally modeled systems An important application of this technique is for the optimization of design parameters for spectral instruments Evolutionary computation is a method that operates on a population of existing computationalbased engineering models or simulators and competes them using biologically inspired genetic operators on large parallel cluster computers We have 
demonstrated that complex engineering and science models can be automatically inverted by incorporating them into evolutionary frameworks and that these inversions have advantages over conventional searches by not requiring expert starting guesses designs and by running on large cluster computers with less overall computational time than conventional approaches 1,2,3 The result is the ability to automatically find design optimizations and trades and thereby greatly amplify the role of the system engineer ECM was originally developed for the automated retrieval of 
spectral data 4,5 In this application we randomly vary spectral input components and solve for a synthetic spectral fit to real data We have found that when actual observational parameters are used as inputs we get a very accurate fit to the data However the ECM technique also allows us to determine the range of input conditions that will also produce good fits to the data Plotting this range of solutions on a principal components diagram allows us to determine the 
degeneracy of solutions that have non-ground truth inputs yet still fit the data This is a way of demonstrating the robustness of discriminability of the spectral technique We are now examining a secondary application of ECM where we can co-evolve the weighting of components of the spectral fitting e.g line centers continuum values spectral range signal to noise etc These parameters are tuned to maximize the spectral degeneracy in the principal components diagrams and thereby can be implemented 
to specify instrumental parameters and design requirements that optimize spectral discrimination In this paper we will describe the ECM application to the automated retrieval of atmospheric and surface spectral signatures from Earthshine observational data We will also show how the synthetic spectral model can be used to define instrument requirements to optimize the discrimination of spectral features 1 1 1-4244-1488-1/08/$25.00 
C 2008 IEEE 2 IEEEAC paper  
1 194 Version 6 Updated October 23 2007 1 


2 EARTHSHINE SPECTRAL DATA Earthshine as an Analogue for Extrasolar Planets The next generation of terrestrial planetary exploration missions NASA Terrestrial Planet Finder-Coronagraph TPF-C 0.5-1.6 microns and NASA Terrestrial Planet Finder-Interferometer TPF-I 6.5-18 microns 6,7 has been designed to provide spectral information about terrestrial planets outside our solar system Daunting technological challenges prohibit the ability to obtain spatial resolution on the extrasolar planets and severely limit both the spectral and temporal sampling of even the most interesting discovery The spectral information provided would be therefore averaged over the visible planetary disk and the exposure time which may be hours days or weeks depending on the target Due to these reasons the interpretation of the observed spectrum may not be unique and instead a family of solutions i.e degeneracy will provide an equally good explanation of the spectral features within a given accuracy Previous research in this area has focused on measurements and preliminary interpretation of the Earthshine on the nonilluminated side of the Moon 8,9 models of diurnal photometric variability on an Earth-like planet and models that simulate disk-averaged spectra from a description of a spatially resolved terrestrial planet on diurnal or seasonal time scales 10,1 1 These 3D models are direct models i.e they compute observable quantities starting from a set of model parameters Analysis of Earthshine reflected off of the Moon Figure 1 provides an excellent analogue of an extrasolar planet spectra integrated into one spatial resolution element Additionally knowledge of the groundtruth observational conditions of the Earth at the time of the observations allows comparison of spectrally retrieved results tigure 1 tarthsline illuminatea aarK sid e lVofoon Copyright 251 2005 by Jerry Lodriguss Classical Retrieval Methods Retrieval in general is the process that solves the inverse problem which is the determination of the model parameters for a given set of observed quantities The inverse problem in spectral retrieval consists of determining given an observed spectrum the combination solution of planetary and atmospheric conditions at the time of the observation The existence of multiple equally valid solutions i.e degeneracy and the lack of sensitivity both affect the inversion process often to the point of preventing a successful retrieval This problem has been studied extensively using a number of different approaches A good theoretical understanding of the inversion process has been achieved in studies of dynamical systems information theory and complexity theory but the underlying techniques have not yet been systematically applied within the atmospheric remote sensing community The traditional retrieval techniques developed to study the environments of the Earth and other planets in the solar system are inadequate to analyze disk-time averaged spectra because they assume spatially homogeneous environments and short observational time scales 12 Moreover traditional techniques benefit from a fairly good knowledge of the environment under investigation This information is used to constrain the initial parameter set and the retrieval method will search for the best possible solution that reproduces the observed spectrum in the local domain of the initial condition The assumption that the solution needs to belong to the local domain of the initial condition is an unavoidable limitation of traditional gradient-based methods 13 We have employed Evolutionary Computational Methods ECM developed by the Center for Evolutionary Computation and Automated Design CECAD at the Jet Propulsion Laboratory Caltech to automatically retrieve planetary and atmospheric information from disk-averaged planetary spectra 4,5 ECM has been coupled to the direct model developed by Tinetti et al 10,11 that simulates the 3-D spectral response of the planet ECM is used to optimize planetary parameters of interest here surface type and cloud fraction in an iterative process that minimizes a fitness function measuring the degree of similarity between observed and synthetic spectra The specific functional formula of the fitness function depends on spectral resolution spectral integral and signal-to-noise ratio of the observed data Repeated application of ECM automatically yields a population of solutions parameter sets within the user-defined accuracy fitness Using this 3-D retrieval method the final fit between the observed spectrum and the synthetic one is no longer heuristic with respect to the space inhomogeneities but is the result of an accurate screening of possibilities such as surface types viewing geometries phases and illumination The advantage of ECM over traditional retrieval methods is 2 


the ability to perform an automatic unbiased search not dependent on initial ad-hoc expert guesses for all solutions within the entire model-defined parameter space using search criteria that are computationally far more economical than complete enumeration brute force Monte Carlo or random searches The only a priori information used is what is built into the synthetic spectral models employed Figure 2 Phase and viewing geometry observed by Woolf et al 2002 during their Earthshine measurement We present here first results of this method applied to the retrieval of surface and atmospheric parameters from an Earth disk-averaged spectrum in the optical observed by Woolf et al 8 Further we estimate and analyze the degree of degeneracy of the retrieved solutions 3 TECHNICAL APPROACH AND METHODOLOGY The developed spectral retrieval framework is composed of three modules the central core is ECM on the front end is the Synthetic Spectra Generator which coupled with the ECM generates a population of automatically retrieved spectral solutions on the back-end is the Synthetic Spectra Degeneracy Analyzer which allows an analysis of the uniqueness of individual solutions within the population Figure 3 shows a schematic diagram of the ECM-driven spectral retrieval framework Figure 3 Schematic diagram of the spectral retrieval framework Evolutionary Computational Methods ECM ECM is comprised of two well-proven multi-dimensional stochastic and evolutionary optimization techniques Genetic Algorithms GA and Simulated Annealing SA Unlike other traditional optimization algorithms both SA and GA are not fundamentally limited by restrictive assumptions about the search space such as continuity and existence of derivatives GA and SA have been successfully used for a variety of high-dimensional optimization problems in space systems 1,14 and engineering and biomedical applications 15,16 SA has also been applied to the problem of Rutherford backscattering spectral retrieval 17 Genetic Algorithms GA Genetic algorithms 18,19 rely on biologically inspired computational techniques that utilize evolutionary operators on a population of individuals The process starts with an initial population of individuals potential solutions which then undergoes a sequence of unary mutation and higher order crossover transformations The individuals strive for survival a selection reproduction scheme biased towards selecting fitter individuals produces the individuals for the next generation After several generations the population converges to a set of optimal solutions which represent the intrinsic degeneracy in the search space Simulated Annealing-related Algorithms SA The objective of SA 20,21 is to minimize an energy function E which is a function of N variables the observational and compositional parameters for the synthetic spectral data The minimization is performed by randomly changing the value of one or more of the N variables and reevaluating the energy function E Two cases can occur 1 the change in the variable results in a new lower energy function value or 2 the energy function value is higher or unchanged In the first scenario the new set of variables is stored and the change accepted In the second scenario the new set of variables is only stored with a certain likelihood Boltzmann probability including an annealing temperature This process reduces the probability that the optimization algorithm becomes trapped in local minima as can be the case with greedy downhill optimization techniques e.g gradient-descent The annealing temperature directly influences the Boltzmann probability by determining the likelihood of accepting an energetically unfavorable step The temperature is gradually decreased cooling schedule and the overall procedure is repeated until the annealing temperature has reached its end value a preset number of iterations has been exceeded or the energy function has reached an acceptable user-defined level 3 


Synthetic Spectra Generator The Synthetic Spectra Generator generates a library of synthetic spectra using radiative transfer and planetary models as well as planetary and atmospheric parameters as input e.g the size of the planet gas-mixing ratio of the atmospheric components temperature and pressure profiles surface albedo cloud/aerosol optical properties stellar spectrum etc In this work the optical radiances were generated using the Spectral Mapping Atmospheric Radiative Transfer SMART model 22,23 for the clear sky and cloudy cases The inputs to this model were the vertical profiles of temperature and gas-mixing ratios extracted from the Atmospheric Infrared Sounder AIRS Level 2 Simulation System 24 simulations Estimates of surface reflectance and emissivity are based on ASTER data The planetary 3D geometry and disk-averaging technique we chose for our calculations is described in Tinetti et al 1I0,11 I The model uses a partition of the sphere Healpix Hierarchical Equal Area and Iso-Latitude Pixelization that was originally implemented for the NASA-WMAP mission 25 The planetary sphere can be resolved with an arbitrary number of pixels A library of spectra can be built Figure 4 by running the radiative transfer codes for each pixel for a variety of situations including temperature profile gas mixing ratios surface type ocean vegetation desert ice etc or the cloud/aerosol type Cirrus Alto-Stratus etc viewing and stellar angles By specifying the positions of the observer and the star which determine the phase and the viewing geometry a disk-averaged spectrum is computed by integrating the area-weighted pixels over the visible disk A time-averaged spectrum can be obtained by integrating over time the contributions of the disk-averaged spectra for a rotating planet seen from a specified viewing point Alto-Strotuos Cirru 0.5 0.4 j0.3 0.2 0.1 o 5 0~6 0.7 0.5 0.9 Wavelength PiM Figure 4 Disk-averaged spectra of the Earth in the optical showing a planet covered by one surface or cloud type at a time The phase selected for these simulations is the one shown in Figure 2 Synthetic Spectra Degeneracy Analyzer The solutions obtained with ECM are points in the highdimensional solution parameter space To characterize the degeneracy of the solutions found by ECM the Synthetic Spectra Degeneracy Analyzer relies on several wellestablished mathematical techniques such as Level Set Analysis LSA and Principal Component Analysis PCA Level Set Analysis-LSA groups ECM results into a set of clusters If more than one cluster can be identified the conclusion is that the retrieval process has produced a set of equivalent or degenerate solutions which are precious input for the subsequent science-based analysis The LSA process starts with assigning a membership value to each solution for each cluster The number of clusters is a fixed parameter and the centers of the clusters in the parameter space are themselves obtained from an optimization process The membership value is for example a normalized function of the Euclidean distance between solutions in the parameter space A solution is said to belong to a particular cluster if the membership value is larger than a set threshold For each fixed number of clusters the percentage of solutions belonging to a cluster gives a measure of the quality of this particular clustering configuration The best clustering configuration is the one with the largest percentage of solutions belonging to a cluster Details about the LSA procedure are given in Huntsberger et al 26 Principal Components Analysis PCA is employed to visualize and characterize the solutions found by ECM A Singular Value Decomposition of the matrix of column vectors representing the entire set of solutions found by a Genetic Algorithm or Simulated Annealing optimization is performed to find the set of deviations in the solutions principal values along a corresponding set of orthogonal directions principal component vectors which are sorted in descending order so that the first principal component is the direction of maximum deviation and the last principal component is the direction of minimum deviation A projection of the solutions onto the plane defined by the first two principal component vectors tends to exhibit the largest separation between solutions The solutions tend to clump together in clusters about an exemplar positioned at the center of each cluster enabling an improved visualization of potential degeneracy in the solution set 4 ECM SPECTRAL RETRIEVAL STUDIES We have performed a set of ECM-driven retrieval studies in retrieving an Earthshine spectrum which serves as an analogue for Terrestrial Planet Finder-Coronagraph TPFC data The Earthshine spectrum was measured by Woolf et al with the Steward Observatory 2.3m telescope 8 For the retrieval studies presented here several approximations are made in order to confine the retrieval 4 


wdisbife Data i f 6de 1 o3de 3 afi 6del 4 X_ I A 0.6 0 7 WaVeength ori 0.8 0.9 Figure 5 Synthetic spectra fitted to Earthshine data The retrieved solutions are processed to determine the degeneracy degree They are classified into clusters using LSA Figure 6 displays the albedo component configuration of the 17 identified cluster centers The LSAselected cluster centers illustrate the representative picture of the variations of the albedo configurations among all the 2825 retrieved solutions According to the LSA results the second study led to more distinct solutions cluster centers than the first study indicating that the second study is more efficient in controlling the diversity of the solutions Retrieved Albedo Configurati H3Medium cIoud u Low cloud 1 2 3 4 5 6 7 8 9 tl e t 12 13 14 15 16 17 Cluster Center II 5 t C Ocean IHLR 1001/1 9 01/1 8 01/1 7 01 6 01 5 01 4 01 3 01 2 01 101/1 01/1 12 _  6 005  parameter space First a minimal set of component synthetic spectra is prepared by varying albedo types and stellar and viewing angles The trace gas and temperature profiles of the atmosphere remain fixed Nine different albedo types are considered and are characterized as ocean forest grass ground tundra ice high cloud medium cloud and low cloud A component spectrum at a general angle is obtained through linear and bicubic spline interpolations The resulting library of the component spectra allows us to explore the various configurations of albedo types within a fixed atmosphere profile Second the Earth's surface area is divided into 48 equal-area pixels in order to spatially resolve the visible planetary disk and each of the pixels is assumed to consist of the same albedo properties This approximation captures the effect of the overall averaged configuration of the albedo types but eliminates the effect of the spatial distribution of the albedo-type configuration Note that although the albedo properties are uniform through pixels the contribution of each pixel to the diskaveraged spectrum is still different due to its relative location to the sun and the viewer The observer and solar positions were known from the observation and kept fixed thereby constraining both the phase and the viewing geometry Fig 3 and reducing the number of illuminated pixels to 22 Using the selected observer-stellar positions a disk-averaged spectrum was generated for each of the cloud/surface type configuration prescribed by ECM ECM is used to optimize these different cloud/surface fractions in an iterative process that minimizes a fitness function measuring the degree of similarity between the observed and the synthetic spectrum Repeated application of ECM automatically yields a population of solutions parameter sets within the userdefined accuracy fitness Two distinct retrieval studies were designed using ECM i evolution of one large population with 1000 individuals and ii evolution of multiple 19 islands with 100 individuals in each island The two retrieval studies are prepared to compare their effectiveness in terms of the fitting quality and degeneracy degree of retrieved solutions As a first guess it is expected that the first study has an advantage of a sufficiently large population size over the second study while the second study has an advantage of diversity promotion over the first study Besides the population size and the number of populations the two studies use the same gene representations and algorithmic procedures for selection reproduction and replacement steps A gene is represented by a real-valued parameter which corresponds to the weight/percentage of one albedo type A binary tournament is used for selection Mutation with probability 0.1 per gene and Crossover with rate 0.8 per individual are used for reproduction The population of the next generation is composed of the top 15 of individuals from the current population and the offspring generated from selection and reproduction procedures 5 RESULTS These two retrieval studies returned over 2800 automatically generated retrievals satisfying the error criteria fitness of 10 least squares match to the observed spectra The first study resulted in 990 eligible solutions out of 1000 candidates in the final population The second study led to 1835 eligible solutions out of 1900 This shows that the resulting fitting quality and success rate are comparable between the two studies The total computational time for these studies is 20 hours with 16 processors working in parallel on a Linux-based cluster computer with 3.06 GHz Pentium IV CPUs Figure 5 shows the synthetic spectra generated by several retrieved solutions in comparison with the observed spectrum 0.15 j  lE 0.1 _ _M w mI  Model 5 Model   ModeI 10 IWMde III Model Grass E3 Forest M I DIce IM Ground E3Tundra 13 


Figure 6 Albedo configurations of the synthetic spectra found by the Synthetic Spectra Degeneracy Analyzer Each configuration leads to a synthetic spectrum that matches the Earthshine data within a 10 error bar 6 DISCUSSION The representative solutions of the retrieved solutions shown in Figure 6 enable a science-based discussion of the results Some of the cluster centers almost exclusively differ by the ratios of the grass to forest coverage e.g cluster 9 has a high ratio whereas cluster 8 has a low ratio This result suggests that grass and forest coverage are equivalent with respect to their spectral contribution within error-bars Figure 7 0.3  Population Solutions Is and Solutions Clus0 T 5 et OPPLtatio Solutions The cluster C slueslet enters of slalod SolutithLis ic cano beA rerive fro the Eahhnv pctu 8,i saelit data i.e.,gon rt u Fto th iwn m 1 30 6 0.55 0.5 0-45 _ Fi:rst Principal Compoent Figure 7 Principal Component Analysis results obtained with the Synthetic Spectra Degeneracy Analyzer The cluster center solutions also suggest that low clouds and ice cannot be retrieved from the Earthshine spectrum 8 in agreement with known observational parameters and satellite data i.e ground truth Due to the viewing geometry and season of the year N.H summer in fact ice was not visible As concerns low clouds they are easily masked by medium and high clouds which reside at higher altitude It is important to note that these conclusions were reached without introducing any prior knowledge of the system This demonstrates that the ECM-based retrieval framework introduced here seems to be capable of producing meaningful scientific results with a minimal set of a priori assumptions ECM-based spectral retrieval will become particularly relevant in the context of extra-solar planetary studies where close to nothing is known about the observed objects Outlook The ECM-based spectral retrieval process can be refined by increasing the parameter space to a large number of components Further one can also iterate the manner in which fitnesses are computed by examining large numbers of solutions thereby optimizing fitness functions i.e for maximizing discriminability of degeneracies among solutions In forthcoming work we will explore/expand the search space as permitted by the scalability of the available computer resources We will also run numerical experiments to assess the gain/loss in information content induced by an increased spectral resolution which in turn requires an increased integration time necessary to complete the observations We have conducted preliminary experiments using a synthetic target spectrum instead of the observational Earthshine spectrum as a standard reference for automated spectral retrieval using ECM Retrievals were run for various modifications of the fitness functions Our standard method uses minimization of the area between the reference and retrieved spectra Additional methods preferentially weight special regions of the target spectrum e.g continuum values line centers steep slopes etc The results of PCA were compared for varying constraints on the fitness function to determine if clustering i.e spectral degeneracy can be modulated Initial results indicate that constraints on instrument requirements i.e wavelength range signal to noise resolution etc can be determined from these ECM-based retrievals 7 CONCLUSIONS We have demonstrated that Evolutionary Computational Methods ECM can be used for automatic spectral retrieval and that the results are scientifically consistent with ground truth We have further demonstrated that we can use clustering tools to discriminate classes of spectral fits and identify degeneracy non-uniqueness in solutions The computational time used in these experiments indicates that full parameter retrievals are achievable with available computational resources in reasonable run-times Preliminary experiments using synthetic target spectra indicate that spectral instrument design parameters can be derived from scientific forward models of the observational environment Evolutionary Computational Methods are applied to the forward models to retrieve large populations of synthetic spectra that can be evaluated under varying fitness conditions to maximize spectral discriminability ACKNOWLEDGEMENTS The work described in this publication was carried out at the Jet Propulsion Laboratory California Institute of Technology under a contract with the National Aeronautics and Space Administration 6 


References herein to any specific commercial product REFERENCES process or service by trade name trademark manufacturer or otherwise does not constitute or imply its endorsement by 1 Terrile R J Adami C Aghazarian H Chau S N the United States Government or the Jet Propulsion Dang V T Ferguson M I Fink W Huntsberger T Laboratory Califoria Institute of Technology L Klimeck G Kordon M A Lee S von Alhmen P A and Xu J 2005 Evolutionary Computation Technologies for Space Systems IEEE Aerospace Conference Proceedings Big Sky MT March 2005 2 Terrile R J Kordon M Mandutianu D Salcedo J Wood E and Hashemi M 2006 Automated Design of Spacecraft Power Subsystems IEEE Aerospace Conference Proceedings Big Sky MT March 2006 3 Terrile R J Kordon M Postma M Salcedo J Hanks D and Wood E 2007 Automated Design of Spacecraft Telecommunication Subsystems Using Evolutionary Computational Techniques IEEE Aerospace Conference Proceedings Big Sky MT March 2007 4 Terrile R J Fink W Huntsberger T Lee S Tisdale E R Tinetti G and von Alhmen P 2005 Retrieval of Extra-Solar Planetary Spectra Using Evolutionary Computational Methods Bull Amer Astron Soc 37 5 Terrile R Lee S Tinetti G Fink W Tisdale E R Huntsberger T and von Alhmen P 2006 Spectral Retrieval of Exoplanetary Signatures Using Evolutionary Computational Methods Proceeding of the EGU General Assembly Vienna Austria 6 Beichman C.A N J Woolf and C.A Lindensmith The Terrestrial Planet Finder TPF JPL 99-3,1999 7 Lawson P.R Unwin S.C  Beichman C.A 2004 Precursor Science for the Terrestrial Planet Finder JPL Publication 04-014 8 Woolf N.J P.S Smith W.A Traub and K.W Jucks The spectrum of earthshine A pale blue dot observed from the ground Astrophysical Journal 574 1 430-433 2002 9 Arnold L S Gillet 0 Lardiere P Riaud and J Schneider A test for the search for life on extrasolar planets Looking for the terrestrial vegetation signature in the Earthshine spectrum Astronomy  Astrophysics 392 1 231-237 2002 10 Tinetti G V.S Meadows D Crisp,W Fong T Velusamy H Snively Disk-averaged synthetic spectra of Mars Astrobiology 5 4 2005 7 


11 Tinetti G V.S Meadows D Crisp E Fishbein M Tumbull and J.P Bibring Detectability of Planetary Characteristics in Disk-Averaged Spectra I the Earth Model Astrobiology 2006 Vol 6 n 1 12 Hanel R.A Conrath B.J Jennings D.E Samuelson R.E Exploration of the Solar System by infrared remote sensing Cambridge Planetary Science Series Cambridge University Press 1992 13 Rodgers C.D Inverse Methods for Atmospheric Sounding Theory and Practice Series on Atmospheric Oceanic and Planetary Physics Vol 2 World Scientific Publishing Co 2004 14 Terrile RJ Aghazarian H Ferguson MI Fink W Huntsberger TL Keymeulen D Klimeck G Kordon MA Lee S von Alhmen P 2005b Evolutionary Computation Technologies for the Automated Design of Space Systems accepted for publication in 2005 NASA/DoD Conference on Evolvable Hardware IEEE Computer Society 15 Mitchell M An Introduction to Genetic Algorithms The MIT Press 1996 16 Aarts E J Korst Simulated Annealing and Boltzmann Machines A Stochastic Approach to Combinatorial Optimization and Neural Computing John Wiley  Sons Chichester 1989 17 Barradas N.P C Jeynes R.P Webb Simulated annealing analysis of Rutherford backscattering data Appl.Phys.Lett 71 1997 291-3 18 Holland J.H Adaptation in Natural and Artificial Systems The University of Michigan Press Ann Arbor Michigan 1975 19 Goldberg D.E Genetic Algorithms in Search Optimization and Machine Learning Addison-Wesley 1989 20 Metropolis N A.W Rosenbluth M.N Rosenbluth A.H Teller E Teller Equation of State Calculation by Fast Computing Machines J of Chem Phys 21 1087-1091 1953 21 Kirkpatrick S C.D Gelat M.P Vecchi Optimization by Simulated Annealing Science 220 671--680 1983 22 Meadows V.S and D Crisp Ground-based nearinfrared observations of the Venus nightside The thermal structure and water abundance near the surface Journal of Geophysical Research-Planets 101 E2 4595-4622 1996 23 Crisp D Absorption of sunlight by water vapor in cloudy conditions A partial explanation for the cloud absorption anomaly Geophysical Research Letters 24 5 571-574 1997 24 Fishbein E C.B Farmer S.L Granger D.T Gregorich M.R Gunson S.E Hannon M.D Hofstadter S.-Y Lee S.S Leroy Formulation and Validation of Simulated Data for the Atmospheric Infrared Sounder AIRS IEEE Transactions on Geoscience  Remote Sensing Vol 41 N 2 Feb 2003 1 25 Gorski K.M Hivon E and Wandelt B.D Analysis issues for large CMB data sets Proceedings Evolution of Large Scale Structure-Garching 1998 26 Huntsberger T.L C L Jacobs and R.L Cannon Iterative fuzzy image segmentation Pattern Recognition Vol 18 pp 13 1-138 1985 BIOGRAPHY Richard J Terrile created and directs the Center for Evolutionary Computation and Automated Design at NASA s Jet Propulsion Laboratory His group has dveloped genetic algorithm based tools to improve on human design of space systems and has demonstrated that computer aided design tools can also be used for automated innovation and design of complex systems He is a planetary astronomer and the co-discoverer of the Beta Pictoris circumstellar disk Dr Terrile has B.S degrees in Physics and Astronomy from the State University of New York at Stony Brook and an MS and a Ph.D in Planetary Science from the California Institute of Technology in 1978 Seungwon Lee is a member of the technical staff at the Jet Propulsion Laboratory Her research interest includes genetic algorithms low-thrust trajectory design nanoelectronics quantum computation parallel cluster computation and advanced scientiJfic software modernization techniques Seungwon received her Ph.D in physics from the Ohio State University in 2002 Her work is documented in numerous journals and conference proceedings 8 


Institute of Technology in Lausanne Switzerland in 1990 His work is documented in numerous publications and patents Giovanna Tinetti is a researcher at the Dep of Physics and Astronomy of the University College London since September 2007 She is author of more than twenty peer-reviewed publications on planetary science spectroscopy and exoplanet characterization among which the most recent discovery of water vapor in the atmosphere of an extrasolar planet After her PhD in theoretical physics from the University of Torino Italy she worked for four years at the California Institute of Technology and two years at the Institut d'Astrophysique de Paris Wolfgang Fink is a Senior Researcher at NASA's Jet Propulsion Laboratory in Pasadena CA Research Associate Professor of both Ophthalmology and Neurological Surgery at the University of Southern California Los Angeles CA and Visiting Associate in Physics at the California Institute of Technology Pasadena CA He is the founder and head of the Visual and Autonomous Exploration Systems Research Laboratory at Caltech t o  His research interests include autonomous planetary and space exploration computational field geology computer optimization image processing and analysis sensor data fusion astrobiology and biomedicine Dr Fink obtained a B.S and M.S degree in Physics and Physical Chemistry from the University of Gottingen and a Ph.D in Theoretical Physics from the University of Tubingen in 1997 His work is documented in numerous publications andpatents Terrance L Hunts berger is a Principal Member of the Technical Staff in the Mobility and Robotics Section at the Jet Propulsion Laboratory in Pasadena CA where he is the Manager for numerous tasks in the areas of multi-robot control systems rover systems for access to high risk terrain and long range traverse algorithms for rovers He is an Adjunct Professor and former Director of the Intelligent Systems Laboratory in the Department of Computer Science at the University of South Carolina His research interests include behavior-based control computer vision neural networks wavelets and biologically inspired system design Dr Huntsberger has published over 120 technical articles in these and associated areas He received his PhD in Physics in 1978 from the University of South Carolina He is a member of SPIE ACM IEEE Computer Society and INNS Paul von A ilmen is the supervisor of the Applied Cluster Computing Technologies group and a senior researcher at the Jet Propulsion Laboratory Paul is currently leading research in quantum computing thermoelectric and nonlinear optics material and device design nano-scale chemical sensors semiconductor optical detectors and low-thrust trajectory optimization Prior to joining JPL in 2002 Paul worked at the IBM Zurich Research Lab on semiconductor diode lasers at the University of Illinois on the silicon device sintering process and at the Motorola Flat Panel Display Division as manager of the theory and simulation group and as principal scientist on micro-scale gas discharge UV lasers Paul received his Ph.D in physics from the Swiss Federal 9 


align than would opinions from a more diverse group of experts, thus measures of conflict are thought to be conservative in this report Also, concerning respondent bias, this study generated its output from a limited number of responses.  Non-respondents expressed reasons for not participating that included distrust, being too busy, vacation, and difficulty authenticating themselves on the survey s Website.  Invalid e-mail addresses and spam blocking filters also contributed to the reduction of responses [8  The set of 103 tasks presented within this report are not implied to represent a comprehensive set of tasks forensic examiners perform pertaining to the forensic data acquisition of personal computer workstations.  This set of tasks is limited to those that were identified by respondents of this study.  No conditional logic regarding the performance of tasks is suggested nor is the sequence of the performance of tasks  4.3. Call for additional research  Given the importance of expert testimony in legal proceedings and the level of conflict among forensic computer experts revealed within this study, more study is needed to develop a better understanding of the causes of conflict and solutions to reduce conflict For example, future studies may identify beneficial solutions from licensing organizations, industry standards, mandatory training, or legislation regarding the credentials of forensic computer examiners. Clearly, the inconsistency among forensic computer examiners opinions identified within this study illustrates a weakness within our legal system that has the potential to alter trail outcomes, thus allowing the guilty to be acquitted and the not-guilty to be wrongly convicted  5. References  1 V o lo ni no, L A n z a l dua R., a nd G odw in, J Co m pute r  Forensics Principles and Practices, Prentice Hall, Upper Saddle River, New Jersey, 2007  2 N e ls on B Phil lips  A Enf i ng e r F., a n d S t e w a r t, C Guide to Computer Forensics and Investigations, 3 rd Ed Thomson, Boston, 2008  3 Ke rr, O.S Digital Evidence and the New Criminal Procedure Columbia Law Review, 105\(1\005, p.279318  4 K n a pp, K  L Me e ting the D a ube rt Cha lle ng e  A Mode l  to Test the Relevance and Reliability of Expert Testimony ProQuest, Ann Arbor, Michigan, UMI 3098259, 2003  5 Na tiona l Instit ute of Justic e  Fore nsic Ex a m ina tion of  Digital Evidence: A Guide for Law Enforcement, \(NCJ 199408\.S. Government Printing Office, Washington DC, 2004  6 Ca rlton  G  H., A P r otoc ol f o r the Fore nsic Da ta  Acquisition of Personal Computer Workstations, ProQuest Ann Arbor, Michigan, UMI 3251043, 2007  7 G l a s e r B G a nd S t ra us s  A  L T h e D i s c ov e r y o f  Grounded Theory: Strategies for Qualitative Research Aldine Publishing Co., New York, 1967  8 Ca rlton  G  H., Fore nsic Da ta  A c quisition T a sk Performance Guide The Identification and Measurement of a Protocol for the Forensic Data Acquisition of Personal Computer Workstations, http://www.htcia.org, 2006  Proceedings of the 42nd Hawaii International Conference on System Sciences - 2009 10 


Scenario 7 Figure 3 Plots for the frame size distributions for the various scenarios along with the as the SCaN simulator based was available 11 I Frames P Frames B Frames T  I-1 a-2--a 0 0 0 0 0 m on Qualnet 4 TELEMETRY TRAFFIC MODEL Telemetry transmissions from the spacecraft to the command center generally take as follows First some are aperiodic These traffic may represent various instrumentation measurements sensory outputs file downloads etc On the right side of the picture was not partitioned into sub-channels but rather data was transmitted only when it we come to the following conclusions about the packet size distribution for this type of encoding scheme  In the we present we determine the statistical distribution of the type of video which we are interested in transmitting As we note from the above picture the telemetry transmission wastes one can use the traffic synthesizing tool to generate random traffic whose frame statistical distribution approximates the distribution of the traffic which a lot of bandwidth when a lot or blue sky the size of the I frames is relatively small see scenarios 1 4  In the are much smaller than those of I frames see scenarios 1,2,5,6,7  If the main object in the picture is moving quite are multiplexed together Some of these traffics are constant bit rate are described by on the above data a large evenly painted surface a file in a large amount of bandwidth The type of traffic that generally is being transmitted via a telemetry channel is formed by multiple types of traffic which so that each telemetry data has its a particular sub-channel For this reason cases the telemetry transmission will look something like in Figure 5 Contrary to Figure 4 right side in Figure 5 the channel own designated sub-channel see Figure 4 For example in the left side of Figure 4 can be used by network simulation tools such we are interested in analyzing This synthesized traffic generated by we designate each telemetry type to we have seen one can model the frame sizes of the different type of frames by gamma approximations Based or there is very little detail in the pictures i.e the pictures are of even if the picture has many objects with rich detail the sizes of P and B frames even if the background is rather stationary the distribution of the frame sizes is much thicker i.e having higher variance see scenarios 3,4,7 Video synthesis In this section a video synthesizer for MPEG v4 encoded video which has been developed in order to generate sample traffic for live video transmissions The synthesizing of the video traffic is done a gamma distribution Using the tools developed above on preexisting traffic of the type we are interested to transmit one can find the parameters of the gamma distribution which best fit this type of traffic Given the parameters determined by those tools our tool is outputted to a format which some are periodic in nature while others may be event based non-periodic The classical approach to telemetry is to schedule the transmission we see multiple types of traffic some of which a constant bit rate some are periodic and we see the traffic being fit through a channel which has been partitioned into sub-channels Figure 4 Traffic allocated to dedicated channels As a more desirable approach would be to multiplex together all of the transmissions In such case in which the background for the video is dark case in which there is little movement in the background 


Figure 5 Statistically multiplexed traffic We note that in this case we would be able to utilize some of the free channel space for other types of transmissions which may be more delay tolerant see Figure 6 For example in this figure the bottom blue transmission can be thought to be a file which is packetized and needs to be transmitted down from the spacecraft We consider this file to be delay tolerant i.e the data is not needed right away down on the ground and it has a lower priority then the other traffics needed to be transmitted The delay tolerant packets will be transmitted only when the channel is not being fully utilized as to fill in the gaps available in the channel bandwidth This technique will delay the arrival of the delay tolerant traffic but will enable us to more fully utilize our channel bandwidth m T]T m Figure 6 Telemetry traffic along with delay tolerant traffic being sent via a channel We note in above scenario that although the delay tolerant traffic was transmitted at time 0 none of it was able to be transmitted until time 1 Also we note that the final delay tolerant traffic packet was transmitted 9 time instances later then it was received For this reason a buffering scheme must be devised such that all the delay tolerant traffic may be buffered until enough bandwidth for transmission exists Since no specific data was available on the dynamics of the various telemetry type traffics we developed a generic telemetry model which is formed by two types of traffic one constant bit rate which represents the sensory information which is constantly being transmitted down to the ground and an intermittent transmission similar to the on/off type of traffic used to model the voice activity in the audio/voice transmission section which represents file download and periodic data updates We assume that there will be a maximum bandwidth which may be allocated to telemetry constant bit rate  peak of intermittent transmission We will also assume that the intermittent transmission file transfer will transmit at the maximal possible rate when new files are ready to be transferred Using the above model we created a Matlab based tool for synthesizing traffic for simulation purposes The traffic generated by this tool is output to a file in a format which can be used by network simulation tools such as the SCaN simulator 5 COMMAND TRAFFIC MODEL The model for the command will be similar in spirit to the model which we have proposed for telemetry We see the data transmitted for command to be formed by two different types of transmission One constant bit rate which represents calls to various preloaded spacecraft subroutines and an intermittent transmission similar to the on/off type of traffic used to model the voice activity in the audio/voice transmission section which represents subroutine uploads to the spacecraft We assume that there will be a maximum bandwidth which may be allocated to command and we also assume that the intermittent transmission subroutine upload will transmit at the maximal possible rate when new subroutines are ready to be transferred Using this model we have developed a Matlab based traffic synthesizing tool The traffic provided by this tool can be used by network simulation tools such as the SCaN simulator 6 CONCLUSIONS This work has resulted in the development of a suite of traffic models that captures the fundamental types that will be in the space communications environment and in particular These models provide the capability to investigate the new IP-based communications functions and resulting performance that are required by the human exploration missions of NASA's Constellation Program and the Space Communications and Navigation SCaN network's ability to support them Four prototypical traffic models have been developed from which any number of streams may be generated 1 audio/voice 2 real-time motion imager live video 3 telemetry including both regular periodic data as well as intermittent file downloads and 4 command including periodic data as well as intermittent subroutine uploads The voice traffic model stochastically parameterizes calls talk times and talk spurts Multiple audio analysis tools were developed to assist in the derivation of parameters from data samples taken from relevant space missions Using these tools parameters of probability distributions were fit to data taken from Shuttle/ISS archives 12     n 


The characterization of motion imagery video traffic involved the stochastic characterization of I P B-frames of MPEG-4 sequences Several Matlab tools were developed to support video analyses wherein ISS and Shuttle specific mission video sequences were used to derive parameters for the associated model A general stochastic model was derived for data telemetry enabling broad parametric applicability ranging among constant bit stream periodic or bursty patterns This same general model through proper selection of parameters may also be used to model command data flow traffic Matlab programs were developed to enable each of the traffic types above to be synthesized and saved into a file for use by SCaN simulation for performance analyses Example flows were generated for a LEO case and an Ascent case and results illustrated using the SCaN Simulator These analyses show the need for such traffic models to determine packet loss including speech intelligibility and latency arising from both statistical multiplexing and potential use of DiffServ prioritization techniques when peak offered loads may undergo transient overload conditions 7 ACKNOWLEDGEMENTS The research described in this paper was carried out at the Jet Propulsion Laboratory California Institute of Technology and the National Aeronautics and Space Administration REFERENCES 1 Esther Jennings and David Heckman Architecture Modeling and Performance Characterization of Space Communications and Navigation SCaN Network using MACHETE submitted to 2008 IEEE Aerospace Conference Proceedings March 1-8 2008 2 Michael Hammer and James Champy Reengineering the Corporation New York Harper Business 1993 3 G Edward Bryan Not All Programmers Are Created Equal 1994 IEEE Aerospace Applications Conference Proceedings February 5-12 1994 4 Voice Activity Detection Using Generalized Gamma Distribution in Advances in Artificial Intelligence part of the series Lecture Notes in Computer Science Volume 3955 2006 5 Athina Markopoulou Fouad Tobagi and Mansour Karam Assessment of VoIP quality over Internet backbones In Proceedings of INFOCOM 2002 6 John Daigle and Joseph Langford Models for Analysis of Packet Voice Communications Systems IEEE JSAC SAC-4 6 1986 7 Harold Stem and Kim-Kwok Wong Modeling the on-off patterns in conversational speech including short silence gaps and the effects of interaction between speaking parties Vehicular Technology Conference 1994 8 0 Rose Statistical Properties of MPEG video traffic and their impact on traffic modeling in ATM systems Institute of Computer Science Report 101 University of Wurzburg 1995 BIOGRAPHY Tudor Stoenescu received a BS in Electrical Engineering  and an MS in Mathematics from North Dakota State University in 1999 and a MSE and PhD in  Electrical Engineering and Computer Science from University of Michigan in 2001 and 2004 respectively After receiving his PhD Dr Stoenescu accepted a Postdoctoral Scholar position in Information Science and Technology at California Institute of Technology In 2006 Dr Stoenescu joined the Telecommunications Architecture Group at Jet Propulsion Laboratory Dr Stoenescu's current research interests lie 13 


in the areas of resource allocation in networks mechanism design dynamic scheduling and decision processes stochastic control and optimization Loren Clare is the supervisor for the Communications Networks Group at the Jet Propulsion Laboratory He obtained the Ph.D in System Science from the University of California Los Angeles in 1983 His research interests include wireless communications protocols self-organizing systems network systems design modeling and analysis and distributed control systems Prior to joining JPL in May 2000 he was a senior research scientist at the Rockwell Science Center where he acquired extensive experience in distributed sensor networks satellite networking and communications protocols for realtime networks supporting industrial automation 14 


References 225 Krauss J D Antennas 2 nd Edition McGraw-Hili 1988 225 Yang G-Z Body Sensor Networks Springer 2005 225 Higgins H Implant Communication Made Real Body Sensor Networks Conference 2007 225 Sivard A et al Challenge of Designing In-body Communications Embedded System News 2004 225 Higgins H Human Body Implant Communication Making it Possible European Conference on Antennas and Propagation 2007 225 Hodgins D et al Healthy Aims Developing New Medical Implants and Diagnostic Equipment IEEE C5 Pervasive Computing January March 2008 225 Higgins H Implant Communications Out of the Lab and Into Patients lET Body-Centric Communication Conference London April 20 2009 225 Higgins H Body implant Communications Is It a Reality Antennas and Propagation for Body\255 Centric Wireless Communications lET/loP London April 24 2007 225 Higgins H Radio Frequency Technology and In-Body Communication Systems Implantable and Body Centric Conference Imperial College London 2005 225 Higgins H In-body Communications the Challenges and The Opportunities COST 2005 225 Rahmat-Samii Y and Kim J Implanted Antennas in Medical Wireless Communications Morgan  Claypool 2006 225 The Antenna Book 20th Edition American Radio Relay League ARRL 255 Main Street Newington CT,USA 225 Fujimoto K et al Small Antennas Research Studies Press 1967 225 Bancroft R Microstrip and Printed Antenna Design Noble Publishing 225 http://www.zarlink.com/zarlink/hs/82_ZL70101.htm 


Conclusions 225 Communication with very small implants is possible 225 The human body can both help and hinder communication 225 Power consumption is an issue for long term implants 225 The communication system antenna and implant should be designed together 225 There is no one size fits all solution 225 Transmission of data to and from an implant is practical and is being done and is making a difference to the lives of real patients 


Thank you Questions 


 18  Astronautical Congress Valencia, 2006 27  Bu reau  In tern atio n a l d e s Po ids et Mesures. \(2 008  August\SI Base Units. [On http://www.bipm.org/en/si/base_units   B IOGRAPHY  Author, Karl Strauss, has been employed by the Jet Propulsion Laboratory for over 22 years.  He has been in the Avionics Section from day One.  He is considered JPL\222s memory technology expert with projects ranging from hand-woven core memory \(for another employer\o high capacity solid state designs.  He managed the development of NASA\222s first Solid State Recorder, a DRAM-based 2 Gb design currently in use by the Cassini mission to Satu rn and the Chandra X-Ray observatory in Earth Orbit.  Karl was the founder, and seven-time chair of the IEEE NonVolatile Memory Technology Symposium, NVMTS, deciding that the various symposia conducted until then were too focused on one technology.  Karl is a Senior IEEE member and is active in the Nuclear and Plasma Scie nce Society, the Electron Device Society and the Aerospace Electronic Systems Society Karl is also an active member of SAE Karl thanks his wonderful wife of 28 years, Janet, for raising a spectacular family: three sons, Justin, Jeremy Jonathan.  Karl\222s passion is trains and is developing a model railroad based upon a four-day rail journey across Australia\222s Northern Outback   


 19 Bollobs, B. 2001. Random Graphs. Cambridge University Press; 2nd edition. 500pp  Cawley, G. C., B. L. C. Talbot, G. J. Janacek, and M. W Peck. 2006. Sparse Bayesian Ke rnel Survival Analysis for Modeling the Growth Domain of Microbial Pathogens  Chiang C. L. 1960. A stochastic study of life tables and its applications: I. Probability distribution of the biometric functions. Biometrics, 16:618-635  Cox,  D. R. 1972. Regression models and life tables J. R Stat. Soc. Ser. B 34:184-220  Cox, D. R. 1975.   Partial likelihood Biometrika 62:269276  Cox, D. R. & D. Oakes. 1984 Analysis of Survival Data  Chapman & Hall. London  Cressie, N. A. 1993 Statistics for Spatial Data John Wiley Sons. 900pp  Duchesne, T. 2005. Regression models for reliability given the usage accumulation history. In "Modern Statistical and Mathematical Methods in Reliability". Edited by A. Wilson N. Limnios, S. Kelly-McNulty Y. Armijo. pp.29-40. World Scientific, New Jersey  Eleuteri, A., R. Tagliaferri, L. Milano, G. Sansone, D D'Agostino, S. De Placido,  M. Laurentiis. 2003.  Survival analysis and neural networks. Proceedings of the International Joint Conference on Neural Networks, Vol. 4 20-24 July 2003 Page\(s\:2631 - 2636  Ellison, E., L. Linger, and M Longstaff. 1997.  Survivable Network Systems: An Emerging Discipline, Carnegie Mellon, SEI, Technical Report CMU/SEI-97-TR-013, 1997  Fleming, T. R. & D. P. Harrington. 1991. Counting process and survival analysis. John Wiley & Sons. 429pp  Graver, J. and M. Sobel 2005. You may rely on the Reliability Polynomial for much more than you might think Communications in Statistics: Theory and Methods  34\(6\1411-1422  Graves, T. and M. Hamada. 2005. Bayesian methods for assessing system reliability: models and computation. In Modern Statistical and Mathematical Methods in Reliability". Edited by A. Wilson, et al. pp.41-53  Grimmett, G. 2006 The Random-Cluster Model Springer  Grimmett, G. 1999 Percolation Springer  Hougaard, P. 2000. Analysis of Multivariate Survival Data Springer. 560pp  Ibrahim, J. G., M. H. Chen and D. Sinha. 2005. Bayesian Survival Analysis.  Springer. 481pp  Jin Z. 2005. Non-proportional semi-parametric regression models for censored data. In "Modern Statistical and Mathematical Methods in Reliability". Edited by A. Wilson N. Limnios, S. Kelly-McNulty, Y. Armijo. pp.279-292 World Scientific  Kalbfleisch, J. D. & R. L. Prentice. 1980 The Statistical Analysis of Failure Time Data John Wiley & Sons.  New York. 1980  Kalbfleisch, J. D. &  R. L. Prentice, 2002. The Statistical Analysis of Failure Time Data.  Wiley-InterScience, 2nd ed 462pp  Lisboa, P. J. G. and H. Wong. 2001. Are neural networks best used to help logistic regression? Proceedings of International Joint Conference on Neural Networks, IJCNN 01. Volume 4, 15-19,  July 2001. Page\(s\:2472 - 2477 vol.4  Kauffman, R. J. and B. Wang. 2002. Duration in the Digital Economy. Proceedings of th e 36th Hawaii International Conference on System Sciences \(HICSS03\ Jan 2003  Kaplan, E. L. & P.  Meier.  1958.  Nonparametric estimation from incomplete observations J. Amer. Statist. Assoc  53:457-481  Klein, J. P. and P. K. Goel 1992. Survival Analysis: State of the Art.  Kluwer Academic Publishes. 450pp  Klein, J. P. and  M. L Moeschberger. 20 03. Survival analysis techniques for ce nsored and truncated data Springer  Krings, A. and Z. S. Ma. 2006.  "Fault-Models in Wireless Communication: Towards Survivable Ad Hoc Networks MILCOM 2006, Military Communications Conference, 2325 October, 7 pages, 2006  Krings, A. W. 2008.  Survivable Systems.  in Information Assurance: Dependability and Security in Networked Systems Yi Qian, James Joshi, David Tipper, and Prashant Krishnamurthy, Morgan Kaufmann Publishers. \(in press  Lawless, J. F. 1982. Statistical models and methods for lifetime data.  John Wiley & Sons. 579pp  Lawless, J. F. 2003. Statistical models and methods for lifetime data.  John Wiley & Sons. 2nd ed. 630pp  Li, M. and P. Vitanyi. 1997. Introduction to  Kolmogorov Complexity and Its Applications. 2nd ed, Springer  Ma, Z. S. 1997.  Survival analysis and demography of Russian wheat aphid populations.  Ph.D dissertation, 307pp University of Idaho Moscow, Idaho, USA 


 20 Ma, Z. S., and E. J. Bechinski. 2008.  Developmental and Phenological Modeling of Russian Wheat Aphid Annals of Entomological Soc. Am In press  Ma, Z. S. and A. W. Krings. 2008a. The Competing Risks Analysis Approach to Reliability Survivability, and Prognostics and Health Management.  The 2008 IEEEAIAA AeroSpace Conference. BigSky, Montana, March 18, 2008. \(In Press, in the same volume  Ma, Z. S. and A. W. Krings 2008b. Multivariate Survival Analysis \(I\e Shared Frailty Approaches to Reliability and Dependence Modeling. The 2008 IEEE-AIAA AeroSpace Conference. BigSky Montana, March 1-8, 2008 In Press, in the same volume  Ma, Z. S. and A. W. Krings. 2008c. Multivariate Survival Analysis \(II\ Multi-State Models in Biomedicine and Engineering Reliability. 2008 IEEE International Conference on Biomedical Engineering and Informatics BMEI 2008\27th-30th, 2008 Accepted   Mani, R., J. Drew, A. Betz, P. Datta. 1999. Statistics and Data Mining Techniques for Lifetime Value Modeling ACM Conf. on Knowledge Discovery and Data Mining  Mazzuchi, T. A., R Soyer., and R. V Spring. 1989. The proportional hazards model in reliability. IEEE Proceedings of Annual Reliability and Maintainability Symposium pp.252-256  Meeker, W. Q. and L. A. Escobar. 1998. Statistical Methods for Reliability Data. Wiley-Interscience  Munson, J. C. 2003. Software Engineering Measurement Auerbach Publications  Nelson, W. 1969. Hazard plotting for incomplete failure data J. Qual. Tech 1:27-52  Nakagawa, T. 2006.  Shock and Damage Models in Reliability Theory. Springer  Osborn, B. 2005. Leveraging remote diagnostics data for predictive maintenance.   In "Modern Statistical and Mathematical Methods in Reliability". Edited by A. Wilson N. Limnios, S. Kelly-McNulty, Y. Armijo. pp. 353-363  Pena, E. A. and E. H. Slate. 2005. Dynamic modeling in reliability and survival analysis. In "Modern Statistical and Mathematical Methods in Reliability". Edited by A. Wilson N. Limnios, S. Kelly-McNulty, Y. Armijo. pp.55-71  Reineke, D. M., E. A. Pohl, and W. P. Murdock. 1998 Survival analysis and maintenance policies for a series system, with highly censore d data.  1998 Proceedings Annual Reliability and Maintainability Symposium. pp 182-188  Schabenberger, O. and C. A. Gotway. 2005. Statistical Methods for Spatial Data Analysis.  Chapman & Hall/CRC  Severini, T. A. 2000. Likelihood methods in statistics Oxford University Press  Shooman, M. L. 2002. Reliability of Computer Systems and Networks: Fault Tolerance, Analysis and Design. John Wiley and Sons. 551pp  Stillman, R. H. and M. S. Mack isack, B. Sharp, and C. Lee 1995. Case studies in survival analysis of overhead line components. IEE Conferen ce of the Reliability and Distribution Equipment. March 29-31, 1995. Conference Publication No. 406. pp210-215  Therneau, T. and P. Grambsch. 2000 Modeling Survival Data: Extending the Cox Model Springer  Wilson, A.  N. Limnios, S Kelly-McNulty, Y. Armijo 2005. Modern Statistical and Mathematical Methods in Reliability. World Scientific, New Jersey  Xie, M. 1991. Software Reliability Modeling. World Scientific Press    B IOGRAPHY   Zhanshan \(Sam\ Ma holds a Ph.D. in Entomology and is a Ph.D. candidate in Computer Science at the University of Idaho. He has published approximately 30 journal and 30 conference papers, mainly in the former field.  Prior to his recent return to academia, he worked as senior network/software engineers in software industry.  His current research interests include reliability and survivability of wireless sensor networks, fault tolerance survival analysis, evolutionary game theory, evolutionary computation and bioinformatics  Axel W. Krings is a professor of Computer Science at the University of Idaho.  He received his Ph.D. \(1993\ and M.S 1991\ degrees in Computer Science from the University of Nebraska - Lincoln, and his M.S. \(1982\ in Electrical Engineering from the FH-Aachen, Germany.  Dr. Krings has published extensively in the area of Computer Network Survivability, Security, Fault-Tolerance and Realtime Scheduling. In 2004/2005 he was a visiting professor at the Institut d'Informatique et Mathmatiques Appliques de Grenoble, at the Institut National Polytechnique de Grenoble, France.  His work has been funded by DoE/INL DoT/NIATT, DoD/OST and NIST 


