Key Issues of Security and Integrity in Third Party Association Rule Mining   Kamal K Sethi 1 D K Mishra 2 Gopal Solanki 3 Bharat Mishra 4   1 Patel College of Science & Technology, Indore, M.P., India 2 Acropolis Institute of Technology Research, Indore, M.P., India 3 Shri Raojibhai Gokalbhai Patel Gujarati Professional Institute, Indore, M.P., India 4 
Mahatma Gandhi Chitrakoot Gramoday Vi shwavidyalay, Chitrakoot, M.P., India  E-mail  1 kamalksethi@gmail.com 2 durgeshmishra@ieee.org 3 gopalmca2k@gmail.com 4 bm_cgv@rediffmail.com   ABSTRACT  Association rule mining discovers interesting association or correlations among a large set of data items. Association rule mining make decision making process easier by providing the important information to the user. The most of the work done in 
this field is concerned with mining in an isolated form, but it is not only the case and many times more than one parties are involved in this process. Data mining task may be done by third party as a service provider. The database is made available to service provider and he returns the computed association rule to the owner of the database. For example, number of companies dealing in same type of product or services, may work together to identify the cu rrent trends in the industry their customer. The organizations have to share the data information with their friend or competitor to identify the 
global trends. There are many situations where more than one parties involve in the data mining process.  In this situation we require security of data so that information stealing by the dishonest party from dataset can be stopped and integrity of result be ensured by stopping dishonest party to corrupt the result or process. In this paper, we have summarized the integrity & security issues related to association rule mining in third  party computation  Keywords Privacy Preserving Data Mining \(PPDM Third Party Data Mining, Sensitive Data Security 
Association Rule Mining  1. INTRODUCTION  Association rule mining is one of the most important frequently used and fundamental technique in data mining which discovers the association and correlation among the itemsets in large database. Now a day\222s data collection is huge and omnipresent in social and business areas. Many organizations are interested in association rule mining in collaborations to achieve joint benefits But doing so will leak some sensitive information. This should not happen and for the security of such information, application of privacy preserving association 
rules mining is compulsory  15 I n Associa t ion r u l e  mining databases are transactional database. In transactional database, each transaction represents set of items and these set of items are those items which customers purchase together. By this transactional database, we are interested to find out those set of items which are purchased by customers frequently. This helps the marketing department to design strategy, mainly to design of display layout with associated items placed together The format of an association rule is \223X 
Y\224 where X & Y are the itemsets. \223X Y\224 can be interpreted as presence of X itemset in a particular transaction implies the presence of Y itemset. The extraction of such association rules from transactional database is referred to as association rule mining. Association rule mining is a two step process, in the first step all set of frequent itemsets are identified, while in the second step association rules from the set of frequent itemsets can be extracted. First step is very expensive and has exponential time complexity. An algorithm named Apriori for finding set of frequent itemsets has been 
suggested by Agrawal and Shrikant  Mo st o f pr ev ious  researches focus on centralized case of mining, where mining task is performed by the database owner  I n  this paper we turn our attention from centralized model to distributed model, where mining procedure involves different parties other than the database owner. For association rule mining, the idea of third party mining can 337 
Second International Conference on Emerging Trends in Engineering and Te\chnology, ICETET-09 
978-0-7695-3884-6/09 $26.00 \251 2009 IEEE 


be used. By using this we can take the benefits of other service provider ability & emerging computing paradigm This offers technical and financial advantages over the traditional model of computing. A database owner, who uses cloud computing, sends its database to cloud service provider, which in turn returns the association rules for the database owner [14   There are various third party service providers who run distributed mining algorithms. These providers use the transactional database of different companies Suppose there are n malls, located different sites, all are interested to find out the global trends for better management of decision making process. The extraction of association rule in such environment is referred to as global association rule. When multiple parties are sharing their database to find out global association rules, there are few issues that needs to be considered. While sharing statistical information \(i\How this can be ensured that nobody has stolen such information. This is sometime referred as security issue in data mining 11   i i H o w  this can be ensured that the mining process is resulting accurate result [8 This i s som e tim e re fe rr ed a s  re sul t  integrity issues in mining In this paper we have discussed these two issues in next two sections. In first section we discussed security issues in distributed association rule mining and idea to handle dynamic updates securely. In section two integrity of result has been insured. Lastly the paper has been summarized with conclusion & proposed future work  2. RELATED WORK  In this paper the idea of security has been discussed cryptographically, in which the idea of substitution cipher and poly cipher has been used. Some other approaches of security are k-anonymity d da ta p er t urb at i on 5    n kanonym it y approa ch an a r r ang em ent of m ak i ng  each individual indistinguishable from a number of other individuals by generalization Data perturbation performs random modifications on original data. Both the approaches are not suitable in the sense that they carry loss of information when original data is recovered. Hence correctness in result is not guaranteed. Some task related to authentication between database owner and server side can be performed by using hash trees built on both the sides was proposed by Li et al   The l i m itat i on o f  thi s work is up  to query outputs not for association rule mining  3. SECURITY ISSUES IN INCREMENTAL ENVIRONMENT  Association rule mining is a two step process finding frequent itemsets and mining strong association rules from frequent itemsets. Cheung et al has proposed the model for distributed association rule mining  but they did not given solution for security concern in their work In non-distributed environment, a transactional database is required as a input from a single party, while in distributed environment many parties are involved and each party holds a similar type of database. These parties are cooperating together to find out the global association rule. The working of this environment is based on that each party is sharing set of frequent itemsets and then global association rules are mined. If we see this situation in reference to security, the sharing of information of frequent itemsets in this way in distributed environment is problematic. Solution to this problem is suggested by Kantarcioglu et al in his work of Privacy-preserving distributed mining of association rules  The algorithm suggested by him computes the global association rules with the guarantee that each party can only observe its database and mining result but can not observe other sensitive information. The problem of maintenance has not been considered by him. Whenever there are some updations to the database, whole work requires to be repeated and model to handle this problem is suggested by Wong et al [11  In distributed environment there would be an open welcome to join new parties with there own database, causing updation in the association rules Suppose at any instance of time t 1   m parties are working in the distributed environment and as a result we get R 1 and R 2 R 1 represents set of globally frequent itemsets and R 2 represents sets of supported association rules Suppose some new parties join with m parties, causing total n parties to work with, in some next instance of time Now R 1 and R 2 are useless. Joining of new parties require new results say R\222 1 and R\222 2 where R\222 1 represents set of new globally frequent itemsets and  R\222 2 represents set of new supported association rules. The support of itemsets are treated as sensitive information and are required to be kept secret from all the parties To keep sensitive information secret, requirement of privacy preserving techniques is strongly recommended. R\222 1 and R\222 2 can not be achieved easily without the information of old support count , because the old parties has to recompute the supports every time. So we are required to develop a technique which can store 338 


supports of frequent itemsets and finally remembered supports can be used securely and efficiently  One of the way to store an itemset x securely, is using two parties say p i and p j p i holds \(x + r\ mod m and p j hold r, where m is randomly generated. The values that p i and p j hold, can not be distinguished from random number and in this way security of sensitive information is ensured. When we are going to update, the x can be recovered from these two parties. For privacy issue of association rules mining  a secure frequent-pattern tree FP-tree\ based schemes [12 Sec ur e Se t Union  algorithm can also be used for securing the secret information.[13 Whe n ne w part ies a r e g o ing to be ad ded  updation of set of frequent itemsets can be generated in two routines a. If support of some itemset is going to be increased than the updated support count can be calculated from the following formula  Updated support count = old support count + new support count of same itemset  b New itemsets are going to frequent after adding new parties  Cheung has shown in his work that a globally frequent itemset can not be both infrequent in the old parties as well as in the new parties [2 S o  f i rs t new  itemset is checked in new parties, if it is frequent then it will be checked in old parties and finally overall support is calculated, otherwise itemset can not be in final result While performing Updation, new parties learn the old result, needs to be hidden. Two routing of updation can be described by applying some sequence of steps. First of all we define some atomic steps  1  Computation of supports in new parties 2  Computation of overall support 3  Compare support to threshold 4  Compute supports in old parties routine \(1\ can be defined as 1 2 3 and routine \(2 as 1 3 4 2 3. 4 2 3 is done only in old parties nothing is performed by new parties So both the procedure can be represented in single procedure by 1 2 3 4 2 3 Hence updates can be performed without using the sensitive information in its original form   4. THIRD PARTY COMPUTATION  When the issue of mining association rules via third party i.e. service provider comes, then privacy of parties become great concerns. Two common issues are automatically reflected a. Stealing the information \(data security problem\t performing the mining tasks properly \(result integrity problem\though, if these two are not the cases with third party service providers, then this offers the database owners the benefits of cost relief and use of minimal resources. Following we discuss these two issues in detail  4.1 Security Issues in Third Party Computation  The information can be stolen by third parties, when it looks for him to be interested. As we know that input for algorithm is transactional database. If transactional database is using actual names of items, for example, say a transaction t i bread, butter}, then the necessary information can be understood by third parties and can be stolen by them. Beside this if we use encrypted codes for such items then the securities of information can be achieved up to a certain extent. For example, a transaction {bread, butter} for database owner, can be I 55 I 63 for third party. Here bread item is replaced by I 55  and butter is replaced by I 63 We call this idea to replace an item by a unique symbol as one-to-one mapping. This is similar to the principle of substitution cipher, in which each letter of text is replaced by another character. By the drawback of this scheme is known to be vulnerable to frequency analysis. Similarly the one-to-one mapping of items vulnerable to frequency analysis. If the supports of itemsets are given, we are able to recover the original database. Also one to one mapping leaks statistical information, like the number of frequent itemsets. So we needs to develop a more secure scheme. One idea is oneto-n mapping, in this, say item milk can be mapped to I 51 I 88 I 96 I 101 doing so will affect the frequency outputs of itemsets. Mapping of item names to unique symbol in this process is referred to as encryption Decryption, mapping of symbols to their names, should be performed unambiguously and for this item must associated with one unique symbol has suggested by Wong et al  I t em codes are fo r th ird pa rt ie s, w h il e  names are for database owners. Besides this transformation, some fake items can also be used in transformed database, to make security tight  4.2 Integrity Issues in Th ird Party Computation  The problem of integrity can be solved by the idea of using audit environment suggested by Wong et al [8  Basically an audit environment consists of two parts. Part 1, consists a set of transformational methods, through which original database is transformed and sent to the service providers. The output from service provider is the 339 


mined result say R. While part 2 consists again two parts i\et of verification methods \(ii\iliary data that consist the process of verification. Here it should be noted that audit environment is in itself a complete system The techniques of database transformation and verification are referred to as artificial itemset planning AIP\is the AIP, through which it is guaranteed that incorrect or incomplete mining results have been returned by service providers. Correctness guarantee can be achieved by the logic described below i  suppose some set of itemsets are given say FI\222. Through AIP an artificial database T\222 is constructed, such that all itemsets in FI\222 are frequent and their exact supports are known ii  Besides just sending T\222 as input to third party service provider, we send T+T\222 as input T+T\222 can be performed by just appending the transaction of T\222 with T, called it W iii  Service provider now mines W and generates an output say R. This R consists FI +FI\222 iv  As we know FI\222 earlier, then FI\222 generated by miner is checked with FI\222 known earlier v  If FI\222 generated by miner is incorrect or incomplete, and then there is a high guarantee of being FI, incomplete or incorrect So just by verifying FI\222, we are able to guarantee whether the integrity of result is enforced or not  5. CONCLUSION AND FUTURE WORK  In this paper an abstract idea of security and integrity issues, while working in distributed environment has been demonstrated. In future different techniques and algorithm will be our interest to discuss. Similar idea will be discussed for some other major technique of data mining like clustering, etc. How authentication will be achieved between database owner and third party will also be a work of future interest  REFERENCES  1  R. Agrawal, T. Imielinski, and A. Swami. Mining association rules between sets of items in large databases. In SIGMOD, 1993 2  D. W. Cheung, V. Ng, A. W. Fu, and Y. Fu. Efficient mining of association rules in distributed databases In Special Issue in Data Mining, IEEE Transaction on Knowledge and Data Engineering, IEEE Computer Society, Vol 8, No 6, Dec 1996 3  W. K. Wong, D. W. Cheung, E. Hung, B. Kao, and N Mamoulis. Security in outsourcing of association rule mining. In VLDB, 2007 4  R. Agrawal and R. Srikant. Fast algorithms for mining association rules. In VLDB, 1994 5  R. Agrawal and R. Srikant. Privacy-preserving data mining. In SIGMOD, 2000 6  M. Kantarcioglu and C. Clifton. Privacy-preserving distributed mining of association rules on horizontally partitioned data. In IEEE Trans Knowledge Data Eng., Vol 16 No 4, July 2004 7  Y. Cui, W. K. Wong, and D. W. Cheung. Privacypreserving clustering with high accuracy and low time complexity. In DASFAA, 2009 8  W. K. Wong, D. W. Cheung, E. Hung, B. Kao, and N Mamoulis. An audit environment for outsourcing of frequent itemset mining. PVLDB, Vol. 2, No 1, 2009 9  F. Li, M. Hadjieleftheriou, G. Kollios, and L. Reyzin Dynamic authenticated index structures for outsourced databases. In SIGMOD, 2007 10  L. Sweeney. k-anonymity: A model for protecting privacy. In International Journal on Uncertainty Fuzziness and Knowledge-based Systems, 2004 11  W. K. Wong, D. W. Cheung, E. Hung, and H. Liu Protecting privacy in incremental maintenance for distributed association rule mining. In PAKDD, 2008 12  C. Tang, Su. Chunhua and Sa. Kouichi. A Distributed Privacy-Preserving Association Rules Mining Scheme Using Frequent-Pattern Tree,In ADMA 2008 13  W. Jing, L. Huang, Y. Luo, W. Xu  and Y. Yao. An Algorithm for Privacy-Preserving Quantitative Association Rules Mining. In Proceedings of the 2nd IEEE International Symposium on Dependable Autonomic and Secure Computing, 2006 14  W. K. Wong and W. Cheung. Security and Integrity of Association Rule Mining, In ACM-HK, 2009 15  J. Liu , X. Piao and S. Huang.  A Privacy-Preserving Mining Algorithm of Association Rules in Distributed Databases. In  IMSCCS, Vol 2, 2006  340 


 GAR H  S  s l1  s l 2   c l  Input: H   a hierarchy concept for every attribute S  U  A  V an information system, where U are objects A are attributes, and V are their values s l1   threshold for a minimum Right Support at level l s l2   threshold for a minimum Left Support at level l c l   threshold for a minimum Confidence at level l  Step 1 Find the frequent generalized closed factor-sets: the sets of factors that have minimum left and right supports at highest level Step 1.1 Find the domain of each concept at level l and its support count above the predefined s l1 or s l2  AV  Get all distinct attribute-concept-value pairs for all attribute-concept-value pair  a,v  do begin HD  A, CV, L, D\:=Get domain of each concept value CV – concept value, L – Level value, 1, 2, 3,…., D – domain While L 007 1 do For each concept value If Card\(HD  min \(s l1 s l2    qualified attribute-value pairs  a, v  distinctValueQueue  006  a,v   end if end for end while end for Step 1.2 Find the frequent generalized closed factor-set Step 1.2.1 1-factor-sets N:= Get all elements at level  1 from distinctValueQueue M:= Get all elements at level  1 from distinctValueQueue while subLevelDistinctValueQueue changed do  for each attribute-value pair  a n v n  do For each attribute-value pair  a m v m  do If  a n  a m  AtomicFactor  a l  v n 005 v m   If  supL  AtomicFactor  012 s l1 supR  AtomicFactor  012 s l2  atomicFactorQueue 006  AtomicFactor  subLevelDistinctValueQueue 006 subLevelDistinctValue  end if end if end for N:= Get all elements from subLevelDistinctValueQueue M:= Get all elements from subLevelDistinctValueQueue end for end while  Step 1.2.2 2-factor-sets F:= Get all atomic factors  from atomicFactorQueue every factor denotes as f=\(a, v 005 v n:= F.size         // the total number of primitive factors in F for  i:=0; i++; i>n  do for  j  i+1  j++; j>n  do if  f i a 007 f j a  newCandidate  f i 015 f j  if \( supL  newCandidate  s 11  supR  newCandidate  s 12  add this new factor-set into the frequent factor-set queue and mark its length with 2 frequentFactorQueue 006  newCandidate    end if end if end for end for Step 1.2.3 Find the frequent k factor-sets, where k 2.  This step is iteratively generating new k factor-sets using the frequent \(k1\ctor-sets found in the previous iteration until there are no new frequent factor-sets generated P:=Get all frequent  k 1  factor-sets from frequentFactorQueue n:= the total number of \(k-1\-factor-sets  in P For  i:=0; i++; i>n  do If the first \(k-2\ factors are identical in f i and f j newCandidate  f i 015 f j  If \( supL  newCandidate  s 1 supR  newCandidate  s 2  If all subsets of newCandidate 023 frequentFactorQueue add this new factor-set into the frequent factor-set queue and mark its length with k frequentFactorQueue 006  newCandidate  end if end if end if end for Step 1.2.4 F max get all frequent factor-sets f with max Length from frequentFactorQueue maxLength:= the length of a factor-set in F max CompactFactorQueue  006 F k for  i   maxLength-1  i- -, i  1  do F i get all frequent factor-sets f’ with length i from frequentFactorQueue for each f’ in F i do if f  supL > max  010 f.supL in F i+1  if f  supR > max  010 f.supR in F i+1   CompactFactorQueue  006 f  end if end if end for end for Step 2. Generate strong Rules having the confidence above c  For each frequent factor-set f in frequentFactorQueue do n := f.length //the length of the frequent factor-set EQ for elementQueque EQ:= Parse the factor-set into factors and store each factor with level of 999 for the length of  the premise i from 1 to n-1 get next available premise for all factors in EQ Consequence  f- premise.factor   end for ruleCandidate  premise 000 Consequence  if \(conf\(ruleCandidate  012 c add rule the output and place a positive mark results 006 ruleCandidate mark EQ.level with level i //place a Positive mark end if end for end for print all Reclassification rules from result Figure 2. Pseudo-code of algorithm GAR 
2008 
2020 


5. Generalized Reclassification Rules Authors in [15  n tro d u ce h i erarch y  tax o n o m y  into association rule mining to identify more interesting rules and their results show promise. In this paper, we also studied generalization in mining, but used a different mining paradigm, actionable rule mining.  We developed a similar approach, called Generalized Actionable Rules \(GAR\, in order to find a concise set of reclassification rules.  The algorithm GAR is a breadth-first approach to mining a set of all frequent generalized closed factor-sets within concept hierarchies from top to lower level abstraction and then constructs reclassification rules straightforward by partitioning the valid factor-sets into a IF-THEN representation A generalized closed factor-set 000 G in S is defined as 000 G  a 1  013 1 005 014 1  015  a 2  013 2 005\014 2  015  015  a p  013 p 005\014 p  iff 000 G 023 000 and none of its factors is the ancestor factor of others A frequent generalized closed factor-set 022 G is defined as 022 G  a 1  013 1 005 014 1  015  a 2  013 2 005\014 2  015  015  a p  013 p 005\014 p  is a frequent generalized closed factor-set at level l iff 022 G 023 000 G  supL 022 G  012 s l1 and supR 022 G  012 s l2 where s l1 and s l2 are the user specified minimum left support  and minimum right support thresholds at level l respectively If a factor occurs rarely, its descendants will be even less frequent. For finding generalized actionable rules, different minimum left support right support, and confidence thresholds can be specified at different levels.   By doing this, if users want to find actionable rules at relatively lower levels of abstraction, the minimum left and right supports can be set relatively low without compromise, generating many valid uninteresting rules at higher or intermediate levels A generalized reclassification rule 000U G in S is defined as a statement 000U G  000 000 000<\000\017\000\003\000\017 where 000  000<\000\017\000\003 003\022 G  000 007 000<\000\017  000 016 000<\000\017\000\003  017 and no factor-set in 000 is an ancestor of any factor-set in 000 in the concept hierarchy Algorithm GAR consists of two main steps: \(1 generate all frequent generalized closed factor-sets, \(2 generate strong generalized reclassification rules Below is the short description of the algorithm and the pseudo-code of GAR is presented in Figure 2 5.1 Generate all Frequent Generalized Closed Factor-Sets  This step computes the frequent factor-sets in the data set through several iterations and the breadth-first top-downward approach is utilized. In each iteration we generate new candidates from frequent generalized closed factor-sets found in the previous iteration; the left support and right support for each candidate is then computed and tested against the user-specified thresholds for that level.  It examines the highest top level of abstraction to generate frequent closed factorsets and then progresses deeper into their frequent descendants at lower concept levels. The lower level concepts will be evaluated only when its ancestor has large left and right supports at the corresponding upper level.  End users have the power to gradually decrease the minimum left and right support thresholds at lower levels of abstraction in order to discover rules at different levels 5.2 Generate Generalized Rules  A reclassification rule is extracted by partitioning the factor-set W into two non-empty subsets X and Y and represented as X 000 Y where X, Y 023 W  X, Y 024 F S and X  W Y A level-wise approach is utilized for generating rules, where each level corresponds to the number of factors belonging to the rule premise The rule-premise is extended one factor at a time.  It starts with one factor on the rule-premise, such as X If the rule confidence is above the predetermined threshold, it is called a strong rule and marked with a positive mark  The principle of minimum description length is also adopted to identify the general rules.  Therefore, in the next iteration, it generates new candidates from only unmarked rules found in the previous iteration by moving one of the consequence-type factors to the rule premise, now X is a 2-factor-set.  Repeat the previous step until there is only one flexible factor on the rule consequent, such as Y By doing this, the resulting set of rules is comprised of those with the shortest length of premise, not all the lengths 
2009 
2021 


6.   Conclusion This paper addressed the problem of discovering generalized actionable rules in a dataset.   We investigated the properties of Reclassification Rules presented the notions of generalized closed factor-sets generalized reclassification rules, and introduced algorithm GAR This new algorithm is based on the concept of frequent generalized closed factor-sets to generate a very concise set of rules. The proposed framework provides more generalized knowledge from data than previous existing methods by incorporating concept hierarchy into mining procedure.  In addition the quality of the extracted rules in terms of their interestingness and understandability is improved Therefore, it would be easier for the user to comprehend the rule result in a timely manner.   In the future, we intend to apply this approach to a large variety of databases and application domains 7. References 1 A grawal R   Imiel i n s ki  T an d  S w ami, A M i n i n g  association rules between sets of items in large databases. In Proceedings of the ACM SIGMOD International Conference on the Management of Data. P. Buneman and S. Jajodia, Eds ACM Press, Washington DC, 1993, pp. 207–216   B e ne dit t o  M  E M  D  a nd Ba r r o s L  N d Us ing  Concept Hierarchies in Knowledge Discovery. A.L.C Bazzan and S. Labidi \(Eds.\: SBIA 2004, LNAI 3171, pp 255–265, 2004. Springer-Verlag Berlin Heidelberg 2004   G r z y m a l a B us se   J  A ne w v e r s i on of the r u le induc t i on system LERS. In: Fundamenta Informaticae, 31\(1\, 1997, pp 27-39  Ha n  J  Ca i  Y   and Ce r c one  N  Da t a D ri v e n D i s c ov e r y  of Quantitative Rules in Relational Databases. In: IEEE Trans. Knowledge and Data Eng., vol. 5, pp. 29-40, 1993   Ha n J   a nd Fu Y   D i s c ov e r y  of  m u lt ipl e l e v e l  association rules from large databases. In Proc. of the 21st Int'l Conference on Very Large Databases Zurich Switzerland, September 1995  H e  Z  Xu, X  a nd De ng  S  M i ning  Cl us te r D e f i ning  Actionable Rules. In: Proceedings of NDBC’04, 2 004   H e Z X u X  D e ng S a nd M a R  M i ning A c t i on Rules From Scratch. Expert Systems with Applications. Vol 29, No. 3, 691--699 \(2005   I m S and R a 001\036 Z.W.: Action Rule Extraction from a Decision Table: ARED.  In: 17th International Symposium on Methodologies for Intelligent Systems \(ISMIS\, pp 160—168. Springer,  Toronto, Canada \(2008 9 i n g  C  X Che n T  Y a ng Q a nd Che n   J  M i ni ng  Optimal Actions for Intelligent CRM. In: 2002 IEEE International Conference on Data Mining, pp.767--770 IEEE Computer Society, Maebashi City, Japan \(2002 9 i u B   H s u  W   a nd M a  Y    I d e n ti f y ing  Nona c t i ona ble  Association Rules. In: Proceedings of KDD 2001, pp. 329-334. San Francisco, CA, USA \(2001  a s quie r N    B a st i d e Y T a oui l R a nd L a k h a l   L    Discovering Frequent Closed Itemsets for Association Rules In: the 7th international conference on database theory ICDT’99\ pp 398--416, Jerusalem, Israel \(1999 11 P a wlak Z   In f o r m at io n S y st em s   Th eo ret i ca l Foundations. Information Systems Journal. Vol. 6, pp. 205-218 \(1981  i a t e s k y S ha pi ro G   a nd M a t h eu s C   J    T h e  interestingness of deviations. In: Proceedings of AAA Workshop on Knowledge Discovery in Database, pp. 25--36 AAAI Press, Menlo Park, CA \(1994  n la n J   R  C4.5: program for machine learning  Morgan Kaufmann, 1992  m a k r i s hns n  S  a nd R a k e s h  A    M i ni ng G e ne ra l i z e d  Association Rules. In: Proceedings of ICDM’03, pp 685688. IEEE Computer Society, Florida, USA \(2003  a 001\036 Z.W. and Tsay, L.-S.: Discovering Extended Action-Rules \(System DEAR\. In: Proceedings of the IIS'2003 Symposium, Advances in Soft Computing, pp. 293300. Springer, Zakopane, Poland \(2003  001\036 Z.W. and Wieczorkowska, A.: Action Rules: How to Increase Profit of a Company. In: Principles of Data Mining and Knowledge Discovery, Proceedings of PKDD'00, LNAI, pp. 587-592. Springer, Lyon, France 2000  T s a y L  S a nd Ra 001\036 Z.W.: Action Rules Discovery System DEAR2, Method and Experiments. Journal of Experimental and Theoretical Artificial Intelligence, Vol. 17 No. 1-2, pp. 119-128. Taylor and Francis \(2005  s a y L  S a nd Ra 001\036 Z.W.: E-Action Rules. In: Lin T.Y., Xie, Y., Wasilewska, A., and Liau, C.-J. \(eds Foundations of Data Mining, Studies in Computational Intelligence, pp. 261--272. Springer, Berlin / Heidelberg 2007  s ay   L  S a nd Ra 001\036 Z.W.: Discovering the Concise Set of Actionable Patterns. In: 17th International Symposium on Methodologies for Intelligent Systems \(ISMIS\ LNAI, Vol 4994, pp. 169--178. Springer \(2008 20  Tsay  L  S   R as  Z  W   an d Im, S   Re class i ficat io n  Rules. In: IEEE/ICDM Workshop on Foundations of Data 
2010 
2022 


Mining \(FDM 2008\, pp. 619--627. IEEE Computer Society Pisa, Italy \(2008  T s a y L  S   a nd I m   S    M i ni ng NonRe dunda nt Reclassification Rules.  In: Proceedings of the Twenty Second International Conference on Industrial, Engineering Other Applications of Applied Intelligent Systems IEA/AIE'09\, Tainan, Taiwan, June 24-27, 2009, 806-815  W ong R  C  W a nd Fu A   W  C    I S M   It e m  Se le c t ion for Marketing with Cross-selling Considerations. In the Eighth Pacific-Asia Conference on Knowledge Discovery and Data Mining \(PAKDD  pp. 431--440. Sydney, Australia 2004  ng Q Yi n  J   L i n  C  X   a nd C h e n  T     Postprocessing Decision Trees to Extract Actionable Knowledge. In Proceedings of ICDM’03, pp 685-688 IEEE Computer Society, Florida, USA \(2003  Z h a n g   H  Zha o Y  C a o, L  a nd Zha n g   C    C o m b i n e d  Association Rule Mining. In: Advances in Knowledge Discovery and Data Mining, Proceedings of the PAKDD Conference, Lecture Notes in Computer Science, 5012, pp 1069-1074. Springer, Antwerp, Belgium \(2008  n g  T  Ra m a k r i s hna n, R a nd L i v n y  M   B I R C H  An efficient data clustering method for very large databases In: Proceedings of ACM SIGMOD Conference, Montreal Canada, pp. 103–114 
2011 
2023 


