Distributed Conìdence-Weighted Classiìcation on MapReduce Nemanja Djuric Temple University Philadelphia PA USA nemanja.djuric@temple.edu Mihajlo Grbovic Yahoo Labs Sunnyvale CA USA mihajlo@yahoo-inc.com Slobodan Vucetic Temple University Philadelphia PA USA vucetic@temple.edu Abstract Explosive growth in data size data complexity and data rates triggered by emergence of high-throughput technologies such as remote sensing crowd-sourcing social networks or computational advertising in recent years has led to an increasing availability of data sets of unprecedented scales with billions of high-dimensional data examples stored on hundreds of terabytes of memory In order to make use of this large-scale data and extract useful knowledge researchers in machine learning and data mining communities are faced with numerous challenges since the classiìcation algorithms designed for standard desktop computers are not capable of addressing these problems due to memory and time constraints As a result there exists an evident need for development of novel more scalable algorithms that can handle large data sets In this paper we propose such method named AROWMR a linear SVM solver for efìcient training of recently proposed conìdence-weighted CW classiìers Linear CW models maintain a Gaussian distribution over parameter vectors thus allowing a user to estimate in addition to separating hyperplane between two classes parameter conìdence as well The proposed method employs MapReduce framework to train CW classiìer in a distributed way obtaining signiìcant improvements in both training time and accuracy This is achieved through training of local CW classiìers on each mapper followed by optimally combining local classiìers on the reducer to obtain aggregated more accurate CW linear model We validated the proposed algorithm on synthetic data and further showed that AROW-MR algorithm outperforms the baseline classiìers on an industrial large-scale task of Ad Latency prediction with nearly one billion examples Keywords conìdence-weighted classiìcation MapReduce I I NTRODUCTION Recent advent of high-throughput applications which generate data sets that can easily reach terabytes in size such as remote sensing crowd-sourcing high-energy physics social networks or computational advertising has brought forward a clear need for computational approaches that can efìciently learn from Big Data problems 2 3 Emerging conferences that speciìcally address the Big Data issues as well as the number of recent publications related to large-scale tasks underline the signiìcance of the Big Data eld Moreover recently introduced Big Data Research and Development Initiative by the United States government aimed at providing support for these efforts clearly indicates globally-recognized strategic importance as well as future potential and impact of Big Data-related research With the emergence of extremely large-scale data sets researchers in machine learning and data mining communities are faced with numerous challenges related to the sheer size of the problems at hand as many well-established classiìcation and regression approaches were not designed and are not suitable for such memoryand time-intensive tasks The inadequacy of standard machine learning tools in this new setting has led to investment of signiìcant research efforts into the development of novel methods that can address such challenges Classiìcation tasks are of particular interest as the problem of classifying input data examples into one of nite number of classes can be found in many areas of machine learning However state-of-the-art non-linear classiìcation methods such as Support Vector Machines SVMs are not applicable to truly big data due to v ery high time and memory overhead which are in general superlinear and linear in the data size N  respectively signiìcantly limiting their use when solving large-scale problems Several methods have been proposed to make SVMs more scalable ranging from algorithmic speed-ups 7 8 9 10  to parallelization approaches 12 13 14 Ho we v e r  scalability of SVM training is inherently limited as nonlinear SVMs are characterized by linear growth of model size with training data size N  This led to an increased interest in linear SVM models 17 18 19 20 which have constant memory and O  N  training time These linear models provide a scalable alternative to non-linear SVMs albeit with a certain drop in prediction accuracy Unfortunately even linear time complexity may not be sufìciently efìcient for modern data sets stored across petabytes of memory space requiring researchers to develop and adopt new machine learning approaches in order to address extremely large-scale classiìcation tasks Signiìcant research efforts culminated in several highly-inîuential frameworks for solving parallelizable problems that involve data sets which can not be loaded on a single machine These frameworks for parallel computations include MapReduce  22 AllReduce 23 GraphLab 24 25 Pre gel  and others MapReduce in particular has become v ery popular framework in industry with major companies such as Yahoo Google and Facebook spearheading its use in large-scale commercial systems 28 2013 IEEE International Conference on Big Data 978-1-4799-1293-3/13/$31.00 ©2013 IEEE 458 


Unlike other distributed frameworks that assume frequent communication and shared memory between the computation nodes e.g 24 MapReduce frame w ork and its open-source implementation called Hadoop allows limited communication overhead between the nodes which results in very strong fault-tolerance and guaranteed consistency These favorable properties of MapReduce led to development of parallelizable variants of popular machine learning algorithms such as k means perceptron logistic regression PCA and others 30 31 32 Ho we v e r  the proposed classiìcation methods mostly rely on iterative training and two-way communication between the computation nodes 32 This may impose signiìcant costs during training as it does not closely follow the computational paradigm of MapReduce which derives its reliability from the high level of autonomy of computation nodes In this paper we describe an efìcient linear SVM learner with sub-linear training time capable of fully employing the MapReduce framework to signiìcantly speed up the training The algorithm uses recently proposed Conìdence-Weighted CW linear classiìers 34 to train a number of SVM models on each of the mappers Following completion of the map step the local CW models are sent to the reducer that optimally combines local classiìers to obtain a single model more accurate than any of the individual ones Compared to the CW algorithms the proposed method named AROW-MapReduce AROW-MR allows signiìcantly more efìcient training of accurate SVMs on extremely large data sets due to the distributed training We validate our approach on real-world large-scale problem of Ad Latency prediction with nearly one billion data examples where AROW-MR achieved higher accuracy and faster training than the baseline approaches The paper is organized as follows In Section II we describe the Conìdence-Weighted classiìers shown to achieve state-of-the-art performance on a number of real-world applications In Section III we overview popular frameworks for distributed learning MapReduce and AllReduce Then in Section IV we describe the proposed algorithm a distributed variant of CW classiìers which can be used to efìciently train highly accurate models on large-scale problems In Section V we validate our approach on synthetic data set and further show that the method outperforms the baseline approaches on real-world industrial data set from the computational advertising domain Lastly we give the concluding remarks in Section VI II C ONFIDENCE W EIGHTED C LASSIFICATION In this section we review the recently proposed conìdence-weighted classiìers We rst detail the CW algorithm proposed in follo wed by the description of Adaptive Regularization of Weights AROW algorithm from an impro v e d C W method sho wn to signiìcantly outperform the original CW algorithm First described in the CW algorithm is a linear classiìer that in addition to the prediction margin for the new data example also outputs probability of the correct classiìcation This is achieved by maintaining a multivariate Gaussian distribution over the separating hyperplanes and during the training procedure both mean  and covariance matrix  of the distribution are learned In this way a more expressive and informative model is found giving us information about noise in each of the individual features as well as about the relationship between features Let us assume that a trained CW model with known mean vector  and covariance matrix   is given Then for an example  x y  from data set D  described by feature vector x and binary label y  1  1   this induces a Gaussian distribution over the prediction margin  y as follows  y N  y   T x   x T  x   1 Following 1 we can compute the probability of correct classiìcation by using the equation for the normal cumulative distribution function to obtain the expression P sign  T x  y  1  2  1+erf y   T x   2 x T  x    2 The CW classiìer is learned online and the current model is updated each round after observing a training example During training our belief about the classiìer before the t th training iteration expressed through the current mean  t and the current covariance matrix  t  is updated so that the new example  x t  y t  is correctly classiìed with probability larger than some user-set parameter   In addition we impose an additional constraint that our new belief before iteration t 1 is not too far from our belief at the previous iteration t  More formally the stated requirements yield the following optimization problem   t 1   t 1 rgmin    D KL  N      N   t   t   subject to P  y t   T x t  0    3 where D KL is the Kullback-Leibler KL divergence Since the problem 3 is non-convex the authors of solv e an approximate convex problem and derive closed-form updates for the parameters of the Gaussian distribution As formulated in 3 we seek such an update of the classiìcation model so that the new training example is correctly classiìed with certain probability   In the authors point out that this may be suboptimal for noisy data sets More speciìcally once the learning algorithm observes a noisy example the update would modify the current model so that the noise is correctly classiìed which could have an adverse effect on the generalization performance of the classiìer To address this issue a new CW formulation is proposed in called Adapti v e Re gularization of W eights 459 


AROW In this approach the following problem is solved   t 1   t 1 argmin    D KL  N      N   t   t     1  max\(0  1  y t  T x t   2   2  x T t  x t   4 We can see that at each training step the old and the new belief are still constrained to be close as measured by the KL-divergence However unlike in the CW algorithm which aggresively updates the model in order to accomodate new examples in AROW formulation the aggresiveness of maximization of margin and minimization of uncertainty for the new example are controlled by the regularization parameters  1 and  2  respectively As shown in after nding the derivative of the objective function with respect to the parameters update equations for  and  in the case of misclassiìcation of the t th example i.e when sign   T t x t    y t  can be written in closed-form  t 1   t   t y t  t x t   t 1   t   t  t x t x T t  t  5 where  t and  t are computed as  t   t max\(0  1  y t  T x t    t  x T t  x t  r   1  6 and r 1  2  1   for  1   2  Online AROW training is initiated with a zero-vector  0 and an identity matrix  0  and it further proceeds to observe training examples and to update the parameters using equations 5 and 6 III M AP R EDUCE FRAMEWORK With the recent explosive growth of data set sizes analysis and knowledge extraction from modern data sets using a single machine is becoming increasingly intractable In particular training time of popular classiìcation and regression methods e.g SVM classiìcation trees is at best linear in training set size which may be too expensive for problems with billions of examples To address this pressing issue a number of frameworks for distributed learning on clusters of computation nodes has been introduced offering different levels of parallelization node independence and reliability  22 23 24 25 26 In this section we describe one such framework which has become very popular in industry called MapReduce We also discuss AllReduce distributed framework which is utilized in Vowpall Wabbit a state-of-the-art distributed machine learning package MapReduce framework 22 implemented as an open-source platform Hadoop 1  consists of two distinct phases called map and reduce  which constitute one MapReduce job  In the map phase mappers read parts of the dataset possibly stored on multiple computers and perform some action e.g ltering grouping counting sorting with 1 http://hadoop.apache.org accessed June 2013 nal results being sent to reducer in a form of ordered  key  value  pairs In the reduce phase reducer performs a summary operation on the data received from the mappers where the received data is sorted by their key values There may be multiple mappers and reducers and the framework guarantees that all values associated with a speciìc key will appear in one and only one reducer Note that the limited communication between computation nodes in MapReduce framework which is allowed only from mappers to reducers ensures high independence of mappers and signiìcant faulttolerance of the framework Even in the case of mapper failure the entire job is not signiìcantly affected as remaining mappers are not aware of the failure which can be xed with a simple restart of the failed node We illustrate MapReduce abstraction on a simple example Given a dataset D with D features we may want to nd how many times each feature has a non-zero value which can be achieved using several mappers and a single reducer Each mapper reads a part of the dataset and for each example outputs  k 1  if the k th feature was non-zero When the mappers nish outputing  key  value  pairs the reducer starts reading these pairs sorted by their key Then on the reducer side we initialize the count variable to 0  and add all values associated with the same key as the ordered pairs are received Once a key that is different from the one associated with the current count is read reducer outputs the total count and resets the variable to compute the non-zero count for the following feature In this way there is no need to store the individual counts which lowers memory cost of the reducer There are several ways of utilizing MapReduce for distributed learning 1 read the data using multiple mappers and learn the model on a reducer in an online learning manner 2 maintain a global model that is used by all mappers to compute partial updates which are aggregated on reducer to update the global model requires running multiple MapReduce jobs for convergence and 3 learn several local models on mappers and combine them into a global one on a reducer For the rst option distributed learning takes the same amount of time as learning on a single machine with the beneìt that there is no need to store the data on a single disk The second option is typically used for batch learning 31 32 where each mapper computes partial gradient using the current model while the reducer sums the partial gradients and updates the model A new MapReduce job is then instantiated with the updated model used by all mappers for the next round of gradient calculation Thus one job is analogous to one gradient descent step Since learning may require several iterations to converge multiple MapReduce jobs need to be ran one after another which may be ineffective and time costly In contrast the third approach ensures more robust learning and small communication overhead as only a single job is run and we utilize this approach to propose an efìcient and accurate classiìer in Section IV 460 


A AllReduce framework MapReduce abstraction allows very limited interaction between the computation nodes to ensure high fault-tolerance In the following we introduce signiìcantly less-constrained framework called AllReduce which is utilized by the popular Vowpal Wabbit VW software package 2 35 Unlike MapReduce AllReduce framework assumes communication between mappers as well while the reducers are not used In particular when computing the update step for the current global model partial update step computed on one mapper is communicated to all other mappers Then once every mapper receives a message from all other mappers the aggregated update step is performed on all computation nodes simultaneously A typical implementation of AllReduce is done by imposing a tree structure on the computation nodes such that the partial messages are aggregated up the tree and then broadcasted down to all mappers Disadvantage of AllReduce framework is that the mappers need to run truly concurrently However it is common for large clusters to run many independent jobs requiring different amount of resources on the computation nodes and for higher number of mappers there may be no guarantee that all of them will be available for concurrent execution Furthermore as we have observed in practice due to the fact that all nodes are required to send their updates before the next learning iteration starts AllReduce learning will stall if any individual mapper fails once the job has started IV C ONFIDENCE W EIGHTED C LASSIFICATION USING M AP R EDUCE F RAMEWORK In this section we present a distributed AROW algorithm which can be used to efìciently train very accurate linear classiìers on large-scale data Let us assume that we have M mappers and on each mapper an AROW model is trained using only a subset of the whole data set D  by running the algorithm described in Section II More speciìcally on the m th mapper an AROW model is trained using a data set D m D  such that  m 1 M D m  D and D i D j   i   j  We denote the trained AROW parameters for the m th mapper as  m and  m  which are sent to the reducer after the completion of the map stage During the reduce stage we learn the nal aggregated parameters   and   such that the multivariate Gaussian distribution N        is an optimal combination of M multivariate Gaussian distributions learned on mappers More formally let us deìne objective function L to be minimized on the reducer L  E N       D S KL  N        N         7 where the expectation is taken over the distributions over hyperplanes that separate the data set D  and D S KL is the 2 https://github.com/JohnLangford/vowpal  wabbit accessed June 2013 symmetric KL-divergence deìned as D S KL  A  B  1 2  D KL  A  B  D KL  B  A    8 As can be seen from 7 the reducer computes aggregated parameters   and   such that the expected symmetric KLdivergence between the aggregated Gaussian distribution and hyperplane distributions drawn from the probability distribution over separating hyperplane distributions for the data set D  is minimized We note that the proposed method can be viewed as a generalization of the averaging CW model used for large-scale data sets brieîy discussed in Gi v e n the mapper-speciìc parameters  m and  m m 1 M  empirical estimate of the objective function L can be expressed as follows L  M  m 1 P  N   m   m   D S KL  N        N   m   m    9 where we deìne P  N   m   m    or probability of the m th distribution over the separating hyperplanes as the fraction of the training set used to train the m th AROW classiìer We refer to the nal CW classiìcation model as AROW-MR A Reducer optimization of AROW-MR The optimization function 9 is convex thus there exists a unique set of        parameters that minimize L  In this section we derive update equations for AROW-MR parameters the mean and the covariance matrix of the aggregated Gaussian distribution over the separating hyperplanes In order to solve 9 we compute the rst derivatives of the objecive function L with respect to the parameters of the aggregated Gaussian distribution After nding the derivative of L with respect to   and equating the resulting expression with 0  we obtain the following update rule for mean        M  m 1 P  N   m   m      1     1 m    1  M  m 1 P  N   m   m      1     1 m   m   10 In order to compute the update rule for covariance matrix we nd the derivative of L with respect to   and equate the resulting equation with 0  After derivation we obtain the following expression    M  m 1 P  N   m   m     1 m     M  m 1 P  N   m   m    m      m       m  T   11 Equation 11 is a Riccati equation of the form XAX  B  solved with respect to matrix X with matrices A and B given After nding the decomposition of matrix A as 461 


 Algorithm 1 AROW-MapReduce AROW-MR Inputs Data set D  number of mappers M Output Parameters of AROW-MR   and   1 Map Train the m th AROW classiìer on subset D m of the data set D using equations 5 and 6 one AROW classiìer for each mapper to obtain  m and  m  where m 1 M 2 Reduce Combine the local AROW classiìers into an aggregated AROW classiìer using equations 10 11 and 12 3 Output aggregated AROW parameters   and   A  U T U e.g using the Cholesky decomposition we can compute X in a closed-form using the following steps XAX  B XU T UX  B UXU T UXU T  UBU T  UXU T  2  UBU T UXU T  U 0  5 B 0  5  U T  0  5 X  U  0  5 B 0  5  U T   0  5  12 By matching the elements of equation 12 with the elements of equation 11 we can nd the closed-form solution for the covariance matrix    Then in order to nd the optimal parameters   and    equations 10 and 11 are solved iteratively until convergence we empirically found that only a few iterations are sufìcient for the optimization procedure to converge The pseudocode given in Algorithm 1 summarizes the steps of the AROW-MR algorithm Let us discuss the time complexity of AROW and its distributed version AROW-MR Given a D dimensional data set D of size N  complexity of AROW training amounts to O  ND 2   On the other hand complexity of AROW-MR is O  ND 2 M  MD 2  D 3   where the rst term is due to local AROW training on mappers and the second and the third term are due to reducer optimization which involves summation over M matrices of size D  D and Cholesky decomposition of the result respectively For large-scale data sets for which it holds N 012 M  we can conclude that AROW-MR offers efìcient training with signiìcantly lower time overhead when compared to AROW algorithm V E XPERIMENTS In this section we present the results of empirical evaluation of the AROW-MR algorithm We rst validated our method on a synthetic data set then explored its performance on a real-world large-scale task of Ad Latency prediction A Validation on synthetic data In order to better characterize the proposed distributed algorithm in the rst set of experiments we compared AROW and AROW-MR algorithms on synthetic data We used the waveform data set generator available from the UCI Repository where we labeled the rst and the second class as being positive and the third class as being negative We generated 50  000 training examples and 5  000 test examples and set  1   2 0  1 through cross-validation We split the training set into M disjoint subsets of equal sizes and used one subset to train a local AROW on one mapper where we increased the number of mappers M from 2 to 100 to evaluate the effect of higher levels of parallelization We report the results of the original AROW which used the entire training data set denoted by AROW-total which was not affected by the number of mappers the results of AROW-MR as well as the results of a local AROW model trained on a single mapper denoted by AROW-single for which the number of training examples decreased as the number of mappers was increased i.e number of training examples for each local model was 50  000 M  We included AROW-single results to illustrate the performance of local AROW models that are eventually combined on the reducer to obtain AROW-MR model Experiments on synthetic data were run in Matlab on MacBook Pro with 2GHz Intel Core i7 with 8GB of DDR3 memory Mean accuracy and training time after 10 repetitions are shown in Figures 1a and 1b respectively where the error bars in Figure 1a represent intervals of two standard deviations we omitted error bars for AROW-single as the standard deviation was around 0  5 and error bars would clutter the gure We can see in Figure 1a that the accuracy of AROW-MR initially increased as the number of mappers increased statistically signiìcantly outperforming AROWtotal The accuracy of local AROW models trained on each mapper shown as AROW-single dropped steadily with the increase of the number of mappers which was expected as less training examples were used Nevertheless even though the accuracy of local models decreased AROWMR consistently outperformed AROW-total Interestingly as the number of mappers further increased we can see that the accuracy of AROW-MR started decreasing when M surpassed 40  until it decreased to reach the accuracy of AROW for M  100  This decrease is due to the fact that there are too few training examples on mappers for the local models to be close to convergence which in turn affected accuracy of the aggregated model As illustrated in Figure 1b distributed training also resulted in a signiìcant speed-up in training time We can see that AROW-MR training is order of magnitude faster than 462 


 20 40 60 80 100 88 88.1 88.2 88.3 88.4 88.5 88.6 88.7 88.8 88.9    Number of mappers Accuracy   AROWätotal  AROWäsingle  AROWäMR  a Classiìcation accuracy 10 1 10 2 0 0.2 0.4 0.6 0.8 1    Number of mappers Time [sec   AROWätotal  AROWäsingle  AROWäMR  b Training time Figure 1 Results on the synthetic waveform data set with 50  000 training examples training of AROW-total while at the same time achieving higher accuracy Similarly to the accuracy results the training time did not decrease further as we increased the number of mappers beyond a certain point Although the mapper time continued to drop shown by the dashed line this was countered by longer time spent to solve the optimization problem 9 in the reduce phase due to larger M  This validates the known result that for certain problems too much parallelization or distribution can have negative consequences and that the le v e l o f parallelization should be determined after deeper analysis of the problem being solved Having said that we can conclude that distributed training of AROW model resulted in signiìcant accuracy and training time gains over the original AROW B Ad Latency problem description In the following section we compare the performance of AROW-MR and the baseline methods on large-scale industrial task of Ad Latency prediction However before moving on to the discussion of empirical results we rst introduce this important problem in online advertising as well as the large-scale data set used in the experiments Over the previous decade income generated by internet companies through online advertising has been growing steadily at amazing rates with the total revenue reaching a record 36  6 billion in the US in 2012 alone 3  This burgeoning highly competitive market consists of several key players 1 advertisers companies that want to advertise their products 2 publishers websites that host advertisements and 3 intermediate players that connect advertisers to publishers In some cases such clear segmentation is not possible and certain companies can be found in more than 3 http://news.yahoo.com/us-internet-ad-revenue-grows-15-percent-2012153752947.html accessed June 2013 one role e.g Yahoo or Google may provide both the products and the advertising space Typically advertiser designs an image of the advertisement called a creative specifying size and dimension requirements of the image to be shown on websites This is then sent to the intermediate companies which have contracts with publishers and which decide when and to whom the ads will be shown in order to maximize proìts In order to retain existing and attract new users publishers aim at improving user experience by minimizing page load times In addition equally important task for publishers is to ensure that the ads are delivered on time Considering that ad latency time accounts for a signiìcant percentage of the overall load time improving ad load times would directly beneìt both the user experience and the website revenue Thus correctly predicting ad latency time and using this information to decide which ad should be shown to a user is an extremely important problem in online advertising where an additional latency of several milliseconds could result in a signiìcant loss of revenue In this paper we considered Ad Latency dataset consisting of nearly 1  3 billon ad impressions for which 21 features were measured at serve time along with ad latency given in milliseconds Features can be divided into several groups  User-speciìc features include userês device type operating system and browser We also used userês geographic location i.e state and city userês physical distance from the colocation center serving the ad userês connection speed e.g broadband dial-up as well as internet service provider used by the user  Advertiser-speciìc features include the advertiserês account ID size of the advertisement 2-D dimensions of the creative and its size in kilobytes as well as the creative ID of a speciìc image used by the advertiser  Publisherês website can be partitioned into several re463 


Table I Features from the Ad Latency data set Feature name Cardinality  Device 15 Operating system 22 Browser 100 Connection speed 10 State 50 City 574 ISP  Distance to colocation center continuous Account ID  Creative ID  Ad size dimensions 33 Ad size size in KB continuous Region ID  Space ID location on the page  Ad position 28 Hostname  Ad network  Serve type  Colocation center  Hour of the day 24 Day of the week 7 gions where each region has several spaces on which the ad can be shown Further ad can be placed at several different positions in the space e.g top bottom Thus publisher-speciìc features include region ID space ID position ad network used to serve the ad serve type hostname as well as colocation center used to serve the ad  Lastly we use time-stamp of ad impression using time of day and day of the week In Table I we give the data set features as well as the cardinalities for discrete features we omitted sensitive information which is marked with the    symbol We can represent the problem as a binary classiìcation by thresholding the value of ad latency An ad is considered late i.e y 1  if the time period from the moment when the webpage loads to the moment when the ad renders is longer than k milliseconds and not late otherwise i.e y   1  Value of k can be selected depending on a product or ad campaign requirements and we omit the speciìc value used in the experiments as it represents a sensitive information C Validation on Ad Latency data In order to evaluate performance of the classiìcation algorithms we randomly split the Ad Latency data set into training set consisting of 997  055  154 examples and nonoverlapping testing set with 279  026  428 labeled examples For the Ad Latency prediction task the publishers prefer low False Positive Rate FPR ensuring that very few ads are wrongly classiìed as late thus minimally hurting revenue At the same time the publisher prefer high True Positive Rate TPR which improves user experience and increases proìt As these two goals are often conîicting the optimal strategy is to maximize the area under the Receiver Table II Performance comparison of AROW and AROWMapReduce on Ad Latency task in terms of the AUC  mappers  reducers Avg map time Reduce time AUC 1 0 408h n/a 0.8442 100 1 30.5h 1 min 0.8552 500 1 34 min 4 min 0.8577 1,000 1 17.5 min 7 min 0.8662 10,000 1 2 min 1h 0.8621 Operating Characteristic ROC curve referred to as the AUC Thus unlik e i n the e xperiments with the synthetic data we report AUC as a measure of performance Given a predicted margin for the n th example  y n  R  a binary classiìcation prediction is found as sign  y n     where different values of threshold  result in different predictions and different TPR and FPR values We can obtain an ROC curve by sliding the threshold  from  to   and plotting the resulting TPR and FPR in a 2 D plot The experiments were conducted using MapReduce on Apache Hadoop with AROW-MR mapper and reducer implemented in Perl Performance of AROW-MR was compared to AROW algorithm which was run on a single machine as well as to the logistic regression implemented in highly-scalable Vowpal Wabbit package run both on a single machine and in a distributed manner using AllReduce on Hadoop We ensured that Hadoop scheduled exactly M mappers by storing the data in M gzip-compressed part les We rst compared the performance of AROW learned on a single machine with AROW-MR learned in a distributed manner Similarly to experiments presented in Section V-A we increased the number of mappers to evaluate the effects of different levels of parallelization The results are given in Table II We can see that the running time of AROWMR drastically improved over the non-distributed AROW trained using a single mapper While it took 17 days for AROW to train we were able to train accurate AROW-MR models in less than an hour Expectedly average mapper time decreased and reducer time increased as the number of mappers was increased as each mapper was trained on smaller partition of the data and reducer was required to combine higher number of local models Interestingly we can also see that the results in Table II validate the results obtained on synthetic data regarding performance gains with increasing levels of parallelization In particular both the accuracy and training time improved until we reached M 1  000  and dropped slightly for higher number of mappers The detailed results are presented in Figure 2 where we plotted ROC curves of the conìdence-weighted models trained using different number of mappers We can see that the curve for non-distributed AROW denoted by 1 mapper results in the smallest AUC while the level of parallelization achieved with 1  000 mappers represents the best choice for the Ad Latency prediction task 464 


   0 5 10 15 20 25 30 35 40 0 10 20 30 40 50 60 70 80 90 100 False Positive Rate True positive rate      1 mapper  100 mappers  500 mappers 1,000 mappers  10,000 mappers  Figure 2 ROC curve for AROW-MR and AROW Next in Table III we show the performance of logistic regression LR model trained using VW package in both distributed mode using AllReduce and non-distributed manner on a single machine We can see that AROW-MR achieved higher accuracy than LR which is a very popular approach using in large-scale classiìcation While AROWMR obtained AUC of 0  8662  the best AUC achieved by LR was 0  8508  this increase in accuracy may result in signiìcant increase of revenue in computational advertising domain Interestingly the results also indicate that more distributed training of LR actually hurt its generalization performance which slightly dropped as the number of mappers was increased Further we can see that LR was trained in 8 minutes while it took 25 minutes to train AROW-MR model However although LR training is seemingly faster than training of AROW-MR it is important to emphasize that VW package implements logistic regression in C language while for technical reasons AROW-MR was implemented in Perl Considering that Perl is not an optimal choice for mathematical computations we expect AROW-MR training time to improve signiìcantly once implemented in C It is also worth noting that we were not able to run the LR experiment for more than one thousand mappers The LR implementation in VW package uses AllReduce framework which requires that all mappers run concurrently without any node failures otherwise the training might fail However this is usually hard to guarantee in practice even for larger clusters and it further exempliìes the advantage of the proposed algorithm over the competition We can conclude that AROW-MR offers robust highly efìcient training of accurate classiìers outperfoming the existing state-of-theart for extremely large-scale industrial-size problems VI C ONCLUSION In this paper we presented AROW-MR a distributed linear SVM solver capable of learning accurate models in time subTable III Performance of distributed logistic regression  mappers  reducers Avg map time Reduce time AUC 1 0 7h n/a 0.8506 100 0 1h n/a 0.8508 500 0 8 min n/a 0.8501 1,000 0 6 min n/a 0.8498 linear in the size of a training set The proposed method utilizes the MapReduce paradigm which provides distributed fault-tolerant environment for large-scale machine learning Map phase of the method involves training a number of local AROW models on each mapper followed by reduce phase which combines local classiìers to obtain a single aggregated model more accurate than any of the individual ones The experiments on synthetic data and real-world Ad Latency data set with nearly one billion examples indicate that AROW-MR allows for signiìcant accuracy and training time improvements over the original AROW algorithm Moreover on Ad Latency task the proposed method outperformed distributed logistic regression available in a popular Vowpal Wabbit package suggesting that the proposed distributed conìdence-weighted model provides a scalable accurate tool for large-scale classiìcation problems A CKNOWLEDGMENT The authors would like to thank Vladan Radosavljevic for helpful discussions ND and SV would also like to acknowledge NSF support through grant IIS-0546155 R EFERENCES  C Bizer  P  Boncz M L Brodie and O Erling The meaningful use of big data four perspectivesÖfour challenges ACM SIGMOD Record  vol 40 no 4 pp 56Ö60 2012  A Labrinidis and H Jagadish Challenges and opportunities with big data Proceedings of the VLDB Endowment  vol 5 no 12 pp 2032Ö2033 2012  S Lohr  The age of big data  New York Times  vol 11 2012  J Mervis Agencies Rally to T ackle Big Data  Science  vol 336 no 6077 pp 22Ö22 2012  C Cortes and V  V apnik Support-v ector netw orks  Machine Learning  vol 20 no 3 pp 273Ö297 1995  J Platt F ast training of Support V ector Machines using Sequential Minimal Optimization Advances in kernel methods support vector learning MIT Press  1998  J Ki vinen A J Smola and R C W illiamson Online learning with kernels IEEE Transactions on Signal Processing  vol 52 no 8 pp 2165Ö2176 2002  S V  N V ishw anathan A J Smola and M N Murty  SimpleSVM in International Conference on Machine Learning  2003 465 


 A Se v eryn and A Moschitti Lar ge-scale support v ector learning with structural kernels in Machine Learning and Knowledge Discovery in Databases  Springer 2010 pp 229Ö244  I W  Tsang J T  Kw ok and P M Cheung Core v ector machines Fast SVM training on very large data sets Journal of Machine Learning Research  vol 6 no 1 p 363 2005  P  Rai H Daum  e III and S Venkatasubramanian Streamed learning one-pass SVMs in Proceedings of the 21st International Joint Conference on Artiìcial Intelligence  Morgan Kaufmann Publishers Inc 2009 pp 1211Ö1216  H Graf E Cosatto L Bottou I Dourdano vic and V  V apnik Parallel Support Vector Machines The cascade SVM Advances in Neural Information Processing Systems  vol 17 pp 521Ö528 2004  E Chang K Zhu H W ang H Bai J Li Z Qiu and H Cui Psvm Parallelizing support vector machines on distributed computers Advances in Neural Information Processing Systems  vol 20 p 16 2007  Z A Zhu W  Chen G W ang C Zhu and Z Chen PpackSVM parallel primal gradient descent kernel SVM in IEEE International Conference on Data Mining  2009 pp 677Ö686  I Steinw art Sparseness of support v ector machines  Journal of Machine Learning Research  vol 4 pp 1071Ö1105 2003  C Gentile A ne w approximate maximal mar gin classiìcation algorithm Journal of Machine Learning Research  vol 2 pp 213Ö242 2002  Y  Li H Zaragoza R Herbrich J Sha we-T aylor  and J Kandola The perceptron algorithm with uneven margins in International Conference on Machine Learning  2002 pp 379Ö386  S Shale v-Shw artz Y  Singer  and N Srebro Pe gasos Primal estimated sub-gradient solver for SVM in Proceedings of the 24th international conference on Machine learning  ACM 2007 pp 807Ö814  R.-E F an K.-W  Chang C.-J Hsieh X.-R W ang and C.-J Lin LIBLINEAR A library for large linear classiìcation Journal of Machine Learning Research  vol 9 pp 1871 1874 2008  H.-F  Y u C.-J Hsieh K.-W  Chang and C.-J Lin Lar ge linear classiìcation when data cannot t in memory ACM Transactions on Knowledge Discovery from Data  vol 5 no 4 p 23 2012  J Dean and S Ghema w at MapReduce simpliìed data processing on large clusters Communications of the ACM  vol 51 no 1 pp 107Ö113 2008   MapReduce a  e xible data processing tool  Communications of the ACM  vol 53 no 1 pp 72Ö77 2010  A Agarw al O Chapelle M Dud  k and J Langford A reliable effective terascale linear learning system arXiv preprint arXiv:1110.4198  2011  Y  Lo w  J Gonzalez A K yrola D Bickson C Guestrin and J M Hellerstein GraphLab A new parallel framework for machine learning in Proceedings of the Conference on Uncertainty in Artiìcial Intelligence  2010 pp 340Ö349  Y  Lo w  D Bickson J Gonzalez C Guestrin A K yrola and J M Hellerstein Distributed GraphLab A framework for machine learning and data mining in the cloud Proceedings of the VLDB Endowment  vol 5 no 8 pp 716Ö727 2012  G Male wicz M H Austern A J Bik J C Dehnert I Horn N Leiser and G Czajkowski Pregel a system for largescale graph processing in Proceedings of the ACM SIGMOD International Conference on Management of data  ACM 2010 pp 135Ö146  D Borthakur  J  Gray  J  S  Sarma K Muthukkaruppan N Spiegelberg H Kuang K Ranganathan D Molkov A Menon S Rash et al  Apache Hadoop goes realtime at Facebook in International Conference on Management of Data  ACM 2011 pp 1071Ö1080  K Shv achk o H K uang S Radia and R Chansler  The hadoop distributed le system in IEEE Symposium on Mass Storage Systems and Technologies MSST  IEEE 2010 pp 1Ö10  J.-H B  ose A Andrzejak and M H  ogqvist Beyond online aggregation Parallel and incremental data mining with online map-reduce in Proceedings of the 2010 Workshop on Massive Data Analytics on the Cloud  ACM 2010 p 3  Y  Lin F  Lv  S  Zhu M Y ang T  Cour  K  Y u L Cao and T Huang Large-scale Image Classiìcation Fast Feature Extraction and SVM Training in IEEE Conference on Computer Vision and Pattern Recognition CVPR  IEEE 2011 pp 1689Ö1696  A Gesmundo and N T omeh HadoopPerceptron a toolkit for distributed perceptron training and prediction with MapReduce in Proceedings of the Demonstrations at the 13th Conference of the European Chapter of the Association for Computational Linguistics  Association for Computational Linguistics 2012 pp 97Ö101  C Chu S K Kim Y A Lin Y  Y u  G  Bradski A Y  Ng and K Olukotun Map-reduce for machine learning on multicore Advances in Neural Information Processing Systems  vol 19 p 281 2007  M Dredze K Crammer  and F  Pereira ConìdenceWeighted Linear Classiìcation in Proceedings of the International Conference on Machine Learning  ACM 2008 pp 264Ö271  K Crammer  A  K ulesza and M Dredze  Adapti v e Re gular ization of Weight Vectors Advances in Neural Information Processing Systems  vol 22 pp 414Ö422 2009  J Langford L Li and T  Zhang Sparse online learning via truncated gradient The Journal of Machine Learning Research  vol 10 pp 777Ö801 2009  C Hughes and T  Hughes Parallel and distributed programming using C  pp 31Ö32 2004  T  F a wcett R OC graphs Notes and practical considerations for researchers Machine Learning  vol 31 pp 1Ö38 2004 466 


                                               


                                                                                                      


                  


On the Evolution of Contacts and Communities in Networks of Face-to-Face Proximity 993 Mark Kibanov, Martin Atzmueller, Christoph Scholz, and Gerd Stumme Community Detection Based on Readers' Borrowing Records 1001 Liu Xin, E. Haihong, and Song Junde Design of a Mobile Telephony System for Social Interaction 1006 Yuan-Chih Yu Understanding News Sharing in Social Media from the Diffusion of Innovations Perspective 1013 Long Ma, Chei Sian Lee, and Dion H. Goh A Study of Offline Events and Its Influence on Online Social Connections in Douban 1021 Alvin Chin, Jilei Tian, Junwei Han, and Jianwei Niu How Long a Passenger Waits for a Vacant TaxióLarge-Scale Taxi Trace Mining for Smart Cities 1029 Guande Qi, Gang Pan, Shijian Li, Daqing Zhang, Lin Sun, and Laurence Tianruo Yang iThings/CPSCom 2013 Symposia Symposium on Frontiers of Internet of Things \(SymIoT Frequent Itemset Based Event Detection in Uncertain Sensor Networks 1037 Yongxuan Lai and Jinshan Xie Improved RETE Algorithm in Context Reasoning for Web of Things Environments 1044 Teng Gao, Xiaofeng Qiu, and Lijuan He Ultra-low-power Neural Recording Microsystem for Implantable Brain Machine Interface 1050 Weidong Cao and Hongge Li From Internet of Things to Internet of Agents 1054 Han Yu, Zhiqi Shen, and Cyril Leung Using Kasa Method to Separate Target's RCS Characters from Background in Electromagnetic Sensing within Anechoic Chamber Measurement 1058 Jingcheng Zhao and Ming Lv Research on IPv6 Address Forecast Model of Smart Grid 1064 Xin Miao and Xi Chen Relay Node Deployment Based Small World Effect in Hierarchical Industrial Wireless Sensor Networks 1066 Jieyu Wu, Xinyu Shao, and Haiping Zhu A Development Analysis of China's Intelligent Transportation System 1072 Yuxiang Yan and Chenxue Xu An Anti-collision Algorithm Using Tag Random-Dispersing for RFID Systems 1077 Yang Qing, Li Jian-cheng, Wang Hong-yi, and Shen Rong-jun Pairing and Authentication Security Technologies in Low-Power Bluetooth 1081 Junfeng Xu, Tao Zhang, Dong Lin, Ye Mao, Xiaonan Liu, Shiwu Chen, Shuai Shao Bin Tian, and Shengwei Yi 
xvii 


An Attribute-Based Encryption Scheme with Constant-Size Ciphertexts 1086 Yanfeng Qi, Chunming Tang, Yu Lou, Maozhi Xu, and Baoan Guo Synthetic Evaluation of the Trustworthiness of Integrated Monitoring-Controlling System for LED Display Based on Fuzzy AHP 1089 Yuanmei Wen, Li Luo, Xuechen Yu, and Yanyu Chen Improvement of Peach Platform to Support GUI-Based Protocol State Modeling 1094 Hao Wang, Qiaoyan Wen, and Zhao Zhang Game Theoretic Analysis of Workload Factoring in Federation of Clouds 1098 Yonggen Gu and Changlei Lin Study on Heartbeat Information Acquired from Pressure Cushion Based on Body Sensor Network 1103 Junrong Bao, Xiaoyun Shou, Hua Wang, and Haiyan Yang Towards an Equitable Federated Name Service for the Internet of Things 1109 Xinchi Li, Yang Liu, Ye Tian, Ning Kong, Yan Wang, and Wei Mao Double Nested Internet of Things for Intelligent Management of Police Equipment 1116 Li Shengguang, Tan Lin, Wang Junxiu, and Yu Rui A Universal Object Name Resolution Scheme for IoT 1120 Zhiwei Yan, Ning Kong, Ye Tian, and Yong-Jin Park The New Intelligent Prediction for Bus Congestion Based on History Information Processing 1125 Yan Zhang and Guixi Xiong Construction and Strategies in IoT Security System 1129 Quandeng Gou, Lianshan Yan, Yihe Liu, and Yao Li Fuzzy Double-Threshold Track Association Algorithm Using Adaptive Threshold in Distributed Multisensor-Multitarget Tracking Systems 1133 Wei Du, Huansheng Ning, Yuan Wei, and Jun Wang An Intelligent System for Precast Concrete Element Manufacturing Management Based on RFID Technology 1138 Hu Min and Lu Junyu Data Management for Internet of Things: Challenges, Approaches and Opportunities 1144 Meng Ma, Ping Wang, and Chao-Hsien Chu Residential Energy Management in Smart Grid: A Markov Decision Process-Based Approach 1152 Sudip Misra, Ayan Mondal, Shukla Banik, Manas Khatua, Samaresh Bera and Mohammad S. Obaidat A Space-Time with Weight Algorithm for RFID Data Interpolation 1158 Ming Ke, Xin Wang, Jianxin Tang, and Xuhui Chen Integration of Smart Sensor Networks into Internet of Things: Challenges and Applications 1162 Dan Partynski and Simon G.M. Koo 
xviii 


Integrating Context-Awareness and Trustworthiness in IoT Descriptions 1168 Kaiyu Wan and Vangalur Alagar Building Smart M2M Applications Using the WuKong Profile Framework 1175 Kwei-Jay Lin, Neils Reijers, Yu-Chung Wang, Chi-Sheng Shih, and Jane Y. Hsu A Human Trajectory Estimate Based on Individual Mobility Pattern Library 1181 Yang Yang, Bowen Du, and Xiao Jiang The Research on Monitoring of Discrete Manufacturing Process Based on Internet of Things 1186 Liuyin Yuan, Yu Guo, Jiajun Jiang, and Liyun Nian Research on the Framework of Internet of Things in Manufacturing for Aircraft Large Components Assembly Site 1192 Jihong Liu and Jie Yu Technical State Monitoring and Evaluation of Aerospace Product Manufacturing Workshop Based on Internet of Things 1197 Jihong Liu and Wenting Xu Temperature Map Recovery Based on Compressive Sensing for Large-Scale Wireless Sensor Networks 1202 Xuanxuan Wu, Cheng-Long Chuang, and Joe-Air Jiang Interoperability Repository System for the Internet-of-Things 1207 Pedro MalÛ, Tiago Teixeira, Bruno Almeida, and M·rcio Mateus Discussion on Key Technologies in Forestry Fundamental Scientific Information Cloud Service Platform 1216 Mubo Zhang, Zhongming Li, and Fan Li Symposium on Frontiers of Cyber-Physical-Social Computing SymCPS Leveraging Social Network APIs for Enhancing Smartphone Apps: An Example of VoIP App 1219 Shuchih Ernest Chang and Pin-Fan Lee Extending and Recompiling AADL for CPS Modeling 1225 Zhonghao Sun and Xingshe Zhou A Novel Frequency Hopping Scheme Based on Cognitive Radio for Aircraft 1231 Lei Zhidong and Zhang Xiaolin Modeling Effects of Physical Factors on Controller Area  Network in Cyber-physical Systems 1237 Bo Shen, Xingshe Zhou, and Ru Wang Detecting Flu Transmission by Social Sensor in China 1242 Jiangmiao Huang, Hui Zhao, and Jie Zhang A Smart Cyber-physical Systems-Based Solution for Pest Control \(Work in Progress 1248 Farhad Mehdipour, Krishna Chaitanya Nunna, and Kazuaki J. Murakami 
xix 


A Hybrid Content-Based Filtering Approach: Recommending Microbloggers for Web-Based Communities 1254 Kejun Dong and Yi Shen Just-in-Time Social Cloud: Computational Social Platform to Guide People's Just-in-Time Decisions 1259 Kwan Hong Lee, Andrew Lippman, Alex S. Pentland, and Pattie Maes Towards a Hybrid Approach of Primitive Cognitive Network Process and K-Means Clustering for Social Network Analysis 1267 Chun Guan and Kevin Kam Fung Yuen A Compressive Sensing Based Secure Data Transmission Scheme 1272 Guorui Li and Ying Wang An IO Optimized Data Access Method in Distributed Key-Value Storage System 1276 Li Chao, Wu Guangjun, Wang Shupeng, and Li Yixi W e  K n o w  W h a t  Y o u  A r e A  U s e r  C l a s s i f i c a t i o n  B a s e d  o n  M o b i l e  D a t a                                                             1 2 8 2 Duan Hu, Fei Sun, Lai Tu, and Benxiong Huang E f f i c i e n t  S e c u r i t y  S o l u t i o n  f o r  I n f o r m a t i o n c e n t r i c  N e t w o r k i n g                                                                          1 2 9 0 Hasen Nicanfar, Peyman TalebiFard, Chunsheng Zhu, and Victor C.M. Leung Towards Dynamic Resource Provisioning for Traffic Mining Service Cloud 1296 Jianjun Yu and Tongyu Zhu Leading Users Detecting Model in Professional Community Question Answering Services 1302 Siqi Song, Ye Tian, Wenwen Han, Xirong Que, and Wendong Wang A Moving Foreground Expansion Method Based on the Gaussian Distribution 1308 Yanhua Li, Wei Li, and Qi Xiang A Hybrid Emotion Recognition on Android Smart Phones 1313 Weishan Zhang, Xin Meng, Qinghua Lu, Yuan Rao, and Jiehan Zhou Multi-view Approach for Modeling Aerospace Cyber-physical Systems 1319 Lichen Zhang EigenCrime: An Algorithm for Criminal Network Mining Based on Trusted Computing 1325 Shujun Cai, Jiangnan Xia, Keyi Sun, and Zhen Wang A Task-Attribute-Based Workflow Access Control Model 1330 Yi Liu, Ke Xu, and Junde Song GreenBicycling: A Smartphone-Based Public Bicycle Sharing System for Healthy Life 1335 Yifan Zhao, Longbiao Chen, Chao Teng, Shijian Li, and Gang Pan Multi-step Sensor Scheduling for Energy-Efficient High-Accuracy Collaborative Target Tracking in Wireless Sensor Networks 1341 Biao Song, Wendong Xiao, and Zhaohui Zhang xx  


International Workshop on Vehicular Sensor and Ad-Hoc Networks \(VeSAN 2013 Toward Optimal Additive Noise Distribution for Privacy Protection in Mobile Statistics Aggregation 1346 Hao Zhang, Yonggang Wen, Honggang Hu, and Nenghai Yu Performance Analysis of a Hierarchical Structured VANET 1352 Wanting Zhu, Qing Zhang, and A.C.M. Fong Multilevel Cluster-Based Information Fusion in Vehicle Ad Hoc Networks 1357 Weicheng Zhao, Linjuan Zhang, Wanting Zhu, and Yanqi Zhao PSFCS: Robust Emergency Communications Supporting High-Mobility Based on WiMAX MMR Networks 1363 Wen-Kang Jia, Chia-Yao Chen, and Yaw-Chung Chen International Workshop on Next Topics for Green Communications and Computing \(GreenCom-Next 2013 On Energy Efficiency Data Access and Backup for Cloud Computing Networks 1369 Yeanf-Fu Wen A Model to Analyze the Energy Savings of Base Station Sleep Mode in LTE HetNets 1375 Paolo Dini, Marco Miozzo, Nicola Bui, and Nicola Baldo Soft Timing Synchronization Algorithm for CPM Signals 1381 Xiangchao Zhou, Rui Xue, Danfeng Zhao, and Fu Fang Secure Framework for the Return Routability Procedure in MIPv6 1386 Faisal Al Hawi, Chan Yeob Yeun, and Khaled Salah An Energy Efficient Cache Design for Multi-core Processors 1392 Cao Xiangrong and Zhang Xiaolin Analysis Method of Energy for C Source Program and Its Application 1397 Yang Yuechuan, Zeng Guosun, Ding Chunling, and Wang Wei Simulating Stochastic Activation Functions 1403 Hanno Hildmann, Sebastien Nicolas, and Fabrice Saffre Power-Efficient Virtual Machine Placement and Migration in Data Centers 1408 Shuo Fang, Renuga Kanagavelu, Bu-Sung Lee, Chuan Heng Foh, and Khin Mi Mi Aung Probabilistic Modeling during Power Estimation for Mixed Polarity Reed-Muller Logic Circuits 1414 Xiang Wang, Ying Lu, Yi Zhang, Zexi Zhao, Tongsheng Xia, Jishun Cui, and Limin Xiao Ant-Colony Based Heuristics to Minimize Power and Delay in the Internet 1419 Shankar Raman, Gaurav Raina, Hanno Hildmann, and Fabrice Saffre Materialization of a Comprehensive Digital City with CityMaker and ArcGIS 1424 Mingzhu Deng, Guangming Liu, and Yuran Hu 
xxi 


iThings/CPSCom 2013 Workshops International Workshop on Biometric Recognition and Its Applications \(BR&A 2013 A New Method of Designing High-Power Electroplating Power Supply 1429 Yihong He and Shuiyong Yu The Study of Fusion Image Block and Sparse Representation Classification in Disguised Face Recognition 1434 Gan Junying, Liu Dan, Zeng Junying, and Tian fengxia SMT Components Model Inspection Based on Characters Image Matching and Verification 1438 Bing Luo, Yuehua Gao, Zhongyu Sun, and Sufang Zhao The Manipulation of Chaotic Synchronization Quality Based on VCSEL with Optical Feedback 1442 Dongzhou Zhong Fast Wavelet Thresholding Algorithms for Face Image Inpainting 1445 Yibin Yu, Jinguo Cao, Yaofang Tang, and JunYing Gan Multispectral Palmprint Recognition Using Score-Level Fusion 1450 Yibin Yu, Yaofang Tang, Jinguo Cao, and JunYing Gan Encryption Node Design in Internet of Things Based on Fingerprint Features and CC2530 1454 Zeng Bohan, Wang Xu, Zhou Kaili, and Zhao Xueyuan Facial Expression Recognition Based on Local Binary Pattern and Gradient Directional Pattern 1458 Wenjin Chu Design of Intelligent Inducing Switch 1463 Yang Zhao and Fengxia Tian International Workshop on Cyber Physical Society Information Processing \(CPSIP 2013 Identify Online Fraudster with Extended Cellular Automata 1467 Ji Li and Yueliang Xiao Harmonization of Cyber-physical Society 1473 Alexander Abramovich and Rashid Khunagov Influence Analyzing and Modeling of High Frequency Forwarding Microblogs 1479 Shangbo Zhou, Wei Wang, Jie Luo, Li Wan, and Yao Zhang Requirement Specification for Transportation Cyber Physical Systems 1486 Lichen Zhang Integration-Oriented Modeling of Cyber-physical Interactive Process 1492 Tao Guan and Gang Yang 
xxii 


Web-of-Things Framework for WeChat 1496 Huang Yitong, Lai Xiaozheng, Dai Bingpei, and Chen Qinyi International Workshop on Cyberspace Security and Information Countermeasures \(CS&IC 2013 Simulation Experiment Research of Cyberspace Confront Effectiveness Evaluation 1501 Yu Zhang, Chen Shansong, and Xie Deping Technology of Situation Awareness Based on Radar Network in Cyberspace 1505 Xun Yang, Wei Shan, and Liu Jia Space Information Security and Cyberspace Defense Technology 1509 Su Kang, Dong Qiaozhong, and Zhu WeiQiang International Workshop on Connected Vehicles and Vehicular Networks \(CV2N 2013 Real-Time Vehicle Route Guidance Based on Connected Vehicles 1512 Daxin Tian, Yong Yuan, Jianshan Zhou, Yunpeng Wang, Guangquan Lu, and Haiying Xia A Novel Two-Timer-Based Broadcast Routing Algorithm for Vehicular Ad-Hoc Networks 1518 Song Fang and Tao Luo Research of Vehicle Counting Based on DBSCAN in Video Analysis 1523 Dayang Sun, Binbin Li, and Zhihong Qian A Self-Adaptive V2V Communication System with DSRC 1528 Daxin Tian, Hao Luo, Jianshan Zhou, Yunpeng Wang, Guizhen Yu, and HaiyingXia International Workshop on Electromagnetic Characteristics of Target and Environment \(ECTE 2013 SAR Segmentation and Recognition Based SCM 1533 Liping Hu and Xiaoyu Xing EM Scattering Analysis of Complex Target Coated with Plasma by Conformal SO-FDTD Method 1538 Hao-Chuan Deng, Xiao Wei, and Hong-Cheng Yin SAR RAW Data Simulation by Electromagnetic Computation in Frequency Domain 1542 Xupu Geng, Chunzhu Dong, Hongcheng Yin, and Guoqing Zhu Precession and Structural Parameters Estimation of the Cone-Shaped Target Based on the Profile Length 1545 Jing Huang, Chao Ning, and Zhihe Xiao Terahertz Gaussian Beam Scattering by a Conducting Sphere 1550 Liangsheng Li and Hongcheng Yin Reshaped Window Iterative Super-Resolution Imaging Algorithm 1554 Sheng Li, Liangsheng Li, and Hongcheng Yin Study on the influential factors of radar target RCS in resonance region 1557 Liang Man, Xiao Wei, and Zhihe Xiao 
xxiii 


A New Method for Estimating Radar Profile Length of a Cone Target 1561 Chao Ning, Jing Huang, Chao Gao, and Yong Zhu The Feature Extraction of Time-Frequency Image Based on Frequency Diversity 1566 Jing Sheng, Zhihe Xiao, and Jing Huang Characteristic Study of Target Micro-motion Based on the Wavelet Analysis 1571 Yuguang Tian, Chao Ning, and Xiangyang Zhang The Decorrelation Time Accumulation Restrain Method for Sea Clutter Spike 1576 Xujin Yuan, Yong Chen, Chao Wang, and Hongcheng Yin The Radar Echo Simulation of Moving Targets Based on HRRP 1580 Tao Zhao, Chun-Zhu Dong, Hong-Mei Ren, and Hong-Cheng Yin A Novel Method for Generating Planar Wave Based on Dielectric Gratings 1584 Dai Fei, Cheng Qiping, and Yue Hui Application of Terahertz Technology on RCS Measurement 1587 Wang Xiaobing, Huang Xin, Wu Yajun, Dai Fei, and Li Li Typical Target RCS Reduction Using Structural Radar Absorbing Material 1591 Yongfeng Wang and Kainan Qi International Workshop on Electromagnetic Detection and Identification \(EDI 2013 Error Analysis in Calculating RCS Using GRECO Method 1594 Zhi Hua Cheng, Yong Jun Xie, Xue Mei Wang, Yu Ru Mao, and Xiao Dong Ma Placement Optimization of Vehicular Antenna Using Particle Swarm Optimization 1597 Yu-Ru Mao, Yong-Jun Xie, Zhi-Hua Cheng, Xue-Mei Wang, and Xiao-Dong Ma A Novel Loss Compensated Multipath Power Divider for Frequency Synthesizer 1600 Tongfei Yu, Jungang Miao, Yan Xie, Baohua Yang, and Xianxun Yao An Approach for Extrapolating Far Field Radar Cross-Section from Near Field Measurement 1604 Gao Chao, Yuan Xiaofeng, and Bai Yang Implementation of the Digital Correlation Unit for Synthetic Aperture Interferometric Radiometer 1608 Xianxun Yao, Cheng Zheng, Baohua Yang, Jin Zhang, and Jungang Miao Design Procedures and Considerations of FOD Detection Millimeter-Wave FMCW Radar 1612 Jin Zhang, Cheng Zheng, Baohua Yang, Xianxun Yao, and Jungang Miao Exact Design of a Ka Band H-Plane Inductance Diaphragm Waveguide Band-Pass Filter 1618 Yong Fu, Baohua Yang, and Jungang Miao The Compact Microstrip Bandstop Filter Using Equal Width Open Stub 1622 Bao-Hua Yang, Ghulam Mehdi, Jin Zhang, Tong-fei Yu, Xian-xun Yao, and Jungang Miao 
xxiv 


The Design and Simulation of Hardware Architecture of the Fast and On-Site Assessing System of Scattering Characteristics of Stealth Aircraft Based on Simulink 1626 Hong Tao and Song Dan Second International Workshop on Engineering Pervasive Service Systems \(EPS 2013 Food Image Recognition Using Pervasive Cloud Computing 1631 Pengcheng Duan, Wenshan Wang, Weishan Zhang, Faming Gong, Peiying Zhang and Yuan Rao An Approach of Semantic Similarity by Combining HowNet and Cilin 1638 Peiying Zhang, Zhanshan Zhang, and Weishan Zhang Reconstruction of 3D Maps for 2D Satellite Images 1644 Lianzhang Zhu, Xuexing Zheng, and Pengfei Li Component-Based Cloud Computing Service Architecture for Measurement System 1650 Chao Liu, Qingsong Yu, Tianao Zhang, and Zhongwen Guo Second International Workshop on Energy and Wireless Sensors  \(e-WiSe 2013 Design Optimization of Electromagnetic MEMS Energy Harvester with Serpentine Coil 1656 Yuji Tanaka, Takayuki Fujita, Tatsuya Kotoge, Kohei Yamaguchi, Koji Sonoda Kensuke Kanda, and Kazusuke Maenaka Experimental Study of a Passive Impedance Matching Interface Based on a Centimeter-Size High Inductance Coil for Practically Enhanced Piezoelectric Energy Harvester Performance at Low Frequency 1659 Alessandro Giuliano and Meiling Zhu SPICE Modeling of Piezoelectric Energy Harvesting Device Utilizing Stress Influence 1662 Koji Sonoda, Takayuki Fujita, Kensuke Kanda, Kazusuke Maenaka, Hidenori Katsumura Masaya Tamura, and Hiroshi Kagata Modeling, Validation and Design Analyses of a Piezoelectric Cymbal Transducer for Non-resonant Energy Harvesting 1665 Alice Daniels, Alessandro Giuliano, Meiling Zhu, and Ashutosh Tiwari Towards Energy Autonomy of Wireless Sensors in Aeronautics Applications SMARTER Collaborative Project 1668 Marise Bafleur and Jean-Marie Dilhac 
xxv 


International Workshop on Gas Sensors and Gas-Sensing Platforms \(GS&GSP 2013 A Novel Surface Acoustic Wave Sensor for Optical Lens Surface Dirt Detection 1673 Jiuling Liu, Minghua Liu, Wen Wang, and Shitang He Electrical Sensoring Characteristics of Pseudo-LFE Sensors with Different Single Crystals 1676 Zhitian Zhang, Chao Zhang, Wenyan Wang, Yan Liu, and Tingfeng Ma Investigation of Polymer-Coated Film Bulk Acoustic Wave Resonator for Acetone Vapor Detection 1680 Jingjing Wang and Da Chen Polyaniline-Coated Surface Acoustic Wave Sensor for Humidity Detection 1685 Xiao Xie, Wen Wang, Shitang He, Ning Mu, and Yong Pan Effect of Facets of  Fe2O3 Nanostructures on Gas-Sensing Performance 1688 Jing Wang, Xiaoman Zhang, Weihong Xu, Liang Chen, Xingjiu Huang, and Jinhuai Liu Application and Development Trend of Gas Sensing Technology Based on Absorption Spectroscopy 1692 Zhenzhen Zhao, Fengchun Tian, and Shouqiong Liu Identification of Toxic VOC Pollutants Using FAIMS 1698 Youjiang Liu, Lehua Zhang, Hongwei Wang, Xiaotian Zhang, Chilai Chen Huanqin Wang, Deyi Kong, Mario A. Chavarria, and Juergen Brugger Detection of benzene series by two-dimensional  FAIMS technique 1702 Lehua Zhang, Youjiang Liu, Hongwei Wang, Chilai Chen, Huanqin Wang, Deyi Kong Xiaotian Zhang, Mario Chavarria, and Juergen Brugger Fabrication of Prototypal Nanomechanical Resonator Based on a Single Copper Nanowire 1706 Weihong Xu and Li-Feng Ge The SAW Gas Chromatograph and Its Applications in the Public Security 1710 Shitang He, Jiuling Liu, and Minghua Liu Theory of Lamb Wave Transducers and Their Applications for Gas and Liquid Sensing 1714 Li-Feng Ge Study of the Space Station On-Orbit Leak Detection Based on the Differential Pressure Gas Sensor 1718 Wei Sun, Rongxin Yan, Lichen Sun, Donghui Meng, Zheng Li, Haitao Guo, and Wenbin Li 
xxvi 


International Workshop on Human Body Communications and Biomedical Signal Processing \(HBC&BSP 2013 Pulse-Output Monitor Genetic Circuit of Breast Cancer Testing 1722 Xiang Wang, Guangqian Yuan, Xun Wang, and Zexi Zhao Elderly Gait Analysis and Assessment Based on Body Area Network 1729 Y.D.Xuan, Z. Zhao, Z. Fang, Z.H.Xu, F.M.Sun, D.L.Chen, L.D.Du, Y.M.Qian, H.Y.Hu and L.L.Tian Combined Motion and Region-Based 3D Tracking in Active Depth Image Sequence 1734 Xingyu Wu, Xia Mao, Lijiang Chen, and Angelo Compare Characteristic Optimization of Multilayer Dielectric for the Bloch-Surface-Wave Based Sensor 1740 Shuna Li, Jiansheng Liu, Zheng Zheng, Yuhang Wan, Weijing Kong, Sun Yu, and Shuna Li Facial Expression Recognition Based on t-SNE and AdaboostM2 1744 Jizheng Yi, Xia Mao, Yuli Xue, and Angelo Compare A Design of Security Module to Protect Program Execution in Embedded System 1750 Wang Xiang, Zhao Zexi, Lu Ying, and Zhang Yi Improved P-T Algorithm Applied to a Wearable Integrated Physiological Parameters System 1756 Z.H.Xu, Z. Fang, Z. Zhao, X.X.Chen, D.L.Chen, F.M.Sun, L.D.Du, Y.M.Qian, H.Y.Hui and L.L.Tian Iterative Threshold Selection for TOA Estimation of IR-UWB System 1763 Xiang Wang, Bo Yin, Ying Lu, Bin Xu, Pei Du, and Limin Xiao A Novel Alternative Exponent-Weighted Fuzzy C-Means Algorithm 1767 Renhao Fan, Xiang Wang, and Jordi Madrenas A Wireless ZigBee Router with P-H-T Sensing for Health Monitoring 1773 Z. Fang, F. M. Sun, J. Tan, and Z. Zhao A Whole Integrated System for Detection of Neural Signal and Wireless Transmission 1779 Dang Hua, Qu Ruoyuan, Chen Zhiming, Gui Xiaoyan, and Wang Xinghua Research on the Monitoring and Controlling Model of SIP Network 1784 Liang Zhang, Zhaoxin Zhang, Xu Cui, and Dan Liu Saliency-Based Feature Learning for No-Reference Image Quality Assessment 1790 Zhang Hong, Feng Ren, and Yuan Ding A Compensated Technique for 2.5-GHz Ring-Oscillator-Based PLL used in Wireless Transmission 1795 Dang Hua, Liu Zicheng, Gui Xiaoyan, and Zhong Shunan Speech Synthesis Research Based on EGG 1799 Lijiang Chen, Xia Mao, Pengfei Wei, and Angelo Compare A Temperature Insensitive Ring Oscillator for Low Power RF Communications 1804 Pilong Yang, Tongsheng Xia, Hongge Li, and Xiang Wang 
xxvii 


Low-Noise Biopotential Recording Circuit with Correlated Timeshare Sampling 1810 Hongge Li and Weidong Cao A No-Reference Quality Metric for Blur Image 1813 Zhang Taojia, Zhang Hong, and Yuan Ding Circuit Design of Analog Front-End for Neural Signal Detection 1817 Dang Hua, Zhang Lei, Chen Zhiming, Gui Xiaoyan, and Wang Xinghua A New Pedestrian Detect Method in Crowded Scenes 1820 Hou Xin, Zhang Hong, and Yuan Ding Design and Implementation of a Circuit System for Neural Signal Detection 1825 Dang Hua, Li Xiao, Chen Zhiming, Gui Xiaoyan, Wang Xinghua, and Zhong Shunan Design and Implementation of a CMOS 1Gsps 5bit Flash ADC with Offset Calibration 1829 Li Shiwen, Dang Hua, Gao Peng, Gui Xiaoyan, Chen Zhiming, Wang Xinghua and Zhong Shunan Spike Detection Based on Fractal Dimension 1834 Zhou Jiyang, Xu Shengwei, Lin Nansen, Wang Mixia, and Cai Xinxia A GPU-Accelerated Large-Scale Music Similarity Retrieval Method 1839 Limin Xiao, Yao Zheng, Wenqi Tang, Guangchao Yao, Li Ruan, and Xiang Wang Power Spectral Analysis of Acupoint Bioelectricity 1844 Quan Zhou, Nansen Lin, Shuping Gai, Jingjing Zhang, Lu Zhang, Wentao Shi Renhuan Yu, and Xinxia Caii Compressive Sensing of Neural Action Potentials by Designing Overcomplete Dictionaries 1848 Shuai Zhou, Bowei Dai, Yin Xiang, Shengwei Xu, Bingchen Zhang, Yilin Song Mixia Wang, and Xinxia Cai CloudDVMM: Distributed Virtual Machine Monitor for Cloud Computing 1853 Li Ruan, Jinbin Peng, Limin Xiao, and Xiang Wang Metadata-Intensive I/O Performance Optimization by Merging Read/Write Requests 1859 Li Ruan, Qimeng Wu, Limin Xiao, Ke Xie, and Xiang Wang International Workshop on Machine-to-Machine Communication \(IWMMC 2013 Angle of Arrival Estimation for Passive UHF RFID Tag Backscatter Signal 1865 Meng-Chang Hua, Guo-Chen Peng, Yan-Jun Lai, and Hsin-Chin Liu Mobile IMS Integration of the Internet of Things in Ecosystem 1870 Han-Chuan Hsieh, Jiann-Liang Chen, Ing-Yi Chen, and Sy-Yen Kuo Design of Gateway for Monitoring System in IoT Networks 1876 Ji-De Huang and Han-Chuan Hsieh Dependable Architecture of RFID Middleware on Networked RFID Systems 1881 Yung-Li Hu, Wei-Bing Su, Yennun Huang, Ing-Yi Chen, and Sy-Yen Kuo 
xxviii 


The Design and Implementation of the Front-End Software for the Telemetry and Telecontrol System of Satellite 1885 Zhao Qi and Ma Li Internet of Things for Special Materials Transportation Vehicles 1891 Li Shengguang, Tan Lin, Zhu Yuanshuo, and Zhang Rucai Performance Analysis of COMPASS for the Asia-Pacific Region 1895 Hangyu Huo, Xiaolin Zhang, and Canhui Chen International Workshop on Localization Technology and Location-Based Services \(LTLS 2013 A KNN Indoor Positioning Algorithm That Is Weighted by the Membership of Fuzzy Set 1899 Jiankun Yu and Jianye Liu Building Location-Based Service Based on Social Network API: An Example of Check-In App 1904 Pin-Fan Lee and Shuchih Ernest Chang Prioritizing the Data in the Target-Tracking Wireless Sensor Networks 1910 Dan Xu, Xiaojiang Chen, Xiaoyan Yin, Lvju Wang, Hao Chen, Yuan Zhang, and Dingyi Fang DLF: Target Detection and Localization in Wireless Network 1916 Tianzhang Xing, Dingyi Fang, Xiaojiang Chen, Liqiong Chang, and Yuhui Ren Bandwidth Reservation for Target Tracking in Region-Base Wireless Sensor Networks 1922 Xiaoyan Yin, Dingyi Fang, Xiaojiang Chen, Hao Chen, and Wei Wei Fusion Estimation Based on UKF for Indoor RFID Tracking 1928 Xue-bo Jin International Workshop on New Media and Computer Vision for Smart City \(NMCV4SC 2013 Facile Analysis of Smartphone Comics 1932 Beili Qiu Research on Production of Regional Animation Style Based on Computer Graphic Rendering 1935 Jingjing Chen, Yi Lin, Kexuan Ma, and Yue Liu A Blind Demodulation Algorithm for MFSK Signals Using STFT-Radon-Wavelet Transform 1940 Zhang Guoyi, Qi Xinglong, Zhang Xuzhou, and Lin Caiyong A Novel Method to Remove Eye-Blink Artifacts Based on Correlation Using ICA 1946 Hengsong Sheng and Hongjun Tian Virtual Assembly, Maintenance and Training System Based on the Virtual - Real Fusion Technology 1949 Ning Wang and Yue Qi 
xxix 


International Workshop on Optical Characteristics and Applications \(OC&A 2013 A New Infrared Sensor Model Based on Imaging System Test Parameter 1953 Zheng Liu, Hong-xia Mao, Ying-hong Dai, and Jing-li Wu Mixed Norm-Based Image Restoration Using Neural Network 1957 Yuan-nan Xu, Jing Wang, and Yan-bing Dong Simulation and Analysis of Turbulent Optical Wavefront Based on Zernike Polynomials 1962 Yan Chen, Shu-hua Wang, Yuan-nan Xu, and Yan-bing Dong Study on the Interaction of Optical Field and Transverse Acoustic Mode in Silicon Optical Fibers 1967 Jing Wang, Yuan-nan Xu, and Yan-bing Dong Testing Technology of Infrared Point Source Target Optical Axis 1972 Yue Peng and Hao Lu Human Segmentation in Infrared Videos Using Markov Random Field 1976 Wenjia Yang, Xiaodan Xie, Zhi Chai, and Yapeng Li Third IEEE International Workshop on Sensing, Networking and Computing with Smartphones \(PhoneCom 2013 SmartProbe: A Bottleneck Capacity Estimation Tool for Smartphones 1980 Francesco Disperati, Dario Grassini, Enrico Gregori, Alessandro Improta Luciano Lenzini, Davide Pellegrino, and Nilo Redini CANDIS: Heterogenous Mobile Cloud Framework and Energy Cost-Aware Scheduling 1986 Sebastian Schildt, Felix B¸sching, Enrico Jˆrns, and Lars Wolf An Experimental Study on Wireless Magnetic Communication with Smart Phone Using a MEMS Magnetometer 1992 Jiabo Wang and Xi Chen PhoneJoule: An Energy Management System for Android-Based Smartphones 1996 Xiaojing Liu, Fangwei Ding, Jie Li, Haifeng Liu, Zhuo Yang, Juan Chen, and Feng Xia KeyGraph-Based Social Network Generation for Mobile Context Sharing 2002 Myeong-Chun Lee, Young-Seol Lee, and Sung-Bae Cho Cyber-physical Directory: A Dynamic Visualization of Social Media Data 2007 Jean-Loup Lamothe, James She, and Ming Cheung 
xxx 


International Workshop on Sensor Data Processing and Integration \(SDPI 2013 Capturing, Calculating, and Disseminating Real-Time CO2 Emissions and CO2 Flux Measurements via Twitter in a Smart City 2013 Laurie Butgereit and Alecia Nickless Freshness-Aware Sensor Mashups Based on Data Services 2018 Guiling Wang and Feng Zhang A Method of Sensor Data Services Query in Emergency Management 2024 Xin Chen, Yanbo Han, Yongshan Wei, Feng Zhang, and Yan Wen A Sensory-Data-Hosting Oriented Scheduling Strategy on Virtual Machine 2029 Xiang Li and Yong Jiang International Workshop on Software Engineering for Internet of Things-Based Applications \(SeIoTA 2013 From the Internet of Things to Trusted Apps for Things 2037 Christian Prehofer A Profile for Step Data Transmission Based on Bluetooth Low Energy 2043 Youcong Ni, Sun Cong, Zhao Ting, Peng Ye, Chunyan Wang, and Luo Zeng Exception Handling in Service-Oriented Software: A Survey 2048 Xue Tong, Ying Shi, and Wu Qing On the Application of the Internet of Things in the Field of Medical and Health Care 2053 Fang Hu, Dan Xie, and Shaowu Shen Hierarchical RBAC Model with Alpha Factor in the Water Supply Pipeline Network Information System 2059 Wu Ting, Yuan Tianliang, and Yu Long Modeling Concern of Online Auction System with SA-CDL 2063 Linlin Zhang, Kai Zhao, Zhenhong Jia, and Youcong Ni The Research on Interactive Exhibition Technology of Digital Museum Resources 2067 Ning Wang and Xukun Shen International Workshop on Sensor Networks and Data Communications Security \(SNDCS 2013 Integrity Protection and Attestation of Security Critical Executions on Virtualized Platform in Cloud Computing Environment 2071 Bingyu Zou and Huanguo Zhang A Fuzzing Framework Based on Symbolic Execution and Combinatorial Testing 2076 Jian Yang, Huanguo Zhang, and Jianming Fu Dynamic Knowledge Repository-Based Security Auxiliary System of User Behavior 2081 Fan Yang, Jinxia Wu, Shanyu Tang, and Huanguo Zhang 
xxxi 


Research on a New Mathematic Description for Fingerprint Identification 2085 Zhao Ma, Shanyu Tang, Liping Zhang, Linchen Yu, and Sifa Zhang Robust and Efficient Authentication Protocol Based on Elliptic Curve Cryptography for Smart Grids 2089 Liping Zhang, Shanyu Tang, Yijing Jiang, and Zhao Ma De Bruijn Graph-Based Whole-Genomic Sequence Assembly Algorithms and Applications 2094 Xiaojun Kang, Shanyu Tang, Yongge Ma, Ruixiang Liu, and Yaping Wang Review of Digital Watermarking for 2D-Vector Map 2098 Jinxia Wu, Fan Yang, and Chonglong Wu Real-Time Covert VoIP Communications over Smart Grids by Using AES-Based Audio Steganography 2102 Yijing Jiang, Liping Zhang, Shanyu Tang, and Zhangbing Zhou Improving Performance of E-Government System from the User Perspective 2108 Hang Zhang, Sifa Zhang, Muzhou Xiong, and Shanyu Tang ECC-Based Authenticated Key Agreement Protocol with Privacy Protection for VoIP Communications 2114 Shaohui Zhu, Fan Yang, Liping Zhang, Shanyu Tang, and J. Li Establishment of Security Levels in Trusted Cloud Computing Platforms 2119 Fan Yang, Li Pan, Muzhou Xiong, and Shanyu Tang Efficient Divisible E-Cash in the Standard Model 2123 Jiangxiao Zhang, Zhoujun Li, Hua Guo, and Chang Xu International Workshop on Secure Smart Objects \(SSO 2013 Towards a Modular and Lightweight Model for Android Development Platforms 2129 Mussab Zneika, Hasan Loulou, Fatiha Houacine, and Samia Bouzefrane Towards a Secure Identity Management in Smartphone Environments 2133 Maryline Laurent, Samia Bouzefrane, and Christophe Kiennert Third International Workshop on Trends and Future of Web Science \(TFWS 2013 Extracting Protein Terminologies in Literatures 2136 Jangwon Gim, Donald J. Kim, Myunggwon Hwang, Sa-kwang Song, Do-Heon Jeong and Hanmin Jung Author Name Disambiguation in Technology Trend Analysis Using SVM and Random Forests and Novel Topic Based Features 2141 Sebastian Kastner, Sung-Pil Choi, and Hanmin Jung Research on Quantum-Bit Error Correction Coding for Smart Grid Substation 2145 Xin Miao and Xi Chen 
xxxii 


Fourth International Workshop on Universal User Modeling and Applications \(UUMA 2013 The Research of MEICSP Model through a REST Web Service 2148 Zhilei Huang, Lingyu Xu, and Yang Liu A Text Association Rules Mining Method Based on Concept Algebra 2153 Feiyue Ye, Jiannan Xiong, and Lingyu Xu Research and Application of the Intelligent Flow 2159 Yang Liu, Lingyu Xu, Liang Chen, and Fei Zhong Application of Hybrid MPI+TBB Parallel Programming Model for Traveling Salesman Problem 2164 Jinke Zhu and Qing Li Data Deduplication Cluster Based on Similarity-Locality Approach 2168 Xingyu Zhang and Jian Zhang The Application of the Knowledge Representation Based on Concept Algebra in the Knowledge Management System of Petroleum Enterprise 2173 Hongjie Duan, Shanpeng Wu, and Feiyue Ye A New Reliable Hybrid Algorithm for Shortening the Expanding Range of Interval 2178 Cheng Chen and Yongmei Lei A Novel Data Encryption in HDFS 2183 Thanh Cuong Nguyen, Wenfeng Shen, Jiwei Jiang, and Weimin Xu The Dynamically Efficient Mechanism of HDFS Data Prefetching 2188 Shaochun Wu, Guobing Zou, Honghao Zhu, Xiang Shuai, Liang Chen, and Bofeng Zhang Multi-granularity Recommendation Based on Ontology User Model 2194 Jianxing Zheng, Bofeng Zhang, and Guobing Zou Friend Recommendation Based on the Similarity of Micro-blog User Model 2200 Fan Tang, Bofeng Zhang, Jianxing Zheng, and Yajun Gu The Research of Image Detail Enhancement Algorithm with Laplacian Pyramid 2205 Yanwen Teng, Fuyan Liu, and Ruoyu Wu Information Gain with Weight Based Decision Tree for the Employment Forecasting of Undergraduates 2210 Yue Liu, Lingjie Hu, Fei Yan, and Bofeng Zhang A User Model-Based Resource Scheduling Framework 2214 Guannan Hu, Wenhao Zhu, Kangkang Niu, and Wu Zhang A Novel Method of Adopting Graph Reduction for Resource Management in Parallel Computing Model 2218 Shen Chao and Tong Weiqin Sentiment Classification for Topical Chinese Microblog Based on Sentences' Relations 2221 Kang Wu, Bofeng Zhang, Jianxing Zheng, and Haidong Yao An Anomaly Intrusion Detection Method Based on PageRank Algorithm 2226 Quan Qian, Jianyu Li, Jing Cai, Rui Zhang, and Mingjun Xin 
xxxiii 


Distributed File System and Classification for Small Images 2231 Shaojian Zhuo, Xing Wu, Wu Zhang, Xing Wu, and Wanchun Dou The Possibility of Normal Gait Analysis Based on a Smart Phone for Healthcare 2235 Susu Jiang, Bofeng Zhang, Guobing Zou, and Daming Wei IoT/CPS Demo and Exhibition Mo-Fi: Discovering Human Presence Activity with Smartphones using Non-intrusive Wi-Fi Monitors 2241 Weijun Qin, Hongsong Zhu, Jiadi Zhang, and Bo Li Towards a Pervasive Cloud Computing Based Food Image Recognition 2243 Wenshan Wang, Pengcheng Duan, Weishan Zhang, Faming Gong, Peiying Zhang and Yuan Rao Wireless IoT Platform Based on SDR Technology 2245 Yong Hua Lin, Qing Wang, Jun Song Wang, Ling Shao, and Jianbin Tang Join the Workshop Better with Telepresence Capturer 2247 Pin Tao, Lixin Feng, and Minxi Yu InSciTe Adaptive: R&D Decision Support System for Strategic Foresight 2249 Jangwon Gim, Do-Heon Jeong, Myunggwon Hwang, Sung-Pil Choi, Donald J. Kim Seungwoo Lee, Sa-kwang Song, and Hanmin Jung Author Index 2251 
xxxiv 


FrA6 \226 Privacy and Big Data Visitor Center   Chair Oh, Sewoong University of Illinois  Organizer\(s Duchi, John University of California, Berkeley  Oh, Sewoong University of Illinois Viswanath, Pramod University of Illinois  Local Privacy and Statistical Minimax Rates 1592  Duchi, John C University of California, Berkeley  Jordan, Michael I University of California, Berkeley  Wainwright, Martin J University of California, Berkeley  Differential Privacy, Equilibrium, and Efficient Allocation of Resources 1593  Roth, Aaron University of Pennsylvania  A Bayesian Method for Matching Tw o Similar Graphs without Seeds 1598  Pedarsani, Pedram 311cole Polytechnique F\351d\351rale de Lausanne  Figueiredo, Daniel R Federal University of Rio de Janeiro  Grossglauser, Matthias 311cole Polytechnique F\351d\351rale de Lausanne  Privacy as a Coordination Game 1608  Ghosh, Arpita Cornell University  Ligett, Katrina California Institute of Technology  De-Anonymizing Private Data by Matching Statistics 1616  Unnikrishnan, Jayakrishnan 311cole Polytechnique F\351d\351rale de Lausanne  Movahedi Naini, Farid 311cole Polytechnique F\351d\351rale de Lausanne  Robust Subspace Iteration and Privacy-Preserving Spectral Analysis 1624  Hardt, Moritz IBM Research Almaden  Privacy-Utility Tradeoff und er Statistical Uncertainty 1627  Makhdoumi, Ali Massachusetts Institute of Technology  Fawaz, Nadia Technicolor   


Copyright © 2009 Boeing. All rights reserved Advanced Arrival Procedures with Active Abatement Potentials   9/23/10  32 Backup Slides 


Copyright © 2009 Boeing. All rights reserved  Initial Approach Initial Investigations  Apache Solr/Lucene  Data Warehouse Evaluate Hadoop in the future 


Copyright © 2009 Boeing. All rights reserved  Using SOLR Uncompress Track Information Messages To use with Solr  Transforming track messages from their  original schema to Solr required building a ìkey, valueî list using an XSTL  Queries made against this list of ìkey, valueî pairs Transformation Process  One day of data ~ 4.5 hours Once transformation complete search/query performance very good Geo spatial queries using  unique query language 


Copyright © 2009 Boeing. All rights reserved  Representation Aviation data is frequently represented in more than one form 


