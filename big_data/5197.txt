Ef“cient Updates in Cross-Object Erasure-Coded Storage Systems Kyumars Sheykh Esmaili School of Computer Engineering Nanyang Technological University Singapore kyumarss@ntu.edu.sg Aatish Chiniah Computer Science and Engineering Department University of Mauritius Mauritius a.chiniah@uom.ac.mu Anwitaman Datta School of Computer Engineering Nanyang Technological University Singapore anwitaman@ntu.edu.sg Abstract In the past few years erasure codes have been increasingly embraced by distributed storage systems as an alternative for replication since they provide high fault-tolerance for low overheads Erasure codes however have few shortcomings that need to be addressed to make them a complete solution for networked storage systems Lack of support for ef“cient data repair and data update are the two most notable shortcomings We recently proposed to use a 2-dimensional product code Reed-Solomon coding per object and simple XORing across objects and showed that at a reasonable storage overhead it can greatly reduce the repair cost In this paper we propose an ef“cient approach to handle data updates in cross-object erasure-coded storage systems Our proposed solution has been implemented and experimentally evaluated Our results show that compared to the naive approach re-encoding the data our proposed scheme can considerably decrease the update cost especially for when the number of updated blocks is small I I NTRODUCTION In the past few years erasure codes most prominently Reed Solomon RS codes have been increasingly embraced by distributed storage systems as an alternative for replication In the coding scheme of RS n  k  an object consisting of k blocks is encoded into n blocks  k<n  in a way that the original object can be recreated from any k subset of the n encoded pieces The main advantage of erasure codes compared to replication is that they provide higher fault-tolerance for lower overheads However as erasure codes were originally designed for a different environment error control in transmission of one-time messages over an erasure channel they do not consider two of the essential constraints/properties of distributed storage systems i data is scattered among a large number of storage nodes connected through a network with limited bandwidth and ii data has a long lifespan during which its content may be updated These constraints result in several shortcomings that need to be addressed to make erasure codes a complete solution for networked storage systems Two of the most notable such shortcomings are lack of support for ef“cient data repair and update  The naive approach to address these problems are costly More speci“cally to repair one single block in a storage system encoded with RS n  k  k other blocks must be fetched and  This work was supported by A*Star SERC Grant No 102 158 0038 Aatish Chiniah contributed to this work while he was a student at NTU then decoded Likewise upon updating one single block in the same system all the k blocks are fetched and re-encoded again These are clearly inef“cient solutions especially in cases where the repair/update size i.e number of affected data blocks is small and the costs are not amortized Recently we proposed to use cross-object redundanc y to reduce repair cost by combining simple and mature techniques  juxtaposing RS codes with RAID-4 like parity This proposal was later realized 3 as CORE storage primiti v e hereafter CORE and its bene“ts in terms of repairability over the other alternatives were demonstrated through analytical and experimental studies In this paper we aim at addressing the update problem in CORE by designing an update scheme that is more ef“cient than re-encoding the whole data At a very high level our solution belongs to the family of parity update solutions  6 in which rst data diff-blocks i.e the difference between the old and the new versions of the updated blocks are computed and then they are used to compute the new versions of the affected parity blocks However as we argue in Section II-C apart from the general idea the existing proposals on parity update are not applicable to CORE and the representation of RS codes that it uses To address these issues we make the following contributions in this paper  we de“ne the theoretical foundations for parity update in the generator polynomial representation of RS codes  we implement the re-encoding as well the parity update approaches and integrate them into the CORE system  we study the effectiveness of the aforementioned update techniques analytically and experimentally We would like to note that the applicability of theoretical aspects reported in this paper particularly the rst contribution in the list above is not limited to the CORE system and can in fact be adopted by any system that uses similar codes/representations and speci“cally this includes the standard codes/representations and speci“cally this includes the standard HDFS-RAID implementation The rest of this paper is structured as follows We rst give a short overview of the relevant background in Section II Then we explain the details of COREs update handling approaches 978-1-4799-1293-3/13/$31.00 ©2013  IEEE 


a 6 a 7 a 8 b 6 b 7 b 8 c 6 c 7 c 8 p 6 p 7 p 8 c 3 c 4 c 5 c 0 c 1 c 2 a 3 a 4 a 5 b 3 b 4 b 5 a 0 a 1 a 2 b 0 b 1 b 2 p 3 p 4 p 5 p 0 p 1 p 2 Three Objects in a RS\(9,6 Scheme Vertical XOR Parities Fig 1 Illustration of COREs Basic Idea in Section III A brief description of the implementation is given in Section IV and the subsequent experimental results are presented in Section V Finally the paper is concluded in Section VI II B ACKGROUND This section gives a short overview of the background i.e the CORE storage primitive II-A the two representations of RS codes II-B and a very brief survey of the related work on ef“cient updates in erasure coded storage systems II-C A The CORE Storage Primitive CORE builds upon a simple observation by introducing a RAID-4 like parity over t erasure encoded pieces resulting in whats called CORE matrix of size n,k,t  it is possible to achieve signi“cant reduction in the expected cost to repair missing/corrupt blocks In fact in the average case not only fewer blocks are needed to carry out repairs but also the required computations are simpler and cheaper XOR instead of RS decoding Figure 1 shows an example of CORE\(9,6,3 three distinct objects  a  b  and c  each comprising of 6 blocks are rst individually encoded using an RS\(9,6 code Note that each data objects parity blocks are depicted next to it in gray color Additionally a simple XOR parity check is computed over each columns blocks and thereby a new row is added at the bottom of the matrix In this example repairing any single failure would only require XORing 3 blocks It is worth noting that the price paid for COREs repair ef“ciency is the extra storage overhead the last row in Figure 1 However as the detailed analysis and discussions in show in realistic settings this extra overhead is reasonably low and comparable with those of the existing repairable code alternatives This idea along with a set of related algorithms e.g ef“cient scheduling of multiple repairs were later implemented as the CORE storage primitive 3 and its performance was thoroughly evaluated B Reed-Solomon Representations The construction method proposed in the original ReedSolomon code paper is based on V andermonde matrices and is non-systematic  hence it is seldom used for storage systems However two other methods one using a matrix representation and the other one using a polynomial representation were later proposed to construct systematic Reed-Solomon codes  Cauchy Generator Matrix  this representation is based on a Cauchy matrix G n  k which contains the Identity matrix I k  k  As shown below to encode a message M of size k  it is multiplied by G  resulting in a codeword composed of the original data message M and the parity message P of size n  k             1  0     0  1 g 0  0  g 0 k  1     g n  k  1  0 g n  k  1 k  1                m 0   m k  1                m 0   m k  1 p 0   p n  k  1            For a detailed example of the process see  Generator Polynomial  This approach uses a generator polynomial g  x  which consists of n  k 1 factors and its roots are consecutive elements of the Galois Field GF g  x  n  k  i 0 g i x i Moreover the message elements are also represented as coef“cients of a polynomial m  x   To encode m  x   it is rst multiplied by x n  k and then divided by the generator polynomial g  x   The coef“cients of the remainder polynomial r  x  are the output parity elements m  x   x n  k  r  x od g  x  1 or k  1  i 0 m i x i  n  k  n  k  1  i 0 r i x i mod n  k  i 0 g i x i 2 A set of numerical example of the process can be found in Except for few recent instances including HDFS-RAID which the CORE implementation is built upon the storage community has been traditionally using the generator matrix representation On the other hand as noted in in the error control literature the generator polynomial representation is more commonly used C Related Work Research on updates in erasure coded storage systems has been centered around size-preserving 1 block updates 6  5 15 16 The nai v e approach to handle updates in erasure-coded storage system is to re-encode the data blocks and generate new parity blocks from scratch This approach is clearly quite expensive especially when the update size number of updated blocks is small Hence improving the ef“ciency of update handling in erasure-coded storage systems is crucial In storage systems like CORE that maintain additional redundancies the need for ef“cient update solutions in even more crucial  1 Size-increasing and size-decreasing updates can be handled through adding new blocks and zero-padding of the updated blocks respectively 29 


a 6 a 7 a 8 b 6 b 7 b 8 c 6 c 7 c 8 p 6 p 7 p 8 c 3 c 4 c 5 c 0 c 1 c 2 a 3 a 4 a 5 b 3 b 4 b 5 a 0 a 1 a 2 b 0 b 1 b 2 p 3 p 4 p 5 p 0 p 1 p 2 a Re-encoding a 6 a 7 a 8 b 6 b 7 b 8 c 6 c 7 c 8 p 6 p 7 p 8 c 3 c 4 c 5 c 0 c 1 c 2 a 3 a 4 a 5 b 3 b 4 b 5 a 0 a 1 a 2 b 0 b 1 b 2 p 3 p 4 p 5 p 0 p 1 p 2 b Parity Update Fig 2 The Two Update Approaches in CORE Apart from few recent proposals 16 that aim at designing new and inherently update-ef“cient erasure codes the majority of previous work 6 14 5 on update in erasure-coded storage systems use the classic ReedSolomon codes and are primarily concerned with the concurrency/consistency tradeoff There are nonetheless a number of papers 5 6 in which the idea of ef cient update of erasure coded data has been discussed The existing solutions however are not directly applicable to the CORE system for the following reasons i they all target the generator matrix representation of RS code see for detailed explanations and formulas and not the generator polynomial representation which is used in HDFS-RAID and consequently in our CORE implementation In fact to the best of our knowledge designing parity update schemes for the generator polynomial representation of RS codes remains an open problem and ii CORE has an extra set of vertical XORbased parities In this paper we address these issues and analyze the effectiveness our solution through analytical and empirical studies III U PDATE H ANDLING IN CORE In the following we rst give an overview of both reencoding and parity update approaches in CORE III-A Then after presenting the formal foundations of parity update approach for horizontal III-B and vertical III-C parities we analytically compare both approaches III-D A Overview Figure 2 highlights the differences between the two update approaches while handling one single update  a 1 n CORE n=9,k=6,t=3  The chain of steps taken in each case are as follows  re-encoding  i fetch a 0 a 5  the k blocks of the updated object and encode them to generate a 6 a 8  the new n  k parities ii fetch a 1 b 1 c 1  the t data blocks on the updated column and XOR them to generate p 1  the new vertical parity iii similarly generate p 6 p 8  the other n  k vertical parities  parity update  i rst calculate  a 1  the diff-block of the updated data block and use it to generate  a 6   a 8  the diff-blocks of the horizontal parities ii combine  a 6   a 8 and the old versions of a 6 a 8 to compute their new versions iii use  a 1 and the old version of p 1 to compute its new version iv likewise update p 6 p 8  the n  k vertical parities B Updating Horizontal Parities Lets assume that the updated message is represented by m   x   meaning m   x   x n  k  r   x od g  x  3 without the loss of generality lets also assume that only the rst data block of the message m  x  has been updated More precisely m 0   m  0   i  0 m i  m  i now by summing up equation 1 and equation 3 we obtain  m  x  m   x   x n  k   r  x  r   x  mod g  x  or in the  form 2  k  1  i 0  m i  x i  n  k  n  k  1  i 0  r i  x i mod n  k  i 0 g i x i but since  i  0 m i  m  i   i  0 m i 0 then  m 0  x n  k  n  k  1  i 0  r i  x i mod n  k  i 0 g i x i 4 In other words the parity update mechanism when only the rst data block  m 0  has been updated is as follows i compute  m 0  ii encode  m 0  the outputs are   r i   0  i  n  k  1  iii for each i  use  r i and the old version of r i to generate its new version   r i  r i  r  i  Note that the formula in 4 can easily be generalized  i  m i   m  i  m i  x i  n  k  n  k  1  i 0  r i  x i mod n  k  i 0 g i x i 5  2 Notice that in the GF\(2 arithmetic m 0  m  0  m 0  m  0  m 0  30 


C Updating Vertical Parities Due to the simple and commutative nature of the XOR operation updating the vertical parities of the CORE matrix is straightforward If p is the vertical parity of a given column of t blocks t  1  j 0 m j  p then it can be immediately inferred that t  1  j 0  m j  p  p  6 In other words the new version of the parity block can be obtained by XORing its old version with the diff-blocks of the updated data blocks D Analytical Comparison Next we present a set of cost functions that re”ect the analytical cost of using the re-encoding and the parity update approaches For the sake of simplicity we limit our study to centralized update managers Moreover to measure the update cost we consider the statically-computable read traf“c  i.e the amount of data read by the update manager during the process in the centralized case the write traf“cs of both approaches are identical  Re-encoding Parity Update Single Column t 2 u 1 Single Row k 2 u  n  k  Full Matrix k  u.t  n  k  t 2 u  n  k  u  n  k  Full Matrix u.k  t  n  k  t 2 u  u  n  k   n  k  TABLE I Amount of Data to Fetch to Perform u Updates Table I shows the generalized cost functions of both approaches for XOR parities  Single Column  the RS codes  Single Row  and the complete CORE matrix  Full Matrix  In this table u denotes the update size Furthermore since in the full matrix there are many possible distributions for u updates we have considered only two special cases all in one row denoted by   and all in one column denoted by   Finally its worth noting that the coef“cient 2 in the parity update cost functions represent the fact that to compute each diff-block both the old and the new versions of that particular block must be read Lets again consider the example given in Figure 2 where in the CORE matrix of size n=9,k=6,t=3 one data block has been updated u=1  In this example the overall cost read traf“c of the re-encoding and the parity update approaches are 18 and 9 blocks respectively One important conclusion from these cost functions is that the bene“ts of parity update approach are more visible in case of small updates In fact as shown in and con“rmed later in our experiments for a given object if the number of updated blocks is high e.g more than half of its blocks the naive alternative re-encoding from scratch can be not only competitive but even preferred since the costs are amortized IV I MPLEMENTATION The update approaches explained in Section III have been implemented and integrated into the CORE storage primitive which itself has been de v eloped on top of F acebook s HDFS-RAID HDFS-RAID embeds the Apache HDFS 18 inside an erasure code-supporting wrapper le system named Distributed Raid File System DRFS DRFS supports both Reed-Solomon coding as well as simple XOR parity les One of the main components of HDFS-RAID is RaidNode which is a daemon responsible for the creation and maintenance of parity les Since neither Apache HDFS nor HDFS-RAID support data updates we rst added a feature to the CORE implementation which replaces certain blocks of a le with some other pre-de“ned blocks Our implementation of the re-encoding approach uses extended versions of the CORE functionalities to recompute the horizontal and vertical parities of the affected rows and columns The parity update approach rst deals with the horizontal parities according to equation 5 and then with the vertical parities according to equation 6 In both cases all the computations are performed in a centralized fashion at RaidNode The correctness of our implementation was veri“ed through multiple test cases in which the MD5 hash values of the updated parity les generated by the re-encoding and the parity update approaches were compared against each other The source codes binary distribution documentations and a visualized demo based on the actual implementation functions are available at http://sands.sce.ntu.edu.sg/StorageCORE  V E XPERIMENTS We benchmarked the implementation with experiments run on a cluster of 20 nodes which has one powerful PC 4  3.2GHz Xeon Processors with 4GB of RAM hosting the NameNode/RaidNode and 19 HP t5745 ThinClients acting as DataNodes each with an Intel Atom N280 Processor 1.66 GHz with 1 GB of RAM and a solid state drive of 2 GB The average bandwidth of this cluster is 12MB/s We ran two sets of experiments In the rst set we compare the performance of the re-encoding versus parity update schemes for one block update in the context of one single object row as well as the full CORE matrix In the second set we study the impact of update size parameter and identify the sweet spots of each of the update approaches In both sets we used two groups of CORE matrix parameters n=9,k=6,t=3 and n=14,k=12,t=5  inspired by the code length and storage overheads of Googles GFS and Microsoft Azure respectively Moreover the block size used was 64MB HDFSs default value Finally although in each experiment we measured both completion time and data traf“c  but due to space limitation we only present the time results the data results are in line with the cost functions of Section III-D A Ef“ciency of the Parity Update Approach We rst compare the ef“ciency of the update schemes for one block update  u=1  Figure 3 shows the completion time of a single update at the level of a row part 3a and the whole 31 


0 20 40 60 80 100 123456 Re encoding Parity Update Time seconds Number of Block Updates a In RS 9,6 0 20 40 60 80 100 120 140 123456789101112 Re encoding Parity Update Time seconds Number of Block Updates b In RS 14,12 Fig 4 Impact of Update Size on the Performance of the Update Approaches in the Polynomial Representation of RS Codes 0 20 40 60 80 100 n=9,k=6,t=3 n=14,k=12,t=5 Re encoding Parity Update Time seconds a Within a Row 0 50 100 150 200 250 n=9,k=6,t=3 n=14,k=12,t=5 Re encoding Parity Update Time seconds b Within the Full Matrix Fig 3 Completion Time of Handling One Block Update CORE matrix part 3b In accordance with the cost functions of Table I the results show a signi“cant gain in the update time specially in the CORE\(14,12,5 B Impact of Update Size As highlighted in Section III-D for large number of block updates the naive data re-encoding approach can be competitive To obtain some insights about the crossover point between the two approaches we ran an experiment in which the update size parameter u was varied between 1 minimum and k maximum the full object size A subset of the results only for the RS parities are depicted in Figure 4 and show that when around more than half of the blocks of an object are updated  u  k 2  the naive re-encoding approach can outperform the parity update approach These results are similar to those reported in where the authors measured the impact of update size in the matrix representation of RS codes Based on this observation we ultimately incorporate in our CORE implementation a hybrid approach that can adaptively decide between the two schemes based on the values of u and k  Such approach can offer the best update performance under all circumstances VI C ONCLUSIONS AND F UTURE W ORK In this paper we addressed the problem of ef“cient updates in the CORE storage primitive a cross-object erasure-coded storage system We de“ned and implemented a parity update scheme which outperforms the naive approach of data reencoding The bene“ts of our solution are especially pronounced in cases where the number of updated blocks is small Our current implementation of the update manager has a centralized design In future we plan to further optimize the update process by exploiting the computational resources of the storage nodes and in doing so reduce the update traf“c over network and further lower the update time R EFERENCES  A Datta and F  Oggier  Redundantly Grouped Cross-object Coding for Repairable Storage in Proceedings of the Asia-Paci“c Workshop on Systems  2012 p 2  K S Esmaili L P amies-Juarez and A Datta The CORE Storage Primitive Cross-Object Redundancy for Ef“cient Data Repair  Access in Erasure Coded Storage CoRR  vol abs/1302.5192 2013  K S Esmaili L P amies-Juarez and A Datta CORE Cross-Object Redundancy for Ef“cient Data Repair in Cloud Storage Systems in Proceedings of the IEEE International Conference on Big Data  2013  F  Zhang J Huang and C Xie T w o Ef cient P artial-Updating Schemes for Erasure-Coded Storage Clusters in Proceedings of the 2012 IEEE Seventh International Conference on Networking Architecture and Storage  ser NAS 12 2012 pp 21…30  K Peter and A Reinefeld Consistenc y and F ault T olerance for Erasure-coded Distributed Storage Systems in Proceedings of the 5th International Workshop on Data-Intensive Distributed Computing Date  2012 pp 23…32  M K Aguilera R Janakiraman and L Xu Using Erasure Codes Ef“ciently for Storage in a Distributed System in Proceedings of the International Conference on Dependable Systems and Networks DSN  2005 pp 336…345  HDFS-RAID http://wiki.apache.or g/hadoop/HDFS-RAID  I S Reed and G Solomon Polynomial Codes Ov er Certain Finite Fields Journal of the Society for Industrial  Applied Mathematics  vol 8 no 2 pp 300…304 1960  J Bloemer  M  Kalf ane R Karp M Karpinski M Luby  and D Zuckerman An XOR-Based Erasure-Resilient Coding Scheme International Computer Science Institute Tech Rep TR-95-048 1995  J S Plank and C Huang T utorial Erasure Coding for Storage Applications The 11th Usenix Conference on File and Storage Technologies FAST13 2013  S B W ick er and V  K Bhar ga v a  Reed-Solomon Codes and Their Applications  Wiley-IEEE Press 1999  U of Ne w Brunswick EE4253 Digital Communications  http://www.ee.unb.ca/cgi-bin/tervo/rscodes.pl 2013  S Frolund A Merchant Y  Saito S Spence and A V eitch A Decentralized Algorithm for Erasure-coded Virtual Disks in Proceedings of the International Conference on Dependable Systems and Networks DSN  2004 pp 125…134  P  Sobe A P artial-Distrib ution-F ault-A w are Protocol for Consistent Updates in Distributed Storage Systems in Proceedings of the 5th IEEE International Workshop on Storage Network Architecture and Parallel I/Os  2008 pp 54…61  A Ra w at S V ishw anath A Bho wmick and E Soljanin Update Ef cient Codes for Distributed Storage in Information Theory Proceedings ISIT 2011 IEEE International Symposium on  2011 pp 1457…1461  Y  Han H.-T  P ai R Zheng and P  K V arshne y  Update-Ef cient Error-Correcting Regenerating Codes arXiv preprint arXiv:1301.4620  2013  CORE http://sands.sce.ntu.edu.sg/StorageCORE  HDFS http://hadoop.apache.or g/hdfs 32 


goal mining plan mining Discovered innovations innovation harvesting 
n n 
 M J Bitner  A L Ostrom and F  N Mor gan Service blueprinting A practical technique for service innovation  50\(3  94 2008  R K et al Breakthrough ideas for 2005  83\(2  54 2005  A K Ghose and G K oliadis Auditing b usiness process compliance In  2007  A K Ghose G K oliadis and A Cheung Rapid b usiness process discovery r-bpd In  SPringer LNCS 2007  A K Ghose E Morrison and L.-S Le Correlating ser vices with business objectives in the servalign framework In  Springer LNBIP 2013  P  D Hertog Kno wledge-intensi v e b usiness services as coproducers of innovation  4\(4 2000  K Hinge A Ghose and G K oliadis Process seer A tool for semantic effect annotation of business process models In  pages 54 63 2009  E Klein Computational semantics in the natural language toolkit In  2006  G K oliadis and A K Ghose Relating b usiness process models to goal-oriented requirements models in kaos In  2006  G K oliadis and A K Ghose Semantic v eri“cation of b usiness processes in inter-operation In 
6 Systematized innovation 7 Conclusions References 
for each decision Our approach to involves an extension of the effect mining machinery for business processes described in the previous section Our approach to  as described in e xtends the process mining machinery implemented in ProM Our approach to the mining of objective functions involves plotting each decision entry in the behaviour log in an dimensional space where is the number of distinct QoS variables and using support vector machines to infer the best expression in terms of the available QoS variables that discriminates between the available options and selected one We do not detail this machinery here due to space constraints The key observation here is that it is possible to devise automated machinery for inferring enterprise intent from logs of enterprise behaviour As discussed earlier innovation requires a departure from past precedent Yet many current approaches to supporting innovation such as open innovation portals  are somewhat ad-hoc and have met with limited success We argue that innovation must ultimately be underpinned by systematic search The best metaphor is that of Thomas Edisons search for the material that would serve as the lament of the electric bulb His search was systematic through a space of several thousand materials until he met with success with tungsten Service innovation can be similarly conceived of as a search problem The search problem can be characterized by 1 a search space 2 innovation driver and 3 the search constraints Consider the search for innovative process designs We might be given an existing process design with the need to improve processing time being the innovation driver The search space in this instance would be the space of all possible process designs that might be generated from the current set of enterprise capabilities even this set might be treated as extensible in more complex formulations of the problem The set of search constraints would include the requirement to preserve the functionality of the current process We would search through the space of process designs that realize the current process functionality this might be speci“ed in terms of the nal effect scenarios of the current semantically annotated process design to identify the design that minimizes processing time Our current research addresses this problem The search space is typically quite large and good heuristics are required to improve search ef“ciency Yet it is useful to note that there are few real-time constraints on this search which might be executed in the background over a prolonged period of time  not only from process designs but for other types of artefacts involved in the speci“cation of an enterprise architecture can be systematically derived via a process of search as outlined above This is a critical ingredient of service innovation where we recognize the limits of big data analytics and seeks to surpass these using systematic search This paper argues that a novel approach to big data analytics offers interesting solutions in this space The paper argues that the use of big data analytics for generating enterprise service insights is often ignored while the extraction of insights about customers the market and the enterprise context has received considerable attention The paper offers a set of techniques collectively referred to as  which leverage big data in various forms including object state sensor data behaviour logs as well large-scale sources of open data such as the web to mine service innovation insights The paper also outlines how systematic search might help overcome the limitations of big data analytics in this space 
California Management Review Harvard Business Review Proceedings of the International Conference on Service-Oriented Computing ICSOC-07 Proc of the 2007 ER Conference ER-2007 Proc of the CAISE-2013 Workshop on Business IT Alignment BUSITAL-13 International Journal of Innovation Management Enterprise Distributed Object Computing Conference 2009 EDOC 09 IEEE International Proceedings of the 2006 Australasian Language Technology Workshop ALTW2006 Proc of the 2006 Paci“c-Rim Knowledge Acquisition Workshop PKAW-2006 Proc of the 2007 IEEE 
213 


Services Computing Conference Proc of the 2008 IEEE Services Congress IBM Systems Journal Commun ACM IEEE Trans Knowl Data Eng Proc of the AAMAS-2013 Workshop on Engineering Multi-Agent Systems 
 IEEE Computer Society Press 2007  G K oliadis and A K Ghose T o w ards an enterprise b usiness process architecture standard In  IEEE Computer Society Press 2008  I Miles P atterns of inno v ation in service industries  47\(1 2008  J Spohrer and D Rieck en Introduction  49\(7 July 2006  W  M P  v an der Aalst T  W eijters and L Maruster  W ork”ow mining Discovering process models from event logs  16\(9 2004  H Xu B T  R Sa v arimuthu A K Ghose and E Morrison Automatic bdi plan recognition from process and logs and event logs In  
214 


propose to build a problem solving framework from a knowledge management base on the SVB The general target is to easy the complexity of the E-Tourism system building and the comprehensive improvement of the pro“ting on the service provider side the satisfaction and acceptance on the customer side and the eciency and precision of the market surveillance and control from the public administrative side In the future we will improve the added value modeling modules on each parties and consider comprehensive business application We would like to apply the prototype system to collect rst hand feedback from the ETourism markets in speci“c agencies in Hainan province for further modi“cations and deeper Big Data analysis The future work will also include exploring the direction of SVB composition for MashUp development Acknowledgment This paper was supported in part by NSFC grant 61162010 and 61363007 and by Hainan University grant KYQD1242 and HDSF-A01 represents corresponding author References  M  B ic hler A  S egev a nd C Beam  An electronic broker for business-to-business electronic commerce on the internet Int J Cooperative Inf Syst vol.7,no.4 pp 315…330 1998  D  B udgen M  Rigb y  P  B rereton and M  T urner A data integration broker for healthcare systems IEEE Computer  vol 40 no 4 pp 34…41 2007  V  C ardellini E Casalicc hio V Grassi a nd R Mirandola A framework for optimal service selection in broker-based architectures with multiple qos classes in SCW  2006 pp 105…112  F  C asati S Ilnic k i L.-j J in V  K rishnamo orth y  and M.-C Shan Adaptive and dynamic service composition in e”ow in CAiSE 2000  pp 13…31  D  A  D Mello V  S  A nan t hanara y a na a nd S Thilagam A qos broker based architecture for dynamic web service selection in Proceedings of AMS2008  pp 101 106  Y  D uan A Surv ey on Service C on tract i n SNPD  IEEE Computer Society 2012 pp 805…810    Service Con t racts Curren t state a nd F u ture Directionsmeasure in ICWS  2012 pp 664…665    V alue Mo deling and C alculation for E v e rything as a Service XaaS based on Reuse in Proceedings of SNPD 2012  IEEE Computer Society 2012  Y  D uan A Kattepur and W  D u Service v a lue b rok e r patterns Integrating business modeling and economic analysis with knowledge management in IEEE ICWS  June 2013 pp 615…616  Y Duan A  K attepur H Zhou Y  C hang M  H uang and W Du Service value broker patterns towards the foundation in IEEE ICIS2013     Service v alue brok er patterns A n e mpirical collection in IEEE SNPD  2013 pp 675…682  Y Duan H  Z hou Y Chang M Huang S Chen A Elfaki and W Du Characterizing e-service economics based on e-contract and driven by e-value in IEEE ICIS2013   R F a rmer A  R a y b o ne R  U ddin M Odeta y o and K M Chao Metadata discovery for a service-broker architecture in Proceedings of the 2008 IEEE International Conference on e-Business Engineering  pp 173…178  M F e ldstein Domestic s a v ing a nd in ternational capital movements in the long run and the short run National Bureau of Economic Research Tech Rep 947 1982  E Gamma R Helm R  E  J ohnson a nd J M Vlissides Design patterns Abstraction and reuse of objectoriented design in ECOOP  1993 pp 406…431  A Kattepur A Ben v eniste a nd C Jard Optimizing decisions in web services orchestrations in ICSOC  2011 pp 77…91  A Kumar.p.s G Mahadev a n and G  K rishna.c  Article A qos towards dynamic web services recapitulation and selection International Journal of Computer Applications  vol 54 no 4 pp 12…18 September 2012 18 K  J L i n H L u  T  Y u a n d C  e T a i   Ar e p u t a t i o n and trust management broker framework for web applications in Proceedings of the IEEE EEE  2005 pp 262…269  S Loreto T  M ec klin M  O psenica and H M Rissanen Service broker architecture location business case and mashups Comm Mag  vol 47 no 4 pp 97…103 Apr 2009  B Mo ore a nd Q H Mahmoud A service b rok e r a nd business model for saas applications in AICCSA  2009 pp 322…329  Z P a n a nd J Baik  Qos b rok e r-based t rust m o d el for eective web service selection in Proceedings of the 11th IASTED SEA2007  Anaheim CA USA pp 590…595  D Plummer Cloud services brok erage A m u st-ha v e for most organizations A v a ilable h ttp www.forbes.com/sites/gartnergroup/2012/03/22 cloud-services-brokerage-a-must-have-for-most-organizations  Z Qian S  L u and L  X ie  Mobile-agen t based w e b service composition in 4th Intl conf on Grid and Cooperative Computing  pp 35…46  S Ran A mo del f or w e b s ervices d isco v e ry with qos SIGecom Exch  vol 4 no 1 pp 1…10 Mar 2003  F Rosen b erg a nd S Dustdar Design a nd implementation of a service-oriented business rules broker in CECW  2005 pp 55…63  H L T ruong M  C omerio F  D  P aoli G R Gangadharan and S Dustdar Data contracts for cloud-based data marketplaces IJCSE  vol 7 no 4 pp 280…295 2012  S V e n u gopal R Buyy a and L  W in ton A grid service broker for scheduling distributed data-oriented applications on global grids in MGC  2004 pp 75…80  Y W a ng and J  W ei  Viaf V eri“cation-based in tegrit y assurance framework for mapreduce in IEEE CLOUD  2011 pp 300…307  Y W a ng J  W ei a nd M Sriv atsa  Result in tegrit y check for mapreduce computation on hybrid clouds in IEEE CLOUD  2013  T Y u and K J Lin A brok er-based framew o rk for q osaware web service composition in EEE  2005 pp 22 29 24 


 Even using a 2Gbps optical fiber, five parallel encryptions suffice to the requirement of max speed of 250MB/s. The max speeds are also illustrated in Fig. 13 as dot lines Since the speed bound line ascends linearly, it  s easy to determine, as the method above, how many parallels should be deployed to achieve the maximum transmitting speed of bandwidth  Figure 13  Speed bounds comparing to max transmitting speed b  Analysis of Key Generation Since key generation occurs only once for a new torrent file, it  s easy to determine that generating ten thousand keys consumes only 11 seconds \(multiply 0.11 milliseconds to 10,000\. So it  s safe to argue that the cost of time is negligible 3  Efficiency of IVCSD According to the results and analyses above transmission in IVCSD is as efficient as original BT meaning that adding these functions and schemes will not affect the overall performance in BT network V  C ONCLUSION  This paper proposes a scheme, Identity Verification and Cipher System Distribution \(IVCSD\, to address secure problems in distributing big data. Identity verification protects the network in the aspect of peer admittance and data spreading, by assigning authority to torrents and peers, blocking unauthorized behaviors and keeping track of peers  actions. Cipher system protects the transmission in the aspect of data security and transmitting efficiency. With data encryption, intermediaries are allowed to participate into network without getting original data, sustaining the advantage of BT protocol After implementing IVCSD in testing machines experiment is performed and the results are analyzed Functionality and efficiency is positively demonstrated in the experimental results. As a conclusion, IVCSD is a feasible scheme to distribute big data, with some compromises between security and complexity There  re still some imperfect conditions. \(1\lthough behavior of intermediaries are proposed, implemented and tested, details about how or who to trigger or stop these actions are still absent. \(2\ The code implementing IVCSD for experiment in this paper uses Java. It may have some effects on evaluating efficiency. Other languages may be used in realistic deployment to achieve better performance 3\ Restricted by facilities an d environments in lab, all experiments and evaluations are completed within the local area network, instead of wider one such as Internet This fact may result in inaccuracy of experimental results but according to the analyses in Part IV, the functionality won  t be affected and the efficiency will still be acceptable in future implementation A CKNOWLEDGMENT  This paper is supported by the Hi-tech Research and Development Program of China \(863 Program\ under Grant No. 2011AA01A205, the Open Research Fund of The Academy of Satellite Application under grant NO SSTC-YJS-01-03, the National Natural Science Foundation of China under Grant No. 61232009, the Doctoral Fund of Ministry of Education of China under Grant No. 20101102110018,Beijing Natural Science Foundation under Grant No. 4122042, the fund of the State Key Laboratory of Software Development Environment under Grant No. SKLSDE-2012ZX-06 R EFERENCES  1  The Coming Data Deluge, IEEE Spectrum, February 2011 2  The data deluge, www.economist.com/node/15579717, Feb 25 2010 3  Arun Chokkalingam, Firasath Riyaz. BitTorrent Protocol Specification V 1.0. CSI 5321, Dec 12 2004 4  Zhang, X., Liu, D., Chen, S., Zhang, Z., & Sandhu, R. \(2008 Towards digital rights protection in BitTorrent-like P2P systems Proc. 15th SPIE/ACM Multimedia Computing and Networking MMCN 5  Balfe, S., Lakhani, A. D., & Paterson, K. G. \(2005, August Trusted computing: Providing security for peer-to-peer networks In Peer-to-Peer Computing, 2005. P2P 2005. Fifth IEEE International Conference on \(pp. 117-124\. IEEE 6  So, Jung Ki. Defending against Malicious Behaviors in BitTorrent Systems. Diss. NORTH CAROLINA STATE UNIVERSITY 2012 7  Douceur, J. R. \(2002\. The sybil attack. In Peer-to-peer Systems pp. 251-260\ Springer Berlin Heidelberg 8  Jun, S., & Ahamad, M. \(2005, August\. Incentives in BitTorrent induce free riding. In Proceedings of the 2005 ACM SIGCOMM workshop on Economics of peer-to-peer systems \(pp. 116-121 ACM 9  Sit E, Morris R. Security considerations for peer-to-peer distributed hash tables[J   Pe e r t o Peer Sy ste ms 2 0 0 2  2 6 1 2 6 9     Kinateder M, Pearson S. A privacy-enhanced peer-to-peer reputation system[J E Co m m e r ce a n d W e b T e chno l o g i e s  2 0 0 3   206-215   Damiani E, di Vimercati D C, Paraboschi S, et al. A reputationbased approach for choosing reliable resources in peer-to-peer networks[C P r o ce e d ing s o f t h e 9t h A C M co nf e r e n ce o n  Computer and communications security. ACM, 2002: 207-216   Shamir, A. \(1985\. Identity-based cryptosystems and signature schemes. InAdvances in cryptology \(pp. 47-53\. Springer Berlin/Heidelberg   Cohen B. Incentives build robustness in BitTorrent[C  W o r ks ho p  on Economics of Peer-to-Peer systems. 2003, 6: 68-72 90 90 90 


Figure 15  3D model of the patio test site Figure 16  Model of the patio test site combining 2D map data with 3D model data a Largest explored area b Smallest explored area Figure 14  Maps built by a pair of 2D mapping robots Yellow indicates area seen by both robots Magenta indicates area seen by one robot and Cyan represents area seen by the other a 3D point cloud built of the patio environment Figure 16 shows a model built combining 2D map data with 3D model data A four-robot mission scenario experiment was conducted at the mock-cave test site This included two 2D mapping robots a 3D modeling robot and a science sampling robot There was no time limit on the run Figure 17 shows a 3D model of the tunnel at the mock cave Figure 18 shows a model built combining 2D map data with 3D model data 7 C ONCLUSIONS  F UTURE W ORK The multi-robot coordination framework presented in this paper has been demonstrated to work for planetary cave mission scenarios where robots must explore model and take science samples Toward that end two coordination strategies have been implemented centralized and distributed Further a core communication framework has been outlined to enable a distributed heterogenous team of robots to actively communicate with each other and the base station and provide an online map of the explored region An operator interface has been designed to give the scientist enhanced situational awareness collating and merging information from all the different robots Finally techniques have been developed for post processing data to build 2  3-D models of the world that give a more accurate description of the explored space Fifteen 2D mapping runs with 2 robots were conducted The average coverage over all runs was 67 of total explorable area Maps from multiple robots have been merged and combined with 3D models for two test sites Despite these encouraging results several aspects have been identi\002ed that can be enhanced Given the short mission durations and small team of robots in the experiments conducted a simple path-to-goal costing metric was suf\002cient To use this system for more complex exploration and sampling missions there is a need for learning-based costing metrics Additional costing parameters have already been identi\002ed and analyzed for future implementation over the course of this study One of the allocation mechanisms in this study was a distributed system however task generation remained centralized through the operator interface In an ideal system robots would have the capability to generate and auction tasks based on interesting features they encounter Lastly the N P complete scheduling problem was approximated during task generation However better results could potentially 10 


Figure 17  3D model of the tunnel in the mock cave test site Figure 18  Model of the mock cave test site combining 2D map data with 3D model data be obtained by releasing this responsibility to the individual robots A CKNOWLEDGMENTS The authors thank the NASA STTR program for funding this project They would also like to thank Paul Scerri and the rCommerceLab at Carnegie Mellon University for lending hardware and robots for this research R EFERENCES  J C W erk er  S M W elch S L Thompson B Sprungman V Hildreth-Werker and R D Frederick 223Extraterrestrial caves Science habitat and resources a niac phase i study\\224 NASA Innovative Advanced Concepts NIAC Tech Rep 2003  G Cushing T  T itus and E Maclennan 223Orbital obser vations of Martian cave-entrance candidates,\224 in First Intl Planetary Caves Workshop  Carlsbad NM 2011  J W  Ashle y  M S Robinson B R Ha wk e A K Boyd R V Wagner E J Speyerer H Hiesinger and C H van der Bogert 223Lunar caves in mare deposits imaged by the LROC narrow angle camera,\224 in First Intl Planetary Caves Workshop  Carlsbad NM 2011  J W  Ashle y  A K Bo yd H Hiesinger  M S Robinson T Tran C H van der Bogert and LROC Science Team 223Lunar pits Sublunarean voids and the nature of mare emplacement,\224 in LPSC  The Woodlands,TX 2011  S Dubo wsk y  K Iagnemma and P  J Boston 223Microbots for large-scale planetary surface and subsurface exploration niac phase i.\224 NASA Innovative Advanced Concepts NIAC Tech Rep 2006  S Dubo wsk y  J Plante and P  Boston 223Lo w cost micro exploration robots for search and rescue in rough terrain,\224 in IEEE International Workshop on Safety Security and Rescue Robotics Gaithersburg MD  2006  S B K esner  223Mobility feasibility study of fuel cell powered hopping robots for space exploration,\224 Master's thesis Massachusetts Institute of Technology 2007  M T ambe D Pynadath and N Chauv at 223Building dynamic agent organizations in cyberspace,\224 IEEE Internet Computing  vol 4 no 2 pp 65\22673 March 2000  W  Sheng Q Y ang J T an and N Xi 223Distrib uted multi-robot coordination in area exploration,\224 Robot Auton Syst  vol 54 no 12 pp 945\226955 Dec 2006  A v ailable http://dx.doi.or g/10.1016/j.robot 2006.06.003  B Bro wning J Bruce M Bo wling and M M V eloso 223Stp Skills tactics and plays for multi-robot control in adversarial environments,\224 IEEE Journal of Control and Systems Engineering  2004  B P  Gerk e y and M J Mataric 223 A formal analysis and taxonomy of task allocation in multi-robot systems,\224 The International Journal of Robotics Research  vol 23 no 9 pp 939\226954 September 2004  M K oes I Nourbakhsh and K Sycara 223Heterogeneous multirobot coordination with spatial and temporal constraints,\224 in Proceedings of the Twentieth National Conference on Arti\002cial Intelligence AAAI  AAAI Press June 2005 pp 1292\2261297  M K oes K Sycara and I Nourbakhsh 223 A constraint optimization framework for fractured robot teams,\224 in AAMAS 06 Proceedings of the 002fth international joint conference on Autonomous agents and multiagent sys11 


tems  New York NY USA ACM 2006 pp 491\226493  M B Dias B Ghanem and A Stentz 223Impro ving cost estimation in market-based coordination of a distributed sensing task.\224 in IROS  IEEE 2005 pp 3972\2263977  M B Dias B Bro wning M M V eloso and A Stentz 223Dynamic heterogeneous robot teams engaged in adversarial tasks,\224 Tech Rep CMU-RI-TR-05-14 2005 technical report CMU-RI-05-14  S Thrun W  Bur g ard and D F ox Probabilistic Robotics Intelligent Robotics and Autonomous Agents  The MIT Press 2005 ch 9 pp 222\226236  H Mora v ec and A E Elfes 223High resolution maps from wide angle sonar,\224 in Proceedings of the 1985 IEEE International Conference on Robotics and Automation  March 1985  M Yguel O A ycard and C Laugier  223Update polic y of dense maps Ef\002cient algorithms and sparse representation,\224 in Intl Conf on Field and Service Robotics  2007  J.-P  Laumond 223T rajectories for mobile robots with kinematic and environment constraints.\224 in Proceedings International Conference on Intelligent Autonomous Systems  1986 pp 346\226354  T  Kanungo D Mount N Netan yahu C Piatk o R Silverman and A Wu 223An ef\002cient k-means clustering algorithm analysis and implementation,\224 IEEE Transactions on Pattern Analysis and Machine Intelligence  vol 24 2002  D J Rosenkrantz R E Stearns and P  M Le wis 223 An analysis of several heuristics for the traveling salesman problem,\224 SIAM Journal on Computing  Sept 1977  P  Scerri A F arinelli S Okamoto and M T ambe 223T oken approach for role allocation in extreme teams analysis and experimental evaluation,\224 in Enabling Technologies Infrastructure for Collaborative Enterprises  2004  M B Dias D Goldber g and A T  Stentz 223Mark etbased multirobot coordination for complex space applications,\224 in The 7th International Symposium on Arti\002cial Intelligence Robotics and Automation in Space  May 2003  G Grisetti C Stachniss and W  Bur g ard 223Impro ving grid-based slam with rao-blackwellized particle 002lters by adaptive proposals and selective resampling,\224 in Proceedings of the IEEE International Conference on Robotics and Automation  2005  227\227 223Impro v ed techniques for grid mapping with raoblackwellized particle 002lters,\224 IEEE Transactions on Robotics  2006  A Geiger  P  Lenz and R Urtasun 223 Are we ready for autonomous driving the kitti vision benchmark suite,\224 in Computer Vision and Pattern Recognition CVPR  Providence USA June 2012  A N 250 uchter H Surmann K Lingemann J Hertzberg and S Thrun 2236d slam with an application to autonomous mine mapping,\224 in Proceedings of the IEEE International Conference on Robotics and Automation  2004 pp 1998\2262003  D Simon M Hebert and T  Kanade 223Real-time 3-d pose estimation using a high-speed range sensor,\224 in Proceedings of the IEEE International Conference on Robotics and Automation  1994 pp 2235\2262241 B IOGRAPHY  Ammar Husain received his B.S in Mechanical Engineering Robotics from the University of Illinois at Urbana-Champaign He is pursuing an M.S in Robotic Systems Development at Carnegie Mellon University He has previously worked on the guidance and control of autonomous aerial vehicles His research interests lie in the 002eld of perception-based planning Heather Jones received her B.S in Engineering and B.A in Computer Science from Swarthmore College in 2006 She analyzed operations for the Canadian robotic arm on the International Space Station while working at the NASA Johnson Space Center She is pursuing a PhD in Robotics at Carnegie Mellon University where she researches reconnaissance exploration and modeling of planetary caves Balajee Kannan received a B.E in Computer Science from the University of Madras and a B.E in Computer Engineering from the Sathyabama Institute of Science and technology He earned his PhD from the University of TennesseeKnoxville He served as a Project Scientist at Carnegie Mellon University and is currently working at GE as a Senior Cyber Physical Systems Architect Uland Wong received a B.S and M.S in Electrical and Computer Engineering and an M.S and PhD in Robotics all from Carnegie Mellon University He currently works at Carnegie Mellon as a Project Scientist His research lies at the intersection of physics-based vision and 002eld robotics Tiago Pimentel Tiago Pimentel is pursuing a B.E in Mechatronics at Universidade de Braslia Brazil As a summer scholar at Carnegie Mellon Universitys Robotics Institute he researched on multi-robots exploration His research interests lie in decision making and mobile robots Sarah Tang is currently a senior pursuing a B.S degree in Mechanical and Aerospace Engineering at Princeton University As a summer scholar at Carnegie Mellon University's Robotics Institute she researched multi-robot coordination Her research interests are in control and coordination for robot teams 12 


Shreyansh Daftry is pursuing a B.E in Electronics and Communication from Manipal Institute of Technology India As a summer scholar at Robotics Institute Carnegie Mellon University he researched on sensor fusion and 3D modeling of sub-surface planetary caves His research interests lie at the intersection of Field Robotics and Computer Vision Steven Huber received a B.S in Mechanical Engineering and an M.S in Robotics from Carnegie Mellon University He is curently Director of Structures and Mechanisms and Director of Business Development at Astrobotic Technology where he leads several NASA contracts William 223Red\224 L Whittaker received his B.S from Princeton University and his M.S and PhD from Carnegie Mellon University He is a University Professor and Director of the Field Robotics Center at Carnegie Mellon Red is a member of the National Academy of Engineering and a Fellow of the American Association for Arti\002cial Intelligence 13 


