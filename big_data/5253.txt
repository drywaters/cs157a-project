Research of Data Mining Based on Apriori algorithm in Cutting Database  Guofeng Wang, Xiu Yu, Dongbiao Peng, Yinhu Cui, Qiming Li School of Mechanical Engineering Tianjin University Tianjin 300072, China  Abstract Cutting data mining is an important method to increase efficiency  discover hidde n knowledges in cutting database, and provide guidance for cutting decisions.This paper analyze the Apriori algorithm for association rules mining, and make some improvement for this algorithm based on the features of cutting database. Apriori algorithm is improved to mine association rules in cutting database. The results show that the Apriori algorithm can be efficien tly used in cutting data mining and improved algorithm can achiev e expected effect better than traditional algorithm Keywords-data mining; association rules mining; cutting database; Apriori algorithm I  I NTRODUCTION  Cutting database app ared after the combination of machining technique and database technique which can provide effective data information support for machining process. we can get higher machining efficiency and economic efficiency if the reasonable and optimized cutting data provided by cutting database is us r, it is a pity that it can’t derive enough more useful information so as to  provide guidance for actual m achining although large amount of cutting parameters processing knowledges, empirical formulas have been stored In this sense, it can only be called static cutting database, which result in “explosive data, howeve r lack of knowledge”. So it is important to adopt data mining technique for cutting database and discover hidden knowledges from this cutting database. In t h is paper, on studying the properties of cutting database Apriori algorithm is improved before using into cutting data mining and the final results shows that some useful knowledge can be get from these large amount of cutting data II A SSOCIATION RULES MINING AND A PRIORI ALGORITHM  Association rules mining is one of the most important research methods in data mining which can obtain some useful knowledge to describe the association between different valuable data items out of a great amount of datas. A lot of algorithms about mining associati on rules have been presented recently, among which Apriori algorithm is one of typical algorithm. It was introduced in 1993 by Agrawal as a powerful method used to find regular algorithm is a width-first search arithmetic in which recursive method was adopted. A basic property of “every subset of a frequent item sets is still  frequ ent item set, and every superset of a non-frequent item set is not a frequent item has  been used in Apriori algorithm to discover all of the frequent item sets. Details and formulas are given as follows C 1 candidate 1-itemsets L 1 c C 1 c.count>=minimum support For \(k=2; L k-1 k C k sc_candidate\(L k-1  For each transaction t D C t count_support\(C k t For all candidates c C t c.count  L k c C k c.count>=minimum support  Return L=U k L k  The notations and definitions are given as follows 1\nsactions; each transaction t is included in D 2 k set of large k-item sets\(set of items having minimum support 3 k set of candidate k-item sets\(items to be counted 4\unction of  sc_candidate is aimed at using L k-1 to get C k  5\unction of count_support is aimed at using C k and t to get all of the candidate k-itemsets that included in t The Apriori algorithm finds onl y the frequent item sets. In order to find the associations rules in the database , we must apply the following improved algorithm that is For each frequent item set L k  Generate all non-empty subsets of  L k  For each non-empty subset L s of L k  Output-rule L s L k if support\(L k  L s in-confidence  The Above steps can be concluded to the following two points: \(1\The support of every frequent item sets should be larger than the minimum sup port threshold, and \(2 This paper is sponsored by Chinese National Science Fund \(50805100 and Chinese National Science & Technology Supporting Program 2008BAF32B11 978-1-4244-7739-5/10/$26.00 ©2010 IEEE 


confidence of every associati on rules that derived from frequent item sets should be larger than the minimum confidence threshold II I T HE APPLICATION OF IMPROVED APRIORI ALGORITHM IN CUTTING DATABASE  Since the Apriori algorithm was proposed, many scholars have carried on a series of researches and applications Meanwhile, some improvements have been made to reduce the time cost of scanning the da e for searching frequent item which occur whe n the  traditional Apriori algorithm is used. But there are still some problems in the various kinds of applications more or less. As the main target of algorithm Apri ori is to find the frequent item sets in which the support and the confidence are larger than the minimum threshold respectively If the support is too small many useless rules will be obtai ned, but if the support is too large, there would be some rules missed such as the rules with high confidence and not large enough support. In the cutting database, the support of cutti ng data for difficult-to-machine material and high-speed cutting is always not very large, but in practice, the rules of that kind is requisite due to a lack of experience. In that case, the minimum support and the minimum confidence need to be set according to various circumstances. The method of this paper is to set the minimum support, the maximum support, the minimum confidence, the maximum confidence based on the principle so that no important rules can be missed and the useless rules can be reduced according to the limited scale. The steps are listed as follows 1\ng out the frequent item sets in which the support is l arger than the minimum support 2\m s ets primarily which satisfy the ru le \(the attribute of judgment in the left and the attribute of the result in the right as the rough rule  3\of the roughing sets. If the confidence is smaller than th e maximum confidence and larger than the minimum confidence, judge the roughing sets and pick out the roughing rule minimum c onfidence of which is larger than maximum support as the eventual output rule; If the confidence is bigger than the maximum confidence, then the rule is outputted as the eventual rule  In order to make the process clearly, the flow chart of improved algorithm is showed in Fig. 1 IV D ATA MINING EXAMPLE OF CUTTING DATABASE  A Data Sources Parts o f milling data are stored in this database, some of which are from experime and the others are from  the usual cutting data handbook of metal material written by companies such B Selection of Mining Data Attributes and its Discretization Cutting conditions such as cutting speed Vc, feed rate f and cutting depth a p are influenced by milling methods, hardness of work-piece material, heat-resistance temperature of tool material, cutting precision, machine, cutting coolant, heat treatment conditions of work-piece material, tool diameter and so on. Among the 3 basics of cutting conditions, cutting depth is determined by working allowance and surface quality, which can be neglected during the mining process. Cutting speed and  Start Find frequent itemsets which suppot>minim um support Choose rules which confidence>minim un confidence Confidence>maximum confidence Output as final rules Yes No Compare support to minimum support Support>maximu m support Yes  Figure 1.  Flow chart of improved algorithm  feed rate are onditions in C Data Mining are exported from cut ting database as XLS file b e included in the final results. Oppositely, if a lower minimum key para meters to evaluate cutting c machining center. In this paper, cutting precision, work-piece material and the other 4 influenced factors are selected as regular conditioning attribute, while cutting speed and feed rate are selected as regular determined attribute. In order to extract the regular conveniently, continuo us data should be discretized before data mining. Its dividing range and discretized result are shown in TABL Additionally, the value of each attribute is reflected 1 to 44 respectively so as to facilitate compiling of mining program Partial d atas then 33 data groups are inter cepted from it. In order to mine by MATLAB, all the datas have to be discretized and reflected to 1 to 44 as TABL The selection of the minimum support threshold and the minimum confidence t hreshold play an important role in whole process of mining. If just one minimum support threshold as 0.1 and one maximum confidence as 0.6 thresholds are defined as traditional alg orithm, we can get the result as TABL As shown in TABL although the rules with high support can be got from the mining results, some im portant rules would be missed at the same time. For example, the support of frequent item set for stainless steel in mining data is not high enough, but the association rule got from it can reach 100%, which also has to 


TABLE I D ECARTELIZATION  TABLE  FOR D ATA P ROPERTIES  Machining Classification of Cutting Sp  Feed Ra z Precision Work piece Material Classification of Milling Diameter of Hardness of Work Cutter Material Method Cutter\(mm piece\(HBS eed\(m/min te\(mm p\ s1\(l 1\(Roughing Carbon stee c1\(Tool steel x1\(face milling d1\(0-4\ h1\(125-175\ v1\(20-25\ f1\(0-0.02 p2\(Semifinishing s2\(Alloy steel c2\(High speed steel x2 l f Periphera milling d2\(4-8\ h2\(175-225\ v2\(25-30\ 2\(0.02-0.04 p\ s  3\(Finishing 3\(Stainless steel c3\(Carbide d3\(8-12\h3\(22530-35 f3\(0.04-0.06 s4\(Cast steel\ c4\(Ceramic\  d4\(12-16\ h4\(275-325\ v4\(35-40 f4\(0.06-0.08   s5\(Aluminum alloy c5\(Diamond\  d5\(16-20\ h5\(325 above\ v5\(40-100\ f5\(0.08-0.10 S6\(Ti  tanium alloy   d6\(20-30  v6\(100-150 f6\(0.1-0.15  d7\(30-40\ v7\(150 above f7\(0 15  above d8\(40-50   d 9\(50 above     TABLE II M INING  WITH  TRADITIONAL  APRIORI  ALGORITHM  Number Rules Support confidence 1 p1 & s2 d4 f5 c2 & x1 18.18 100 2 p1 & s2 & c2 & x1 & d5 f5 18.18 100 3 p1 & s2 & c2 & x1 & d7 f6 18.18 85.71 4 p1 & s2 & c2 & x1 & h1 f6 12.12 60 5 p1 & s2 & c2 & x1 & h2 f6 12.12 60 6 p1 6 s2 & c2 & x1 & d6 & h1 f 15.15 100 7 p  1 & s2 & c2 & x1 & d6 & h3 v1 f6 12.12 100  pport threshold is chosen, a lot of useless rules will derive TABLE III MINING  WITH  IMPROVED  APRIORI  ALGORITHM  D Result Analysis TABL that the results got from the impr ses, the maximum feed rate for m V Conclusion In t his paper proved based on the prop R EFERENCES  Y. Wan, Z. Q. L G, Development of a cutting database system tion and analysis functions Materials Science Forum, vol. 471-472, pp. 32-36, 2004 It is shown in oved algorithm keep the da ta information about stainless steel with low support and high confidence, which is in agreem ent with expected goal. What’s more, by analyzing the rules in TABL some important info rmation about cutting can be obtained as follows 1\ cutter diameter increa rough machining of alloy steel increases correspondingly 2\he carbide cutter whose diameter ranges from 40m t o 50mm is employed, cutting speed between 100m/min and 150m/min can be used to face mill stainless steel whose hardness ranges from 275HBS to 325HBS. But when it is used in actual process, some parameters change as actual condition, because its support is not large enough at all Besides the above conclusions, the information that the cutting speed decrease as the hardness of work-piece increase would be derived at the same time, but some rules can’t be discovered  because the quantity of data is not big enough, in order to get more reliable rules, lots of datas are needed in future application  su B y comprehensive consideration, a minimum support threshold as 0.08, a maximum support threshold as 0.1, a minimum confidence threshold as 0.6, and a maximum confidence threshold as 0.8 is chosen for this mining, then carry out data mining with improved algorithm, while the mining results is showed in TABL  Apriori algorithm is im Nu mber Rules Support Confidence erties of cutting database, and then it is used in cutting data mining. From the results we can conclude that the improved algorithm is efficient in cutting database mining. In order to get more useful rules e fficiently, the future work is to get more cutting datas to mine and make further improvement on Apriori algorithm  1 p1 & s2 d4 f5 c2 & x1 18 18% 100 2 p1 & s2 & c2 & x1 & d5 f5 18.18% 100 3 p1 & s2 & c2 & x1 & d7 f6 18.18% 85.71 4 p1 6 s2 & c3 & x1 & d8 & h4 v 12.12% 100 5 p1 & s2 & c2 & x1 & d6 & h1 f6 15.15 100 6 p  1 & s2 & c2 & x1 & d6 & h3 v1 f6 12.12% 100 iu, and X, Ai, J with predic 


Agrawal R, Imielinski T, Swami A. Mining association rules between sets of items in large databases. In: Proc. ACM SIGMOD Intl. Conf. Management Data, 1993 X. Wang, T. F. Xu, and L Z. Tang, SQL Sever 2005 data mining analysis by living example,Beijing:china press of water resources and hydropower res earch, 2008, pp. 128-131 of the World Congress on Intelligent Control and lications, DBA 03 C. Aflori, M. Craus, Grid implementation of the Apriori algorithm, Advances in Engineering Software, vol. 38, pp. 295300, 2007 J. Gao, S. J. Li, and F. Qian, A method of improvement and optimization on association rules Apriori algorithm Proceedings Automation \(WCICA\905 2006[Proceedings of the World Congress on Intelligent Control and Automation \(WCICA P. Judith, V. Sidney, G. Santia go, Matrix Apriori: Speeding up the search for frequent patterns, Proceedings of the IASTED International Conference on Databases and App 2006, pp. 75-82, 2006[Proceedings of the IASTED International Conference on Databases and Applications, DBA 2006 B. Qu, H. Zhou, and C. M. Jia ng, Experimental investigation on cutting performances of carbide face milling Cutters During cutting 0Crl3Ni5Mo, Tool engin eering, vol. 37, pp. 3-4, 20 Companies of CPMEC , Shanghai University Of Technology and Tsinghua University, Usual cutting data handbook of metal material, Beijing: Press of petroleum industry, June 1995 


Proposition 5 a\ The consequence rules in F R L, S\are non-repeatedly generated b F R L, S\ = F R  B L,S L  B L,S  Proof a All rules in F R L, S\ave either the left-hand sides in Left\(L, S\ or the right-hand sides in Right\(L, S which are different. Hence, all consequences rules generated in F R L, S\on-repeatedly generated b Obviously by the definitions of F R L, S\ and F R  B L,S\F L  B L,S 3 Complete derivation of non-repeated and confidence-preversed consequence rules Theorem 3 \(Disjoint splitting of non-repeated rules in each equivalence class  AR_S L, S B L, S\ + F L L, S\ + F R L, S Similarly AR_S L, L B L, L\ + F L L, L\ + F R L, L Proof: Consequence of propositions 3, 4 and 5 From the above propositions, the algorithm MG_CARS is suggested for deriving all non-repeated consequence rules C L, S\ in every equivalence rule class AR_S L, S C L, S MG_CARS L, S 1 F L L, S LeftAdding L, S R L, S   2 for each \(L  Left\(L, S 3 F R L, S R L, S RightAdding L, S 4 C L, S L L, S R L, S 5 return C L, S The algorithm RightAdding for finding consequence rule subset F R L, S\s indicated as follows \(the algorithm LeftAdding can be derived in the same way F R L, S RightAdding L, S 1 F R L, S  MS := R min L, S 2 S U,L  MS R i i R  S  L S\\\(K U,L L 3 for each \(R   S  L  4 for each \(R i  MS 5 S U,L,i S U,L R i  6 for each \(R i  S U,L,i o 7 if \(R i  or R   hen 8 Repeated := false 9 if \(i>1\en for each \(R k  MS | k<i 10 if \(R k  R i R i hen 11 Repeated := true 12 break; // for each R k 13 if \(not\(Repeated\en 14 F R L, S R L, S R L 012 R i R i R 15 return F R L, S IV E XPERIMENTAL RESULTS Four benchmark databases in [8 r e use d d u r i ng the s e  experiments. Table I shows their characteristics. The source code of M. J. Zaki [9 i s a l so use d t o fi nd t h e  fr e q ue nt  closed itemset lattice \(Charm-L d g e n e rators   TABLE I D ATABASE CHARACTERISTICS Database \(DB Transaction Items Average size  P 49046 7117 74 M 8124 119 23 Co 67557 129 43 Ch 3196 75 37 Table II shows the experimental results of our approach for finding association rule set based on the basic rules as min-min form. It shows the minimum support and the minimum confidence \(MS=MC\e cardinality of the association rule set \(#Tra\d the cardinality of basic rule set \(#BAR\. Column RT c shows the percent ratio of the time for finding the consequence rules to the one for finding all association rules. The ratio of the basic rules to all association rules and the number of redundant candidates generated in the GenerateRules algorithm are in turn showed in columns R BT and #R z Table II also shows the run time for mining the basic rules by our algorithm MG_BARS T o d the ratio \(RT\ of the one by the GenerateRules T z T o  TABLE II T HE EXPERIMENTAL RESULTS WITH BENCHMARK DATABASES DB MS = MC Tra BAR R BT RT c R z T o s RT Ch 80 552564 316493 0.6 88.9 480 1.07 1.5 Ch 70 8171198 3396360 0.4 91.3 6498 11.34 1.6 Co 97 8092 4621 0.6 88.0 21 0.02 1.5 Co 90 3640704 324974 0.1 96.9 10000 1.00 2.2 M 40 7020 1419 0.2 93.1 26 0.01 1.5 M 20 19191656 59297 0.0 99.9 16166 0.30 8.2 P 95 1170 786 0.7 81.4 0 0.01 2.0 P 85 1408950 727532 0.5 87.4 1368 2.90 1.7 The experimental results show that: first, the algorithm MG_BARS quickly and directly finds basic rules; second the algorithm MG_CARS completely derives all confidence-preserved and non-repeated consequence rules from the basic rules by adding appropriate eliminable itemsets to two sides of them. The total number of rules generated in our approach is the same as the one in the traditional algorithms [6  Figures 2 and 3 show the relation between the cardinality of basic rule set and the one of association rule set and also the effect of minimum confidence on the number of basic rules Figure 2 All rules vs basic rules: Chess and Connect 


Figure 3 All rules vs basic rules: Mushroom and Pumsb Figure 4, 5 and 6 compare the run times for finding the basic rules by the MG_BARS and GenerateRules algorithms on Co \(similar to Ch\, M and P with the different minimum confidences. It shows that the run time of our algorithm MG_BARS is shorter in almost cases Figure 4 The run times of MG_BARS vs GenerateRules Connect Figure 5 The run times of MG_BARS vs GenerateRules Mushroom Figure 6 The run times of MG_BARS vs GenerateRules Pumsb V C ONCLUSION In this paper, based on the eliminable itemset concept  h i c h pl a y s a n i m port an t  rol e i n pres erv i n g  su pport of  itemsets and confidence of rules in each equivalence class an efficient approach for extracting all association rules based on min-min basis is proposed. This approach with four phases is built based on the theoretical results and tested on benchmark databases. The first phase is to partition the association rule set into the disjoint equivalence rule classes. The second one is to disjointly split each of them into two rules sets of min-min basis and consequent. Using the above structures, in the third phase the algorithm MG_BARS which significantly reduces the time for mining basic rules is obtained. And in the last phase, the algorithm MG_CARS that non-repeatedly and completely derive all consequence rules \(together with their support and confidence\rom the basic rules is proposed A CKNOWLEDGMENT We would like to express our sincere thanks to M. J Zaki for his permission of using his source code [9 i n  o u r research. We also would like to thank the Department of Mathematics and Informatics, University of Dalat for their valuable support in the completion of this article R EFERENCES 1 C C. A g g a r w al P  S  Y u  O nl i n e g e ne r a tio n o f asso ci at io n r u l e sŽ in  Proceedings of the international conference on data engineering, pp 402-411, 1998 2 H  T  B a o A n a p p r oa ch  t o c onc ep t form at i on ba s e d on form a l  concept analysis,Ž IEICE Trans. Infor. and systems, vol. E78-D, no 5, 1995 3 N P a sq uie r  R  T a o u il Y   Bas ti de G  S t um m e L   L a khal   Generating a condensed representation for association rulesŽ in J. of Intelligent Information Systems, vol. 24, no. 1, pp. 29-60, 2005 4 R  Ta oui l Y  B a s t id e N. Pa s q ui er  L   L a k h a l M in in g b a s e s for association rules using closed setsŽ in 16 th IEEE Intl. Conf. on Data Engineering, 2000 5 T C. T r uo ng  A  N  Tr an S tr uc tur e o f se t o f asso ciatio n r u l e s base d  on concept latticeŽ in Advances in intelligent information and database systems, pp. 217…227, N. T. Nguyen et al. \(Eds.\, Springer 2010 6 M. J  Z a ki M i n i n g no nr e d u n d a n t as s o ciat io n r u l e s  in D a ta m i n i ng  and knowledge discovery, 9, pp. 223-248, 2004 7 M  J  Z a k i  C J  Hs i a o E ffi ci en t  a l gori t h m s for m i ni n g  c l os ed  itemsets and their lattice structure,Ž IEEE Trans. Knowledge and data engineering, vol. 17, no. 4, 2005 8 F re que nt I t e m s e t Mini ng D a tas e t Re po s i to r y   http://fimi.cs.helsinki.fi/data  2009 9 h tt p  www  c s  rp i ed u za k i  w w w new/pmwiki.php/Software/Software#patutils  


34 P  D a y a n a n d T  S e j n o w s k i  223 T h e v a r i a n c e o f c o v a r i a n c e r u l e s for associative matrix memories and reinforcement learning.\224 Neural Computation  vol 5 pp 205\226209 1993 35 G  P a l m a n d F  S o m m e r  223 A s s o c i a t i v e d a t a s t o r a g e a n d r e t r i e v a l i n neural nets.\224 in Models of Neural Networks III  E Domany J van Hemmen and K Schulten Eds New York Springer-Verlag 1996 pp 79\226118 36 G  C h e c h i k  I  M e i l i j s o n  a n d E  R u p p i n  223 E f f e c t i v e n e u r o n a l l e a r n i n g with ineffective hebbian learning rules.\224 Neural Computation  vol 13 pp 817\226840 2001 37 D  S t e r r a t t a n d D  W i l l s h a w  223 I n h o m o g e n e i t i e s i n h e t e r o a s s o c i a t i v e memories with linear learning rules.\224 Neural Computation  vol 20 pp 311\226344 2008 38 A  L a n s n e r a n d O  E k e b e r g  223 A n a s s o c i a t i v e n e t w o r k s o l v i n g t h e 224 4 bit adder problem\224.\224 in Proceedings of the IEEE First International Conference on Neural Networks  M Caudill and C Butler Eds San Diego CA 1987 pp II\226549 39 227 227  223 A o n e l a y e r f e e d b a c k a r t i 002 c i a l n e u r a l n e t w o r k w i t h a B a y e s i a n learning rule.\224 International Journal of Neural Systems  vol 1\(1 pp 77\22687 1989 40 I  K o n o n e n k o  223 B a y e s i a n n e u r a l n e t w o r k s  224 Biological Cybernetics  vol 61\(5 pp 361\226370 1989 41 227 227  223 O n B a y e s i a n n e u r a l n e t w o r k s  224 Informatica Slovenia  vol 18\(2 pp 183\226195 1994 42 A  L a n s n e r a n d A  H o l s t  223 A h i g h e r o r d e r B a y e s i a n n e u r a l n e t w o r k with spiking units.\224 International Journal of Neural Systems  vol 7\(2 pp 115\226128 1996 43 A  S a n d b e r g  A  L a n s n e r  K  P e t e r s s o n  a n d O  E k e b e r g  223 A p a l i m p s e s t memory based on an incremental Bayesian learning rule.\224 Neurocomputing  vol 32-33 pp 987\226994 2000 44 A  K n o b l a u c h  223 N e u r a l a s s o c i a t i v e n e t w o r k s w i t h o p t i m a l b a y e s i a n learning.\224 Honda Research Institute Europe GmbH D-63073 Offenbach/Main Germany HRI-EU Report 09-02 May 2009 45 S  W a y d o  A  K r a s k o v  R  Q u i r o g a  I  F r i e d  a n d C  K o c h  223 S p a r s e representation in the human medial temporal lobe.\224 Journal of Neuroscience  vol 26\(40 pp 10 232\22610 234 2006 46 A  K n o b l a u c h  223 C o m p a r i s o n o f t h e l a n s n e r  e k e b e r g r u l e t o o p t i m a l bayesian learning in neural associative memory.\224 Honda Research Institute Europe GmbH D-63073 Offenbach/Main Germany HRI-EU Report 10-06 April 2010 47 227 227  223 N e u r a l a s s o c i a t i v e m e m o r y w i t h o p t i m a l b a y e s i a n l e a r n i n g  224 submitted  pp 226 2010 48 227 227  223 O n t h e c o m p u t a t i o n a l b e n e 002 t s o f i n h i b i t o r y n e u r a l a s s o c i a t i v e networks.\224 Honda Research Institute Europe GmbH D-63073 Offenbach/Main Germany HRI-EU Report 07-05 May 2007 49 A  K n o b l a u c h a n d G  P a l m  223 P a t t e r n s e p a r a t i o n a n d s y n c h r o n i z a t i o n in spiking associative memories and visual areas.\224 Neural Networks  vol 14 pp 763\226780 2001 50 T  S e j n o w s k i  223 S t o r i n g c o v a r i a n c e w i t h n o n l i n e a r l y i n t e r a c t i n g n e u rons.\224 Journal of Mathematical Biology  vol 4 pp 303\226321 1977 51 227 227  223 S t a t i s t i c a l c o n s t r a i n t s o n s y n a p t i c p l a s t i c i t y  224 Journal of Theoretical Biology  vol 69 pp 385\226389 1977 52 D  W i l l s h a w a n d P  D a y a n  223 O p t i m a l p l a s t i c i t y i n m a t r i x m e m o r i e s  what goes up must come down.\224 Neural Computation  vol 2 pp 85\226 93 1990 53 G  P a l m a n d F  S o m m e r  223 I n f o r m a t i o n c a p a c i t y i n r e c u r r e n t McCulloch-Pitts networks with sparsely coded memory states.\224 Network  vol 3 pp 177\226186 1992 54 B  G r a h a m a n d D  W i l l s h a w  223 I m p r o v i n g r e c a l l f r o m a n a s s o c i a t i v e memory.\224 Biological Cybernetics  vol 72 pp 337\226346 1995 55 H  M a r k r a m  M  T o l e d o R o d r i g u e z  Y  W a n g  A  G u p t a  G  S i l b e r b e r g  and C Wu 223Interneurons of the neocortical inhibitory system.\224 Nature Reviews Neuroscience  vol 5 pp 793\226807 2004 56 H  Z h a n g  223 T h e o p t i m a l i t y o f n a i v e b a y e s  224 i n Proceedings of the 17th Florida Arti\002cial Intelligence Research Society Conference  V Barr and Z Markov Eds AAAI Press 2004 pp 562\226567 57 P  D o m i n g o s a n d M  P a z z a n i  223 O n t h e o p t i m a l i t y o f t h e s i m p l e Bayesian classi\002er under zero-one loss.\224 Machine Learning  vol 29 pp 103\226130 1997 58 G  P a l m  223 L o c a l s y n a p t i c r u l e s w i t h m a x i m a l i n f o r m a t i o n s t o r a g e capacity.\224 in Neural and synergetic computers  ser Springer Series in Synergetics H Haken Ed Berlin Heidelberg New York Springer Verlag 1988 vol 42 pp 100\226110 59 D  G o l o m b  N  R u b i n  a n d H  S o m p o l i n s k y  223 W i l l s h a w m o d e l  A s s o ciative memory with sparse coding and low 002ring rates.\224 Phys Rev A  vol 41 pp 1843\2261854 1990 60 A  H o l t m a a t a n d K  S v o b o d a  223 E x p e r i e n c e d e p e n d e n t s t r u c t u r a l s y n a p tic plasticity in the mammalian brain.\224 Nature Reviews Neuroscience  vol 10 pp 647\226658 2009 61 A  K n o b l a u c h  223 S y n c h r o n i z a t i o n a n d p a t t e r n s e p a r a t i o n i n s p i k i n g associative memory and visual cortical areas.\224 PhD thesis Department of Neural Information Processing University of Ulm Germany  2003 62 227 227  223 O n c o m p r e s s i n g t h e m e m o r y s t r u c t u r e s o f b i n a r y n e u r a l a s s o ciative networks,\224 Honda Research Institute Europe GmbH D-63073 Offenbach/Main Germany HRI-EU Report 06-02 April 2006 63 227 227  223 N e u r a l a s s o c i a t i v e m e m o r y a n d t h e W i l l s h a w P a l m p r o b a b i l i t y distribution.\224 SIAM Journal on Applied Mathematics  vol 69\(1 pp 169\226196 2008 64 227 227  223 T h e r o l e o f s t r u c t u r a l p l a s t i c i t y a n d s y n a p t i c c o n s o l i d a t i o n f o r memory and amnesia in a model of cortico-hippocampal interplay.\224 in Connectionist Models of Behavior and Cognition II Proceedings of the 11th Neural Computation and Psychology Workshop  J Mayor N Ruh and K Plunkett Eds Singapore World Scienti\002c Publishing 2009 pp 79\22690 65 227 227  223 Z i p n e t s  E f 002 c i e n t a s s o c i a t i v e c o m p u t a t i o n w i t h b i n a r y synapses.\224 in Proceedings of the International Joint Conference on Neural Networks IJCNN 2010  2010 


   Table 4. Normalized Criteria Comparison Table In AHP   Reusability Meeting Operational Requirements Meeting project Deadline Reusability 0.157 0.148 0.272 Meeting Operational Requirements 0.789 0.744 0.636 Meeting Project Deadline 0.052 0.106 0.090  Table 3 and Table 4 show the weight values of the three criterions as compared to each other using the AHP process. These weights have been decided by the stakeholders after discussions among themselves Average weights can be derived from Table 4 as follows Reusability- 0.193 Meeting Operational Requirements- 0.724 Meeting Project Deadline- 0.083 These weights represent the priority of each criterion on a scale of 0 to 1  5.3. Argumentation Tree  We develop argumentation tree for each and every alternative separately. The ar guments are stated by stake holders and assembled under the alternative but they target a specific cr iterion. These arguments can either be supporting or attacking each other or their respective alternative nodes. We present three figures, where each figure represents the argumentation hierarchy for one alternative. Rectangular boxes represent the alternatives with the name of the alternative under it. Ovals represent the criteria with their descr iption. The arguments are specified by labels A, B, C for alternative Adobe flashŽ, Adobe DirectorŽ and Open GLŽ respectively Along with the labels, the arguments also have indexes associated with them. Beneath the labels are two boxes The box on left shows the weight of the argument whereas the box on right shows the priority of the stakeholder who specifies the argument  Once the argument has been sp ecified, the user enters its weight. We first reassess the weights of the arguments using priority reassessment discussed in h e n us ing the techniques specified in [11 w e red u ce t h e arg u m e n t s  to a single level. Finally, the weighted summation of the arguments with the criteria weights helps us evaluate the final weights for the decision matrix. It is important to note here that, the aggregation method used for calculating the favorability is a weighted summation  The three argumentation hierarchies for the three alternatives are presented in the Figures 7, 8, and 9. The diagrams contain arguments, their weights and the stakeholders priorities     Figure 7. Argumentation Tree For Adobe Flash   Figure 8. Argumentation Tree For Adobe Director 150 


     Figure 9. Argumentation Tree For Open GL  A1 The current system in flash does not have the functionality of dynamic allocation of particles like mine or clutter. It places them randomly  A1.1 That is not of much importance because it still gives a new position to mine and clutter particles A2 Current system in flash has faster response time as compared to system in Adobe Director A3 The current system doesnt satisfy many of the features required for the new system like database A4 Adobe Flash cannot communicate with database A4.1 Flash doesnt support database but database support is very important and critical A4.1.1 The system should be able to generate evaluation reports for trainee based on pr evious records stored in the database A5 Flash doesnt create sound clips  A5.1 We dont need sound creating features as the sys tem has to generate sound. We can play externally recorded sound files using Adobe Flash A6 Flash can provide good visual effects as compared to Adobe Director A7 The developer has good knowledge in development using Flash so the system can be developed quickly B1 We could reuse the system already developed for sound generation, as it is developed using Adobe Audition for analysis which is somehow related to Adobe Director B1.1 The current system is better synthesized in terms of sound production and the sound produced is also instantaneous rather than discrete B1.2 That current system has certain performance issues like slow response time B1.3 The current system in Adobe Director has the feature of producing dynamic coloring scheme on approaching a mine. This kind of scheme is highly preferable and is not present in Adobe Flash system B2 Adobe Director can provide more functionality as compared to the current flash system. E.g. Multiple sounds while detecting mines   B2.1 Adobe Director can provide better visual effects as compared to flash e.g. in case of GUIs   B2.2 A modified version of the current system in flash can also provide the same functionality B2.2.1 We cannot integrate code developed in other platforms with Flash, but Flash can be integrated in Adobe Director B3 The interface provided by flash is not professional enough. It is too simple and straight forward for doing more things in future   B4 Easily available plug-ins can help integrate the tracking system developed in C# with Adobe Director  B4.1 Code developed in Open GL/AL can also be integrated using Adobe Director using suitable stubs   B5 A new sound recognition algorithm is being developed in Adobe Audition which can be integrated with Adobe Director but not with Open GL or Flash Evidence supported B6 If the current system is reused; the project deadline can be met easily B7 The developer has very little experience in development using Adobe Director   B7.1 The developer can take help from the already developed system in Adobe Director C1 The tracking software already developed is coded in C#/NX5. We could reuse that and develop our system in Open GL/AL C1.1 Open GL has C# libraries which can be used to develop the system C2 Because the platform used is for high end application development, it can provide good GUI and database support C2.1 Open GL/AL can help us generate dynamic surfaces for mine detection and training which the original system in flash does not have C4 Open GL does not support connectivity with Adobe Audition. Adobe Audition is required for creating sound recognition algorithm C3 Open GL does not support connectivity with Adobe Audition. Adobe Audition is required for creating sound recognition algorithm C4 The time taken for developing the project using open GL will be comparatively more as the whole system would have to be developed from scratch C4.1 If Open GL has support for C# libraries, and then the system could be develope d faster as developer is quite familiar with programming languages like C 151 


   C4.2 Open GL has excellent documentation that could help the developer learn the platform with ease C4.3 Developer has very little ex perience in working with Open GL platform  For our case study, alternative B i.e. Adobe Director was the most favorable alternative amongst all the three. It catered to the reusability criteria quite well and aimed at meeting most of the desired operational requirements for the system   6. CONCLUSION & FUTURE WORK  The main contribution of this paper is to develop an approach for evaluating performance scores in MultiCriteria decision making using an intelligent computational argumentation network. The evaluation process requires us to identify performance scores in multi criteria decision making which are not obtained objectively and quantify the same by providing a strong rationale. In this way, deeper analysis can be achieved in reducing the uncertainty problem involved in Multi Criteria decision paradigm. As a part of our future work we plan on conducting a large scale empirical analysis of the argumentation system to validate its effectiveness   REFERENCES  1  L  P Am g o u d  U sin g  A r g u men ts f o r mak i n g an d  ex p lain in g  decisions Artificial Intelligence 173 413-436, \(2009 2 A  Boch m a n   C ollectiv e A r g u men tatio n    Proceedings of the Workshop on Non-Monotonic Reasoning 2002 3 G  R Bu y u k o zk an  Ev alu a tio n o f sof tware d e v e lo p m en t  projects using a fuzzy multi-criteria decision approach Mathematics and Computers in Simualtion 77 464-475, \(2008 4 M T  Chen   F u zzy MCD M A p p r o ach t o Selec t Serv ice  Provider The IEEE International Conference on Fuzzy 2003 5 J. Con k li n  an d  M. Beg e m a n   gIBIS: A Hypertext Tool for Exploratory Policy Discussion Transactions on Office Information Systems 6\(4\: 303  331, \(1988 6 B P  Duarte D e v elo p in g a p r o jec ts ev alu a tio n sy ste m based on multiple attribute value theroy Computer Operations Research 33 1488-1504, \(2006 7 E G  Fo rm an  T h e  A n a l y t ic Hier a rch y P r o cess A n  Exposition OR CHRONICLE 1999 8 M. L ease  an d J L  L i v e l y  Using an Issue Based Hypertext System to Capture Software LifeCycle Process Hypermedia  2\(1\, pp. 34  45, \(1990 9  P e id e L i u   E valu a tio n Mo d e l o f Custo m e r Satis f a c tio n o f  B2CE Commerce Based on Combin ation of Linguistic Variables and Fuzzy Triangular Numbers Eight ACIS International Conference on Software Engin eering, Artificial Intelligence Networking and Parallel Distributed Computing, \(pp 450-454 2007  10  X  F L i u   M an ag e m en t o f an In tellig e n t A r g u m e n tatio n  Network for a Web-Based Collaborative Engineering Design Environment Proceedings of the 2007 IEEE International Symposium on Collaborative Technologies and Systems,\(CTS 2007\, Orlando, Florida May 21-25, 2007 11 X. F L i u   A n In ternet Ba se d In tellig e n t A r g u m e n tatio n  System for Collaborative Engineering Design Proceedings of the 2006 IEEE International Symposium on Collaborative Technologies and Systems pp. 318-325\. Las Vegas, Nevada 2006 12 T  M A sub jec tiv e assess m e n t o f altern ativ e m ission  architectures for the human exploration of Mars at NASA using multicriteria decision making Computer and Operations Research 1147-1164, \(June 2004 13 A  N Mo n ireh  F u zzy De cisio n Ma k i n g b a se d o n  Relationship Analysis between Criteria Annual Meeting of the North American Fuzzy Information Processing Society 2005 14 N  P a p a d ias HERMES Su p p o rti n g A r g u m e n tative  Discourse in Multi Agent Decision Making Proceedings of the 15th National Conference on Artifical Intelligence \(AAAI-98  pp. 827-832\dison, WI: AAAI/MIT Press,  \(1998a 15  E. B T riantaph y llo u   T h e Im p act o f  Ag g r e g atin g Ben e f i t  and Cost Criteria in Four MCDA Methods IEEE Transactions on Engineering Management, Vol 52, No 2 May 2005 16 S  H T s a u r T h e Ev alu a tio n o f airlin e se rv ice q u a lity b y  fuzzy MCDM Tourism Management 107-115, \(2002 1 T  D W a n g  Develo p in g a f u zz y  T O P S IS app r o ach  b a sed  on subjective weights and objective weights Expert Systems with Applications 8980-8985, \(2009 18 L  A  Zadeh  F u z z y Sets   Information and Control 8  338-353, \(1965  152 


                        





