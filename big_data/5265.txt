Support driven opportunistic aggregation for generalized itemset extraction Elena Baralis Luca Cagliero Tania Cerquitelli Vincenzo D'Elia and Paolo Garza Abstract 227Association rule extraction is a widely used exploratory technique which has been exploited in different contexts e.g biological data medical images However association rule extraction driven by support and con\002dence constraints entails i generating a huge number of rules which are dif\002cult to analyze or ii pruning rare itemsets even if their hidden knowledge might be relevant To address the above issues this paper presents a novel frequent itemset mining algorithm called G EN IO 
 G EN eralized I temset Disc O verer to analyze correlation among data by means of generalized itemsets which provide a powerful tool to ef\002ciently extract hidden knowledge discarded by previous approaches The proposed technique exploits a user provided taxonomy to drive the pruning phase of the extraction process Instead of extracting itemsets for all levels of the taxonomy and post-pruning them the GenIO algorithm performs a support driven opportunistic aggregation of itemsets Generalized itemsets are extracted only if itemsets at a lower level in the taxonomy are below the support threshold Experiments performed in the network traf\002c domain show the ef\002ciency and the effectiveness of the proposed algorithm 
Index Terms 227Generalized itemset mining knowledge discovery data mining techniques network traf\002c data analysis I I NTRODUCTION Association rule extraction is a po werful data mining technique to effectively discover correlation among data Association rules are usually represented in the form A  B  where A and B are itemsets i.e sets of data items Each rule is usually characterized by the support and con\002dence quality indices The support is the probability of A and B i.e its observed frequency in the dataset The con\002dence is the conditional probability of B 
given A and characterizes the 223strength\224 of a rule Since association rules identify pairs of itemsets that are statistically related i.e frequently together in transactions they 002nd application in a wide range of different domains including medical images and biological data 6 Association rule mining is a tw o-step process i Frequent itemset extraction and ii association rule generation from frequent itemsets Research activity usually focuses on de\002ning ef\002cient algorithms for itemset extraction which represents the most computationally intensive knowledge extraction task in association rule mining The traditional itemset mining problem can be described as follows Given a dataset of transactions and a minimum support threshold 002nd all itemsets whose support is above the given threshold However such a threshold may prevent 
E Baralis L Cagliero T Cerquitelli V D'Elia and P Garza are with the Dipartimento di Automatica e Informatica Politecnico di Torino Italy f elena.baralis luca.cagliero tania.cerquitelli vincenzo.delia paolo.garza g polito.it infrequent but potentially relevant itemsets from being extracted while enforcing a very low threshold makes the task computationally expensive and the mined knowledge too large to be analyzed This paper proposes a novel algorithm called G EN IO G EN eralized Itemset DiscOverer to support data analysis by automatically extracting higher level more abstract correlations from data G EN IO extends the concept of multiple-level 
itemsets 10 13 by performing an opportunistic e xtraction of generalized itemsets The proposed algorithm exploits a user provided taxonomy to drive the pruning phase of the extraction process and ef\002ciently extract generalized itemsets Instead of extracting itemsets for all levels of the taxonomy and post-pruning them the proposed generalization technique over the taxonomy is support driven i.e it generalizes an itemset only if the itemsets at a lower level in the taxonomy are below the support threshold Thus G EN IO automatically performs generalization only when needed to exceed the support threshold Furthermore the proposed approach should be exploited in every application context in which meaningful taxonomies might be inferred from structured data sources e.g network traf\002c analysis context-aware applications 
G EN IO has been designed by customizing the Apriori algorithm to ef 002ciently e xtract generalized itemsets with variable support thresholds from structured data It has been tested on network traf\002c data for two reasons i A huge amount of data may be collected in a short time ii in very large traf\002c network traces it is hard to detect correlations among data and identify anomalies because of the excessively detailed granularity of information e.g IP addresses In this context the proposed generalization approach proves to be particularly effective Experiments performed on different network dumps show the ef\002ciency and the effectiveness of the proposed algorithm The paper is organized as follows Section II de\002nes the problem statement addressed in this paper Section III de 
scribes the proposed approach for generalized frequent itemset mining where taxonomies are lazily evaluated to effectively handle rare itemsets Section IV discusses the experiments performed to evaluate the effectiveness of the proposed algorithm in discovering frequent generalized itemsets in network traf\002c domain Section V compares our approach with previous works Finally Section VI draws conclusions and presents future developments of the proposed approach A Motivating example Consider an ftp server on port 21 having address 130.192.15.17  To describe the activity of a client 978-1-4244-5164-7/10/$26.00 ©2010 IEEE 


 154.125.3.2  connecting to this server an itemset in the form i  source-IP-address  154.125.3.2 destination-IP-address  130.192.15.17 destination-port  21  sup  1  15  should be extracted Since such triplet is infrequent in a very large traf\002c network trace extracting this itemset would require enforcing a very low support threshold which makes the task unfeasible However an opportunistic taxonomy evaluation may be more effective in mining valuable knowledge Suppose to set the minimum support threshold at 2 A higher level view of the network may be provided by the following generalized itemset ii  source-IP-address  154.125.3.0/17 destination-IP-address  130.192.15.17 destination-port  21  sup  2  4  which shows a generalization of the source-IP-address attribute i.e a subnet including IP addresses 154.125.3.0/17 This itemset is characterized by a larger support which ful\002lls the support constraint and shows that the subnet detected by the generalization process is actually generating most of the traf\002c Thus it provides valuable knowledge for network monitoring Furthermore the number of different items e.g source-IP-address  154.125.3.2 in network traf\002c may be very large Hence itemsets at this detail level may provide hardly interpretable knowledge Our generalization approach allows preserving a detailed view of frequent items e.g destination-IP-address  130.192.15.17 while generalizing at a higher taxonomy level infrequent items e.g source-IPaddress  154.125.3.2 Consider again itemset i If it would have support 2  15 instead of 1  15  by enforcing the same minimum support threshold equal to 2 the itemset becomes frequent thus it is extracted since it provides valuable knowledge Further generalization steps to generate itemset ii are prevented because they do not enrich the actual mined set anymore II P ROBLEM STATEMENT Let T  f t 1  t 2      t n g be a set of labels called attributes which describe data features and n  f n 1  n 2      n n g be the correspondent attribute domains An item is a pair t i  value i which assigns value value i 2 n i to attribute t i  The attributes may have either a categorical or a continuous domain In the case of continuous attributes the value range is discretized into intervals and the intervals are also mapped into consecutive positive integers In the network traf\002c domain value i are values captured from the net e.g the IP address 130  192  15  17  and t i are the descriptions of the represented information A structured dataset D e.g network trace is a collection of records e.g network 003ows where each record r is a set of items and contains at most one item for each attribute in T  Let I be the enumeration of all items in D  an itemset X 022 I is a set of items Each attribute t i may occur at most once in X     Fig 1 A rewriting rule tree RR port for the source and destination port attributes Ov er each attribute t i it is de\002ned at most one predetermined hierarchy of aggregations over values in n i  Each hierarchy is called a rewriting rule tree RR i  RR i is a tree whose leaves are values in n i  while each non-leaf node in the tree is an aggregation of its children which may be further generalized by its father The root node aggregates all values for attribute t i  The set of rewriting rules RR i de\002ned over the attributes of D is called taxonomy    Consider for example the destination-port address attribute A simple rewriting rule tree RR port  de\002ned over the destination-port address attribute is shown in Figure 1 The RR port assigns well known if the destination-port value is lower than 1024 registered if in the range 1024-49151 dynamic otherwise A generalized item is a pair t i  expression i  where t i is an attribute n i the correspondent domain and expression i a not-leaf node in RR i de\002ning an aggregation value over values in n i  leaves  expression i  022 n i de\002nes the set of leaf nodes descendants of expression i in RR i  Usually the quality of a generalized item t i  expression i is measured by its support which is the sum of the observed frequency in D of leaves  expression i   A generalized itemset X is a set of items and/or generalized items Each attribute t i 2 T may occur at most once in X  Its support is the observed frequency of X in D  Given a structured dataset D  a minimum support threshold min sup  and a taxonomy   the G EN IO algorithm extracts i All itemsets whose support exceeds min sup and ii all generalized itemsets whose a descendants include at least an infrequent itemset i.e a descendant whose support is lower than min sup  and b support exceeds min sup  III T HE G EN IO A LGORITHM G EN IO discovers all frequent itemsets and all generalized itemsets having at least an infrequent descendant The generalization process driven by the taxonomy   is support driven i.e it generalizes an itemset only if it is infrequent with respect to the mininum support threshold The pseudo-code of G EN IO is given by Algorithm 1 G EN IO implementation is based on Apriori 2 Apriori is a level-wise algorithm which at each iteration generates all frequent itemsets of a given length At arbitrary iteration k  two steps are performed i Candidate generation the most computationally and memory 


Algorithm 1 Generalized Itemset Discoverer Input minimum support min sup  taxonomy   dataset D Output L  set of generalized frequent itemsets 1 k  1  L   2 C 1  set of items in D 3 repeat 4 scan D and count support for each c 2 C k 5 Gen    generalized itemset container 6 for all c in C k do 7 if support of c  min sup then 8 new gen itemset  taxonomy evaluation   c  9 update Gen with new gen itemset 10 end if 11 end for 12 if Gen 6   then 13 scan D and count support for each itemset in Gen 14 end if 15 L k  f itemsets in f C k  Gen g whose support 025 min sup g 16 k  k  1 17 C k  candidate generation L k  1  18 until C k 6   19 retur n L intensive step in which all possible k itemsets are generated from k-1 itemsets ii candidate pruning which is based on the property that all subsets of frequent itemsets must also be frequent to discard candidate itemsets which cannot be frequent Finally actual candidate support is counted by reading the dataset G EN IO approach follows the same level-wise pattern However it i manages rare itemsets by lazily evaluating the taxonomy  lines 6-11 and ii exploits the characteristics of the structured datasets to effectively prune candidates line 17 Once the support of each candidate itemset in C k has been computed line 4 generalized versions of infrequent ones are generated by evaluating the taxonomy line 8 and inserted in the Gen set line 9 In particular by applying on each item t j  value j in itemset c the corresponding rewriting rule tree RR j  the generalized versions of each item in c is generated line 8 All the itemsets obtained by replacing one or more items in c with their generalized versions are generalized itemsets of c  Hence the taxonomy evaluation on itemset c potentially generates a set of generalized itemsets The generalization process of c is triggered if and only if c is infrequent with respect to the mininum support threshold line 7 Once triggered the generalization process is repeated until a complete taxonomy evaluation has been performed For example let  destination-IP-address  130.192.15.17 destination-port  21 be an infrequent itemset in C k  By applying on destination port the rewriting rule tree RR port shown in Figure 1 and on destination IP address RR IP  address shown in Figure 2 the following generalized itemsets are generated 017  destination-IP-address  130.192.15.0/24 destinationport  21 017  destination-IP-address  130.192.15.17 destination-port  Well-known 017  destination-IP-address  130.192.15.0/24 destinationport  Well-known The insertion of redundant generalized itemsets i.e generalized itemsets previously generated by different infrequent descendants in Gen is prevented by the update procedure in line 9 If the Gen set is not empty the support of each generalized itemset in Gen is computed by performing a ID Number of records Number of different items D1 18051 32143 D2 17374 30617 D3 16783 30072 D4 3802 9350 D5 2074 5825 TABLE I C HARACTERISTICS OF THE DATASETS     Fig 2 A rewriting rule tree RR IP  address for the source and destination IP address attributes further scan of the dataset line 13 During the candidate generation step line 17 G EN IO exploits the uniqueness of attributes in a given record of a structured dataset to further prune candidate itemsets e.g in the traf\002c network domain a 003ow i.e a record of the network trace with multiple destination-IP-address cannot be de\002ned For example suppose that after the 002rst dataset traversal we have m frequent 1-itemsets tagged source-IP-address and n tagged destination-IP-address  Apriori exhaustive candidate generation would produce  m  n 2 001 possible combinations Since each attribute could appear only once in each record only m 001 n 2-itemsets obtained by combining one item tagged sourceIP-address and one item tagged destination-IP-address  are relevant combinations Hence G EN IO generates only this subset of candidates Thus the required computational and memory cost is reduced IV E XPERIMENTAL RESULTS We evaluated the performance of the G EN IO algorithm by means of a signi\002cant set of experiments which analyze i the performance of the proposed frequent generalized itemset miner ii the number and relevance of the extracted itemsets and iii the algorithm scalability by varying the number of transactions A Experimental setting Experiments have been performed on an AMD Sempron TM 2400 PC with 1666 MHz CPU and 512 Mb main memory  Linux operating system Five real datasets have been exploited to validate the ef\002ciency and effectiveness of the 


a Execution time b Number of extracted itemsets 90 92 94 96 98 100 0 0.25 0.5 0.75 1 1.25 1.5 1.75 2 Itemsets containing generalized items Minimum support threshold D1 D2  D3  D4  D5  c Aggregation impact factor Fig 3 Performance of the G EN IO algorithm G EN I O algorithm These datasets were obtained by performing different capture sessions using the open-source Network Analyzer tool on a backbone link of the campus netw ork Captured traf\002c has been aggregated in traf\002c 003ows i.e records which summarize a group of similar and temporally contiguous packets Each 003ow is a transaction characterized by six attributes Source IP address destination IP address source port destination port 003ow size i.e the size of the 003ow expressed in byte and number of IP packets aggregated in that 003ow We will refer to each dataset using the ID shown in the 002rst column of Table I Table I reports the number of records and the number of different items for each dataset The used datasets have signi\002cantly different characteristics in terms of cardinality and number of different items Dataset ids are sorted by decreasing cardinality The taxonomy used in the experiments aggregates infrequent items according to the following rewriting rule trees 1 Source and destination ports are aggregated by exploiting the rewriting rule tree shown in Figure 1 which introduces three aggregation values i.e well known registered dynamic  2 Source and destination IP addresses are aggregated by exploiting the rewriting rule tree shown in Figure 2 IP addresses are aggregated in subnet if they are local to the campus network IP addresses which do not belong to the campus network are aggregated in a more general external address node Furthermore both the 003ow size bytes and number of IP packets attributes are uniformly discretized in 4 bins whose intervals are 1,1000 1000 2000 2000 3000 and equal or greater than 3000 B Frequent generalized itemset extraction performance To evaluate the proposed algorithm the following issues have been addressed i Performance of the proposed generalized itemset miner in terms of execution time number of extracted itemsets and aggregation impact factor ii comparison between G EN IO and an optimized version of the wellknown multiple-level algorithm namely Cumulate proposed in in terms of time reduction and pruning selecti vity  1 The G EN IO algorithm performance Figure 3 shows the execution time Figure 3\(a the number of extracted generalized itemsets see Figure 3\(b and the aggregation impact factor see Figure 3\(c yielded by the G EN IO algorithm by enforcing different support thresholds G EN IO execution time shown in Figure 3\(a is mainly due to the generalization process and the dataset scans While the 002rst factor depends on taxonomy features e.g number of aggregation levels the latter is proportional to the number of transactions Since the taxonomy exploited in the network traf\002c analysis is characterized by few aggregation levels the time spent for dataset scans is dominant Furthermore the execution time increases for larger datasets and lower support thresholds for which dataset scans require much more time Figure 3\(b shows the number of extracted generalized itemsets by enforcing different support thresholds When support threshold decreases the number of mined itemsets increases For high support thresholds the number of extracted generalized itemsets is quite constant When low support thresholds are enforced the number of generalized itemsets signi\002cantly increases especially when the data distribution becomes sparser see datasets D4 and D5 in Figure 3\(b This effect is given by the high number of low frequency items characterizing a sparse dataset These items become frequent when the mining process is performed by enforcing a low support threshold We also analyzed the impact of the aggregation process on the number of mined itemsets for each dataset In particular Figure 3\(c reports the percentage of itemsets arising from the generalization process with respect to the total number of extracted itemsets by varying the minimum support threshold Since generalization is a support driven process the number of itemsets containing terms at higher level of the taxonomy increases by enforcing higher support thresholds 2 Comparison between G EN IO and Cumulate We compared G EN IO with our optimized implementation of Cumulate a traditional well-kno wn generalized itemset mining algorithm Figure 4 shows the time reduction for generalized itemset extraction yielded by G EN IO with respect to Cumulate Experiments on all considered datasets have been performed by enforcing different support thresholds Cumulate did not correctly terminate the extraction task on datasets D1 D2 D3 for the lowest considered support see Figure 4 G EN IO algorithm yields a signi\002cant reduction of 


0 20 40 60 80 100 0 0.25 0.5 0.75 1 1.25 1.5 1.75 2 Time reduction Minimum support threshold D1 D2  D3  D4  D5  Fig 4 G EN IO w.r.t Cumulate Time reduction  0 1 2 3 4 5 6 7 0 0.25 0.5 0.75 1 1.25 1.5 1.75 2 Pruned generalized itemsets Minimum support threshold D1 D2  D3  D4  D5  Fig 5 G EN IO w.r.t Cumulate Pruned generalized itemsets  the e xecution time for any considered datasets and for all support thresholds The reduction is mainly due to the support driven opportunistic aggregation which reduces the number of extracted generalized itemsets as shown in Figure 5 and to the exploited strategy to further prune candidate itemsets see Section III To evaluate the pruning selectivity of our approach we have analyzed the corresponding percentage of pruned generalized itemsets with respect to Cumulate Since the G EN IO algorithm performs a support driven opportunistic aggregation of itemsets it extracts a smaller number of generalized itemsets than Cumulate Figure 5 shows the percentage of pruned generalized itemsets for all datasets G EN IO yields a good percentage of pruned itemsets for any considered support thresholds For high support thresholds since the absolute number of generalized itemsets is small see Figure 3\(b the corresponding percentage of pruned generalized itemset is about 4%-6 see Figure 5 For low support thresholds a high number of low frequency items become frequent Thus the absolute number of generalized itemsets signi\002cantly increases see Figure 3\(b while the percentage of pruned generalized itemsets see Figure 5 preserves its trend Hence the G EN IO algorithm signi\002cantly reduces the cardinality of the extracted knowledge The Cumulate algorithm could obtain the same knowledge mined by G EN IO only through a very expensive post-processing analysis over a very large set of itemsets C Analysis of the extracted generalized itemsets In the following we analyze the meaning of the extracted generalized itemsets in the network traf\002c domain 0 1 2 3 4 5 6 7 8 130.192.A 130.192.A.a 130.192.B 130.192.B.b 130.192.C 130.192.D 130.192.E 130.192.F 130.192.G 130.192.H 130.192.I 130.192.J 130.192.J.j 130.192.K 130.192.L 130.192.M 130.192.N 130.192.O.o 130.192.P 130.192.Q.q 130.192.R 130.192.S 130.192.T 130.192.U 130.192.V 130.192.W.w 130.192.X 130.192.X.x 130.192.Y 130.192.Z 130.192.AA Support Destination-IP-address destination-port:well-known destination-port:registered destination-port:dynamic destination-port:57403 Fig 6 Support of extracted 2-itemsets for different destination IP addresses and ports Figure 6 shows the support of the generalized 2-itemsets in the form destination-IP-address destination-port obtained from dataset D1 For better visualization results have been restricted to addresses of the campus network Thus no external IP address has been considered The address is automatically aggregated to the subnet when the single IP address support is under the minimum support threshold set to 1 Figure 6 provides a characterization of the traf\002c on the campus network Many extracted itemsets describe general network features For example the 002rst top supported generalized itemset identi\002es the VPN concentrator of the campus network Larger generalized itemsets i.e itemsets with more than 2 items can be exploited to focus the analysis on speci\002c traf\002c behaviors For example the 4-itemsets  destination-IP-address  130.192.O.o destination-port  57403 source-IP-address  x.x.x.x source-port  registered-port  having support equal to 2.3 highlights an unconventional high-volume traf\002c towards a speci\002c host of the campus network whereas the 4-itemsets  destination-IP-address  130.192.A.a  destinationport  registered-port  source-IP-address  y.y.y.y  sourceport  well-known  having support equal to 2 identi\002es connections to the VPN concentrator by means of a client using well-known source ports D Scalability We analyzed the scalability of the G EN IO algorithm with respect to the cardinality of records on synthetic datasets generated by means of the TPC-H generator By v arying the scale factor parameter tables with different cardinalities are generated We generated datasets of size ranging from 30,000 to 210,000 records with 12 categorical attributes We mined generalized itemsets from the lineitem table and we exploited the part  nation  and region tables to de\002ne taxonomies on line items Figure 7 which plots the extraction time for various supports shows that the proposed algorithm scales well also for large datasets Since the number of extracted itemsets grows for low supports e.g 1 the process becomes computationally more expensive However the overall CPU time is still low less than 7600 s for the lowest considered support and largest dataset 


0 1000 2000 3000 4000 5000 6000 7000 8000 30 60 90 120 150 180 210 Execution time \(s Number of records \(x 1000 minsup=1 minsup=2  minsup=5  Fig 7 Scalability on TPC-H datasets V R ELATED WORK The problem of generalized association rules was 002rstly introduced in Gi v en a dataset where each transaction is a set of items and a taxonomy de\002ned on the items generalized association rule mining consists in 002nding associations between items at any level of the taxonomy Proposed algorithms generate generalized itemsets by considering for each item its parents in the hierarchy Hence candidate frequent itemsets are exhaustively generated by producing a large amount of unnecessary item combinations One step towards a more ef\002cient extraction process for generalized itemset extraction have been proposed in  12 14 7 002rstly proposes a top-do wn hierarch y traversal based on the Apriori principle to ef\002ciently identify infrequent itemsets When a more general term is infrequent its descendants are ignored during the candidate generation However appopriate support thresholds have to be enforced to properly handle different data granularity in the taxonomy A more ef\002cient approach based on the FP-tree structure has been proposed in 12 First the FP-tree containing all frequent multiple-level items is built Then frequent generalized itemsets are generated by using a divide-an-conquer strategy as in FP-growth algorithm An ancestor list for the items belonging to the currently mined itemset is exploited to ef\002ciently prune itemsets containing both an item and its ancestor All the state-of-the-art approaches perform a similar exhaustive taxonomy evaluation by extracting most of all possible itemsets at all levels of abstraction A huge amount of itemsets is mined and valuable pattern discovery is often left as post-processing step limiting support threshold enforcement effectiveness G EN IO aims at overcoming such an issue by performing an opportunistic extraction of generalized itemsets It exploits a user provided taxonomy to drive the pruning phase of the extraction process Instead of extracting itemsets for all levels of the taxonomy and post-pruning them the proposed generalization technique over the taxonomy is support driven i.e it generalizes an itemset only if it is below the support threshold Thus G EN IO automatically performs generalization only when needed A preliminary version of the G EN IO algorithm was exploited in context-aware and netw ork traf 002c 4 domains The focus in is on pro\002ling users and services in a mobile context-aware application while in is on the characterization of stream network data Both in and 5 the G EN IO algorithm is shortly introduced as a tool to extract generalized itemsets while this paper thoroughly describes the G EN IO algorithm and extensively analyzes its performance both on synthetic and real datasets VI C ONCLUSION AND FUTURE WORK In this paper we proposed the G EN IO algorithm to ef\002ciently address generalized itemset extraction An user provided taxonomy is exploited to merge rare patterns in more general expressions The behavior of the G EN IO algorithm has been tested on real network traf\002c data The experimental results show the effectiveness of the proposed approach in discovering unexpected and generalized hidden knowledge in network traf\002c data Future works will address i the extention of G EN IO to incrementally update the extracted knowledge when new data become available ii the exploitation of multiple taxonomies over a single attribute and iii the application of the opportunistic generalization approach to more ef\002cient itemset extraction algorithms e.g LCM v.2 R EFERENCES  R Agra w al T  Imielinski and Sw ami Mining association rules between sets of items in large databases In ACM SIGMOD 1993  pages 207\226216 1993  R Agra w al and R Srikant F ast algorithm for mining association rules In VLDB 1994  1994  M L Antonie O R Zaiane and A Coman Application of data mining techniques for medical image classi\002cation In MDM/KDD 2001  2001  D Apiletti E Baralis T  Cerquitelli and V  D'Elia Characterizing network traf\002c by means of the netmine framework Computer Networks  53\(6 2009  E Baralis L Cagliero T  Cerquitelli P  Garza and M Marchetti Context-aware user and service pro\002ling by means of generalized association rules In KES 09  2009  G Cong A K H T ung X Xu F  P an and J Y ang F armer 002nding interesting rule groups in microarray datasets In ACM SIGMOD 2004  2004  J Han and Y  Fu Mining multiple-le v el association rules i n lar ge databases IEEE TKDE  11\(5 1999  J Han J Pei and Y  Y in Mining frequent patterns without candidate generation In ACM SIGMOD 2000  2000  J Hipp A Myka R W irth and U Guntzer  A ne w algorithm for f aster mining of generalized association rules In PKDD 1998  pages 74\22682 1998  M Kaya and R Alhajj Mining multi-cross le v el fuzzy weighted association rules In IEEE Conf on Intell Systems  pages 225\226230 2004  NetGroup Analyzer 3.0 2009  I Pramudiono and M Kitsure g a w a FP-tax tree structure based generalized association rule mining In DMKD 04 ACM SIGMOD workshop on Research issues in data mining and knowledge discovery  2004  R Srikant and R Agra w al Mining generalized association rules In VLDB 1995  1995  K Sriphae w and T  Theeramunk ong A ne w method for 002nding generalized frequent itemsets in association rule mining In Proceeding of the VII International Symposium on Computers and Communications  pages 420\226431 2002  TPC-H The TPC benchmark H Transaction Processing Performance Council 2009 http://www.tpc.org/tpch/default.asp  T  Uno L Kiyomi and H Arimura LCM v er 2 Ef 002cient mining algorithms for frequent/closed/maximal itemsets In FIMI 04  2004 


composition debugging model, are discussed in details. After the decision table is constru cted through collecting WSDL interface information, composition process specification, and testing execution information rule extraction algorithm in rough set reasoning is used to find the rules associated with system or service failures. In a ddition, the feasibility and effectiveness of our approach are validated by two examples and experiments. At present, we onl y consider the debugging problem for the common Web service system, the fault location for semantic Web services should be further explored in the on-going research A CKNOWLEDGMENT  This work was supported in part by the National Natural Science Foundation of China \(NSFC\under Grant No 60803046, China Postdoctoral Science Foundation under Grant No.2007041 0946, the Science Fo undation of Jiangxi Educational Committee under Grant No. GJJ10433, and the Youth Foundation of Jiangxi University of Finance and Economics. The author is grateful to Qiong Zhang for her warm-heart help, and thanks the anonymous reviewers for their insightful comments R EFERENCES  1 W. Han  Integrating Peer-to-Peer into Web Services Master thesis University of Saskatchewan, 2006  W3C Web S e rvi ces Activit y avai lable fro m  http://www w3.org 2002/ws/, accessed on July 2010  W o rld W i de W e b Cons ortiu m  W3C Web Services Description Language \(WSDL\ Version 1.1 March, 2001. Available at http://www. w3.org/TR/wsdl  W o r l d W i de W e b Consor tiu m  W 3C  Simple Object Access Protocol Version 1.2 April 2007, available at http://www.w3.org/TR/soap12  OASIS WSBP EL Technical Co mm i ttee  Web Services Business Process Execution Language, Version 2.0 available at http://docs oasis-open.org/wsbpel/2.0 /wsbpelv2.0.pdf  M. Aoya m a S Wee rawa rana, H Maruya m a and et al W eb  Services Engineering: Promises and Challenges Proc. of ICSEí02  ACM Press, New York 2002, pp. 647-648  C. Liu L. Fei X Yan, and et al., çStatistical Debuggin g: A Hypothesis Testing-Based Approach IEEE Transactions on Software Engineering 2006, vol. 32, no. 10, pp.1-17  W  Dickinson, D. Leon, and A Podgurski, çFinding Failures by Cluster Analysis of Execution Profiles Proc. of ICSEí01 2001, pp 339-348  Z. Li and Y Zhou, çPRM iner: Automatically Extracting Implicit Programming Rules and Detecting Violations in Large Software Code Proc. of ESEC/ FSEí05 2005, pp. 306-315  M. Renieris, and S. P Reiss, çFault LocalizationWith Nearest Neighbor Queries Proc. of ASEí03 2003, pp. 30-39  C. Liu, Z Lian and J. Han, çHow Bayesians Debug Proc. of ICDMí06 2006, pp.382-393  G. D. F a tta, S   Leue, and E. St e g antova D iscri m inative Pattern Mining in Software Fault Detection Proc. of SOQUAí06 2006 pp.62-69  M. J Harrold, G. Rotherm e l, K Sayre, and et al., çAn Empirical Investigation of the Relationship Between Fault-revealing Test Behavior and Differences in Program Spectra Journal of Software Testing Verification and Reliability 2000, vol. 10, no.3, pp. 171-194  D. Jeffrey, N. Gup ta, and R. Gupta Fault Localizatio n Using Value Replacement Proc. of ISSTAí08 2008, pp. 167-178  IBM W e b Services: Taking e-Busi ness to the Next Level White Paper, 2000, available from: http://www.ibm.com/developerworks/cn websphere/ download/pdf/e-businessj.pdf  S. Noikajana, and T. Suwannasart, çW eb Service Test Case Generation Based on Decision Table Proc. of the 8th International Conference on Quality Software \(QSICí08 2008, pp. 321-326  C M a o Per form ing Co m b inator ial Testing on W e b Ser viceBased  Software Proc. of Intíl Conf. on Computer Science and Software Engineering \(CSSEí08 2008, vol.2, pp.755-758  T  Y Chen F.C  Kuo T  H T s e and et al  M eta m or phic T e sting and Beyond Proc. of the 11th International Workshop on Software Technology and Engineering Practice \(STEPí03 2003, pp.94-100  Business Process Managem e nt Initiative Business Process Modeling Language \(BPML November, 2002  W 3 C  OWL-S: Semantic Markup for Web Services Nov. 22, 2004 available from: http://www.w3.org/ Submission/OWL-S  Z. Pawlak, çRoug h Set Intíl Journal of Information and Computer Science vol. 11, 1982, pp. 341-356  Jianhua Dai Research on Rough Set Theory and Its Applications in Knowledge Discovery \(Ph. D. Dissertation Library of Wuhan University, 2003, pp. 97104.   \(in Chinese  M Kry szkiewicz, çRou gh Set Approach to Inco m p l e t e Inform ation Systems Information Sciences 1998, vol. 112, pp. 39-49  C  M a o, çSlicing W e b Ser vicebased Softwar e Proc. of IEEE International Conference on Service-Oriented Computing and Applications \(SOCAí09 Taipei, Taiwan, December 14-15, 2009, pp 91-98  C M a o X Hu and Y L u  T owards a Softwar e Diagnosis M e tho d  Based on Rough Set Reasoning Proc. of the IEEE 8th International Conference on Computer and Information Technology \(CITí08  Sydney, Australia, July 811, 2008, pp. 718-723  I   Gr osclaude  M odelbased M o nitor ing of Co m ponentbased Software Systems Proc. of the 15th International Workshop on Principles of Diagnosis 2004, pp. 155-160  L  Ar dissono L  Console A Go y  and et al Enhancing W e b  Services with Diagnostic Capabilities Proc. of the 3rd IEEE European Conference on Web Services 2005, pp. 182-191  X Fu P Z ou  Z   Shang and et al   Fault Diagnosis f o r W e b Ser vice Composition Based on Bayesian Networké, Computer Applications 2008, vol.28, no. 5, pp. 1095-1097.   \(in Chinese   
299 


        


9 Appendix Fig 6: Forest Cover Types of the U.S. \(Source. USGS National Atlas of US Summary of Forest Cover Type Data Type Multivariate Abstract The forest cover type for 30 x 30 meter cells obtai ned from US Forest Service \(USFS\ Region 2 Resource Information System RIS\ data Data Characteristics The actual forest cover type for a given observatio n \(30 x 30 meter cell\ was determined from US Fores t Service \(USFS\ Region 2 Resource Information System RIS data Independe nt variables were derived from data originally obta ined from US Geological Survey \(USGS\ and USFS data. Data is in raw form \(not scaled\ and contains binary \(0 or 1 columns of data for qualitative independent variables \(wilderness areas and soil types Summary Statistics Number of instances observations 581012 Number of Attributes 54 Attribute breakdown 12 measures, but 54 columns of data \(10 quantitativ e variables, 4 binary wilderness areas and 40 binary soil type variables Missing Attribute Values None 43 


   C4.2 Open GL has excellent documentation that could help the developer learn the platform with ease C4.3 Developer has very little ex perience in working with Open GL platform  For our case study, alternative B i.e. Adobe Director was the most favorable alternative amongst all the three. It catered to the reusability criteria quite well and aimed at meeting most of the desired operational requirements for the system   6. CONCLUSION & FUTURE WORK  The main contribution of this paper is to develop an approach for evaluating performance scores in MultiCriteria decision making using an intelligent computational argumentation network. The evaluation process requires us to identify performance scores in multi criteria decision making which are not obtained objectively and quantify the same by providing a strong rationale. In this way, deeper analysis can be achieved in reducing the uncertainty problem involved in Multi Criteria decision paradigm. As a part of our future work we plan on conducting a large scale empirical analysis of the argumentation system to validate its effectiveness   REFERENCES  1  L  P Am g o u d  U sin g  A r g u men ts f o r mak i n g an d  ex p lain in g  decisions Artificial Intelligence 173 413-436, \(2009 2 A  Boch m a n   C ollectiv e A r g u men tatio n    Proceedings of the Workshop on Non-Monotonic Reasoning 2002 3 G  R Bu y u k o zk an  Ev alu a tio n o f sof tware d e v e lo p m en t  projects using a fuzzy multi-criteria decision approach Mathematics and Computers in Simualtion 77 464-475, \(2008 4 M T  Chen   F u zzy MCD M A p p r o ach t o Selec t Serv ice  Provider The IEEE International Conference on Fuzzy 2003 5 J. Con k li n  an d  M. Beg e m a n   gIBIS: A Hypertext Tool for Exploratory Policy Discussion Transactions on Office Information Systems 6\(4\: 303  331, \(1988 6 B P  Duarte D e v elo p in g a p r o jec ts ev alu a tio n sy ste m based on multiple attribute value theroy Computer Operations Research 33 1488-1504, \(2006 7 E G  Fo rm an  T h e  A n a l y t ic Hier a rch y P r o cess A n  Exposition OR CHRONICLE 1999 8 M. L ease  an d J L  L i v e l y  Using an Issue Based Hypertext System to Capture Software LifeCycle Process Hypermedia  2\(1\, pp. 34  45, \(1990 9  P e id e L i u   E valu a tio n Mo d e l o f Custo m e r Satis f a c tio n o f  B2CE Commerce Based on Combin ation of Linguistic Variables and Fuzzy Triangular Numbers Eight ACIS International Conference on Software Engin eering, Artificial Intelligence Networking and Parallel Distributed Computing, \(pp 450-454 2007  10  X  F L i u   M an ag e m en t o f an In tellig e n t A r g u m e n tatio n  Network for a Web-Based Collaborative Engineering Design Environment Proceedings of the 2007 IEEE International Symposium on Collaborative Technologies and Systems,\(CTS 2007\, Orlando, Florida May 21-25, 2007 11 X. F L i u   A n In ternet Ba se d In tellig e n t A r g u m e n tatio n  System for Collaborative Engineering Design Proceedings of the 2006 IEEE International Symposium on Collaborative Technologies and Systems pp. 318-325\. Las Vegas, Nevada 2006 12 T  M A sub jec tiv e assess m e n t o f altern ativ e m ission  architectures for the human exploration of Mars at NASA using multicriteria decision making Computer and Operations Research 1147-1164, \(June 2004 13 A  N Mo n ireh  F u zzy De cisio n Ma k i n g b a se d o n  Relationship Analysis between Criteria Annual Meeting of the North American Fuzzy Information Processing Society 2005 14 N  P a p a d ias HERMES Su p p o rti n g A r g u m e n tative  Discourse in Multi Agent Decision Making Proceedings of the 15th National Conference on Artifical Intelligence \(AAAI-98  pp. 827-832\dison, WI: AAAI/MIT Press,  \(1998a 15  E. B T riantaph y llo u   T h e Im p act o f  Ag g r e g atin g Ben e f i t  and Cost Criteria in Four MCDA Methods IEEE Transactions on Engineering Management, Vol 52, No 2 May 2005 16 S  H T s a u r T h e Ev alu a tio n o f airlin e se rv ice q u a lity b y  fuzzy MCDM Tourism Management 107-115, \(2002 1 T  D W a n g  Develo p in g a f u zz y  T O P S IS app r o ach  b a sed  on subjective weights and objective weights Expert Systems with Applications 8980-8985, \(2009 18 L  A  Zadeh  F u z z y Sets   Information and Control 8  338-353, \(1965  152 


                        





