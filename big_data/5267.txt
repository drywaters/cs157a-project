Rule Induction for Identifying Multi Layer Tool Commonalities  Alexander Borisov, Igor Chikalov, Eric St. Pierre, Eugene Tuv Intel Corporation 4500 S Dobson Rd Chandler, AZ  85248 USA   Abstract A methodology based on association rule concepts is given for detecting fab tool commonality of affected lots.  The performance of the methodology is then compared to several traditional methods such as ANOVA and contingency tables using eight actual production cases.  In each case, the offending tool is affecting lots at multiple process layers  I. INTRODUCTION  Many fab tools are used at more than one process step which poses a challenge for iden tifying tool commonality of yield problems.  For example a specific wet bench might be used for a dozen layers \(operation numbers\which makes it difficult to find a yield problem caused by the bench if one looks only a layer at a time.  Also, it would be desirable to be able to identify not only which tool is at fault, but also which layers on the tool are at fault and on what dates.  There are several existing methods in common use to search for tool commonality across multiple layers Some are model based and rank commonalities using statistical tests, such as ANOVA and contingency tables.  Others are simple ranking criterions that typically have as their goal to rank the tool which processed the most affected lots in the shortest period of time at the top of the rank list.  Generally these methods do not include time or layer in the model or search criterion.  We present a rule induction methodology that efficiently searches through tools, layers, and ti me combinations finding and ranking those that are likely responsible for the yield problems. We compare   performance of the proposed methodology with ANOVA, con tingency tables, and mostlots-in-least-time ranking  A multi layer tool comm onality is loosely defined as a commonality which is best found by looking across all layers a fab tool is running, rather than looking a layer at a time.  For example, consider Fig. 1.  A single fab tool is running 4 layers.  Lots with a ë1í on the y axis have been categorized as Badî and lots with a ë0í have been categorized as ìGood By looking at all layers at once it is clear that the problem started after Dec. 15 th and ended before Dec. 21 st Contrast Fig. 1 with Fig. 2, which show s the same time trend split into a separate graph for each layer.  The trend is no longer apparent when looking a layer at a time   0  1 Lot Category               09Dec2008  11Dec2008  13Dec2008  15Dec2008  17Dec2008  19Dec2008  21Dec2008  23Dec2008 Date  A  B  C  D Layer  Fig. 1.  Time trend for single fab tool showing good and bad lots by layer   0  1 Lot Category   18Dec2008  19Dec2008  19Dec2008  20Dec2008  20Dec2008  21Dec2008  21Dec2008  21Dec2008  22Dec2008  22Dec2008  Date   Sca tte rplot Ma trix La ye r=D  0  1 Lot Category   17Dec2008  18Dec2008  19Dec2008  20Dec2008  21Dec2008  22Dec2008  Date   Sca tte rplot Ma trix La ye r=C  0  1 Lot Category   11Dec2008  13Dec2008  15Dec2008  17Dec2008  19Dec2008  21Dec2008 Date   Sca tte rplot Ma trix La ye r=B  0  1 Lot Category       10Dec2008  11Dec2008  12Dec2008  13Dec2008  14Dec2008  15Dec2008  16Dec2008  17Dec2008  18Dec2008  19Dec2008  Date   Sca tte rplot Ma trix La ye r=A  Fig. 2.  Time trend from Fig.1 separated by layer        322 978-1-4244-6519-7/10/$26.00 ©2010 IEEE ASMC 2010 


II.  METHODOLOGY A.  Basic Concept of Association Rules A common application of association rules is searching a large database of customer purchases at a retail business. It is often referred as ìmarket basket analysisî where rules generally have the form of {A,B}=>{C}, meaning that if A and B are bought, customers also buy C. Rules are usually measured by their support and confidence.  Support measures what percent of rows in the database are covered by the rule conditions. Confidence measures ho w often the rule is correct For example, if a rule {A,B}=>{C} has 0.65 support and 0.41 confidence, this indicates that 65% of the transactions in the database contain both A and B and 41% of the {A,B combination results in {C}.   A tool commonality rule would look like {fab tool, date range layers}=.{yield issue}.  Here we are more interested in the conditional support, which is the number of known bad lots that we re processed on a specific tool, subset of the correspondi ng layers, during the date range identified by the rule.  Confidence can be thought of as a ìhit rateî, that is, if a number of lots were sent through the specific tool, during the rule date range and at one of the identified layers, how many do we expect would be hit with the yield problem.  For more on association rules, interested readers are referre  Using the association rule concepts, we could count the number of bad lots that occur on tool, layer, and date combinations and the number of times that combination results in a bad lot.  Our goal is to put the tool at fault at the top of a rank list.  However, cal culating every possible rule is not usually possible since fabs typically have hundreds of tools and operation numbers and analysts usually are looking at tens of bad lots across 30 day time periods, so the count of possible combinations explodes to an impractical number. In  we succe ssfully a d opte d t h e prim a ry association rule induction algorithm, Apriori for single layer commonality analysis targeting spatial patterns in sort wafer maps.   Here we look to expand the methodology for multi layer commonality B.  Applying the Concept to Ranking Tool Commonality The main limitation of the association rules approach which creates an exhaustive set of rules, is the requirement of discrete attributes. It means that time through the tool has to be pre-discretized and layers are pre-grouped before the Apriori algorithm can be used. That poses a significant challenge when a correct rule could have multiple constraints on the tool, subset of layers, and the time interval. We address these limitations by using a direct search optimization technique to solve a 2-targ et \(conditional support and confidence\aximization probl em. The 2-target problem is transformed to a single fitn ess function optimization task that combines a weighted combina tion of conditional support and confidence of the resulting ru le. Conditional support and confidence are intuitiv e measures that allow us to rank rules by a combination of how many ba d lots they contain and their hit rate. Rules are sorted by the fitness function, and accompanied by insightful, novel visualization.  The algorithm is given formally in Algorithm 1 ALGORITHM 1 1. For  t = 1,...,T 2.    Calculate c* = c\(min\(X i3 ax\(X i3 and cs* = cs\(min\(X i3 ax\(X i3  3.    For k = 1,Ö,K 4.       for k>1 if\(cs\(LB k-1 UB k-1  min then go to step 14 end for 5.       for k = 1 set I UBk I and UB k max\(X i3  end for 6.       For l 1,Ö,I UBk  set LB l x l 3  calculate f\(LB l UB k  End For l  7.       select LB k  f\(LB l UB k  8.       set I LBk to row number in X T of LB k  9.       For u = I,Ö,I LBk  set UB u x u3  calculate f\(LB k UB u  End For u 10.     select UB k   f\(LB k UB u  11.     set I UBk to row number in X T of UB k  12.     for k > 1 if f\(LB k UB k  f\(LB k-1 UB k-1 go to step 14 end for 13.    End For K 14.      set LB = LB k and UB = UB k  15.    End For T  l max arg u max arg TABLE I NOTATION FOR ALGORITHM 1  T  Number of fab tools I  Number of occurrences of lots on tool t K  Number of user specified iterations LB Lower date bound for rule UB Upper date bound for rule C  Confidence calculated on distinct lots CS Conditional support calculated on distinct lots CS min  User specified minimum conditional support f\(LB,UB\function c\(LB,UB cs\(LB,UB\ ñ cs   User specified trade off between C and CS X T x i,j  i=1,Ö,I,j=1,Ö,3 where X i1 Lot ID, X i2 Affected ID \(0 or 1\X i3 Date   323 ASMC 2010 


C. Competing Methods Algorithm 1 will be compared to the methods described below.  The goal of each is to rank the tool at fault at the top of a rank list, but how this is attempted is much different between the methods.  For mo re background on traditional commonality methods, see 4 i ANOVA Very common method for detecting yield differences between tools.  The mean of the failing sort bin\(s\ake up the spatial pattern are calculated by tool, by operation.  The means of all tools at an operation are then compared using a statistical test.  Tools are then ranked by the statistical significance of the difference between the tools at a layer.  This is a layer-at-a-time method since means for the tools are calculated by layer This method is commonly automated by fab yield analysts where a set number of days back \(say 30 days\of end of line sort data is extracted daily and ANOVA is automatically performed ii Contingency Tables Another common statistical model based method for finding tool commonality of bad lots.  Here, a table is constructed for each fab tool, where all lots in the data set are categorized by the user as ìGoodî or ìBadî and also ìYesî or  ìNo as to whether they ran on a specific tool.  A 2X2 table is then constructed where the columns indicate whether lots were affected or not, e.g Goodî,îBadî\r lots ran on the tool or not, e.g.   \(ìYesî,îNo statistical test is then pe rformed to see if the proportion of bad lots for a fab tool exceeds that of other tools of its kind.  T ools are then ranked by the statistical significance of the test.  This is a multi layer approach since the 2X2 tables are constructed by tool, NOT by tool, by layer iii Most-lots-in-least-time An intuitive approach which ranks fab tools by the percent of the user classified ìBadî lots they ran and the shortest length of time required to span all ìBadî lots ran on the tool For example, if Tool A and Tool B each ran 9 of 10 Badî lots, but the minimum time span needed to cover the 9 lots was 2 days for Tool A and 3 days for Tool B, then Tool A would be ranked above Tool B Is a multi layer approach since the count and time span are done by tool, NOT by tool and layer iv Single Layer Rule An association rule based method which uses conditional support and confidence to rank rules.  Rules are ranked based upon their distance from the pareto bound on the conditional support-confidence plane.  The pareto bound is defined by points for which there is no other point with greater conditional support and confidence.  Method is de scribed in deta  Similar in concept to Algo rithm 1, except this is a single layer method since rules are built by tool, by layer III A PPLICATION   A.  Data Sets  The performance of Algorithm 1 was compared to the traditional methods for findin g tool commonality, namely ANOVA, contingency tables, and most-lots-in-least-time ranking.  The 8 data sets used are production data where the tool causing the yield problem is affecting lots at multiple operation numbers \(layers\.  These data sets were selected as they are typical of the yield problems seen at a modern semiconductor fab with high yi elds.  Because of the high yields, the number of die affected per wafer tends to be small which hurts the ability of mean die per wafer based methods like ANOVA of finding the correct tool commonality.  All 8 yield issues have a spatial pattern.  A summary of the 8 data sets is given in Table II.  No te that hit rate is the percent of bad lots that ran through the tool during the affected time period TABLE II DATA SET SUMMARY   Space constraints prevent providing more detail on each of these cases, however, the Deposition Tool 2 case will be highlighted to provide a goo d idea of the challenges the commonality methods face in identifying the fab tool which is at fault.  Fig. 3 shows some of the sort wafer maps for wafers affected by the deposition tool.  Note that the spatial pattern is a small, approximately square region which rotates around the edge of the wafer   324 ASMC 2010 


 Fig. 3.  Sort wafer maps of a sample of the affected wafers  There are several challenges presented by this data set to any commonality method.  Specifically, only 7 lots are affected, the problem is intermittent \(hit rate is only 16 only a small number of die per wafer are affected, there are 30 days of end of line data in the data set, there are approximately 500 fab tools which could be at fault and many of these tools are used at multiple operations.  Some or all of these challenges are present in each data set B.  Results Table III provides the su mmary results of applying each method to the data sets.  The value given in the table is the rank which was given to the correct tool.  For example, a ë1 indicates the tool which was at fault was ranked at the top of the rank list, a ë17í indicates th e tool which was at fault was ranked 17 th in the rank list.  A ëNRí means that the method did not provide a rank for the corr ect tool since no difference between the tool and its peers was detected.  The median and range of the ranks for each method are also provided.  The order of the methods in the tab le are from best to worst at consistently finding the correct tool as determined by the median and range of the ranks  TABLE III RESULTS SUMMARY  Algorithm 1 \(Layer=Multiple, Method=Rule\ in Table III, ranks the correct tool at the top of the list for all but one of the data sets where it ranks the correct tool as 2 nd  Fig.ís 4-6 show supporting graphics generated for the rules found by Algorithm 1 for the Deposition Tool 2 data set.  Fig. 4 shows the rules list and x y scatter plot of conditional support and confidence which allows easy browsing of all competing rules in the rank list Fig. 5 is the time trend plot of all lots that ran on the tool identified at the top of the rule list.  Multi layer time plots are complicated by a lot being able to enter the tool many times, as opposed to a single layer time plot where a lot can only enter once.  To reduce clutter, only the first and last times a lot enters a tool are charted and a line is drawn between these two points to indicate that the lot may have entered the tool additional times within that range.  Since we are plotting a bi response \(ìGoodî,îBadî\, it is necessary to add jitter to the y axis so that many points are not drawn on top of each other and become unidentifiable.  The ìBadî lots are shown in red and are at the top of the graph, the ìGoodî lots are shown in the bottom of the graph.  Th symbols on the graph correspond to which operation number the lot entered the tool.  Fig. 6 shows other graphs generated which allow the user to compare the identifie   nary e d tool to others of its kind, compare operation numbers, and look at the hit rate versus number of times lots passed through a bad tool  Fig. 4.  Sorted rule list and x y scatter plot of confidence and conditional support for the Deposition Tool 2 case, multilayer analysis  Fig. 5.  Time trend for the tool at fault  in the Dep. Tool 2 data set  325 ASMC 2010 


  Fig. 6.  Other supporting graphics for the rule identified in Fig. 4   violated, but that is less critical than say, looking only a layer at C.  Discussion of Resu lts for Competing Methods In general, these methods fail to consistently rank the correct tool at the top of the list for at least one of the primary reasons in the list below.  There are secondary reasons as well such as some of the assumptions of the statistical tests are a time for a multi layer yield signal i Method searches a layer at a time The ANOVA and single layer rule methods look at the data split into a layer at a time.  As demonstrated in the simple example in Fig. 1  and 2, this can hide an otherwise obvious signal ii Method searches for a difference in the mean number of bad die \(or specific sort fail bins This is why ANOVA tends to fail on these data sets.  At high yielding factories many of the yield issues affe ct only a small number of lots and only a small number of die per wafer on affected lots Too few lots and die per wafer affected results in a small, if any difference, between the corr ect tools and other tools of its kind iii Method does not effectiv ely restrict the data set to approximately the affected time period only ANOVA calculates the means for each tool on all data provided This means it mixes unaffected and affected time periods diluting the signal.  Continge ncy tables also tabulate all the data provided, again mixing affected and unaffected time  periods and also diluting the signal iv Method uses a statistic for ranking which is sensitive to widely differing run rates and number of layers processed  between tool types This is the case with the most-lots-in least-time method.  Both Al gorithm 1 and most-lots-inleast time use conditional support as part of the ranking criterion.  However, Algorithm 1 also uses hit rate, which normalizes for differences in run rates and layers proc by dividing by the number of lo ts during the time period Most-lots-in-least time does not normalize for these differences, rather it simply searches for the smallest time window that includes the largest number of affected lot This leaves it vulnerable to ranking tools like wet benches consistently near the top of all the data sets  since wet benches typically have high run rates and are used at many layers.  A tool with a high run rate that is in use for many layers is more likely to essed s   have a small time window for the affected lots simply because it can run more lots in less time more often  in  e time d, rather than on constructing a sample.  Also, it enables greater efficiency in that more signals can be found in less time  IV.  CONCLUSIONS  In [2   we de m onstrated how m e thods bas e d on m oder n statistical learning algorithms can greatly reduce the time required to do the typical analysis done by yield analysts fabs.  Here, we have focused specifically on how a modern method generally referred to as association rules can be adapted to out perform traditi onal methods for doing multi layer tool commonality.  While any of the traditional methods could perform better with more human intervention, such as preparing well groomed data sets with carefully constructed Goodî lot lists or time periods to compare against, thes consuming efforts are made unnecessary by Algorithm 1.   We have coded the algorithm to run in seconds on a laptop computer against data sets of 500 lots and no time consuming sample selection is required fro m the user in order for the method to find the correct tool commonality, just run the past n days of data through the algorithm.  The benefit for the analyst is that more time can be spent following up on the top few commonalities identifie    326 ASMC 2010 


 IEEE/SEMI International vol., no pp.85-89, 21-23 May 1990 V R EFERENCES   1  T. Hastie,  R Tibshirani, and J. Friedman The Elements of Statistical Learning New York:  Springer-Verlag, 2001 2  St. Pierre, E.R.; Tuv, E.; Borisov, A., "Spatial Patterns in Sort Wafer Maps and Identifying Fab Tool Commonalities Advanced Semiconductor Manufacturing Conference, 2008. ASMC 2008 IEEE/SEMI vol., no., pp.268-272, 5-7 May 2008 3  Kong, G., "Tool commonality analysis for yield enhancement Advanced Semiconductor Manufacturing 2002 IEEE/SEMI Conference and Workshop vol., no., pp. 202-205, 2002 4  Garling, L.K.; Woods, G.P., "Determining equipment performance using analysis of variance Semiconductor Manufacturing Science Symposium, 1990. ISMSS 1990 327 ASMC 2010 


   for overlooking the overall software development process and playing a crucial role in making important decisions  5.1.3. The Criterion Set As stated earlier, criterion is the attribute for which favorability of an alternativ e is calculated. The criterion set defined for this case study comprises of Reusability  Meeting Operational Requirements and Meeting Project Deadline By reusability, we mean, the amount of reuse of different functionalities that ca n be achieved from the previously developed system on Mine detection training tool. Meeting operational requirements implies how effectively a desired operational capability can be satisfied by an alternative. For example, some alternative might lack a certain operational capability like database support whereas another may support it with enhanced features. Meeting project deadline stresses on the fact whether the project requirements can be satisfactorily achieved within the stipulated deadline which in our case was around one year  5.1.4. The Alternatives To resolve the concerned issu e, the stakeholders decided to choose one software platfor m for developing the mine detection training tool among the three stated alternatives Adobe Director  Adobe Flash  Open GL were chosen as the three possible alternatives along with some justifications. Adobe Flash was chosen as one of the alternatives because; the stakeholders already had a previous developed system for mine detection developed using Adobe Flash    Figure 6. Mine Detection System Along With Three Alternatives One of the considerations involved here was to enhance this system rather than develop a new system from scratch. Same reason applied to choosing Adobe Director as one of the other alternatives. Open GL was picked up as one of the three alternatives in the case when a new development had to be started Open GL is an advanced software development platform and it could have served as a good platform for the mine detection training system  Figure 6 summarizes the pro ject and its three alternatives positions available  5.2. Prioritizing The Criteria  For an effective decision making, we had to weigh the criteria according to their im portance in the decision making process. For this, we choose Analytic Hierarchy process because of its effectiveness in performing pair wise comparison of elements .Table 2 shows the ranking table used for comparing the two criteria  Table 2. Criteria Comp arison Table For AHP  Value a ij  Comparison Description 1 Criteria i and j are of equal importance 3 Criteria i is weakly more important than j 5 Criteria i is strongly more important than j 7 Criteria i is very strongly more important than j 9 Criteria i is absolutely more important than j   Table 3. Comparison Values For Prioritizing Different Criteria   Reusability Meeting Operational Requirements Meeting project Deadline Reusability 1 1/5 3 Meeting Operational Requirements 5  1  7 Meeting Project Deadline  1/3 1/7  1   149 


   Table 4. Normalized Criteria Comparison Table In AHP   Reusability Meeting Operational Requirements Meeting project Deadline Reusability 0.157 0.148 0.272 Meeting Operational Requirements 0.789 0.744 0.636 Meeting Project Deadline 0.052 0.106 0.090  Table 3 and Table 4 show the weight values of the three criterions as compared to each other using the AHP process. These weights have been decided by the stakeholders after discussions among themselves Average weights can be derived from Table 4 as follows Reusability- 0.193 Meeting Operational Requirements- 0.724 Meeting Project Deadline- 0.083 These weights represent the priority of each criterion on a scale of 0 to 1  5.3. Argumentation Tree  We develop argumentation tree for each and every alternative separately. The ar guments are stated by stake holders and assembled under the alternative but they target a specific cr iterion. These arguments can either be supporting or attacking each other or their respective alternative nodes. We present three figures, where each figure represents the argumentation hierarchy for one alternative. Rectangular boxes represent the alternatives with the name of the alternative under it. Ovals represent the criteria with their descr iption. The arguments are specified by labels èAê, èBê, èCê for alternative çAdobe flashé, çAdobe Directoré and çOpen GLé respectively Along with the labels, the arguments also have indexes associated with them. Beneath the labels are two boxes The box on left shows the weight of the argument whereas the box on right shows the priority of the stakeholder who specifies the argument  Once the argument has been sp ecified, the user enters its weight. We first reassess the weights of the arguments using priority reassessment discussed in h e n us ing the techniques specified in [11 w e red u ce t h e arg u m e n t s  to a single level. Finally, the weighted summation of the arguments with the criteria weights helps us evaluate the final weights for the decision matrix. It is important to note here that, the aggregation method used for calculating the favorability is a weighted summation  The three argumentation hierarchies for the three alternatives are presented in the Figures 7, 8, and 9. The diagrams contain arguments, their weights and the stakeholderês priorities     Figure 7. Argumentation Tree For Adobe Flash   Figure 8. Argumentation Tree For Adobe Director 150 


     Figure 9. Argumentation Tree For Open GL  A1 The current system in flash does not have the functionality of dynamic allocation of particles like mine or clutter. It places them randomly  A1.1 That is not of much importance because it still gives a new position to mine and clutter particles A2 Current system in flash has faster response time as compared to system in Adobe Director A3 The current system doesnêt satisfy many of the features required for the new system like database A4 Adobe Flash cannot communicate with database A4.1 Flash doesnêt support database but database support is very important and critical A4.1.1 The system should be able to generate evaluation reports for trainee based on pr evious records stored in the database A5 Flash doesnêt create sound clips  A5.1 We donêt need sound creating features as the sys tem has to generate sound. We can play externally recorded sound files using Adobe Flash A6 Flash can provide good visual effects as compared to Adobe Director A7 The developer has good knowledge in development using Flash so the system can be developed quickly B1 We could reuse the system already developed for sound generation, as it is developed using Adobe Audition for analysis which is somehow related to Adobe Director B1.1 The current system is better synthesized in terms of sound production and the sound produced is also instantaneous rather than discrete B1.2 That current system has certain performance issues like slow response time B1.3 The current system in Adobe Director has the feature of producing dynamic coloring scheme on approaching a mine. This kind of scheme is highly preferable and is not present in Adobe Flash system B2 Adobe Director can provide more functionality as compared to the current flash system. E.g. Multiple sounds while detecting mines   B2.1 Adobe Director can provide better visual effects as compared to flash e.g. in case of GUIês   B2.2 A modified version of the current system in flash can also provide the same functionality B2.2.1 We cannot integrate code developed in other platforms with Flash, but Flash can be integrated in Adobe Director B3 The interface provided by flash is not professional enough. It is too simple and straight forward for doing more things in future   B4 Easily available plug-ins can help integrate the tracking system developed in C# with Adobe Director  B4.1 Code developed in Open GL/AL can also be integrated using Adobe Director using suitable stubs   B5 A new sound recognition algorithm is being developed in Adobe Audition which can be integrated with Adobe Director but not with Open GL or Flash Evidence supported B6 If the current system is reused; the project deadline can be met easily B7 The developer has very little experience in development using Adobe Director   B7.1 The developer can take help from the already developed system in Adobe Director C1 The tracking software already developed is coded in C#/NX5. We could reuse that and develop our system in Open GL/AL C1.1 Open GL has C# libraries which can be used to develop the system C2 Because the platform used is for high end application development, it can provide good GUI and database support C2.1 Open GL/AL can help us generate dynamic surfaces for mine detection and training which the original system in flash does not have C4 Open GL does not support connectivity with Adobe Audition. Adobe Audition is required for creating sound recognition algorithm C3 Open GL does not support connectivity with Adobe Audition. Adobe Audition is required for creating sound recognition algorithm C4 The time taken for developing the project using open GL will be comparatively more as the whole system would have to be developed from scratch C4.1 If Open GL has support for C# libraries, and then the system could be develope d faster as developer is quite familiar with programming languages like C 151 


   C4.2 Open GL has excellent documentation that could help the developer learn the platform with ease C4.3 Developer has very little ex perience in working with Open GL platform  For our case study, alternative B i.e. Adobe Director was the most favorable alternative amongst all the three. It catered to the reusability criteria quite well and aimed at meeting most of the desired operational requirements for the system   6. CONCLUSION & FUTURE WORK  The main contribution of this paper is to develop an approach for evaluating performance scores in MultiCriteria decision making using an intelligent computational argumentation network. The evaluation process requires us to identify performance scores in multi criteria decision making which are not obtained objectively and quantify the same by providing a strong rationale. In this way, deeper analysis can be achieved in reducing the uncertainty problem involved in Multi Criteria decision paradigm. As a part of our future work we plan on conducting a large scale empirical analysis of the argumentation system to validate its effectiveness   REFERENCES  1  L  P Am g o u d  U sin g  A r g u men ts f o r mak i n g an d  ex p lain in g  decisions Artificial Intelligence 173 413-436, \(2009 2 A  Boch m a n   C ollectiv e A r g u men tatio n    Proceedings of the Workshop on Non-Monotonic Reasoning 2002 3 G  R Bu y u k o zk an  Ev alu a tio n o f sof tware d e v e lo p m en t  projects using a fuzzy multi-criteria decision approach Mathematics and Computers in Simualtion 77 464-475, \(2008 4 M T  Chen   F u zzy MCD M A p p r o ach t o Selec t Serv ice  Provider The IEEE International Conference on Fuzzy 2003 5 J. Con k li n  an d  M. Beg e m a n   gIBIS: A Hypertext Tool for Exploratory Policy Discussion Transactions on Office Information Systems 6\(4\: 303  331, \(1988 6 B P  Duarte D e v elo p in g a p r o jec ts ev alu a tio n sy ste m based on multiple attribute value theroy Computer Operations Research 33 1488-1504, \(2006 7 E G  Fo rm an  T h e  A n a l y t ic Hier a rch y P r o cess A n  Exposition OR CHRONICLE 1999 8 M. L ease  an d J L  L i v e l y  Using an Issue Based Hypertext System to Capture Software LifeCycle Process Hypermedia  2\(1\, pp. 34  45, \(1990 9  P e id e L i u   E valu a tio n Mo d e l o f Custo m e r Satis f a c tio n o f  B2CE Commerce Based on Combin ation of Linguistic Variables and Fuzzy Triangular Numbers Eight ACIS International Conference on Software Engin eering, Artificial Intelligence Networking and Parallel Distributed Computing, \(pp 450-454 2007  10  X  F L i u   M an ag e m en t o f an In tellig e n t A r g u m e n tatio n  Network for a Web-Based Collaborative Engineering Design Environment Proceedings of the 2007 IEEE International Symposium on Collaborative Technologies and Systems,\(CTS 2007\, Orlando, Florida May 21-25, 2007 11 X. F L i u   A n In ternet Ba se d In tellig e n t A r g u m e n tatio n  System for Collaborative Engineering Design Proceedings of the 2006 IEEE International Symposium on Collaborative Technologies and Systems pp. 318-325\. Las Vegas, Nevada 2006 12 T  M A sub jec tiv e assess m e n t o f altern ativ e m ission  architectures for the human exploration of Mars at NASA using multicriteria decision making Computer and Operations Research 1147-1164, \(June 2004 13 A  N Mo n ireh  F u zzy De cisio n Ma k i n g b a se d o n  Relationship Analysis between Criteria Annual Meeting of the North American Fuzzy Information Processing Society 2005 14 N  P a p a d ias HERMES Su p p o rti n g A r g u m e n tative  Discourse in Multi Agent Decision Making Proceedings of the 15th National Conference on Artifical Intelligence \(AAAI-98  pp. 827-832\dison, WI: AAAI/MIT Press,  \(1998a 15  E. B T riantaph y llo u   T h e Im p act o f  Ag g r e g atin g Ben e f i t  and Cost Criteria in Four MCDA Methods IEEE Transactions on Engineering Management, Vol 52, No 2 May 2005 16 S  H T s a u r T h e Ev alu a tio n o f airlin e se rv ice q u a lity b y  fuzzy MCDM Tourism Management 107-115, \(2002 1 T  D W a n g  Develo p in g a f u zz y  T O P S IS app r o ach  b a sed  on subjective weights and objective weights Expert Systems with Applications 8980-8985, \(2009 18 L  A  Zadeh  F u z z y Sets   Information and Control 8  338-353, \(1965  152 


                        





