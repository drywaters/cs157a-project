Ef\002cient Execution of Conjunctive Complex Queries on Big Multimedia Databases Karina Fasolin 003  Renato Fileto 003  Marcelo Kruger y  Daniel S Kaster z  M  onica R P Ferreira x  Robson L F Cordeiro x  Agma J M Traina x  Caetano Traina Jr x 003 PPGCC/INE CTC Federal University of Santa Catarina Florian  opolis SC Brazil  Email f kfasolin r.\002leto g ufsc.br y CCTMar Itaja  021 Valley University Florian  opolis SC Brazil  Email marcelo kruger@univali.br z Computer Science Department State University of Londrina PR Brazil  Email dskaster@uel.br x Computer Science Dep Univ of S  ao Paulo at S  ao Carlos Brazil  Email f monika robson caetano agma g icmc.usp.br Abstract This paper proposes an approach to ef\002ciently execute conjunctive queries on big complex data together with their related conventional data The basic idea is to horizontally fragment the database according to criteria frequently used in query predicates The collection of fragments is indexed to ef\002ciently 002nd the fragment\(s whose contents satisfy some query predicate\(s The contents of each fragment are then indexed as well to support ef\002cient 002ltering of the fragment data according to other query predicate\(s conjunctively connected to the former This strategy has been applied to a collection of more than 106 million images together with their related conventional data Experimental results show considerable performance gain of the proposed approach for queries with conventional and similaritybased predicates compared to the use of a unique metric index for the entire database contents I I NTRODUCTION Large amounts of complex data e.g image sound video have been collected and organized in databases every day These complex data can come in various formats and cannot be ordered by their content in the same way as it is done for conventional data those represented as strings or numbers This scenario combined with the huge size and considerable growth of some complex data collections pose new challenges for information retrieval IR  Complex data can be collected or enriched with conventional data e.g metadata such as tags titles upload time that help to describe their contents Huge collections of complex data with related conventional data have been gathered by a myriad of information systems e.g shared photo databases on the Web medical databases Such databases can be queried via their conventional data or/and by using some similarity measure of their complex data contents  Ne v ertheless neither of these strategies alone is enough to produce highquality results in many situations Thus several techniques have been proposed to combine these strategies  Complex queries 14 logically combine traditional predicates e.g equality inequality on conventional data with similarity-based predicates on conventional or unconventional data However current IR systems are not able to ef\002ciently execute such queries on large complex databases This paper proposes an approach to ef\002ciently execute conjunctive complex queries on huge collections of complex data and related conventional data The central idea is to horizontally fragment the database according to criteria frequently used in query predicates e.g the tag values The collection of database fragments is indexed to support ef\002cient identi\002cation of the fragment\(s containing data that satisfy particular query predicates e.g tag   dog   Then the data of each fragment can be indexed according to another criteria e.g some similarity measure of the complex data contents to support further ef\002cient data 002ltering according to other predicate\(s of conjunctive queries The database fragments can be built and indexed to support ef\002cient execution of queries with multiple conjunctive predicates Multi-level indexing structures e.g B-trees whose entries for particular indexing values point to indexes based on other criteria enable ef\002cient processing of some conjunctive complex queries The fragments and access methods are transparent to the user who poses the queries to a database view that integrates the fragments The following examples show some queries that can be executed with much better performance by using the proposed approach based on the conjugation of access methods instead of using a unique index for the whole database contents A Motivating Examples Q 1   Retrieve the k images more similar to q  im 1  Assume that the image q  im 1 is given as the query center and presents a human face Using this information extracted from q  im 1 itself by using a face detection algorithm for example an IR system can imply that the user who posed this query is probably interested in retrieving data about people whose face is similar to the one present in q  im 1  Generic image descriptors e.g color texture perform sub-optimally in this case For retrieving images of similar human faces it is better to use descriptors and similarity measures designed for this speci\002c task on horizontal fragment\(s of the database containing images of human faces Q 2   Retrieve the k images more similar to a given image q  im 2  and annotated with the tag lost dog  The contextual information in this query is the tag lost dog  It can be used to 002nd an appropriate fragment whose tuples are tagged with lost dog  and process the similarity-based predicate only for the contents of this fragment If there is no fragment for this tag value other predicates 
2013 IEEE International Symposium on Multimedia 978-0-7695-5140-1/13 $26.00 © 2013 IEEE DOI 10.1109/ISM.2013.112 536 


may be used e.g whose tuples are tagged just with dog  In this case precision is compromised in favor of recall We believe that to divide the database into horizontal fragments according to predicates typically used in conjunctive complex queries have the following advantages i speed up query execution ii allow better scalability for processing conjunctive complex queries on very large databases and iii improve the quality of results by using access methods tailored for the contents of speci\002c database fragments and particular categories of IR predicates In this paper we show how to achieve the goals i and ii for a real world database with millions of images and related metadata and conjunctive queries composed of a predicate based on tag values and another one based on content similarity This paper is organized as follows Section II presents some foundations and related work Section III describes the proposed approach to ef\002ciently execute conjunctive complex queries in horizontal fragments of databases with complex data and related conventional data Section IV presents the system architecture and tools used to implement this approach in a prototype Section V reports and discusses experimental results Finally Section VI 002nishes the paper with conclusions and indications for future work II F OUNDATIONS AND R ELATED W ORK This section presents some fundamentals used in this paper It describes how complex data and their related conventional data can be stored in relational databases how complex data contents can be compared by using similarity metrics and how complex queries can be expressed as compositions of conventional and similarity-based predicates It closes by discussing some related work A Complex Relation A complex relation   S A  has a set of complex attributes S  f S 1  S 2     S m g and a set of conventional attributes A  f A 1  A 2     A n g  Each complex tuple t 2   S A  relates complex and conventional attribute values For example a complex tuple can relate an image or a series of images with conventional data such as associated tags title description upload time and the geographic position where the image\(s has\(have been taken Queries can be speci\002ed on a complex relation by using both conventional and similarity-based predicates Conventional predicates are used to compare values of conventional attributes with constants and/or among themselves e.g to retrieve the tuples with a given tag value Complex data e.g images on the other hand usually cannot be compared by equality    6   inequality    024  025    or even spatial containment predicates e.g IN SIDE  Complex data are usually compared by similarity The notion of similarity used for IR can vary with the kind of data and the application Different descriptors e.g color texture shape can be extracted from complex data and represented as vectors of varying sizes These descriptors or/and conventional data can be compared by using a variety of similarity or dissimilarity measures B Dissimilarity Metrics Dissimilarity functions measure the distance between objects The greater the distance between two objects the less similar they are Given a data domain D 1  a dissimilarity function 016  D 002 D  R  is called a metric iff it satis\002es the following properties 8 x y z 2 D  1  Symmetry 016  x y   016  y x   2  Non-negativity 016  x y  025 0  3  Identity 016  x x   0  and 4  Triangular inequality 016  x z  024 016  x y   016  y z   There are several distance metrics that can be used for information retrieval Some of the simplest fastest to calculate and most used metrics to compare general complex data e.g collections of images of varied themes are those from the Minkowski family  L p  This set of metrics can be de\002ned as stated in Equation 1 L p  x y   p v u u t d X i 1 j x i 000 y i j p 1 where d is the dimension of the space and each value p  1  2     1 de\002ne a metric of this family such as L 1 Manhattan for p  1  L 2 Euclidean for p  2 and L 1 Chebychev for p  1  Other examples of distance metrics useful for IR are Mahalanobis Camberra 15 and K ullback-Leibler 16 Different metrics perform more or less accurately for different datasets features extracted from the data and categories of queries A metric space 19 is a pair M   D  016  where D denotes the universe of valid elements and 016 is a metric The metric space  D  016  allows comparing tuples of complex and/or conventional objects from the collection D by using the metric 016  When the compared objects are vectors of numeric values in a d dimensional space with a metric distance de\002ned we have a particular case of the metric space that is called a vector space Vector and metric spaces can be indexed with multidimensional and metric data structures respectively to speed up the execution of queries based on spatial and/or similarity-based predicates 20 C Similarity-based Query Operators In similarity-based IR one provides a reference to a query object named as the query center  to retrieve similar objects from the database The most used operators to specify similarity-based queries are 017 Range Query  Range q  Given a query center s q 2 D and a maximum distance 030 2 R   the range query Range q  s q  030  retrieves all objects s 2 D  such that 016  s s q  024 030  i.e all the objects of the database that are within a distance of at most 030 from s q  1 For comparing data of a complex relation   S A  consider D  005 X  dom  S  002 dom  A   where X 022  S  A  and dom  S  and dom  A  are the domains of the sets of attributes S and A  respectively 
537 


017 k-Nearest Neighbor Query  kN N q  Given a query center s q 2 D and a natural number k  the kN N query kN N q  s q  k  retrieves the k objects from D that are the closest ones to s q  i.e D 0  f s i 2 D j8 s j 2  D 000 D 0   j D 0 j  k 016  s q  s i  024 016  s q  s j  g  D Conjunctive Complex Queries Given a complex relation   S A   as described in Section II-A a Conjunctive Complex Query on   S A  is expressed as a conjunction of l predicates 036 X 1  036 X 2      036 X l  Each predicate 036 X i    S A   f T RU E F ALSE g receives a tuple t 2   S A  and returns T RU E or F ALSE depending on the values t  X  of the attributes X 022 S  A in the tuple t  Such a predicate can use equalities inequalities spatial and similarity-based query operators In this paper we only consider conjunctive complex queries with two atomic predicates i an equality of conventional attributes with a constant e.g tag   lost dog   tag   dog   and ii a similarity-based query operator e.g Range q or kN N q  For instance the following conjunctive complex query searches tuples of the complex relation PhotoSharingData associated with a tag dog  and whose contents of the image attribute are at a distance of at most 5 of the given image img1.jpg  This query uses the extended SQL syntax proposed by and the ScalableColor similarity that is de\002ned by the scalable color descriptor and the L 1 Manhattan metric SELECT R  FROM PhotoSharingData R NAT JOIN Tag WHERE Tag.value  dog AND R.picture NEAR D:/images/img1.jpg BY ScalableColor RANGE 5 E Related Work Several methods have been proposed for ef\002cient IR by exploiting various properties of the datasets and posed queries   7 22 and in v estig ating appropriate data descriptors and access methods for distinct situations 7 23]ñ[25 The combination of content and textual similarity has also been investigated to improve IR on complex data  In addition some works use parallelism and techniques such as MapReduce to speed up IR on large datasets  Our proposal combines several ideas of these previous proposals to improve the performance of IR systems for big collections of complex data with their related conventional data For the best of our knowledge it is the 002rst proposal to take advantage of horizontal fragments de\002ned in conformance with typical query predicates to speed up query execution and enable the customization of IR techniques according to the contents of each fragment of a possibly huge complex data collection with heterogeneous contents III P ROCESSING C ONJUNCTIVE C OMPLEX Q UERIES USING H ORIZONTAL F RAGMENTS OF A D ATABASE Our proposal to speed up the execution of conjunctive complex queries uses horizontal fragments of complex relations These fragments are built in accordance with predicates that are common in queries For example consider a database with photos of different sources and mixed themes such as cities homes of\002ces landscapes 003owers trees animals people food etc These photos can be organized in groups so that to perform a search for some speci\002c photo it is not necessary to consider all the elements in the database Instead a more ef\002cient approach is to identify the appropriate group\(s to solve some query predicate\(s and process the search considering only the contents of that group\(s Figure 1 illustrates the proposed approach Suppose that a database is divided in four fragments according to the subjects Human Faces  Cars  Dogs  and Cats  Considering the examples presented in Section I-A query Q 1 can be solved by just checking the contents of the fragment of Human Faces  while query Q 2 can be solved in the fragment of Dogs  Conjunctive complex queries on big databases can be solved much more ef\002ciently by accessing only fragments having data that satisfy some of their predicates instead of searching the whole database Furthermore the data in each fragment can be examined by using a distinct access method tailored for the contents of the respective fragment It can help us to obtain more accurate query results too Fig 1 Query execution strategies for queries Q 1 and Q 2  The major challenges to implement the proposed strategy are i partition the database in suitable horizontal fragments to support query executions ii devise ef\002cient ways to identify suitable fragments to solve particular query predicates iii properly index the contents of each fragment whose size requires ef\002cient access methods to support the veri\002cation of further query predicates iv develop smart strategies for optimized query processing by identifying and searching appropriate horizontal database fragments The following subsections describe each one of these sub-problems in detail A Creating Horizontal Fragments The tuples of a complex relation   S A  can be fragmented for information retrieval purposes by using a wide variety of methods The proposed approach allows any complex relation fragmentation function of the form H    S A   2  2   S;A  000  
538 


The fragmentation function H takes as input a complex relation   S A  and outputs a set H    S A  of horizontal fragments i.e subsets of the tuples in   S A   such that 1 j H    S A  j 025 1  i.e H    S A  has at least one horizontal fragment 2 8  S A  2 H    S A   j  S A  j 025 1  i.e each horizontal fragment   S A  has at least one tuple 3  Each fragment   S A  2 H    S A  has the same schema as   S A  and contains a subset of its tuples Fragmentation functions can also be related to subsets of attributes only For example a complex relation fragmentation function H X    S A  generates subsets of   S A  by checking only the values of the projection 005 X    S A   If X 022 A then we say that H X    S A  is based on the projection of conventional attributes and if X 022 S we say that it is based on the projection of complex attributes Notice that we allow one tuple t 2   S A  to appear in more than one fragment   S A  2 H    S A   It is allowed because the contents of any tuple may be of interest for different IR purposes In other words even when two fragments    0 2 H    S A  refer to distinct data groups sometimes they overlap i.e there are some tuples t 2  such that t 2  and t 2  0  enabling its retrieval according to different points of view For instance pictures of beaches may be relevant to different kinds of people 002shermen surfers travelers geologists oceanographers etc These communities can have distinct interests and use different notions of similarity which use different features to compare data contents as the same tuple may be of interest to people from different communities though for distinct reasons e.g the 002shermen may be interested in a particular texture caused by 002sh close to the water surface the surfers may be looking for waves with a particular shape while some ordinary travelers may just wonder pristine water Conversely the fragmentation process can leave some tuples t 2  out of any fragment  2 H     i.e 9 t 2    8 2 H     t  2    It may happen for example if t is an outlier with respect to the criteria considered in H to fragment  and/or if t is not of interest to the IR focus of any  2 H  B Indexing the Fragments Collection When the number of horizontal fragments j H    S A  j created to support IR from a complex relation   S A  is large it may be necessary to index the collection of fragments H    S A  e.g a collection with a fragment per tag value for a large number of tag values to ef\002ciently 002nd the fragment\(s suitable to solve particular query predicates The indexing method for this purpose may vary with the nature of the predicates that de\002ne the fragments For example collections of horizontal fragments de\002ned by tag values can be indexed by a conventional index e.g a B-tree or by an inverted 002le C Intra-Fragment Indexing The contents of each fragment may have to be indexed as well to accelerate additional 002ltering of the fragment data according to other predicates For instance to support ef\002cient processing of a similarity-based query operator e.g Range q  kN N q  on the contents of large fragments a Metric Access Method MAM can be used A MAM inde x es the fragment contents in a metric space de\002ned by a descriptor extracted from the contents of some attribute\(s and a metric to compare the data descriptors by similarity Several MAMs have been proposed in the literature 20 and man y of them are available in well-known DBMS and IR tools The appropriate descriptor similarity metric and MAM to support ef\002cient access to the contents of a fragment depends on the nature of the data contents and on the query predicates to be processed in that fragment 17 25 D Query Execution Algorithm 1 describes our approach to ef\002ciently process conjunctive complex queries on a big complex database by using horizontal fragments of that database and multi-level indexing The user who is unaware of the database fragmentation and access methods poses the query referring to the whole database This query is received in the parameter c query on line 1 First the IR system extracts the predicates from the query by calling the function EXTRACT PREDICATES line 2 Then the system chooses suitable fragments to process the query i.e fragments whose tuples satisfy some query predicate\(s by calling the function SELECT FRAGMENTS line 3 An index built over the fragments collection may speed up the fragment selection The next step is to 002lter tuples of the chosen fragment\(s according to the query predicates by calling the function FILTER DATA line 6 This function receives in its second parameter all the query predicates to verify the other query predicates on the fragment data Each chosen fragment is expected to be smaller than the whole database If the fragment size is still large its contents can be indexed and/or more fragmented to allow ef\002cient processing of particular query predicates Finally if the query processing has used more than one fragment the IR system combine the results obtained for each fragment by using the APPEND RESULTS function line 7 The combination of results may use unions or intersections depending on the way the query is structured and the criteria used to choose the fragments to process the query Algorithm 1 Query execution using horizontal fragments 1 function EXECUTE QUERY c query  2 predicates  EXTRACT PREDICATES c query  3 f ragments  SELECT FRAGMENTS predicates  4 results   5 for each f in f ragments do 6 f results  FILTER DATA f  predicates  7 results APPEND RESULTS  f results  8 end for 9 return results 10 end function The proposed approach is general in terms of the number nature and logical connections of predicates in a complex query Nevertheless for simplicity and lack of space in our current implementation and experiments we only consider queries with a conventional predicate of the form tag  value conjunctively connected to a similarity-based query operator i.e Range q or kN N q  We believe that it is enough to show some potential bene\002ts of the proposed approach 
539 


IV I MPLEMENTATION We have implemented a prototype to validate our approach using FMI-SiR O user-de\002ned F eatures M etrics and I ndexes for Si milarity R etrieval a module coupled to Oracle to solve queries having similarity-based predicates This module supports the two kinds of similarity-base query operators mentioned in section II-C  Range q and kN N q  and uses MAMs to ef\002ciently execute these predicates on large data volumes In our implementation FMI-SiR O has been changed to read complex objects feature vectors from tables A Architecture Figure 2 illustrates the implemented architecture The module Extract Predicates parses the complex conjunctive query written in SQL in the way accepted by FMI-SiR O  The predicates supported by our current implementation fall in two categories i comparison of a conventional attribute with a constant e.g tag   dog   or ii similarity-based predicates on complex or conventional data  Range q or kN N q  Fig 2 Prototype architecture A B-tree index allows the Select Fragments module to ef\002ciently 002nd fragments whose tuples satisfy predicates of the 002rst category when the cardinality of the compared attribute is high and there are many horizontal fragments for the different attribute values Once the suitable fragment\(s i.e whose tuples satisfy some predicate\(s of the 002rst category has been selected the Oracle Query Processor solves the remaining predicates of the conjunctive query on the contents of such fragment\(s FMI-SiR O solves the similarity-based predicates on the fragments contents using the Arboretum 2  MAM library to improve the performance of these operations for large databases In our experiments we have used the Slimtree as the MAM for ef 002cient similarity-based IR from the horizontal fragments of the database The Slim-tree is dynamic height-balanced and bottom-up constructed 2 http://www.gbdi.icmc.usp.br/arboretum V E XPERIMENTS This section reports the experiments done to demonstrate the bene\002ts of the proposed approach for executing complex conjunctive queries on big complex databases The primary goal is to show that the queries have better performance when executed in the fragments instead of using the entire database A Experiment Setup Our experiments were performed on CoPhIR 3 Contentbased Photo Image Retrieval a multimedia metadata collection that serves as a basis for experiments with contentbased image retrieval techniques It contains image descriptors MPEG-7 feature vectors and textual information tags title description upload time location regarding 106 million images uploaded in FLICKR 4  CoPhIR does not include the images themselves but just their MPEG-7 feature vectors and URLs pointing to the original images in FLICKR and to their thumbnails in the CoPhIR Web site The images presented in the following results were obtained via their FLICKR URL We have converted each CoPhIR XML 002le containing data describing an image into a tuple related with some other tuples e.g with associated tag values The resulting relational database was loaded in Oracle to allow the execution of queries with conventional and similarity-based predicates The ef\002cient execution of the former is supported by Oracle itself using conventional access methods and the latter by FMI-SiR O using Slim-trees The experiments were performed in a server equipped with an Intel R 015 Core TM i7 3.8Ghz processor and 8GB of memory This machine was running Oracle Database 11g on the Debian 7.0 wheezy operating system Kernel 3.2.0 x86-64 B Fragments Creation The horizontal fragments of the database were created according to the tag values associated to the images The total number of tag instances used to annotate the CoPhIR images is 334,254,683 employing a set of 4,666,256 distinct tag values A tag v alue can be ass ociated with v arious images and an image can be annotated with several tag values The strategy used to generate the fragments for the experiment was the following First the data collection was 002ltered to eliminate the tag values used to annotate only one image leaving 2,111,554 distinct tag values i.e 46.86 of the total Then a 002lter based on the WordNet was applied to keep only the tag values of the English language It left 68,767 tag values i.e just 2.87 of the total number of tag values in CoPhIR Figure 3 shows the frequency distribution of the selected tag values among the CoPhIR image descriptions The most frequent tag values are wedding used to annotate 1,678,711 images party 1,334,741 images and travel 1,154,688 images On the other extreme of our selection the tag values algonkin  precognitive  and chamberlains are used to annotate just 2 images each one We divided this distribution in quartiles yielding four regions labeled with R1  R2  R3  and R4  We used the 5 tag values on the limits of each region 3 http://cophir.isti.cnr.it 4 http://www.\003ickr.com 
540 


dashed vertical lines making 10 fragments on each region limits In addition we have randomly chosen 10 distinct tag values inside each region to build further fragments for our experiments It gave a total of 80 horizontal fragments of the CoPhIR database each one for the images annotated with one of the chosen tag values Fig 3 Frequency distribution of tag values in CoPhIR image annotations C Contents Indexing with MAMs The contents of the whole database all the 106 million images and of each fragment whose size is above a certain threshold more than 1 thousand tuples in these experiments have been indexed with Slim-trees for ef 002cient contentbased image retrieval Among the various MPEG-7 feature vectors available for describing images available in CoPhIR we have used the scalable color This descriptor is deri v ed from a color histogram de\002ned in HSV Hue-Saturation-Value The values extracted from the histogram are normalized and mapped to a non-linear representation with four bits After that a Haar transformation was applied Several distance functions can be used to retrieve the images described by MPEG-7 features vectors In these e xperiments we used the L 1 metric Manhattan because it usually provides more precise results than other simple metrics such as those of the Minkowski family as reported in the literature This beha vior w as observed in our preliminary experiments D Queries The next step was to pose queries with equality predicates on tag values and similarity-based predicates on the image contents The tag values used in the equality predicates were the same used to build the fragments for the experiments Section V-B A randomly chosen image of each fragment serve as the query center of the similarity-based predicate Thereafter we compare the average time to execute queries on fragments of each chosen size with that to execute the same similarity queries on the entire database Figure 4 shows an example of complex conjunctive query that looks for images similar to a given one in the fragment with descriptors and metadata of images that are tagged with puppy  It uses the FMI-SiR O Oracle syntax SELECT frag_name INTO fragment FROM cophir_frag_catalog WHERE tag='puppy EXECUTE IMMEDIATE SELECT  FROM   fragment   WHERE MANHATTAN_DIST\(coeff SELECT coeff FROM   fragment   WHERE PHOTO_ID=123456  50 Fig 4 An example of complex query on Oracle with FMI-SiR O E Experimental Results Figure 5 shows the sizes of fragment indexes in disk and the time spent to create horizontal fragments of a relation with image metadata and descriptors taken from CoPhIR Each fragment is de\002ned by a tag value Fragment sizes vary with the number of tag values occurrences The creation of a fragment includes selecting the tuples that refer to images annotated with the respective tag value and the construction of the Slim-tree index to support ef\002cient image retrieval by contents similarity in that fragment Fig 5 Fragment indexes sizes and time spent to create the fragments Figure 6 presents the number of disk accesses and the number of similarity calculations done to execute queries analogous to the one of Figure 4 in database fragments The total elapsed time encompass i searching a B-tree to 002nd the fragment containing tuples annotated with the tag value appearing in the conventional predicate and ii solving the similarity-based predicate in a Slim-tree that indexes only the contents of that fragment Unfortunately the image descriptor similarity function indexes and fragments used in these experiments did not ensure sub-linear growing of the time spent to execute the similarity-based predicates for growing fragment sizes The query execution using the Slim-tree that indexes the contents of a fragment is around an order of magnitude faster than using the Slim-tree that indexes the entire database for most fragments It is still more than 10 times faster to solve the queries in the biggest fragments than in the entire database For example the execution of a query to retrieve images annotated with the tag value wedding 1,334,741 images and within 
541 


Fig 6 Number of Disk Accesses and number of similarity calculation on query execution on database fragments of different sizes a distance radius equal to 50 of a given image takes around 1,200 seconds using the Slim-tree for the respective fragment and 18,577 seconds using the Slim-tree for the entire database On the other hand the query to retrieve images annotated with the tag value chamberlains just 2 images and within the same distance radius of 50 from a given image takes less than 1 second using the respective fragment and 12,514 seconds using the Slim-tree index for the entire database Finally Figure 7 presents the results of a conjunctive complex query with the equality predicate tag  puppy and a kN N q predicate with the center in the image presented in the top left corner highlighted by the red square These 4 images are ranked in the results from left to right and from top to bottom The execution of this query using the fragment referring to the tag puppy  which contains the descriptions of 105,570 images took 108 seconds using a B-tree to 002nd the fragment and a Slim-tree to process the similarity-based predicate in the contents of this fragment As the kN N predicate is not commutative with other predicates for data 002ltering we sho w in Figure 8 the results of a query by a Range q predicate with radius 50 and center in the image on the top left corner These results were produced by using a Slim-tree that indexes the entire database This query took 13,176 seconds to execute Filtering these results for the tag value puppy to produce the result showed in Figure 7 would require further processing but the time to solve the Range q predicate on the Slim-tree that indexes the entire database contents is dominant VI C ONCLUSIONS AND F UTURE W ORK This paper introduces an approach for ef\002ciently processing queries on big complex databases by using horizontal fragments of the database and multi-level indexing This approach has three steps i 002nd fragments with data satisfying some query predicate\(s ii 002lter the data in the chosen fragment\(s according to other predicate\(s conjunctively connected to the former iii compose the results obtained from each fragment The experimental results demonstrate that this proposal drastically improve query execution speed They show that it is not viable to run the similarity-based predicates over the Fig 7 Results of a conjunctive query executed by using the fragment that describes only images tagged with puppy Fig 8 Results of a Range q predicate on the entire database that took almost 100 times longer to produce than those in Figure 7 entire CoPhIR database that describes around 106 million images even using the Slim-tree metric index to speedup the execution of similarity-based predicates on image content descriptors In fact even big fragments describing more than a 100 thousand images approximately need to be further fragmented to ensure acceptable response time Though the case study presented in this paper only considers conjunctive queries with an equality predicate and a similarity-based predicate the proposed approach can be employed for ef\002cient execution of queries with arbitrary numbers of predicates of various kinds and logically connected in different ways In fact our approach opens new research paths towards ef\002cient query execution on big complex data Among the challenges involved in the full exploitation of the proposed approach we mention the following ones for future work i develop automatic techniques to create appropriate horizontal fragments of large databases for ef\002cient query execution ii index fragment collections to ef\002ciently 002nd fragments suitable to solve different kinds of predicates iii devise and validate queries optimization techniques that exploit appropriate database fragments and access methods VII A CKNOWLEDGMENTS Thanks to CNPq CAPES FEESC and FAPESP for their 002nancial support 
542 


R EFERENCES   J Darmont O Boussaid J.-C Ralaivao and K Aouiche An architecture framework for complex data warehouses CoRR  vol abs/0707.1534 2007   A Goker J Davies and M Graham Information Retrieval Searching in the 21st Century  John Wiley  Sons 2007   R A Baeza-Yates and B A Ribeiro-Neto Modern Information Retrieval the concepts and technology behind search Second edition  Pearson Education Ltd Harlow England 2011   R Baeza-Yates and M Melucci Eds Advanced Topics in Information Retrieval  Springer 2011   P Zezula G Amato V Dohnal and M Batko Similarity Search The Metric Space Approach  Springer 2006 vol 32   H Blanken A de Vries H Blok and L Feng Eds Multimedia Retrieval  ser Data-Centric Systems and Applications Heidelberg Springer Verlag 2007 iSBN=978-3-540-72894-8   R Datta D Joshi J Li and J Z Wang Image retrieval Ideas in\003uences and trends of the new age ACM Comput Surv  vol 40 no 2 pp 1ñ60 2008   J Wang J Li and G Wiederhold Simplicity semantics-sensitive integrated matching for picture libraries Pattern Analysis and Machine Intelligence IEEE Trans on  vol 23 no 9 pp 947 963 sep 2001   Y Zhuang Q Li and R Lau Web-based image retrieval a hybrid approach in Computer Graphics International 2001 Proceedings  2001 pp 62 69   J.-R Wen Q Li W.-Y Ma and H.-J Zhang A multi-paradigm querying approach for a generic multimedia database management system SIGMOD Rec  vol 32 pp 26ñ34 March 2003   D Joshi R Datta Z Zhuang W P Weiss M Friedenberg J Li and J Z Wang PARAgrab a comprehensive architecture for web image management and multimodal querying in Proceedings of the 32nd International Conference on Very Large Databases  ser VLDB VLDB Endowment 2006 pp 1163ñ1166   N Rasiwasia J C Pereira E Coviello G Doyle G R G Lanckriet R Levy and N Vasconcelos A new approach to cross-modal multimedia retrieval in ACM Multimedia  A D Bimbo S.-F Chang and A W M Smeulders Eds ACM 2010 pp 251ñ260   C Traina Jr A J M Traina M R Vieira A S Arantes and C Faloutsos Ef\002cient processing of complex similarity queries in rdbms through query rewriting in ACM 15th International Conference on Information and Knowledge Management CIKM 06  P S Yu V J Tsotras E A Fox and B Liu Eds Arlington VA USA ACM Press 2006 pp 4ñ13   M C N Barioni H L Razente A J M Traina and C Traina Jr Seamlessly integrating similarity queries in SQL Software Practice and Experience  vol 39 no 4 pp 355ñ384 2009   F Long H Zhang and D Feng Fundamentals of content-based image retrieval Multimedia Information Retrieval and Management  2002   D R Wilson and T R Martinez Improved heterogeneous distance functions J of Arti\002cial Intelligence Research  vol 6 pp 1ñ34 1997   P H Bugatti A J M Traina and C Traina Jr Assessing the best integration between distance-function and image-feature to answer similarity queries in 23rd Annual ACM Symposium on Applied Computing SAC2008  Fortaleza Cear Brazil ACM Press 2008 pp 1225ñ1230   T Bozkaya and M Ozsoyoglu Indexing large metric spaces for similarity search queries ACM Trans Database Syst  vol 24 pp 361 404 September 1999   P Ciaccia and M Patella Searching in metric spaces with user-de\002ned and approximate distances ACM Trans Database Syst  vol 27 pp 398ñ437 December 2002 A v ailable http://doi.acm.org/10.1145/582410.582412   H Samet Foundations of Multidimensional and Metric Data Structures The Morgan Kaufmann Series in Computer Graphics and Geometric Modeling  San Francisco CA USA Morgan Kaufmann Publishers Inc 2005   L C mitsubishi Electric Ite-vil The mpeg-7 color descriptors jensrainer ohm rwth aachen institute of communications engineering   M R P Ferreira L F D Santos A J M Traina I Dias R Chbeir and C Traina Jr Algebraic properties to optimize knn queries in Proc of the 26th Brazilian Symposium on Databases SBBD  2011   M S Lew N Sebe C Djeraba and R Jain Content-based multimedia information retrieval State of the art and challenges ACM Trans Multimedia Comput Commun Appl  vol 2 pp 1ñ19 February 2006 Onl A v ailable http://doi.acm.or g/10.1145/1126004.1126005   R d S Torres A X F ao M A Gonc∏alves J P Papa B Zhang W Fan and E A Fox A genetic programming framework for content-based image retrieval Pattern Recognition  vol 42 no 2 pp 283  292 2009 learning Semantics from Multimedia Content A v ailable http://www.sciencedirect.com/science/article/pii/S0031320308001623   T Skopal Where are you heading metric access methods a provocative survey in SISAP  P Ciaccia and M Patella Eds ACM 2010 pp 13ñ21   U Murthy E A Fox Y Chen E Hallerman R d S Torres E J Ramos and T R C Falc  ao Superimposed image description and retrieval for 002sh species identi\002cation in ECDL  ser Lecture Notes in Computer Science M Agosti J L Borbinha S Kapidakis C Papatheodorou and G Tsakonas Eds vol 5714 Springer 2009 pp 285ñ296   K C L Santos H M de Almeida M A Gonc∏alves and R d S Torres Recuperac  ao de imagens da web utilizando m  ultiplas evid  encias textuais e programac  ao gen  etica in SBBD  A Brayner Ed SBC 2009 pp 91ñ105   D C G a Pedronette and R da S Torres Exploiting contextual spaces for image re-ranking and rank aggregation in Proceedings of the 1st ACM International Conference on Multimedia Retrieval  ser ICMR 11 New York NY USA ACM 2011 pp 13:1ñ13:8  A v ailable http://doi.acm.or g/10.1145/1991996.1992009   D Hiemstra and C Hauff Mapreduce for information retrieval evaluation let's quickly test this on 12 tb of data in Proceedings of the 2010 international conference on Multilingual and multimodal information access evaluation cross-language evaluation forum  ser CLEF'10 Berlin Heidelberg Springer-Verlag 2010 pp 64ñ69  A v ailable http://dl.acm.or g/citation.cfm?id=1889174.1889186   N Alipanah P Parveen L Khan and B Thuraisingham Ontologydriven query expansion using map/reduce framework to facilitate federated queries in Proceedings of the 2011 IEEE International Conference on Web Services  ser ICWS 11 Washington DC USA IEEE Computer Society 2011 pp 712ñ713 A v ailable http://dx.doi.org/10.1109/ICWS.2011.21   Z Wu B Mao and J Cao Mrgir Open geographical information retrieval using mapreduce in Geoinformatics 2011 19th International Conference on  2011 pp 1ñ5   D S Kaster P H Bugatti A J M Traina and C T Jr Fmisir A 003exible and ef\002cient module for similarity searching on oracle database JIDM  vol 1 no 2 pp 229ñ244 2010   F J T Chino M R Vieira A J M Traina and C Traina Mamview a visual tool for exploring and understanding metric access methods in Proceedings of the 2005 ACM Symposium on Applied computing  ser SAC 05 New York NY USA ACM 2005 pp 1218ñ1223  A v ailable http://doi.acm.or g/10.1145/1066677.1066952   C Traina Jr A J M Traina C Faloutsos and B Seeger Fast indexing and visualization of metric datasets using slim-trees IEEE Transactions on Knowledge and Data Engineering TKDE  vol 14 no 2 pp 244ñ260 2002   P Bolettieri A Esuli F Falchi C Lucchese R Perego T Piccioli and F Rabitti CoPhIR a test collection for content-based image retrieval CoRR  vol abs/0905.4627v2 2009   H Eidenberger Distance measures for mpeg-7-based retrieval in Proceedings of the 5th ACM SIGMM international workshop on Multimedia information retrieval  ser MIR 03 New York NY USA ACM 2003 pp 130ñ137 A v ailable http://doi.acm.org/10.1145/973264.973286   R Dorairaj and K R Namuduri Compact combination of mpeg-7 color and texture descriptors for image retrieval in Signals Systems and Computers 2004 Conference Record of the Thirty-Eighth Asilomar Conference on  vol 1 IEEE 2004 pp 387ñ391 
543 


014 014 
014 014 004 
vol 15, issue 2, 2006, pp165190  Ding Z, Huang G, "Real Time Traffic Flow Statistical Analysis Based on Network-Constrained Moving Object Trajectories", proc. of 20th Intl. Conf. on Database and Expert Systems Applications DEXA'09\August, 2009 
Sensor number 4 Node Servers 32 Node Servers 
speedup Q Q  Q General Statistical Database Cluster Mechanism for Big Data Analysis in the Internet of Things 
VLDB Journal 
 SNQP IOTStatisticDB 
005 1000 
icDB IOTStatist SNQP speedup 
1  2 4 have similar results TABLE III S PEEDUP R ATE OF IOT-S TATISTIC DB 
 
 From Figure 8 we can see that, when data size increases the performance of CSA-DSD decreases rapidly while the performance of IOT-StatisticDB is relatively stable. The main reason is that in CS A-DSD, large volumes of statistical raw data needs to be transferred to and stored at the master server for statistical analysis. Therefore, the query response time is prop ortional to the whole data size On the other hand, in IOT-StatisticDB, the main workload is distributed among the nod e servers, so that the overall performance is less sensitiv e to the overall data size To better analysis how the statistical analysis workload is shared by multiple node servers in IOT-StatisticDB, we define the speedup rate 60 100 140 180 220 2.85 3.05 3.71 3.81 3.73 19.25 21 22.36 22.5 21.85 We can observe from Table 3 that when the number of node servers is 4, the speedup rate is between 2.85~3.81 and when the number of node servers is increased to 32, the speedup rate is between 19.25~22.36. In general, with the number of node servers incr easing, the query response time decreases, since in IOT-StatisticDB, the query response time is main decided by the da ta size of each node server V C ONCLUSIONS  Statistical analysis on sensor sampling data is one of the most important procedures in IoT systems to transform dataé into çknowledgeé. In this paper, we propose a 
as follows where is the query response time of single node query processing, and is the query response time of IOT-StatisticDB. Table 3 shows th e speedup rate of  IOT-StatisticDB The main contribution is as follows 1\general statistical database cluster mechanism is proposed, with data typ es and operators for statistical analyzing provided. The mechanism is a general model which can support complicated statistical queries through standard SQL statements 2 methods, including Euclidean-based spatial aggregation, Network-based spatial aggregation, Euclidean-based parameter aggregation, and Network-based parameter aggregation, are proposed with detailed algorithms presented 3\he parallel processing techniques of statistical queries are proposed, so that multiple servers can conduct statistical analysis in parallel and the performance can be greatly improved As the future work, event detections and data mining techniques based on IoT statistical analysis will be studied A CKNOWLEDGMENTS  The work was partially supported by National Natural Science Foundation of Chin a \(NSFC\under grant number 91124001 and by National High-Tech. R&D Program of China \(863 program\gr ant number 2013AA01A603 R EFERENCES   W a ng D, çClustering Mesh-like W i reless Sensor Networks with an Energy-efficient Scheme,é International Journal of Sensor Networks vol. 7 No. 4 2010, pp. 199-206  Chen H, Minen o H Mizuno T, çA Meta-data-based Data  Aggregation Scheme in Clustering Wireless Sensor Networksé. Proc of Intl. Conf. on Mobile Data Managem ent \(MDMê06 May 2006, pp. 154-161  Liu C, W u K Pei J, çA Dy nam i c Clustering and Scheduli ng Approach to Energy Saving in Data Collection from Wireless Sensor Networksé, Proc. of IEEE Conf. on Sensor, Mesh and Ad Hoc Communications and Networks \(SECONê05 IEEE press, Sep. 2005 pp. 374-385  Z hang Y, W a ng H T i an L   E ner gy and Data Awar e Cluster ing for  Data Aggregation in Wireless Sensor Networ ksé, Proc. of IEEE 4th Intl. Conf. on Mobile Ad hoc and Sensor Systems \(MASSê07 Press, Oct. 2007 pp. 1-6  Ordonez C S tatistical Model Com putation with UDFs IEEE Transactions on Knowledge and Data Engneering \(TKDE Dec. 2010, pp. 1752-1765  Ester M, K r iegel H P, Sander J Xu X A Density-Ba sed Algorith m for Discovering Clusters in Large Spatial Databases with Noise Proc. of Intl. Conf. on Knowledge Discovery and Data Mining KDDê96\, Aug. 1996, pp:226-231  Ankerst M, Breunig M, Kriegel H P, Sander J, çOptics: Or der ing Points to Identify the Clustering Structureé, Proc. of ACM Intl. Conf on Management of Data \(SIGMODê9 9  Yang Y, W u L Guo J, Liu S, çResearch on Distrib uted Hilbert R  Tree Spatial Index Based on Birch Clusteri ngé, Proc. of Intl. Conf. on Geoinformatics \(Geoinformaticsê12\IEEE Pr ess, Jun. 2012, pp. 1-5  Chitta R, Jin R Havens T, Jain A   A pproxim ate Ke rnel k-Means  Solution to Large Scale Kernel Clustering Proc. of ACM Intl. Conf on Knowledge Discovery and Data Mining \(SIGKDDê11  Zhang Z Yang Y Tung A, Papadias D, çContin uous kMeans Monitoring over Moving Objects IEEE Transactions on Knowledge and Data Engineering \(TKDE May 2008, pp. 1205-1216  Feng X, Ku m a r A, Recht B, RÈ C  Towar ds a Unified Ar chitecture for in-RDBMS Analyticsé Proc. of ACM Intl. Conf. on Management of Data \(SIGMODê12\, May 2012, pp. 325-336  Heller stein J R C Schopp m a nn F, W a ng D, Fr atkin E, Gor ajek A et al. çThe MADlib Analytics Library or MAD skills, the SQL Journal Proceedings of the Very Large Data Base Endowment, vol. 5 issue 12, 2012, pp. 1700-1711  Jam p ani R Xu F W u M, P e rez L Jermaine C, Haas P, çThe Monte Carlo Database System: Stochastic Analysis Close to the Data ACM Transactions on Database Systems \(TODS\1 pp. 18:1-18:41  Xiong Z Luo W   Chen L Ni L Data Vitalization: A New Par adig m  for Large-Scale Dataset Analysisé. Proc of IEEE 16th Intl. Conf. on Parallel and Distributed Systems ICPADSê10 Dec. 2010  G¸ting R.H, Al m e ida V, Ding Z, çModeling and Quer y i ng Moving Objects in Networks 
543 


  


Bottom Top A B 
Figure 15 Figure 16 
messages seen for all workers in a superstep \(Figures 10 and 13\. When looking at the messages sent by workers in a superstep for METIS, we see that there are message load imbalances within work ers in a superstep, caused due to concentration of vertices being traversed in that superstep in certain partitions This variability is much more pronounced in CP as compared to WG \(Figures 11 and 14\ E.g. in superstep 9 for CP, twice as many messages \(4M\ are generated by a worker compared to another \(2M\.  For Pregel BSP, the time taken in a superstep is determined by the slowest worker in that superstep. Hence increase d variability in CP causes even çgoodé partitioning strategies to cause an increase in total execution time wh en using the Pregel/BSP model VIII A NALYSIS OF E LASTIC C LOUD S CALING  Cloud environments offer elasticity Ö the ability to scale-out or scale-in VMs on-demand and only pay for what one uses [28   On th e f l i p s i de  on e en ds u p  paying for VMs that are acquired even if they are underutilized. We have already shown the high variation in compute/memory resources used by algorithms like BC and APSP across different supersteps. While our earlier swath initiation heuristics attempt to flatten these out by overlapping swath executions, one can consider leveraging the cloudês elasticity to, instead, scale up and down the concurrent workers \(and graph partitions\ allocated in each superstep The peak and trough nature of resource utilization combined with Pregel/BSPês synchronous barrier between supersteps offers a window for dynamic scaleout and Öin at superstep boundaries. Peak supersteps can greatly benefit from additional workers, while those same workers will contribute to added synchronization overhead for trough supersteps We offer an analysis of the potential benefits of elastic scaling by extrapolating from observed results for running BC on WG and CP graphs, using four and eight workers.  To provide a fair and focused comparison, we turned off swath heuristics in favor of fixed swath sizes and initiation intervals Figure 15 \(Bottom\ plots the speedup of BC running on eight workers when normalized to BC running on four workers, at corresponding supersteps.  The number of workers does not impact the number of supersteps We also plot the number of active vertices \(i.e. vertices still computing for a given swath\these supersteps which is a measure of how much work is required \(Fig 15 \(Top\. We find that we occasionally get superlinear speedup spikes \(i.e. >2x\ that shows a strong correlation with the peaks of active messages, for both WG and CP graphs. At other times, the sp eedup is sublinear or even a speed-down \(i.e. <1\responding to inactive vertices.  The superlinear speedup is attributable to the lower contention and reduced memory pressure for 8 workers when the active vertices peak \(similar to what we observed for the swath initiation heuristics Similarly, the below par speedup during periods of low activity is contributed by the increased overhead of barrier synchronization across 8 workers. Intuitively, by dynamically scaling up the number of workers for supersteps with peaking active vertices and scaling them down otherwise, we can leverage the superlinear speedup and get more value per worker Using a threshold of 50% active vertices as the threshold condition for between 4 and 8 workers in a superstep, we extrapolate the time per superstep and compared this to the fixed 4 and 8 worker runtimes. We also compute the best-case run time using an çoracleé approach to i.e. for each superstep, we pick the minimum of the 4 or 8 workerês time.  Note that these projections do not yet consider the overheads of scaling, but are rather used to estimate the potential upside if we had an ideal or an automated heuristic for scaling. The total time estimates for running BC on WG and CP graphs, normalized to  
 plot shows speedup of 8 workers relative to 4 workers, for each superstep, when running BC on WG and CP graphs plot shows the number of vertices active in that superstep Estimated time for BC using elastic scaling, normalized to time taken for 4 workers. Normalized cost is shown on secondary Y axis WG graph shown on left CP graph shown on right. Smaller is better 
022\011 022\010 022\007 022\002 006 002 007 006 002 007 010 011 012 013 014 015 006 006\003\002 006\003\007 006\003\010 006\003\011 006\003\012 006\003\013 006\003\014 006\003\015 006\003\016 002 027\031\030\037\020#@\020"\031\030\027\020\035 0201!2#\024$#\015#5\024",\020"#\017\003"\003\031\003#\011#5\024",\020"\035 024"'\033\026\0309\0201#\\031\020 2 035#\032\020"#+!\034 017\020\021\022\023\024\024\025\026\020 027\030\031\022\032\033\031\020\034\031\035 017\020\021\022\023\024\024\025\026\020#?#/\027\031\030\037\020#@\020"\031\030\027\020\035 027\030\031\022\032\033\031\020\034\031\035#?#/\027\031\030\037\020#@\020"\031\030\027\020\035 036\030\034\020\033"#\\0201!2 006 006\003\007 006\003\011 006\003\013 006\003\015 002 002\003\007 006 006\003\002 006\003\007 006\003\010 006\003\011 006\003\012 006\003\013 006\003\014 006\003\015 006\003\016 002 011#5\024",\020 B\034\0267 015#5\024",\020 B\034\0267 1\0332\031\030\037\020 030\034\025 1\0332\031\030\037\020 036\024\017\020 024!\0341 024\035\031#>\024"'\033\026\0309\0201#\031\024#\011#5\024",\020"#.\024\035\031 017\020\021\022\023\024\024\025\026\020#+!\034\022&\030'\020#>\024"'\033\026\0309\0201#\031\024#\011#5\024",\020"#&\030'\020 011#5\024",\020"#&\030'\020 015#5\024",\020"#&\030'\020 024\035\031 006 006\003\007 006\003\011 006\003\013 006\003\015 002 002\003\007 002\003\011 002\003\013 006 006\003\002 006\003\007 006\003\010 006\003\011 006\003\012 006\003\013 006\003\014 006\003\015 006\003\016 002 011#5\024",\020 B\034\0267 015#5\024",\020 B\034\0267 1\0332\031\030\037\020 033\026\030\034\025 1\0332\031\030\037\020 036\024\017\020 024!\0341 024\035\031#>\024"'\033\026\0309\0201#\031\024#\011#5\024",\020"#.\024\035\031 027\030\031\022\032\033\031\020\034\031\035#+!\034\022&\030'\020#>\024"'\033\026\0309\0201#\031\024#\011#5\024",\020"#&\030'\020 011#5\024",\020"#&\030'\020 015#5\024",\020"#&\030'\020 024\035 031 
 
dynamically scaling ideal scaling 
Our hypothesis is that an intelligent adaptive scaling of workers can achieve a similar performance as a large, fixed number of workers, but with reduced cost 
213 


Nature Nature Ecological Applications Nature ACM International Conference on Management of Data \(SIGMOD In Parallel Object-Oriented Scientic Computing \(POOSC Science Communications of the ACM ACM Workshop on Mining and Learning with Graphs Communications of the ACM HotCloud Proceedings of the 19th ACM International Symposium on High PErformance Distributed Computing HPDC Knowledge and Information Systems KAIS International Conference on Computational Science IEEE International Conference on Cloud Computing Technology and Science ACM/IEEE Conference on Advances in Social Network Analysis and Mining \(ASONAM IEEE International Parallel and Distributed Processing Symposium \(IPDPS International Conference on Distributed Computing and Networking Journal of Mathematical Sociology International Conference on Parallel Processing Communications of the ACM 
 
observed time taken using 4 workers, are plotted in Figures 16\(A\ and 16\(B We see that our dynamic scaling heuristic using the percentage of active vertices achieves nearly the same CP\ or better \(WG\ performance as a fixed 8 worker approach. Clearly there is benefit of using fewer workers for low utilization su persteps to eliminate the barrier synchronization overhead. Also, the dynamic scaling heuristic performs almost as well as the ideal scaling. Finally, when we consider the monetary cost of the proposed approaches, assuming a pro-rata normalized cost per VM-second plotted on the secondary Y axis, we see that dynamic scaling is comparable \(CP\ or cheaper \(WG\ than a 4 worker scenario while offering the performance of an 8 worker deployment IX C ONCLUSION  In conclusion, we introduce optimization and heuristics for controlling memory utilization and show they are critical to performance.  By breaking computation into swaths of vertices and using our sizing heuristics we achieve up to 3.5x speedup over the maximum swath size that does not cause the a failure.  In addition overlapping swath executions can provide a 24% gain with automated heuristics and even greater speedup when a priori knowledge of the network characteristics is applied This evaluation offers help to eScience users to make framework selection and cost-performancescalability trade-offs. Our he uristics are generalizable and can be leveraged by other BSP and distributed graph frameworks, and for graph applications beyond BC. Our work uncovered an unexpected impact of partitioning and it would be worthwhile, in future, to examine the ability to pred ict, given certain graph properties, a suitable partitioning model for Pregel/BSP It may also be useful to perform such evaluations on larger graphs and more numbers of VMs. At the same time, it is also worth considering if non-linear graph algorithms are tractable in pr actice for large graphs in a distributed environment B IBLIOGRAPHY  1  F  L i lj er os C   Ed l i n g L  A m a r a l H  S t an ley   and Y    berg The web of human sexual contacts 
vol. 411, pp. 907908, 2001   H Je o n g  S   Ma so n A  L   B a ra b s i  a nd Z   Oltva i  L e t ha l i t y  and centrality in protein networks vol. 411, pp. 41-42 2001   O. B o din and E   E s t r ada    U s i n g n e t w ork c e nt r a l i t y  m e a s ures t o  manage landscape connectivity vol 18, no. 7, pp. 1810-1825, October 2008   D. W a ts s  and S  S t r ogat z  C olle c t i v e  d y nam i cs of  s m a ll-w orl d   networks vol. 393, no. 6684, pp. 440Ö442, June 1998   G  Ma lew i c z   M A u s t er n A   Bik  J   Dehn er t I  Hor n   N. L e i s er and G. Czajkowski, "Pregel: A system for large-scale graph processing," in 2010   D. G r egor  and A  L u m s dain e  T h e  pa r a llel  B G L  A gen e r i c  library for distributed graph computations," in 2005   B. S h a o  H. W a n g  and Y  L i T he T r init y G r aph E n g i n e    Microsoft Research, Technical Report MSR-TR-2012-30, 2012   A  F ox  C lo ud c o m putin g w h at  s  in it for m e  as  a  s c i e n tis t     vol. 331, pp. 406-407, 2011   S. G h e m a w a t  and J  De an   Map re duc e s i m p lifi e d data  processing on large clusters vol 51, no. 3, pp. 107-113, 2008   J  L i n and M. S c hat z   Des i g n  patt er n s  for eff i ci ent gr aph algorithms in MapReduce," in 2010   L   Va l i ant   A b r id g i n g m o d e l f or pa r a llel com putati o n  vol. 33, no. 8, pp. 103-111, 1990 12 a c h e  Ha ma    O n l i n e    http://hama.apache.org   13 Ap a c h e  Ha d o op    O n l i n e    http://hadoop.apache.org     M Z a h a r i a, M. Ch ow dhu ry M F r ank l in S  S h e n k e r, and I   Stoica, "Spark: Cluster Computing with Working Sets," in 2010   J  Ekana y ak e e t a l     T w i st er A  r untim e f o r it er ati v e  MapReduce," in Chicago, 2010, pp. 810-818   U. K a n g  C  T s o u rakakis   and C. F a l outs o s  Peg a s us   Minin g  Peta-scale Graphs," in 2010   M. P a c e  B S P vs  MapR e duc e    in vol. 103.2081, 2012   S. Seo  E  Yoo n, J  K i m  S  J i n  J-S. K i m   and S   Ma e n g HAMA: An Efficient matrix computation with the MapReduce framework," in 2010, pp. 721-726   S. S a l i h ogl u  and J  W i d o m  G PS A G r a ph P r oc e s s i n g Sy s t em    Stanford University, Technical Report 2011   R L i cht e n w a l t e r and N   Cha w la D is Ne t  A fr am ew ork for  distributed graph computation," in  2011   K  Maddu r i  D. E d i g er K   J i an g  D. Bad e r  and D  Cha v a r riaMiranda, "A faster parallel algorithm and efficient multithreaded implementations for evaluating betweenness centrality on massive datasets," in 2009   E  K r e p s k a, T  K i el m a nn, W  F o kkink, H   Ba l, "A  hi g h level framework for distributed processing of large-scale graphs," in 2011, pp. 155-166   L   Pa ge  S  B r in R. M o t w ani and T  W i nogr ad  T h e P a geRank citation ranking: Bringing order to the web," Stanford InfoLab Technical Report 1999-66, 1999   U  Brand  s  A f a s t er  a l gor ith m for  b e t w eenn e s s c e nt r a l i t y    vol. 25, no. 2, pp. 163-177 2001   Stan fo r d  Net w or k A na l y s is Pro j e c t  O n l in e    http://snap.stanford.edu    I  S t ant o n and G  K l i o t, "S t r e a m i n g G r aph P a rtiti o n in g  for L a rge Distributed Graphs," Microsoft Corp., Technical Report MSRTR-2011-121, 2011   G   K a ry pis and V   K um a r A fas t and hi g h qua l i t y m u l t i l evel scheme for partitioning irregular graphs," in 1995, pp. 113-122   M. A r m b r u s t e t  a l   A v i ew of  c l o u d  c o m putin g    vol. 53, no. 0001-0782, pp. 50-58 April 2010  
214 


  13  or gani c  c he m i s t r y  i n our  Sol ar  Sy s t e m       Xi a n g  L i r e c e i v e d h i s B  S   m is tr y  fr o m  th e  P e k in g  U n iv e r s ity  C h in a  in  2 0 0 3  and P h D   i n P hy s i c al  C he m i s t r y  f r om  t he  J ohns  H opk i ns  Un i v e r s i t y  i n  2 0 0 9   He  h a s  b e e n  a  R e s e a r c h  A s s o c i a t e  wi t h  a  j o i n t  a p p o i n t m e n t  a t  t h e  U n i v e r s i t y  o f  M a r y l a n d   Ba l t i m o r e  C o u n t y  a n d  N AS A G o d d a r d  S p a c e  Fl i  Ce n t e r  s i n c e  2 0 1 1   H i s  r e s e a r c h  f o c u s e s  o n  t h e  d e t e c t i o n  of  t r ac e  e l e m e nt  and as t r obi ol ogi c al l y  r e l e v ant  or gani c  mo l e c u l e s  i n  p l a n e t a r y  s y s t e ms   l i k e  M a r s   He  i s  es p eci a l l y i n t er es t ed  i n  t h e d evel o p m en t  o f  T i m e of  and I on T r ap m as s  s pe c t r om e t e r s w i t h v a r i o u s i o n i z a t i o n  ng te c h n iq u e s   Wi l l  B r i n c k e r h o f f  sp a c e  sc i e n t i st  i n  t h e  Pl a n e t a r y  En v i r o n m e n t s  La b  a t  N A S A  s  G o d d a r d  Spac e  F l i ght  C e nt e r  i n Gr e e n b e l t   M D w i t h  pr i m ar y  r e s pons i bi l i t y  f or  th e  d e v e lo p m e n t o f th e  L D TO F  m a s s  s p e c t r o  th is  p r o je c t H e  h a s  fo c u s e d  re c e n t l y  o n  t h e  d e v e l o p m e n t  o f  m i n i a t u re  l a se r d ma s s  s p e c t r o me t e r s  f o r  f u t u r e  p l a n e t a r y  mi s s i o n s  a l o n g  wi t h  b a s i c  e x p e r i m e n t a l  r e s e a r c h  i n  a s t r o b i o l o g y  a n d  p r e bi ot i c  s y nt he s i s   D r   B r i nc k e r hof f  i s  i nv ol v e d i n t he  de v e l opm e nt  of  m as s  s pe c t r om e t e r  f or  bot h t he  2011 Ma r s  S c i e n c e  L a b o r a t o r y  a n d  t h e  2 0 1 8  E x o Ma r s  mi s s i o n s   


  14   


Copyright © 2009 Boeing. All rights reserved  Issues and Observations Initial load of one day of data ~ 7 hours Optimizations  Write data in batches  Use a mutable data structure to create data strings  Deploy a higher performance machine  Use load instead of insert  Use DB2 Range-Partitioned tables  Database tunings Time reduced from 7 hours to approx 30 minutes 


Copyright © 2009 Boeing. All rights reserved  Optimizations Use a mutable data structure to create data strings  Original application created the SQL statement by appending elements to a Java String  It was taking five hours \(of the seven hours Strings  Instead Java StringBuilder used  Java Strings immutable  Time savings of 71.4 


Copyright © 2009 Boeing. All rights reserved  Optimizations Deployed on a higher-performance machine  Application ported from IBM Blade Center HS21 \(4GB of RAM and 64-bit dual-core Xeon 5130 processor to Dell M4500 computer \(4GB of RAM and 64-bit of quad-core Intel Core i7 processor  Reduced the time to thirty minutes Bulk loading instead of insert  Application was modified to write CSV files for each table  Entire day worth of data bulk loaded  Reduced the time to fifteen minutes 


Copyright © 2009 Boeing. All rights reserved  Optimizations Range-Partitioned tables \(RPT  To limit the size of tables, the original code created multiple tables per table type  This puts burden on the application to query multiple tables when a range crosses several tables  With RPT, user is not required to make multiple queries when a range crosses a table boundary  Increased the time to thirty minutes  Additional fifteen minute cost per day of partitioning enabled time savings during queries 


Copyright © 2009 Boeing. All rights reserved  Optimizations Database tunings  Range periods changed from a week to a month  Automatic table space resizing changed from 32MB to 512KB  Buffer pool size decreased  Decreased the time to twenty minutes Overall, total time savings of 95.2 


Copyright © 2009 Boeing. All rights reserved  20 IBM Confidential Analytics Landscape Degree of Complexity Competitive Advantage Standard Reporting Ad hoc reporting Query/drill down Alerts Simulation Forecasting Predictive modeling Optimization What exactly is the problem What will happen next if What if these trends continue What could happen What actions are needed How many, how often, where What happened Stochastic Optimization Based on: Competing on Analytics, Davenport and Harris, 2007 Descriptive Prescriptive Predictive How can we achieve the best outcome How can we achieve the best outcome including the effects of variability Used with permission of IBM 


Copyright © 2009 Boeing. All rights reserved Initial Analysis Activities Flights departing or arriving on a date Flights departing or arriving within a date and time range Flights between city pair A,B Flights between a list of city pairs Flights passing through a volume on a date. \(sector, center, etc boundary Flights passing through a volume within a date and time range Flights passing through an airspace volume in n-minute intervals All x-type aircraft departing or arriving on a date Flights departing or arriving on a date between city pair A,B Flights departing or arriving on a date between a list of city pairs Flights passing through a named fix, airway, center, or sector Filed Flight plans for any of the above Actual departure, arrival times and actual track reports for any of the above 


Copyright © 2009 Boeing. All rights reserved  Initial SPSS Applications Show all tracks by call sign 


Copyright © 2009 Boeing. All rights reserved  Predictive / Prescriptive Analytics Use-Case For a given Airspace Volume of Interest \(AVOI compute distinct traffic volume at some point in the future  Aim to alert on congestion due to flow control areas or weather if certain thresholds are exceeded  Prescribe solution \(if certain thresholds are exceeded Propose alternate flight paths  Use pre-built predictive model  SPSS Modeler performs data processing Counts relevant records in the database \(pattern discovery Computes traffic volume using statistical models on descriptive pattern Returns prediction with likelihood 


Copyright © 2009 Boeing. All rights reserved  Predictive / Prescriptive Analytics Use-Case Advanced Arrival Procedures with Active Abatement Potentials   9/23/10  24 Pulls in the TRACKINFO table of MAIN using SQL Limits the data to database entries which fall inside the AVOI Combines the SOURCE_DATE and SOURCE_TIME to a timestamp that can be understood by modeler Computes which time interval the database entry falls in. The time interval is 15 minutes Defines the target and input fields needed for creating the model Handles the creation of the model Produces a graph based off of the model results Final prediction 


Copyright © 2009 Boeing. All rights reserved  Initial Cognos BI Applications IBM Cognos Report Studio  Web application for creating reports  Can be tailored by date range, aircraft id, departure/arrival airport etc  Reports are available with links to visuals IBM Framework Manager  Used to create the data package  Meta-data modeling tool  Users can define data sources, and relationships among them Models can be exported to a package for use with Report Studio 


Copyright © 2009 Boeing. All rights reserved  Flights Departing Las Vegas on Jan 1, 2012 1 of 3 Report shows the departure date, departure and arrival locations and hyperlinks to Google Map images DeparturePosition and ArrivalPosition are calculated data items formatted for use with Google Maps Map hyperlinks are also calculated based on the type of fix 


Copyright © 2009 Boeing. All rights reserved  Flights Departing Las Vegas on Jan 1, 2012 2 of 3 DeparturePosition, Departure Map, ArrivalPosition and Arrival Map are calculated data items \(see departure items below DepartureLatitude DepartureLongitude DeparturePosition Departure Map 


Copyright © 2009 Boeing. All rights reserved  Flights Departing Las Vegas on Jan 1, 2012 3 of 3 


Copyright © 2009 Boeing. All rights reserved  Conclusion and Next Steps Current archive is 50 billion records and growing  Approximately 34 million elements per day  1GB/day Sheer volume of raw surveillance data makes analytics process very difficult The raw data runs through a series of processes before it can be used for analytics Next Steps  Continue application of predictive and prescriptive analytics  Big data visualization 


Copyright © 2009 Boeing. All rights reserved  Questions and Comments Paul Comitz Boeing Research & Technology Chantilly, VA, 20151 office Paul.Comitz@boeing.com 


Copyright © 2009 Boeing. All rights reserved Advanced Arrival Procedures with Active Abatement Potentials   9/23/10  31 


Copyright © 2009 Boeing. All rights reserved Advanced Arrival Procedures with Active Abatement Potentials   9/23/10  32 Backup Slides 


Copyright © 2009 Boeing. All rights reserved  Initial Approach Initial Investigations  Apache Solr/Lucene  Data Warehouse Evaluate Hadoop in the future 


Copyright © 2009 Boeing. All rights reserved  Using SOLR Uncompress Track Information Messages To use with Solr  Transforming track messages from their  original schema to Solr required building a ìkey, valueî list using an XSTL  Queries made against this list of ìkey, valueî pairs Transformation Process  One day of data ~ 4.5 hours Once transformation complete search/query performance very good Geo spatial queries using  unique query language 


Copyright © 2009 Boeing. All rights reserved  Representation Aviation data is frequently represented in more than one form 


