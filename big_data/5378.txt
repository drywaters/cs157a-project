2010 Second International conference on Computing, Communication and Networking Technologies Classification Ensemble for Mammograms Using Ant-Miner Roselin  .R 1 Thangavel. K  2  Assistant Professor of  Computer Science Sri Sarda College for Women Autonomous Salem  636 016,Tamil Nadu, India 1 rose_line_r@yahoo.co.in  Prof & Head , Department of Computer Science Periyar University Salem 636 011 Tamil Nadu,  India 2 drktvelu@yahoo.com Abstract  This paper proposes a new classification method based on association rule mining. This association rule-based classifier is experimented on a real dataset; a database of medical images from MIAS database. The proposed system employs Ant-Miner metaheuristic algorithm for extracting knowledge in the form of decision rules using texture features extracted with the help of co-occurrence matrices. These rules are used to predict unseen mammogram. The experimental results show that the method performs with greater accuracy Keywords  Ant-Miner, Data mining, Mammogram GLCM Matrix Metaheuristic I.  INTRODUCTION Breast Cancer is one of the most common cancers, leading to cause of death among women, especially in developed countries. There is no primary prevention since cause is still not understood. So, early detection of the stage of cancer allows treatment which could lead to high survival rate. The accuracy with which tumors are detected, when large volumes of images are to be read by radiologists tends to decrease, and hence an automated mechanism for reading of digital mammograms is always preferable. However with the use of proper computer aided systems, we could reduce the number of unnecessary biopsies being conducted. Waveletbased subband image decomposition for detecting microcalcification in digital mammograms is presented in 1 Tumor detection using Markov Random field is proposed in  I n this t e c hniq u e   de te c tio n o f  t u m o r  i n dig i t a l mammography is performed in two steps, segmentation and classification. Classification of medical images using neural networks is presented in [3  O s ma r R  Z a i n e  e t   a l  5   ha ve  classified medical images using Association Rule based Classifiers by Category \(ARCBC\. A study of the breast cancer using data mining techniques has been presented in 6 978-1-4244-6589-7/10/$26.00 ©2010 IEEE Metaheuristics are generally applied to problems for which there is no satisfactory problem-specific algorithm or heuristic; or when it is not practical to implement such a method. Most commonly used metaheuristics are targeted to combinatorial optimization problems, but of course can handle any problem that can be recast in that form, such as solving boolean equations. In this research, the Ant-Miner metaheuristic algorithm has been used to generate rules for classification purpose.  A voting scheme algorithm has been proposed to classify an unknown case which is not classified under one particular angle. A similar technique has been proposed by Andrew Kusiak et al. [7 i n pr e d i c t i ng s u r v i v a l  time for kidney dialysis patients This paper is organized as follows: Section II explains the concepts and importance of datamining. Section III elucidates Ant Colony-Based Association Rule Miner, Section IV gives out the proposed algorithm using voting scheme. Section V reports the computational results and discussions II. DATA MINING Mining information and knowledge from large database has been recognized by many researchers as a key research topic in database system and machine learning and by many industrial companies as an important area with an opportunity of major revenues. One of the data mining tasks gaining significant attention is the classification rules extraction from databases. The goal of this task is to assign each case \(object record and instance\ to one class, out of a set of predefined classes, based on the values of some attributes for the case There are different classification algorithms used to extract relevant relationship in the data as decision trees which operate performing a successive partitioning of cases until all subsets belong to single class [8  Q u i n la n,198 6  T his  operating way is impracticable except for trivial data sets There are many other approaches for data classification, such as statistical and roughest approaches \(Ziarko,1994\ and neural networks\(Lu et al.,1995\.Though these classification 


techniques are algorithmically strong they require significant expertise to work effectively and do not provide intelligible rules. The classification problem becomes very hard when the number of possible different combinations of parameters is so high that algorithms based on exhaustive searches of the parameter space rapidly become computationally infeasible The metaheuristic algorithms based on nature, such as genetic algorithms GA\, neural networks, immune algorithm, are extremely appealing for the tasks of data mining. This paper deals with Ant-Miner metaheuristic algorithm. In the context of the classification task of data mining, discovered knowledge is often expressed in the form of IF-THEN rules, as follows IF  conditions  THEN  class  The rule antecedent \(IF part\ contains a set of conditions usually connected by a logical conjunction operator AND A. Data Pre-processing Pre-processing is always a necessary whenever the data is to be mined in noisy, inconsistent or incomplete and preprocessing significantly improves the effectiveness of the data mining techniques [1   M a m m o g r a m i m a g e s a r e no is y  and inconsistent to interpret in their raw form. To produce a reliable representation of the breast anatomy we need to preprocess the mammograms. There are basically two steps involved in processing the mammogram images and they are noise reduction and enhancement of image. Many images have existing artifacts like written labels that need to be eliminated and this can be done by cropping the images. The pruning of images removes nearly all background noise The second step is image enhancement. In the process of image generation, transmission and transformation, with the influences of different external and internal factors, the quality of images would be decreased. The purpose of image enhancement is to use special techniques to improve the quality of image or change the images to other formats that are more suitable for processing afterwards. Usually there are two categories of image enhancement techniques: space domain and frequency domain. Histogram equalization technique is an algorithm of gray level enhancement performed in space domain. The distribution of the histogram of an image with low contrast will normally aggregate in a relatively small region. For images after equalization, the different gray levels will have similar occurring rate. In the above situation, the entropy of the image is the largest and contains the most information. In this paper, we choose the widely used histogram equalization technique to enhance the images Noise removal should be performed first in order not to enhance the noise simultaneously. The results after noise removing and histogram equalizing are shown in Fig 1  a. Original Image            b. After Noise Removal  and Histogram  Equilization Fig1 The Preprocessing stage B. Grey level co-occurrence matrices features \(GLCM The GLCM is a well-established robust statistical tool for extracting second order texture information from images [11 12   T h e GL CM ch ar a c t e r i ze s t h e sp at i a l d i st r i b u t i o n  o f g r e y  levels in an image. Specifically, an element in the GLCM P d  i,j represents the probability of occurrence of the pair of grey levels i,j  separated by a distance d at direction In this study, four GLCMs are computed, corresponding to three different directions  0°, 45°, 90° \ and one distance  d 1 pixel\. Haralick 14 features [1  a r e  de r i v e d f r o m  ea ch  GLCM: Angular second moment, Contrast, Correlation Variance, Inverse second different moment, Sum Average Sum Variance, Sum Entropy, Entropy, Difference Variance Difference Entropy, Measure of Correlation 1, Measure of Correlation 2, and Local Mean C. Discretization of Numerical Attributes In order to perform data mining by decision tree algorithm or Ant-miner algorithm, numerical attributes should be discretized first, i.e. continuous attribute values should be divided into multiple segments. For some attributes, if doctors have had existing dividing points, we can adopt it directly. For example, patients’ weight can be divided to thin common and heavy; their age can be divided into under age youth and the elderly; Medical test results can be said to be normal and abnormal. But for extracted image feature value there is no existing threshold. Previous research indicated that supervised discretization methods are better than unsupervised methods [13  I n  t h i s r e s e a r c h  e n t r op yba s e d binning via binarization has been used. It intuitively, find best split so that the bins are as pure as possible and formally characterized by maximal information gain [14  III. ANT COLONY-BASED ASSOCIATION RULE MINER Ant Colony-Based is proposed by Parpinelli et al [9 as a n  association rule mining algorithm. An Ant Colony Optimization algorithm \(ACO\ is essentially a system based on agents which simulate the natural behavior of ants including mechanisms of cooperation and adaptation. In solving the optimization problems with ACO we have three major functions. Choosing these functions appropriately helps the algorithm to get faster and better results. The first function is a problem-dependent heuristic function \( \ which 


measures the quality of items that can be added to the current partial solution. The heuristic function stays unchanged during the algorithm. A rule for pheromone updating, which specifies how to modify the pheromone trail \(\, and a probabilistic transition rule based on the value of the heuristic function and on the contents of the pheromone trail that is used to iteratively construct a solution In Ant-Miner algorithm the author refer to each rule condition as a term, so that the rule antecedent is a logical conjunction of terms in the form: IF term1 AND term2 AND ... Each term is a triple  attribute, operator, value such as <Gender = female>. The rule consequent \(THEN part\ specifies the class predicted for cases whose predictor attributes satisfy all the terms specified in the rule antecedent. From a data mining viewpoint, this kind of knowledge representation has the advantage of being intuitively comprehensible for the user, as long as the number of discovered rules and the number of terms in rule antecedents are not large ACO algorithms involve simple agents \(ants\ that cooperate with one another to achieve an emergent, unified behavior for the system as a whole, producing a robust system capable of finding high-quality solutions for problems with a large search space. In the context of rule discovery, an ACO algorithm has the ability to perform a flexible, robust search for a good combination of terms \(logical conditions involving values of the predictor attributes In ACO algorithm each ant incrementally constructs/modifies a solution for the target problem. In the proposed model the target problem is the discovery of classification rules for mammogram classification A. Pheromone Initialization All cells in the pheromone table are initialized equally as per the following equation       a i i ij b t 1 1  0    where a is the total number of attributes, and b i is the number of possible values that can be taken on by attribute A i The rule is constructed by the ant incrementally by adding one term at a time. The term selection is based on the probability as given by the following equation    a i b j ij ij i ij ij ij i t x t P 11              where ij is the value of a problem-dependent heuristic function for term ij the higher the value of ij the more relevant for classification the term ij is, and so the higher its probability of being chosen a is the total number of attributes x i is set to 1 if the attribute A i was not yet used by the current ant, or to 0 otherwise b i is the number of values in the domain of the i th attribute B.  Heuristic value In traditional ACO, a heuristic value is usually used in conjunction with the pheromone value to decide on the transitions to be made. In Ant-Miner, the heuristic value is taken to be an information theoretic measure for the quality of the term to be added to the rule. The quality here is measured in terms of the entropy for preferring this term to the others, and is given by the following equation     log        2 1 ij i ij K W i ij i V A W P V A W P V A W H        where W is the class attribute \(i.e., the attribute whose domain consists of the classes to be predicted k is the number of classes P\(W|A i V ij  is the empirical probability of observing class W conditional on having observed A i V ij The higher the value of H\(W|A i V ij  the more uniformly distributed the classes are and so, the smaller the probability that the current ant chooses to add term ij to its partial rule The information-theoretic heuristic function is        a i b j ij i i ij i ij i V A W H k x V A W H k 11 2 2    log     log   where a  x i and b i have the same meaning as in term selection equation Immediately after the ant completes the construction of a rule, pruning is undertaken to increase the comprehensibility and accuracy of the rule. After the pruning step, the rule may be assigned a different predicted class based on the majority class in the cases covered by the rule antecedent. The rule pruning procedure iteratively removes the term whose removal will cause a maximum increase in the quality of the rule. The quality of a rule is measured using the following equation  TN F P TN FN T P TP Q     where TP true positives\ is the number of cases covered by the rule that have the class predicted by the rule FP false positives\ is the number of cases covered by the rule that have a class different from the class predicted by the rule FN false negatives\ is the number of cases that are not covered by the rule but that have the class predicted by the rule TN true negatives\ is the number of cases that are not covered by the rule and that do not have the class predicted by the rule C.  Pheromone Update Rule After each ant completes the construction of its rule pheromone updating is carried out as per the following equation  Q t t t ij ij ij      1         R j i     where R is the set of terms occurring in the rule constructed by the ant at iteration t In Ant-Miner, pheromone evaporation is implemented in an indirect way. More precisely, the effect of pheromone evaporation for unused terms is achieved by normalizing the value of each pheromone ij This normalization is performed by dividing the value of each ij by the summation of all  ij  D.  Ant-Miner Parameter Setting  The parameters used to achieve the results  Number of ants =  100 Minimum cases per rule =   10 


Maximum uncovered cases = 10 Number cases for rules converge = 10 E. A high-level description of Ant-Miner Algorithm TrainingSet = {all training cases DiscoveredRuleList   ru le l i s t is in itia liz e d w i t h a n  empty list WHILE \(TrainingSet > Max_uncovered_cases t = 1; /* ant index j = 1; /* convergence test index Initialize all trails with the same amount of pheromone REPEAT Ant t starts with an empty rule and incrementally constructs a classification rule Rt by adding one term at a time to the current rule Prune rule Rt Update the pheromone of all trails by increasing pheromone in the trail followed by Ant t \(proportional to the quality of Rt\ and decreasing pheromone in the other trails \(simulating pheromone evaporation IF \(Rt =  Rt … 1\ /* update convergence test THEN j = j + 1 ELSE j = 1 END IF t = t + 1 UNTIL \(i < No_of_ants\ OR \(j <  No_rules_converg Choose the best rule Rbest among all rules Rt constructed by all the ants Add rule Rbest to DiscoveredRuleList TrainingSet = TrainingSet - {set of cases correctly covered by Rbest END WHILE F.  Comparative study The metaheuristic Ant-Miner algorithm has been compared with standard C4.5 algorithm. The experimental results show that Ant-Miner classifies the mammogram region with greater accuracy and with less number of rules than C4.5. Another observation made is the default rules used for classification in both the algorithm decreases the accuracy. Ten-fold cross validation has been done on the features extracted in the mammogram region by constructing coocurrence matrices at three different angles namely 0, 45 and 90.  Experimental results reveal that some of the cases which are misclassified by the default rule in one particular angle could be classified by the rules generated in other angles IV. THE PROPOSED DECISION MAKING ALGORITHM To the author’s knowledge there are studies focus on extracting features from co-occurrence matrix at different angles and combing all features to form feature set and then build classification models. There is only one study using mean and range of different features at different Angles namely \( = 0 0 45 0 90 0 135 0 5  The Ant-Miner algorithm has been applied to generate classifiers for the features generated over the co-occurrence matrix at different angles namely \( = 0 0 45 0 90 0 These classifiers are used to make predictions of tumor as benign or malignant. Each classifier can be considered as a digital expert. If all digital experts generate the same outcome, then this would be the confident prediction. The predictions generated by all classifiers are often not identical, and therefore a decision making algorithms is needed A simple voting scheme has been used with each classifier having one vote. Thus the decision outcome with maximum number of votes is the predicted outcome. To be conservative if there is tie or no classifier can classify a particular case the outcome will be Unknown instead of giving any approximate classification using default rule. Figure 2 shows the diagrammatic representation of proposed decision making scheme Fig 2  Diagrammatic Representation of Proposed Decision-making Scheme V. COMPUTATIONAL RESULT Initial experiment was conducted to classify the mammogram region as normal and abnormal \(abnormal includes benign and malignant\.  The result shows the accuracy reaches 99% for the proposed method. In the second level the experiment has been extended to classify the region of abnormality as benign and malignant.  Since it is very difficult to interpret the region as benign and malignant there is a drop in the classification rate A.  Sample Rule Set The rule set for Fold 3 at Angle 0 is given below Number of Rules = 2 Rule  : 1 Contrast   = low\  and  \(Entropy  = high\  and  \(MC1  = low and  \(SE = high Malignant Rule  : 2 Contrast  = low\   and Correlation = low\   and  \(LM = low and  \(ASM =  low\  and  \(MC2 = low Benign 


Where MC1 … Measure of Correlation 1 SE- Sum Entropy LM … Local Mean ASM … Angular Second Moment MC2 … Measure of Correlation 2 Table I reports the prediction given in various angle classifier and the voting scheme prediction TABLE 1 PREDICTION RESULTS AND OVERLAP ANALYSIS B – Benign    A – Malignant   UK – Unknown For an independent angle analysis some of the mammograms remains unclassified that can be classified by the default class that decreases the classification accuracy The Classification percentage which is improved by the proposed algorithm  is illustrated in Table II TABLE II CLASSIFICATION PERCENTAGE AT DIFFERENT ANGLES AND PROPOSED ALGORITHM \(10 FOLDS The Classifier at different angles and the classification percentage is given in Table III TABLE III AVERAGE CLASSIFICATION PERCENTAGE FOR 10 FOLDS The results show that the cases which are not classified in one particular angle could be classified by the proposed algorithm with the greater accuracy. The graphical representation of the improvement in classification percentage is shown in Figure 3 Fig  3  Classification Accuracy VI. CONCLUSION The result shows the significance of data mining in image processing. This system gives us more accurate result compared with the co-occurrence matrix constructed by independent angle. Also the malignancy which could not be classified under particular angle of co-occurrence matrix can be classified by the features extracted in other angles.  This paper proposes the decision making tree that considers the result in three different angles. The further study can be made to improve the classification accuracy using different feature set as an additional expert of the proposed algorithm REFERENCES 1 T   W a ng a n d N Ka r a yi a nni s    D e t e c t i on of M i c r oc a l c i f i c a t i ons i n  Digital  Mammograms using WaveletsŽ, IEEE transactions on Medical Imaging, 1998, pp. 498-509 2 H   D  L i   M  K a ll e r g i  L   P  Cl a r k e V   K  J a i n a n d R A  C l a r k    Markov Random Field for Tumor Detection in DigitalMammography IEEE Transactions on Medical Imaging 14\(3\, 1995, pp. 565-576 3 M a r i a L uz i a  A n t oni e  O s m a r R  Z a i a ne   a n d A l e x a n d r u C o m a n   Application of Data Mining Techniques for MedicalImage Classification Proceedings of the Second International Workshop on Multimedia Data Mining \(MDM/KDD `2001\ in conjunction with Seventh ACM SIGKDD, USA, 2001, pp. 94101 4 I oa n n a C h r i s t o y i a nni  E v a l ge l o s D e r m a t a s   a n d Ge or ge  Kokkinakis. Fast Detection of Masses in Computer-Aided MammographyŽ, IEEE Signal Processing Magazine, 2000, pp 54-64 5 O s m ar R  Z a i n e Mar i a L u zi a A n to n i e  an d  A l ex an d e r Co n m a n  Mammography Classifications by an Association Rule Based ClassifierŽ Proceedings of the Third International Workshop on Multimedia Data mining \(MDM/KDD’2002\ in conjunction with Eighth ACM SIGKDD, USA, 2002, pp. 62- 69 6 V i b ha L  V e nu go pa l  K R   a n d  L   M   P a t n a i k   A Study of Breast Cancer Using Data Mining Techniques Technical Report University Visvesvaraya College of  Engineering, Bangalore University, August 2003 Predictions Case No 0 0 45 0 90 0 Final Prediction Result Mdb252 M M M M Match Mdb253 B B UK B Match Mdb256 M M M M Match Mdb264 M M UK M Match Mdb265 UK UK UK UK Mdb267 M M M M Match Mdb270 B B UK B Match Mdb271 M UK UK M Match Mdb274 B B UK B Match Mdb290 M M M M Match Classification Percentage Training Data Angle 0 0 Angle 45 0 Angle 90 0 Proposed Algorithm Fold 1 10 10 100 100 Fold 2 30 60 60 100 Fold 3 100 60 60 100 Fold 4 30 40 80 90 Fold 5 40 30 80 50 Fold 6 30 10 50 100 Fold 7 10 30 30 30 Fold 8 30 70 30 100 Fold 9 10 50 60 70 Fold 10 90 80 40 90 Classifier at different Angles Average Classification Percentage for 10 Folds Angle 0 38 Angle 45 44 Angle 90 59 Proposed Algorithm 83 


7 A nd r e w  Ku s i a k  B r a d l e y Di xon S h i t a l S h a h  P r e d i c t i ng s u r v i v a l  time for kidney dialysis patients : a data mining approach Computers in Biology and Medicine 35 \(2 005\ 311-327 8 Q ui nl a n  J  R    S i m p l i f yi ng d e c i s i on t r e e s I n t e r n a t i ona l J our na l o f  Man-Machine   Studies, 27, 221-234, 1987 9 R   S  P a r p in elli  H  S  L o p e s a n d  A  A   F r eitas    D ata M i n i n g  w i th  an Ant Colony Optimization AlgorithmŽ, IEEE Transactions on Evolutionary Computing, Vol. 6, No. 4, 321-332, August 2002 10 J i aw ei H a n an d Mich e l i n e K a m b er  Data Mining,Concepts and Techniques Morgan Kaufmann, 2001 11 Ha r a l i c k R M  S h a n m u ga m  K  D i n s t e i n I  T e xt ur a l f e a t ur e s f o r  image classification. IEEE Trans Syst Man Cybern 1973;SMC3:610…21 12 B r e i m a n F r i e d m a n  O l s he n S t one  C l a s s i f i c a t i on a n d De c i s i on  Trees Wadsworth International Group 1984  Do ugh e r ty  J  K oha v i R  S a h a m i M  S u p e r v is e d a n d u n s up e r v i s e d  discretization of    continuous features. In: Proceedings of the 12th international conference on machine learning.San Francisco Morgan Kaufmann; \(1995\ pp 194…202 14 H L i u F  H u s s a i n  C  L  T a n  a n d M  Da s h  Di s c r e t i z a t i on An  Enabling Technique. DMKD 6 \(2002\ 393-423 15 A K a r a ha l i ou  S S k i a d opo ul o s  B oni a t i s   P  S a k e l l a r opo ul o s   P, E Likaki, , G Panayiotakis, and L Costaridou, Texture analysis of tissue surrounding microcalcifications on mammograms for breast cancer diagnosis  British Journal of Radiol ogy , 80 \(2007  648-656 


    Figs. 7 and 8 show the average rank for the training data accuracy and the test data accuracy. We can observe almost all of the same effects of candidate rule addition and lateral tuning as in the case of 0.0  Pareto EC ECW Pareto EC ECW  0.00 0.01 0.05 0.10 0 2 4 6 Average rank  Fig. 7.  Average rank for the training data accuracy over all the data sets A smaller rank is better Pareto EC ECW Pareto EC ECW  0.00 0.01 0.05 0.10 0 2 4 6 Average rank  Fig. 8.  Average rank for the test data accuracy over all the data sets A smaller rank is better  C  Comparison between Low and High Imbalanced Data We divided the data sets used in our experiments into two subsets: Low imbalance data sets \(IR < 3.0\gh imbalanced data sets \(IR > 3.0\gs. 9 and 10 show the average rank for the test data accuracy over the low imbalanced data sets and the high imbalance data sets respectively. We can see that the positive effect of genetic lateral tuning became weaker as became larger for the low imbalance data sets. On the other hand, the approaches with candidate rule addition and ge netic lateral tuning \(i.e., EC and ECW*\kept good ranking in almost all cases. This observation may indicate that the proposed extensions are effective especially for the high imbalanced data sets V   C ONCLUSION  In this paper, we proposed two extensions of our genetic fuzzy rule selection for designi ng more accurate classifiers One extension is to add compatible rules with misclassified patterns into candidate rules for genetic fuzzy rule selection The other extension is to tune membership functions by genetic lateral tuning after genetic fuzzy rule selection Experimental results showed that the candidate rule addition can improve the training data accuracy. This is because the possibility that the misclassified training patterns are classified by additional rules becomes high. Experimental results also showed that the genetic lateral tuning can improve the test data accuracy as well as the training data accuracy, since fuzzy membersh ip functions are properly adjusted according to the pattern distributions. The combination of the proposed two extensions would be the best choice As a future study, we will examine the effects of the proposed extensions using a large number of data sets TABLE  VI A DJUSTED P VALUES OBTAINED BY N EMENYI 222 S T EST   H OLM 222 S T EST   S HAFFER 222 S T EST  AND B ERGMANN H OMMEL P ROCEDURE FOR THE T EST D ATA A CCURACY OBTAINED IN OUR C OMPUTATIONAL E XPERIMENTS  i Hypothesis Unadjusted p  p Neme  p Holm  p Shaf  p Berg  1 Pareto vs. ECW 3.1 x 10 10 4.8 x 10 9 4.8 x 10 9 4.8 x 10 9 4.9 x 10 9  2 Pareto vs. EC 1.6 x 10 7 2.4 x 10 6 2.2 x 10 6 1.6 x 10 6 1.6 x 10 6  3 EC vs. ECW 1.6 x 10 4 0.0024 0.0021 0.0016 0.0016 4 Pareto vs. ECW 8.0 x 10 4 0.0119 0.0095 0.0080 0.0056 5 Pareto* vs. ECW 0.0012 0.0173 0 0127 0.0116 0.0081 6 Pareto vs. Pareto 0.0024 0.0355 0 0237 0.0237 0.0142 7 ECW vs. ECW 0 0033 0.0500 0.0300 0.0237 0.0142 8 EC vs. EC 0.0064 0.0963 0.0514 0.0449 0.0385 9 Pareto vs. EC 0 0119 0.1781 0.0831 0.0831 0.0475 10 Pareto* vs. EC 0 0277 0.4156 0.1662 0.1662 0.0831 11 ECW vs. EC 0.0592 0.8876 0.2959 0.2367 0.1183 12 EC* vs. ECW 0 2945 1.0000 1.0000 1.0000 1.0000 13 EC vs. ECW 0.4017 1.0000 1.0000 1.0000 1.0000 14 EC vs. Pareto 0 6002 1.0000 1.0000 1.0000 1.0000 15 ECW vs. Pareto 0 7532 1.0000 1.0000 1.0000 1.0000 


   including data sets with more than two classes. We also have to compare the proposed method with other learning algorithms. There are still a lot of things we have to improve in the proposed extensions, es pecially the search space and genetic operations in the lateral tuning. The discussion on the tradeoff relation among accuracy, complexity, and interpretability is also another important future research issue  Pareto EC ECW Pareto EC ECW  0.00 0.01 0.05 0.10 0 2 4 6 Average rank  Fig. 9.  Average rank for the test data accuracy over low imbalanced data sets A smaller rank is better Pareto EC ECW Pareto EC ECW  0.00 0.01 0.05 0.10 0 2 4 6 Average rank  Fig. 10.  Average rank for the test da ta accuracy over high imbalanced data sets. A smaller rank is better R EFERENCES  1  R. J. Bayardo Jr. and R. Agrawal 223Mining the most interesting rules,\224 Proc. of the 5th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining ACM Press, New York, NY USA, pp. 145-154, 1999 2  B. Liu, W. Hsu, and Y. Ma, \223Integ rating classification and association rule mining,\224 Proc. of 4th International Conference on Knowledge Discovery and Data Mining New York, AAAI Press, August 27-31 1998, pp. 80-86 3  X. Yin and J. Han, \223CPAR: Cl assification based on predictive association rules,\224 Proc. of SIAM International Conference on Data Mining, San Francisco CA, May 2003, pp. 331-335 4  H. Ishibuchi, K. Nozaki, N. Yamamoto, and H. Tanaka, \223Selecting fuzzy if-then rules for classi fication problems using genetic algorithms,\224 IEEE Trans. on Fuzzy Systems vol. 3, no. 3, pp. 260-270 1995 5  H. Ishibuchi, T. Murata, and I B. Turksen, \223Single-objective and two-objective genetic algorithms for selecting linguistic rules for pattern classification problems,\224 Fuzzy Sets and Systems vol. 89, no. 2 pp. 135-150, 1997 6  H. Ishibuchi, T. Nakashima, and T Murata, \223Three-objective genetics based machine learning for linguistic rule extraction,\224 Information Sciences vol. 136, no. 1-4, pp. 109-133, 2001 7  H. Ishibuchi and T. Yamamoto, \223F uzzy rule selection by multi objective genetic local search algorith ms and rule evaluation measures in data mining,\224 Fuzzy Sets and Systems vol. 141, no. 1, pp. 59-88 2004 8  H. Ishibuchi, I. Kuwajima, and Y Nojima, \223Prescreening of candidate rules using association rule mining a nd Pareto-optimality in genetic rule selection,\224 Proc. of 11th International Conference on Knowledge Based and Intelligent Informa tion and Engineering Systems pp 509-516, 2007 9  I. Kuwajima, Y. Nojima, and H. Ishibuchi, \223Obtaining accurate classifiers with Pareto-optimal and near Pareto-optimal rules,\224 Proc. of 11th International Symposium on Artificial Life and Robotics pp 195-198, Beppu, Japan, January 31-February 2, 2008 10  H. Ishibuchi and T. Nakashima, \223E ffect of rule weights in fuzzy rule-based classification systems,\224 IEEE Trans. Fuzzy Systems vol. 9 no. 4, pp. 506-515, August 2001 11  H. Ishibuchi and T. Yamamoto, \223Rule weight specification in fuzzy rule-based classification systems,\224 IEEE Trans. on Fuzzy Systems vol 13, no. 4, pp 428-435, August 2005 12  J. M. Alonso and L. Magdalena, \223A n interpretability-guided modeling process for learning comprehensible fuzzy rule-based classifiers,\224 Proc of 9th International Conference on Intelligent Systems Design and Applications pp. 432-437, 2009 13  K. Deb, A. Pratap, S. Agarwal, a nd T. Meyarivan, \223A fast and elitist multiobjective genetic algorithm: NSGA-II,\224 IEEE Trans. on Evolutionary Computation vol. 6, no. 2, pp. 182-197, April 2002 14  R. Alcal\341, J. Alcal\341-Fdez, and F Herrera, \223A proposal for the genetic lateral tuning of linguistic fuzzy syst ems and its interaction with rule selection,\224 IEEE Trans. on Fuzzy Systems vol. 15, no. 4, pp. 616-635 2007 15  J. Alcal\341-Fdez, R. Alcal\341, M. J. Gacto, and F. Herrera, \223Learning the membership function contexts for mining fuzzy association rules by using genetic algorithms,\224 Fuzzy Sets and Systems vol. 160, pp 905-921, 2009 16  M. Kaya and R. Alhaji, \223Utilizi ng genetic algorithms to optimize membership functions for fuzzy weighted association rules mining,\224 Applied Intelligence vol. 24, no. 1, pp. 7-15, February 2006 17  W. Wang and S. M. Bridges, \223G enetic algorithm optimization of membership functions for mining fuzzy association rules,\224 Proc. of the 7th International Conference on Fuzzy Theory & Technology  pp.131-134, Atlantic City, NJ February 27-March 3, 2000 18  J. Dem\232ar, \223Statistical comparisons of classifiers over multiple data sets,\224 Journal of Machine Learning Research vol. 7, pp. 1-30, 2006 19  M. Friedman, \223The use of ranks to avoid the assumption of normality implicit in the analysis of variance,\224 Journal of the American Statistical Association vol. 32, pp. 675-701, 1937 20  P. B. Nemenyi Distribution-free Multiple Comparisons PhD thesis Princeton University, 1963 21  S. Holm, \223A simple sequentially re jective multiple test procedure,\224 Scandinavian Journal of Statistics vol. 6, pp. 65-70, 1979 22  J. P. Shaffer, \223Modified seque ntially rejective multiple test procedures,\224 Journal of the American Statistical Association vol. 81 pp. 826-831, 1986 23  G. Bergmann and G. Hommel, \223Impr ovements of general multiple test procedures for redundant systems of hypotheses,\224 In Bauer, Hommel and Sonnemann, eds  Multiple Hypotheses Testing Springer, Berlin, pp 100-115, 1988 24  S. Garc\355a and F. Herrera, \223An exte nsion on \221Statistical comparisons of classifiers over multiple data sets\222 for all pairwise comparisons,\224 Journal of Machine Learning Research vol. 9, pp. 2677-2694 December 2008 The source code is available at http sci2s.ugr.es/keel/multipleTest.zip   


Application of Chaotic Particle Swarm Optimization Algorithm in Chinese Documents Classification 763 Dekun Tan Qualitative Simulation Based on Ranked Hyperreals 767 Shusaku Tsumoto Association Action Rules and Action Paths Triggered by Meta-actions 772 Angelina A. Tzacheva and Zbigniew W. Ras Research and Prediction on Nonlinear Network Flow of Mobile Short Message Based on Neural Network 777 Nianhong Wan, Jiyi Wang, and Xuerong Wang Pattern Matching with Flexible Wildcards and Recurring Characters 782 Haiping Wang, Fei Xie, Xuegang Hu, Peipei Li, and Xindong Wu Supplier Selection Based on Rough Sets and Analytic Hierarchy Process 787 Lei Wang, Jun Ye, and Tianrui Li The Covering Upper Approximation by Subcovering 791 Shiping Wang, William Zhu, and Peiyong Zhu Stochastic Synchronization of Non-identical Genetic Networks with Time Delay 794 Zhengxia Wang and Guodong Liu An Extensible Workflow Modeling Model Based on Ontology 798 Zhenwu Wang Interval Type-2 Fuzzy PI Controllers: Why They are More Robust 802 Dongrui Wu and Woei Wan Tan Improved K-Modes Clustering Method Based on Chi-square Statistics 808 Runxiu Wu Decision Rule Acquisition Algorithm Based on Association-Characteristic Information Granular Computing 812 JianFeng Xu, Lan Liu, GuangZuo Zheng, and Yao Zhang Constructing a Fast Algorithm for Multi-label Classification with Support Vector Data Description 817 Jianhua Xu Knowledge Operations in Neighborhood System 822 Xibei Yang and Tsau Young Lin An Evaluation Method Based on Combinatorial Judgement Matrix 826 Jun Ye and Lei Wang Generating Algorithm of Approximate Decision Rules and its Applications 830 Wang Yun and Wu-Zhi Qiang Parameter Selection of Support Vector Regression Based on Particle Swarm Optimization 834 Hu Zhang, Min Wang, and Xin-han Huang T-type Pseudo-BCI Algebras and T-type Pseudo-BCI Filters 839 Xiaohong Zhang, Yinfeng Lu, and Xiaoyan Mao A Vehicle License Plate Recognition Method Based on Neural Network 845 Xing-Wang Zhang, Xian-gui Liu, and Jia Zhao Author Index 849 
xiii 


   C4.2 Open GL has excellent documentation that could help the developer learn the platform with ease C4.3 Developer has very little ex perience in working with Open GL platform  For our case study, alternative B i.e. Adobe Director was the most favorable alternative amongst all the three. It catered to the reusability criteria quite well and aimed at meeting most of the desired operational requirements for the system   6. CONCLUSION & FUTURE WORK  The main contribution of this paper is to develop an approach for evaluating performance scores in MultiCriteria decision making using an intelligent computational argumentation network. The evaluation process requires us to identify performance scores in multi criteria decision making which are not obtained objectively and quantify the same by providing a strong rationale. In this way, deeper analysis can be achieved in reducing the uncertainty problem involved in Multi Criteria decision paradigm. As a part of our future work we plan on conducting a large scale empirical analysis of the argumentation system to validate its effectiveness   REFERENCES  1  L  P Am g o u d  U sin g  A r g u men ts f o r mak i n g an d  ex p lain in g  decisions Artificial Intelligence 173 413-436, \(2009 2 A  Boch m a n   C ollectiv e A r g u men tatio n    Proceedings of the Workshop on Non-Monotonic Reasoning 2002 3 G  R Bu y u k o zk an  Ev alu a tio n o f sof tware d e v e lo p m en t  projects using a fuzzy multi-criteria decision approach Mathematics and Computers in Simualtion 77 464-475, \(2008 4 M T  Chen   F u zzy MCD M A p p r o ach t o Selec t Serv ice  Provider The IEEE International Conference on Fuzzy 2003 5 J. Con k li n  an d  M. Beg e m a n   gIBIS: A Hypertext Tool for Exploratory Policy Discussion Transactions on Office Information Systems 6\(4\: 303  331, \(1988 6 B P  Duarte D e v elo p in g a p r o jec ts ev alu a tio n sy ste m based on multiple attribute value theroy Computer Operations Research 33 1488-1504, \(2006 7 E G  Fo rm an  T h e  A n a l y t ic Hier a rch y P r o cess A n  Exposition OR CHRONICLE 1999 8 M. L ease  an d J L  L i v e l y  Using an Issue Based Hypertext System to Capture Software LifeCycle Process Hypermedia  2\(1\, pp. 34  45, \(1990 9  P e id e L i u   E valu a tio n Mo d e l o f Custo m e r Satis f a c tio n o f  B2CE Commerce Based on Combin ation of Linguistic Variables and Fuzzy Triangular Numbers Eight ACIS International Conference on Software Engin eering, Artificial Intelligence Networking and Parallel Distributed Computing, \(pp 450-454 2007  10  X  F L i u   M an ag e m en t o f an In tellig e n t A r g u m e n tatio n  Network for a Web-Based Collaborative Engineering Design Environment Proceedings of the 2007 IEEE International Symposium on Collaborative Technologies and Systems,\(CTS 2007\, Orlando, Florida May 21-25, 2007 11 X. F L i u   A n In ternet Ba se d In tellig e n t A r g u m e n tatio n  System for Collaborative Engineering Design Proceedings of the 2006 IEEE International Symposium on Collaborative Technologies and Systems pp. 318-325\. Las Vegas, Nevada 2006 12 T  M A sub jec tiv e assess m e n t o f altern ativ e m ission  architectures for the human exploration of Mars at NASA using multicriteria decision making Computer and Operations Research 1147-1164, \(June 2004 13 A  N Mo n ireh  F u zzy De cisio n Ma k i n g b a se d o n  Relationship Analysis between Criteria Annual Meeting of the North American Fuzzy Information Processing Society 2005 14 N  P a p a d ias HERMES Su p p o rti n g A r g u m e n tative  Discourse in Multi Agent Decision Making Proceedings of the 15th National Conference on Artifical Intelligence \(AAAI-98  pp. 827-832\dison, WI: AAAI/MIT Press,  \(1998a 15  E. B T riantaph y llo u   T h e Im p act o f  Ag g r e g atin g Ben e f i t  and Cost Criteria in Four MCDA Methods IEEE Transactions on Engineering Management, Vol 52, No 2 May 2005 16 S  H T s a u r T h e Ev alu a tio n o f airlin e se rv ice q u a lity b y  fuzzy MCDM Tourism Management 107-115, \(2002 1 T  D W a n g  Develo p in g a f u zz y  T O P S IS app r o ach  b a sed  on subjective weights and objective weights Expert Systems with Applications 8980-8985, \(2009 18 L  A  Zadeh  F u z z y Sets   Information and Control 8  338-353, \(1965  152 


                        





