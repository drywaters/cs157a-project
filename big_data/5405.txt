Proceedings of 2013 International Conference on Fuzzy Theory and Its Application National Taiwan University of Science and Technology, Taipei, Taiwan Dec. 6-8, 201 3 Abstract Aiming at the problems of increasing energy consumption of cloud storage, big environmental resources pressure exist research on replica placement lacking of focus on energy consumption, this paper proposes a energy conservation replica placement method ECRP\(Energy Conservation Replica Placement ECRP Based on the three main different levels of energy consumption of hardware components the data node is divided into hot zone, warm zone and cold zone three logical zone, each zone uses different power management strategies and replica placement strategies, and after building a file activity prediction model which based on the simulated annealing BP neural network files are stored in the data nodes on different zone according to the type of file activity and then 
calculate the file activity periodically when file activity exceeds a certain threshold, the file begins flow among the hot zone warm zone and cold zone step by step in the two-way. Experiment results show that this method better solve the problems of replica placement and energy consumption optimization, have good energy saving effect Keywords replica placement simulated anneal neural network; file activity; energy conserving  I  I NTRODUCTION  With the continuous improvement of the whole social information degree especially under the push of Cloud Computing  the Internet of Things and Mobile Internet, the scale of applied information processing and data service in various industry is more and more large  various types of data-intensive applications emerging  the amount of data generated by the application presents 
geometric growth. IDC  the world in 2010 produced 1.2 ZB \(1 ZB = 1 trillion GB data    the explosion of digital information scale promotes the people to the huge demand for information storage  Turing Award winner Jim Gray presented a new Moore's Law in storage industry, that every 18 months the amount of additional memory storage capacity is equal to the sum ever  UC Berkley study shows that the data generated from the next three years will be more than the sum of the past 40000 years, and 93% of the new generation information will be existed in digital form  Such vast amounts of data, makes the global data center's scale expands the consumption of energy is also increasing Pike Research points out that the data centers consumes 20.18 billion degrees of electricity in 2010 electricity 
expenses as much as $23.3 billion  Electricity consumption of data centers has been close to a total generating capacity of the Three Gorges power station  Huge amounts of data in the cloud provide more intelligent more convenient services for people at the same time, and also brought the bottleneck and confused of data application, and greatly increasing the difficulty for people to find useful knowledge. How to effectively storage, process and manage these massive data has been a new challenge facing in cloud computing era, but also become the driving force for many researchers to explore new concepts new methods and new technology of cloud computing Now usually adopts the replica placement method to solve the problem of availability and reliability of the data in cloud computing environment How to efficiently place the replica making the highest income obtained under the minimum cost, is one of the key problems of 
cloud storage system needs further study 2 Research suggests that by suitable replica placement strategy will keeping multiple copies of a data item in a distributed system of multiple nodes can effectively improve the reliability throughput and performance 4  of system by  smaller cost, but also has proved that the replica placement problem is a NP-complete problem 5 it's impossible to find a universal optimal solution, can only obtain a nearly optimal solution by heuristic method. Therefore the research of the replica placement problem in cloud computing, finding nearly optimal solution which suitable for cloud storage environment, has important significance The current study of replica placement mainly divided into two categories one category is to establish mathematical model according to the specific optimization goal optimize replica placement by mathematical 
models Among them Liu Tian Tian etc 7 discussed the research status of replica management from five aspects  ion delete and consistency and analyzed that in different network environment different file system requirements and different application requirements environment can adopt management methods in different emphasis Wang et etc 8 proposed a RPRTM model, the model consider the response time in each node, and use the genetic algorithm to minimize the replica number while ensuring the response time of node Wei 9  modeled the relationship between the usability of files and the replica number using queuing theory, puts forward a dynamic adjustment mechanism for replica Zhu Jiayu etc 10  proposed a dynamic replication management strategy by establish 
ing the relationship model between the availability of Xiao Yong  Zhao  Lei  Wang  School of Information Management   School of Information Management   Beijing Information Science and Technology University  Beijing Information Science and Technology University  Beijing   China  Beijing  
 China  e mail  zhaoxiaoyong bistu.edu.cn  e mail   wanglei575882@163.com  A n Activity based Replica Placement Method of Energy conservation  Proceedings of 2013 International Conference on Fuzzy Theory and Its App\lication\r\nNational Taiwan University of Science and Technology, Taipei\, Taiwan, Dec. 6-8, 2013\r\n 446 


Proceedings of 2013 International Conference on Fuzzy Theory and Its Application National Taiwan University of Science and Technology, Taipei, Taiwan Dec. 6-8, 201 3 files and the replica number to calculate the minimum number of replica which systems should maintain while satisfy the requirement of file availability at the same time and then place the replicas according to the number of copies data is accessed and transport costs to achieve optimal system performance and load balancing; FuWei etc 11 in view of the application scenario with strict requirement of the quality of service established an abstract replica placement model which based on graph theory on the basis of service quality distance, and make the system to meet all user's QoS requirements by looking for approximate optimal QoS-aware replica placement method Agneeswaran etc 12  establish relationship model between data replica and availability, and then set a threshold according to the need, and calculate minimum number of replica that each file block needs The other is based on historical information, build a statistical prediction model, and thus predict the optimal layout of replica placement. Among them, Li Jinmiao etc 13 put forward a dynamic mechanism based on user behavior analysis by analyzing the replica visitor access time, file size, access to reply, delay and other relevant information, use the file heat to determine the dynamic changes of the number of replica and adopt the best-effort approach to determine the location of the replica, so as to achieve the target of dynamically change the number of replicas and confirm the location of copies to provide users with more flexible, efficient and reliable safeguard mechanism. Zou Li Da etc 14 proposed replica placement policy based on traffic prediction, and introduced two kind of traffic forecast methods, one is based on historical data and the other one is based on artificial neural network Now these studies mainly focus on how to efficient use of storage space, improve the efficiency of file access enhance the system reliability and guarantee the data consistency and so on but usually there are two main problems 1  Does not distinguish between data nodes in the cluster and think that all nodes are homogeneous But  ervers are usually batch purchased in different period, even if the new data center, as time goes on, later will also join the cluster server which has better computing performance I/O performance and more storage space than previous server 2  Does not distinguish between data, but treat the data in the same position; In fact, the data have a life cycle show the obvious time activity associated characteristics This paper based on the heterogeneous of servers the three main working status in different levels of energy consumption and the characteristics of different activity level in data lifecycle puts forward an energy-saving replica placement algorithm based on file activity. First based on three main different levels of energy consumption of hardw  data node into three logical zones: Hot Zone, Warm Zone and Cold Zone each zone adopt corresponding power management strategy and replication strategy Using historical data as the training samples to construct the file activity prediction model which based on simulated annealing BP neural network, and store the files in different parts of the data node depending on the activity of files calculate the activity of files in each zone periodically, if the file activity over below/above a certain threshold the file will start two-way flow among hot zone warm zone and cold zone Experimental results show that compared with HDFS built-in random replica placement strategy, this method can 28% reduction in energy consumption at the same time reduce 7 of the storage space Section II is the construction of the file activity predicted model Section III is the toward energy conservation replica placement method. Section IV is the actual simulation results analysis. Finally, we give a conclusion and proposed future research recommendations II F ILE A CTIVITY P REDICTED M ODEL Studies show that the newly created file is accessed most frequently with the passage of time the access frequency drops In large-scale file system most files unused for long a few files frequently used 15  In the Yahoo 5PB data Hadoop cluster constituted by 2600 servers,90.26 of the data within 2 days after creation will be accessed, and 89.61% after 10 days of data access in creating trend is clearly down, and 60% The data has never been accessed in 20 days 16  The file prediction model has been extensively studied by many researchers based on this statistical properties at present there are two models a model based on global accessing information and the other is  based on the recently accessing information Among them, the model based on global accessing information typical representatives Griffioen etc 17  proposed methods based on probabilistic graphical model built with the greatest probability of succeeding the file as predictions; Kroeger, etc 18 proposed ideas based on data compression multi-tree prediction model FMOC  using the higher probability of occurrence matching path as the prediction results The other the model based on recently accessing information typical representatives: LS \(Last Successor model using the latest successor to the current accessing file as the prediction results based on LS models constructed PLS 19  model ULS 20  model and PULS 21 model. In these prediction models, the main use of the file attributes include the number of users to access the file the size of the requested data, the time characteristic, file access times \(repeatability\ and I/O operation types etc  As  the cloud computing environment files accessing variability and complexity, define a precise mathematical model to describe the multiple nonlinear relationship of file activity with these factor is  very difficult so this paper used simulated Annealing BP neural network method with the self-learning characteristics through historical data training, obtained the file activity prediction model to predict the activity of the file. In order to simplify the complexity of the model, the paper select the Proceedings of 2013 International Conference on Fuzzy Theory and Its App\lication\r\nNational Taiwan University of Science and Technology, Taipei\, Taiwan, Dec. 6-8, 2013\r\n 447 


Proceedings of 2013 International Conference on Fuzzy Theory and Its Application National Taiwan University of Science and Technology, Taipei, Taiwan Dec. 6-8, 201 3 file access times, number of users, and the average access time as the factors of file activity model A Sample data selection File activity is defined as the file being accessed probability within the next cycle; this paper use Microsoft MSN Storage File Server Traces of IOTTA as sample data which contains 6 hours of file access logs at 10 March 2008. Samples were divided into two groups, the first five hours as training samples, the last hour of data as the prediction sample  B BP network structure design BP neural network can approximate any nonlinear function that can self-learning and adaptive with the ability to generalize the learning results but also has certain degree of fault tolerance, has been widely used Therefore, the paper uses BP neural network prediction model. BP network structure design needs to determine the network layers, each layer of nodes, transfer function the initial weights and learning algorithms still no common approach for the clearly calculation , more so in certain guiding principles, relying on human experience and continuous trying. Its construction process is as follows  1\ Hidden layers According to Kolmogorov theorem for any continuous functions in  closed interval a three-layer BP network including one hidden layer sufficient for any n-dimensional to m-dimensional mapping combined with our problems scene in this paper neural network hidden layer  selected as one layer 2\ Transfer function As the network output value meaning file activity was the probability value so the output layer transfer function selection logsig function, limited its value in the range 0-1. The transfer function of hidden layer   us ed the try and error method to determine, selected respectively tan-sigmoid function and log-sigmoid function, using the sample data for training the results, the system error will be smaller while tan-sigmoid function be used, so choose tan-sigmoid function as the transfer function of the hidden layer  3\ The number of nodes in each layer Based on the file average access time, the number of users, the file history accessing times these three indicators  used t, t-1, t-2 of 3 cycles of statistical data to build file activity predictive models , so BP network input layer node had 9, the output layer node had 1, the output value was the file activity So far, people still did not find a common theoretical approach to determine the number of hidden nodes, the general principle was under the premise to meet the accuracy requirements and accurately reflect the input-output relationship, used as little as possible hidden layer nodes. More representative of the empirical formula we re   1    2   3   4 Reference to the above empirical formula to determine the number of nodes in the hidden layer ranges from 5 to 13, and then continued to use the node cumulative try and error method, comprehensive analysis of comparison determining 7 nodes in the hidden layer to be most appropriate  C Simulated Annealing BP Neural Network SA algorithm Simulated Annealing from solid annealing principle has been proved theoretically to be a probability of 1 to converge to the global optimal solution of global optimization algorithm, the algorithm obtained solution has nothing to do with the initial state with gradual convergence. Since the standard BP neural network in the presence of gradient descent slow convergence and easy to fall into local minima problem, we used simulated annealing algorithm to train the BP network the mean square error  5 as the objective function, the problem was converted to the use of simulated annealing algorithm to looking optimal solution of BP network weights W and thresholds B  to make E reaches the minimum the algorithm was described as follows Inp ut training sample set Output the network weights W and thresholds B Algorithm steps Step  1 Initialized a higher temperature T 0 0, and the network weights W and the threshold value B initialized Step  2 For each training sample, loop steps 3 to 8 un til the annealing process termination condition be satisfied, that is T i reduced to a predetermined minimum value Step  3 Calculate the sample mean square error value E Step  4 Use obey Cauchy uniformly distributed random perturbations generate new network weights W   and thresholds B  at this time    which is a random disturbance Step  5 Based on the new network weights W  and the threshold value B  for each sample to recalculate a new mean square error E and the error increment value   Step  6 Use the Metropolis rule to determine whether to accept the new solution: If then accept the new W* and B* as a new network weights and thresholds; otherwise under acceptance probability to determine whether to accept the new solution, set p=random\(0,1 as  0,1  in ter v al u n if o r m ly  distributed random function, if r>p then accept the new Proceedings of 2013 International Conference on Fuzzy Theory and Its App\lication\r\nNational Taiwan University of Science and Technology, Taipei\, Taiwan, Dec. 6-8, 2013\r\n 448 


Proceedings of 2013 International Conference on Fuzzy Theory and Its Application National Taiwan University of Science and Technology, Taipei, Taiwan Dec. 6-8, 201 3 W* and B* as a new network weights and thresholds, or do not accept the new solution Step 7  Loop steps 3 to 7 until the system reaches equilibrium, this time performed Markov chain length  iterations, j Step 8 cooling with cooling schedule T T i 1, T i 1 <T i i  where is a value between 0.8 and 0.9999 Step 9  Used the current solution as the optimal solution, output the network weights W* and threshold value B   D. File activity prediction model Using 2.2 to establish the BP network, and using the simulated annealing algorithm to training, the predictive model is   6  Thereinto, the input weights W  Output weights V= \(0.861 0.492 1.126 -1.189 0.669 0.869 0.776 Input threshold B1  0.673 0.177 -0.237 -0.178 -0.232 0.504 -0.382 Output threshold B2=0.587 III T OWARD E NERGY CONSERVING R EPLICA P LACEMENT M ETHOD  Within the current server, the main power consumption components including CPU hard drive memory fans and power supply unit PDU these components have different working state, corresponding the different power. There are three major states: active state, idle state and sleep state The major hardware components of mainstream server power consumption and powerup latency case in different st ates  22 as shown in Table 1 Table I Hardware component power consumption and powerup-latency in different states A  Zone definition Based on the above analysis the data nodes partitioned into three logic zone the hot zone Hot Zone warm zone \(Warm Zone\ and cold zone \(Cold Zone\, to add Zone file metadata attribute representing the files currently zone, you can set values for the {Hot Warm Cold Each zone used different power management strategy and replication strategy, including 1\ Hot zone Z hot  D hot  This zone stores frequently accessed data the activity of Y> = Threshold hot  R hot  Using Rack-aware data replication policy the default replication is 3 P hot  The nodes were Actived state providing max imum performance and throughput 2\ Warm zone Z warm  D warm  This zone stores greater probability again recently accessed data;Threshold hot Y> = Threshold warm  R warm Using Rack-aware data replication policy, but the default replication is set to 2, the replication reduction can be corresponding increase  disk space utilization P warm The node s were the Idle state, the energy consumption is equal to 58% of Actived state, can return to Actived state within 10 milliseconds after files be accessed, the corresponding node was holding Actived state for some time T warm default 1 hour\ to respond to possible subsequent arrival access, T warm of time without any access then re-enter the Idle state The node transition between the idle state and actived state the main consideration was to wake up around 10 milliseconds state transition latency 3\ Cold zone Z cold  D cold  This zone stores rarely accessed data Threshold warm Y R cold  This zone files d id  not chunking using Rack Aware replica placement strategy, but the replication is set to 2. Regardless of the chunk can guarantee access to files in the zone, only need to activate a node, reducing the replication also improves disk utilization P cold Nodes usually were Slept state, the en ergy equal Actived state 1/30, in about 10 seconds to return to Actived state to maximize energy savings After files be access ed  the corresponding node was holding Actived state for some time T cold  default is 30 minutes to respond to possible subsequent arrival access, T cold of time without any access, then re-enter Slept state Metadata node by detecting heartbeat signals to determine whether the data node is available, but the cold zone node is Slept state, can not send heartbeat, heartbeat de tection method therefore needs to be modified, usually not detect the heartbeat of the zone nodes, only when the node in Actived state, exchanged heartbeat information with the metadata node B  Data Migration Algorithm Research shows that file accessing was sudden load characteristics, most access was concentrated on a certain period of time, while a smaller part of the dispersed Wang et al 23 obtained by experiment that most applications having I/O access burst characteristic and the 65 of the write request focused on a period of time Therefore, in this paper ,at I/O idle time window t \(0:00 am by default\ then the metadata node MDS is relatively idle, the background worker threads read file metadata  then migrated data using the following algorithm Input Z hot Z warm and Z cold metadata Output  Z hot  successfully migrated files C hot  Z warm  H ardware Component  A ctive  Power  W  I dle   Power  W  S leep Power  W  P owerup Latency  CPU  95  15  3  30us  Memory  4  2  0.2  1us  Hard disk  11  9  1  10s  PDU  50  25  0.5  300us  FAN  10  1    Proceedings of 2013 International Conference on Fuzzy Theory and Its App\lication\r\nNational Taiwan University of Science and Technology, Taipei\, Taiwan, Dec. 6-8, 2013\r\n 449 


Proceedings of 2013 International Conference on Fuzzy Theory and Its Application National Taiwan University of Science and Technology, Taipei, Taiwan Dec. 6-8, 201 3 successfully migrated files C warm  Z cold  successfully migrated files C cold   Step  1  Extracted access times creation time last access time, file block number from metadata, the number of files migrated successfully initialized C hot 0, C warm   0, C cold 0 Step  2  Using formula 6 file activity prediction model to calculate next time period of activity of Z hot  Z warm and Z cold zone files Step  3 Joined files of hot zone below the threshold Threshold hot to be migrated list Queue hot Joined files of warm zone below the threshold Threshold warm to be migrated list Queue warm Joined files of warm zone above the threshold Threshold hot  to be migrated list ReverseQueue warm Joined files of cold zone above the threshold Threshold warm to be migrated list ReverseQueue cold  Step  4  Batched migrated Queue hot Queue warm  ReverseQueue warm and ReverseQueue cold files, according the corresponding zone replica placement strategy to place files once file for each migrated successfully the corresponding C hot C warm C cold plus 1 IV E XPERIMENT RESULTS AND ANALYSIS A Experiment environment  In order to validate the replica placement method in this paper, we implemented a set of prototype based on the Hadoop platform, and compared it with unmodified Hadoop  Hadoop which using standard BP neural network and Hadoop which using SA BP neural network in system energy consumption, performance, space utilization hard Life and other aspects Experiment platform was a Hadoop cluster which consisted of 31 servers, the proportion of the number of nodes in each region references the proportion in paper 24  zone division and the hardware configuration of nodes in each zone is shown in Table 2 Table 2  Configuration of Nodes in Each Zone Software Environment operating system is 64 bit CentOS 5.5 \(kernel version 2.6.18\, the original version of Hadoop is 1.0.0, JDK version 1.6.0 B. Experiment results  The comparison in system energy consumption was shown in figure 1 Figure 1: Comparison of energy consumption As we can see from Figure 1, thanks to the low energy consumption in warm zone and cold zone the system's overall energy consumption was reduced by 28 A cluster node that composed of 1,000 nodes of this configuration according to the Beijing electricity price 0.6625 Yuan k W h can save cost about $430000 a year In addition, the equipment energy consumption reducing corresponding will also reduce cooling costs As the number of copies in warm zone and cold zone is lower than traditional way and the lower number of copies also results in a corresponding reduction of the disk space occupied, the prediction model established by simulated annealing BP neural network is more accurate than the standard BP neural network. So the disk space occupancy rate is lower when using simulated annealing BP neural network, the overall disk space utilization increased by 7 The Comparison of space occupied is shown in figure 2 Figure 2: Disk space usage Proportion of number of visits in each zone as shown in figure 3 Figure 3: The proportion of visits in each zone  As can be seen from Figure 3, in the way of standard BP neural network and simulated annealing neural network, more than 96% of the accesses are performed on the hot zone files, the performance impact is negligible, and, because of the division of logical partitions, it can optimize the strategy of hot zone targeted to gain higher throughput; 2.5~3.0% access to warm zone have 10 milliseconds delay; Only 0.42 to 0.62% for cold zone have greater access delay, and for the cold zone file access probability is very low; Moreover, since the simu prediction accuracy rate is higher so the hot zone file access has higher proportion and the warm and cold zones have fewer visits. In general, the improvement way has little impact on the performance for the whole system In the ways of standard BP network and SA BP network, the amount of transfer data between three zones was shown in Figure 4 Zone  N umber  CPU  Memory  Hard  disk  Power  MDS  1  X3430  4G  500G 450  Hot 18  X3430  4G  2T 450  W arm 6  Core i5  2G  2T 270  Cold 6  Core i5  1G  2T 10  Proceedings of 2013 International Conference on Fuzzy Theory and Its App\lication\r\nNational Taiwan University of Science and Technology, Taipei\, Taiwan, Dec. 6-8, 2013\r\n 450 


Proceedings of 2013 International Conference on Fuzzy Theory and Its Application National Taiwan University of Science and Technology, Taipei, Taiwan Dec. 6-8, 201 3 Figure 4: The amount of transfer data between zones  As can be seen from the Figure 4, the average amount of data transferred daily between hot zone with warm zone is 48 GB, and transferred between warm zone with cold zone is 27.2 GB, in the condition of 80MB/s hard disk speed and Gigabit Ethernet network environment, on average, they need 10 minutes and 6 minutes to complete separately, and the network will no t result in a significant effect Under the simulated annealing neural network approach, the improvement of the accuracy of prediction model makes data transfer becomes smoother V  C ONCLUSION  This paper proposes an energy conservation replica placement method ECRP\(Energy Conservation Replica Placement, ECRP\,using simulated annealing BP neural network with self-learning feature, through historical data training to obtained file activity prediction model then predict the activity of the file. This method s essence was based on the data load scheduling, cluster ed files together by heat and thus affect server loads. On the other hand based on the three major levels of energy consumption of hardware components the data node were divided into hot warm and cold three logical zone each zone uses different power management strategies and repli ca placement strategies ,files are stored in the data nodes on different zone according to the type of file activity, and then calculate the file activity periodically, when file activity exceeds a certain threshold the file begins flow among the hot zone warm zone and cold zone step by step in the two-way. Experimental results show that the paper proposed method better use of heterogeneous servers and file life cycle characteristics of the different level of activity better solved the problems of replica pl acement and energy consumption optimization have good energy saving effect. This paper did not depth research the number of nodes ratio in each zone how to effectively divided zone, recommendations for follow-up research R EFERENCES  1  Gantz J, Reinsel D. The digital universe decade:are you ready?[Z   IDC White Paper, 2011 2  Deng zili Topology Design and Hadoop Research in Cloud Computing [D 2009  3  Sun peng Design and Implementation of Multi-Tenancy File Storage System for SaaS Applications[D 2010  4  Dai Xiaolu Research on Replication Management Related Problems in Wide-Area Storage System Based on PZP[D 2007  5  Tel G Introduction to distributed algorithms[M   C a mb r i d g e  university press, 2000 6  Pitoura E, Bhargava B. Maintaining consistency of data in mobile distributed environments: Distributed Computing Systems, 1995 Proceedings of the 15th International Conference on 1995[C   IEEE 7  Liu Tiantian,Li Chao,Hu Qingcheng    Zhang Guigang Multiple-Replicas Management in the Cloud Environment  Journal of Computer Research and Development 2011 48\(z2 632 638  8  Wang W Wei W A Dynamic Replica Placement Mechanism Based on Response Time Measure: Communications and Mobile Computing \(CMC\, 2010 International Conference on, 2010[C   IEEE 9  Wei Q Veeravalli B Gong B et al CDRM A cost-effective dynamic replication management scheme for cloud storage cluster Cluster Computing CLUSTER 2010 IEEE International Conference on, 2010[C   I EEE  10  ZHU Jia-yu,XIAO Dan.Dynamic replication management scheme for cloud computing  C o mp u t e r  En g i n e e r i n g  a n d  D e sign,2012 33\(9 3362 3366  11  Fu wei,Ye qing,Liao wei.A fast QoS-aware replica placement method   JO U R N A L  O F  H U A Z H O N G  U N I V ER S I T Y  O F  SCIENCE AND TECHNOLOGY.NATURE SCIENCE, 2011 39\(12 81 84  12  Agneeswaran V S, Janakiram D Node-capability-aware replica management for peerto peer grids   T r a n s S y s M a n  C y b e r   Part A, 2009,39\(4\:807818  13  Li jinmiao,Yuan shuofeng,Yang dongju.A Dynamic Backup Mechanism Based on the Analysis of User Behavior  M o d e r n  Computer, 2012\(5 18 22  14  ZOU Li-da,LIU Fan-gai,MA Yan. Forecast of access traffic based education resource grid replication strategy  C O M P U T ER  ENGINEERING AND APPLICATIONS 2009 45\(13 103 106, 135  15  Gibson TJ Miller EL Long DDE Long-Term file activity and inter-reference patterns In Proc of the 24  Technology Management and Performance Evaluation of Enterprise  16  Rini T. Kaushik, Milind Bhandarkar. Klara Nahrstedt. Evaluation and Analysis of GreenHDFS A Self-Adaptive Energy Conserving Variant of the Hadoop Distributed File System[C   2010 IEEE 17  Griffioen J Appleton R Reducing file system latency using a predictive approach: Proceedings of USENIX summer Technical Conference, 1994[C   18  Kroeger T M, Long D D. The case for efficient file access pattern modeling: Hot Topics in Operating Systems, 1999. Proceedings of the Seventh Workshop on, 1999[C   I EEE  19  T. Yeh, D. Long, and S. Brandt. Performing File Prediction with a Program-Based Successor Model[C   I n  P r o c e e d i n g s o f  t h e  N i n t h  International Symposium on Modeling, Analysis, and Simulation on Computer and Telecommunication Systems\(MASCOTS 2001  20  Liu Ai-gui and Chen Gang.User-based LAST N Successors file prediction model  C o mp u t e r  En g i n e e r i n g  a n d  A p p l i c a tions.2007,43\(29\:P1416  21  T. Yeh, D. D. E. Long, and S. Brandt. Using Program and User Information to Improve File Prediction Performance[C   I n  P r o ceedings of the International Symposium on Performance Analysis of Systems and Software \(ISPASS\, pages 111 119, 2001 22  David Meisner , Brian T. Gold , Thomas F. Wenisch, PowerNap Eliminating Server Idle Power[C   P r o c e e d i n g s o f  t h e  1 4 t h  i n ternational conference on Architectural support for programming languages and operating systems, 2009, 205216  23  Wang F Xin Q Hong B Brandt SA Miller EL Long DDE Mclarty TT. File system workload analysis for large scale scientific computing applications In Kobler B Hariharan PC eds Proc of the 21st IEEE Conf on Mass Storage Systems and Technologies/12th NASA Goddard Conf. on Mass Storage Sys  24  Rini T. Kaushik, Milind Bhandarkar. GreenHDFS: Towards An Energy-Conserving, Storage Cluster[C   2 0 1 0  Proceedings of 2013 International Conference on Fuzzy Theory and Its App\lication\r\nNational Taiwan University of Science and Technology, Taipei\, Taiwan, Dec. 6-8, 2013\r\n 451 


  Fig. 6.   2 years survivability area under the curve \(AUC ison of 65 attributes, 13 attributes and 13 attributes after S MOTE class balancing Fig. 5.  2 years survivability percentage accuracy comparison of 65 attributes, 13 attributes and 13 attributes after SMOTE clas s balancing 15 


   Fig. 8.   5 years survivability area under the curve \(AUC ison of 65 attributes, 13 attributes and 13 attributes after S MOTE class balancing Fig. 7.  5 years survivability percentage accuracy comparison of 65 attributes, 13 attributes and 13 attributes after SMOTE cla ss balancing 16 


overhead of job initialization in Hadoop is much larger than cNeural VIII C ONCLUSION AND F UTURE W ORK The past several years have witnessed an ever-increasing growth speed of data To address large scale neural network training problems in this paper we proposed a customized parallel computing platform called cNeural Different from many previous studies cNeural is designed and built on perspective of the whole architecture from the distributed storage system at the bottom level to the parallel computing framework and algorithm on the top level Experimental results show that cNeural is able to train neural networks over millions of samples and around 50 times faster than Hadoop with dozens of machines In the future we plan to develop and add more neural network algorithms such as deep belief networks into cNeural in order to make further support training large scale neural networks for various problems Finally with more technical work such as GUI done we would like to make it as a toolbox and open source it A CKNOWLEDGMENT This work is funded in part by China NSF Grants No 61223003 the National High Technology Research and Development Program of China 863 No 2011AA01A202 and the USA Intel Labs University Research Program R EFERENCES  C Bishop Neural networks for pattern recognition  Clarendon press Oxford 1995  J Collins Sailing on an ocean of 0s and 1s  Science  vol 327 no 5972 pp 14551456 2010  S Haykin Neural networks and learning machines  Englewood Cliffs NJ Prentice Hall 2009  R Hecht-Nielsen Theory of the backpropagation neural network in Proc Int Joint Conf on Neural Networks,IJCNN IEEE 1989 pp 593605  Y  Loukas  Arti田ial neural netw orks in liquid chromatography Ef田ient and improved quantitative structure-retention relationship models Journal of Chromatography A  vol 904 pp 119129 2000  N Serbedzija Simulating arti田ial neural netw orks on parallel architectures Computer  vol 29 no 3 pp 5663 1996  M Pethick M Liddle P  W erstein and Z Huang P arallelization of a backpropagation neural network on a cluster computer in Proc Int Conf on parallel and distributed computing and systems PDCS  2003  K Ganeshamoorthy and D Ranasinghe On the performance of parallel neural network implementations on distributed memory architectures in Proc Int Symp on Cluster Computing and the Grid CCGRID  IEEE 2008 pp 9097  S Suresh S Omkar  and V  Mani P arallel implementation of back-propagation algorithm in networks of workstations IEEE Trans Parallel and Distributed Systems  vol 16 no 1 pp 2434 2005  Z Liu H Li and G Miao Mapreduce-based backpropagation neural network over large scale mobile data in Proc Int Conf on Natural Computation ICNC  vol 4 IEEE 2010 pp 17261730  M Glesner and W  P  ochm  uller Neurocomputers an overview of neural networks in VLSI  CRC Press 1994  Y  Bo and W  Xun Research on the performance of grid computing for distributed neural networks International Journal of Computer Science and Netwrok Security  vol 6 no 4 pp 179187 2006  C Chu S Kim Y  Lin Y  Y u  G  Bradski A Ng and K Olukotun Map-reduce for machine learning on multicore Advances in neural information processing systems  vol 19 pp 281288 2007  U Seif fert  Arti田ial neural netw orks on massi v ely parallel computer hardware Neurocomputing  vol 57 pp 135150 2004  D Calv ert and J Guan Distrib uted arti田ial neural netw ork architectures in Proc Int Symp on High Performance Computing Systems and Applications  IEEE 2005 pp 210  H Kharbanda and R Campbell F ast neural netw ork training on general purpose computers in Proc Int Conf on High Performance Computing HiPC  IEEE 2011  U Lotri  c and e a Dobnikar A Parallel implementations of feed-forward neural network using mpi and c on  net platform in Proc Int Conf on Adaptive and Natural Computing Algorithms  Coimbra 2005 pp 534537  Q V  Le R Monga and M e a De vin Building high-le v e l features using large scale unsupervised learning in Proc Int Conf on Machine Learning ICML  ACM 2012 pp 216  J Ekanayak e and H e a Li T wister a runtime for iterati v e mapreduce in Proc of the 19th ACM International Symposium on High Performance Distributed Computing  ACM 2010 pp 810818  Y  Bu B Ho we M Balazinska and M D Ernst Haloop Ef田ient iterative data processing on large clusters Proc of the VLDB Endowment  vol 3 no 1-2 pp 285296 2010  M Zaharia M Cho wdhury  T  Das A Da v e  J  Ma M McCauley M Franklin S Shenker and I Stoica Resilient distributed datasets A fault-tolerant abstraction for in-memory cluster computing in Proc USENIX Conf on Networked Systems Design and Implementation  USENIX Association 2012 pp 216 384 


Figure 15  3D model of the patio test site Figure 16  Model of the patio test site combining 2D map data with 3D model data a Largest explored area b Smallest explored area Figure 14  Maps built by a pair of 2D mapping robots Yellow indicates area seen by both robots Magenta indicates area seen by one robot and Cyan represents area seen by the other a 3D point cloud built of the patio environment Figure 16 shows a model built combining 2D map data with 3D model data A four-robot mission scenario experiment was conducted at the mock-cave test site This included two 2D mapping robots a 3D modeling robot and a science sampling robot There was no time limit on the run Figure 17 shows a 3D model of the tunnel at the mock cave Figure 18 shows a model built combining 2D map data with 3D model data 7 C ONCLUSIONS  F UTURE W ORK The multi-robot coordination framework presented in this paper has been demonstrated to work for planetary cave mission scenarios where robots must explore model and take science samples Toward that end two coordination strategies have been implemented centralized and distributed Further a core communication framework has been outlined to enable a distributed heterogenous team of robots to actively communicate with each other and the base station and provide an online map of the explored region An operator interface has been designed to give the scientist enhanced situational awareness collating and merging information from all the different robots Finally techniques have been developed for post processing data to build 2  3-D models of the world that give a more accurate description of the explored space Fifteen 2D mapping runs with 2 robots were conducted The average coverage over all runs was 67 of total explorable area Maps from multiple robots have been merged and combined with 3D models for two test sites Despite these encouraging results several aspects have been identi\002ed that can be enhanced Given the short mission durations and small team of robots in the experiments conducted a simple path-to-goal costing metric was suf\002cient To use this system for more complex exploration and sampling missions there is a need for learning-based costing metrics Additional costing parameters have already been identi\002ed and analyzed for future implementation over the course of this study One of the allocation mechanisms in this study was a distributed system however task generation remained centralized through the operator interface In an ideal system robots would have the capability to generate and auction tasks based on interesting features they encounter Lastly the N P complete scheduling problem was approximated during task generation However better results could potentially 10 


Figure 17  3D model of the tunnel in the mock cave test site Figure 18  Model of the mock cave test site combining 2D map data with 3D model data be obtained by releasing this responsibility to the individual robots A CKNOWLEDGMENTS The authors thank the NASA STTR program for funding this project They would also like to thank Paul Scerri and the rCommerceLab at Carnegie Mellon University for lending hardware and robots for this research R EFERENCES  J C W erk er  S M W elch S L Thompson B Sprungman V Hildreth-Werker and R D Frederick 223Extraterrestrial caves Science habitat and resources a niac phase i study\\224 NASA Innovative Advanced Concepts NIAC Tech Rep 2003  G Cushing T  T itus and E Maclennan 223Orbital obser vations of Martian cave-entrance candidates,\224 in First Intl Planetary Caves Workshop  Carlsbad NM 2011  J W  Ashle y  M S Robinson B R Ha wk e A K Boyd R V Wagner E J Speyerer H Hiesinger and C H van der Bogert 223Lunar caves in mare deposits imaged by the LROC narrow angle camera,\224 in First Intl Planetary Caves Workshop  Carlsbad NM 2011  J W  Ashle y  A K Bo yd H Hiesinger  M S Robinson T Tran C H van der Bogert and LROC Science Team 223Lunar pits Sublunarean voids and the nature of mare emplacement,\224 in LPSC  The Woodlands,TX 2011  S Dubo wsk y  K Iagnemma and P  J Boston 223Microbots for large-scale planetary surface and subsurface exploration niac phase i.\224 NASA Innovative Advanced Concepts NIAC Tech Rep 2006  S Dubo wsk y  J Plante and P  Boston 223Lo w cost micro exploration robots for search and rescue in rough terrain,\224 in IEEE International Workshop on Safety Security and Rescue Robotics Gaithersburg MD  2006  S B K esner  223Mobility feasibility study of fuel cell powered hopping robots for space exploration,\224 Master's thesis Massachusetts Institute of Technology 2007  M T ambe D Pynadath and N Chauv at 223Building dynamic agent organizations in cyberspace,\224 IEEE Internet Computing  vol 4 no 2 pp 65\22673 March 2000  W  Sheng Q Y ang J T an and N Xi 223Distrib uted multi-robot coordination in area exploration,\224 Robot Auton Syst  vol 54 no 12 pp 945\226955 Dec 2006  A v ailable http://dx.doi.or g/10.1016/j.robot 2006.06.003  B Bro wning J Bruce M Bo wling and M M V eloso 223Stp Skills tactics and plays for multi-robot control in adversarial environments,\224 IEEE Journal of Control and Systems Engineering  2004  B P  Gerk e y and M J Mataric 223 A formal analysis and taxonomy of task allocation in multi-robot systems,\224 The International Journal of Robotics Research  vol 23 no 9 pp 939\226954 September 2004  M K oes I Nourbakhsh and K Sycara 223Heterogeneous multirobot coordination with spatial and temporal constraints,\224 in Proceedings of the Twentieth National Conference on Arti\002cial Intelligence AAAI  AAAI Press June 2005 pp 1292\2261297  M K oes K Sycara and I Nourbakhsh 223 A constraint optimization framework for fractured robot teams,\224 in AAMAS 06 Proceedings of the 002fth international joint conference on Autonomous agents and multiagent sys11 


tems  New York NY USA ACM 2006 pp 491\226493  M B Dias B Ghanem and A Stentz 223Impro ving cost estimation in market-based coordination of a distributed sensing task.\224 in IROS  IEEE 2005 pp 3972\2263977  M B Dias B Bro wning M M V eloso and A Stentz 223Dynamic heterogeneous robot teams engaged in adversarial tasks,\224 Tech Rep CMU-RI-TR-05-14 2005 technical report CMU-RI-05-14  S Thrun W  Bur g ard and D F ox Probabilistic Robotics Intelligent Robotics and Autonomous Agents  The MIT Press 2005 ch 9 pp 222\226236  H Mora v ec and A E Elfes 223High resolution maps from wide angle sonar,\224 in Proceedings of the 1985 IEEE International Conference on Robotics and Automation  March 1985  M Yguel O A ycard and C Laugier  223Update polic y of dense maps Ef\002cient algorithms and sparse representation,\224 in Intl Conf on Field and Service Robotics  2007  J.-P  Laumond 223T rajectories for mobile robots with kinematic and environment constraints.\224 in Proceedings International Conference on Intelligent Autonomous Systems  1986 pp 346\226354  T  Kanungo D Mount N Netan yahu C Piatk o R Silverman and A Wu 223An ef\002cient k-means clustering algorithm analysis and implementation,\224 IEEE Transactions on Pattern Analysis and Machine Intelligence  vol 24 2002  D J Rosenkrantz R E Stearns and P  M Le wis 223 An analysis of several heuristics for the traveling salesman problem,\224 SIAM Journal on Computing  Sept 1977  P  Scerri A F arinelli S Okamoto and M T ambe 223T oken approach for role allocation in extreme teams analysis and experimental evaluation,\224 in Enabling Technologies Infrastructure for Collaborative Enterprises  2004  M B Dias D Goldber g and A T  Stentz 223Mark etbased multirobot coordination for complex space applications,\224 in The 7th International Symposium on Arti\002cial Intelligence Robotics and Automation in Space  May 2003  G Grisetti C Stachniss and W  Bur g ard 223Impro ving grid-based slam with rao-blackwellized particle 002lters by adaptive proposals and selective resampling,\224 in Proceedings of the IEEE International Conference on Robotics and Automation  2005  227\227 223Impro v ed techniques for grid mapping with raoblackwellized particle 002lters,\224 IEEE Transactions on Robotics  2006  A Geiger  P  Lenz and R Urtasun 223 Are we ready for autonomous driving the kitti vision benchmark suite,\224 in Computer Vision and Pattern Recognition CVPR  Providence USA June 2012  A N 250 uchter H Surmann K Lingemann J Hertzberg and S Thrun 2236d slam with an application to autonomous mine mapping,\224 in Proceedings of the IEEE International Conference on Robotics and Automation  2004 pp 1998\2262003  D Simon M Hebert and T  Kanade 223Real-time 3-d pose estimation using a high-speed range sensor,\224 in Proceedings of the IEEE International Conference on Robotics and Automation  1994 pp 2235\2262241 B IOGRAPHY  Ammar Husain received his B.S in Mechanical Engineering Robotics from the University of Illinois at Urbana-Champaign He is pursuing an M.S in Robotic Systems Development at Carnegie Mellon University He has previously worked on the guidance and control of autonomous aerial vehicles His research interests lie in the 002eld of perception-based planning Heather Jones received her B.S in Engineering and B.A in Computer Science from Swarthmore College in 2006 She analyzed operations for the Canadian robotic arm on the International Space Station while working at the NASA Johnson Space Center She is pursuing a PhD in Robotics at Carnegie Mellon University where she researches reconnaissance exploration and modeling of planetary caves Balajee Kannan received a B.E in Computer Science from the University of Madras and a B.E in Computer Engineering from the Sathyabama Institute of Science and technology He earned his PhD from the University of TennesseeKnoxville He served as a Project Scientist at Carnegie Mellon University and is currently working at GE as a Senior Cyber Physical Systems Architect Uland Wong received a B.S and M.S in Electrical and Computer Engineering and an M.S and PhD in Robotics all from Carnegie Mellon University He currently works at Carnegie Mellon as a Project Scientist His research lies at the intersection of physics-based vision and 002eld robotics Tiago Pimentel Tiago Pimentel is pursuing a B.E in Mechatronics at Universidade de Braslia Brazil As a summer scholar at Carnegie Mellon Universitys Robotics Institute he researched on multi-robots exploration His research interests lie in decision making and mobile robots Sarah Tang is currently a senior pursuing a B.S degree in Mechanical and Aerospace Engineering at Princeton University As a summer scholar at Carnegie Mellon University's Robotics Institute she researched multi-robot coordination Her research interests are in control and coordination for robot teams 12 


Shreyansh Daftry is pursuing a B.E in Electronics and Communication from Manipal Institute of Technology India As a summer scholar at Robotics Institute Carnegie Mellon University he researched on sensor fusion and 3D modeling of sub-surface planetary caves His research interests lie at the intersection of Field Robotics and Computer Vision Steven Huber received a B.S in Mechanical Engineering and an M.S in Robotics from Carnegie Mellon University He is curently Director of Structures and Mechanisms and Director of Business Development at Astrobotic Technology where he leads several NASA contracts William 223Red\224 L Whittaker received his B.S from Princeton University and his M.S and PhD from Carnegie Mellon University He is a University Professor and Director of the Field Robotics Center at Carnegie Mellon Red is a member of the National Academy of Engineering and a Fellow of the American Association for Arti\002cial Intelligence 13 


