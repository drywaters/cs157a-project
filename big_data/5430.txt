Research and Improvement of Apriori Algorithm for Association Rules  Chengyu?Xiongying School of Computer dept Hubei University of Technology Wuhan ,China chengyu125@126.com  AbstractWith the development and the wide application of DBMS, large-scale database system is popularized in daily life Data mining is a process of fetching valuable or important information from magnanimous database. Association rules mining is one important research topic of data mining area Above all most important of all is research on increment association rules mining. In order to renew association rules effectively, the paper introduces the idea of Apriori algorithm meanwhile it has already analyzed the classic association rule algorithm FUP and IUA, it pointing out its advantages and disadvantages. Finally, it also gives narrative to another improved NIUP and NFUP algorithm. NFUP algorithm joins strong large itemsets into small quantitative of candidate itemsets based on strong large itemsets concept, and adopts early pruning strategy to cut down the times of scanning database Keyword Data mining; Association rule; Apriori algorithm Frequent item sets; Fast Update\(FUP I.  INTRODUCTION The association rule reflects the related relationship between the database and data item, frequent items are found in association rule mining applications in key technologies and procedures. People have done a lot of research on frequently items mining algorithm, Apriori[1] algorithm by R. Agrawal which is the most influential and representative. The presentation of these algorithms is the minimum support for mining database and carried out under the same conditions However, as time goes on, mining the size of the database may be swelling or need to remove part of the records. Therefore how to renew the association update rule from the changed data of the database efficiently has a very important value, which called incremental mining association rules II. ASSOCIATION RULE AND APRIORI CORE ALGORITHM A. Description of Association rule 


The description of the problem: Set I={i1?i2?...?im is a collection of m different projects, given a transaction database D, each transaction T in which D is a group of items I set, that is T I, T has a unique identifier TID. If X is a subset of I, and X T, we call a transaction T contains X. An association rule is a implicate of the X=>Y, in which X,Y T and X?Y=?. The conditions of association rules are set up according to: it has a minimum supports, that is, in transaction database D, there are at least s% of the services included in XY; it has minimal credibility c, that is, in the transaction database D contains c% of X affairs, also containing Y. Given a transaction sets D, the issue of mining association rules is that have support and confidence given by the user, respectively, greater than the minimum support and minimum confidence of association rules, in other words generate a strong rules. Mining association rules can be broken down into the following two questions Identify the smallest degree items supported by all users in database, which is called frequent items constantly, referred as non-frequent items. The number of projects of a project contained is known as the length of the project The use of frequent items generate association rule For each frequent items A, if the B A, B??, and support\(A B rules B=>\(A-B on the first question above B. Apriori core algorithm Agrawal sets an important way\(Apriori algorithm can make a customer transaction database mining of association rule in 1994. Its core is based on two-stage recursive algorithm of frequent items thinking. Algorithms basic idea is to identify all the frequent sets whose emerging is same as predefined minimum support at least. Frequent item generates strong association rule, which must satisfy minimum support and minimum confidence. Apriori ideas is a brief description of the core algorithm is that algorithm has two key steps: connecting step and the pruning step Connecting step: In order to identify the Lk \(a frequent k set CK Lk-1 and its connections, which elements of Lk-1 can be connected 


Pruning step: Ck is a superset of Lk whose members may or may not be frequent, but all the frequent sets are included in Ck. If scanning database, each count of a candidate in Ck can be determined, also Lk\(frequent candidates whose count is not less than the minimum support count calculation amount also be lots. For compression of Ck, the Apriori may be used: any non-frequent \(k-1 978-1-4244-5874-5/10/$26.00 2010 IEEE items can be not subsets of frequent k-items Therefore, if \(k-1 in Lk, then the candidate can not be frequent, which can be deleted from Ck. This test of subsets can be finished rapidly by using all frequent items of the hash tree This approach requires repeated scanning the large transaction database, that is, if the frequent items include no more than 20 items, then scanning the transaction database 20 times may be needed, that requires a lot of I/O load. It may generate a large number of candidate sets and need to repeat to scan database, which is the two major shortcomings in Apriori algorithm III. INCREMENTAL UPDATE OF ASSOCIATION RULE The association rule reflects the related relationship among the data of database, of which discovering frequent items for mining association rule is the key technology and steps. People has done a lot of research on frequently items mining algorithm, such as Apriori, AprioriTid algorithm by R Agrawal which are the most influential and representative ones. The ways of Algorithm is offered in the same conditions of smallest in the mining database and supports. However, it may be encountered in practice, the size of the database mining is ever-expanding over time or remove the part of record otherwise it need to adjust the minimum support in order to gather gradually in the interested frequent items. Therefore how to update the derived association rules from new database is a very important, that is the so-called incremental mining association rules Generalized association rule on the issue is the problem to mine new association rule based new DB which can be generated through plus \(or minus original database DB. Association Rules of incremental 


updating has three main issues: given minimum support and minimum confidence level, how to generate the dbDB link rules when a new data sets add to the old DB database; given minimum support and minimum confidence level, how to generate the DB-db association rules when delete data sets from the old database db; given database DB, how to generate a database of association rules in DB when the minimum supports and degree of changed. Two of the more classic algorithm are as follows: FUP and IUA algorithm A. The basic idea of FUP algorithm For any k\(k?1 items, they must be frequent items; if its DB and db are nonfrequent items, then they are certain non - frequent items; if it is a frequent items only in the DB\(db be added to the support of db\(DB whether it is the frequent items. FUP[2] algorithm assumptions has been preserved in the found DB frequent items LiL U ni 1== \(n is number of the largest element of L of elements first scanning, the algorithm scans db at first, the L1 in the dbDB is still credited element L1 in frequent items, and generates a candidate frequent sets C1, whose element for the frequent does not contain in the L1; then scanned DB to determine whether the C1 is the frequent items in the dbDB and credited element belong to dbDB frequent items to L1 Before kth\(k>1 frequent k items Ck by Apriori_Gen function, and remove the element of Lk, that is, Ck=Ck-Lk, pruning Lk, which matching with X Lk,. If it exists  & Y Lk-1 Lk-1, then X is certainly not frequent k items of the dbDB, it should be deleted in Lk; then scan db, credited remained frequent items of Lk belong to dbDB to Lk', recording support number of Ck in the db; finally scanning DB, records support number of the elements of Ck in DB. When finished scanning, credited element of frequent items of dbDB in Ck to Lk. Algorithm will be finished when Lk and Ck are space-time Function Analysis: FUP algorithm using mining results of the original database, i.e. frequent items L, nth scans to DB and db, and finally gets frequent items L of DBdb, so the efficiency of algorithm FUP is much higher than DHP algorithm and Apriori algorithm. However, FUP algorithm has its disadvantages, although this algorithm uses mining results 


of the original database sets DB, but when renewing the database, need to repeat scanning the original database DB matching the candidates, so we will spend a lot of time to deal with the enormous size of the candidates, a waste of time when updating in the association rules of FUP algorithm B. the basic idea of IUA algorithm IUA[3] algorithm uses a unique candidate frequent itemset to generate algorithm iua_gen, that generates smaller frequent items before scanning the DB for each time, thereby enhancing the efficiency of the algorithm. It also requires frequent items i n i lUl 1==  mined DB in the last time can be used in this time. Because of the discovery of association rules it is need to adjust constantly the minimum support and minimum confidence to gather interest in association rules, the result of the algorithm has very important significance. The basic framework of the IUA algorithm is same as Apriori algorithm, need for multi-times scanning database DB scan Because of s' <s, all the frequent k items \(Lk minimum support is still frequent items k. Therefore, every time to scan the transaction database D to calculate support count of k candidate items, it would not be necessary to consider again candidate k items of the corresponding Lk. If wish to avoid re-generating the corresponding k candidate items again, we can consider the adoption of a strategy for time against space, as long as preserve \(Ck-Lk algorithm each time. According to this characteristic, IUA algorithm will have divided a new support s' of all frequent k\(k?2 c=\(i1, i2,..., ik 1?j?k ij frequent k items c=\(i1, i2,...,ik 1?j?k ij For each frequent k items c=\(i1, i2,...,ik non-empty subsets c1 and c2, making c1c2=c, c1?c2=?, and c1<L1, c2 <L1". In search of bottom-up process of IUA, kth frequent items generate \(k+1 items, and then calculate degree of support for the candidate frequent items to obtain its frequent items until it is empty Function analysis:  IUA algorithm, same as Apriori algorithm, use primarily the "any non-empty items of one frequent items must be frequent items". According to this nature, for any item i, if i is not any one of j\(j<k 


items, then i must not be element of k-items. In the IUA algorithm step-by-step cycle, each function called an iua_gen through the splicing function will obviously not have been the frequent k-items of k-Project integration for the candidate kitems C3k elements, which increase computing capacity to iua_gen pruning, as well as the time complexity of algorithm In association rule updating, for the k-items mining, IUA algorithm noted that the frequent use of the existence of kitems collection Lk, being not aware of " any non-empty items of one frequent items must be frequent items ", the new arising from the frequent \(k-1 to be used. IUA has been due to take full advantage of the mining results and the use of an effective candidate frequent items generation method, and the adoption of a strategy for time in space, because this significantly reduces the candidate at all levels of frequent items, which improve the association rules update efficiency. Because of the limitations of Apriori framework, the main existing drawback is as follows: many times scanning to the database, and a large number of candidates to be needed IV. NIUA ALGORITHM AND NFUP ALGORITHM A. NIUA algorithm The basic framework of NIUA algorithm is the same as the IUA agreement algorithm and Apriori algorithm, for k=1,2 m, a strategy used to generate candidate k-items Ck, and Ck is to scan the database to determine which k-items are frequent items. The difference between NIUA algorithm and the traditional incremental updating algorithm is as in follows because s' <s, so all the old minimum s of frequent kitems in the new minimum s' is still under frequent kitems. Therefore, in scanning the database D for each visit to calculate the candidate k-items the support of a few hours, there is no need for the project Lk again NIUA algorithm in generating candidate k-items Ck is not including items Lk When NIUA algorithm generates candidate k-items Ck not only use the existing frequent k-items Lk, but also fully uses new \(k-1 IUA algorithm, NIUA algorithms make good use of the apriori-gen function, repeating the original approach of Lk-1, so NIUA compared with Apriori algorithm has only a limited improved efficiency 


B.  NFUP algorithm The basic idea of NFUP algorithm is similar to the FUP algorithm. Their difference is shown in follows: FUP algorithm using the original database to set DB mining results, that is frequent items Ls need for DB and db scan for n times, getting final frequent items L' of DBdb; And algorithm NFUP just scan DB for one time and db for several times. NFUP algorithm can improve efficiency by less scanning to DB's I/O operations. Apriori algorithm for db verifies whether the elements of L is he frequent item of dbDB, and generates the frequent items Ldb, then verifies whether elements of Ldb is the frequent items of dbDB through scanning of DB However, the premise of NFUP algorithm is frequent items known metadata DB and the support of elements Therefore, the theoretical NFUP efficiency is far more than that of FUP. In order to compare the two algorithms, the actual operation comparison will be shown in below. Hardware environment: the CPU is Intel p4 2.4 GHz; memory is DDR 1.0 GB. Software environment: Windows 2000 Server operation system, a programming language is Matlab 7.1. The original data DB exist in Boolean matrix form, which is nine project including 10 000 record. The new data base has 500 records \(about 850 KB and FUP is shown in figure 1, minimum support degree in the 20 percent and 80 percent    Figure 1 The comparison of the execution time among same database algorithms From figure 1, for the same database and support circumstances, the execution time of NFUP algorithm is reduced by 50% than FUP algorithm. NFUP algorithm is much fast than FUP algorithm when the support degree in 0.2 and 0.6 V.  CONCLUSIONS Now some algorithm of some existing frequent items has some missed questions, such as many candidate items, big space. The algorithm may reduce the mining efficiency when increasing scan db frequent items. Although algorithm is simple, its process carries on more effective pruning. This paper brings in some knowledge about association rule 


especially discussing the classic association rule of algorithm and mainly pointing out the analysis and conclusion of the FUP Minimum support degree The execution tim e\(in seconds and the IUA. Also two improved algorithm have been discussed in order to help the study of negative association rules for incremental updating   REFERENCES 1] Agrawal R.Srikant R. Fast algorithms for mining association rules in large database [A]. Proceedings of the 1994 International Conference on VLDB [C ]. San Francisco ?  Morgan Kaufmann Publishers 1994.pp487- 499 2] BrinS ? MotwaniR ? SilversteinC..Beyondmarket ? Generalizing association rules tocorrelations [A]. Processing of the ACMSIGMOD Conference 1997[C]. NewYork?ACMPress?1997. 265?276 3]  Hao Xincheng, Zhang Degang, Zhao Hai: E-commerce data mining research. Small Micro-computer Science[J], 2007\(7 4] HUANG De-cai, ZHANG Liang-yan, GONG Wei-hua, LIU Duan-yang Improved Incremental Updating Algorithm for Association Rules. The computer engineering[J], 2008\(5 in Chinese 5] Zhao Huanping: Web data mining and its application in e-commerce Fujian Computer [J].2008 \(1 in Chinese 6] Shi Yan: Applications of web mining techniques in e-commerce Scientific and Technological Information and Economic Development J] 2006 \(7 in Chinese 7] Ling Chuan-Fan: Web mining techniques applications in e-commerce Intelligence Journal [J] 2008 \(1 8] Witten I H?Frank E?Data Mining?Practical Machine LearningTools and Techniques[M]?2005 9] Margarent H?Dunham . Data Mining: A Tutorial-Based Primer  2005 10] J.B. Schafer, J.A. Konstan, and J.Rie1, Recommender Systems in ECommerce. In ACM Conference on Electronic Commerce \(EC99 11] YooJS,Shekhars,ClikM,A Join-less approach for co-location pattern miniing:a summary of rssults. Proceedings of the IEEE International Conference on Data Mining\(ICDM   


0 1 2 3 4 5 2 3 4 5 6 average error\(distance MinTs STT HPM a Prediction performance comparison 0 200 400 600 800 1000 1200 1400 2 3 4 5 6 storage size\(MB MinTs STT HPM b Storage requirements comparison Fig 9 Prediction model comparison DBSCAN clustering may result in clusters of arbitrary shapes and sizes while the error of STT is restricted by the 003xed cell size C Storage Requirements Comparison We next study the storage requirements comparison of STT with HPM As expected Figure 9\(b demonstrates that our method has smaller storage size than HPM While the storage size of HPM dramatically grows with the number of frequent regions increases our method STT still remains the small storage size with tiny changes The reason is that HPM using association rule based patterns generates the exponential number of rules as the number of frequent regions increases On the contrary STT using data structure of suf\003x tree can compress the number of sequential patterns into a compact model D Sensitivity Analysis of Parameters In this section we examine the effect of cell size and MinTs to our model and prediction Figure 11 presents the experimental results with cell size varied The number of trajectory patterns decreases dramatically as the value of cell size grows Furthermore the prediction error affected by cell size is provided in Figure 11 The prediction error potentially rises as the cell size increases We also investigate the effect of MinTs  In our de\003nition a frequent region is decided by MinTs number of trajectories pass the region in a cell size Therefore a high value of 0 2000 4000 6000 8000 10000 12000 0.006 0.009 0.012 0.015 0.018 0.021 0.024 0.027 number of patterns cell size a Car 0 2000 4000 6000 8000 10000 12000 0.006 0.009 0.012 0.015 0.018 0.021 0.024 0.027 number of patterns cell size b Bike 0 50 100 150 200 250 300 0.006 0.009 0.012 0.015 0.018 0.021 0.024 0.027 number of patterns cell size c Run 0 200 400 600 800 1000 0.006 0.009 0.012 0.015 0.018 0.021 0.024 0.027 number of patterns cell size d Walk Fig 10 Effect of cell size on number of patterns 0.6 1 1.4 1.8 2.2 2.6 3 0.006 0.009 0.012 0.015 0.018 0.021 0.024 0.027 average error\(distance cell size a Car 0.6 1 1.4 1.8 2.2 2.6 3 0.006 0.009 0.012 0.015 0.018 0.021 0.024 0.027 average error \(distance cell size b Bike 0.6 0.8 1 1.2 1.4 1.6 1.8 0.006 0.009 0.012 0.015 0.018 0.021 0.024 0.027 average error\(distance cell size c Run 1.2 1.4 1.6 1.8 2 2.2 0.006 0.009 0.012 0.015 0.018 0.021 0.024 0.027 average error\(distance cell size d Walk Fig 11 Effect of cell size on prediction error MinTs may cause a small number of frequent regions and trajectory patterns Prediction based on trajectory patterns could be affected by MinTs  As the results shown in Figure 12 the number of trajectory patterns is reduced as the number of MinTs increases The prediction error increases signi\003cantly due to the small number of trajectory patterns as shown in Figure 13 VII C ONCLUSION In this paper we presented a pattern-based approach to predict an objects future locations We not only focus on that how to discover frequent movement patterns and manage these patterns to answer predictive queries but also aim to propose 
60 
66 
66 


0 500 1000 1500 2000 2500 3000 3500 2 4 6 8 10 number of patterns MinTs a Car 0 500 1000 1500 2000 2500 3000 3500 2 4 6 8 10 number of patterns MinTs b Bike 0 500 1000 1500 2000 2500 3000 3500 2 4 6 8 10 number of patterns MinTs c Run 0 500 1000 1500 2000 2500 3000 3500 2 4 6 8 10 number of patterns MinTs d Walk Fig 12 Effect of MinTs on number of patterns 0.6 1 1.4 1.8 2.2 2.6 3 2 4 6 8 10 average error\(distance MinTs a Car 0.6 1 1.4 1.8 2.2 2.6 3 2 4 6 8 10 average error\(distance MinTs b Bike 0.6 1 1.4 1.8 2.2 2.6 3 2 4 6 8 10 average error\(distance MinTs c Run 0.6 1 1.4 1.8 2.2 2.6 3 2 4 6 8 10 average error\(distance MinTs d Walk Fig 13 Effect of MinTs on prediction error a model that can reduce the pattern storage size To achieve this idea we propose a spatial-temporal trajectory model to capture an objects moving behavior and STT model could be a predictor to forecast its future locations Experimental results show that the STT model is able to re\002ect an objects moving behavior with a smaller storage size compared to existing patten-based approaches while still guaranteeing the accuracy of location prediction Acknowledgments Wen-Chih Peng was supported in part by the National Science Council Project No 97-2221-E009-053-MY3 by Taiwan MoE ATU Program by ITRIJRC Project No 100-EC-17-A-05-01-0626 by D-Link and by Microsoft R EFERENCES  H Jeung Q Liu H T  Shen and X Zhou A Hybrid Prediction Model for Moving Objects in Proc of ICDE  2008 pp 70…79  A Monreale F  Pinelli R T r asarti and F  Giannotti Wherene xt a location predictor on trajectory pattern mining in Proc of KDD  2009 pp 637…646  M Morzy   Mining frequent trajectories of mo ving objects for location prediction in Proc of MLDM  2007 pp 667…680  W C Peng Y  Z K o  a nd W  C Lee On Mining Mo ving P atterns for Object Tracking Sensor Networks in Proc of MDM  2006 pp 41…44  N Mamoulis H Cao G K ollios M Hadjieleftheriou Y  T ao and D W  Cheung Mining Indexing and Querying Historical Spatiotemporal Data in Proc of KDD  2004 pp 236…245  C.-W  C  C.-C Hung and W C Peng Mining trajectory pro\003les for discovering user communities in Proc of GIS-LBSN  2009 pp 1…8  J Krumm and E Horvitz Predestination Inferring destinations from partial trajectories in Proc of UbiComp  2006 pp 243…260  F  Giannotti M Nanni F  Pinelli and D Pedreschi T rajectory P attern Mining in Proc of KDD  2007 pp 330…339  T  Guyet and R Quiniou Mining temporal patterns with quantitati v e intervals in Proc of ICDM Workshops  2008 pp 218…227  F  V e rhein k-ST ARs Sequences of Spatio-T emporal Association Rules in Proc of ICDM Workshops  2006 pp 387…394  F  V e rhein and S Cha wla Mining spatio-temporal association rules sources sinks stationary regions and thoroughfares in object mobility databases in Proc of DASFAA  2006 pp 187…201  H Jeung H T  Shen and X Zhou Mining T rajectory P atterns Using Hidden Markov Models in Proc of DaWaK  2007 pp 470…480  Y  Ishika w a  Y  T sukamoto and H Kitaga w a   Extracting mobility statistics from indexed spatio-temporal datasets in Proc of STDBM  2004 pp 9…16  H.-P  T sai D.-N Y ang W  C Peng and M.-S Chen Exploring Group Moving Pattern for an Energy-Constrained Object Tracking Sensor Network in Proc of PAKDD  2007 pp 825…832  H Cao N Mamoulis and D W  Cheung Mining Frequent SpatioTemporal Sequential Patterns in Proc of ICDM  2005 pp 82…89  F  Giannotti M Nanni and D Pedreschi Ef 003cient Mining of T emporally Annotated Sequences in Proc of SDM  2006 pp 593…597  A Hinneb ur g and D A K eim  A n e f 003 cient approach to clustering in large multimedia databases with noise in Proc of KDD  1998 pp 58…65  P  Sun S Cha wla and B Arunasalam Mining for outliers in sequential databases in Proc of SDM  2006  J Y a ng and W  W ang  A gile A General Approach T o Detect T r ansitions In Evovling Data Streams in Proc of ICDM  2004 pp 559…562  G Bejerano and G Y ona Modeling protein f a milies using probabilistic suf\003x trees in Proc of RECOMB  1999 pp 15…24  D Ron Y  Singer  and N T ishby  The Po wer o f Amnesia Learning Probabilistic Automata with Variable Memory Length Machine Learning  vol 25 no 2-3 pp 117…149 1996  B Ostle and L Malone Statistics in research basic concepts and techniques for research workers  Iowa State Press 1988  C.-H Lo W  C Peng C.-W  C hen T  Y  Lin and C.-S Lin CarW eb A Traf\003c Data Collection Platform in Proc of MDM  2008 pp 221 222 
61 
67 
67 


i?{i? |?R?Rel R\(f,i i ratioocc\(u, i 1 2 where ratioocc\(u, i instance i among the instances of the same concept in the users history D. Frequency Module This module aims at detecting the frequent instances and the frequent associations of instances. Indeed, such a frequency depicts an important interest of the user for the concerned instances. Consequently, it is relevant to recommend items with these characteristics to the user 1 considers the profile of the user. It aims at detecting the most important features of interest for the user Regardless of the estimated interest of an instance for a user, we consider that if the user has in his history a significant percentage of items which have as a feature that particular instance, the interest of this instance is significant Unlike the previous computation, this computation ignores the users ratings for the items which have the instance as a feature Example: A user who has watched 80% of the films interpreted by the actor Tom Hanks should get the recommendation of the other 20% he has not seen even if some of the films of Tom Hanks in his history are badly rated 2 case with frequent instances described above, this part of the module deals not only with the profile of the user, but also with the set of items. It aims at discovering frequent associations between the features in the user history. It detects the features that often occur together in order to discover new recommendations. To achieve this, frequent sets of the instances related to the items in the users history are computed. Then, items with such instances are recommended to the user Example: A possible frequent association is the actor Johnny Depp and the director Tim Burton. A user who is interested in these two instances will be recommended the other films related to them E. Recommendation and explanation 


As explained in Sect. II, the collaborative and the semantic modules are in cascade. Consequently, the result is a set of recommendations rec1 which is mixed with the recommendations of the frequency module rec2 such that rec1 is presented before rec2 to the user. This order can be inverted according to user feedback. Concerning the explanation of the recommendations, this is done by highlighting the instances which have highly scored the interest of the user for the items of rec1, and by highlighting the frequent instances in the items of rec2 F. Example In this section, we illustrate the recommendation process for any user u, in the movie domain. We will simplify to preserve the clarity of the example 2010 10th International Conference on Intelligent Systems Design and Applications 473 Table I EXTRACT OF THE PROFILE OF THE USER u Film Rating Transformation Psycho 5 Psychol Rear Window 4 Rear Windowl Four Weddings and a Funeral 4 Four Weddings and a Funerall Monty Pythons Life of Brian 5 Monty Pythons Life of Brianl Carrie 3 Carried Stephen Kings The Langoliers 1 Stephen Kings The Langoliersd Pulp Fiction 4 Pulp Fictionl Dr. Strangelove 2 Dr. Strangeloved A Clockwork Orange 1 A Clockwork Oranged Let us consider u who has rated the movies in Tab. I Collaborative Filtering Module: Let us assume that the association rule mining result is r1 : {Psychol, Pulp Fictionl} ? {The Shiningl r2 : {Pulp Fictionl,Monty Pythons Life of Brianl Monty Python and the Holy Graill r3 : {Monty Python and the Holy Graill, Jurassic Parkl Indiana Jones and the Last Crusadel According to the rules introduced in Sect III-B2, we only keep the association rules r1 and r2 Semantic-Based Module: In this step, the interest of the user for each movie in the head of each rule from the last module is computed. The concerned movies are The Shining and Monty Python and the Holy Grail For The Shining, we obtain the following interest re 


sults conceptInterestActor \(u, TheShining conceptInterestDirector \(u, TheShining conceptInterestWriter \(u, TheShining conceptInterestGenre \(u, TheShining Unlike the prediction of the previous modules, it seems that The Shining is not a good recommendation for u Actually, this film shares its director with Dr. Strangelove and A Clockwork Orange which are negatively rated by u Moreover, it has a writer in common with Carrie and The Langoliers which are also movies disliked by u. The same reasoning is made about the concepts Actor and Genre Concerning Monty Python and the Holy Grail, the interests by concept are conceptInterestActor \(u, HolyGrail conceptInterestDirector \(u, HolyGrail conceptInterestWriter \(u, HolyGrail conceptInterestGenre \(u, HolyGrail This recommendation is a good one. The film shares its actors, writers and director with Monty Pythons Life of Brian which is highly rated by the user. The recommendation is thus justified Figure 3. Extract of the movie ontology Frequency Module: Let us assume that the user rated 60% of Alfred Hitchcocks films \(in Tab. I, Psycho and Rear Window are some of them recommended to u IV. EXPERIMENTAL EVALUATION A. Ontology Description For the experimentation, we built the ontology manually see Fig. 3 IMDB8. We focused only on a set of data which led to the concepts Film, Person, Actor, Director, Writer and Genre The connections between these concepts are Each movie is related to a certain number of persons who can be actors, directors or writers but it can also be related to other movies \(Example: Free Willy 2: The Adventure Home and Free Willy 3: The Rescue are related A person and a movie have a genre \(Action, Adventure Animation, Children, Comedy, Crime, etc B. Experimentation and Evaluation 


We use a subset of the dataset provided by MovieLens, the recommender system of GroupLens Research. The dataset contains a set of users, the set of items they have evaluated with a rating between 1 \(for the least liked for the most liked framework, we deal with a set of 86 movies, 934 users and 13 053 ratings. The dataset contains 3593 actors, 77 directors, 275 writers and 17 genres Using a 65% confidence and a 5% support, association rule mining resulted in 1472 rules after running the collaborative module. We evaluated the results obtained from the system by eighteen 20-50-year-old volunteers. The evaluation consisted exclusively in explicit valuations \(ratings 8http://www.imdb.com 474 2010 10th International Conference on Intelligent Systems Design and Applications Figure 4. Users evaluation of the system between 1 and 5 rated at the beginning between 11 and 31 films. For each recommended item, the user rates it as liked or disliked. If an item is rated as liked, the recommendation is considered as accurate. Otherwise, the system explains the reason why this item is recommended. The user can then agree with this explanation or not. Explanation of recommendation can be effective in convincing users in their appreciation of the items [24]. In our approach, the explanation aims at discovering if the detected patterns in the recommended item are accurate or not. Let us consider the following explanation in the recommendation of a film: This film may interest you because you frequently watched Tim Burtons films with Johnny Depp. If the user agrees with the explanation, that means that the association \(Tim Burton - Johnny Depp relevant but this particular film do not appeal to the user Otherwise, we consider that the detected association was purely a coincidence. In this case, the system will be able to ignore this pattern for this user in the future The results of this evaluation are depicted on Fig. 4. We can see that 84,9% of the recommendations satisfy the users Concerning the recommendations rated as disliked, 59,4% of the explanations are approved by users. Finally, 93,9% of the recommendations are satisfying or approved An average of 5 recommendations is obtained by running the collaborative and the semantic-based modules \(which is 


acceptable due to the low number of movies  86  in the dataset frequency module. This difference is due to the fact that the cascading modules \(collaborative and semantic-based are limited by the unique usage of the ratings to compute the association rules. The frequency module, on the other hand, is based on a statistical analysis of the item contents Consequently, it does not suffer from the sparsity of the user rating matrix like the previous modules The collaborative module results in some recommendations which are not liked by users. Fortunately, such recommendations are eliminated by the semantic-based module Other recommendations are eliminated by the semanticbased module though they appeal to users. We explain this because the concerned items dont share any features with the ones in the users history. This is why, we aim at introducing a semantic similarity measure to alleviate this problem \(see Sect. V module recommendations and 58,1% of the explanations of the disliked recommendations, satisfy the users. We can conclude that the combination of all the modules results in better recommendations V. CONCLUSION AND FUTURE WORK In our work, we propose a hybrid recommender system that combines collaborative filtering and semantic analysis of the items. The approach is based on many modules that refine the rules which progressively lead to a recommendation. A process targeting users with various interests is described. First, the collaborative filtering step is achieved using association rule mining which is a flexible way to classify the user. His history is then used to make the results more adapted to him. The semantic module aims at refining the recommendation issued from the rules. Finally, a frequency module is used to discover other items of interest for the user. Using distinct modules allows us to explain the recommendations to the user The results we have obtained from the evaluation experiments are promising. The combination of the collaborative and semantic modules improves the quality of the recommendations and the frequency module adds new ones. 93,9 of the recommendations are satisfying or approved In near future, we aim at defining the approach to learn 


the user profile in order to adapt the combination of the recommendation modules. We also plan to improve the semantic module by defining the semantic similarity between instances [25], [26]. Thus, when computing the interest by instance, those which are semantically similar to the current instance can be used when the instance is not present in the users history This similarity could also be used during the personalization of the association rules. The personalization rule \(a which consists in only keeping the rules which have a body composed of items contained in the users history, can be relaxed if the items violating \(a the items in the users history. The advantage of the semantic similarity is that it can be computed off-line which does not slow down the recommendation process Another improvement we want to introduce is the use of implicit data collected and based on the users behavior e.g. his search history, the time he spent looking at an item and his navigational patterns. This will help to increase the knowledge about the user and, in turn, lead to a better understanding of his expectations Finally, we plan to experiment the framework on other domains to confirm the domain-independence of the system REFERENCES 1] G. Adomavicius and A. Tuzhilin, Toward the next generation of recommender systems: A survey of the state-of-the-art and 2010 10th International Conference on Intelligent Systems Design and Applications 475 possible extensions, IEEE Trans. Knowl. Data Eng., vol. 17 no. 6, pp. 734749, 2005 2] R. Burke, Hybrid recommender systems: Survey and experiments, User Modeling and User-Adapted Interaction vol. 12, no. 4, pp. 331370, 2002 3] K. Lang, Newsweeder: Learning to filter netnews, in Proceedings of the 12th International Machine Learning Conference \(ML, 1995 4] M. J. Pazzani and D. Billsus, Content-based recommendation systems, in The Adaptive Web, P. Brusilovsky, A. Kobsa, and W. Nejdl, Eds., 2007, vol. 4321, pp. 325341 5] P. Resnick, N. Iacovou, M. Suchak, P. Bergstrom, and J. Riedl Grouplens: An open architecture for collaborative filtering of netnews, in Proceedings of ACM 1994 Conference on Computer Supported Cooperative Work, Chapel Hill, North 


Carolina, 1994, pp. 175186 6] B. Sarwar, G. Karypis, J. Konstan, and J. Reidl, Itembased collaborative filtering recommendation algorithms, in Proceedings of the 10th international conference on World Wide Web \(WWW 295 7] B. Sarwar, G. Karypis, J. Konstan, and J. Riedl, Analysis of recommendation algorithms for e-commerce, in Proceedings of the 2nd ACM conference on Electronic commerce \(EC Minneapolis, Minnesota, USA, 2000, pp. 158167 8] M. Balabanovic and Y. Shoham, Fab: content-based, collaborative recommendation, Commun. ACM, vol. 40, no. 3, pp 6672, 1997 9] D. Billsus and M. J. Pazzani, User modeling for adaptive news access, User Modeling and User-Adapted Interaction vol. 10, no. 2-3, pp. 147180, 2000 10] M. J. Pazzani, A framework for collaborative, content-based and demographic filtering, Artif. Intell. Rev., vol. 13, no. 5-6 pp. 393408, 1999 11] S. Castagnos, A. Brun, and A. Boyer, Probabilistic association rules for item-based recommender systems, in Proceedings of the Fourth Starting AI Researchers Symposium STAIRS 12] W. Lin, Association rule mining for collaborative recommender systems, Masters thesis, Faculty of the Worcester Polytechnic Institute, 2000 13] J. J. Sandvig, B. Mobasher, and R. Burke, Robustness of collaborative recommendation based on association rule mining, in Proceedings of the 2007 ACM conference on Recommender systems \(RecSys 14] B. Mobasher, H. Dai, T. Luo, and M. Nakagawa, Effective personalization based on association rule discovery from web usage data, in Proceedings of the 3rd international workshop on Web information and data management \(WIDM Georgia, USA, 2001, pp. 915 15] R. Agrawal, T. Imielinski, and A. Swami, Mining association rules between sets of items in large databases, in Proceedings of the 1993 ACM SIGMOD international conference on Management of data, New York, NY, USA, 1993, pp. 207 216 16] B. Liu, W. Hsu, and Y. Ma, Integrating classification and association rule mining, in Knowledge Discovery and Data 


Mining, New York City, New York, USA, Aug. 1998, pp 8086 17] Y. Blanco-Fernandez, J. J. P. Arias, A. Gil-Solla, M. R Cabrer, M. L. Nores, J. G. Duque, A. F. Vilas, R. P. D Redondo, and J. B. Munoz, A flexible semantic inference methodology to reason about user preferences in knowledgebased recommender systems, Knowl.-Based Syst., vol. 21 no. 4, pp. 305320, 2008 18] S. E. Middleton, H. Alani, N. R. Shadbolt, and D. C. D Roure, Exploiting synergy between ontologies and recommender systems, in Semantic Web Workshop 2002 At the Eleventh International World Wide Web Conference, 2002 19] M. Zanker and M. Jessenitschnig, Case-studies on exploiting explicit customer requirements in recommender systems User Modeling and User-Adapted Interaction, vol. 19, no 1-2, pp. 133166, 2009 20] N. Ducheneaut, K. Partridge, Q. Huang, B. Price, M. Roberts E. H. Chi, V. Bellotti, and B. Begole, Collaborative filtering is not enough? experiments with a mixed-model recommender for leisure activities, in Proceedings of the 17th International Conference on User Modeling, Adaptation, and Personalization \(UMAP 21] H. Nguyen and P. Haddawy, The decision-theoretic interactive video advisor, in Proceedings of the Fifteenth Conference on Uncertainty in Artificial Intelligence \(UAI 494501 22] B. Mobasher, Data mining for web personalization, in The Adaptive Web, ser. Lecture Notes in Computer Science P. Brusilovsky, A. Kobsa, and W. Nejdl, Eds. Springer Berlin Heidelberg, 2007, vol. 4321, ch. 3, pp. 90135 23] T. R. Gruber, A translation approach to portable ontology specifications, Knowl. Acquis., vol. 5, no. 2, pp. 199220 1993 24] N. Tintarev and J. Masthoff, The effectiveness of personalized movie explanations: An experiment using commercial meta-data, in Proceedings of the 5th international conference on Adaptive Hypermedia and Adaptive Web-Based Systems AH 25] R. Albertoni and M. D. Martino, Asymmetric and contextdependent semantic similarity among ontology instances Journal on Data Semantics, vol. 10, pp. 130, 2008 26] X. Jin and B. Mobasher, Using semantic similarity to 


enhance item-based collaborative filtering, in 2nd IASTED International Conference on Information and Knowledge Sharing, Scottsdale, Arizona, 2003 476 2010 10th International Conference on Intelligent Systems Design and Applications 


Basi Association Rles Basi c  Association R u les Association is basically connecting or tying up occurrences of Association is basically connecting or tying up occurrences of events Ol dib t f ilt t O n l y d escr ib e se t s o f s i mu lt aneous even t s Cannot describe patterns that iterate over time e g  itemset a  0  b  0  g    Eg If you sense higher data rates on the downlink than normal AND New Route generated Implies high chances of Intrusion AND New Route generated Implies high chances of Intrusion Associative IDS for NextGen Frameworks Dr S Dua LA Tech 20 


Enhanced Inte r transaction Association Rules Enhanced Inter transaction Association Rules Enhanced Inter transaction Association Rules Extension of association rules Conditional relationships at multiple different time steps e.g itemset a\(0 0 1 2 You sense Higher data rate than normal AND You see New Route g enerated AND 1 minute a g o you detected checksum gg error packets AND 2 minutes ago your encountered wrong checksum   Implies High Chance of Intrusion Enhanced Rules and Confidence Associative IDS for NextGen Frameworks Dr S Dua LA Tech 21 


Complex Spatio temporal Association Complex Spatio temporal Association Rules Further extension of inter transaction association rules Describe event durations e.g itemset a\(0,X j,Y k,Z Eg  You sense high data rates for X seconds AND new route generated j minutes ago task completed in Y AND new route generated j minutes ago task completed in Y seconds AND checksum error packets received k minutes ago for Z seconds High Chance of Intrusion With highest confidence level in association rules  association rules  Associative IDS for NextGen Frameworks Dr S Dua LA Tech 22 


DMITAR Al ith ARD DMITAR Al gor ith m  ARD Problem Domain Problem Statement and Challenges Aiti Miig bd IDS A ssoc i a ti ve Mi n i n g b ase d IDS  Introduction to data mining Association rule in data mining DMITAR Algorithm  ARD New research Associative IDS for NextGen Frameworks Dr S Dua LA Tech 23 


DMITAR Algorithm DMITAR Difference Matrix Based Inter Transaction Association Rule Miner developed in DMRL Uses vertical data format Differences of the transaction IDs are used to generate extended itemsets Windowless mechanism Associative IDS for NextGen Frameworks Dr S Dua LA Tech 24 


Deep into the Mechanism The DMITAR algorithm is based on lhilii comp l ex mat h emat i ca l assoc i at i ve formulation and proofs Four major parts Four major parts Frequent 1 itemset generation Frequent 2 itemset generation Frequent k itemset generation k>2 Spatio temporal rule formation Associative IDS for NextGen Frameworks Dr S Dua LA Tech 25 


DMITAR, Datasets Used Stock Data Stock Data Daily stock information provided by Yahoo finance Wth Dt W ea th er D a t a Provided by the US Department of Commerce and National Climactic Data Center for 700 locations across US Synthetic Data Provided by a CRU weather generator that uses a Markov chain model to generate simulated weather data for 11 UK sites Associative IDS for NextGen Frameworks Dr S Dua LA Tech 26 


DMITAR Results 1/5 Varying Support DMITAR Results 1/5 Stock Database Support FITI ITPMine PROWL DMITAR 14 6424.7s 132.39s 3.03s 5.556s 16 2348.9s 67.14s 2.14s 4.015s 18 861.92s 34.62s 1.55s 2.89s 20 334.51s 18.89s 1.12s 2.07s 22 143 84s 10 87s 0 87s 1 45s 22 143  84s 10  87s 0  87s 1  45s 24 63.62s 7.15s 0.671s 1.04s Weather Database Support FITI ITPMine PROWL DMITAR 14 36362.6s 893.1094s 5.843s 19.8281s 36362.6s 893.1094s 5.843s 19.8281s 16 11913.04s 378.2188s 3.8906s 13.4375s 18 4116s 170.3438s 2.75s 9.1406s 20 1507s 86.5781s 2.14s 6.203s 22 859.2813s 63.3438s 1.7969s 5.7656s 24 378.5313s 36.1875s 1.4375s 3.5625s Synthetic Dataset Support FITI ITPMine PROWL DMITAR 14 1651.6s 199.843s 3.1406s 17.015s 16 574 32 119 32 2 0938 10 875 16 574  32 s 119  32 s 2  0938 s 10  875 s 18 416.109s 95.31s 1.6094s 7.39s 20 370.25s 83.31s 1.453s 5.8438s 22 265.78s 66.3438s 1.3594s 4.75s 24 133.96s 43.0781s 0.9219s 3.5781s 


DMITAR Rlt  DMITAR  R esu lt s 2  5 Rules Formed Associative IDS for NextGen Frameworks Dr S Dua LA Tech 28 


DMITAR Rl  Varying Maxspan DMITAR  R esu l ts 3  5 Varying Maxspan Associative IDS for NextGen Frameworks Dr S Dua LA Tech 29 


DMITAR Res lts 4/5 Vig Di i DMITAR  Res u lts  4/5 V ary i n g Di mens i ons Associative IDS for NextGen Frameworks Dr S Dua LA Tech 30 


DMITAR Rl  Varying Number of Transactions DMITAR  R esu l ts 5  5 Varying Number of Transactions Associative IDS for NextGen Frameworks Dr S Dua LA Tech 31 


N/C t Rh N ew C urren t R esearc h Problem Domain Problem Statement and Challenges Associative Mining based IDS Associative Mining based IDS Introduction to data mining ii lid ii Assoc i at i on ru l e i n d ata m i n i ng DMITAR Algorithm  ARD h New Researc h Associative IDS for NextGen Frameworks Dr S Dua LA Tech 32 


Further Research Further Research Objectives of Our Intrusion Detection System Development Objectives of Our Intrusion Detection System Development 1 Refine and scale the DMITAR algorithm to suit our application 2 Develop methods for dynamically altering the sensor parameters Our Focus is Securing the NextGen Frameworks with New Technology Technology Associative IDS for NextGen Frameworks Dr S Dua LA Tech 33 


Simulated Sensing Environment Simulated Sensing Environment Screenshots of Data C ollected from S ynthetic Sensors Screenshots of Data C ollected from S ynthetic Sensors Simulated in Our Laboratory Three Steps Slides Collect data Collect data from all sources  all attributes  Select Select the source and their hierarchical attributes attributes to be monitored and Select Select the source and their hierarchical attributes attributes to be monitored  and Sample Sample them at different rates different rates and process them Associative IDS for NextGen Frameworks Dr S Dua LA Tech 34 


Data Collection Simultaneous collection of data screen from ENTITIES aircrafts Associative IDS for NextGen Frameworks Dr S Dua LA Tech 35 Source PRTG Network Monitor software screen shot Demo info www.paessler.com 


Parameter Selection Selection of an ENTITY/aircraft and monitoring its parameters and sensor readings Associative IDS for NextGen Frameworks Dr S Dua LA Tech 36 Source PRTG Network Monitor software screen shot Demo info www.paessler.com 


Sensor Sampling Selecting one sensor/probe and reading it at different resolutions or sampling rates Associative IDS for NextGen Frameworks Dr S Dua LA Tech 37 Source PRTG Network Monitor software screen shot Demo info www.paessler.com 


Si l ti Nt k Si mu l a ti on on N e t wor k Most scenarios can be simulated on a computer or computer network network  The aircrafts and sensors are simulated on a computer network bllb b y ana l ogica l su b stitutions Sensors provide information at different rates Sensors provide information at different rates Need Based Sensor Prioritization NSP and Dynamic Sensing Rate Sampling Associative IDS for NextGen Frameworks Dr S Dua LA Tech 38 


Vulnerability Search Scan 39 Sample UQA script with Nmap performed in DMRL Associative IDS for NextGen Frameworks Dr S Dua LA Tech 39 Source Nmap screenshot with a pearl script  Find Namp on Nmap.org 


Modality Aspect Modality Aspect A Multimodal distribution is a continuous probability distribution with two or more modes of underlying data Mltil d i M u lti p l e mo d es i n our model Associative IDS for NextGen Frameworks Dr S Dua LA Tech 40 Source http://en.wikipedia.org/wiki/File:Bimodal bivariate small.png 


Multi Modality Modality Fusion 41 SENSITIVE  UNCLASSIFIED For Official Use Only Associative IDS for NextGen Frameworks Dr S Dua LA Tech 41 


Emphasis Emphasis Our approach emphasizes on pre empting the attack Our intent is NOT to perform an autopsy to discover attacks Instead we aim to detect and prevent in attacks in real time Associative IDS for NextGen Frameworks Dr S Dua LA Tech 42 


Techniques for Discriminative Rules Techniques for Discriminative Rules Resolution Analysis Features Analyzed at Different Depths Anti Monotonic Principle Modality Aspect Treading into Unexplored Feature spaces Associative IDS for NextGen Frameworks Dr S Dua LA Tech 43 


Representative Outcomes Representative Outcomes Illustration of the Final Analysis Our method shifts between modalities and sampling rates for optimization The blue parallelograms are actual intrusions 44 The blue parallelograms are actual intrusions The Red Green Blue Plots are response of system Associative IDS for NextGen Frameworks Dr S Dua LA Tech 44 


Advantages of Our M ethod Advantages of Our M ethod Exploit the memory v ertical data format utilizes slidin g windows to g form a much larger database to analyze  Flexibility in Choosing what to choose  Choosing what to choose to build the rules Computational and memory efficiency We have a team working only on this aspect 45 Associative IDS for NextGen Frameworks Dr S Dua LA Tech 45 


Preliminary Results Intra transaction Relations Data rate simulator NH-134 Mb HOP PATH update \(Y/N Inference 11.5 Y Y 2 0.120 N N      Y   n 0.345 N NH134 Y/N   Inf 1 0.150 N N 2 0 120 Y N Inter transaction Relations 2 0  120 Y N       5 5.55 0.456 Y Relations  n 0.345 N N Nmap on DMRL nmap.org 


Anticipated Outcome Anticipated Outcome Develop algorithm capable of learning from a given heterogeneous diverse Develop algorithm capable of learning from a given heterogeneous diverse data ff Dynamic algorithmic f ramework designed to shi f t modalities and sampling rates based on complex logic Flexibility of integration into the Snort intrusion detection system 47 Associative IDS for NextGen Frameworks Dr S Dua LA Tech 47 


References References Aircraft Cockpit Image courtesy USAF http://www.faa.gov htt p   www.faa g ov  air traffic  technolo gy  p g  _ gy  Acharya R Dua S Du X Sree V Chua C K Automated Diagnosis of Glaucoma Using Texture and Higher Order Spectra Features To appear in IEEE Transactions on Information Technology in Biomedicine  Du X Dua S 2011 Cancer Prognosis Using Support Vector Regression in Imaging  Modality World Journal of Clinical Oncology 2  1   44 49 Du X Dua S 2010 Salient Frame Extraction Using Support Vector Regression and Motion Features pp 5 Proc of the National Aerospace and Electronics Conference July 14 16 2010 D M P D S 2010 Di i i ti Ft d Cl ifi ti Mthd f D essaue r  M  P  D ua S  2010  Di scr i m i na ti ve F ea t ures an d Cl ass ifi ca ti on M e th o d s f or Accurate Classification 1st ed vol 7704 pp 14 Bellingham WA Proceedings of SPIE Dessauer M P Dua S 2010 Low Resolution Vehicle Tracking using Dense and Reduced Local Gradient Features Maps 1st ed vol 7694 pp 8 Bellingham WA Proceedings of SPIE SPIE 


Acknowledgements Acknowledgements Fundin g A g encies  US 4 1 Million direct fundin g g g 4 g LA BoR NIH NSF AFRL AFOSR and NASA Research Team Samuel Kasimalla Brandy McKnight Dr Pradeep Chowriappa Connor Johnson Vasanth Nair Mihir Chowriappa  Connor Johnson  Vasanth Nair  Mihir Karnik Mohit Jain and Swadheen Songmen Associative IDS for NextGen Frameworks Dr S Dua LA Tech 49 All the respective Logos belong to their owners 


Rf d Rdi R e f erence d R ea di ngs Copyright of cover pages held by respective publishers 


Thank You Questions Thank You  Questions Dr Sumeet Dua E mail sdua@latech.edu Web http://dmrl.latech.edu Associative IDS for NextGen Frameworks Frameworks Dr S Dua LA Tech 51 Image Source roadtrafficsigns.com 


