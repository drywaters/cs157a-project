A Data M ining Method on the Study of Medical Information  Xiaofe ng Zhao School of Economics and Management Hebei University of Engineering Handan, China Qboy_best@163.com Li yan Jiao, Jinping An, Li Wang Af filiated hospital Hebei University of Engineering Handan, China Jiaoliyan88@163.com Li pin Jia Medical S chool Hebei University of Engineering Handan, China Jiaoliyan88@163.com   Abst ract 
227For a long time, the cause of diabetes has been an unsolved problem. And with the deepening of diabetes research, much information has been collected. There may contain lots of interesting information within the collected medical information. But, the traditional medical methods can only study the human organ from the microscopic view, and lack of the capability of process large medical data set. So, in this paper, an data mining method is introduced to provide a new way to find the diabetes etiology  Keywords-Data mining, Apriori algorithm, diabetes, medical data I   I NTR ODUCTION  N ext to cardiovascular disease and tumor, diabetes has 
been as the third major disease all over the world. But, for a long time, the etiology of diabetes has still been unidentified which makes the treatment and prevention of diabetes much difficult. The traditional research methods on the diabetes etiology mainly focus on the microscopic medical methods which studies human body only. Over a hundred years of Modern medical research makes it clear that pancreas is the organ that causes diabetes. Furthermore, islet cells cells and insulin have been found. And now, hundreds of diabetes pathogenic genes have been found by the gene method However, until now, we just know the pathological change of pancreas, islet and the cells causes the di but, how? How can these pathological changes cause the diabetes? Further, what causes the changes? Dose this relates 
to human\222s living habit or dose this relates to inheritance Those are still questions, which makes the diabetes an incurable disease. And, the key to find the answers of above questions is to make the relations among those factors clear Unfortunately, the traditional medical methods of diabetes research can only process small amounts of tissue samples and lack the capacity to find relations from large amount of medical information gained from the patients. Thus, the key to the answer slipped through the fingers Data mining is a process of extracting valid, previously unknown and actionable information from large data set. We can find the relations which are hided in the large medical data set using the data mining technology. But, the researches on the using of data mining method into the 
medical studies are not too mu According to the limitation of traditional medical methods, a data mining method is put forward in this paper and we hope it can pick up the lost key to open the door of finding the diabetes etiology. For finding the relation of the diabetes factors, an attribute important degree measure methods is introduced first, and then a correlation algorithm is put forward, finally, a method is proposed to combine them to find the factors and their relation that causes the diabetes II  T HE I MPORTANT DEGREE OF ATTRIBUTES  A  rough set theories[6   Information Systems: A Information Systems can be 
define as L=\(U, Q,V ,f\ in which U={x 1 205,x n is the do mains of discourse, Q A D is a ttribute set, in which A is condition attributes set, D is decision attributes set, V is attributes value set, f is the map of U\327Q V I ndiscernibility relation: For x, y U, P Q, i f q P F q X y  y\hen for the attributes set P, x and y is indiscernible, if x and y are not discernible. The 
Indiscernibility relation of P notes for ind\(P upper approximation and lower approximation: Set P Q x P  y U | x ind \( P\ y}, Y U then the lower approximation of Y is P Y  x U p  Y and the upper approximation is PY x U p  Y 
 appro ximation accuracy: Set P Q L is a division of U determined by decision attribute D{Y 1 Y 2 205 Y k  Y U V9-183 2010 International Conference on Computer Application and System Modeling \(ICCASM 2010 C 9 78 1 42 4 4 7 237 6   2 6  0 0  201 0 I E EE 


then the approximation accuracy of Y according to P is a p  P Y\d P Y which card\(Y element number of Y. The approximation accuracy of L according to attribute set P is as \(1\ the rough approximation accuracy of L according to attribute set P is as 2 1      k pi i r L card PY card U  1  11      kk p ii ii a L card PY card PY  2 B  The important degrees of attributes The important degree of attribute is computed by the two approximation accuracy \(1\\(2\of rough set. Set decision attribute set is D, and condition attributes set is F = {f 1  f 2 205, f m The division L determined by D is {L 1 L 2 205 L k For each condition attribute f i compute K+2 parameter a f i Y j 1 , 2 , \205, k, and a fi L\ and r f i L\ which a f i  L\ and r f i L\is the mean value and variance of the K+2 parameter[7  The important degree of attribute fi is W fi  1 j k a fi Yj a fi L\ +r fi k + 2\, and We should take the advice of expert into account. Set the important degree of attribute f i  given by expert be W pi  Then the final important degree of attribute f i is W i W fi  W pi  III  F IND THE RELATION FROM MEDICAL DATA SET  The purpose of us is to find the factors that cause diabetes and their relations with diabetes. First, we have to gain sufficient diabetes information, which include the patients\222 basic condition \(including the weight, age, sex etc medical history, their relatives\222 medical history, habits and customs and examination results \(including the hemogram CT, and B ultrasonic result etc.\. For the integrity and consistency of the information, a mature information gathering system should be built among several hospital including well designed unified diagram, table data expression and storage format We use the correlation algorithm of the data mining to find the potential relation from the medical information. The apriori algorithm [8, 9, 10 is one o f t h e m o s t fa m o u s  correlation algorithms, which can find the frequent itemsets from large scale data set. And, there are many improved algorithm based on it. Most of them focus on the improving of the mining efficiency. But, for the medical research mining efficiency is not the most important factor, and we want to find more useful association rules and abandon more useless association rules. So, a new association algorithm which is suitable for finding diabetes etiology is introduced in this section The data set we got is all the diabetes patients information, and is stored as a table, which has the form of Name, Sex, Height, Medical History, \205 , Diabetes\and if the attribute value of diabetes is 1 means the patient gets the diabetes. For the diabetes research, we just analyze the records whose diabetes value is 1.So, when we use the apriori algorithm on such a data set \(all records diabetes value is 1\ attribute diabetes seems to be nonsense, and the frequent itemsets we find seem to be independent of attribute diabetes, which conflicts with our purpose. So, the important degree of attribute diabetes which is defined in the former section is used to solve the problem. The apriori algorithm is used to analyze the data set without attribute diabetes to find all the frequent itemsets, and then, they are matched with the important attributes we find, and those matched frequent itemsets are selected. Then the attribute diabetes is added into all the frequent itemsets to find the association rule. Among all the rules, the rules with the pattern \223*=>*, diabetes, *\224 \(which contain the diabetes etiology information\ are chosen, and those with no attribute 223diabetes\224 appears on the right side of the \221=>\222 are ignored because we want to find what causes diabetes, but not diabetes causes what\he rules we find contain the direct cause of diabetes, e.g. b=1 => diabetes=1 means b=1 may cause diabetes. Furthermore, we want to find what causes b=1, and we can not use the frequent itemsets we find by upper apriori algorithm, because the data set we used is focus on the diabetes information \(all the attribute value of diabetes is 1\. So, we have to extract the records that the attribute value of b is 1 from the original data set. And then, we find the association rule with the pattern of * => *, b=1, * using the method we find the rule *=>*, diabetes, *, and this time the attribute diabetes is replaced by attribute b. After this, we can find an association chain such as c=1 => b=1 diabetes=1, which means b=1 is the direct cause of diabetes and c=1 is the direct cause of b=1 and may be the indirect cause of diabetes=1. The algorithm is shown in algorithm 1.We can set an iteration time N, which makes the iteration run N times to find N length association chains DiaApriori\(D, FA, Fa, V, N Input: D The medical dataset FA The attribute set of D Fa The attribute for which we want to find the association, and the value of the first call is diabetes V The value of Fa N iteration time Begin N=N-1 If N>=0 Begin Select the subset from D, in which the value of attribute Fa for all the records is V Remove attribute Fa from the selected subset, and the remained dataset is D a  Compute the important degree of attributes using equation 3. Set the threshold value be t, and select the attributes whose important degree is higher than t. Set the select attribute set be IA={F i1 F i2 205, F im  Select all Frequent Itemsets FI from D a using the apriori algorithm For each itemset in FI Begin If 80% attributes is in IA, put the itemset into attribute set FIS, and put attribute Fa into the itemset 


End For Compute association rules from FIS using apriori algorithm, and select the rule with the pattern of a=V, * into rule set RS For each rule AR in RS \(AR may has the pattern *, Fb=Vb a=V Begin For each Fb=Vb in AR Begin DiaApriori\(D, FA, Fb, Vb, N-1 End for End for End if End DiaApriori Algorithm 1: The improved apriori algorithm for diabetes data If we just want to find the direct association, set N=1 at the first call of DiaApriori IV  E XPRIMENT  An information gathering system was established for the experiment, and the medical data were got from 3 first-level hospital of Handan, China. We used the data structure of [1  which includes 40 attributes. A data set of 57291 records was got with the time span form april, 2007 to april 2009. And among all the data, 13748 records are from diabetes patients and the value of DIABETES is 1 for them. Among the 13748 record, 12956 records are valid for algorithm 1.The data structure is shown in table 1 TABLE I  T HE DATA STRUCTURE OF THE EXPERIMENT DATA SET  Attribute Meaning Attribute Meaning AGE Age SM K Smoke SEX Sex DRIN K Drink EDU Education EXERC Exercise PSYSTR psychological pressure DMA Diabetes history DIETA Diet Habbit HRTA Heart disease history HPA Hypertension history CBVA Cerebrovascular history HRTSYM Cardiovascular symptom MCYCA Menarche age KIDN Nephropathy history WEIGHT Weight WAIST Waist SBP1 systolic pressure DBP1 diastolic pressure HDL High Cholesterol CHOL Total Cholesterol  DIABETES Diabetes ETHNIC ethnic group JOBA Job nature SLPA Sleep ESTROGB timing of estrogen JOB Job JOBSTR Job stress DIETB Salt intake HYPLIPA Hyperlipidemia history DIETC Fat intake LIVER Liver disease history DIETD Staple food intake VLDL very low density lipoprotein CBVSYM Cerebrovascul ar symptom MCYCB menstrual HEIGHT Height MARRIAG E Marriage HIP Hip ESTROGA Estrogen taking GLU Blood suga r LDL Low Cholesterol TG triglycercide TC Cholesterol An information gathering system was established for the experiment, and the medical data were got from 3 first-level hospital of Handan, China. We used the data structure of  which includes 40 attributes. A data set of 57291 records was got with the time span form april, 2007 to april 2009. And among all the data, 13748 records are from diabetes patients and the value of DIABETES is 1 for them. Among the 13748 record, 12956 records are valid for algorithm 1. We call DiaAprior with DIABETES=1, N=2. A total 174 direct association rules, and 563 two level indirect association rules are found. It can be seen that the rule number is much smaller than traditional apriori algorithm, because we just choose the rule with the pattern *=>diabetes=1. And some of the meaningful results are shown below Age=3 => diabetes=1 DME=3 => diabetes=1 AGE=3, dme=3 => diabetes=1 DIETD=2 => diabetes=1 JOB=1 =>diabetes=1 EDU=2, job=1 => diabetes=1 GLU=3 => diabetes=1 DIETA=5 => diabetes=1 TC=3, DRINK=0 => diabetes=1 WEIGHT=0 =>diabetes=1 AGE=3, DME=6=>diabetes=1 SLPA=3 => diabetes=1 DIETC=5 => diabetes=1 BYC=0 =>dizbetes=1 BYC=0, DRINK=3, DIETD=2 =>diabetes=1 EXER=0 => diabetes=1 DRINK =3=>DIETC=5 => diabetes=1 JOBA=1 => JOB=1 => diabetes=1 JOB=1=> BYC=0=>diabetes=1 DIETD=2 => WEIGHT=0 => diabetes=1 PSYSTR=3 => SLPA=3 =>diabetes=1 JOBA=1 => DIETC=5 => diabetes=1 JOBA=0 => DIETA=5 => diabetes=1 


From the result we can see that some of the rules we find are similar to the known cause of diabetes, which means the method can get meaningful knowledge, such as Age=3 diabetes=1\(Patients age are above 45 may cause diabetes DME=3 => diabetes=1 \( Above 30% immediate families have diabetes\ and DIETD=2 => diabetes=1 The carbohydrate intake is more than normal level The method can get some unknown association rule, such as PSYSTR=3 SLPA=3 =>diabetes=1 which means high psychological pressure may cause too little sleep and may indirectly cause diabetes, .TC=3, DRINK=0 => diabetes=1 which means Cholesterol is higher than normal level and no drink may be one of the diabetes symptom, JOBA=1 => DIETC=5 diabetes=1 which means high strength brainwork may cause intake too mach fat which may cause diabetes and JOBA=0 DIETA=5 => diabetes=1 which means physical work may cause gluttony which may cause diabetes   From the result we can see that the cause of diabetes is most likely be living habit including food habit and job condition, and seems to have nothing to do with height, heart disease Nephropathy history  Liver disease and sex Limited by the conditions, the patient data set is just got form 3 hospitals, and there are only 40 attribute in it, so although some interesting rules were found, the origin that causes diabetes is still not clear, and the next stage of our work is to expand the data set, including add some more specialized attributes, and improve the record number V  C ONCLUSION  A data mining method is introduced in this paper to solve the problem that traditional medical method can not find the complicated relations of the factors that cause diabetes from large scale patients\222 data. Using the algorithm that improved from apriori, direct and indirect association can be found from the patients\222 data set. The method not only can find the direct factors related to diabetes, but also can find the indirect factors that cause diabetes, which gives a new way to the research of diabetes           R EFERENCES  1  Florez H, Steps toward the primary prevention of type II diabetes mellitus various epidemiological consid erations[J lin  1997 38\( 1\ pp. 39 43 2  Barroso I, Luan J, Middelberg RPS, et al, Candidate gene association study in type 2 diabetes indicates a role for genes involved in cell function as well as insulin action, Plos Biol,2003, 1 \( 3\, pp.15921597 3  Cough lan M T, Oliva K, Georgiu HM, et al, Glucose induced release of tumor necrosis factor alpha from human placental tissues in gestational diabetes mellitu et Med,  2001; 18,pp.  9212-9271 4  Milan Z, Gou M, Peter K et.al. Mining diabetes database with decision trees and associ In: Pr o c eedings o f the 15th IEEE Symposium on Computer- Based Medical Systems, 2002,pp 867\227871 5  D Sleeman, F Mitchell, R Milne Applying KDD techniques to produce diagnostic rules for dyna mic systems[R t e c h n ic al rep o rt AUCS/TR9604, 1996 6  Pawlak Z, Rough sets[J Inte rnati ona l J ournal  o f Co m puter a nd Information Science, 1982, 11\( 5\ pp. 341- 356 7  HU Xuegang , LI Nan, A random decision tree algorithm based on attribute significance[J  J ourna l o f  hef e i univer sity of  t e c hno logy   Vol . 30, No. 6 ,J un. 2007, pp.87--91 8  Han J , Kambr M. Data mining : concepts and techniques  S a n Francisco : Morgan Kaufmann Publishers , 2001 pp. 279 - 333 9  Wu Xindong,Vipin Kumar, Ross Quinla n J, Top 10 algorithms in data mining [J Know l e dge and Inf or m a t i on Sy s t e m s  2008 1 4 1    pp 1-37  10  Han Jiawei, Pei Jian, Yin Yiwen, et al. Mining frequent patterns without candidate generation [J D a ta Mining a nd K n ow ledge  Discovery, 2004, 8\(1\ pp.53-87 11  Luo Sen lin, Cheng Hua, Gu Yuqing, Zhang tiemei , Zeng ping Application of C4.5 algorithm in the construction of the type 2 diabetes classified rules Ap p licat io n Re sear c h o f  C o mp u t er s Vo l 30, 2004, pp. 174-179  


  confidence than R1. However, in example 1, R1 and R2 of X 2 value are 88.6 and 14.8 respectively. But, in CMAR algorithm, R1 and R2 of Weighted X 2 are 27.36 and 4.91 respectively. It can be seen from example 1 that using X 2 testing and Weighted X 2 can not actually reflect fact in this situation. In view of th is, this paper proposes a new weight method in association ru le so that the new weight can actually reflect fact and obtains better accuracy. This paper proposed a new weight calculation method is based on confidence. It is to utilize confidence itself provided quality information to be a base of weight calculation. And it also collocates with exponential function and power function for using. Therefore, it can readjust effect of confidence in rule grou p due to the functions decrease the effect of low quality rules This paper proposed weight calculation method is represented in formula 2. The p1 and p2 are adjustable argumen ts, it affects variation of rule weight value for each matched rules      exp 2 1 p conf p Weighted  2  Using example 1 to demonstrate, the arguments p1 and p2 are set to 2. The R1 and R2 are 2.05 and 6.08 respectively. R2 will be choice in our proposed method. But R1 will be choice in CMAR al gorithm. Thus, using our proposed weight calculation method can avoid bias of Weighted X 2 of CMAR in example 1 situation In parts of section 4, we test our proposed algorithm on 26 data sets from UCI Machine Learning Repository The 26 data sets has often been used to experiment of classification algorithm accuracy, and so are we 4  Experiment 4.1  Experiment Environment This paper uses UCI 26 data sets for experime  It is the most popular on classification algorithm. Those are anneal, austral, auto, breast, cleve, crx, diabetes, german glass, heart, hepatic, horse, hypo, iono, iris, labor, led7 lymph, pima, sick, sonar, tic tac, vehicle, waveform, wine and zoo data sets, respectively The experiment were performed on Windows 7 64bits and Intel i7-860\(OC 3.5G and 4GByte RAM. The program was constructed by Microsoft Visual C++ 2008 Express and was compiled into 64 bits. The experimentês arguments settings are according to the most common settings in associative classification algorithm. Th e support threshold  minsup dence threshold minconf o 50%, and coverage threshold to 4, and p 1 and p 2 of formula 3 is set to 2 4.2  Experiment  Result  In parts of rule producing limit, it is according to CMAR algorithm to limit the nu mber of rules on 9 data sets Other data sets will be completely mining. The limitation of number of rules is represented by table 4. In table 4, the condition is the meaning of number of X in rule X Y. For example, the number of conditions is 6 in data set of anneal It represents that permutation of attribute items will be end when the conditions of rule have more than 6 attribute items. Then, the algorithm will in to next phase. Due to that we can easily avoid that rules producing cannot be performed in finite resource when attribute items are too more Table 4. Limitation of the number of conditions Data Sets Conditions Data Sets Conditions Anneal 6 Sick 3 Auto 4 Sonar 4 Hypo 3 Vehicle 4 Iono 3 Zoo 6 Lymph 6    This paper of experiment compares to CBA ,CMAR LAC and L 3 8 algorit h m s. In parts of CB A a n d CMAR  algorithms results, we cited both data directly form paper of CMAR provided results. Bu t, LAC and L 3 algorithms data cite from their original papers The experiment results can be seen from table 5, we wi n 11 data sets over other algorithms. Our classification algorithm accuracy is 87.1 This paper proposed algorithm of accuracy is greater than CBA algorithm 2.41%, CMAR algorithm 1.88%, LAC algorithm 1.12% and L 3 1.01 5  Conclusion This paper is based on CMAR algorithm, and successfully integrates support calculation method of LAC algorithm into this paper. Th e experiment proves that using support calculation method of LAC algorithm to obtain small disjunction rule. Aft er combining with multiple associative-rule method, we can effectively raise the accuracy. On the other hand, this paper proposed a new weight calculation method not only greater than CMAR and LAC algorithm but also greater than L 3 algorithm 1.01%. In addition, this paper proposed algorithm usually has high accuracy whether the number of rules or number of candidates are high limitation or low limitation. Hence, the experiment demonstrates to us that our algorithm has features of stable and high accuracy In parts of follow-up, this paper has no perform all of 895 Proceedings of the 2011 International Conference on Machine Learning and Cybernetics, Guilin, 10-13 July, 2011 


  L 3 used data sets. Therefore, follow-up pursuer might consider performing more data set so that it could test our proposed algorithm whether it still has stable and high accuracy. Beside, using FP-Growth to mining rule is not suitable for support calculation method of LAC algorithm so far. Because of support calculation method of LAC algorithm is different than other classification algorithm But, we can still test other algorithm or data structure to combine with FP-Growth in rule mining. It might accelerate performed time in rule mining and support calculation so that the whole rule produci ng time could be cut down Table 5. Experiment results Data Sets CBA CMAR LAC L 3 Our Results Anneal 97.9 97.3 96.5 97.9 98.10 Austral 84.9 86.1 87.3 85.7 86.23 Auto 78.3 78.1 77.8 79 86.24 Breast 96.3 96.4 96.8 95.7 96.57 Cleve 82.8 82.2 84.4 82.2 82.48 Crx 84.7 84.9 85.8 84.8 85.07 Diabetes 74.5 75.8 80.3 78.7 77.34 German 73.4 74.9 76.6 74.2 74.9 Glass 73.9 70.1 74 77.6 75.78 Heart 81.9 82.2 83.1 84.4 83.33 Hepatic 81.8 80.5 82.9 85.8 86.50 Horse 82.1 82.6 85.5 84.2 83.12 Hypo 98.9 98.4 99 98.9 97.28 Iono 92.3 91.5 92.2 92 93.74 Iris 94.7 94 96.8 93.3 93.33 Labor 86.3 89.7 80.9 91.2 92.67 Led7 71.9 72.5 77.9 72.34 Lymph 77.8 83.1 80.9 85.1 87.19 Pima 72.9 75.1 78 78.3 78.39 Sick 97 97.5 98 95.5 95.86 Sonar 77.5 79.4 79.5 79.3 84.62 Tic-tac 99.6 99.2 99.4 99.5 98.75 Vehicle 68.7 68.8 71.1 72.2 74.00 Waveform 80 83.2 80.7 82.3 84.80 Wine 95 95 96.6 97.2 98.89 Zoo 96.8 97.1 93.5 92.1 97.09 Avg. 84.69 85.22 85.98  87.1 L 3 Avg 85.2 85.724 86.304 86.68 87.69 Win 0 1 11 3 11 References 1  Bing Liu, Wynne Hsu, Yiming Ma, çIntegrating Classification and Association Rule Mining Proceedings of the Fourth International Conference on Knowledge Discovery and Dat a Mining \(KDD-98  New York, USA, 1998, pp 80-86. \(The CBA system can be downloaded from http://www.comp.nus edu.sg/~dm2 2  Rakesh Agrawal, Tomasz Imie liski, and Arun Swami Mining Association Rules Between Sets of Items in Large Databases ACM SIGMOD Conference New York, USA, 1993, pp 207-216 3  Rakesh Agrawal, and Ramak rishnan Srikant, çFast algorithms for mining association rules in large databases Proceedings of the 20th International Conference on Very Large Data Bases\(VLDB  Santiago, Chile, September 1994, pp 487-499 4  W. Li, çClassication based on multiple association rules M.Sc. Thesis Simon Fraser University, April 2001 5  Adriano Veloso et al., çLazy Associative Classication Proceedings of the Sixth International Conference on Data Mining Washington, USA, 2006 pp 645-654 6  Robert C. Holte and Liane E. Acker and Bruce W Porter., çConcept  Learning  and  the Problem  of Small  Disjuncts In Proceedings of the Eleventh International Joint Conference on Artificial Intelligence 1989, pp 813-818 7  W. Li, J Han, and J. Pei, çCMAR: Accurate and Efficient Classification Based on Multiple Class-Association Rules Proc. IEEE Intêl Conf. Data Mining \(ICDM ê01 San Jose, Califor nia, Nov. 2001 pp 369 8  Baralis, E., Chiusano, S., and Garza, P., çA Lazy Approach to Associative Classification Knowledge and Data Engineering, IEEE Transactions on Vol. 20 Issue.2, Feb. 2008 pp 156-171 9  UCI Machine Learning Repository http://archive ics.uci.edu/ml 1  Adriano Veloso et al Multi-label Lazy Associative Classification Proceedings of the 11th European conference on Principles and Practice of Knowledge Discovery in Databases Warsaw, Poland, 2007, pp 605-612 1  J. Han, J. Pei, and Y. Yin, çMining frequent patterns without candidate generation In SIGMOD Dallas TX, United States, May 2000, pp 1-12 1  Fayyad, U. M., And Irani, K B., çMulti-interval discretization of continuous-valued attributes for classification learning Proceedings of the 13th international joint conference on artificial intelligence  Chambery, France, Sep. 1 993, pp 1 022-1027 896 Proceedings of the 2011 International Conference on Machine Learning and Cybernetics, Guilin, 10-13 July, 2011 


for Data Mining in E-learning: The case of Open E-class ISBN:978-972-8924-97-3,2009 , pp 254-258 5] Jaideep Srivastava, Robert Cooley et al.,Web Usage Mining:Discovery and Applications of Usage patterns from Web Data, ACM SIGKDD, Vol 1, Issue 2, Jan 2000, pp 12-22 6] Khribi, M.K., Jemni M., Nasraoui O ,Automatic Recommendation for E-learning Personalization based on Web Usage mining techniques and information retrieval, Educational Technology and Society, I2\(4 7] Mei-Ling Shyu, Choochart Haruechaiyasak, Collaborative Filtering by Mining Association Rules from User Access Sequences,Proceedings of 2005 International workshop on challenges in web information retrieval and integration, 0-76952414-1/05,IEEE, 2005 8] Nasraoui, O. Soliman, M. Saka, E. Badia, A.Germain,  R A Web Usage Mining Framework for Mining Evolving User Profiles in  Dynamic  Web  Sites,IEEE  transaction   on Knowledge  and data engineering,Volume 20,Issue 2, Feb 2008 pp. 202-215 9]  Pasi   Franti,Olli   Virmajoki,   and   Ville   Hautamaki    Fast Agglomerative Clustering Using a k Nearest Neighbor graph,IEEE transaction on pattern analysis and machine intelligence.Vol 28,No11. November 2006, pp 1875-1881 10] Sathiya Moorthi V, Murali Bhaskaran V, Data preparation Techniques for Web Usage Mining in World Wide Web  an approach, International Journal of Recent Trends in Engineering Vol 2, No 4, November 2009 11] Sen Guo, Yongshen Liang et al.,Association Rule Retrieved from Web log based on Rough Set Theory, Fourth International conference on Fuzzy systems and Knowledge discovery, IEEE 2007 12] Siripom chimphlee,Naomie Salim,Mohd Salihin Bin Ngadiman, Witcha,Surat ,Rough Sets Clustering and  Markov Model for Web Access Prediction ,Proceedings of post graduate annual seminar 2006, pp. 470-474 13] Ying Cong, Changxu Ji, Application of Web-based Data Mining in Personalized online learning system, Proceedings of Wuhan International Conference on E-Business,pp150-156 


To be preserved, an association rule must satisfy two measures The support of an itemset A, denoted s\(A the frequency of the itemset A among the set of transactions T \(users history items in the context s\(A The con?dence of a rule X ? B, denoted c\(X ? B is defined by: c\(X ? B X?B s\(X Association rules are mined using the Apriori algorithm 15]. The liked and disliked items are first distinguished in the user history using their item ratings. This is done in order to gain a global view of the liked and disliked items For ratings between 1 and 5, values strictly lower than 4 are considered to represent disliked items. On the other hand values equal to or higher than 4 represent items that fit the users taste. Thus, items can be labeled with two values l like dislike users who have rated some of these items, we can obtain the extraction of the rules This module doesnt depend on a particular user. The computation is conducted generally for all users and is 6The insertion of multiple profiles under false identities in order to promote or denote the recommendation of a particular item performed periodically 2 aims at personalizing the association rules for the user The association rules are filtered according to the user by applying the following rules in the following order a of items contained in the users history \(this is a strong rule which can be relaxed  see Sect. V b the head because there is no sense in recommending an item he has already consulted c because there is no sense in recommending to the user an item he will not appreciate d as a consequence of \(b c Example: Let us consider movie recommendation Given a user u who rated and liked the movies F1, F3 and 


F5 denoted F l1, F l3 and F l5. The following rules are obtained r1 : {F l1, F l3} ? {F l5 r2 : {F l1, F l2} ? {F l4 r3 : {F l3, F l5} ? {F d6 r4 : {F l1, F l5} ? {F l3, F l7 By the application of \(b d kept. The rule r2 is also not kept by the application of \(a r3 is not kept after passing \(c d r?4 : {F l1, F l5} ? {F l7} because of \(b rule r?4 This result is justified because r1 leads to the recommendation of an item already consulted by the user, which is useless. r2 doesnt fit the user because he hasnt consulted all of the items contained in the body so we cannot make any conclusions. The recommendation of r3 is not accurate because the item is predicted as disliked. Finally, we can extract rule r4 which results in a possible recommendation the item F7 C. Semantic-Based Module This module is based on an ontology. An ontology is an explicit specification of a shared conceptualization [23]. It is used to formally describe domains by means of concepts and properties. Typically, concepts are classes and properties are relations characterizing the concepts. A property has a domain and a range. For example, the domain of the property hasActor\(Film,Actor Instances of concepts and properties are called individuals7 In the following, we denote C as the set of the concepts of the the ontology, and Rel as the set of properties \(relations We consider that an item is characterized by the concepts hes related to. Moreover, each concept has its proper influence on each user. This is why, the interest of a user 7The terms instance and individual are used without distinction 472 2010 10th International Conference on Intelligent Systems Design and Applications in an item is defined by his interest in the concepts related to the item. The user preference for a concept over another is learned by analyzing his profile. We do not explain this process in this paper Once the association rules concerning the user are identified, we use the ontology to compute the interests of each item in the head. This helps to refine the obtained results from the previous module. Indeed, before applying 


the semantic module, the recommendation is issued from collaborative filtering. While in some cases these recommendations can fit the user, it is possible that they dont suit his other interests. This semantic module performs the required adjustments and takes into account the user as a unique entity The prediction of the interest of these features of item f uses the following parameters for the user u the users valuations for the items which have at least one shared feature with f the number of occurrences of each feature of f among those rated by u This is done in two steps: the computation of the instance interest and then the computation of the concept interest 1 Definition: Given a user u, the interest of u for an instance i is a prediction based on the past valuations of u for the items connected to i by a certain relation R ? Rel An instance i is connected to 0 to n items in the users history. Thus, 0 to n valuations related to this instance are obtained. The interest of i is then estimated according to the valuations connected with it. This is done by computing the median of these valuations. Actually, median allows one to avoid extreme and unusual values which add some noise when computing a basic average of a set of values instanceInterest\(u, i median\({eval\(u, f f, i 1 where eval\(u, f f 2 Definition: Given a user u, the interest of u according to a concept c for an item f is based on the instance interests of the individuals of the concept c connected to f by a certain relation R ? Rel conceptInterestc\(u, f   i?{i? |?R?Rel R\(f,i i instanceInterest\(u, i ratioocc\(u, i   


i?{i? |?R?Rel R\(f,i i ratioocc\(u, i 1 2 where ratioocc\(u, i instance i among the instances of the same concept in the users history D. Frequency Module This module aims at detecting the frequent instances and the frequent associations of instances. Indeed, such a frequency depicts an important interest of the user for the concerned instances. Consequently, it is relevant to recommend items with these characteristics to the user 1 considers the profile of the user. It aims at detecting the most important features of interest for the user Regardless of the estimated interest of an instance for a user, we consider that if the user has in his history a significant percentage of items which have as a feature that particular instance, the interest of this instance is significant Unlike the previous computation, this computation ignores the users ratings for the items which have the instance as a feature Example: A user who has watched 80% of the films interpreted by the actor Tom Hanks should get the recommendation of the other 20% he has not seen even if some of the films of Tom Hanks in his history are badly rated 2 case with frequent instances described above, this part of the module deals not only with the profile of the user, but also with the set of items. It aims at discovering frequent associations between the features in the user history. It detects the features that often occur together in order to discover new recommendations. To achieve this, frequent sets of the instances related to the items in the users history are computed. Then, items with such instances are recommended to the user Example: A possible frequent association is the actor Johnny Depp and the director Tim Burton. A user who is interested in these two instances will be recommended the other films related to them E. Recommendation and explanation 


As explained in Sect. II, the collaborative and the semantic modules are in cascade. Consequently, the result is a set of recommendations rec1 which is mixed with the recommendations of the frequency module rec2 such that rec1 is presented before rec2 to the user. This order can be inverted according to user feedback. Concerning the explanation of the recommendations, this is done by highlighting the instances which have highly scored the interest of the user for the items of rec1, and by highlighting the frequent instances in the items of rec2 F. Example In this section, we illustrate the recommendation process for any user u, in the movie domain. We will simplify to preserve the clarity of the example 2010 10th International Conference on Intelligent Systems Design and Applications 473 Table I EXTRACT OF THE PROFILE OF THE USER u Film Rating Transformation Psycho 5 Psychol Rear Window 4 Rear Windowl Four Weddings and a Funeral 4 Four Weddings and a Funerall Monty Pythons Life of Brian 5 Monty Pythons Life of Brianl Carrie 3 Carried Stephen Kings The Langoliers 1 Stephen Kings The Langoliersd Pulp Fiction 4 Pulp Fictionl Dr. Strangelove 2 Dr. Strangeloved A Clockwork Orange 1 A Clockwork Oranged Let us consider u who has rated the movies in Tab. I Collaborative Filtering Module: Let us assume that the association rule mining result is r1 : {Psychol, Pulp Fictionl} ? {The Shiningl r2 : {Pulp Fictionl,Monty Pythons Life of Brianl Monty Python and the Holy Graill r3 : {Monty Python and the Holy Graill, Jurassic Parkl Indiana Jones and the Last Crusadel According to the rules introduced in Sect III-B2, we only keep the association rules r1 and r2 Semantic-Based Module: In this step, the interest of the user for each movie in the head of each rule from the last module is computed. The concerned movies are The Shining and Monty Python and the Holy Grail For The Shining, we obtain the following interest re 


sults conceptInterestActor \(u, TheShining conceptInterestDirector \(u, TheShining conceptInterestWriter \(u, TheShining conceptInterestGenre \(u, TheShining Unlike the prediction of the previous modules, it seems that The Shining is not a good recommendation for u Actually, this film shares its director with Dr. Strangelove and A Clockwork Orange which are negatively rated by u Moreover, it has a writer in common with Carrie and The Langoliers which are also movies disliked by u. The same reasoning is made about the concepts Actor and Genre Concerning Monty Python and the Holy Grail, the interests by concept are conceptInterestActor \(u, HolyGrail conceptInterestDirector \(u, HolyGrail conceptInterestWriter \(u, HolyGrail conceptInterestGenre \(u, HolyGrail This recommendation is a good one. The film shares its actors, writers and director with Monty Pythons Life of Brian which is highly rated by the user. The recommendation is thus justified Figure 3. Extract of the movie ontology Frequency Module: Let us assume that the user rated 60% of Alfred Hitchcocks films \(in Tab. I, Psycho and Rear Window are some of them recommended to u IV. EXPERIMENTAL EVALUATION A. Ontology Description For the experimentation, we built the ontology manually see Fig. 3 IMDB8. We focused only on a set of data which led to the concepts Film, Person, Actor, Director, Writer and Genre The connections between these concepts are Each movie is related to a certain number of persons who can be actors, directors or writers but it can also be related to other movies \(Example: Free Willy 2: The Adventure Home and Free Willy 3: The Rescue are related A person and a movie have a genre \(Action, Adventure Animation, Children, Comedy, Crime, etc B. Experimentation and Evaluation 


We use a subset of the dataset provided by MovieLens, the recommender system of GroupLens Research. The dataset contains a set of users, the set of items they have evaluated with a rating between 1 \(for the least liked for the most liked framework, we deal with a set of 86 movies, 934 users and 13 053 ratings. The dataset contains 3593 actors, 77 directors, 275 writers and 17 genres Using a 65% confidence and a 5% support, association rule mining resulted in 1472 rules after running the collaborative module. We evaluated the results obtained from the system by eighteen 20-50-year-old volunteers. The evaluation consisted exclusively in explicit valuations \(ratings 8http://www.imdb.com 474 2010 10th International Conference on Intelligent Systems Design and Applications Figure 4. Users evaluation of the system between 1 and 5 rated at the beginning between 11 and 31 films. For each recommended item, the user rates it as liked or disliked. If an item is rated as liked, the recommendation is considered as accurate. Otherwise, the system explains the reason why this item is recommended. The user can then agree with this explanation or not. Explanation of recommendation can be effective in convincing users in their appreciation of the items [24]. In our approach, the explanation aims at discovering if the detected patterns in the recommended item are accurate or not. Let us consider the following explanation in the recommendation of a film: This film may interest you because you frequently watched Tim Burtons films with Johnny Depp. If the user agrees with the explanation, that means that the association \(Tim Burton - Johnny Depp relevant but this particular film do not appeal to the user Otherwise, we consider that the detected association was purely a coincidence. In this case, the system will be able to ignore this pattern for this user in the future The results of this evaluation are depicted on Fig. 4. We can see that 84,9% of the recommendations satisfy the users Concerning the recommendations rated as disliked, 59,4% of the explanations are approved by users. Finally, 93,9% of the recommendations are satisfying or approved An average of 5 recommendations is obtained by running the collaborative and the semantic-based modules \(which is 


acceptable due to the low number of movies  86  in the dataset frequency module. This difference is due to the fact that the cascading modules \(collaborative and semantic-based are limited by the unique usage of the ratings to compute the association rules. The frequency module, on the other hand, is based on a statistical analysis of the item contents Consequently, it does not suffer from the sparsity of the user rating matrix like the previous modules The collaborative module results in some recommendations which are not liked by users. Fortunately, such recommendations are eliminated by the semantic-based module Other recommendations are eliminated by the semanticbased module though they appeal to users. We explain this because the concerned items dont share any features with the ones in the users history. This is why, we aim at introducing a semantic similarity measure to alleviate this problem \(see Sect. V module recommendations and 58,1% of the explanations of the disliked recommendations, satisfy the users. We can conclude that the combination of all the modules results in better recommendations V. CONCLUSION AND FUTURE WORK In our work, we propose a hybrid recommender system that combines collaborative filtering and semantic analysis of the items. The approach is based on many modules that refine the rules which progressively lead to a recommendation. A process targeting users with various interests is described. First, the collaborative filtering step is achieved using association rule mining which is a flexible way to classify the user. His history is then used to make the results more adapted to him. The semantic module aims at refining the recommendation issued from the rules. Finally, a frequency module is used to discover other items of interest for the user. Using distinct modules allows us to explain the recommendations to the user The results we have obtained from the evaluation experiments are promising. The combination of the collaborative and semantic modules improves the quality of the recommendations and the frequency module adds new ones. 93,9 of the recommendations are satisfying or approved In near future, we aim at defining the approach to learn 


the user profile in order to adapt the combination of the recommendation modules. We also plan to improve the semantic module by defining the semantic similarity between instances [25], [26]. Thus, when computing the interest by instance, those which are semantically similar to the current instance can be used when the instance is not present in the users history This similarity could also be used during the personalization of the association rules. The personalization rule \(a which consists in only keeping the rules which have a body composed of items contained in the users history, can be relaxed if the items violating \(a the items in the users history. The advantage of the semantic similarity is that it can be computed off-line which does not slow down the recommendation process Another improvement we want to introduce is the use of implicit data collected and based on the users behavior e.g. his search history, the time he spent looking at an item and his navigational patterns. This will help to increase the knowledge about the user and, in turn, lead to a better understanding of his expectations Finally, we plan to experiment the framework on other domains to confirm the domain-independence of the system REFERENCES 1] G. Adomavicius and A. Tuzhilin, Toward the next generation of recommender systems: A survey of the state-of-the-art and 2010 10th International Conference on Intelligent Systems Design and Applications 475 possible extensions, IEEE Trans. Knowl. Data Eng., vol. 17 no. 6, pp. 734749, 2005 2] R. Burke, Hybrid recommender systems: Survey and experiments, User Modeling and User-Adapted Interaction vol. 12, no. 4, pp. 331370, 2002 3] K. Lang, Newsweeder: Learning to filter netnews, in Proceedings of the 12th International Machine Learning Conference \(ML, 1995 4] M. J. Pazzani and D. Billsus, Content-based recommendation systems, in The Adaptive Web, P. Brusilovsky, A. Kobsa, and W. Nejdl, Eds., 2007, vol. 4321, pp. 325341 5] P. Resnick, N. Iacovou, M. Suchak, P. Bergstrom, and J. Riedl Grouplens: An open architecture for collaborative filtering of netnews, in Proceedings of ACM 1994 Conference on Computer Supported Cooperative Work, Chapel Hill, North 


Carolina, 1994, pp. 175186 6] B. Sarwar, G. Karypis, J. Konstan, and J. Reidl, Itembased collaborative filtering recommendation algorithms, in Proceedings of the 10th international conference on World Wide Web \(WWW 295 7] B. Sarwar, G. Karypis, J. Konstan, and J. Riedl, Analysis of recommendation algorithms for e-commerce, in Proceedings of the 2nd ACM conference on Electronic commerce \(EC Minneapolis, Minnesota, USA, 2000, pp. 158167 8] M. Balabanovic and Y. Shoham, Fab: content-based, collaborative recommendation, Commun. ACM, vol. 40, no. 3, pp 6672, 1997 9] D. Billsus and M. J. Pazzani, User modeling for adaptive news access, User Modeling and User-Adapted Interaction vol. 10, no. 2-3, pp. 147180, 2000 10] M. J. Pazzani, A framework for collaborative, content-based and demographic filtering, Artif. Intell. Rev., vol. 13, no. 5-6 pp. 393408, 1999 11] S. Castagnos, A. Brun, and A. Boyer, Probabilistic association rules for item-based recommender systems, in Proceedings of the Fourth Starting AI Researchers Symposium STAIRS 12] W. Lin, Association rule mining for collaborative recommender systems, Masters thesis, Faculty of the Worcester Polytechnic Institute, 2000 13] J. J. Sandvig, B. Mobasher, and R. Burke, Robustness of collaborative recommendation based on association rule mining, in Proceedings of the 2007 ACM conference on Recommender systems \(RecSys 14] B. Mobasher, H. Dai, T. Luo, and M. Nakagawa, Effective personalization based on association rule discovery from web usage data, in Proceedings of the 3rd international workshop on Web information and data management \(WIDM Georgia, USA, 2001, pp. 915 15] R. Agrawal, T. Imielinski, and A. Swami, Mining association rules between sets of items in large databases, in Proceedings of the 1993 ACM SIGMOD international conference on Management of data, New York, NY, USA, 1993, pp. 207 216 16] B. Liu, W. Hsu, and Y. Ma, Integrating classification and association rule mining, in Knowledge Discovery and Data 


Mining, New York City, New York, USA, Aug. 1998, pp 8086 17] Y. Blanco-Fernandez, J. J. P. Arias, A. Gil-Solla, M. R Cabrer, M. L. Nores, J. G. Duque, A. F. Vilas, R. P. D Redondo, and J. B. Munoz, A flexible semantic inference methodology to reason about user preferences in knowledgebased recommender systems, Knowl.-Based Syst., vol. 21 no. 4, pp. 305320, 2008 18] S. E. Middleton, H. Alani, N. R. Shadbolt, and D. C. D Roure, Exploiting synergy between ontologies and recommender systems, in Semantic Web Workshop 2002 At the Eleventh International World Wide Web Conference, 2002 19] M. Zanker and M. Jessenitschnig, Case-studies on exploiting explicit customer requirements in recommender systems User Modeling and User-Adapted Interaction, vol. 19, no 1-2, pp. 133166, 2009 20] N. Ducheneaut, K. Partridge, Q. Huang, B. Price, M. Roberts E. H. Chi, V. Bellotti, and B. Begole, Collaborative filtering is not enough? experiments with a mixed-model recommender for leisure activities, in Proceedings of the 17th International Conference on User Modeling, Adaptation, and Personalization \(UMAP 21] H. Nguyen and P. Haddawy, The decision-theoretic interactive video advisor, in Proceedings of the Fifteenth Conference on Uncertainty in Artificial Intelligence \(UAI 494501 22] B. Mobasher, Data mining for web personalization, in The Adaptive Web, ser. Lecture Notes in Computer Science P. Brusilovsky, A. Kobsa, and W. Nejdl, Eds. Springer Berlin Heidelberg, 2007, vol. 4321, ch. 3, pp. 90135 23] T. R. Gruber, A translation approach to portable ontology specifications, Knowl. Acquis., vol. 5, no. 2, pp. 199220 1993 24] N. Tintarev and J. Masthoff, The effectiveness of personalized movie explanations: An experiment using commercial meta-data, in Proceedings of the 5th international conference on Adaptive Hypermedia and Adaptive Web-Based Systems AH 25] R. Albertoni and M. D. Martino, Asymmetric and contextdependent semantic similarity among ontology instances Journal on Data Semantics, vol. 10, pp. 130, 2008 26] X. Jin and B. Mobasher, Using semantic similarity to 


enhance item-based collaborative filtering, in 2nd IASTED International Conference on Information and Knowledge Sharing, Scottsdale, Arizona, 2003 476 2010 10th International Conference on Intelligent Systems Design and Applications 


Basi Association Rles Basi c  Association R u les Association is basically connecting or tying up occurrences of Association is basically connecting or tying up occurrences of events Ol dib t f ilt t O n l y d escr ib e se t s o f s i mu lt aneous even t s Cannot describe patterns that iterate over time e g  itemset a  0  b  0  g    Eg If you sense higher data rates on the downlink than normal AND New Route generated Implies high chances of Intrusion AND New Route generated Implies high chances of Intrusion Associative IDS for NextGen Frameworks Dr S Dua LA Tech 20 


Enhanced Inte r transaction Association Rules Enhanced Inter transaction Association Rules Enhanced Inter transaction Association Rules Extension of association rules Conditional relationships at multiple different time steps e.g itemset a\(0 0 1 2 You sense Higher data rate than normal AND You see New Route g enerated AND 1 minute a g o you detected checksum gg error packets AND 2 minutes ago your encountered wrong checksum   Implies High Chance of Intrusion Enhanced Rules and Confidence Associative IDS for NextGen Frameworks Dr S Dua LA Tech 21 


Complex Spatio temporal Association Complex Spatio temporal Association Rules Further extension of inter transaction association rules Describe event durations e.g itemset a\(0,X j,Y k,Z Eg  You sense high data rates for X seconds AND new route generated j minutes ago task completed in Y AND new route generated j minutes ago task completed in Y seconds AND checksum error packets received k minutes ago for Z seconds High Chance of Intrusion With highest confidence level in association rules  association rules  Associative IDS for NextGen Frameworks Dr S Dua LA Tech 22 


DMITAR Al ith ARD DMITAR Al gor ith m  ARD Problem Domain Problem Statement and Challenges Aiti Miig bd IDS A ssoc i a ti ve Mi n i n g b ase d IDS  Introduction to data mining Association rule in data mining DMITAR Algorithm  ARD New research Associative IDS for NextGen Frameworks Dr S Dua LA Tech 23 


DMITAR Algorithm DMITAR Difference Matrix Based Inter Transaction Association Rule Miner developed in DMRL Uses vertical data format Differences of the transaction IDs are used to generate extended itemsets Windowless mechanism Associative IDS for NextGen Frameworks Dr S Dua LA Tech 24 


Deep into the Mechanism The DMITAR algorithm is based on lhilii comp l ex mat h emat i ca l assoc i at i ve formulation and proofs Four major parts Four major parts Frequent 1 itemset generation Frequent 2 itemset generation Frequent k itemset generation k>2 Spatio temporal rule formation Associative IDS for NextGen Frameworks Dr S Dua LA Tech 25 


DMITAR, Datasets Used Stock Data Stock Data Daily stock information provided by Yahoo finance Wth Dt W ea th er D a t a Provided by the US Department of Commerce and National Climactic Data Center for 700 locations across US Synthetic Data Provided by a CRU weather generator that uses a Markov chain model to generate simulated weather data for 11 UK sites Associative IDS for NextGen Frameworks Dr S Dua LA Tech 26 


DMITAR Results 1/5 Varying Support DMITAR Results 1/5 Stock Database Support FITI ITPMine PROWL DMITAR 14 6424.7s 132.39s 3.03s 5.556s 16 2348.9s 67.14s 2.14s 4.015s 18 861.92s 34.62s 1.55s 2.89s 20 334.51s 18.89s 1.12s 2.07s 22 143 84s 10 87s 0 87s 1 45s 22 143  84s 10  87s 0  87s 1  45s 24 63.62s 7.15s 0.671s 1.04s Weather Database Support FITI ITPMine PROWL DMITAR 14 36362.6s 893.1094s 5.843s 19.8281s 36362.6s 893.1094s 5.843s 19.8281s 16 11913.04s 378.2188s 3.8906s 13.4375s 18 4116s 170.3438s 2.75s 9.1406s 20 1507s 86.5781s 2.14s 6.203s 22 859.2813s 63.3438s 1.7969s 5.7656s 24 378.5313s 36.1875s 1.4375s 3.5625s Synthetic Dataset Support FITI ITPMine PROWL DMITAR 14 1651.6s 199.843s 3.1406s 17.015s 16 574 32 119 32 2 0938 10 875 16 574  32 s 119  32 s 2  0938 s 10  875 s 18 416.109s 95.31s 1.6094s 7.39s 20 370.25s 83.31s 1.453s 5.8438s 22 265.78s 66.3438s 1.3594s 4.75s 24 133.96s 43.0781s 0.9219s 3.5781s 


DMITAR Rlt  DMITAR  R esu lt s 2  5 Rules Formed Associative IDS for NextGen Frameworks Dr S Dua LA Tech 28 


DMITAR Rl  Varying Maxspan DMITAR  R esu l ts 3  5 Varying Maxspan Associative IDS for NextGen Frameworks Dr S Dua LA Tech 29 


DMITAR Res lts 4/5 Vig Di i DMITAR  Res u lts  4/5 V ary i n g Di mens i ons Associative IDS for NextGen Frameworks Dr S Dua LA Tech 30 


DMITAR Rl  Varying Number of Transactions DMITAR  R esu l ts 5  5 Varying Number of Transactions Associative IDS for NextGen Frameworks Dr S Dua LA Tech 31 


N/C t Rh N ew C urren t R esearc h Problem Domain Problem Statement and Challenges Associative Mining based IDS Associative Mining based IDS Introduction to data mining ii lid ii Assoc i at i on ru l e i n d ata m i n i ng DMITAR Algorithm  ARD h New Researc h Associative IDS for NextGen Frameworks Dr S Dua LA Tech 32 


Further Research Further Research Objectives of Our Intrusion Detection System Development Objectives of Our Intrusion Detection System Development 1 Refine and scale the DMITAR algorithm to suit our application 2 Develop methods for dynamically altering the sensor parameters Our Focus is Securing the NextGen Frameworks with New Technology Technology Associative IDS for NextGen Frameworks Dr S Dua LA Tech 33 


Simulated Sensing Environment Simulated Sensing Environment Screenshots of Data C ollected from S ynthetic Sensors Screenshots of Data C ollected from S ynthetic Sensors Simulated in Our Laboratory Three Steps Slides Collect data Collect data from all sources  all attributes  Select Select the source and their hierarchical attributes attributes to be monitored and Select Select the source and their hierarchical attributes attributes to be monitored  and Sample Sample them at different rates different rates and process them Associative IDS for NextGen Frameworks Dr S Dua LA Tech 34 


Data Collection Simultaneous collection of data screen from ENTITIES aircrafts Associative IDS for NextGen Frameworks Dr S Dua LA Tech 35 Source PRTG Network Monitor software screen shot Demo info www.paessler.com 


Parameter Selection Selection of an ENTITY/aircraft and monitoring its parameters and sensor readings Associative IDS for NextGen Frameworks Dr S Dua LA Tech 36 Source PRTG Network Monitor software screen shot Demo info www.paessler.com 


Sensor Sampling Selecting one sensor/probe and reading it at different resolutions or sampling rates Associative IDS for NextGen Frameworks Dr S Dua LA Tech 37 Source PRTG Network Monitor software screen shot Demo info www.paessler.com 


Si l ti Nt k Si mu l a ti on on N e t wor k Most scenarios can be simulated on a computer or computer network network  The aircrafts and sensors are simulated on a computer network bllb b y ana l ogica l su b stitutions Sensors provide information at different rates Sensors provide information at different rates Need Based Sensor Prioritization NSP and Dynamic Sensing Rate Sampling Associative IDS for NextGen Frameworks Dr S Dua LA Tech 38 


Vulnerability Search Scan 39 Sample UQA script with Nmap performed in DMRL Associative IDS for NextGen Frameworks Dr S Dua LA Tech 39 Source Nmap screenshot with a pearl script  Find Namp on Nmap.org 


Modality Aspect Modality Aspect A Multimodal distribution is a continuous probability distribution with two or more modes of underlying data Mltil d i M u lti p l e mo d es i n our model Associative IDS for NextGen Frameworks Dr S Dua LA Tech 40 Source http://en.wikipedia.org/wiki/File:Bimodal bivariate small.png 


Multi Modality Modality Fusion 41 SENSITIVE  UNCLASSIFIED For Official Use Only Associative IDS for NextGen Frameworks Dr S Dua LA Tech 41 


Emphasis Emphasis Our approach emphasizes on pre empting the attack Our intent is NOT to perform an autopsy to discover attacks Instead we aim to detect and prevent in attacks in real time Associative IDS for NextGen Frameworks Dr S Dua LA Tech 42 


Techniques for Discriminative Rules Techniques for Discriminative Rules Resolution Analysis Features Analyzed at Different Depths Anti Monotonic Principle Modality Aspect Treading into Unexplored Feature spaces Associative IDS for NextGen Frameworks Dr S Dua LA Tech 43 


Representative Outcomes Representative Outcomes Illustration of the Final Analysis Our method shifts between modalities and sampling rates for optimization The blue parallelograms are actual intrusions 44 The blue parallelograms are actual intrusions The Red Green Blue Plots are response of system Associative IDS for NextGen Frameworks Dr S Dua LA Tech 44 


Advantages of Our M ethod Advantages of Our M ethod Exploit the memory v ertical data format utilizes slidin g windows to g form a much larger database to analyze  Flexibility in Choosing what to choose  Choosing what to choose to build the rules Computational and memory efficiency We have a team working only on this aspect 45 Associative IDS for NextGen Frameworks Dr S Dua LA Tech 45 


Preliminary Results Intra transaction Relations Data rate simulator NH-134 Mb HOP PATH update \(Y/N Inference 11.5 Y Y 2 0.120 N N      Y   n 0.345 N NH134 Y/N   Inf 1 0.150 N N 2 0 120 Y N Inter transaction Relations 2 0  120 Y N       5 5.55 0.456 Y Relations  n 0.345 N N Nmap on DMRL nmap.org 


Anticipated Outcome Anticipated Outcome Develop algorithm capable of learning from a given heterogeneous diverse Develop algorithm capable of learning from a given heterogeneous diverse data ff Dynamic algorithmic f ramework designed to shi f t modalities and sampling rates based on complex logic Flexibility of integration into the Snort intrusion detection system 47 Associative IDS for NextGen Frameworks Dr S Dua LA Tech 47 


References References Aircraft Cockpit Image courtesy USAF http://www.faa.gov htt p   www.faa g ov  air traffic  technolo gy  p g  _ gy  Acharya R Dua S Du X Sree V Chua C K Automated Diagnosis of Glaucoma Using Texture and Higher Order Spectra Features To appear in IEEE Transactions on Information Technology in Biomedicine  Du X Dua S 2011 Cancer Prognosis Using Support Vector Regression in Imaging  Modality World Journal of Clinical Oncology 2  1   44 49 Du X Dua S 2010 Salient Frame Extraction Using Support Vector Regression and Motion Features pp 5 Proc of the National Aerospace and Electronics Conference July 14 16 2010 D M P D S 2010 Di i i ti Ft d Cl ifi ti Mthd f D essaue r  M  P  D ua S  2010  Di scr i m i na ti ve F ea t ures an d Cl ass ifi ca ti on M e th o d s f or Accurate Classification 1st ed vol 7704 pp 14 Bellingham WA Proceedings of SPIE Dessauer M P Dua S 2010 Low Resolution Vehicle Tracking using Dense and Reduced Local Gradient Features Maps 1st ed vol 7694 pp 8 Bellingham WA Proceedings of SPIE SPIE 


Acknowledgements Acknowledgements Fundin g A g encies  US 4 1 Million direct fundin g g g 4 g LA BoR NIH NSF AFRL AFOSR and NASA Research Team Samuel Kasimalla Brandy McKnight Dr Pradeep Chowriappa Connor Johnson Vasanth Nair Mihir Chowriappa  Connor Johnson  Vasanth Nair  Mihir Karnik Mohit Jain and Swadheen Songmen Associative IDS for NextGen Frameworks Dr S Dua LA Tech 49 All the respective Logos belong to their owners 


Rf d Rdi R e f erence d R ea di ngs Copyright of cover pages held by respective publishers 


Thank You Questions Thank You  Questions Dr Sumeet Dua E mail sdua@latech.edu Web http://dmrl.latech.edu Associative IDS for NextGen Frameworks Frameworks Dr S Dua LA Tech 51 Image Source roadtrafficsigns.com 


