An Alternative Approach to Mine Association Rules  CH.Sandeep Ku mar   K Srinivas   Peddi K ishor  T.Bhaskar M.Tech\(CSE\ Student                    Assoc  Prof\(CSE\                  Asst Prof\(IT\                             Sr.Asst Pro f\(IT SCCE,Karim Nagar                       SCCE,Karim Nagar               SCITS,Karim Nagar                SCCE,Karim Nagar sandeepchbtech@gmail.com         kaparthisrini@yahoo.com     kish135@gmail.com                 bhas_ani@yahoo.co.in    Abstract Recently, mining negative association rules has received some attention and been proved to be useful in real world. This paper presents an efficient algorithm \(PNAR mining both positive and negative association rules in databases. The algorithm extends traditional association rules to include negative association rules. When mining negative association rules, we use same minimum support threshold to mine frequent negative itemsets. With a Yule’s Correlation Coefficient measure and pruning strategies, the algorithm can find all valid association rules quickly and overcome some limitations of the previous mining methods. The experimental results demonstrate its effectiveness and efficiency  Index Terms  Association Rule Mining, Data Mining Frequent Itemsets, Minimum Support, Yule’s Correlation Coefficient  I. INTRODUCT ION  The research and application of data mining technology are a hot spot in database and artificial intelligence at recent years. Association Rules Mining introduced by R. Agrawal 1 i s a n im port a n t re s e a r c h  t o pi c a m ong th e v a ri ou s d ata  mining problems. Association rules have been extensively studied in the literature for their usefulness in many application domains such as market basket analysis recommender systems, diagnosis decisions support telecommunication, intrusion detection, and etc. All the traditional association rule mining algorithms were developed to find positive associations between itemsets Several algorithms has been developed to cope with the popular and computationally expensive task of association rule mining, such as Apriori [1   AIS [2], DHP  3 Parti tion  4 etc.. Wi t h t h e incre a sing u s e and deve l o p m e n t of data mining techniques and tools, much work has recently focused on finding negative patterns, which can provide valuable information. However, mining negative association rules is a difficult task, due to the fact that there are essential differences between positive and negative association rule mining. We will attack two key problems in negative association rule mining 1\w to effectively search for negative frequent itemsets 2\w to effectively identify negative association rules  Although some researchers pointed out the importance of negative associations, only some groups of researchers 6  7 an d et c    propose d an alg o r ith m to  m i ne t h ese ty pes of associations. This not only illustrates the novelty of negative association rules, but also the challenge in discovering them  II. BASIC KNOWLEDGE  A. Concepts and Definitions Let I={i 1 i 2  i n  be a set of n distinct literals called items Let DB be a set of transactions, where each transaction T is a set of items, and each transaction is associated with a unique identifier called TID. Let A, called an itemset, be a set of items in I. The number of items in an itemset is the length \(or the size\ an itemset. Itemsets of length k are referred to as k-itemsets. A transaction T is said to contain A if A  T. An association rule is an implication of the form A=>B, where A  I, B  I, and A B We call A the antecedent of the rule and B the consequent of the rule The rule A=>B has a support \(denoted as supp s in DB if s of the transactions in DB contains A=>B. In other words the support of the rule is the probability that A and B hold together among all the possible presented cases. i.e  AUB\……….. \(1  The rule A=>B has a measure of its strength called confidence \(denoted as conf\ c if c% of transactions in DB that contain A also contain B. In other words, the confidence of the rule is the conditional probability that the consequent B is true under the condition of the antecedent A. i.e  A\… \(2  B. Classical Method The classical method is well known as the support confidence framework for association rule mining [1 c a n  be decomposed into the following two issues 1\Generate all frequent itemsets: All itemsets that have a support greater than or equal to user-specified minimum support \(ms\generated 2\erate all the rules that have a user-specified minimum confidence \(mc\ in the following naive way: For every frequent itemset X and any B  X, let A=X-B. If the rule A=>B has the mc, then it is a valid rule The generative rules are called interesting positive rules A frequent itemset \(denoted as PL\8 i s an ite m s e t t h at meets the user-specified ms. Accordingly we define an infrequent itemset \(denoted as NL\ as an itemset that does not meet the user-specified ms. The second sub problem is 420 ___________________________________ 978-14244 8679-3  11 26.00 ©201 1 IEEE 


straight forward and can be done efficiently in a reasonable time. However, the first sub problem is very tedious and computationally expensive for very large database and this is the case for many real life applications In order to generate the frequent itemsets, an iterative approach is used to first generate the set of frequent 1itemsets L 1 then th e set of frequent itemsets L 2 and so on until for some value of r the set L r is empty. At this stage the algorithm can be terminated. During the k-th iteration of this procedure a set of candidates C k is generated by performing a k-2\join on the frequent itemsets L k-1 Th e itemsets in this set C k are candidat es for frequent itemsets, and the final set of frequent itemsets L k m us t be a subset of C k Each  element of C k nee ds to be validated against the transaction database to see if it indeed belongs to L k  The val idation of the candidate itemset C k against the transaction database seems to be bottleneck operation for the algorithm. In order to improve the algorithm efficiency, the Apriori property is introduced that all subsets of a frequent itemset A in DB are also frequent in DB, and all supersets of an infrequent itemset A in DB are also infrequent in DB  C. Negative Association Rules The negation of an itemset A is indicated by ¬A, which means the absence of the itemset A. We call a rule of the form A=>B a positive association rule, and rules of the other forms \(A=>¬B, ¬A=>B and ¬A=>¬B\ negative association rules The support and confidence of the negative association rules can make use of those of the positive association rules 9 p or t is gi ve n b y the f o l l owing f o rm ulas   supp\(¬A\=1-supp\(A\……… \(3 supp\(A=>¬B\=supp\(A\-supp\(AUB\ ..…………… \(4 supp\(¬A=>B\=supp\(B\supp\(AUB\………\(5 6    The confidence is given by the following formulas    The n ega tive association rules discovery seeks rules of the three forms with their support and confidence greater than, or equal to, user-specified ms and mc thresholds respectively. These rules are referred to as an interesting negative association rule  III. PNAR ALGORITHM  A. Yule’s Correlation Coefficient When mining positive and negative association rule at the same time, we will find that the mining rules are contradictory frequently. For example, the rules of the forms A=>¬B and ¬A=>B may be mined together, but the two rules are contradictory. In order to resolve these contradictions, we can judge the types of mining association rules by the correlation coefficient A an d B f o r th e  two itemsets. The correlation coefficient \(denoted as Q A,B  can show the relevance of the two itemsets. As follows    The value of Yule’s correlation coefficient exist the following three situations  1\f Q A,B 0 then A and B are positive correlation. The more A occurs in a transaction the more B will likely also occur in the same transaction and vice versa 2\f Q A,B 0 then A and B are negative correlation. The more A occurs in a transaction the less B will likely also occur in the same transaction and vice versa By the definition of correlation coefficient, we can conclude the below lemmas Lemma 1 If the itemset A and B are positive correlation then the forms of A=>B or ¬A=>¬B will be mined Lemma 2 If the itemset A and B are negative correlation then the forms of A=>¬B or ¬A=>B will be mined  B. Pruning Strategies As we have seen, there can be an exponential number of infrequent itemsets in a database, and only some of them are useful for mining interesting association rules. Therefore pruning strategy is critical to efficient search for interesting frequent negative itemsets. When mining negative association rules, we can adopt same minimum support \(ms and minimum confidence \(mc\ threshold to improve the usability of the rules. Through the experimental analysis, we found that the association rules of the forms A=>B and A=>¬B have considerable proportion when mining both positive and negative association rules. In particular, the number of the form ¬A=>¬B is very large, and these rules including pure negative itemsets are usually of little use in real application. For example, we assume that the database DB in a supermarket contain n transactions. Now we concern the sale of tea \(t\ coffee \(c\. Suppose we mine the rule of the form ¬t=>¬c, which means customers not to buy tea and coffee in a transaction, the result is not useful to our market basket analysis. So we adopt a pruning strategy that we will not to consider the part negative association rules of the form A=>¬B to improve mining efficiency. The search space can be significantly reduced by the pruning strategy Supp\(AB\upp\(¬A¬B  Supp\(A¬B\Supp\(¬AB Q A,B  Supp\(AB\upp\(¬A¬B\Supp\(A¬B\upp\(¬AB 421 


In addition, we are only interested in those absence itemsets whose positive counterparts are frequent for market basket analysis when mining negative association rules. For example, the absence itemset ¬A is not show if the itemset A is not frequent. The pruning strategy is more benefit to generate frequent 1-itemset. Because of reducing the number of frequent 1-itemset, the number of frequent and infrequent k-itemset is reduced accordingly  C. PNAR Algorithm As mentioned before, the process of mining both positive and negative association rules can be decomposed into the following three sub problems, in a similar way to mining positive rules only 1\e the set PL of frequent itemsets and the set NL of infrequent itemsets 2\ositive rules of the form A=>B in PL 3\ative rules of the forms A=>¬B and ¬A=>B in NL Let DB be a database, and ms, mc, dms and dmc given by the user. Our algorithm for extracting both positive and negative association rules with a correlation coefficient measure and pruning strategies is designed as follows  Algorithm  Positive and Negative Association Rules  Input TDB-Transactional Database MS-Minimum Support MC-Minimum Confidence Output Positive and Negative Association Rules Method  1  P  N  2  Find F 1 Set of frequent 1- itemsets 3  for \( k=2;F k-1  k  4   5  C k F k-1 join F k-1  6   Prune using Apriori Property 7  for each i   C k an y subset of i is not in F k-1 then C k C K  i 8  for each i   C k fi nd Support  i 9   for each A,B \(A U B= i 10   11  Q A,B Associati on\(A,B 12  if Q>0 13  if supp A B MS conf A B MC\then 14  P P U { A B 15  if Q<0 16   17  if supp A B MS conf A B MC then 18  N N U { A  B 19  if supp  A B MS conf  A B MC then 20  N N U A B 21   22   23   24  AR P U N PNAR generates not only all positive association rules in PL, but also negative association rules in NL. When mining negative association rules, we use same threshold to improve the usability of the frequent negative itemsets. With a Yule’s correlation coefficient measure and pruning strategies, the algorithm can find all valid association rules quickly. An example of mining positive and negative itemsets is given below for illustrative purposes  IV. RESULTS  For the convenience of comparison, we conducted our experiments on the synthetic dataset to study the behaviors of the algorithm Example-1: Let us consider a small transactional table with 10 transactions and 6 items. In Table1 a small transactional database is given  Table1: A Transaction Database TD  TID Items TID Items 1 A,C,D 6 E 2 B,C 7 B,F 3 C 8 B,C,F 4 A,B,F 9 A,B,E 5 A C,D 10 A,D  In the following tables, Lk is denoted as all frequent kitemset. Given that ms=0.3, all the positive and negative frequent itemsets can then be discovered. And in Table2, we compare three algorithms in the same TD From Table2 we discover that the PNAR algorithm can reduce the number of the positive and negative frequent itemsets efficiently. The proposed algorithm can generate negative association rules without calculating negative frequent itemsets     422 


 Table2: Comparison of the Two Algorithms    Nu mber of Rules  Minim um Support & Minimum Confidence  20   40  25  45  30  50  20 55  15 60  ML ANT ONIE  88  62  62  63  63  PNARY  166  70  70  132  136  A Comparison Graph between ML ANTONE & PNARY     Exa mple-2  The Tran sactional database contains 12030 transactions and x number of items  Fig-1: Minim um Support =30% and different Minimum Confidences  Fig-2 Minimum Support =40% and different Minimum Confidences  Fig-3Mi nimum Support =50% and different Minimum Confidences  Fig-4:Minim um Confidence =60% and different Minimum Supports   Fig-5 Mini m um Confidence =70% and different Minimum Supports 423 


 Fig-6 Mini mum Confidence =80% and different Minimum Supports  V. CONCLUS ION In this paper, we have designed a new algorithm for efficiently mining positive and negative association rules in databases. Our approach is novel and different from existing research. We have designed pruning strategies for reducing the search space and improving the usability of mining rules and have used the Yule’s correlation coefficient to judge which form association rule should be mined. It is shown by empirical studies that the proposed approach is effective efficient and promising  REFERENCES  1  R. A grawal, T. IMIELINSKI, and A. SWAMI, “Mining association rules between sets of items in massive databases,” In Proc. of the 1993 ACM SIGMOD International Conference on Management of Data, ACM, Washington D.C., 1993, pp. 207-216 2  R. Agrawal, R. Srikant, “Fast Algorithms for Mining Association Rules,” In Proc. of the 20th Int. Conf. on Very Large Databases\(VLDB ’94\Santiago Chile, 1994, pp. 487-499 3  J. S. Park, M. S. Chen, and P. S. Yu, “An Effective Hash-based Algorithm for Mining Association Rules,” In Proc. of the ACM SIGMOD Int. Conf. on Management of data \(ACM SIGMOD ’95 San Jose, California, 1995, pp. 175-186 4  A. Savasere, E. Omiecinski, and S. Navathe, “An efficient algorithm for mining association rules in large databases,” In Proc.1995 Int Conf. Very Large Database \(VLDB’95\, Zurich, Switzerland, 1995 pp. 1-24 5  A. Savasere, E. Omiecinski, and S. Navathe, “Mining for strong negative associations in a large database of customer transactions,” In Proc. of ICDE, 1998, pp. 494-502 6  W. Teng, M. Hsieh, and M. Chen, “On the mining of substitution rules for statistically dependent items,” In Proc. of ICDM, 2002, pp 442-449 7  X. Wu, C. Zhang, and S. Zhang, “Efficient Mining of Both Positive and Negative Association Rules,” ACM Transactions on Information Systems, Vol. 22, No. 3, 2004, pp. 381–405 8  M. CHEN, J. HAN, and P. YU, “Data mining: An overview from a database perspective,” IEEE Transactions on Knowledge and Data Engineering, Vol. 8 No. 6, 1996, pp. 866-883 9  X. Dong, S. Wang, H. Song, and Y. Lu, “Study on Negative Association Rules,” Transactions of Beijing Institute of Technology Vol. 24, No. 11, 2004, pp. 978-981 10  S. Brin, R. Motwani, and C. Silverstenin, “Beyond market baskets Generalizing association rules to correlations,” In Proc. of the 1997 ACM SIGMOD International Conference on Management of Data ACM, Tucson, Arizona, 1997, pp. 265–276 11  Honglei Zhu and Zhigang Xu “An Effective Algorithm for Mining Positive and Negative Association Rules,” 2008 International Conference on Computer Science and Software Engineering   424 


In other words the mining results of Apriori algorithm are basically consistent with the results of sp atial autocorrelation and spatial regression that is spa tial analysis However the advantage of the spatial analysis is efficiency as spatial data is already known to be large in size It can save time consumption significantly In addition spatial analysis method will find much more in teresting and useful rules and knowledge from the spatial d ata such as the distribution of the variables the cluster ce nters of the variables even the changing trend of the variables VI C ONCLUSION AND F UTURE WORK A Conclusion In this paper two methods are applied to mining association rules including the Apriori algorithm and spatial analysis method\(spatial auto correlation and spatial regression to extract the co rrelation between the county-level revenue and population education state health state and social security state in China from 2 000 to 2005 Results of the two methods are compared in order to find which one is more appropriate under certain circumstance Log transformation is applied to the experiment data which is effective in normalising the data in addition to weakening the negative effect of outliers A strong correlation of the variables is observed, revealing that there are clear spatial patterns of the variables on the distribution map Mining spatial association rules present a great challenge to the developers of multi-relational data mining methods as the explosive growth of spatial data and widespread use of spatial databases emphasize the need for the automated discovery of spatial knowledge In this paper we explore the spatial association rule mining which take account of the spatial autocorrelation of the data. Illustrative examples taken from spatial data of county-level revenue and popu lation education state, health state and social security state in China show that our method enables us to use GeoDa to compute the spatial autocorrelation between the variables and locations. It will be very time consuming if there are a lot of counties to mine the spatial association rules with Ap riori algorithm Moreover implicit spatial patterns will be extracted from the analysis results of spatial auto correlation The most important thing is spatial analysis method will provides priori knowledge to the mining procedure as the results of both methods have so many rules in common However the differences between the two methods showed that the spatial autocorrelation will also brings deviation to the results which we must find ways to eliminate B Future work Besides the deviation that spatial autocorrelation brings to the mining results its very difficult to set the rules to specify the candidate frequ ent itemsets from the spatial autocorrelation In this paper, we get the candidate frequent itemsets by the level of correlation between the variables and the goodness of fit of the models and dont know how the spatial autocorrelation affect the mining procedure So how to maintain the impact on mining procedure that is when to make use of the spatial autocorrelati on and when to eliminate it should be impro ved in the future A CKNOWLEDGEMENTS This paper is funded by the National Natural Science Foundation of China-Yout h Science Fund Project\(No 40801152 and Scho larship Research Fund Pr oject Ministry of Education\(No.213153249 R EFERENCES  Tobler W A com pute r m ovie si mulating urban growth in the Detroit  region Economic Geography  vol 46, pp. 234-240 Feb. 1970  Clark, Philip Evans, "Distance to nearest neighbor as a m easure of  spatial relationships in populations Ecology \(Ecological Society of America  vol. 35 pp. 445…453. Apr. 1954  Moran Notes on Continuous Stocha stic Pheno m ena Biometrika  vol 37 pp 17…33 1950  Cressie, N Statistics for Spatial Data \(Revised Edition New York Wiley 1993  S. Rouhani, R.M. Srivastava, A.J Desbar ats, M.V. Cromer and A.I Johnson Geostatistics for Environmental and Geotechnical Applications West Conshohocken,USA:ASTM ,1996  Jacqueline Geoghegan Lisa A Wainger and Nanc y E.Bockstael Analysis Spatial Landscape Indices in a Hedonic Framwork: an ecological economics analysis using GIS Ecological Economics  vol 23 pp. 251-264 Mar. 1997  Sabyasachi B asu Anal y sis of S p atial Autocorrel ation in Hous e Prices Journal of Real Estate Finance and Economics  vol. 17, pp 61-85, Jan. 1998  Raym ond T a nd Jiawei Han Effcient and Effec tive Clustering Methods for Spatial Data Mining  Proceedings of the 20th VLDB Conference  1998 paper 10.1.1, p. 144  Roddick, J. F an d Spiliopoulo u,M A Bibliography of Temporal Spatial and Spatio-Temporal Data Mining Research SIGKDD Explorations  Vol. 1 pp 34-38 Jan. 1999  W. Lu, J. Han, an d B. C   Ooi Dis covery of G e neral Knowledge in  Large Spatial Databases In Proc. Far East Workshop on Geographic Information Systems  1993 paper 11.1.2 p 275  Quinlan, J Programs for Machine Learning Morgan Kaufmann Publishers.1993  Barnett, V.and Le wis, T  Outliers in Statistical Data 3rd edition  John Wiley 1994  Agrawal, R., and Srikant R    Fast  Algorith m s for Mi ning Association Rules In Proc. of Very Large Databases 1994 paper 10.1.1, p. 1  A.Jain and R.Dubes Algorithms for Clustering Data  Lodon,UK:Prentice Hall 1988  Quinlan.J Programs for Machine Learning Morgan Kaufmann Publishers, 1993  S.S.Shekhar,P S.Zhang,Y.Huang and R.G.Raju Trends in Spatial Data Mining Vatsavai India:Next generation challengens and future directions, 2004  CHEN Jiangpng FU Zhongliang and XU Zhihong, "An I m proved Algorithm of Apriori Geomatics and Information Science of Wuhan University  vol. 28, pp. 94-99 Jan. 2005  R.G.D.Steel and J.H.Torrie Principles and Procedures of Statistics New York,USA: McGraw-Hill 1960  R.C Dennis Residuals and Influence in Regression New York,USA Chapman and Hall 1982  G. L  Ri chard Statistical Concepts: A Second Course New York,USA Routledge Academic 2007  O'Mahony and Michael Sensory Evaluation of Food: Statistical Methods and Procedures CRC Press 1986 


s2,c2 from Xl sl,c1  s,C association rule X3 s,c  B. Post Mining o/Non-redundant Association Rules /or Sensor Data Estiamtion In this subsection, we describe our proposed technique for post mining of non-redundant association rules for sensor data estimation purpose. This algorithm is developed based on non-redundant informative association rules which means all rules cannot be derived from other rules and the left hand side and right hand side of the selected rules contain the input itemset. There are some research works that can generate the closed itemsets and corresponding association rules using generated closed itemsets [3 , 18 Based on our previous works [8] we assume to have the non-redundant association rules ready and the criteria of selecting the rules from non-redundant rules further reduce the number of rules to the minimum In this algorithm, dn.vm is treated as one item in association rules. Dn represents the sensor which is indexed as n. Vm represents the value of the sensor n is read as m. In the following figure, Xinput is the itemset represent the current round of sensor readings, it can be represented by a set of dn.vm pairs. Xl and X2 are the itemsets in left hand side and right hand side of association rules. Z represents all items in X2/Xinput. Index\(z z and value of sensor value pair z. Confidence{Xl=>X represents the confidence of the rule Xl=>X2 Support\(Xl=>X2 C represents the confidence of association rule, dn V represents the identifier and value pair of the sensor dn Xestimate represents the returned estimation itemset which contains the senor identifiers with missing values in the current round of readings of stream data and their corresponding estimated values. Sspecify represents the user specified support, and Cspecify represents the user-specified confidence The algorithm is described as below. The input of the procedure Estimate includes the current round of sensor reading, current association rule confidence, user-specified minimum support and user-specified minimum confidence 


In line 4, all association rules that satisfy with the conditions of minimum support and confidence are selected The confidence of the select association rules are calculated in line 5. The condition of line 6 filters out the rules whose left hand side itemset Xl does not contain the itemset Xinput in this case, sensor identifier is filtered based on the enriched contextual information. The condition of line 7 filters out the rules whose right hand side itemset X2 does not contain new estimated items. Each new item was processed in line 8 and 9 so that missing sensor values are V5-104 2010 2nd International Conference on Education Technology and Computer \(ICETC modified and updated. At the end of this procedure, an iterative call of the same procedure keep on searching and processing for the new association rules that are able to make contribution on the sensor value estimation Input: \( 1 contains missing values 2 3 Output: Xestimste: a set containing the senor ids with missing values in the current round of sensor readings and their corresponding estimated values Method 1 Xestirnste = <\\l 2 Cinput=l 3 Procedure Estimate\(XinpUb Cinpub Sspecify, Cspecify 4 for all \(rule: X,=>X2 and Support\(X,=>X2 Confidence\(X,=>X2 5 C = Conjidence\(X,=>X2 6 if \(X,EAinput 7 if\(X2\\Xinput*<\\l 8 for all \(ZEX2\\Xinput and zE Xestimste 9 Xestimste = Xestimste U z 10 n = index\(z 1 1  d., v= dn v +C*value\(z 12 end for 13 end if 14 Estimate\(X2, C, Sspecify, Cspecify 15 end if 16 end for 17 end procedure 


Figure 1. The post mining of non-redundant association rule for sensor data estimation IV. EXPERIMENTAL STUDY The performance of our proposed approach is studied by means of simulation. Several different simulation experiments are conducted in order to evaluate the proposed technique and compare it with the Average Window Size A WS linear trend approach, and with the WARM approach, the state-of-the-art data estimation algorithm in sensor databases using 2-frequent itemsets based association mining [6]. We compared the estimation accuracy, running time and memory space usage when applying different methods to the application dataset The dataset was collected in year 2000 at various locations throughout the city of Austin, Texas. The data represents the current location, the time interval, and the number of vehicles detected during this interval. All sensor nodes report to a single server. The sensors are deployed on city streets, collect and store the number of the vehicles detected for a given time interval. The vehicle counts taken as sensor readings that are used as input for our simulation experiments are traffic data provided by [2 A. Performance Study of Estimation Accuracy The evaluation of the estimation accuracy of the missing values is done by using the average Root Mean Square Error RMSE I'\(xa, -Xe 1 ___ l __ lI_?''? ____ _ numStates # estimations where Xa; and Xe; are the actual value and the estimated value, respectively; #estimations is the number of estimations performed in a simulation run; and numStates is the number of subsets, in which the actual readings are distributed The expression u  xa, -Xe estimations error and is an estimate of the standard deviation under the assumption that the errors in the estimated values \(i.e. Xai Xei 


see the smaller the RMSE, the better the estimation accuracy From Figure 2, we can see that the proposed technique gives the best average estimation result of the above approaches regarding the accuracy, followed by the WARM approach. The linear interpolation, A WS, and linear trend approaches perform no better than WARM and the proposed approaches. From Figure 2, we can also see that the proposed technique gives the best estimation result on the maximum estimation accuracy, which is the root square error for the maximum difference between the estimated and accurate values 0.6 0.5 0.4 w n 0.3 cz 0.2  Average 0.1  Maximum 0 l' ?? 0" </.,oQ Figure 2. Perfonnance study of average and maximum estimation accuracy for traffic monitoring application B. Performance Study of Running Time Figure 3 illustrates the running time in seconds of A WS linear interpolation, linear trend, WARM and proposed approaches. The experimental results show that in terms of running time, the WARM and proposed approaches are outperformed by A WS, linear interpolation and linear trend V5-105 2010 2nd International Conference on Education Technology and Computer \(ICETC approaches. The proposed approach is faster than the WARM technique 0.03 v 0.025 0.02 E U.uJ c 0.01 0.005 0 a  r 


r r r  9  Figure 3. Performance study of running time for traffic monitoring application in seconds C. Performance Study of Memory Usage Figure 4 illustrates the memory usage of A WS, linear interpolation, linear trend, WARM and proposed approaches in MB. The experimental results show that in terms of memory space, the WARM approach is outperformed by all the other four approaches. The results of the simulation experiments show that for 108 sensors the needed memory space using WARM is much higher than that using proposed approach. This is because the closed lattice data structure uses less memory space than the cube data structures, and it only stores the condensed closed itemsets information Figure 4. Performance study of memory usage for traffic monitoring application in MB V. CONCLUSTIONS Sensor stream applications are becoming very common with the advances in technologies for sensor devices. In this paper we propose a method to post mine non-redundant association rules, and used the result to produce missing data estimation in sensor network applications. The objective is to further reduce the resulting rules from non redundant association rule mining based on the users request, and apply the retrieved meaningful information to perform missing data estimation in wireless sensor networks We have evaluated the proposed technique with real data from a wireless sensor network of a traffic monitoring site Our proposed method is able to estimate missing sensor value with both time and space efficiency, and greatly improves the estimation accuracy. Our performance study 


shows that proposed post mining of association rule mining technique for missing sensor data estimation is an area worth to explore REFERENCES 1] Agrawal, R., & Imielinski, T., & Swami, A., "Mining association rules between sets of items in massive databases", International Conference on Management of Data, 1993 2] Austin, F. I., "Austin Freeway ITS Data Archive", Retrieved January 2003 from http://austindata.tamu.eduidefauIt.asp 3] Bastide, Y., & Pasquier, N., & Taouil, R, & Stumme, G., & Lakhal L., "Mining minimal non-redundant association rules using frequent closed itemsets", First International Conference on Computational Logic, 2000 4] Cool, A. L., "A review of methods for dealing with missing data The Annual Meeting of the Southwest Educational Research Association, 2000 5] Deshpande, A., & Guestrin C., & Madden, S., "Using probabilistic models for data management in acquisitional environments", The Conference on Innovative Data Systems Research, 2005 6] Halatchev, M., & Gruenwald, L., "Estimating missing values in related sensor data streams", International Conference on Management of Data, 2005 7] Iannacchione, V. G., "Weighted sequential hot deck imputation macros", Proceedings of the SAS Users Group International Conference, 1982 8] Nan Jiang, "Discovering Association Rules in Data Streams Based On Closed Pattern Mining", SIGMOD Ph.D. Workshop on Innovative Database Research, 2007 9] Li, Y., & Liu, Z. T., & Chen, L., & Cheng, W., & Xie, C.H Extracting minimal non-redundant association rules from QCIL The 4th International Conference on Computer and Information Technology, 2004 10] Little, R 1. A., & Rubin, D. B., "Statistical analysis with missing data", New York: John Wiley and Sons, 1987 II] McLachlan, G., & Thriyambakam, K., "The EM algorithm and extensions", New York: John Wiley & Sons, 1997 12] Mitchell, T., "Machine Learning", McGraw Hill, 1997 13] Papadimitriou, S., & Sun, 1., & Faloutsos, C., "Streaming pattern discovery in multiple time-series", The International Conference on Very Large Databases, 2005 14] Rubin, D., "Multiple imputations for nonresponce in surveys", New York: John Wiley & Sons, 1987 


15] Shafer, 1., "Model-Based Imputations of Census Short-Form Items In Proceedings of the Annual Research Conference, 1995 16] Taouil, R., & Pasquier, N., & Bastide, Y., & Lakhal, L., "Mining bases for association rules using closed sets", International Conference on Data Engineering, 2000 17] Wilkinson & The AP A Task Force on Statistical Inference, 1999 18] Zaki, M. 1., Hsiao, C. 1., "Efficient algorithms for mining closed itemsets and their lattice structure", IEEE Transactions on Knowledge and Data Engineering, 2005 V5-106 


General Chair f!!\f  Organizing Chairs  f!!\f  f$% \f!!\f  Organizing Co-chairs f    f  f\f   f\f\f   f*!\f!\f.\f  f f  Program Committee Chairs  f\f\f   f!!\f  Publication Chair 0   


200 250 300  The size of dataset/10,000 R es po ns e tim e S    a 0 50 100 150 200  The size of dataset/10,000 R es po ns e tim e S    b 0 10 20 30 40 50 


60  The size of dataset/30,000 R es po ns e tim e S    c Fig. 9 The scalability of our algorithm compared with FP-growth  Paper [12] proposed a way to reduce times of scanning transaction database to reduce the cost of I/O IV. CONCLUSIONS AND FUTURE WORK This paper first discusses the theory of foundations and association rules and presents an association rules mining algorithm, namely, FP-growth algorithm. And then we propose an improved algorithm IFP-growth based on many association rules mining algorithms. At last we implement the algorithm we propose and compare it with algorithm FPgrowth algorithm. The experimental evaluation demonstrates its scalability is much better than algorithm FP-growth 177 Now, lets forecast something we want to do someday Firstly, we would parallelize our algorithm, because data mining needs massive computation, and a parallelable environment could high improve the performance of the algorithm; Secondly, we would apply our algorithm on much more datasets and study the run performance; At last, we would study the performance when the algorithm deal with other kinds of association rules  REFERENCES 1] S. Sumathi and S. N. Sivanandam. Introduction to Data Mining and its Applications, Springer, 2006 2] V. J. Hodge, J. Austin, A survey of outlier detection 


methodologies, Artificial Intelligence Review, 2004, 22 85-126 3] Han, J. and M. Kamber. Data Mining: Concepts and Techniques. Morgan Kaufmann, San. Francisco, 2000 4] Jianchao Han, Mohsen Beheshti. Discovering Both Positive and Negative Fuzzy Association Rules in Large Transaction Databases, Journal of Advanced Computational Intelligence and Intelligent Informatics 2006, 10\(3 5] Jiuyong Li, Hong Shen, Rodney Topor. Mining Informative Rule Set for Prediction. Journal of Intelligent Information Systems, 2004, 22\(2 6] Jianchao Han, and Mohsen Beheshti. Discovering Both Positive and Negative Fuzzy Association Rules in Large Transaction Databases. Journal of Advanced Computational Intelligence, 2006, 10\(3 7] Doug Burdick, Manuel Calimlim, Jason Flannick Johannes Gehrke, Tomi Yiu. MAFIA: A Maximal Frequent Itemset Algorithm. IEEE Transactions on Knowledge and Data Engineering, 2005, 17\(11 1504 8] Assaf Schuster, Ran Wolff, Dan Trock. A highperformance distributed algorithm for mining association rules. Knowledge and Information Systems, 2005, 7\(4 458-475 9] Mohammed J. Zaki. Mining Non-Redundant Association Rules. 2004, 9\(3 10] J.Han, J.Pei, Y.Yin, Mining frequent patterns without candidate generation, Proceedings ACM SIGMOD 2000 Dallas, TX, May 2000: 1-12 11] P.Viola, M.Jones. Rapid Object Detection Using A Boosted Cascade of Simple Features. Proc. IEEE Conf. on Computer Vision and Pattern Recognition, 2001 12] Anthony K. H. Tung, Hongjun Lu, Jiawei Han, Ling FengJan. Efficient Mining of Intertransaction Association Rules. 2003, 154\(1 178 


For each vertex b in g form j forests body\(a, g, i s.t. bodyAnt\(a, g, i a, g, i with itemsets Ant\(b b and each subset of itemsets Ant\(b b in P\(a, g, j Assign to each leaf l of trees bodyAnt\(a, g, i bodyCons\(a, g, i a fresh variable Vm,M, m, M = size\(itemset\(l Assign to each leaf l of tree headAnt\(a, g, j the variable assigned to itemset l in some leaf of some tree bodyCons\(a, g, i TABLE II.  EXPERIMENTAL DATA Conf. #rules #pruned #dftrs PtC 0.5 6604 2985 1114 0.6 2697 2081 25 0.75 1867 1606 10 0.8 1266 1176 0 0.95 892 866 1 0.98 705 699 1 DSP 0.5 2473 1168 268 0.6 1696 869 64 0.75 1509 844 89 0.8 1290 1030 29 0.95 1032 889 15 0.98 759 723 1 Arry 0.5 770 492 82 0.6 520 353 60 0.75 472 327 39 0.8 408 287 22 0.95 361 255 25 0.98 314 243 30  Our induction algorithm has been launched for each combination of thresholds. Our scheme eliminates all redundant rules in the sense of [25, 31], i.e. those association rules that are not in the covers. All the meta-rule deductive schemes implicitly included in [25] and [31] are induced by our method. The percentage of pruning, thus, outperforms [25 


The results produced for k=3, support 0.25 and confidences between 0.7 and 0.99 are shown in Fig. 3, in terms of pruning percentage \(vertical axis when applied to low confidences \(from 0.7 to 0.9 The percentage of pruning achieved diminishes as the confidence is superior to 0.9. Nevertheless, the pruning is effective with confidence of 0.99 in the majority of cases Pruning at Support = 0.25 0,00 5,00 10,00 15,00 20,00 25,00 30,00 35,00 40,00 45,00 50,00 0,7 0,8 0,9 0,95 0,99 Confidence P ru n in g L e v e l Case 1 Case 2 Case 3  Figure 3.  Pruning experiences at support 0.25  V. DISCUSSION AND CHALLENGES It is important to discuss the technique presented here with focus on the purpose the technique pursues:  to produce semantic recommendation The reader should have noticed that the algorithm presented 


relies strongly on "choice". For instance, the algorithm chooses ears in the graph to form an order for elimination, and the choice is arbitrary. This strategy is essential to maintain low complexity \(polynomial practical. Nevertheless, a warned reader may conclude that this arbitrary choice implies that there are many compactions to produce and therefore the approach as a whole does not show to produce an optimal solution. And the reader is right in this conclusion. Since the goal is compaction, the search for an optimal solution can be bypassed provided a substantial level of pruning is achieved To complete the whole view, we describe how web service descriptions are complemented with the association rules as recommendations. In effect, under our scheme, the document describing the web service is augmented with a set of OWL/RDF/S triples that only incorporate the non-pruned rules with the format of Example 1, that is, the set ARmin of the compaction program obtained by our algorithm, together with the thresholds applied to the mining process and a registered URI of a registered description service. The assumptions and defeaters are not added to the web service description. If the associations encoded in the triples are not sufficient for the client \(a search engine, for instance widening of the response to the description service identified by the given URI, and then the assumptions and defeaters are produced. The reasoning task required for deriving all the implicitly published rules is client responsibility Notice that, under this scheme, the actual rules that appear as members of the set initial ARmin set are irrelevant; the only important issue is the size of the set The developed scheme also supports an extension of the algorithm that admits the assignment of priorities to rules and to itemsets, in order to allow the user to produce a more controlled program as output. Nonetheless, the importance of the extension has not been already tested, and therefore it is beyond the subject of the present paper It would be also interesting to design a scheme that supports queries where the client provides an itemset class and values for support and confidence and the engine produces a maximal class of inferred associated itemsets as a response. This scheme is also under development, so we have not discussed this aspect here 


VI. CONCLUSION In this paper, we have presented a defeasible logic framework for managing associations that helps in reducing the number of rules found in a set of discovered associations. We have presented an induction algorithm for inducing programs in our logic, made of assumption schemas, a reduced set of association rules and a set of counter-arguments to conclusions called defeaters, guaranteeing that every pruned rule can be effectively inferred from the output. Our approach outperform those of [17], because all reduction compactions presented there can be expressed and induced in our framework, and several other patterns, particular to the given datasets, can also be found. In addition, since a set of definite clauses can be obtained from the induced programs, the knowledge obtained can be modularly inserted in a richer inference engine Abduction can be also attempted, asking for justifications that explain the presence of certain association in the dataset The framework presented can be extended in several ways Admitting defeaters to appear in the head of assumption, to define user interest Admitting arithmetic expressions within assumptions for adjustment in pruning Admitting set formation patterns as itemset constants Extending the scope, to cover temporal association rules REFERENCES 1]  R. Agrawal, and R. Srikant: Fast algorithms for mining association rules In Proc. Intl Conf. Very Large Databases. \(1994 2]  A. V. Aho, J. E. Hopcroft, J. Ullman. The design and analysis of computer algorithms, Addison-Wesley, 1974 3]  G. Antoniou, D. Billington, G. Governatori, M. J. Maher, A. Rock: A Family of Defeasible Reasoning Logics and its Implementation. ECAI 2000: 459-463 4]  G. Antoniou, D. Billington, G. Governatori, M. J. Maher: Representation results for defeasible logic. ACM Trans. Comput. Log. 2\(2 2001 5]  A. Basel, A. Mahafzah, M. Al-Badarneh: A new sampling technique for association rule mining, Journal of Information Science, Vol. 35, No. 3 358-376 \(2009 6]  R. Bayardo and R. Agrawal: Mining the Most Interesting Rules. In Proc of the Fifth ACMSIGKDD Intl Conf. on Knowledge Discovery and Data Mining, 145-154, \(1999 


7]  R. Bayardo, R. Agrawal, and D. Gunopulos: Constraint-based Rule Mining in Large, Dense Databases. Data Mining and Knowledge Discovery Journal, Vol. 4, Num-bers 2/3, 217-240. \(2000 8]  A. Berrado, G. Runger: Using metarules to organize and group discovered association rules. Data Mining and Knowledge Discovery Vol 14, Issue 3. \(2007 9]  S. Brin, R. Motwani, J. Ullman, and S. Tsur: Dynamic itemset counting and implication rules for market basket analysis. In Proc. ACMSIGMOD Intl Conf. Management of Data. \(1997 10] L. Cristofor and D.Simovici: Generating an nformative Cover for Association Rules. In ICDM 2002, Maebashi City, Japan. \(2002 11] Y. Fu and J. Han: Meta-rule Guided Mining of association rules in relational databases. In Proc. Intl Workshop on Knowledge Discovery and Deductive and Object-Oriented Databases. \(1995 12] B. Goethals, E. Hoekx, J. Van den Bussche: Mining tree queries in a graph. KDD: 61-69. \(2005 13] G. Governatori, D. H. Pham, S. Raboczi, A. Newman and S. Takur: On Extending RuleML for Modal Defeasible Logic. RuleML, LNCS 5321 89-103. \(2008  14] G. Governatori and A. Stranieri. Towards the application of association rules for defeasible rules discovery In Legal Knowledge and Information Systems, JURIX, IOS Press, 63-75. \(2001 15] J. Han, J. Pei and Y. Yin: Mining frequent patterns without candidate generation. In Proc. ACM-SIGMOD Intl Conf. Management of Data 2000 16] C. Hbert, B. Crmilleux: Optimized Rule Mining Through a Unified Framework for Interestingness Measures. DaWaK: LNCS 4081, 238247. \(2006 17] E. Hoekx, J. Van den Bussche: Mining for Tree-Query Associations in a Graph. ICDM 2006: 254-264 18] R. Huebner: Diversity-Based Interestingness Measures For Association Rule Mining. Proceedings of ASBBS Volume 16 Number 1, \(2009 19] B. Johnston, Guido Governatori: An algorithm for the induction of defeasible logic theories from databases. Proceedings of the 14th Australasian Database Conference, 75-83. \(2003 20] P. Kazienko: Mining Indirect Association Rules For Web Recommendation. Int. J. Appl. Math. Comput. Sci., Vol. 19, No. 1, 165 186. \(2009 21] M. Klemettinen, H. Mannila, P. Ronkainen, H. Toivonen, and A Verkamo: Finding interesting rules from large sets of discovered association rules. In Proc. 3rd Intl Conf. on Information and Knowledge 


Management. \(1994 22] M. J. Maher, A. Rock, G. Antoniou, D. Billington, T. Miller: Efficient Defeasible Reasoning Systems. International Journal on Artificial Intelligence Tools 10\(4 2001 23] C. Marinica, F. Guillet, and H. Briand: Post-Processing of Discovered Association Rules Using Ontologies. The Second International Workshop on Domain Driven Data Mining, Pisa, Italy \(2008 24] N. Pasquier, Y. Bastide, R. Taouil, and L. Lakhal: Closed sets based discovery of small covers for association rules. In Proc. BDA'99 Conference, 361-381 \(1999 25] N. Pasquier, R. Taouil, I. Bastide, G. Stume, and  L. Lakhal: Generating a Condensed Representation for Association Rules. In Journal of Intelligent Information Systems, 24:1, 29-60 \(2005 26] P. Pothipruk, G. Governatori: ALE Defeasible Description Logic Australian Conference on Artificial Intelligence.  110-119 \(2006 27] J. Sandvig, B. Mobasher Robustness of collaborative recommendation based on association rule mining, Proceedings of the ACM Conference on Recommender Systems \(2007 28] W. Shen, K. Ong, B. Mitbander, and C. Zaniolo: Metaqueries for data mining. In Fayaad, U. et al. Eds. Advances in Knowledge Discovery and Data Mining. \(1996 29] I. Song, G. Governatori: Nested Rules in Defeasible Logic. RuleML LNCS 3791, 204-208 \(2005 30] H. Toivonen, M. Klemettinen, P. Ronkainer, K. Hatonen, and H Mannila: Pruning and grouping discovered association rules. In ECML Workshop on Statistics, Machine Learning and KDD. \(1995 31] M. Zaki: Generating Non-Redundant Association Rules. In Proc. of the Sixth ACMSIGKDD Intl Conf. on Knowledge Discovery and Data Mining, 34-43, \(2000 32] w3c. OWL Ontology Web Language Reference. In http://www.w3.org/TR/2004/REC-owl-ref-20040210 33] w3c. RDF/XML Syntax Specification. In: http://www.w3.org/TR/rdfsyntax-grammar 34] w3c. RDF Schema. In: http://www.w3.org/TR/rdf-schema      


 8   2  3\f            8  D    F  \b 1 8 & #J      b 1  1  4    2  


4 1    9  E 1  2 4 1    9 1   4      8 2  8 1  D 1        1 1  b 


     b b b b b  K            8          2 D 9   F  \b 1 8 ,+J  9 


     b 1     1 2  9 1  12 L 1   9  8       1  2      2   


     b b b b b  K            2  0 \b f  b\f      9       


  8 2   E 1   1     M13 31L 1    b  8E 1   1 #3\b?### 1  1     E 1   1 \b?###3        


1   1   b 1  2 2 18 2     8              1    2 \b 1    2  


    2          2   1 L 2 1   1   L 2 2    2 1  2        


    8  2H D \b A             2  2H D \b A 2 \f 3%\f  f   4%\f f !  , \f\b  C    2    2 


 6    3 1      253 6   1 L 2    6   1         f\b3\f       


               1     1     8 2    E       2  1   


     2 8    b 4      1 8             1 2     1  8 2  


1 9    8      2 1       1     2    8    2 3\f        


     8 D 4 9  F  \b 1 8 #J 9 1     2 1   2 #-@ 1   2 9  E 1   1   2 9      6  


    8  8   1  D 1         1 F  \b0         2 D    F  \b 1 8  9  


  1 9  1   E 1  2 9     1 1 F  \b       1    18   F   1    1 #-$+  \b  2 2  


1 D     1 #-$+.B- 0/:% .0             9 1      18    1 6     1 2  1  1  


1   6      2    1 2 E 8 D 1      1 2   1   1 #-4  #-@E     2  1  1  1       


 8     1          2 F    6   F  2   8    2 C<CC/C N\bO 5      


CD    b$44NO F P Q 6   2 b$$$ ,=\b\bA  A N,O 2 C C  b$$4N  92 2   f  9-\b$$4 B N?O  !-    91  2 1 HH111-18-N+O    -1 :3%   2     0-4 


     b N4O 2   2- \f  C b$@$ \b# >\b\b$3\b$N@O  f :.% 9 /9 \f    1  6  f 2  4   A254 


Advantages of Our M ethod Advantages of Our M ethod Exploit the memory v ertical data format utilizes slidin g windows to g form a much larger database to analyze  Flexibility in Choosing what to choose  Choosing what to choose to build the rules Computational and memory efficiency We have a team working only on this aspect 45 Associative IDS for NextGen Frameworks Dr S Dua LA Tech 45 


Preliminary Results Intra transaction Relations Data rate simulator NH-134 Mb HOP PATH update \(Y/N Inference 11.5 Y Y 2 0.120 N N      Y   n 0.345 N NH134 Y/N   Inf 1 0.150 N N 2 0 120 Y N Inter transaction Relations 2 0  120 Y N       5 5.55 0.456 Y Relations  n 0.345 N N Nmap on DMRL nmap.org 


Anticipated Outcome Anticipated Outcome Develop algorithm capable of learning from a given heterogeneous diverse Develop algorithm capable of learning from a given heterogeneous diverse data ff Dynamic algorithmic f ramework designed to shi f t modalities and sampling rates based on complex logic Flexibility of integration into the Snort intrusion detection system 47 Associative IDS for NextGen Frameworks Dr S Dua LA Tech 47 


References References Aircraft Cockpit Image courtesy USAF http://www.faa.gov htt p   www.faa g ov  air traffic  technolo gy  p g  _ gy  Acharya R Dua S Du X Sree V Chua C K Automated Diagnosis of Glaucoma Using Texture and Higher Order Spectra Features To appear in IEEE Transactions on Information Technology in Biomedicine  Du X Dua S 2011 Cancer Prognosis Using Support Vector Regression in Imaging  Modality World Journal of Clinical Oncology 2  1   44 49 Du X Dua S 2010 Salient Frame Extraction Using Support Vector Regression and Motion Features pp 5 Proc of the National Aerospace and Electronics Conference July 14 16 2010 D M P D S 2010 Di i i ti Ft d Cl ifi ti Mthd f D essaue r  M  P  D ua S  2010  Di scr i m i na ti ve F ea t ures an d Cl ass ifi ca ti on M e th o d s f or Accurate Classification 1st ed vol 7704 pp 14 Bellingham WA Proceedings of SPIE Dessauer M P Dua S 2010 Low Resolution Vehicle Tracking using Dense and Reduced Local Gradient Features Maps 1st ed vol 7694 pp 8 Bellingham WA Proceedings of SPIE SPIE 


Acknowledgements Acknowledgements Fundin g A g encies  US 4 1 Million direct fundin g g g 4 g LA BoR NIH NSF AFRL AFOSR and NASA Research Team Samuel Kasimalla Brandy McKnight Dr Pradeep Chowriappa Connor Johnson Vasanth Nair Mihir Chowriappa  Connor Johnson  Vasanth Nair  Mihir Karnik Mohit Jain and Swadheen Songmen Associative IDS for NextGen Frameworks Dr S Dua LA Tech 49 All the respective Logos belong to their owners 


Rf d Rdi R e f erence d R ea di ngs Copyright of cover pages held by respective publishers 


Thank You Questions Thank You  Questions Dr Sumeet Dua E mail sdua@latech.edu Web http://dmrl.latech.edu Associative IDS for NextGen Frameworks Frameworks Dr S Dua LA Tech 51 Image Source roadtrafficsigns.com 


