  The Application of Association Rules Algorithm in the Optimization of Information Processing in Intelligent Question-Answering System  Liang Yunjuan School of Information Engineering Henan Institute of Science and Technology Xinxiang, China Liang_yunjuan@126.com Zhang Lijun School of Information Engineering Henan Institute of Science and Technology Xinxiang, China 17283875@qq.com Kong Dechuan School of Information Engineering Henan Institute of Science and Technology Xinxiang, China 
kdc@hist.edu.cn Yin Liqiang School of Information Engineering Henan Institute of Science and Technology Xinxiang, China liqiangyin@tom.com   Abstract This paper applied association rule mining method in the intelligent question-answering system, dug out the potential rules which user uses to sort the results in the process of browsing the results, and then generated the rule base and optimized the processing of information.  Present the steps of mining association rules. Through pre-mining resources and analysis of mining association rules, focus on the improvement 
of associated Boolean Apriori algorithm and application in the transaction database.  Finally, get the algorithm for the strong association rules extracted from the frequent itemsets Keywords-Association Rule; Information Optimization Apriori Algorithm; Frequent Itemsets I  I NTRODUCTION  In the distance learning platform, question-answering system becomes an important part of online education, it plays an essential role in enhancing the exchange of teachers and distance learners, and helping distance learners access to the information they really need 1 2  In question-answering 
system, how to effectively optimize the processing of information has become a hot topic of current research  As to data mining methods like the correlation analysis this paper did the comprehensive analysis and research in theory and algorithms, dug out the hidden information classification behind the database by using data mining technology,  found the relationship between knowledge points and the questions that students frequently asked, dug out  the potential rules which user uses to sort the results in the process of browsing the results, and then generated the rule base and optimized the processing of information.  This 
built a strong guarantee for intelligent question-answering system II I MPLEMENTATION OF M INING A SSOCIATION R ULES  The concept of association rules was raised by the Agrawal, Imielnski, Swami. It is a hot topic in data mining and widely used in marketing, business analysis, financial industry and other applications.  Association rule mining algorithm is the main content of research on mining association rules.  The task for discovering association rules is to find all the rules meeting pre-specified frequency and 
accuracy standard 3 4  A Pre-mining resources  Transaction data set is the data source that association rule mining directly faces, and it has an important impact on the precision of mining results.  Therefore, while establishing transaction data set, we must preprocess the original data     After the user raises the initial questions, the system will produce a series of relevant results and these results are calculated according to the derived weights of users questions.  When the user performs a selective review of 
some of the results \(R1 ... Rn\\(R1 ... Rn transaction, but we can not blindly add all the transactions to the transaction data set, not only because of the huge number of these transactions, and little value of a considerable portion. Some screenings of these transactions are needed For example, in an interview process, a user only browses one or two results and ends the visit. In general, we think that the user has found a satisfactory answer and doesnt need add this transaction to the transaction data set.  After the investigation, the user usually browses the results three to five times if the user has the questions in doubt, and these result sets are the last mining data set 
 B Association Rules Mining Association rules are given a set of items \(Item\and a record collection. By analyzing record collection, derive the correlation between Items.  In the system of association rules the rule itself is a simple form like "If what condition is met then what results or circumstances will be gotten".  It can be expressed as "X 002 Y" association rule, which consists of two parts: the left part of X is called antecedent and the right part of Y is called consequent 
2011 International Symposium on Computer Science and Society 978-0-7695-4443-4/11 $26.00 © 2011 IEEE DOI 10.1109/ISCCS.2011.86 296 


  Association rules can be described in mathematical formula 6  Let I = {i 1, i 2, ..., i m} is a collection composed of m different items \(normally we also call I itemset\.  Given a database D, each record T in the database D is one collection in I, namely T 003 I.  Let X be one set of items in I, if X 003 T we say T contains X.  An association rule is an implication like the form X 002 Y, where X 002 I,Y 002 I, X 002 Y 004  Association rules mining is a two-step process 1.  Find all the frequent itemsets By definition the emergence frequency of these itemsets is minimum, same as predefined minimum support value 2. Strong association rules generated by frequent itemsets By definition, these rules must satisfy minimum support and minimum confidence The second step of these two steps is the easiest, so the overall performance of mining association rules is determined by the first step.  Generating all the frequent itemsets is the first step in mining association rules, and largely determines the overall efficiency of mining Determine whether it is the frequent itemset by calculating the minimum support of a variety of combinations of itemsets in the transaction database In the process of mining association rule at the first step the most famous algorithm is the Apriori algorithm III A PRIORI A LGORITHM AND ITS A PPLICATION  A Apriori Algorithm  Apriori algorithm is one Boolean Association Rule Mining algorithm proposed by Agrawal et al. It is the foundation of the level algorithm and the most typical level algorithm. It is the most successful and first-class algorithm among Boolean Association Rule Mining algorithms.  Its core technology is widely used by other types of Boolean Association Rule Mining algorithms   Apriori uses an iterative method called the layer-by-layer searching, k-itemset is used to search for \(k +1\-itemset First, find the collection of frequent 1-itemset, which is denoted as L1.  L1 is used to find the collection L2 of frequent 2-itemset and L2 is used to find L3, and so on until no frequent k-itemset is found.  Searching for each Lk requires scanning the database each time.  Therefore, Apriori algorithm has two fatal performance bottlenecks 1.  Repeatedly scanning the transaction database requires a lot of I/O load.  In each loop of k, each element in candidate itemset Ck must be verified by scanning the database to find out if it joins Lk.  If a large frequent itemset contains 10 major items, and then need scan the transaction database at least 10 times 2.  Very large candidate itemsets are possibly generated The number of candidate itemset Ck generated by L k-1 grows exponentially, for example, 104 1-frequent itemset possibly generates 2-frequent candidate itemset with about 107 elements.  Such a large candidate itemset is a challenge to time, memory and space B Apriori Algorithm Improvements For the above-mentioned issues, it can be resolved by compressing the transactions and classifying the transactions and data sets Compress the number of the transactions used for further iterative scan.  If the transaction does not contain any k itemset, it can not contain any \(k + l\ item set. The DELETE flag may be added to these transactions and they are no longer considered while scanning the database The division of transaction data sets divides transaction data sets into three disjoint blocks based on different majors As to questions raised by the user, scan the corresponding block and obtain maximal frequent itemsets for different majors. This can significantly reduce the consumption of time, memory and space C Application and Implementation of Apriori Algorithm  This paper applied the improved association rules algorithm to dig out the association analysis between keywords in question-answering system. Find out a keyword or keywords which often appear together, and find out the correlation or relationship.  Correlation analysis, which is same as the majority of text-based analysis of the same data set, first pre-cut and preprocess the text data, and then call the association rule mining algorithms.  Generate a keyword associated table from the generated association rules, and calculate the correlation between the keywords through the associated table All the documentation sets are regarded as the transaction database, each document \(questions or answers is regarded as a transaction, the words contained in each document is regarded as a collection of item sets, and keyword groups in the document are regarded as a set of transactions. Then the text transaction can be expressed as Document ID, Keyword 1, Keyword 2, Keyword 3 Keyword n Keyword association analysis in text database is changed to association mining of transaction in transaction database and meanwhile similarity analysis of the problem is changed to association rules mining of transaction in transaction database Text-based Association associated analysis, which is same as traditional association rules mining algorithm, also includes two main steps 1. Dig out frequent keywords, which are frequent itemsets 2. Generate the association rules between keywords according to frequent itemsets In the phase of algorithm implementation, transaction number is 437, setting support value is 0.02 and confidence level is 0.6.  Part of the association rules from mining results are expressed in the form of spreadsheet \(no, front, rear, S, C and their meanings are \(the serial number of generated association rules, the antecedent of association rules, the consequent of association rules. support, confidence Association rules can be gotten by running query on combinations of the antecedent and consequent Partial results shown in Table 1 
297 


  TABLE I A SSOCIATION RULES BASED ON KEYWORDS TABLE  No Front Rear S C 1 Computer Software 0.0934256 0.6 2 Conclusion  Prove 0.1237364 0.7236185 3 Algorithm Scan 0.0153402 0.6666667 Association rules, which are composed of the keywords of antecedent and consequent from the query on one same record, are stored in the association table. If the administrators are not satisfied with the results, he can adjust the support, confidence value and re-run the test process until satisfied IV S TRONG A SSOCIATION R ULES GENERATED BY F REQUENT I TEMSETS   The second step of association rule mining, which extracts the strong association rules from frequent itemsets is relatively easier than the first step generating frequent itemsets Algorithm 1. For each frequent itemset M, obtain all of its nonempty subset 8  2. For each non-empty subset S of M, set R=M-S and generate association rules S \002 R. If this rule meets the minimum confidence, it is the strong association rules and then added to the rule base After testing, set the minimum confidence level to 60 and the relevant answers user gets are the most reasonable If the minimum confidence level is set lower, it will produce a large number of irrelevant results. If it is set higher it will obtain the less relevant results, which would not achieve its role V C ONCLUSION   In order to enhance intelligence of Question-Answering system, this paper focused on in-depth research in the optimization of information processing in the system, and applied the improved association rules algorithm into intelligent Question-Answering system, dug out the potential rules which user uses to sort the results in the process of browsing the results, and then generated the rule base and optimized the processing of information. The practical application shows that the optimization of information processing has greatly been improved by applying the association rules algorithm in intelligent QuestionAnswering system  R EFERENCES  1 S h en Rui m in, Liu Yun A W e bb a sed Auto m a tic Que s t ion-Ans wer ing  System. Computer Engineering, vol. 9, 1999, pp. 89-91 2 Wan g Changd a Re m o te Tutor Qu estion-an swer i n g Syste m  Design  and Implementation Based on WWW. Computer Applications, vol. 6 2001, pp. 34-36 3 Minna Puustinen, Je a n F ra n  ois Roue t. L earning w ith new technologies: Help seeking and information searching revisited Learning with new technologies: Help seeking and Information searching revisited. Computers & Education, In Press, Corrected Proof, Available online 24 December 2008,  pp. 43-48 4 Zou L i  Sun Hui. I m ple m entation of Javab ased A ssociation Rule Mining Algorithm. Computer Era, vol. 1, 2005, pp. 48-51 5 Jiaw ei H a n Mich e line K a m b e r  C o n c ep t and Te chnolo gy o f Da ta Mining. Machinery Industry Press, 2001, pp90-92 6 W a n g Zha ngang, Z h u a ng D a f a n g Q i u  D o ng s h eng. Applic ation of Visualization Technology in Spatial Data Mining. Computer Engineering, vol. 9, 2007, pp. 18-21 7 D ing-An Chiang Hu an-C h a o K e h  H u i-Hua Hu ang De r m ing C h yr  The Chinese text categorization system with association rule and category priority System with the Chinese text categorization Association rule and category Priority. Expert Systems with Applications, Volume 35, Issues 1-2, July-August 2008, pp.102-110 8 Wu Yanwen Wu Z h enghong. Design o f Intellig ent Ques tionAnswering Platform based on learners personality model Eeducation Research, vol. 6, 2005, pp. 67-69   
298 


been created in a row of BDT \(impossible to see 2 equal views in the same row of a BDT We use the 2 phases of the extraction algorithm of association rules \(described above order to classify the set of views \(the number of classes is unknown and to extract the characteristic view of each class According to CHARM[2], the outcome will be a certain number of groups. Each group will contain a set of minimal reduced views depending on the minimum support threshold These views are the most frequent ones We use the confidence value between the views of the same class to extract the characteristic views of the 3D Object \(one view per class only one that has the minimal confidence value in relation to the sets of views of its class B. Algorithm of extraction of association rules CHARM Algorithm CharmEtend Input : [P],FC Output: FC modified for every  Ai x e\(Ai  Pi] =0 and X= Ai for  every Aj x e\(Aj  X=X?Ai Y=e\(Ai Aj Charm-Properties\([P], [Pi if [Pi] 0 then CharmEtend\([Pi],FC Delete\([Pi FC=FC?X End if End for End for return FC charm properties For every itemset X, support\(X X The rule X -p?Y is equivalent to the rule \(X Y and p=q We have X1 x e\(X1 X2 if e\(x1 x2 X1 ?x2 e\(x1 x2 X1 x2 


occurrence of X1 by X2 if e\(x1 x2 X1?x2 e\(x1 x2 X1 x2 occurrence of X1 by X1 ?x2 because X1 appears in every object where x2 appears if e\(x1 x2 X1 x2 x1?x2 X2 x1 each occurrence of X2 par X1 ?x2 because X2 appears in every object where x1 appears if e\(x1 x2 X1?x2 e\(x1?x2 X2 x1 X1 and X2 lead to a closed 1 C. Generation of association rules The association rules that are used here are not limited to the rules which consequences are composed of one single item. To generate the rules, we take into account all non empty sub-sets of f for each frequent itemset of f. And, for each of these subsets h, we return a rule in the form of h => \(f-h support  \(f h threshold  minconf. We evaluate all the sub-sets of f to generate the rules which consequences are the itemsets of size greater than one IV. EXPERIMENTS AND RESULTS In order to measure the performance of our algorithms, we used non-complex objects the Princeton benchmark base that is classified into 20 classes depending on their visual similarity The 3D Objects of figure 1 shows examples of 3D objects of different classes In our current implementation, Zernike moments are extracted from views from second order. To compare two Zernike moments, the distance Minkowski order 1 is used Figure 1.  Examples of 3D Objects of different classes The choice of a minimum support and a minimum confidence threshold is justified by the number of experiences For a minsup <50%, we will have enough characteristic views, with unsignificant views among them For a minsup >60%, we will have a small number of characteristic views which represent a limited number of initial views of the 3D object In order to get characteristic views that represents best their class, it is better to choose a minsup that belongs to the interval 48% , 60%], as well as a minimum confidence threshold 


greater than 70 A. Steps of the experiment Example 1: extraction of characteristic views Based on a minimum support of 50% and a minimum confidence threshold of 80%, we tested our method on a 3D object of the class Helicopter. The obtained outcomes are shown in figure 2 Figure 2. Characteristic views of the object  m1312.off Example 2: Research of objects that are similar to the 2D requested view Using a minimum support of 50% and a minimum confidence threshold of 80%, the research of similarity according to our method and the use of probability on a 2D request example produces the outcomes displayed in figure3 Figure 3. 3D objects that are similar to the requested 2D view of class airplane B. Measurement of performance indices For a more accurate analysis of performance, a study in terms of curve \(Recall/Precision be denoted by the following fomula \(Osada     We apply our algorithm  CHARM and Extraction of association rules between views and the Kmeans algorithm over 10 requested views of the same object of the class airplane of the Benchmark base. These views are randomly selected by a program. ie from a 342 views of the object "fighter", Our search algorithm selects a random 10 views queries. Figure 4 displays results comparing Kmeans \(in red algorithm in blue Figure 4. Curves of Recall/ Precision with values of 10 requested views To measure the performance of our algorithm, we applied the two indices of performance mentioned above Figure 4 displays the Recall/Precision curve computed using our algorithm and the Kmeans curve. In this figure, we notice that the accuracy score of the first 35 K \(first third 100% for our suggested method. This means that most of the objects that are similar to the requested object are placed at the top of the search list. And, as of the K greater than 35 \(second thirds which signifies that the rest of the objets \(belonging to the 


same class ranked/placed* as two thirds in the search list. These indices are in accordance with the visual results displayed in Figure 3 On the other hand, the Kmeans algorithm gives a result between 70 and 33% for the first 35K \(first third that the first third of the search list contains a combination of objects: those belonging to the same class as the requested object and others belonging to other classes. Moreover, the K that is greater than 35 corresponds to a score less than 85 which suggests that the rest of the objects belonging to the same class that are similar to the requested object are far from the top of list search V. CONCLUSION In this article, we introduced the concept of 3D object indexation, in particular the indexation from the views of these 3D objects. First, we introduced an algorithm that is independent of the 2D used descriptor in order to extract the characteristic views of a 3D object. The outcomes of this method are very satisfying since this latter reduces the 3D object size \(instead of using 342 initial views, the system automatically reduces this number depending on the threshold of the distance  to a smaller number be characterized by a small number of views called characteristic views. Next, we used the probabilistic bayesian view \(translated by T.F Ansary, J.P. Vandeborred and M Daoudi[5 displayed results highlight the good performances of this method compared to some classical methods of classification This method produces great results when the object size is big enough, with more than 340 views per object These tests are performed based on Princeton Shape benchmark REFERENCES 1] Rakesh Agrawal , Ramakrishnan Srikant, Fast Algorithms for Mining Association Rules in Large Databases, Proceedings of the 20th International Conference on Very Large Data Bases, p.487-499 September 12-15, 1994 2] Mohammed J. Zaki, Member, IEEE, and Ching-Jui Hsiao Efficient Algorithms for Mining Closed Itemsets and Their Lattice Structure IEEE TRANSACTIONS ON KNOWLEDGE AND DATA ENGINEERING VOL. 17, NO. 4, APRIL 2005 3] A. Baskurt, F. Blum, M. Daoudi, J.L. Dugelay, F. Dupont, A. Dutartre 


T. Filali Ansary, F. Fratani, E. Garcia, G. Lavou, D. Lichau, F. Preteux J. Ricard, B. Savage, J.P. Vandeborre, T. Zaharia. SEMANTIC-3D COMPRESSION, INDEXATION ET TATOUAGE DE DONNES 3D Rseau National de Recherche en Tlcommunications \(RNRT 2002 4] T.Zaharia F.Prteux, Descripteurs de forme : Etude compare des approches 3D et 2D/3D 3D versus 2D/3D Shape Descriptors: A Comparative study 5] T.F.Ansary J.P.Vandeborre M.Daoudi, Recherche de modles 3D de pices mcaniques base sur les moments de Zernike 6] A. Khothanzad, Y. H. Hong, Invariant image recognition by Zernike moments, IEEE Trans. Pattern Anal. Match. Intell.,12 \(5 1990 7] Agrawal R., Imielinski T., Swani A. \(1993 between sets of items in large databases. In : Proceedings of the ACM SIGMOD Conference on Management of Data, Washington DC, USA 8] Hbrail G., Lechevallier Y. \(2003 In : Govaert G. Analyse des donnes. Ed. Lavoisier, Paris, pp 323-355 9] T.F.Ansary J.P.Vandeborre M.Daoudi, une approche baysinne pour lindexation de modles 3D base sur les vues caractristiques 10] Ansary, T. F.   Daoudi, M.   Vandeborre, J.-P. A Bayesian 3-D Search Engine Using Adaptive Views Clustering, IEEE Transactions on Multimedia, 2007 11] Ansary, T.F.   Vandeborre, J.-P.   Mahmoudi, S.   Daoudi, M. A Bayesian framework for 3D models retrieval based on characteristic views, 3D Data Processing, Visualization and Transmission, 2004 3DPVT 2004. Proceedings. 2nd International Symposium Publication Date: 6-9 Sept. 2004 12] Agrawal R., Srikant R., Fast algorithms for mining association rules in larges databases. In Proceeding of the 20th international conference on Very Large Dada Bases \(VLDB94 September 1994 13] U. Fayyad, G.Piatetsky-Shapiro, and Padhraic Smyth, From Data Mining toKnowledge Discovery in Databases, American Association for Artificial Intelligence. All rights reserved. 0738-4602-1996 14] S.Lallich, O.Teytaud,  valuation et validation de l'intrt des rgles d'association 15] Osada, R., Funkhouser, T., Chazelle, B. et Dobkin, D. \(\( Matching 3D Models with Shape Distributions International Conference on Shape Modeling & Applications \(SMI 01 pages 154168. IEEE Computer Society,Washington, DC, Etat-Unis 2001 16] W.Y. Kim et Y.S. Kim. A region-based shape descriptor using Zernike 


moments. Signal Processing : Image Communication, 16 :95100, 2000 


And put forward that we could use confidence, category homoplasy and relevancy strength to improve the quality of feature extension modes. We also verified that confidence category homoplasy and relevancy strength are effective through our experiments. In the same time we have drawn the following conclusions: \(1 relationships for short-text can improve their classification performance; \(2 effectiveness of information in the feature extension mode library we should choose the suitable thresholds; \(3 information is too small to meet the demand of short-text feature extension. So we should find out a perfect method which can increase information coverage in the feature extension mode library for short-text classification; \(4 extension library for short-text extension effectively, i.e., choosing a perfect feature extension strategy is also our further work ACKNOWLEDGMENT The research is supported in part by the National Natural Science Foundation of China under grant number 60703010 the Nature Science Foundation of Chongqing province in China under grant number CSTC, 2009BB2079, and the Scientific Research Foundation for the Returned Overseas Chinese Scholars of Ministry of Education of China under grant number [2007] 1109 REFERENCES 1] Fabrizio Sebastiani.Machine Learning in Automated Text Categorization, A.ACM Computing Surveys, C.2002.34\(1 2] Fan Xing-hua,Wang peng. Chinese Short-Text Classification in TwoStep, J.Journal of DaLian Maritime Universtiy, 2008,11\(2 3] Zelikovitz S. and Hirsh H. Improving Short Text Classification Using Unlabeled Background Knowledge to Assess Document Similarity C. In: Proceedings of ICML-2002, 2002, 1183-1190 4] Wang Xi-wei,Fan Xing-hua and Zhao Jun. A Method for Chinese Short Text Classification Based on Feature Extension, J.Journal of Computer Applications,2009,29\(3 5] JIAWEI HAN,JIAN PEI ,YIWEN YIN, BUNYING MAO.Ming Frequent Patterns without Candidate Generation:A Frequent-Pattern Tree.Data Mining and Knowledge Discovery,2004,8:53-87 6] Liu Fei. Huang Xuan-qing and Wu Li-de.Approach for Extracting Thematic Terms Based on Association Rule, J.Computer Engineering,2008\(4 7] Xinhua Fan, Jianyun Nie. Link Distribution Dependency Model for 


Document Retrieval, C.Journal of Information and Computational Science6:3\(2009  90 


shows that proposed post mining of association rule mining technique for missing sensor data estimation is an area worth to explore REFERENCES 1] Agrawal, R., & Imielinski, T., & Swami, A., "Mining association rules between sets of items in massive databases", International Conference on Management of Data, 1993 2] Austin, F. I., "Austin Freeway ITS Data Archive", Retrieved January 2003 from http://austindata.tamu.eduidefauIt.asp 3] Bastide, Y., & Pasquier, N., & Taouil, R, & Stumme, G., & Lakhal L., "Mining minimal non-redundant association rules using frequent closed itemsets", First International Conference on Computational Logic, 2000 4] Cool, A. L., "A review of methods for dealing with missing data The Annual Meeting of the Southwest Educational Research Association, 2000 5] Deshpande, A., & Guestrin C., & Madden, S., "Using probabilistic models for data management in acquisitional environments", The Conference on Innovative Data Systems Research, 2005 6] Halatchev, M., & Gruenwald, L., "Estimating missing values in related sensor data streams", International Conference on Management of Data, 2005 7] Iannacchione, V. G., "Weighted sequential hot deck imputation macros", Proceedings of the SAS Users Group International Conference, 1982 8] Nan Jiang, "Discovering Association Rules in Data Streams Based On Closed Pattern Mining", SIGMOD Ph.D. Workshop on Innovative Database Research, 2007 9] Li, Y., & Liu, Z. T., & Chen, L., & Cheng, W., & Xie, C.H Extracting minimal non-redundant association rules from QCIL The 4th International Conference on Computer and Information Technology, 2004 10] Little, R 1. A., & Rubin, D. B., "Statistical analysis with missing data", New York: John Wiley and Sons, 1987 II] McLachlan, G., & Thriyambakam, K., "The EM algorithm and extensions", New York: John Wiley & Sons, 1997 12] Mitchell, T., "Machine Learning", McGraw Hill, 1997 13] Papadimitriou, S., & Sun, 1., & Faloutsos, C., "Streaming pattern discovery in multiple time-series", The International Conference on Very Large Databases, 2005 14] Rubin, D., "Multiple imputations for nonresponce in surveys", New York: John Wiley & Sons, 1987 


15] Shafer, 1., "Model-Based Imputations of Census Short-Form Items In Proceedings of the Annual Research Conference, 1995 16] Taouil, R., & Pasquier, N., & Bastide, Y., & Lakhal, L., "Mining bases for association rules using closed sets", International Conference on Data Engineering, 2000 17] Wilkinson & The AP A Task Force on Statistical Inference, 1999 18] Zaki, M. 1., Hsiao, C. 1., "Efficient algorithms for mining closed itemsets and their lattice structure", IEEE Transactions on Knowledge and Data Engineering, 2005 V5-106 


General Chair f!!\f  Organizing Chairs  f!!\f  f$% \f!!\f  Organizing Co-chairs f    f  f\f   f\f\f   f*!\f!\f.\f  f f  Program Committee Chairs  f\f\f   f!!\f  Publication Chair 0   


200 250 300  The size of dataset/10,000 R es po ns e tim e S    a 0 50 100 150 200  The size of dataset/10,000 R es po ns e tim e S    b 0 10 20 30 40 50 


60  The size of dataset/30,000 R es po ns e tim e S    c Fig. 9 The scalability of our algorithm compared with FP-growth  Paper [12] proposed a way to reduce times of scanning transaction database to reduce the cost of I/O IV. CONCLUSIONS AND FUTURE WORK This paper first discusses the theory of foundations and association rules and presents an association rules mining algorithm, namely, FP-growth algorithm. And then we propose an improved algorithm IFP-growth based on many association rules mining algorithms. At last we implement the algorithm we propose and compare it with algorithm FPgrowth algorithm. The experimental evaluation demonstrates its scalability is much better than algorithm FP-growth 177 Now, lets forecast something we want to do someday Firstly, we would parallelize our algorithm, because data mining needs massive computation, and a parallelable environment could high improve the performance of the algorithm; Secondly, we would apply our algorithm on much more datasets and study the run performance; At last, we would study the performance when the algorithm deal with other kinds of association rules  REFERENCES 1] S. Sumathi and S. N. Sivanandam. Introduction to Data Mining and its Applications, Springer, 2006 2] V. J. Hodge, J. Austin, A survey of outlier detection 


methodologies, Artificial Intelligence Review, 2004, 22 85-126 3] Han, J. and M. Kamber. Data Mining: Concepts and Techniques. Morgan Kaufmann, San. Francisco, 2000 4] Jianchao Han, Mohsen Beheshti. Discovering Both Positive and Negative Fuzzy Association Rules in Large Transaction Databases, Journal of Advanced Computational Intelligence and Intelligent Informatics 2006, 10\(3 5] Jiuyong Li, Hong Shen, Rodney Topor. Mining Informative Rule Set for Prediction. Journal of Intelligent Information Systems, 2004, 22\(2 6] Jianchao Han, and Mohsen Beheshti. Discovering Both Positive and Negative Fuzzy Association Rules in Large Transaction Databases. Journal of Advanced Computational Intelligence, 2006, 10\(3 7] Doug Burdick, Manuel Calimlim, Jason Flannick Johannes Gehrke, Tomi Yiu. MAFIA: A Maximal Frequent Itemset Algorithm. IEEE Transactions on Knowledge and Data Engineering, 2005, 17\(11 1504 8] Assaf Schuster, Ran Wolff, Dan Trock. A highperformance distributed algorithm for mining association rules. Knowledge and Information Systems, 2005, 7\(4 458-475 9] Mohammed J. Zaki. Mining Non-Redundant Association Rules. 2004, 9\(3 10] J.Han, J.Pei, Y.Yin, Mining frequent patterns without candidate generation, Proceedings ACM SIGMOD 2000 Dallas, TX, May 2000: 1-12 11] P.Viola, M.Jones. Rapid Object Detection Using A Boosted Cascade of Simple Features. Proc. IEEE Conf. on Computer Vision and Pattern Recognition, 2001 12] Anthony K. H. Tung, Hongjun Lu, Jiawei Han, Ling FengJan. Efficient Mining of Intertransaction Association Rules. 2003, 154\(1 178 


For each vertex b in g form j forests body\(a, g, i s.t. bodyAnt\(a, g, i a, g, i with itemsets Ant\(b b and each subset of itemsets Ant\(b b in P\(a, g, j Assign to each leaf l of trees bodyAnt\(a, g, i bodyCons\(a, g, i a fresh variable Vm,M, m, M = size\(itemset\(l Assign to each leaf l of tree headAnt\(a, g, j the variable assigned to itemset l in some leaf of some tree bodyCons\(a, g, i TABLE II.  EXPERIMENTAL DATA Conf. #rules #pruned #dftrs PtC 0.5 6604 2985 1114 0.6 2697 2081 25 0.75 1867 1606 10 0.8 1266 1176 0 0.95 892 866 1 0.98 705 699 1 DSP 0.5 2473 1168 268 0.6 1696 869 64 0.75 1509 844 89 0.8 1290 1030 29 0.95 1032 889 15 0.98 759 723 1 Arry 0.5 770 492 82 0.6 520 353 60 0.75 472 327 39 0.8 408 287 22 0.95 361 255 25 0.98 314 243 30  Our induction algorithm has been launched for each combination of thresholds. Our scheme eliminates all redundant rules in the sense of [25, 31], i.e. those association rules that are not in the covers. All the meta-rule deductive schemes implicitly included in [25] and [31] are induced by our method. The percentage of pruning, thus, outperforms [25 


The results produced for k=3, support 0.25 and confidences between 0.7 and 0.99 are shown in Fig. 3, in terms of pruning percentage \(vertical axis when applied to low confidences \(from 0.7 to 0.9 The percentage of pruning achieved diminishes as the confidence is superior to 0.9. Nevertheless, the pruning is effective with confidence of 0.99 in the majority of cases Pruning at Support = 0.25 0,00 5,00 10,00 15,00 20,00 25,00 30,00 35,00 40,00 45,00 50,00 0,7 0,8 0,9 0,95 0,99 Confidence P ru n in g L e v e l Case 1 Case 2 Case 3  Figure 3.  Pruning experiences at support 0.25  V. DISCUSSION AND CHALLENGES It is important to discuss the technique presented here with focus on the purpose the technique pursues:  to produce semantic recommendation The reader should have noticed that the algorithm presented 


relies strongly on "choice". For instance, the algorithm chooses ears in the graph to form an order for elimination, and the choice is arbitrary. This strategy is essential to maintain low complexity \(polynomial practical. Nevertheless, a warned reader may conclude that this arbitrary choice implies that there are many compactions to produce and therefore the approach as a whole does not show to produce an optimal solution. And the reader is right in this conclusion. Since the goal is compaction, the search for an optimal solution can be bypassed provided a substantial level of pruning is achieved To complete the whole view, we describe how web service descriptions are complemented with the association rules as recommendations. In effect, under our scheme, the document describing the web service is augmented with a set of OWL/RDF/S triples that only incorporate the non-pruned rules with the format of Example 1, that is, the set ARmin of the compaction program obtained by our algorithm, together with the thresholds applied to the mining process and a registered URI of a registered description service. The assumptions and defeaters are not added to the web service description. If the associations encoded in the triples are not sufficient for the client \(a search engine, for instance widening of the response to the description service identified by the given URI, and then the assumptions and defeaters are produced. The reasoning task required for deriving all the implicitly published rules is client responsibility Notice that, under this scheme, the actual rules that appear as members of the set initial ARmin set are irrelevant; the only important issue is the size of the set The developed scheme also supports an extension of the algorithm that admits the assignment of priorities to rules and to itemsets, in order to allow the user to produce a more controlled program as output. Nonetheless, the importance of the extension has not been already tested, and therefore it is beyond the subject of the present paper It would be also interesting to design a scheme that supports queries where the client provides an itemset class and values for support and confidence and the engine produces a maximal class of inferred associated itemsets as a response. This scheme is also under development, so we have not discussed this aspect here 


VI. CONCLUSION In this paper, we have presented a defeasible logic framework for managing associations that helps in reducing the number of rules found in a set of discovered associations. We have presented an induction algorithm for inducing programs in our logic, made of assumption schemas, a reduced set of association rules and a set of counter-arguments to conclusions called defeaters, guaranteeing that every pruned rule can be effectively inferred from the output. Our approach outperform those of [17], because all reduction compactions presented there can be expressed and induced in our framework, and several other patterns, particular to the given datasets, can also be found. In addition, since a set of definite clauses can be obtained from the induced programs, the knowledge obtained can be modularly inserted in a richer inference engine Abduction can be also attempted, asking for justifications that explain the presence of certain association in the dataset The framework presented can be extended in several ways Admitting defeaters to appear in the head of assumption, to define user interest Admitting arithmetic expressions within assumptions for adjustment in pruning Admitting set formation patterns as itemset constants Extending the scope, to cover temporal association rules REFERENCES 1]  R. Agrawal, and R. Srikant: Fast algorithms for mining association rules In Proc. Intl Conf. Very Large Databases. \(1994 2]  A. V. Aho, J. E. Hopcroft, J. Ullman. The design and analysis of computer algorithms, Addison-Wesley, 1974 3]  G. Antoniou, D. Billington, G. Governatori, M. J. Maher, A. Rock: A Family of Defeasible Reasoning Logics and its Implementation. ECAI 2000: 459-463 4]  G. Antoniou, D. Billington, G. Governatori, M. J. Maher: Representation results for defeasible logic. ACM Trans. Comput. Log. 2\(2 2001 5]  A. Basel, A. Mahafzah, M. Al-Badarneh: A new sampling technique for association rule mining, Journal of Information Science, Vol. 35, No. 3 358-376 \(2009 6]  R. Bayardo and R. Agrawal: Mining the Most Interesting Rules. In Proc of the Fifth ACMSIGKDD Intl Conf. on Knowledge Discovery and Data Mining, 145-154, \(1999 


7]  R. Bayardo, R. Agrawal, and D. Gunopulos: Constraint-based Rule Mining in Large, Dense Databases. Data Mining and Knowledge Discovery Journal, Vol. 4, Num-bers 2/3, 217-240. \(2000 8]  A. Berrado, G. Runger: Using metarules to organize and group discovered association rules. Data Mining and Knowledge Discovery Vol 14, Issue 3. \(2007 9]  S. Brin, R. Motwani, J. Ullman, and S. Tsur: Dynamic itemset counting and implication rules for market basket analysis. In Proc. ACMSIGMOD Intl Conf. Management of Data. \(1997 10] L. Cristofor and D.Simovici: Generating an nformative Cover for Association Rules. In ICDM 2002, Maebashi City, Japan. \(2002 11] Y. Fu and J. Han: Meta-rule Guided Mining of association rules in relational databases. In Proc. Intl Workshop on Knowledge Discovery and Deductive and Object-Oriented Databases. \(1995 12] B. Goethals, E. Hoekx, J. Van den Bussche: Mining tree queries in a graph. KDD: 61-69. \(2005 13] G. Governatori, D. H. Pham, S. Raboczi, A. Newman and S. Takur: On Extending RuleML for Modal Defeasible Logic. RuleML, LNCS 5321 89-103. \(2008  14] G. Governatori and A. Stranieri. Towards the application of association rules for defeasible rules discovery In Legal Knowledge and Information Systems, JURIX, IOS Press, 63-75. \(2001 15] J. Han, J. Pei and Y. Yin: Mining frequent patterns without candidate generation. In Proc. ACM-SIGMOD Intl Conf. Management of Data 2000 16] C. Hbert, B. Crmilleux: Optimized Rule Mining Through a Unified Framework for Interestingness Measures. DaWaK: LNCS 4081, 238247. \(2006 17] E. Hoekx, J. Van den Bussche: Mining for Tree-Query Associations in a Graph. ICDM 2006: 254-264 18] R. Huebner: Diversity-Based Interestingness Measures For Association Rule Mining. Proceedings of ASBBS Volume 16 Number 1, \(2009 19] B. Johnston, Guido Governatori: An algorithm for the induction of defeasible logic theories from databases. Proceedings of the 14th Australasian Database Conference, 75-83. \(2003 20] P. Kazienko: Mining Indirect Association Rules For Web Recommendation. Int. J. Appl. Math. Comput. Sci., Vol. 19, No. 1, 165 186. \(2009 21] M. Klemettinen, H. Mannila, P. Ronkainen, H. Toivonen, and A Verkamo: Finding interesting rules from large sets of discovered association rules. In Proc. 3rd Intl Conf. on Information and Knowledge 


Management. \(1994 22] M. J. Maher, A. Rock, G. Antoniou, D. Billington, T. Miller: Efficient Defeasible Reasoning Systems. International Journal on Artificial Intelligence Tools 10\(4 2001 23] C. Marinica, F. Guillet, and H. Briand: Post-Processing of Discovered Association Rules Using Ontologies. The Second International Workshop on Domain Driven Data Mining, Pisa, Italy \(2008 24] N. Pasquier, Y. Bastide, R. Taouil, and L. Lakhal: Closed sets based discovery of small covers for association rules. In Proc. BDA'99 Conference, 361-381 \(1999 25] N. Pasquier, R. Taouil, I. Bastide, G. Stume, and  L. Lakhal: Generating a Condensed Representation for Association Rules. In Journal of Intelligent Information Systems, 24:1, 29-60 \(2005 26] P. Pothipruk, G. Governatori: ALE Defeasible Description Logic Australian Conference on Artificial Intelligence.  110-119 \(2006 27] J. Sandvig, B. Mobasher Robustness of collaborative recommendation based on association rule mining, Proceedings of the ACM Conference on Recommender Systems \(2007 28] W. Shen, K. Ong, B. Mitbander, and C. Zaniolo: Metaqueries for data mining. In Fayaad, U. et al. Eds. Advances in Knowledge Discovery and Data Mining. \(1996 29] I. Song, G. Governatori: Nested Rules in Defeasible Logic. RuleML LNCS 3791, 204-208 \(2005 30] H. Toivonen, M. Klemettinen, P. Ronkainer, K. Hatonen, and H Mannila: Pruning and grouping discovered association rules. In ECML Workshop on Statistics, Machine Learning and KDD. \(1995 31] M. Zaki: Generating Non-Redundant Association Rules. In Proc. of the Sixth ACMSIGKDD Intl Conf. on Knowledge Discovery and Data Mining, 34-43, \(2000 32] w3c. OWL Ontology Web Language Reference. In http://www.w3.org/TR/2004/REC-owl-ref-20040210 33] w3c. RDF/XML Syntax Specification. In: http://www.w3.org/TR/rdfsyntax-grammar 34] w3c. RDF Schema. In: http://www.w3.org/TR/rdf-schema      


 8   2  3\f            8  D    F  \b 1 8 & #J      b 1  1  4    2  


4 1    9  E 1  2 4 1    9 1   4      8 2  8 1  D 1        1 1  b 


     b b b b b  K            8          2 D 9   F  \b 1 8 ,+J  9 


     b 1     1 2  9 1  12 L 1   9  8       1  2      2   


     b b b b b  K            2  0 \b f  b\f      9       


  8 2   E 1   1     M13 31L 1    b  8E 1   1 #3\b?### 1  1     E 1   1 \b?###3        


1   1   b 1  2 2 18 2     8              1    2 \b 1    2  


    2          2   1 L 2 1   1   L 2 2    2 1  2        


    8  2H D \b A             2  2H D \b A 2 \f 3%\f  f   4%\f f !  , \f\b  C    2    2 


 6    3 1      253 6   1 L 2    6   1         f\b3\f       


               1     1     8 2    E       2  1   


     2 8    b 4      1 8             1 2     1  8 2  


1 9    8      2 1       1     2    8    2 3\f        


     8 D 4 9  F  \b 1 8 #J 9 1     2 1   2 #-@ 1   2 9  E 1   1   2 9      6  


    8  8   1  D 1         1 F  \b0         2 D    F  \b 1 8  9  


  1 9  1   E 1  2 9     1 1 F  \b       1    18   F   1    1 #-$+  \b  2 2  


1 D     1 #-$+.B- 0/:% .0             9 1      18    1 6     1 2  1  1  


1   6      2    1 2 E 8 D 1      1 2   1   1 #-4  #-@E     2  1  1  1       


 8     1          2 F    6   F  2   8    2 C<CC/C N\bO 5      


CD    b$44NO F P Q 6   2 b$$$ ,=\b\bA  A N,O 2 C C  b$$4N  92 2   f  9-\b$$4 B N?O  !-    91  2 1 HH111-18-N+O    -1 :3%   2     0-4 


     b N4O 2   2- \f  C b$@$ \b# >\b\b$3\b$N@O  f :.% 9 /9 \f    1  6  f 2  4   A254 


Advantages of Our M ethod Advantages of Our M ethod Exploit the memory v ertical data format utilizes slidin g windows to g form a much larger database to analyze  Flexibility in Choosing what to choose  Choosing what to choose to build the rules Computational and memory efficiency We have a team working only on this aspect 45 Associative IDS for NextGen Frameworks Dr S Dua LA Tech 45 


Preliminary Results Intra transaction Relations Data rate simulator NH-134 Mb HOP PATH update \(Y/N Inference 11.5 Y Y 2 0.120 N N      Y   n 0.345 N NH134 Y/N   Inf 1 0.150 N N 2 0 120 Y N Inter transaction Relations 2 0  120 Y N       5 5.55 0.456 Y Relations  n 0.345 N N Nmap on DMRL nmap.org 


Anticipated Outcome Anticipated Outcome Develop algorithm capable of learning from a given heterogeneous diverse Develop algorithm capable of learning from a given heterogeneous diverse data ff Dynamic algorithmic f ramework designed to shi f t modalities and sampling rates based on complex logic Flexibility of integration into the Snort intrusion detection system 47 Associative IDS for NextGen Frameworks Dr S Dua LA Tech 47 


References References Aircraft Cockpit Image courtesy USAF http://www.faa.gov htt p   www.faa g ov  air traffic  technolo gy  p g  _ gy  Acharya R Dua S Du X Sree V Chua C K Automated Diagnosis of Glaucoma Using Texture and Higher Order Spectra Features To appear in IEEE Transactions on Information Technology in Biomedicine  Du X Dua S 2011 Cancer Prognosis Using Support Vector Regression in Imaging  Modality World Journal of Clinical Oncology 2  1   44 49 Du X Dua S 2010 Salient Frame Extraction Using Support Vector Regression and Motion Features pp 5 Proc of the National Aerospace and Electronics Conference July 14 16 2010 D M P D S 2010 Di i i ti Ft d Cl ifi ti Mthd f D essaue r  M  P  D ua S  2010  Di scr i m i na ti ve F ea t ures an d Cl ass ifi ca ti on M e th o d s f or Accurate Classification 1st ed vol 7704 pp 14 Bellingham WA Proceedings of SPIE Dessauer M P Dua S 2010 Low Resolution Vehicle Tracking using Dense and Reduced Local Gradient Features Maps 1st ed vol 7694 pp 8 Bellingham WA Proceedings of SPIE SPIE 


Acknowledgements Acknowledgements Fundin g A g encies  US 4 1 Million direct fundin g g g 4 g LA BoR NIH NSF AFRL AFOSR and NASA Research Team Samuel Kasimalla Brandy McKnight Dr Pradeep Chowriappa Connor Johnson Vasanth Nair Mihir Chowriappa  Connor Johnson  Vasanth Nair  Mihir Karnik Mohit Jain and Swadheen Songmen Associative IDS for NextGen Frameworks Dr S Dua LA Tech 49 All the respective Logos belong to their owners 


Rf d Rdi R e f erence d R ea di ngs Copyright of cover pages held by respective publishers 


Thank You Questions Thank You  Questions Dr Sumeet Dua E mail sdua@latech.edu Web http://dmrl.latech.edu Associative IDS for NextGen Frameworks Frameworks Dr S Dua LA Tech 51 Image Source roadtrafficsigns.com 


