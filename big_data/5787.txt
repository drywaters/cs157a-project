Abstract  Data mining is the process of extracting hidden patterns from data. With the explosion of data at a tremendous rate, data mining is essential to extract useful information Association rule mining is a method of finding correlation relationships among large set of data items. A rule is characterized as sensitive if its disclosure risk is above a certain confidence value. Sensitive rules should not be disclosed to the public, as they can be used to infer sensitive data and provide an advantage for the business competitors. Techniques for hiding association rules are limited to binary items. But, real world data consists of quantitative values. In this paper, a method to hide fuzzy association rule is proposed, in which, the fuzzified data is mined using modified apriori algorithm in order to extract rules and identify sensitive rules. The sensitive rules are hidden by decreasing the support value of Right Hand Side \(RHS\ of the rule. A framework for automated generation of membership function is also proposed. Experimental results of the proposed approach demonstrate efficient information hiding with minimum side effects Keywords „ Association Rules; Data Mining; Fuzzy Logic Sensitive Rule; membership function I INTRODUCTION Data mining is the process of extracting useful knowledge from large databases. However, data mining also poses a threat to privacy and information protection if not used properly. Association rule analysis is a popular tool for discovering associations among large amount of data. Useful hidden information could be easily exposed using this kind of tool. Information privacy is essential to prevent private data from being available to others. Once private data is released, it will be impossible to prevent misuse h eref ore, th e protection of sensitive hidden information has become a critical issue to be resolved Privacy preserving data mining which involves getting valid data mining results in addition to hiding sensitive information has been receiving attention in the research community. Consider the case of a health drink reseller who purchase health drink at low price from two companies Horlicks and Complan. Reseller also grants the companies access to his customer database. Complan supplier may misuse the database to mine association rules related to the Horlicks, inferring facts like People who buy Milk also buy HorlicksŽ. Using this information Complan supplier offers a discount coupon on milk on purchase of Complan. Hence sales on Horlicks drops steeply and Horlicks supplier will not be able to offer his promised discounts. This enables Complan to monopolize the health drink market which results in the hike of health drink prices. As a result, reseller may start losing his business. This scenario emphasis need for research on hiding sensitive knowledge Techniques of hiding association rules can be classified into two broad categories di s t ort i o n ba s e d t echn i q u e a n d blocking based technique. In distortion based technique, the data is distorted such that the support and confidence of sensitive association rules is reduced below threshold. Here threshold refers to minimum value of support and confidence below which the association rule becomes uninteresting. This technique has side effects of Lost Rules and Ghost Rules Lost Rules refers to undesirable hiding of items and association rules that are not sensitive. Ghost rules are non genuine association rules which become part of association rules set. Distortion based technique reduces these side effects while maintaining a linear time complexity with dataset size This technique also poses a serious bottleneck in some specific situations like medical database where deleting a part of dataset may infer to a wrong prescription Blocking based technique is characterized by introducing uncertainty without distorting the database. It also suffers from side effects of lost item, lost rule and ghost rule Initially, rule hiding techniques proposed by Vassilios et  e re dis t ortion bas ed alg o rithm s a n d s i de ef f ect s of  these algorithms were high. Duraiswamy et cribed  an algorithm called Sensitive Rule Hiding. In this algorithm sensitive rules with single antecedent and consequent were clustered. Each rule is modified to reduce its confidence When all sensitive association rules are hidden, clusters are converted into a modified database. This technique shows high side effects both in terms of ghost rules as well as loss of non sensitive rules. Yuhong et al. presented FP-tree based method for inverse frequent set minin t h is a l g o rit h m after extraction and pruning of frequent itemset, FP-tree is constructed, which is later converted into many versions of modified database. The strengths of this technique is its efficiency and availability of multiple versions of  modified database. Number of released databases was characterized by the number of non frequent items chosen. This technique is focused on hiding sensitive items only. Further, it has the side effect of large number of lost rules. Chih-Chia proposed novel algorithms - Frequent Hiding Sensitive Frequent Item Frequent Hiding Sensitive Association Rule[8  9   Ea c h  transaction in dataset was assigned a weight based on its support for a sensitive rule. All transactions in dataset are first sorted by weight in descending order. Transactions are then modified till the confidence of sensitive association rules fall below the given threshold. Most of the studies proposed concentrated on hiding association rules associated with binary items without giving importance to its quantity However, many transactions in real world applications have quantitative values. For a diabetes patient, the quantity of the attribute sugar in blood is more important than the presence or absence of sugar A New Method for Preserving Privacy in Quantitative Association Rules using DSR Approach with Automated Generation of Membership Function K. SathiyaPriya         G. Sudha Sadasivam         N. Celin Dept. of CSE          Dept. of CSE              Dept. of CSE PSG College of Technology   PSG College of Technology      PSG College of Technology Coimbatore,             Coimbatore,               Coimbatore India -641 004            India -641 004              India -641004 sathya_jambai@yahoo.com    sudhasadhasivam@yahoo.com       n_celin@yahoo.com 148 978-1-4673-0126-8/11/$26.00 c  2011 IEEE 


Some work has been done to discover association rules from quantitative data using fuzzy set concepts. But, only limited research papers are available in the field of hiding fuzzy association rule in quantitative data. Hiding quantitative rule can be done by increasing the support of Left Hand Side LHS\ the rule which in turn decreases the confidence of the ru Fuzzification of support and confidence framework with variable number of fuzzy membership function and decreasing the support can also be used for quantitative association rule hiding w e v e r both th e approach es requ ire th e membership function to be predefined and are usually built by human experts. In absence of expertise, the membership functions cannot be accurately defined which reduces system performan This paper proposes a learning method to derive membership functions automatically. Further the paper also presents a method for preventing extraction of useful association rules from quantitative data by decreasing the support of the rule. The support of a rule A B is decreased by decreasing the support count of itemset AB which is achieved by decreasing the support value of B on Right hand Side\(RHS\ the rule. This is done until either support or confidence value of the rule goes below minimum support or minimum confidence value respectively The rest of this paper is organized as follows. Privacy preserving fuzzy association rule hiding in quantitative data is described in Section II. Approach to derive membership function automatically is detailed in section III. The method to hide useful fuzzy association rules is described in Section IV Experimental results are given in Section V II PROBLEM STATEMENT An association rule is defined as an implication X Y where both X and Y are defined as sets of attributes interchangeably called items X is called as the body LHS\ the rule and Y is called as the head RHS\ the rule. It is interpreted as follows: for a specified fraction of the existing transactions, a particular value of an attribute set X determines the value of attribute set Y as another particular value under a certain confidenceŽ. For instance, an association rule in a supermarket basket data may be stated as, In  20 of the transactions, 75% of the people buying butter also buy milk in the same transactionŽ; 20% and 75% represent the support and the confidence, respectively. The significance of an association rule is measured by its support and confidence Support is the percentage of transactions that contain both X and Y and confidence is the ratio of the support of X U Y to the support of X  Let I  i 1 i 2 i 3  be the complete item set where each i j 1  j  m  is a quantitative attribute. Given a database D  t 1 t 2 t n  where each t j is a  transaction with attributes I and the fuzzy sets associated with attributes in I our goal is to find out some interesting useful association rules Let X  x 1 x 2 x p  and Y  y 1 y 2 y q  be two large itemsets. Then, the fuzzy association rule is given as follows A  B where A  f 1 f 2 f p  and B  g 1 g 2 g q  and f i  the fuzzy regions related to attribute x i  g j  the fuzzy regions related to attribute y j  X and Y are subsets of I and are disjoint. A and B contain the fuzzy sets associated with the corresponding attributes in X an  In a classical set or crisp set, the objects in a set are called elements or members of the set. An element x belonging to a set A is defined as x  A A characteristic function or membership function  A  x defined as an element in the universe U having a crisp value of 1 or 0. For every x  U The membership functions for crisp set can take a value of 1or 0, the membership functions for fuzzy sets can take values in the interv T h e ran g e bet w een 0 an d 1 is ref erred  to as the membership grade or degree of membership. A fuzzy set A is defined as Where  A  x membership function belonging to the interval th e proble m can be s t a t ed as Au to m a tic generation of membership function for the fuzzy set, mining fuzzy association rules and hiding the sensitive association rule by decreasing the support of item on right hand side of the rule until confidence goes below minimum confidence III ALGORITHM FOR GENERATING MEMBERSHIP FUNCTION AUTOMATICALLY The procedure for automated generation of fuzzy membership function is detailed in this section. The data are clustered into classes. Membership functions are then generated from these class  T h e alg orithm is  detailed as follows Step 1 Consider a data set with n transactions. If the domain of all attributes is same and has limited values then for each transaction the values of all attributes are averaged and the transactions are sorted in ascending order of the average value else go to step 2 Step 2 The difference  between adjacent values of a particular attribute in all transactions in the sorted data is determined. The difference as shown in equation \(1\ill provide a way to calculate the similarity between adjacent values The difference for a set of transactions  is for i=\(1,2,3, n-1\          \(1 Where y i and y i+1 are adjacent values in the sorted data Step 3 The similarities between adjacent values are determined using equation \(2\d are mapped into real numbers between 0 and 1     2 Where diff i is the difference between adjacent data  s is the standard deviation of diff i and C is the control parameter and is used to determine the shape of the membership function Step 4 The data is then grouped according to similarities A threshold value  divides adjacent values into classes. The number of classes determines the number of membership i i i y y diff    1     otherwise 0   for  1 s i s i i C diff C diff s       A for 0 A for 1 x x x A       1  0       x A x x x A A A   2011 World Congress on Information and Communication Technologies 149 


functions. If the similarity \(s i greater than the threshold value, then the two adjacent values belong to the same class otherwise the values are divided into different classes as represented in equation \(3  3 where C i and C i+1 denote two distinct classes for the same input or output parameter Step 5 Membership Function is defined for each class One of the simplest membership functions is the triangular membership function, and is used for the remainder of the equations. Triangular membership function for class j consists of three points, the central vertex point, b j and the two endpoints, a j and c j as shown in fig. 1 Figure 1. Triangular membership function The central vertex point for each class is determined using the formula        4 Where j represents the j th class, y min represents the first data index for this class, i.e., data y i through y k fall into class j, and y max represents the ending data index within that class The left and right endpoints of the membership function, aj and cj, are obtained using equation \(5\d \(6     5       6 Where is the threshold value IV ALGORITHM FOR HIDING SENSITIVE FUZZY ASSOCIATION RULES In a quantitative database, if a critical rule X Y needs to be hidden, its confidence value is decreased to a value smaller than the minimum confidence value. One way of decreasing confidence value is decreasing the support value of an item Y at RHS, and the other way is increasing the support value of item X at LHS Our approach decreases confidence value of a rule, by decreasing the support value of RHS item. If the value of item in RHS  is greater than 0.5 and value of item in LHS then its value is subtracted from 1. Abbreviations used in the proposed algorithm are given as follows D  Initial database with n transaction data  C  Cleaned database with n transaction data  F  Fuzzified database X  A set of predicting items TL Transactions belong to a LHS item TR Transactions belong to a RHS item U Rule Rh sensitive rule Input 1\ource database D 2\imum support value \(min_support 3\imum confidence value \(min_confidence Output A transformed database D so that useful fuzzy association rules cannot be mined Algorithm DSR 1. Cleaning of database, D C 2. Fuzzification of the cleaned database, C F 3. Calculation of  support value for all items,  where f  F in fuzzified database F 4. IF all f \(support\in_support THEN   EXIT; // there isnt any rule 6. Find large 2-itemsets from F 7. FOR EACH Xs large 2-itemset //find all rules Find R = {Rules from itemset X for X= {i1, i2}, rules are i1 i2, i2 i1 Compute confidence of the rule U   IF confidence \(U\min_confidence and sensitive THEN Add the rule U to Rh end//if end//end of FOR EACH Hides all rules in Rh 8.  FOR EACH U in Rh  {//until no more rule can be hidden   FOR EACH TR of rule if TR >0.5 and TR > TL TR = 1 - TR end // if end // FOR EACH  Re-calculate confidence value of rule U if rule U\(confidence\min_confidence FOR EACH TR of the rule   if TR = 1.0 TR = 0.0 end// if end // FOR EACH else go to step 9  end //if 9. Transform the updated database F to D and output updated D 10. end An illustration of the working of the proposed algorithm is as follows Step 1 The database as in Table1 is cleaned by substituting the unknown values by zero, and eliminating the redundant records. In case of mu ltiple records having the same id the last one is taken Table 1.  Sample data with 5 attributes A B C D E T1 3   2 1 T2 14 5 10 4 2 T3 12 9 8 5 3 T4 10 8 10 6 4 T5 13 4 11 8 9 1 i 1 i i 1 C  C ELSE  C  THEN   IF        i i i i i y y y y s  Data Fuzzy Values 1 0 a i c i a k c k 150 2011 World Congress on Information and Communication Technologies 


Table 2. Cleaned data A B C D E  T1 3 0 0 2 1 T2 14 5 10 4 2 T3 12 9 8 5 3 T4 10 8 10 6 4 T5 13 4 11 8 9 Step 2 Fuzzification The cleaned database as shown in table 2 is fuzzified using triangular membership function given in equation \(8\ into 3 regions Z, O, B as shown in fig 2. The fuzzified data is shown in table 3        8 Where a  is the left end of the triangle, b is the peak of the triangle and c is the right end of the triangle \(values are the corresponding x axis values Fig 2. Triangular Membership Function used Step 3 Calculate the support count of each attribute region R on the transactions data by summing up the fuzzy values of all the transactions in the fuzzified transaction data as in table 3 Step 4 Check whether count of each attribute is greater than or equal to the predefined minimum support value. If an attribute satisfies the above condition, put it in the set of large2 itemsets \(L2 Consider the minimum support is set to 2.3 and minimum confidence to 70%. The regions Bz, Co and Dz are have their support value greater than minimum support, so are considered in forming the rules and finding the corresponding confidence value. The rules  can  be   Bz Co Co Dz, Bz Dz, Co Bz, Dz Co, Dz Bz. Consider Bz Co is a critical rule to be hidden and the support of the rule is calculated as shown in table 4 Step 5 For each large 2 itemsets, based on user specified minimum confidence value, rules are extracted. Confidence value of  A B rule is computed as follows    The confidence value is calculated for the rule Bz Co    Step 6 To hide a critical rule, its confidence value is decreased by decreasing support\(AB\ order to hide the rule Bz Co, the  support \(BzCo\ reduced by subtracting the transaction value of Co from 1 when the value of Co is greater than 0.5 and corresponding Bzs value. Using this procedure the support values of transaction T3 and T4 are reduced as shown in table 5 Now the confidence is    As the confidence is still greater than minimum confidence, in those transactions that have Bz and Co value as 1, Co is replaced with 0 as shown in T2 of table 6. The confidence value after the modification is calculated as    As the confidence value is less than the predefined confidence value the rule Bz Co is hided.  The modified values replace the original fuzzified values in the fuzzification table as shown in table 7. Defuzzification using centroid method is done on the modified values to get back quantitative values using the equation \(9 Table 4. Fuzzy values of Bz and Co Bz Co Support T1 0.0 0.0 0.0 T2 1.0 1.0 1.0 T3 0.2 0.6 0.2 T4 0.4 1.0 0.4 T5 0.8 0.8 0.8 Count 2.4  2.4 Table 5. Modified T3 and T4 Bz Co Support T1 0.0 0.0 0.0 T2 1.0 1.0 1.0 T3 0.2 0.4 0.2 T4 0.4 0.0 0.0 T5 0.8 0.8 0.8 Count 2.4  2.0 Table 6. Modified T1 Bz Co Support T1 0.0 0.0 0.0 T2 1.0 0.0 0.0 T3 0.2 0.4 0.2 T4 0.4 0.0 0.0 T5 0.8 0.8 0.8 Count 2.4 1.0 The  defuzzified values  are shown  in  table 8     9 Where  X is the quantitative value, n is the number of regions, xi is the center point of that triangle xi\ding membership value in that triangle 5 10 15       20 Quantity Membership value z o b 2011 World Congress on Information and Communication Technologies 151 


Table 3. Fuzzification of transaction data Transaction A B C D E  n Az Ao Ab Bz Bo Bb Cz Co Cb Dz Do Db Ez Eo Eb T1 0.6 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.4 0.0 0.0 0.2 0.0 0.0 T2 0.0 0.2 0.8 1.0 0.0 0.0 0.0 1.0 0.0 0.8 0.0 0.0 0.4 0.0 0.0 T3 0.0 0.6 0.4 0.2 0.8 0.0 0.4 0.6 0.0 1.0 0.0 0.0 0.6 0.0 0.0 T4 0.0 1.0 0.0 0.4 0.6 0.0 0.0 1.0 0.0 0.8 0.2 0.0 0.8 0.0 0.0 T5 0.0 0.4 0.6 0.8 0.0 0.0 0.0 0.8 0.2 0.4 0.6 0.0 0.2 0.8 0.0 Count 0.6 2.2 1.8 2.4 1.4 0.0 0.4 3.4 0.2 3.4 0.8 0.0 2.2 0.8 0.0 Table 7 Modified Fuzzy values Transaction A B C D E n Az Ao Ab Bz Bo Bb Cz Co Cb Dz Do Db Ez Eo Eb T1 0.6 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.4 0.0 0.0 0.2 0.0 0.0 T2 0.0 0.2 0.8 1.0 0.0 0.0 0.0 0.0 0.0 0.8 0.0 0.0 0.4 0.0 0.0 T3 0.0 0.6 0.4 0.2 0.8 0.0 0.4 0.4 0.0 1.0 0.0 0.0 0.6 0.0 0.0 T4 0.0 1.0 0.0 0.4 0.6 0.0 0.0 0.0 0.0 0.8 0.2 0.0 0.8 0.0 0.0 T5 0.0 0.4 0.6 0.8 0.0 0.0 0.0 0.8 0.2 0.4 0.6 0.0 0.2 0.8 0.0 Count 0.6 2.2 1.8 2.4 1.4 0.0 0.4 1.2 0.2 3.4 0.8 0.0 2.2 0.8 0.0 Table 8. Defuzzified table A B C D E T1 3 0 0 2 1 T2 14 5 0 4 2 T3 12 9 8 5 3 T4 10 8 0 6 4 T5 13 4 11 8 9 V EXPERIMENTAL RESULTS Experimental results were taken using Wisconsin Breast Cancer dataset from UCI Machine Learning Repository  T h e dataset con s is ts of on e id attrib u t e, nine quantitative attributes and one categorical    attribute This algorithm was implemented using nine quantitative attributes which are mapped to three fuzzy sets each. Three rules were randomly selected for hiding. Experimental results were taken with membership function given by expert and automatically generated membership function i\ membership function provided by experts Figure 3. Number of rules vs minimum support Fig. 3 shows the number of generated rules and hidden rules for varying values of support with a constant minimum confidence of 50 when quantitative data is fuzzified using membership function values supplied by the experts. As DSR method is used the number of rules hidden for increased values of support is less. In previous work  it changes according to the support value Figure 4. Number of rules vs minimum confidence Fig. 4 shows the number of generated rules and hidden rules for varying values of confidence and a constant minimum support of 50 Figure 5. Rules lost after hiding a set of three rules 152 2011 World Congress on Information and Communication Technologies 


Fig. 5 shows the number of rules lost as a side effect of hiding three rules is less in proposed method than in previous work ii\ Automated Generation of  Membership Function\(AGMF Experimental results in Fig. 6 show the number of generated rules and hidden rules for varying values of support with a constant minimum confidence of 50. Fig. 7 shows the number of generated rules and hidden rules for varying values of confidence with a constant minimum support of 50 when quantitative data is fuzzified using membership function values generated by the proposed algorithm Figure 6. Number of rules under different minimum support Figure 7. Number of rules under different minimum confidence Figure 8. Rules lost after hiding a set of three rules Fig. 8 illustrates that the number of lost rules is less in the proposed approaches, DSR and DSR with autogenerated membership function, when compared to the previous work rth er the DSR  m e t h od decreas es th e  support so that no ghost rules are produced. From the results it is inferred that automatic membership function generation provides consistent rule hiding even in the absence of expertise VI C ONCLUSION In this paper, we proposed a learning method to derive membership functions automatically for numeric data and presented a method for preventing extraction of useful association rules from quantitative data by decreasing the support of the RHS of the rule. Unlike previous approaches which mainly deals with association rules in binary database, our approach deals with hiding the association rules in quantitative database. Experimental results demonstrate that the proposed approach is more efficient as it facilitates better rule hiding and  minimizes the number of lost rules and ghost rules. Also, this approach makes minimum modification of data. To further minimize the side effect and modification to database genetic algorithm can be used REFERENCES 1 T Be rbe rog lu a n d M Ka y a  H iding F u z z y  A s soc ia tion R u le s in Quantitative Data  The 3rd InternationalConference on Grid and Pervasive Computing Workshops, May 2008, pp. 387392 2 M a noj G upta a nd R  C  J o s h i  P r i v a cy P r e s e r v i ng Fuz zy  Association Rules in in Quantitative DataŽ, International Journal of Computer Theory and Engineering, Vol. 1, No. 4 October, 2009, 382-388 3 V a ssilios S V e ry k i os, A  K. E l m a g a r m id, E. Be rtino, Y  Saygin, and E. Dasseni, Association Rule Hiding IEEE Transactions on Knowledge and Data Engineering vol. 16 no. 4, pp. 434-447, 2004  Dr Du raiswa my  K Dr M a n j u l a D an d M a h e swari N A  New Approach to Sensitive Rule HidingŽ, ccsenet journal, vol 1, No. 3, August, 107-111 5 Yuc e l Sa y g in, V a ssilios V e ry k i os, a nd Chris Clif ton  Using Unknowns to Prevent Discovery of Association Rules  SIGMOD Record 30 \(2001\, no. 4, 45…54 6 Y uho ng G uo, 200 7 R e c ons tr uc tionB a s e d A s s o c i a tion R u le  HidingŽ, Proceedings of SIGMOD2007 Ph.D. Workshop on Innovative Database Research 2007\(IDAR2007\51-56 7 C hris C lif ton a nd Mura t K a nta rc iog lu a nd J a ide e p Va idy a   Defining Privacy for Data Mining," in Proceedings of the National Science Foundation Workshop on Next Generation Data Mining, November 1-3, 2002, Baltimore, MD 8 Chih-C hia W e ng e t e t  A Nove l A l g o rithm  f o r Co m p le te l y  Hiding Sensitive Frequent ItemsetŽ , Dept. of Information Science, Chung Cheng Institute of Technology, National Defense University , 2007  C h i h C h ia W e n g  S h an T ai Ch en  Hun g-Ch e L o  A  No vel  Algorithm for Completely Hiding Sensitive Association RulesŽ , Eighth International Conference on Intelligent Systems Design and Applications, 2008 10 C a no, J  a nd P  N a v a A Fuzzy Me thod f o r  A u tom a tic Generation Of Membership Function Using Fuzzy Relations from Training Examples  Proceedings of the 21st NAFIPS International Conference, pp. 158-162, June 2002 11 T  P  H ong  C  Y  L e e   I nduc tion of f u z z y r u le s a nd membership functions from training examplesŽ, Fuzzy Sets and Systems - FSS , vol. 84, no. 1, pp. 33-47, 1996 12 T  P  H o n g  C  S  K u o  S  C  C h i   M i n i n g a s s o c i a t i o n r u l e s  from quantitative dataŽ, Intell. Data Anal. 3 \(5\3 376, 1999 13 L  A  Za de h F uz z y Se ts  Inf o r m a tion a n d Co ntrol V o l 8  pp.338-353, 1965 14 http://mlearn.ics.uci.edu/databases/breast-cancer wisconsin/breast-cancer-wisconsin.data 2011 World Congress on Information and Communication Technologies 153 


187 


188 


189 


190 


               


Table V gives the set of intervals in which the variations are not significant. These intervals are computed based on the risk RSA 1.65;+1.65] 10 1.96;+1.96] 5 2.58;+2.58] 1 3.29;+3.29] 0.1 TABLE V INTERVALS IN WHICH NON-SIGNIFICANCE IS DETECTED When the RSA is applied to the association education ? wage results listed in table VI education wage [6;7] [8;9] [10;13] [14;18 2.85; 4.70] 1.83 1.69 3.88 -4.94 4.75; 7.14] 0.41 0.76 1.37 -1.88 7.30; 12.67] -0.72 -0.62 0.17 0.59 13.00; 26.29] -0.99 -1.49 -6.35 6.56 TABLE VI ADJUSTED STANDARDIZED RESIDUAL OF THE ASSOCIATION EDUCATION-WAGE The negative values denote underrepresentativeness, and the positive ones overrepresentativeness We can now transpose these results to initial variations contingency, table III Table VII represents the enhanced variations contingency. In order to notice the differences, all grayed cells are pruned thanks to the RSA education wage [6;7] [8;9] [10;13] [14;18 2.85; 4.70] 3 4 15 -22 4.75; 7.14] 1 3 8 -12 7.30; 12.67] -2 -3 1 5 13.00; 26.29] -1 -4 -25 30 TABLE VII ENHANCED CONTINGENCY TABLE OF VARIATIONS FOR THE ASSOCIATION \(EDUCATION-WAGE This table is the starting point of the consolidation process described below 39 


V. CONSOLIDATION PROCESS The first step to build the largest zones is to scan the enhanced contingency table of variations looking for the cell with the highest absolute value This cell constitutes the first rectangle noted R1 with the coordinates of upper left point pl and lower right point pr The second scan compares all the values in the immediate neighborhood of R1. The expansion is performed in descending fashion, i.e. starting from the largest value with similar behavior of the constituted rectangle expanded to the new coordinates The expansion of the formed rectangle continues by performing the summation of its vicinity cells values. We start by including cells whose values sum is the largest. The expansion stops once meeting null cells and the consolidation process ends when all maximal rectangles are formed. These results allow restricting the number of records to be processed by only keeping those retained after the consolidation phase When applying this process to the enhanced contingency table of variations resulting from the education-wage only would be considered the records included in the clusters "education=[10;13]" or "education=[14;18]" associated to "wage=[2.85;4.70]" or wage=[13;26.29 Notice, in the case of the association education ? wage process enables to focus on 172 records instead of 526 \(32 VI. CONCLUSIONS In this paper, we describe our discretization approach focusing on the potential interactions between a databases variables. This approach makes it possible to carry out a contextual discretization maximizing the informativeness and highlighting the variables dependencies The use of a tabular representation is particularly interesting in the case of numeric variables 


where knowledge is synthetically summarized. The formed attractive and repulsive zones, based on human considerations and statistics, guarantee that potentially interesting knowledge will be discovered with decreasing by the way the search space REFERENCES 1] J. Ben-Zvi, The time relational model, Ph.D., University of California, Los Angeles, 1982 2] A. Agresti,Categorical Data Analysis, New York: Wiley pp. 224, 1990 3] J.R. Quinlan,C4.5: Programs for Machine Learning, Morgan Kaufmann. San Mateo, Calif.,1993 4] T. J. Archdeacon,Correlation and Regression Analysis: A Historians Guide,pp. 352,Univ of Wisconsin Press,1994 5] J. Dougherty, R. Kohavi, M. Sahami, Supervised and unsupervised discretization of continuous features, In Proceedings of the 12th International Conference on Machine Learning, 1995, pp. 194-202 6] P.M. Murphy and D.W. Aha, UCI Repository of Machine Learning Databases,Machine-readable collection, Dept of Information and Computer Science, Irvine, 1995 7] F. Hussain, H. Liu, Ch.L. Tan, M. Dash, Discretization An Enabling Technique, Technical Report ?U School of Computing, Singapore, 1999, June 8] Y. Aumann and Y. Lindell, A Statistical Theory for Quantitative Association Rules, Knowledge Discovery and Data Mining, pp. 261-270, 1999 9] S. Bay, Multivariate discretization of continuous variables for set mining, In Proceedings of the 6th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, 2000, pp. 315 ?U319 10] G. Bisson and C. Nedellec, Aide  la conception de mthodes de classification pour la construction dontologies latelier MoK, 1res journes francophones Extraction et Gestion des Connaissances \(EGC01 19 janvier, 213-225, 2001 11] S. Guillaume, Discovery of Ordinal Association Rules PAKDD, pp. 322-327, 2002 12] S. Kotsiantis and D. Kanellopoulos, Discretization Techniques: A recent survey, GESTS International Transactions on Computer Science and Engineering, Vol.32 \(1 58, 2006 


13] S. Guillaume and L. Nemmiche Alachaher, Visualisation des zones dattraction entre les variables, 15me RFIA Tours, France, 2006 40 


Proceedings of Supercomputing 96, Pittsburg, PA, pp. 17-22 November 1996 9] Ceglar and J. Roddick, Association Mining, ACM Computing Surveys, Vol. 38, No. 2, pp. 1-42, July 2006 10] Y. Ye and C.-C. Chiang, A parallel apriori algorithm for frequent itemsets mining, Proceedings of the Fourth International Conference on Software Engineering Research, Management, and Applications SERA 06 11] J. JaJa, An Introduction to Parallel Algorithms, Upper Saddle River NJ: Addison Wesley, 1996  214 


12] Dhond, Gupta, A., Vadhavkar, S. Data mining techniques for optimizing inventories for electronic commerce[C]. In the Proceeding of the ACM-SIGKDD International Conference on Knowledge Discovery and Data Mining, 2005:480-486 13]Chui-Yu Chiu , Yi-Feng Chen. An intelligent market segmentation system using k-means and particle swarm optimization[J]. Expert Systems with Applications, 2009, 36: 45584565 14]Tzung-Shi Chen , Shih-Chun Hsu. Mining frequent tree-like patterns in large datasets[J]. Data & Knowledge Engineering, 2007,62:6583 15]H. Tsukimoto, Extracting rules from trained neural networks[J]. IEEE Trans.Neural Networks, 2000, 11 \(2 156 


http://datamining.buaa.edu.cn/TopKCos.pdf 14] M. Zaki, Scalable algorithms for association mining, TKDE, vol. 12, pp. 372390, 2000 


enhance item-based collaborative filtering, in 2nd IASTED International Conference on Information and Knowledge Sharing, Scottsdale, Arizona, 2003 476 2010 10th International Conference on Intelligent Systems Design and Applications 


Basi Association Rles Basi c  Association R u les Association is basically connecting or tying up occurrences of Association is basically connecting or tying up occurrences of events Ol dib t f ilt t O n l y d escr ib e se t s o f s i mu lt aneous even t s Cannot describe patterns that iterate over time e g  itemset a  0  b  0  g    Eg If you sense higher data rates on the downlink than normal AND New Route generated Implies high chances of Intrusion AND New Route generated Implies high chances of Intrusion Associative IDS for NextGen Frameworks Dr S Dua LA Tech 20 


Enhanced Inte r transaction Association Rules Enhanced Inter transaction Association Rules Enhanced Inter transaction Association Rules Extension of association rules Conditional relationships at multiple different time steps e.g itemset a\(0 0 1 2 You sense Higher data rate than normal AND You see New Route g enerated AND 1 minute a g o you detected checksum gg error packets AND 2 minutes ago your encountered wrong checksum   Implies High Chance of Intrusion Enhanced Rules and Confidence Associative IDS for NextGen Frameworks Dr S Dua LA Tech 21 


Complex Spatio temporal Association Complex Spatio temporal Association Rules Further extension of inter transaction association rules Describe event durations e.g itemset a\(0,X j,Y k,Z Eg  You sense high data rates for X seconds AND new route generated j minutes ago task completed in Y AND new route generated j minutes ago task completed in Y seconds AND checksum error packets received k minutes ago for Z seconds High Chance of Intrusion With highest confidence level in association rules  association rules  Associative IDS for NextGen Frameworks Dr S Dua LA Tech 22 


DMITAR Al ith ARD DMITAR Al gor ith m  ARD Problem Domain Problem Statement and Challenges Aiti Miig bd IDS A ssoc i a ti ve Mi n i n g b ase d IDS  Introduction to data mining Association rule in data mining DMITAR Algorithm  ARD New research Associative IDS for NextGen Frameworks Dr S Dua LA Tech 23 


DMITAR Algorithm DMITAR Difference Matrix Based Inter Transaction Association Rule Miner developed in DMRL Uses vertical data format Differences of the transaction IDs are used to generate extended itemsets Windowless mechanism Associative IDS for NextGen Frameworks Dr S Dua LA Tech 24 


Deep into the Mechanism The DMITAR algorithm is based on lhilii comp l ex mat h emat i ca l assoc i at i ve formulation and proofs Four major parts Four major parts Frequent 1 itemset generation Frequent 2 itemset generation Frequent k itemset generation k>2 Spatio temporal rule formation Associative IDS for NextGen Frameworks Dr S Dua LA Tech 25 


DMITAR, Datasets Used Stock Data Stock Data Daily stock information provided by Yahoo finance Wth Dt W ea th er D a t a Provided by the US Department of Commerce and National Climactic Data Center for 700 locations across US Synthetic Data Provided by a CRU weather generator that uses a Markov chain model to generate simulated weather data for 11 UK sites Associative IDS for NextGen Frameworks Dr S Dua LA Tech 26 


DMITAR Results 1/5 Varying Support DMITAR Results 1/5 Stock Database Support FITI ITPMine PROWL DMITAR 14 6424.7s 132.39s 3.03s 5.556s 16 2348.9s 67.14s 2.14s 4.015s 18 861.92s 34.62s 1.55s 2.89s 20 334.51s 18.89s 1.12s 2.07s 22 143 84s 10 87s 0 87s 1 45s 22 143  84s 10  87s 0  87s 1  45s 24 63.62s 7.15s 0.671s 1.04s Weather Database Support FITI ITPMine PROWL DMITAR 14 36362.6s 893.1094s 5.843s 19.8281s 36362.6s 893.1094s 5.843s 19.8281s 16 11913.04s 378.2188s 3.8906s 13.4375s 18 4116s 170.3438s 2.75s 9.1406s 20 1507s 86.5781s 2.14s 6.203s 22 859.2813s 63.3438s 1.7969s 5.7656s 24 378.5313s 36.1875s 1.4375s 3.5625s Synthetic Dataset Support FITI ITPMine PROWL DMITAR 14 1651.6s 199.843s 3.1406s 17.015s 16 574 32 119 32 2 0938 10 875 16 574  32 s 119  32 s 2  0938 s 10  875 s 18 416.109s 95.31s 1.6094s 7.39s 20 370.25s 83.31s 1.453s 5.8438s 22 265.78s 66.3438s 1.3594s 4.75s 24 133.96s 43.0781s 0.9219s 3.5781s 


DMITAR Rlt  DMITAR  R esu lt s 2  5 Rules Formed Associative IDS for NextGen Frameworks Dr S Dua LA Tech 28 


DMITAR Rl  Varying Maxspan DMITAR  R esu l ts 3  5 Varying Maxspan Associative IDS for NextGen Frameworks Dr S Dua LA Tech 29 


DMITAR Res lts 4/5 Vig Di i DMITAR  Res u lts  4/5 V ary i n g Di mens i ons Associative IDS for NextGen Frameworks Dr S Dua LA Tech 30 


DMITAR Rl  Varying Number of Transactions DMITAR  R esu l ts 5  5 Varying Number of Transactions Associative IDS for NextGen Frameworks Dr S Dua LA Tech 31 


N/C t Rh N ew C urren t R esearc h Problem Domain Problem Statement and Challenges Associative Mining based IDS Associative Mining based IDS Introduction to data mining ii lid ii Assoc i at i on ru l e i n d ata m i n i ng DMITAR Algorithm  ARD h New Researc h Associative IDS for NextGen Frameworks Dr S Dua LA Tech 32 


Further Research Further Research Objectives of Our Intrusion Detection System Development Objectives of Our Intrusion Detection System Development 1 Refine and scale the DMITAR algorithm to suit our application 2 Develop methods for dynamically altering the sensor parameters Our Focus is Securing the NextGen Frameworks with New Technology Technology Associative IDS for NextGen Frameworks Dr S Dua LA Tech 33 


Simulated Sensing Environment Simulated Sensing Environment Screenshots of Data C ollected from S ynthetic Sensors Screenshots of Data C ollected from S ynthetic Sensors Simulated in Our Laboratory Three Steps Slides Collect data Collect data from all sources  all attributes  Select Select the source and their hierarchical attributes attributes to be monitored and Select Select the source and their hierarchical attributes attributes to be monitored  and Sample Sample them at different rates different rates and process them Associative IDS for NextGen Frameworks Dr S Dua LA Tech 34 


Data Collection Simultaneous collection of data screen from ENTITIES aircrafts Associative IDS for NextGen Frameworks Dr S Dua LA Tech 35 Source PRTG Network Monitor software screen shot Demo info www.paessler.com 


Parameter Selection Selection of an ENTITY/aircraft and monitoring its parameters and sensor readings Associative IDS for NextGen Frameworks Dr S Dua LA Tech 36 Source PRTG Network Monitor software screen shot Demo info www.paessler.com 


Sensor Sampling Selecting one sensor/probe and reading it at different resolutions or sampling rates Associative IDS for NextGen Frameworks Dr S Dua LA Tech 37 Source PRTG Network Monitor software screen shot Demo info www.paessler.com 


Si l ti Nt k Si mu l a ti on on N e t wor k Most scenarios can be simulated on a computer or computer network network  The aircrafts and sensors are simulated on a computer network bllb b y ana l ogica l su b stitutions Sensors provide information at different rates Sensors provide information at different rates Need Based Sensor Prioritization NSP and Dynamic Sensing Rate Sampling Associative IDS for NextGen Frameworks Dr S Dua LA Tech 38 


Vulnerability Search Scan 39 Sample UQA script with Nmap performed in DMRL Associative IDS for NextGen Frameworks Dr S Dua LA Tech 39 Source Nmap screenshot with a pearl script  Find Namp on Nmap.org 


Modality Aspect Modality Aspect A Multimodal distribution is a continuous probability distribution with two or more modes of underlying data Mltil d i M u lti p l e mo d es i n our model Associative IDS for NextGen Frameworks Dr S Dua LA Tech 40 Source http://en.wikipedia.org/wiki/File:Bimodal bivariate small.png 


Multi Modality Modality Fusion 41 SENSITIVE  UNCLASSIFIED For Official Use Only Associative IDS for NextGen Frameworks Dr S Dua LA Tech 41 


Emphasis Emphasis Our approach emphasizes on pre empting the attack Our intent is NOT to perform an autopsy to discover attacks Instead we aim to detect and prevent in attacks in real time Associative IDS for NextGen Frameworks Dr S Dua LA Tech 42 


Techniques for Discriminative Rules Techniques for Discriminative Rules Resolution Analysis Features Analyzed at Different Depths Anti Monotonic Principle Modality Aspect Treading into Unexplored Feature spaces Associative IDS for NextGen Frameworks Dr S Dua LA Tech 43 


Representative Outcomes Representative Outcomes Illustration of the Final Analysis Our method shifts between modalities and sampling rates for optimization The blue parallelograms are actual intrusions 44 The blue parallelograms are actual intrusions The Red Green Blue Plots are response of system Associative IDS for NextGen Frameworks Dr S Dua LA Tech 44 


Advantages of Our M ethod Advantages of Our M ethod Exploit the memory v ertical data format utilizes slidin g windows to g form a much larger database to analyze  Flexibility in Choosing what to choose  Choosing what to choose to build the rules Computational and memory efficiency We have a team working only on this aspect 45 Associative IDS for NextGen Frameworks Dr S Dua LA Tech 45 


Preliminary Results Intra transaction Relations Data rate simulator NH-134 Mb HOP PATH update \(Y/N Inference 11.5 Y Y 2 0.120 N N      Y   n 0.345 N NH134 Y/N   Inf 1 0.150 N N 2 0 120 Y N Inter transaction Relations 2 0  120 Y N       5 5.55 0.456 Y Relations  n 0.345 N N Nmap on DMRL nmap.org 


Anticipated Outcome Anticipated Outcome Develop algorithm capable of learning from a given heterogeneous diverse Develop algorithm capable of learning from a given heterogeneous diverse data ff Dynamic algorithmic f ramework designed to shi f t modalities and sampling rates based on complex logic Flexibility of integration into the Snort intrusion detection system 47 Associative IDS for NextGen Frameworks Dr S Dua LA Tech 47 


References References Aircraft Cockpit Image courtesy USAF http://www.faa.gov htt p   www.faa g ov  air traffic  technolo gy  p g  _ gy  Acharya R Dua S Du X Sree V Chua C K Automated Diagnosis of Glaucoma Using Texture and Higher Order Spectra Features To appear in IEEE Transactions on Information Technology in Biomedicine  Du X Dua S 2011 Cancer Prognosis Using Support Vector Regression in Imaging  Modality World Journal of Clinical Oncology 2  1   44 49 Du X Dua S 2010 Salient Frame Extraction Using Support Vector Regression and Motion Features pp 5 Proc of the National Aerospace and Electronics Conference July 14 16 2010 D M P D S 2010 Di i i ti Ft d Cl ifi ti Mthd f D essaue r  M  P  D ua S  2010  Di scr i m i na ti ve F ea t ures an d Cl ass ifi ca ti on M e th o d s f or Accurate Classification 1st ed vol 7704 pp 14 Bellingham WA Proceedings of SPIE Dessauer M P Dua S 2010 Low Resolution Vehicle Tracking using Dense and Reduced Local Gradient Features Maps 1st ed vol 7694 pp 8 Bellingham WA Proceedings of SPIE SPIE 


Acknowledgements Acknowledgements Fundin g A g encies  US 4 1 Million direct fundin g g g 4 g LA BoR NIH NSF AFRL AFOSR and NASA Research Team Samuel Kasimalla Brandy McKnight Dr Pradeep Chowriappa Connor Johnson Vasanth Nair Mihir Chowriappa  Connor Johnson  Vasanth Nair  Mihir Karnik Mohit Jain and Swadheen Songmen Associative IDS for NextGen Frameworks Dr S Dua LA Tech 49 All the respective Logos belong to their owners 


Rf d Rdi R e f erence d R ea di ngs Copyright of cover pages held by respective publishers 


Thank You Questions Thank You  Questions Dr Sumeet Dua E mail sdua@latech.edu Web http://dmrl.latech.edu Associative IDS for NextGen Frameworks Frameworks Dr S Dua LA Tech 51 Image Source roadtrafficsigns.com 


