Bounded Rationality for Data Reasoning based on Formal Concept Analysis Gonzalo A Aranda-Corral Department of Information Technology Universidad de Huelva Palos de La Frontera Spain Email:gonzalo.aranda@dti.uhu.es Joaqu  021n Borrego-D  021az and Juan Gal  an-P  aez Department of Computer Science and Arti\002cial Intelligence Universidad de Sevilla Sevilla Spain Email:jborrego@us.es juangalan@us.es Abstract Formal Concept Analysis FCA is a theory whose 
goal is to discover and extract Knowledge from qualitative data It also provides tools for sound reasoning implication basis and association rules The aim of this paper is to apply FCA to a new model for bounded rationality based on the implicational reasoning over contextual knowledge bases which are obtained from contextual selections A contextual selection is a selection of events and attributes about them which induces partial contexts from a global formal context In order to avoid inconsistencies association rules are selected as reasoning engine The model is applied to forecast sport results Keywords Formal Concept Analysis Bounded Rationality 
Con\002dence Reasoning I I NTRODUCTION Bounded Rationality BR is intimately related with the human capacity for making inferences under limited time and Knowledge From the vie wpoint of Arti\002cial Intelligence AI BR comprises reasoning techniques that facilitate for example context and temporal reasoning Psychological research on speci\002c heuristics in human inference processing reveals a complex framework where traditional approaches to classical logic is not sound for explaining the success of several of them as for example Recognition Heuristic RH A number of e xperiments sho w that cognitive mechanisms capable of successful performance in 
the real world do not need to satisfy the classical norms of rational inference cf see also 4 In f act an intriguing question from ecological rationality analysis is How could more knowledge be no better—or worse—than signi\002cantly less knowledge One of the k e y features in BR is that inference process is concentrated on a limited set of experiences in which objects properties and actions are selected In this paper we aim to model this feature with Formal Concept Analysis Formal Concept Analysis FCA is a mathematical theory for data analysis using formal contexts and concept lattices as key tools Domains can be formally modelled according to the extent and the intent of each formal concept 
In FCA the basic data structure is a formal context with a qualitative nature which represents a set of objects and their properties It is useful both to detect and to describe regularities and the relationship structures among concepts It also provides a sound formalism for reasoning with such structures mainly implication basis and association rules Roughly speaking formal contexts represent weak structures easily built from experience that allow the extraction of knowledge from them Despite its simple data structure formal contexts are useful structures for knowledge extraction cf and reasoning Moreo v er  in BR it is well kno wn that in several cases simple statistical forecasting rules which are 
usually simpli\002cations of models have been shown to make better predictions than more complex rules especially when the future values of a criterion are highly uncertain The thesis of the paper is that association rules associated to formal contexts can be an interesting source for BR The aim is to present a logical model of BR based on reasoning on subcontexts of a predetermined global context which plays the role of global memory/qualitative dataset The model is based on the existence of some selective processes named contextual selection here which induce speci\002c contexts and implicational basis are extracted from them namely Stem Basis and association rules The reasoning with these Knowledge Bases KB called 
contextual KB is the model reasoning proposed in the paper Logical combination of contextual KBs in order to avoid inconsistencies with background Knowledge can be made The model has been used in to describe a con\002dencebased and contextual reasoning system for forecasting sports betting In this paper we analyse the soundness of the formal model as one of bounded rationality presenting the theoretical framework The structure of the paper is as follows The next section reviews the main elements of FCA and its logical features In section 3 the role of formal contexts as basic bricks for a model of bounded rationality is presented Section 4 reviews 
an experiment by using the model for forecasting in sports betting Section 5 is devoted to describe future work II B ACKGROUND  F ORMAL C ONCEPT A NALYSIS According to R Wille FCA mathematizes the philosophical understanding of a concept as a unit of thoughts composed of two parts the extent and the intent The extent covers all objects belonging to this concept while the intent comprises of all common attributes valid for all the 
2011 22nd International Workshop on Database and Expert Systems Applications 1529-4188/11 $26.00 © 2011 IEEE DOI 10.1109/DEXA.2011.18 350 


Figure 1 partial context from observation and Stem Basis objects under consideration It also allows the computation of concept hierarchies from data tables In this section we succinctly present basic FCA elements see for details A formal context M   O A I  consists of two sets O objects and A attributes and a relation I 022 O 002 A  Finite contexts can be represented by a 1-0-table identifying I with a Boolean function on O 002 A  See Fig 1 for an example of formal context about live beings The FCA main goal is the computation of the concept lattice from the context For X 022 O and Y 022 A we de\002ne X 0  f a 2 A j oIa for all o 2 X g Y 0  f o 2 O j oIa for all a 2 Y g A formal concept is a pair  X Y  such that X 0  Y and Y 0  X  In this paper it works with logical relations on attributes which are valid in the context and the standard implicational logic in FCA see e.g called implications between attributes  De\002nition 1 An implication between attributes is a pair of sets of attributes written as Y 1  Y 2  An implication is true with respect to a formal context M   O A I  according to the following de\002nition A subset T 022 A respects Y 1  Y 2 if Y 1 6\022 T or Y 2 022 T  It says that Y 1  Y 2 holds in M  M j  Y 1  Y 2  if for all o 2 O  the set f o g 0 respects Y 1  Y 2  In that case it is said that Y 1  Y 2 is an implication of M  De\002nition 2 Let L be a set of implications and L be an implication of M  1 L follows from L  L j  L  if each subset of A respecting L also respects L  2 L is complete if every implication of the context follows from L  3 L is non-redundant if for each L 2 L  L n f L g 6j  L  4 If L is a implication basis for M is complete and non-redundant A well-known method for computing speci\002c implicational basis called Stem Basis SB exists It is implemented into Conexp http://sourceforge.net/projects/conexp software A SB for live beings formal context is provided in Fig 1 It is important to remark that SB is only an example of a basis for a formal context In this paper any speci\002c property of the SB can be used so it can be replaced by any implication basis It is possible to extend j  in relation to any propositional formula with propositional variables in A  by considering each object o 2 M as a valuation v o on A de\002ning v o  A   1   o A  2 I So M j  F if and only if v o j  F for any o 2 O  By de\002ning  A as the proof relation induced by Armstrong rules  R 1  X  X R 2  X  Y X  Z  Y R 3  X  Y Y  Z  W X  Z  W it holds that the implicational bases are  A complete a straightforward consequence of Armstrong's result Theorem 3 Let L be a basis for a formal context M  and L an implication Then M j  L if and only if L  A L  In order to work with formal contexts stem basis and association rules the Conexp has been selected It is used as a library to build the module which provides the implications and association rules to the reasoning module of our system The reasoning module is a production system based on what was designed for Initially it w orks with Stem Basis and entailment is based on the following result Theorem 4 Let L be a basis for the context M and f A 1      A n g  Y 022 A  The following conditions are equivalent 1 S  f A 1     A n g  p Y   p is the entailment with the production system 2 S  A A 1     A n  Y 3 M j  f A 1     A n g  Y  A Association rules for a a formal context We can consider a Stem Basis as an adequate knowledge base for a production system in order to reason However Stem Basis is designed for entailing true implications only without any exceptions in the object set nor implications with a low number of counterexamples in the context Another more important question arises when it works on predictions In this case we are interested in obtaining methods for selecting a result among all obtained results even if they are mutually incoherent Theorem 4 does not provide such a method Therefore it is better to consider association rules with con\002dence instead of true implications Moreover the initial production system must be revised for working with con\002dence Investigations on sound logical reasoning methods with association rules is a relatively recent research line with promising applications In FCA association rules are implications among sets of attributes Con\002dence and support are de\002ned as usual Recall that the support of X  
351 


Figure 2 Model for reasoning based on  9 supp  X  of a set of attributes X is de\002ned as the proportion of objects which satisfy every attribute of X  and the con\002dence of a association rule is conf  X  Y   supp  X  Y  supp  X   Con\002dence can be interpreted as an estimate of the probability P  Y j X   the probability of an object satisfying every attribute of Y under the condition that it also satis\002es every one of X  Conexp software provides association rules and their con\002dence for formal contexts III F ORMAL C ONTEXTS AS KNOWLEDGE STRUCTURES Global memory is composed of events objects which have a number of properties attributes They constitute a global formal context M   O  A  I  which we call monster context following the tradition in Model Theory from which subcontexts are extracted Once the speci\002c subcontext is considered it is also possible to consider background knowledge 001 which would be combined with the KB extracted from formal context Stem basis or association rules De\002nition 5 Let M be a monster context and let O 022 O  1 A context on O is a context M   O 1  A I  where O 022 O 1 022 O  A 022 A and I 022 I  2 A contextual selection on O and M is a map s  O  P  O 1  002 P  A   3 A contextual KB for an object o 2 O w.r.t a selection s with con\002dence 015 is a subset of association rules with con\002dence greater or equal to 015 of the formal context associated to s  o    s 1  o   s 2  o   that is to the context M  s  o    s 1  o   s 2  o   I 026 s 1  o  002 s 2  o   note that when con\002dence is 1 the contextual KB is a implicational basis The reasoning model on M is argumentative where the argument is based on KBs extracted from subcontexts Anagously to the e xistential ar guments are considered but replacing the consistent set by subcontext De\002nition 6 Let L be an implication and 001 a background knowledge It is said that L is a possible consequence of M under the background knowledge 001  M j  001 9 L  if there exists M a nonempty subcontext of M such that M j  001  f L g  Note that by theorem 4 when 001 is a set of implications it holds that j  9 is equivalent to  9 which is de\002ned by M  9 L if there exists M j  001 a subcontext of M such that S  p L where S is a SB for M  In the example described in Sect 4 the reasoning model is based on  p on contextual KBs for an object o 2 O w.r.t a selection given by an expert To compute all consequences by  001 9 implies to consider the entire model However we only need consequences entailed by a submodel See section IV bellow Given M i   O i  A i  I i   i  1  2 two subcontexts of M the intersection of M 1 and M 2  M 1  M 2 is  O 1  O 2  A 1  A 2  I 1   O 1  O 2  002 A 1   I 2   O 1  O 2  002 A 2  In order to study  9 under background knowledge it is necessary to study the relationship among arguments based on distinct contexts Two compatibility notions can be used De\002nition 7 Let M i   O i  A i  I i   i  1  2 be two subcontexts of M  and let 001 be a background propositional knowledge on the language of A 1  A 2  017 It is said that M 1 and M 2 are compatible w.r.t 001 if there exists a supercontext M of M 1 and M 2 such that M j  001  017 It is said that M 1 and M 2 are downward compatible w.r.t 001 if M 1  M 2 j  001  Compatible contexts are also downward compatible Therefore it can jointly extend downward compatible contexts but they can not be restricted with logical reliability Thus formal contexts can be extended in order to re\002ne results It is also possible to work with any context whose objects satisfy background knowledge 001 to obtain  9 consequences Proposition 8 If two contexts are compatible then they are downward compatible Proof Suppose that M 1 and M 2 are compatible Let M be the supercontext for M 1 and M 2  By considering each object o 2 M as a valuation v o on A de\002ned by v o  A   1   o A  2 I the objects in M 1  M 2 are models of 001  Thus M 1  M 2 j  001 The reciprocal is not true Consider the context M   O A I  with O  f o 1  o 2  o 3 g and A  a 1  a 2  a 3 and let I  f  o 1  a 1    o 1  a 3    o 2  a 2    o 3  a 1    o 3  a 3  g  Let M 1 be the subcontext with O 1  f o 1  o 2 g and A 1  f a 1  a 2 g and let M 2 be the subcontext with O 2  f o 2  o 3 g and A 2  a 2  a 3  The intersection M 3  M 1  M 2 has O 3  f o 2 g and A 3  a 1  a 2  a 3 and I 3  f  o 2  a 2  g  Since M 3 j  a 2  we have that M 1 and M 2 are downward compatible w.r.t f a 2 g seen as a propositional formula yet there is no supercontext of M 1 and M 2 satisfying a 2  The inference process for  001 9 has tree steps Fig 2 1 A question on whether a new event object has a property attribute is raised On the new object some properties are known attribute values f A 1     A n g  
352 


Figure 3 Context based reasoning system 2 A contextual selection outputs a subcontext of M  A contextual KB L for some con\002dence threshold is computed for the subcontext Selection made by a user is composed by a small set of attributes 3 The production system is executed on L  f A 1     A n g  The results obtainedare the attributes inferred about the event It has that if A 0 is inferred by the production system then M  001 9 f A 1     A n g  f A 0 g Note that it does not compute all implications only those which are entailed from the attributes selected by the user A Incompatible attributes Implication logics do not suffer from inconsistency issues However in FCA it can be usual to consider incompatible attributes A pair A 1  A 2 of incompatible attributes veri\002es that M j    A 1  A 2   If such a formula is included in background knowledge 001 it is possible to deal with inconsistency issues because  9 is an argumentative entailment which works on subcontexts see def of  9 in Two options have been considered for solving this problem by FCA The 002rst one is based on avoiding inconsistencies using conservative retraction  The aim is to remo v e one attribute from incompatible pairs in contextual KB next to present related attribute proof We have selected a second option to use association rules and do not consider any background knowledge In this way inferred attribute with maximum con\002dence is selected IV E XAMPLE  D ATA ON SOCCER LEAGUE MATCHES We have applied the model for soccer betting The project starts with the hypothesis that past data hides trends of soccer teams that experts use for forecasting The monster model is composed of data past and current on matches the objects with temporal stamp The experiment carries out seven stages see Fig 3 1 Selection of the set of relevant attributes to consider It is made by the user 2 Data extraction  With this data the system is capable of building any subcontext needed In the data time stamps are important because a number of attributes deal with past matches Data has been extracted from the RSSSF Archive http://www.rsssf.com from the past ten years Objects are matches with temporal stamp and attributes are computed for each object The relevant properties attributes that experts selected was 17 several of them are parametrized for example ranking difference above a threshold An attribute with threshold can produce a large number of binary attributes by changing the threshold Thus the explicit computation of M is not feasible It has three distinguished attributes corresponding of T eam 1 wins 1 T eam 2 wins 2 and draws X 3 Selection of a future match  4 Contextual selection  based on the selection of thresholds for attributes 5 Computing of attribute values for the match from data to build the subcontext except obviously the value of distinguished attributes 6 Execution of the System association rules as KB and attributes for the object as facts Several modes for con\002dence computing based on uncertain reasoning techniques by Expert Systems are considered 7 Result a triple  1  c 1    X c x   2  c 2   of pairs attribute con\002dence for the selected match V E XPERIMENTS Two experiments were launched for Spanish soccer league on 2009-10 and 2010-11 seasons Attributes were selected according to authors knowledge about Spanish soccer league which are not experts From this contextual selection  9 was computed for all matches and weeks 2009-10 season Experiments with the system show forecasts of about 58.16 by a contextual selection based on the previous 38 matches Such a percentage of hits for a qualitative reasoning system may be considered as an acceptable result comparable with expectable results of experts Experiments also sho ws an increase in the number of hits by about 7 in the second half of the season The reason is that data from the 002rst half provides more recent information on teams and past matches 2010-11 season A way to evaluate how good is this forecasting sistem is comparing number of successes in our pool with the most popular betting selections This popular selections are collected from the most voted results for each match published at state agency web that controls soccer pools In Fig 4 both results are compared Our hits are in blue and popular ones in green and last seventeen weeks from 2010-11 season are represented Note that Spanish soccer pools are over 15 matches VI C ONCLUDING REMARKS AND F UTURE W ORK The model presented is concerned with association rule reasoning and it does not use in its current formmore sophisticated probability tools se e.g As is stated in the theory of probabilistic mental models assumes 
353 


Figure 4 Correct predictions on the last 17 weeks of the season 2010-11 compared with popular the most popular bets that inferences about unknown states of the world are based on probability cues In some sense as sociation rules s con\002dence plays the role of probability cues in the model The relationship of our proposal with RH roughly speaking if one of the possibilities is recognized and the other is not then infer that the recognized object has the higher value with respect to the criterion is not clear We may assert that our model recognises trends in contexts Trends represented as association rules or implication basis can be considered as a kind of recognizing method though It is worth noting that it only uses  9 because the aim is to simulate bounded reasoning Other entailment relationships from argumentative framework as for example  8  have not been considered in this paper because it requires of an exhaustive exploration of M  Part of our ongoing work includes two research lines The 002rst one is the analysis of conservative retraction method for working with incompatible attributes The second one is to simulate the attribute learning process in our model applying non monotone reasoning techniques A CKNOWLEDGMENTS Supported by TIN2009-09492 project of Spanish Ministry of Science and Innovation and Excellence project TIC-6064 of Junta de Andaluc  021a co\002nanced with FEDER founds R EFERENCES  H A Simon Models of bounded rationality  MIT Press 1982  D G Goldste in and G Gigerenzer  Models of ecological rationality the recognition heuristic Psychological Review  vol 109 no 1 pp 75–90 2002  D Kahneman P  Slo vic and A Tv ersk y  eds Judgment under uncertainty Heuristics and biases  Cambridge University Press 1982  T  P achur and G Biele F orecasting from ignorance the use and usefulness of recognition in lay predictions of sports events Acta Psychologica  vol 125 no 1 pp 99–116 2007  B Ganter and R W ille Formal Concept Analysis Mathematical Foundations  Springer 1999  D G Goldstein and G Gigerenzer  F ast and frug al forecasting International Journal of Forecasting  vol 25 no 4 pp 760–772 2009  J.-L Guigues and V  Duquenne F amilles minimales d'implications informatives resultant d'un tableau de donnees binaires Mathematiques et Sciences Humaines  vol 95 pp 5–18 1986  G A Aranda-Corral J Borre go-D  021az and J Gal  an-P  aez Con\002dence-based reasoning with local temporal formal contexts in IWANN 2  2011 pp 461–468  W  W  Armstrong Dependenc y structures of data base relationships in IFIP Congress  1974 pp 580–583  G A Aranda-Corral and J Borre go-D  021az Reconciling knowledge in social tagging web services in HAIS 2  2010 pp 383–390  J L Balc  azar Redundancy deduction schemes and minimum-size bases for association rules Logical Methods in Computer Science  vol 6 no 2 2010  A Hunter  Reasoning with inconsistenc y in structured te xt  Knowledge Engineering Review  vol 15 pp 200–0 1999  G A Aranda-Corral J Borre go-D  021az and M M Fern  andezLebr  on Conservative retractions of propositional logic theories by means of boolean derivatives Theoretical foundations in Calculemus/MKM  2009 pp 45–58  P  Andersson M Ekman and J Edman F orecasting the f ast and frugal way A study of performance and informationprocessing strategies of experts and non-experts when predicting the world cup 2002 in soccer Stockholm School of Economics Tech Rep 2003:9 May 2003  B Min J Kim C Choe H Eom and R Bobmckay   A compound framework for sports results prediction A football case study Knowledge-Based Systems  vol 21 no 7 pp 551–562 2008  G Gigerenzer and D G Goldstein Reasoning the f ast and frugal way models of bounded rationality Psychological Review  vol 103 no 4 pp 650–669 1996  E Brunswik Representati v e design and probabilistic theory in a functional psychology Psychological Review  vol 62 no 3 pp 193–217 1955 
354 


optimised to contain the largest possible number of registers which, consequently, results in a lower number of partitions and also a lower number of accesses to the disc Compared to the GFP-growth, the MR-Radix-Partition and MR-Radix algorithms stand out, principally with the optimised use of the memory. With the execution time comparative tests, it was noted that the GFP-growth had a slightly superior performance, though memory usage was high when compared to the algorithm proposed in this work The proposed algorithm produced results that allied low execution time to a better use of the memory V  C ONCLUSION  The MR-Radix algorithm had a superior performance with execution time and used memory when compared to other multi-relational proposals. Inclusion of the database partitioning strategy in that algorithm made it possible to prospect data from large repositories, such as CENSUS, in which the principal memory space needed to process the data was higher than the space available in the equipment. Results show that, for low support values, only this approach was able to extract knowledge from that repository. That being so, this work presents a significant and original contribution as the proposed algorithm was able to overcome the available memory space problem and do the mining of multirelational data from large data repositories A CKNOWLEDGMENT  Project financed by the CAPES  Figure 5  Utilised memory … BT repository  Figure 6  Execution time … CENSUS repository  Figure 7  Utilised memory … CENSUS repository R EFERENCES  1  A. J. Knobbe. Multi-Relational Data MiningŽ. Thesis Ph.D.\.The Netherlands, pp. 130, 2004 2  S. Dzeroski, L. D. Raedt and S. Wrobel. Multi-Relational Data MiningŽ: Workshop Report. ACM SIGKDD 2003 Explorations Newsletter, vol. 5, n. 2, December 2003, pp.200202 3  P. Domingos. Prospects and challenges for multi-relational data miningŽ. ACM SIGKDD Explorations Newsletter, vol. 5 n. 1, July. 2003 4  A. Pietracaprina and D. Zandolin. Mining frequent itemsets using patricia triesŽ. Proc. IEEE ICDM Workshop Frequent Itemset Mining Implementations, vol. 80. Citeseer, 2003 5  L. C. Pizzi. Data mining in multiple tables: GFP-Growth algorithmŽ. Thesis \(Masters\deral University of São Carlos, 2006, pp. 106 [in Portuguese   6  J. Pei, J. Han, H. Lu, S. Nishio, S. Tang and D. Yang. Hmine: hyper-structure mining of frequent patterns in large databasesŽ. Proc. IEEE International Conference on Data Mining. IEEE Computer Society, 2001, pp.441-448 7  J. Liu, Y. Pan, K. Wang and J. Han. Mining frequent item sets by opportunistic projection.Ž. Proc. Eighth ACM SIGKDD international conference on Knowledge discovery and data mining - KDD '02. New York, USA: ACM Press 2002, pp. 229 8  L. Dehaspe and L. De Raedt. Mining association rules in multiple relationsŽ. Proc. 7th Intl. Workshop on Inductive Logic Programming, Prague, Czech Republic, 1997, pp.125132 9  R. Agrawal and R. Srikant. Fast Algorithms for Mining Association Rules in Large DatabasesŽ. Proc. 20th International Conference on Very Large Data Bases September 1994, pp.487-499   S. Nijssen and J. Kok. Faster association rules for multiple relationsŽ. International Joint Conference on Artificial Intelligence, vol. 17. Citeseer, 2001, pp. 891…896   M. X. Ribeiro, M. T. P. Vieira and A. J. M. Traina. Mining Association Rules Using ClusteringŽ. I workshop on algorithms for data mining. Uberlândia, Brazil, 2005 , pp. 916 [in Portuguese     F. T. Oyama. Extraction of knowledge in databases using multi-relational clustering tuplesŽ. Monograph Undergraduate\São Paulo State University, 2006, pp. 51 [in Portuguese     K. Wang, L. Tang, J. Han and J. Liu. Top Down FP-Growth for Association Rule MiningŽ. Lecture notes in computer science. Springer, 2002, pp.334…340   
274 
274 


Jr.u T  u .' ,- JIT. v j . .Al.Low Al H igh connection - ? :i:ld:e connection Low connection T:TineDe.lay N ,Tetalnum beref attnbutes o ,JudgementNode ,Proressng Node Current Consequent Fig. 3. Basic structure of class association rule mining using Generalized GNP A route with the fixed number of n attributes\(user-defined starting from the processing node is used as the possible an tecedent parts, and it is combined with the current consequent class to generate the candidate rules All the items of the consequent part are placed in Conse quent Table\(CT  individuals are evolved to extract the class association rules for each class of the attributes, respectively, i.e., for each traffic volume level of each section of the road networks, and this procedure is repeated for all the consequent items When extracting the rules, the basic procedure is like the following: firstly, the processing node randomly moves to the connecting another judgement node from the current judge ment node one after another. Then, a candidate rule of length neuser-defined candidate rule will be checked according to the database The basic checking process is shown in Fig.4, it starts from database tuple 0000, check whether attribute Ai is Middle at 0000 and whether attribute A2 is Low at 0002, . . .  , likewise if the condition is satisfied, increase the corresponding count otherwise, start the same checking process from the next time point 0001 checking whether attribute Ai is Middle at 0001 and whether attribute A2 is Low at 0003, . . .  , likewise, and get the final counts after studying all the records of the database which is the one turn of checking for the candidate rules In Fig.4, N is the total number of the searches, and a, band 2251 c are the number of searches moving to AI\(Mid Low and A3\(Mid the count c corresponds to the count for the whole candidate 


rule, the count a and b can be used for the sub candidate rules The measurements of candidate rules are calculated by these numbers After one turn of the database searching, the support confidence and chi-squared value can be calculated for the candidate rules and sub candidate rules. If the criteria are higher than their thresholds, then the time transitions and its sub time transitions become association rules and will be stored in a rule pool during the generations r 0000 0001 0002 0003 0004 0005 0006 0007 Ml M\\ -:1!"1 _   ,Low __ ,M Idle b &/c H:gh AJ CurrentConseguent T= 2  T= 2 A c Middle   I H L M L M L L L M lMj  HI M L L r-- L ""'\(M1. H M \\LJ. L ......... M M M M --CM H H L C Fig. 4. Two dimensional searching method 


D. Extraction of Rules Using the counts obtained by searching mechanisms, the support, confidence and chi-squared value can be calculated considering both the antecedent and consequent part of the candidate rules. Now, the important association rules are defined as the ones which satisfy the minimum chi-squared support and confidence value, i.e., X;'in' sUPmin and con!min respectively. Only the important association rules can be con sidered as interesting and stored in the rule pool The rules which contain more than Nthre kinds of attributes are the so called mUltiple rules, where Nthre is a user defined threshold. This is added to increase the diversity of the evolution process and the proposed method regards the rules containing many different kinds of attributes as important ones in addition to the conventional interests The interesting rules will not only be stored in the rule pool together but also be validated according to a different database, which is the validating database. As a result, both the conventional criteria of the association rules and the validation accuracy rates will be considered in the rule extraction phase thus the evolution concentrates on extracting more general rules which adapt to real-time traffic databases and avoid the over-fitting to training database during the evolution process For each interesting rule r, the validation accuracy is defined as follows where Da\(r tecedent part of rule r D\(r After the validation of the interesting rules generated by a GNP individual, their validation accuracies will be taken into the fitness value, hence can guide the evolution to generate GNP individuals which can extract more general rules adapt able to real-time databases Therefore, the fitness function of the GNP individual is now defined as F = L {x2\(r r nante\(r rER anew\(r r The symbols are as follows R : set of suffixes of important associatIOn rules which satisfy the importance requirements of chi-squared 


support and confidence value X2 \(r nante \(r rule r anew \(r r ule r is new anew = 0, otherwise amult \(r amult, if rule r has more than amult\(r 0, otherwise x2\(r r r r r cerned with the importance, accuracy, complexity, novelty and diversity of rule r, respectively From the fitness function, it can be seen that GNP indi viduals are defined as a tool to pick up candidate rules, and the proposed method does not aim at obtaining the optimal individuals, but extracting rules as many as possible. So, the individuals which can obtain many new rules with multiple attributes will have high fitness values In each generation, GNP individuals are replaced with the new ones by the selection policy and other genetic opera tions. Four kinds of genetic operators are used, i.e., uniform crossover, mutation for functions, mutation for connections and time delays of judgement nodes, respectively Classification Firstly, classify the extracted association rules in the pool into consequent classes. Every attribute has three consequent classes, i.e., attribute Ai is classified into the following conse quent classes, Ai\(Low Mid High Then, the association rules in each class are used to study whether the testing data satisfy the antecedent items. The testing data are called satisfied if they satisfy the antecedent items of the rules 2252 Unlike the validation process, the following partial match ing strategy is carried out for calculating the matching of rule r and testing data where Nk\(d, r in the antecedent part of rule r in class k 


Nk\(r r in class k The ratio of the number of satisfied rules to the total number of rules for every class is calculated considering confidence matching degree and validation accuracy, and the testing data is classified into the class whose ratio is the highest. The concrete process is like the following 1 in class k 2 Creditk = L confidence\(r Mk\(r r rERk where, a is weight of the prediction accuracy 3 Creditk Scorek T l  ota k where, Totalk is the total number of rules in class k that is, the fixed number of Nf in this paper 4 becomes the winner for the consequent attribute Ac, e.g if Ac \(Low into Low IV. S IMULAT ION In this section, the effectiveness and efficiency of the proposed methods are studied by traffic simulations. Unlike other methods in the traffic prediction of recent years, the proposed methods not only aim at predicting the traffic jam on a specific section of the road networks, but also interested in providing the whole traffic prediction for all of the interesting sections on the road networks so that the navigation system can refer to this kind of information for the calculation of the optimal route of the road networks A. Simulator Real-time simulator SOUND/4U, which is a fully customizable macroscopic free-flow traffic simulator aiming at providing efficient traffic control and management of the urban-level large scale traffic network, has been used. The SOUND/4U simulates the real-time traffic volume and trav eling speed of vehicles on the VICS[15] systems based on 


input OD\(Origin/Destination The simulation is carried out using the traffic network of Kurosaki in Kitakyusyu, Japan. As shown in Fig.5, the road model is based on the real traffic network and there are a TABLE J IJ PARAMETER SETTING FOR SIMULATION Items Values Number of sections 7941 N umber of intersections 4243 Number of traffic lights 142 Data collection interval I \(minute Total execution time 2\(hr Number of 00 points 20 Number of 00 pairs 100 Routing algorithm Logit Route Choice Logit parameter 1.0 Fig. 5. Road model used in simulations huge number of sections on the traffic network. The traffic conditions are shown in the Table III The real-time traffic volume of section s, represents as T\( s at the current time point is calculated like T\(s Nr\(s s s Cs x Ls The symbols are as follows Ls: The length of section s Cs: The capacity of section s, e.g., for sections with one lane Cs = 1, for sections with two lanes section Cs = 2 likewise Nr\(s the last time point Nin \(s sections at the current time point Nout\(s sections at the current time point After the calculation of real-time traffic volume T\( s each section, Nin\(user-defined chosen as the interesting section, here in the simulation Nin = 500 sections with heavier traffic volumes were selected and their corresponding traffic volume at every time point were discretized to LowlMiddle/High 2253 


Judging by common sense, the High threshold is defined as follows: for sections with one lane , if there exist 2 or more cars in 10 meters, then it is a High volume situation. On the other hand, the middle threshold is defined as follows: for sections with one lane, if there exist more than 1, and less than 2 cars in 10 meters, it is a Middle volume situation. The remains will be discretized to Low traffic volume situation The cars are randomly generated based on the values of the pre-defined OD\(OringinJDestination for every OD pair is changing during the execution as shown in Fig.6 lY l Jl .? 15 co ? 10 Xl 5 Q O .r:: 0 o 50 100  150 T:in e 4n ilutes Fig. 6. Change of OriginiDestination values in simulations B. Simulation Result The parameter setting of the proposed data mining during the evolution is shown in Table IV. The total number of rules stored in the rule pool is shown in Fig.7. Each round has the same number of generations of 50 and the chosen set size for AAM is 100[14 TABLE IV PARAMETER SETTING FOR EVOLUTION Items Values Number of judgment nodes 100 Number of processing nodes 10 N umber of attributes 500 Number of consequents 1500 Number of time points 120 Minimum confidence value 0.9 Minimum chi-squared value 6.63 Minimum support value 0.05 40000 Ul 35000 !Il " 30000 '" .... "0 25000 20000 ? '" 15000 j9 10000 0 5000 E 


r r  r r l o 100 200 300 400 500 ROlU1ds Fig. 7. Total number of rules extracted In order to check the effectiveness of the extracted rules we tested the classification accuracy of the proposed method using the classifier with competition The average prediction accuracy is shown in Table V. The accuracy is defined in the following: if the traffic prediction result of the section at time t is "Low" and the real traffic of this section at time t is exactly "Low", then the accuracy is 100%. The low/middle/high accuracy means the accuracy when the real traffic is low/middle/high, respectively Table V shows that the method with Accuracy Validation can improve the overall accuracy than the method without Accuracy Validation. The Middle volume of the traffic network can not be predicted accurately because the middle situations do not appear frequently enough to generate an enough number of association rules TABLE V AVERAGE PREDICTION ACCURACY FOR TESTING DATABASE Method Prediction Accuracy Overall Low Middle High With Accuracy Validation 84.82 85.84 57.71 89.71 Without Accuracy Validation 82.64 83.57 56.57 87.13 Longer step prediction is explored by studying the 2-step, 3step and 4-step prediction, where n-step means the prediction of the traffic volume at n time points later. It's results are shown in Fig. 8. It is shown from Fig.8 that the prediction accuracy decreases as the number of prediction step increases but the increase of the number of steps does not affect the overall accuracy so much, so the proposed method can do relative stable prediction even if the number of prediction steps Increases The ratio of the usable rules to the total number of rules in each prediction step is shown in Fig.9, which describes that 


how the number of the usable rules for prediction decreases by the increase of the prediction steps, considering the condition that the time delay between the antecedent part and consequent part should be bigger or equal to the prediction step. In another word, as the prediction step increases, the number of the usable rules decreases 86 if G 84 82 80 f-------?-""":__---------1 0:: 78 r-------------">.-======---1 :? 76 -------------------j 74 72 4 n-6tep I?w ihAcCUlacyValiiarnn -w ihoutAcCUlacyValiiarnn I Fig. 8. Overall accuracy for 2-step, 3-step and 4-step prediction The proposed method cannot extract all the rules meeting the given definition of importance since it uses the fixed 2254 120 II 100 80 "'<Ie o 60 ?? ? 0: 40 20 0 N Step Fig. 9. Average percentage of usable rules for each prediction step number of rules for each class of the consequent attributes but the result shows that the ability to extract important rules is sufficient enough for the purposes. The mechanism of Accuracy Validation shows more stable performances as shown in Fig. 8 V. CONCLUSION In this paper, an association rule mining method using GNP with Accuracy Validation mechanism has been proposed. It is clarified from simulations that the proposed method can extract important time-related association rules for each class of the consequent attributes efficiently. What's more important is that these rules can be used to decide to which class the time related data belong accurately. From simulations, we have also 


found that the proposed method can be used in traffic volume prediction problems. Further improvements of the proposed method is studied in terms of applying the proposed method to real world navigation systems REFERENCES I Vehicle Routing and Congestion Predictions for Real-time Driver Guid ance, Transportation Research Records, 1408, Transportation Research Board, Washington D.C., pp. 66-74, 1993 2 October 17, 1989 3 network predictions, In Proc. of the Conference of Canadian Society of Civil Engineers, Sherbrooke, Quebec, June, pp. 331-339, 1997 4 dynamic traffic networks with joint route and departure time choice. In Proc. of the 84th Annual Meeting of the Transportation Research Board Washington, DC., 2005 5 Springer, 2002 6 Related Sequential Association Rule Mining and Traffic Prediction", In Proc. of the IEEE Congress on Evolutionary Computation 2009, 2009/5 7 gorithm: Genetic Network Programming\(GNP Reinforcement Learning", Evolutionary Computation, MIT press, Vol. IS No.3, pp.369-398, 2007 8 Multiagent Models Based on Symbiosis", IEEE Trans. on Syst., Man and Cybernetics - Part B -, Vol.36, No.1, pp.179-193, 2006 9 Deck Elevator Group Supervisory Control System Using Genetic Network Programming, IEEE Trans. on Systems, Man and Cybernetics, Part C, Vol 38, No. 4, pp. 535-550, 200817 10 University of Michigan Press, 1975 11] D. E. Goldberg, Genetic Algorithm in search, optimization and machine learning, Addison -Wesley, 1989 12 means of natural selection, Cambridge, Mass., MIT Press, 1992 13 Programs, Cambridge, Mass.: MIT Press, 1994 


14 Association Rules Mining with Attribute Accumulation Mechanism and its Application to Traffic Prediction", Journal of Advanced Computational Intelligence and Intelligent Informatics, Vol. 12, No. 5, pp. 467-478 200817 15 Information and Communication System", Vehicle Navigation and Infor mation Systems Conference, 1993 2255 


intend to expand this work to involve some interesting features in each stage prediction and evaluate it on many datasets   REFERENCES  1] F. Ricardo, N. Ana, M. Paula, B. Gleidson, R. Fabiano ODE: Ontology-based software Development Environment, Proceedings of the IX Argentine Congress on Computer Science, pp. 1124-1135, 2003 2] E. Mendes, B. A. Kitchenham. Further comparison of cross-company and within-company effort estimation models for Web applications. In: Proc. 10th IEEE International Software Metrics Symposium, Chicago USA, pp.348-357, 2004 3] B. Boehm, R. Valerdi. Achievements and Challenges in Software Resource Estimation, Proceedings of ICSE 06 Shanghai, China, pp. 74-83,  2006 4] K. Molokken, M. Jorgensen. A review of software surveys on software effort estimation, Proceedings of International Symposium on Empirical Software Engineering \(ISESE 2003 5] M. Jorgensen, K. Molokken-Ostvold. How large are software cost overruns? A review of the 1994 CHAOS report, Information and Software Technology, Vol. 48 issue 4. PP. 297-301, 2006 6] X. Huanga, D. Hob, J. Rena, L. F. Capretz. Improving the COCOMO model using a neuro-Fuzzy approach Applied Soft Computing, Vol.7, issue 1, pp. 29-40, 2007 7] L. Briand, T. Langley, I. Wieczorek. A replicated assessment and comparison of common software cost modeling techniques, Proceedings of the 22nd international conference on Software Engineering, 2000 8] S.-J Huang, N. H. Chiu. Optimization of analogy weights by genetic algorithm for software effort estimation Information and Software Technology, Vol. 48, issue 11 pp. 1034-1045, 2006 9] Z. Xu, T. M. Khoshgoftaar. Identification of Fuzzy models of software cost estimation, Fuzzy Sets and Systems, Vol. 145, issue 1, pp. 141-163, 2004 10] R. Pressman. Software Engineering: practitioner 


approaches, McGraw Hill, London, 2004 11] M. Boraso, C. Montangero, H. Sedhi. Software cost estimation: an experimental study of model performance Universita di Pisa, Italy, 1996 12] Y. Wang, Q. Song, J. Shen., 2007. Grey Learning Based Software Stage-Effort Estimation. International Conference on Machine Learning and Cybernetics, pp 1470-1475, 2007 13] S. G. MacDonell, M. J. Shepperd. Using prior-phase effort records for re-estimation during software projects Ninth International, Software Metrics Symposium, pp 73- 86, 2003 14] M .C Ohlsson, C. Wohlin. An Empirical Study of Effort Estimation during Project Execution, Sixth International Software Metrics Symposium \(METRICS'99 1999 15] N. H. Chiu,,S. J. Huang.  The adjusted analogy-based software effort estimation based on similarity distances Journal of Systems and Software, Vol. 80, issue 4, pp 628-640, 2007 16] P. Sentas, L. Angelis, I. Stamelos, G.  Bleris. Software productivity and effort prediction with ordinal regression Information and Software Technology, Vol. 47, issue 1 pp. 17-29, 2005 17] E. Mendes, N. Mosley. Comparing effort prediction models for Web design and authoring using boxplots Australian Computer Science Communications,  Vol. 23 Issue 1, pp. 125-133, 2001 18] E. Mendes, N. Mosley, I. Watson. A comparison of casebased reasoning approaches, Proceedings of the 11th international conference on World Wide Web, pp. 272280, 2002 19] Q. Zhao, S. S. Bhowmick. Association Rule Mining: A Survey  http://citeseer.ist.psu.edu/734613.html, 2003 20] S. Morisak, A. Monden, H. Tamada. An Extension of association rule mining for software engineering data repositories, Information Science Technical Report NAIST, 2006 21] Q. Song, M. Shepperd.  M. Cartwright, C. Mair. Software defect association mining and defect correction effort prediction, IEEE transaction on software engineering Vol. 32, No.2, pp. 69-82, 2006 


22] R. Agrawal, T. Amielinski, A. Swami. Mining association rule between sets of items in large databases Proceedings of the ACM SIGMOD International Conference on Management of Data, pp. 207-216, 1993 23] M-J. Huang, Y-L. Tsou, S-C. Lee.  Integrating Fuzzy data mining and Fuzzy artificial neural networks for discovering implicit knowledge, J. Knowledge-Based Systems, Vol.19 \(6 24] ISBSG International Software Benchmarking standards Group, Data repository release 10, Site http://www.isbsg.org, 2007 25] L. Zadeh. Toward a theory of Fuzzy information granulation and its centrality in human reasoning and Fuzzy logic. J. Fuzzy sets and Systems 90, pp. 111-127 1997 26] I. H. Witten, E. Frank. Data Mining: Practical machine learning tools and techniques, 2nd Edition, Morgan Kaufmann, San Francisco, 2005   256 


encountering a related term, i.e. IC\(c e intuition behind the use of the negative likelihood is that the more probable a term to appear, the less information it conveys. All these features show that Jiangs measure tends to be more general and more appropriate for evaluating nontaxonomically related terms. Indeed, a high score of the relatedness measures suggests a strong relationship between terms Nevertheless, all relatedness measures have limitations because they assume that all the semantic content of a particular term is modeled by semantic links in WordNet Consequently, in many situations, truly related terms obtain a low scores even though their belongings to a certain category of tags, e.g., jargon tags Additionally, when measuring the quality of an automatically knowledge acquisition results, the typical measures used in Information Retrieval are Recall, Precision and F-Measure. However, computing Recall and F-Measure requires the availability of a Gold Standard. Hence, we will only compute the Precision which speci?es to which extent the non-taxonomic relationships is extracted correctly. In this case, the ratio between the correctly extracted relations i.e., their relatedness measures is greater than or equal to a minimum threshold, and the whole number of extracted ones is computed. Thus, we have Precision Total correctly selected entities Total selected entities 12 http://search.cpan.org/dist/WordNet-Similarity 13 A term refers to a tag subject or a tag object C. Evaluation of non-taxonomic relationships Only a percentage of the full set of non-taxonomic relationships \(89 is caused by the presence of non standard terms which are not contained in WordNet and, in consequence, cannot be evaluated using WordNet-based relatedness measures. Fig. 5 depicts the evaluation results of the extracted non-taxonomic relationships against their relatedness measures High relatedness score \(88 17% of the extracted relationships, as most of terms are strongly related with respect WordNet Null Scores were obtained for 5% of the extracted 


relationships. Analyzing this case in more detail, we have observed that the poor score is caused in many situations by the way in which Jiangs distance metric works. This latter completely depends on the distance between two terms based on the number of edges found on the path between them in WordNet. In consequence this measure returns a value that does not fully represent reality. For example, on the one hand, Jiangs distance metric returns a null value for the relationship between insurance and car, even though the ?rst is a commonly related to the second, i.e., car involved insurance Finally with a minimal Jiangs distance metric threshold, set to 46%, the computed precision of correctly extracted relationships candidates is equal to 68.8 An example of extracted non-taxonomic relationships is depicted in Table V where each relation describes the subject tag, e.g., tool, the predicate, e.g is being developed within, and the object tag, e.g mesh. Fig. 4 represent a fragment output of the extracted ontological structure where each concept de?nes a set of similar and synonym tags and labels, i.e., mentions has been, revealed, caused and is created with describe the predicates of the non-taxonomic relationships between terms Due to the limitations observed by the automatic evaluation procedure and the lack of gold standards containing non-taxonomic relationships, we have examined the extracted non-taxonomic relationships from a linguistic point 377 Top space      distance     quad great     groovy nifty caused address      addresses extension      quotation   reference  references extensions        referenz     source      refrence sources    rfrences    quotations research    search     searching searchs open-source     open_source 


opensource linux aim     design     designer      designers patern    project     patterns     projekte projects web+design    web_design webdesign internet       internetbs net          web network      networking networks      web discussion     news       password word      words community      communities is_created_with mentions revealed has_been Figure 4. A fragment output of the extracted ontological structure of view. This qualitative evaluation can bring some interesting insights about the kind of results one can expect Invalid relations are extracted: Even though a relation such as music cities skill is considered as correct one since tag subject, tag object and predicate are correctly extracted. From a semantic point of view, this relation has no meaning. Hence, a higher precision is expected Figure 5. Summary of non-taxonomic evaluation measure Table V EXAMPLES OF EXTRACTED NON TAXONOMIC RELATIONSHIPS Subject Predicate Object search has been reference reference mentions search tool is being developed within mesh security added encoding search revealed reference java provides library by performing the sense analysis on complete relations An ambiguity in the extracted predicates between terms is observed: Hence, same relations are redundant since they use a synonym predicates between terms, e.g java provides library and java yields library. Thus we expect that the redundancy removal within extracted relations will be of bene?t for the improvement of the 


obtained results VI. CONCLUSION AND FUTURE WORK The extraction of non-taxonomic relationships from folksonomies is to the best of our knowledge is the least tackled task within ontology building from folksonomy. This is why there is a need of novel and general purpose approaches covering the full process of learning relationships. In this paper, we introduced a new approach called NONTAXFOLKS that starts by pre-processing tags aiming at getting a set of frequent tagsets corresponding to an agreed representation Then, they are used to retrieve related tags using external resources such as WordNet. Thanks to the particular structure of triadic concepts, it allows grouping semantically related tags by considering the semantic relatedness embodied in the different frequencies of co-occurences among users, resources and tags in the folksonomy. Thereafter we introduced an algorithm called NTREXTRACTION for extracting non-taxonomic relationships between pair of tags picked from the triadic concepts. In summary, our approach uses several well known techniques \(such as formal concept analysis or association rule discovering the social bookmaring environnement in order to propose a new way of extracting labeled non-taxonomic relationships between tags. Currently, we are investigating the following topic concerning the discovered predicates between two terms. Indeed, in order to avoid relationships redundancy and thus a redundancy in the builded ontology. One can try to classify them into prede?ned semantic classes, detect synonyms, inverses, etc. A standard classi?cation of verbs could be used for this purpose, adding additional information about the semantic content, e.g., senses, verb types, thematic roles, etc., of predicates relationships 378 REFERENCES 1] J. Pan, S. Taylor, and E. Thomas, Reducing ambiguity in tagging systems with folksonomy search expansion, in Proceedings of the 6th Annual European Semantic Web Conference \(ESWC2009 2] V. S. M. Kavalec, A. Maedche, Discovery of lexical entries for non-taxonomic relations in ontology learning, in Proceedings of the SOFSEM 2004, LNCS, vol. 2932, 2004, pp 249256 


3] L. Specia and E. Motta, Integrating folksonomies with the semantic web, in Proceedings of the 4th European Semantic Web Conference \(ESWC 2007 Innsbruck, Austria, vol. 4519, June 2007, pp. 624639 4] P. Mika, Ontologies are us: A uni?ed model of social networks and semantics, in Proceedings of the 4th International Semantic Web Conference \(ISWC2005 3729, Galway, Ireland, June 2005, pp. 522536 5] P. Schmitz, Inducing ontology from ?ickr tags, in Proceedings of the Workshop on Collaborative Tagging \(WWW 2006 Edinburgh, Scotland, May 2006 6] M. Zhou, S. Bao, X. Wu, and Y. Yu, An unsupervised model for exploring hierarchical semantics from social annotations, in Proceedings of the 6th International Semantic Web Conference and 2nd Asian Semantic Web Conference ISWC/ASWC2007 Korea, vol. 4825, November 2006, pp. 673686 7] C. Schmitz, A. Hotho, R. Jaschke, and G. Stumme, Mining association rules in folksonomies, in Proceedings of the 10th IFCS Conference \(IFCS 2006 2006, pp. 261270 8] A. Hotho, A. Maedche, S. Staab, and V. Zacharias, On knowledgeable unsupervised text mining, in Proceedings of Text Mining Workshop, Physica-Verlag, 2003, pp. 131152 9] A. Hotho, R. Jaschke, C. Schmitz, and G. Stumme, Information retrieval in folksonomies: Search and ranking, in The Semantic Web: Research and Applications, vol. 4011 Springer, 2006, pp. 411426 10] F. Lehmann and R. Wille, A triadic approach to formal concept analysis, in Proceedings of the 3rd International Conference on Conceptual Structures: Applications, Implementation and Theory. Springer-Verlag, 1995, pp. 3243 11] R. Jaschke, A. Hotho, C. Schmitz, B. Ganter, and G.Stumme Discovering shared conceptualizations in folksonomies Web Semantics: Science, Services and Agents on the World Wide Web, vol. 6, pp. 3853, 2008 12] A. Mathes, Folksonomies - cooperative classi?cation and communication through shared metadata, Graduate School of Library and Information Science, University of Illinois Urbana-Champaign, Tech. Rep. LIS590CMC, December 2004 13] H. Lin, J. Davis, and Y. Zhou, An integrated approach 


to extracting ontological structures from folksonomies, in Proceedings of the 6th European Semantic Web Conference ESWC 2009 vol. 5554, 2009, pp. 654668 14] M. Szomszor, H. Alani, K. OHara, and N. Shadbolt, Semantic modelling of user interests based on cross-folksonomy, in Proceedings of the 7th International Semantic Web Conference \(ISWC 2008 15] G.Begelman, P. Keller, and F.Smadja, Automated tag clustering: Improving search and exploration in the tag space, in Proceedings of the the Collaborative Web Tagging Workshop WWW 2006 16] R. Jaschke, A. Hotho, C. Schmitz, B. Ganter, and G. Stumme TRIAS - an algorithm for mining iceberg tri-lattices, in Procedings of the 6th IEEE International Conference on Data Mining, \(ICDM 2006 2006, pp. 907911 17] C. Borgelt, Ef?cient implementation of APRIORI and ECLAT, in FIMI, COEUR Workshop Proceedings, COEURWS.org, vol. 126, 2003 18] J. Tang, H. Leung, Q. Luo, D. Chen, and J. Gong, Towards ontology learning from folksonomies, in Proceedings of the 21st international jont conference on Arti?cal intelligence IJCAI 2009 20892094 19] L. Ding, T. Finin, A. Joshi, R. Pan, R. Cost, Y. Peng P. Reddivari, V. Doshi, and J. Sachs, Swoogle: A search and metadata engine for the semantic web, in Proceedings of the 13th ACM Conference on Information and Knowledge Management, ACM Press, 2004, pp. 652659 20] A. Hliaoutakis, G. Varelas, E. Voutsakis, E. Petrakis, and E. E Milios, Information retrieval by semantic similarity, International Journal on Semantic Web and Information Systems IJSWIS 21] G. Pirro, M. Ruffolo, and D. Talia, Secco: On building semantic links in peer to peer networks, Journal on Data Semantics XII, LNCS 5480, pp. 136, 2009 22] C. Meilicke, H. Stuckenschmidt, and A. Tamilin, Repairing ontology mappings, in Proceedings of the International Conference AAAI 2007, Vancouver, British Columbia, Canada 2007, pp. 14081413 23] S. Ravi and M. Rada, Unsupervised graph-based word sense 


disambiguation using measures of word semantic similarity in Proceedings of the International Conference ICSC 2007 Irvine, California, USA, 2007 24] H. G. A. Budanitsky, Semantic distance in wordnet: an experimental application oriented evaluation of ?ve measures in Proceedings of the International Conference NACCL 2001 Pittsburgh, Pennsylvania, USA, 2007, pp. 2934 25] J. Jiang and D. Conrath, Semantic similarity based on corpus statistics and lexical taxonomy, in Proceedings of the International Conference ROCLING X, 1997 379 


DMITAR Rlt  DMITAR  R esu lt s 2  5 Rules Formed Associative IDS for NextGen Frameworks Dr S Dua LA Tech 28 


DMITAR Rl  Varying Maxspan DMITAR  R esu l ts 3  5 Varying Maxspan Associative IDS for NextGen Frameworks Dr S Dua LA Tech 29 


DMITAR Res lts 4/5 Vig Di i DMITAR  Res u lts  4/5 V ary i n g Di mens i ons Associative IDS for NextGen Frameworks Dr S Dua LA Tech 30 


DMITAR Rl  Varying Number of Transactions DMITAR  R esu l ts 5  5 Varying Number of Transactions Associative IDS for NextGen Frameworks Dr S Dua LA Tech 31 


N/C t Rh N ew C urren t R esearc h Problem Domain Problem Statement and Challenges Associative Mining based IDS Associative Mining based IDS Introduction to data mining ii lid ii Assoc i at i on ru l e i n d ata m i n i ng DMITAR Algorithm  ARD h New Researc h Associative IDS for NextGen Frameworks Dr S Dua LA Tech 32 


Further Research Further Research Objectives of Our Intrusion Detection System Development Objectives of Our Intrusion Detection System Development 1 Refine and scale the DMITAR algorithm to suit our application 2 Develop methods for dynamically altering the sensor parameters Our Focus is Securing the NextGen Frameworks with New Technology Technology Associative IDS for NextGen Frameworks Dr S Dua LA Tech 33 


Simulated Sensing Environment Simulated Sensing Environment Screenshots of Data C ollected from S ynthetic Sensors Screenshots of Data C ollected from S ynthetic Sensors Simulated in Our Laboratory Three Steps Slides Collect data Collect data from all sources  all attributes  Select Select the source and their hierarchical attributes attributes to be monitored and Select Select the source and their hierarchical attributes attributes to be monitored  and Sample Sample them at different rates different rates and process them Associative IDS for NextGen Frameworks Dr S Dua LA Tech 34 


Data Collection Simultaneous collection of data screen from ENTITIES aircrafts Associative IDS for NextGen Frameworks Dr S Dua LA Tech 35 Source PRTG Network Monitor software screen shot Demo info www.paessler.com 


Parameter Selection Selection of an ENTITY/aircraft and monitoring its parameters and sensor readings Associative IDS for NextGen Frameworks Dr S Dua LA Tech 36 Source PRTG Network Monitor software screen shot Demo info www.paessler.com 


Sensor Sampling Selecting one sensor/probe and reading it at different resolutions or sampling rates Associative IDS for NextGen Frameworks Dr S Dua LA Tech 37 Source PRTG Network Monitor software screen shot Demo info www.paessler.com 


Si l ti Nt k Si mu l a ti on on N e t wor k Most scenarios can be simulated on a computer or computer network network  The aircrafts and sensors are simulated on a computer network bllb b y ana l ogica l su b stitutions Sensors provide information at different rates Sensors provide information at different rates Need Based Sensor Prioritization NSP and Dynamic Sensing Rate Sampling Associative IDS for NextGen Frameworks Dr S Dua LA Tech 38 


Vulnerability Search Scan 39 Sample UQA script with Nmap performed in DMRL Associative IDS for NextGen Frameworks Dr S Dua LA Tech 39 Source Nmap screenshot with a pearl script  Find Namp on Nmap.org 


Modality Aspect Modality Aspect A Multimodal distribution is a continuous probability distribution with two or more modes of underlying data Mltil d i M u lti p l e mo d es i n our model Associative IDS for NextGen Frameworks Dr S Dua LA Tech 40 Source http://en.wikipedia.org/wiki/File:Bimodal bivariate small.png 


Multi Modality Modality Fusion 41 SENSITIVE  UNCLASSIFIED For Official Use Only Associative IDS for NextGen Frameworks Dr S Dua LA Tech 41 


Emphasis Emphasis Our approach emphasizes on pre empting the attack Our intent is NOT to perform an autopsy to discover attacks Instead we aim to detect and prevent in attacks in real time Associative IDS for NextGen Frameworks Dr S Dua LA Tech 42 


Techniques for Discriminative Rules Techniques for Discriminative Rules Resolution Analysis Features Analyzed at Different Depths Anti Monotonic Principle Modality Aspect Treading into Unexplored Feature spaces Associative IDS for NextGen Frameworks Dr S Dua LA Tech 43 


Representative Outcomes Representative Outcomes Illustration of the Final Analysis Our method shifts between modalities and sampling rates for optimization The blue parallelograms are actual intrusions 44 The blue parallelograms are actual intrusions The Red Green Blue Plots are response of system Associative IDS for NextGen Frameworks Dr S Dua LA Tech 44 


Advantages of Our M ethod Advantages of Our M ethod Exploit the memory v ertical data format utilizes slidin g windows to g form a much larger database to analyze  Flexibility in Choosing what to choose  Choosing what to choose to build the rules Computational and memory efficiency We have a team working only on this aspect 45 Associative IDS for NextGen Frameworks Dr S Dua LA Tech 45 


Preliminary Results Intra transaction Relations Data rate simulator NH-134 Mb HOP PATH update \(Y/N Inference 11.5 Y Y 2 0.120 N N      Y   n 0.345 N NH134 Y/N   Inf 1 0.150 N N 2 0 120 Y N Inter transaction Relations 2 0  120 Y N       5 5.55 0.456 Y Relations  n 0.345 N N Nmap on DMRL nmap.org 


Anticipated Outcome Anticipated Outcome Develop algorithm capable of learning from a given heterogeneous diverse Develop algorithm capable of learning from a given heterogeneous diverse data ff Dynamic algorithmic f ramework designed to shi f t modalities and sampling rates based on complex logic Flexibility of integration into the Snort intrusion detection system 47 Associative IDS for NextGen Frameworks Dr S Dua LA Tech 47 


References References Aircraft Cockpit Image courtesy USAF http://www.faa.gov htt p   www.faa g ov  air traffic  technolo gy  p g  _ gy  Acharya R Dua S Du X Sree V Chua C K Automated Diagnosis of Glaucoma Using Texture and Higher Order Spectra Features To appear in IEEE Transactions on Information Technology in Biomedicine  Du X Dua S 2011 Cancer Prognosis Using Support Vector Regression in Imaging  Modality World Journal of Clinical Oncology 2  1   44 49 Du X Dua S 2010 Salient Frame Extraction Using Support Vector Regression and Motion Features pp 5 Proc of the National Aerospace and Electronics Conference July 14 16 2010 D M P D S 2010 Di i i ti Ft d Cl ifi ti Mthd f D essaue r  M  P  D ua S  2010  Di scr i m i na ti ve F ea t ures an d Cl ass ifi ca ti on M e th o d s f or Accurate Classification 1st ed vol 7704 pp 14 Bellingham WA Proceedings of SPIE Dessauer M P Dua S 2010 Low Resolution Vehicle Tracking using Dense and Reduced Local Gradient Features Maps 1st ed vol 7694 pp 8 Bellingham WA Proceedings of SPIE SPIE 


Acknowledgements Acknowledgements Fundin g A g encies  US 4 1 Million direct fundin g g g 4 g LA BoR NIH NSF AFRL AFOSR and NASA Research Team Samuel Kasimalla Brandy McKnight Dr Pradeep Chowriappa Connor Johnson Vasanth Nair Mihir Chowriappa  Connor Johnson  Vasanth Nair  Mihir Karnik Mohit Jain and Swadheen Songmen Associative IDS for NextGen Frameworks Dr S Dua LA Tech 49 All the respective Logos belong to their owners 


Rf d Rdi R e f erence d R ea di ngs Copyright of cover pages held by respective publishers 


Thank You Questions Thank You  Questions Dr Sumeet Dua E mail sdua@latech.edu Web http://dmrl.latech.edu Associative IDS for NextGen Frameworks Frameworks Dr S Dua LA Tech 51 Image Source roadtrafficsigns.com 


