Notice of Retraction      After careful and considered review of the content of this paper by a duly constituted expert committee, this paper has been found to be in violation of IEEE's Publication Principles  We hereby retract the content of this pape r. Reasonable effort should be made to remove all past refere nces to this paper  The presenting author of this paper ha s the option to appeal this decision by contacting TPII@ieee.org   


  Teaching Evaluation System Based on Association Rule Mining   Hong Liu Yuanyuan Xia Department of Management Department of Management Liaoning Normal University Liaoning Normal University Dalian, Liaoning Province, China Dalian, Liaoning Province, China Hong321Liu@yeah.net   Abstract - The paper using Association Rule Mining of Data Mining, extracted and analysised the Indicator-score in Teaching Evaluation Data, and found the information of Indicator-score that have high frequency, then analyzed the strengths and 
weaknesses of the teaching, to provide recommendations of improving teaching quality of teachers 
 1  I NTRODUCTION   The traditional Teaching Quality Evaluation System uses the Fuzzy Comprehensive Evaluation \(FCE\method to calculate the scores of the indicators. The FCE method can summary the teaching effectiveness comprehensively and give an evaluation value, that is a common method to assess the overall situation. After assessment, the flood of scoring data 
  Key words-Association rules; 0-1 Matrix; Teaching evaluation 
will be deleted, and the indicators were left as the next assessment indicators. In fact, the Score Data, which has or will be deleted, still have lots of valuable information that is not nutritious mining and use. The indicators, which were left are not reasonable and comprehensive at all. Using association rule techniques of data mining, the data, which to be deleted can be extracted and analyzed the indicators which are redundant and which can be replaced for. If the data which we ignored and discarded can be re-use, not only the design of indicators can become more reasonable, but also the assessment of teaching quality can be designed  more specific and more useful. This can be used as a guide of the teaching evaluation system to improve the teaching quality 
2  O VERVIEW OF A SSOCIATION R ULE M INING  Data Mining is a non-trivial process, which obtain valid novel, porentially useful and ultimately understandable patterns from a large number of data. Agrawal 1 first proposed the mining of association rules between entries in the database of customer transaction, and then many of the researchers do research on the Association Rule Mining 2.1  The process of association rule mining Association rule mining process mainly consists of two 
stages to find all the frequent itemsets associated rules 2.1.1  Find all the frequent itemsets High-frequency refers to the frequency of a item group relative to the frequency of all the records, must reach a certain level. The frequency of occurrence for a item group called the Support. Take 2-itemset, which contains two projects A and B, for example, we can obtained the project team support, by the formula \(1\ which contains {A, B}. If the support is greater than equal to the set minimum support threshold, {A, B} is called frequent itemsets. Meet the minimum support of a k-itemset, named as the Frequent kitemset, algorithm generate high-frequency k +1 from the 
Frequent k-itemset group, until can not found longer high frequent itemset A 
225 B\N A->B N\327100%            \(1 Confidence\(AB\\(A|B\=N A->B N A 327100%       \(2 2.1.2  Generate association rules To generate association rules from the frequent itemset, is the use of frequent k-itemset in the previous step to generate the rules. In the condition of the minimum reliability threshold, if a reliability obtained from a rule meet the minimum reliability, the rule is a association rule. For example, the rule of AB generated through the frequent kitemset{A, B}, its reliability can be obtained by the formula 
2\ if the reliability is greater than equal to the minimum reliability, AB is the association rule 2.2  Apriori Algorithm Apriori algorithm is one of the most influential mining Boolean association rules algorithm for frequent itemsets. The core is based on a two-stage recursive algorithm for Frequent Set thinking. Algorithm is as follows L1=find_frequent_1-itemsets\(D for\(k=2;Lk-1 k  Ck= apriori_gen\(Lk-1,min_sup for each transaction t 
201 D scan D for counts Ct= subset\(Ck,t\et the subsets of t that are candidates for each candidate c 201 Ct 
c.count  Lk ={c 978-1-4577-0856-5/11/$26.00 \2512011 IEEE 
201 Ck|c.count min_sup  return L 201 k Lk In the Apriori algorithm, candidates set is produced layer by layer, while to genarate the frequent set of second layer must scan the entire database, then gather frequent sets to generate the next level of candidate items, until the frequent item sets can not combine to produce the candidate set Therefore, the algorithm has two weak points: the existence of 


  a large number of redundant rules mining; performance slow which caused by too much computing implementation 3  I MPROVED A PRIORI A LGORITHM  3.1 Convert the transaction database to 0-1 matrix Definition: Let the transaction database D, have n transactions T i i = 1,2, ... n\, m items I j j = 1,2, ... m\. First order to generate a n × m matrix A \(D\matrix as follows 1   I j T i  a ij  0    I j T i  Matrix A \(D\e 0-1 matrix 2 corresponding to transaction database D Among them, the support count of single set I j in the transaction database D, is the number of 1 in column j of A D\ while the support count of general item set is the nuber of all 1 row in the corresponding sub-matrix 3.2 Improved Algorithm Calculate the sum of each row in the the 0-1 matrix A ,and the number of items included in all transactions Select the largest number of items k \(may contain more\ alternative sets for the frequent item sets Calculate every support of the alternative sets, if support is less than the minimum support \( minsup\move the set directly from the alternative sets; if the final selected alternative sets is empty, the k minus 1 to until find the frequent item sets Among them calculate the support of itemsets does not use the traditional links, pruning and other steps, but use of matrix calculations directly. Mainly through the new matrix which constituted by the itemsets, until scan the matrix and calculate the number of rows to all 1, that is the support. This methord do not repeat the database scaning, reducing the I / 0 load 4  I MPROVED A PRIORI ALGORITHM IN TEACHING EVALUATION  August 2004 the Ministry of Education promulgated the Undergraduate Teaching Assessment Program \(Trial Assessment Program\, provides for the evaluation of three hierarchical levels, including 7 Overall targets, 19 Secondary indicators and 44 Observation points, as shown in Table 3-1 Table 4-1 Overall targets, Secondary indicators and Observation points Overall targets Secondary indicators Observation points Quantity Percentage  Quantity Percentage  weight distribution Guiding ideology 2 10.5 3 6.8 1.0  0.5  0.5 Faculty 2 10.5 3 13.6 0.3  0.4  0.3 0.3  0.3  0.4 Conditions and the using 2 10.5 7 16.0 0.2  0.2  0.2 0.2  0.2  0.6 0.4 Construction and reform 3 15.8 10 22.7 0.5  0.5  0.3 0.3  0.3  0.1 0.4  0.3  0.2 0.1 Teaching management 2 10.5 5 11.4 0.6  0.4  0.3 0.3  0.4 Style 2 10.5 4 9.1 1.0  0.3  0.3 0.4 Teaching effectiveness 6 31.7 9 20.5 0.7  0.3  0.5 0.5  1.0  1.0 0.6  0.4  1.0 Total 19 100.0 44 100   The Overall targets,Secondary indicators and Observation points teaching evaluation index involved in the "assessment program" to be extracted, according to the own teachers requirements of most university, as indicators of the teaching evaluation system,and valued with the output of fuzzy comprehensive evaluation method Teaching evaluation system of teachers evaluation index established by various colleges and universities, is not identical. But the evaluation method is similar, that is no assign scores to the level of assessment from the evaluation of teachers which is done by students, such as excellent, good, in and poor. After the calculation of the scores, the results of quality assessment of teachers can be got. This traditional Teaching Quality Evaluation System can summary the teaching effectiveness comprehensively and give an evaluation value, that is a common method to assess the overall situation. However, this assessment is calculated by a large number of index scores. Althouge the overall rating of teaching quality can be valued, the strengths and weaknesses of the teacher can not be informed clearly, and thus can not be made for teachers to improve teaching quality. After assessment, the flood of scoring data will be deleted, and the indicators were left as the next assessment indicators. In fact the Score Data, which has or will be deleted, still have lots of valuable information that is not nutritious mining and use. The indicators, which were left, are not reasonable and comprehensive at all Using of association rule mining technology, the student evaluation of teachers of high frequency indicators can be extracted. Table 3-2 is a certain summary of rates scored by 10 students Table 4-2 Summary Rating  Teaching Attitudes No late Supplementary program Excellent Good In Poor Excellent Good In Poor Excellent Good 01       02 03       04 05       06 07       08       09 10 Supplementary program Note students practice Correcting homework In Poor Excellent Good In Poor Excellent Good In Poor   


                                    Numeric attributes will be mapped to Boolean attributes as shown in Table 3-3 Table 4-3 Boolean Table 1 0 0 0 1 0 0 0 0 1 0 0 0 1 0 0 1 0 0 0 0 1 0 0 0 1 0 0 0 1 0 0 0 1 0 0 0 1 0 0 0 0 1 0 1 0 0 0 0 1 0 0 0 1 0 0 0 0 1 0 1 0 0 0 1 0 0 0 1 0 0 0 0 0 1 0 1 0 0 0 1 0 0 0 1 0 0 0 0 0 0 1 1 0 0 0 1 0 0 0 0 1 0 0 0 1 0 0 0 1 0 0 0 1 0 0 0 1 0 0 1 0 0 0 1 0 0 0 0 0 1 0 1 0 0 0 1 0 0 0 1 0 0 0 1 0 0 0 0 1 0 0 0 1 0 0 1 0 0 0 1 0 0 0 0 1 0 0 0 1 0 0 0 1 0 0 0 0 0 1 1 0 0 0 1 0 0 0 1 0 0 0 1 0 0 0 1 0 0 0 The matrix operations as follows  R 0010001000 1000100010 0001000001 1000010001 0001001000 1000100001 1010001000 1000100000 0001000100 0100010001 0110001000 1000100000 0000101000 1000100010 0001000010 0010100001 0001000100 0100010001 0001001000 1000100001     3014404315 3321131351 5233323533 3013405314 2520050230 3013504314 3015303314 3251121321 2520050230 5233323533 T R R T T R is the transpose of R  Clearly T is a symmetric matrix of 10. Get the triangular matrix 3 to observe 5 2 3 3 3 2 3 5 3 3 5 2 0 0 5 0 2 3 0  5 1 1 2 1 3 2 1   5 3 0 3 3 1 4   5 0 4 3 1 4   5 0 2 3 0  5 3 1 4  5 3 3   5 1   5 If the support is set to 60%, and the confidence is set to 80%, then draw the two largest frequent itemsets 4  Teaching Attitudes: excellent, No Late: excellent, Correcting Homework: excellent} and { Supplementary Program: Good Note Students Practice: good }. And three association rules No Late: excellent, Correcting Homework: excellent   Teaching Attitudes: excellent} , { Supplementary Program Good  Note Students Practice: Good}, {Note Students Practice: Good  Supplementary Program: Good Evaluation of this indicator can screen out the highest frequency index evaluation value, that is more scientific and effective, enabling more targeted teacher evaluation. In the above example, there are at least six students in ten in the assessment selected following evaluation: excellent in Teaching Attitude bar, excellent in No Late bar, and excellent in Correcting Homework bar. At least six students in ten in the assessment of teachers also selected following evaluation good in Supplementary Program bar, good in Note Students Practice bar. So the teacher seriously done well in the three indicators,these were Teaching Attitudes, No Late, Correcting Homework. And should pay attention to two indicators , that are Supplementary Program and Note Students Practice. From the association rule Mining, we can found that all the sets that excellent in No Late bar and excellent in Correcting Homework bar, do score excellent in Teaching Attitudes bar This shows the Teaching Attitudes of the evaluation is repetitive and can be removed or changed to other evaluation index Through the analysis of instance evaluation results indicate that the use of association rules in data mining technology on teaching quality assessment in-depth analysis of the data is feasible, and can clearly inform the strengths and weaknesses in teaching, and make recommendations to improve the quality of teaching. Not only dig deep using value of data, but also improve the teaching quality of teachers, and provides an important reference for teaching quality assessment R EFERENCES  1  Agrawal R, Srikant R Fast Algorithm for Mining Association rules  Proceedings of the 20th International Conference on VLDB, Santiago Chile, 1994, pp: 487 ~ 499 2  Jaiwei Han, Michcline Kamber Data Mining: Concepts and Techniques  Beijing: China Machinery Industry Press, 2007, 146 183 3  Zhang Herui,Hao Bingxin Higher Algebra 3 rd ed, Beijing: Higher Education Press, 1993, 112~140 4  Pei Guying, "Algorithm for Association Rule Mining Based on Boolean Matrix Automation and Instrumentation No. 5, 2009 16~18  


Table 3. Fuzzification of transaction data Transaction A B C D E  n Az Ao Ab Bz Bo Bb Cz Co Cb Dz Do Db Ez Eo Eb T1 0.6 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.4 0.0 0.0 0.2 0.0 0.0 T2 0.0 0.2 0.8 1.0 0.0 0.0 0.0 1.0 0.0 0.8 0.0 0.0 0.4 0.0 0.0 T3 0.0 0.6 0.4 0.2 0.8 0.0 0.4 0.6 0.0 1.0 0.0 0.0 0.6 0.0 0.0 T4 0.0 1.0 0.0 0.4 0.6 0.0 0.0 1.0 0.0 0.8 0.2 0.0 0.8 0.0 0.0 T5 0.0 0.4 0.6 0.8 0.0 0.0 0.0 0.8 0.2 0.4 0.6 0.0 0.2 0.8 0.0 Count 0.6 2.2 1.8 2.4 1.4 0.0 0.4 3.4 0.2 3.4 0.8 0.0 2.2 0.8 0.0 Table 7 Modified Fuzzy values Transaction A B C D E n Az Ao Ab Bz Bo Bb Cz Co Cb Dz Do Db Ez Eo Eb T1 0.6 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.4 0.0 0.0 0.2 0.0 0.0 T2 0.0 0.2 0.8 1.0 0.0 0.0 0.0 0.0 0.0 0.8 0.0 0.0 0.4 0.0 0.0 T3 0.0 0.6 0.4 0.2 0.8 0.0 0.4 0.4 0.0 1.0 0.0 0.0 0.6 0.0 0.0 T4 0.0 1.0 0.0 0.4 0.6 0.0 0.0 0.0 0.0 0.8 0.2 0.0 0.8 0.0 0.0 T5 0.0 0.4 0.6 0.8 0.0 0.0 0.0 0.8 0.2 0.4 0.6 0.0 0.2 0.8 0.0 Count 0.6 2.2 1.8 2.4 1.4 0.0 0.4 1.2 0.2 3.4 0.8 0.0 2.2 0.8 0.0 Table 8. Defuzzified table A B C D E T1 3 0 0 2 1 T2 14 5 0 4 2 T3 12 9 8 5 3 T4 10 8 0 6 4 T5 13 4 11 8 9 V EXPERIMENTAL RESULTS Experimental results were taken using Wisconsin Breast Cancer dataset from UCI Machine Learning Repository  T h e dataset con s is ts of on e id attrib u t e, nine quantitative attributes and one categorical    attribute This algorithm was implemented using nine quantitative attributes which are mapped to three fuzzy sets each. Three rules were randomly selected for hiding. Experimental results were taken with membership function given by expert and automatically generated membership function i\ membership function provided by experts Figure 3. Number of rules vs minimum support Fig. 3 shows the number of generated rules and hidden rules for varying values of support with a constant minimum confidence of 50 when quantitative data is fuzzified using membership function values supplied by the experts. As DSR method is used the number of rules hidden for increased values of support is less. In previous work  it changes according to the support value Figure 4. Number of rules vs minimum confidence Fig. 4 shows the number of generated rules and hidden rules for varying values of confidence and a constant minimum support of 50 Figure 5. Rules lost after hiding a set of three rules 152 2011 World Congress on Information and Communication Technologies 


Fig. 5 shows the number of rules lost as a side effect of hiding three rules is less in proposed method than in previous work ii\ Automated Generation of  Membership Function\(AGMF Experimental results in Fig. 6 show the number of generated rules and hidden rules for varying values of support with a constant minimum confidence of 50. Fig. 7 shows the number of generated rules and hidden rules for varying values of confidence with a constant minimum support of 50 when quantitative data is fuzzified using membership function values generated by the proposed algorithm Figure 6. Number of rules under different minimum support Figure 7. Number of rules under different minimum confidence Figure 8. Rules lost after hiding a set of three rules Fig. 8 illustrates that the number of lost rules is less in the proposed approaches, DSR and DSR with autogenerated membership function, when compared to the previous work rth er the DSR  m e t h od decreas es th e  support so that no ghost rules are produced. From the results it is inferred that automatic membership function generation provides consistent rule hiding even in the absence of expertise VI C ONCLUSION In this paper, we proposed a learning method to derive membership functions automatically for numeric data and presented a method for preventing extraction of useful association rules from quantitative data by decreasing the support of the RHS of the rule. Unlike previous approaches which mainly deals with association rules in binary database, our approach deals with hiding the association rules in quantitative database. Experimental results demonstrate that the proposed approach is more efficient as it facilitates better rule hiding and  minimizes the number of lost rules and ghost rules. Also, this approach makes minimum modification of data. To further minimize the side effect and modification to database genetic algorithm can be used REFERENCES 1 T Be rbe rog lu a n d M Ka y a  H iding F u z z y  A s soc ia tion R u le s in Quantitative Data  The 3rd InternationalConference on Grid and Pervasive Computing Workshops, May 2008, pp. 387392 2 M a noj G upta a nd R  C  J o s h i  P r i v a cy P r e s e r v i ng Fuz zy  Association Rules in in Quantitative DataŽ, International Journal of Computer Theory and Engineering, Vol. 1, No. 4 October, 2009, 382-388 3 V a ssilios S V e ry k i os, A  K. E l m a g a r m id, E. Be rtino, Y  Saygin, and E. Dasseni, Association Rule Hiding IEEE Transactions on Knowledge and Data Engineering vol. 16 no. 4, pp. 434-447, 2004  Dr Du raiswa my  K Dr M a n j u l a D an d M a h e swari N A  New Approach to Sensitive Rule HidingŽ, ccsenet journal, vol 1, No. 3, August, 107-111 5 Yuc e l Sa y g in, V a ssilios V e ry k i os, a nd Chris Clif ton  Using Unknowns to Prevent Discovery of Association Rules  SIGMOD Record 30 \(2001\, no. 4, 45…54 6 Y uho ng G uo, 200 7 R e c ons tr uc tionB a s e d A s s o c i a tion R u le  HidingŽ, Proceedings of SIGMOD2007 Ph.D. Workshop on Innovative Database Research 2007\(IDAR2007\51-56 7 C hris C lif ton a nd Mura t K a nta rc iog lu a nd J a ide e p Va idy a   Defining Privacy for Data Mining," in Proceedings of the National Science Foundation Workshop on Next Generation Data Mining, November 1-3, 2002, Baltimore, MD 8 Chih-C hia W e ng e t e t  A Nove l A l g o rithm  f o r Co m p le te l y  Hiding Sensitive Frequent ItemsetŽ , Dept. of Information Science, Chung Cheng Institute of Technology, National Defense University , 2007  C h i h C h ia W e n g  S h an T ai Ch en  Hun g-Ch e L o  A  No vel  Algorithm for Completely Hiding Sensitive Association RulesŽ , Eighth International Conference on Intelligent Systems Design and Applications, 2008 10 C a no, J  a nd P  N a v a A Fuzzy Me thod f o r  A u tom a tic Generation Of Membership Function Using Fuzzy Relations from Training Examples  Proceedings of the 21st NAFIPS International Conference, pp. 158-162, June 2002 11 T  P  H ong  C  Y  L e e   I nduc tion of f u z z y r u le s a nd membership functions from training examplesŽ, Fuzzy Sets and Systems - FSS , vol. 84, no. 1, pp. 33-47, 1996 12 T  P  H o n g  C  S  K u o  S  C  C h i   M i n i n g a s s o c i a t i o n r u l e s  from quantitative dataŽ, Intell. Data Anal. 3 \(5\3 376, 1999 13 L  A  Za de h F uz z y Se ts  Inf o r m a tion a n d Co ntrol V o l 8  pp.338-353, 1965 14 http://mlearn.ics.uci.edu/databases/breast-cancer wisconsin/breast-cancer-wisconsin.data 2011 World Congress on Information and Communication Technologies 153 


187 


188 


189 


190 


               


Table V gives the set of intervals in which the variations are not significant. These intervals are computed based on the risk RSA 1.65;+1.65] 10 1.96;+1.96] 5 2.58;+2.58] 1 3.29;+3.29] 0.1 TABLE V INTERVALS IN WHICH NON-SIGNIFICANCE IS DETECTED When the RSA is applied to the association education ? wage results listed in table VI education wage [6;7] [8;9] [10;13] [14;18 2.85; 4.70] 1.83 1.69 3.88 -4.94 4.75; 7.14] 0.41 0.76 1.37 -1.88 7.30; 12.67] -0.72 -0.62 0.17 0.59 13.00; 26.29] -0.99 -1.49 -6.35 6.56 TABLE VI ADJUSTED STANDARDIZED RESIDUAL OF THE ASSOCIATION EDUCATION-WAGE The negative values denote underrepresentativeness, and the positive ones overrepresentativeness We can now transpose these results to initial variations contingency, table III Table VII represents the enhanced variations contingency. In order to notice the differences, all grayed cells are pruned thanks to the RSA education wage [6;7] [8;9] [10;13] [14;18 2.85; 4.70] 3 4 15 -22 4.75; 7.14] 1 3 8 -12 7.30; 12.67] -2 -3 1 5 13.00; 26.29] -1 -4 -25 30 TABLE VII ENHANCED CONTINGENCY TABLE OF VARIATIONS FOR THE ASSOCIATION \(EDUCATION-WAGE This table is the starting point of the consolidation process described below 39 


V. CONSOLIDATION PROCESS The first step to build the largest zones is to scan the enhanced contingency table of variations looking for the cell with the highest absolute value This cell constitutes the first rectangle noted R1 with the coordinates of upper left point pl and lower right point pr The second scan compares all the values in the immediate neighborhood of R1. The expansion is performed in descending fashion, i.e. starting from the largest value with similar behavior of the constituted rectangle expanded to the new coordinates The expansion of the formed rectangle continues by performing the summation of its vicinity cells values. We start by including cells whose values sum is the largest. The expansion stops once meeting null cells and the consolidation process ends when all maximal rectangles are formed. These results allow restricting the number of records to be processed by only keeping those retained after the consolidation phase When applying this process to the enhanced contingency table of variations resulting from the education-wage only would be considered the records included in the clusters "education=[10;13]" or "education=[14;18]" associated to "wage=[2.85;4.70]" or wage=[13;26.29 Notice, in the case of the association education ? wage process enables to focus on 172 records instead of 526 \(32 VI. CONCLUSIONS In this paper, we describe our discretization approach focusing on the potential interactions between a databases variables. This approach makes it possible to carry out a contextual discretization maximizing the informativeness and highlighting the variables dependencies The use of a tabular representation is particularly interesting in the case of numeric variables 


where knowledge is synthetically summarized. The formed attractive and repulsive zones, based on human considerations and statistics, guarantee that potentially interesting knowledge will be discovered with decreasing by the way the search space REFERENCES 1] J. Ben-Zvi, The time relational model, Ph.D., University of California, Los Angeles, 1982 2] A. Agresti,Categorical Data Analysis, New York: Wiley pp. 224, 1990 3] J.R. Quinlan,C4.5: Programs for Machine Learning, Morgan Kaufmann. San Mateo, Calif.,1993 4] T. J. Archdeacon,Correlation and Regression Analysis: A Historians Guide,pp. 352,Univ of Wisconsin Press,1994 5] J. Dougherty, R. Kohavi, M. Sahami, Supervised and unsupervised discretization of continuous features, In Proceedings of the 12th International Conference on Machine Learning, 1995, pp. 194-202 6] P.M. Murphy and D.W. Aha, UCI Repository of Machine Learning Databases,Machine-readable collection, Dept of Information and Computer Science, Irvine, 1995 7] F. Hussain, H. Liu, Ch.L. Tan, M. Dash, Discretization An Enabling Technique, Technical Report ?U School of Computing, Singapore, 1999, June 8] Y. Aumann and Y. Lindell, A Statistical Theory for Quantitative Association Rules, Knowledge Discovery and Data Mining, pp. 261-270, 1999 9] S. Bay, Multivariate discretization of continuous variables for set mining, In Proceedings of the 6th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, 2000, pp. 315 ?U319 10] G. Bisson and C. Nedellec, Aide  la conception de mthodes de classification pour la construction dontologies latelier MoK, 1res journes francophones Extraction et Gestion des Connaissances \(EGC01 19 janvier, 213-225, 2001 11] S. Guillaume, Discovery of Ordinal Association Rules PAKDD, pp. 322-327, 2002 12] S. Kotsiantis and D. Kanellopoulos, Discretization Techniques: A recent survey, GESTS International Transactions on Computer Science and Engineering, Vol.32 \(1 58, 2006 


13] S. Guillaume and L. Nemmiche Alachaher, Visualisation des zones dattraction entre les variables, 15me RFIA Tours, France, 2006 40 


Proceedings of Supercomputing 96, Pittsburg, PA, pp. 17-22 November 1996 9] Ceglar and J. Roddick, Association Mining, ACM Computing Surveys, Vol. 38, No. 2, pp. 1-42, July 2006 10] Y. Ye and C.-C. Chiang, A parallel apriori algorithm for frequent itemsets mining, Proceedings of the Fourth International Conference on Software Engineering Research, Management, and Applications SERA 06 11] J. JaJa, An Introduction to Parallel Algorithms, Upper Saddle River NJ: Addison Wesley, 1996  214 


12] Dhond, Gupta, A., Vadhavkar, S. Data mining techniques for optimizing inventories for electronic commerce[C]. In the Proceeding of the ACM-SIGKDD International Conference on Knowledge Discovery and Data Mining, 2005:480-486 13]Chui-Yu Chiu , Yi-Feng Chen. An intelligent market segmentation system using k-means and particle swarm optimization[J]. Expert Systems with Applications, 2009, 36: 45584565 14]Tzung-Shi Chen , Shih-Chun Hsu. Mining frequent tree-like patterns in large datasets[J]. Data & Knowledge Engineering, 2007,62:6583 15]H. Tsukimoto, Extracting rules from trained neural networks[J]. IEEE Trans.Neural Networks, 2000, 11 \(2 156 


http://datamining.buaa.edu.cn/TopKCos.pdf 14] M. Zaki, Scalable algorithms for association mining, TKDE, vol. 12, pp. 372390, 2000 


enhance item-based collaborative filtering, in 2nd IASTED International Conference on Information and Knowledge Sharing, Scottsdale, Arizona, 2003 476 2010 10th International Conference on Intelligent Systems Design and Applications 


Basi Association Rles Basi c  Association R u les Association is basically connecting or tying up occurrences of Association is basically connecting or tying up occurrences of events Ol dib t f ilt t O n l y d escr ib e se t s o f s i mu lt aneous even t s Cannot describe patterns that iterate over time e g  itemset a  0  b  0  g    Eg If you sense higher data rates on the downlink than normal AND New Route generated Implies high chances of Intrusion AND New Route generated Implies high chances of Intrusion Associative IDS for NextGen Frameworks Dr S Dua LA Tech 20 


Enhanced Inte r transaction Association Rules Enhanced Inter transaction Association Rules Enhanced Inter transaction Association Rules Extension of association rules Conditional relationships at multiple different time steps e.g itemset a\(0 0 1 2 You sense Higher data rate than normal AND You see New Route g enerated AND 1 minute a g o you detected checksum gg error packets AND 2 minutes ago your encountered wrong checksum   Implies High Chance of Intrusion Enhanced Rules and Confidence Associative IDS for NextGen Frameworks Dr S Dua LA Tech 21 


Complex Spatio temporal Association Complex Spatio temporal Association Rules Further extension of inter transaction association rules Describe event durations e.g itemset a\(0,X j,Y k,Z Eg  You sense high data rates for X seconds AND new route generated j minutes ago task completed in Y AND new route generated j minutes ago task completed in Y seconds AND checksum error packets received k minutes ago for Z seconds High Chance of Intrusion With highest confidence level in association rules  association rules  Associative IDS for NextGen Frameworks Dr S Dua LA Tech 22 


DMITAR Al ith ARD DMITAR Al gor ith m  ARD Problem Domain Problem Statement and Challenges Aiti Miig bd IDS A ssoc i a ti ve Mi n i n g b ase d IDS  Introduction to data mining Association rule in data mining DMITAR Algorithm  ARD New research Associative IDS for NextGen Frameworks Dr S Dua LA Tech 23 


DMITAR Algorithm DMITAR Difference Matrix Based Inter Transaction Association Rule Miner developed in DMRL Uses vertical data format Differences of the transaction IDs are used to generate extended itemsets Windowless mechanism Associative IDS for NextGen Frameworks Dr S Dua LA Tech 24 


Deep into the Mechanism The DMITAR algorithm is based on lhilii comp l ex mat h emat i ca l assoc i at i ve formulation and proofs Four major parts Four major parts Frequent 1 itemset generation Frequent 2 itemset generation Frequent k itemset generation k>2 Spatio temporal rule formation Associative IDS for NextGen Frameworks Dr S Dua LA Tech 25 


DMITAR, Datasets Used Stock Data Stock Data Daily stock information provided by Yahoo finance Wth Dt W ea th er D a t a Provided by the US Department of Commerce and National Climactic Data Center for 700 locations across US Synthetic Data Provided by a CRU weather generator that uses a Markov chain model to generate simulated weather data for 11 UK sites Associative IDS for NextGen Frameworks Dr S Dua LA Tech 26 


DMITAR Results 1/5 Varying Support DMITAR Results 1/5 Stock Database Support FITI ITPMine PROWL DMITAR 14 6424.7s 132.39s 3.03s 5.556s 16 2348.9s 67.14s 2.14s 4.015s 18 861.92s 34.62s 1.55s 2.89s 20 334.51s 18.89s 1.12s 2.07s 22 143 84s 10 87s 0 87s 1 45s 22 143  84s 10  87s 0  87s 1  45s 24 63.62s 7.15s 0.671s 1.04s Weather Database Support FITI ITPMine PROWL DMITAR 14 36362.6s 893.1094s 5.843s 19.8281s 36362.6s 893.1094s 5.843s 19.8281s 16 11913.04s 378.2188s 3.8906s 13.4375s 18 4116s 170.3438s 2.75s 9.1406s 20 1507s 86.5781s 2.14s 6.203s 22 859.2813s 63.3438s 1.7969s 5.7656s 24 378.5313s 36.1875s 1.4375s 3.5625s Synthetic Dataset Support FITI ITPMine PROWL DMITAR 14 1651.6s 199.843s 3.1406s 17.015s 16 574 32 119 32 2 0938 10 875 16 574  32 s 119  32 s 2  0938 s 10  875 s 18 416.109s 95.31s 1.6094s 7.39s 20 370.25s 83.31s 1.453s 5.8438s 22 265.78s 66.3438s 1.3594s 4.75s 24 133.96s 43.0781s 0.9219s 3.5781s 


DMITAR Rlt  DMITAR  R esu lt s 2  5 Rules Formed Associative IDS for NextGen Frameworks Dr S Dua LA Tech 28 


DMITAR Rl  Varying Maxspan DMITAR  R esu l ts 3  5 Varying Maxspan Associative IDS for NextGen Frameworks Dr S Dua LA Tech 29 


DMITAR Res lts 4/5 Vig Di i DMITAR  Res u lts  4/5 V ary i n g Di mens i ons Associative IDS for NextGen Frameworks Dr S Dua LA Tech 30 


DMITAR Rl  Varying Number of Transactions DMITAR  R esu l ts 5  5 Varying Number of Transactions Associative IDS for NextGen Frameworks Dr S Dua LA Tech 31 


N/C t Rh N ew C urren t R esearc h Problem Domain Problem Statement and Challenges Associative Mining based IDS Associative Mining based IDS Introduction to data mining ii lid ii Assoc i at i on ru l e i n d ata m i n i ng DMITAR Algorithm  ARD h New Researc h Associative IDS for NextGen Frameworks Dr S Dua LA Tech 32 


Further Research Further Research Objectives of Our Intrusion Detection System Development Objectives of Our Intrusion Detection System Development 1 Refine and scale the DMITAR algorithm to suit our application 2 Develop methods for dynamically altering the sensor parameters Our Focus is Securing the NextGen Frameworks with New Technology Technology Associative IDS for NextGen Frameworks Dr S Dua LA Tech 33 


Simulated Sensing Environment Simulated Sensing Environment Screenshots of Data C ollected from S ynthetic Sensors Screenshots of Data C ollected from S ynthetic Sensors Simulated in Our Laboratory Three Steps Slides Collect data Collect data from all sources  all attributes  Select Select the source and their hierarchical attributes attributes to be monitored and Select Select the source and their hierarchical attributes attributes to be monitored  and Sample Sample them at different rates different rates and process them Associative IDS for NextGen Frameworks Dr S Dua LA Tech 34 


Data Collection Simultaneous collection of data screen from ENTITIES aircrafts Associative IDS for NextGen Frameworks Dr S Dua LA Tech 35 Source PRTG Network Monitor software screen shot Demo info www.paessler.com 


Parameter Selection Selection of an ENTITY/aircraft and monitoring its parameters and sensor readings Associative IDS for NextGen Frameworks Dr S Dua LA Tech 36 Source PRTG Network Monitor software screen shot Demo info www.paessler.com 


Sensor Sampling Selecting one sensor/probe and reading it at different resolutions or sampling rates Associative IDS for NextGen Frameworks Dr S Dua LA Tech 37 Source PRTG Network Monitor software screen shot Demo info www.paessler.com 


Si l ti Nt k Si mu l a ti on on N e t wor k Most scenarios can be simulated on a computer or computer network network  The aircrafts and sensors are simulated on a computer network bllb b y ana l ogica l su b stitutions Sensors provide information at different rates Sensors provide information at different rates Need Based Sensor Prioritization NSP and Dynamic Sensing Rate Sampling Associative IDS for NextGen Frameworks Dr S Dua LA Tech 38 


Vulnerability Search Scan 39 Sample UQA script with Nmap performed in DMRL Associative IDS for NextGen Frameworks Dr S Dua LA Tech 39 Source Nmap screenshot with a pearl script  Find Namp on Nmap.org 


Modality Aspect Modality Aspect A Multimodal distribution is a continuous probability distribution with two or more modes of underlying data Mltil d i M u lti p l e mo d es i n our model Associative IDS for NextGen Frameworks Dr S Dua LA Tech 40 Source http://en.wikipedia.org/wiki/File:Bimodal bivariate small.png 


Multi Modality Modality Fusion 41 SENSITIVE  UNCLASSIFIED For Official Use Only Associative IDS for NextGen Frameworks Dr S Dua LA Tech 41 


Emphasis Emphasis Our approach emphasizes on pre empting the attack Our intent is NOT to perform an autopsy to discover attacks Instead we aim to detect and prevent in attacks in real time Associative IDS for NextGen Frameworks Dr S Dua LA Tech 42 


Techniques for Discriminative Rules Techniques for Discriminative Rules Resolution Analysis Features Analyzed at Different Depths Anti Monotonic Principle Modality Aspect Treading into Unexplored Feature spaces Associative IDS for NextGen Frameworks Dr S Dua LA Tech 43 


Representative Outcomes Representative Outcomes Illustration of the Final Analysis Our method shifts between modalities and sampling rates for optimization The blue parallelograms are actual intrusions 44 The blue parallelograms are actual intrusions The Red Green Blue Plots are response of system Associative IDS for NextGen Frameworks Dr S Dua LA Tech 44 


Advantages of Our M ethod Advantages of Our M ethod Exploit the memory v ertical data format utilizes slidin g windows to g form a much larger database to analyze  Flexibility in Choosing what to choose  Choosing what to choose to build the rules Computational and memory efficiency We have a team working only on this aspect 45 Associative IDS for NextGen Frameworks Dr S Dua LA Tech 45 


Preliminary Results Intra transaction Relations Data rate simulator NH-134 Mb HOP PATH update \(Y/N Inference 11.5 Y Y 2 0.120 N N      Y   n 0.345 N NH134 Y/N   Inf 1 0.150 N N 2 0 120 Y N Inter transaction Relations 2 0  120 Y N       5 5.55 0.456 Y Relations  n 0.345 N N Nmap on DMRL nmap.org 


Anticipated Outcome Anticipated Outcome Develop algorithm capable of learning from a given heterogeneous diverse Develop algorithm capable of learning from a given heterogeneous diverse data ff Dynamic algorithmic f ramework designed to shi f t modalities and sampling rates based on complex logic Flexibility of integration into the Snort intrusion detection system 47 Associative IDS for NextGen Frameworks Dr S Dua LA Tech 47 


References References Aircraft Cockpit Image courtesy USAF http://www.faa.gov htt p   www.faa g ov  air traffic  technolo gy  p g  _ gy  Acharya R Dua S Du X Sree V Chua C K Automated Diagnosis of Glaucoma Using Texture and Higher Order Spectra Features To appear in IEEE Transactions on Information Technology in Biomedicine  Du X Dua S 2011 Cancer Prognosis Using Support Vector Regression in Imaging  Modality World Journal of Clinical Oncology 2  1   44 49 Du X Dua S 2010 Salient Frame Extraction Using Support Vector Regression and Motion Features pp 5 Proc of the National Aerospace and Electronics Conference July 14 16 2010 D M P D S 2010 Di i i ti Ft d Cl ifi ti Mthd f D essaue r  M  P  D ua S  2010  Di scr i m i na ti ve F ea t ures an d Cl ass ifi ca ti on M e th o d s f or Accurate Classification 1st ed vol 7704 pp 14 Bellingham WA Proceedings of SPIE Dessauer M P Dua S 2010 Low Resolution Vehicle Tracking using Dense and Reduced Local Gradient Features Maps 1st ed vol 7694 pp 8 Bellingham WA Proceedings of SPIE SPIE 


Acknowledgements Acknowledgements Fundin g A g encies  US 4 1 Million direct fundin g g g 4 g LA BoR NIH NSF AFRL AFOSR and NASA Research Team Samuel Kasimalla Brandy McKnight Dr Pradeep Chowriappa Connor Johnson Vasanth Nair Mihir Chowriappa  Connor Johnson  Vasanth Nair  Mihir Karnik Mohit Jain and Swadheen Songmen Associative IDS for NextGen Frameworks Dr S Dua LA Tech 49 All the respective Logos belong to their owners 


Rf d Rdi R e f erence d R ea di ngs Copyright of cover pages held by respective publishers 


Thank You Questions Thank You  Questions Dr Sumeet Dua E mail sdua@latech.edu Web http://dmrl.latech.edu Associative IDS for NextGen Frameworks Frameworks Dr S Dua LA Tech 51 Image Source roadtrafficsigns.com 


