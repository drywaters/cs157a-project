Bvd. Decebal, Nr 107, 200440, Craiova, Dolj, ROMANIA E-mail\(s\yahoo.com, s_udristoiu@yahoo.com 
In this paper we propose a framework in which some methods are compared to achieve the medical diagnosis based on image analysis The proposed framework includes besides components for the extraction of low-level 
Anca Loredana Ion 1 Stefan Udristoiu 1  
Abstract 
An Experimental Framework for Learning the Medical Image Diagnosis  
1 University of Craiova, Faculty of Automation, Computers and Electronics 
     
features, methods for the integration of semantic knowledge about the medical diagnosis into the retrieval process. So, the paper approaches modalities for learning the medical diagnosis using low-level characteristics automatically extracted from the visual content to generate high-level concepts by means of semantic association rules. The experiments through this experimental framework were realized on medical collections of images 
 
Keywords  
Medical image diagnosis, medical image mining, association rules, content-based 
 
visual retrieval  
 The motivation of this study is due to the limitations of the researches regarding the semantic modeling of multimedia data. In the medical domain, a lot of researches were developed to investigate automated techniques for extracting the low \205level features that could generate semantic descriptions of the medical image content. Among these techniques are the methods based on machine learning that manually annotate the test image datasets.  In the medical domain, algorithms that recognize specific organs with different structures of the 
1. Introduction 
medical images are studied in [3 R E 2 application and IR th g ood resu lt s  the sub-symbolic processing of images. Though the actual methodologies of medical image analysis are not generically sufficient for interpreting different diseases. Their major problems are i The description of semantic concepts and the problem understanding-the relationships between the low-level features and semantic concepts are unclear in the actual developed methods.  So detailed tests and analysis have to be realized to ensure which combinations of lowlevel features capture the best the semantic 
concepts ii The generality of the application-in some of the previous researches, only certain semantic concepts could be learned, or the rule were generated of a fixed set of visual features The medical applications with automatic diagnosis capacity imply unique challenges, but at the same time new opportunities. In some way we understand an image from nature and in another way a medical image, if we are not physicians. On the other hand, there are a lot of formal representations of the medical knowledge that could be exploited to realize the automation of the medical diagnosis in any medical domain 
Also, in the medical domain, taxonomies thesaurus and ontology were developed, varying from the general target, like UM  SNOMED CT to th e spe ci fic ones l i k e   o r ana tom y RadLex [7] for  radiology, and AI jec t developed at Stanford University Anyway, the semantic medical systems are not yet scalable because of their big dependency on image modalities and applicability domain The remainder of this paper discusses the problem of automatically establishing of the image diagnosis and the architecture of our system in Section 2. A comparative study on 
m edical im ag e v i sual rep re sent at ion is p r es en ted  in Section 3. The capturing of semantic knowledge and steps required to generate semantic image representations are detailed in Section 4. Finally, in Section 5, we present a summary of the presented approach  
2. Architecture of the medical framework 
 The principal objective of our diagnosis system is to provide physicians an image retrieval system with the capabilities of medical 465 Proceedings of the 
ITI 2011 33 rd 
Int. Conf. on Information Technology Interfaces June 27-30 2011, Cavtat Croatia 


3. Content-based retrieval in medical images Image Mapping Component. This component has the role of mapping the low-level features of images to semantic indicators b  Colour feature    1. The database of about 300 images is creating including images from medical collections   duodenal ulcer, gastric ulcer, gastric cancer esophagitis, polyps, duodenal ulcer and rectocolitis 2. The two colour descriptors are computed for each image from the database 466 image classification and assignment of data to high level concepts. By analyzing the visual structure of already diagnosed images, the system provides a semi-automatic annotation which generates descriptions for a new and unlabeled image. Since the system is working semi-automatically, it depends on an expert at the mapping processing step. The more detailed description of the framework architecture is done in [6 h ere w e d ev el oped and com pare d methods for the interpretation of images from different nature categories.  The main components are Feature Extraction Component. This component mainly provides methods for extracting primitive visual\haracteristics of medical images Image Segmentation Component. In order to find out the semantic relations between image diagnoses and \215objects\216 contained in an image, it should be divided into objects. The segmentation approach is based on colour homogeneity criterion Content-Based Visual Retrieval Component This component manages the visual retrieval process. Beginning with query formulation by image example, the component provides functions for similarity computation between the query object and the image data stored in the database Diagnosis Component. This component has the role of deciding the diagnoses for new unlabelled images. It includes the following subcomponents a  Rules Generation and Classification Component. This component provides methods to generate semantic rules used to recognize the diagnoses of unlabelled medical images Storage Component. This component manages the physically storage of images and their features  is a very important feature in many image domains and is the most used feature in the content-based image retrieval systems because the colour characteristic is easy to be detected from images and objects. More, the colour is invariant to orientation and scaling and the analysis by colour is intuitive The performance and efficiency of the colour feature for characterizing the perceptual similitude of images is strongly influenced by the selection of the colour space and its quantization The developed comparative study of methods for colour representation includes the following descriptors The first representation is the colour histogram represented in HSV colour space quantized at 166 colours [1  The second descriptors is MPEG-7 \205 colour structure descriptor \(CSD\presented in HMMD colour space quantized at 128 colours  The CSD des cr ipto r repr ese nts the loc al  colour structure from an image, counting the number of appearances   of a colour into a block of dimension 8x8, which scans the image. The histogram represents the number of block in which appears each of the 128 quantized colours The average normalized modified retrieval rate \(ANMRR is c o m puted for tes ting the  efficiency and performance of the colour descriptors. To compare the developed methods the following conditions were set    In our framework, we develop a study of comparing different representations of medical images visual features, to select the ones with the best retrieval performances that are not limited to any particular domain The most important characteristics of image databases are: colour, texture, and shape. In this section, we present these features and the relationship between them and the results returned by the content-based visual retrieval component of the framework. To find a set of performing visual image descriptors for heterogeneous medical domains is a very difficult task, because there is not a-priori knowledge to be used The motivation of realizing this comparative study is the necessity of finding a good set of visual image descriptors, as a precondition for the accuracy of the image retrieval and diagnosis   Colour 3.1 


Colon Cancer 0.181 0.19 Duodenal ulcer 0.236 0.259 Colon Cancer 0.21 0.21 Table 1: The ANMRR for colour feature 3. The relevant images were established for each experiment 4. For each image diagnosis, the average of the normalized modified retrieval rate was computed, as can be observed in Table 1 By analyzing the results of the content-based retrieval using the colour feature, the best results are using the colour histogram in the HSV colour space  Gastric ulcer 0.19 0.21 Gastric ulcer 0.24 0.24   3.3 Polyps 0.228 0.232 Gastric cancer 0.19 0.20 3.2 Diagnosis Co-occurrence Matrix Gabor Filter   Gastric cancer 0.231 0.235 Shape feature Texture feature Esophagitis 0.18 0.187 Esophagitis 0.218 0.22 Polyp 0.243 0.26 Duodenal ulcer 0.2267 0.2267 Diagnosis HSV166 HMMD128   1. The database of about 300 images is creating including images from medical collections   ulcer, gastric cancer, duodenal ulcer etc 2. The two texture descriptors are computed for each image from the database 3. The relevant images were established for each experiment 4. For each image diagnosis, the average of the normalized modified retrieval rate was computed, as can be observed in Table 2 By analyzing the results of the content-based retrieval using the texture feature, the best results are obtained by the co-occurrence matrices  Table 2. The ANMRR for texture feature  The texture is another important characteristic taken into consideration for classifying and recognizing the sick images regions In the current framework, two methods are developed and compared: Gabor filter and cooccurrence matrices For the first method, we interpret the hue and saturation channels like polar coordinates to allow the direct use of the HSV colour space for Fourier transform [6 T h is te chni que is use d f o r  the extraction of the Gabor characteristics for colour texture  The co-occurrence matrix is another method studied and implemented in this framework. The co-occurrence matrix is based on the repeated occurrence of some configurations of pixels intensity in the texture. The classification of texture is based on the characteristics extracted from the co-occurrence matrices [4 ene rg y   entropy, maximum probability, contrast, cluster shade, cluster prominence, and correlation The average normalized modified retrieval rate \(ANMRR is c o m puted for tes ting the  efficiency and performance of the texture descriptors. To compare the developed methods the following conditions were set  The surface methods for shape detection are the most promising descriptors for image retrieval based on shape [1 n this fr am ework   two shape descriptors were developed: the Zernike moments and the eccentricity Zernike moments are another method used with success for shape detection [6  The  precision of the shape representation depends on the number of moments. We took into consideration the first 36 moments of maximum order 10 to equilibrate the efficiency and precision The eccentricity descriptor is another global descriptor taken into account that characterizes the shape at a general lev  The average normalized modified retrieval rate \(ANMRR is c o m puted for tes ting the  efficiency and performance of the texture descriptors. To compare the developed methods the following conditions were set 1. The database of about 300 images is creating including images from medical collections   ulcer, gastric cancer, polyps, etc 2. The two shape descriptors are computed for each image from the database 3. The relevant images were established for each experiment 4. For each image diagnosis, the average of the normalized modified retrieval rate was computed, as can be observed in Table 3 By analyzing the results of the content-based retrieval using the shape feature, the two methods have proximate results 467 Rectocolitis 0.213 0.213 Rectocolitis 0.196 0.196 


Duodenal ulcer 0.28 0.198 Gastric cancer 0.27 0.2  4. Learning the medical diagnosis of images using semantic rules Rectocolitis 0.218 0.21 Gastric ulcer 0.27 0.198   The image diagnosis process means the correlation between medical diagnoses and images. The annotation process should assign the image data to one or more predefined diagnoses with a certain confidence. For that, the proposed method uses a vocabulary-based knowledge and semantic rules, which serve as a source of semantic types and their relations. Accordingly the image process includes the following steps 1.The automatic segmentation of medical images and the indexing of resulted colour regions 2. The mapping of visual features of images to semantic indicators 3. The definition of a knowledge database, using the declarative language, Prolog, which facilitates the mapping process 4. The automatic discovery of semantic inference rules for discovery the semantic concepts from images 5. The representation of the semantic rules, using the declarative language, Prolog, to easier infer them to any domain The selection of the visual feature set and the image segmentation algorithm are the definitive stage for the medical image diagnosis. After we performed a large set of experiments in Section 3, we inferred the importance of semantic concepts in establishing the similitude between images. Using the results of experiments realized in Section 3, the HSV colour space quantized at 166 colours is used for representing the colour features, the co-occurrence matrix is used for representing the texture features, and the eccentricity is used for representing the shape features. The colour regions extraction is realized with the colour set back projection algorithm [4  e g i on is d e sc rib ed by a v ector wi th 13  components [5 T h e resu lt s of th e seg m entatio n  algorithm on an image diagnosed with colon cancer can be observed in Figure 1 For mapping the visual features of images to semantic interpretation, a vocabulary and syntax are used [4, 5     The vocabulary words are limited to the name of semantic indicators, which are visual elements   T h e sy ntax i s r epr es ented by th e m odel  which describes the images in terms of semantic indicators values. The values of each semantic descriptor are mapped to a value domain, which corresponds to the mathematical descriptor  The scope of image association rules is to find semantic relationships between image objects.  The methods used in this study bring important improvements related to the detailed descriptions of images, which are necessary for defining relationships between objects/regions classes of visual characteristic, objects/regions and classes of visual characteristics [5  The proposed method uses a modified version of CBA algorithm [4  f or di s c o ve r i n g the semantic rules between the images\220 sick regions and diagnoses. The image modelling in terms of itemsets and transactions is the following the set of sick regions of the training images represent the transaction set Figure 1. The result of segmentation algorithm on a colon cancer image a\age. \(b\gions of the image Esophagitis 0.223 0.216  the itemsets are formed by semantic indicators of transactional regions, so an item is 468 D Colon Cancer 0.20 0.20 Diagnosis Zernike Moment Eccentricity Polyp 0.235 0.236 Table 3. The average normalized modified rate for shape feature a b 


that contain the semantic indicator set represents the classifier. The classifier is used to predict which diagnoses the images from the test database belong to. Being given a new image, the classification process searches in the rules set for finding its most appropriate diagnosis. The algorithm verifies if the image Rules minsup=20 support represented by a pair \(semantic indicator, value  the frequent itemsets represent the itemsets with the support greater than or equal to the minimum support defined that contain the semantic indicator set  for a rule of the form  the support is  \(ruleCount     the itemsets of cardinality between 1 and  Some generated rules for medical diagnoses are represents the maximum length of an itemset; in our case and are labelled with the diagnosis k k k D SI SI d D SI d  R I is the number of semantic indicators, namely thirteen for a rule of the form is matched to any rule D SI \002 d SI \002 d Colour, light-red\,\(Texture-entropy, small 30%\, \(gastric-ulcer,100  Colour, light-yellow\, \(Texture-entropy medium\},20%\, \(duodenal-ulcer,100  Colour, medium-yellow\, \(Texture-entropy medium\},20%\, \(duodenal-ulcer,100  Colour, dark-yellow\, \(Texture-entropy small\},20%\, \(duodenal-ulcer,100 The set of rules generated by the proposed method set, and the semantic rules with maximum confidence are selected The application of the learning results\205 semantic rules, on other images than the ones used in the learning process is much more difficult. In the experiments realized through this study, two databases are used for learning and diagnosis process. The database used for learning contains 150 images from different medical diagnoses and is used to learn the correlations between images and diagnoses. The database used in the learning process is categorized into 7 diagnoses For testing the efficiency and performance of rules generation algorithm, for each image diagnosis, the percent of images correctly classified by the two algorithms is computed, as in Figure 2. The minimum support was established to 20% and the minimum confidence to 66.7  100% and  the confidence is  \(ruleCount/SICount\0 the frequent itemsets are used for rules generation A rule is represented by the algorithm, in the following form are iteratively found, where 5. Conclusion   6. Acknowledgements  from the  The direct motivation for our work is the fact that physicians are highly interested in querying images at conceptual and semantic level, not only in terms of low-level features The need of enhancement of the retrieval performance and the importance of \215semantic meaning\216 makes indispensable the process of image diagnosis. Presently, most of the medical image database systems utilize manual annotation, where experts assign diagnoses to images. In summary, since it is very difficult to automatically construct semantic knowledge from the extracted low-level features and map them on human perception, methods which combine both approaches are of great interest  This work was supported by the strategic grant POSDRU/89/1.5/S/61968, Project ID 61968 2009\financed by the European Social Fund within the Sectorial Operational Program Human Resources Development 2007 - 2013   re ide r O. T h e Unifi ed Med ic al  Language System \(UMLS\ntegrating biomedical terminology. Nucleic Acids Research 2004; 32:267-270   D esel aer s T   Key se r s D  N ey H  F I R E 205  flexible image retrieval engine: ImageCLEF 469 SICount represents the number of cases in the transactional set 7. References ruleCount represents the number of cases in the transactional set confidence 


Figure 2. Diagnosis vs. percent of images correctly classified by the system 2004; 43\(4 354-361    Liu B  H su W, Ma Y   I n teg rating  classification and association rule mining Proceedings 4th International Conference on Diagnosis; 1998. p. 80\20586   Man juna th BS, Ohm J R V a s udev an V V   Yamada A.Colour and Texture Descriptors IEEE Transaction on Circuits and Systems for Video Technology 2001; 11\(6\: 703-715  rok op R J Reev es AP. A Surv ey of  Moment-based Techniques for Unoccluded Object Representation and Recognition Graphical Models and Image Processing 1992; 54: 438-460  sse C, M e jino J L V A re fer ence on tolog y  for bioinformatics: The Foundational Model of Anatomy. Journal of Biomedical Informatics 2003; 36: 478-500 13 R ubin DL, Mongkolwat P, Kleper V Supekar K, Channin DS. Annotation and Image Markup: Accessing and Interoperating with the Semantic Content in Medical Imaging. IEEE Intelligent Systems 2009; 24\(1\7-65  i t h JR, Chang SF V i sua l SEEk  a full y  automated content-based image query system. Proceedings of the Fourth ACM International Multimedia Conference and Exhibition. 1996 November 18-22; Boston MA, USA; 1996. p. 87-98  tan escu L  B u rd escu D  I on A  B r ez o v an M. Improving the results of the contentbased image query on medical imagery Proceedings of the Third International Conference on Informatics in Control Automation and Robotics, Robotics and Automation, 2006 August 1-5; Setubal Portugal; 2006. p. 432-437  tea rns M, Pri ce C, Spack m an K, Wang A   SNOMED clinical terms: overview of the development process and project status Proceedings of American Medical Informatics Association Symposium; 2001 p. 662-666  Teag ue MR I m a g e A n aly sis Via the G ene ral  Theory of Moments. Journal of Optical Society of America 1980; 70\(8\: 920-930  T h e Ga tro lab I m a g e Libra ry 2007  http://www.gastrolab.net   470 Methods Inf Med   2004 evaluation. Multilingual Information Access for Text, Speech and Images 2004 3491:688\205698   Hong W, Georg escu B Z hou X S   K r ishn an S, Ma Y, Comaniciu D. Database-guided simultaneous multi-slice 3D segmentation for volumetric data. In: Ales Leonardis Horst Bischof and Axel Pinz, editors Proceedings of 9th European Conference on Computer Vision 2006 May 7-13 Graz Austria; 2006. p. 397-409  on AL, Udri sto iu S  I m a g e Mining fo r  Establishing Medical Diagnosis. Information Technology and Control 2010; 39\(2\: 123\205 129  on AL I m a g e Annota ti on Based o n  Semantic Rules. Human-Computer Systems Interaction: Backgrounds and Applications 2009; 60: 83-94   I on AL. A Fra m ework for sem anti c modeling of images. Annals of the University of Craiova-Mathematics and Computer Science Series 2010; 37\(4\: 3749  lo tz C. Radlex A new m e thod for indexing online educational materials RadioGraphics 2006; 26: 1595\2051597  ehm ann T,  G 374 ld M T h ie s C  F i sch er B   Spitzer K, Keysers D, Ney H, Kohnen M Schubert H, Wein B. Content-based image retrieval in medical applications      


with a probability of 90 Finally regarding the covering of the data set by the set of association rules extracted the AP model obtains signi田ant differences with respect to ARMGA with a 99 of probability and with exhaustive methods with a 95 of likelihood Future work lies in studying the employment of other heuristic metrics and other pheromone updating strategies to improve the performance of the algorithm On the other hand it would be interesting to extend the multi-objective approach considering more objectives to be optimized A CKNOWLEDGMENT This work has been supported by the Regional Government of Andalusia and the Ministry of Science and Technology projects P08-TIC-3720 and TIN2008-06681C06-03 and FEDER funds R EFERENCES  R Agra w a l and R Srikant F ast algorithms for mining association rules in large databases in Proceedings of the 20th International Conference on Very Large Data Bases  ser VLDB 94 San Francisco CA USA Morgan Kaufmann Publishers Inc 1994 pp 487499 A v ailable http://portal.acm.org/citation.cfm?id=645920.672836  J Han J Pei Y  Y in and R Mao Mining frequent patterns without candidate generation A frequent-pattern tree approach Data Min Knowl Discov  vol 8 pp 5387 January 2004 A v ailable http://dx.doi.or g/10.1023 B:DAMI.0000005258.31418.83  J M Luna J R Romero and S V entura  Analysis of the effectiveness of G3PARM algorithm in HAIS  ser LNCS Springer Berlin  Heidelberg 2010 vol 6077 pp 2734 A v ailable http://dx.doi.or g/10.1007 978-3-642-13803-4  X Y an C Zhang and S Zhang Genetic algorithmbased strategy for identifying association rules without specifying actual minimum support Expert Syst Appl  vol 36 pp 30663076 March 2009 A v ailable http://dx.doi.org/10.1016/j.eswa.2008.01.028  R J K uo C M Chao and Y  T  Chiu  A pplication of particle swarm optimization to association rule mining Appl Soft Comput  vol 11 pp 326336 January 2011 Available http://dx.doi.org/10.1016/j.asoc.2009.11.023  M Dorigo V  Maniezzo and A Colorni The ant system Optimization by a colony of cooperating agents IEEE Transactions on Systems Man and Cybernetics-Part B  vol 26 pp 2941 1996  D Martens M De Back er  J  V anthienen M Snoeck and B Baesens Classi田ation with ant colony optimization IEEE Transactions on Evolutionary Computation  vol 11 pp 651665 2007  R P arpinelli A A Freitas and H S Lopes Data mining with an ant colony optimization algorithm IEEE Trans on Evolutionary Computation  vol 6 pp 321332 2002  R J K u o and C W  Shih  Association rule mining through the ant colony system for national health insurance research database in Taiwan Comput Math Appl  vol 54 pp 13031318 2007 A v ailable http dx.doi.org/10.1016/j.camwa.2006.03.043  H A Abbass X Hoai and R I Mckay  AntT A G  A ne w method to compose computer programs using colonies of ants in In The IEEE Congress on Evolutionary Computation  2002 pp 16541659  M Boryczka and Z J Czech Solving approximation problems by ant colony programming in GECCO Late Breaking Papers  2002 pp 3946  J L Olmo J R Romero and S V entura  A grammar based ant programming algorithm for mining classi田ation rules in 2010 IEEE Congress on Evolutionary Computation CEC  2010 pp 225232 A v ailable http dx.doi.org/10.1109/CEC.2010.5586492  J R K oza Genetic programming on the programming of computers by means of natural selection  Cambridge MA The MIT Press 1992  J M Luna J R Romero and S V entura Design and behaviour study of a grammar guided genetic programming algorithm for mining association rules Knowledge and Information Systems  pp 121 In Press 2011  H Ishib uchi I K u w ajima and Y  Nojima Multiobjecti v e association rule mining in Proceedings of the Multiobjective Problem Solving from Nature Reykjavik Iceland  September 2006  J L Olmo J R Romero and S V entura Using ant programming guided by grammar for building rule-based classi兎rs IEEE Transactions on Systems Man and Cybernetics Part B Cybernetics In Press  pp 115 2011 A v ailable http://dx.doi.or g/10.1109/TSMCB 2011.2157681  R J Mullen D Monek osso S Barman and P  Remagnino A review of ant algorithms Expert Systems with Applications  vol 36 pp 96089617 2009 Available http://dx.doi.org/10.1016/j.eswa.2009.01.020  K Deb A Pratap S Agarw al and T  Me yari v an  A f ast and elitist multiobjective genetic algorithm Nsga-ii IEEE Transactions on Evolutionary Computation  vol 6 pp 182 197 2002  A Ge yer Schulz Fuzzy Rule-Based Expert Systems and Genetic Machine Learning  ser Studies in Fuzziness Heidelberg Physica-Verlag 1995 vol 3  U M F ayyad and K B Irani Multi-interv al discretization of continuous-valued attributes for classi田ation learning in 13th International Joint Conference on Uncertainly in Arti田ial Intelligence\(IJCAI93  1993 pp 10221029  M Hall E Frank G Holmes B Pf ahringer  P  Reutemann and I H Witten The weka data mining software an update SIGKDD Explor Newsl  vol 11 pp 1018 November 2009  J Dem  sar Statistical comparisons of classi兎rs over multiple data sets J Mach Learn Res  vol 7 pp 130 2006 2011 11th International Conference on Inte lligent Systems Design and Applications 977 


Dominant factors: Output value of industry, Secondary industry product, GPD, as well as Per capita GDP 2 D? A 0.649 3 G? A 0.644 4 B? A 0.613 5 R? A 0.575 Sub-dominant factors: Total value of imports and exports Per capita disposable income Non-agricultural population Total investment in fixed assets and Peak summer temperature 6 J? A 0.556 7 AB? A 0.555 8 F? A 0.537 9 V? A 0.520  The analytical result shows a heavy dependence of electricity consumption, and hence the power load growth, on industrial output value and per capita GDP Total value of imports and exports, income, nonagricultural population and total investment in fixed assets are found out as the sub-dominant factors to growth in electricity Weather conditions in summer influence peak load level, along with the proliferation of air conditioning load. Peak summer temperature is thus found relevant to some extent as well. The remaining 18 candidate variables, therefore, are suggested to be ignored in power load analysis and forecast V. CONCLUSION In this paper, we have introduced a new data mining methodology to investigate association degrees between Chinese power load growth and 27 different candidate factors This methodology offers some advantages as, for example allowing us to properly extract interesting association rules from large historical database. By ordering confidence of selected rules, four dominant factors and five sub-dominant factors boosting the electricity consumption in China are identified, which can been adopted for better understanding the growth law and more accurately predicting the electricity demand Future work includes the development of a new prediction 


method for electricity demand using the dominant variables identified in this research as inputs. Furthermore, other data mining techniques, such as clustering analysis, are also being considered REFERENCES 1] J. Kraft, A. Kraft, On the relationship between energy and GNP Journal of Energy and Development, vol.3, pp.401-403, 1978 2] E. S. H. Yu, J. Y. Choi, The causal relationship between electricity and GNP: an international comparison, Journal of Energy and Development vol.10, pp.249-272, 1985 3] U. Erol, E. S. H. Yu, On the relationship between electricity and income for industrialized countries, Journal of Electricity and Employment, vol.13, pp.113-122, 1987 4] D. C. Bohm, Electricity consumption and economic growth in the European Union: A causality study using panel unit root and cointegration analysis, 5th International Conference on European Electricity Market, 2008 5] A. Ciarreta, A. Zarraga, Economic growth and electricity consumption in 12 European countries: A Causality Analysis Using Panel Data, 6th International Conference on the European Energy Market, Leuven, 2009 6] U. Soytas, R. Sari, Energy consumption and GDP: causality relationship in G-7 countries and emerging markets, Energy Economics pp.33-37, 2003 7] S. H. Yoo, Electricity consumption and economic growth: evidence from Korea, Energy Policy, pp.1627-1632, 2005 8] C. C. Lee, Energy consumption and GDP in developing countries: A cointegrated analysis, Energy Economics, pp.415-427, 2005 9] S. T. Chen, H. I. Kuo, C. C. Chen, The relationship between GDP and electricity consumption in 10 Asian countries, Energy Policy, pp.26112621, 2007 10] C. C. Lee, C. P. Chang, Energy consumption and economic growth in Asian economies: A more comprehensive analysis using panel data Resource and Energy Economics, pp.50-65, 2008 11] A. Shiu, P. L. Lam, Electricity consumption and economic growth in China, Energy Policy, pp.47-54, 2004 12] G. D. Li, D. Yamaguchi, H. S. Lin, The simulation modeling about the developments of GDP, population and primary energy consumption in China based on MATLAB, 2006 IEEE Conference on Cybernetics and Intelligent Systems, Bangkok, 2006 13] L. P. Wang, Study on the relationship between economic development and energy consumption in Henan Province of China, 2008 International Seminar on Business and Information Management, 2008 


14] X. Zhang, Y. Mao, The relationship between energy consumption and economic growth in China based on ANFIS, International Workshop on Intelligent Systems and Application, ISA2009, Wuhan, 2009 15] H. R. Cui, D. Wang, The study on the relationship between energy consumption and economy growth in China based on VAR model 2009 First International Workshop on Database Technology and Applications, 2009 16] M. Delgado, N. Marn, D. Snchez, M. A. Vila, Fuzzy association rules general model and applications, IEEE Transactions on Fuzzy Systems vol.2, pp.214-225, 2003 17] R. Agrawal, T. Imielinski, A. Swami, Mining association rules between sets of items in large databases the ACM SIGMOD Conference on Management of data. Washington DC, pp.207-216, 1993 18] D. Dubois, H. Prade, T. Sudkamp, On the representation, measurement and discovery of fuzzy associations, IEEE Transactions on Fuzzy Systems, vol.2, pp.250-262, 2005   


means that the service is in the same branch, but at a lower level in the hierarchy of services execution. Therefore, this service will only be conducted if an error has occurred in the execution of the previous one. As shown in chart II the latter service uses an image resource in charge of showing some information at the MIDlet display and whose content is also stored on the device Besides, the MIDlet allows in a simple way to modify all those parameters that define the execution of the services and their use. As commented before, a user could not want that a service is executed automatically and requires manual confirmation. For that, he/she only would need to change the value of the execution parameter of the service into manual. In the same way, the user can activate or deactivate the use of resources just by modifying the value of the state attribute into off. Even more, it is possible to add new resources, if, together with their definition some content needed for their execution is included Therefore, it can be checked as, even when the user define an initial interaction for a scenario and even when the same deployment is done in different devices, each user could easily adapt and customize the interaction to its needs and preferences afterwards Equally, the user could activate or deactivate a service changing the execution order and modifying the hierarchy initially defined for them. Herewith, the same scenario could be customized and act in a different way depending of the person that interacts with it V. DISCUSSION IoT is not a reality yet, but a prospective view of a series of technologies that, combined, could sharply modify the interaction mode with our environment and the working of our society in the following years. In order to establish the IoT philosophy, it would be needed an advance of the development and dissemination of elements as sensors, new communication technologies \(as well as their intercommunication mobile devices able to integrate them, a proper infrastructure and above all software applications that supports them and are able to integrate all those elements, as well as to fulfills the needs and requirements of the users Those new systems must also be adapted to the different interaction scenarios and, mainly, to the different 


characteristics, requirements, preferences and needs of the people that interact with the environment. In this paper we present a model that provides a solution to this issue The model is based in augment different objects among a scenario with Tags, by the assignment of services and resources defined in an abstracted hierarchy that allows configuring a customized interaction model. Thus, for the same scenario, the model is able to define different interaction contexts. So, a context is defined as the aggregation of: a certain scenario formed by a set of intelligent objects offering a set of services, b characteristics, preferences and needs, c and d Under the proposed model a tool that allows the definition and scenario deployment has been built. A neuter MIDlet installed in the NFC device is the one in charge of guiding the 13 interaction through the definition of the scenarios stored in a XML file. This architecture allows that the same MIDlet could be used with any scenario and that the user could adapt the interaction to his preferences Currently we are working in the completeness of the model and the complex interaction scenarios generalization, being the latter based in rules systems that allows adapting the different interaction contexts to the users ACKNOWLEDGMENT This work was supported by the Ministry of Science and Innovation of Spain \(MICINN Project TIN2009-07184 REFERENCES 1] M. Weiser. The Computer for the Twenty-First Century. Scientific American, 1991, pp. 91-104 2] G. Broll, S . Siorpaes, E. Rukzio, M. Paolucci, J. Hamard, M. Wagner and A. Schmidt. Supporting Mobile Service Usage through Physical Mobile Interaction, 5th Annual IEEE International Conference on Pervasive Computing and Communications, White Plains,NY, USA 2007 3] C. Floerkemeier, M. Langheinrich, E. Fleisch, F. Mattern and S.E Sarma. The Internet of Things. Proceedings of First International Conference, IOT 2008, Zurich, Switzerland. Lecture Notes in Computer Science, vol. 4952, 2008 4] Revising Europes ICT Strategy, ftp://ftp.cordis.europa.eu/pub/ist/docs 


istag-revising-europesict-strategy-final-version_en.pdf 5] E. Rukzio, G. Broll, K. Leichtenstern, A. Schmidt. Mobile Interaction with the Real World: An Evaluation and Comparison of Physical Mobile Interaction Technique, Ambient Intelligence. Lecture Notes in Computer Science, vol. 4794, 2007, pp. 1-18 6] J. Hong and E. Suh, S. Kim. Context-aware systems: A literature review and classification, Expert Systems with Applications. 2009 Elsevier 7] A.K. Dey and G.D. Abowd. Towards a better understanding of context and context-awareness, Proceedings of the Workshop on the What Who, Where, When and How of Context-Awareness, ACM Press, New York. 2000 8] H. Chen, T. Finin and A. Joshi.An Intelligent Broker for ContextAware Systems, Adjunct Proceedings of Ubicomp 2003 9] H. Chen, F. Perich, T. Finin, A. Joshi. SOUPA: standard ontology for ubiquitous and pervasive applications, The First Annual International Conference on Mobile and Ubiquitous Systems: Networking and Services, 2004, MOBIQUITOUS 2004 10] M. Roman, C. Hess, R. Cerqueira, A. Ranganathan, R.H. Campbell and K. Nahrstedt. GAIA: A middleware infrastructure for active spaces IEEE Pervasive Computing, vol. 1, no. 4, 2002, pp. 74-83 11] Service Platform for Innovative Communication Environment \(SPICE An Integrated Project in European Unions IST 6th Framework Programme, http://www.ist-spice.org 12] Open Platform for User-centric service Creation and Execution OPUCE Framework Programme, http://www.opuce.tid.es 13] MobiLife, an Integrated Project in European Unions IST 6th Framework Programme, http://www.ist-mobilife.org 14] L. Lamorte. A platform for enabling context aware telecommunication services, Third Workshop on Context Awareness for Proactive Systems. 2007 15] C. Venezia, C.A. Licciardi Improve ubiquitous Web applications with Context Awareness, 11th ICIN 2007 16] J.J. Chen, C. Adams. Short-range wireless technologies with mobile payments systems, Proc. ICEC 04, ACM Press, 2004, pp. 649 656 17] K. Cheverst. Experiences of developing and deploying a context-aware tourist guide: The GUIDE project, 6th International Conference on Mobile Computing and Networking, Boston, August 2000, pp. 2031 18] D.J. Cooka, J.C. Augusto, V.R. Jakkula, Ambient intelligence Technologies, applications, and opportunitie, Pervasive and Mobile Computing. 2009 


19] J. Hong, E. Suh, S. Kim. Context-aware systems: A literature review and classification, Expert Systems with Applications. Elsevier. 2008 20] G. Matas Miraz, I. Luque Ruiz, M.A. Gmez-Nieto. How NFC can be used for the Compliance of European Higher Education Area Guidelines in European Universities. Proceedings 1st International IEEE Workshop on Near Field Communication. 3-8. 2009   14 


dataset contains a stream of TCP connection records from two weeks of LAN traffic over MIT Lincoln Labs. It consists of 42 attributes that usually characterize network traffic behavior, both categorical attributes and quantitative attributes such as duration of the connections, protocol type etc. Attribute src_byte denoting the number of data bytes from source to destination and attribute dst_bytes inverse are selected in this experiment.  They are both quantitative attributes The user specified parameters are set as follows 5, 0.3, 0.03, 0.01,W min_sup preMinsup T 0.5, 0.4, 30.min_confidence max_MFB min_num_triples And the number of transactions in each time slot is 250 It is assumed that there are no more than three fuzzy sets or intervals in the datasets i.e. 3F Four different approaches to mine association rules are compared using the following notations: Fuzzy+MFB: the approach that use both fuzzy method and MFB_measure with 1 3.0? = and 2 0 .5 2 0.5? = , Fuzzy+P: the approach using fuzzy method with 1 3.0? = and 2 0.5? = also but repressing the first part of the MFB_measure that ignores the changed rate of the membership function, Discrete1: the approach using discrete method with 1 2 1.5? ?= =  and Discrete2 : the approach using discrete method with 1 2 2.5 TABLE I. RESULT OF EXPERIMENT ONE NUM_C NUM_FI NUM_RULE TIME\(s 1 \(50,50 2 \(60,60 3 \(70,70 4 \(80,80 5 \(90,90 6 \(100,100 7 \(110,110 8 \(120,120 9 \(130,130 10 \(140,140 Volume 4] 2010 2nd International Conference on Computer Engineering and Technology V4-157 0 0.5 1 1.5 2 x 104 


0 200 400 600 800 1000 1200 1400 Size of Databases\(250 Ex ec u tio n Ti m e\(s ec  Fuzzy+MFB Discrete1 Discrete2 Fuzzy+P Figure 3. Comparison of Execution Time Fig. 3 shows the execution time of the four approaches The runtimes of them grow linearly as the data stream grows which confirms that they are scalable with respect to the size of data stream, and it is mainly because of the usage of sliding window model. Fuzzy+P uses the least time Fuzzy+MFB has similar execution time to Discrete2, and Discrete1 has the most execution time. The difference of runtimes between them is mainly influenced by the clustering operations they use. The more clustering operations were executed, the more runtime it was Fig. 4 and Fig. 5 show the number of frequent itemsets and interesting rules found with the data stream increased Fuzzy+P and Fuzzy+MFB used less clustering operations than Discrete1 and Discrete2. Fuzzy+MFB nearly finds the most number of frequent fuzzy sets and interesting rules with the second least of clustering operations. Sometimes Discrete2 returns nearly the same number of fuzzy sets and interesting rules but with more clustering operations and the 


semantics of Discrete2 are meaningless as discussed in experiment one. Furthermore, the number of interesting rules found by Discrete1 is even less than Fuzzy+P that used the clustering operations least which illustrates the superiority of the method using fuzzy sets V. CONCLUSIONS In this paper, a novel fuzzy ARM algorithm called FFI_Stream is presented to tackle quantitative attributes in data streams and some techniques are proposed in the algorithm. Both synthetic and real datasets are used to evaluate the performance of the proposed algorithm. The experimental results show both the effectiveness and efficiency of the proposed algorithm.  In comparison with the discrete method, the proposed algorithm using fuzzy sets and MFB_measure gets a trade-off between the number of interesting rules and efficiency ACKNOWLEDGMENT This work is supported by The National High Technology Research and Development Program of China 863 Program 2008AA042902 Technology Research and Development Program of China 863 Program 2009AA04Z162 Project \(B07031 0 500 1000 1500 2000 2500 3000 3500 4000 0 2000 4000 6000 8000 10000 12000 Size of Databases\(250 N um be r o f F re qu e n t I 


te m se ts Fuzzy+MFB Discrete2 Discrete1 Fuzzy+P Clustering Operation Figure 4. Number of Frequent Itemsets 0 500 1000 1500 2000 2500 3000 3500 4000 0 1000 2000 3000 4000 5000 6000 7000 8000 Size of Databases\(250 Nu m be r o f I n te re st in g Ru le s Fuzzy+MFB Discrete2 Discrete1 Fuzzy+P Clustering Operation Figure 5. Number of Interesting Rules REFERENCE 1] R. Srikant and R. Agrawal, Mining Quantitative Association Rules 


in Large Relational Talbes, Proc. ACM SIGMOD, 1996, pp. 1-12 2] A.W. Fu et al. Finding Fuzzy Sets for the Mining of Fuzzy Association Rules for Numerical Attributes, In Proceedings of the First International Symposium on Intelligent Data Engineering and Learning \(IDEAL'98 3] C. M. Kuok, A. Fu and M. H . Wong, Fuzzy Association Rules in Large Databases with Quantitative Attributes, In ACM SIGMOD Records, vol. 27, 1998, pp. 41-46 4] X. Dang, V. Lee, W. K. Ng and K.L Ong, Incremental and Adaptive Clustering Stream Data over Sliding Window, Database and Expert Systems Applications, vol. 5690, 2009, pp. 660-674 5] M. Kaya,?R. Alhajj, F. Polat, and A. Arslan, Efficient Automated Mining of Fuzzy Association Rules, Database and Expert System Applicaton, vol. 2453, 2002, pp.133-142 6] http://kdd.ics.uci.edu/databases/kddcup99/kddcup99.html 7] S. Guha, A. N. Mishra, R. Motwani, L. OCallaghan, Clustering Data Streams: Theory and Practice,  Proc. IEEE Transactions on Knowledge and Data Engineering, vol. 15, May/Jun. 2003, pp. 515528 8] C. Aggarwal, J. Han, J. Wang, P. Yu, A Framework for Clustering Evolving Data Streams,  Proc. VLDB Conference, 2003,  pp. 81-92 9] C. K. S. Leung, B. Y. Hao, Mining of Frequent Itemsets from Streams of Uncertain Data,  Proc. IEEE International Conference on Data Engineering \(ICDE 09 10] C. C. Aggarwal, Y. Li, J. Y. Wang, and J. Wang, Frequent Pattern Mining with Uncertain Data, Proc. ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, Jun. 2009, pp 29-37 11] P. M. Tsai, Mining Frequent Itemsets in Data Streams using the Weighted Sliding Window Model, Expert Systems and Applications vol. 36, Nov. 2009, pp.11617-11625 V4-158 2010 2nd International Conference on Computer Engineering and Technology [Volume 4 


In all charts reported in this section, the X-axis is k, which denotes the size of sample under the space of a target rule drawn from deep web. The sample size for each point on X-axis is k x, where x is a ?xed value for our experiment, and depends upon the dataset. At each time, queries are issued to obtain kx data records under the space of a target rule. Overall, all our experiments show the variance of estimation, sampling costs and sampling accuracy with varying sample size Figure 1 shows the result from our strati?ed sample methods on the US census data set. The size of pilot sample is 2000, from which all of the 50 initial rules are derived. In this experiment the ?xed value x is set to be 300, which means the smallest sample size at k = 1 is 300, and the largest sample size at k 10 is 3000. Figure 1 a the ?ve sampling procedures. Figure 1 b cost for the sampling procedures. In order to better illustrate the experiment result, in each execution of sampling, the variance of 330 6DPSOLQJ9DULDQFH            9D UL DQ FH R I V WL PD WL RQ  


9DU 9DU 9DU 5DQG a timation 6DPSOLQJ&RVW           6D PS OL QJ  RV W 9DU 9DU 9DU 5DQG b 6DPSOLQJ$FFXUDF            5 


 9DU 9DU 9DU 5DQG c Fig. 1. Evaluation of Sampling Methods for Association Rule Mining on US Census Dataset estimation and sampling cost for the sampling procedures var7 var5, var3, and rand are normalized by the corresponding values of Full Var. Thus, in our experiment, the values of sampling cost and variance of estimation for sampling procedure Full Var are all 1. Furthermore, Figure 1 c sampling procedures From Figure 1 a pared with sampling procedures Var7, Var5 and Var3, Full Var has the lowest estimation variance and the highest sampling cost. From sampling procedures Var7, Var5, and Var3, we can see a pattern that the variance of estimation increases, and the sampling cost decreases consistently with the decrease of the weight for variance of estimation. At the largest sample size of k = 10, the estimation variance of sampling procedure Var3 is increased by 27% and the sampling cost is decreased by 40 compared with sampling procedure Full Var. The experiment shows that our method decreases the sampling cost ef?ciently by trading off a percent of variance of estimation. Similar to variance of estimation, the sampling accuracy of these procedures also decreases with the decrease of the weight on variance of estimation. For the largest sample size at k = 10, we can see that the AER of sampling procedure Var3 is increased by 20 compared with sampling procedure Full Var. However, for many users, increase of the AER will be acceptable, since the sampling cost is decreased by 40%. By setting the weights for sampling variance and sampling cost, users would be able to control the trade-off between the variance of estimation, sampling cost, and estimation accuracy In addition, compared with sampling procedure of Full Var Var7, Var5, and Var3, sampling procedure Random, has higher estimation of variance, sampling cost and lower estimation accuracy. Thus, our approach clearly results in more effective methods than using simple random sampling for data mining on the deep web Figure 2 shows the experiment result of our proposed strati?ed 


sampling methods on the Yahoo! data set. The size of pilot sample on this data set is 2,000, and the ?xed value x for sample size is 200. The results are similar to those from the US census dataset. We can still see the pattern of the variance of estimation increasing with the decrease of its weight. Besides, the sampling accuracy is also similar to the variance of estimation. However although the variance estimation of sampling procedure Random is 60% larger than sampling procedure Full Var, the sampling cost of Random is 2% smaller than Full Var. This is because Full Var does not consider sampling cost. It is possible that Full Var assigns a large sample to a stratum with low ?, which denotes the probability of containing data records under the space of A = a, resulting the larger sampling cost than that of simple random sampling. Sampling procedures Var7, Var5, Var3 consider sampling cost as well, and have smaller variance estimation and sampling cost, compared with Random. Furthermore, Random has smaller sampling accuracy than Full Var, Var7 and Var5, but has larger sampling accuracy than Var3. This is because Var3 assigns much more importance to the sampling cost, and loses accuracy to a large extent To summarize, our results shows that our proposed strati?ed sampling are clearly more effective than simple random sampling on the deep web. Moreover, our approach allows users to tradeoff variance of estimation and sampling accuracy to some extent while achieving a large reduction in sampling costs B. Differential Rule Mining In this section, we present results from experiments based on differential rule mining. Particularly, we look at the rules of the form A = a ? D1\(t t categorical attribute and t is an output numerical attribute, while other categorical attributes in the data set are considered as input attributes In this experiment, we also evaluate our proposed method with different weights assigned to variance of estimation and sampling cost. Five sampling procedures, Full Var, Var7, Var5,Var3 and Random, have same meanings with those in the experiments of association rule mining. Similarly, 50 rules are randomly selected from the datasets, and each of the 50 differential rules are reprocessed 100 times using 100 different \(pilot sample, sample iterations 5000 runs First, we evaluated the performance of these procedures on 


the US census data set. The size of pilot sample is 2000, and all 50 rules are derived from this pilot sample. In this experiment the ?xed value x for the sample size is set to be 300. The attribute income is considered as a differential attribute, and the difference of income of husband and wife is studied in this experiment. Figure 3 shows the performance of the 5 sampling 331 6DPSOLQJ9DULDQFH             9D UL DQ FH R I V WL PD WL RQ  9DU 9DU 9DU 5DQG a timation 6DPSOLQJ&RVW    


      6D PS OL QJ  RV W 9DU 9DU 9DU 5DQG b 6DPSOLQJ$FFXUDF          5  9DU 9DU 9DU 5DQG c Fig. 2. Evaluation of Sampling Methods for Association Rule Mining on the Yahoo! Dataset procedures on the problem of differential rule mining on the US census data set. The results are also similar to the experiment results for association rule mining: there is a consistent trade off between the estimation variance and sampling cost by setting their weights. Our proposed methods have better performance than simple random sampling method 


We also evaluated the performance of our methods on the Yahoo! dataset. The size of pilot sampling is 2000, and the xed value x for the sample size is 200. The attribute price is considered as the target attribute. Figure 4 shows the performance of the 5 sampling procedures on the problem of differential rule mining on the Yahoo! dataset. The results are very similar to those from the previous experiments VI. RELATED WORK We now compare our work with the existing work on sampling for association rule mining, sampling for database aggregation queries, and sampling for the deep web Sampling for Association Rule Mining: Sampling for frequent itemset mining and association rule mining has been studied by several researchers [23], [21], [11], [6]. Toivonen [23] proposed a random sampling method to identify the association rules which are then further veri?ed on the entire database. Progressive sampling [21], which is based on equivalence classes, involves determining the required sample size for association rule mining FAST [11], a two-phase sampling algorithm, has been proposed to select representative transactions, with the goal of reducing computation cost in association rule mining.A randomized counting algorithm [6] has been developed based on the Markov chain Monte Carlo method for counting the number of frequent itemsets Our work is different from these sampling methods, since we consider the problem of association rule mining on the deep web. Because the data records are hidden under limited query interfaces in these systems, sampling involves very distinct challenges Sampling for Aggregation Queries: Sampling algorithms have also been studied in the context of aggregation queries on large data bases [18], [1], [19], [25]. Approximate Pre-Aggregation APA  categorical data utilizing precomputed statistics about the dataset Wu et al. [25] proposed a Bayesian method for guessing the extreme values in a dataset based on the learned query shape pattern and characteristics from previous workloads More closely to our work, Afrati et al. [1] proposed an adaptive sampling algorithm for answering aggregation queries on hierarchical structures. They focused on adaptively adjusting the sample size assigned to each group based on the estimation error in each group. Joshi et al.[19] considered the problem of 


estimating the result of an aggregate query with a very low selectivity. A principled Bayesian framework was constructed to learn the information obtained from pilot sampling for allocating samples to strata Our methods are clearly distinct for these approaches. First strata are built dynamically in our algorithm and the relations between input and output attributes are learned for sampling on output attributes. Second, the estimation accuracy and sampling cost are optimized in our sample allocation method Hidden Web Sampling: There is recent research work [3 13], [15] on sampling from deep web, which is hidden under simple interfaces. Dasgupta et al.[13], [15] proposed HDSampler a random walk scheme over the query space provided by the interface, to select a simple random sample from hidden database Bar-Yossef et al.[3] proposed algorithms for sampling suggestions using the public suggestion interface. Our algorithm is different from their work, since our goal is sampling in the context of particular data mining tasks. We focus on achieving high accuracy with a low sampling cost for a speci?c task, instead of simple random sampling VII. CONCLUSIONS In this paper, we have proposed strati?cation based sampling methods for data mining on the deep web, particularly considering association rule mining and differential rule mining Components of our approach include: 1 the relation between input attributes and output attributes of the deep web data source, 2 maximally reduce an integrated cost metric that combines estimation variance and sampling cost, and 3 allocation method that takes into account both the estimation error and the sampling costs Our experiments show that compared with simple random sampling, our methods have higher sampling accuracy and lower sampling cost. Moreover, our approach allows user to reduce sampling costs by trading-off a fraction of estimation error 332 6DPSOLQJ9DULDQFH      


     V WL PD WL RQ R I 9D UL DQ FH  9DU 9DU 9DU 5DQG a timation 6DPSOLQJ&RVW          6D PS OL QJ  RV W 9DU 9DU 


9DU 5DQG b 6DPSOLQJ$FFXUDF          5  9DU 9DU 9DU 5DQG c Fig. 3. Evaluation of Sampling Methods for Differential Rule Mining on the US Census Dataset 6DPSOLQJ9DULDQFH             9D UL DQ FH R I V WL 


PD WL RQ  9DU 9DU 9DU 5DQG a timation 6DPSOLQJ&RVW          6D PS OL QJ  RV W  9DU 9DU 9DU 5DQG b 6DPSOLQJ$FFXUDF         


    5  9DU 9DU 9DU 5DQG c Fig. 4. Evaluation of Sampling Methods for Differential Rule Mining on the Yahoo! Dataset REFERENCES 1] Foto N. Afrati, Paraskevas V. Lekeas, and Chen Li. Adaptive-sampling algorithms for answering aggregation queries on web sites. Data Knowl Eng., 64\(2 2] Rakesh Agrawal and Ramakrishnan Srikant. Fast algorithms for mining association rules. In Proceedings of the 20th International Conference on Very Large Data Bases, pages 487499, 1994 3] Ziv Bar-Yossef and Maxim Gurevich. Mining search engine query logs via suggestion sampling. Proc. VLDB Endow., 1\(1 4] Stephen D. Bay and Michael J. Pazzani. Detecting group differences Mining contrast sets. Data Mining and Knowledge Discovery, 5\(3 246, 2001 5] M. K. Bergman. The Deep Web: Surfacing Hidden Value. Journal of Electronic Publishing, 7, 2001 6] Mario Boley and Henrik Grosskreutz. A randomized approach for approximating the number of frequent sets. In ICDM 08: Proceedings of the 2008 Eighth IEEE International Conference on Data Mining, pages 4352 Washington, DC, USA, 2008. IEEE Computer Society 7] D. Braga, S. Ceri, F. Daniel, and D. Martinenghi. Optimization of Multidomain Queries on the Web. VLDB Endowment, 1:562673, 2008 8] R. E. Ca?isch. Monte carlo and quasi-monte carlo methods. Acta Numerica 7:149, 1998 9] Andrea Cali and Davide Martinenghi. Querying Data under Access Limitations. In Proceedings of the 24th International Conference on Data Engineering, pages 5059, 2008 10] Bin Chen, Peter Haas, and Peter Scheuermann. A new two-phase sampling based algorithm for discovering association rules. In KDD 02: Proceedings of the eighth ACM SIGKDD international conference on Knowledge discovery and data mining, pages 462468, New York, NY, USA, 2002 ACM 


11] W. Cochran. Sampling Techniques. Wiley and Sons, 1977 12] Arjun Dasgupta, Gautam Das, and Heikki Mannila. A random walk approach to sampling hidden databases. In SIGMOD 07: Proceedings of the 2007 ACM SIGMOD international conference on Management of data pages 629640, New York, NY, USA, 2007. ACM 13] Arjun Dasgupta, Xin Jin, Bradley Jewell, Nan Zhang, and Gautam Das Unbiased estimation of size and other aggregates over hidden web databases In SIGMOD 10: Proceedings of the 2010 international conference on Management of data, pages 855866, New York, NY, USA, 2010. ACM 14] Arjun Dasgupta, Nan Zhang, and Gautam Das. Leveraging count information in sampling hidden databases. In ICDE 09: Proceedings of the 2009 IEEE International Conference on Data Engineering, pages 329340 Washington, DC, USA, 2009. IEEE Computer Society 15] Loekito Elsa and Bailey James. Mining in?uential attributes that capture class and group contrast behaviour. In CIKM 08: Proceeding of the 17th ACM conference on Information and knowledge management, pages 971 980, New York, NY, USA, 2008. ACM 16] E.K. Foreman. Survey sampling principles. Marcel Dekker publishers, 1991 17] Ruoming Jin, Leonid Glimcher, Chris Jermaine, and Gagan Agrawal. New sampling-based estimators for olap queries. In ICDE, page 18, 2006 18] Shantanu Joshi and Christopher M. Jermaine. Robust strati?ed sampling plans for low selectivity queries. In ICDE, pages 199208, 2008 19] Bing Liu. Web Data Mining: Exploring Hyperlinks, Contents, and Usage Data \(Data-Centric Systems and Applications Inc., Secaucus, NJ, USA, 2006 20] Srinivasan Parthasarathy. Ef?cient progressive sampling for association rules. In ICDM 02: Proceedings of the 2002 IEEE International Conference on Data Mining, page 354, Washington, DC, USA, 2002. IEEE Computer Society 21] William H. Press and Glennys R. Farrar. Recursive strati?ed sampling for multidimensional monte carlo integration. Comput. Phys., 4\(2 1990 22] Hannu Toivonen. Sampling large databases for association rules. In The VLDB Journal, pages 134145. Morgan Kaufmann, 1996 23] Fan Wang, Gagan Agrawal, Ruoming Jin, and Helen Piontkivska. Snpminer A domain-speci?c deep web mining tool. In Proceedings of the 7th IEEE International Conference on Bioinformatics and Bioengineering, pages 192 199, 2007 24] Mingxi Wu and Chris Jermaine. Guessing the extreme values in a data set a bayesian method and its applications. VLDB J., 18\(2 25] Mohammed J. Zaki. Scalable algorithms for association mining. IEEE Transactions on Knowledge and Data Engineering, 12:372390, 2000 


333 


