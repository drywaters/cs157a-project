Data Mining in Library Reader Management Ping YU Computer and Information Technology Department Tianjin University of Commerce Boustead College Tianjin, China e-mail: bd_yup@126.com   Abstract  Data mining technology has been applied to library management. In this paper, based on the data resource come from Boustead College Library Information Management System include record of book lending history, readers information and library holdings, using Microsoft SQL Server 2005 as a data mining tool and use the data mining techniques to identify characteristics of the readersí book borrowing, in order to achieve 
individual service  Keywords-DataMining; Reader Management in Library Cluster; Association Rules; Time Series I   I NTRODUCTION  Boustead College uses database technology to manage the library currently. Its main purpose is to facilitate the procurement of books, cataloging, and circulation management. In order to better satisfy the needs of readers we must to explore the needs of readers, to provide the information which they need initiatively. Most current library evaluation techniques focus on frequencies and 
aggregate measures; these statistics hide underlying patterns Discovering these patterns is the key that use library services 1 a  m i nin g is ap plied t o l i br ary op er atio ns [2  In this paper, we focused on the using of the appropriate data mining techniques into the circulation data of the Library Information Management System, and make analysis in the following aspects: \(1\ Classification of the readers classify the readers groups with grades, majors or other factors. By this means, it is a clearer understanding of the characteristics of various groups, analyzing the class of the borrowed books, in order to provide the personalized service 
2\ersí interest analysis, the association analysis on the books which readers are interested in could help to identify some of the association from books borrowing. It is very helpful to buy books more reasonable and conduct book recommendation service. \(3\ The peaks and valleys analysis of circulation data, through the library circulation data mining to identify the change regulars to scientific management. It could provide readers with more and better services within limited human resources and library resources According to the research contents above, we will use 
Microsoft SQL Server 2005 as a data mining tool. The Microsoft Clustering algorithm will be used to classify readers. The Microsoft Association Rules algorithm will be used to analyze reader's interest. The Microsoft Time Series algorithm will be used to analyze Readers peaks and valleys II  D ATA M INING IN LIBRARY READER MANAGEMENT  The circulation data is the best evidence of the library resources used. It is a mirror can reflect the actual information that readers needed. Therefore, it is a certain reference to grasp readersí interesting, and thus as the basis 
for strengthening the use of library resources [3 Boustead College's Library Information Management System is based on Microsoft SQL Server 2000.It is selecting the data which related with research topic as a data source, including library circulation tables, reader information tables, library collections tables and book barcode tables A  Data cleaning First check whether the selected tables filled with null values, modify or delete exception values B  Data transformation In order to analyze the features of the readers, create a 
query TSG_READER_COUNT, counting borrowing amount for each reader, illustrating in Fig.1. Apply the cluster methods on the borrowing amount of Readers, that is divided 36 to 98\ \(18 to 35\, E \(smaller than 18\dd the RATE attribute, illustrating in Fig.2. After data transformation check whether it is including null values or exception values before the next step  Figure 1  Borrowing amount for each reader 
Figure 2  Readerís rate of borrowing amount 2011 International Conference on Network Computing and Information Security 978-0-7695-4355-0/11 $26.00 © 2011 IEEE DOI 10.1109/NCIS.2011.109 54 2011 International Conference on Network Computing and Information Security 978-0-7695-4355-0/11 $26.00 © 2011 IEEE DOI 10.1109/NCIS.2011.109 54 


C  Data Mining 1  Analyses reader characteristics by clustering In this paper, k-means clustering algorithm which is one of the Clustering algorithms is used in analyzing reader characteristics K-means algorithm procedure follows a simple and easy way to classify a given data set through a certain number of clusters \(assume k clusters\ fixed a priori. The main idea is to define k centroids, one for each cluster. These centroids should be placed in a cunning way because of different location causes different result. So, the better choice is to place them as much as possible far away from each other The next step is to take each point belonging to a given data set and associate it to the nearest centroid. When no point is pending, the first step is completed and an early groupage is done. At this point we need to re-calculate k new centroids as barycenters of the clusters resulting from the previous step After we have these k new centroids, a new binding has to be done between the same data set points and the nearest new centroid. A loop has been generated. As a result of this loop we may notice that the k centroids change their location step by step until no more changes are done. Finally, this algorithm aims at minimizing an objective function, in this case a squared error function. The objective function  k j n i j j i c x J 11 2  where  j j i c x is a chosen distance measure between a data point j i x and the cluster centre j c is an indicator of the distance of the n data points from their respective cluster centres Selecting circulation data as mining data sources, using the Microsoft Clustering algorithm to create a mining model BOOK_CLU, as shown in Fig.3. Viewing the model, it is characterized by various types of categories as following, B I and H are bibliography, illustrating in Fig.4  Figure 3  Reader clustering model  Figure 4  Category section Category1 Junior, B \(Philosophy\ books, Logistics Management major Category2 College senior, B \(Philosophy\ books Marketing major Category3 Sophomore, Financial major Category4 Freshman, I \(Literature\ books and H Language\ books Category5 F \(Economy\ books, Tourism Management major The results of the classification told us the readers are mainly clustered by grades and majors. The freshman usually borrows category I \(Literary\ and category H \(Language the distinction of major is not significant. The sophomore junior and senior are stronger clustered by majors additionally, junior and senior usually borrow category B Philosophy\ooks. It shows that, increasing with grade readersí borrowing trend to more associate with their majors 2  Finding out reader interesting by association rules Use association rules to find out the readers interest The association rules algorithm is finding frequent  itemsets common attribute value sets\. There are two steps in it. The first step of the algorithm, a calculation intensive phase, is to find frequent itemsets. The second step is to generate association rules based on frequent itemset  An itemset is a set of items. Frequent itemsets are those itemsets that are relatively popular in the dataset. The popularity threshold for an itemset is defined using Support  Support is used to measure the popularity of an itemset Support of an itemset A, B is made up of the total number of transactions that contain both A and B  Support \({A, B}\ = NumberofTransactions\(A, B   Minimum_Support is a threshold parameter you need to specify before processing an association model. It means that you are interested only in those itemsets and rules that represent at least minimum support of the dataset Probability is a property of an association rule. The probability of a rule A=>B is calculated using the support of itemset A, B divided by the support of A It is defined as follows Probability \(A => B\ = Probability \(B|A\ = Support \(A, B Support \(A   Minimum_Probability is a threshold parameter you need to specify before running the algorithm. It means that the user is interested in only those rules that have a high probability rather than a minimum probability Minimum_Probablity has no impact on itemsets, but it does impact rules Importance can be used to measure itemsets and rules The importance of an itemset is defined using the following formula Importance \({A,B}\ = Probability \(A, B\/\(Probability \(A Probability\(B   55 55 


If importance = 1  A and B are independent items. It means that A and B are two independent events. If importance < 1  A and B are negatively correlated. If importance > 1  A and B are positively correlated For rules, the importance is calculated using the following formula  Importance \(A => B\ = log \(p\(B|A\\(B|not A  An importance is 0 means that there is no association between A and B A positive importance score means that the probability of B goes up when A is true Select reader information, circulation and borrowing categories as the mining data source, set the value of Mininum_Support and Minimum_Probability as 0.2 and 0.6 use Microsoft Association Rules to create the data mining pattern, illustrating in Fig.5 Viewing the pattern, it is to generate frequent itemsets and rules as following Fig.6 and Fig.7 From the association rule in the mining result, Category I Literary\ is the biggest itemset, the following categories are History & Geography\, F \(Economy\, B Philosophy\, T \(Industry & Technology\d C \(Social Science\. The category I \(Literary\ has most strong relations with other categories, 75.5% of the readers who borrowed category I borrowed books belong to category K as well From the association rule in the mining result, Category I Literary\ is the biggest itemset, the following categories are History & Geography\, F \(Economy\, B Philosophy\, T \(Industry & Technology\d C \(Social Science\. The category I \(Literary\ has most strong relations with other categories, 75.5% of the readers who borrowed category I borrowed books belong to category K as well   Figure 5  Aassociation rules model  Figure 6  Frequent itemsets  Figure 7  Association rules result  Figure 8  Monthly circulation data time series pattern 3  The peaks and valleys analysis of circulation by Time Series Use Microsoft Time Series Algorithm to forecast the circulation variation tendency The Microsoft Time Series algorithm is a forecasting algorithm. It is a hybrid of the autoregression and decision tree techniques. An autoregressive process is one in which the value of x and time t\(xt is a function of the values of x at previous time, for example  Xt = f \(Xt-1,Xt-2,Xt-3,Xt-n t  where xt is the time series under investigation, and n is the order of autoregression ,which is generally much less than the length of the series. The last term, epsilon represents the noise. One of the key steps of this algorithm is to transform single cases of a time series into multiple cases internally Select monthly circulation data query as the mining date source, use Microsoft Time Series Algorithm to create the data mining pattern [5  i l l u str a ti n g in Fig.8 Vie w  the patter n result, monthly circulation data time series chart, illustrating in Fig.9 From the monthly circulation variation tendency analysis the first semester in academic year \(September to next January\ is more than the second semester \(March to July The later two months circulations are less then the first months. The Fig.9 shows the circulation in Jan. 2008 that forecasted by the pattern, the circulation will reduce close to the end of the semester III  C ONCLUSIONS AND FUTURE WORK  The results of the Cluster analysis reflect the category of the books that readers borrowing change with their grade The library can recommend books to the readers according to their classification The readers who borrow category I accounted for 75.5 while borrowed category K and 57% while borrowed 56 56 


category H. The 49% of the readers who borrow category F have borrowed category H. The library can establish the Recommended Book Information" and "associated bookshelf" for readersí selection by this association According to the Circulation data analysis on quarterly book borrowing, the second and fourth quarter is greater liquidity. First and third quarter includes holidays, the circulation in two months before each semester is greater than two months after the turnover. According to the characteristics of liquidity, arrange book purchasing shelving and maintenance Use the results of the analysis and data mining into data without the experimental to verify mining model to improve its accuracy. Considering about how to make data mining technology for library management of more humane, to research the readers need, motivation and tendency in depth Therefore, the expand collection of reader information is necessary R EFERENCES  1  Nicholson, S. The Bibliomining Process: Data Warehousing and Data Mining for Library Decision-Making. Information Technology and Libraries. 2003, 22\(4  2  Jiann-Cherng Shieh, Yung-Shun Lin. Bibliomining User Behaviors in the Library. Journal of Educational Media & Library Sciences.2006 44\(1\36-60 3  Hsiao-Tieh Pu. Explore improving the utilization of library resources by bibliomining. Journal of Library Association of the Republic of China.2006, pp.59-72 4  ZhaoHui Tang, Jamie MacLennan. Data Mining with SQL Server 2005.Wiley Publishing Inc, 2005, pp.230-238 5  Seth Paul, Jamie MacLennan, Zhaohui Tang.Data Mining Tutorial Microsoft Corporation.2005, pp.50-59   Figure 9  Monthly circulation data time series trend 57 57 


The performance of the proposed algorithm comparing with the other two algorithms when the size of quasi-identifier and the k value is varied is shown in Figure 3 and 4 respectively In Figure 3, it can be seen that all the three algorithms, i.e proposed approximation algorithm, optimal algorithm, and the MCCRT algorithm, generate the transformed datasets with almost the same CFCM when the size of quasi-identifier is varied. From Figure 4, we can see that the performance in term of CFCM of the approximation algorithm is almost the same as the optimal algorithm particularly when k value is low  25\The rationale behind this is the approximation factor which contains the k value. By the way, all the three algorithms generate the dataset with poor data utility when the k value is increased. These results are expectable since the algorithms are given the very strict optimization goal However, such high k values are rather not typically applied in practices as mentioned before. Note that it is also slightly better than the heuristic algorithm, MCCRT. We will investigate the efficiency of both algorithms further in subsequent section B  Efficiency The efficiency in term of execution time of the proposed algorithm is evaluated in this section. More specifically, we investigate the efficiency of the algorithm when the size of the datasets is varied. We fix the k value at 4, while, the size of the quasi-identifier is set at maximum   Figure 5. Execution time when D is varied   From Figure 5, we can see that the execution time of the proposed algorithm is significantly less than the execution of the optimal algorithm. However, it is still less efficient than the compared heuristic algorithm. However, such gap could be a trade-off in term of effectiveness in other cases. Since the heuristic algorithm can not guarantee the upper bound of the CFCM metric    V  C ONCLUSION  In this paper, an approximation data-transformation algorithm for privacy preservation in the context of associative classification has been proposed.  We have shown that the algorithm can achieve O  k log k imation factor in which when the k value is not high, such algorithm can perform almost as effective as the optimal algorithm. Also, the proposed algorithm is efficien t as it can be executed much efficient than the optimal algorithm and almost as efficient as the heuristic algorithm In our future work, we will focus on extend the algorithm to work on the other privacy models which are based on the k Anonymity e.g tcloseness  w h ich ai m s to m ai n tai n th e  distribution of the given dataset to provide privacy protection against particular attacks. Also, the algorithm will be improved in order to cope with \223on-line\224 environment where the data can be inserted at any time  A CKNOWLEDGMENT  We would like to thank Bowonsak Srisungsittisunti for providing the source code of the MCCRT algorithm and guide the algorithm-implementation based on his framework R EFERENCES  1  L  Sw e e ne y  223 k anonymity: a model for protecting privacy,\224 International Journal on Uncertainty, Fuzziness and Knowledge based Systems vol. 10 no. 5, pp. 557-570, 2002 2 A  M e y e rs on  an d  R  W i lli a m s  223On th e c o m p lexi t y o f op t i m a l k anonymity,\224 in Proceedings of the Twenty-third ACM SIGACTSIGMOD-SIGART Symposium on Principles of Database Systems pp 223-228, ACM Press,  2004 3 P  S a m a ra ti 223P rot e c t i n g res p o n d e nt s  id en ti ti es in m i c r o d a t a relea s e 224  IEEE Transactions on Knowledge and Data Engineering vol. 13 no. 6 pp. 1010-1027, 2001 4  B C F ung K  W a ng  a n d P  S  Y u  223 A no n y m i z i ng cl as s if i c a t io n  d a t a  for privacy preservation,\224 IEEE Transactions on Knowledge and Data Engineering vol. 19 no. 5, pp. 711-725, 2007 5  N  H a r n s a m u t, a n d J  N a tw ich a i 223A no v e l he ur is tic al g o r ithm f o r  privacy preserving of associative classification,\224 in PRICAI2008 Trends in Artificial Intelligence, Proceedings of the 10 th Pacific Rim International Conference on Artificial Intelligence pp. 273-283, 2008 6  N  H a r n s a m u t  J  N a tw ic ha i X  S u n  an d X  L i, \223 D at a Q u al ity i n P r iv acy  Preservation for Associative Classification,\224 in Proceedings of the 4 th  International Conference on Advanced Data Mining and Applications  pp. 111-122, 2008 7  G   A g gr aw al T   F e der  K   K e ntha pa di R   Mo tw ani  R  P a n ig r ahy  D   Thomas, and A. Zhu, \223Approximation Algorithms for k Anonymity\224 Journal of Privacy Technology November, 2005 8 V V Va z i ra ni   Approximation Algorithms Springer, 2004 9  K   Le F e vr e D  J  D e W i t t an d R  Ram a k r is hn an R  223I n c ogn i t o ef f i c i en t full-domain kanonymity,\224 in SIGMOD\222 05: Proceedings of the 2005 ACM SIGMOD International Conference on Management of Data pp 49-60, ACM Press, 2005 10  B. L iu, W  H s u, a n d Y  M a 223I nte g rati ng cl as s if ic a t io n a n d as s o c ia tio n  rule mining, \224 in Proceedings of the fourth ACM SIGKDD International Conference on Knowledge Discovery and Data Mining pp. 80-86 AAAI Press, 1998 11  N   L i, T   L i, and S  V e n k a tas ubr am a n i a n  223 C l o s e ne s s  A New P r iv acy  Measure for Data Publishing,\224 IEEE Transactions on Knowledge and Data Engineering to appear, 2009    0 100 200 300 400 500 600 700 800 683 1366 2732 4098 5464 6830 Time \(second Dataset Size Approximation Optimal MCCRT 


4 S  C h a k r a v a r t h y  J  M u t h u r a j  R  V a r a d a r a j a n  a n d S  N a v athe An objective function for vertically partitioning relations in distributed databases and its analysis Distributed and Parallel Databases  vol 2\(21 pp 183-207 1994 5 M  S  C h e n a n d J  H a n  P  S  Y u   D a t a m i n i n g  a n o v e r v i e w f r om a database perspective IEEE Trans on Knowledge and Data Engineering  vol 8 no 6 pp 866-883 1996 6 M  L  S h y u  S  C  C h e n  a n d R  L  K a s h y a p   G e n e r a l i z e d a f  nity-based association rule mining for multimedia database queries Knowledge and Information Systems  vol 3 pp 319-337 2001 7 G  T z a n i s a n d C  B e r b e r d i s   M i n i n g f o r m u t u a l l y e x c l u s i ve items in transaction databases International Journal of Data Warehousing and Mining  vol 3 no 3 2007 8 N  G o r l a a n d P  W  Y  B e t t y   V e r t i c a l f r a g m e n t a t i o n i n d a tabases using data-mining technique International Journal of Data Warehousing and Mining  vol 4 no 3 2008 9 J  D u  K  B a r k e r  a n d R  A l h a j j   A t t r a c t i o n  a g l o b a l a f  nity measure for database vertical partitioning in Proc of the IADIS Int Conf WWW/Internet  pp 538-548 2003 10 R  A g r a w a l a n d R  S r i k a n t   F a s t a l g o r i t h m s f o r m i n i n g a ssociation rules in Proc of the 20th Int Conf on Very Large Databases  1994 11 J  H  S o n a n d M  H  K i m   A n a d a p t a b l e v e r t i c a l p a r t i t i o n ing method in distributed systems J of Syst and Software  vol 73 pp 551-561 2004 12 M  T   z s u a n d P  V a l d u r i e z   Principles of distributed database systems  Third Edition Springer Heidelberg 2011 13 M  H  A l s u w a i y e l   A l g o r i t h m s  d e s i g n t e c h n i q u e s a n d a nalysis Lecture Notes Series on Computing  vol 7 World Scientic 1999 


B.  NFUP algorithm The basic idea of NFUP algorithm is similar to the FUP algorithm. Their difference is shown in follows: FUP algorithm using the original database to set DB mining results, that is frequent items Ls need for DB and db scan for n times, getting final frequent items L' of DBdb; And algorithm NFUP just scan DB for one time and db for several times. NFUP algorithm can improve efficiency by less scanning to DB's I/O operations. Apriori algorithm for db verifies whether the elements of L is he frequent item of dbDB, and generates the frequent items Ldb, then verifies whether elements of Ldb is the frequent items of dbDB through scanning of DB However, the premise of NFUP algorithm is frequent items known metadata DB and the support of elements Therefore, the theoretical NFUP efficiency is far more than that of FUP. In order to compare the two algorithms, the actual operation comparison will be shown in below. Hardware environment: the CPU is Intel p4 2.4 GHz; memory is DDR 1.0 GB. Software environment: Windows 2000 Server operation system, a programming language is Matlab 7.1. The original data DB exist in Boolean matrix form, which is nine project including 10 000 record. The new data base has 500 records \(about 850 KB and FUP is shown in figure 1, minimum support degree in the 20 percent and 80 percent    Figure 1 The comparison of the execution time among same database algorithms From figure 1, for the same database and support circumstances, the execution time of NFUP algorithm is reduced by 50% than FUP algorithm. NFUP algorithm is much fast than FUP algorithm when the support degree in 0.2 and 0.6 V.  CONCLUSIONS Now some algorithm of some existing frequent items has some missed questions, such as many candidate items, big space. The algorithm may reduce the mining efficiency when increasing scan db frequent items. Although algorithm is simple, its process carries on more effective pruning. This paper brings in some knowledge about association rule 


especially discussing the classic association rule of algorithm and mainly pointing out the analysis and conclusion of the FUP Minimum support degree The execution tim e\(in seconds and the IUA. Also two improved algorithm have been discussed in order to help the study of negative association rules for incremental updating   REFERENCES 1] Agrawal R.Srikant R. Fast algorithms for mining association rules in large database [A]. Proceedings of the 1994 International Conference on VLDB [C ]. San Francisco ?  Morgan Kaufmann Publishers 1994.pp487- 499 2] BrinS ? MotwaniR ? SilversteinC..Beyondmarket ? Generalizing association rules tocorrelations [A]. Processing of the ACMSIGMOD Conference 1997[C]. NewYork?ACMPress?1997. 265?276 3]  Hao Xincheng, Zhang Degang, Zhao Hai: E-commerce data mining research. Small Micro-computer Science[J], 2007\(7 4] HUANG De-cai, ZHANG Liang-yan, GONG Wei-hua, LIU Duan-yang Improved Incremental Updating Algorithm for Association Rules. The computer engineering[J], 2008\(5 in Chinese 5] Zhao Huanping: Web data mining and its application in e-commerce Fujian Computer [J].2008 \(1 in Chinese 6] Shi Yan: Applications of web mining techniques in e-commerce Scientific and Technological Information and Economic Development J] 2006 \(7 in Chinese 7] Ling Chuan-Fan: Web mining techniques applications in e-commerce Intelligence Journal [J] 2008 \(1 8] Witten I H?Frank E?Data Mining?Practical Machine LearningTools and Techniques[M]?2005 9] Margarent H?Dunham . Data Mining: A Tutorial-Based Primer  2005 10] J.B. Schafer, J.A. Konstan, and J.Rie1, Recommender Systems in ECommerce. In ACM Conference on Electronic Commerce \(EC99 11] YooJS,Shekhars,ClikM,A Join-less approach for co-location pattern miniing:a summary of rssults. Proceedings of the IEEE International Conference on Data Mining\(ICDM   


0 1 2 3 4 5 2 3 4 5 6 average error\(distance MinTs STT HPM a Prediction performance comparison 0 200 400 600 800 1000 1200 1400 2 3 4 5 6 storage size\(MB MinTs STT HPM b Storage requirements comparison Fig 9 Prediction model comparison DBSCAN clustering may result in clusters of arbitrary shapes and sizes while the error of STT is restricted by the 003xed cell size C Storage Requirements Comparison We next study the storage requirements comparison of STT with HPM As expected Figure 9\(b demonstrates that our method has smaller storage size than HPM While the storage size of HPM dramatically grows with the number of frequent regions increases our method STT still remains the small storage size with tiny changes The reason is that HPM using association rule based patterns generates the exponential number of rules as the number of frequent regions increases On the contrary STT using data structure of suf\003x tree can compress the number of sequential patterns into a compact model D Sensitivity Analysis of Parameters In this section we examine the effect of cell size and MinTs to our model and prediction Figure 11 presents the experimental results with cell size varied The number of trajectory patterns decreases dramatically as the value of cell size grows Furthermore the prediction error affected by cell size is provided in Figure 11 The prediction error potentially rises as the cell size increases We also investigate the effect of MinTs  In our de\003nition a frequent region is decided by MinTs number of trajectories pass the region in a cell size Therefore a high value of 0 2000 4000 6000 8000 10000 12000 0.006 0.009 0.012 0.015 0.018 0.021 0.024 0.027 number of patterns cell size a Car 0 2000 4000 6000 8000 10000 12000 0.006 0.009 0.012 0.015 0.018 0.021 0.024 0.027 number of patterns cell size b Bike 0 50 100 150 200 250 300 0.006 0.009 0.012 0.015 0.018 0.021 0.024 0.027 number of patterns cell size c Run 0 200 400 600 800 1000 0.006 0.009 0.012 0.015 0.018 0.021 0.024 0.027 number of patterns cell size d Walk Fig 10 Effect of cell size on number of patterns 0.6 1 1.4 1.8 2.2 2.6 3 0.006 0.009 0.012 0.015 0.018 0.021 0.024 0.027 average error\(distance cell size a Car 0.6 1 1.4 1.8 2.2 2.6 3 0.006 0.009 0.012 0.015 0.018 0.021 0.024 0.027 average error \(distance cell size b Bike 0.6 0.8 1 1.2 1.4 1.6 1.8 0.006 0.009 0.012 0.015 0.018 0.021 0.024 0.027 average error\(distance cell size c Run 1.2 1.4 1.6 1.8 2 2.2 0.006 0.009 0.012 0.015 0.018 0.021 0.024 0.027 average error\(distance cell size d Walk Fig 11 Effect of cell size on prediction error MinTs may cause a small number of frequent regions and trajectory patterns Prediction based on trajectory patterns could be affected by MinTs  As the results shown in Figure 12 the number of trajectory patterns is reduced as the number of MinTs increases The prediction error increases signi\003cantly due to the small number of trajectory patterns as shown in Figure 13 VII C ONCLUSION In this paper we presented a pattern-based approach to predict an objectês future locations We not only focus on that how to discover frequent movement patterns and manage these patterns to answer predictive queries but also aim to propose 
60 
66 
66 


0 500 1000 1500 2000 2500 3000 3500 2 4 6 8 10 number of patterns MinTs a Car 0 500 1000 1500 2000 2500 3000 3500 2 4 6 8 10 number of patterns MinTs b Bike 0 500 1000 1500 2000 2500 3000 3500 2 4 6 8 10 number of patterns MinTs c Run 0 500 1000 1500 2000 2500 3000 3500 2 4 6 8 10 number of patterns MinTs d Walk Fig 12 Effect of MinTs on number of patterns 0.6 1 1.4 1.8 2.2 2.6 3 2 4 6 8 10 average error\(distance MinTs a Car 0.6 1 1.4 1.8 2.2 2.6 3 2 4 6 8 10 average error\(distance MinTs b Bike 0.6 1 1.4 1.8 2.2 2.6 3 2 4 6 8 10 average error\(distance MinTs c Run 0.6 1 1.4 1.8 2.2 2.6 3 2 4 6 8 10 average error\(distance MinTs d Walk Fig 13 Effect of MinTs on prediction error a model that can reduce the pattern storage size To achieve this idea we propose a spatial-temporal trajectory model to capture an objectês moving behavior and STT model could be a predictor to forecast its future locations Experimental results show that the STT model is able to re\002ect an objectês moving behavior with a smaller storage size compared to existing patten-based approaches while still guaranteeing the accuracy of location prediction Acknowledgments Wen-Chih Peng was supported in part by the National Science Council Project No 97-2221-E009-053-MY3 by Taiwan MoE ATU Program by ITRIJRC Project No 100-EC-17-A-05-01-0626 by D-Link and by Microsoft R EFERENCES  H Jeung Q Liu H T  Shen and X Zhou A Hybrid Prediction Model for Moving Objects in Proc of ICDE  2008 pp 70Ö79  A Monreale F  Pinelli R T r asarti and F  Giannotti Wherene xt a location predictor on trajectory pattern mining in Proc of KDD  2009 pp 637Ö646  M Morzy   Mining frequent trajectories of mo ving objects for location prediction in Proc of MLDM  2007 pp 667Ö680  W C Peng Y  Z K o  a nd W  C Lee On Mining Mo ving P atterns for Object Tracking Sensor Networks in Proc of MDM  2006 pp 41Ö44  N Mamoulis H Cao G K ollios M Hadjieleftheriou Y  T ao and D W  Cheung Mining Indexing and Querying Historical Spatiotemporal Data in Proc of KDD  2004 pp 236Ö245  C.-W  C  C.-C Hung and W C Peng Mining trajectory pro\003les for discovering user communities in Proc of GIS-LBSN  2009 pp 1Ö8  J Krumm and E Horvitz Predestination Inferring destinations from partial trajectories in Proc of UbiComp  2006 pp 243Ö260  F  Giannotti M Nanni F  Pinelli and D Pedreschi T rajectory P attern Mining in Proc of KDD  2007 pp 330Ö339  T  Guyet and R Quiniou Mining temporal patterns with quantitati v e intervals in Proc of ICDM Workshops  2008 pp 218Ö227  F  V e rhein k-ST ARs Sequences of Spatio-T emporal Association Rules in Proc of ICDM Workshops  2006 pp 387Ö394  F  V e rhein and S Cha wla Mining spatio-temporal association rules sources sinks stationary regions and thoroughfares in object mobility databases in Proc of DASFAA  2006 pp 187Ö201  H Jeung H T  Shen and X Zhou Mining T rajectory P atterns Using Hidden Markov Models in Proc of DaWaK  2007 pp 470Ö480  Y  Ishika w a  Y  T sukamoto and H Kitaga w a   Extracting mobility statistics from indexed spatio-temporal datasets in Proc of STDBM  2004 pp 9Ö16  H.-P  T sai D.-N Y ang W  C Peng and M.-S Chen Exploring Group Moving Pattern for an Energy-Constrained Object Tracking Sensor Network in Proc of PAKDD  2007 pp 825Ö832  H Cao N Mamoulis and D W  Cheung Mining Frequent SpatioTemporal Sequential Patterns in Proc of ICDM  2005 pp 82Ö89  F  Giannotti M Nanni and D Pedreschi Ef 003cient Mining of T emporally Annotated Sequences in Proc of SDM  2006 pp 593Ö597  A Hinneb ur g and D A K eim  A n e f 003 cient approach to clustering in large multimedia databases with noise in Proc of KDD  1998 pp 58Ö65  P  Sun S Cha wla and B Arunasalam Mining for outliers in sequential databases in Proc of SDM  2006  J Y a ng and W  W ang  A gile A General Approach T o Detect T r ansitions In Evovling Data Streams in Proc of ICDM  2004 pp 559Ö562  G Bejerano and G Y ona Modeling protein f a milies using probabilistic suf\003x trees in Proc of RECOMB  1999 pp 15Ö24  D Ron Y  Singer  and N T ishby  The Po wer o f Amnesia Learning Probabilistic Automata with Variable Memory Length Machine Learning  vol 25 no 2-3 pp 117Ö149 1996  B Ostle and L Malone Statistics in research basic concepts and techniques for research workers  Iowa State Press 1988  C.-H Lo W  C Peng C.-W  C hen T  Y  Lin and C.-S Lin CarW eb A Traf\003c Data Collection Platform in Proc of MDM  2008 pp 221 222 
61 
67 
67 


i?{i? |?R?Rel R\(f,i i ratioocc\(u, i 1 2 where ratioocc\(u, i instance i among the instances of the same concept in the users history D. Frequency Module This module aims at detecting the frequent instances and the frequent associations of instances. Indeed, such a frequency depicts an important interest of the user for the concerned instances. Consequently, it is relevant to recommend items with these characteristics to the user 1 considers the profile of the user. It aims at detecting the most important features of interest for the user Regardless of the estimated interest of an instance for a user, we consider that if the user has in his history a significant percentage of items which have as a feature that particular instance, the interest of this instance is significant Unlike the previous computation, this computation ignores the users ratings for the items which have the instance as a feature Example: A user who has watched 80% of the films interpreted by the actor Tom Hanks should get the recommendation of the other 20% he has not seen even if some of the films of Tom Hanks in his history are badly rated 2 case with frequent instances described above, this part of the module deals not only with the profile of the user, but also with the set of items. It aims at discovering frequent associations between the features in the user history. It detects the features that often occur together in order to discover new recommendations. To achieve this, frequent sets of the instances related to the items in the users history are computed. Then, items with such instances are recommended to the user Example: A possible frequent association is the actor Johnny Depp and the director Tim Burton. A user who is interested in these two instances will be recommended the other films related to them E. Recommendation and explanation 


As explained in Sect. II, the collaborative and the semantic modules are in cascade. Consequently, the result is a set of recommendations rec1 which is mixed with the recommendations of the frequency module rec2 such that rec1 is presented before rec2 to the user. This order can be inverted according to user feedback. Concerning the explanation of the recommendations, this is done by highlighting the instances which have highly scored the interest of the user for the items of rec1, and by highlighting the frequent instances in the items of rec2 F. Example In this section, we illustrate the recommendation process for any user u, in the movie domain. We will simplify to preserve the clarity of the example 2010 10th International Conference on Intelligent Systems Design and Applications 473 Table I EXTRACT OF THE PROFILE OF THE USER u Film Rating Transformation Psycho 5 Psychol Rear Window 4 Rear Windowl Four Weddings and a Funeral 4 Four Weddings and a Funerall Monty Pythons Life of Brian 5 Monty Pythons Life of Brianl Carrie 3 Carried Stephen Kings The Langoliers 1 Stephen Kings The Langoliersd Pulp Fiction 4 Pulp Fictionl Dr. Strangelove 2 Dr. Strangeloved A Clockwork Orange 1 A Clockwork Oranged Let us consider u who has rated the movies in Tab. I Collaborative Filtering Module: Let us assume that the association rule mining result is r1 : {Psychol, Pulp Fictionl} ? {The Shiningl r2 : {Pulp Fictionl,Monty Pythons Life of Brianl Monty Python and the Holy Graill r3 : {Monty Python and the Holy Graill, Jurassic Parkl Indiana Jones and the Last Crusadel According to the rules introduced in Sect III-B2, we only keep the association rules r1 and r2 Semantic-Based Module: In this step, the interest of the user for each movie in the head of each rule from the last module is computed. The concerned movies are The Shining and Monty Python and the Holy Grail For The Shining, we obtain the following interest re 


sults conceptInterestActor \(u, TheShining conceptInterestDirector \(u, TheShining conceptInterestWriter \(u, TheShining conceptInterestGenre \(u, TheShining Unlike the prediction of the previous modules, it seems that The Shining is not a good recommendation for u Actually, this film shares its director with Dr. Strangelove and A Clockwork Orange which are negatively rated by u Moreover, it has a writer in common with Carrie and The Langoliers which are also movies disliked by u. The same reasoning is made about the concepts Actor and Genre Concerning Monty Python and the Holy Grail, the interests by concept are conceptInterestActor \(u, HolyGrail conceptInterestDirector \(u, HolyGrail conceptInterestWriter \(u, HolyGrail conceptInterestGenre \(u, HolyGrail This recommendation is a good one. The film shares its actors, writers and director with Monty Pythons Life of Brian which is highly rated by the user. The recommendation is thus justified Figure 3. Extract of the movie ontology Frequency Module: Let us assume that the user rated 60% of Alfred Hitchcocks films \(in Tab. I, Psycho and Rear Window are some of them recommended to u IV. EXPERIMENTAL EVALUATION A. Ontology Description For the experimentation, we built the ontology manually see Fig. 3 IMDB8. We focused only on a set of data which led to the concepts Film, Person, Actor, Director, Writer and Genre The connections between these concepts are Each movie is related to a certain number of persons who can be actors, directors or writers but it can also be related to other movies \(Example: Free Willy 2: The Adventure Home and Free Willy 3: The Rescue are related A person and a movie have a genre \(Action, Adventure Animation, Children, Comedy, Crime, etc B. Experimentation and Evaluation 


We use a subset of the dataset provided by MovieLens, the recommender system of GroupLens Research. The dataset contains a set of users, the set of items they have evaluated with a rating between 1 \(for the least liked for the most liked framework, we deal with a set of 86 movies, 934 users and 13 053 ratings. The dataset contains 3593 actors, 77 directors, 275 writers and 17 genres Using a 65% confidence and a 5% support, association rule mining resulted in 1472 rules after running the collaborative module. We evaluated the results obtained from the system by eighteen 20-50-year-old volunteers. The evaluation consisted exclusively in explicit valuations \(ratings 8http://www.imdb.com 474 2010 10th International Conference on Intelligent Systems Design and Applications Figure 4. Users evaluation of the system between 1 and 5 rated at the beginning between 11 and 31 films. For each recommended item, the user rates it as liked or disliked. If an item is rated as liked, the recommendation is considered as accurate. Otherwise, the system explains the reason why this item is recommended. The user can then agree with this explanation or not. Explanation of recommendation can be effective in convincing users in their appreciation of the items [24]. In our approach, the explanation aims at discovering if the detected patterns in the recommended item are accurate or not. Let us consider the following explanation in the recommendation of a film: This film may interest you because you frequently watched Tim Burtons films with Johnny Depp. If the user agrees with the explanation, that means that the association \(Tim Burton - Johnny Depp relevant but this particular film do not appeal to the user Otherwise, we consider that the detected association was purely a coincidence. In this case, the system will be able to ignore this pattern for this user in the future The results of this evaluation are depicted on Fig. 4. We can see that 84,9% of the recommendations satisfy the users Concerning the recommendations rated as disliked, 59,4% of the explanations are approved by users. Finally, 93,9% of the recommendations are satisfying or approved An average of 5 recommendations is obtained by running the collaborative and the semantic-based modules \(which is 


acceptable due to the low number of movies  86  in the dataset frequency module. This difference is due to the fact that the cascading modules \(collaborative and semantic-based are limited by the unique usage of the ratings to compute the association rules. The frequency module, on the other hand, is based on a statistical analysis of the item contents Consequently, it does not suffer from the sparsity of the user rating matrix like the previous modules The collaborative module results in some recommendations which are not liked by users. Fortunately, such recommendations are eliminated by the semantic-based module Other recommendations are eliminated by the semanticbased module though they appeal to users. We explain this because the concerned items dont share any features with the ones in the users history. This is why, we aim at introducing a semantic similarity measure to alleviate this problem \(see Sect. V module recommendations and 58,1% of the explanations of the disliked recommendations, satisfy the users. We can conclude that the combination of all the modules results in better recommendations V. CONCLUSION AND FUTURE WORK In our work, we propose a hybrid recommender system that combines collaborative filtering and semantic analysis of the items. The approach is based on many modules that refine the rules which progressively lead to a recommendation. A process targeting users with various interests is described. First, the collaborative filtering step is achieved using association rule mining which is a flexible way to classify the user. His history is then used to make the results more adapted to him. The semantic module aims at refining the recommendation issued from the rules. Finally, a frequency module is used to discover other items of interest for the user. Using distinct modules allows us to explain the recommendations to the user The results we have obtained from the evaluation experiments are promising. The combination of the collaborative and semantic modules improves the quality of the recommendations and the frequency module adds new ones. 93,9 of the recommendations are satisfying or approved In near future, we aim at defining the approach to learn 


the user profile in order to adapt the combination of the recommendation modules. We also plan to improve the semantic module by defining the semantic similarity between instances [25], [26]. Thus, when computing the interest by instance, those which are semantically similar to the current instance can be used when the instance is not present in the users history This similarity could also be used during the personalization of the association rules. The personalization rule \(a which consists in only keeping the rules which have a body composed of items contained in the users history, can be relaxed if the items violating \(a the items in the users history. The advantage of the semantic similarity is that it can be computed off-line which does not slow down the recommendation process Another improvement we want to introduce is the use of implicit data collected and based on the users behavior e.g. his search history, the time he spent looking at an item and his navigational patterns. This will help to increase the knowledge about the user and, in turn, lead to a better understanding of his expectations Finally, we plan to experiment the framework on other domains to confirm the domain-independence of the system REFERENCES 1] G. Adomavicius and A. Tuzhilin, Toward the next generation of recommender systems: A survey of the state-of-the-art and 2010 10th International Conference on Intelligent Systems Design and Applications 475 possible extensions, IEEE Trans. Knowl. Data Eng., vol. 17 no. 6, pp. 734749, 2005 2] R. Burke, Hybrid recommender systems: Survey and experiments, User Modeling and User-Adapted Interaction vol. 12, no. 4, pp. 331370, 2002 3] K. Lang, Newsweeder: Learning to filter netnews, in Proceedings of the 12th International Machine Learning Conference \(ML, 1995 4] M. J. Pazzani and D. Billsus, Content-based recommendation systems, in The Adaptive Web, P. Brusilovsky, A. Kobsa, and W. Nejdl, Eds., 2007, vol. 4321, pp. 325341 5] P. Resnick, N. Iacovou, M. Suchak, P. Bergstrom, and J. Riedl Grouplens: An open architecture for collaborative filtering of netnews, in Proceedings of ACM 1994 Conference on Computer Supported Cooperative Work, Chapel Hill, North 


Carolina, 1994, pp. 175186 6] B. Sarwar, G. Karypis, J. Konstan, and J. Reidl, Itembased collaborative filtering recommendation algorithms, in Proceedings of the 10th international conference on World Wide Web \(WWW 295 7] B. Sarwar, G. Karypis, J. Konstan, and J. Riedl, Analysis of recommendation algorithms for e-commerce, in Proceedings of the 2nd ACM conference on Electronic commerce \(EC Minneapolis, Minnesota, USA, 2000, pp. 158167 8] M. Balabanovic and Y. Shoham, Fab: content-based, collaborative recommendation, Commun. ACM, vol. 40, no. 3, pp 6672, 1997 9] D. Billsus and M. J. Pazzani, User modeling for adaptive news access, User Modeling and User-Adapted Interaction vol. 10, no. 2-3, pp. 147180, 2000 10] M. J. Pazzani, A framework for collaborative, content-based and demographic filtering, Artif. Intell. Rev., vol. 13, no. 5-6 pp. 393408, 1999 11] S. Castagnos, A. Brun, and A. Boyer, Probabilistic association rules for item-based recommender systems, in Proceedings of the Fourth Starting AI Researchers Symposium STAIRS 12] W. Lin, Association rule mining for collaborative recommender systems, Masters thesis, Faculty of the Worcester Polytechnic Institute, 2000 13] J. J. Sandvig, B. Mobasher, and R. Burke, Robustness of collaborative recommendation based on association rule mining, in Proceedings of the 2007 ACM conference on Recommender systems \(RecSys 14] B. Mobasher, H. Dai, T. Luo, and M. Nakagawa, Effective personalization based on association rule discovery from web usage data, in Proceedings of the 3rd international workshop on Web information and data management \(WIDM Georgia, USA, 2001, pp. 915 15] R. Agrawal, T. Imielinski, and A. Swami, Mining association rules between sets of items in large databases, in Proceedings of the 1993 ACM SIGMOD international conference on Management of data, New York, NY, USA, 1993, pp. 207 216 16] B. Liu, W. Hsu, and Y. Ma, Integrating classification and association rule mining, in Knowledge Discovery and Data 


Mining, New York City, New York, USA, Aug. 1998, pp 8086 17] Y. Blanco-Fernandez, J. J. P. Arias, A. Gil-Solla, M. R Cabrer, M. L. Nores, J. G. Duque, A. F. Vilas, R. P. D Redondo, and J. B. Munoz, A flexible semantic inference methodology to reason about user preferences in knowledgebased recommender systems, Knowl.-Based Syst., vol. 21 no. 4, pp. 305320, 2008 18] S. E. Middleton, H. Alani, N. R. Shadbolt, and D. C. D Roure, Exploiting synergy between ontologies and recommender systems, in Semantic Web Workshop 2002 At the Eleventh International World Wide Web Conference, 2002 19] M. Zanker and M. Jessenitschnig, Case-studies on exploiting explicit customer requirements in recommender systems User Modeling and User-Adapted Interaction, vol. 19, no 1-2, pp. 133166, 2009 20] N. Ducheneaut, K. Partridge, Q. Huang, B. Price, M. Roberts E. H. Chi, V. Bellotti, and B. Begole, Collaborative filtering is not enough? experiments with a mixed-model recommender for leisure activities, in Proceedings of the 17th International Conference on User Modeling, Adaptation, and Personalization \(UMAP 21] H. Nguyen and P. Haddawy, The decision-theoretic interactive video advisor, in Proceedings of the Fifteenth Conference on Uncertainty in Artificial Intelligence \(UAI 494501 22] B. Mobasher, Data mining for web personalization, in The Adaptive Web, ser. Lecture Notes in Computer Science P. Brusilovsky, A. Kobsa, and W. Nejdl, Eds. Springer Berlin Heidelberg, 2007, vol. 4321, ch. 3, pp. 90135 23] T. R. Gruber, A translation approach to portable ontology specifications, Knowl. Acquis., vol. 5, no. 2, pp. 199220 1993 24] N. Tintarev and J. Masthoff, The effectiveness of personalized movie explanations: An experiment using commercial meta-data, in Proceedings of the 5th international conference on Adaptive Hypermedia and Adaptive Web-Based Systems AH 25] R. Albertoni and M. D. Martino, Asymmetric and contextdependent semantic similarity among ontology instances Journal on Data Semantics, vol. 10, pp. 130, 2008 26] X. Jin and B. Mobasher, Using semantic similarity to 


enhance item-based collaborative filtering, in 2nd IASTED International Conference on Information and Knowledge Sharing, Scottsdale, Arizona, 2003 476 2010 10th International Conference on Intelligent Systems Design and Applications 


Basi Association Rles Basi c  Association R u les Association is basically connecting or tying up occurrences of Association is basically connecting or tying up occurrences of events Ol dib t f ilt t O n l y d escr ib e se t s o f s i mu lt aneous even t s Cannot describe patterns that iterate over time e g  itemset a  0  b  0  g    Eg If you sense higher data rates on the downlink than normal AND New Route generated Implies high chances of Intrusion AND New Route generated Implies high chances of Intrusion Associative IDS for NextGen Frameworks Dr S Dua LA Tech 20 


Enhanced Inte r transaction Association Rules Enhanced Inter transaction Association Rules Enhanced Inter transaction Association Rules Extension of association rules Conditional relationships at multiple different time steps e.g itemset a\(0 0 1 2 You sense Higher data rate than normal AND You see New Route g enerated AND 1 minute a g o you detected checksum gg error packets AND 2 minutes ago your encountered wrong checksum   Implies High Chance of Intrusion Enhanced Rules and Confidence Associative IDS for NextGen Frameworks Dr S Dua LA Tech 21 


Complex Spatio temporal Association Complex Spatio temporal Association Rules Further extension of inter transaction association rules Describe event durations e.g itemset a\(0,X j,Y k,Z Eg  You sense high data rates for X seconds AND new route generated j minutes ago task completed in Y AND new route generated j minutes ago task completed in Y seconds AND checksum error packets received k minutes ago for Z seconds High Chance of Intrusion With highest confidence level in association rules  association rules  Associative IDS for NextGen Frameworks Dr S Dua LA Tech 22 


DMITAR Al ith ARD DMITAR Al gor ith m  ARD Problem Domain Problem Statement and Challenges Aiti Miig bd IDS A ssoc i a ti ve Mi n i n g b ase d IDS  Introduction to data mining Association rule in data mining DMITAR Algorithm  ARD New research Associative IDS for NextGen Frameworks Dr S Dua LA Tech 23 


DMITAR Algorithm DMITAR Difference Matrix Based Inter Transaction Association Rule Miner developed in DMRL Uses vertical data format Differences of the transaction IDs are used to generate extended itemsets Windowless mechanism Associative IDS for NextGen Frameworks Dr S Dua LA Tech 24 


Deep into the Mechanism The DMITAR algorithm is based on lhilii comp l ex mat h emat i ca l assoc i at i ve formulation and proofs Four major parts Four major parts Frequent 1 itemset generation Frequent 2 itemset generation Frequent k itemset generation k>2 Spatio temporal rule formation Associative IDS for NextGen Frameworks Dr S Dua LA Tech 25 


DMITAR, Datasets Used Stock Data Stock Data Daily stock information provided by Yahoo finance Wth Dt W ea th er D a t a Provided by the US Department of Commerce and National Climactic Data Center for 700 locations across US Synthetic Data Provided by a CRU weather generator that uses a Markov chain model to generate simulated weather data for 11 UK sites Associative IDS for NextGen Frameworks Dr S Dua LA Tech 26 


DMITAR Results 1/5 Varying Support DMITAR Results 1/5 Stock Database Support FITI ITPMine PROWL DMITAR 14 6424.7s 132.39s 3.03s 5.556s 16 2348.9s 67.14s 2.14s 4.015s 18 861.92s 34.62s 1.55s 2.89s 20 334.51s 18.89s 1.12s 2.07s 22 143 84s 10 87s 0 87s 1 45s 22 143  84s 10  87s 0  87s 1  45s 24 63.62s 7.15s 0.671s 1.04s Weather Database Support FITI ITPMine PROWL DMITAR 14 36362.6s 893.1094s 5.843s 19.8281s 36362.6s 893.1094s 5.843s 19.8281s 16 11913.04s 378.2188s 3.8906s 13.4375s 18 4116s 170.3438s 2.75s 9.1406s 20 1507s 86.5781s 2.14s 6.203s 22 859.2813s 63.3438s 1.7969s 5.7656s 24 378.5313s 36.1875s 1.4375s 3.5625s Synthetic Dataset Support FITI ITPMine PROWL DMITAR 14 1651.6s 199.843s 3.1406s 17.015s 16 574 32 119 32 2 0938 10 875 16 574  32 s 119  32 s 2  0938 s 10  875 s 18 416.109s 95.31s 1.6094s 7.39s 20 370.25s 83.31s 1.453s 5.8438s 22 265.78s 66.3438s 1.3594s 4.75s 24 133.96s 43.0781s 0.9219s 3.5781s 


DMITAR Rlt  DMITAR  R esu lt s 2  5 Rules Formed Associative IDS for NextGen Frameworks Dr S Dua LA Tech 28 


DMITAR Rl  Varying Maxspan DMITAR  R esu l ts 3  5 Varying Maxspan Associative IDS for NextGen Frameworks Dr S Dua LA Tech 29 


DMITAR Res lts 4/5 Vig Di i DMITAR  Res u lts  4/5 V ary i n g Di mens i ons Associative IDS for NextGen Frameworks Dr S Dua LA Tech 30 


DMITAR Rl  Varying Number of Transactions DMITAR  R esu l ts 5  5 Varying Number of Transactions Associative IDS for NextGen Frameworks Dr S Dua LA Tech 31 


N/C t Rh N ew C urren t R esearc h Problem Domain Problem Statement and Challenges Associative Mining based IDS Associative Mining based IDS Introduction to data mining ii lid ii Assoc i at i on ru l e i n d ata m i n i ng DMITAR Algorithm  ARD h New Researc h Associative IDS for NextGen Frameworks Dr S Dua LA Tech 32 


Further Research Further Research Objectives of Our Intrusion Detection System Development Objectives of Our Intrusion Detection System Development 1 Refine and scale the DMITAR algorithm to suit our application 2 Develop methods for dynamically altering the sensor parameters Our Focus is Securing the NextGen Frameworks with New Technology Technology Associative IDS for NextGen Frameworks Dr S Dua LA Tech 33 


Simulated Sensing Environment Simulated Sensing Environment Screenshots of Data C ollected from S ynthetic Sensors Screenshots of Data C ollected from S ynthetic Sensors Simulated in Our Laboratory Three Steps Slides Collect data Collect data from all sources  all attributes  Select Select the source and their hierarchical attributes attributes to be monitored and Select Select the source and their hierarchical attributes attributes to be monitored  and Sample Sample them at different rates different rates and process them Associative IDS for NextGen Frameworks Dr S Dua LA Tech 34 


Data Collection Simultaneous collection of data screen from ENTITIES aircrafts Associative IDS for NextGen Frameworks Dr S Dua LA Tech 35 Source PRTG Network Monitor software screen shot Demo info www.paessler.com 


Parameter Selection Selection of an ENTITY/aircraft and monitoring its parameters and sensor readings Associative IDS for NextGen Frameworks Dr S Dua LA Tech 36 Source PRTG Network Monitor software screen shot Demo info www.paessler.com 


Sensor Sampling Selecting one sensor/probe and reading it at different resolutions or sampling rates Associative IDS for NextGen Frameworks Dr S Dua LA Tech 37 Source PRTG Network Monitor software screen shot Demo info www.paessler.com 


Si l ti Nt k Si mu l a ti on on N e t wor k Most scenarios can be simulated on a computer or computer network network  The aircrafts and sensors are simulated on a computer network bllb b y ana l ogica l su b stitutions Sensors provide information at different rates Sensors provide information at different rates Need Based Sensor Prioritization NSP and Dynamic Sensing Rate Sampling Associative IDS for NextGen Frameworks Dr S Dua LA Tech 38 


Vulnerability Search Scan 39 Sample UQA script with Nmap performed in DMRL Associative IDS for NextGen Frameworks Dr S Dua LA Tech 39 Source Nmap screenshot with a pearl script  Find Namp on Nmap.org 


Modality Aspect Modality Aspect A Multimodal distribution is a continuous probability distribution with two or more modes of underlying data Mltil d i M u lti p l e mo d es i n our model Associative IDS for NextGen Frameworks Dr S Dua LA Tech 40 Source http://en.wikipedia.org/wiki/File:Bimodal bivariate small.png 


Multi Modality Modality Fusion 41 SENSITIVE  UNCLASSIFIED For Official Use Only Associative IDS for NextGen Frameworks Dr S Dua LA Tech 41 


Emphasis Emphasis Our approach emphasizes on pre empting the attack Our intent is NOT to perform an autopsy to discover attacks Instead we aim to detect and prevent in attacks in real time Associative IDS for NextGen Frameworks Dr S Dua LA Tech 42 


Techniques for Discriminative Rules Techniques for Discriminative Rules Resolution Analysis Features Analyzed at Different Depths Anti Monotonic Principle Modality Aspect Treading into Unexplored Feature spaces Associative IDS for NextGen Frameworks Dr S Dua LA Tech 43 


Representative Outcomes Representative Outcomes Illustration of the Final Analysis Our method shifts between modalities and sampling rates for optimization The blue parallelograms are actual intrusions 44 The blue parallelograms are actual intrusions The Red Green Blue Plots are response of system Associative IDS for NextGen Frameworks Dr S Dua LA Tech 44 


Advantages of Our M ethod Advantages of Our M ethod Exploit the memory v ertical data format utilizes slidin g windows to g form a much larger database to analyze  Flexibility in Choosing what to choose  Choosing what to choose to build the rules Computational and memory efficiency We have a team working only on this aspect 45 Associative IDS for NextGen Frameworks Dr S Dua LA Tech 45 


Preliminary Results Intra transaction Relations Data rate simulator NH-134 Mb HOP PATH update \(Y/N Inference 11.5 Y Y 2 0.120 N N      Y   n 0.345 N NH134 Y/N   Inf 1 0.150 N N 2 0 120 Y N Inter transaction Relations 2 0  120 Y N       5 5.55 0.456 Y Relations  n 0.345 N N Nmap on DMRL nmap.org 


Anticipated Outcome Anticipated Outcome Develop algorithm capable of learning from a given heterogeneous diverse Develop algorithm capable of learning from a given heterogeneous diverse data ff Dynamic algorithmic f ramework designed to shi f t modalities and sampling rates based on complex logic Flexibility of integration into the Snort intrusion detection system 47 Associative IDS for NextGen Frameworks Dr S Dua LA Tech 47 


References References Aircraft Cockpit Image courtesy USAF http://www.faa.gov htt p   www.faa g ov  air traffic  technolo gy  p g  _ gy  Acharya R Dua S Du X Sree V Chua C K Automated Diagnosis of Glaucoma Using Texture and Higher Order Spectra Features To appear in IEEE Transactions on Information Technology in Biomedicine  Du X Dua S 2011 Cancer Prognosis Using Support Vector Regression in Imaging  Modality World Journal of Clinical Oncology 2  1   44 49 Du X Dua S 2010 Salient Frame Extraction Using Support Vector Regression and Motion Features pp 5 Proc of the National Aerospace and Electronics Conference July 14 16 2010 D M P D S 2010 Di i i ti Ft d Cl ifi ti Mthd f D essaue r  M  P  D ua S  2010  Di scr i m i na ti ve F ea t ures an d Cl ass ifi ca ti on M e th o d s f or Accurate Classification 1st ed vol 7704 pp 14 Bellingham WA Proceedings of SPIE Dessauer M P Dua S 2010 Low Resolution Vehicle Tracking using Dense and Reduced Local Gradient Features Maps 1st ed vol 7694 pp 8 Bellingham WA Proceedings of SPIE SPIE 


Acknowledgements Acknowledgements Fundin g A g encies  US 4 1 Million direct fundin g g g 4 g LA BoR NIH NSF AFRL AFOSR and NASA Research Team Samuel Kasimalla Brandy McKnight Dr Pradeep Chowriappa Connor Johnson Vasanth Nair Mihir Chowriappa  Connor Johnson  Vasanth Nair  Mihir Karnik Mohit Jain and Swadheen Songmen Associative IDS for NextGen Frameworks Dr S Dua LA Tech 49 All the respective Logos belong to their owners 


Rf d Rdi R e f erence d R ea di ngs Copyright of cover pages held by respective publishers 


Thank You Questions Thank You  Questions Dr Sumeet Dua E mail sdua@latech.edu Web http://dmrl.latech.edu Associative IDS for NextGen Frameworks Frameworks Dr S Dua LA Tech 51 Image Source roadtrafficsigns.com 


