Greenhouse Monitoring with Wireless Sensor Network Teemu Ahonen Reino Virrankoski and Mohammed Elmusrati University of Vaasa Department of Computer Science Telecommunication Engineering Group P.O Box 700 FI-65101 Vaasa Finland Tel 358-6-324 8111 Fax 358-6-324 8677 teemu.ahonen reino.virrankoski mohammed.elmusrati}\(uwasa.fi Abstract In modern greenhouses several measurement In the past generation greenhouses it was enough to have points are required to trace down the local climate parameters one cabled measurement point in the middle to provide the in different parts of the big greenhouse to make the greenhouse 
information to the greenhouse automation system The automation system work properly Cabling would make the system itself was usually simple without opportunities to measurement system expensive and vulnerable Moreover the control locally heating lights ventilation 
or some other cabled measurement points are difficult to relocate once they are installed Thus a Wireless Sensor Network WSN activity whichwas affecting the greenhouse interior climate consisting of small-size wireless sensor nodes equipped with This all has changed in the modern greenhouses The typical radio and one or several sensors is an 
attractive and costsize of the greenhouse itself is much bigger what it was efficient option to build the required measurement system before and the greenhouse facilities provide several options In this work we developed a wireless sensor node for to make local adjustments to the lights ventilation heating greenhouse monitoring by integrating a sensor platform and other greenhouse support systems However more provided by Sensinode Ltd 1 with three commercial sensors measurement data is also needed to make this kind of capable to measure four climate variables The feasibility of the 
automation system work properly Increased number of developed node was tested by deploying a simple sensor measurement points should not dramatically increase the network into Martens Greenhouse Research Foundation's greenhouse in Niirpio town in Western Finland During a one automation system cost It should also be possible to easily day experiment we collected data to evaluate the network change the location of the measurement points according to reliability and its ability to detect the microclimate layers the particular needs which depend on the specific plant 
on which typically exist in the greenhouse between lower and the possible changes in the external weather or greenhouse upper flora We were also able to show that the network can structure and on the plant placement in the greenhouse detect the local differences in the greenhouse climate caused by Wireless sensor network WSN can form a useful part of various disturbances such as direct sunshine near the the automation system architecture in modem greenhouses greenhouse walls This article is our first step in the area of Wireless communication can be used to 
collect the greenhouse monitoring and control and it is all about the measurements and to communicate between the centralized developed sensor network feasibility and reliability Data control and the actuators located to the different parts of the analysis control solutions and more complex network setups will be left to be the main directions of our future work greenhouse In advanced WSN solutions some parts of the control system itself can also be implemented in a distributed manner to the network such that local control I INTRODUCTION loops can be 
formed Compared to the cabled systems the The most important factors for the quality and installation of WSN is fast cheap and easy Moreover it is productivity of plant growth are temperature humidity light easy to relocate the measurement points when needed by just and the level of the carbon dioxide Continuous monitoring moving sensor nodes from one location to another within a of these environmental variables gives information to the communication range of the coordinator device If the grower to better understand how each factor affects 
growth greenhouse flora is high and dense the small and light and how to manage maximal crop productiveness 2 The weight nodes can even be hanged up to the plants branches optimal greenhouse climate adjustment can enable us to WSN maintenance is also relatively cheap and easy The improve productivity and to achieve remarkable energy only additional costs occur when the sensor nodes run out of savings especially during the winter in northern countries batteries and the batteries need to be charged or replaced but 3 the lifespan of the battery can be several years if an efficient power saving algorithm is applied 1-4244-2368-2/08/$20.OO 2512008 IEEE 403 


In this work we took the very first steps towards the reference values to certain environmental variables and then wireless greenhouse automation system by building a the greenhouse automation system targets to keep the wireless measuring system for that purpose and by testing its variables in these values The optimal levels of water and feasibility and reliability with a simple experimental setup fertilizer can also be defined 5 We integrated three commercial sensors to Sensinode's Carbon dioxide CO2 is a natural gas which is sensor platform 1 By using these sensors we are able to dangerous for humans in high concentrations but a lifeline measure four parameters which are crucial in greenhouse for trees and plants The air consists of nitrogen oxygen and climate adjustment temperature relative humidity light carbon dioxide In the photosynthesis process the plants irradiance and air carbon dioxide content The platform uses convert CO2 water and light into glucose and oxygen 6LoWPAN protocol which allows us to send compressed according to IPv6 packets over IEEE 802.15.4 networks II RELATED WORK 6H20  6CO2  light C6HI206+602 The Rinnovando group 4 is doing research work in a Thus CO2 is an important greenhouse climate variable tomato greenhouse in the South of Italy They are usin which enhances the growth of the plants Sunshine and lights in CD-cren nsde he renhoseanddelves te atato greenhouses Normally the range of healthy relative the main PC by using GSM module The central PC located ghouses Normally th frang to healtHy ati further apart from the network takes care of data logging and midty r the plant to 700n H ha processing Mote programming and data receiving is moisture reduces the reauired plant watering frequency The possible through the RS-232 serial interface provided by gremenhoue automatin u ses the wtr ga sting MIBS10 bard.The eceied SgnalStregth ndictor system if the air moisture decreases under the targeted level MIB5 10 board The Received Signal Strength Indicator 6 RSSI values over the distance between nodes with different 6 antena hight an polrizaion ngls wee copare to Temperature and humidity are closely linked together in antenna heights and polarization angles were compared to agrehu.Cod irasalwrmste-lin each other Based on the results it was possible to conclude aagreenhouse Cold airh an lowe moisture-holding that        th logs.omncto ag a civdwe capacity than warmer air and therefore the decrease of the node tha sameest corientation randemax an  hieve hei relative humidity is a sign of increased air temperature 3 Transpiration rate tells how many grams plant's leaf surface The temperature difference in experimental measurement ygl p between two nodes where one nodle was placed in the center cle tmt eesswtrvpu e iue between twondes,hereonendewaplaedinthecnter The greenhouse protects the plants from the extreme of the greenhouse and another near the greenhouse wall indiatestheexisenceof he mcrocimae laers 5].prevents the photosynthetic activity the plants do not grow Horticultural lighting allows the grower to extend the III PLANT DEVELOPMENTAL FACTORS growing season It enables a year-round producing of plants The prdciiyo h renos eed nmn or makes it possible for the grower to start sowing in early different   l fatos Mayrsac rjet r ouigt spring and continue season till the first frost Plants need these factors and their interdependencies Grower can set the aot1-2huslgtt mrv rwh hntepat 404 humidit increase the amount of carbon dioxide During the summer Sensicast devices for the air temperature relativity humd the greenhouse gets the C2 it needs from the natural air and soil temperature measurements with wireless senso when ventilation and roof windows are open 3 In norther network They have also developed a Web-based plant countries this opportunity does not exist during the winter monitoring application Greenhouse grower can read the Grower can use pure extra CO2 or he can produce more measurements over the Internet and an alarm will be sent to carbon dioxide by C burner Some reenhouse heatin his mobile phone by SMS or GPRS if some measurement y variable changes rapidly The Rinnovando group has a test systems re-circulate their CO2 emissions into the greenhouse bed in 20 x 50 meters tomato greenhouse In their test bed making double advantages for the producer 2 The use of six nodes are deployed into two rows 12.5 m apart from each external CO2 offers also a way to tie the carbon dioxide other One mesh node works as a repeater and improves the collected from some industrial process to the biomass grown throughput of the communication Bridge node gathers data in the greenhouse instead of emitting it to the atmosphere from other sensor nodes which transmit the measurements The optimal greenhouse air temperature depends on the intended level of the photosynthetic activity Each plant of temperature and relative humidity in one minute intervals has its own o y y 4 species hslSonoptimal values of air temperature and 4  active radiation of light which enable the maximum Liu et al 5 have developed and tested a WSN prototype acierdaino ih,wiheal h aiu for environmentale m onitorn insid thsed greeNhprouse.te photosynthetic activity see Figure 1 Soil temperature for environmentar topol og netor of Crossbo MICA plays also an important role Conduction heat transfers moteus.ng The motes measurey temperatuore humi An directly to the soil structure and through convection between motes The motes measure temperature humidity and soil thplnrosadwtefowrudtem moisture and send their measurements to the sink node in th.ln ot n ae flo aonthm ioisture,ntservls Sheir measurements tothesink node in A main concern in humidity and temperature control is to five minutes intervals Sink node is a combination of MICAz y mote and MBS 10 boad with daa termina Th temia provide the best conductivity to active movement of water withand A Mpr IOcessoarmdule stho thermialaTet m earement and nutrients through the plant Humidity control is also an withn LCceside the g hou s the dataeto important tool to prevent the spread of plant diseases in 


are producing flowers or fruits the supplemental need of signal amplifier cabled sensor units cannot transmit the data light per day increases up to 16 hours Figure 1 shows the correctly Wireless sensor network does not have such photosynthetic activity in different wavelengths of light problems Measured data can be sent directly to the gateway radiation 2 node which is plugged in to the computer see Figure 5 or it can be transmitted in a multi-hop manner via router nodes Photosntheti Ac..t Radif the distance between the measuring nodes and the Photo s~mthetic Activite Radiation computer exceeds the length of a single radio link Besides data collecting and control calculation the computer also presents the climate variable values and statistics on the o80 4 srenfr the user The computer runs the greenhouse 60 F climate control algorithm and the new values for the control i 40 signals are computed typically in every 15-60 seconds jjjjjjjj I Control output signals from the computer have low 0 20 _ 1      voltage 24 volts Each output is connected to electronic relay which switches the equipment under its control on or 400 500 600 700 off through the second relay which gives to the device the ULTRA input voltage it needs The control system is illustrated in VIOLET VISIBLE LIGHT INFRA RED Figure 2 Computer computes the intermediate time from the output signal and then determines how long each relay is Fig 1 Photosynthetic activity in different wavelengths of light turned on 2 radiation Figure from 2 A modern greenhouse can consist of several parts which contain their own local climate variable settings As a consequence several measurement points are also needed ADJUSTMENTS CALCULATIONS V EXPERIMENTAL SETUP IN A GREENHOUSE Plumsp  A The Greenhouse Environment  I ootimun old vlI yeO We made our experiments in Martens Greenhouse Boiler Research Center's greenhouse in the Narpio town in Western BTu ef Finland 7 The size of the greenhouse was 18 x 80 meters X  IJ and in its traditional control system it has only one cabled measurement unit in the middle Lununahoni Greenhouse's moist climate and dense flora are similar to Scr.eii the surroundings of a jungle This kind of environment is challenging both for the sensor node electronics and for the C02 eiliieti I short-range IEEE 802.15.4 wireless network which m I I communication range is much longer in open areas Therefore we limited the distances between communicating MEASUREMENTS nodes to 15 meters in our deployment ieehlioii mo\247nt1 Outsidt e 11'otunet B Sensor Nodes State of eqtupilet The wireless sensor node we used was Sensinode's Fig 2 Tasks in greenhouse environmental control Figure from 2 Micro.2420 U100 see Figure 3 6 It operated as a basic measuring node with a CC2420 802.15.4 RF-transceiver and a MSP430 Microcontroller The gateway node was a IV GREENHOUSE CONTROL combination of U100 node and USB serial adapter board Greenhouse monitoring and control can be divided into Micro.USB U600 1 Sensors were soldered to a board three main tasks Measuring calculating and adjusting 2 equipped with the needed components resistors capacitors These three tasks have their own functionalities as presented and operation amplifier Then the sensor board see Figure in Figure 2 4 on the left was plugged in to the Ut100 node through its The measured values of the greenhouse climate variables I/O pins The node and two 1 5V AA-batteries acting as a are first converted from analog to digital and then power source were sheltered by a plastic box 80*55*33mm transmitted to the computer Because of the high moisture in to prevent them from the humidity Sensor board was placed the greenhouse the computer is normally located outside on the top of the box and sensitive electrical components Signal provided by the sensors is normally weak Without were protected from the moisture by a plastic coating spray 405 


Finally the whole board was enveloped by ESD plastic D NodeDeploymentandNetworkArchitecture sachet leaving only the heads of the sensors outside We applied a simple star topology where four nodes with temperature luminosity and humidity sensors measured climate variables and communicated directly with the nector gateway node The gateway node acted as a coordinator and received the measured data from the sensor nodes It was sensor was tricky because it sets special requirements for the input voltage and the response time Figaro's TGS4l61 12 alternahive whch was the most compatible with low voltage U Itu sensor node CO2 measuring takes longer time than other matewayiodey measurements and CO2 s ensor voltage supply must be within s0.sV from the 5 Volts The carbon dioxide value can be s o read from the output voltage Operation amplifier raises the orniuer\(t b e voltage level of otherwise weak signal from the sensor We Fig 5 Experimental setup in Martens greenhouse end up to left the TGS4161 to be implemented in its own node which can also act as a router node in a multi hop Node 1 see Figure 5 was placed 490 cm away from the network which will be part of the future work glazed side wall of the greenhouse It was hanged in 120 cm height and the distance to the edge of dense tomato foliage was 410 cm Node 2 had 180 cm distance to the side wall and it was placed at the height of 176 cm That location was a shadowy spot where the nearest lamp was broken The length between the first plants and the device was 174 cm 406 C106k located in the greenhouse entrance hall because the humidity  II giW 7 lE.|;0|=WA g nthere was 20-30o lower than inside the greenhouse A laptop computer was connected to the gateway node by USB-cable Martens greenhouse was divided into vertical blocks and Fig 3 Sensinode's Micro.2420 UIOO The node is equipped the nodes monitored one block at a time Figure 5 illustrates with ZigBee radio but it operates under 6LoWPAN how the sensor nodes were deployed to the greenhouse protocol block The idea of the vertical deployment was to get a better understanding of the microclimate layers which Sensinode's devices are based on 6LoWPAN protocol typically exist in the greenhouse and to figure out what kind which enables transmission of compressed Internet Protocol of differences occur in the climate between lower and upper version 6 IPv6 packets over IEEE 802.15.4 networks 8 flora Sensinode's Nanostack protocol provides the use of 6LoWPAN and a standard Socket API for accessing the network It works in 2,4GHz ISM band and offers 250 kbps data rate 9 C Sensors Fast response time low power consumption and tolerance against moisture climate made SHT75 relative humidity and temperature sensor 10 a perfect solution for the greenhouse environment Temperature accuracy of the and clock line are the same in both cases but SHT75 has tmeauehmdt esr ixd esr only one pull-up resistor between data and power supply line  Luminosity was measured by TAOS TSL262R 11l  which converts light intensity to voltage Unstable output signal is handled by low-pass filter to get correct luminosity values  d hunnidlty 1 Woe issmounrtedII irradiance temelperaur and Phumiip.Dtyi.4esrbad\(qupe ihlmnstn sensors in t o four nodes but Carbon dioxide Connector w R hing 


Node 3 measured the crown layer in 310 cm height just and the block where our sensor nodes were deployed was in above the Node 1 Node 4 was in the middle of the the greenhouse's south end greenhouse block 930 cm away from the side wall and The temperature values measured by four wireless sensor hanged at a height of 295 cm The distance from the node to nodes are shown in Figure 7 Local temperature values were the edge of the foliage was 135 cm Node 2 and Node 3 are strongly influenced by the sunshine at the beginning of the shown in Figure 6 experiment period Node 1 was far away from the Periodical sleep and wake modes were applied In its greenhouse ceiling and from both greenhouse walls Thus turn each node woke up and turned on its radio for 15 the temperature stayed stable in its area for most of the time seconds and went then back to sleep and turned off its radio The 15 minutes sampling period in the greenhouse control for 255 seconds 4 min 15 s At a time only one of the four system explains why temperature raised over 30 Celsius in nodes equipped with temperature luminosity and humidity some spots before the control system opened the roof sensors was reading data from the sensors and waiting data windows Later on a partly cloudy weather balanced the request from the coordinator The coordinator took care of results between the nodes for the rest of the experiment data requesting and the other nodes were only able to answer to the request Thus the coordinator acted as a master device which polled data from the sensor nodes in TEMPERATURE certain time periods Collisions between other node transmissions were easily avoided in this way E 1  r.value 246 iNOE 2 fav vale 25.Z avr NOE 4 arval ue 22S,14 30 OM mn 40 1-m me C Mr 1 9 X**s t**s*gg**a 25 20 Fig 6 The node 2 and node 3 inside red squares in a 5 greenhouse test setup M WOW Me en in m d go X cm XI TIME VI RESULTS RI I I M MIn our experimental setup four nodes were deployed to Fig 7 Temperature measurent results one greenhouse block to gather information about the differences in climate variables between lower and upper flora Each node red temperature humidity and irradiance values once in four minute intervals over three hours During the experiment the coordinator sent 200 data requests and each sensor node responded 50 times Ten packets with NODE 1 J lim s 6AG readings were either lost or received incorrectly That NODE 2 Wr va[Lu 67X2 indicated 5 data loss rate in terms of packets The maximal NODE 3 talr value S65 27J communication range 15 meters was figured out in NODE 4 vaua 5A1 individual test where the distance between the coordinator and the sensor node inside the greenhouse dense flora was increased until the connection was lost We also observed that the reliable range in terms of tolerable packet loss was 70 approximately 10 meters Compared to our previous ge experiment in an open parking lot the reliable communication range fell to one third in the greenhouse's dense flora A fickle weather on the measurement day affected the 5 results The sun was shining for a half an hour in the beginning of the test and later on during shorter periods of 40 the day The greenhouse environmental control system  Priva[13 adjusted the ventilation heating and misting TIMIE w40"^t-o 4 according to new samples once in 15 minutes Priva's measurement box located in the middle of the greenhouse Fig 8 Relative humidity measurement results 407 


for 0 Environmental Monitoring F Bustaffa Node 3 and Node 4 were both placed on the crown layer Irradiance sensor does not have the sleep mode at all and to of the tomato growth A slant ceiling of the greenhouse save energy it have to be turned off most of the time made the distance between Node 4 and the ceiling three In the nearby future we will develop a multi-hop meters longer than distance between Node 3 and the ceiling network to cover the entire greenhouse We will also attach Therefore the measurements provided by node 4 indicated probes to the nodes so that the wireless nodes can be used to one degree lower temperature Node 2 was located near the measure soil moisture and possibly other parameters from side wall of which the sun was heating raising the the flower pots but still be flexibly moved with the pots or temperature measured by the node from one pot to another We are also considering the option The relation between the humidity and temperature was to implement the C02 sensor to the network by connecting it explained in Chapter III The measurements collected by the to the plug-in router node nodes verified the fact that the lowering of the relative In addition to networking in data collecting purposes we humidity increases the air temperature and vice versa Figure will develop the control part and close the wireless control 8 shows the changes in relative humidity between four loop The control commands will be counted in a centralized nodes Comparison between temperature and humidity or locally centralized manner and then transmitted values Figures 7 and 8 shows how variables are linked wirelessly to the actuators located to the different parts of the together For example two distinct drops in humidity are greenhouse Required local control implementations suggest clearly to be seen in the Figure 8 Temperature values us to use DSP-units with some of the wireless sensor nodes increased at the same time when moisture dropped as shown in Figure 7 Relative humidity did not differ much between REFERENCES the nodes Node 1 and Node 2 were placed on a shadowy spot and they measured a little bit higher moisture than 1 Sensinode 2007 OEM Product catalog Online Available nodes on the upper layer http://www.sensinode.com/pdfs/sensinode-catalog-20071 101.pdf seconds  Available http www.roborugby org/docs/Taos-TSL260R.pdf G H Sensirion 2007 SHTlx   Temperature SHT7x Humidity in Greenhouses IPv6 Packets over The pollen from the tomato flowers colored one Of the black  4 M Mancuso and Kamp Computerised Environmental VII CONCLUSIONS AND FUTURE WORK Control G Montenegro and N Kushalnagar Transmission of Sensors Network for system feasibility was verified in a simple star topology Monitoring Environmental Variables in a Tomato Greenhouse presented setup in a tomato greenhouse We achieved up to 10 meter at 6t IEEE International Workshop on Factory Communication Systems in communication range with tolerable 5 packet loss Torino Italy June 28-30 2006 Because of the high humidity and dense tomato growth the reliable communehicathumion trange w nsred tomao gron thid f 5 H Liu Z Meng Sensor v.3 0.1 Online].Available:http://www.sensirion.com/en/pdf/product inform node was receiving and sending packets in its own turn ation Data_Sheet_humidity_sensor_SHTlx_SHT7x_E.pdf according to the polling of the coordinator node The sleep time of the node was 93.75 which could be increased over 11 Texas Advanced Optoelectronic Solutions Inc 2003 TSL260R 97.50 by shortening the operation time from 15s to five TSL261R TSL262R Light to voltage optical sensors Online 2003 In this work we integrated three commercial sensors 3 Greenhouse guide Referred 20.04.2008 Online Available with Sensinode's sensor platform to measure four http://www.littlegreenhouse.com/guide.shtml environmental key variables in greenhouse control The environmenta key variables in greenhousecontrol Te Sensors were turned on all the time Both 5HT7 2003 TGS 4161 for the detection in Greenhouses PTC The Netherlands Page\(s 15-124 25to the top 80 1998 High moisture forced to consider the possible damages 7 Martens Greenhouse Research Center Web-page http://www.martens.fi and to protect sensitive boards carefully When running the referred 17.5.2008 experiments another board damaging factor was noticed Te pollent romther toato flowers color r one no th bc 8 A Wireless 2 G J Timmerman and P and S Cui  A Wireless Sensor Network Prototype presented at Wireless the respective communication range in open space The Communications Networking and Mobile Computing 2007 WiCom measurements also indicated that the system is able to detect 2007 International Conference on 21-25 Sept 2007 Page\(s the local differences in the greenhouse environment such as 2344 2347 different climate layers which exist from greenhouse bottom 6 M Aberg Secher Kasvihuone Otava Helsinki Finland Page\(s 12 Figaro engineering inc of Carbon humidity/temperature sensor and TSL262R light irradiance Dioxide Online].Available:http://www.figarosensor.com/products/416 lpdf sensor are suitable for the low power nodes Especially the SHT75 with low current sleep mode and accurate sensors is 13 PRIVA Greenhouse Environmental Control Systems Online well suitable for wireless sensor nodes powered by batteries Aalbe tp/wwpiac 408 IEEE 802.15.4 Networks Internet-Draft IETF Septemper 2007.[Online plastic boxes yellow Small particles of the pollen could also Available http://www.ietf.org block the measuring component of the sensors affecting the measuring results 9 Sensinode 2007 NanoStack manual vl.0.1 Online Available Applied 15 seconds wake periods between 4 min 15 s www,sensinode.com sleep periods fulfilled the requirements of the energysefe wirls sensor net aqrciectu a ch sensrg 10 


The hardware implementation of these SVMs produced results that agree very well with the software simulations of the algorithms Figure 8b shows the 30-band linear SVM classification output Figure 8c shows the polynomial SVM classification output See Table VI for a summary of classification disagreement for each of the three SVMs These disagreements may be due to floating-point hardware implementation differences between the FPGA hardware and the processor that ran the software simulations SW/HW Implementation SVM Classifier Difference 1 11-band Linear 0.34 30-band Linear 0*19  Polynomial 1.23 TABLE VI CLASSIFICATION DISAGREEMENT PERCENTAGE BEWTEEN SOFTWARE SIMULATION  PHYSICAL IMPLEMENTATION 3 SEU MITIGATION Space-flight qualified FPGAs are susceptible to radiation single event upsets SEUs therefore this issue must be addressed for the SVM V4FX design to be flight-ready The expected SEU rates of Rad-Hard flight processors such as the RAD750 in a GEO environment is on the order of 1 error every 5-10 years Expected SEU rates for the Xilinx Virtex FPGA are approximately one error per week Recent data from similar FPGAs flown on JPL's Mars Exploration Rovers validate these predictions 10 It should be noted that next generation Xilinx parts such as the Virtex-4 are expected to be produced on CMOS SOI process lines providing an order of magnitude improvement in SEU rate as well as other speed/power and radiation tolerance improvements In order to achieve parity with Rad-Hard processors we must reduce the SEU error rates by approximately two orders of magnitude and do this in a way that is relatively transparent to the application Future work toward this goal could use the Xilinx Triple Modular Redundancy TMR Tool 11 to triplicate logic as there are sufficient remaining resources as well as run the dual-core processors in lock-step The simplest approach may be to include only SEU detection in the design and when detection occurs re-load the FPGA configuration file This is a viable strategy for non-critical applications that can withstand occasional interruption for re-configuration Partial reconfiguration is another possible solution albeit more complex to implement where only the effected portion of the FPGA needs to be configured 4 CONCLUSION FPGAs with embedded processing capabilities are demonstrating breakthrough performance previously impossible with traditional processors This paper presented results from the synthesis of a legacy software SVM classification algorithm to the Xilinx V4FX60 FPGA platform as well as two extensions to demonstrate the increased capabilities of this implementation Using commercially available C-to-HDL translation tools this work was made possible under very limited funding Hardware acceleration of legacy software algorithms such as the described SVMs promises to provide needed capability for more advanced on-board data processing in future science missions While the current method is to implement only those software classification algorithms that will fit within very constrained on-board processing resources with embedded FPGAs such as the V4FX60 increasingly advanced SVMs may be implemented with room to grow in on-board resources Our results demonstrate that our most advanced extension the 2,1 polynomial kernel is achieved with only 9\2600 utilization of the FPGAs DSPs Imagine the possibilities 5 ACKNOWLEDGEMENTS Abdullah Aljabri their vision and development JPL and Charles D Norton JPL for support of Smart Payload technology 6 REFERENCES 1 Virtex-4 Family Overview DS112 v1.5 Xilinx Inc San Jose CA 2006 Available 2 MCP750 CompactPCI Host Slot Processor Motorola Computer Group Temple AZ 2001 Available 3 Xilinx Development Boards Xilinx Inc San Jose CA 2006 Available 4 C Cortez and V Vapnik Support vector networks Machine Learning 20 1995 273 279 5 Rebecca Castano Ngia Tang Thomas Dogget Steve Chien Dominic Mazzoni Ron Greely Ben Cichy and Ashley Davis Onboard classifiers for science event detection on a remote sensing spacecraft Proceedings of the 12th ACM SIGKDD International conference of 7 


Knowledge Discovery and Data Mining ACM Press 2006 845 851 6 M Aizerman E Braverman and L Rozonoer Theoretical foundations of the potential function method in pattern recognition learning Automation and Remote Control 25 1964 821 837 7 J Platt Sequential Minimal Optimization A Fast Algorithm for Training Support Vector Machines Microsoft Research Technical Report MSR-TR-98-14 1998 8 David Pellerin and Scott Thibault Practical FPGA Programming in C Prentice Hall 2005 9 P Pingree C Norton Smart Payload Development for High Data Rate Instrument Systems Proceedings of the NASA Space Technology Conference 2007 10 J George R Koga G Swift G Allen C Carmichael and C W Tseng Single Event Upsets in Xilinx Virtex-4 FPGA Devices pre-publication paper 2006 11 Xilinx TMRTool Fact Sheet The research described in this paper was carried out by the Jet Propulsion Laboratory California Institute of Technology under a contract with the National Aeronautics and Space Administration 7 BIOGRAPHY Paula Pingree is a Senior Engineer in the Instruments and Science Data Systems Division at JPL She has been involved in the design integration test and operation of several JPL flight projects the most recent being Deep Impact DI where she was Test Bench Manager pre-launch and Co-Lead of the Impactor Comet Encounter activity postlaunch She is presently the Electronics CogE for the Microwave Radiometer instrument on the Juno spacecraft planned for a 2011 launch to Jupiter She also enjoys research and technology development for Smart Payloads such as this paper presents Paula has a Bachelor of Engineering degree in Electrical Engineering from Stevens Institute of Technology in Hoboken NJ and a Master of Science in Electrical Engineering from California State University Northridge She is a member of IEEE Lucas Scharenbroich is a Researcher in the Machine Learning and Instrument Autonomy group at JPL He has been involved with the design implementation and deployment of machine learning algorithms to enable autonomous science capabilities primarily through the Autonomous Sciencecraft Experiment ASE He is presently involved in the application of machine learning to automated code generation crop yield prediction and object tracking in remote sensing data Lucas has Bachelor of Science degrees in Electrical Engineering and Compute Science from the University of Minnesota Duluth and a Master of Science in Information and Computer Science from the University of California Irvine Thomas Werne is an Associate Engineer in the Model Based Systems Engineering and Architectures group at JPL He is currently working on implementing FPGA-based technology for Smart Payload applications Thomas has Bachelor of Science degrees in Electrical Engineering and Mathematics and a Master of Engineering in Electrical and Computer Engineering from Rose-Hulman Institute of Technology He is a member of IEEE Christine Hartzell is an undergraduate Aerospace Engineering student at the Georgia Institute of Technology GIT She will be graduating in May 2008 and then pursuing a PhD in Aerospace Engineering with a focus on Space System Design Her research has focused on bioastronautics instrument design methods heatshield design and trajectory selection in labs at GIT and at the Jet Propulsion Laboratory JPL 8 


Communities and Commercial Success: Individual and community-level theory grounded in the atypical case of TimeZone.Com," Journal of Management, 27, 2001, pp 297-312 55  T  R Gr a e ff  U sin g P r omo tio na l M e ssa ge s to M a n a g e  the Effect of Brand Self Image on Brand Evalution Journal of Consumer Marketing, 1996, 13, pp. 4-18  T  W   Bri g n a l l  a n d T  L  V  V a l e y   A n ol i n e co m m uni t y  as a new tribalism: The World of Warcraft," Proceedings of the 40 th Hawaii International Conference on System Science, Big Island, Hawaii, 2007   J. Y i an d S  A   L a  B ran d Pers on alit y  Bran d  Identification - Brand Equity Model : An Exploratory Study on the Difference Between Users vs. Non … Users Marketing Research, 17\(3\02, pp. 1-33  W i k e pedia M M ORP G \(h ttp://e n  w i k e pedia org/wiki/MMORPG   K. L ee, an d J.I K w o n   T h e Inf l u en ce of Appropriation and on Performance in Online Game Focusing on MMORPG The Journal of MIS Research Vol. 16, No. 4, 2006  W i k e pedia, th e Free En c y clopedia, MMOR P G   available in http:// en.wikipedia.org/ siki/MMORPG#Aca  demic_attention\, 2006  e De v e lopm e n t  Prom otio n Ins tit u t e   2006 The Rise of Korean Games 2006  w w  m m o rpg c h art.co m  Proceedings of the 42nd Hawaii International Conference on System Sciences - 2009 9 


 10  Early Career Award for Scientists and  Engineers PECASE in 2000 He has been co investigator on the NASA/ ESA SOHO spacecraft and the CNES Picard mission Michael is a member of the IEEE Computer Society the Institute for Mathematical Statistics and AAAS  Jay Parker is a Senior Scientist in the Satellite Geodesy and Geodynamics group of the Jet Propulsion Laboratory California Ins titute of Technology His graduate research used computer simulations to explain mesospheric ionization response to solar flares and dynamic instabilities Dr Parker's research subjects at the Jet Propulsion Laboratory include a variety of topics in remote  sensing analysis and modeling  These include supercomputing algorithms for electromagnetic scattering and radiation satellite geodesy and finite element simulation for earthquake related deformation and ocean sensing through GPS signal reflection He i s currently the software engineer and co investigator for the QuakeSim project which has developed a solid Earth science framework including a variety of simulation and analysis tools He also develops the SEASCRAPE software system for high fidelity simul ation and parametric retrieval of atmospheric infrared spectrometry at Remote Sensing Analysis Systems Inc of Altadena CA Dr Parker is a member of the American Geophysical Union and co chair of the Data Understanding and Assimilation working group of t he APEC Cooperation for Earthquake Simulation   


 11 This model specifies that covariates act multiplicatively on time t r than on the hazar d function.  That is, we assume a baseline hazard function to exist and that the effects of the covariates are to alter the rate at which an individual proceeds along the time axis.  In other words, the covariates z accelerates or decelerates the time to failure Kalbfleisch and Prentice 2002, Lawless 2003  It should be pointed out that the distribution-based regression models for exponential and Weibull distributions in the previous section are th e special cases of both PHM and AFT.  This correspondence is not necessarily true for models based on other distribu tions. Indeed, two-parameter Weibull distribution has the uniq ue property that it is closed under both multiplication of fa ilure time and multiplication of the hazard function by an arbitrary nonzero constant Lawless 2003, Kalbfleisch & Prentice 2002, Klein Moeschberger 2003  2.6. Counting Process and Survival Analysis   In the previous sections, we introduced censoring and survival analysis models th at can handle the censored information; however, we did not discuss how the censored information is processed.  Accommodating and maximally utilizing the partial information from the censored observations is the most challenging and also the most rewarding task in survival anal ysis.  This also establishes survival analysis as a unique fiel d in mathematical statistics Early statistical inferences for censored data in survival analysis were dependent on asymptotic likelihood theory Severini 2000\ Cox \(1972, 1975\ proposed partial likelihood as an extension to classical maximum likelihood estimation in the context of hi s proportional hazards model as a major contribution. Asymptotic likelihood has been and still is the dominant theory for developing survival analysis inference and hypothesis testing methods \(Klein and Moeschberger 2003, Severini 2000\. There are many monographs and textbooks of survival analysis containing sufficient details for applying survival analysis \(Cox and Oakes 1984, Kalbfleisch and Prentice 1980, 2002, Lawless 1982, 2003, Klein and Moeschberger, 2003\. A problem with traditional asymptotic lik elihood theory is that the resulting procedures can become very complicated when handling more complex censoring mechanisms \(Klein Moeschberger 2003\. A more elegant but requiring rigorous measure-theoretic probability theo ry is the approach with counting stochastic processes and the Martingale central limit theorems.  Indeed, this approach was used by Aalen 1975\ to set the rigorous mathematical foundation for survival analysis, and later further developed and summarized by Fleming and Harrington \(1991\, Andersen et al. \(1993\several research papers.  In reliability theory Aven and Jensen \(1999\ dem onstrated such an approach by developing a general failure model, which we briefly introduced in Section 1.2. However, the counting process and Martingale approach require measure theoretic treatments of probability and st ochastic processes, which is often not used in engineering or applied statistics.  A detailed introduction of the topic is obviously beyond the scope of this paper, and we only present a brief sketch of the most important concepts involved.  Readers are referred to the excellent monographs by Andersen et al. \(1993 Fleming and Harrington \(1991\ Aven and Jensen \(1999\ for comprehensive details, and Kal bfleisch and Prentice \(2002 Klein and Moeschberger \(2003\, Lawless \(2003\ for more application–oriented treatments The following discussion on this topic is drawn from Klein and Moeschberger \(2003  A counting stochastic process N  t  t 0 possesses the properties that N  0 ro and N  t   with probability one. The sample paths of N  t ht continuous and piecewise constant with jumps of size 1  step function In a right-censored sample, \(we assume only right censoring in this section N i  t  I  T i t  i   which keep the value 0 until individual i fails and then jump to 1  are counting processes. The accumulation of N i  t ocess     1 t N t N n i i is again a counting process, which counts the number of failures in the sample at or before time t   The counting process keeps track of the information on the occurrences of events,   for instance, the history information such as which individual was censored prior to time t and which individual died at or prior to time t as well as the covariates information This accumulated history information of the counting process at time t is termed filtration at time t denoted by F t For a given problem F t  rests on the observer of the counting process.  Thus, two observers with different recordings at different times will get different filtrations.  This is what Aven and Jensen 1999\ referred to as different information levels or the amount of actual available information about the state of a system may vary  If the failure times X i and censoring times C i  are independent,  then the probability of an event occurs at time t given the history just prior to t  F t\n be expressed as  t T if dt t h t C t X dt t C dt t X t P F dt t T t P i i i i i i r t i i r          1     t T if F dt t T t P i t i i r 0   1    51  Let dN  t be the change in the process N  t over a short time interval    t t t Ignoring the neglig ible chance of ties 1   t dN if a failure occurred and 0   t dN otherwise  Let Y  t denote the number of individuals with an observation time T i t Then the conditional expectation of dN  t   dt t h t Y F dt t C dt t X t with ns observatio of number E F t dN E t i i i t              52 


 12 The process  t  Y  t  h  t  is called the intensity process  of the counting process.  It is a stochastic process that is determined by the information contained in the history process F t via Y  t  Y  t  records the number of individuals experiencing the risk at a given time t   As it will become clear that   t is equivalent to the failure rate or hazard function in tr aditional reliability theory, but here it is treated as a stochastic process, the most general form one can assume for it. It is this generalization that encapsulates the power that counting stochastic process approach can offer to survival analysis  Let the cumulative intensity process H  t be defined as   t t ds s t H 0 0      53  It has the property that  E  N  t  F t  E  H  t  F t  H  t   54  This implies that filtration F t, is known, the value of Y  t  fixed and H  t es deterministic H  t is equivalent to the cumulative hazards in tr aditional reliability theory  A stochastic process with the property that its expectation at time t given history at time s < t is equal to its value at s is called a martingale That is M  t martingale if           t s s M F t M E s  55  It can be verified that the stochastic process         t H t N t M 56  is a martingale, and it is called the counting process martingale The increments of the counting process martingale have an expected value of zero, given its filtration F t That is  0      t F t dM E 57 The first part of the counting process martingale [Equation 56  N  t non-decreasing step function.  The second part H  t smooth process which is predictable in that its value at time t is fixed just prior to time t It is known as the compensator  of the counting process and is a random function. Therefore, the martingale can be considered as mean-zero noise and that is obtainable when one subtracts the smoothly varying compensator from the counting process  Another key component in the counting process and martingale theory for survival analysis is the notion of the predictable variation process of M  t oted by    t M It is defined as the compensator of process   2 t M  The term predictable variation process comes from the property that, for a martingale M  t it can be verified that the conditional variance of the increments of M  t  dM  t  h e inc r em ents of   t M That is          t M d F t dM Var t  58  To obtain      t F t dM Var  one needs the random variable N  t  variable with probability   t of having a jump of size 1 at time t The variance of N  t   t  1 t   since it follows b i nom ial distribution    Ignoring the ties in the censored data 2  t  is close to zero and Var  dM  t  F t    t  Y  t  h  t   This implies that the counting process N  t on the filtration F t behaves like a Poisson process with rate  t    Why do we need to convert the previous very intuitive concepts in survival analysis in to more abstract martingales The key is that many of the sta tistics in survival analysis can be derived as the stochastic integrals of the basic martingales described above The stochastic integral equations are mathematically well structured and some standard mathematical techniques for studying them can be adopted  Here, let   t K be a predictable  process An example of a predictable process is the process   t Y Over the interval 0 to t the stochastic integral of su ch a process, with respect to a martingale, is denoted by     0 u dM u K t It turns out that such stochastic integrals them selves are martingales as a function of t and their predictable variation process can be found from the predictable variation process of the original martingale by           0 2 0 u M d u K u dM u K t t 59 The above discussion was drawn from Klein and Moeschberger \(2003 also provide examples of how the above process is applied. In the following, we briefly introduce one of their exampl es — the derivation of the Nelson-Aalen cumulative hazard estimator  First, the model is formulated as           t dM dt t h t Y t dN  60  If   t Y is non-zero, then               t Y t dM t d t h t Y t dN 61  Let   t I be the indicator of whether   t Y  is positive and define 0/0 = 0, then integrating both sides of above \(61 One get 


 13                     0 0 0 u dM u Y u I u d u h u I u dN u Y u I t t t 62  The left side integral is the Nelson-Aalen estimator of H t           0  u dN u Y u I t H t 63  The second integral on the right side           0 u dM u Y u I t W t 64  is the stochastic integral of the predictable process      u Y u I with respect to a martingale, and hence is also a martingale  The first integral on the right side is a random quantity    t H   t du u h u I t H 0        65  For right-censored data it is equal to   t H  in the data range, if the stochastic uncertainty in the   t W is negligible Therefore, the statistic    t H is a nonparametric estimator of the random quantity    t H   We would like to mention one more advantage of the new approach, that is, the martingale central limit theorem.  The central limit theorem of martingales ensures certain convergence property and allows the derivations of confidence intervals for many st atistics.  In summary, most of the statistics developed with asymptotic likelihood theory in survival analysis can be derived as the stochastic integrals of some martingale.  The large sample properties of the statistics can be found by using the predictable variation process and martingale central limit theorem \(Klein and Moeschberger \(2003  2.7. Bayesian Survival Analysis  Like many other fields of statistics, survival analysis has also witnessed the rapid expansion of the Bayesian paradigm.  The introduction of the full-scale Bayesian paradigm is relative recent and occurred in the last decade however, the "invasion" has been thorough.  Until the recent publication of a monograph by Ibrahim, Chen and Sinhaet 2005\val anal ysis has been either missing or occupy at most one chapter in most survival analysis monographs and textbooks.  Ibrahim's et al. \(2005\ changed the landscape, with their comprehensive discussion of nearly every counterp arts of frequentist survival analysis from univariate to multivariate, from nonparametric, semiparametric to parametric models, from proportional to nonproportional hazards models, as well as the joint model of longitudinal and survival data.  It should be pointed out that Bayesian survival analysis has been studied for quite a while and can be traced back at least to the 1970s  A natural but fair question is what advantages the Bayesian approach can offer over the established frequentist survival analysis. Ibrahim et al 2005\entified two key advantages. First, survival models are generally very difficult to fit, due to the complex likelihood functions to accommodate censoring.  A Bayesi an approach may help by using the MCMC techniques and there is available software e.g., BUGS.  Second, the Bayesian paradigm can incorporate prior information in a natural way by using historical information, e.g., from clinical trials. The following discussion in this subsection draws from Ibrahim's et al. \(2005  The Bayesian paradigm is based on specifying a probability model for the observed data, given a vector of unknown parameters This leads to likelihood function L   D   Unlike in traditional statistics is treated as random and has a prior distribution denoted by   Inference concerning is then based on the posterior distribution which can be computed by Bayes theorem d D L D L D              66 where is the parameter space  The term    D is proportional to the likelihood    D L  which is the information from observed data, multiplied by the prior, which is quantified by   i.e          D L D 67 The denominator integral m  D s the normalizing constant of    D and often does not have an analytic closed form Therefore    D often has to be computed numerically The Gibbs sampler or other MCMC algorithms can be used to sample    D without knowing the normalizing constant m  D xist large amount of literature for solving the computational problems of m  D nd    D   Given that the general Bayesian algorithms for computing the posterior distributions should equally apply to Bayesian survival analysis, the specification or elicitation of informative prior needs much of the atte ntion.  In survival analysis with covariates such as Cox's proportional hazards model, the most popular choice of informative prior is the normal prior, and the most popular choice for noninformative is the uniform Non-informative prior is easy to use but they cannot be used in all applications, such as model selection or model comparison. Moreover, noninformative prior does not harness the real prior information. Therefore, res earch for informative prior specification is crucial for Bayesian survival analysis  


 14 Reliability estimation is influenced by the level of information available such as information on components or sub-systems. Bayesians approach is likely to provide such flexibility to accommodate various levels of information Graves and Hamada \(2005\roduced the YADAS a statistical modeling environment that implements the Bayesian hierarchical modeli ng via MCMC computation They showed the applications of YADES in reliability modeling and its flexibility in processing hierarchical information. Although this environment seems not designed with Bayesian surviv al analysis, similar package may be the direction if Bayesian survival analysis is applied to reliability modeling  2.8. Spatial Survival Analysis  To the best of our knowledge spatial survival analysis is an uncharted area, and there has been no spatial survival analysis reported with rigor ous mathematical treatment There are some applications of survival analysis to spatial data; however, they do not address the spatial process which in our opinion should be the essential aspect of any spatial survival analysis. To develop formal spatial survival analysis, one has to define the spatial process first  Recall, for survival analysis in the time domain, there is survival function   R t t T t S  Pr   68  where T is the random variable and S  t e cumulative probability that the lifetime will exceed time t In spatial domain, what is the counterpart of t One may wonder why do not we simply define the survival function in the spatial domain as   S  s  Pr S s  s R d  R > 0  69  where s is some metric for d-dimensional space R d and the space is restricted to the positive region S is the space to event measurement, e.g., the distance from some origin where we detect some point object.  The problem is that the metric itself is an attribute of space, rather than space itself Therefore, it appears to us that the basic entity for studying the space domain has to be broader than in the time domain This is probably why spatial process seems to be a more appropriate entity for studying  The following is a summary of descriptions of spatial processes and patterns, which intends to show the complexity of the issues involved.  It is not an attempt to define the similar survival function in spatial domain because we certainly unders tand the huge complexity involved. There are several monographs discussing the spatial process and patterns \(Schabenberger and Gotway 2005\.  The following discussion heavily draws from Cressie \(1993\ and Schabenberger and Gotway \(2005  It appears that the most widely adopted definition for spatial process is proposed in Cressie \(1993\, which defines a spatial process Z  s in d-dimensions as    Z  s  s D R d  70  Here Z  s denotes the attributes we observe, which are space dependent. When d = 2 the space R 2 is a plane  The problem is how to define randomness in this process According to Schabenberger and Gotway \(2005 Z  s an be thought of as located \(indexed\by spatial coordinates s  s 1  s 2  s n  the counterpart of time series Y  t  t   t 1  t 2  t n   indexed by time.  The spatial process is often called random field   To be more explicit, we denote Z  s  Z  s   to emphasize that Z is the outcome of a random experiment  A particular realization of produces a surface    s Z  Because the surface from whic h the samples are drawn is the result of the random experiment Z  s called a random function  One might ask what is a random experiment like in a spatial domain? Schabenberger and Gotway \(2005\ offered an imaginary example briefly described below.  Imagine pouring sand from a bucket on to a desktop surface, and one is interested in measuring the depth of the poured sand at various locations, denoted as Z  s The sand distributes on the surface according to the laws of physics.  With enough resources and patience, one can develop a deterministic model to predict exactly how the sand grains are distributed on the desktop surface.  This is the same argument used to determine the head-tail coin flipping experiment, which is well accepted in statistical scie nce. The probabilistic coinflip model is more parsimonious than the deterministic model that rests on the exact \(perfect\but hardly feasible representation of a coin's physics. Similarly deterministically modeling the placement of sand grains is equally daunting.  However, th e issue here is not placement of sand as a random event, as Schabenberger and Gotway 2005\phasized.  The issue is that the sand was poured only once regardless how many locations one measures the depth of the sand.  With that setting, the challenge is how do we define and compute the expectation of the random function Z  s Would E  Z  s   s  make sense  Schabenberger and Gotway \(2005\further raised the questions: \(1\to what distribution is the expectation being computed? \(2\ if the random experiment of sand pouring can only be counted once, ho w can the expectation be the long-term average  According to the definition of expectation in traditional statistics, one should repeat the process of sand pouring many times and consider the probability distributions of all surfaces generated from the repetitions to compute the expectation of Z  s is complication is much more serious 


 15 than what we may often reali ze. Especially, in practice many spatial data is obtained from one time space sample only. There is not any independent replication in the sense of observing several independent realizations of the spatial process \(Schabenberger and Gotway 2005  How is the enormous complexity in spatial statistics currently dealt with? The most commonly used simplification, which has also been vigorously criticized, is the stationarity assumption.  Opponents claim that stationarity often leads to erroneous inferences and conclusions.  Proponents counte r-argue that little progress can be made in the study of non-stationary process, without a good understanding of the stationary issues Schabenberger and Gotway 2005  The strict stationarity is a random field whose spatial distribution is invariant under translation of the coordination.  In other word s, the process repeats itself throughout its domain \(Schabenberger and Gotway 2005 There is also a second-order or weak\ of a random field  For random fields in the spatial domain, the model of Equation \(70  Z  s  s D R d  is still too general to allow statistical inference.  It can be decomposed into several sub-processes \(Cressie 1993             s s s W s s Z  D s  71  where  s  E  Z  is a deterministic mean structure called large-scale variation W  s is the zero-mean intrinsically stationary process, \(with second order derivative\nd it is called smooth small-scale variation   s is the zero-mean stationary process independent of W  s and is called microscale variation  s  is zero-mean white noise also called measurement error. This decomposition is not unique and is largely operational in nature \(Cressie 1993\he main task of a spatial algorithm is to determine the allocations of the large, small, and microscale components However, the form of the above equation is fixed Cressie 1993\, implying that it is not appropriate to sub-divide one or more of the items. Therefore, the key issue here is to obtain the deterministic  s  but in practice, especially with limited data, it is usually very difficult to get a unique  s   Alternative to the spatial domain decomposition approach the frequency domain methods or spectral analysis used in time series analysis can also be used in spatial statistics Again, one may refer to Schabenberger and Gotway \(2005  So, what are the imp lications of the general discussion on spatial process above to spatial survival analysis?  One point is clear, Equation \(69 S  s  Pr S s   s R d is simply too naive to be meaningful.  There seem, at least, four fundamental challenges when trying to develop survival analysis in space domain. \(1\ process is often multidimensional, while time pr ocess can always be treated as uni-dimensional in the sense that it can be represented as  Z  t  t R 1  The multidimensionality certainly introduces additional complications, but that is still not the only complication, perhaps not even the most significant 2\One of the fundamental complications is the frequent lack of independent replication in the sense of observing several independent realizations of the spatial process, as pointed out by Cressie \(1993\\(3\e superposition of \(1 and \(2\brings up even more complexity, since coordinates  s of each replication are a set of stochastic spatial process rather than a set of random variables. \(4\n if the modeling of the spatial process is separable from the time process, it is doubtful how useful the resulting model will be.  In time process modeling, if a population lives in a homogenous environment, the space can be condensed as a single point.  However, the freezing of time seems to leave out too much information, at least for survival analysis Since the traditional survival analysis is essentially a time process, therefore, it should be expanded to incorporate spatial coordinates into original survival function.  For example, when integrating space and time, one gets a spacetime process, such as          R t R D s t s Z d   where s is the spatial index \(coordinate t is time.  We may define the spatial-temporal survival function as   S  s  t  Pr T t  s D  72  where D is a subset of the d dimensional Euclidean space That is, the spatial-temporal survival function represents the cumulative probability that an individual will survive up to time T within hyperspace D which is a subset of the d dimensional Euclidian space.  One may define different scales for D or even divide D into a number of unit hyperspaces of measurement 1 unit  2.9. Survival Analysis and Artificial Neural Network   In the discussion on artificial neuron networks \(ANN Robert & Casella \(2004\noted, "Baring the biological vocabulary and the idealistic connection with actual neurons, the theory of neuron networks covers: \(1\odeling nonlinear relations between explanatory and dependent explained\ariables; \(2\mation of the parameters of these models based on a \(training\ sample."  Although Robert & Casella \(2004\ did not mentioned survival analysis, their notion indeed strike us in that the two points are also the essence of Cox s \(1972\roportional Hazards model  We argue that the dissimilarity might be superficial.  One of the most obvious differences is that ANN usually avoids probabilistic modeling, however, the ANN models can be analyzed and estimated from a statistical point of view, as demonstrated by Neal \(1999\, Ripley \(1994\, \(1996 Robert & Casella \(2004\What is more interesting is that the most hailed feature of ANN, i.e., the identifiability of model structure, if one review carefully, is very similar to the work done in survival anal ysis for the structure of the 


 16 Cox proportional hazards model. The multilayer ANN model, also known as back-propagation ANN model, is again very similar to the stratified proportional hazards model  There are at least two advantages of survival analysis over the ANN.  \(1\val analysis has a rigorous mathematical foundation. Counting stochastic processes and the Martingale central limit theory form the survival analysis models as stochastic integral s, which provide insight for analytic solutions. \(2\ ANN, simulation is usually necessary \(Robert & Casella \(2004\which is not the case in survival analysis  Our conjecture may explain a very interesting phenomenon Several studies have tried to integrate ANN with survival analysis.  As reviewed in the next section, few of the integrated survival analysis and ANN made significant difference in terms of model fittings, compared with the native survival analysis alone The indifference shows that both approaches do not complement each other.  If they are essentially different, the inte grated approach should produce some results that are signifi cantly different from the pure survival analysis alone, either positively or negatively Again, we emphasize that our discussion is still a pure conjecture at this stage   3   B RIEF C ASE R EVIEW OF S URVIVAL A NALYSIS A PPLICATIONS     3.1. Applications Found in IEEE Digital Library  In this section, we briefly review the papers found in the IEEE digital library w ith the keyword of survival analysis  search. The online search was conducted in the July of 2007, and we found about 40 papers in total. There were a few biomedical studies among the 40 survival-analysis papers published in IEEE publications. These are largely standard biomedical applications and we do not discuss these papers, for obvious reasons  Mazzuchi et al. \(1989\m ed to be the first to actively  advocate the use of Cox's \(1 972\ proportional hazards model \(PHM\in engineering re liability.  They quoted Cox's 1972\ original words industrial reliability studies and medical studies to show Cox's original motivation Mazzuchi et al \(1989 while this model had a significant impact on the biom edical field, it has received little attention in the reliability literature Nearly two decades after the introducti on paper of Mazzuchi et al 1989\ears that little significant changes have occurred in computer science and IEEE related engineering fields with regard to the proportional hazards models and survival analysis as a whole  Stillman et al. \(1995\used survival analysis to analyze the data for component maintenance and replacement programs Reineke et al. \(1998 ducted a similar study for determining the optimal maintenance by simulating a series system of four components Berzuini and Larizza \(1996 integrated time-series modeling with survival analysis for medical monitoring.  Kauffman and Wang \(2002\analyzed the Internet firm su rvival data from IPO \(initial public offer to business shutdown events, with survival analysis models  Among the 40 survival analysis papers, which we obtained from online search of the IEEE digital library, significant percentage is the integration of survival analysis with artificial neural networks \(ANN In many of these studies the objective was to utilize ANN to modeling fitting or parameter estimation for survival analysis.  The following is an incomplete list of the major ANN survival analysis integration papers found in IEEE digital library, Arsene et 2006 Eleuteri et al. \(2003\oa and Wong \(2001\,  Mani et al 1999\ The parameter estimation in survival analysis is particular complex due to the requirements for processing censored observations. Therefore, approach such as ANN and Bayesian statistics may be helpful to deal with the complexity. Indeed, Bayesian survival analysis has been expanded significantly in recent years \(Ibrahim, et al. 2005  We expect that evolutionary computing will be applied to survival analysis, in similar way to ANN and Bayesian approaches  With regard to the application of ANN to survival analysis we suggest three cautions: \(1\he integrated approach should preserve the capability to process censoring otherwise, survival analysis loses its most significant advantage. \(2\ Caution should be taken when the integrated approach changes model struct ure because most survival analysis models, such as Cox's proportional hazards models and accelerated failure time models, are already complex nonlinear models with built-in failure mechanisms.  The model over-fitting may cause model identifiability  problems, which could be very subtle and hard to resolve 3\he integrated approach does not produce significant improvement in terms of model fitting or other measurements, which seemed to be the case in majority of the ANN approach to survival analysis, then the extra complication should certainly be avoided. Even if there is improvement, one should still take caution with the censor handling and model identifiability issues previously mentioned in \(1\ and \(2  3.2. Selected Papers Found in MMR-2004  In the following, we briefly review a few survival analysis related studies presented in a recent International Conference on Mathematical Methods in Reliability, MMR 2004 \(Wilson et al. 2005  Pena and Slate \(2005\ddressed the dynamic reliability Both reliability and survival times are more realistically described with dynamic models. Dynamic models generally refer to the models that incorporate the impact of actions or interventions as well as thei r accumulative history, which 


 17 can be monitored \(Pena and Slate 2005\he complexity is obviously beyond simple regression models, since the dependence can play a crucial ro le. For example, in a loadsharing network system, failure of a node will increase the loads of other nodes and influences their failures  Duchesne \(2005\uggested incorporating usage accumulation information into the regression models in survival analysis.  To simplify the model building Duchesne \(2005\umes that the usage can be represented with a single time-dependent covariate.  Besides reviewing the hazard-based regression models, which are common in survival analysis, Duchesne 2005\viewed three classes of less commonly used regression models: models based on transfer functionals, models based on internal wear and the so-called collapsible models. The significance of these regression models is that they expand reliability modeling to two dimensions. One dimension is the calendar time and the other is the usage accumulation.  Jin \(2005\ reviewed the recent development in statisti cal inference for accelerated failure time \(AFT\odel and the linear transformation models that include Cox proportional hazards model and proportional odds models as special cases. Two approaches rank-based approach and l east-squares approach were reviewed in Jin \(2005\. Osbo rn \(2005\d a case study of utilizing the remote diagnostic data from embedded sensors to predict system aging or degradation.  This example should indicate the potential of survival analysis and competing risks analysis in the prognostic and health management PHM\ since the problem Osborn \(2005 addressed is very similar to PHM. The uses of embedded sensors to monitor the health of complex systems, such as power plants, automobile, medical equipment, and aircraft engine, are common. The main uses for these sensor data are real time assessment of th e system health and detection of the problems that need immediate attention.  Of interest is the utilization of those remote diagnostic data, in combination with historical reliability data, for modeling the system aging or degradation. The biggest challenge with this task is the proper transformation of wear  time The wear is not only influenced by internal \(temperature, oil pressures etc\xternal covariates ambient temperature, air pressure, etc\, but also different each time   4  S UMMARY AND P ERSPECTIVE   4.1. Summary  Despite the common foundation with traditional reliability theory, such as the same probability definitions for survival function  S  t  and reliability  R  t  i.e  S  t  R  t well as the hazards function the exact same term and definition are used in both fields\rvival analysis has not achieved similar success in the field of reliability as in biomedicine The applications of survival analysis seem still largely limited to the domain of biomedicine.  Even in the sister fields of biomedicine such as biology and ecology, few applications have been conducted \(Ma 1997, Ma and Bechinski 2008\ the engin eering fields, the Meeker and Escobar \(1998\ monograph, as well as the Klein and Goel 1992\ to be the most comprehensive treatments  In Section 2, we reviewed the essential concepts and models of survival analysis. In Section 3, we briefly reviewed some application cases of survival analysis in engineering reliability.  In computer science, survival analysis seems to be still largely unknown.  We believe that the potential of survival analysis in computer science is much broader than network and/or software reliability alone. Before suggesting a few research topics, we no te two additional points  First, in this article, we exclusively focused on univariate survival analysis. There are two other related fields: one is competing risks analysis and the other is multivariate survival analysis The relationship between multivariate survival analysis and survival analysis is similar to that between multivariate statistical analysis and mathematical statistics.  The difference is that the extension from univariate to multivariate in survival analysis has been much more difficult than the developm ent of multivariate analysis because of \(1\rvation cens oring, and \(2\pendency which is much more complex when multivariate normal distribution does not hold in survival data.  On the other hand, the two essential differences indeed make multivariate survival analysis unique and ex tremely useful for analyzing and modeling time-to-event data. In particular, the advantages of multivariate survival analysis in addressing the dependency issue are hardly matched by any other statistical method.  We discuss competing risks analysis and multivariate survival analysis in separate articles \(Ma and Krings 2008a, b, & c  The second point we wish to note is: if we are asked to point out the counterpart of survival analysis model in reliability theory, we would suggest the shock or damage model.   The shock model has an even longer history than survival analysis and the simplest shock model is the Poisson process model that leads to exponential failure rate model The basic assumption of the shock model is the notion that engineered systems endure some type of wear, fatigue or damage, which leads to the failure when the strengths exceed the tolerance limits of th e system \(Nakagawa 2006 There are extensive research papers on shock models in the probability theory literature, but relatively few monographs The monograph by Nakagawa \(2006\s to be the latest The shock model is often formulated as a Renewal stochastic process or point process with Martingale theory The rigorous mathematical derivation is very similar to that of survival analysis from counting stochastic processes  which we briefly outlined in section 2.6  It is beyond the scope of the paper to compare the shock model with survival analysis; however, we would like to make the two specific comments. \(1\Shock models are essentially the stochastic process model to capture the failure mechanism based on the damage induced on the system by shocks, and the resulting statistical models are 


 18 often the traditional reliability distribution models such as exponential and Weibull failure distributions.  Survival analysis does not depend on specific shock or damage Instead, it models the failure with abstract time-to-event random variables.  Less restrictive assumptions with survival analysis might be more useful for modeling software reliability where the notions of fatigue, wear and damage apparently do not apply.  \(2\hock models do not deal with information censoring, the trademark of failure time data.  \(3\ Shock models, perhaps due to mathematical complexity, have not been applied widely in engineering reliability yet.  In contrast, the applications of survival analysis in biomedical fields are much extensive.  While there have been about a dozen monographs on survival analysis available, few books on shock models have been published.  We believe that survival analysis and shock models are complementary, a nd both are very needed for reliability analysis, with shock model more focused on failure mechanisms and the survival analysis on data analysis and modeling  4.2. Perspective   Besides traditional industrial and hardware reliability fields we suggest that the following fields may benefit from survival analysis  Software reliability Survival analysis is not based on the assumptions of wear, fatigue, or damage, as in traditional reliability theory.  This seems close to software reliability paradigm. The single biggest challenge in applying above discussed approaches to softwa re systems is the requirement for a new metric that is able to replace the survival time variable in survival analysis. This "time" counterpart needs to be capable of characterizing the "vulnerability" of software components or the system, or the distance to the next failure event. In other words, this software metric should represent the metric-to-event, similar to time-toevent random variable in survival analysis.  We suggest that the Kolmogorov complexity \(Li and Vitanyi 1997\n be a promising candidate. Once the metric-to-event issue is resolved, survival analysis, both univariate and multivariate survival analysis can be applied in a relative straightforward manner. We suggest that the shared frailty models are most promising because we believ e latent behavior can be captured with the shared fra ilty \(Ma and Krings 2008b  There have been a few applications of univariate survival analysis in software reliability modeling, including examples in Andersen et al.'s \(1995\ classical monograph However, our opinion is that without the fundamental shift from time-to-event to new metric-to-event, the success will be very limited. In software engineering, there is an exception to our claim, which is the field of software test modeling, where time variable may be directly used in survival analysis modeling  Modeling Survivability of Computer Networks As described in Subsection 2.3, random censoring may be used to model network survivability.  This modeling scheme is particularly suitable for wireless sensor network, because 1\ of the population nature of wireless nodes and \(2\ the limited lifetime of the wireless nodes.  Survival analysis has been advanced by the needs in biomedical and public health research where population is th e basic unit of observation As stated early, a sensor networ k is analogically similar to a biological population. Furthermore, both organisms and wireless nodes are of limited lifetimes. A very desirable advantage of survival analysis is that one can develop a unified mathematical model for both the reliability and survivability of a wireless sensor network \(Krings and Ma 2006  Prognostic and Health Management in Military Logistics PHM involves extensive modeling analysis related to reliability, life predictions, failure analysis, burnin elimination and testing, quality control modeling, etc Survival analysis may provide very promising new tools Survival analysis should be able to provide alternatives to the currently used mathematical tools such as ANN, genetic algorithms, and Fuzzy logic.  The advantage of survival analysis over the other alternatives lies in its unique capability to handle information censoring.  In PHM and other logistics management modeling, information censoring is a near universal phenomenon. Survival analysis should provide new insights and modeling solutions   5  R EFERENCES   Aalen, O. O. 1975. Statistical inference for a family of counting process. Ph.D. dissertation, University of California, Berkeley  Andersen, P. K., O. Borgan, R D. Gill, N. Keiding. 1993 Statistical Models based on Counting Process. Springer  Arsene, C. T. C., et al. 2006.  A Bayesian Neural Network for Competing Risks Models with Covariates. MEDSIP 2006. Proc. of IET 3rd International Conference On Advances in Medical, Signal and Info. 17-19 July 2006  Aven, T. and U. Jensen. 1999. Stochastic Models in Reliability. Springer, Berlin  Bazovsky, I. 1961. Reliability Theory and Practice Prentice-Hall, Englewood Cliffs, New Jersey  Bakker, B. and T.  Heskes. 1999. A neural-Bayesian approach to survival analysis. IEE Artificial Neural Networks, Sept. 7-10, 1999. Conference Publication No 470. pp832-837  Berzuini, C.  and C. Larizza 1996. A unified approach for modeling longitudinal and failure time data, with application in medical mon itoring. IEEE Transactions on Pattern Analysis and Machine Intelligence. Vol. 18\(2 123 


 19 Bollobás, B. 2001. Random Graphs. Cambridge University Press; 2nd edition. 500pp  Cawley, G. C., B. L. C. Talbot, G. J. Janacek, and M. W Peck. 2006. Sparse Bayesian Ke rnel Survival Analysis for Modeling the Growth Domain of Microbial Pathogens  Chiang C. L. 1960. A stochastic study of life tables and its applications: I. Probability distribution of the biometric functions. Biometrics, 16:618-635  Cox,  D. R. 1972. Regression models and life tables J. R Stat. Soc. Ser. B 34:184-220  Cox, D. R. 1975.   Partial likelihood Biometrika 62:269276  Cox, D. R. & D. Oakes. 1984 Analysis of Survival Data  Chapman & Hall. London  Cressie, N. A. 1993 Statistics for Spatial Data John Wiley Sons. 900pp  Duchesne, T. 2005. Regression models for reliability given the usage accumulation history. In "Modern Statistical and Mathematical Methods in Reliability". Edited by A. Wilson N. Limnios, S. Kelly-McNulty Y. Armijo. pp.29-40. World Scientific, New Jersey  Eleuteri, A., R. Tagliaferri, L. Milano, G. Sansone, D D'Agostino, S. De Placido,  M. Laurentiis. 2003.  Survival analysis and neural networks. Proceedings of the International Joint Conference on Neural Networks, Vol. 4 20-24 July 2003 Page\(s\:2631 - 2636  Ellison, E., L. Linger, and M Longstaff. 1997.  Survivable Network Systems: An Emerging Discipline, Carnegie Mellon, SEI, Technical Report CMU/SEI-97-TR-013, 1997  Fleming, T. R. & D. P. Harrington. 1991. Counting process and survival analysis. John Wiley & Sons. 429pp  Graver, J. and M. Sobel 2005. You may rely on the Reliability Polynomial for much more than you might think Communications in Statistics: Theory and Methods  34\(6\1411-1422  Graves, T. and M. Hamada. 2005. Bayesian methods for assessing system reliability: models and computation. In Modern Statistical and Mathematical Methods in Reliability". Edited by A. Wilson, et al. pp.41-53  Grimmett, G. 2006 The Random-Cluster Model Springer  Grimmett, G. 1999 Percolation Springer  Hougaard, P. 2000. Analysis of Multivariate Survival Data Springer. 560pp  Ibrahim, J. G., M. H. Chen and D. Sinha. 2005. Bayesian Survival Analysis.  Springer. 481pp  Jin Z. 2005. Non-proportional semi-parametric regression models for censored data. In "Modern Statistical and Mathematical Methods in Reliability". Edited by A. Wilson N. Limnios, S. Kelly-McNulty, Y. Armijo. pp.279-292 World Scientific  Kalbfleisch, J. D. & R. L. Prentice. 1980 The Statistical Analysis of Failure Time Data John Wiley & Sons.  New York. 1980  Kalbfleisch, J. D. &  R. L. Prentice, 2002. The Statistical Analysis of Failure Time Data.  Wiley-InterScience, 2nd ed 462pp  Lisboa, P. J. G. and H. Wong. 2001. Are neural networks best used to help logistic regression? Proceedings of International Joint Conference on Neural Networks, IJCNN 01. Volume 4, 15-19,  July 2001. Page\(s\:2472 - 2477 vol.4  Kauffman, R. J. and B. Wang. 2002. Duration in the Digital Economy. Proceedings of th e 36th Hawaii International Conference on System Sciences \(HICSS’03\ Jan 2003  Kaplan, E. L. & P.  Meier.  1958.  Nonparametric estimation from incomplete observations J. Amer. Statist. Assoc  53:457-481  Klein, J. P. and P. K. Goel 1992. Survival Analysis: State of the Art.  Kluwer Academic Publishes. 450pp  Klein, J. P. and  M. L Moeschberger. 20 03. Survival analysis techniques for ce nsored and truncated data Springer  Krings, A. and Z. S. Ma. 2006.  "Fault-Models in Wireless Communication: Towards Survivable Ad Hoc Networks MILCOM 2006, Military Communications Conference, 2325 October, 7 pages, 2006  Krings, A. W. 2008.  Survivable Systems.  in Information Assurance: Dependability and Security in Networked Systems Yi Qian, James Joshi, David Tipper, and Prashant Krishnamurthy, Morgan Kaufmann Publishers. \(in press  Lawless, J. F. 1982. Statistical models and methods for lifetime data.  John Wiley & Sons. 579pp  Lawless, J. F. 2003. Statistical models and methods for lifetime data.  John Wiley & Sons. 2nd ed. 630pp  Li, M. and P. Vitanyi. 1997. Introduction to  Kolmogorov Complexity and Its Applications. 2nd ed, Springer  Ma, Z. S. 1997.  Survival analysis and demography of Russian wheat aphid populations.  Ph.D dissertation, 307pp University of Idaho Moscow, Idaho, USA 


 20 Ma, Z. S., and E. J. Bechinski. 2008.  Developmental and Phenological Modeling of Russian Wheat Aphid Annals of Entomological Soc. Am In press  Ma, Z. S. and A. W. Krings. 2008a. The Competing Risks Analysis Approach to Reliability Survivability, and Prognostics and Health Management.  The 2008 IEEEAIAA AeroSpace Conference. BigSky, Montana, March 18, 2008. \(In Press, in the same volume  Ma, Z. S. and A. W. Krings 2008b. Multivariate Survival Analysis \(I\e Shared Frailty Approaches to Reliability and Dependence Modeling. The 2008 IEEE-AIAA AeroSpace Conference. BigSky Montana, March 1-8, 2008 In Press, in the same volume  Ma, Z. S. and A. W. Krings. 2008c. Multivariate Survival Analysis \(II\ Multi-State Models in Biomedicine and Engineering Reliability. 2008 IEEE International Conference on Biomedical Engineering and Informatics BMEI 2008\27th-30th, 2008 Accepted   Mani, R., J. Drew, A. Betz, P. Datta. 1999. Statistics and Data Mining Techniques for Lifetime Value Modeling ACM Conf. on Knowledge Discovery and Data Mining  Mazzuchi, T. A., R Soyer., and R. V Spring. 1989. The proportional hazards model in reliability. IEEE Proceedings of Annual Reliability and Maintainability Symposium pp.252-256  Meeker, W. Q. and L. A. Escobar. 1998. Statistical Methods for Reliability Data. Wiley-Interscience  Munson, J. C. 2003. Software Engineering Measurement Auerbach Publications  Nelson, W. 1969. Hazard plotting for incomplete failure data J. Qual. Tech 1:27-52  Nakagawa, T. 2006.  Shock and Damage Models in Reliability Theory. Springer  Osborn, B. 2005. Leveraging remote diagnostics data for predictive maintenance.   In "Modern Statistical and Mathematical Methods in Reliability". Edited by A. Wilson N. Limnios, S. Kelly-McNulty, Y. Armijo. pp. 353-363  Pena, E. A. and E. H. Slate. 2005. Dynamic modeling in reliability and survival analysis. In "Modern Statistical and Mathematical Methods in Reliability". Edited by A. Wilson N. Limnios, S. Kelly-McNulty, Y. Armijo. pp.55-71  Reineke, D. M., E. A. Pohl, and W. P. Murdock. 1998 Survival analysis and maintenance policies for a series system, with highly censore d data.  1998 Proceedings Annual Reliability and Maintainability Symposium. pp 182-188  Schabenberger, O. and C. A. Gotway. 2005. Statistical Methods for Spatial Data Analysis.  Chapman & Hall/CRC  Severini, T. A. 2000. Likelihood methods in statistics Oxford University Press  Shooman, M. L. 2002. Reliability of Computer Systems and Networks: Fault Tolerance, Analysis and Design. John Wiley and Sons. 551pp  Stillman, R. H. and M. S. Mack isack, B. Sharp, and C. Lee 1995. Case studies in survival analysis of overhead line components. IEE Conferen ce of the Reliability and Distribution Equipment. March 29-31, 1995. Conference Publication No. 406. pp210-215  Therneau, T. and P. Grambsch. 2000 Modeling Survival Data: Extending the Cox Model Springer  Wilson, A.  N. Limnios, S Kelly-McNulty, Y. Armijo 2005. Modern Statistical and Mathematical Methods in Reliability. World Scientific, New Jersey  Xie, M. 1991. Software Reliability Modeling. World Scientific Press    B IOGRAPHY   Zhanshan \(Sam\ Ma holds a Ph.D. in Entomology and is a Ph.D. candidate in Computer Science at the University of Idaho. He has published approximately 30 journal and 30 conference papers, mainly in the former field.  Prior to his recent return to academia, he worked as senior network/software engineers in software industry.  His current research interests include reliability and survivability of wireless sensor networks, fault tolerance survival analysis, evolutionary game theory, evolutionary computation and bioinformatics  Axel W. Krings is a professor of Computer Science at the University of Idaho.  He received his Ph.D. \(1993\ and M.S 1991\ degrees in Computer Science from the University of Nebraska - Lincoln, and his M.S. \(1982\ in Electrical Engineering from the FH-Aachen, Germany.  Dr. Krings has published extensively in the area of Computer Network Survivability, Security, Fault-Tolerance and Realtime Scheduling. In 2004/2005 he was a visiting professor at the Institut d'Informatique et Mathématiques Appliquées de Grenoble, at the Institut National Polytechnique de Grenoble, France.  His work has been funded by DoE/INL DoT/NIATT, DoD/OST and NIST 


