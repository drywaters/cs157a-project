For the ability to explore the memorys fullest potential, memory de-duplication has been widely experimented with in current main stream virtualization platforms. A lot of work has been done to improve the efficiency of memory deduplication, while too little attention was paid to the introduced security issues which have been proved by prior work.  To deal with this security risk and efficiently manage the memory we 
Abstract 
SEMMA: Secure Efficient Memory Management Approach in Virtual Environment  Xian Chen, Wenzhi Chen, Peng Long, Zhongyong Lu, Zonghui Wang College of Computer Science and Technology Zhejiang University, Hangzhou, China Email: {chenxiancool, chenwz, longpeng, lzy6032, zhwang}@zju.edu.cn   
start our work in this paper. We first conduct extensive experiments on different OS platforms to study the realistic situation of page sharing By analyzing the results we find 1\ Page sharing is contributed mostly by self-sharing \(nearly 90%\nd the self-sharing rate varies significantly between Linux and Windows OS platforms. Compared with self-sharing the inter-VM sharing rate is extremely low, under 1% in most cases. 2\ Page size has a larger influence on Linux platform than Windows platform, so sub-page de-duplication proposed in prior work may achieve better performance on Linux platform. On the basis of above findings we propose a group-based secure page sharing model \(or GSKSM\, in which we consider both VM 
processes and normal processes. We have successfully implemented it in Linux kernel 3.6.6, and the experiment results show it works well with negligible overhead. Finally based on GSKSM we further present an efficient memory management approach \(or SEMMA\, which combines GSKSM and balloon technique to efficiently manage the memory, and the preliminary experiment result is satisfactory 
 I NTRODUCTION  Nowadays cloud computing is widely-known not only in academia and industry but also in our daily life. As the key technology of cloud computing, virtualization plays an import 
Keywords„virtual machine; KSM; Ballooning technique memory de-duplicaiton 
 
I 
role in many fields for its ability to efficiently manage the underlying hardware resources and enable cloud service providers to service many tenants simultaneously. With virtualization one physical machine in cloud computing center could run several virtual machines which are rent to the tenants, thus the utilization of hardware resources can be significantly improved. But as the number of tenant increases the workload on an individual physical machine becomes heavier, thus the performance of VMs running on it will be affected differently. One main cause is the memory capacity is not sufficient, which has triggered a lot of academic work 6    i n  t h i s fi e l d t o e x p l or e t h e m e m o r y s ful l e st  
potential. One direction is to de-duplicate the duplicate memory content to ease the physical machines memory pressure. The representative technique is content-based page sharing \(CBPS\ [6 w h ich is im plem en ted  in th e h y perv is or  layer and has already been experimented with in current main stream virtualization platforms, e.g., XEN KV M [12 and VMware ESX [21  A lot of work has been done to improve the efficiency of CBPS, and it is adopted in many fields such as VM migration 13 an d  VM  ch e ck po in tin g 1 4   B u t t o o litt le  at ten ti on w as  paid to its introduced security problems. As presented in [4   one VM user can use the difference in write access time to 
snoop the working set running on the other VM, which is unacceptable for the tenants whose applications running in their rented VMs are very important. On the other hand, work in [2 h a s p r o v ed th at th e in t e rVM sh ar in g r a te is ex tr em ely  low, which is also validated in our following experiments. So in theory, group mechanism is the best way to solve this security risk, because it isolates all the VMs into different groups, avoiding the malicious memory detection from the root cause. This is what we will present in section IV In addition to page sharing, there are also some other techniques to overcommit the memory [1  e.g  s w appi n g  mechanism, balloon technique [1 nd m e m o r y c o m p ress  Swapping is controlled by the operating system, and may cause 
high performance cost, so its usually the last choice. Balloon technique is a widely adopted skill, and the achieved performance is very good. On the other hand, much work has been done to appropriately use balloon technique to balance memory load in host machine, e.g., [19 an d  2 0  B u t  all  t h e  prior work only considers balloon technique, lack of a reasonable management approach which can take all the memory overcommit techniques or several of them into consideration, and this is the motivation of our work in section V The rest of the paper is organized as follows. The related work is introduced in section II, section III presents our 
experimental study on page sharing, and then we detail our proposed group-based secure page sharing model \(GSKSM\ in section IV. Section V will describe our secure efficient memory management approach \(SEMMA\, which is based on the work in section IV. Section VI is about our conclusion and future work II 
RELATED WORK  Disco [5 is th e f i rs t sy stem to im p l em en t p a g e sh ar in g to  improve memory utilization on a multiprocessor platform. It uses Copy-On-Write mechanism on disks. If the content that a 
 
2013 International Conference on Advanced Cloud and Big Data 978-1-4799-3261-0/14 $31.00 © 2014 IEEE DOI 10.1109/CBD.2013.32 131 


 
 
  
 
Hardware \(DELL OPTIPLEX 9010 Software Configuration 
EXPERIMENTAL STUDY ON PAGE SHARING  To better understand the real situation of page sharing in virtual environment, we conduct extensive experiments in several different scenarios. Table I shows the detailed configuration in our experimental environment TABLE I Processor type Intel I7-3770 Number of cores 4 cores \(8 threads Clock frequency 3.4GHZ Memory 8GB DDR3 1600 Disk 500GB SATA 7200rpm Host OS Ubuntu12.04 LTS \(64 bits kernel3.6.6 QEMU 1.4.0 VM CPU:2  Memory:1GB  IMG:10G/30G  We run Ubuntu12.04 \(64 bits\on our hardware platform and recompile kernel3.6.6 in the host OS for the need of following experiments. As to VMM, we chose Qemu1.4 for the front end of the KVM module, because this version has supported the stable KSM. In our tests, we configure each VM instance with 2 cores, 1GB memory and 10GB virtual disk \(30 GB in kernel building experiments 
A Data Collection 
VM instance wants to read from a COW disk is already in the main memory, the VM instance directly maps the content page into its own address space, reducing the memory footprint and access time. However it needs to modify the guest operating system, which severely limits its implementation and usage Content-based page sharing is proposed in VMware ESX 6  i t is im plem en ted in th e h y perv iso r lay er an d d o es  n o t  need the assistance from the guest machine. The feature of transparent to the guest OS makes CPBS widely adopted in many virtualization systems.  As one implementation of CBPS in Linux  co ul d sig nificantly im p r o v e the a b i lity o f  KVM, and work in [16   d o e s s o m e op t i m i z a t i o n t o m a ke the native KSM work more efficiently. Potemkin [15 is another system based on the core idea of CBPS, in which new virtual machines can be created as clones of an existing VM image, thus the benefit of page sharing is greatly explored Based on CBPS, another type of page sharing is proposed in Different Engine hi c h i s  c a l l e d sub p a ge sh a r i ng. Sub page sharing not only explores the potential of the same pages but also the similar pages. For its excellent performance Memory Buddies [10 s adop ted  it in V M m i gr a t i o n  13 and VM consolidation  Empirical studies of memory sharing in virtual environment have been done in 2 I n 1  t h e a u t hor s c o n d uc t e x t e nsi ve  experiments on the effectiveness of KSM on various kinds of workload. They find that for mixed CPU and I/O workload KSM could achieve the most significant memory saving. But for CPU intensive applications, KSM does not have significant effect on dynamic sharing and it also causes higher runtime overhead Different from  2  do e s  no t o n l y foc us o n t h e o u t p ut  performance of benchmarks, they provide insight into the typical sources of sharing potential through an exploration and analysis of memory traces captured from real user machines and controlled virtual machines. They find that the absolute memory sharing rate is generally under 15%, contrasting with prior work, but partly in accordance with what we have got Another important fact demonstrated in [2 is sh arin g w i t h in  individual machines accounts for nearly all \(>90%\ of the sharing within a set of machines, also in accordance with our results The security issues introduced by KSM has been proved in 4 t h e y p ropo se a cr o ss-VM at t a c k m e t h o d t o snoop  t h e working set running on the other VM with the help of the difference in write access time on de-duplicated memory pages. In their experiments, they have successfully detected the existence of sshd and apache2 on Linux, and IE6 and Firefox on Windows XP Work in [3 is sim ilar t o th e s ec o n d  pa rt  of  ou r w o rk   T h ey  also propose a group-based approach to solve the secure risk introduced by page sharing. However, they split the global ksmd thread into per-group ksmds with a cgroup-based user interface. In our implementation we use only one ksmd thread which can provide all the functions in [3 bu t w ith n o  additional cost of other ksmd threads. In addition, the normal processes are also taken into consideration in our work in this paper Ginkgo [20 pro vi de s a m e m o r y o v e rco mm i t fr a m e w o r k  which regularly monitors application progress and incoming load for each VM. Then use this data to predict application performance under different VM memory sizes, and automatically adjust VMs memory occupation. Ginkgo only considers balloon technique while in our work we also take page sharing into consideration III There are some ready-made tools for us to fetch the memory of VM instances e.g., pmemsave command in Qemu monitor and snapshot command in virsh monitor. In our experiments, we find that the dump files generated by the tools are not corresponding to the real situation of resident memory the dump files are usually larger than the memory actually used. Then, we dive into this issue, finding out that all the tools generate a zero page when the page is not in physical memory or even does not have an entry in the page table, but those pages should not be contained in the dump files. This situation may be the cause of many zero pages in memory traces proved in prior work. So we make a tool to generate the dump files which only contain these pages resident in physical memory The tool works intuitively: it scans all the VMAs \(Virtual Machine Area\of a specific VM process, if one page in the VMA is resident in physical memory, then it will be put into the dump file. In addition, our tool can fetch the memory actually used by a normal process, thus we can analysis the page duplication rates of normal processes In order to fully study the situation of page sharing on different OS platforms, we configure 7 distinct VMs, each with 1GB physical memory Centos 6.4 \(no GUI\d Ubuntu 12.04 LTS These distributions were chosen to be representative of 
EXPERIMENTAL ENVIRONMENT  
 
Linux 
132 


    
    
  
typical desktop. we consider both 32-bit and 64-bit versions \(4 VMs in total both Windows 7 x86 and X64 versions, and also Windows XP \(3 VMs in total We conduct our experiments in three scenarios as follows The VM is freshly booted, but not running any further applications. When the VM is running steadily, we stop the VM, and use our tool to fetch the VMs memory content. Three dump files each VM instance, 21 dump files in total In this scenario, the VM runs several normal applications, e.g., web browser, email client, office applications, media player. As the memory is not stable when the VM instance is running applications, we generate a dump file every 3 minutes lasting for 30 minutes We choose kernel build as the work load running in VM instances as [7 g e ne ra t i ng a dump file every 15 seconds, lasting for 30 minutes All the memory traces are generated when the VMs are stopped, so the VMs are not affected when tracing, and the logical time spent on tracing is zero As described in w e sep ar a t e sh a r ing p a ge s int o tw o  main categories: self-sharing \(sharing within single VM inter-VM sharing \(sharing between different VMs\. To clearly depict what the two categories really mean, we use two figures to show how to calculate self-sharing rate and inter-VM sharing rate      Figure 1. Self-sharing       Figure 2. Inter-VM Sharing  In Figure 1, there are three VMs \(VM1, VM2, VM3\ each contains sharable memory pages: both VM1 and VM2 have three copies of page P, VM3 has three copies of page Q which is different from page P. If we only consider self-sharing, each VM can reduce its memory footprint to one third of the original space: only one copy of page P is reserved in VM1 and VM2 one copy of page Q in VM3. If we take inter-VM sharing into consideration, the remainder pages in VM1 and VM2 could be shared further as depicted in Figure 2. Then we can expand the benefit of page sharing, even though the inter-VM sharing only occupies a very small fraction. From the above analysis, we could get the self-sharing rate for each VM in Figure 1 is 67 2/3\, and the inter-VM sharing rate among three VMs in Figure 2 is 11.1% \(1/9\. In the following tests, we will use the same method to calculate the page sharing rates To gain deeper insight into the page sharing rates in virtualization environment, we conduct several experiments both on different OS platforms and in different usage scenarios First we study the self-sharing on different platforms in no workload scenario. As depicted by Figure 3, there is a big gap between Linux and Windows platforms. The self-sharing rate is only less than 18% on Linux platforms, while it can reach as high as 87% within Windows XP. With further work, we find that this is caused by their different memory management mechanisms, for Windows OS it will occupy all the memory declared for it when the VM is created, while for Linux OS the memory is used on demand. In addition, we could find the majority of self-sharing on Windows platforms is occupied by zero pages, while little on Linux platforms  Figure 3. Self-sharing On Different OS Platforms Without Workload  Figure 4. Self-sharing On Different OS Platforms With Normal Workloads 
B Calculating Sharing C Page Sharing In VMs 
Windows No workloads Normal workloads  Kernel build workload  
133 


D Impact Of Page Size On Page Sharing 
1 2 
 Figure 5. Comparison Between Non-workload And Normal Workloads Figure 4 shows the self-sharing rates on different OS platforms with normal applications running in guests, its similar to Figure 3, but the decrease in self-sharing rate on Windows platforms can be easily found, especially for window 7 \(64 bits\. Figure 5 can better depict this phenomenon, and we deduce this is because zero pages in self-sharing have been used by the normal applications. For Linux platforms, zero pages occupy very little part of self-sharing, so little influence on them  Figure 6. Inter-VM Sharing Between Virtual Machine Pairs Second we study the inter-VM sharing between different virtual machines, and the result is presented in Figure 6. On the whole, inter-VM sharing rate is extremely low, occupying only 2.4% even in the best case and below 1% in most cases. If we dive into Figure 6, we can notice some interesting things  The inter-VM sharing rate is usually higher when the VMs have the same OS but different versions, e.g., 32-bit Ubuntu 12.04 and 64-bit Ubuntu 12.04 The inter-VM sharing rate between different OS platforms is usually lower \(under 1 In our experiments the dump files of Linux are about 600 MB and 1G for Windows, then by combining Figure 5 and Figure 6 we could easily conclude that majority of page sharing between different OS platforms is contributed by the selfsharing within individual VM, while the inter-VM sharing only occupies about 10 Third we use the kernel build workload to test the volatility of page sharing, Figure 7 shows the result. From Figure 7 we could conclude that the page sharing rate varies with workload so we should use dynamic mechanism to exploit the benefit of page sharing  Figure 7. Sharing Pages On Kernel Build Workload  Previous works in  ve de m o nstr a t e d  tha t  significant benefits can be achieved by sharing portions of similar, but not identical pages. In order to further study the real situation, we take a close look at our collected traces from the above experiments. This time we calculate the page sharing rate with different page size ranging from 1KB to 16KB, and the result is presented in Figure 8. The x-axis shows the page size in KB, the y-axis represents the page sharing rate which has been normalized to 4KB \(normal page size\. In Figure 8 we can see the influence of page size on Linux platform is larger than Windows platform, especially when page size is smaller than 4KB. So subpage level sharing proposed in prior work may bring more benefits for Linux platforms, and 4KB seems already OK for Windows platforms  Figure 8. Impact of Page Size On Page Sharing Rate IV 
GROUP BASED SECURE PAGE SHARING MODEL  As proved by [2 an d ou r w o rk  in s e c t i o n I I I th e pag e  sharing rate between different VMs is really low compared with self-sharing rate. On the other hand, the prior work in [4 has demonstrated that one VM user can use cross-VM attack to snoop the working set running on other VMs which are resident in the same physical machine. This is unacceptable for the tenants whose applications running in their rented VMs are very important. So we deem that a secure mechanism must be implemented to reduce the risk of information leakage. Groupbased page sharing is the best way to address the security issue as it isolates all VMs into different groups, thus one cannot snoop the memory information resident in other VMs by the shared pages 
 
 
134 


  
   
A Architecture B Implementation C Evaluation 
 
In this section we propose a group-based secure page sharing model, in which we assign all VMs into different groups as  a c c o rd i ng t o  t h e ne ed s o f  t e na nt s   b u t w e dont  split the global ksmd \(server thread\nto per-group ksmds which we think will introduce more cost on memory space and executing time. In addition, our model can automatically group the normal processes into a private group which does not contain any VM process. We have successfully implemented the model in kernel 3.6.6, and test results show it can work well with negligible overhead   Figure 9. Architecture Of Group-based Secure Page Sharing Model Figure 9 presents the overall architecture of our proposed group-based secure page sharing model. As the model demonstrates, group controller can construct two kinds of groups: VM group and private group \(denoted by the red dashed line box\. VM group only contains VM processes of different tenants, one group is corresponding to a tenant. The private group is used only for the normal processes running in the host OS, through this group we could de-duplicate the duplicate memory content in normal processes, thus expanding the benefit of page sharing in host machine The construction and destruction of each group is controlled by the group controller module which also exposes an interface to the user space. In addition, we can also tune the merging speed of every group respectively. If the workload is too heavy in one group, we can let the merging service thread occupy less CPU time by lowering the merging speed and vice versa The normal process analyzer is responsible for selecting appropriate normal processes which should have large memory footprint and the page sharing rate is relatively high. Once the normal processes are determined, this module puts them into the private group through user space interface. In the process of selecting appropriate candidates, the normal process analyzer module first sorts all the processes \(except for VM processes running in the host OS by their memory footprint, then select those with enough memory footprint and estimate their page sharing rates with the help of page sharing detector module Eventually, the processes with large memory footprint and high page sharing rate will be selected and put into the private group From a certain meaning, the VM groups decider module in Figure 9 refers to the cloud service provider who should isolate all the VMs into different merging groups in accordance to the will of the tenants Our proposed page sharing model is implemented based on KSM in ker ne l 3 6.6  As pr e s e nted in Figure  9   e a c h group  has two red-black trees, one is the stable tree and the other is the unstable tree. The stable tree contains all the already shared and not changing KSM generated pages while the unstable tree is used to maintain the pages which are not shared yet but still tracked by KSM. The detailed operations on the two trees are same as those implemented in KSM To reduce the cost on memory space and CPU time, we only construct a main merging thread to manage all the groups which is different from [3 T h e m a i n m e r g i ng t h r e ad \(i  e  ksmd\peatedly scans all the memory content in each group and merges these pages with the same content. Here we use the weight mechanism to treat every group fairly, in which every group has a weight value corresponding to its workload, and the weight value ranges from 0 to 10. If a group wants to get more benefits from page sharing, so it should have a larger weight value, then the main thread will spend more time on merging same content pages in this group. In our implementation we calculate the number of pages which the main thread should scan for each group by the following formula  In the above formula, GroupPages represents the number of pages which the main thread should scan for a group, N is the number of existing groups, MaxPages is the number of pages the main thread should scan for a group if all the groups have the same weight value. GroupWeight represents the groups weight value and the TotalWeight is the sum of all the groups weight values As to normal processes, we implemented a daemon to repeatedly analyze the memory footprint and page sharing rate of the applications running on the host machine. In the process of analysis, the daemon first sorts all the normal server processes by their memory footprint, then select those with enough memory occupation. Once the candidates are determined, the daemon will use page sharing detector kernel module to determine whether the page sharing rate is enough high, if all conditions are appropriate, the process will be selected and put into the private group to make its contribution to the benefit of page sharing  To evaluate the performance of our proposed group-based secure page sharing model, we select three VMs \(32 bits Ubuntu 12.04, 32 bits Windows 7 and Windows XP\d group them with different combinations as follows we put the three VMs into one group, and calculate the total sharing pages every 2 seconds lasting for about 220 seconds 
 
t TotalWeigh t GroupWeigh MaxPages N GroupPages 
One Group 
135 


SECURE EFFICIENT MEMORY MANAEMENT APPROACH  Based on our work in section IV, we further propose a novel memory management approach which we named SEMMA. As we all know there are several methods to allow a virtual machine to overcommit its memory, e.g., swapping mechanism, balloon technique and page sharing. The swapping mechanism is automatically managed by OS, and may cause high performance cost, so not suitable for user to use. Balloon technique is a widely used skill in current main stream virtualization platforms, and it is implemented as a virtual device. When it inflates, it will take some memory from the guest, and give the reclaimed memory to the host this situation is also called guest shrinking. When the guest does not have enough memory for its applications, it will deflate the balloon, thus some memory will be back to the guest. In the actual production environment balloon technique is really a powerful tool for cl oud system administrator to balance the memory load while providing stable performance However, there still lack of a reasonable memory management approach which can consider all the memory overcommit techniques or several of them, and this is the motivation of SEMMA 
Two Groups Three Groups MUV MUP UR MUH 
       
 
      
A Premise Explanation 
the VMs running Ubuntu and Windows 7 are in the same group, while Windows XP in another group, then calculate the total sharing pages as above one VM occupies one group, the calculation method is the same as the above  Figure 10. Total Sharing Pages Using Different Grouping Methods In order to get rid of the influence of normal processes, we disable the normal process analyzer module in our tests. The experiment result is depicted by Figure 10. Because its hard to make all the test scenarios completely consistent, so the time intervals between the start moment and the moment all the VMs are running smoothly differ from each other, but this will not influence the conclusion. As depicted in Figure 10 once the state is stable, the number of total sharing pages with different grouping methods is very close, which indicates that the overhead of our grouping mechanism on the page sharing is low In addition, we also conduct another contrast experiment to evaluate the efficiency of the normal process analyzer module NPA\ this experiment we just construct one VM group containing three VMs running Ubuntu 12.04, Windows 7 and Windows XP. In the host we start Firefox browser to browse some web sites and open the Office tools to edit several texts then we calculate the total sharing pages achieved by GSKSM when NPA is enabled and disabled, the result is shown in Figure 11  Figure 11. Total Sharing Pages With Different NPA configuration  If we enable the normal process analyzer module, we can get 47436 more sharing pages \(about 185MB\ and the performance is improved by about 13%. These added pages are mainly contributed by the Firefox browser and Office tools V SEMMA is based on the group-based secure page sharing model proposed in section IV, and now under implementation To clearly describe its working mechanism, we make the following definition memory used in virtual machines memory actually used by the VM process calculated by dividing MUV by MUP. It indicates the actually memory used percentage by the guest memory utilization in host machine To efficiently use the memory in host, we always maintain UR between the lower bound \(70% in current implementation and the upper bound \(80%\, if UR is higher than the upper bound, the guest has little free memory for its applications, and the performance may be influenced, so the host should return the occupied memory to the guest by deflating the guests balloon driver until UR is lower than the upper bound. If UR is lower than the lower bound, the memory occupied by the guest is more than its actually need, so we should reclaim the unused memory by inflating the balloon driver, then the host will have more free memory and can host more virtual machines As to page sharing, we adjust the scan speed of each group according to the hosts memory load. Here we also define two thresholds: the lower bound \(60% in current implementation and the upper bound \(80%\f the MUH is higher than the upper bound, which indicates the host is suffering higher memory load, then we speed up GSKSM scanning to generate more usable memory by merging more pages. When MUH is lower than the lower bound, the host has enough free memory for all the VMs running on it, and then we should slow down the scanning to reduce the overhead of GSKSM. More detailed mechanism is presented in Algorithm 1 
136 


  
B Architecture and Implementation C Evaluation 
 Figure 12. Architecture Of SEMMA As depicted by Figure 12, SEMMA contains three main subsystems: memory usage information collector \(or MUIC decision maker and GSKSM \(proposed in section 4\. MUIC periodically collects three types of memory utilization, i.e MUV, MUP and MUH. Its easy to collect MUP and MUH just by executing top command in the host, while some more work is needed to get the memory usage information from the guests, but still there are many ways to finish this work. In current implementation, we use a network application for the guests running Windows OS, while just executing the scp command for the guests running Linux OS According to value of MUV, MUP and MUH, decision maker will take corresponding actions for each VM as presented in Algorithm 1. If it wants to reclaim/return memory from/to a guest, it needs to use the interfaces provided by Qemu monitor to inflate or deflate the balloon driver \(or BD If the host is suffering from heavier memory load, the GSKSM module will be notified to speed up the scanning to generate more free pages We conduct an experiment to evaluate the efficiency of SEMMA, in which we create a VM instance when the memory utilization in the host is about 75%, and use it to browse some web sites and edit some documents. At the same time we record the memory utilization in the host machine with three different configurations: disable KSM and SEMMA, only enable KSM and only enable SEMMA  Figure 13. Memory Usage In Host With Different Configurations As shown in Figure 13, in the beginning the memory utilization is about 75% resulting from other workloads running in the same host machine, then it increases gradually when the VM instance is being created. When the creating is done the memory usage is about 83%, if without any optimization it will increase by about 3% for the following operations in VM. If SEMMA is enabled, there will be a sharp down in the memory footprint. This is because the balloon technique is triggered when the UR is lower than the lower bound \(70%\, which indicates there are many unused memory in guest, so the balloon driver is inflated to reclaim some memory from the guest, maintaining the UR always between the lower bound and the upper bound. For native KSM, the result is also not bad, but still about 2.5% \(205MB\higher than SEMMA It should be noted that: in our experiment we only construct one VM instance running Linux OS, so the benefit is not very obvious. If more VMs are taken into consideration or the VM is running Windows OS, the result will be better. SEMMA is still under implementation, many optimizations can be added to it, although the preliminary test result is a bit satisfactory VI CONCLUSION  AND  FUTURE  WORK In this paper we first conduct extensive experiments on different OS platforms to study the real situation of page sharing, and get several conclusions: 1\ Self-sharing occupies majority of the total page sharing, nearly 90%, and the selfsharing rate is very different between Linux and Windows platforms. Compared with self-sharing the inter-VM sharing rate is extremely low, under 1% in most cases. 2\ Page size has a larger influence on Linux platform than Windows platform so sub-page de-duplication may achieve better performance on Linux platform. On the basis of the above findings we propose a group-based secure page sharing model \(or GSKSM\ which not only considers the VM processes but also the normal processes. We have successfully implemented it in Linux kernel 3.6.6, and the results show it works well with negligible overhead. Based on GSKSM, we further present a secure efficient memory management approach \(SEMMA\, which combines GSKSM and balloon technique to efficiently manage 
 
Algorithm 1  Core processing in Decision Maker for all if  then else if then end if end if if then else if end if end if end for 
VMs in host  UR > UR_UPPER_BOUND guest does not get all its memory  deflate the balloon driver to return the occupied memory to guest  UR < UR_LOWER_BOUND  inflate the balloon driver to reclaim the unused memory from guest    MUH > MUH_UPPER_BOUND  speed up GSKSM scanning to generate more usable memory  MUH < MUH_LOWER_BOUND slow down GSKSM scanning to reduce the overhead of GSKSM   
137 


Chang Chao-Rui, Jan-Jan Wu, and Pangfeng Liu. "An empirical study on memory sharing of virtual machines for server consolidation Parallel and Distributed Processing with Applications \(ISPA\, 2011 IEEE 9th International Symposium on. IEEE, 2011 000\003 2 Sean Barker, Timothy Wood, Prashant Shenoy, Ramesh Sitaraman. "An empirical study of memory sharing in virtual machines." Usenix ATC 2012 3 Sangwook Kim, Hwanju Kim, Joonwon Lee. "Group-Based memory deduplication for virtualized clouds." Euro-Par 2011: Parallel Processing Workshops. Springer Berlin Heidelberg, 2012 4 Kuniyasu Suzaki, Kengo lijima, Toshiki Yagi, Cyrille Artho. "Mem ory deduplication as a threat to the guest OS." Proceedings of the Fourth European Workshop on System Security. ACM, 2011 5 Edouard Bugnion, Scott Devine, Kinshuk Govil, Mendel Rosenblum Disco: Running commodity operating systems on scalable multiprocessors." ACM Transactions on Computer Systems \(TOCS 15.4 \(1997\: 412-447 6 Waldspurger, Carl A. "Memory resource management in VMware ESX server." ACM SIGOPS Operating Systems Review 36.SI \(2002\: 181194 7 Grzegorz Mi 001\003 s, Derek G.Murray, Steven Hand, Michael A. Fetterman Satori: Enlightened page sharing." Proceedings of the 2009 conference on USENIX Annual technical conference. USENIX Association, 2009 8 Arcangeli, Andrea, Izik Eidus, and Chris Wright. "Increasing memory density by using KSM." Proceedings of the linux symposium. 2009 9 Diwaker Gupta, Sangmin Lee, Michael Vrable, Stefan Savage, Alex C Snoeren, George Varghese. "Difference engine: Harnessing memory redundancy in virtual machines." Communications of the ACM 53.10 2010\: 85-93  Timothy Wood, Gabriel Tarasuk-Levin, Prashant Shenoy. "Memory buddies: exploiting page sharing for smart colocation in virtualized data centers." Proceedings of the 2009 ACM SIGPLAN/SIGOPS international conference on Virtual execution environments. ACM 2009  Paul Barham, Boris Dragovic, Keir Fraser, Steven Hand, Tim Harris Xen and the art of virtualization." ACM SIGOPS Operating Systems Review 37.5 \(2003\4-177  Avi Kivity, Yaniv Kamay, Dor Laor. "kvm: the Linux virtual machine monitor." Proceedings of the Linux Symposium. Vol. 1. 2007  Christopher Clark, Keir Fraser,Steven Hand, Jacob Gorm Hansen, Eric Jul. "Live migration of virtual machines." Proceedings of the 2nd conference on Symposium on Networked Systems Design Implementation-Volume 2. USENIX Association, 2005  Saurabh Agarwal. Rahul Garg, Meeta S. Gupta, Jose E. Moreira Adaptive incremental checkpointing for massively parallel systems Proceedings of the 18th annual international conference on Supercomputing. ACM, 2004  Michael Vrable, Justin Ma, Jay Chen, David Moore, Erik Vandekieft Scalability, fidelity, and containment in the potemkin virtual honeyfarm." ACM SIGOPS Operating Systems Review. Vol. 39. No. 5 ACM, 2005  Sharma, Prateek, and Purushottam Kulkarni. "Singleton: system-wide page deduplication in virtual environments." Proceedings of the 21st international symposium on High-Performance Parallel and Distributed Computing. ACM, 2012  Konrad Miller, Fabian Franz, Thorsten Groeninger, Marc Rittinghaus Marius Hillenbrand. "KSM++: Using I/O-based hints to make memorydeduplication scanners more efficient." RESoLVE.2012  Ishan Banerjee, Fei Guo, Kiran Tati, Rajesh Venkatasubramaninan Memory Overcommitment in the ESX Server." VMWARE TECHNICAL JOURNAL: 2, 2013  Chiang, Jui-Hao, Han-Lin Li, and Tzi-cker Chiueh. "Working Set-based Physical Memory Ballooning  A  bel Gordon, Michael R. Hines, Dilma da Silva, Muli Ben-Yehuda Gabriel Lizarraga. "Ginkgo: Automated, application-driven memory overcommitment for cloud computing." Proc. RESoLVE \(2011  Al Mu ller, Seburn Wilson. "Virtualization with VMware ESX server Rockland,  Ma: Syngress Publ. Inc, 2005  
the memory. Even though the preliminary experiment result is satisfactory, SEMMA is still under implementation and many parts need to be optimized In future, we will continue our work in section V. First we will try to design a better algorithm to predict the memory usage, thus we could eliminate the instantaneous fluctuation of the sampled data. Second we will try more benchmarks on SEMMA to select a better set of bound values. Third we will pay more attention to the stability of SEMMA, making it a usable memory management system ACKNOWLEDGMENT We would like to thank all the members of Linux Interest Group of ARC Lab at Zhejiang University for their fruitful discussions that motivate this work. We also wish to thank the anonymous reviewers for their hard work for this conference This work is supported by the key state science and technology project \(2013ZX03003010-002 R EFERENCES  1 
                     
138 


Copyright © 2009 Boeing. All rights reserved  Architecture Server-1 Server-2 DB2 SURVDB XML Shredder WebSphere Message Broker Ext.4 H Ext.3 G Ext.2 F Ext.1 E C WebSphere MQ TCP/IP Live ASDI Stream IBM Cognos Server-3 IBM SPSS Modeler SPSS Collaboration Deployment Services 


Copyright © 2009 Boeing. All rights reserved  Database Modeling Schemas for correlated ASDI messages translated into equivalent relational schemas  Database tables generated based on classes created from schema definitions  Nine main, eleven supporting tables  Each main table contains FLIGHT_KEY 


Copyright © 2009 Boeing. All rights reserved  Database Modeling 


Copyright © 2009 Boeing. All rights reserved  Correlation Process To archive received ASDI data  Track messages must be correlated with flight plan messages FLIGHT_KEY assigned Uncorrelated data tagged Approx 30 minutes to correlate one day of data 


Copyright © 2009 Boeing. All rights reserved  Historical Data Processing To load correlated data  Uncompress, unmarshall  Create a list of files containing the correlated data  Write data to warehouse 


Copyright © 2009 Boeing. All rights reserved  Live Data Processing Processed using IBM MQ IBM Message Broker and a technique called XML Shredding Message Broker Compute Nodes  Uncompress Node  Extract correlated messages  Shred Node adds to DB Stored Procedure “shreds XML docs and adds to tables 


Copyright © 2009 Boeing. All rights reserved  Issues and Observations Initial load of one day of data ~ 7 hours Optimizations  Write data in batches  Use a mutable data structure to create data strings  Deploy a higher performance machine  Use load instead of insert  Use DB2 Range-Partitioned tables  Database tunings Time reduced from 7 hours to approx 30 minutes 


Copyright © 2009 Boeing. All rights reserved  Optimizations Use a mutable data structure to create data strings  Original application created the SQL statement by appending elements to a Java String  It was taking five hours \(of the seven hours Strings  Instead Java StringBuilder used  Java Strings immutable  Time savings of 71.4 


Copyright © 2009 Boeing. All rights reserved  Optimizations Deployed on a higher-performance machine  Application ported from IBM Blade Center HS21 \(4GB of RAM and 64-bit dual-core Xeon 5130 processor to Dell M4500 computer \(4GB of RAM and 64-bit of quad-core Intel Core i7 processor  Reduced the time to thirty minutes Bulk loading instead of insert  Application was modified to write CSV files for each table  Entire day worth of data bulk loaded  Reduced the time to fifteen minutes 


Copyright © 2009 Boeing. All rights reserved  Optimizations Range-Partitioned tables \(RPT  To limit the size of tables, the original code created multiple tables per table type  This puts burden on the application to query multiple tables when a range crosses several tables  With RPT, user is not required to make multiple queries when a range crosses a table boundary  Increased the time to thirty minutes  Additional fifteen minute cost per day of partitioning enabled time savings during queries 


Copyright © 2009 Boeing. All rights reserved  Optimizations Database tunings  Range periods changed from a week to a month  Automatic table space resizing changed from 32MB to 512KB  Buffer pool size decreased  Decreased the time to twenty minutes Overall, total time savings of 95.2 


Copyright © 2009 Boeing. All rights reserved  20 IBM Confidential Analytics Landscape Degree of Complexity Competitive Advantage Standard Reporting Ad hoc reporting Query/drill down Alerts Simulation Forecasting Predictive modeling Optimization What exactly is the problem What will happen next if What if these trends continue What could happen What actions are needed How many, how often, where What happened Stochastic Optimization Based on: Competing on Analytics, Davenport and Harris, 2007 Descriptive Prescriptive Predictive How can we achieve the best outcome How can we achieve the best outcome including the effects of variability Used with permission of IBM 


Copyright © 2009 Boeing. All rights reserved Initial Analysis Activities Flights departing or arriving on a date Flights departing or arriving within a date and time range Flights between city pair A,B Flights between a list of city pairs Flights passing through a volume on a date. \(sector, center, etc boundary Flights passing through a volume within a date and time range Flights passing through an airspace volume in n-minute intervals All x-type aircraft departing or arriving on a date Flights departing or arriving on a date between city pair A,B Flights departing or arriving on a date between a list of city pairs Flights passing through a named fix, airway, center, or sector Filed Flight plans for any of the above Actual departure, arrival times and actual track reports for any of the above 


Copyright © 2009 Boeing. All rights reserved  Initial SPSS Applications Show all tracks by call sign 


Copyright © 2009 Boeing. All rights reserved  Predictive / Prescriptive Analytics Use-Case For a given Airspace Volume of Interest \(AVOI compute distinct traffic volume at some point in the future  Aim to alert on congestion due to flow control areas or weather if certain thresholds are exceeded  Prescribe solution \(if certain thresholds are exceeded Propose alternate flight paths  Use pre-built predictive model  SPSS Modeler performs data processing Counts relevant records in the database \(pattern discovery Computes traffic volume using statistical models on descriptive pattern Returns prediction with likelihood 


Copyright © 2009 Boeing. All rights reserved  Predictive / Prescriptive Analytics Use-Case Advanced Arrival Procedures with Active Abatement Potentials   9/23/10  24 Pulls in the TRACKINFO table of MAIN using SQL Limits the data to database entries which fall inside the AVOI Combines the SOURCE_DATE and SOURCE_TIME to a timestamp that can be understood by modeler Computes which time interval the database entry falls in. The time interval is 15 minutes Defines the target and input fields needed for creating the model Handles the creation of the model Produces a graph based off of the model results Final prediction 


Copyright © 2009 Boeing. All rights reserved  Initial Cognos BI Applications IBM Cognos Report Studio  Web application for creating reports  Can be tailored by date range, aircraft id, departure/arrival airport etc  Reports are available with links to visuals IBM Framework Manager  Used to create the data package  Meta-data modeling tool  Users can define data sources, and relationships among them Models can be exported to a package for use with Report Studio 


Copyright © 2009 Boeing. All rights reserved  Flights Departing Las Vegas on Jan 1, 2012 1 of 3 Report shows the departure date, departure and arrival locations and hyperlinks to Google Map images DeparturePosition and ArrivalPosition are calculated data items formatted for use with Google Maps Map hyperlinks are also calculated based on the type of fix 


Copyright © 2009 Boeing. All rights reserved  Flights Departing Las Vegas on Jan 1, 2012 2 of 3 DeparturePosition, Departure Map, ArrivalPosition and Arrival Map are calculated data items \(see departure items below DepartureLatitude DepartureLongitude DeparturePosition Departure Map 


Copyright © 2009 Boeing. All rights reserved  Flights Departing Las Vegas on Jan 1, 2012 3 of 3 


Copyright © 2009 Boeing. All rights reserved  Conclusion and Next Steps Current archive is 50 billion records and growing  Approximately 34 million elements per day  1GB/day Sheer volume of raw surveillance data makes analytics process very difficult The raw data runs through a series of processes before it can be used for analytics Next Steps  Continue application of predictive and prescriptive analytics  Big data visualization 


Copyright © 2009 Boeing. All rights reserved  Questions and Comments Paul Comitz Boeing Research & Technology Chantilly, VA, 20151 office Paul.Comitz@boeing.com 


Copyright © 2009 Boeing. All rights reserved Advanced Arrival Procedures with Active Abatement Potentials   9/23/10  31 


Copyright © 2009 Boeing. All rights reserved Advanced Arrival Procedures with Active Abatement Potentials   9/23/10  32 Backup Slides 


Copyright © 2009 Boeing. All rights reserved  Initial Approach Initial Investigations  Apache Solr/Lucene  Data Warehouse Evaluate Hadoop in the future 


Copyright © 2009 Boeing. All rights reserved  Using SOLR Uncompress Track Information Messages To use with Solr  Transforming track messages from their  original schema to Solr required building a “key, value” list using an XSTL  Queries made against this list of “key, value” pairs Transformation Process  One day of data ~ 4.5 hours Once transformation complete search/query performance very good Geo spatial queries using  unique query language 


Copyright © 2009 Boeing. All rights reserved  Representation Aviation data is frequently represented in more than one form 


