Jiaqi Zhao  Jie Tao  Lizhe Wang  Rajiv Ranjan  and Joanna Koõodziej School of Basic Science Changchun University of Technology P.R China Steinbuch Center for Computing Karlsruhe Institute of Technology Germany Institute of Remote Sensing and Digital Earth Chinese Academy of Sciences China 
Using Traditional Data Analysis Algorithms to Detect Access Patterns for Big Data Processing 
1 2 3 4 5 1 2 3 
4 
ICT Centre Commonwealth Scientiìc and Industrial Research Organisation Australia Institute of Computer Science Cracow University of Technology Poland scorpiozhao@yahoo.com.cn jie.tao@kit.edu lizhe.wang@gmail.com rranjans@gmail.com jokoldziej@pk.edu.pl 
5 
The data sets produced in our daily life is getting larger and larger How to manage and analyze such big data is currently a grand challenge for scientists in various research elds MapReduce is regarded as an appropriate programming model for processing such big data However the users or developers still need to efìciently program appropriate data processing actions related to their analytics requirements In 
Abstract 
other words analytics actions in MapReduce is not portable across different big data types In this paper we propose to adopt traditional data clustering algorithms to automatically analyze large data sets We applied this approach to process performance data on distributed shared memory machines for detecting the application access patterns The advantage is that application developers need not write codes to understand the runtime access behavior of their applications We optimized several benchmark applications based on the analysis results and the experiments show a considerable improvement in terms of execution time and speedup Keywords 
Data Analysis Memory Performance Data Locality Distributed Shared Memory Code Optimization I I NTRODUCTION The amount of data created in our daily life is growing exponentially Scientiìc instruments the Web and the simulation facilities are the major sources for this big data The Large Hadron Collider in the European Or g anization for Nuclear Research CERN for example produces 15 Petabytes of scientiìc data every year The Large Synoptic Survey Telescope LSST generates 20 T erabytes per night which aggregates to a total data volume of 60 Petabytes in a year Massive data sets are not only being generated by scientiìc applications but also by Web operators 
including Google Facebook Twitter and eBay Today dataintensive computing is gaining signiìcant momentum and it is expected that data-based science will eventually bypass the conventional computation-based simulation science as the main driving force of HPC in the future As applications need to process larger and larger data sets the performance data or statistics such as cache miss memory usage processor throughput and the like which are collected at the runtime for understanding the applications execution behavior are also growing up It is a fact that the analysis of performance data is necessary for optimizing the placement of applications on the underlying computing 
platform like physical servers and virtual machines We have been working with performance data in the last several years and developed different tools for acquiring and visualizing the performance data on both physical architectures and the virtualized machines The visualization with graphical views makes it easy for programmers to understand and analyse the performance data However such tools do not work well for visualising the performance data related to processing massive or big data sets The main reason behind this is the fact that a single view cannot highlight the abnormal points over large time series This problem could be possibly eliminated by reducing the amount of 
data using either lossy tracing lo wer sampling rate  or tracing of only global e v ents 7 Ho we v er  for an exact location of the problem and more importantly for detecting the reasons and potentially the solution a full trace is required Therefore we need more advanced solutions for processing the large performance data Currently MapReduce is widely used for processing large data sets With a Map and a Reduce function MapReduce provides simple semantics for users to program data analysis tasks However it can be burden for a programmer to write specialized code for understanding and analysing the runtime performance data of his application 
Therefore we follow a traditional approach by applying data clustering algorithms concretely the classiìcation and regression trees to process the performance data This solution is based on several considerations 1 The data clustering algorithms are capable of self-learning This guarantees the required accuracy of the analysis result and thereby the efìciency of the runtime performance tuning 2 The same stream of performance data often contains several interesting patterns For example a memory access trace holds the access stride access hotspots chained references 
2013 IEEE International Conference on High Performance Computing and Communications & 2013 IEEE International Conference on Embedded and Ubiquitous Computing 978-0-7695-5088-6/13 $26.00 © 2013 IEEE DOI 10.1109/HPCC.and.EUC.2013.155 1097 
2013 IEEE International Conference on High Performance Computing and Communications & 2013 IEEE International Conference on Embedded and Ubiquitous Computing 978-0-7695-5088-6/13 $31.00 © 2013 IEEE DOI 10.1109/HPCC.and.EUC.2013.155 1097 


and so on By combining different rules of data clustering all these patterns can be detected This avoids the necessity of implementing a single algorithm for each pattern 3 Data clustering algorithms not only detect the problem but also can predict the trend This allows the runtime adaptation system to take actions before the problem occurs and 4 A complete system optimization is associated with different optimization targets that interact with each other For example optimization on the speedup can potentially enlarge the power consumption The generic data analysis approach allows a combined analysis of different data streams and hence is potentially capable of delivering appropriate solutions for a balancing trade-off across all performance metrics For this concrete work we apply the proposed approach to conduct data locality optimization on a distributed shared memory system Today shared memory models are increasingly used to develop parallel programs due to its simplicity Traditionally shared memory programs run on systems with a physically shared memory Such systems however are limited to system scales Therefore architecture vendors are producing machines with a distributed shared memory The memory hierarchy in such machines is usually multi-levels with different access time at each level An example is the Gordon Supercomputer at the San Die go Supercomputer Center which is speciìcally designed for data-intensive computing Gorden has a ve-level memory hierarchy with a node-local shared memory a distributed shared memory within a Supernode a distributed memory between Supernodes the ash memory and disk arrays A problem with such machines is the different latency between a local memory access and a remote access This latency distinction can be several factors as on some commercial machines like SGI Origin and Altix and even one hundred folds such as on Gorden The main novel contributions of our paper include i optimization of data allocation of parallel application on a shared memory cluster via intelligent analysis of runtime performance data We collected the performance data using a monitor simulator ii application of the data mining techniques i.e the classiìcation and regression trees to the performance data iii detection of the bottlenecks with large remote memory accesses and iv conducting extensive experimental evaluations which show that our approach changes 40 of the total memory accesses from remote to local hence achieving an improvement in execution time with a factor of two The remainder of the paper is organized as follows Section II gives a brief overview of the related work This is followed by introducing how the performance data are analyzed with traditional data analysis algorithms in Section III In Section IV the experimental results with data locality optimization are demonstrated The paper concludes in Section V with a short summary and future directions II R ELATED W ORK Performance optimization is an important research area and has been intensively investigated The basis for any performance optimization is to rst understand the applications runtime behavior To help application developers in this task different visualization tools or analysis frameworks have been implemented in the last years The Tuning and Analysis Utilities TAU is a proìling and tracing toolkit for performance analysis It consists of a visualization component providing graphical displays of performance analysis results This allows the user to identify the source of performance hotspots in the programs The tool has been adopted by researchers to characterize the I/O performance measure the GPU performance 22 as well as study the application behavior The Center for Information Services and High Performance Computing at the University of Dresdnen developed Vampir for performance visualization It w as originally developed to show the communication bottlenecks of MPI applications but extended to depict the cache performance It can show the number of cache misses in a time-line view as well as in the source code allowing the detection of cache critical code regions The Intel VTune Performance Analyzer is re g arded as a useful tool for performance analysis It provides several views like Sampling and Call Graph to help programmers identify bottlenecks For memory performance it shows the absolute number of cache miss in a code region allowing the user to detect functions and even code lines that introduce excessive cache misses In addition to the visualization tools described above analysis frameworks and models 3 were also de v eloped to support programmers with the task of analyzing performance data Scalasca 16 is a trace-analysis infrastructure supporting the performance optimization of parallel programs by measuring and analyzing their runtime behavior The analysis identiìes potential performance bottlenecks in particular those concerning communication and synchronization and offers guidance in exploring their causes Dinu Pop and Cristea de v eloped a model for representing the patterns in the parallel time series describing the distributed system parameters and states Based on the model an application architecture was implemented for systems that adopt advanced machine learning techniques for detecting and learning patterns The application was implemented as an add-on to the well-known MonALISA monitoring framework for distributed systems We go beyond of the traditional approach of using visualization to show the performance data by using classiìcation and regression techniques that are usually used for data mining Actually these algorithms have been applied in other research elds Olaru et al in v estig ated the application of classiìcation and regression techniques in power system engi 
1098 
1098 


neering Athanasopoulou et al used classiìcation to predict control monitoring rules in order to optimize the efìciency of electric power generation processes In further elds L  etourneau et al in v estig ated the use of decision trees instance based learning and na  ve Bayes classiìers to optimize aircraft component replacements Kusiak and Song emplo yed linear re gression neural netw orks and decision trees to optimize combustion efìciency of coal-ìred boilers Due to the fact that performance data are becoming larger and the data clustering algorithms can analyze large data with low overhead we propose the approach of using these algorithms to process the performance data with a case study on distributed shared memory systems The idea is to apply statistical methods to a given data set in order to discover potentially new and useful knowledge III D ETECTING THE A CCESS P ATTERN The prerequisite for any performance optimization is the runtime performance data Modern processors are equipped with a performance monitoring unit that contains several registers for tracing the runtime events such as cache miss context switches TLB miss and so on Most of the performance analysis tools including those introduced in the previous section rely on the performance counters to collect the runtime data However for this work the hardware counters cannot fully help us because they are not able to trace the communications between computing nodes in a distributed system We speciìcally designed a hardware monitor for this purpose The hardware device is composed of three components a B-Link interface to the network for extracting information from the packets transferred on the network a counter array for temporally storing the acquired information and a PCI interface that allows the users to deliver the monitoring data to the user space The monitor can be conìgured into a static and a dynamic working mode In the former case an integrated lter in the counter array allows the monitor to only trigger user speciìed events With the dynamic mode the complete inter-node trafìc is captured and recorded For this work we use the dynamic monitoring to inspect all packets delivered on the network thus to acquire a complete histogram of the communications between the processor nodes on the system Each record in the histogram contains four attributes source destination access type and access address Here source and destination specify the sender and receiver of a packet i.e a remote memory reference on a distributed shared memory architecture The next step is to apply data clustering approach to nd useful information in large sets of data concretely the access pattern for this work The data clustering process describes a common approach to identify certain patterns in given data sets The acquired data are rst transformed to a speciìc Figure 1 A sample decision tree for predicting a processor node format required by the applied algorithm and then mined to create results for computing predictions Depending on the input data and the expected patterns to identify several different algorithms exist While the clustering helps to identify several data tuples with similar properties association rules nd combinations of attributes frequently occurring together in the whole data set Classiìcation and regression are methods to predict one attributevalue based on a set of input attributes With respect to performance data classiìcation algorithms are especially useful When analyzing inter-node communications we try to nd the access characteristics of a certain memory address or access region and the optimal processor node for it Here an optimal processor is the one that has performed the most accesses on the data item It is clear that the data item shall be placed on this processor for less remote accesses Hence we reduce the problem of inter-node communication into the problem of predicting an optimal node with a set of given attributes One approach to do classiìcation is to learn a decision tree Such a tree consists of one root node and several subsequent nodes which represent the decision rules The leaf nodes nally represent the class of a tuple satisfying all the conditions denoted by parent nodes Figure 1 depicts a simple example An unknown attribute of a data tuple is predicted by traversing through the tree until reaching a leaf node containing a classiìcation For our case the leaves are the processors contained in the system and the goal is to search the decision tree to achieve a leaf for the given address Figure 1 demonstrates a search process for the location of a data block containing the memory address 441 that is accessed by the program prog.2 According to the decision tree this block shall be allocated to CPU 3 because for all addresses bigger than 123 the best destination is this processor Since the decision trees have a simple structure and forms 
1099 
1099 


2 
14 
Figure 2 The analysis procedure for processing performance data an easy way for classifying data tuples it is more complex to automatically learn the decision trees from a database of sample records The usual technique is a top-down induction of such trees which starts at the root node and applies the same algorithm to all subsequent children At every node it has to be decided which attribute has to be selected and at which threshold value the attribute should be split This is done in a greedy manner using entropy or information gain measures 5 If only the records from the same class remain in one node or no further conditions offer any improvement the majority class is decided to be the nal classiìcation of the corresponding data tuples Actually the monitoring data provides the access address for each single communication This allows us to acquire the best position of individual data addresses However such ne granularity is generally not necessary for data locality optimization Therefore we transferred the data into a format in which the access frequency per processor is associated with each memory block in size of a virtual page With this transformation each data tuple consists of the desired memory block and one column for each processor in the system Figure 2 depicts the whole procedure of analyzing the monitoring data In the rst step the monitoring data is transformed This is followed by data clustering The results are then delivered to the programmers with three different granularities i.e data set level page level and single address IV O PTIMIZATION AND E XPERIMENTAL R ESULTS In order to examine the feasibility of the discovered knowledge we performed data locality optimization on several standard big data applications 
A Experimental Setup 
  
In order to conduct repeatable experiments under controlled settings we decided to develop a monitor simulator instead of using the real hardware monitor We integrated the monitor simulator into a multiprocessor simulator that focuses on modeling the memory system of NonUniform Memory Access NUMA architectures and the execution of shared memory applications parallelized with m4 macros used by e.g the SPLASH-II benchmark suite  This simulator allo ws us to specify v arious memory conìgurations including the cache associated parameters and the access latency for different memory locations More speciìcally it is possible to explicitly specify the location of the complete working set or an individual virtual page We use this feature to realize both the coarse-grained and ne-grained memory locality optimization In addition the simulator delivers as output the execution time of a program and the number of accesses at each memory location This allows us to study the impact of optimizations in the code in terms of the memory performance The applications for the experiments are chosen from the SPLASH-II benchmark The benchmark consists of several programs The LU program factors a dense matrix into the product of a lower triangular matrix and an upper triangular one The primary data structure in LU is the matrix being decomposed For this experiment we use a matrix of size 128 128 FFT is a complex one-dimensional version of the Six-Step FFT algorithm described in The data set consists of complex data points to be transformed and another complex data points referred to as the roots of unity For this experiment FFT is simulated using data points RADIX implements an integer radix sort based on the method described in W e performed this sort on 65,536 elements WATER is a N-body molecular dynamics application that evaluates the forces and potentials in a system of water molecules in the liquid state For this experiment a data size of 216 molecules was speciìed The OCEAN program uses a restricted Red-Black Gauss-Seidel Multigrid solver to simulate the role of eddy and boundary currents on large-scale ocean movements The simulation is performed for many time-steps until the eddies and mean ocean ow attain a mutual balance We use a grid of 130 130 to model the ocean basin BARNES implements the Barnes-Hut method to simulate the interaction of a system of bodies N-body problem We performed this simulation using a N-body size of 1,024 
n n 
1100 
1100 


0 0,2 0,4 0,6 0,8 1 1,2 1,4 2 4 8 16 32 first-touch opt-coarse opt-fine 
original optimized 
As mentioned and shown in Figure 2 data clustering provides us three results with different granularities i.e single memory address individual virtual page and the complete data set The rst result enables extremely negrained optimization i.e to allocate each data item to the corresponding processor node However such a granularity introduces high overhead especially for the case of runtime optimization Therefore we performed the ne-grained page-level optimization using single pages as an allocation unit and the coarse-grained optimization of allocating the whole data set on a single node The optimization was enabled by using the annotations provided by the simulation platform to explicitly specify the best location in the source code In the case of page-level optimization each virtual page is speciìcally allocated on its dominating node while with the coarse-grained optimization a single node is speciìed for the entire working load A dominating node is the computing node that performs the most accesses on the virtual page The baseline for both optimization versions is the transparent data placement i.e all data are placed on the host node on which the job is submitted We also addressed the rst-touch scheme which is usually applied to e v aluate the memory optimization on systems with a distributed shared memory 31 First-touch allocates data on the node that rst accesses it This scheme tends to behave better than other data distribution policies because the node that rst accesses a page is usually the node that mostly accesses it Our rst experiment aims at studying the direct impact of the optimizations For this we simulated all applications with rst-touch node-level optimization opt-coarse pagelevel optimization opt-ìne and the conventional host-node data placement We also executed the application using different numbers of processors in order to examine the scalability of our locality optimization approach According to the requirement of some applications the number of processors is speciìcally chosen as a power of two For each test the execution time of all applications was measured and the speedup was calculated by dividing the time needed for running the code with the conventional data placement policy via the execution time of an optimized version i.e  The L1 cache is speciìed as a two-way associative cache with a size of 16 KB while the L2 cache is four-way associative with a size of 512 KB The local memory access latency is speciìed as 100 CPU cycles and remote access latency 1,000 cycles based on the conìguration of modern commodity processors For the following tests we use the most strict communication policy which allows only one node to access one remote memory at the same time During this delay no other nodes can perform remote accesses 
S T T 
B Locality Optimization C Optimization with Exclusive Data Access 
 
Figure 3 Improvement in execution time with the LU application Figure 3 to 7 depict the experimental results with different applications The x-axis of these gures shows the number of processors we used for the experiments while the y-axis depicts the speedup of the optimized code version against the transparent version in absolute execution time The gures show the data with the two optimization schemes and the allocation policy rst-touch Observing the result with LU as illustrated in Figure 3 it can be seen that the rst-touch scheme has no speedup to the basic policy where the y-axis shows a value of 1 in speedup for all tests meaning that this scheme results in the same execution time as the default version This also indicates that rst-touch brings the same runtime data layout as the host-node scheme that allocates all data sets on the same node i.e the host node The reason may lie on the data initialization which is usually done by the host and the rst-touch scheme hence puts all shared data on the host node that rst accesses the data The gure also depicts that the node-level optimization has a similar behavior where only on two-processor systems a slight speedup in execution time is observed Page-level optimization on the other hand introduces a speedup with the LU application and the speedup arises with the number of processors For example a speedup of factor 1.04 is achieved with twoprocessor systems while on 32 processors a factor of 1.23 is obtained This renders that the page-level optimization achieves a good scalability with LU FFT shows a different behavior As illustrated in Figure 4 all three data allocation policies perform better than the conventional data placement Nevertheless both rst-touch scheme and coarse-grained optimization present a poor scalability because the improvement goes down as the number of processors increases The same behavior can also be seen with the ne-grained page-level optimization on small systems However using page-level optimization the performance achievement arises and goes up starting with 16-node 
Number of processors Speedup \(opt vs. basis 
1101 
1101 


Figure 4 Improvement in execution time with the FFT application systems The speedup on a 32-node system for example is still lower than that on the two-node system but higher than the case with four-node systems Further observation of the trend on larger systems would be interesting Unfortunately the simulation platform is limited to 32 processors Figure 5 Reduction rate of remote accesses on different system scales The improved runtime behavior with page-level optimization directly contributes to the better data locality For a deeper insight into this issue we have measured the number of remote accesses for both page-level optimization and the transparent data placement We then computed the reduction rate which is deìned as the percentage of reduced remote accesses achieved by the optimized version to the total remote accesses introduced by the transparent version Figure 5 presents the results with all tested applications running on systems with 2 to 32 processing nodes Observing the curves in Figure 5 it can be seen that for most applications the reduction rate is higher on smaller systems than on larger ones for example LU WATER OCEAN and BARNES This is not surprising because on smaller systems a data page is requested by few processor nodes However on large systems the references to a single page are distributed across a set of nodes which possibly all require the page frequently This means that the optimization of exclusively putting the data on the dominating node can only remove the remote accesses from this node but not of the others Nevertheless if an application has a lower shared degree a data page would be potentially only dominantly accessed by a single processor In this case the reduction rate of remote accesses can still be high on larger systems FFT and RADIX are such examples With the FFT application we achieved a reduction of as high as 47 in remote memory accesses on 32-processor systems while RADIX shows a constant reduction rate of 40 from 4 to 32 processors Figure 6 Improvement in execution time with the RADIX application The high reduction rate of RADIX directly results in the performance gain in terms of execution time As demonstrated in Figure 6 page-level locality optimization introduces an exciting speedup in execution time and this improvement increases drastically with the number of processors On a 32-node system for instance we achieved a speedup of as high as a factor of two The scalability achieved with RADIX has to be contributed by the reduction in remote memory accesses As shown in the previous gure the reduction rate with RADIX is similar with systems of different scales which also means a similar reduction in the remote access penalty In this case the speedup on larger systems is higher because the execution time is smaller The application WATER however does not present good results with the optimization As shown in Figure 7 even the page-level locality tuning is not effective This is caused by its speciìc access pattern which will be explained later In summary the applications demonstrate different behavior with our locality optimization This distinction lies directly on the access pattern of each individual program Using the proposed approach we found that for the LU application nearly half of the total data pages is accessed equally by many processors while the other half has several dominating nodes Only 6 of the pages is accessed mainly by a single processor We have placed each page to its best position suggested by our data classiìer However for most pages other nodes also require them Hence still many 
Number of processors Reduction rate of remote accesses 
0 0,1 0,2 0,3 0,4 0,5 0,6 0,7 2 4 8 16 32 lu fft radix water ocean barnes 
Number of processors Speedup \(opt vs. basis Number of processors Speedup \(opt vs. basis 
0 0,2 0,4 0,6 0,8 1 1,2 1,4 1,6 1,8 2 2 4 8 16 32 first-touch opt-coarse opt-fine 0 0,5 1 1,5 2 2,5 2 4 8 16 32 first-touch opt-coarse opt-fine 
1102 
1102 


Proceedings of the 6th IASTED International Conference on European Power and Energy Systems EuroPES Journal of Supercomputing Proceedings of the International Conference on Intelligent Networking and Collaborative Systems INCoS Proceedings of the 8th Annual ACM Symposium on Parallel Algorithms and Architectures Proceedings of the 6th European Congress on Intelligent Techniques and Soft Computing EUFIT Classiìcation and Regression Trees 
0 0,2 0,4 0,6 0,8 1 1,2 2 4 8 16 32 first-touch opt-coarse opt-fine 
Figure 7 Improvement in execution time with the WATER application remote accesses exist after the location tuning Similarly for WATER although 36 of the data pages is dominantly accessed by a single node the number of accesses by this node is only 2 of the total remote accesses The others are shared by all or almost all processors and these processors perform equally accesses to an individual page For BARNES the whole shared data is accessed by all nodes Even though some nodes do not frequently request a page there exists no dominating node for any data page This means that at least two processors equally access the same page Therefore it is difìcult to optimize this code With FFT nevertheless 96 of the data pages has a dominating node and 33 of them are exclusively accessed by this node RADIX is even better with more than a half of the data pages accessed by a single node For OCEAN nearly 70 of the pages are exclusively used by one node and 2/3 of the rest has a clear dominating processor Therefore the optimization with these three applications leads to a considerable performance gain As observed in the gures the coarse-grained optimization generally does not work well The reason is as following The global dominating node for the whole data set is discovered based on the total remote accesses each node performed at the runtime Actually most pages are shared by many processors The page-level optimization improves the performance because of the existence of a dominating node for each individual page However we note that in most cases this dominating node varies from page to page Therefore node-level optimization could improve the data locality in smaller systems For example on a two-node machine there are only two candidates for a page hence placing all data on the global dominating node can achieve speedup However on larger systems the best position for a virtual page can be any of the processors therefore only a ne tuning with the ability of placing each page on a speciìc node is able to improve the memory access behavior V C ONCLUSIONS This paper describes our research work of applying generic data analysis techniques for memory locality optimization on systems with a distributed memory The goal of this work is to validate the feasibility of the data classiìcation algorithms in the task of detecting performance bottlenecks and proposing an efìcient solution This is actually the rst step towards our nal target of establishing self-optimizing parallel systems with respect to different interacting performance metrics For this research goal we deploy data clustering to evaluate the runtime performance data because this technique provides the required properties such as analysis accuracy overhead and association of multiple optimization targets The proposed approach has shown its ability in nding access patterns and bottlenecks The data analysis results have guided us to achieve signiìcant improvement in both execution time and scalability of parallel programs With this initial experience we will further address other performance metrics like the cache performance processor utility energy consumption etc A more exciting future work is to optimize the system with all these metrics taken into account A CKNOWLEDGEMENTS Dr Lizhe Wangês work is supported by the National Natural Science Foundation of China 61361120098 R EFERENCES  C Athanasopoulou V  Chatziathanasiou M K omninou and Z Petkani Applying Knowledge Engineering and Data Mining for Optimization of Control Monitoring of Power Plants In 
 2006  D H Baile y  FFTs in External or Hierarchical Memory   4\(1 March 1990  N Bessis S Sotiriadis V  Cristea and F  Pop Modelling Requirements for Enabling Meta-scheduling in Inter-Clouds and Inter-Enterprises In  pages 149Ö156 2011  G E Blelloch C E Leiserson B M Maggs C G Plaxton S J Smith and M Zagha A Comparison of Sorting Algorithms for the Connection Machine CM-2 In  pages 3Ö16 July 1991  Christian Bor gelt A Decision Tree Plug-In for DataEngine In  volume 2 pages 1299Ö1303 Aachen Germany 1998 Verlag Mainz  L Breiman J Friedman R Olshen and C Stone  Chapman  Hall 1993 
Number of processors Speedup \(opt vs. basis 
1103 
1103 


 S Bro wne J Dongarra N Garner  G Ho and P  Mucci Portable Programming Interface for Performance Evaluation on Modern Processors  14\(3 2000  H Brunst D Hack enber g G Juck eland and H Rohling Comprehensive Performance Tracking with Vampir 7 In M.S Mller M.M Resch A Schulz and W.E Nagel editors  pages 17Ö29 Springer 2009  B R Buck and J K Hollingsw orth Data Centric Cache Measurement on the Intel Itanium 2 Processor In  November 2004  CERN LHC  The Lar ge Hadron Collider  W eb P age http://lhc-new-homepage.web.cern.ch/lhc-new-homepage  The LSST Corporation Lar ge Synoptic Surv e y T elescope Web Page http://www.lsst.org/lsst  J Dean and S Ghema w at Mapreduce simpliìed data processing on large clusters  51\(1 2008  C M Dinu F  Pop and V  Cristea P attern Detection Model for Monitoring Distributed Systems In  pages 268 275 2011  Gordon at san die go supercomputing center  http://www.sdsc.edu/us/resources/gordon  J R Hammond S Krishnamoorthy  S Shende N A Romero and A D Malony Performance Characterization of Global Address Space Applications A Case Study with NWChem  24\(2 2012  M Hermanns S Krishnamoorthy  and F  W olf A scalable infrastructure for the performance analysis of passive target synchronization  39\(3 March 2013  T on y He y  Ste w art T ansle y  and Kristin T olle editors  Microsoft Research Redmond Washington 2009  Intel Intel VT une Ampliìer XE 2013 Performance and Thread Proìler http://software.intel.com/en-us/intel-vtuneampliìer-xe  A K usiak and Z Song Comb ustion Ef cienc y Optimization and Virtual Testing A Data-Mining Approach  2\(3 August 2006  Sylv ain Letourneau F azel F amili and Stan Matwin Data Mining to Predict Aircraft Component Replacement  14\(6 1999  H L  of M Nord  en and S Holmgren Improving Geographical Locality of Data for Shared Memory Implementations of PDE Solvers In  volume 3037 of  pages 9Ö16 2004  A D Malon y  S Biersdorf f S Shende H Jagode S T omo v  G Juckeland R Dietrich D Poole and C Lamb Parallel Performance Measurement of Heterogeneous Parallel Systems with GPUs In  pages 176Ö185 September 2011  J Marathe F  Mueller  and B de Supinski A Hybrid Hardware/Software Approach to Efìciently Determine Cache Coherence Bottlenecks In  pages 21Ö30 June 2005  C Olaru P  Geurts and L W ehenk el Data mining tools and applications in power system engineering In  1999  B Quaing J T ao and W  Karl Y A CO A User Conducted Visualization Tool for Supporting Cache Optimization In  volume 3726 of Lecture Notes in Computer Science pages 694Ö703 Sorrento Italy September 2005  J Ross Quinlan  Morgan Kaufmann Publishers Inc San Francisco USA 1993  S Shende A Malon y  W  Spear  and K Schuchardt Characterizing I/O Performance Using the TAU Performance System In   S Shende and A D Malon y  The T A U P arallel Performance System  20\(2 2006  H T akashi O Hiroshi I T akayoshi and D Henry  Automatic Data Distribution Method Using First Touch Control for Distributed Shared Memory Multiprocessors In  volume 2624 of  pages 147Ö161 2001  J T ao M Schulz and W  Karl A Simulation Tool for Evaluating Shared Memory Systems In  pages 335Ö342 Orlando Florida April 2003  M M T ikir and J K Hollingsw orth Using Hardw are Counters to Automatically Improve Memory Performance In  2004  F  W olf Scalasca In  pages 1775Ö1785 Springer October 2011  S C W oo M Ohara E T orrie J P  Singh and A Gupta The SPLASH-2 Programs Characterization and Methodological Considerations In  pages 24Ö36 June 1995  J Zhao J T ao L W ang and A W irooks A T oolchain For Proìling Virtual Machines In  pages 497Ö503 Aalesund Norway May 2013 
The International Journal of High Performance Computing Applications Tools for High Performance Computing Proceedings of SuperComputing Commun ACM Proceedings of the International Symposium on Symbolic and Numeric Algorithms for Scientiìc Computing SYNASC Concurrency and Computation Practice and Experience Parallel Computing The Fourth Paradigm Data-Intensive Scientiìc Discovery IEEE Transactions on Industrial Informatics IEEE Intelligent Systems Computational Science ICCS 2004 Lecture Notes in Computer Science Proceedings of International Conference on Parallel Processing Proceedings of the International Conference on Supercomputing Proceedings of the Power Systems Computation Conference PSCC High Performance Computing and Communcations First International Conference HPCC 2005 Proceedings C4.5 Programs for Machine Learning Proceedings of the ICPP Parco 2011 conference Exascale Mini-symposium International Journal of High Performance Computing Applications Languages and compilers for parallel computing International workshop Lecture Notes in Computer Science Proceedings of the 36th Annual Simulation Symposium Proceedings of the 2004 ACM/IEEE conference on Supercomputing Encyclopedia of Parallel Computing Proceedings of the 22nd Annual International Symposium on Computer Architecture Proceedings of the 27th European Conference on Modelling and Simulation ECMS 2013 
1104 
1104 


boards of several journals including IEEE Transactions on Service Computing and the Journal of Performance Evaluation   Zhen has given keynotes and distinguished lectures in various conferences and universities. He was an adjunct professor at University of Science and Technology of China and Beijing University of Post and Telecommunications While he was in France Zhen was  also an adjunct professor of the University of Paris VI \(University of Pierre & Marie Curie\and the University of Nice  Sophia Antipolis, France   His areas of expertise include mobile computing, mobile services, cloud computing, stream processing re al time analytics performance modeling stochastic optimization service oriented architecture and semantic Web      
lxxxi 


en-US Keynote VI I I  en-US GreenCom iThings CPSCom 2013   Towards Carrier Cloud   Dr. Tarik Taleb  Senior Researcher and 3GPP Standards Expert  NEC Europe Ltd, Heidelberg, Germany  Email tarik.taleb@nw.neclab.eu    Abstract   Mobile operators are in need of means to cope with the ever increasing mobile data traffic, introducing minimal additional capital expenditures on existing infrastructures, principally due to the modest Average Revenues per User ARPU Network virtualizat ion and cloud computing techniques along with the principles of the latter in terms of service elasticity on demand and pay per use could be important enablers for various mobile network enhancements and cost reduction This talk discusses the recent tr ends the mobile telecommunications market is experiencing showcasing some of the emerging consumer products and services that are facilitating such trends. The talk also discusses the challenges these trends are representing to mobile network operators. T he talk also demonstrates the possibility of extending cloud computing beyond data centers towards the mobile end user providing end to end mobile connectivity as a cloud service. The talk introduces a set of technologies and methods for the on demand pro vision of a decentralized and elastic mobile network as a cloud service over a distributed network of cloud computing data centers; federated cloud. The concept of Follow Me Cloud whereby not only data but also mobile services are intelligently following t heir respective users is also introduced. The novel business opportunities behind the envisioned carrier cloud architecture and service are also discussed, considering various multi stakeholder scenarios   Bio   Tarik Taleb is currently working as Senior Researcher and 3GPP Standards Expert at NEC Europe Ltd Heidelberg, Germany. Prior to his current position and till Mar. 2009, he worked as assistant professor at the Graduate School of Information Sciences, Tohoku University, Japan, in a lab fully funded by KDDI, the second largest network operator in Japan From Oct 2005 till Mar 2006 he was working as research fellow with the Intelligent Cosmos Research Institute Se ndai Japan He received his B E   degree in Information Engineering with distinction M.Sc and Ph.D degrees in Information Sciences from GSIS Tohoku Univ., in 2001, 2003, and 2005, respectively   Dr Taleb  s research interests lie in the field of architectural enhancements to mobile core networks particularly 3GPP  s mobile cloud net working mobile multimedia streaming congestion control protocols handoff and mobility management inter vehicular communications and social media networking Dr Taleb has been also directly engaged in the development and standardization of the Evolved  Packet System as a member of 3GPP  s System Architecture working group. Dr. Taleb is a board member of the  IEEE Communications Society Standardization Program Development Board  As an attempt to bridge the gap between academia and industry Dr Taleb has f ounded and has been the     Dr Taleb  is/was on the editorial board of the IEEE Wireless Communications Magazine IEEE Transactions on Vehicular Technology, IEEE Communications Surveys & Tutorials, and a number of Wiley journals. He is serving as vice chair of the Wireless Communications Tech nical Committee, the largest in IEEE ComSoC He also served as Secretary and then as Vice Chair of the Satellite and Space Communications Technical Committee of IEEE ComSoc 2006  2010 He has been on the technical   
lxxxii 


program committee  of different IEEE c onferences including Globecom, ICC and WCNC and chaired some of their symposia   Dr Taleb is the recipient of the 2009 IEEE ComSoc Asia Pacific Best Young Researcher award Jun 2009 the 2008 TELECOM System Technology Award from the Telecommunicati ons Advancement Foundation Mar 2008 the 2007 Funai Foundation Science Promotion Award Apr 2007 the 2006 IEEE Computer Society Japan Chapter Young Author Award Dec 2006 the NiwaYasujirou Memorial Award Feb 2005 and the Young Researcher's Enc ouragement Award from the Japan chapter of the IEEE Vehicular Technology Society \(VTS\\(Oct. 2003\ Some of Dr. Taleb  s research work has been also awarded best paper awards at prestigious conferences. Dr. Taleb is a senior IEEE member      
lxxxiii 


en-US Keynote I X  en-US GreenCom iThings CPSCom 2013   How Densely Should the Data Base Stations  B e Deployed in Hyper Cellular Networks   Professor Zhisheng Niu  Tsinghua National Lab for Information Science and Technology  Tsinghua University, Beijing 100084, China  E mail niuzhs@tsinghua.edu.cn    Abstract   One of the key approaches to make the mobile communication networks more GREEN Globally Resource optimized and Energy Efficient Networks\is to have the cellular architecture and radio resource allocation more adaptive to the environment and traffic varia tions including making some lightly loaded base stations \(BSs\go to sleep. This is the concept of so called TANGO \(Traffic Aware Network planning and Green Operation and CHORUS Collaborative and Harmonized Open Radio Ubiquitous Systems published by th e author earlier. To realize this, a new cellular framework, named hyper cellular networks HCN has been proposed in which the coverage of control signals is decoupled from the coverage of data signals so that the data coverage can be more elastic in ac cordance with the dynamics of traffic characteristics and QoS requirements. Specifically, the data base stations \(DBSs\in HCN can be densely deployed during peak traffic time in order to satisfy the capacity requirement, while a portion of DBSs can be swi tched off or go to sleep mode if the traffic load is lower than a threshold in order to save energy. A fundamental question then arises how densely should the DBSs be deployed in order to balance the QoS requirements and the energy consumption in hyper ce llular networks     In this talk, we characterize the optimal DBS density for both homogeneous and heterogeneous hyper cellular networks to minimize network cost with stochastic geometry theory For homogeneous cases both upper and lower bounds of the optimal DBS density are derived For heterogeneous cases our analysis reveals the best type of DBSs to be deployed for capacity extension or to be switched off for energy saving. Specifically, if the ratio between the micro DBS cost and the macro DBS cost  is lower than a threshold which is a function of path loss and their transmit power then the optimal strategy is to deploy micro DBSs for capacity extension or to switch off macro DBSs \(if possible\for energy saving with higher priority Otherwise the  optimal strategy is the opposite Based on the parameters from EARTH numerical results show that in the dense urban scenario compared to the traditional macro only homogeneous cellular network with no DBS sleeping deploying micro DBSs can reduce about 40 of the total energy cost, and further reduce about 20% with DBS sleeping capability   Bio   Zhisheng Niu graduated from Northern Jiaotong University currently Beijing Jiaotong University Beijing China in 1985 and got his M.E and D.E degrees fr om Toyohashi University of Technology Toyohashi, Japan, in 1989 and 1992, respectively. After spending two years at Fujitsu Laboratories Ltd Kawasaki, Japan, he joined with Tsinghua University, Beijing, China, in 1994, where he is now a professor at the  Department of Electronic Engineering and the deputy dean of the School of Information Science and Technology. His major research interests include queueing theory, traffic engineering, mobile Internet radio resource management of wireless networks, and g reen communication and networks   Dr Niu has been an active volunteer for various academic societies including council member of Chinese Institute of Electronics 2006 10 vice chair of the Information and Communication Network Committee of Chinese In stitute of Communications 2008 12 Councilor of IEICE Japan 2009 11 and membership development coordinator of IEEE Region 10 \(2009 10\ In particular, in IEEE Communication 
lxxxiv 


Society, he has been serving as an editor of IEEE Wireless Communication Magaz ine \(2009 12\ director of Asia Pacific Region \(2008 09\ director for Conference Publications \(2010 11\ chair of Beijing Chapter 2001 08 and members of Award Committee 2011 13 Emerging Technologies Committee 2010 12 On line Content Committee 20 10 12 and Strategy Planning Committee He has also been serving as general co   co    chairs o f    Prof. Niu is a co recipient of the Best Paper Awards from the 13th and 15th Asia Pacific Conference on Communication APCC in 2007 and 2009 respectively and received Outstanding Young Researcher Award from Natural Science Foundati on of China in 2009 He is now the Chief Scientist of the National  Energy and Resource Optimized Hyper Cellular Mobile Communication System 2012 2016 which is the first national project green communications in China He is the fellow of IEEE and IEICE and a distinguished lecturer of IEEE Communication Society \(2012 2013  
lxxxv 


