A Big Data Correlation Orchestrator for Internet of Things Mohammad Mozumdar Amir Shahbazian and Nhat-Quang Ton Electrical Engineering California State University Long Beach mohammad.mozumdar@csulb.edu  amir.shahbazian nhatquang.ton  student.csulb.edu Abstract Connecting embedded sensors with cloud infrastructure could open enormous possibility for creating new services which eventually could have unprecedented impact in our way of living To provide robust and reliable services embedded sensor generally need to produce signiìcant amount of data 
which could easily exceed storage capability of micro-servers To address this problem in this paper we present BigCO a big data correlation orchestrator for internet of things This orchestrator is implemented in a micro cloud server whose role is to manage centralized as well as distributed wireless sensor nodes In this paper we address how multifaceted data could be interrelated and analyzed using 3D modeling and present a streaming compression algorithm extending RamerDouglas-Peucker heuristic Applying our proposed compression algorithm we have achieved as high as 99.86 compression of sensor data I I NTRODUCTION A constantly growing number of wirelessly connected sens 
ing devices are bringing new opportunities and challenges New opportunities appear in many areas such as the medical eld smart houses and cities automation and in the industrial workîows Researchers adapted sensors and controllers to semantic concepts by introducing the Things as a Service TaaS paradigm or the more general Cloud of Things CoTs The low acquisition cost of micro-sized programmable systemon-chip computers combined with reliable wireless technology and micro-sized MEMs sensors have greatly contributed to the expansion of the automation industry Advancement in distributed systems and availability of cloud services created the necessary infrastructure to connect wireless nodes as Internet of things IoTs These sensors can produce massive amounts of data which impose many challenges such as data 
storage and analysis Wireless connected sensors a prominent example of IoT can produce a large amount of data in a short period of time On the one hand sensors generally have an insufìcient amount of memory or processing power Sensors being scattered in remote locations makes them easy targets of vandalism or other environmental harms Therefore it is essential to store data produced in a secure location One of the most secure place to store data would be an off-site database provided through Infrastructure as a Service IaaS Some of the main beneìts of using an IaaS are their easy access real time sensor data visualization capability and their ability to monitor and control wireless sensor networks An active community has already built several ready-to-adapt templates for sensor-driven 
data applications intended for data on the Cloud IaaS based companies Nimbits ThingSpeak 9 and others pro vides data storage processing and subscription on the Cloud for IoT 4 5 Most of these service pro viders support users by accessing IoT sensors while addressing individual devices they are bounded to the transmission control and Internet packet protocols TCP/IP This paper addresses the challenges involved in storing large amount of data and provides a holistic algorithm to manage big data in micro-cloud environment We have implemented the algorithm in distributed Wireless Sensor Networks WSN and proven the validity and practicality through simulation Our aim is to connect wirelessly linked tiny sensors to cloud infrastructure for developing multi 
purpose applications in large scale distributed systems Our developed framework connects micro wireless sensor nodes to the internet public cloud or intranet private cloud As a whole we focus on developing a framework for the orchestration of sensor nodes and the management of the large amount of data produced by sensors We discuss how multifaceted data can be connected here for instance we have mapped temperature humidity and cooling power consumption data and how these data elements can be interrelated and analyzed using 3D modeling providing loss-less compression as well as database query optimization based on 3D surface mapping vs running database queries on multiple relational database tables This orchestration provides beneìts in big data management for IoT here we utilized Ramer-Douglas 
Peucker Heuristic R-DPH 2 R-DPH is an application dependent data compression algorithm to turn a low cost single board computer into a data warehouse Our proposed datatype dependent compression technique also assists in fault reduction and the development of reliable networks II B IG D ATA O RCHESTRATION AND C OMPRESSION FOR WSN S Wireless sensors can produce a signiìcant amount of data Accumulated data should be either transmitted or aggregated and sent to a remote server Since wireless sensors have a limited storage capacity they need to either dispose of old data 
or stop producing new ones Based on the data logging and monitoring applications requirements a constant transmission may be necessary If a live operation is not required it is important to reduce the number of times an on-board radio is turned on to transmit packets This step is carried out to save battery consumption At the same time the transmission of live packets on the current cloud infrastructure requires 2014 IEEE World Forum on Internet of Things \(WF-IoT 978-1-4799-3459-1/14/$31.00 ©2014 IEEE 304 


extensive resources and sometimes becomes impractical For example in one experiment of our study we have found that transmitting temperature humidity power consumption and status data such as battery power level from a single node can produce 16 bytes of data We set the sampling for every second assuming real time application scenario total data including time stamp and related meta tags such as node id and resolution added to 2.9 GB over 30 days period with only four sensing nodes Obviously an orchestrator with enough storage capacity can handle the required space for a small scale setup such as monitoring a greenhouse over a period of one month However we will need a larger data management and storage capacity for large scale deployments In our deployment we experimented with a streaming compression algorithm using the Ramer-Douglas-Peucker Heuristic R-DPH is used for reducing the number of points in a curve that is approximated by a series of vectors The domain samplings done by sensors produce series of points which can be visualized in a 2D 3D or nD Cartesian coordinate system These points are within the margin of error distance of  0 In most relational database each point is stored in a table row along with other values such as a unique key i.e time to create relationships between tables A line graph is created using the temperature points with the goal of generating similar graph with fewer points The algorithm R-DPH rst looks at an acceptable maximum distance between the original and the simpliìed graph made of a subset of the deìned coordinates It starts with dissimilar Y values coordinates temperature and tries to nd a vector that will closely pass by all points The start and end coordinates are untouched whereas other coordinates are deleted R-DPH heuristic starts by ordering the points in time sensors data stored in the database sorted automatically based on time stamp Point to line distance calculation algorithm called error distance then generates a line cluster containing beginning and end points The heuristic continues by breaking the cluster into smaller lines then the points that fall within error margin are removed and only the beginning and end points are saved This process is repeated recursively by breaking the line further and nding the outermost point from the line While the start and end points are maintained the distance to the drawn line of all the other non-ìxed points is measured If the distance error is more than  then that point must remain and is called the worst point This particular point becomes the end point during the following recursion If there is no error distance greater than  then all the point outside the line will be removed The created vectors will generate the curve for future database queries Figure 1 shows error distance calculation as explained above for the three combinations of points with lines The pointto-line calculation provides an efìcient heuristic for temperature-time 2D data management However in our case orchestrator will have to store data from different type of sensors temperature humidity light to analyze correlation between them Fig 1 Distance calculation and measuring the error A Ramer-Douglas-Peucker Heuristic Shortest path Calculation for Data Compression Given a point P and a line L formulated as X   t  A  t   b  the nearest point on the line to the P is the projection X  t  of P onto the   b for a value of t  Figure 1 shows the vector PX  t  is perpendicular to   b thus 0   b  P  X  t     b  P  A  t   b     b  P  A   t    b  2 As a result the projection of nearest point value or parameter of projection t on line b is calculated by dot product  t    b  P  A      b  2  The distance of point P is  P  A  t   b  2 and nally distance of point P to line Lis  P  A  2     b  P  A  2    b  2  If we assume   b to be a unit vector       b  1  we can simplify the equations to   m X  constant The closest point  P on the line satisìes the relationship P  K  s   m for some s\(s is the correction factor Dot product with   m yields   m P   m K+s    m  2  c+s    m  2 sos   m Y c    m  2  The distance between the P and the line is  P  K    s    m  or distance  P L     m P  c   m  2  If we consider   m being a unit vector we can simplify the equation this will reduce amount of processing requirement  P  A  2 P-A  P  A  T   P  A  T I  P  A    P  A  T   b  b T  m  m T   P  A    b  P  A  2   m  P  A  2   b  P  A  2   m.P  c  2 Here construct   b  b T  m  m T  is a 2x2 identity matrix Finally product of  b  b T will be a 2x2 matrix this is proven since   b  m  are orthonormal basis for R 2 and every vector can be represented as IX X    b T X   b   m T X  m    b  b T  X   m  m T  X  Since we have to process a great number of points to line distances it is important to make quick calculations To this end we can use the memory of the orchestrator to recalculate    b  and store it per segment other method for low memory applications and orchestrator is to defer the calculation of 2014 IEEE World Forum on Internet of Things \(WF-IoT 305 


Fig 2 Cooling system energy consumption relationship with temperature and humidity observation reveals how humidity encourage consumers to utilize more cooling power to create a more comfortable experience while the lowest consumption point is achieved at 60 humidity and 18  C for a particular participated household in California Fig 3 3D point distance to surface compression with large error distance only ve surfaces are recognized 1     b  2 until there is an absolute necessity remaining points Points that are identiìed to be deleted need no further calculation A new challenge arises when multiple data points are associated together The values of temperature humidity and light are plotted by setting them in a two dimensional surface To map the elevation with the relative temperature and humidity in 3D we need to create a planar base and deìne error Fei Lifan in their three dimensional Douglas-Peuck er described an algorithm on how to create a base plate This process will help execute a multi-point compression in one run rather than executing each 2D plane separately B Cooling system energy consumption relationship with temperature and humidity Using 3D visualization of related points we have depicted energy consumption relationship with temperature and humidity for a subset of points measured in one month shown in Figure 2 In order to remove points that are closer than the error we need to compute the distance from a point to a base surface in Figure 3 Without loss of generality here our assumption is that the surface is a no-uniform rational basis spline e.g a NURBS surface With a base surface S\(u v and a point P we need to nd S closest distance to P Our goal is to nd a coordinate u v for which the distance from S\(u v to point P is minimum Figure 1 It is known that shortest line distance forms a perpendicular from P to S As we create a function of the parameters of the surface we need to examine how a surface is built from multiple points There are multiple ways to build a surface by using Bezier triangle patches polynomial curves and by B-Spline surface The concept covers a triangle patch there are also multiple types of B-Splines but we considered only the triangle patch in our experiment Letês consider a set of points  S i  n 0 i 0  S i  S i 1 called knots and the vector connecting them called knot vectors  Given a rectangular lattice of 3D points and controlling point P for 0  i 0  n 0  we will have 0  i 1  n 1  a B-Spline rectangle patch X  s t   n 0 ii 0 0  n i 0 B 0 i 0 j 0  s  B 1 i 1 j 1  t  P i 0 j 1 polynomial satisìes Cox-de Boor formula and nally we will end up with the polynomial components X  s t   B 1 i 0  t  012 1 t i  t<t i 1 0 otherwise B 1 i,j  t   t  t i  B 1 i,j  1  t   t i  J  1  t i   t i  J  t B 1 i  j,j  1  t  t i  j  1  t i 1 Now that we could deìne the surface based on our point cloud we will try to nd the distance from a point to a polynomial Given a parametric surface and a point P  to apply the R-DRH we want to nd a point on the surface S that is closest to P  Our objective is to nd the parameters u v such that the distance from S\(u v to P is minimal Our approach begins with the geometric calculation of the line segment from P to Q\(t by drawing a right angle triangle on the tangent plane of the surface at S\(u0 v0 The vector between the surface and the arbitrary point can be expressed as a function of the parameters of the surface r  u v  S  u v   P f  u v  r  u v  Su  u v  and g  u v  r  u v  Sv  u v  By using the Newton Iteration we can nd an initial estimation by evaluating a surface tile of size nxn at equally spaced points With these parameters we will have  i   u v    u i 1  u i v i 1  v i  f i   f u Cf v  u i v i  g u  u i v i  g u  u i v i    015       S u  u i v i   2  r  u i v i  S uu  u i v i  S u  u i v i  S v  u i v i  r  u i v i  S vu  u i v i   S u  u i v i  S v  u i v i  r  u i v i  S uv  u i v i   S v  u i v i   2  r  u i v i  S vv  u i v i        2014 IEEE World Forum on Internet of Things \(WF-IoT 306 


TABLE I P ERFORMANCE EVALUATION OF B IG C O  Error margin  of data points BigCO R-DPH Compression execution time\(sec  0 1440 0 0  2 427 37.5 88  3 2 38.4 99.86  k i    f  u i v i  g  u i v i   Considering the fact that we have an initial estimation of  u 0 v 0  using Newton iterations Piegl and Tiller and two zero tolerance of Euclidean distance and zero cosine measure we will check the following formula to nd the lowest distance  S u  u i v i    S  u i v i   P    S u  u i v i    S  u i v i   P      S v  u i v i    S  u i v i   P    S v  u i v i    S  u i v i   P     If the criteria below are not met then a Newton step is taken to make sure a   u i   b and c   v i   d  III E XPERIMENTAL RESULTS The Orchestrator is implemented using Raspberry-Pi and it stores data from sensors into a MySQL database Python is used to develop command interface for sensors as well as to implement R-DPH algorithm to compress sensor data The user interface and web development are done using PHP language while the Apache Web server engine is used to provide the necessary interfacing Wireless sensor nodes are programmed to send data at periodic intervals to the orchestrator WSN nodes from MAXFOR CM5000 are used to setup WSN Each node has temperature light and humidity sensors The orchestrator is connected to the cloud using Wi-Fi and using a sink node it connects with deployed sensor networks Sensors are categorized as sink node base station access points supports multi-hop routing and end points sensing or actuation device Nodes are identical and are compatible of IEEE 802.15.4 Micro-controllers CC2420 RF Chip radio and sensors are mounted on MAXFOR CM5000 and they are programmed using TinyOS In our development we use hierarchical gradient based routing described in to form a mesh netw ork among the sensor nodes In the gradient based routing the backbone network is initially formed by using controlled ooding The base station initiates the network formation by broadcasting a packet in which it sets the gradient height to 1 Nodes that receive the gradient packet set their gradient to the received value and rebroadcast the packet by increasing the gradient value by one This constructs a network organized into layers where the higher gradient nodes report to the lower gradient ones For a given temperature and a humidity taken over a period of time t  we identify series of points with t h in a series of equally distanced in time scale utilizing R-DPH a tolerance of error  is deìned compression will implement the point reduction using the given error distance Table 1 shows compression result of 1440 sample points per day once every one minute and it clearly demonstrates the effectiveness of this approach The ability to compress remains relevant to the diversity of the points how far they are apart and the given error margin   In a real scenario such as a green house where temperature spikes are not expected the algorithm could be extremely effective In the experiment we inferred that interrelated points like temperature and humidity can be correlated to the amount of energy needed to cool down a room for an acceptable human comfort level For example a low temperature triggers a reduction in the ability of the air to hold moisture In addition the information extracted from their combination can provide easier combinations with other relevant data sets like power consumption temperature feedback by air conditioning units By adding multiple measurements we can process the compression as a 3D entity IV C ONCLUSION Embedded sensor networks can produce signiìcant amount of data Accumulated data should be either transmitted or aggregated and sent to a remote cloud server Since wireless sensors have a limited storage capacity they need to either dispose of old data or stop producing new ones until old data is ofîoaded Our study shows aggregating data from several sensors can produce gigabytes of data in a week Obviously an orchestrator with enough storage capacity can handle the required space for a small sensor network setup for a short period of time However we will need a larger data management and storage capacity for large scale deployments To address this problem we experimented with a streaming compression algorithm extending Ramer-Douglas-Peucker heuristic and we achieved as high as 99.86 compression of sensor data In future a multi-orchestration will be designed to handle multicast and unicast data reception and parallel data warehousing for higher availability and disaster recover for large sensorcloud architecture V A CKNOWLEDGMENTS The authors would like to thank Kim Young Jin and Sung-il Hwang from MAXFOR Technology Inc Korea for generously donating sensor nodes for this project Part of this work is funded by the research grant available from Electrical Engineering and College of Engineering California State University at Long Beach R EFERENCES  F  Lif an Indirect generalization of contour lines based on DEM gener alization using the 3D Douglas Peucker algorithm School of Resource and Environment Science Wuhan University 129 Luoyu Road Wuhan 430079 China 2010  D Douglas T  Peuck er  Algorithms for the reduction of the number of points required to represent a digitized line or its caricature The Canadian Cartographer 10\(2 112122 1973  C Doukas I Maglogiannis Bringing IoT and Cloud Computing to w ards Pervasive Healthcare Sixth International Conference on Innovative Mobile and Internet Services in Ubiquitous Computing,922-926 2012  M Y uriyama T  K ushida Sensor Cloud Infrastructure P hysical Sensor Management with Virtualized Sensors on Cloud Computing,The 13th International Conference on Network-Based Information Systems 18,NBiS 2010 2014 IEEE World Forum on Internet of Things \(WF-IoT 307 


 M Hassan B Song and E Huh A frame w ork of sensor cloud inte gration opportunities and challenges In Proceedings of the 3rd International Conference on Ubiquitous Information Management and Communication ICUIMC 09 618-626 2009  Philip Le vis Samuel Madden Da vid Gay  Joseph Polastre Robert Szewczyk Alec Woo Eric A Brewer and David E Culler The Emergence of Networking Abstractions and Techniques in TinyOS In the Proceedings of 1st Symposium on Networked Systems Design and Implementation  NSDI pages 1-14 2004  M Mozumdar  A  Puggelli A Pinto L La v agno L V anzago Alberto L Sangiovanni-Vincentelli A Hierarchical Wireless Network Architecture for Building Automation and Control Systems Proceedings of the 7th International Conference on Networking and Services ICNS May 2011  Nimbits The Open Source Internet of Things on a Distrib uted Cloud www.nimbits.com  ThingSpeak Internet of Things www thingspeak.com 2013  Raspberry Pi single board computer an open hardw are platform based on ARM processor www.raspberrypi.org  MAXFOR T echnology INC MTM-CM5000-MSP  http://maxfor co.kr Mohammad Mostaìzur Rahman Mozumdar is a tenure track faculty in the Electrical Engineering department of the California State University at Long Beach and an ex-postdoc from the University of California Berkeley He received a Ph.D in electronics and communication engineering from Politecnico di Torino Italy His ideas on modelbased design for sensor networks made profound impact on engineering and industrial communities and have been published in book chapters renowned journals reputed conference proceedings and major scientiìc magazines Dr Mozumdarês research interests include methodologies and tools for sensor network design energy-efìcient building information and control system design cloud computing methodologies for the design of distributed embedded systems and cyber-physical systems subject to real-time safety and reliability constraints Amir Shahbazian is currently a Microsoft practice manager He received masters degree in computer science from California State University at Long beach and Business degree from University of California Los Angeles his interests evolve around Big Data Content Management Wireless sensor networks and artiìcial intelligence Amir has been a group manager at MS DMO MS Data Management Organization an international team at Microsoft handling terabytes of data for business intelligence where he developed several amazing applications in natural language analysis business intelligence data de-duplication and compression he was the recipient of Microsoft data champion award in 2004 he is currently a research lead on data patterns and correlations modeling Nhat Quang Ton received his double B.S degree in Electrical Engineering and Bio-medical Engineering from California State University Long Beach where he is currently pursuing a Master degree In 2010 he interned at Alcon Laboratories where he developed a tool for automating laser coupling into ber optics From 2011 to present he holds software intern positions in RD and AE divisions at Broadcom Corporation He is currently participated in developing cell phone related software tools for Broadcom mobile platforms His research interests include embedded systems design cloud computing and agent-based systems in sensor networks domain 2014 IEEE World Forum on Internet of Things \(WF-IoT 308 


FastQC Trimmomatic STAR HTSeq 
Trimmomatic FastQC STAR + hg19 HTSeq 
genome reads  genome reads Quality Control Patient vs Control Differential Expression Produce a Report End End No Trimming Reads Mapping Reads vs hg19 index Expression count Custom R script Custom script 
which provides a simp le way to do some quality control checks on raw sequence data coming from high throughput sequencing pipelines  performs a variety of useful trimming tasks for paired-end and single ended data h e selection of trimming steps and their associated parameters are provided via command line is an ultrafast tool for aligning sequencing reads to long reference sequences. STAR outperforms other aligners by a factor of >50 in mapping speed, while at the same time improving alig nment sensitivity and precision 3   is a Python packag e that provides infrastructure to process data from high-throug hput sequenci  It provides API and libra ries to perform DE analysis In addition, also the latest human genome reference model 19 \(hg19, see used   This pipeline has been implemented over a Linux virtual machine. The final size of the disk image of this virtual machine is 3GB, and it requires to allocate at least 30 GB of RAM for executing a proper processing. The number of cores can be defined dynamically, according to the available resources and tolerable processing time. During the computations, the total disk consumption, managed by OpenStack, was up 300 GB In our experiment we emulated a doctor interaction with the ARES system as follows  Assume a doctor needs to investigate the expression of a gene related to, e.g., a cancer, and he selects the DE analysis for this purpose An optimization function determines the processing location among the available PoPs The implemented CDN service provides the needed genomic data sets, including the patientês genome, the size of which is a 3.2 GB, together with the VM necessary to perform the relevant processing The DE analysis is done and the results is sent to the requesting medical personnel  The functional experiments have been executed over the network shown in Figure 4. These experiments are quite simple and aim to verify the correct functional implementation of the ARES components and obtain an evidence that the dynamic caching mechanism works and is effective. The genomic data are initially stored onto a single server, and caches are dynamically populated with them over time. Three clients ask for the same service The overall time needed for the execution of the software pipeline is variable according to the number of biological samples analyzed. It approximately ranges in the interval between 1 and 2 days. These outcomes of experimental processing time are used to determine the remaining time available for data and VM transfer and to define the CDN service classes. In this regards we have defined the approach illustrated in Figure 6, used in ongoing experiments, that follows a metrological approach for validating the proposed proce   3 3  In particular, the outcome of measuring the client-side success of the procedure is the achievement of results within the pre-established timeframe compliant with the CDN service deployed   Figure 4 Ö Topology of the networ k used for experiments    Figure 5 Ö Differential expression pipeline  Each measured service time, is estimated under many different conditions. In particul ar, we evaluate both the worst case approach, when the CDN service is required for the first time and caches are not populated with the needed data, and also the estimate of the expected value of the service time versus the number of requests submitted to the system in a month. In this case, estimates are obtained by averaging outcomes of the experiments an d have been characterized by calculating the corresponding uncertain ty in terms of type A 
         
         
Patient Control 
20 
20 
20 


SUCCESS 
 DNA Sequencing Costs, Data from the National Human Genome Research Institute \(NHGRI\me Sequencing Program \(GSP http://www.genome.gov/sequencingcosts/. Site visited on January 13 2014  Amazon Simple Storage Services \(S3\mazon.com/s3/. Site visited on January 13, 2014  E. Strickland, çThe gene machine and meé, IEEE Spectrum, Volume: 50 Issue: 32013 , pp. 30 Ö 59  S.F. Altschul, W. Gish, W. Miller, E.W. Myers, and D.J. Lipman, çBasic Local Alignment Search Tool,é J. Mo lecular Biology, vol. 215, pp. 403410, 1990  C. Trapnell and al, çDifferential gene and transcript expression analysis of RNA-seq experiments with TopHat and Cufflinksé, Nature Protocols 7\(3\, 2012, p.562 2012  S.F. Altschul et al., çGapped BLAST and PSI-BLAST: A New Generation of Protein Database Search Programs,é Nucleic Acids Research, vol. 25, pp 3389-3402, 1997  Technical note: Illumina systems and software http://support.illumina.com/sequencing/sequencing_software/casava.ilmn Site visited on January 13, 2014  T.F. Smith and M.S. Waterman, çIdentification of Common Molecular Subsequences,é J. Molecular Biology, vol 147, pp. 195-197, 1981  Y. Liu, B. Schmidt, D. L. Maskell. çCUSHAW: a CUDA compatible short read aligner to large genome s based on the Burrows-Wheeler transformé Bioinformatics Advance Access, published May 9, 2012 http://www.nvidia.com/content/tesla/pdf/CUSHAW-CUDA-compatibleshort-read-aligner-to-la rge-genomes.pdf. Site visited on January 13, 2014  W.R. Pearson, çSearching Protein Sequence Libraries: Comparison of the Sensitivity and Selectivity of the Smith-Waterman and FASTA Algorithms,é Genomics, vol. 11 pp. 635-650, 1991  K. Karplus, C. Barrett, and R Hughey, çHidden Markov Models for Detecting Remote Protein Homologies Bioinformatics, vol. 14, pp. 846856, 1998  A.A. Scha®ffer et al., çIMPALA: Matching a Protein Sequence Against a Collection of PSI-BLAST Constructed PositionSpecific Score Matrices Bioinformatics, vol. 15, pp. 1000-1011, 1999   1 http://www.geant.net/opencall/Applications_and_Tools/Pages/Home.aspx#ar es 
            
Access transparency Location transparency Availability Failure transparency partition tolerance Consistency Scalability 
User request 1 Service time T1 User request 2 Service time T2<T1  User request n Service time Tn<Tn-1 
YES 
Ackowledgements References 
CDN service mapping and execution Service time T1 CDN service mapping and execution CDN service mapping and execution Processing and metadata creation Processing and metadata creation Processing and metadata creation Service time T2 Service time Tn 
uncertainty, i.e. standard deviation of each estim h e  validation of the test of the ne twork consists in verifying that obtained estimates respect the given service time with a target reliability at least equal to 99%, i.e. that each service time estimate is lower than the target service time with a probability value at least equal to 0 99. Thus, the possibility of implementing different cloud service classes can therefore be demonstrated    Figure 6 ÖMethodology used for evaluating service time performance  The project ARES is still in pr ogress. Similar metrological approaches, based on the GUM \(Guide to the expression of uncertainty in measurement\fications, will be implemented through multiple experiments, used to collect also network-side me  the set of CDN services are accessible regardless the user locations, to be verified experimentally. Success = successful verification for all locations the NSIS signaling provides transparency to any change of the repository locations Success=transparency verified for all PoPs according to the CAP theorem, a distributed information system cannot gu arantee consistency, availability and partition-tolerance at the sam e time. The achievable availability for all CDN classes will be investigated in relation to the tolerable service time and the metrics illustrated below or CDN service are robust to PoP and rout er failures. We will show how the system can manage and overcome node failures. In particular the client programs will operate correctly after a server or repository failure. Repeated failures will be emulated so as to investigate and maximize the actual robustness. This metric is strictly related to access transparency the cache instantiation and update procedures will guarantee metadata cons istency. This metric is strictly related to location transparency. Repeated experiments, also in the presence of node failu res, will be executed. Any experiment will be considered successful if all caches are synchronized with the relevant metadata CDN services will allow increasing the tolerable network load and also scale gracefully to huge ones Scalability will be analyzed and op timized in relation to the suitable trade-off induced by the CAP theorem VII C ONCLUSIONS  In this paper we have illu strated the current cloud services defined and implemented by the project ARES. These services aims to offer medical and re search personnel suitable ICT tools in a networked enviro nment for handling genome data set. Services, organized in different classes according to the time requirements of the situation handled, are accessible though a cloud interface. The cloud environment is implemented by using OpenStack. In add ition to verifying the correct execution of all the virtualized software components we have presented a case study relevant to the execution of a genomic pipeline widely used for diagnostic purposes This work is co-funded by EU u nder the project ARES supported by G…ANT/GN3plus in the framework of the first G…ANT open call 1  
 
21 
21 
21 


                            
 S.R. Eddy, çProfile Hidden Markov Models,é Bioinformatics, vol. 14, pp 755-763, 1998  A.E. Darling, L. Carey, and W Feng, çThe Design, Implementation, and Evaluation of mpiBLAST,é ClusterWorld Conf. and Expo and the Fourth Intêl Conf. Linux Clusters: The HPC Revolution, 2003  R. Bjornson, A. Sherman, S. Weston, N. Willard, and J. Wing TurboBLAST\(r\A Parallel Implementation of BLAST Built on the TurboHub,é Proc. 16th IEEE Intêl Parallel and Distributed Processing Symp. \(IPDPS\002  C. Oehmen and J. Nieplocha, çScalaBLAST: A Scalable Implementation of BLAST for High-Per formance Data-Intensive Bioinformatics Analysis,é IEEE Trans. Parallel and Distributed Systems, vol. 17, no. 8 Aug. 2006  N. Camp, H. Cofer, and R. Go mperts, High-Throughput BLAST, SGI whitepaper, 2002  M. Femminella, G. Reali, D. Valocchi, R. Francescangeli, H Schulzrinne, çAdvanced Caching for Distr ibuting Sensor Data Through Programmable Nodesé, IEEE LA NMAN 2013, Brussels, April 10-12 2013   H. Lin, X. Ma, P. Chandramohan, A. Geist, and N. Samatova, çEfficient Data Access for Parallel BLAST,é Proc. 19th IEEE Intêl Parallel and Distributed Processing Symp. \(IPDPS  O. Thorsen, B. Smith, C.P. Sosa, K. Jiang, H. Lin, A. Peters, and W Feng, çParallel Genomic Sequence-Search on a Massively Parallel System,é Proc. Fourth Intêl Conf Computing Frontiers CF 1607-1623, 2005  X. Fu et al., çNSIS: a new extensible IP signaling protocol suiteé, IEEE Communications Magazine, 43\(10\2005, pp. 133- 141  H. Schulzrinne, R. Hancock, çGIST: General Internet Signalling Transporté, IETF RFC 5971, October 2010  NSIS-ka, open source NSIS im plementation by Kalsruhe University available at: https://projekte.tm.uka.de/trac/NSIS/wiki/. Site visited on January 13, 2014  M. Femminella, R. Francescangeli G. Reali, H. Schulzrinne, "Gossipbased signaling dissemination extension for next steps in signaling IEEE/IFIP NOMS 2012 Maui, US, 2012  OpenStack web site, http://www.openstack.org/. Site visited on January 13, 2014  M. Yandell and D. Ence, çA beginnerês guide to eukaryoticgenome annotationé, Nature Reviews, Genetics, vol 13, May 2012  TGen achieves 12-foldperformance improvementin processing of genomicdata with Dell and Intel-basedHPC cluster http://i.dell.com/sites/doccontent/corporate/casestudies/en/Documents/2012-tgen-10011143.pdf. Site visited on January 13, 2014  M Femminella, R Francescangeli, G Reali, JW Lee, H Schulzrinne, çAn enabling platform for autonomic management of the future internet IEEE Network, 25 \(6\, pp. 24-32  M. Femminella, G. Reali, D. Valocchi, E. Nunzi, çThe ARES Project Network Architecture for Deliverying and Processing Genomics Data IEEE 3rd Symposium on Network Cloud Computing and Applications NCCA 2014\, Rome, 2014  Don Pr euss, ç1,000 Genomes in the Cloud and NCBI Experiences https://respond.niaid.nih.gov/conferences/bioinformatics2012/Festival%2 0Proceedings/Preuss_1000_Genomes.pdf. Site visited on January 13 2014  The project AR ES, http://conan.diei.unipg.it/lab/index.php/research/ares Site visited on January 13, 2014  Evaluation of measurement data Ö Guide to the expression of uncertainty in measurementé JCGM 100:2008  Nunzi, E., "Uncertainties Analysis in RTT Network Measurements: the GUM and RFC Approaches," Advanced Methods for Uncertainty Estimation in Measurement, 2006. AMUEM 2006. Proceedings of the 2006 IEEE International Workshop on , vol., no., pp.87,91, 20-21 April 2006  P. Romano, F. Quaglia, "D esign and Evaluation of a Parallel Invocation Protocol for Transactional Applications over the Web", IEEE Transactions on Computers, 63\(2 014, pp. 317-334  FastQC, http://www.bioinformatics.babraham.ac.uk/projects/fastqc/. Site visited on January 13, 2014  HTSeq: Analysing high-throughput sequencing data with Python http://www-huber.embl.de/users/anders/HTSeq/doc/overview.html. Site visited on January 13, 2014  Lohse M, Bolger AM, Nagel A, Fernie AR, Lunn JE, Stitt M, Usadel B RobiNA: a user-friendly, integrated software solution for RNA-Seqbased transcriptomicsé, Nucleic Acids Res. 2012 Jul; 40 \(Web Server issue\622-7  A. Dobin et al, "STA R: ultrafast universal RNA-seq aligner"Bioinformatics 2012; doi: 10.1093/bioinformatics/bts635  The human genome \(hg19, GRCh37 Genome Reference Consortium Human Reference 37 \(GCA_000001405.1 http://hgdownload.cse.ucsc.edu/goldenpath/hg19/chromosomes/. Site visited on January 13, 2014  S. Anders and W. Huber Differential expression analysis for sequence count data", Genome Biology 2010 11:R106  
invited paper 
22 
22 
22 


                                     


                                                        


                           


                                        


                  


  


                                               


   


                                


                        


                           


   












































     2 8    b 4      1 8             1 2     1  8 2  


1 9    8      2 1       1     2    8    2 3\f        


     8 D 4 9  F  \b 1 8 #J 9 1     2 1   2 #-@ 1   2 9  E 1   1   2 9      6  


    8  8   1  D 1         1 F  \b0         2 D    F  \b 1 8  9  


  1 9  1   E 1  2 9     1 1 F  \b       1    18   F   1    1 #-$+  \b  2 2  


1 D     1 #-$+.B- 0/:% .0             9 1      18    1 6     1 2  1  1  


1   6      2    1 2 E 8 D 1      1 2   1   1 #-4  #-@E     2  1  1  1       


 8     1          2 F    6   F  2   8    2 C<CC/C N\bO 5      


CD    b$44NO F P Q 6   2 b$$$ ,=\b\bA  A N,O 2 C C  b$$4N  92 2   f  9-\b$$4 B N?O  !-    91  2 1 HH111-18-N+O    -1 :3%   2     0-4 


     b N4O 2   2- \f  C b$@$ \b# >\b\b$3\b$N@O  f :.% 9 /9 \f    1  6  f 2  4   A254 


Advantages of Our M ethod Advantages of Our M ethod Exploit the memory v ertical data format utilizes slidin g windows to g form a much larger database to analyze  Flexibility in Choosing what to choose  Choosing what to choose to build the rules Computational and memory efficiency We have a team working only on this aspect 45 Associative IDS for NextGen Frameworks Dr S Dua LA Tech 45 


Preliminary Results Intra transaction Relations Data rate simulator NH-134 Mb HOP PATH update \(Y/N Inference 11.5 Y Y 2 0.120 N N      Y   n 0.345 N NH134 Y/N   Inf 1 0.150 N N 2 0 120 Y N Inter transaction Relations 2 0  120 Y N       5 5.55 0.456 Y Relations  n 0.345 N N Nmap on DMRL nmap.org 


Anticipated Outcome Anticipated Outcome Develop algorithm capable of learning from a given heterogeneous diverse Develop algorithm capable of learning from a given heterogeneous diverse data ff Dynamic algorithmic f ramework designed to shi f t modalities and sampling rates based on complex logic Flexibility of integration into the Snort intrusion detection system 47 Associative IDS for NextGen Frameworks Dr S Dua LA Tech 47 


References References Aircraft Cockpit Image courtesy USAF http://www.faa.gov htt p   www.faa g ov  air traffic  technolo gy  p g  _ gy  Acharya R Dua S Du X Sree V Chua C K Automated Diagnosis of Glaucoma Using Texture and Higher Order Spectra Features To appear in IEEE Transactions on Information Technology in Biomedicine  Du X Dua S 2011 Cancer Prognosis Using Support Vector Regression in Imaging  Modality World Journal of Clinical Oncology 2  1   44 49 Du X Dua S 2010 Salient Frame Extraction Using Support Vector Regression and Motion Features pp 5 Proc of the National Aerospace and Electronics Conference July 14 16 2010 D M P D S 2010 Di i i ti Ft d Cl ifi ti Mthd f D essaue r  M  P  D ua S  2010  Di scr i m i na ti ve F ea t ures an d Cl ass ifi ca ti on M e th o d s f or Accurate Classification 1st ed vol 7704 pp 14 Bellingham WA Proceedings of SPIE Dessauer M P Dua S 2010 Low Resolution Vehicle Tracking using Dense and Reduced Local Gradient Features Maps 1st ed vol 7694 pp 8 Bellingham WA Proceedings of SPIE SPIE 


Acknowledgements Acknowledgements Fundin g A g encies  US 4 1 Million direct fundin g g g 4 g LA BoR NIH NSF AFRL AFOSR and NASA Research Team Samuel Kasimalla Brandy McKnight Dr Pradeep Chowriappa Connor Johnson Vasanth Nair Mihir Chowriappa  Connor Johnson  Vasanth Nair  Mihir Karnik Mohit Jain and Swadheen Songmen Associative IDS for NextGen Frameworks Dr S Dua LA Tech 49 All the respective Logos belong to their owners 


Rf d Rdi R e f erence d R ea di ngs Copyright of cover pages held by respective publishers 


Thank You Questions Thank You  Questions Dr Sumeet Dua E mail sdua@latech.edu Web http://dmrl.latech.edu Associative IDS for NextGen Frameworks Frameworks Dr S Dua LA Tech 51 Image Source roadtrafficsigns.com 


