A PPDM Model Using Bayesian Network for Hiding Sensitive XML Association Rules  Khalid Iqbal Department of Computer Science SZABIST Islamabad, Pakistan mykhalidiqbal@yahoo.com  Sohail Asghar Associate Professor, Department of Computer Science Mohammad Ali Jinnah University Islamabad, Pakistan sohail.asghar@Jinnah.edu.pk Simon Fong Department of Computer and Information Science University of Macau Macau SAR ccfong@umac.mo Abstract Association Rule Mining \(ARM\was introduced for the market basket analysis where items that are frequently appeared together per transaction are identified as rules.  In such 
mining process, sensitivity issue of rules has never been addressed for more than a decade. Thus, research on guarding sensitivity in ARM should be attended to in priority by researchers, so that the risk of sensitive information disclosure can be avoided especially when the data sources are being shared In this paper, we presented a Mode-based PPDM model via Bayesian Network \(BN\ which can reliably hide away sensitive rules in ARM. Such reliability was never studied nor reported in the literature of XML domain of PPDM. One useful advantage of PPDM model is its ability to unfasten a variety of directions that could be effectively used to overcome disclosure risk in XML 
Association Rules \(XARs\oreover, PPDM model is known to benefit businesses even in absolute competitive environment Keywords- Bayesian Network; Asso ciation Rule; K2 algorithm PPDM model I   I NTRODUCTION  In Data Mining, huge datasets are used to discover knowledge in terms of trends and patterns analysis. For this purpose, a number of algorithms are formulated, such as classification, clustering and association rules mining for extracting significant patterns. Association rule mining \(ARM has its unique advantage in picking up rules that reveal strong association of items from comple x datasets. In such analysis 
user defines arbitrary minimum values for c confidence\ and s support\hresholds. Such threshold values are used to control how many transactional items from the original data source D hich are represented as association rules that we would be interested in. The representation of rule can take a form such as X Y where X and Y are the antecedent and consequent respectively. The problem in such presentation is the potential risk of disclosing the sensitive information to a third party while sharing data so urces because the identities of both X and 
Y are clearly revealed. Consequently, Privacy Preserving in Data Mining emerges as a popular research topic and it has a large relevancy to association rules mining In association rule mining, a question arises - how to identify the sensitive it ems in the original da ta source? For this purpose, researchers have proposed various methodologies such as in [1 U n for t unate l y  the s e t e c hni q u e s ar e unab l e t o  identify the sensitive item\(s\ base d on just the antecedent or consequent of the rules after they are statistically transformed from the amount of transactional records from the original data source. In such transformation, another question rises - how many item\(s\ should be considered as reliable, for declaring 
them to be sensitive hence a recommendation/justification for a modification of database should be made? These two questions pertaining to reliability and privacy hiding need to be addressed even if the problem is NP-hard 4 w ith the m i ni m a l ef f ect t o  the database To address the above-mentioned issues in ARM, Bayesian Network \(BN\attempted by the authors in handling uncertain situations of the ARM rules for achieving a high degree of reliability. This is technical possible because from literature, K2 algorithm [10  w a s used t o gene r a t e  B N f r om XML document. This document can also be used to generate XML association rules with the help of Apriori algorithm   By using K2 algorithm, we record the occurrences of the 
transactional items according to their dependencies on each other, and then we compute the mode \(the most frequent item\(s\. Such item\(s\n be used to modify the most frequent transactions of the original data source. The modified data source D is later used for minimizing the disclosure risk involved in association rule mining. Our proposed method is verified to be feasible with testing data, in hiding sensitive association rules The structure of the remaining paper is as follows. Section II provides a literature review over PPDM, XARs and BN which are the core techniques used in our method. Section III presents the proposed PPDM model while Experimental Results are shown in Section IV. Finally, section V concludes and ponders on the future work 
II  L ITERATURE REVIEW  Digital data has been increasing enormously. Therefore privacy issues are considered by the researchers in a wide variety of domains. Association Rule Mining as a popular topic in data mining needs especially to be addressed with the privacy issues. In such association rule mining process from large databases, there is a high danger of revealing valuable information to external parties In this paper, we focus on the privacy preservation in Association Rule Mining in order to 978-1-4577-1539-6/11/$26.00 ©2011 IEEE 30 


reveal non-obvious information from data sources. As such, the literature is presented mainly on Privacy Preservation in Data Mining as below Weng et al. proposed an efficient algorithm for fast hiding sensitive association rules named as FHSAR  1  Th i s  algorithm considers a database D and SAR \(Sensitive Association Rules\ with minimum support and minimum confidence to hide. For this purpose, the FHSAR generates a released database  D Afterwards  D is used to generate rules Consequently, sensitive rules ar e entirely hidden with the minimized side effects The implementation of this al gorithm is carried out in two stages. In first stage FHSAR scans the database D one time and it gathers correlated information of the transactions and sensitive rules. This correlation is represented by a graph G 1 Moreover, a transaction t 1 has i k items and can be represented as kki1kj  R where R j | SAR t i SAR  k R      In addition to t i transactions\ a prior weight w i is associated with each edge u, v as heuristic to estimate side effects. It can be computed by a simple formula such as   1 ik  2 where M IC max\(|R  ti ii wMIC         1 In  t h e  second stage, transactions t i e modified one after another until the entire set of sensitive rules is hidden. This modification of transactions is carried out according to the prior weight w i  associated with the transactions. Therefore the proposed steps are repeated until SAR      These steps include selection of transactions, deletion of items, function for checking-and-removing item for the sake of avoiding hidden rules, computation of w k for modified item and placing it in PWT \(Prior Weighted Transaction\, modifying SAR j  and L\(SAR j  and removal of SAR j from SAR    T hus  t h e i r proposed algorithm contributes in hiding the entire sensitive rules with minimum side effects. The main strength of FHSAR is the outclass performance over the other techniques Moreover, it modifies the original data source into a release database with minimum side effects. The limitation of the proposed algorithm is over-hidi ng a significant number of nonsensitive rules  To restrict the sensitivity issu e in quantitative analysis data using association rules, Krishna et al. proposed a novel method to mine statistical and fuzzy association rules from quantitative data [2   Bef o r e the use o f A p r i o r i a l gor ithm  1 1 o n  the dat a   they are booleanized by changing the quantity of an attribute to 1. Also for the quantity of zero for attribute is taken as 0. Thus these booleanized data are passed to the Apriori algorithm [11 12  to gene r a t e  B A Rs B o o le anize d A ssocia t i o n Rules   L a te r  on, SARs \(Statistical Association Rules\ and FARs \(Fuzzy Association Rules\ are generated from the quantitative data using other relationship measures. The measures used in place of support and confidence for SARs are Mean X     and Standard Deviation \(SD or  These measures are calculated with the following formulas in the equations below [2             2 1 11   2.3  2.4                 n ii i XX X nn   Let D be a database that contains set of attributes A, B C, ƒ , P and n transactions. Therefore D presents paired entries based on attributes and transactions over a set of real numbers R Hence, the SARs can be presented in the form of association rules as 11 11 11   aa bb cc AX BX CX            where X     and  represent the Mean and Standard deviation respectively, and A, B, C are attributes in D FARs is then mined from the quantitative database using fuzzy logic. Fuzzy logic suggests the belonging of an element to a membership value of either 1 or 0. The memb ership value is assigned by the membership function as  0,1 x mf x D     2 Mo re ov e r   FA R  is presented in pairwise form such as attribute, linguistic term which is useful for the assessment and understanding by users. Thus the membership function can be built with fuzzy sets that are comprehensible, such as Low, Medium, High and Very High. Hence, FAR is presented in the form   0.8  0.2   0.7  A Low Medium B Medium High 0.3   0.1  0.9 C High VeryHigh 2   Th i s ru l e c a n  be  interpreted in a simplier form such as 0.8 0.7 ALow BMedium  C VeryHigh  0.9 Thus the theoretical interpretation is based on higher values Consequently, the authors converted quantified data into BARs and generated association rules using Apriori algorithm 11, 12   F u rt h e rm or e, t h e qu an t i f i e d dat a bas e i s  u s e d  f o r t h e  generation of SARs and FARs using the commodity dataset and the results are compared with the BARs. The main strength of the proposed approach is to describe the behavior of each attribute in the form of association rules. Additionally the clustering technique dependency is removed by using cross validation to cluster data in an optimal and automated way Moreover, dissimilarity among values of clusters is calculated with the use of coefficient variation which is the ratio of  and  X     In spite of reasonable benefits, the measures used in the proposed approach are highly influenced either from the very low or very high value of commodities. Furthermore, the proposed method does not hide the sensitive data and display all the patterns regardless of interesting or not. Finally, the output results are not very easy to interpret especially when the values of the measures in the rule are chosen to be very high or very low With the new metric introduction for not to disclose sensitive information, Saygin et al. [3 pr es ente d  a l gor ithm s  f o r  privacy preserving by demonstration of security issues related to association rules. They extended their approach by making some modifications in the original dataset. This modification is carried out with an introduction of new symbol ?Ž mark. The question mark in the transactions neither represents the presence nor the absence of an item. With this modification in the original dataset, support and confidence are also affected and modified definitions are presented. For this purpose, the support for an itemset is taken in interval form such as  minSupport  A  maxSupport  A   3    M o r e ov er th e c o n f ide n ce  interval is presented as minConfidence  antecedent  consequent  maxConfidence  antecedent consequent  T h e following equations \(2.5\nd \(2.6\ represent the minConfidence  antecedent consequent   maxConfidence  antecedent consequent  31 


 min   100  max   2.5  max   100  min   2.6 minConfidence A B Support A B Support A maxConfidence A B Support A B Support A      From the above equations, they noted some interesting properties     minConfidence A B maxConfidence A B   and min   max   Support A B Support A B   The problem with the placement of ?Ž mark in sanitization process is the deviation from the Minimum Support Threshold \(MST Minimum Confidence Threshold \(MCT\s which increase the degree of uncertainty of the rule called as Safety Margin SM\. Therefore, the introduction of ?Ž mark in place of 1 does not reduce the support and leads to confidence reduction This reduction is made by placing ?Ž in place of 0 in an interleaved fashion in the process of hiding association rules Consequently, half of the sensitive association rules are hidden with the reduction of support and the rest of the half is hidden with confidence reduction As most of the literature do not provide an accurate solution for addressing sensitivity of association rules, Atallah et al. [4  focused on association rules R mined from the source database D The problem focused is how to transform a database D into released database D Moreover, hidden rules R h be observed through the modified database  by reducing the support of rules. Thus, transformation is referred to as sanitization of D from which the knowledge is preserved from disclosing to the public eyes. Such optimal transformation is of a NP-hard problem [4  T o solve this pr ob l e m a p p r o x im a t e l y   let A and B be the two itemsets which are goodŽ and bad respectively [4  F r o m thes e i t em sets, w e a r e n o t int e r e ste d in  restricting the occurrence of A but we want to ensure little occurrence of B Both occurrence and non-occurrence of itemsets are incompatible. Besi des this incompatibility, NPhardness problem comprises of three Optimization Problems such as Problem 1, Problem 2 and Problem 3. To solve these problems, the HITTING SET instances are taken into account for each of the proposed problems  Mor e o v er he u r i s tic approach is suggested for optimal sanitization with illustration based on preliminary definitions and data structure required for algorithm are described [4   The reliability estimation is carried out by Doguc et al. [5  who came up in literature with a generic approach to estimate the trustworthiness of a system. Such estimation of an approach in terms of reliability is presented by BN \(Bayesian Network Model. In such estimation, historical dataset is used based on the edges and nodes. Edges represent the relationship among nodes which is uncertain. For th is purpose, Bayesian theorem is used through which an i th node occurrence can be measured with a-priori occurrences of j th nodes. Therefore K2 algorithm 5, 10  can  b e u s e d t o m eas u r e th e  rel i a b il ity of  oc cu r r en c e s of  nodes at any position in an incremental fashion. Moreover, K2 algorithm [1  qu an tif i e s as s o ciat ion s an d r a n k s th e p a r e n t  s e t  with a reduction of search space heuristically and with the use of scoring function. On the down side, however, the limitation of K2 algorithm [1  is th e fix e d ord e r in c l uding the fi r s t nod e in order as parent which can benefit in mining process of preserving association rule privacy. This may reduce the n  attributes set to n-1 th attributes set  Furthermore Bayesian Networks can be used in more complex environment for reliability analysis. In such case Richiardi et al. [6 st ed a n app r oa c h t o m e a s ur e t h e  modality reliability information. Such reliability can be obtained through Bayesian Network by combining the acoustic environment as well as classifier behavior under noisy acoustic conditions. Consequently, the overall average accuracy and variability results show the effectiveness of measuring reliability through Bayesian Network Similarly to diagnose the abnormalities of a system, Doguc et al. [7 p r es en te d a SO E  S y s te m Oper ati o n  Ef f ectiv en e s s   assessment through Bayesian Network model. This model has nodes which show sub-systems with a related dependency between them. With the evaluation of dependency, a problematic node/variable/item is identified for review. This problematic review of node/item/variable helps in re-designing of the problematic part of the system. In this way, the overall SOE effectiveness is improved In relation to Privacy Preservation, Vaidya et al. [8 a p p l i e d a method to preserve information using Naïve Bayes Classifier for vertically partitioned data. In this data, the numbers of items/column are variable but the numbers of entities are the same. Such situation can be observed while sharing information between the insu rance companies and the drug companies. Thus, to hide information from being revealed to others, model parameters are computed for the purpose of sharing and classified as new instance Similarly for preserving information, Wright et al. [9 presented a privacy-preserving protocol with the use of BN for the distributed heterogeneous data. In this case, confidential database can be shared by using the BN structure between the databases of the two parties. To construct a BN structure, K2 algorithm [10, 9 is us e d   The co nstr ucti o n  o f BN st r u c t ur e produces joint data of the two parties. The production of joint data is computed by summing a ll the intermediate values in a cryptographic manner. In this way the proposed methodology becomes secured against passive adversaries. Despite cryptographic security, the suggested methodology does not offer any detail on the irrelevant data as well as the loss of data So there is no easy way to understand the generated reliable output. For this reason, the output may not give the relevant results for which both parties share their databases III  PROPOSED  PPDM  MODEL Public concerns regarding privacy are on the rise when association rules are being genera ted especially from database that contains personal records. Privacy Preserving Data Mining PPDM\ has been studied extensively by researchers and practitioners mainly for upholding privacy and security. One way is to counter the interference from data mining by hiding sensitive information from the data. That is, by modifying a database and the output representations of association rules Here we focus on data in XML domain that are common in private and public organizations, and address security issues in the context of XML association rules. We propose a PPDM model as shown in Figure 1. Although various table text styles are provided, the formatter will need to create these components, incorporating the applicable criteria that follow 32 


 XML Document K2 Apriori XML Associat ion Rules Transactional Itemset Binary Table D/D K2 based Mode D D Modify D Output using D and D  Figure 1  Proposed Mode based PPDM Model The steps on how our proposed model function are described as follow 1  Read XML Document. The document all the transactions in XML format 2  Form transactional itemset and binary table from the inputted document. Transactional Symbolized Items are a group of symbolized items that forms a transaction based on XML document items. Binary Table of Transaction is a table containing 1s and 0s to represent the presence or absence of an item in a transaction 3  Apply Apriori algorithm on the transactional itemset from D to generate association rules. Apriori algorithm is suggested in [11 for  e ffe c tive l y ge ner a t i ng X M L  association rules after preprocessing in step 2 4  From the binary table of transactional itemset, use K2 to generate a Bayesian Network. BN and K2 Algorithm produce a useful graphical model that trains and displays interesting relationship among nodes in a probabilistic manner. The combined usage of BN and K2 is suggested by [1 5  Item# column is read to identify Mode using Conditional Probability Table \(CPT\. This table contains items and their conditional probabilities according to their dependency in Bayesian Network 6  Modify the transactional itemset based on Mode that is obtained in step 5. From CPT, the most frequent item\(s are identified for the modification of transactions. This kind of frequent item identification is called Mode 7  Apply Apriori algorithm again on the modified transactional itemsets. Then output the results in XARs IV  E XPERIMENT  In the proposed PPDM model, XML document is formed from the primary-tumor dataset  F r o m this datas e t   a  sample of 15 transactions with 14 variables of different diseases including sex is taken in the XML document. The reason for taking a small number of transactions is to help researchers to easily observe compact results with a concise dataset. Therefore, this would also be helpful while performing the comparison of their research methodologies.  Table 1 shows the experimental dataset with variables \(first row alphabetical order of variables \(second row\ and numerical order corresponding to second row. The purpose of such arrangement order is to maintain the consistency among the analysis of dataset after passing to the Apriori algorithm [1  and K2 algorithm [1  I n this w a y  the sam e  o r d e r gives m o r e  accuracy and reliability in the generated results TABLE I  A SAMPLE OF PRIMARY TUMOUR DATASET                                Figure 2  Bayesian Network formed from the dataset in Table 1 33 


The dataset in Table 1 is being used to generate the Bayesian Network \(BN\. BN is generated by using the original data source \(Table 1\ and a snapshot of the resultant BN is shown in Figure 2. The BN shows dependency of items/variables for which an item/variable has the maximum probability in an incremental fash ion with the given order. This order limits the generalization of K2 algorithm  B u t  despite this, K2 gives great reliability because of the computation of probabilities which enhances the accuracy Besides BN, mode is computed based on BN. In this case N is computed as mode because this item/variable/node was the most frequent one. So, this item is being modified in the original data source. From the primary-tumour dataset as in Table 1, XML Association Rules are generated from Original Data Source as shown in Table 2 TABLE II  XML  A SSOCIATION R ULES FROM D            The above table presents rules that have some sensitive information which must be restricted from disclosure Therefore, mode \(computed from BN\is used to modify the largest transaction in Table 1 \(extracted from the primarytumor dataset\. This modified dataset is used to generate XML Association Rules using Apriori algorithm. This ensures to minimize the disclosure risk of sensitive rules as shown in Table 3 TABLE III  XML  A SSOCIATION R ULES FROM D             With the use of Primary-tumor dataset w e pr uned three rows of this dataset because data was not available in these rows. There were 18 variables in which only 14 were chosen for their relevancy as input. Hence, the overall hidden rules with no side effect \(in term s of new rules, ghost rules\ are shown based on 215 rows/transactions of the dataset in Table 4 TABLE IV  H IDDEN XML  A SSOCIATION R ULES S UMMARY                                            V  C ONCLUSION  We proposed a method for hiding sensitive XML association rules by using PPDM model and Bayesian Networks. Original data stored as a XML document is read automatically in the PPDM model and it is converted to structure transactional itemset and binary itemset. These structures are used for generation of association rule and BN by using Apriori and K2 algorithms. Our contribution in this paper is to compute the mode based on BN while declaring the item\(s as sensitive for modification of the D. This process enables us to put out of sight the identified sensitive XARs with reasonable reliability and accuracy. Furthermore, PPDM model modifies only one largest transaction in case of a single mode Likewise, PPDM model also modifies the transaction which is the next largest in size even if two or more modes exist and declared as sensitive. This method works well as we can just focus on the largest transaction; it will be identified and declared as sensitive, and subsequently get hidden away  A CKNOWLEDGMENT  We acknowledge Lowel Guandi for K2 algorithm and Sadik Hava for Apriori implementation in Matlab  R EFERENCES  1  Chih-Chia Weng, Shan-Tai Chen, Hung-Che Lo, A Novel Algorithm for Completely Hiding Sensitive Association RulesŽ, Eighth International Conference on Intelligent Systems Design and Applications, 26-28 Nov. 2008, pp.202-208 2  G Vijay Krishna, P Radha Krishna, A Novel Approach for Statistical and Fuzzy Association Rule Mining on Quantitative DataŽ, Journal of Scientific and Industrial Research, Vol. 67 July 2008, pp. 512-517 3  Yucel Saygšn, Vassilios S. Verykios, Ahmed K. Elmagarmid, Privacy Preserving Association Rule MiningŽ, RIDE '02 Proceedings of the 12th International Workshop on Research Issues in Data Engineering Engineering E-Commerce/E-Business Systems \(RIDE 2002 ISSN:1066-1395, IEEE Computer Society  Washington, DC, USA pp.151-158 4  M. Atallah, E. Bertino, A. Elmagarmid, M. Ibrahim, V. Verykios Disclosure Limitation of Sensitive RulesŽ Proceedings of the 1999 Workshop on Knowledge and Data Engineering Exchange  ISBN: 07695-0453-1, IEEE Computer Society Washington, DC, USA, pp.45-52 34 


5  O. Doguc, and J.E. Ramirez-Marquez A generic method for estimating system reliability using Bayesian networksŽ, Reliability Engineering System Safety, Volume 94, Issue 2, February 2009, Elsevier, Pages 542550 6  Jonas Richiardi, Plamen Prodanov, Andrzej Drygajlo, "A probabilistic measure of modality reliability in speaker verification", Winner of Best Student Paper Competition, IEEE ICASSP 2005, pp.709-712 7  Ozge Doguc, Wei Jiang, A Bayesian Network \(BN\odel for System Operational Effectiveness Assessment and DiagnosisŽ, 26th ASEM National Conference Proceedings, October 2005 8  Jaideep Vaidya, Chris Clifton, Privacy Preserving Naive Bayes Classifier for Vertically Partitioned DataŽ, SDM2004, SIAM, pp.522526 9  Rebecca Wright, Zhiqiang Yang, "Privacy Preserving Bayesian Network Structure Computation on Distributed Heterogeneous Data", KDD '04 Proceedings of the tenth ACM SIGKDD international conference on Knowledge discovery and data mining, August 22…25, 2004, USA pp.713-718   Gregory F. Cooper and Edward Herskovits, "A Bayesian method for the induction of probabilistic networks from data", Machine Learning Volume 9, Issue 4, Kluwer Academic Publishers, The Netheriands pp.309-347   R. Agralwal, T.Imielinski, and A.Swami, "Mining associations between sets of items in large databases", In P.Buneman and S. Jajodia, editors SIGMOD93, Washington, D.C, USA, May 1993, pp.207-216   Primary-tumor dataset, http://mlearn.ics.uci.edu/databases/primarytum/[Accessed date: Aug. 2011    35 


      niasup 1ni1}asupminconf{maxasup  a i 1ii i  For example: we can see from Table 2, the support of [1 is 4/6, and the support of [1 **] is the greatest in the all items, so its MIS value is its own support 2/3. From this calculation, we can draw the support of various items and items among layers in Table 3 IV. APPLICATION EXAMPLE We use the form of a hierarchical structure to encode the user purchase information in table 1, express the value in the corresponding with the various items hierarchical encoded of the TID by information granulation, and calculate the support corresponding to each item encoded by the hierarchical structure, which are shown in table 2. Through the definition of multiple minimum supports based on Granular Computing and the minimum support derived form the various items calculated in Table 2,we can calculate minimum supports corresponding to each item and level-items and show  in Table 3 The entire mining process of multi-level association rules is start at the search of is high-level frequent itemsets. Each item has a minimum support by definition 2. Search the transaction data in table 2 to find the frequent itemsets which meet the minimum support in same layer and multiple layers, while record them in table 4. For example, we calculate the multiple minimum support of [1 **] and [2 **] is1 / 3, sup \([1 **] [2  111100 ? 100101 which meet the minimum support 1 / 3. therefore, [1 **] and [2 are combined as frequent itemset. To extract the frequent itemsets repeatedly, and filter the candidate itemsets which does not meet the minimum support. Finally all the frequent 2 


itemsets are shown in table 4. While no further increase in levels, the entire search process will end Then we find frequent 3 - itemsets from all the frequent 2 itemsets in table 4 which meet the multiple minimum support of definition 2, and filter out the candidate itemsets which does not meet. Repeatly extract the frequent 3  itemsets, until the entire search process is completed, the results is shown in table 5 The generation process of frequent itemsets of multi-level mining is as follows TABLE II.  THE EXPRESSION ANDSUPPORT OF BINARY INFORMATION GRANULE The Name of Information Granule The Expression of Binary Information Granule Support 21*] 000001 1/6 112] 001000 1/6 3**] 010010 2/6 22*] 100100 2/6 111] 100100 2/6 11*] 101100 3/6 12*] 011100 3/6 121] 011100 3/6 2**] 100101 3/6 1**] 111100 4/6 TABLE III.  MULTIPLE MINIMUM SUPPORTS Items MIS Items MIS 1**] 2/3 [21*] 1/12 2**] 1/3 [22*] 1/6 3**] 1/6 [111] 1/6 11*] 1/4 [112] 1/12 12*] 1/4 [121] 1/4 TABLE IV.  TABLE TYPE STYLES The Combination of Items The Expression of Binary Information Granules Support 1**]and[2**] 100100 2/6 1**]and[22*] 100100 2/6 1**]and[3**] 010000 1/6 11*]and[12*] 001100 2/6 


11*]and[22*] 100100 2/6 11*]and[2**] 100100 2/6 11*]and[121] 001100 2/6 12*]and[111] 000100 1/6 12*]and[112] 001000 1/6 12*]and[22*] 000100 1/6 12*]and[3**]  010000 1/6 111]and[2**]  100100 2/6 566 111]and[22*] 100100 2/6 111]and[121] 000100 1/6 112]and[121] 001000 1/6 121]and[22*] 000100 1/6 121]and[3**] 010000 1/6 TABLE V.  TABLE TYPE STYLES The Combination of Items The Expression of Binary Information Granules Support 11*]and[12*]and[22*] 000100 1/6 11*]and[121]and[22*] 000100 1/6 12*]and[111]and[22*]  000100 1/6 12*]and[111]and[2**] 000100 1/6 121]and[111]and[22*] 000100 1/6 121]and[111]and[2**] 000100 1/6 The multiple minimum support of each item is compared with the support assembled by various items shown in the table 4, then we can get the sets of the table 5. From the results, we can get the association rules of the same layer, such as [11 and [12 *] and [22 *], and they all satisfy the minimum support MIS \([11 *] and [12 *] and [ 22  12 22 rules of different layers, such as [12 *] and [111] and [2 they also satisfy the minimum support MIS \([12 *] and [111 and [2  111 2 6, so that we achieve the multi-level association rules Different rules support of different data items produced need to meet different multiple minimum support in order to find these rules, such as the support of [12 *] and [2 **] is sup 12 *] and [2 011100 ? 100101 multiple minimum supports MIS \([12 *] and [2 


MIS \([MIS \([12 2 12 *] and 2 frequency down-generating search space of frequent itemsets V. CONCLUSIONS This paper presents a multi-level association rule mining method based on binary information granules operations and multiple minimum support constraint, with hierarchical encoding and binary granular computing of information granules operation to acquire frequent itemsets at intra level as well as inter level. We give a new definition of support and confidence based on binary information granules. And combined with the definition of multiple minimum supports we effectively restrained the generation search space of frequent itemsets, and found new rules implied in the scarce data items, achieved association rule mining of multi-layer including cross-layer. We got more meaningful rules, and avoided the generated useless rules from the high frequency data items. At last, the method is applied to mining agricultural information association rules, which has been proven to be effective and practical REFERENCES  1] Agrawal R, Imielinski T, Swami A. Mining association rules between sets of items in large databases[C] // Proceedings of the 1993 ACM SIGMOD. Washington:ACM SIGMOD, 1993: 207-216 2] Lin Q.Granular Language and Its Deductive Reasoning.[J Communications of ACM,2002,5\(2 3] Xu Jianfeng, Liu Lan, Qiu Taorong, Hu Ran. On Data Ming Algorithms Based on Binary Numeral Granular Computing. [J].Compter Science 2008,35\(3 4] Liu Qing,Jiang S L.Reasoning about Information Granules Based on Rough Logic.In:RSCTC 2002,L NA I 2475,2002.139?143 5] Ming-Cheng Tseng,Wen-Yang Lin.Efficient mining of generalized association rules with non-uniform minimum support.[J].Data knowledge engineering,62\(2007  567 


of the proposed approach are described. A simulation dataset with 64 items and 10000 transactions were used in the experiments. The dataset followed the exponential distribution. The initial population size P is set at 50, the archive size is set at 30, the crossover rate pc is set at 0.8, and the mutation rate pm is set at 0.001. The parameter d of the crossover operator is set at 0.35 according to Herrera et al.s paper [14] and the set of minimum support values is {3 4%, , 13%}. The experiments were first made for demonstrating the evolution of the Pareto fronts by the proposed approach. The evolution of the Pareto fronts of chromosomes in the archive along with different generations by the proposed approach is shown in Fig. 1 From Fig. 1, we can observe that the solutions were distributed on the Pareto fronts and the final solutions after 500 generations were better than those in different generations. Besides, we can also found that the derived solutions on a Pareto front are trade-offs between the two objectives. It thus depends on the user preference to decide which solutions on a Pareto front are desired. The experiment was then made for comparing the final Pareto front of chromosomes in the archive of the proposed approach with the previous approach [2], and is shown in Fig. 2  250 300 350 400 450 500 550 600 60 70 80 90 100 110 120 130 140 Suitability To tal N um be r o f L 1 


Generation = 0 Generation = 100 Generation = 200 Generation = 300 Generation = 400 Generation = 500  Fig. 1. The Pareto fronts derived by the proposed approach with different generations 450 500 550 600 65 70 75 80 85 90 95 Suitability To tal N um be r o f L 1 The Proposed Approach The Previous Approach  Fig. 2. Comparison results of final Pareto fronts between the proposed approach and the previous approach  From Fig. 2, it is easily to know that the Pareto front derived by using the proposed approach is better than the previous one.  From the experimental results, we thus can conclude that the proposed approach is not only effective in finding an appropriate set of solutions, but also can provide different options to users for further analysis VI. CONCLUSIONS AND FUTURE WORKS The SPEA2 adopted a fine-grained fitness assignment strategy, a density estimation technique, and an enhanced archive truncation method to derive better Pareto solutions 25]. In this paper, we have utilized it to propose a more sophisticated multi-objective approach to find the appropriate sets of membership functions for fuzzy data mining. Two objective functions are used to find the Pareto front. They are minimizing the suitability of membership functions and maximizing the total number of large 1-itemsets respectively Experiments on a simulation dataset were also made to 


show the effectiveness of the proposed approach. The results show that the proposed approach is effective in finding an appropriate set of solutions. Further, the experiments also show that the proposed approach can derive better Pareto front than the previous one [2]. In the future, we will continuously enhance the multi-objective genetic-fuzzy approach for more complex problems REFERENCES 1] C. C. Chan and W. H. Au, Mining fuzzy association rules, The Conference on Information and Knowledge Management, Las Vegas pp. 209-215, 1997 2] C. H. Chen, T. P. Hong, Vincent S. Tseng and L. C. Chen, A multi-objective genetic-fuzzy mining algorithm, The 2008 IEEE International Conference on Granular Computing, 2008 3] C. H. Chen, T. P. Hong, Vincent S. Tseng and C. S. Lee, A genetic-fuzzy mining approach for items with multiple minimum supports, Soft Computing, Vol. 13, No. 5, pp. 521-533, 2009 4] C. H. Chen, Vincent S. Tseng and T. P. Hong, Cluster-based evaluation in fuzzy-genetic data mining, IEEE Transactions on Fuzzy Systems, Vol. 16, No. 1, pp. 249-262, 2008 5] O. Cordn, F. Herrera, and P. Villar, Generating the knowledge base of a fuzzy rule-based system by the genetic learning of the data base IEEE Transactions on Fuzzy Systems, Vol. 9, No. 4, pp. 667674, 2001 6] C. A. Coello, D. A. Van Veldhuizen and G. B. Lamont, Evolutionary Algorithms for Solving Multi-objective Problems, Kluwer Academic Publishers, 2002    7] K. Deb, Multi-objective Optimization Using Evolutionary Algorithms John Wiley & Sons, 2001 8] K. Deb, S. Agrawal, A. Pratab and T. Meyarivan, A fast and elitist multiobjective genetic algorithm: NSGA-II, IEEE Transactions on Evolutionary Computation, Vol. 6, No. 2, pp. 681-695 9] C. M. Fonseca and P. J. Fleming, "Genetic algorithms for multiobjective optimization: Formulation, discussion and generalization," The International Confidence on Genetic Algorithms pp. 416-423, 1993 10] T. P. Hong, C. H. Chen, Y. L. Wu and Y. C. Lee, " Genetic-Fuzzy Data Mining with Divide-and-Conquer Strategy", IEEE Transactions on Evolutionary Computation, Vol. 12, No. 2, pp. 252-265, 2008 11] T. P. Hong, C. H. Chen, Y. L. Wu and Y. C. Lee, "A GA-based fuzzy 


mining approach to achieve a trade-off between number of rules and suitability of membership functions", Soft Computing, Vol. 10, No. 11 pp. 1091-1101. 2006 12] T. P. Hong, C. S. Kuo and S. C. Chi, "Mining association rules from quantitative data," Intelligent Data Analysis, Vol. 3, No. 5, pp 363-376, 1999 13] T. P. Hong, C. S. Kuo and S. C. Chi, "Trade-off between time complexity and number of rules for fuzzy mining from quantitative data," International Journal of Uncertainty, Fuzziness and Knowledge-based Systems, Vol. 9, No. 5, pp. 587-604, 2001 14] F. Herrera, M. Lozano and J. L. Verdegay, Fuzzy connectives based crossover operators to model genetic algorithms population diversity Fuzzy Sets and Systems, Vol. 92, No. 1, pp. 2130, 1997 15] M. Kaya and R. Alhajj, A clustering algorithm with genetically optimized membership functions for fuzzy association rules mining The IEEE International Conference on Fuzzy Systems, pp. 881-886 2003 16] M. Kaya and R. Alhaji, Utilizing genetic algorithms to optimize membership functions for fuzzy weighted association rules mining Applied Intelligence, Vol. 24 ,  No 1, pp. 7-15, 2006 17] M. Kaya and R. Alhajj, Integrating multi-objective genetic algorithms into clustering for fuzzy association rules mining, The IEEE International Conference on Data Mining, pp. 431-434, 2004 18] M. Kaya, Multi-objective genetic algorithm based approaches for mining optimized fuzzy association rules, Soft computing, Vol. 10 pp. 578-586, 2006 19] C. Kuok, A. Fu and M. Wong, Mining fuzzy association rules in databases, SIGMOD Record, Vol. 27, No. 1, pp. 41-46, 1998 20] Y. C. Lee, T. P. Hong and W. Y. Lin, Mining fuzzy association rules with multiple minimum supports using maximum constraints, Lecture Notes in Computer Science, Vol. 3214, pp. 1283-1290, 2004 21] H. Roubos and M. Setnes, Compact and transparent fuzzy models and classifiers through iterative complexity reduction, IEEE Transactions on Fuzzy Systems, Vol. 9, No. 4, pp. 516-524, 2001 22] J. D. Schaffer, Multiple objective optimization with vector evaluated genetic algorithms, The International Conference on Genetic Algorithms, pp. 93-100, 1985 23] C. H. Wang, T. P. Hong and S. S. Tseng, Integrating membership functions and fuzzy rule sets from multiple knowledge sources, Fuzzy Sets and Systems, Vol. 112, pp. 141-154, 2000 24] S. Yue, E. Tsang, D. Yeung and D. Shi, Mining fuzzy association rules with weighted items, The IEEE International Conference on Systems 


Man and Cybernetics, pp. 1906-1911, 2000 25] E. Zitzler, M. Laumanns and L. Thiele, "SPEA2: Improving the strength Pareto evolutionary algorithm for multiobjective optimization," Proc. Evolutionary Methods for Design, Optimization and Control with App. to Industrial Problems \(Barcelona, Spain, 2001 pp. 95-100 


9] Y. Gong, S. Mabu, C. Chen, Y. Wang, and K. Hirasawa, "Intrusion detection system combining misuse detection and anomaly detection using genetic network programming," in Proc. of the SICE-ICASE International Joint Conference, 2009, pp. 3463-3467 10] "Kddcupl999 data. " [Online]. Available: kdd.ics.uci.eduldatabases kddcup99/kddcup99.htrn1 11] R. P. Lippmann, D. J. Fried, I. Graf, J. Haines, K. P. Kendall, D. Mc Clung, D. Weber, S. Webster, D. Wyschogrod, R. K. Cunningham and M. A. Zissman, "Evaluating intrusion detection systems: The 1998 darpa offline intrusion detection evaluation," in Proc. of DARPA Information Survivability Conference and Exposition 2000, vol. 2 IEEE Computer Society Press, 2000 12] K. Shimada, K. Hirasawa, and J. Hu, "Class association rule mining with chi-squared test using genetic network programming," in Proc. of the IEEE International Conference on Systems, Man and Cybernetics 2006, pp. 5338-5344 


n-dimension data cube\( I1  I k Support=sup_count/total_count 2 3 4. Performance Analysis Example 2 Lets talk about a practical problem just like the status of sales. Assume that we will mine the association rules involved 4 dimension attributes of sales, the minsup=25%. First of all, using OLAP technology to build a 4-D data cube and the 4 dimension attributes are: time location, item, and supplier. For location dimension which contains area, country and so on, we choose province level We use brand level for item dimension, company level for supplier dimension. Time dimension can be divided as Q1 1-3 4-6 7-9 10-12 location\(P1,P2,L1,L2 York, item\(B1,B2,B3,B4 C1,C2,C3 sales data cube can be generalized like this Graphic 2: The 4-Dimension Data Cube of Sales The details of this sales data cube are in the table follow: The amount of cells is 100 Location Time Item Supplier Count Cell-1 P1 Q1 B1 C2 5 Cell-2 P1 Q3 B1 C1 2 Cell-99 L1 Q3 B1 C1 3 Cell-100 L2 Q4 B1 C3 11 Table 2: The details data table of sales data cube We use original Apriori_Cube Algorithm to find frequent predicate set with minsup_num= 25%*100=25 According the data table we calculate that sup_count of every member of dimension L is \(P1:8, P2:5, L1:1, L2:24 and also T, I, S. So there is the process Graphic 3: The processes of old algorithm As we know, through comparing with the minsup_num dimension location has no one frequent 1-predicate set, so that there have no frequent 4-predicate set in the output by the original algorithm. But users are interested in the Candidate 1-Predicate set L T I S P1 P2 L1 


L2 Q1 Q2 Q3 Q4 B1 B2 B3 B4 C1 C2 C3 Frequent 1-Predicate set T I S Q1 Q3 B2 B3 C1 C2 I1 I 2 C1              C2                 C3 2 12 1 3 5 1 6 2 12 8 11 Q 1  Q 2  Q 3  Q 4 P 1 P 2 L 1 L 2 Candidate 2-Predicate set Q1,B2},{Q1,B3 Q1,C1},{Q1,C2 Q3,B2},{Q3,B3 


Q3,C1},{Q3,C2 Candidate 3-Predicate set Q1,B2,B3}{Q 1,Q3,B2},{Q3 C1,B2 Frequent 2-Predicate set Q1,B2}{Q1,B 3},{Q3,B2 Q3,C1 Output: 1L U 2L U 3L Frequent 3-Predicate set Q1,B2,C1},{Q1,B3,B2 Q1,B2,B3  6 level from the same dimension and SP to pruning Candidate 3 Set, pruning {Q1,Q3,B2}, keep {Q1,B2,B3} due to the special requirement on location B by users 7 1 max_support of every dimension 1 frequent 4-predicate set which contains location dimension And the candidate 3-predicate set {Q1,Q3,B2} is useless because when we mine multi-dimension association rules we should follow that one predicate set contains no more than one different level from the same dimension even the sup_count >minsup_num when there are no requirements from users. But this time, users require that different members from dimension item can exist at the same time So we redo this mining process by the improved Algorithm Graphic 4: The processes of improved algorithm At last, we got the frequent 4-predicate set which the users are interested in, and then can format the rules 5. Conclusion In this paper, we have studied issues and methods on efficient mining of multi-dimension association rules based on data cube. With the development of technology, the size 


of database has become much huge than ever before unimaginable. So the multi-dimension model of database based on data cube has become useful and popular relatively how to mine useful multi-dimension association rules based on this model has been important too. Among the algorithms for the problems we choose the most classify one to improve, to make it more efficient and useful An efficient algorithm, Apriori_Cube_Improved, has been developed which explores the multi-dimension association rules. First, we use max_support and min_support of every frequent 1-predicate set to check the levels of dimensions, and then adjust the data cube by roll-up and drill-down operation immediately. This step is embed in the process of mining association rules, so it makes the rules much more useful and flexible; second applying one predicate set contains no more than one different level from the same dimension and SP pruning can help reduce the amount of predicate set, especially with the great growing of the number. So the speed of algorithm improved is faster than ever At last, there are also many other interesting issues and flaws of the algorithm which call for further study including efficient mining multi-dimension association rules of complex measures and so on. Finally, I should thank all the people who have give me help for this paper Reference 1] Jiawei Han, Micheline Kamber. Data Mining Concepts and Techniques. China Machine Press, 2007 2] Agrawal R, Imielinski T and Swami A. Mining association rules between sets of items in large database. Proc. of the ACM SIGMOD Conf., Washington DC, 1993 3] Gao Xuedong, Wang Wenxian and Wu Sen. Multidimensional Association Rule Mining Method Based on Data Cube Computer Engineering, China,2003 4] Sheng Yingying, Yan Ren, Wang Jiamin and Li Jia. Research Multi-dimensional Association Rule Ming Based on Apriori Science Technology and Engineering, China, 2009 5] R. Agrawal and R. Srikant. Fast Algorithms for Mining Association Rules. Proc. of the 20th Int.Conf. on VLDB Santiago, Chile, 1994 6] Guozhu Dong, Jiawei Han, Joyce Lam, Jian Pei and Ke Wang Mining Multi-Dimension Constrained Gradients in Data 


Cubes. Proc. of the 27th Int.Conf. on VLDB, Roma, Italy 2001 7] M. J. Zaki. Scalable Algorithms for Association Mining. IEEE Transactions on Knowledge and Data Engineering, 2000 Candidate 1-Predicate set L T I S P1 P2 L1 L2 Q1 Q2 Q3 Q4 B1 B2 B3 B4 C1 C2 C3 Candidate 1-Predicate set L T I S P L Q1 Q2 Q3 Q4 B1 B2 B3 B4 C1 C2 C3 Frequent 1-Predicate L T I S P L 


Q1 Q3 B2 B3 C1 C2 Frequent 4-Predicate set Q3,C1,B2,P},{Q1,B2,B3 Output L1 U L2 U L3 U L4 The Dimension need to be adjust Dimension: Location Operation: Roll-up to increase the level of this dimension Result P\(P1,P2 L1,L2 2 3 2 3 The Features Of Every 1-Predicate Set Location: min_support=13 max_support=25 Time: min_support=5 max_support=30 Item: min_support=10 max_support=25 Supplier: min_support=11 max_support=27 4 5 4 max_support of every dimension 5 minsup_num=25, and no one has to be adjusted Frequent 3-Predicate set Q3,C1,B2},{Q1,B2,L Q1,B3,L},{Q3,P,B2 Candidate 4-Predicate set 


Q3,C1,B2,P},{Q1,B2,B3,L}\(7 The Features of Every 1-Predicate Set Location: min_support=1 max_support=24 Time: min_support=5 max_support=30 Item: min_support=10 max_support=25 Supplier: min_support=11 max_support=27 Candidate 2-Predicate set Q1,B2},{Q1,B3},{Q1,C1 Q1,C2},{Q3,B2},{Q3,B3 Q3,C1},{Q3,C2},{P,Q1 P,Q3},{P,B2},{P,B3},{P,C1 P,C2},{L,Q1},{L,Q3 L,B2},{L,B3},{L,C1},{L,C2 Frequent 2-Predicate set Q1,B2}{Q1,B3},{Q3,B2 Q3,C1},{P,Q3},{L,Q1 6 Candidate 3 -Predicate set Q3,C1,B2},{Q3,C1,P},{Q1,B 2,L},{Q1,B3,L},{Q3,P,B2},{Q 1,B2,B3  6 level from the same dimension and SP to pruning Candidate 3 Set, pruning {Q1,Q3,B2}, keep {Q1,B2,B3} due to the special requirement on location B by users 7 1 max_support of every dimension 1 frequent 4-predicate set which contains location dimension And the candidate 3-predicate set {Q1,Q3,B2} is useless because when we mine multi-dimension association rules we should follow that one predicate set contains no more than one different level from the same dimension even the sup_count >minsup_num when there are no requirements from users. But this time, users require that different 


members from dimension item can exist at the same time So we redo this mining process by the improved Algorithm Graphic 4: The processes of improved algorithm At last, we got the frequent 4-predicate set which the users are interested in, and then can format the rules 5. Conclusion In this paper, we have studied issues and methods on efficient mining of multi-dimension association rules based on data cube. With the development of technology, the size of database has become much huge than ever before unimaginable. So the multi-dimension model of database based on data cube has become useful and popular relatively how to mine useful multi-dimension association rules based on this model has been important too. Among the algorithms for the problems we choose the most classify one to improve, to make it more efficient and useful An efficient algorithm, Apriori_Cube_Improved, has been developed which explores the multi-dimension association rules. First, we use max_support and min_support of every frequent 1-predicate set to check the levels of dimensions, and then adjust the data cube by roll-up and drill-down operation immediately. This step is embed in the process of mining association rules, so it makes the rules much more useful and flexible; second applying one predicate set contains no more than one different level from the same dimension and SP pruning can help reduce the amount of predicate set, especially with the great growing of the number. So the speed of algorithm improved is faster than ever At last, there are also many other interesting issues and flaws of the algorithm which call for further study including efficient mining multi-dimension association rules of complex measures and so on. Finally, I should thank all the people who have give me help for this paper Reference 1] Jiawei Han, Micheline Kamber. Data Mining Concepts and Techniques. China Machine Press, 2007 2] Agrawal R, Imielinski T and Swami A. Mining association rules between sets of items in large database. Proc. of the ACM SIGMOD Conf., Washington DC, 1993 3] Gao Xuedong, Wang Wenxian and Wu Sen. Multidimensional Association Rule Mining Method Based on Data Cube 


Computer Engineering, China,2003 4] Sheng Yingying, Yan Ren, Wang Jiamin and Li Jia. Research Multi-dimensional Association Rule Ming Based on Apriori Science Technology and Engineering, China, 2009 5] R. Agrawal and R. Srikant. Fast Algorithms for Mining Association Rules. Proc. of the 20th Int.Conf. on VLDB Santiago, Chile, 1994 6] Guozhu Dong, Jiawei Han, Joyce Lam, Jian Pei and Ke Wang Mining Multi-Dimension Constrained Gradients in Data Cubes. Proc. of the 27th Int.Conf. on VLDB, Roma, Italy 2001 7] M. J. Zaki. Scalable Algorithms for Association Mining. IEEE Transactions on Knowledge and Data Engineering, 2000 Candidate 1-Predicate set L T I S P1 P2 L1 L2 Q1 Q2 Q3 Q4 B1 B2 B3 B4 C1 C2 C3 Candidate 1-Predicate set L T I S P L Q1 Q2 Q3 Q4 B1 B2 


B3 B4 C1 C2 C3 Frequent 1-Predicate L T I S P L Q1 Q3 B2 B3 C1 C2 Frequent 4-Predicate set Q3,C1,B2,P},{Q1,B2,B3 Output L1 U L2 U L3 U L4 The Dimension need to be adjust Dimension: Location Operation: Roll-up to increase the level of this dimension Result P\(P1,P2 L1,L2 2 3 2 3 The Features Of Every 1-Predicate Set Location: min_support=13 max_support=25 Time: min_support=5 max_support=30 Item: min_support=10 max_support=25 Supplier: min_support=11 max_support=27 4 5 


4 max_support of every dimension 5 minsup_num=25, and no one has to be adjusted Frequent 3-Predicate set Q3,C1,B2},{Q1,B2,L Q1,B3,L},{Q3,P,B2 Candidate 4-Predicate set Q3,C1,B2,P},{Q1,B2,B3,L}\(7 The Features of Every 1-Predicate Set Location: min_support=1 max_support=24 Time: min_support=5 max_support=30 Item: min_support=10 max_support=25 Supplier: min_support=11 max_support=27 Candidate 2-Predicate set Q1,B2},{Q1,B3},{Q1,C1 Q1,C2},{Q3,B2},{Q3,B3 Q3,C1},{Q3,C2},{P,Q1 P,Q3},{P,B2},{P,B3},{P,C1 P,C2},{L,Q1},{L,Q3 L,B2},{L,B3},{L,C1},{L,C2 Frequent 2-Predicate set Q1,B2}{Q1,B3},{Q3,B2 Q3,C1},{P,Q3},{L,Q1 6 Candidate 3 -Predicate set Q3,C1,B2},{Q3,C1,P},{Q1,B 2,L},{Q1,B3,L},{Q3,P,B2},{Q 1,B2,B3  


DMITAR Rlt  DMITAR  R esu lt s 2  5 Rules Formed Associative IDS for NextGen Frameworks Dr S Dua LA Tech 28 


DMITAR Rl  Varying Maxspan DMITAR  R esu l ts 3  5 Varying Maxspan Associative IDS for NextGen Frameworks Dr S Dua LA Tech 29 


DMITAR Res lts 4/5 Vig Di i DMITAR  Res u lts  4/5 V ary i n g Di mens i ons Associative IDS for NextGen Frameworks Dr S Dua LA Tech 30 


DMITAR Rl  Varying Number of Transactions DMITAR  R esu l ts 5  5 Varying Number of Transactions Associative IDS for NextGen Frameworks Dr S Dua LA Tech 31 


N/C t Rh N ew C urren t R esearc h Problem Domain Problem Statement and Challenges Associative Mining based IDS Associative Mining based IDS Introduction to data mining ii lid ii Assoc i at i on ru l e i n d ata m i n i ng DMITAR Algorithm  ARD h New Researc h Associative IDS for NextGen Frameworks Dr S Dua LA Tech 32 


Further Research Further Research Objectives of Our Intrusion Detection System Development Objectives of Our Intrusion Detection System Development 1 Refine and scale the DMITAR algorithm to suit our application 2 Develop methods for dynamically altering the sensor parameters Our Focus is Securing the NextGen Frameworks with New Technology Technology Associative IDS for NextGen Frameworks Dr S Dua LA Tech 33 


Simulated Sensing Environment Simulated Sensing Environment Screenshots of Data C ollected from S ynthetic Sensors Screenshots of Data C ollected from S ynthetic Sensors Simulated in Our Laboratory Three Steps Slides Collect data Collect data from all sources  all attributes  Select Select the source and their hierarchical attributes attributes to be monitored and Select Select the source and their hierarchical attributes attributes to be monitored  and Sample Sample them at different rates different rates and process them Associative IDS for NextGen Frameworks Dr S Dua LA Tech 34 


Data Collection Simultaneous collection of data screen from ENTITIES aircrafts Associative IDS for NextGen Frameworks Dr S Dua LA Tech 35 Source PRTG Network Monitor software screen shot Demo info www.paessler.com 


Parameter Selection Selection of an ENTITY/aircraft and monitoring its parameters and sensor readings Associative IDS for NextGen Frameworks Dr S Dua LA Tech 36 Source PRTG Network Monitor software screen shot Demo info www.paessler.com 


Sensor Sampling Selecting one sensor/probe and reading it at different resolutions or sampling rates Associative IDS for NextGen Frameworks Dr S Dua LA Tech 37 Source PRTG Network Monitor software screen shot Demo info www.paessler.com 


Si l ti Nt k Si mu l a ti on on N e t wor k Most scenarios can be simulated on a computer or computer network network  The aircrafts and sensors are simulated on a computer network bllb b y ana l ogica l su b stitutions Sensors provide information at different rates Sensors provide information at different rates Need Based Sensor Prioritization NSP and Dynamic Sensing Rate Sampling Associative IDS for NextGen Frameworks Dr S Dua LA Tech 38 


Vulnerability Search Scan 39 Sample UQA script with Nmap performed in DMRL Associative IDS for NextGen Frameworks Dr S Dua LA Tech 39 Source Nmap screenshot with a pearl script  Find Namp on Nmap.org 


Modality Aspect Modality Aspect A Multimodal distribution is a continuous probability distribution with two or more modes of underlying data Mltil d i M u lti p l e mo d es i n our model Associative IDS for NextGen Frameworks Dr S Dua LA Tech 40 Source http://en.wikipedia.org/wiki/File:Bimodal bivariate small.png 


Multi Modality Modality Fusion 41 SENSITIVE  UNCLASSIFIED For Official Use Only Associative IDS for NextGen Frameworks Dr S Dua LA Tech 41 


Emphasis Emphasis Our approach emphasizes on pre empting the attack Our intent is NOT to perform an autopsy to discover attacks Instead we aim to detect and prevent in attacks in real time Associative IDS for NextGen Frameworks Dr S Dua LA Tech 42 


Techniques for Discriminative Rules Techniques for Discriminative Rules Resolution Analysis Features Analyzed at Different Depths Anti Monotonic Principle Modality Aspect Treading into Unexplored Feature spaces Associative IDS for NextGen Frameworks Dr S Dua LA Tech 43 


Representative Outcomes Representative Outcomes Illustration of the Final Analysis Our method shifts between modalities and sampling rates for optimization The blue parallelograms are actual intrusions 44 The blue parallelograms are actual intrusions The Red Green Blue Plots are response of system Associative IDS for NextGen Frameworks Dr S Dua LA Tech 44 


Advantages of Our M ethod Advantages of Our M ethod Exploit the memory v ertical data format utilizes slidin g windows to g form a much larger database to analyze  Flexibility in Choosing what to choose  Choosing what to choose to build the rules Computational and memory efficiency We have a team working only on this aspect 45 Associative IDS for NextGen Frameworks Dr S Dua LA Tech 45 


Preliminary Results Intra transaction Relations Data rate simulator NH-134 Mb HOP PATH update \(Y/N Inference 11.5 Y Y 2 0.120 N N      Y   n 0.345 N NH134 Y/N   Inf 1 0.150 N N 2 0 120 Y N Inter transaction Relations 2 0  120 Y N       5 5.55 0.456 Y Relations  n 0.345 N N Nmap on DMRL nmap.org 


Anticipated Outcome Anticipated Outcome Develop algorithm capable of learning from a given heterogeneous diverse Develop algorithm capable of learning from a given heterogeneous diverse data ff Dynamic algorithmic f ramework designed to shi f t modalities and sampling rates based on complex logic Flexibility of integration into the Snort intrusion detection system 47 Associative IDS for NextGen Frameworks Dr S Dua LA Tech 47 


References References Aircraft Cockpit Image courtesy USAF http://www.faa.gov htt p   www.faa g ov  air traffic  technolo gy  p g  _ gy  Acharya R Dua S Du X Sree V Chua C K Automated Diagnosis of Glaucoma Using Texture and Higher Order Spectra Features To appear in IEEE Transactions on Information Technology in Biomedicine  Du X Dua S 2011 Cancer Prognosis Using Support Vector Regression in Imaging  Modality World Journal of Clinical Oncology 2  1   44 49 Du X Dua S 2010 Salient Frame Extraction Using Support Vector Regression and Motion Features pp 5 Proc of the National Aerospace and Electronics Conference July 14 16 2010 D M P D S 2010 Di i i ti Ft d Cl ifi ti Mthd f D essaue r  M  P  D ua S  2010  Di scr i m i na ti ve F ea t ures an d Cl ass ifi ca ti on M e th o d s f or Accurate Classification 1st ed vol 7704 pp 14 Bellingham WA Proceedings of SPIE Dessauer M P Dua S 2010 Low Resolution Vehicle Tracking using Dense and Reduced Local Gradient Features Maps 1st ed vol 7694 pp 8 Bellingham WA Proceedings of SPIE SPIE 


Acknowledgements Acknowledgements Fundin g A g encies  US 4 1 Million direct fundin g g g 4 g LA BoR NIH NSF AFRL AFOSR and NASA Research Team Samuel Kasimalla Brandy McKnight Dr Pradeep Chowriappa Connor Johnson Vasanth Nair Mihir Chowriappa  Connor Johnson  Vasanth Nair  Mihir Karnik Mohit Jain and Swadheen Songmen Associative IDS for NextGen Frameworks Dr S Dua LA Tech 49 All the respective Logos belong to their owners 


Rf d Rdi R e f erence d R ea di ngs Copyright of cover pages held by respective publishers 


Thank You Questions Thank You  Questions Dr Sumeet Dua E mail sdua@latech.edu Web http://dmrl.latech.edu Associative IDS for NextGen Frameworks Frameworks Dr S Dua LA Tech 51 Image Source roadtrafficsigns.com 


