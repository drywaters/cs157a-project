The 100 Most Influential Persons in History  A Data Mining Perspective Noora Mohammad Al-Naimi Computer Science and Engineering Department College of Engineering, Qatar University Doha, Qatar 200054034@qu.edu.qa Khaled Bashir Shaban Computer Science and Engineering Department College of Engineering, Qatar University Doha, Qatar khaled.shaban@qu.edu.qa   Abstract  Data mining has been widely applied in various domains; however, there have been limited studies into discovering hidden knowledge from factual data about selected groups of people with special c haracteristics. It is important to mine data about such group of ind ividuals to extract insightful knowledge that could lead to a better understanding of their personalities, in addition to  further sociological conclusions 
This paper presents the appli cation and outcome of data mining techniques, namely data c lustering and association rules extraction, to find com mon features and relations among social, environmental and socioeconomic factors from the lives of known influential individuals in his tory. The mining process was initiated by constructing a dataset through defining extracting, and retrieving import ant known facts about these individuals from selected and reliable sources. Second association rules discovery algorithms were applied in order to show interesting patterns and highlight relations between attributes. Finally, the data were clustered into different groups and each cluster was further analyzed to identify its most strongly defining attributes. Th e extracted association rules showed how some factors are re lated, such as the effect of environment type and order of birth in the family on the age at which the individual first engaged with their domain of 
influence. The clustering exer cise demonstrated that influential people who grew up in families of a similar size and financial status share many similar characteristics Keywords- mining of socioeconomi c data; association rules extraction; data clustering the 100 most influential people I   I NTRODUCTION   The 100: A Ranking of the Most Influential Persons in History     by M i c h a e l H. Ha rt, wa s fi rs t pu bl i s he d i n 19 78  and reprinted in 1992 with revisions. It lists a ranking of 100 people who, according to Mr. Hart, most influenced human history. The book leads the reader to distinguish between influence, greatness and fame, since a person like Ts'ai Lun 
who invented paper, may not be very well-known; however he undoubtedly had a strong influence on human history Unlike greatness and fame, which may be relative and rather subjective designations, influence can be measured in terms of number of followers, consequents of actions, etc. In his book, Mr. Hart tried to objectively measure the influence each character had, whethe r positive or negative. He introduced the biographies of the individuals he selected along with justifications of their position on the list, as compared with their peers. As may be expected given the nature of the book, it has been subject to a great deal of questioning and criticism. In the Cambridge Handbook of 
Creativity [1 th at th e scale t h at was u s e d in  this book underestimate s e mag n itu de of th e v a riatio n in  achieved eminence Moreover, the list could be accused of being biased, since it only includes a few women. Despite the criticisms on the ranking order and inclusiveness, and even if this group doesnt represent the t op 100, it definitely represents a set of highly influential persons in human history The aim of the work is to extract social, environmental and economic attributes and factors that affected and formulated the lives of the people on Mr. Harts list These attributes and factors are then processed by data mining techniques to find common characteristics and relations 
between attributes. Discovering such hidden knowledge could lead to further understanding of what affects and shapes influential people personalities. Furthermore, this work may lead to social studies that could make the best use of the findings. To the best of the authors  knowledge, no work has been conducted previously using data mining techniques to discover patterns and shared characteristics of historical figures. However, similar approaches have been discussed and applied in other contexts B. Custers   di s c us s e d t h e a d va nt a g e s a n d  disadvantages of group profiling, an action he described as 
the ascribing of common character istics to groups of people He stated that while group profiling helps in selecting targets and increasing efficiency in marketing business, it may lead to discrimination. The argument was that in a nondistributive group, where the characteristic is not shared 100%, individuals are misjudged. A technical solution to this problem was not proposed, but an emphasis on the role of law and regulations was presented. The concerns raised in this paper may be valid and special care must be taken when generalizing rules and patterns in serious cases, such as in the medical or criminological fields of study. However, the impact that these disadvantages would have on individuals 
may be negligible in many other fields In a criminological study  3 clu ster an alysis m e th od s including k-means and semi-supervised pattern learning techniques were applied on juvenile offenders data from three US systems in an attempt to identify offenders types and critical living factors of each. The clustering results produced 7 groups of offenders that correspond to previously identified types in criminology literature. It also identified variables that strictly define each cluster. These are: criminal history variables \(total adjudications, age-at-first 
2011 11th IEEE International Conference on Data Mining Workshops 978-0-7695-4409-0/11 $26.00 © 2011 IEEE DOI 10.1109/ICDMW.2011.1 719 


adjudication and total violent felony adjudications\d one demographic variable \(age-at-assessment In  4  an s po pu latio n cen su s w a s ex am in ed to study the characteristics of three disadvantaged social classes: single-parent families, elders and aborigines. The objective of the study was to find association patterns that correlate education and marital status. After constructing a decision tree and clustering using k-means algorithm, it was found that in the case of female-led single parent families with a low level of education, the woman is usually divorced or widowed. In addition, the study indicated that divorced or widowed elderly people are most likely to be living alone, an exception being widows with elementary or self-derived education. Finally, the analysis showed that there was a lack of educational resources for aborigines In the educational domain, Ramaswami and Bhaskaran    s t ud i e d t h e e ffe c t of va ri ou s pe rs on a l  ps y c ho l o g i c a l  socio-economic and environmental factors when predicting academic achievement of high school students in India. They defined these factors according to the literature and specialists from the domain. The CHAID predication model was constructed with an over all accuracy of only 44.69 The results indicated that some features, such as medium of instruction \(i.e., language\ool location and living area have a stronger influence on predicting students   performance A similar application, i.e. applying data mining to personal and social data, was performed in marketing as a contribution to the cross-selling problem raised by PAKDD07 Data Mining Competition  Bi et al    examined building classifiers from a high dimensional dataset. The objective was to identify potential customers using their personal, social and transactional information They first reduced the dimensions by identifying the critical features with the highest information gain. Second, they applied a sampling technique that overcame the problem of an imbalanced dataset and that provided better results given the criteria of the competition. Third, they used different techniques, such as decision trees, logistic regression and using multilayer perception \(MLP\d n-tuple to construct the classification models. Finally, the area under the receiver operating characteristic \(ROC\sed to evaluate the performance. The model constructed using MLP and n-tuple provided the best result, which was approximately 0.755 The rest of this paper is organized as follows: Section II describes the methodology and approach adopted when developing this work along with a brief overview of the data mining techniques used, i.e., Association Rules Discovery and Data Clustering. Section III explains the implementation steps taken in data gathering, preprocessing, and mining Results of the work are presented and discussed in Section IV, and Section V concludes the paper and suggests directions for future work II  M INING K NOWLEDGE FROM F ACTUAL D ATA OF I NFLUENTIAL C HARACTERS  The methodology followed in developing the work was based on the steps proposed for knowledge discovery in databases \(KDD\ Han and Kamber   are 1  Defining the goals In this step the objectives of the process are stated o  The aim of this work was to analyze factual information regarding the lives of influential individuals for the sake of two goals: first, to find any dependency between social, environmental and socioeconomic factors. Second, to find shared factors, if present, among the individuals or groups of them 2  Establishing target dataset This step involves two tasks: collecting the data and defining the features To accomplish this, data sources are identified and the features are selected according to the domain knowledge and the objectives stated in the previous step o  Consequently, the required data about the 100 individuals were collected from reliable sources and features were filtered as described in deta ils in Section III 3  Data preprocessing Preprocessing is performed by cleaning data from noise an d outliers, adopting a strategy to deal with missing values, etc o  Regarding noise and outliers, nothing was required in this work since the dataset was constructed initially for a special purpose However, the dataset suffered from the missing values problem which was solved using two techniques: elimination and replacement 4  Data conversion Data are standardized or transformed from one type to another, depending on target algorithms criteria o  In our work, the ranges of all features were converted to be categorical in order to facilitate the interpretation of the results and reduce the variation of values. In addition, it was a requirement of the target algorithms. This also involved discretizing the values of some attributes 5  Data mining Algorithms are applied and models are created to achieve the goals stated in step 1 o  In our case, first, association rules discovery algorithms were applied to discover the dependency between the factors. Second, the clustering algorithms were applied to form groups and find common factors within these groups. The algorithms underwent iterative parameters tuning and experimentation in order to achieve the best results 6  Interpretation and assessment During this step the output is analyzed, interpreted and evaluated. If the output is not satisfactory, the previous steps are repeated with new features o  As for this work, this step was performed twice. First to analyze the association rules obtained and select relevant and interesting ones. Second to analyze and interpret the 
720 


clusters and figure out common characteristics 7  Taking the action If the knowledge is useful, it is then applied in an appropriate way o  Other than publishing the research results and providing initial analysis through discussions, the authors are not in a position to make real use of the findings. In fact, it is suggested that the results might be the subject of a further social study \(see Section V A  Association Rules Discovery Association rules extraction is the process of discovering relations between features in databases. An association rule is an implication of the form X 002 Y where X  Y are features and X 003 Y  004 The rule X 002 Y holds in the dataset D with support s where s is the percentage of objects in D that contain both X and Y Support is calculated as the probability of X and Y  005 s 005\006\005 P 007 X 010 Y 011\005\006\005\012\007 X 010 Y 011\005\013\005 014\005\005\005\005\005\005\005\005\005\005\005\005\005\005\005\005\005\005\005\005\005\005\005\005\005\005 007\015\011\005 where 012  X 010 Y e frequency of occurrence of both X and Y and N is the number of objects in D  The rule X 002 Y has confidence c in the dataset D where c  is the percentage of objects in D containing both X and Y to those that contain only X Confidence is calculated as the conditional probability, P X  Y  005 c  006\005 P 007 Y 016 X 011\005\006\005\012\007 X 010 Y 011\005\013\005\012\007 X 011\005\005\005\005\005\005\005\005\005\005\005\005\005\005\005\005\005\005\005\005\007\017\011\005 where 012  X 010 Y e frequency of occurrence of both X and Y and 012  X frequency of occurrence of X  B  Data Clustering Clustering is the process of grouping a set of similar objects into subsets or clusters. Data objects should be similar within the cluster and dissimilar to the objects belonging to other clusters. A cluster of data objects can be treated collectively as one group and so may be considered as a form of data compression  9 Si milari ty a n d dissimilarity, known as proximity, are measures of how much two objects are alike There are several ways to calculate the proximity of two objects. One classical way is the Euclidean distance d between two objects x and y  which is given by the formula 005 020 006 021 006 n k k k y y x d x 1 2      005\005\005\005\005\005\005\005\005\005\005\005\005\005\005\005\005\005\005\005\007\022\011\005 where n is the number of dimensions and x k and y k are the k th  attributes of x and y respectively. Some other measures are limited to special kind of data such as Boolean vectors. An example of this is the Simple Matching Coefficient SMC  which is defined as 005 SMC=\(number of matching attribute values\/\(number of attributes f 00 f 11 f 00 f 01 f 10 f 11  005\005\005\005\005\005\005\005\005\005\005\005\005\005\005\005\005\007\023\011  Where f 00 the number of attributes where x is 0 and y is 0 f 01 the number of attributes where x is 0 and y is 1 f 10 the number of attributes where x is 1 and y is 0 f 11 the number of attributes where x is 1 and y is 1  Jaccard Coefficient is a modification of SMC that handles sparse objects, defined as 005 J=\(number of matching presences\/\(number of attributes not involved in 00 match f 11 f 01 f 10 f 11  005\005\005\005\005\005\005\005\005\005\005\005\005\005\005\005\005\005\005\005\005\005\005\005\007\024\011\005 III  I MPLEMENTATION  In order to discover the required knowledge, the steps provided in the proceeding section were implemented. The details of how each step was implemented are provided in the following subsections A  Data gathering Initially, the attributes of the multi-dimensional dataset were defined as: name, field of influence, year of birth, place of birth, age at first engagement with field of influence environment at childhood, whether a parent had died whether contact with an influential person had been made at an early age, height, weight, chronic disease\(s\birth order in family, family size, financial status during childhood, marital status, age at death, and religion at death. The main source of the data was Encyclopedia Britannica   In case t h e  required data were not found th ere, the following guidelines were followed 1  If the data are found in a published biographical book, then trust them 2  If the data are found in at least three websites compare the rest of the information in those websites to that in Encyclopedia Britannica. If they are identical, trust them 3  Otherwise, mark the data as missing During data gathering, there were some interesting remarks 025  In approximately 65% of the cases, the environment at childhood was on a river or a coastal area 025  In 34% of the cases, the character was the oldest child in the family; the percentage is 70% among the top 10 with 20% missing values and 10% as the youngest child. In many other cases, he was the oldest child of a second marriage or the oldest son 
721 


B  Data preprocessing and types conversion After constructing the dataset, the following steps were applied 1  Dimensions with 20% or more missing values were removed. This eliminated height, weight, and chronic disease\(s 2  Tuples with 50% or more missing values were removed. This eliminates 11 tuples  Table I  shows the final dimensions along with their possible values and their coverage percentage. The problem of missing values was handled according to what is shown in Table II    TABLE I  T HE FINAL DIMENSIONS OF THE DATA  Attribute  Value  Range Coverage Field of influence Religion 9  Philosophy 8  Invention 10  Science chemistry physics biology medicine psychology  30  Politics  politics, exploring conquest economics  38  Art art, music literature 5  Age at first engagement with field of influence  early teens 10-15 8  late teens 16-19 27  early twenties 20-25  37  late twenties 26-29  early thirties 30-35  late thirties 36-39 3  Environment  C oastal/ island 12  On a river/ on a lake  on a river, on a lake, river & forest 57  Country 8  Valley  valley s forests 7  V illage 8  City 8  Whether a parent had died  Yes 46  No 54  F amily size Small 1-3 35  Medium 4-7 4 8   Large 8 17  Birth o rder in the family  First 35  Middle  48  Last 17  M arital status Single 19  Married  married, divorced widowed 81  Early contact with an influential person Yes 65  No 35  Religion at death Abrahamic 74  non Abrahamic 26  Financial status during  childhood Poor 16  P oor-average 4  A verage 30  A verage-rich 11  R ich 39  A ge at death Thirties 30-39  1  Forties 40-49  7  Fifties 50-59 21  Sixties 60-69 27  Seventies 70-79 26  Eighties 80-89 17  Nineties 90-99  1  TABLE II  REPLACEMENT OF M ISSING VALUES  Attribute Percentage Replaced value Reasoning Environment 1 City The exact location is unknown so it is replaced by the capital city Family size 10 Medium Replaced by the median of the available data Order in family 15 Middle Replaced by the median of the available data Marital status 1 Single Replaced by the default value Religion at death  1 Abraham ic  The character is a European scientist from the nineteenth century so it is assumed that he was of an Abrahamic faith Financial status during childhood 1 Average Replaced by the median of the available data  Age at death 1 Eighties The character is alive and in his early eighties, so it is replaced by  eighties   C  Extraction of Association Rules As the objectives are to extract the association rules and cluster the data to find common characteristics,  Apriori and DBSCAN algorithms were used, respectively The Apriori algorithm, which is considered one of the best 10 data mining algorithms according to   op ts a bottom up approach in which it attempts to find frequent item sets from a transaction dataset. Each frequent item set is supposed to have frequency larger than or equal to a user specified minimum support. De pending on the frequent item 
722 


sets, association rules are generated with confidence larger than or equal to a user specified minimum confidence To discover association rules, Rapid Miner software was used to apply the W-Apriori algo rithm. Due to the size of the dataset and the scattered nature of the data, the minimum support threshold was set low \(2%\etect rare patterns while the confidence parameter was set high \(100%\ to ensure accuracy. The rationale behind these choices is: if the same combination of factors occurred in the lives of at least two most influential people, then this combination is likely to be significant D  Clusters Identification DBSCAN \(Density-Based Spatial Clustering of Applications with Noise\ensity-based clustering algorithm. The algorithm grows regions with sufficiently high density into clusters. It can discover clusters of arbitrary shape in spatial databases with noise. It defines a cluster as a maximal set of density-connected objects. The algorithm accepts two inputs 026 and MinPoints The parameter 026 is used to define the radius of the object s neighborhood while MinPoints defines the least sufficient number of objects in a neighborhood to be considered dense. In this case 026\005 was set to equal 1.0 and MinPoints to 8 To cluster the dataset, first, the values of some attributes were generalized as follows 025  Field of influence: religion - art & philosophy science & invention - politics 025  Age at first engagement in field of influence: teens  twenties  thirties 025  Financial status at childhood: poor  average  rich 025  Age at death: less than 50, 50-69, more than 70 Then, using Rapid Miner and the DBSCAN algorithm we experimented using different combinations of features to cluster the dataset. Ultimately, family size and financial status during childhood generate d the best clusters in terms of density, distribution and feasibility IV  R ESULTS AND D ISCUSSIONS  Association rules discovery and data clustering algorithms were applied indepe ndently. The following subsections contain the results obtained from the use of each technique A  Association Rules The following rule s were extracted 025  Rule 1 People who came from small poor families who also had a dead parent became influential in philosophy 025  Rule 2 If the individual was raised in the country and did not have early contact with an influential person, then he would definitely have had a dead parent 025  Rule 3 Influential people in religion who came from small families did not need to have early contact with an influential person 025  Rule 4 Unmarried people who first engaged with their field of influence in their late teens, did not have early contact with an influential person 025  Rule 5 Scientists who first engaged with their field of influence in their late teens and had a dead parent, were also the fi rst child in the family 025  Rule 6 Scientists who first engaged with their field of influence in their early teens came from small families 025  Rules 7 & 8 Scientists who were raised in a city came from small families an d died in their fifties 025  Rule 9 Influential people in religion who were the first children in the family all had a dead parent 025  Rule 10 Philosophers who did not get married lived to their eighties 025  Rule 11 Inventors who did not get married also did not have early contact with an influential person 025  Rule 12 Influential people in art who first engaged with their field of influence in their early teens never got married 025  Rules 13 & 14 People who came from poor families first engaged with their field in their late teens if they were raised in the country, while the first engagement was in their late twenties if they were raised in a village 025  Rules 15 & 16 People who were raised in a valley first engaged with their field of influence in their late teens if they were the last child in the family whereas if they were the first, the first engagement would be in their late twenties 025  Rule 17 confidence 80 1 ntors who were middle children did not need to have had early contact with an influential person B  Clustering Family size and financial status during childhood were used to cluster the available dataset. The result was five clusters whose distribution is shown in Fig. 1 and is described as follows TABLE III  C LUSTERS  CHARACTERISTICS  Cluster No Family size Financial status at childhood Coverage 1 Medium rich 23.5 2 Small rich 16 3 Small poor 10 4 Medium average 18 5 Small average 9 6 Large rich 11  Cluster 1 shows people who were raised in rich families of medium size, among which 85.7% were influential either  1  The confidence is below 100% but th e rule provides an interesting fact regarding middle children  
723 


in politics or in science and inventions. The same percentage represents those who first engaged with the field of influence in their twenties or earlier, and those who lived to be more than 50 years of age. 33% made it to their seventies. 71.5 had early contact with an influential person, and 81% got married. In addition, 62% were middle children. However all the last-born children of this cluster had both a dead parent and early contact with an influential person Cluster 2 demonstrates people who were raised in small rich families. 78.5% were either in politics or in science and inventions. 93% first engaged with their field of influence in their twenties or earlier. 71.5% were raised beside rivers or in a coastal area. Although 64% of this group were first children who usually had a dead parent, none of the last-born children had a dead parent. 85.7% got married and 57% lived more than seventy years In cluster 3, we find people who were raised in small poor families. 77.7% were rais ed beside rivers. 66.6% first engaged with their field of influence in their twenties and 66.6% lived more than seventy years. 77.7% had early contact with an influential person and 55.5% were first children. In addition, none of the people influential in religion belongs to this cluster Cluster 4 describes influential people who were raised in medium-size families with average financial status. 62.5 were raised beside rivers. 50% first enga ged with their field of influence in their teens and 31.25% in their twenties. 75 got married and all those who did not were middle children 93.75% lived more than fifty years and 37.5% made it to their seventies. 81% were of an Abrahamic faith Cluster 5 deals with people who were raised in small families with average financial status. 75 didnt have a dead parent, yet 87.5% had early contact with an influential person. 87.5% were either first or last children, and the same percentage were of an Abrahamic faith. Moreover, none of the artists or philosophers were included in this cluster Cluster 6 demonstrates influential people who were raised in large rich families. 70% were influential in politics while none were influential in religion. 90% were raised beside rivers or in a coastal area. 70% were middle children 80% either had both a dead parent and early contact with an influential person, or neither. All of them got married, but only 80% were of an Abrahamic faith Figure 1  The distibution of the clusters V  C ONCLUSION  In this paper, data mining techniques were applied to discover common characteristics and special patterns from social, environmental and economic factors in the lives of a group of the most influential people in history. The association rules showed how some factors might be related such as how the environment affected the age at first engagement in the field of influence for individuals from poor families. Another rule demonstrated how birth order in the family affected the age at first engagement in the field of influence for people who grew up in similar environments In addition, the association rules suggested that marital status was affected by the field of influence, age at first engagement with the field of influence, and whether or not there was early contact with an influential person On the other hand, clustering divided the data into 6 clusters depending on different combinations of the family size and financial status during childhood. Each cluster was analyzed and it was found that some characteristics were dominant within a cluster. The rules derived and the resulting clusters might be the subject of a further social study. This study may lead to further understanding of personality traits and an increased capacity to measure the effect of environmental and sociological factors on peoples abilities and achievements R EFERENCES  1  Michael H. Hart The 100: A Ranking of th e Most Influential Persons in History Kensington Publishing Corp., 1992 2  B.H.M. Custers  Effects of Unreliable Group Prof iling by Means of Data Mining  Proceedings of the 6 th International Conference on Discovery Science; Spring er LNCS, Vol. 2843, 2003 3  Markus Breitenbach, Tim Brennan, William Dieterich, and Gregory Grudic  Clustering of Psychological Person ality Tests of Criminal Offenders  ECML PKDD 2006 SAS Workshop on Practical Data Mining, 2006 4  CJ Chang, and SW Shyue  A Study on the Application of Data Mining to Disadvantaged Social Clas ses in Taiwan's Population Census  Expert Systems with Applications, Vol. 36, pp. 510-518 2009 5  M. Ramaswami, and R. Bhaskaran  A CHAID Based Performance Prediction Model in Educational Data Mining  International Journal of Computer Science Issues \(IJCSI Vol. 7, Issue 1, No. 1, January 2010 6  PAKDD 2007 Data Mining Competition http://lamda.nju.edu.cn/conf pakdd07/dmc07 7  Bin Bi, Lei Ji, and Qian Hu  Comparative Study on Classification Techniques to Identif y Potential Customers  Proceedings of the 2008 International Symposium on Computational Intelligence and Design ISCID'08 8  J. Han, an M. Kamber Data Mining Concepts and Technique Moran Kaufmann Publishers,pp. 45  61, 2001 9  Pang-Ning Tan, Michael Steinbach, and Vipin Kumar Introduction to Data Mining Pearson Education, US, 2006 10  Britainica Online Encyclopidea. h ttp://www.britannica.com 11  XindongWu, Vipin Kumar, J. Ross Quinlan, Joydeep Ghosh, Qiang Yang, Hiroshi Motoda, Geoffrey J. McL achlan, Angus Ng, Bing Liu Philip S. Yu, Zhi-Hua Zhou Michael Steinbach, David J. Hand, and Dan Steinberg  Top 10 algorithms in data mining  Springer-Verlag London Limited, 2007 12  James C. Kaufman,Robert J. Sternberg   The Cambridge Handbook of Creativity Cambridge University Press, pp. 180, 2010 
724 


StepS: If there is an existing itemset A in Lk and A  B u C , then calculate the value of confm \(B ? C reserve the rule such as B ? C which value is greater or equal than Wminconf Step6: Output all the mixed weighted rules such 1ikeB? c VI. THE MINING SAMPLES AND ANALYSIS ON CONSEQUENCE OF MIXED WEIGHTED ASSOCIATION RULES BASED ON COLLEGE-WIDE EXMINATION COURSE GRADE Convenient for mining, the score of each question has been divided into three sections which contains excellent average, weak. Meanwhile, made a certain notation for each section, and then use the notation instead of the score in the corresponding section. Taking score of windows for example windows have IS points, the score has been divided into three sections: if it is not only greater or equal than 13, but also equal or lower than IS ,or scoreE[13,IS], which is defined excellent part, make 0 instead of the scores in this part; Similarly, score E [9,13 use E instead of the scores in that part; score E [0,9 defined weak part, and use F instead of the scores in the part The score of network, word, excel, optional have been divided into three sections, which apply the same approach where powerpoint and access questions as a questions of optional, and the greater points of power point and access as optional grades. The detail corresponding relations between sections of questions and notations are shown in table 1 TABLE! DISCRETIZATION OF SCORES  otations Excellent Average Weak Questions Windows\(J5 Network\(20 Word\(25 ExceJ\(20 OptionaJ\(20  SImIlarly, each college IS aSSIgned a certam notatIOn to instead of them. In sequence, the notations of colleges of Mathematic Science, Electronic engineering, Physics and 


technology, Education science, Economics and management Law, Foreign studies, Physical culture, Music, File art are 0,1,2,3,4,S,6,7,8,9. The vertical weights of ten colleges Vi set as following: Vo:O.l; VJ:O.l; V2:O.l; V3:0.6; V4:O.S; Vs:O.S V6:0.6; V7:O.9; Vs:0.9; V9:O.9. The horizontal weights of questions hj set as following: Windows \(hl h2 h3  hs The following list of ten transactions \(as shown in table II algorithm Where H _weight is abbreviation of Horizontal weight V_weight is abbreviation of Vertical weight Applied mixed weights in college computer cultural foundation grades database, with Wminsup=30% and Wminconf=60%, the following interesting two rules have been extracted from the database 1 u a ? Z\(W sup = 53%, Wcan! = 84 V14-532 2010 International Conference on Computer Application and System Modeling \(rCCASM 2010 L u Z => O\(W sup = 33%, Wcon! = 90 TABLE I!. TEN TRANSACTIONS  cores Windows Network Word Er:cel Optional v ? weights notations 0.3 0.4 0.6 0.7 0.9 Vo:O.1 D G J N X V\(O.I D G J M X V2:0.1 E I J M Y VJ:0.6 D G J M X V4:O.5 0 H K M Z V5:0.5 E I K N Z V6:0.6 F G K M Y V7:O.9 E H J M Z V8:0.9 0 H L 0 Z V9:0.9 0 H L 0 Z From the first aSSocIatIOn rule, we can find that the students who get weak grades in network and excel, also obtain weak in the optional questions, moreover, the mixed weighted support of the rule is 53%, and confidence is 84 The second rule shows that the students who get weak grades in word and optional, also get weak grades in the excel questions, and the mixed weighted support of this rule is 


33%, confidence is 90%. However, the rules relevant to excel by using Apriori algorithm can not be found at the same thresholds And then, add score of single choice, the total score of student and the college as horizontal weighted items to transaction database, furthermore, 0.5, 1.2 and 1 have been assigned to the items in sequence. Other items' weights are the same as above setting. Score of single choice has been divided into three sections in the same way, and a certain notation has been assigned to each part. Also total score has been treated in the same way. In sequence, use notation A, B and C instead of scores in excellent, average and weak sections for single-choice questions, X, Y and Z for total score. With Wminsup=20% and Wminconf=30%, the following valuable rules have been discovered in the database 9 ? CCW sup = 27%, Wcan! = 38 9 ? L\(W sup = 27%, Wean! = 39 9 ? O\( W sup = 27%, Wean! = 69 9 ? Z\(W sup = 27%, Weanf = 83 Then set Wminsup=50% and Wminconf=80%, the rules have been extracted from the database o u Z ? T\(W sup = 53%, Wearif = 87 O u T  ? C\(W sup = 78%, Wean! = 100 Analyzing of the first four rules can discover that students from college of File art get the worst score in optional questions. Only if teachers strengthen the teaching of this chapter can improve average of the college, thereby improving average of the university. From later two rules we can find that grades of excel, optional and single choice have closer relationship with total score than other scores of questions. But if apply Apriori to mining rules in the transaction database and only if minimum support is decreased to 5%, rules relation with colleges can be obtained Moreover, the last rule with 48% support and 95 confidence can be obtained by using Apriori. Obviously using mixed weighted association rules algorithm improves the support and confidence of rules, and makes them be discovered easier VII. CONCLUSION This paper takes college computer cultural foundation course grade database as example, applies mixed weighted 


association rules algorithm to obtain some importance and valuable information according to characteristic of the database, such as the correlations of chapters, and the factors influence total score of students. The information has reference value for teaching, and is helpful to improve learning efficiency of students. Ultimately, the average scores of the students are improved. Similarly, the approach of analysis in scores of computer foundation course database can also be applied in other college examination course grade database, such like college English test grades database, principles of Marxist philosophy test scores database and so on. In addition, application in other database like national computer rank test, CET-4, a lot of valuable information can be discovered. This important information as reference for the teaching reform is beneficial to improve quality of teaching REFERENCES I] R. Agrawal and R. Srikant, "Fast algorithms for mining association," In Proc. of the 20th In!'1 Conf. on Very Large Database Santiago, Chile, 1994, pp. 487-499 2] Cai ,e.H., Fu, Ada W.e., Cheng,e.H., et al. "Mining association rules with weighted items," Database Engineering and Applications Symposium, Cardiff, 1998,m Porceedings, IDEAS '98, Internationa 3] Lu, S ,  Hu, H.,and Li, F., "Mining weighted association rules Intelligent Data Analysis 5\(200 I 4] Yu, S, Zhu, D., Liu, Z ,  "Application study in E-business using weighted association rule mining algorithm," Computer Engineering and Applications,2008,44\(17 5] Han,J.,Kamber,M.,2005,"Data Mining: concepts and techniques in press 6] Wang, W., Yang, J., and Yu, P.S., "Efficient mining of weighted association rules\(WAR 2000,pp.270-274 7] Kao, W ,  Huang, I., and Shen, H., et aI. "A study of weighted association rule applied in human resource job requirement Pervasive Computing\(JCPC 8] Cheng, L.,Chen,S., and Chen,J , "Applying weighted association rules with the consideration of product item relevancy," Service Systems and Service Management,2009.ICSSM'09.6th International conference, pp 888-893 V14-533 


  Xi?X s0 = ?iusx Yi?Y s0 = ?iusy Zi?Zs0 = ?iusz 4  OMsi = i  Osmi   Xi = ixsi Yi = iysi Zi = izsi 5 Substituting \(5 4 equations  ixsi ?X s0 = ?iusx iysi ?Y s0 = ?iusy izsi ?Zs0 = ?iusz 6 If ? is a vertical plane in the sphere frame Rs, i.e. us 0,0,1]T , then  ixsi ?X s0 = 0 iysi ?Y s0 = 0 izsi ?Zs0 = ?i 7 Because we know [xsi ,ysi ,zsi ]T and [X s0 ,Y s0 ,0]T , we can compute i for each i. We can then substitute in Equation \(5 obtain the extreme points of the lines in ?. Finally, we apply the homogeneous transformation to transform the coordinates of those points to the global coordinate system and trace the 3D lines. The result is shown in Fig. 8. Observe how the vertical lines are consistent with the 2D map Fig. 8. Environment with 3D lines VI. DISCUSSION AND PERSPECTIVES This paper describes an original composite sensor approach that takes advantage of the information given by an omnidirectional camera and a laser range finder to ef 


ficiently solve the Simultaneous Localization and Mapping problem for indoor environments, and to reconstruct a 3D representation of the environment. The accompanying video illustrates the incremental generation of a 2D map and the estimation of the robot trajectory alongside the laser range data projected on omnidirectional images. It also shows the vertical lines detected in the images and their mapping into a 3D reconstruction of the environment In order to show the robustness of the methodology, we tested the algorithm with a sequence taken in a different indoor environment with our old robot Anis which is equipped with the same catadioptric camera and an AccuRange 4000 2D laser range finder. This laser is composed of a laser telemeter with a rotating mirror that allows measurements of points on 360?, except for an occlusion cone of approximately 30? caused by the assembly of the mirror. The resulting 2D map is shown in Figure 9. The vertical line extraction and the reconstruction of the 3D environment were 3523 Fig. 9. Global Map obtained by SLAM in Borel Building consistent as well The SLAM problem has been solved using many different approaches, however some important problems need to be addressed that are often directly linked to the sensors used Laser range finders cannot help in evaluating the translation of a robot moving in a straight line in a corridor. Mapping in dynamic environments is also hard with only laser data. On the other hand, using visual sensors alone introduces issues such as propagating correctly the scale factor, initializing the range when using a monocular sensor, and merging data when using multiples cameras In our approach, the laser provides metric information of the environment that helps to fix a scale factor \(removing the difficulty of propagating the scale factor need to use multiple cameras. Throughout the paper we have identified several advantages of combining laser and visual sensors. Our experimental results are encouraging and give us valuable insight into the possibilities offered by this composite sensor approach We have considered several research directions that could be pursued to improve the results obtained so far. We have thought about extending our algorithm with loop closure de 


tection. This would allow the algorithm to detect previously visited locations and improve the accuracy of mapping and the precision in the estimation of the robot pose. Being able to detect previously visited places is of great importance to solve the problem of global localization and to recover the robot from kidnapping, a situation occurring when the robot is displaced by something out of its control \(e.g. taking an elevator, being transported from one location to another Therefore, solving the loop closure problem will not only improve SLAM performance, but will as well enable new capabilities Further work will concentrate on an extension of the PSM algorithm to exploit the information about vertical lines detected using omnidirectional images. Segmentation of the ground \(floor a dense \(textured onto the geometric model of the world. Finally, we believe the general approach can be extended to solve the full six degrees of freedom \(6DOF active field of research REFERENCES 1] L.Charbonnier and O.Strauss, A suitable polygonal approximation for laser range finder data, Proceedings of the Intelligent Vehicles 95 Symposium, Detroit, Mi, 1995, pp 118-123 2] J.Nieto, T.Bailey and E.Nebot, Recursive scan-matching SLAM Robotics and Autonomous Systems, vol. 55, 2007, pp 39-49 3] J.S. Gutmann,T.Weigel and B. Nebel, A fast, accurate and robust method for self-localization in polygonal environments using laser range finders, Advanced Robotics Journal, vol 14, 2001, pp 651-667 4] P.J. Besl and N.D. Mackay, A method for registration of 3D shapes IEEE Transactions on Pattern Analysis and Machine Intelligence, vol 14, 1992, pp.239-256 5] F.Ramos, J.Nieto and H.Durrant-Whyte, Recognising and modelling landmarks to close loops in outdoor SLAM, Proceedings of the IEEE International Conference on Robotics and Automation, Roma, It, 2007 pp 2036-2041 6] F.Lu and E.Milos, Robot pose estimation in unknown environments by matching 2D range scans, Journal of Intelligent and Robotic Systems vol. 20, 1997, pp 249-275 7] A.Diosi and L.Kleeman, Laser Scan Matching in polar coordintes with application to SLAM, Proceedings of the IEEE/RSJ International Conference on Robotics and Automation, Edmonton, Canada, 2005, pp 


3317-3322 8] G.Dudek and M.Jenkin, Computational Principles of Mobile Robotics Cambridge University Press, Cambridge, 2000 9] T.Lemaire, C.Berger, I.K.Jung and S.Lacroix, Vision-Based SLAM Stereo and Monocular Approaches, International Journal of Computer Vision, vol. 74, 2007, pp 343,364 10] G.Silveira, E.Malis and P.Rives, An efficient direct method for improving visual SLAM, IEEE International Conference on Robotics and Automation, Roma, It, 2007, pp 4090-4095 11] A.J.Davison, Real-time simultaneous localisation and mapping with a single camera. Proceedings of International Conference on Computer vision, vol. 2, 2003, pp 1403-1410 12] C.Mei and P.Rives, Calibration between a Central Catadioptric Camera and a Laser Range Finder for Robotic Aplications, IEEE International Conference on Robotics and Automation, Orlando, Florida, 2006 13] http://www.robots.ox.ac.uk  cmei/Toolbox.html 14] C.Mei and E.Malis, Fast central catadioptric line extraction, estimation, tracking and structure from motion. Proceedings of of the IEEE/RSJ International conference on Intelligent Robots and Systems Beijing, China, 2006, pp. 4774-4779 15] C.Mei, Laser-Augmented Omnidirectional Vision for 3D localisation and mapping.PhD thesis, Ecole des mines de Paris, Inria Sophia Antipolis, 2007 16] J.P. Barreto, General central projection systems, modeling, calibration and visual servoing, PhD thesis,University of Coimbra, Department of electrical and computer engineering, 2003 17] C.Geyer and K.Daniilidis, A Unifying Theory for Central Panoramic Systems and Practical Applications, in European Conference on Computer Vision, 2000, pp. 445-461 18] R.Smith and P.Cheeseman, On the representation of spatial uncertainty, International Journal of Robotic Research, vol 5, No.4, 1987 pp.56-68 19] R.Smith, M.Self and P.Cheeseman Estimating Uncertain Spatial Relationships in Robotis, Proceedings of the Second Annual Conference on Uncertainty in Artificial Intelligence, Philadelphia, PA, USA Elsevier, 1986, pp. 435-461 20] P.Biber, H.Andreasson, T.Duckett and A.Schilling,3D Modeling of Indoor Environments by a Mobile Robot with a Laser Scaner and Panoramic Camera, IEEE/RSJ International conference on Intelligent Robots and Systems, Sendai, Japan, October 2004 


21] S. Baker and S.K. Nayar, A Theory of Catadioptric Image Formation, IEEE International Conference on Computer Vision \(ICCV pp.35-42, Jan, 1998 22] S.K. Nayar, Catadioptric Omnidirectional Cameras, IEEE Conference on Computer Vision and Pattern Recognition \(CVPR 488, Jun, 1997 23] A.Victorino, La commande referencee capteur: une approche robuste au proble`me de navigation, localisation et cartographie simultanees pour un robot dinterieur. PhD thesis, LUniversite de Nice-Sophia Antipolis, Inria Sophia Antipolis, 2002 3524 


ec  d Fig. 5: Computation Performance Comparison Tab. 4: Computation Savings by TOP-MATA K Connect K Retail K Wap La12 50 58.35% 100 0.01% 200 0.83% 23.04 150 55.91% 400 2.65% 400 30.12% 45.38 250 53.61% 700 1.84% 800 20.03% 25.95 350 48.28% 1100 3.95% 1600 13.06% 27.89 450 43.12% 1400 1.48% 3200 6.14% 12.70 550 39.36% 1700 4.00% 6400 5.63% 7.11 Second, Fig. 5 shows the results of four data sets computed by TOP-MATA and TOP-DATA, respectively. As can be seen, in general, TOP-MATA shows a better performance than TOP-DATA. And as the increase of the ? value, the advantage tends to be even more impressive for these four data sets 4.3. The Computation Saving of TOP-MATA As can be seen in the Tab. 4, four data sets, enjoy signi?cant computation savings brought by TOP-MATA. We can conclude that the computation saving is a major factor for the performance of TOP-MATA. That is, compared with TOP-DATA, a higher computation saving implies a much better performance of TOP-MATA. Since this saving is more signi?cant as the increase of the items, TOP-MATA works better for large scale data sets with a large number of items 5. Conclusion In this paper, we studied the problem of searching for top? item pairs with the highest cosine values among all item pairs. Speci?cally, we provided a novel algorithm TOPMATA which employ a Max-First traversal strategy for ef?ciently performing top-? cosine similarity search. Extensive experimental results veri?ed the effectiveness of the algorithms, And TOP-MATA algorithm is superior to TOPDATA for large-scale data sets with multiple items Acknowledgment This research was partially supported by the National Natural Science Foundation of China \(NSFC No. 70901002 and the Ph.D. Programs Foundation of Ministry of Education of China \(No. 20091102120014 


REFERENCES 1] R. Agrawal, T. Imielinski, and A. Swami, Mining association rules between sets of items in large databases, in SIGMOD 1993 2] C. Alexander, Market Models: A Guide to Financial Data Analysis. John Wiley & Sons, 2001 3] W. Kuo, T.-K. Jensen, A. Butte, L. Ohno-Machado and I. Kohane, Analysis of matched mrna measurements from two different microarray technologies Bioinformatics, vol. 18, p. 405C412, 2002 4] H. Xiong, X. He, C. Ding, Y. Zhang, V. Kumar, and S. Holbrook, Identi?cation of functional modules in protein complexes via hyperclique pattern discovery in PSB, 2005 5] J. Han, H. Cheng, D. Xin, and X. Yan, Frequent pattern mining: Current status and future directions DMKD, vol. 15, no. 1, pp. 5586, 2007 6] P.-N. Tan, M. Steinbach, and V. Kumar, Introduction to Data Mining. Addison-Wesley, 2005 7] S. Brin, R. Motwani, and C. Silverstein, Beyond market basket: generalizing association rules to correlations, in SIGMOD 1997, Tucson, AZ, 1997, pp 265276 8] E. Omiecinski, Alternative interestmeasures formining associations, TKDE, vol. 15, pp. 5769, 2003 9] H. Xiong, S. Shekhar, P.-N. Tan, and V. Kumar Exploiting a support-based upper bound of pearsons correlation coef?cient for ef?ciently identifying strongly correlated pairs, in KDD 2004, 2004, pp 334343 10] I. Ilyas, V. Markl, P. Haas, P. Brown, and A. Aboulnaga, Cords: Automatic discovery of correlations and soft functional dependencies, in SIGMOD 2004 2004, pp. 647658 11] J. Zhang and J. Feigenbaum, Finding highly correlated pairs ef?ciently with powerful pruning, in CIKM 2006, 2006, pp. 152161 12] H. Xiong, W. Zhou, M. Brodie, and S. Ma, Top-k correlation computation, JOC, vol. 20, no. 4, pp 539552, 2008 13] S. Zhu, J. Wu, and G. Xia, Top-k cosine similarity interesting pairs search, in 


http://datamining.buaa.edu.cn/TopKCos.pdf 14] M. Zaki, Scalable algorithms for association mining, TKDE, vol. 12, pp. 372390, 2000 


enhance item-based collaborative filtering, in 2nd IASTED International Conference on Information and Knowledge Sharing, Scottsdale, Arizona, 2003 476 2010 10th International Conference on Intelligent Systems Design and Applications 


Basi Association Rles Basi c  Association R u les Association is basically connecting or tying up occurrences of Association is basically connecting or tying up occurrences of events Ol dib t f ilt t O n l y d escr ib e se t s o f s i mu lt aneous even t s Cannot describe patterns that iterate over time e g  itemset a  0  b  0  g    Eg If you sense higher data rates on the downlink than normal AND New Route generated Implies high chances of Intrusion AND New Route generated Implies high chances of Intrusion Associative IDS for NextGen Frameworks Dr S Dua LA Tech 20 


Enhanced Inte r transaction Association Rules Enhanced Inter transaction Association Rules Enhanced Inter transaction Association Rules Extension of association rules Conditional relationships at multiple different time steps e.g itemset a\(0 0 1 2 You sense Higher data rate than normal AND You see New Route g enerated AND 1 minute a g o you detected checksum gg error packets AND 2 minutes ago your encountered wrong checksum   Implies High Chance of Intrusion Enhanced Rules and Confidence Associative IDS for NextGen Frameworks Dr S Dua LA Tech 21 


Complex Spatio temporal Association Complex Spatio temporal Association Rules Further extension of inter transaction association rules Describe event durations e.g itemset a\(0,X j,Y k,Z Eg  You sense high data rates for X seconds AND new route generated j minutes ago task completed in Y AND new route generated j minutes ago task completed in Y seconds AND checksum error packets received k minutes ago for Z seconds High Chance of Intrusion With highest confidence level in association rules  association rules  Associative IDS for NextGen Frameworks Dr S Dua LA Tech 22 


DMITAR Al ith ARD DMITAR Al gor ith m  ARD Problem Domain Problem Statement and Challenges Aiti Miig bd IDS A ssoc i a ti ve Mi n i n g b ase d IDS  Introduction to data mining Association rule in data mining DMITAR Algorithm  ARD New research Associative IDS for NextGen Frameworks Dr S Dua LA Tech 23 


DMITAR Algorithm DMITAR Difference Matrix Based Inter Transaction Association Rule Miner developed in DMRL Uses vertical data format Differences of the transaction IDs are used to generate extended itemsets Windowless mechanism Associative IDS for NextGen Frameworks Dr S Dua LA Tech 24 


Deep into the Mechanism The DMITAR algorithm is based on lhilii comp l ex mat h emat i ca l assoc i at i ve formulation and proofs Four major parts Four major parts Frequent 1 itemset generation Frequent 2 itemset generation Frequent k itemset generation k>2 Spatio temporal rule formation Associative IDS for NextGen Frameworks Dr S Dua LA Tech 25 


DMITAR, Datasets Used Stock Data Stock Data Daily stock information provided by Yahoo finance Wth Dt W ea th er D a t a Provided by the US Department of Commerce and National Climactic Data Center for 700 locations across US Synthetic Data Provided by a CRU weather generator that uses a Markov chain model to generate simulated weather data for 11 UK sites Associative IDS for NextGen Frameworks Dr S Dua LA Tech 26 


DMITAR Results 1/5 Varying Support DMITAR Results 1/5 Stock Database Support FITI ITPMine PROWL DMITAR 14 6424.7s 132.39s 3.03s 5.556s 16 2348.9s 67.14s 2.14s 4.015s 18 861.92s 34.62s 1.55s 2.89s 20 334.51s 18.89s 1.12s 2.07s 22 143 84s 10 87s 0 87s 1 45s 22 143  84s 10  87s 0  87s 1  45s 24 63.62s 7.15s 0.671s 1.04s Weather Database Support FITI ITPMine PROWL DMITAR 14 36362.6s 893.1094s 5.843s 19.8281s 36362.6s 893.1094s 5.843s 19.8281s 16 11913.04s 378.2188s 3.8906s 13.4375s 18 4116s 170.3438s 2.75s 9.1406s 20 1507s 86.5781s 2.14s 6.203s 22 859.2813s 63.3438s 1.7969s 5.7656s 24 378.5313s 36.1875s 1.4375s 3.5625s Synthetic Dataset Support FITI ITPMine PROWL DMITAR 14 1651.6s 199.843s 3.1406s 17.015s 16 574 32 119 32 2 0938 10 875 16 574  32 s 119  32 s 2  0938 s 10  875 s 18 416.109s 95.31s 1.6094s 7.39s 20 370.25s 83.31s 1.453s 5.8438s 22 265.78s 66.3438s 1.3594s 4.75s 24 133.96s 43.0781s 0.9219s 3.5781s 


DMITAR Rlt  DMITAR  R esu lt s 2  5 Rules Formed Associative IDS for NextGen Frameworks Dr S Dua LA Tech 28 


DMITAR Rl  Varying Maxspan DMITAR  R esu l ts 3  5 Varying Maxspan Associative IDS for NextGen Frameworks Dr S Dua LA Tech 29 


DMITAR Res lts 4/5 Vig Di i DMITAR  Res u lts  4/5 V ary i n g Di mens i ons Associative IDS for NextGen Frameworks Dr S Dua LA Tech 30 


DMITAR Rl  Varying Number of Transactions DMITAR  R esu l ts 5  5 Varying Number of Transactions Associative IDS for NextGen Frameworks Dr S Dua LA Tech 31 


N/C t Rh N ew C urren t R esearc h Problem Domain Problem Statement and Challenges Associative Mining based IDS Associative Mining based IDS Introduction to data mining ii lid ii Assoc i at i on ru l e i n d ata m i n i ng DMITAR Algorithm  ARD h New Researc h Associative IDS for NextGen Frameworks Dr S Dua LA Tech 32 


Further Research Further Research Objectives of Our Intrusion Detection System Development Objectives of Our Intrusion Detection System Development 1 Refine and scale the DMITAR algorithm to suit our application 2 Develop methods for dynamically altering the sensor parameters Our Focus is Securing the NextGen Frameworks with New Technology Technology Associative IDS for NextGen Frameworks Dr S Dua LA Tech 33 


Simulated Sensing Environment Simulated Sensing Environment Screenshots of Data C ollected from S ynthetic Sensors Screenshots of Data C ollected from S ynthetic Sensors Simulated in Our Laboratory Three Steps Slides Collect data Collect data from all sources  all attributes  Select Select the source and their hierarchical attributes attributes to be monitored and Select Select the source and their hierarchical attributes attributes to be monitored  and Sample Sample them at different rates different rates and process them Associative IDS for NextGen Frameworks Dr S Dua LA Tech 34 


Data Collection Simultaneous collection of data screen from ENTITIES aircrafts Associative IDS for NextGen Frameworks Dr S Dua LA Tech 35 Source PRTG Network Monitor software screen shot Demo info www.paessler.com 


Parameter Selection Selection of an ENTITY/aircraft and monitoring its parameters and sensor readings Associative IDS for NextGen Frameworks Dr S Dua LA Tech 36 Source PRTG Network Monitor software screen shot Demo info www.paessler.com 


Sensor Sampling Selecting one sensor/probe and reading it at different resolutions or sampling rates Associative IDS for NextGen Frameworks Dr S Dua LA Tech 37 Source PRTG Network Monitor software screen shot Demo info www.paessler.com 


Si l ti Nt k Si mu l a ti on on N e t wor k Most scenarios can be simulated on a computer or computer network network  The aircrafts and sensors are simulated on a computer network bllb b y ana l ogica l su b stitutions Sensors provide information at different rates Sensors provide information at different rates Need Based Sensor Prioritization NSP and Dynamic Sensing Rate Sampling Associative IDS for NextGen Frameworks Dr S Dua LA Tech 38 


Vulnerability Search Scan 39 Sample UQA script with Nmap performed in DMRL Associative IDS for NextGen Frameworks Dr S Dua LA Tech 39 Source Nmap screenshot with a pearl script  Find Namp on Nmap.org 


Modality Aspect Modality Aspect A Multimodal distribution is a continuous probability distribution with two or more modes of underlying data Mltil d i M u lti p l e mo d es i n our model Associative IDS for NextGen Frameworks Dr S Dua LA Tech 40 Source http://en.wikipedia.org/wiki/File:Bimodal bivariate small.png 


Multi Modality Modality Fusion 41 SENSITIVE  UNCLASSIFIED For Official Use Only Associative IDS for NextGen Frameworks Dr S Dua LA Tech 41 


Emphasis Emphasis Our approach emphasizes on pre empting the attack Our intent is NOT to perform an autopsy to discover attacks Instead we aim to detect and prevent in attacks in real time Associative IDS for NextGen Frameworks Dr S Dua LA Tech 42 


Techniques for Discriminative Rules Techniques for Discriminative Rules Resolution Analysis Features Analyzed at Different Depths Anti Monotonic Principle Modality Aspect Treading into Unexplored Feature spaces Associative IDS for NextGen Frameworks Dr S Dua LA Tech 43 


Representative Outcomes Representative Outcomes Illustration of the Final Analysis Our method shifts between modalities and sampling rates for optimization The blue parallelograms are actual intrusions 44 The blue parallelograms are actual intrusions The Red Green Blue Plots are response of system Associative IDS for NextGen Frameworks Dr S Dua LA Tech 44 


Advantages of Our M ethod Advantages of Our M ethod Exploit the memory v ertical data format utilizes slidin g windows to g form a much larger database to analyze  Flexibility in Choosing what to choose  Choosing what to choose to build the rules Computational and memory efficiency We have a team working only on this aspect 45 Associative IDS for NextGen Frameworks Dr S Dua LA Tech 45 


Preliminary Results Intra transaction Relations Data rate simulator NH-134 Mb HOP PATH update \(Y/N Inference 11.5 Y Y 2 0.120 N N      Y   n 0.345 N NH134 Y/N   Inf 1 0.150 N N 2 0 120 Y N Inter transaction Relations 2 0  120 Y N       5 5.55 0.456 Y Relations  n 0.345 N N Nmap on DMRL nmap.org 


Anticipated Outcome Anticipated Outcome Develop algorithm capable of learning from a given heterogeneous diverse Develop algorithm capable of learning from a given heterogeneous diverse data ff Dynamic algorithmic f ramework designed to shi f t modalities and sampling rates based on complex logic Flexibility of integration into the Snort intrusion detection system 47 Associative IDS for NextGen Frameworks Dr S Dua LA Tech 47 


References References Aircraft Cockpit Image courtesy USAF http://www.faa.gov htt p   www.faa g ov  air traffic  technolo gy  p g  _ gy  Acharya R Dua S Du X Sree V Chua C K Automated Diagnosis of Glaucoma Using Texture and Higher Order Spectra Features To appear in IEEE Transactions on Information Technology in Biomedicine  Du X Dua S 2011 Cancer Prognosis Using Support Vector Regression in Imaging  Modality World Journal of Clinical Oncology 2  1   44 49 Du X Dua S 2010 Salient Frame Extraction Using Support Vector Regression and Motion Features pp 5 Proc of the National Aerospace and Electronics Conference July 14 16 2010 D M P D S 2010 Di i i ti Ft d Cl ifi ti Mthd f D essaue r  M  P  D ua S  2010  Di scr i m i na ti ve F ea t ures an d Cl ass ifi ca ti on M e th o d s f or Accurate Classification 1st ed vol 7704 pp 14 Bellingham WA Proceedings of SPIE Dessauer M P Dua S 2010 Low Resolution Vehicle Tracking using Dense and Reduced Local Gradient Features Maps 1st ed vol 7694 pp 8 Bellingham WA Proceedings of SPIE SPIE 


Acknowledgements Acknowledgements Fundin g A g encies  US 4 1 Million direct fundin g g g 4 g LA BoR NIH NSF AFRL AFOSR and NASA Research Team Samuel Kasimalla Brandy McKnight Dr Pradeep Chowriappa Connor Johnson Vasanth Nair Mihir Chowriappa  Connor Johnson  Vasanth Nair  Mihir Karnik Mohit Jain and Swadheen Songmen Associative IDS for NextGen Frameworks Dr S Dua LA Tech 49 All the respective Logos belong to their owners 


Rf d Rdi R e f erence d R ea di ngs Copyright of cover pages held by respective publishers 


Thank You Questions Thank You  Questions Dr Sumeet Dua E mail sdua@latech.edu Web http://dmrl.latech.edu Associative IDS for NextGen Frameworks Frameworks Dr S Dua LA Tech 51 Image Source roadtrafficsigns.com 


