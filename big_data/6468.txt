An Efficient Scheme for Continuous Skyline Query Processing over Dynamic Data Set He Li Information and Communication Engineering Chungbuk National University Cheongju, 361-763, Korea lihelol@gmail.com Jaesoo Yoo Information and Communication Engineering Chungbuk National University Cheongju, 361-763, Korea yjs@chungbuk.ac.kr Abstract 227 Interests in skyline query processing have significantly increased since it can be used in many applications such as multi-criteria decision making, data mining, and user preference queries. In this paper, we propose continuous skyline 
queries over dynamic data set Since the dynamic data set constantly changes as time passes, continuous skyline queries processing over dynamic data set becomes ever more complicated compared with static data set We propose a multiple layer grids scheme for efficiently processing continuous skyline queries over skewed data set. The proposed scheme divides the work space into multiple layer grids and creates the skyline influence regions of each layer grid based on the existing data set. The continuous skyline queries are handled only when the dynamic data points update within the skyline influence regions of each layer grid Since the multiple layer grids are divided dynamically, it is 
feasible even for the highly skew ed data set. Experiments based on various synthetic data sets and real data sets show that our proposed scheme outperforms the existing schemes Keyword s 227 Skyline query, Continuous skyline query, Dynamic data set, Skewed data set I I NTRODUCTION In recent years, a skyline query as an important operator in databases for multi-preference analysis and decision making has received much attention du e to its wide application backgrounds. The skyline query has been defined as retrieving a set of points which are not dominated by any other points from a multi-dimensional data set. Given a multi-attribute dataset 
P containing objects P 1  P 2 205 P n the skyline operator returns all objects P i such that P i is not dominated by another object P j in each attribute Some existing works on the skyline query have concentrated on its efficient evalua tion in the static data set [3   7  8   1 1 13  19  23 Ho wever   i n  m o st of t h e real applications, the data set is dynamic, i.e. the data set changes constantly as time passes, such as the dynamic data set or data streams. A typical application of continuous skyline query processing over dynamic data is the online stock trading 
Traders are interested not only in the trading price of a stock but also the trading volume at a price or the others. And every trading may affect the last tradi ng price, the volume of trading and others. Since trades are con tinuing and traders may only be interested in trades with the latest information, the results can be obtained by constantly execute the skyline queries. For such cases, directly applying existing techniques would incur inconceivable large overhead Efficient continuously considered algorithms are needed Recently, several methods were proposed for continuous skyline computation on sliding window data stream 24  and moving objects [9  1 5 The  cont i nuo us s k y l i n e computation on sliding window streams assumes that the 
lifespan of the data must be pre-defined and the first-in first-out characteristics must be satisfied However, the lifespan of data set in most applications are indeterminate. The continuous skyline query \(CSQ\ method for moving objects assumes that each object has only one single dy namic attribute \(the location of the moving object\ one or more static attributes, which lacks generalization In this paper, we focus on processing continuous skyline queries over dynamic data set without any constraints. The number of the dynamic attributes of each data tuple is arbitrary All of dynamic data set is processed in a first-in first-service FIFS\ manner. Although a grid index based algorithm for 
continuous skyline computation \(GICSC 2 6 has been  proposed to handle these issues, it is not suitable for highly skewed dynamic data set. We propose a multiple layer grids scheme for efficiently processing continuous skyline queries over skewed dynamic data set. The proposed scheme employs multiple layer grids to manage the highly dynamic data set and maintains skyline influence regi on of each layer grid according to the dynamic skyline data points. For highly skewed data set the high density area of the data space can be handled by creating multiple layer grids upon the base grid layer. If data changes the skyline queries are handled only when the changed data points within skyline infl uence region of each layer grid The skyline influence region is updated according to the change of relevant data points. By doing it, the cell size of high 
density data area is assigned fine and the others is coarse. Since the skyline influence region of high density data area is precise more irrelevant data points can be filtered out. Especially, for the highly skewed dynamic data set, the advantage is very obvious The remainder of this paper is organized as follows Related work is covered in secti on 2. We present our scheme in section 3. Experiment evaluations are presented in section 4 and finally, section 5 contains our conclusions and future works 54 


II R ELATED W ORK In K u n g e t al fi rst prop osed t h e sk y l i n e a l g ori t h m   Borzsonyi et al. [3 first in tro d u ced th e sk ylin e o p eratio n in database systems and proposed two solutions based on Block Nested Loop \(BNL\nd Divide and Conquer \(D&C DC divides the data set into several partitions in memory. The skylines in each partition are co mputed separately and then merged to produce the final skyline. BNL adopts a buffer to store skyline data. Each data tuple in the database is compared with the other data and is stored in the buffer if it is not dominated. The sort-first-skyline SFS\as the variation of BNL was proposed by Chomicki et al. in It sort s t h e dat a set  according to a predefined pref erence function, and then the skyline can be computed from the sorted list. All of the methods in [3  7 are not s u i t a bl e for l a rg e or dy nam i c dat a  set since the skyline result cannot be reported until the entire data set is processed. The nearest neighbor \(NN\ algorithm  indexes the data set with R-tree. NN performs a nearest neighbor query [21 to find t h e sk ylin e results. Th e sk ylin e is evaluated by accessing the R-tree which has not to process the entire data set. In an d 2 0  an im proved al gori t h m nam e d branch and bound skyline \(BBS\proposed. BBS is also based on nearest neighbors search but it only accesses nodes that contain skyline points. Ther efore, BBS is more efficient than NN. However, the R-tree based methods are not suitable for processing dynamic data set as the update of the R-tree is high expensive Recently, some distributed a nd paralleled approaches were proposed to compute skyline over large distributed data sets. [2  and ad dr essed sky l i n e operat i ons ove r di st ri but ed we b  sources. They consider that the data set is vertically partitioned i.e. each server keeps only one attr ibute of the data set. In the subspace skyline processing over a super-peer network was studied. Different from 2 a n d  1 7   ea c h p e e r h o l d s i ts d a t a i n  an autonomous ma The subspace skylines are computed at each peer and me rged at the super peer. The global skyline is computed by gathering the skyline data from super peers. Wang et al  velope d a skyline space partitioning \(SSP\proach to compute the skyline on a treestructured P2P platform BATON Ak ri vi et al prop osed  an angle-based space partitioning scheme for efficient parallel skyline computation in [1 cu ses on h o w to p artitio n th e dataset to the distributed servers. And then, the skyline queries are executed simultaneously on all servers. In order to further improve the computation time, K\366hler et al pr op ose d  parallel skyline processing using hyperplane projections. This approach used hyperplane projections to obtain useful partitions of the data set. The partitions not only ensure small local skyline sets but enable efficient merging of results as well However, the space partitioning scheme    not suitable for processing the highly dynamic data set since the data change will result in the change of partitions. Cui et al 4 5 stu d ied sk ylin e qu eries in a distributed environment They used the Minimum Bounding Regions \(MBRs\o summarize the data stored at each server. According to the MBRs of all servers, incompar able groups are assigned. The skyline is computed within each group using sp ecific plans The methods described above did not provide the operations that reflect the data updates. None of them are suitable for skyline computation over highly dynamic datasets Several methods were proposed for continuous skyline computation on sliding window data streams and moving objects where the data set is update constantly. In  Li n et  al  proposed n-of-N skyline query processing scheme against the most recent N elements to supp ort on-line computation against sliding windows over a rapid data stream. This method indexes all data in an R-tree and uses an interval tree to determine when a point is no longer amongst the most recent N points However, it has to check every data to obtain the skyline result over a data stream which is inefficient. Tao et al. proposed maintaining the sliding window skylines on data streams in 24  T wo a l g o r i t h m s c a l l e d L a z y a n d E a g e r  w e r e  p r o p o s e d  f o r  continuously monitoring the incoming data and maintaining the skyline incrementally. This approach utilizes the properties of stream skyline to expunge the non-promising data from the system as early as possible. Since some non-promising data can be expunged before processing, this method is more efficient than n-of-N skyline. Morse et al. proposed a scalable LookOut algorithm for updating the continuous time-interval skyline efficiently over a data stream H o wever fo r sliding  window streams based continuous skyline computation methods [1 24 an d 18  t h ey assu m e that t h e dat a  m u st  have pre-defined arrival and e xpiration time, and the first-in first-out characteristics must be satisfied. In this paper, we consider that the dynamic data sets change randomly and the lifespan of each data object is indeterministic in advance Huang et al. has given a method to compute continuous skyline for moving objects in [9 It add r esses t h e pr obl em s o f  continuous skyline query processing, where the skyline query point is a moving object and the skyline changes continuously with the movement of a query point. The continuous skyline query method for moving objects assumes that each object has only one single dynamic attribute \(the location of the moving object\ one or more sta tic attributes, which lacks generalization. Li T. et al. [2 2 6 pr op o s ed t h e g r i d i n dex  based algorithm \(GICSC\r continuous skyline computation over highly dynamic datasets without any constraints. It employs a grid structure to manage the entire data set and creates a skyline influence regi on to filter out the unnecessary skyline processing over the dynamic data sets. Since the processing of the non-promising data can be expunged, this method is efficient for continuous skyline computation over the dynamic data set. However, when the dynamic data set is skewed, the cell size of the grid is difficult to be assigned. In these cases, the schemes described in [25 26  will d eg r ade the performance significantly. Ther efore, a multiple layer grids scheme for efficiently processing continuous skyline queries over dynamically skewed data set is proposed in this paper III T HE P ROPOSED C ONTINUOUS S KYLINE Q UERY P ROCESSING S CHEME A Motivations We present the processing of GICSC algorithm on the uniform data set shown in Figure 1 \(a\ The dataset is managed by a grid structure. The grid structure covers the entire data space and it is divided into equalsized cells at each dimension The skyline influence region is the cells which are not dominated by the existing skyline data points, as shown in Figure 1 \(a\the shaded region. When data points change, the 55 


skyline query is re-computed only when the changed data points within the skyline influence region. When existing data points expire, the skyline query is handled only when the data points are skyline points However, when data set is skewed, as shown in Figure 1 \(b the cell size of GICSC scheme is difficult to be assigned, which significantly impacts performance. Since a smaller cell size can decrease the number of the da ta points within each cell and reduces the total area of the skyline influence region, the performance is improved by filtering out more irrelevant data points. However, for skewed data set, a large number of additional trashy cells are genera ted. Processing these cells will cause large computation cost s and memory requirements which is inefficient. In cont rast, a bigger cell size cannot incarnate well the advantage of the grid scheme. For the large data set, a large number of data points will be contained within one cell. The high frequency change of the irrelevant data points cannot be filtered out by the skyline influence region Especially, in extreme cases, the work space has only one cell then, the GICSC scheme is similar to the BNL scheme. The BNL scheme is only suitable for static skyline queries and the data set is not large, which is certified in [25   2 6   t h e b a s i c  continuous skyline computation algorithm. Therefore, in this paper, our objective is finding a new approach which can well decide the cell size for skewed dynamic data set a\The uniform data b\The skewed data Figure 1. Two data sets for skyline query processing If the data set is composed of tuples with d-dimensions, we present to adopt a d-dimensional grid with equal-sized cells to manage the data set. Given the attributes value of an object, it is easy to find the cell that it belongs to. When the number of data points within one cell grows too large, it can be handled by creating a second layer grid. According to the data distributions, three or more layer grids can be generated Therefore, the cells for high dens ity data area of data space are fine, and the rest are coarse. Th e skyline influence regions of each layer grid are created, since the data points fall outside the skyline influence region are dominated by the existing skyline data points that cannot be skyline, we present that the skyline query is only re-computed when the dynamic data changes in the skyline influence re gion of each layer grid. As time passes the cell with low density can become high data density and vice versa. The multiple layer grids structure is variable; the multiple layer grids are revoked when the high data density area of the data space becomes low data density Figure 2 shows an example of the multiple layer grids scheme. In order to easily explain the proposed scheme, we assume that the dimension of the dataset and the layers of the grid are two in the rest of this paper. The high data density cells e.g. the dark gray cells\are ha ndled by creating an upper layer grid. The skyline influence regions of the first and second layer grid are evaluated. Th erefore, the data points within the skyline influence region of the first layer grid but outside the skyline influence region of the second layer grid can be filter out for processing Figure 2. An example of multiple layer grids B Structures and Algorithms of the Proposed Method Figure 3 shows the data structure of the proposed method that is composed of skyline list \(SL\ect list \(OL\and work space grid such as the first laye r grid and the second layer grid For a 2-dimensional data set, a tuple <OID, x, y> represents an object, where \221OID\222 is a uni que number created by a hash function; x, y represent the values of two attributes. OL stores the entire data set. SL is composed of the skyline data points among entire data. The work space grid is composed of cells the cells of the 1st layer grid\d extended cells \(the cells of the 2nd layer grid\ In terms of the data distribution three or more layer grids can be created x axis y axis C\(0,0 x axis y axis C\(0,0   x axis y axis C\(0,0 x axis y axis x axis y axis 56 


Figure 3. The data structure for the proposed method Algorithm SL_Init Input initial dataset, t Output sky line influence region Description 1. set SL=NULL; Queue 1 NULL; int n = t; // t is the threshold value 2. let C 1 x, y 1 0, 0\; C 1 x,y\  represents the cell of the left-bottom corner of the grid 3. insert C 1 0, 0 1  4 while Queue 1 NULL do 5.   remove C 1 x, y\ from Queue 1  6 if 0<the number of the data points of C 1 x, y then 7.      adopt BNL to compute skyline, update SL 8 if C 1 x, y+1\r C 1 x+1, y\ is not extended, and is not strictly dominated by the skyline data points, and \(x+1\ or y+1\ax\(x/y then 9.         insert C 1 x, y+1\r C 1 x+1, y\ into Queue 1 set C 1 x, y skyline influence region 10 else if the number of the date point of C 1 x, y then 11.       create a 2 nd layer grid base on C 1 x, y\and the 2 nd layer grid is processed in the same way as the 1 st layer grid \(line 1~12 12. end while Figure 4. The initialization pha se of the proposed method The main procedure of the proposed method is composed of the initialization phase and the maintenance phase. The initialization module is responsible for computing the skyline influence region and skyline set from the given initial static data set. The pseudo code of the initialization phase is shown in Figure 4. As shown in line 3, it starts from inserting the C 1 0,0 cell \(the cell of the left-bottom corner of the grid\to the queue 1 When the cell C 1 x,y\s popped from the queue 1 its upper cell C 1 x,y+1\ and right cell C 1 x+1,y\ppended to the tail of the queue 1 if they satisfy the extension condition as shown in line 8. The extension condition is that the cell has not been extended and is not stri ctly dominated by the existing skyline data points. The skyline influence region and skyline data are verified as the cells are processed. The skyline data within the cell C 1 x,y\s evaluated by the BNL scheme, as shown in line 7. The cell C 1 x,y\to the skyline influence region if it is not dominated by the existing skyline data. Notice that when the number of data points within C 1 x,y than the predefined threshold value t, C 1 x,y\s converted to a second layer grid, and the second layer grid is handled in the same manner as the first layer grid. The SL_Init algorithm terminates when the queue 1 becomes empty After obtaining the initial skyline set and the skyline influence regions, the skyline and skyline influence regions in the continuous case may change according to new data points arrive or existing data points e xpire. In order to save space, the algorithms for handling new data arriving and existing data expiring are omitted here IV P ERFORMANCE E VALUATION In this section, we compare GICSC scheme with our proposed method through various experiments. We conducted our experiments on a desktop PC running on Windows XP professional. The PC has a Pentium IV 3.20GHz CPU and 1GB memory. All of the experiments were coded in Java. The experimental results based on synthetic data sets and real data set are presented. The three synthetic data sets, correlated, anticorrelated and independent are ge  We  select the batting information of the hustle score of Lahman\222s baseball database from 1871 to 2009 as the real data set. In this data set, there are 92706 instances, and the information of each baseball player is dynamic after each game Figure 5. Effect of the various skewed data rates In the first experiment, we compare GICSC with the proposed method in terms of the diverse skew ratios and data size. We utilize the anti-correlated data type, where the data size is 100000 and the number of dimensions is 2. The distribution of skewed data indicates the percentage that the data distribution region occupies in the full data area. The two methods are examined in terms of execution times when the percentage varies from 65% to 10%. Figure 5 illustrates the execution times of the two methods. The skew data within full data set is varied from 10% to 100%. The results show that the execution time is increased when the number of skew data of full data set increases. The proposed method is obviously more efficient than GICSC when the whole data are distributed in less than 25% of the entire data area. For less skewed data, the difference between GICSC and our proposed method is S 1 S 2 S 3 205 S n Work Space Grid SL \(Skyline List OL \(Object List OID Data O 1 X 1 Y 1 O 2 X 2 Y 2 O 3 X 3 Y 3 205 205 O n X n Y n 2 nd Layer Grid 1 st Layer Grid 0,0                       57 


inconspicuous. To save the sp ace, without specially pointing out, we present only the performance evaluation results of the synthetic data set that is distributed in 25% of the entire data area and occupies full data set a\Synthetic data set b\Real data set Figure 6. Execution times with respect to the size of data We next compare GICSC with the proposed method in different data types, anti \(anti-correlated data set\, cor correlated data set\ndep \(inde pendent data set\ and the real data. This experiment exam ines the performance of the schemes by varying the number of synthetic data from 1K to 250K and real data from 10000 to 92706. We set the number of dimension is 2. Figure 6 \(a\ shows the results for the execution time of the skyline queries with respect to the synthetic datasets All of them achieve nearly similar performance when the number of data is 10k or less. This is because when the data size is small, the number of data within each cell is not large and the multiple layer grids are not generated. When the data size is 10k or more, the proposed method outperforms GICSC since more irrelevant data points are filtered out without computation due to the skyline influence region of multiple layer grids. The execution time of a skyline query in anticorrelated data set is higher than that of a skyline query in the independent data set and correlated data set. The reason is that the skyline influence region of the anti-correlated data set is larger than that of independent and correlated data sets. GICSC can also achieve good performan ce by adjusting its cell size to accommodate the increased data size. Howeve r, for highly skewed data set, it is not efficient since additional trash cells need to be processed. Even for the uniform data set, the cells cannot be increased with the endless data increase. Figure 6 \(b shows the result on the real data set \(the hustle score of Lahman\222s baseball database the number of data is varied And the result of the performance is similar to the synthetic data sets, the execution time is between anti and cor V C ONCLUSION In this paper, we proposed a continuous skyline query processing scheme over skewed dynamic data set. For skewed data sets, the proposed scheme divides the work space into multiple layer grids and creates the skyline influence regions of each layer grid. Under the highl y dynamic data environment the skyline query is handled onl y when the data are changed within the skyline influence region of each layer grid. The skyline influence region of each layer grid is updated when the skyline data change. Since the proposed scheme filters out more irrelevant data points without computation, it significantly improves performance. The experimental results have shown that the proposed method is more efficient than the existing method over synthetic data sets and real data set. In the future, we aim to extend our scheme for more real applications A CKNOWLEDGMENT Following are results of a st udy on the "Leades INdustryuniversity Cooperation" Project, supported by the Ministry of Education, Science & Technology \(MEST\ and the National Research Foundation of Kor ea\(NRF\ant funded by the Korea government\(MSIP\\(No.2013R1A2A2A01015710 R EFERENCES 1 V. Akrivi, D. Christos and K. Yannis, Angle-based space partition for efficient parallel skyline computation, Proc. SIGMOD, 2008, pp.227238 2 W.T. Balke, U. G\250untzer and J. X. Zh eng, Efficient distributed skylining for web information systems. Proc. EDBT, 2004, pp. 256-273 3 S. B\366rz\366nyi, D. Kossmann, and K. Stocker, The Skyline Operator, Proc ICDE, 2001, pp. 421-430 4 B. Cui, H. Lu, Q. Xu, L. Chen, Y. Dai and Y. Zhou, Parallel distributed processing of constrained skyline que ries by filtering, Proc. ICDE, 2008 pp. 546-555 5 B. Cui, L. J. Chen L. H. Xu H. Lu, G. J. Song and Q. Q. Xu, Efficient Skyline Computation in Structured Peer to Peer System, IEEE Transactions on Knowledge and Data Engineering, 2009, vol. 21. no.7 6 C.-Y. Chan, H. V. Jagadish and K. L. Tan, Finding k-dominant Skylines in High Dimensional Space, Pr oc. SIGMOD, 2006, pp. 503\226514 7 J. Chomicki, P. Godfrey, J. Gryz an d D. Liang, Skyline with presorting Proc. ICDE, 2003, pp. 717-720 8 K. Hose, Processing Skyline Queries in P2P Systems, Proc. VLDB 2005 PhD Workshop, 2005, pp. 36-40 9 Z. Y. Huang, H. Lu, B. C. Ooi and A. K. H. Tung, Continuous skyline queries for moving objects, IEEE Journal, 2006, vol. 18, no. 12, pp 1645-1658 10 H. V. Jagadish, B. C. Ooi, and Q. H. Vu, BATON: A balanced tree structure for peer to peer networks, Proc. VLDB, 2005, pp.661-672 11 B. Joao, J. Rocha, V. Akrivi, D. Ch ristos and N. Kjetil, AGiDS: A Gridbased Strategy for Distributed Skyl ine Query,  Proc. Globe, 2009, pp 12-23 12 H. K\366hler, J. Yang and X. Zhou, Efficient Parallel Skyline Processing using Hyperplane Projections, Proc. SIGMOD, 2011, pp.85-96 13 D. Kossmann, F. Ramsak and S. Ro st, Shooting Stars in the Sky: an Online Algorithm for Skyline Queries, Proc. VLDB, 2002, pp. 275-286                    58 


14 H. T. Kung, F. Luccio and F. P. Prep arata, On finding the maxima of a set of vectors, ACM Journal, 1975, vol. 22, no. 4, pp. 469-476 15 M. W. Lee and S. W. Hwang, Continuous Skyline on Volatile Moving Data, Proc. ICDE, 2009, pp. 1568-1575 16 X. M. Lin, Y. D. Yuan, W. Wang and H. J. Lu, Stabbing the Sky Efficient Skyline Computation over Sliding Windows, Proc. ICDE, 2005 pp. 502-513 17 E. Lo, K.Y. Yip, K. I. Lin, and D.W. Cheung, Progressive skyline over web-accessible databases. Data Know ledge Engineering 2006, vol. 57 no.2, pp.122-147 18 M. Morse, J. M. Patel and W. I. Grosky, Efficient Continuous Skyline Computation. Informa tion Science, 2007, vol. 177, no. 17, pp. 34113437 19 D. Papadias, Y. F. Tao, G. Fu and B. Seeger, An optimal and progressive algorithm for skyline queries, Proc. SIGMOD, 2003, pp 467-478 20 D. Papadias, Y. F. Tao, G. Fu and B. Seeger, Progressive skyline computation in database system. AC M Journal, 2005, vol. 30, no. 1, pp 41-82 21 N. Roussopoulos, S. Kelly and F. Vincent, Nearest Neighbor Queries Proc. SIGMOD, 1995, pp. 71-79 22 I. F. Su, Yu-Chi Chung, Chiang Lee and Yi-Ying Lin, Efficient skyline query processing in wireless sensor networks, Journal of Parallel and Distributed Computing, 2010, vol. 70, no. 6, pp. 680-698 23 K. L. Tan, P. K. Eng and B. C Ooi, Efficient Progressive Skyline Computation, Proc. VLDB, 2001, pp. 301-310 24 Y. F. Tao and D. Papadias, Maintia ning sliding window skylines on data streams, TKDE, 2006, vol. 18, no. 3, pp. 377-391 25 L. Tian, L. Wang, P. Zou, Y. Jia and A. Li, Continuous Monitoring of Skyline Query over Highly Dynamic Moving Objects, Proc. MobiDE\22207 2007, pp. 59-66 26 L. Tian, P. Zou, A. Li and Y. Jia, Grid Index Based Algorithm for Continuous Skyline Computation, Chinese Journal of Computers, 2008 vol. 6, no. 6, pp. 998-1012 27 A. Vlachou, C. Doulkeridis, Y. Kotidis, and M. Vazirgiannis SKYPEER: Efficient subspace skyline computation over distributed data Proc. ICDE, 2007, pp.416-425 28 S. Wang, Q.H. Vu, B.C. Ooi, A.K.H. Tung and L. Xu, Skyframe: A framework for skyline query processing in peer-to-peer systems,VLDB Journal, 2009, vol. 18, pp. 345-362  59 


important component of the discussed B DLM and must also be done in a secure and trustworthy way  V  B IG D ATA I NFRASTRUCTURE BDI  Figure 4 provide s a general view on the Big Data infrastructure that includes the general infrastructure for general data management, typically cloud based, and Big Data Analytics part that will require high performance computing clusters  which in their own turn will req uire high performance low latency network    General BDI services and components include  000x  Big Data Management tools  000x  Registries, indexing/search, semantics, namespaces  000x  Security infrastructure \(access control, policy enforcement confidentiality, trust, availa bility, privacy  000x  Collaborative environment \(groups management     Figure 4   General Big Data Infrastructure functional components   We define Federated Access and Delivery Infrastructure FADI as an important component of the general BDI that interconnects different components of the cloud/Intercloud based infrastructure combining dedicated network connectivity provisioning and federated access control [19, 37   A  B ig Data Analytics Infrastructure  Besides the general c loud base infrastructure services storage compute infrastructure/VM management  the following specific applications and services will be required to support Big Data and other  data centric applications  23, 24, 38  wh ich we will commonly refer to as Big Data Analytics Infrastructure \(BDAI  000x  Cluster services  000x  Hadoop related services and tools  000x  Specialist data analytics tools logs events data mining etc  000x  Databases/Servers SQL, NoSQL  000x  MPP \(Massively Parallel Processing  databases     Figure 5   Big Data Analytics Infrastructure components   Big Data analytics tools are currently offered by the major cloud services providers such as: Amazon Elastic MapReduce and Dynamo 39   Mi c r o s o f t  A zu r e H DI n s ig h t   4 0    IBM Big Data Analytics  41   Sc ala b l e  Had o o p  an d  d a ta  an aly tics  to o ls  service s are offered by few companies that position themselves as Big Data companies such as Cloudera, [42  an d  f ew  o th er s  43   VI  C LOUD B AS ED I NFRASTRUCTURE S ERVICES FOR B DI  Figure 6  illustrates the typical e Science or enterprise collaborative infrastructure that  is created on demand and includes enterprise proprietary and cloud based computing and storage resources, instruments, control and monitoring system visualization system, and users represented by user clients and typically residing in real or virtual cam puses   The main goal of the enterprise or scientific infrastructure is to support the enterprise or scientific workflow and operational procedures related to processes monitoring and data processing Cloud technologies simplify the building of such infras tructure and provision it on demand. Figure 6 illustrates how an example enterprise or scientific workflow can be mapped to cloud based services and later on deployed and operated as an instant inter cloud infrastructure It contains cloud infrastructure s egments IaaS VR3 VR5 and PaaS VR6 VR7 separate virtualised resources or services \(VR1, VR2\, two interacting campuses A and B, and interconnecting them network infrastructure that in many cases may need to use dedicated network links for guaranteed p erformance   Efficient operation of such infrastructure will require both overall infrastructure management and individual services and infrastructure segments to interact between themselves This task is typically out of scope of the existing cloud service  provider models but will be required to support perceived benefits of the future e SDI. These topics are a subject of another research we did on the InterCloud Architecture Framework [19 37    110 


  Figure 6 From scientific workflow to cloud based infrastructure  VII  R ELATED WORK  There are not many academic papers related to the definition of the Big Data Architecture or its components Due to the specifics of this paper that intends to explore a new emerging technology domain   we have widely researched  both currently existing publications related to the Big Data technology and research papers and best practices documents from other domains that could contribute to the definition of the proposed Big Data Architecture Framework. A  number of publications  standards, and industry best practices have been  mentioned and cited in this paper. Here we just mention these works that we consider as a foundation for our work The authors actively contribute to the NIST Big Data Working Group that provide s  a good forum for discussion but have plans to produce initial set of the draft document s  only by the end of September 2013 The following publications contribute to the research on the Big Data Architecture  NIST Cloud Computing Reference Architecture CC RA 18   B ig  Data  E co s y s te m  A r ch itect u r e definition by Microsoft [20   B ig  Data  tech n o lo g y  a n al y s is  b y  G.Mazzaferro [21     We also refer to other related architecture definitions Information as a Service  by Open Data Center Alliance [22   TMF Big Data A nalytics Architecture 23   IBM Business Analytics and Optimisation  Reference Architecture 24   LexisNexis HPCC Systems [25   VIII  F UTURE R ESEARCH AND D EVELOPMENT  The future research and development will include further Big Data definition initially presented in this paper  At this stage we attempt ed to summarise and re think some widely used definition s  related to Big Data, further research will require more formal approach and taxonomy of the general Big Data use cases in different Big Data origin and target domains also analyzing different stakeholder groups    The authors will extend their research into defining the Big Data Security Framework with the specific focus on data centric security that should allow secure data storage transfer and processing in di stributed data storage and processing infrastructure   The authors  are  also looking into defining data structures for high performance streaming applications and developing new types of disk based stream oriented data bases, continuing the work started fro m the authors work on CakeDB  database  4 4    The authors will continue contributing to the NIST Big Data WG targeting both goal s  to propose own approach and to validate it against the industry standardisation process   Another target research direction is d efining a Common Body of Knowledge \(CBK\ in Big Data to provide a basis for a consistent curriculum development. This work and related to the Big Data metadata procedures and protocols definition is planned to be contributed to the Research Data Alliance RDA   4 5     The authors believe that the presented paper will contribute  toward the definition of the Big Data Architecture Framework and provide a basis for wider discussion to define a new research and technology domain   en-GB A CKNOWLEDGEMENTS  This work is supported by the FP7 EU funded project s  GN3plus and EUBrazil Cloud Connect The authors also express acknowledgement to the members of the Big Data Interest Group at the University of Amsterdam for contribution to the discussion on Big Data Ar chitecture framework and provided valuable advices regarding use cases, suggested technology use and basic operational models  R EFERENCES  1  Global Research Data Infrastructures: Towards a 10 year vision for global research data infrastructures Final Roadm ap March 2012  O nline  Available  http://www.grdi2020.eu/Repository/FileScaricati/6bdc07fb b21d 4b90 81d4 d909fdb96b87.pdf  2  Riding the wave: How Europe can gain from the rising tide of scientific data Final report of the High Level Expert Group on Scientific Data October 2010   O nline   Available at http://cordis.europa.eu/fp7/ict/e infrastructure/docs/hlg sdi report.pdf  3  Y.Demchenko  P Membrey, P  Grosso, C   de Laat 000 Addressing Big Data Issues in Scientific Data Infrastructure  000  in First International Symposium on Big Data and Data Analytics in Collaboration \(BDDAC 2013 Part of The 2013 Int  Conf   on Collaboration Technologies and Systems CTS 2013 May 20 24, 2013, San Diego, California, USA  4  NIST Big Data Working Group NBD WG   O nline  Available  http://bigdatawg.nist.gov/home.php  5  Definting Big Data Architetcure Framework Outcome of the Brainstorming Session at the University of Amsterdam 17 July 2013 Present ed  at  NBD WG 24 July 2013  O nline  Available  http://bigdatawg.nist.gov/_uploadfiles/M0055_v1_7 606723276.pdf  6  Reflections on Big Data Data Science and Related Subjects Blog by Irving Wladawsky Berger  online  Available http://blog.irvingwb.com blog/2013/01/reflections on big data data science and related subjects.html  7  E Dumbill, What is big data? An introduction to the big data landscape  O nline  Available  http://strata.oreilly.com/2012/01/what is big data.html  8  The Big Data Long Tail  Blog post by Jason Bloomberg   Jan uary  17, 2013  O nline  Available  http://www.devx.com/blog/the big data lon g tail.html  111 


9  J  Gantz and David Reinsel   Extracting Value from Chaos  IDC IVIEW June 2011   O nline  Available  http://www.emc.com/collateral/analyst reports/idc extracting value from chaos ar.pdf  10  The Fourth Paradigm Data Intensive Scientific Discovery Edite d by Tony Hey Stewart Tansley and Kristin Tolle  Microsoft Corporation October 2009 ISBN 978 0 9825442 0 4  O nline  Available  http://research.microsoft.com/en us/collaboration/fourthparadigm  11  Big Data defintion Gartner Inc  O nline  Available  http://www.gartner.com/it glossary/big data  12  S.Sicular 000 Gartner's Big Data Definition Consists of Three Parts, Not to Be Confused with Three "V"s 000  Gartner, Inc. 27 March 2013   O nline  Available  http://www.forbes.com/sites/gartnergroup/2013/03/27 gartners big data definition consists of three parts not to be confused with three vs  13  J Layton  000 The Top of the Big Data Stack: Database Applications 000  July 27 2012  O nline  Available  http://www.enterprisestorageforum.com/storage management/the top of the big data stack database applications.html  14  Explore big data analytics and Hadoop  O nline  Available  http://www.ibm.com/developerworks/training/kp/os kp hadoop  15  A Bloom 7 Myths on Big Data Avoiding Bad Hadoop and Cloud Analytics Decisions April 22 2013  O nline  Available  htt p://blogs.vmware.com/vfabric/2013/04/myths about running hadoop in a virtualized environment.html  16  European Union. A Study on Authentication and Authorisation Platforms For Scientific Resources in Europe Brussels  European Commission 2012. Final Report Contributing author. Internal identification SMART Nr 2011/0056  O nline  Available  Available at http://cordis.europa.eu/fp7/ict/e infrastructure/docs/aaa study final report.pdf  17  Y Demchenko  P.Membrey C.Ngo C de Laat D.Gordijenko  Big Security for Big Data: A ddressing Security Challenges for the Big Data Infrastructure Proc  0006\000H\000F\000X\000U\000H\000\003\000'\000D\000W\000D\000\003\0000\000D\000Q\000D\000J\000H\000P\000H\000Q\000W\000\003\000\013\0006\000'\0000\000¶\000\024\000\026\000\014\000\003\000:\000R\000U\000N\000V\000K\000R\000S\000\021\000\003\0003\000D\000U\000W\000\003 of VLDB2013 conference, 26 30 August 213, Trento, Italy  18  NIST SP 500 292 Cloud Computing Reference Architecture v1.0  O nline  Available  http://colla borate.nist.gov/twiki cloud computing/pub/CloudComputing/ReferenceArchitectureTaxonomy/NIS T_SP_500 292_ _090611.pdf  19  Y Demchenko  M Makkes R.Strijkers C.Ngo C de Laat Intercloud Architecture Framework for Heterogeneous Multi Provider Cloud based Inf rastructure Services Provisioning, The International Journal of Next Generation Computing \(IJNGC\, Volume 4, Issue 2, July 2013  20  NIST Big Data Reference Architecture  NBD WG NIST   O nline  Available  http://bigdatawg.nist.gov/_uploadfiles/M0226_v10_1554566513.docx  21  NIST Big Data T echnology Roadmap  NBD WG  O nline  Available  http://bigdatawg.nist.gov/_uploadfiles/M0087_v8_1456721868.docx  22  Open Data Center Alliance Master Usage model Information as a Service Rev 1.0  O nline  Available  http://www.opendatacenteralliance.org/docs  Information_as_a_S ervice_Master_Usage_Model_Rev1.0.pdf  23  TR202 Big Data Analytics Reference Model  TMF Document Version 1.9, April 2013  24  IBM GBS Business Analytics and Optimisation 2011 IBM  2013   O nline  Available  https://www.ibm.com/developerworks  mydeveloperworks  files/basic/anonymous/api/library 48d92427 47d3 4e75 b54c b6acfbd608c0/document/aa78f77c 0d57 4f41 a923 50e5c6374b6d/media&ei=yrknUbjMNM_liwKQhoCQBQ&usg=AFQjC NF_Xu6aifcAhlF4266xXNhKfKaTLw&sig2=j8JiFV_md5DnzfQl0spVr g&bvm=bv.42768644,d.cGE  25  A.M Middleton  HPCC Systems Introduction to HPCC High Performance  Computer Cluster LexisNexis Risk Solutions LexiNexis  May 24, 2011  26  Bierauge M Keeping Up With Big Data American Library Association  2013   O nline  Available  http://www.ala.org/acrl/publications/keeping_up_with/big_data  27  Unstructured Data Mana gement Hitachi Data System  2013  online  http://www.hds.com/solutions/it strategies/unstructured data management.html  28  NIST Big Data WG discussion  O nline  Available  http://bigdatawg.nist.gov/home.php  29  D.Koopa, et al 000 A Provenance Based Infrastructure to Support the Life Cycle of  Executable Papers 000  in International Conference on Computational Science  ICCS 2011   O nline  Available  http://vgc.poly.edu/~juliana/pub/vistrails executable paper.pdf  30  Open Access: Opportunities and Challenges. European Commission for UNESCO  O nline  Available  http://ec.europa.eu/research/science society/document_library/pdf_06/open access handbook_en.pdf  31  OpenAIR 000  Open Access Infrastructure for Research in Europe  O nline  Available  http://www.openaire.eu  32  Open Researcher and Contributor ID online  h t t p    a b o u t  o r c i d  o rg  33  Roundup of Big Data Pundits' Predictions for 2013. Blog post by David Pittman January 18 2013   O nline  Available http://www.ibmbigdatahub.com/blog/roundup big data pundits predictions 2013  34  The Forrester Wave: Big Data Predictive Analytics Solutions, Q1 2013 Mike Gualtieri January 13 2013  O nline  Available  http://www.forrester.com/pimages/rws/reprints/document/85601/oid/1 LTEQDI  35  Big data: The next frontier for innovation, competition, and producti vity May 2011 McKinsey Global Institute  O nline  Available  http://www.mckinsey.com/insights/business_technology/big_data_the_n ext_frontier_for_innovation  36  Data Lifecycle Models and Concepts  O nline  Available  http://wgiss.ceos.org/dsig/whitepapers/Data%20Lifecycle%20Models 2 0and%20Concepts%20v8.docx  37  M Makkes  C  Ngo Y  Demchenko R  Strijkers R  Meijer C   de Laat 000 Defining Intercloud Federation Framework for Multi provider Cloud Services Integration 000  in The Fourth International Conference on Cloud Computing GRIDs and Virtua lization CLOUD COMPUTING 2013  May 27  June 1, 2013,Valencia, Spain  38  M Turk   A chart of the big data ecosystem take 2 online  http://mattturck.com/2012/10/15/a chart of the big data ecosystem take 2  39  Amazon Big Data  O nline Available   http://aws.amazon com/big data  40  Microsoft Azure Big Data Microsoft   2013  O nline  Available  http://www.windowsazure.com/en us/home/scenarios/big data  41  IBM Big Data Analytics  IBM 2 o 13   O nline  Available  http://www 01.ibm.com/software/data/infosphere/bigdata analytics.html  42  Cloudera Impala Big Data Platform   O nline  Available  http://www.cloudera.com/content/cloudera/en/home.html  43  10 hot big data startups to watch in 2013  10 January 2013  O nline  Available  http://beautifuldata.net/2013/01/10 hot big data startups to watch in 2013  44  P Membrey K  C.C. Chan, Y  Demchenko, A Disk B ased Stream Oriented Approach For Storing Big Data I n First International Symposium on Big Data and Data Analytics in Collaboration \(BDDAC 2013 Part of The 2013 International Conference on Collaboration Technologies and Systems \(CTS 2013\, May 20 24, 2013  San Diego, California, USA  45  Research Data Alliance  RDA  O nline  Available  http://rd alliance.org   112 


Size of Largeincrease The reasons are twofold Firstly when increases according to the node selection scheme to construct decrease There are two reasons Firstly when the memory size increases the stop condition for graph contraction is easier to be satis\336ed since more nodes can 336t in memory Secondly when the memory size increases the costs of the external sorts in both graph contraction and graph expansion phases decrease  Average Degree Number of Largeincreases the time and I/O consumptions for both increases the number of iterations in graph contraction increases This is because when number of edges increases the cost to sort and scan edges in each iteration increases thus more time and I/Os are consumed in each iteration                                     2 4 1 u E  V v E    u v  G  V E M V M V K G V V M KB Range 25M,50M,100M,150M,200M 2,3,4,5,6 200M,300M,400M,500M,600M 400K 8K 20,30,40,50,60 30,40,50,60,70 10K to in the operator in line 4 both in line 4 and augmented in all nodes in in line 5-7 VIII P ERFORMANCE S TUDIES In this section we conduct experimental studies by comparing four external algorithms for is the number of bytes to keep a node in memory We set the max time cost to be 24 hours If a test does not stop in the time limit we will denote it using until all nodes form an to Size of Small The results are shown in Fig 7\(a and Fig 7\(b for time and I/O costs respectively When the memory size increases the time and I/O costs for both 100M 400M 40 1 1 50 TABLE I R ANGE AND D EFAULT V ALUE FOR P ARAMETERS Parameter in all cases since more nodes/edges are removed in each iteration in Operator  operator speci\336es a unique total order among all nodes in the graph operator in line 9 when generating algorithm needs to hold and and and and and used in introduced in 26  w h i ch is cu r r e n tly th e m o s t I O ef 336cien t sem i e x t er n a l algorithm for and  Secondly when and out out out out out out out Fig.6\(a and Fig 6\(b show the time and I/O costs when varying the number of edges of WEBSPAM-UK2007 from 20 to 100 respectively v G v G v G v G v G v G v G v G v G v G v G v G v G v G 002 212 327 327  002 002 327 327 327 327 327       2 cannot stop in the time limit even if the graph contains only 20 of the edges When Size of 8 our e x t e rnal cont ract i on-e xpans i o n b as ed algorithm Algorithm 2 and our algorithm by applying the optimization techniques introduced in Section VII in new edges are added into In Algorithm 3 in order to make use of the new s The graphs contain nodes from 25M to 200M with average degree varying from 2 to 6 A synthetic graph is generated as follows We construct a graph computation namely the external contraction based 13 t he e x t e rnal DFS based by randomly selecting all nodes in SCC SCC SCC SCC SCC SCC  we apply the algorithm computation The  Finally additional random nodes and edges are added to the graph The parameters for synthetic datasets and their default values are shown in Table VIII outperforms 1PB 1PB since it cannot stop in all cases Memory Size need to be computed in Ext Ext Ext Ext EM Ext EM Ext Ext Ext Ext Ext Ext Ext Ext    3  002  For the semi-external algorithm  In our experiments we use a real large web graph and several synthetic datasets The real web graph is WEBSPAM-UK2007 4  which consists of 105,896,555 web4 barcelona.research.yahoo.net/webspam/datasets/uk2007/links   4H   8H   12H   16H   20H   24H   INF   20   40   60   80   100   Time\(hour Ext-SCC-Op   Ext-SCC                           DFS-SCC                 Largein in in in in in in 2 plus one disk block in the main memory that is Size of MassiveNumber of Massive\(a Time Vary Memory   1M   2M   3M   4M   5M   6M   7M   8M   INF   400M   600M   800M   1G   Number of I/Os Ext-SCC-Op   Ext-SCC                       DFS-SCC               iff one of the following three conditions holds 1 b I/Os Vary Memory Fig 7 WEBSPAM-UK2007 Varying Memory Size pages in 114,529 hosts in the UK domain The graph contains 105,895,908 nodes and 3,738,733,568 edges with the average degree 35 per node For synthetic data we generate 3 different kinds of datasets denoted Massive.The 4K,6K,8K,10K,12K 6K,8K,10K,12K,14K u w u G u G u G u G u G u G u G  For any  containing different sizes of and Small 327     V i i i i i d d d i i De\036nition 7.1 DFS Op Op Op Op Op Op 217 before adding  The default memory size is  In our experiments we do not show the results of  thus more iterations are needed according to the stop condition of graph contraction in 327 Semi add Datasets Exp-1 Performance on WEBSPAM-UK2007 in Algorithm 3 more nodes will be selected in id id 200K,300K,400K,500K,600K as follows DFS SCC SCC SCC SCC SCC SCC SCC SCC SCC SCC SCC SCC SCC SCC SCC SCC SCC SCC SCC SCC SCC SCC SCC SCC SCC SCC SCC SCC SCC  By considering  All the algorithms are implemented using Visual C 2005 and tested on a PC with Intel Core2 Quar 2.66GHz CPU and 3.5GB memory running Windows XP The disk block size is  according to Theorem 5.3 nodes with small degrees are removed when constructing 256 400   256 400 Default INF 327 deg deg deg deg deg deg deg deg deg deg deg deg deg deg deg deg deg deg deg deg deg  4 w V V E V G V G   u  v V G G E E E E G where can be further reduced We rede\336ne the operator Number of SmallD M s s s i i i i i i i 1 1 1 1 1 1 u>v 4  Secondly using operator  and for each removed node  s 336rst Then we add edges among the nodes in an  We vary the memory size from                     a Time Vary Graph Size   1M   2M   3M   4M   5M   6M   7M   8M   INF   20   40   60   80   100   Number of I/Os Ext-SCC-Op   Ext-SCC                           DFS-SCC                 b I/Os Vary Graph Size Fig 6 WEBSPAM-UK2007 Varying Graph Size Percent   4H   8H   12H   16H   20H   24H   INF   400M   600M   800M   1G   Time\(hour Ext-SCC-Op   Ext-SCC                       DFS-SCC               


SCC SCC SCC SCC SCC SCC SCC SCC SCC SCC SCC increases the time and I/O costs for both dataset dataset The results for both Largedatasets are similar to those in the Massive When either the average   800 105 895 908 8  256  847 200 600 25 200 50 12 30 70 f I/Os SmallTo test the synthetic data we vary the memory size M   K  M M M M M M M M M M D D D D K s s s of nodes from 2 to 6 The time and I/O costs on Largedo not have signi\336cant impact on the ef\336ciency of our algorithms as long as by 20 on average for both time and I/O consumptions Fig 8\(c and Fig 8\(d show the results on Large 1 1 4  the costs for both d I/Os Vary Degree   c Time Vary Degree   25 327         Size and G M G M V V V V V V V K E G Wevary the node size decrease sharply The reason is that in order to process the graph using in all test cases to to is smaller the decrease rate is larger This is because when is smaller more iterations are needed for both to  and the time and I/O costs are shown in Fig 9\(a and Fig 9\(b respectively When to to respectively Fig 9\(g and Fig 9\(h show the time and I/O costs when varying the number of 4   s and and and and and and and and Wevary the average degree Size   Size   Time\(hour Number of I/Os Time\(hour Number of I/Os Time\(hour Number of I/Os Time\(hour Number of I/Os Time\(hour Number of I/Os Time\(hour Number of I/Os Time\(hour Number of I/Os 2H   3H   4H   5H   INF   200M   300M   400M   500M   600M   Ext-SCC-Op   Ext-SCC                           DFS-SCC                 200K   400K   600K   800K   1M   1.2M   INF   200M   300M   400M   500M   600M   Ext-SCC-Op   Ext-SCC                           DFS-SCC                 1H   2H   3H   4H   5H   INF   200M   300M   400M   500M   600M   Ext-SCC-Op   Ext-SCC                           DFS-SCC                 200K   400K   600K   800K   1M   1.2M   INF   200M   300M   400M   500M   600M   Ext-SCC-Op   Ext-SCC                           DFS-SCC                 1H   2H   3H   4H   5H   INF   200M   300M   400M   500M   600M   Ext-SCC-Op   Ext-SCC                           DFS-SCC                 200K   400K   600K   800K   1M   1.2M   INF   200M   300M   400M   500M   600M   Ext-SCC-Op   Ext-SCC                           DFS-SCC                 8H   12H   16H   20H   INF   25M   50M   100M   150M   200M   Ext-SCC-Op   Ext-SCC                           DFS-SCC                 1M   2M   3M   4M   5M   INF   25M   50M   100M   150M   200M   Ext-SCC-Op   Ext-SCC                           DFS-SCC                 2H   4H   6H   8H   10H   INF   2   3   4   5   6   Ext-SCC-Op   Ext-SCC                           DFS-SCC                 400K   600K   800K   1M   1.2M   INF   2   3   4   5   6   Ext-SCC-Op   Ext-SCC                           DFS-SCC                 2H   3H   4H   5H   INF   4K   6K   8K   10K   12K   Ext-SCC-Op   Ext-SCC                           DFS-SCC                 400K   600K   800K   1M   INF   4K   6K   8K   10K   12K   Ext-SCC-Op   Ext-SCC                           DFS-SCC                 2H   3H   4H   5H   INF   30   40   50   60   70   Ext-SCC-Op   Ext-SCC                           DFS-SCC                 400K   600K   800K   1M   INF   30   40   50   60   70   Ext-SCC-Op   Ext-SCC                           DFS-SCC                 e Time Small,andwhen increase This is because when n in Synthetic Data in Synthetic Data DFS DFS DFS Exp-5 Vary Op Op Op Op Op Op Op Op Op Op Op Op Ext  The time and I/O costs on Massiveare shown in Fig 9\(c and Fig 9\(d respectively When decrease When f I/Os Vary Ext Ext Ext Ext Ext Ext Ext Ext Ext Ext Ext Ext Ext Ext Ext Ext Ext Ext Ext Ext Ext Ext Ext Ext  V  V Number in Synthetic Data c Time Large\(a Time Vary e Time Vary cannot stop in limited time in all cases Similar to the results on the real dataset in Fig 7 when dataset and Fig 8\(e and Fig 8\(f show the results on Smallconsume less than 1 hour increases the time and I/O consumptions for both consumes more than 20 hours while both are the number of nodes and the number of edges of the graph As a result the size of memory is needed thus when the memory size is dataset are shown in Fig 8\(a and Fig 8\(b respectively dataset and this is true for all the remaining test cases when varying other parameters in synthetic data In the following due to the lack of space we only show the test results on the Large and in the graph contraction phase the contraction rate decreases when the number of iterations increases since the graph becomes denser with larger number of iterations is larger and the cost on each iteration to scan and   Exp-4 Vary Average Degree in Synthetic Data from from increases the time and I/O consumptions for both and the number of outperforms outperforms cannot stop within the time limit when outperforms in all cases When the memory increases from increases the time and I/O costs for both When a Time Massive\(b I/Os Massiveis larger is larger the gap between is larger This is because when number of edges is larger more edges can be pruned by the edge reduction techniques used in increases the number of edges increases As a result more iterations are needed and larger cost is consumed in each iteration as analyzed in Exp-1 when varying the graph size size increases or the number of are not in\337uenced much As anal yzed in Section VII the key factors that in\337uence the cost of Num   Num Fig 9 Synthetic Data Largecan be directly applied on the original graph to output all                       Fig 8 Synthetic Data Vary Memory Size outperforms  and Smallincrease This is because the stop condition for graph contraction is harder to be satis\336ed when  sort nodes/edges is larger when   Fig 9\(e and Fig 9\(f show the time and I/O costs when varying the average no iteration is needed and size from SCC SCC SCC SCC SCC SCC SCC SCC SCC SCC SCC SCC SCC SCC SCC SCC SCC SCC SCC SCC SCC SCC SCC SCC SCC SCC SCC SCC SCC SCC SCC SCC SCC SCC SCC SCC SCC SCC SCC SCC SCC SCC SCC SCC SCC SCC SCC 1H   4H   200K   1H   200K   1H   200K   sfrom b I/Os Vary g Time Vary h I/Os Vary        218 d I/Os LargeSemi Semi Exp-2 Vary Memory Size Exp-3 Vary Node Size   


are 336xed This also explains why the results in the three datasets Massiveis a primitive operation in directed graph exploration which has been studied for both internal memory model and external memory model In the internal memory model strongly connected components of a directed graph can be computed in s for a directed graph with the assumption that the nodes of the graph cannot reside entirely in memory We overcome the de\336ciencies of the existing external    sort sort computation algorithms and propose a new two-phase algorithm with graph contraction followed by graph expansion We analyze the I/O cost of our approach and show that our algorithm can signi\336cantly reduce the number of random I/Os We propose techniques to further reduce the I/O cost of our algorithm and con\336rm the I/O ef\336ciency of our approaches using extensive experiments on both real and synthetic web scale graphs The work was supported by grant of the Research Grants Council of the Hong Kong SAR China No 418512 R EFERENCES  J  A bello A  L  Buchs baum  a nd J  W e s t brook A f unctional a pproach to external graph algorithms s of a graph Zhang et al 26 i mpro v e s uch a n a l gori t h m by constructing and maintaining a special in-memory spanning tree of the graph The semi-external algorithms 23 an d  2 6  are introduced in details in Section III Other than the problem of 336nding time based on DFS 12  A naive way to externalize the internal DFS algorithm requires s Such an algorithm may end up an in\336nite loop and cannot compute all  33\(2 2001  H  Y ildir im  V  C haoji and M  J  Z aki Grail Scalable reachability index for large graphs s repeatedly until the graph 336ts in memory then an internal memory algorithm is used to 336nd the 336nal sor DFS tree on external directed graphs several problems in the external memory model are studied in the literature Dementiev et al 14 p ro vi de an i m pl ement a t i o n o f a n e xt ernal m emory minimum spanning tree algorithm based on the ideas of 22 which performs extremely well in practice even though theoretically inferior to the algorithms of 1   1 0   A jw an i e t al 4 6  propos e i mpl e ment at i ons of e x t e rnal undi rect ed breadth-\336rst search algorithm with the idea from 18 Ul rich Meyer et al 20 21  19  des i gn and i mpl e ment pract i c al I/O-ef\336cient single source shortest paths algorithm on general undirected sparse graphs Surveys about designing I/O ef\336cient algorithms for massive graphs can be found at 24 5  X C ONCLUSIONS In this paper we study I/O ef\336cient algorithms to 336nd all  3\(1 2010  J  Hellings  G  H  F letcher  and H  H averkort Ef\336cient external-memory bisimulation on dags In  3\(1 2010  Z  Z h ang J  X Y u  L  Q in L  C hang a nd X L i n I/O e f 336 cient Computing sccs in massive graphs In scan by maintaining the list of nodes that should not be traversed using tournament trees 17 and b uf fered repos i t o ry t rees 8  respectively Despite their theoretical guarantees these algorithms are considered impractic al for general directed graphs that encountered in real applications Cosgaya-Lozano and Zeh 13 p res e nt a c ont ract i o n b as ed al gori t h m w hi ch cont ract s V M E B V B 2 are similar as stated in Exp-2 IX R ELATED W ORK Finding strongly connected components of a directed graph V G V G E G E V E E V E  14\(1 1985  T  H  Cor m en C  S tein R  L  R i v es t and C  E  L eis e r s on  2003  U Me yer a nd N Z e h I/O-ef 336c ient undirected shortest paths with unbounded edge lengths In s Both DFS based algorithm 8 and c ont ract i o n b as ed algorithm 13 a re i n t roduced i n det a i l s i n S e ct i o n III In addition to external algorithms there are semi-external algorithms for ACM Comput Surv Introduction to Algorithms IFIP TCS         Proc of ESA\22202 Proc of ESA\22206 SIAM J Comput Commun ACM Proc of SIGMOD\22213  32\(3 2002 2 A  A ggar w a l a nd J  S  V itter  T h e i nput/output com p le xity of s o r ting and related problems  31\(9 1988  A  V  A ho J  E  Hopcroft a nd J  D Ullm an I/Os Chiang et al 10 propos e a n a l gori t h m with I/O complexity  Addison-Wesley 1983 4 D  A jw ani R D e m e ntie v  and U  M e y er  A com putational s tudy of external-memory bfs algorithms In  2006  D  A jw ani a nd U Me yer   6\(1 2011  A  L  Buchs baum  M  H  G oldw a sser S Venkatasubramanian and J Westbrook On external memory graph traversal In  2002  J  S  V itter  E x ter n al m e m o r y algor ithm s and d ata s tr uctur e s   2007 7 E  A ngel R Cam p igotto a nd C L a f o r e s t  A nalys i s a nd com p ar is on of three algorithms for the vertex cover problem on large graphs with low memory capacities  1995  N  Chiba a nd T  N i s h izeki A r bor icity and s ubgr aph lis ting algor ithm s   2009  R Dem e ntie v  P  Sanders  D  S chultes  and J  F  S ibe y n E ngineering an external memory minimum spanning tree algorithm In  2012  V  K u m a r a nd E  J  Schw abe Im pro v e d a lgorithm s and d ata s tructures for solving graph problems in external memory In  2002  U  M e yer a nd V  O s ipo v  D es ign a nd im plem entation o f a pr actical i/o-ef\336cient shortest paths algorithm In  2009  U Me yer a nd N Z e h I/O-ef 336c ient undirected shortest paths In  2006  J  F  S i be yn E x ter n al connected com p onents  I n  2013 A CKNOWLEDGMENT  Algorithmic Operations Research          267        and computation which assume that all nodes of the graph can 336t in the main memory Sibeyn et al 23 propose a semi-external DFS  which can be used to 336nd all og  pages 457\320468 2012  Y  J  C hiang M T  Goodrich E  F  Gro v e  R  T am as s i a D E  V e ngrof f and J S Vitter External-memory graph algorithms In  Proc of ALENEX\22207 Proc of SIGMOD\22212 Proc of SODA\22295 Proc of SEA\22209 PVLDB Proc of ALENEX\22209 Proc of ESA\22203 PVLDB                    McGraw-Hill 2001  A  Cos g ayaL o zano a nd N  Z e h A h eur i s tic s t r o ng connecti vity algorithm for large graphs In Algorithmica LargeProc of SPAA\22202 G O O O O Algorithmics of Large and Complex Networks Data Structures and Algorithms SCC SCC SCC SCC SCC SCC SCC SCC SCC SCC SCC  Later Kumar and Schwabe 17 a nd B u chs b aum e t a l  8  i mprove the I/O complexity to  chapter 1 Design and Engineering of External Memory Traversal Algorithms for General Graphs Springer 2009  D  A jw ani U Me yer  and V  O s i po v  Im pro v e d e xternal m em ory b fs implementation In  2000  J  Cheng Y  K e  S  Chu and C Cheng E f 336 cient p roces s i ng of distance queries in large graphs a vertex cover approach In  2004  W  F a n J  L i  S  M a H W a ng and Y  W u Graph hom om orphis m revisited for graph matching  1996  K Mehlhorn a nd U Me yer  E xtern al-memory breadth-\336rst search with sublinear i/o In  2004  J  F  Sibe yn J  Abello a nd U Me ye r Heuristics for semi-external depth 336rst search on directed graphs In Proc of SWAT\22204  and SmallProc of SODA\22206 Proc of SODA\22200 219 Proc of SPDP\22296 Proc of SIGMOD\22212 


                  


             


 





 17  Jar r e n  A   B al d w i n  is  a  Ch i c a g o  n a t i v e  a n d  c u r r e n t l y  se r v e s a s t h e  l e a d  E l e c t r i c a l  En g i n e e r  a t  B a y  A r e a  s t a r t u p   Oc u l e v e  I n c   He  g r a d u a t e d  fr o m  t h e  U n i v e r s i t y  o f Il l i n o i s  wi t h  a  B  S   i n  2 0 0 9  an d  r ecei v ed  an  M  S   i n  El e c t r i c a l  En g i n e e r i n g  f r  St a n f o r d  U n i v e r s i t y  i n  2 0 1 2   Ja r r e n  d e v e l o p e d  h a r d w a r e  a n d  so f t w a r e  sy st e m s f o r  a  w i d e  ra n g e  o f  f i e l d s   i n c l u d i n g  s p a c e  s c i e n c e  s y s t e m s  a n d  m e d i c a l  de vi c e s  a s  a N A S A  A m es  i nt e r n i n t he  In t e l l i g e n t  S y s t e m s     1  2  3   4   5   6   7   8   9   10   11   12   13   


                        


                           


   












































     2 8    b 4      1 8             1 2     1  8 2  


1 9    8      2 1       1     2    8    2 3\f        


     8 D 4 9  F  \b 1 8 #J 9 1     2 1   2 #-@ 1   2 9  E 1   1   2 9      6  


    8  8   1  D 1         1 F  \b0         2 D    F  \b 1 8  9  


  1 9  1   E 1  2 9     1 1 F  \b       1    18   F   1    1 #-$+  \b  2 2  


1 D     1 #-$+.B- 0/:% .0             9 1      18    1 6     1 2  1  1  


1   6      2    1 2 E 8 D 1      1 2   1   1 #-4  #-@E     2  1  1  1       


 8     1          2 F    6   F  2   8    2 C<CC/C N\bO 5      


CD    b$44NO F P Q 6   2 b$$$ ,=\b\bA  A N,O 2 C C  b$$4N  92 2   f  9-\b$$4 B N?O  !-    91  2 1 HH111-18-N+O    -1 :3%   2     0-4 


     b N4O 2   2- \f  C b$@$ \b# >\b\b$3\b$N@O  f :.% 9 /9 \f    1  6  f 2  4   A254 


Advantages of Our M ethod Advantages of Our M ethod Exploit the memory v ertical data format utilizes slidin g windows to g form a much larger database to analyze  Flexibility in Choosing what to choose  Choosing what to choose to build the rules Computational and memory efficiency We have a team working only on this aspect 45 Associative IDS for NextGen Frameworks Dr S Dua LA Tech 45 


Preliminary Results Intra transaction Relations Data rate simulator NH-134 Mb HOP PATH update \(Y/N Inference 11.5 Y Y 2 0.120 N N      Y   n 0.345 N NH134 Y/N   Inf 1 0.150 N N 2 0 120 Y N Inter transaction Relations 2 0  120 Y N       5 5.55 0.456 Y Relations  n 0.345 N N Nmap on DMRL nmap.org 


Anticipated Outcome Anticipated Outcome Develop algorithm capable of learning from a given heterogeneous diverse Develop algorithm capable of learning from a given heterogeneous diverse data ff Dynamic algorithmic f ramework designed to shi f t modalities and sampling rates based on complex logic Flexibility of integration into the Snort intrusion detection system 47 Associative IDS for NextGen Frameworks Dr S Dua LA Tech 47 


References References Aircraft Cockpit Image courtesy USAF http://www.faa.gov htt p   www.faa g ov  air traffic  technolo gy  p g  _ gy  Acharya R Dua S Du X Sree V Chua C K Automated Diagnosis of Glaucoma Using Texture and Higher Order Spectra Features To appear in IEEE Transactions on Information Technology in Biomedicine  Du X Dua S 2011 Cancer Prognosis Using Support Vector Regression in Imaging  Modality World Journal of Clinical Oncology 2  1   44 49 Du X Dua S 2010 Salient Frame Extraction Using Support Vector Regression and Motion Features pp 5 Proc of the National Aerospace and Electronics Conference July 14 16 2010 D M P D S 2010 Di i i ti Ft d Cl ifi ti Mthd f D essaue r  M  P  D ua S  2010  Di scr i m i na ti ve F ea t ures an d Cl ass ifi ca ti on M e th o d s f or Accurate Classification 1st ed vol 7704 pp 14 Bellingham WA Proceedings of SPIE Dessauer M P Dua S 2010 Low Resolution Vehicle Tracking using Dense and Reduced Local Gradient Features Maps 1st ed vol 7694 pp 8 Bellingham WA Proceedings of SPIE SPIE 


Acknowledgements Acknowledgements Fundin g A g encies  US 4 1 Million direct fundin g g g 4 g LA BoR NIH NSF AFRL AFOSR and NASA Research Team Samuel Kasimalla Brandy McKnight Dr Pradeep Chowriappa Connor Johnson Vasanth Nair Mihir Chowriappa  Connor Johnson  Vasanth Nair  Mihir Karnik Mohit Jain and Swadheen Songmen Associative IDS for NextGen Frameworks Dr S Dua LA Tech 49 All the respective Logos belong to their owners 


Rf d Rdi R e f erence d R ea di ngs Copyright of cover pages held by respective publishers 


Thank You Questions Thank You  Questions Dr Sumeet Dua E mail sdua@latech.edu Web http://dmrl.latech.edu Associative IDS for NextGen Frameworks Frameworks Dr S Dua LA Tech 51 Image Source roadtrafficsigns.com 


