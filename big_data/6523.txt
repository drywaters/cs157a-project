Towards Knowledge Discovery from WWW Log Data Feng Tao                               Fionn Murtagh tao.feng@qub.ac.uk                     f.murtagh@qub.ac.uk School of Computer Science Queen\222s University of Belfast Belfast,  BT7 1NN Northern Ireland, UK Abstract As the result of interactions between visitors and a web site, an http log file contains very rich knowledge about users on-site behaviors, which, if fully exploited, can better 
customer services and site performance. Different to most of the existing log analysis tools which use statistical counting summaries on pages, hosts, etc., we propose a transaction model to represent users access history and a framework to adapt data mining techniques such as sequence and association rule mining to these transactions In this framework, all transactions are extracted from the raw log file though a series of step by step data preparation phases. We discuss different methods to identify a user, and separate long convoluted sequences into semantically meaningful sessions and transactions. A 
new feature called interestingness is defined to model user interests in different web sections. With all the transactions being imported into an adapted cube structure with a concept hierarchy attached to each dimension of it, it is possible to carry out multi-dimensional data mining at multi-abstract levels. Using interest context rules, we demonstrate the potentially significant meaning of this system prototype 1.  Introduction While the Internet has been growing to be an important part of peoples\222 lives, there are more and more data recorded of users online activities. These data can contain 
valuable information on a user\222s behavior, which, if fully used, can guide the resource maintenance, provide personalized services and  support target marketing in ebusiness In this paper, we propose a solution to extract knowledge from the HTTP web log which implies  large quantities of information on user behavior recorded while using the services in  the  web site. Web log is a web server mechanism that records each single request coming from the visitors for the services in the server. Each entry in the log file has three important fields: the IP address from which the request originated, the description of the 
request and a time stamp indicating when this occurs. A popular web site can see its web log growing by hundreds of megabytes every day. Pioneering researchers have done quite good work on investigating the web log data to improve system design, understand the nature of web traffic, and discover user preferences [8,16,19   Ev en more novel ideas have been proposed to design autoadaptive sites [1 an d im prov e p r ox y  cach e ef f i cien c y 6] based on learning visitors\222 access patterns from the web log file. On the application side, there are more than 
20 commercial web log analysis tools available in the internet such as ilux Edge  Mark etw a v e  12] an d WebTrends [2   B u t m o st o f the m r e ve a l o n ly fr e q ue nc y counts at predefined primitive conceptual levels without a systematic underlying data model. The most common reports of these tools are the following: a summary report of the hits over a certain period of time, top n files visited most frequently, hits per domain report, etc. One can easily notice that they only show the statistical results of the raw data recorded in the log file and after that human 
intervention is still needed to generalize user access behavior at high and abstract concept levels Besides, the performance of these tools declines quickly when the size of the dataset increases. The recent progress in data warehouse research has made available powerful data warehousing systems with OLAP \(OnLine Analytical Processing\ility [9,17 W e  c o nstruct a data cube as the intermediate layer between the knowledge discovery modules and the underlying relational database This layer is designed to meet the OLAP \(OnLine Analytical Processing\ standard. This data model enables 
the data mining task to be carried out in a more straightforward manner from various points of view at different aggregation concept levels. We then study how to populate and aggregate data into this data structure as well as that metadata which seeks to embody time relationships of the items so that sequences can be manipulated easily. Based on this data model, we study how to  manipulate the cube to apply sequence mining algorithms on it efficiently 


As already noted, many current analysis tools try to describe the user\222s behavior in a specific web site by a list of hit counts. We believe that the knowledge representing user behavior goes far beyond frequent access to some page di d qu ite g o o d w o rk in th is direction while our contributions are the following: the idea of using a transaction model to represent visitors traces in web log data; the proposal to use interest context rules to represent inter-relationship among different sections of the web site according to user interest; the definition of interestingness as a measurement of the rules and method for its computation in the data preparation phases The rest of this paper is organized as follows: Section 2 proposes the framework that enables the new concept of knowledge discovery on web log data. A breakdown of the data flow is also described there with an emphasis on data preparation phases; Section 3 presents a transaction model to present the user\222s visited sessions. Due to the space limitation, we are not going to describe the cube structure for OLAP in this paper and refer the readers to an extend version of this paper. Then we present the experimental results with semantic explanation before coming to the conclusion and outlook 2. Architecture and Data Flow A web server access log contains a complete history of file accesses by clients. Most WWW access logs follow the Common Log Format specified as part of the HTTP protocol by CERN and NCSA  A  l o g  en t r y  according to that definition, has the structure shown in Figure 2.1. Figure 2.2 is a portion of HTTP log data The primary objective of this log mining is to apply generic data mining techniques to transaction data in order to discover interesting patterns in user accesses to various sections within a specific web site The architecture of the system which we propose, as shown in Figure 2.3, is roughly comprised of four components: the data cleaning/preparation module that extracts relevant information from the raw log data by filtering,  translating, field encoding, measurement selecting and calculating. All of these results are then interpreted by a transaction model to generate different transactions and sessions of the site browsing trace with some measurements integrated in. With all the necessary data collected in the first phase and stored in a database we start the data aggregation phase adapting OLAP technology [14 in ord e r to ad just the d a ta t o the d e sire d level where data mining algorithms can be applied later on. In this module, a series of  concept hierarchy trees is  Client  visitor\222s domain name or IP address that can be resolved to domain name A uth  username if registered Timestamp Date and time of the access R equest request method, document path and name, parameters, etc Status status code indicating the result of a request User agent client side browser type Cookie Crookie ID R eferrer previews link address Figure 2.1  HTTP Server\222s Log Structure optional fields atz.cube.net 01/Jun/1999:00:01:29 +02 G E T  g a r c h in ginfo/computing/weatherdir/europe_meteo.jpg HTTP/1.0" 200 55540 eu.ansp.br 01/Jun/1999:00:01:55 G E T  g a r c h in ginfo/computing/weather.html HTTP/1.0" 304 177 200.247.224.105 01/Jun/1999:00:02:04 +02 G E T  HTTP/1.0" 200 5953 200.247.224.105 01/Jun/1999:00:02:09 +02 G E T  icons/redball.gif HTTP/1.0" 200 398 eu.ansp.br 01/Jun/1999:00:02:14 G E T  icons/blueball.gif HTTP/1.0" 304 436 200.247.224.105 01/Jun/1999:00:02:09 +02 G E T  icons/redball.gif HTTP/1.0" 200 398 Fi g ure 2.2   A fraction of  sam p le lo g data Feature Control  User Interface Knowled g e Visualization Interest Context rule finder Frequent Paths finder Other mining modules\205 Concept hierarchy on location, web section, etc Database Log Data Data Cleaning Data Cube Transactional Feature Extraction Figure 2.3   System Architecture 


designed  and a cube structure is defined to store transaction data with a hierarchy tree attached to each of the cube dimensions if applicable. The data handling component comprises data mining approaches such as interest context rule mining, sequence pattern discovery etc. The last component is the interface part, which can be described as feature control and knowledge visualization. The former takes care of the finer mining parameters inside the rest of the data processing modules which can be controlled via a query mechanism. The latter presents the discovered knowledge in an efficient and straightforward manner 2.1 Data Cleaning As we have seen in Figure 2.2, web access information is stored in a flat file which is not immediately interpretable. Many entries are considered as irrelevant to our final goal, thus being removed at this step. This filtering is application dependent, but usually those accesses to image icon files are filtered out since most of them are triggered automatically on loading an HTML page, and it is the latter which, on the whole, constitutes the important factor describing user traversal patterns and their context interest within the web site. Data cleaning is performed by checking the extension of the URL name For instance, all the log entries with filename extension such as GIF, JPEG, JPG and map are removed from further processes. One exception is an art gallery site where images are the main concern. In that case, we can configure the filter parameters in the feature selecting interface module as shown in Figure 2.3 2.2 Transactional Model and Data Unfortunately, unlike the classical \223basket\224 data mining solutions [1 h ere transactio n is d e f i ned as a list o f itemsets, there is no natural definition of a user transaction in the site navigation scenario where the HTTP server\222s multi-thread and multi-user features make user navigational traces nest together. At one extreme, we can consider each log entry to be a separate transaction while on the other hand we can define a time window to crop a transaction to be a series of adjacent accesses from the same host. Therefore, a semantic transaction model must be defined with extra effort. In the following section, we define this model along with the concept of sessions and discuss how to form transactions from the log entries Definition 2.1 Let e 316 E, E is the set of all log entries after data cleaning and e is a log entry object with direct attributes such as host, document, timestamp etc, and derived features such as dwell time, interestingness and session ID, etc. \(for example, e.interestingness interestingness 316 D.\e denote all these attributes as D and the Domain of D as Dom\(D A transactio i ned in the f o llo w i ng m o d e l E[n  E  n s  275 E[n  o s t  E[n  h os t A N D E[n 1 es ta m p E[n s tim es ta m p  W D T, 1 243 s 243 E[n   where n is the transaction ID number, s is the session ID number within a specific transaction D T is the time interval configured in the window object W, which will be defined in Definition 2.2. The following illustrates these transaction and session concepts. We can notice that all the log data have been transformed to transactions and sessions, the session is an object with various encapsulated measurements contributing to the user\222s overall behavior Definition 2.2 A window W in a transaction set E is a mechanism to categorize sessions into different transactions according to its integrated attribute windowsize D T, which can be adjusted to simulate the time-span of the browsing transaction semantic. We set it as 30 minutes in our case Definition 2.3 Session s = E[n i is th e ith el em en t i n  a specific transaction E[n  w h ere 1 243 i 243 E[n s is an object encapsulating all the attributes and features  that are possibly derived from either a single log entry or the context entries within a single transaction. Figure 2.5 shows a list of features for a session object. We denote these features as D 316 Dom\(D Since the research work on association mining [2, 3  an d sequence mining m o st su bsequ e n t research es h a v e been taking it for granted that the transaction is only a set of literals called items which do not have any attributes themselves. Therefore the association rule mining 205 \205            \205 \205                  \205 \205 E E E[k E j   1 E j   E  j 3 E[k  E[k 2 E[k   3    E[i 2 E  i][3 E  i][4   Transaction s Sessions Fi g ure 2.4 Transactions and Sessions 


algorithms applied to this transaction model were constrained to the counting of the item occurrences and finding dominant  inter and intra co-occurrence relationships among the items set.  In our research, we improved that model to be a multi-feature session model that makes it possible to carry out more detailed intra association rule mining, i.e., the encapsulated features inside the items are also involved. For instance, using this model with interestingness integrated as a feature of the items, we can discover the hidden interest context rules within the site It can be noticed from Figure 2.4 and Figure 2.5 that the transaction-session model is somewhat like a matrix with features integrated for each of the matrix elements. This is extremely useful when traversing  the transactionsession structure to collect the data and to feed the mining algorithms By applying this model to the log data, we can easily transform it to a transaction set, upon which data mining algorithms can be applied to discover interest context rules, etc.  Next, we give the definition of interestingness and the method to compute it 3. Feature selection There are lots of mining targets in the web log data that have been exploited by recent research in this area. The web page accessed, the domain name resolved from the host IP address, all of these, after being aggregated, can produce significant patterns indicating the user\222s distribution and the web sections of interest based on hit count and the frequency  Besides these, however, some more useful yet hidden measurements can be obtained  by analyzing the visiting context and combining other attributes. We studied the patterns of Internet surfers and found that a user usually spends longer time gazing at an interesting page than they do on those less interesting pages.  Noticing that the dwell time is also dependent on the information volume and the network speed in different areas, we firstly calculate the relative dwell time within a single transaction to exclude the factor of different network speed. We then divide this relative dwell time by the size of the page and thus get a new measurement termed relative interestingness to pinpoint the user preference issue in web log data mining more effectively. We call this interestingness for brevity. After grouping the log entries according to the host IP and timestamp, the following equation is applied to compute the interestingness for each of the log entries E[Transaction_ID  S e s s i on _ID   in a transaction E[Transaction_ID  E[k i  316 E[k  E[k][i].dt =E[k][i+1].timestamp \226 E[k][i].timestamp 1 243 i 243  E Session_ID   where E[k  i  is the i th session within a single transaction E[k and the dt is the  dwell time of the session, one of the features or attributes of E[k  i  that can be obtained by calculating the time interval between two adjacent accesses from the same host But before that, however, we need to store this transaction data in a data structure such that flexible mining can be carried out on various features, as well as at different abstraction levels. In the following sections we introduce the approach to this issue 4. A Multi-Dimensional Data Structure In order to accommodate the multi-feature transactional data transformed from the log data, a web log data cube is proposed here for further retrieval and mining activities The generic cube model was proposed in [9 i m prov ed from the multidimensional database [14,1 t o sup p o r t  the increasingly popular On-Line Analytical Processing OLAP\ standard. Our system uses a customized  cube structure to meet the requirement of flexible mining on different features and abstract levels of the transaction data. Due to the space limit, we omit this section and refer interested readers to the extended version of this paper[21  size i k E n dt j k E dt i k E gness Interestin i k E n j             1 345   Figure 2.5 Features in a session V isit ID Transaction v isit ID Session Its sequence number in a transaction Action Derived from the document name Time Time stam p Function of relative dwell time and volume of the content Feature D Descri p tion Interesting ness 


5. Mining approaches and the experiments Up to this point, we have successfully reorganized the web access data to a state where it is convenient to apply classic data mining algorithms. Two mining approaches can be made on these transaction data, one is the adjusted association rule mining  emphasizing the interrelationship of the interested pages. We call the results interest context rules revealing interest-related sections in the site from a visitor\222s point of view; the other approach tends to discover the frequent sequence patterns of the user\222s browsing traces 5.1 Finding interest context rule Let T be a set of transactions and X,Y be the visitor\222s focuses which are the objects encapsulating web sections and its average interestingness \(ai\ to visitors, e.g., X is a set of [X.section, X.ai  X.secti o n  Y.secti o n 314 Dom\(Features.section\ are non-empty subsets of web sections, count\(X\is the number of times that the transaction includes X.  A context rule is an expression of the form where Max\(X.timestamp\\(Y.timestamp the support of the rule s=count\(X.section 310 Y.section\T the confidence of the rule c count\(X.section 307 Y.section\unt\(X.section\  The task of discovering a context rule is to find all rules whose s and c are higher than their respective thresholds. We get a three dimensional cube denoted as  C \(TRANSACTION SESSION, SECTION, interestingness\, and by integrating with a step of computing the relative interestingness and the average value of them, the algorithm described  in [1 can be easily adapte d t o search for the interest context  rules in this web scenario Given a sample web log file of a commercial site and a time window of size 30 minutes, we list part of the interest context rule found with relatively high confidence These results improve results of other tools that provide only statistical summary about the access log. They are also different to classical association rules in that the latter do not have any ordering and any interestingness measurements which involve the item attribute into the process of knowledge discovery. Among these interest context rules, we can find interesting knowledge about the interaction between the site and its visitors. For example, the third interest context rule indicates that 65 of the visitors who browsed the on-sale news section and product1 section with relatively high interest also visited the product3 section later with average interest of 0.02 and this context rule applied in 3% of all the transactions This rule revealed some hidden flaws in the site topology which shows that although visitors are interested in the on-sale news and the content of the product1, they have little interest in the product3 section. However they were cheated or forced into the product3 area by the links. This finding results in the decision to adjust the links among these sections and improve the  relevance of the sections and effectiveness of the links. It also provides a perspective solution of dynamic organized web site based on user-interest-oriented web page clustering 6.  Summary and Future Work In this paper, we have presented a framework for data mining and knowledge discovery on the HTTP server\222s log data. The aim of the research is to find a solution to model the log data and discover user navigation behavior in a specific web site. The knowledge is potentially useful to  e-business and the efficient maintenance of the web site based on the preference of the visitors.  To implement this, we designed  a flexible log mining architecture and discussed the data flow from data preparation, transaction modeling, multi-dimensional storing structure with concept hierarchy  to the mining approaches. According to the interaction between site visitors and the web log mechanism, we proposed a novel transaction model to interpret user access records as transactions and sessions based on the time window threshold and the users identification. Various features have been extracted from the log data including the modeling of visitor\222s interests in specific web sections as a relative interestingness feature. We then proposed the idea to integrate the interestingness feature with the sequence association rule finding algorithm to discover the interest context rules in the web site navigation scenario Although we have proposed several new ideas in the direction of knowledge discovery in web site log data,  it is not enough to use only the web log data especially in Figure 5.1  Sample Result of interest context Rules 0.22      0.17    59  0 11  0 news 276 276 276\256 276 24 roduct2/,0 products/p   0.23   product1 products  0.27    product 80  0 0.04 276 276 276\256 276 ml/,0.02  roduct3.ht products/p   0.23  html product1 products   Sale/,0.17 news/on 65  0 0.03 276 276 276\256 276 0.39 employment company   0.33  history  company  s/,0.21 product 76  0 0.01 276 276 276\256 276  


the more and more complicated  WWW community. For example, for an internet based supermarket, it will be more efficient to combine the user registration information and the ordering information with the log data. We plan to study how to integrate more heterogeneous data sources into the current framework The other direction is to develop more generic models to cope with transactions of other application data such as bank transactions and DNA sequence data in biochemical areas Reference   A g ra w a l A  Gu pta, an d S. Sara w a g i Modeling Multi-dimensional  Databases. In Proc. of the 13 th Int\222l Conference on Data Engineerin g, Birmingham,     UK April 1997   A g ra w a l, T  Im ieli n s k i an d A  S w a m i.  Mi n i n g Association Rules Between Sets of  Items in Large Databases. In Proc. 1993 ACM-SIGMOD Int. Conf Management of Data page 207-216, Washington, D.C May 1993   A g ra w a l an d R  S r i k a n t. F a s t  Alg o rit h m s  f o r Mining Association Rules. In Proc. 1994 Int. Conf. Very Large Data Bases page 487-499, Santiago, Chile September 1994   A g ra w a l an d R  Sri k a n t.  Min i ng Sequ e n tial Patterns. In Proc. 1995 Int. Conf. Data  Engineering pages 3-14, Taipei, Taiwan, March 1995 5]    A. G.B\374chner,  M. D. Mulvenna. Discovering Internet Marketing Intelligence though Online Analytical Web Usage Mining SIGMOD Record 27\(4 page 54-61 1998 6  Co hen and H. Kap l an E x p l o itin g Re g u laritie s in Web Traffic Patterns for Cache Replacement 31th STOC  1999   C ooley B. Mobas h er an d J  Sriv as tav a Data Preparation for Mining World Wide Web Browsing Patterns Journal of Knowledge and Information Systems  Vol. 1, No. 1, 1999   Fu ller an d J  de Graaf f  Measu r ing U s er Motiv atio n from Server Log Files. In http://www.microsoft.com/usability/webconf/fuller/fuller.ht m 1997  J  Gray A  Bos w orth  A  La y m a n an d H. P i rah e s h  Data cube: A Relational Aggregation Operator Generalizing Group-by, Cross-tabs and Sub-totals. In Proc of the 12 th Int\222l Conference on Data Engineering page 152-159,1996  u x Edg e Eb u s i n e s s com p a n y  http://www.ilux.com/products/ent/index.html 1999   L u ot on e n T h e com m o n l o g fi l e f o r m at  http://www.w3.org/pub/WWW 1997  rk etw a v e C o rporat i o n  http://www.marketwave.com/hitlist/newreports/complete.ht m 1998 13  M J  Z a k i Ef f i cien t En um eration of Frequ e n t Sequences 7th International Conference on Information and Knowledge Management Washington DC November 1998  T h e OL A P C oun ci l  MDA PI a n d OLA P  A ppl i cat i o n Program Interface Version 0.5 Specification, September 1996   P e rk o w itz a n d O. Etzion i.  A d apti v e s ite Automatically Learning from User Accesses Patterns. In Proc. 6 th Int. World Wide Web Conf., Santa California  April 1997  T. Su lliv a n R eadi n g  R eader R eaction   A P r opos al f o r Inferential Analysis of Web Server Log Files. In Proc. 3rd Conf. Human Factors & the Web Denver, Colorado, June 1997   S a raw a gi R   A g ra w a l  N. Me g i ddo. Di s c ov er y driven Exploration of OLAP Data Cubes Proc. of the Sixth Int'l Conference on Extending Database Technology  Valencia, Spain, March 1998   Silv ers t ein  S. Brin R  Mot w a n i: Be y o n d Mark e t Baskets: Generalizing Association Rules to Dependence Rules Data Mining and Knowledge Discovery 2\(1 page 39-68. 1998  L  T a u s ch er an d S. Green berg Ho w P e ople R e v i sit Web Pages: Empirical Findings and Implications For the Design of History Systems International Journal of Human Computer Studies, Special issue on World Wide Web Usability, 47 Page 97-138, 1997  Web T ren d s C o rporat i o n http://www.webtrends.com/SampleReports/Cluster_03_b.ht ml 1999  F e n g T  F i on n M. T o w o ards K n o w l e dg e Di s c o v er y from WWW  Log Data, Extended version http://www.qub.ac.uk/~F.Tao/research/extended.ps 


old as in Section 6.2 and increasing confidence thresholds For example, the WWW database was mined with confi dence thresholds of 0.06 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 and 0.9 using a 0.06 support threshold in all cases The results of the application of this preprocessing tech nique on the association rules outputted by these ten min ing processes of the WWW database are summarized in the upper left hand histogram of Figure 2 Each gray bar indi cates the number of rules mined using a specific confidence threshold For example, the first leftmost gray bar in the WWW histogram depicts the 9,206 association rules that were mined with 0.06 confidence level The black bar su perimposed on it indicates the number of rules deleted as a result of the application of this preprocessing technique on the respective list of rules, 3,793 in this case That is over 41 of the rules mined by from the WWW database us ing 0.06 support and confidence thresholds were deleted by Interestingness Preprocessing technique 1. This deletion is very significant considering that no information of any sort was required to perform it. This Interestingness Preprocess ing technique performed even better on the output of mining the WWW database using increasingly higher confidence levels deleting as much as 65 of the rules mined with 0.9 confidence levels, as indicated by the rightmost bar in the WWW database histogram out of the 1,503 rules mined the rightmost gray bar\977 rules \(the superimposed black bar\rules were deleted The other five histograms in Fig ure 2 summarize the results of applying the first Interesting ness PreProcessing technique to the other five databases The average deletion brought about by the application of the first Interestingness PreProcessing technique are 49.3 f 7.9 for the WWW database, 55.2 f 9.8% for the Mushroom database 69.4 If 18.0 for the Nursery database 57.7 f 7.3% for the Chess database, 72.6 f 8.6 for the Adult database and 3.7 f 1.5 for the Gro cery database These results are extremely encouraging a significant number in most cases an average of over half the rules outputted by the mining algorithm are deleted by the application of this preprocessing technique This is a significant result not only because of the large number of rules that is deleted but also because this deletion requires no information of any kind from a user of the KDD process 6.3.2 The results of the application of the Interestingness PrePro cessing 2 technique \(Section 5.2 to the six databases were more modest than those of the application of the first tech nique Even these modest results are very significant a re duction even of a small percentage of the rules is both ef fective and important when these results are achieved au tomatically without any interaction with any users The average elimination brought about by the second prepro Results Interestingness Preprocessing Tech 2 Figure 3 Results of the application of Inter estingness Preprocessing 2 technique cessing technique was as follows 3.3 f 3.4 for the WWW database 17.4 f 5 for the Mushroom database 2.5 f 2.7 for the Nursery database 3.1 f 1.8 for the Chess database 1 f 1.9% for the Adult database We present the detailed results in a graphical representation in Figure 3 for the first two databases 6.3.3 Results Sequential Application of Interesting ness Preprocessing Techniques As depicted in Figure 1, the Interestingness PreProcessing techniques can and should be applied sequentially We pro ceeded to do so applying the two preprocessing techniques we introduced in this paper sequentially The results of this sequential application are depicted in Figure 4 7 Conclusions and Future Work In this work we defined an Interestingness Preprocessing Step, as part of the interestingness analysis framework, that eliminates association rules that can be determined to be not interesting in a user-, domain-, and task-independent man ner The generic nature of the preprocessing differentiates it from the interestingness processing that do impose a bias on the type of rules outputted as interesting In this work we also introduced the first Interestingness PreProcessing techniques The deletion of un-interesting rules by these techniques is very significant since it is achieved without requiring a user to provide any informa tion Our empirical results indicate that these are powerful techniques in most cases more than half the rules were eliminated by their application It is important to note that any filtering power however weak of any preprocessing technique is significant since all the Preprocessing methods are deployed sequentially immediately following the min ing process on any set of mined rules and these results add up We hope that this work will encourage the development of more preprocessing techniques by the KDD community 495 


Figure 4 Results of sequential application of Interestingness Preprocessing Our future work includes the development of other In We are also working on the incorporation of the preprocessing methods into the mining process and of running them in parallel terestingness Preprocessing methodologies References I G Adomavicius and A Tuzhilin Discovery of actionable patterns in databases The action hierarchy approach In SIGKDD pages 11 1-1 14, 1997 2 C C Agganval and P S Yu A new approach to online generation of association rules Technical Report Research Report RC 20899 IBM T J Watson Research Center 1998 3 R. Agrawal H Mannila R Srikant H Toivonen, and A I Verkamo Advances in Knowledge Discovery and Data Min ing chapter 12 Fast Discovery of Association Rules pages 4 R J Bayardo Jr., R. Agrawal, and G D Constraint-based rule mining in large, dense databases In ICDE pages 188 197, 1999 repository of machine learning databases 6 S Brin R Motwani and C Silverstein Beyond market baskets generalizing association rules to correlations In SIGMOD pages 265-276 1997  U M Fayyad G Piatetsky-Shapiro and P Smyth Ad vances in Knowledge Discovery and Data Mining chapter 1 307-328 1996  C Blake E Keogh and C Merz UCI http:l/www.ics.uci.edu/~mlearn/rnlrepository.html From Data Mining to Knowledge Discovery An Overview pages 1-34 1996 8 A A Freitas A multi-criteria approach for the evaluation of rule interestingness In ICDM pages 7-20 1998 9 R Hilderman and H Hamilton Evaluation of interest ingness measures for ranking discovered knowledge In PAKDD pages 247-259,2001 lo M Klemettinen H Mannila P Ronkainen H Toivonen and A I Verkam Finding interesting rules from large sets of discovered association rules In CIKM pages 401-407 1994 1 I W Klosgen Advances in Knowledge Discovery and Data Mining chapter 10 Explora a Multipattern and Multistrat egy Discovery Assistant pages 249-271 1996 12 B Liu W Hsu and S Chen Using general impressions to analyze discovered classification rules In SIGKDD pages 13 B Liu W Hsu and Y M Pruning and summarizing the discovered associations In SIGKDD pages 125-134 1999 14 B Liu M Hu and W Hsu Multi-level organization and summariztion of the discovered rules In SIGKDD pages 15 C J Matheus G Piatetsky-Shapiro and D McNeill Ad vances in Knowledge Discovery and Data Mining chapter 20 Selecting and Reporting What Is Interesting pages 495 515 1996 I61 B Padmanabhan and A Tuzhilin Small is beautiful Discovering the mimimal set of unexpected patterns In SIGKDD pages 54-63,2000  171 G Piatetsky-Shapiro and B. Masand Estimating campaign benefits and modeling lift In SIGKDD pages 185-193 1999  181 F Provost and D Jensen Evaluating knowledge discovery and data mining In Tutorial 77 SIGKDD 1998 19 S Sahar Interestingness via what is not interesting In SIGKDD pages 332-336 1999 20 S Sahar and Y Mansour An empirical evaluation of objec tive interestingness criteria In SPIE Con on Data Mining and Knowledge Discovery pages 63-74 1999 213 D Shah L V S Lakshmanan K Ramamritham, and S Su darshan Interestingness and pruning of mined patterns In SIGMOD Workshop DMKD 1999 22 A Silberschatz and A Tuzhilin. What makes patterns inter esting in knowledge discovery systems IEEE Trans Knowl edge Discovery and Data Engineering 8\(6 1996 23 M Spiliopoulou and J F Roddick Higher order mining Modelling and mining the results of knowledge discovery In Con on Data Mining Methods and Databases 2000  R Srikant Q Vu and R. Agrawal. Mining association rules with item constraints In SIGKDD pages 67-73 1997  R Subramonian Defining diff as a data mining primitive In SIGKDD pages 334-338 1998 26 H Toivonen M Klemettinen P Ronkainen K Hatonen and H Mannila Pruning and grouping discovered associa tion rules In MLnet Familiarization Workshop on Statistics Machine Learning and KDD pages 47-52 1995 27 A Tuzhilin and A Silberschatz A belief-driven discovery framework based on data monitoring and triggering Tech nical Report IS-96-26 Stern School of Business New York University, 1996 31-36 1997 208-2 17,2000 496 


 9 For instance, while in the “ISS Rendezvous Mode”, the function of actuating docking mechanisms might be disabled, and the firing of RCS thruster enabled. However in the “ISS Dock Mode”, the firing of RCS thrusters is inhibited, while docking actuation is available. On the left side of Figure 8 are the mode s from which entrance to the state is allowed.  Note that si nce there is more than one state from which you can enter the ISS Operations State”, the entrance modes called out may not all be in the same state Similarly, the exit modes on the right hand side of the diagram lead to modes in different states The spacecraft states and tran sition activities were then modeled as operational flows in CORE as shown in Figure 9 \(next page\e operational activities and their logical sequence are consistent with the Spacecraft State Transition Diagram shown above in Figure 7.  The operational model also identified the operational elements, which are tied to the physical hardware elements of the system that perform the operational activities Figure 8 Spacecraft Operational Modes  ISS Rendezvous Mode ISS Proximity Operations Mode ISS Dock Mode State Entrance State Exit S/C ISS Operations State From: Orbit Maneuver Mode To: Orbit Maneuver Mode From: ISS Checkout Mode To: ISS Checkout Mode ISS Undock Mode ISS Safe Haven Mode ISS Emergency Departure Mode From: S/C Powered Up Mode To: S/C Powered Up Mode 


 10 Figure 9 Spacecraft Operational Flow Functional Models After addressing the operational activities that the OSP system needed to perform, the functional models of the OSP system were developed consistent with the system engineering process discussed above.  The first step was to identify the physical hardware elements of the OSP system as prescribed by NASA.  The physical hardware elements of the OSP system were captured in CORE through component decomposition and represented as the product breakdown structure shown in Figure 10  Figure 10 Product Breakdown Structure of OSP System The OSP system functional models were developed by identifying the system functions based on the mission goals and operations that the system needed to perform.  These functions were then allocated to the prescribed physical hardware elements of the sy stem. As requirements and the system architecture evolved, the system functionality was re-allocated to different physi cal hardware elements.  In addition, the functional models also captured the physical interfaces between the OSP system, both internally and externally Interface Definition The CORE database also modeled and captured the interface complexity th at existed for the OSP system.  In the database a functional interface was represented as a collection of links that existed between physical hardware elements and an operational interface was represented as a collection of need-lines that existed between operational elements.  The links/need-lines were further defined by either  performance indices or constraints Internal and external functi onal interfaces were modeled within the CORE database by looking at different layers of the system physical hierarchy For example the interfaces between the OSP system and external systems were modeled as shown below in Figure 11, which depicts the interfaces that exist between the ISS Mating Adapter and ISS.  Internal functional inte rfaces were also modeled by looking at the interfaces that ex ist within the OSP System's physical product breakdown structure.  For example, Figure 12 shows the internal interfaces that exist w ithin the OSP System between the  ISS Mating Adapter \(ISSMA Spacecraft.   For clarity, th ese figures only include the single directional links from the ISS Mating Adapter to ISS and from the ISS Mating Ad apter to the Spacecraft respectively  kill kill continue to Earth Return continue to ISS Operations continue to On-Orbit Operations 0.5 continue to ISS Attached Operations 0.5 OSP.OA.1.1.1 Spacecraft Prelaunch Ground Processing OSP.OA.1.1.2 Operate S/C Integrated to Launch Vehicle OSP.OA.1.1.3 Operate Spacecraft Un-Crewed On-Pad AND OSP.OA.1.1.4 Operate Spacecraft Crewed On-Pad OSP.OA.1.1.5 Spacecraft Launch LP OSP.OA.1.1.6 Spacecraft On-Orbit Operations LP OSP.OA.1.1.7 Spacecraft ISS Operations OSP.OA.1.1.8 Spacecraft ISS Attached Operations LE OR LP LE OR LP OSP.OA.1.1.9 Spacecraft Crew Escape AND 0.0 1.0 OSP.OA.1.1.10 Spacecraft Earth Return OSP.OA.1.1.11 Spacecraft Recovery OSP.OA.1.1.12 Spacecraft Post Recovery Ground Processing OR OSP.OA.1.1.13 Spacecraft Storage OR Continued to Part B Continued From Part A Part A Part B 0 OSP System 1 Spacecraft 2 Launch Vehicle 3 ISS Mating A dapte r 4 Ground Segment 


 11  Mating Adapter to ISS Bonding Mating Adapter to ISS Functional Link Mating Adapter to ISS Thermal Mating Adapter to ISS Command and Telemetry Link Mating Adapter to ISS Max Current Rating Mating Adapter to ISS Vibrations Mating Adapter to ISS Berthing Loads Mating Adapter to ISS 1553 PCS Link Mating Adapter to ISS RMS Power Data Grapple Fixture \(PDGF Mating Adapter to ISS IHM Mating Adapter to ISS Electromagnetic Interference Mating Adapter to ISS Current Return Mating Adapter to ISS Instrumentation Mating Adapter to ISS Shock Mating Adapter to ISS Acoustic Loads Mating Adapter to ISS Pressure Loads Mating Adapter to ISS Structural Link Mating Adapter to ISS Fluid Link Mating Adapter to ISS Power Load Constraints Mating Adapter to ISS Current Limiting Mating Adapter to ISS Cable and Wire Design Mating Adapter to ISS On-Orbit Loads Mating Adapter to ISS Wire/Connector Sizing Mating Adapter to ISS Mechanical Link Mating Adapter to ISS Electromagnetic Compatibility Mating Adapter to ISS Video Signals Mating Adapter to ISS Grounding Mating Adapter to ISS Control Atmosphere Mating Adapter to ISS Audio Signals Mating Adapter to ISS 1553 Interface Buses Mating Adapter to ISS Optical PFM NTSC Sync and Control Mating Adapter to ISS Mating/Demating Power Isolation Mating Adapter to ISS Berthing Mechanism Link International Space Station \(ISS 3 ISS Mating Adapter  Figure 11 External Interface Diagram: ISS Mating Adapter  to ISS Mating Adapter to Spacecraft Power Link Mating Adapter to Spacecraft Fluid Link Mating Adapter to Spacecraft Command and Telemetry Link Mating Adapter to Spacecraft Docking/Attachment Mechanism\(s Mating Adapter to Spacecraft 1394 Interface Buses Mating Adapter to Spacecraft 1394 Data Exchange Mating Adapter to Spacecraft Structural Link 1 Spacecraft 3 ISS  Mating Adapter  Figure 12 Internal Interface Diagram: ISS Mating Adapter  to Spacecraft Technologies Due to the short development time frame of the OSP program, NASA required that the system not require any new technology development.  Therefore the OSP system had to meet the mission objectives using only existing technologies.  These existing technologies were introduced into the CORE modeling database as requirement constraints on the OSP system Requirements Management Requirements management was performed within the CORE database to track and perform requirements flowdown as well as tie the requirements together with the operational models, functional models, and technologies Requirements told either how well the system needed to perform, set constraints on the system, or defined the interfaces.  In the CORE database, all requirements appeared as either performance indices or constraints The customer objectives were introduced into the CORE database as originating requirements.  These originating requirements included mission requirements, design requirements, environmental conditions, guidelines, and standards.  Originating requi rements were then traced to OSP System Level requirements.  The OSP System Level requirements defined the performance indices and constraints at the system leve l.  These performance indices and constraints were then flowed down and decomposed into lower level performance i ndices and constraints at the segment level, element level, and component level.  This supported the development of the system and segment performance specifications and requirements traceability matrix All of the requirements captured in CORE were directly tied to either the operational model, functional model, or technologies.  If the requirement was a performance requirement, it was tied to either the operational or functional model through a performance index.  The performance index indicated how well the function or operation needed to be accomplished. The function or operation in turn was tied back to the hardware elements of the OSP system.  For example, the requirement for two days of contingency operations by the spacecraft while not mated to ISS was represented as a performance index exhibited by the “Spacecraft On-O rbit Operations” activity previously shown in Figure 9. The “Sp acecraft On-Orbit Operations activity was in turn performed by the Spacecraft hardware element. If the requirement set a constraint on the system, it was depicted as a constraint on either an operational element or hardware element in CORE.  For example, the requirement that the spacecraft shall have an operational service life of thirty years was captured in CORE as a constraint on the Spacecraft hardware element. If the requirement defined an interface, it appeared as either a performance index or constraint on a link.  For example, the requirement that the mechani cal interface between the ISS Mating Adapter and Spacecraft shall be the Low Impact Docking System \(LIDS constraint that was placed on 


 12 the “Mating Adapter to Sp acecraft Docking/Attachment Mechanism\(s\k previously identified in Figure 12 One of the challenges for the requirements management process was capturing the manmachine interfaces.  This specific challenge was to develop and implement a methodology that allowed operational requirements to drive the physical hardware design.  In CORE, this was accomplished by allowing performance indices tied to the operational model to decompose into performance indices related to the operational model as well as the functional model 6  C ONCLUSION  A robust systems engineering process is required for a large scale program with many interfaces.  The processes and implementation presented in this paper are ideal when faced with a rapidly changing requirements environment and dynamic interfaces.   Traditional acquisition of systems revolves around a rigid set of design-to requirements.   As recent history has shown, opera tionally based acquisition is on the rise.  This means that requirements are more likely to be in flux further into the program The C4ISR methodology and implementation presented in this paper provide a robust system engineering process for a large scale program with many interfaces.  In particular, the dynamic interfaces and the integration of human interfaces were handled through the development of segment states and modes.  The state transitions were driven by system operations.  This operations based systems engineering is necessary to understand large, complex systems The process was implemented using the CORE systems engineering tool.  A flexible tool such as CORE was required to build the custom schema required for this unique program.  The capability to rigorously define the dynamic interfaces as well as decompose those interfaces was required to capture the dynamics of operationally driven systems.  Functional and physical models responded to these operations. This implementation in CORE allowed for a “Systems of Systems” view to be modeled within the same database as requirements management The demise of the OSP and precursor programs cut short the full implementation of this process.  Given time, states modes, and then operational and functional models would have been built for all segments of the system.  In addition the end to end traceability from operational requirements to component design requirements would have provided a robust platform for system verification While human spaceflight is a unique problem, the issue of systems of systems” integration is present in many fields When this is coupled with human integration, the need for an operations approach is multiplied.  Determining how to operate a system after it is functionally and physically designed results in delays and cost escalation.  An approach that takes into account human interaction and operations at the outset is more likely to re sult in a system that succeeds throughout the program lifecycle 7  R EFERENCES    DoD Archi t ect ure Fram ework W o rki ng Group DoD Architecture Framework Version 1.0” August 30, 2003 8  A CKNOWLEDGEMENTS  The primary development effort of the C4ISR CORE methodology as implemented on the OSP program was completed by Michael Wood, Orbital Sciences Corporation and Marge Dyer, Vitech Corporation 9  B IOGRAPHY  Staci N. Merida is a Principal Engineer in the Advanced Programs Group at Orbital Sciences Corporation.  She has over six years of systems engineering experience at Orbital Sciences Corporation Lockheed Martin Corporation, and Massachusetts Institute of Technology.  Past projects include: Orbital Space Plane Program, GEO Communications Satellite Programs, and the Wide Area Surveillance Projectile. Staci is a graduate of the Massachusetts Institute of Technology holdi ng both an S.B and S.M. in Aeronautics and Astronautics Rahul A. Saha is a Principal Engineer in the Advanced Programs Group at Orbital Sciences Corporation. He has over ten years of systems engineering experience at Orbital Sciences Corporation, Georgia Institute of Technology and Massachusetts Institute of Technology.  Most recently, he served as the Systems Engineering Manager for the Orbital Space Plane Program.  Past projects include The CTRV Program NASA’s Space Transportation Architecture Studies, the X34 Hypersonic Reusable Launch Vehicle Program, and The Taurus Launch Vehicle Program.  Rahul holds an M.S. In Aerospace Engineering from Georgia Tech, and an S.B. in Aeronautics and Astronautics from the Massachusetts Institute of Technology 


4 Data mining 4.1 Association rule mining Data mining which is a recent hot research topic in the database field is a method of discovering useful information such as rules and previously unknown patterns existing behind data items It enables more effective utilization of transaction log data which have been just archived and abandoned Among the major applications of data mining is association rule mining so called 217\217basket analysis.\220\220 Each of the transaction data typically consists of a set of items bought in a transaction By analyzing them one can derive some association rule such as 217\21790 of the customers who buy both A and B also buy C.\220\220 In order to improve the quality of obtained rules a very large amount of transaction data have to be examined requiring quite a long time to complete First we introduce some basic concepts of association rule Let 000 000 001 000 1 001\000 2 001\002\002\002\001\000 000 002 be a set of items and 003 000 001 003 1 001\003 2 001\002\002\002\001\003 001 002 be a set of transactions where each transaction 003 002 is a set of items such that 003 002 004\000  n itemset 004 has support 005 in the transaction set 003 if 005  f transactions in 003 contain 004  here we denote 005 000 005\006\007\007\b\t 003 001 004 002 An association rule is an implication of the form 004 005 n  where 004\001 n 004 000  and 004 006 n 000 007  Each rule has two measures of value support and confidence  The support of the rule 004 005 n is 005\006\007\007\b\t 003 001 004 b n 002  The confidence 013 of the rule 004 005 n in the transaction set 003 means 013 of transactions in 003 that contain 004 also contain n  which can be written as 005\006\007\007\b\t 003 001 004 b n 002 f\005\006\007\007\b\t 003 001 004 002  For example let r 1 000 001 1 001 3 001 4 002  r 2 000 001 1 001 2 001 3 001 5 002  r 3 000 001 2 001 4 002  r 4 000 001 1 001 2 002  r 5 000 001 1 001 3 001 5 002 be the transaction database Let minimum  support and minimum confidence be 60 and 70 respectively First all itemsets that have support above the minimum support called large itemsets  are generated In this case the large itemsets are 001 1 002 001 001 2 002 001 001 3 002 001 001 1 001 3 002  Then for each large itemset 004  n association rule 004 t n 005 n 001 n 004 004 002 is derived if 005\006\007\007\b\t 003 001 004 002 f\005\006\007\007\b\t 003 001 004 t n 002 n minimum confidence  The results are 1 005 3 001 005\006\007\007\b\t 003 000 60 001 b\016\017 000\020\021\016\013\021 000 75 002 and 3 005 1 001 005\006\007\007\b\t 003 000 60 001 013\b\016\017 000\020\021\016\013\021 000 100 002  The most well known algorithm for association rule mining is the Apriori algorithm[1 We have studied several parallel algorithms for mining association based on Apriori One of these algorithms called HPA Hash Partitioned Apriori is discussed here Apriori first generates candidate itemsets and then scans the transaction database to determine whether each of the candidates satisfies the user specified minimum support and minimum confidence Using these results the next candidate itemsets are generated This continues until no itemset satisfies the minimum support and confidence The most naive parallelization of Apriori would copy the candidates over all the processing node and make each processing node scan the transaction database in parallel Although this works fine when the number of candidates is small enough to fit in the local memory of a single processing node memory space utilization efficiency of this method is very poor For large scale data mining the storage required for the candidates exceeds the available memory space of a processing node This causes memory overflow which results in significant performance degradation due to an excessive amount of extra I/Os HPA partitions the candidate itemsets among the processing nodes using a hash function as in the parallel hash join which eliminates broadcasting of all the transaction data and can reduce the comparison workload significantly Hence HPA works much better than the naive parallelization for large scale data mining The 022 th iteration pass 022  f the algorithm is as follows 1 Generate the candidate itemsets Each processing node generates new candidate itemsets from the large itemsets of the last  001 022 t 1 002 th iteration Each of the former itemsets contains 022 items while each of the latter itemsets contains 001 022 t 1 002 items They are called 022 itemsets and 001 022 t 1 002 itemsets respectively The processing node applies the hash function to each of the candidates to determine the destination node ID If the candidate is for the processing node itself it is inserted into the hash table otherwise it is discarded 13 Proceedings of the ACM/IEEE SC97 Conference \(SC\22297 0-89791-985-8/97 $ 17.00 \251 1997 IEEE 


 30 40 50 60 70 80 90 100 110 120 30 40 50 60 70 80 90 10 0 Execution Time [s Number of Nodes Figure 13 Execution time of HPA program pass 2 on PC cluster 2 Scan the transaction database and count the support count Each processing node reads the transaction database from its local disk 000 itemsets are generated from that transaction and the same hash function used in phase 1 s applied to each of them Each of the 000 itemsets is sent to certain processing node according the hash value For the itemsets received from the other nodes and those locally generated whose ID equals the node\220s ID the hash table is searched If hit its support count value is incremented 3 Determine the large itemset After reading all the transaction data each processing node can individually determine whether each candidate 000 itemset satisfy user-specified minimum support or not Each processing node sends large 000 itemsets to the coordinator where all the large 000 itemsets are gathered 4 Check the terminal condition If the large 000 itemsets are empty the algorithm terminates Otherwise the coordinator broadcasts large 000 itemsets to all the processing nodes and the algorithm enters the next iteration 4.2 Performance evaluation of HPA algorithm The HPA program explained above is implemented on our PC cluster Each node of the cluster has a transaction data file on its own hard disk Transaction data is produced using data generation program developed by Agrawal designating some parameters such as the number of transaction the number of different items and so on The produced data is divided by the number of nodes and copied to each node\220s hard disk The parameters used in the evaluation is as follows The number of transaction is 5,000,000 the number of different items is 5000 and minimum support is 0.7 The size of the data is about 400MBytes in total The message block size is set to be 16KBytes according to the results of communication characteristics of PC clusters discussed in previous section The disk I/O block size is 64KBytes which seems to be most suitable value for the system Note that the number of candidate itemset in pass 2 s substantially larger than for the other passes which relatively frequently occurs in association rules mining Therefore we have been careful to parallelize the program effectively especially in pass 2 so that unnecessary itemsets to count should not be generated 14 Proceedings of the ACM/IEEE SC97 Conference \(SC\22297 0-89791-985-8/97 $ 17.00 \251 1997 IEEE 


The execution time of the HPA program pass 2 is shown in figure 13 as the number of PCs is changed The maximum number of PCs used in this evaluation is 100 Reasonably good speedup is achieved in this application as the number of PCs is increased 5 Conclusion In this paper we presented performance evaluation of parallel database processing on an ATM connected 100 node PC cluster system The latest PCs enabled us to obtain over 110Mbps throughput in point-to-point communication on a 155Mbps ATM network even with the so-called 217\217heavy\220\220 TCP/IP This greatly helped in developing the system in a short period since we were absorbed in fixing many other problems Massively parallel computers now tend to be used in business applications as well as the conventional scientific computation Two major business applications decision support query processing and data mining were picked up and executed on the PC cluster The query processing environment was built using the results of our previous research the super database computer SDC project Performace evaluation results with a query of the standard TPC-D benchmark showed that our system achieved superior performance especially when transposed file organization was employed As for data mining we developed a parallel algorithm for mining association rules and implemented it on the PC cluster By utilizing aggregate memory of the system efficiently the system showed good speedup characteristics as the number of nodes increased The good price/performance ratio makes PC clusters very attractive and promising for parallel database processing applications All these facts support the effectiveness of the commodity PC based massively parallel database servers Acknowledgment This project is supported by NEDO New Energy and Industrial Technology Development Organization in Japan Hitachi Ltd technically helped us extensively for ATM related issues References  R Agrawal T Imielinski and A Swami Mining association rules between sets of items in large databases In Proceedings of ACM SIGMOD International Conference on Management of Data  pages 207--216 1993  R Agrawal and R Srikant Fast algorithms for mining association rules In Proceedings of International Conference on Very Large Data Bases  1994  A C Arpaci-Dusseau R H Arpaci-Dusseau D E Culler J M Hellerstein and D A Patterson High-performance sorting on Networks of Workstations In Proceedings of International Conference on Management of Data  pages 243--254 1997  D.S Batory On searching transposed files ACM TODS  4\(4 1979  P.A Boncz W Quak and M.L Kersten Monet and its geographical extensions A novel approach to high performance GIS processing In Proceedings of International Conference on Extending Database Technology  pages 147--166 1996 15 Proceedings of the ACM/IEEE SC97 Conference \(SC\22297 0-89791-985-8/97 $ 17.00 \251 1997 IEEE 


 R Carter and J Laroco Commodity clusters Performance comparison between PC\220s and workstations In Proceedings of IEEE International Symposium on High Performance Distributed Computing  pages 292--304 1995  D.J DeWitt and J Gray Parallel database systems  The future of high performance database systems Communications of the ACM  35\(6 1992  J Gray editor The Benchmark Handbook for Database and Transaction Processing Systems  Morgan Kaufmann Publishers 2nd edition 1993  J Heinanen Multiprotocol encapsulation over ATM adaptation layer 5 Technical Report RFC1483 1993  M Kitsuregawa M Nakano and M Takagi Query execution for large relations on Functional Disk System In Proceedings of International Conference on Data Engineering  5th pages 159--167 IEEE 1989  M Kitsuregawa and Y Ogawa Bucket Spreading Parallel Hash:A new parallel hash join method with robustness for data skew in Super Database Computer SDC In Proceedings of International Conference on Very Large Data Bases  16th pages 210--221 1990  M Laubach Classical IP and ARP over ATM Technical Report RFC1577 1994  D.A Schneider and D.J DeWitt Tradeoffs in processing complex join queries via hashing in multiprocessor database machines In Proceedings of International Conference on Very Large Data Bases  16th pages 469--480 1990  T Shintani and M Kitsuregawa Hash based parallel algorithms for mining association rules In Proceedings of IEEE International Conference on Parallel and Distributed Information Systems  pages 19--30 1996  T Sterling D Saverese D.J Becker B Fryxell and K Olson Communication overhead for space science applications on the Beowulf parallel workstaion In Proceedings of International Symposium on High Performance Distributed Computing  pages 23--30 1995  T Tamura M Nakamura M Kitsuregawa and Y Ogawa Implementation and performance evaluation of the parallel relational database server SDC-II In Proceedings of International Conference on Parallel Processing  25th pages I--212--I--221 1996  TPC TPC Benchmark 000\001 D Decision Support Standard Specification Revision 1.1 Transaction Processing Performance Council 1995 16 Proceedings of the ACM/IEEE SC97 Conference \(SC\22297 0-89791-985-8/97 $ 17.00 \251 1997 IEEE 


In accordance with 1910.97 and 1910.209 warning signs are required in microwave areas For work involving power line carrier systems this work is to be conducted according to requirements for work on energized lines Comments s APPA objects to the absolute requirement implied by the word ensure regarding exposure to microwave radiation and recommends revision of s l iii to read when an employee works in an area where electromagnetic radiation levels could exceed the levels specified in the radiation protection guide the employer shall institute measures designed to protect employees from accidental exposure to radiation levels greater than those permitted by that guide  I1 an employee must be stationed at the remote end of the rodding operation Before moving an energized cable it must be inspected for defects which might lead to a fault To prevent accidents from working on the wrong cable would require identification of the correct cable when multiple cables are present Would prohibit an employee from working in a manhole with an energized cable with a defect that could lead to a fault However if the cable cannot be deenergized while another cable is out employees may enter the manhole but must protect against failure by some means for example using a ballistics blanket wrapped around cable Requires bonding around opening in metal sheath while working on cable Underaround EIectrical Installations t Comments t This paragraph addresses safety for underground vaults and manholes The following requirements are contained in this section Ladders must be used in manholes and vaults greater than four feet deep and climbing on cables and hangers in these vaults is prohibited Equipment used to lower materials and tools in manholes must be capable of supporting the weight and should be checked for defects before use An employee in a manhole must have an attendant in the immediate vicinity with facilities greater than 250 volts energized An employee working alone is permitted to enter briefly for inspection housekeeping taking readings or similar assuming work could be done safely Duct rods must be inserted in the direction presenting the least hazard to employees and APPA recommends that OSHA rewrite section 7\regarding working with defective cables This rewrite would include the words shall be given a thorough inspection and a determination made as to whether they represent a hazard to personnel or representative of an impending fault As in Subsection \(e EEI proposes the addition of wording to cover training of employees in emergency rescue procedures and for providing and maintaining rescue equipment Substations U This paragraph covers work performed in substations and contains the following requirements Requires that enough space be provided around electrical equipment to allow ready and safe access for operation and maintenance of equipment OSHA's position A2-16 


is that this requirement is sufficiently performance oriented to meet the requirements for old installations according to the 1987 NEW Requires draw-out circuit breakers to be inserted and removed while in the open position and that if the design permits the control circuits be rendered inoperative while breakers are being inserted and removed stated in the Rules and requests that existing installations not be required to be modified to meet NESC APPA recommends that Section u 4 i which includes requirements for enclosing electric conductors and equipment to minimize unauthorized access to such equipment be modified to refer to only those areas which are accessible to the public Requires conductive fences around substations to be grounded Power Generation v Addresses guarding of energized parts  Fences screens, partitions or walls This section provides additional requirements and related work practices for power generating plants  Entrances locked or attended Special Conditions w  Warning signs posted  Live parts greater than 150 volts to be guarded or isolated by location or be insulated  Enclosures are to be according to the 1987 NESC Sections llOA and 124A1 and in 1993 NESC  Requires guarding of live parts except during an operation and maintenance function when guards are removed barriers must be installed to prevent employees in the area from contacting exposed live parts Requires employees who do not work regularly at the substation to report their presence Requires information to be communicated to employees during job briefings in accordance with Section \(c of the Rules Comments U APPA and EEI provide comments as follows Both believe that some older substations \(and power plants would not meet NESC as This paragraph proposes special conditions that are encountered during electric power generation, transmission and distribution work including the following Capacitors  Requires individual units in a rack to be short circuited and the rack grounded  Require lines with capacitors connected to be short circuited before being considered deenergized Current transformer secondaries may not be opened while energized and must be bridged if the CT circuit is opened Series street lighting circuits with open circuit voltages greater than 600 volts must be worked in accordance with Section q\or t and the series loop may be opened only after the source transformer is deenergized and isolated or after the loop is bridged to avoid open circuit condition Sufficient artificial light must be provided where insufficient naturals illumination is present to enable employee to work safely A2-17 


US Coast Guard approved personal floatation devices must be supplied and inspected where employees are engaged in work where there is danger of drowning Required employee protection in public work areas to include the following  Warning signs or flags and other traffic control devices  Barricades for additional protection to employees  Barricades around excavated areas  Warning lights at night prominently displayed Lines or equipment which may be sub to backfeed from cogeneration or other sources are to be worked as energized in accordance with the applicable paragraphs of the Rules Comments w APPA submits the following comments regarding this Special Conditions section Recommends that the wording regarding capacitors be modified to include a waiting period for five minutes prior to short circuiting and grounding in accordance with industry standards for discharging of capacitors For series street light circuits, recommends that language be added for bridging to either install a bypass conductor or by placement of grounds so that work occurs between the grounds Recommends modification of the section regarding personal floatation devices to not apply to work sites near fountains decorative ponds swimming pools or other bodies of water on residential and commercial property Definitions x This section of the proposed Rules includes definitions of terms Definitions particularly pertinent to understanding the proposal and which have not previously been included are listed as follows Authorized Employee  an employee to whom the authority and responsibility to perform a specific assignment has been given by the employer who can demonstrate by experience or training the ability to recognize potentially hazardous energy and its potential impact on the work place conditions and who has the knowledge to implement adequate methods and means for the control and isolation of such energy CZearance for Work  Authorization to perform specified work or permission to enter a restricted area Clearance from Hazard  Separation from energized lines or equipment Comments x The following summarizes the changes in some of the definitions which APPA recommends Add to the definition for authorized employee It the authorized employee may be an employee assigned to perform the work or assigned to provide the energy control and isolation function  Recommends that OSHA modify the definition for a line clearance tree trimmer to add the word qualified resulting in the complete designation as a qualified line clearance tree trimmer Recommends that OSHA modify the definition of qualified employee" to remove the word construction from the definition since it is felt that knowledge of construction procedures is beyond the scope of the proposed rule resulting in APPA's new A2-18 I 


wording as follows more knowledgeable in operation and hazards associated with electric power generation transmission and/or distribution equipment Recommends that OSHA add a definition for the word practicable and replace the word feasible with practicable wherever it appears in the proposed regulations and that practicable be further defined as capable of being accomplished by reasonably available and economic means OTHER ISSUES Clothing OSHA requested comments on the advisability of adopting requirements regarding the clothing worn by electric utility industry employees EEI has presented comments which indicates research is underway prior to establishing a standard for clothing to be worn by electric utility employees However EEI's position is that this standard has not developed to the extent that it could be included in the OSHA Rules Both APPA and EEI state that they would support a requirement that employers train employees regarding the proper type of clothing to wear to minimize hazards when working in the vicinity of exposed energized facilities Grandfathering Due to the anticipated cost impact on the utility industry of the proposed Rules requiring that existing installations be brought to the requirements of the proposed Rules both APPA and EEI propose that the final Rules include an omnibus grandfather provision This provision would exempt those selected types of facilities from modification to meet the new rules EEI states that if the grandfathering concept is incorporated that electric utility employees will not be deprived of proper protection They propose that employers be required to provide employees with a level of protection equivalent to that which the standard would require in those instances in which the utility does not choose to modify existing facilities to comply with the final standard Rubber Sleeves OSHA requests comments from the industry on whether it would be advisable to require rubber insulating sleeves when gloves are used on lines or equipment energized at more than a given voltage EEI states its position that utilities should continue to have the option of choosing rubber gloves or gloves and sleeves to protect employees when it is necessary to work closer to energized lines than the distances specified in the clearance tables Preemuting State Laws EEI requests that the final Rules be clear in their preempting state rules applicable to the operation and maintenance work rules for electric power systems. This is especially critical since some states now have existing laws which are more stringent than the proposed OSHA Rules Examples are 1 in California and Pennsylvania where electric utility linemen are prohibited from using rubber gloves to work on lines and equipment energized at more than certain voltages and 2 in California and Connecticut where the live line bare hand method of working on high voltage transmission systems is prohibited One utility Pacific Gas  Electric has obtained a variance from the California OSHA to perform live line bare-hand transmission maintenance work on an experimental basis Coiiflicts Between the Rilles and Part 1926 Subpart V Since many of the work procedures in construction work and operation and maintenance work are similar and difficult to distinguish between EEI requests that the final order be clear in establishing which rule has jurisdiction over such similar work areas A2-19 v 


IMPACTS ON COSTS AND ASSOCIATED BENEFITS In its introduction to the proposed rules OSHA has provided an estimate of the annual cost impact on the electric utility industry for the proposed des of approximately 20.7 million OSHA estimates that compliance with this proposed standard would annually prevent between 24 and 28 fatalities and 2,175 injuries per year The utilities which have responded to this proposed standard through their respective associations have questioned the claims both of the magnitude of the cost involved and the benefit to the industry in preventing fatalities and lost-time injuries Both EEI and APPA feel that the annual cost which OSHA estimates are significantly lower than would be realized in practice Factors which APPA and EEI feel were not properly addressed include the following OSHA has not accurately accounted for cost of potential retroactive impacts including retrofitting and modifying existing installations and equipment OSHA has not consistently implemented performance based provisions in proposed rules  many portions require specific approaches which would require utilities to replace procedures already in place with new procedures Estimates were based on an average size investor-owned utility of 2,800 employees and an average rural cooperative of 56 employees, which are not applicable to many smaller systems such as municipal systems OSHA has not adequately addressed the retraining which would be necessary with modifying long-established industry practices to be in accordance with the OSHA rules EEI claims that OSHA's proposed clearance requirements would not allow the use of established maintenance techniques for maintaining high voltage transmission systems and thus would require new techniques For an example of the cost which is estimated to be experienced as a result of the new Rules one of the EEI member companies has estimated that approximately 20,000 transmission towers would need to be modified to accommodate the required step bolts in the Rules at an estimated cost of 6,200,000 Additionally this same company estimates that the annual cost of retesting live line tools for its estimated 1,000 tools would be 265,000 Additionally, both EEI and APPA question the additional benefits which OSHA claims would result from implementation of the new Rules APPA questions the estimates of preventing an additional 24 to 28 fatalities annually and 2,175 injuries per year in that it fails to account for the fact that the industry has already implemented in large part safety measures which are incorporated in the Rules EEI and APPA also point out that many preventable injuries cannot be eliminated despite work rules enforcement and safety awareness campaigns since many such accidents which result in fatalities are due to employee being trained but not following the employer's training and policies PRESENT STATUS OF RULES According to information received from the OSHA office in February 1993 the final Rules are to be published no later than July 1993 and possibly as soon as March 1993 OSHA closed their receipt of comments in March 1991 and no further changes in the rules are thought possible A2-20 


CONCLUSION The OSHA 1910.269 which proposes to cover electric utility operation and maintenance work rules affects a multitude of working procedures as are summarized in this paper It is not possible at the present time to assess the final structure of the Rules as may be proposed in 1993 or subsequent years Since the comments from the utility associations APPA and EEI were made following the initial release of the proposed OSHA Rules in 1989 a significant amount of time has elapsed where other events have occurred which may affect the form of the final Rules The 1993 NESC went into effect in August 1992 and includes some of the requirements to which the commenters objected For example a significant requirement in the Part 4 of the 1993 NESC requires that rubber gloves be utilized on exposed energized parts of facilities operating at 50 to 300 volts This requirement is in conflict with EEl\222s proposed change to the OSHA Rules which would still allow working such secondary facilities without the use of rubber gloves Electric utilities are advised to review the January 31 1989 proposed operation and maintenance Rules as summarized in this paper and to review their procedures which would be affected by application of the Rules Many of the procedures proposed in the Rules provide valuable guidance in electric utilities\222 operation and maintenance activities Where the cost impact is not significant, it is recommended that utilities consider implementing such procedures in expectation of the Rules being published in the next few months Also it would be appropriate for electric utilities to review the 1993 edition of the NESC since there are portions of the Rules which have resulted in changes in the NESC These changes mainly occur in Part 4 Rules for the Operation of Electric Supply and Communications Lines and Equipment The concerns which the commenters have addressed regarding the cost impact and the resulting benefits experienced as a result of the promulgation of the Rules are real ones and must be addressed in the final Rules As a result this paper cannot present a conclusion regarding the full impact of the Rules The development of such Rules continue to be an ongoing matter and will undoubtedly require later analysis when the final rules are published A2-21 


