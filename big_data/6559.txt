Energy Ef\002cient In-Memory AES Encryption Based on Nonvolatile Domain-wall Nanowire Yuhao Wang 003  Hao Yu 003  Dennis Sylvester y  Pingfan Kong 003  003 School of Electrical and Electronic Engineering Nanyang Technological University Singapore 639798 y Department of Electrical Engineering and Computer Science University of Michigan USA Abstract 227 The widely applied Advanced Encryption Standard AES encryption algorithm is critical in secure big-data storage Data oriented applications have imposed high throughput and low power i.e energy ef\002ciency J/bit requirements when applying AES encryption This paper explores an in-memory AES encryption using the newly introduced domain-wall nanowire We show that all AES operations can be fully mapped to a logic-in-memory architecture by non-volatile domain-wall nanowire called DW-AES The experimental results show that DW-AES can achieve the best energy ef\002ciency of 24 pJ/bit which is 9X and 6.5X times better than CMOS ASIC and memristive CMOL implementations respectively Under the same area budget the proposed DW-AES exhibits 6.4X higher throughput and 29 power saving compared to a CMOS ASIC implementation 1.7X higher throughput and 74 power reduction compared to a memristive CMOL implementation I I NTRODUCTION Due to instant-on power-up and ultra-low leakage power the newly introduced nano-scale non-volatile memory NVM such as ReRAM and STT RAM 2 has sho wn great potential for future big-data storage However the sensitive data will not be lost during reboot or suspension and hence is susceptible to attack Further large volume of data must be encrypted with high throughput and low power Traditional memory-logic integration based design incurs large overhead when performing encryption by logic through I/Os Therefore in-memory encryption would be preferred to achieve high energy ef\002ciency during data protection Various CMOS-based hardware implementations for AES have been presented In scenarios where ener gy ef 002cienc y is critical CMOS-based ASIC implementations tend to incur signi\002cant leakage power in current deep sub-micron regime with limited throughput In a memristi v e CMOL implementation by hybrid CMOS and ReRAM design is introduced to facilitate AES application However while the ReRAM serves as recon\002gurable interconnection it is not used for inmemory computation based encryption As spintronic devices have shown great scalability it is promising to build big-data storage with in-memory logic based computing such as encryption Domain-wall nanowire  6 or racetrack memory  is a ne wly introduced spintronic NVM device It has not only potential for high density and high performance memory design but also interesting inmemory computing capability 8 compared to other 978-3-9815370-2-4/DATE14 c 015 2014 EDAA Please address comments to haoyu@ntu.edu.sg This work is sponsored by Singapore NRF-CRP\(NRF-CRP9-2011-01 and MOE Tier-2 MOE2010T2-2-037 ARC 5/11 The authors would also like to express their sincere appreciation to Chuliang Weng Junfeng Zhao and Zhulin Wei from Shannon Laboratory Huawei Technologies Co Ltd China for useful discussions emerging NVM technologies In this work we propose a full domain-wall nanowire device based in-memory AES computing called DW-AES The non-volatile domain-wall nanowire devices are both used as storage element and deployed for logic computing in AES encryption Experimental results show that the proposed DW-AES outperforms both CMOS-based ASIC and the hybrid CMOS/ReRAM based AES computing for data storage Respectively energy ef\002ciency is improved by 9X and 6.5X and throughput improves by 6.4X and 1.7X The rest of the paper is organized as follows Section II details how all AES transformations can be implemented by the domain-wall nanowire Experiment results are presented in Section III with conclusion in Section IV II D OMAIN WALL N ANOWIRE B ASED AES C OMPUTING In-memory encryption offers two major advantages over existing approaches Firstly all domain-wall based AES ciphers DW-AES can be integrated inside the memory and AES encryption is performed directly on target data stored in nonvolatile domain-wall memory This is signi\002cantly different from the conventional memory-logic architecture in which the non-volatile storage data to process must be loaded into volatile main memory processed by logic and written back afterwards Secondly the DW-AES cipher is implemented purely by domain-wall nanowire devices which are identical to the storage elements This provides good integration compatibility between DW-AES ciphers and the memory elements as well as the ability to reuse peripheral circuits like decoders and sense ampli\002ers In this section the detailed domain-wall nanowire based in-memory encryption will be discussed A Data Organization of State Matrix In AES the standard input length is 16 bytes 128 bits which are internally organized as a two-dimensional four rows Fig 1 The 003ow chart of AES algorithm with gate utilization analysis 


by four columns array called state matrix  During the AES algorithm a sequence of transformations are applied to the state matrix after which the input block is considered encrypted and then output The 003ow chart of the AES algorithm is shown in Figure 1 Because in-memory encryption is performed directly on data cells the data needs to be organized in certain fashion to facilitate the AES algorithm As domain-wall nanowires only support serial access the data needs to be distributed into separate nanowires so that multiple bits can be operated concurrently within one cycle In AES algorithm the basic processing unit is each byte in the state matrix Therefore the state matrix is split into eight 4 002 4 arrays as illustrated in Figure 2 where each entry of each array becomes one bit instead of one byte By distributing the bytes and operating eight arrays together the byte access requirement in AES algorithm is satis\002ed Moreover to facilitate the ShiftRows transformation by exploiting the shift property of domain-wall nanowire each row of an array needs to be stored within one domain-wall nanowire In this case each array is composed of four nanowires and within each nanowire the four bits data are kept along with some redundant bits used for ef\002cient circular shift Details regarding redundant bits will be discussed later in ShiftRows transformation By organizing each 16 bytes of data in the above manner the AES algorithm can be applied ef\002ciently B AddRoundKey In the AddRoundKey step each byte in the state array will be updated by bit-wise XOR with corresponding key byte As the dominant operation in this step is XOR shown in Figure 1 we propose a nanowire based XOR logic DW-XOR for leakage free computing As the GMR-effect in the two magnetic layers structure can be interpreted as the bitwiseXOR operation of the magnetization directions of two thin magnetic layers where the output is denoted by high or low resistance In a GMR-based MTJ structure however the XORlogic will fail as there is only one operand as variable since magnetization in the 002xed layer is constant This problem is overcome by the unique domain-wall shift-operation in the domain-wall nanowire device which enables DW-XOR for computing The AddRoundKey with bitwise-XOR logic implemented by two domain-wall nanowires is shown in Figure 3 The Fig 2 Data organization of state matrix by domain-wall nanowire devices in distributed manner Fig 3 AddRoundKey step with XOR logic achieved by domain-wall nanowire proposed bitwise DW-XOR logic is performed by constructing a new read-only-port where two free layers and one insulator layer are stacked The two free layers each have the size of one magnetization domain and are from two respective nanowires Thus the two operands representing the magnetization direction in each free layer can both be variables with values assigned through the MTJs of their own nanowire These assigned values are then shifted to the operating port such that the XOR can be performed by detecting the resistance C SubBytes In this step each byte in the state matrix will undergo an invertible non-linear transformation This transformation is commonly implemented as a look-up table LUT called substitution box S-box S-box LUT essentially a pre-con\002gured memory array takes 8 bit input as a binary address 002nds target cells that contain 8 bit result through decoders and 002nally outputs correspondingly by sense ampli\002ers With 2 8 possible input scenarios and each scenario having 8 bit result the LUT size can be determined as 2 8 001 8  2048 bits The LUT is conventionally implemented by SRAM cells which in this size will incur signi\002cant leakage power Readily implemented by domain wall nanowire device the DW-LUT will enable signi\002cant leakage reduction In addition the memory and DW-LUT can share decoders and sense ampli\002ers which leads to further power and area savings D ShiftRows The ShiftRows transformation can be ef\002ciently achieved by exploiting the unique shift property of domain-wall nanowire Due to the distributed data organization in the ShiftRows transformation the second row needs to be left shifted cyclically by one bit the third by two bits and the fourth row by three bits while the top row remains unshifted In order to accomplish the circular shift in an elegant manner i.e without writing back the most signi\002cant bits to the least signi\002cant bits redundant bits are used to form a virtual circle on the nanowire as illustrated in Figure 4 Since each row has predetermined shift operation the number of redundant bits of each row can be readily determined one redundant bit is required for second row two bits for third row and three bits for last row all attached to the least signi\002cant bit from right side In order to achieve all shifts in one cycle shift currents of different amplitude are applied to 


Fig 4 ShiftRows transformation by domain-wall nanowire shift operations each row according to the linear current-velocity relationship of shift operation In other w ords the third ro w and fourth row are applied shift current that is twice and three times the amplitude applied to the second row Consider the equivalent operations in circular shift with four bits LS1 def  RS3  LS2 def  RS2  LS3 def  RS1  where LS and RS indicate left and right shift the number denotes the length to shift This means in last row instead of shifting 3 bits leftward only right shift 1 bit needs to be performed This helps to reduce the redundant data from 3 bits to 1 bit as well as reduce the applied shift current to one third of previously required amplitude The bits in same color indicate that they are synchronized bits To ensure correct circular shift the redundant bits need to be synchronized with their counterparts As a result during changes in the matrix state the redundant bits must also be updated In contrast with conventional computing 003ow in which data needs to be moved to computing units for execution and written back to memory afterwards the ShiftRows transformation is done directly on the stored data by in-memory computing fashion E MixColumns The MixColumns transformation can be expressed as the state matrix multiplied by the known matrix shown in Figure 1 The operations needed are multiplication by two  xtime2  multiplication by three  xtime-3  and addition de\002ned as bit-wise XOR The xtime-2 is de\002ned by left shift by 1 bit and bit-wise XOR with 0x1B if the most signi\002cant bit is 1 The xtime-3 is de\002ned as xtime-2 result XOR with its original value Therefore there are only two de-facto atomic operations 1 bit-wise XOR executed by proposed DW-XOR and 2 xtime-2  Although xtime-2 can be implemented by inmemory shift together with additional DW-XOR it is more ef\002cient to use 8-bit input 8-bit output DW-LUT due to its branch operations depending on its most signi\002cant bit As such the MixColumns transformation can be purely performed by DW-LUT and DW-XOR III E XPERIMENTAL R ESULTS A Experiment Setup To evaluate DW-AES cipher the following design platform has been set up Firstly at device level the transient simulation of MTJ read and write operations are performed within NVMSPICE 11 12 13 14 to obtain accurate operation energy and timing for domain-wall nanowire The shiftoperation energy is modeled as the Joule heat dissipated on the nanowire when shift-current is applied The shift-current density and shift-velocity relationship are based on The area of one domain-wall nanowire is calculated by its dimension parameters Speci\002cally the technology node of 32nm is assumed with width of 32nm length of 64nm per domain and thickness of 2.2nm for one domain-wall nanowire the R of f is set at 2600 012  the R on at 1000 012  the writing current at 100 026A  and the current density at 6 002 10 8 A=cm 2 for shiftoperation Secondly at circuit level the memory modeling tool CACTI is modi\002ed with name as D W CA CTI It can provide accurate power and area information for domainwall nanowire memory peripheral circuits such as decoders and sense ampli\002ers SAs Together with the device level performance data the DW-XOR as well as the DW-LUT can be evaluated at circuit level The additional sequential controller of DW-AES is described by Verilog HDL which is synthesized with area and power pro\002les Finally at system level an AES behavioral simulator is developed to emulate the AES cipher as well as to explore the trade-offs among power area and speed B AES Performance Comparison The proposed DW-AES cipher is compared with both CMOS-based ASIC design and h ybrid CMOS/ReRAM CMOL design F or these implementations performance data is extracted from the reported results in 4 with necessary technology scaling C-code based software implementation that runs on a general purpose processor GPP is also compared Evaluation of the AES software implementation is done in two steps Firstly gem5 simulator is employed to take AES binary compiled from C-code obtained from which generates the runtime utilization rate of core components Next the generated statistics are taken by McPAT  which pro vides core po wer and area model All hardw are implementations run at the clock-rate of 3MHz while the processor is operated at 2GHz for the software implementation Table I compares the different implementations of AES cipher and the results are discussed as follows TABLE I AES for 128 bits encryption performance comparisons Implementation leakage total power area cycles  026 W power 026 W  026m 2  C code on GPP 1.3e+6 4e+5 2.5e+6 2309 CMOS ASIC 120.54 154.74 953.05 534 memristive CMOL 102.35 119.04 251.5 534 DW-AES 14.602 21.568 78.121 1022 As expected the DW-AES cipher has the smallest leakage power due to the use of non-volatile domain-wall nanowire devices The remaining small leakage power is introduced by its CMOS peripheral circuits i.e decoders sense ampli\002ers as well as simple sequential controllers Speci\002cally DW-AES cipher achieves a leakage power reduction of 88 and 86 compared to the CMOS ASIC and memristive CMOL designs respectively The leakage power can be further reduced if the 


Fig 5 In-memory encryption throughput power and energy ef\002ciency comparisons between different AES platforms decoders and SAs of the memory can be reused by the DWAES ciphers The tradeoff made in the DW-AES cipher is a larger number of cycles required compared to other hardware implementations This is caused by the multiple-cycle operations of DWXOR and its DW-LUT where the shift-operation needs to be performed 002rst in order to align the target cell with MTJ to operate Note that while small latency between the raw data in and the encrypted data out is critical in real-time systems in big-data applications the most signi\002cant 002gures of merit are throughput and energy ef\002ciency C Throughput and Energy Ef\002ciency Comparison In the following the proposed in-memory DW-AES is compared with other implementations at the system level For each AES computing platform the number of AES units is maximized subject to a given 10 mm 2 area constraint All AES units are encrypting input data stream concurrently due to the high data parallelism With the exception of the proposed in-memory DW-AES all platforms will incur I/O energy overhead of 3.7nJ per memory access For memory a capacity of 1GB and buswidth of 128 bits are assumed Figure 5 compares throughput power and energy ef\002ciency of different AES computing platforms All AES hardware implementations have several orders of magnitude throughput and energy ef\002ciency improvement compared to the software implementation on general purpose processor as expected Among all the hardware implementations the proposed DWAES computing platform provides the highest throughput of 5.6 GB/s This throughput is 6.4X higher than that of the CMOS ASIC based platform with a power saving of 29 2.5X higher than that of the pipelined CMOS ASIC platform with 30 power reduction and 1.7X times higher than that of memristive CMOL based platform with 74 power saving Due to the in-memory encryption computing and non-volatility the proposed DW-AES computing platform can achieve the best energy ef\002ciency of 24pJ/bit which is 9X 3.6X 6.5X times higher than its counterpart the CMOS ASIC pipelined CMOS ASIC and memristive CMOL based platforms respectively IV C ONCLUSION The domain-wall nanowire based AES DW-AES is introduced in this paper All AES operations can be fully mapped to exploit the unique properties of this emerging technology For example the DW-XOR logic is proposed for the dominant XOR operation the domain-wall shift is exploited for the row-shift operation and the DW-LUT is utilized for the S-box operation The experiment results show that the proposed DW-AES exhibits the best energy ef\002ciency 24 pJ/bit Respectively it is 9X and 6.5X better than CMOS ASIC and memristive CMOL based platforms R EFERENCES  Y Wang and et al 223Design of low power 3d hybrid memory by non-volatile cbram-crossbar with block-level data-retention,\224 in Proc ISLPED  ACM 2012 pp 197\226202  T Kawahara and et al 2232mb spin-transfer torque ram spram with bit-by-bit bidirectional current write and parallelizing-direction current read,\224 in ISSCC  IEEE 2007 pp 480\226617  J.-P Kaps and B Sunar 223Energy comparison of aes and sha-1 for ubiquitous computing,\224 in Emerging Directions in Embedded and Ubiquitous Computing  Springer 2006 pp 372\226381  Z Abid and et al 223Ef\002cient cmol gate designs for cryptography applications,\224 IEEE Trans on Nanotechnology  vol 8 no 3 pp 315\226 321 2009  S S Parkin M Hayashi and L Thomas 223Magnetic domain-wall racetrack memory,\224 Science  vol 320 no 5873 pp 190\226194 2008  L Thomas and et al 223Racetrack memory a high-performance lowcost non-volatile memory based on magnetic domain walls,\224 in Proc IEDM  IEEE 2011 pp 24\2262  Y Wang and H Yu 223An ultralow-power memory-based big-data computing platform by nonvolatile domain-wall nanowire devices,\224 in Proc ISLPED  IEEE 2013 pp 329\226334  Y Wang and et al 223Energy ef\002cient in-memory machine learning for data intensive image-processing by non-volatile domain-wall memory,\224 in Proc ASPDAC  IEEE 2014  C Augustine and et al 223Numerical analysis of domain wall propagation for dense memory arrays,\224 in Proc IEDM  IEEE 2011 pp 17\2266  Nvmspice spice for non-volatile memory technologies Available http://www.nvmspice.org  Y Shang and et al 223Analysis and modeling of internal state variables for dynamic effects of nonvolatile memory devices,\224 IEEE Trans on TCAS-I  vol 59 no 9 pp 1906\2261918 2012  Y Wang and et al 223Spice simulator for hybrid cmos memristor circuit and system,\224 in Proc CNNA  IEEE 2012 pp 1\2266  W Fei and et.al 223Design exploration of hybrid cmos and memristor circuit by new modi\002ed nodal analysis,\224 IEEE TVLSI  2011  Y Wang and et al 223Design of non-destructive single-sawtooth pulse based readout for stt-ram by nvm-spice,\224 in Proc NVMTS  IEEE 2012 pp 68\22672  S J Wilton and N P Jouppi 223Cacti An enhanced cache access and cycle time model,\224 IEEE JSSC  vol 31 no 5 pp 677\226688 1996  N Binkert and et al 223The gem5 simulator,\224 ACM SIGARCH Computer Architecture News  vol 39 no 2 pp 1\2267 2011  Byte-oriented-aes A public domain byte-oriented implementation of aes in c A v ailable https://code.google.com/p/byteorientedaes  S Li and et al 223Mcpat an integrated power area and timing modeling framework for multicore and manycore architectures,\224 in Proc MICRO  IEEE 2009 pp 469\226480 


       


      


         


8 case Since the process of exibly determining  is done after TR algorithm We also nd that FTR algorithm can save more regeneration time than TR algorithm when d grows B Effect of the bandwidth variance In order to show the impact of network bandwidth variance we run simulations with 5 different link capacity distributions U 1 0  3  120 Mbps U 2 3  120 Mbps U 3 30  120 Mbps U 4 60  120 Mbps U 5 90  120 Mbps The number of providers d is set to 10  Results are shown in Fig 8 In general the performance of our algorithms is better when the variance of network bandwidth is large For uniform distribution U 1 0  3  120 Mbps both TR and FTR can reduce 90 of regeneration time compared with the traditional STAR scheme When the variance of network bandwidth becomes small for example at U 4 60  120 Mbps and U 5 90  120 Mbps TR has the same regeneration time as STAR but FTR still reduces the regeneration time by 10  20   0.3,120]Mbps 3,120]Mbps 30,120]Mbps 60,120]Mbps 90,120]Mbps 0 0.2 0.4 0.6 0.8 1 Regeneration time percentage MSR, n = 20, k = 5, d = 10, file size = 1GB   RCTREE/STAR TR/STAR FTR/STAR Fig 8 Regeneration time of RCTREE TR and FTR normalized by STAR for different bandwidth The parameters are n 20 k 5 d 10 and M 1 GB C Effect of the storage capacity per node  Our previous tests mainly focus on the MSR point which achieves the optimal storage efìciency However as shown by Dimakis et al  the repair bandwidth can be reduced by storing more data on each storage node Speciìcally the MBR point achieves the minimum repair bandwidth We vary the storage  from the MSR point to the MBR point to test its impact on our algorithms Fig 9 shows the regeneration time for different   We can see that every regeneration schemes repair faster as  grows to the minimum repair bandwidth point and the tendencies of different repair schemes are the same Compared with STAR we nd that the ratio of reduced regeneration time does not change much for different values of   This implies that our previous simulation results and conclusions for the MSR case also apply to different storage   205 211 221 236 256 0 2 4 6 8 10 12 14 16 18 Storage per node MB Regeneration time\(s n = 20, k = 5,d = 10, file size = 1GB, bandwidth = [10,120]Mbps   STAR RCTREE TR FTR MSR MBR Fig 9 Regeneration time of STAR RCTREE TR and FTR vs storage capacity of each node    where  vary from MSR point to MBR point The parameters are n 20 k 5 d 10 and M 1 GB VI R ELATED W ORK Li et al  rst considered the heterogeneity of netw ork bandwidth in data regeneration process and proposed a treestructured regeneration scheme to reduce the regeneration time They also proposed a scheme of building parallel regeneration trees to further reduce the regeneration time in the network with asymmetric links Ho we v e r  the y only discussed the case that the regeneration scheme requires k providers which means the minimal regeneration trafìc is equal to the size of original le M  To further reduce the regeneration time they considered the regenerating codes in the tree-structured regeneration scheme and proposed RCTREE in The y emplo y a minimum-storage re generating MSR codes in RCTREE which means the minimal regeneration trafìc is d k  d  k 1 M bytes i.e  in a regeneration with d providers each provider sends  d  k 1 blocks to its parent node To make sure that the newcomer has enough information to restore  blocks it has to receive data directly from at least d  k 1 providers The details of how to construct an optimal regeneration tree can be found in Algorithm 1 in their paper  Although the y h a v e done this in their algorithm to ensure that the degree of newcomer is at least d  k 1  the MDS property can not be preserved after data regeneration Sun et al  considered the scenario of repairing multiple data losses and proposed two algorithms based on treestructured regeneration to reduce the regeneration time However they assumed the amount of data transferred between providers and newcomer is designed to be the same as  in regenerating codes According to our analysis their regeneration schemes can not preserve the MDS property either Some researches such as 17 considered the heterogeneity of nodes availability and optimized the erasure code deployment to reduce the data redundancy Some researches such as jointly considered the repair cost and heterogeneity of communication\(download cost on each links They exibly determine the amount of data to minimize the total repair cost which is different from the regeneration time IEEE INFOCOM 2014 - IEEE Conference on Computer Communications 1885 


9 VII C ONCLUSION We reconsider the problem of how to reduce the regeneration time in networks with heterogeneous link capacities We analyze the minimum amount of data to be transmitted on each link of the regeneration tree and prove that the problem of building optimal regeneration tree is NP-complete We propose a heuristic algorithm to construct a near-optimal regeneration tree and further reduce the regeneration time by allowing non-uniform end-to-end repair trafìcs Simulation results show that our regeneration schemes are able to maintain the MDS property and reduce the regeneration time by 10  90 compared with traditional star-structured regenerating codes With the non-uniform end-to-end repair trafìcs we can exibly determine the amount of coded data generated by each provider The proposed Flexible Tree-structured Regeneration scheme performs even better than RCTREE R EFERENCES  J Li S Y ang X W ang and B Li T ree-structured Data Regeneration in Distributed Storage Systems with Regenerating Codes in Proceedings of IEEE Conference on Computer Communications INFOCOM  2010  S Ghema w at H Gobiof f and S.-T  Leung The google le system in ACM SIGOPS Operating Systems Review  vol 37 no 5 ACM 2003 pp 29Ö43  R Bhagw an K T ati Y C Cheng S Sa v age and G M Voelker Total recall system support for automated availability management in Proceedings of the 1st conference on Symposium on Networked Systems Design and Implementation NSDI  2004  J K ubiato wicz D Bindel Y  Chen S Czerwinski P Eaton D Geels R Gummadi S Rhea H Weatherspoon W Weimer et al  Oceanstore An architecture for global-scale persistent storage ACM Sigplan Notices  vol 35 no 11 pp 190Ö201 2000  W uala-Secure Cloud Storage Online A v ailable http://www.wuala.com  A G Dimakis P  B Godfre y  M J W  Y  W u  and K Ramchandran Network Coding for Distributed Storage System IEEE Transactions on Information Theory  vol 56 no 9 pp 4539Ö4551 2010  B Gast  on J Pujol and M Villanueva A realistic distributed storage system the rack model arXiv preprint arXiv:1302.5657  2013  T  Benson A Ak ella and D A Maltz Netw ork traf c characteristics of data centers in the wild in Proceedings of the 10th ACM SIGCOMM conference on Internet measurement  ser IMC 10 ACM 2010 pp 267Ö280  Google Datacenters Online A v ailable http://www.google.com/about/datacenters/inside/datasecurity/index.html  P  P  C L Y uchong Hu Henry C H Chen and Y  T ang Nccloud applying network coding for the storage repair in a cloud-of-clouds in Proceedings of USSENIX Conference on File and Storage Technologies\(FAST  2012  J Li S Y ang and X W ang Building parallel re generation trees in distributed storage systems with asymmetric links in 2010 6th International Conference on Collaborative Computing Networking Applications and Worksharing CollaborateCom  2010  S.-J Lee P  Sharma S Banerjee S Basu and R F onseca Measuring bandwidth between planetlab nodes in Passive and Active Network Measurement  Springer 2005 pp 292Ö305  A Duminuco and E Biersack  A practical study of regenerating codes for peer-to-peer backup systems in 29th IEEE International Conference on Distributed Computing Systems\(ICDCSê09  IEEE 2009  Prims algorithm Online A v ailable http://en.wikipedia.org/wiki/Primsalgorithm  J Li S Y ang X W ang X Xue and B Li T reestructured data regeneration with network coding in distributed storage systems in Proceedings of 17th International Workshop on Quality of Service\(IWQoS  2009  W  Sun Y  W ang and X Pei T ree-structured parallel regeneration for multiple data losses in distributed storage systems based on erasure codes Communications China  vol 10 no 4 pp 113Ö125 2013  L P amies-Juarez P  Garcia-Lopez and M SanchezArtigas Heterogeneity-aware erasure codes for peer-topeer storage systems in International Conference on Parallel Processing ICPP  2009  G Xu S Lin G W ang X Liu K Shi and H Zhang Hero Heterogeneity-aware erasure coded redundancy optimal allocation for reliable storage in distributed networks in International Performance Computing and Communications Conference IPCCC  2012  S Akhlaghi A Kiani and M R Ghana v ati Costbandwidth Tradeoff in Distributed Storage Systems Computer Communications  vol 33 no 17 pp 2105 2115 2010  M Gerami M Xiao and M Sk oglund Optimal-cost Repair in Multi-hop Distributed Storage Systems in Proc of IEEE International Symposium on Information Theory ISIT  2011 pp 1437Ö1441  S Akhlaghi A Kiani and M Ghana v ati  A fundamental trade-off between the download cost and repair bandwidth in distributed storage systems in Proceedings of IEEE International Symposium on Network Coding NetCod  2010  C Armstrong and A V ardy  Distrib uted storage with communication costs in Proceedings of Annual Allerton Conference on Communication Control and Computing Allerton  2011  N Shah K V  Rashmi and P  K umar   A  e xible class of regenerating codes for distributed storage in Proceedings of IEEE International Symposium on Information Theory Proceedings ISIT  2010 IEEE INFOCOM 2014 - IEEE Conference on Computer Communications 1886 


       


method increases slightly which is due to two reasons 1 the data before In this experiment we investigate the performance of OLTP queries when OLAP queries are running The workload is update-only and the keys being updated are uniformly distributed We launch ten clients to concurrently submit the updates when the system is deployed on 100 nodes Each client starts ten threads each of which submits one million updates 100 updates in batch Another client is launched to submit the data cube slice query That is one OLAP query and approximately 50,000 updates are concurrently processed in R-Store The system reaches its maximum usage in this setting based on our observation When the system is deployed on other number of nodes the number of clients submitting updates is adjusted accordingly Figure 11\(a shows the throughput of the system The throughput increases as the number of nodes increases which demonstrates the scalability of the system However when OLAP queries are running the update performance is lower than running only OLTP queries This result is expected because the OLAP queries compete for resources with the OLTP queries We also evaluate the latency of updates when the system is approximately fully used As shown in Figure 11\(b the aggregated response time for 1000 updates are similar with respect to varying scales VII C ONCLUSION MapReduce is a parallel execution framework which has been widely adopted due to its scalability and suitability in 0    500    1000    1500    2000  0  10  20  30  40  50  60  70  80  90  100  IncreQueryScan             IncreQueryExe              DC DC DC  Q i i i i T part  Q a Data Cube Slice Query                                                                                                b TPC-H Q1 Fig 7 Performance of Querying    Fig 8 Accuracy of Cost Model    Fig 9 Performance vs Freshness On each HBase-R node the key/values are stored in format Though only one or two versions of the same key are returned to MapReduce HBase-R has to scan all the of the table Since the is materialized to HDFS when it is full these 223les are sorted by time Thus instead of scanning all the and between  only the between   are scanned The value of decides the freshness of the result There is a trade-off between the performance of the query and the freshness of the result the smaller is the fewer real-time data are scanned Figure 9 shows the query processing time with different freshness ratios which is de\223ned as the percentage of the real-time data we have to scan for the query In this experiment  1600 million and 800 million updates on 1 distinct keys are submitted to HBase-R When the freshness ratio is 0 the input of the query is only the data cube Thus the cost of scanning the real-time data is 0 When the freshness ratio increases to 10 the cost of scanning the real-time data is around 1500 seconds because the cost of scanning the real-time table dominates the OLAP query As the freshness ratio increases the running time of and  and when it is not  and  We submit 800 million updates to the server each day and the percentage of keys updated is 223xed to 1 The data cube is refreshed at the beginning of each day and the OLAP query is submitted to the server at the end of the day Since the data are compacted after the data cube refresh the amount of data stored in the real-time table are almost the same at the same time of each day The processing time of and are thus almost constant In contrast when the compaction scheme is turned off HBase-R stores much more data and the cost of locally scanning these data becomes larger than the cost of shuf\224ing the data to MapReduce As a result the processing time of and increases over time and and a user speci\223ed timestamp still need to be scanned and 2 the amount of data shuf\224ed to mappers are roughly the same with different ratios Figure 10 depicts the effectiveness of our compaction scheme In this experiment we measure the processing time of the data cube slice query when the compaction scheme is applied  0 1,000 2,000 3,000 4,000 5,000 Baseline IncreQuery Baseline IncreQuery Baseline IncreQuery Baseline IncreQuery Baseline IncreQuery Baseline IncreQuery Processing time \(s Percentage of keys being updated 1 5 10 15 20 25 IncreQueryExe IncreQueryScan CubeScan BaselineExe BaselineScan Processing Time \(s I/Os \(X10 11  Percentage of Keys Updated CubeScan        Processing Time \(s Freshness Ratio CubeScan                                                                                                            50 0 1,000 2,000 3,000 4,000 5,000 Baseline IncreQuery Baseline IncreQuery Baseline IncreQuery Baseline IncreQuery Baseline IncreQuery Baseline IncreQuery Processing time \(s Percentage of keys being updated 1 5 10 15 20 25 IncreQueryExe IncreQueryScan CubeScan BaselineExe BaselineScan store\223le store\223les part memstore store\223les memstore store\223les IncreQuerying Baseline IncreQuerying Baseline-NC IncreQuerying-NC Baseline IncreQuerying Baseline-NC IncreQuerying-NC C Performance of OLTP 0    1200    2400    3600    4800    6000  1  5  10  15  20  25  0  0.8  1.6  2.4  3.2  4  IncreQueryScan        IncreQueryExe        I/Os estimated for IncreQuery                               I/Os estimated for  Baseline                 T T T T T T T T 


3000    6000    9000    12000  1  2  3  4  5  6  7  IncreQuerying                                   Baseline-NC                   IncreQuerying-NC                       51 002 Fig 10 Effectiveness of Compaction    a Throughput    b Latency Fig 11 Performance of OLTP Queries a large scale distributed environment However most existing works only focus on optimizing the OLAP queries and assume that the data scanned by MapReduce are unchanged during the execution of a MapReduce job In reality the real-time results from the most recently updated data are more meaningful for decision making In this paper we propose R-Store for supporting real-time OLAP on MapReduce R-Store leverages stable technology HBase and HStreaming and extends them to achieve high performance and scalability The storage system of R-Store adopts multi-version concurrency control to support real-time OLAP To reduce the storage requirement it periodically materializes the real-time data into a data cube and compacts the historical versions into one version During query processing the proposed adaptive incremental scan operation shuf\224es the real-time data to MapReduce ef\223ciently The data cube and the newly updated data are combined in MapReduce to return the real-time results In addition based on our proposed cost model the more ef\223cient query processing method is selected To evaluate the performance of R-Store we have conducted extensive experimental study using the TPCH data The experimental results show that our system can support real-time OLAP queries much more ef\223ciently than the baseline methods Though the performance of OLTP degrades slightly due to the competition for resources with OLAP the response time and throughput remain good and acceptable A CKNOWLEDGMENT The work described in this paper was in part supported by the Singapore Ministry of Education Grant No R-252000-454-112 under the epiC project and M.T 250 Ozsu\220s work was partially supported by Natural Sciences and Engineering Research Council NSERC of Canada We would also like to thank the anonymous reviewers for their insightful comments R EFERENCES  http://hbase.apache.or g  http://hstreaming.com  http://www comp.nus.edu.sg epic  M Athanassoulis S Chen A Ailamaki P  B Gibbons and R Stoica Masm ef\223cient online updates in data warehouses In  pages 865\205876 2011  Y  Cao C Chen F  Guo D Jiang Y  Lin B C Ooi H T  V o S W u and Q Xu Es2 A cloud data storage system for supporting both oltp and olap ICDE pages 291\205302 2011  S Ceri and J W idom Deri ving production rules for incremental vie w maintenance In  pages 577\205589 1991  T  Condie N Conw ay  P  Alv aro J M Hellerstein K Elmelee gy  and R Sears Mapreduce online In  pages 313\205328 2010  J Dean S Ghema w at and G Inc Mapreduce simpli\223ed data processing on large clusters In  pages 137\205150 2004  L Golab T  Johnson and V  Shkapen yuk Scheduling updates in a real-time stream warehouse ICDE pages 1207\2051210 2009  M Grund J Kr 250 uger H Plattner A Zeier P Cudre-Mauroux and S Madden Hyrise a main memory hybrid storage engine  4\(2 Nov 2010  A Gupta I S Mumick and V  S Subrahmanian Maintaining vie ws incrementally extended abstract In  pages 157\205166 1993  S H 264 eman M Zukowski N J Nes L Sidirourgos and P Boncz Positional update handling in column stores In  pages 543\205 554 2010  D Jiang G Chen B C Ooi and K.-L T an epic an e xtensible and scalable system for processing big data 2014  D Jiang B C Ooi L Shi and S W u The performance of mapreduce an in-depth study  3\(1-2 Sept 2010  D M Kane J Nelson and D P  W oodruf f An optimal algorithm for the distinct elements problem PODS 22010 pages 41\20552  A K emper  T  Neumann F  F  Informatik T  U Mnchen and DGarching Hyper A hybrid oltp&olap main memory database system based on virtual memory snapshots In  2011  T W  K uo Y T  Kao and C.-F  K uo T w o-v ersion based concurrenc y control and recovery in real-time client/server databases  52\(4 Apr 2003  K Y  Lee and M H Kim Ef 223cient incremental maintenance of data cubes In  pages 823\205833 2006  F  Li B C Ooi M T  250 Ozsu and S Wu Distributed data management using mapreduce In  2014  I S Mumick D Quass and B S Mumick Maintenance of data cubes and summary tables in a warehouse In  pages 100\205111 1997  A Nandi C Y u P  Bohannon and R Ramakrishnan Distrib uted cube materialization on holistic measures In  pages 183\205194 2011  L Neume yer  B Robbins A Nair  and A K esari S4 Distrib uted stream computing platform In  pages 170\205177 2010  C Olston B Reed U Sri v asta v a R K umar  and A T omkins Pig latin a not-so-foreign language for data processing In  pages 1099\2051110 2008  K Ser ge y and K Y ury  Applying map-reduce paradigm for parallel closed cube computation In  pages 62\20567 2009  M Stonebrak er  D J Abadi A Batkin X Chen M Cherniack M Ferreira E Lau A Lin S Madden E O\220Neil P O\220Neil A Rasin N Tran and S Zdonik C-store a column-oriented dbms In  pages 553\205564 2005  A Thusoo J S Sarma N Jain Z Shao P  Chakka S Anthon y  H Liu P Wyckoff and R Murthy Hive a warehousing solution over a mapreduce framework  2\(2 2009  P  V assiliadis and A Simitsis Near real time ETL In  volume 3 pages 1\20531 2009  C White Intelligent b usiness strate gies Real-time data w arehousing heats up  2012 SIGMOD VLDB NSDI OSDI SIGMOD SIGMOD Proc VLDB Endow In ICDE IEEE Trans Comput VLDB ACM Computing Survey SIGMOD ICDE ICDMW SIGMOD DBKDA VLDB PVLDB Annals of Information Systems DM Review 0    Processing Time \(s Time since the Creation of Data Cube \(day Baseline                  Updates Per Second \(K Number of Nodes Updates only                  Response Time for 1000 Updates\(s Number of Nodes Updates only                  0    20    40    60    80    100  10  20  30  40  50  60  70  Updates + OLAP                                    0    2    4    6    8    10  10  20  30  40  50  60  70  Updates + OLAP                                    Proc VLDB Endow 


  13    1  2   3   4   5   6   7   8  9  10  11   


and aeronautical engineering with degrees from Universitat Politecnica de Catalunya in Barcelona Spain and Supaero in Toulouse France He is a 2007 la Caixa fellow and received the Nortel Networks prize for academic excellence in 2002 Dr Bruce Cameron is a Lecturer in Engineering Systems at MIT and a consultant on platform strategies At MIT Dr Cameron ran the MIT Commonality study a 16 002rm investigation of platforming returns Dr Cameron's current clients include Fortune 500 002rms in high tech aerospace transportation and consumer goods Prior to MIT Bruce worked as an engagement manager at a management consultancy and as a system engineer at MDA Space Systems and has built hardware currently in orbit Dr Cameron received his undergraduate degree from the University of Toronto and graduate degrees from MIT Dr Edward F Crawley received an Sc.D in Aerospace Structures from MIT in 1981 His early research interests centered on structural dynamics aeroelasticity and the development of actively controlled and intelligent structures Recently Dr Crawleys research has focused on the domain of the architecture and design of complex systems From 1996 to 2003 he served as the Department Head of Aeronautics and Astronautics at MIT leading the strategic realignment of the department Dr Crawley is a Fellow of the AIAA and the Royal Aeronautical Society 050UK\051 and is a member of three national academies of engineering He is the author of numerous journal publications in the AIAA Journal the ASME Journal the Journal of Composite Materials and Acta Astronautica He received the NASA Public Service Medal Recently Prof Crawley was one of the ten members of the presidential committee led by Norman Augustine to study the future of human space\003ight in the US Bernard D Seery is the Assistant Director for Advanced Concepts in the Of\002ce of the Director at NASA's Goddard Space Flight Center 050GSFC\051 Responsibilities include assisting the Deputy Director for Science and Technology with development of new mission and measurement concepts strategic analysis strategy development and investment resources prioritization Prior assignments at NASA Headquarters included Deputy for Advanced Planning and Director of the Advanced Planning and Integration Of\002ce 050APIO\051 Division Director for Studies and Analysis in the Program Analysis and Evaluation 050PA&E\051 of\002ce and Deputy Associate Administrator 050DAA\051 in NASA's Code U Of\002ce of Biological and Physical Research 050OBPR\051 Previously Bernie was the Deputy Director of the Sciences and Exploration Directorate Code 600 at 050GSFC\051 Bernie graduated from Fair\002eld University in Connecticut in 1975 with a bachelors of science in physics with emphasis in nuclear physics He then attended the University of Arizona's School of Optical Sciences and obtained a masters degree in Optical Sciences specializing in nonlinear optical approaches to automated alignment and wavefront control of a large electrically-pumped CO2 laser fusion driver He completed all the course work for a PhD in Optical Sciences in 1979 with emphasis in laser physics and spectroscopy He has been a staff member in the Laser Fusion Division 050L1\051 at the Los Alamos National Laboratories 050LANL\051 managed by the University of California for the Department of Energy working on innovative infrared laser auto-alignment systems and infrared interferometry for target alignment for the HELIOS 10 kilojoule eight-beam carbon dioxide laser fusion system In 1979 he joined TRW's Space and Defense organization in Redondo Beach CA and designed and developed several high-power space lasers and sophisticated spacecraft electro-optics payloads He received the TRW Principal Investigators award for 8 consecutive years Dr Antonios A Seas is a Study Manager at the Advanced Concept and Formulation Of\002ce 050ACFO\051 of the NASA's Goddard Space Flight Center Prior to this assignment he was a member of the Lasers and Electro-Optics branch where he focused on optical communications and the development of laser systems for space applications Prior to joining NASA in 2005 he spent several years in the telecommunication industry developing long haul submarine 002ber optics systems and as an Assistant Professor at the Bronx Community College Antonios received his undergraduate and graduate degrees from the City College of New York and his doctoral degree from the Graduate Center of the City University of New York He is also a certi\002ed Project Management Professional 14 


 





 17  Jar r e n  A   B al d w i n  is  a  Ch i c a g o  n a t i v e  a n d  c u r r e n t l y  se r v e s a s t h e  l e a d  E l e c t r i c a l  En g i n e e r  a t  B a y  A r e a  s t a r t u p   Oc u l e v e  I n c   He  g r a d u a t e d  fr o m  t h e  U n i v e r s i t y  o f Il l i n o i s  wi t h  a  B  S   i n  2 0 0 9  an d  r ecei v ed  an  M  S   i n  El e c t r i c a l  En g i n e e r i n g  f r  St a n f o r d  U n i v e r s i t y  i n  2 0 1 2   Ja r r e n  d e v e l o p e d  h a r d w a r e  a n d  so f t w a r e  sy st e m s f o r  a  w i d e  ra n g e  o f  f i e l d s   i n c l u d i n g  s p a c e  s c i e n c e  s y s t e m s  a n d  m e d i c a l  de vi c e s  a s  a N A S A  A m es  i nt e r n i n t he  In t e l l i g e n t  S y s t e m s     1  2  3   4   5   6   7   8   9   10   11   12   13   


                        


                           


   












































     2 8    b 4      1 8             1 2     1  8 2  


1 9    8      2 1       1     2    8    2 3\f        


     8 D 4 9  F  \b 1 8 #J 9 1     2 1   2 #-@ 1   2 9  E 1   1   2 9      6  


    8  8   1  D 1         1 F  \b0         2 D    F  \b 1 8  9  


  1 9  1   E 1  2 9     1 1 F  \b       1    18   F   1    1 #-$+  \b  2 2  


1 D     1 #-$+.B- 0/:% .0             9 1      18    1 6     1 2  1  1  


1   6      2    1 2 E 8 D 1      1 2   1   1 #-4  #-@E     2  1  1  1       


 8     1          2 F    6   F  2   8    2 C<CC/C N\bO 5      


CD    b$44NO F P Q 6   2 b$$$ ,=\b\bA  A N,O 2 C C  b$$4N  92 2   f  9-\b$$4 B N?O  !-    91  2 1 HH111-18-N+O    -1 :3%   2     0-4 


     b N4O 2   2- \f  C b$@$ \b# >\b\b$3\b$N@O  f :.% 9 /9 \f    1  6  f 2  4   A254 


Advantages of Our M ethod Advantages of Our M ethod Exploit the memory v ertical data format utilizes slidin g windows to g form a much larger database to analyze  Flexibility in Choosing what to choose  Choosing what to choose to build the rules Computational and memory efficiency We have a team working only on this aspect 45 Associative IDS for NextGen Frameworks Dr S Dua LA Tech 45 


Preliminary Results Intra transaction Relations Data rate simulator NH-134 Mb HOP PATH update \(Y/N Inference 11.5 Y Y 2 0.120 N N      Y   n 0.345 N NH134 Y/N   Inf 1 0.150 N N 2 0 120 Y N Inter transaction Relations 2 0  120 Y N       5 5.55 0.456 Y Relations  n 0.345 N N Nmap on DMRL nmap.org 


Anticipated Outcome Anticipated Outcome Develop algorithm capable of learning from a given heterogeneous diverse Develop algorithm capable of learning from a given heterogeneous diverse data ff Dynamic algorithmic f ramework designed to shi f t modalities and sampling rates based on complex logic Flexibility of integration into the Snort intrusion detection system 47 Associative IDS for NextGen Frameworks Dr S Dua LA Tech 47 


References References Aircraft Cockpit Image courtesy USAF http://www.faa.gov htt p   www.faa g ov  air traffic  technolo gy  p g  _ gy  Acharya R Dua S Du X Sree V Chua C K Automated Diagnosis of Glaucoma Using Texture and Higher Order Spectra Features To appear in IEEE Transactions on Information Technology in Biomedicine  Du X Dua S 2011 Cancer Prognosis Using Support Vector Regression in Imaging  Modality World Journal of Clinical Oncology 2  1   44 49 Du X Dua S 2010 Salient Frame Extraction Using Support Vector Regression and Motion Features pp 5 Proc of the National Aerospace and Electronics Conference July 14 16 2010 D M P D S 2010 Di i i ti Ft d Cl ifi ti Mthd f D essaue r  M  P  D ua S  2010  Di scr i m i na ti ve F ea t ures an d Cl ass ifi ca ti on M e th o d s f or Accurate Classification 1st ed vol 7704 pp 14 Bellingham WA Proceedings of SPIE Dessauer M P Dua S 2010 Low Resolution Vehicle Tracking using Dense and Reduced Local Gradient Features Maps 1st ed vol 7694 pp 8 Bellingham WA Proceedings of SPIE SPIE 


Acknowledgements Acknowledgements Fundin g A g encies  US 4 1 Million direct fundin g g g 4 g LA BoR NIH NSF AFRL AFOSR and NASA Research Team Samuel Kasimalla Brandy McKnight Dr Pradeep Chowriappa Connor Johnson Vasanth Nair Mihir Chowriappa  Connor Johnson  Vasanth Nair  Mihir Karnik Mohit Jain and Swadheen Songmen Associative IDS for NextGen Frameworks Dr S Dua LA Tech 49 All the respective Logos belong to their owners 


Rf d Rdi R e f erence d R ea di ngs Copyright of cover pages held by respective publishers 


Thank You Questions Thank You  Questions Dr Sumeet Dua E mail sdua@latech.edu Web http://dmrl.latech.edu Associative IDS for NextGen Frameworks Frameworks Dr S Dua LA Tech 51 Image Source roadtrafficsigns.com 


