Energy Ef\002cient Neural Networks for Big Data Analytics Yu Wang 1  Boxun Li 1  Rong Luo 1  Yiran Chen 2  Ningyi Xu 3  Huazhong Yang 1 1 Dept of E.E Tsinghua National Laboratory for Information Science and Technology Tsinghua University Beijing China 2 Dept of E.C.E University of Pittsburgh Pittsburgh USA 3 Microsoft Research Asia Beijing China Email yu-wang@mail.tsinghua.edu.cn Abstract 227The world is experiencing a data revolution to discover knowledge in big data Large scale neural networks are one of the mainstream tools of big data analytics Processing big data with large scale neural networks includes two phases the training phase and the operation phase Huge computing power is required to support the training phase And the energy ef\002ciency 050power ef\002ciency\051 is one of the major considerations of the operation phase We 002rst explore the computing power of GPUs for big data analytics and demonstrate an ef\002cient GPU implementation of the training phase of large scale recurrent neural networks 050RNNs\051 We then introduce a promising ultrahigh energy ef\002cient implementation of neural networks operation phase by taking advantage of the emerging memristor technique Experiment results show that the proposed GPU implementation of RNNs is able to achieve 2 030 11 002 speed-up compared with the basic CPU implementation And the scaled-up recurrent neural network trained with GPUs realizes an accuracy of 47 on the Microsoft Research Sentence Completion Challenge the best result achieved by a single RNN on the same dataset In addition the proposed memristor-based implementation of neural networks demonstrates power ef\002ciency of  400 GFLOPS/W and achieves energy savings of 22 002 on the HMAX model compared with its pure digital implementation counterpart I I NTRODUCTION The amount of data in our world is exploding at an astounding rate We have entered the Era of Big Data Big data contain huge amount of intelligence and absolutely have the potential to change the way governments organizations and academic institutions conduct business and make discoveries Unstructured data are data that do not follow a speci\002ed format including text speech image video and more Unstructured data are the major components of big data As a ne w  relati v e ly untapped source of intelligence unstructured data analytics is able to reveal important interrelationships that were previously dif\002cult or impossible to determine Ho we v er  the management of unstructured data is a large problem Unstructured data must be converted to structured data for better analysis and management In other words we need to put a label on everything and establish the structure of big data Large scale neural networks also known as the deep neural networks 050DNNs\051 or deep learning have demonstrated a great promise in processing unstructured data State-of-the-art performance has been reported in many unstructured data processing tasks ranging from visual object classi\002cation speech recognition to nature language processing and information retrieval No w adays The DNN has become one of the most popular tools to process big data Processing big data with large scale neural networks includes two phases the training phase and the operation phase Huge computing This work was supported by the Microsoft Research Asia 050MSRA\051 National Natural Science Foundation of China 050No 61373026 No 61261160501 No 61028006\051 973 project 2013CB329000 National Science and Technology Major Project 0502013ZX03003013-003\051 Youth Talent Development Plan of Beijing 050YETP0099\051 and NSF CAREER CNS-1253424 And we gratefully acknowledge the support of NVIDIA Corporation with the donation of the GPUs used for this research power is required to support the training phase Training phase is the critical operation to obtain a neural network for a speci\002c task It usually demands a large volume of memory and computing resources and the time consumption can range from a few seconds to hundreds of hours depending on the scale of the networks In addition recent research has demonstrated that the performance of DNNs such as the classi\002cation accuracy can be drastically improved by increasing the scale of the network Therefore in order to better process big data with large scale neural networks we need to explore more computing power For the operation phase the energy ef\002ciency 050power ef\002ciency\051 is one of the major concerns In order to obtain more computing power with less cost we need to improve the energy ef\002ciency of the computing system The latest estimation indicated that power ef\002ciency of 030 100 GFLOPS/W is necessary to support more powerful information processing systems While the e xist ing contemporary CPU or GPU systems fall far behind 050 030 10 GFLOPS/W\051 10 A revolutionary architecture is demanded to satisfy the continuously growing requirement of energy ef\002ciency for large scale neural networks and big data analytics We explore the computing power of GPUs for big data analytics by demonstrating an ef\002cient GPU implementation of the training phase of large scale recurrent neural networks 050RNNs\051 And we introduce a promising hardware solution to the ultra-high energy ef\002cient implementation of the operation phase the memristor-based neural networks Finally we discuss several challenges of the work and show some future directions II L ARGE S CALE R ECURRENT N EURAL N ETWORKS ON GPU S The recurrent neural network 050RNN\051 is a special type of neural network equipped with additional recurrent connections Those unique recurrent connections enable the RNN to store the processed information and capture the long-range dependencies between input data Therefore the RNN has been regarded as an expressive model to process nonlinear sequential processing tasks such as speech recognition nature language processing and even video indexing  Ho we v er  the lar ge computation comple xity mak es it dif 002cult to effectively train a RNN and therefore signi\002cantly limits the research on RNNs in the last 20 years In recent years the use of graphics processing units 050GPUs\051 has been a signi\002cant advance to accelerate the training process and scale up neural network models In our w ork we focus on accelerating the training process of RNNs with GPUs and further scaling up the RNN model to improve its performance We 002rst explore the potential parallelism of the recurrent neural network and propose a 002ne-grained two-stage pipeline implementation The experiment results are illustrated in Table I The results show that the proposed GPU implementation can achieve 2 030 11 002 speed-up compared with the basic CPU implementation with the Intel Math Kernel Library We then use the proposed GPU implementation 978-3-9815370-2-4/DATE14 c 015 2014 EDAA 


TABLE I P ERFORMANCE OF THE L ARGE S CALE R ECURRENT N EURAL N ETWORK ON GPU S 050a\051 Time consumption of different implementations of the RNN 1   Hidde   BPTT 2 2   BPTT=5   BPTT=10    Size  CPU  GPU  Speed-up  CPU  GPU  Speed-up  CPU  GPU  Speed-up    128  96.63  39.25  2.46  150.59  77.31  1.95  264.07  121.81  2.17    256  128.42  49.89  2.57  240.56  95.14  2.53  389.44  143.39  2.72    512  429.09  73.78  5.82  871.02  137.52  6.33  1490.79  199.24  7.48    1024  1238.60  130.45  9.50  2385.18  239.78  9.95  3796.22  338.92  11.20   050b\051 Performance on the MRSC Challenge 3   Method  Accuracy    Chance 050Baseline\051  20    Smoothed 4-gram in  39    RNN-100 with 100 classes 4  40    Proposed RNN-1000  47    vLBL+NCE5 in 5  60.8   1 The size of the RNN is 10  000 002 HiddenSize 002 10  000  The RNN model is the same as the one described in 2 BPTT represents the step 050training depth\051 of training RNNs with the Backpropagation-Through-Time algorithm 3 We use the RNN as a language model and we test the model performance on the Microsoft Research Sentence Completion Challenge 4 The model is trained with the RNNLM Toolkit in The netw ork nodes are di vided into classes to reduce the computation comple x at the cost of performance reduction 5 The best result we have seen so far to scale up the recurrent neural network and improve its performance The experiment results of the Microsoft Research Sentence Completion Challenge demonstrate that the large scale recurrent network trained with GPUs is able to beat the traditional modest-size recurrent network and achieve an accuracy of 47 the best result achieved by a single recurrent neural network on the same dataset III M EMRISTOR BASED E NERGY E FFICIENT I MPLEMENTATION OF N EURAL N ETWORKS Energy ef\002ciency or power ef\002ciency has become one of the most crucial considerations in computing system design Unfortunately the cessation of Moore's Law has limited further improvements in energy ef\002ciency In recent years the physical realization of the memristor has demonstrated a promising solution to ultra-integrated hardware realization of neural networks which can be leveraged for better performance and energy ef\002ciency gains Memristor was 002rst physically realized by HP Labs in 2008 Afterwards the memristor attracts signi\002cant research interest as it is the 002rst memory technology with enough power ef\002ciency and density to rival biological computation F or e xample the memristor crossbar structure provides an incredible execution ef\002ciency of the matrix-vector multiplication which is one of the most signi\002cant operations of arti\002cial neural networks And as illustrated in Fig 1 the memristor crossbar-based neural network can be used to realize a low power approximated computation unit cooperating with CPUs achieving power ef\002ciency of  400 GFLOPS/W and energy savings of 22 002 with quality loss of at most 1.87 IV F URTHER W ORK AND D ISCUSSION Large scale neural networks are ef\002cient tools for big data analytics We leverage the computing power of GPUs for the training phase And we introduce an ultra-high energy ef\002cient implementation of the operation phase with the emerging memristor technique However many challenges still lie ahead First more computing power is demanded to support large scale neural networks and big data analytics CPUs GPUs FPGAs and even mixed-signal systems Fig 1 Proposed Memristor-based Approximated Computation Framework should cooperate more ef\002ciently to reach this target Secondly the training algorithm especially the most widely used stochastic gradient descent 050SGD\051 algorithm is a sequential iterative process and hard to get parallelized How to realize a parallel implementation of the SGD is a major challenge of further accelerating the training process and scaling up the neural networks Thirdly the present fabrication technology limits the scale of memristor crossbar arrays to modest size We need ef\002cient methods of combining many modestsize memristor crossbar arrays to realize large scale memristor-based neural networks Finally the memristor only enables an ef\002cient implementation of the operation phase of neural networks while the training phase is still con\002ned to the traditional digital systems Although there have been several works trying to realize the self-training of memristor-based neural networks with mixed-signal systems these methods achieve the energy gains at the cost of training quality loss How to realize better training results with less time and energy consumption is another major problem of processing big data with neural networks R EFERENCES  Micros oft The big bang Ho w the big data e xplosion is changing the world  EMC Corporat ion IDC IV ie w  Extracting v alue from chaos  Intel Bi g data 101 Unstructured data analytics  Jef fre y Dean et al Lar ge scale distrib uted deep netw orks In Advances in Neural Information Processing Systems 2012   Kai Y u Lar ge-scale deep learning at baidu In International Conference on Information and Knowledge Management 2013   Jiquan Ngiam et al On optimization met hods for deep learning In International Conference on Machine Learning 2011   Adam Coates et al Deep learning with cots hpc systems In International Conference on Machine Learning 2013   D ARP A Po wer ef 002cienc y re v olution for embedded computing technologies  NVIDIA TESLA K-SERIES D A T ASHEET  K epler f amily product overview 2012  Int el Intel microprocessor e xport compliance metrics 2013  Geof fr e y Zweig et al A challenge set for adv ancing language modeling In NAACL-HLT 2012 Workshop   Andri y Mnih et al Learning w ord embeddings ef 002ciently wit h noisecontrastive estimation In Advances in Neural Information Processing Systems 2013   T oma s Mik olo v et al Rnnlm-recurrent neural netw ork language modeling toolkit In 2011 IEEE workshop on Automatic Speech Recognition and Understanding   Il ya Sutsk e v er et al Generating te xt with recurrent neural netw orks In International Conference on Machine Learning 2011   M assimiliano V ersace and Ben Chandler  Moneta a mind made from memristors IEEE Spectrum  2010  M iao Hu Hai Li Qi ng W u and G.S Rose Hardw are realization of bsb recall function using memristor crossbar arrays In DAC 2012   B oxun Li Y i Shan Miao Hu Y u W ang Y iran Chen and Huazhong Yang Memristor-based approximated computation In ISLPED 2013   Boxun Li Y uzhi W ang Y u W ang Y iran Chen and Huazhong Y ang Training itself Mixed-signal training acceleration for memristor-based neural network In ASPDAC 2014  


Information Visualisation 2005 Proceedings Ninth International Conference on and giving full opacity At the same time it provides context by displaying the rest of the network with shorter edges and transparent colors One of its notable features is that it can accommodate variable aspect ratios This is particularly useful for small displays such as in smartphones Here metro lines are bent around the screen boundaries thus 037tting the route and context in a cramped space without needing to zoom out V C ONCLUSION In this paper we have explained two prior metro map visualization techniques automatic octilinear layouts and label/annotation layouts In addition we have discussed two possible applications Many interesting research directions lie ahead The current MIP approaches are rather slow and thus are not widely used for interactive applications We would like to design an ef\037cient technique for octilinear layouts for metro maps R EFERENCES 1 J Bottger U Brandes O Deussen and H Ziezold 223Map warping for the annotation of metro maps,\224 Visualization and Computer Graphics IEEE Transactions on  vol 28 no 5 pp 56\22665 2008 2 K Garland  Middlesex England Capital Transport Publishing 1994 3 S.-H Hong D Merrick and H A D do Nascimento 223Automatic visualisation of metro maps,\224  vol 17 no 3 pp 203\226224 Jun 2006 A v ailable http://dx.doi.org/10.1016/j.jvlc.2005.09.001 4 K Nesbitt 223Getting to more abstract places using the metro map metaphor,\224 in  2004 pp 488\226493 5 M Nollenburg and A Wolff 223Drawing and labeling high-quality metro maps by mixed-integer programming,\224  vol 17 no 5 pp 626\226641 2011 6 M Ovenden  Middlesex England Capital Transport Publishing 2003 7 E S Sandvad K Gr\370nbaek L Sloth and J L Knudsen 223A metro map metaphor for guided tours on the web the webvise guided tour system,\224 in  vol 17 no 1 pp 101\226114 2011 9 J Stott P Rodgers R Burkhard M Meier and M Smis 223Automatic layout of project plans using a metro map metaphor,\224 in  2005 pp 203\226206 10 Y.-S Wang and M.-T Chi 223Focus+context metro maps,\224  vol 17 no 12 pp 2528\2262535 2011 11 H.-Y Wu S Takahashi D Hirono M Arikawa C.-C Lin and H.-C Yen 223Spatially ef\037cient design of annotated metro maps,\224  vol 31 no 3pt1 pp 925\226934 Jun 2012 A v ailable http://dx.doi.org/10.1111/j.1467-8659.2012.03085.x 21 Information Visualisation 2004 IV 2004 Proceedings Eighth International Conference on Comp Graph Forum Metro Maps of the World IEEE Computer Graphics and Applications  ser WWW 22201 New York NY USA ACM 2001 pp 326\226333  A v ailable http://doi.acm.or g/10.1145/371920.372079 8 J Stott P Rodgers J Martinez-Ovando and S Walker 223Automatic metro map layout using multicriteria optimization,\224 Proceedings of the 10th international conference on World Wide Web Computer Graphics Forum Mr Beck\222s Underground Map J Vis Lang Comput Visualization and Computer Graphics IEEE Transactions on  vol 32 no 3pt3 pp 261\226270 2013 Available http://dx.doi.org/10.1111/cgf.12113 12 H.-Y Wu S Takahashi C.-C Lin and H.-C Yen 223Travel-routecentered metro map layout and annotation,\224 Visualization and Computer Graphics IEEE Transactions on 


                                                                                                                                                                               238 


                                                                                   239 


                                                                                                                                240 


important component of the discussed B DLM and must also be done in a secure and trustworthy way  V  B IG D ATA I NFRASTRUCTURE BDI  Figure 4 provide s a general view on the Big Data infrastructure that includes the general infrastructure for general data management, typically cloud based, and Big Data Analytics part that will require high performance computing clusters  which in their own turn will req uire high performance low latency network    General BDI services and components include  000x  Big Data Management tools  000x  Registries, indexing/search, semantics, namespaces  000x  Security infrastructure \(access control, policy enforcement confidentiality, trust, availa bility, privacy  000x  Collaborative environment \(groups management     Figure 4   General Big Data Infrastructure functional components   We define Federated Access and Delivery Infrastructure FADI as an important component of the general BDI that interconnects different components of the cloud/Intercloud based infrastructure combining dedicated network connectivity provisioning and federated access control [19, 37   A  B ig Data Analytics Infrastructure  Besides the general c loud base infrastructure services storage compute infrastructure/VM management  the following specific applications and services will be required to support Big Data and other  data centric applications  23, 24, 38  wh ich we will commonly refer to as Big Data Analytics Infrastructure \(BDAI  000x  Cluster services  000x  Hadoop related services and tools  000x  Specialist data analytics tools logs events data mining etc  000x  Databases/Servers SQL, NoSQL  000x  MPP \(Massively Parallel Processing  databases     Figure 5   Big Data Analytics Infrastructure components   Big Data analytics tools are currently offered by the major cloud services providers such as: Amazon Elastic MapReduce and Dynamo 39   Mi c r o s o f t  A zu r e H DI n s ig h t   4 0    IBM Big Data Analytics  41   Sc ala b l e  Had o o p  an d  d a ta  an aly tics  to o ls  service s are offered by few companies that position themselves as Big Data companies such as Cloudera, [42  an d  f ew  o th er s  43   VI  C LOUD B AS ED I NFRASTRUCTURE S ERVICES FOR B DI  Figure 6  illustrates the typical e Science or enterprise collaborative infrastructure that  is created on demand and includes enterprise proprietary and cloud based computing and storage resources, instruments, control and monitoring system visualization system, and users represented by user clients and typically residing in real or virtual cam puses   The main goal of the enterprise or scientific infrastructure is to support the enterprise or scientific workflow and operational procedures related to processes monitoring and data processing Cloud technologies simplify the building of such infras tructure and provision it on demand. Figure 6 illustrates how an example enterprise or scientific workflow can be mapped to cloud based services and later on deployed and operated as an instant inter cloud infrastructure It contains cloud infrastructure s egments IaaS VR3 VR5 and PaaS VR6 VR7 separate virtualised resources or services \(VR1, VR2\, two interacting campuses A and B, and interconnecting them network infrastructure that in many cases may need to use dedicated network links for guaranteed p erformance   Efficient operation of such infrastructure will require both overall infrastructure management and individual services and infrastructure segments to interact between themselves This task is typically out of scope of the existing cloud service  provider models but will be required to support perceived benefits of the future e SDI. These topics are a subject of another research we did on the InterCloud Architecture Framework [19 37    110 


  Figure 6 From scientific workflow to cloud based infrastructure  VII  R ELATED WORK  There are not many academic papers related to the definition of the Big Data Architecture or its components Due to the specifics of this paper that intends to explore a new emerging technology domain   we have widely researched  both currently existing publications related to the Big Data technology and research papers and best practices documents from other domains that could contribute to the definition of the proposed Big Data Architecture Framework. A  number of publications  standards, and industry best practices have been  mentioned and cited in this paper. Here we just mention these works that we consider as a foundation for our work The authors actively contribute to the NIST Big Data Working Group that provide s  a good forum for discussion but have plans to produce initial set of the draft document s  only by the end of September 2013 The following publications contribute to the research on the Big Data Architecture  NIST Cloud Computing Reference Architecture CC RA 18   B ig  Data  E co s y s te m  A r ch itect u r e definition by Microsoft [20   B ig  Data  tech n o lo g y  a n al y s is  b y  G.Mazzaferro [21     We also refer to other related architecture definitions Information as a Service  by Open Data Center Alliance [22   TMF Big Data A nalytics Architecture 23   IBM Business Analytics and Optimisation  Reference Architecture 24   LexisNexis HPCC Systems [25   VIII  F UTURE R ESEARCH AND D EVELOPMENT  The future research and development will include further Big Data definition initially presented in this paper  At this stage we attempt ed to summarise and re think some widely used definition s  related to Big Data, further research will require more formal approach and taxonomy of the general Big Data use cases in different Big Data origin and target domains also analyzing different stakeholder groups    The authors will extend their research into defining the Big Data Security Framework with the specific focus on data centric security that should allow secure data storage transfer and processing in di stributed data storage and processing infrastructure   The authors  are  also looking into defining data structures for high performance streaming applications and developing new types of disk based stream oriented data bases, continuing the work started fro m the authors work on CakeDB  database  4 4    The authors will continue contributing to the NIST Big Data WG targeting both goal s  to propose own approach and to validate it against the industry standardisation process   Another target research direction is d efining a Common Body of Knowledge \(CBK\ in Big Data to provide a basis for a consistent curriculum development. This work and related to the Big Data metadata procedures and protocols definition is planned to be contributed to the Research Data Alliance RDA   4 5     The authors believe that the presented paper will contribute  toward the definition of the Big Data Architecture Framework and provide a basis for wider discussion to define a new research and technology domain   en-GB A CKNOWLEDGEMENTS  This work is supported by the FP7 EU funded project s  GN3plus and EUBrazil Cloud Connect The authors also express acknowledgement to the members of the Big Data Interest Group at the University of Amsterdam for contribution to the discussion on Big Data Ar chitecture framework and provided valuable advices regarding use cases, suggested technology use and basic operational models  R EFERENCES  1  Global Research Data Infrastructures: Towards a 10 year vision for global research data infrastructures Final Roadm ap March 2012  O nline  Available  http://www.grdi2020.eu/Repository/FileScaricati/6bdc07fb b21d 4b90 81d4 d909fdb96b87.pdf  2  Riding the wave: How Europe can gain from the rising tide of scientific data Final report of the High Level Expert Group on Scientific Data October 2010   O nline   Available at http://cordis.europa.eu/fp7/ict/e infrastructure/docs/hlg sdi report.pdf  3  Y.Demchenko  P Membrey, P  Grosso, C   de Laat 000 Addressing Big Data Issues in Scientific Data Infrastructure  000  in First International Symposium on Big Data and Data Analytics in Collaboration \(BDDAC 2013 Part of The 2013 Int  Conf   on Collaboration Technologies and Systems CTS 2013 May 20 24, 2013, San Diego, California, USA  4  NIST Big Data Working Group NBD WG   O nline  Available  http://bigdatawg.nist.gov/home.php  5  Definting Big Data Architetcure Framework Outcome of the Brainstorming Session at the University of Amsterdam 17 July 2013 Present ed  at  NBD WG 24 July 2013  O nline  Available  http://bigdatawg.nist.gov/_uploadfiles/M0055_v1_7 606723276.pdf  6  Reflections on Big Data Data Science and Related Subjects Blog by Irving Wladawsky Berger  online  Available http://blog.irvingwb.com blog/2013/01/reflections on big data data science and related subjects.html  7  E Dumbill, What is big data? An introduction to the big data landscape  O nline  Available  http://strata.oreilly.com/2012/01/what is big data.html  8  The Big Data Long Tail  Blog post by Jason Bloomberg   Jan uary  17, 2013  O nline  Available  http://www.devx.com/blog/the big data lon g tail.html  111 


9  J  Gantz and David Reinsel   Extracting Value from Chaos  IDC IVIEW June 2011   O nline  Available  http://www.emc.com/collateral/analyst reports/idc extracting value from chaos ar.pdf  10  The Fourth Paradigm Data Intensive Scientific Discovery Edite d by Tony Hey Stewart Tansley and Kristin Tolle  Microsoft Corporation October 2009 ISBN 978 0 9825442 0 4  O nline  Available  http://research.microsoft.com/en us/collaboration/fourthparadigm  11  Big Data defintion Gartner Inc  O nline  Available  http://www.gartner.com/it glossary/big data  12  S.Sicular 000 Gartner's Big Data Definition Consists of Three Parts, Not to Be Confused with Three "V"s 000  Gartner, Inc. 27 March 2013   O nline  Available  http://www.forbes.com/sites/gartnergroup/2013/03/27 gartners big data definition consists of three parts not to be confused with three vs  13  J Layton  000 The Top of the Big Data Stack: Database Applications 000  July 27 2012  O nline  Available  http://www.enterprisestorageforum.com/storage management/the top of the big data stack database applications.html  14  Explore big data analytics and Hadoop  O nline  Available  http://www.ibm.com/developerworks/training/kp/os kp hadoop  15  A Bloom 7 Myths on Big Data Avoiding Bad Hadoop and Cloud Analytics Decisions April 22 2013  O nline  Available  htt p://blogs.vmware.com/vfabric/2013/04/myths about running hadoop in a virtualized environment.html  16  European Union. A Study on Authentication and Authorisation Platforms For Scientific Resources in Europe Brussels  European Commission 2012. Final Report Contributing author. Internal identification SMART Nr 2011/0056  O nline  Available  Available at http://cordis.europa.eu/fp7/ict/e infrastructure/docs/aaa study final report.pdf  17  Y Demchenko  P.Membrey C.Ngo C de Laat D.Gordijenko  Big Security for Big Data: A ddressing Security Challenges for the Big Data Infrastructure Proc  0006\000H\000F\000X\000U\000H\000\003\000'\000D\000W\000D\000\003\0000\000D\000Q\000D\000J\000H\000P\000H\000Q\000W\000\003\000\013\0006\000'\0000\000¶\000\024\000\026\000\014\000\003\000:\000R\000U\000N\000V\000K\000R\000S\000\021\000\003\0003\000D\000U\000W\000\003 of VLDB2013 conference, 26 30 August 213, Trento, Italy  18  NIST SP 500 292 Cloud Computing Reference Architecture v1.0  O nline  Available  http://colla borate.nist.gov/twiki cloud computing/pub/CloudComputing/ReferenceArchitectureTaxonomy/NIS T_SP_500 292_ _090611.pdf  19  Y Demchenko  M Makkes R.Strijkers C.Ngo C de Laat Intercloud Architecture Framework for Heterogeneous Multi Provider Cloud based Inf rastructure Services Provisioning, The International Journal of Next Generation Computing \(IJNGC\, Volume 4, Issue 2, July 2013  20  NIST Big Data Reference Architecture  NBD WG NIST   O nline  Available  http://bigdatawg.nist.gov/_uploadfiles/M0226_v10_1554566513.docx  21  NIST Big Data T echnology Roadmap  NBD WG  O nline  Available  http://bigdatawg.nist.gov/_uploadfiles/M0087_v8_1456721868.docx  22  Open Data Center Alliance Master Usage model Information as a Service Rev 1.0  O nline  Available  http://www.opendatacenteralliance.org/docs  Information_as_a_S ervice_Master_Usage_Model_Rev1.0.pdf  23  TR202 Big Data Analytics Reference Model  TMF Document Version 1.9, April 2013  24  IBM GBS Business Analytics and Optimisation 2011 IBM  2013   O nline  Available  https://www.ibm.com/developerworks  mydeveloperworks  files/basic/anonymous/api/library 48d92427 47d3 4e75 b54c b6acfbd608c0/document/aa78f77c 0d57 4f41 a923 50e5c6374b6d/media&ei=yrknUbjMNM_liwKQhoCQBQ&usg=AFQjC NF_Xu6aifcAhlF4266xXNhKfKaTLw&sig2=j8JiFV_md5DnzfQl0spVr g&bvm=bv.42768644,d.cGE  25  A.M Middleton  HPCC Systems Introduction to HPCC High Performance  Computer Cluster LexisNexis Risk Solutions LexiNexis  May 24, 2011  26  Bierauge M Keeping Up With Big Data American Library Association  2013   O nline  Available  http://www.ala.org/acrl/publications/keeping_up_with/big_data  27  Unstructured Data Mana gement Hitachi Data System  2013  online  http://www.hds.com/solutions/it strategies/unstructured data management.html  28  NIST Big Data WG discussion  O nline  Available  http://bigdatawg.nist.gov/home.php  29  D.Koopa, et al 000 A Provenance Based Infrastructure to Support the Life Cycle of  Executable Papers 000  in International Conference on Computational Science  ICCS 2011   O nline  Available  http://vgc.poly.edu/~juliana/pub/vistrails executable paper.pdf  30  Open Access: Opportunities and Challenges. European Commission for UNESCO  O nline  Available  http://ec.europa.eu/research/science society/document_library/pdf_06/open access handbook_en.pdf  31  OpenAIR 000  Open Access Infrastructure for Research in Europe  O nline  Available  http://www.openaire.eu  32  Open Researcher and Contributor ID online  h t t p    a b o u t  o r c i d  o rg  33  Roundup of Big Data Pundits' Predictions for 2013. Blog post by David Pittman January 18 2013   O nline  Available http://www.ibmbigdatahub.com/blog/roundup big data pundits predictions 2013  34  The Forrester Wave: Big Data Predictive Analytics Solutions, Q1 2013 Mike Gualtieri January 13 2013  O nline  Available  http://www.forrester.com/pimages/rws/reprints/document/85601/oid/1 LTEQDI  35  Big data: The next frontier for innovation, competition, and producti vity May 2011 McKinsey Global Institute  O nline  Available  http://www.mckinsey.com/insights/business_technology/big_data_the_n ext_frontier_for_innovation  36  Data Lifecycle Models and Concepts  O nline  Available  http://wgiss.ceos.org/dsig/whitepapers/Data%20Lifecycle%20Models 2 0and%20Concepts%20v8.docx  37  M Makkes  C  Ngo Y  Demchenko R  Strijkers R  Meijer C   de Laat 000 Defining Intercloud Federation Framework for Multi provider Cloud Services Integration 000  in The Fourth International Conference on Cloud Computing GRIDs and Virtua lization CLOUD COMPUTING 2013  May 27  June 1, 2013,Valencia, Spain  38  M Turk   A chart of the big data ecosystem take 2 online  http://mattturck.com/2012/10/15/a chart of the big data ecosystem take 2  39  Amazon Big Data  O nline Available   http://aws.amazon com/big data  40  Microsoft Azure Big Data Microsoft   2013  O nline  Available  http://www.windowsazure.com/en us/home/scenarios/big data  41  IBM Big Data Analytics  IBM 2 o 13   O nline  Available  http://www 01.ibm.com/software/data/infosphere/bigdata analytics.html  42  Cloudera Impala Big Data Platform   O nline  Available  http://www.cloudera.com/content/cloudera/en/home.html  43  10 hot big data startups to watch in 2013  10 January 2013  O nline  Available  http://beautifuldata.net/2013/01/10 hot big data startups to watch in 2013  44  P Membrey K  C.C. Chan, Y  Demchenko, A Disk B ased Stream Oriented Approach For Storing Big Data I n First International Symposium on Big Data and Data Analytics in Collaboration \(BDDAC 2013 Part of The 2013 International Conference on Collaboration Technologies and Systems \(CTS 2013\, May 20 24, 2013  San Diego, California, USA  45  Research Data Alliance  RDA  O nline  Available  http://rd alliance.org   112 


Size of Largeincrease The reasons are twofold Firstly when increases according to the node selection scheme to construct decrease There are two reasons Firstly when the memory size increases the stop condition for graph contraction is easier to be satis\336ed since more nodes can 336t in memory Secondly when the memory size increases the costs of the external sorts in both graph contraction and graph expansion phases decrease  Average Degree Number of Largeincreases the time and I/O consumptions for both increases the number of iterations in graph contraction increases This is because when number of edges increases the cost to sort and scan edges in each iteration increases thus more time and I/Os are consumed in each iteration                                     2 4 1 u E  V v E    u v  G  V E M V M V K G V V M KB Range 25M,50M,100M,150M,200M 2,3,4,5,6 200M,300M,400M,500M,600M 400K 8K 20,30,40,50,60 30,40,50,60,70 10K to in the operator in line 4 both in line 4 and augmented in all nodes in in line 5-7 VIII P ERFORMANCE S TUDIES In this section we conduct experimental studies by comparing four external algorithms for is the number of bytes to keep a node in memory We set the max time cost to be 24 hours If a test does not stop in the time limit we will denote it using until all nodes form an to Size of Small The results are shown in Fig 7\(a and Fig 7\(b for time and I/O costs respectively When the memory size increases the time and I/O costs for both 100M 400M 40 1 1 50 TABLE I R ANGE AND D EFAULT V ALUE FOR P ARAMETERS Parameter in all cases since more nodes/edges are removed in each iteration in Operator  operator speci\336es a unique total order among all nodes in the graph operator in line 9 when generating algorithm needs to hold and and and and and used in introduced in 26  w h i ch is cu r r e n tly th e m o s t I O ef 336cien t sem i e x t er n a l algorithm for and  Secondly when and out out out out out out out Fig.6\(a and Fig 6\(b show the time and I/O costs when varying the number of edges of WEBSPAM-UK2007 from 20 to 100 respectively v G v G v G v G v G v G v G v G v G v G v G v G v G v G 002 212 327 327  002 002 327 327 327 327 327       2 cannot stop in the time limit even if the graph contains only 20 of the edges When Size of 8 our e x t e rnal cont ract i on-e xpans i o n b as ed algorithm Algorithm 2 and our algorithm by applying the optimization techniques introduced in Section VII in new edges are added into In Algorithm 3 in order to make use of the new s The graphs contain nodes from 25M to 200M with average degree varying from 2 to 6 A synthetic graph is generated as follows We construct a graph computation namely the external contraction based 13 t he e x t e rnal DFS based by randomly selecting all nodes in SCC SCC SCC SCC SCC SCC  we apply the algorithm computation The  Finally additional random nodes and edges are added to the graph The parameters for synthetic datasets and their default values are shown in Table VIII outperforms 1PB 1PB since it cannot stop in all cases Memory Size need to be computed in Ext Ext Ext Ext EM Ext EM Ext Ext Ext Ext Ext Ext Ext Ext    3  002  For the semi-external algorithm  In our experiments we use a real large web graph and several synthetic datasets The real web graph is WEBSPAM-UK2007 4  which consists of 105,896,555 web4 barcelona.research.yahoo.net/webspam/datasets/uk2007/links   4H   8H   12H   16H   20H   24H   INF   20   40   60   80   100   Time\(hour Ext-SCC-Op   Ext-SCC                           DFS-SCC                 Largein in in in in in in 2 plus one disk block in the main memory that is Size of MassiveNumber of Massive\(a Time Vary Memory   1M   2M   3M   4M   5M   6M   7M   8M   INF   400M   600M   800M   1G   Number of I/Os Ext-SCC-Op   Ext-SCC                       DFS-SCC               iff one of the following three conditions holds 1 b I/Os Vary Memory Fig 7 WEBSPAM-UK2007 Varying Memory Size pages in 114,529 hosts in the UK domain The graph contains 105,895,908 nodes and 3,738,733,568 edges with the average degree 35 per node For synthetic data we generate 3 different kinds of datasets denoted Massive.The 4K,6K,8K,10K,12K 6K,8K,10K,12K,14K u w u G u G u G u G u G u G u G  For any  containing different sizes of and Small 327     V i i i i i d d d i i De\036nition 7.1 DFS Op Op Op Op Op Op 217 before adding  The default memory size is  In our experiments we do not show the results of  thus more iterations are needed according to the stop condition of graph contraction in 327 Semi add Datasets Exp-1 Performance on WEBSPAM-UK2007 in Algorithm 3 more nodes will be selected in id id 200K,300K,400K,500K,600K as follows DFS SCC SCC SCC SCC SCC SCC SCC SCC SCC SCC SCC SCC SCC SCC SCC SCC SCC SCC SCC SCC SCC SCC SCC SCC SCC SCC SCC SCC SCC  By considering  All the algorithms are implemented using Visual C 2005 and tested on a PC with Intel Core2 Quar 2.66GHz CPU and 3.5GB memory running Windows XP The disk block size is  according to Theorem 5.3 nodes with small degrees are removed when constructing 256 400   256 400 Default INF 327 deg deg deg deg deg deg deg deg deg deg deg deg deg deg deg deg deg deg deg deg deg  4 w V V E V G V G   u  v V G G E E E E G where can be further reduced We rede\336ne the operator Number of SmallD M s s s i i i i i i i 1 1 1 1 1 1 u>v 4  Secondly using operator  and for each removed node  s 336rst Then we add edges among the nodes in an  We vary the memory size from                     a Time Vary Graph Size   1M   2M   3M   4M   5M   6M   7M   8M   INF   20   40   60   80   100   Number of I/Os Ext-SCC-Op   Ext-SCC                           DFS-SCC                 b I/Os Vary Graph Size Fig 6 WEBSPAM-UK2007 Varying Graph Size Percent   4H   8H   12H   16H   20H   24H   INF   400M   600M   800M   1G   Time\(hour Ext-SCC-Op   Ext-SCC                       DFS-SCC               


SCC SCC SCC SCC SCC SCC SCC SCC SCC SCC SCC increases the time and I/O costs for both dataset dataset The results for both Largedatasets are similar to those in the Massive When either the average   800 105 895 908 8  256  847 200 600 25 200 50 12 30 70 f I/Os SmallTo test the synthetic data we vary the memory size M   K  M M M M M M M M M M D D D D K s s s of nodes from 2 to 6 The time and I/O costs on Largedo not have signi\336cant impact on the ef\336ciency of our algorithms as long as by 20 on average for both time and I/O consumptions Fig 8\(c and Fig 8\(d show the results on Large 1 1 4  the costs for both d I/Os Vary Degree   c Time Vary Degree   25 327         Size and G M G M V V V V V V V K E G Wevary the node size decrease sharply The reason is that in order to process the graph using in all test cases to to is smaller the decrease rate is larger This is because when is smaller more iterations are needed for both to  and the time and I/O costs are shown in Fig 9\(a and Fig 9\(b respectively When to to respectively Fig 9\(g and Fig 9\(h show the time and I/O costs when varying the number of 4   s and and and and and and and and Wevary the average degree Size   Size   Time\(hour Number of I/Os Time\(hour Number of I/Os Time\(hour Number of I/Os Time\(hour Number of I/Os Time\(hour Number of I/Os Time\(hour Number of I/Os Time\(hour Number of I/Os 2H   3H   4H   5H   INF   200M   300M   400M   500M   600M   Ext-SCC-Op   Ext-SCC                           DFS-SCC                 200K   400K   600K   800K   1M   1.2M   INF   200M   300M   400M   500M   600M   Ext-SCC-Op   Ext-SCC                           DFS-SCC                 1H   2H   3H   4H   5H   INF   200M   300M   400M   500M   600M   Ext-SCC-Op   Ext-SCC                           DFS-SCC                 200K   400K   600K   800K   1M   1.2M   INF   200M   300M   400M   500M   600M   Ext-SCC-Op   Ext-SCC                           DFS-SCC                 1H   2H   3H   4H   5H   INF   200M   300M   400M   500M   600M   Ext-SCC-Op   Ext-SCC                           DFS-SCC                 200K   400K   600K   800K   1M   1.2M   INF   200M   300M   400M   500M   600M   Ext-SCC-Op   Ext-SCC                           DFS-SCC                 8H   12H   16H   20H   INF   25M   50M   100M   150M   200M   Ext-SCC-Op   Ext-SCC                           DFS-SCC                 1M   2M   3M   4M   5M   INF   25M   50M   100M   150M   200M   Ext-SCC-Op   Ext-SCC                           DFS-SCC                 2H   4H   6H   8H   10H   INF   2   3   4   5   6   Ext-SCC-Op   Ext-SCC                           DFS-SCC                 400K   600K   800K   1M   1.2M   INF   2   3   4   5   6   Ext-SCC-Op   Ext-SCC                           DFS-SCC                 2H   3H   4H   5H   INF   4K   6K   8K   10K   12K   Ext-SCC-Op   Ext-SCC                           DFS-SCC                 400K   600K   800K   1M   INF   4K   6K   8K   10K   12K   Ext-SCC-Op   Ext-SCC                           DFS-SCC                 2H   3H   4H   5H   INF   30   40   50   60   70   Ext-SCC-Op   Ext-SCC                           DFS-SCC                 400K   600K   800K   1M   INF   30   40   50   60   70   Ext-SCC-Op   Ext-SCC                           DFS-SCC                 e Time Small,andwhen increase This is because when n in Synthetic Data in Synthetic Data DFS DFS DFS Exp-5 Vary Op Op Op Op Op Op Op Op Op Op Op Op Ext  The time and I/O costs on Massiveare shown in Fig 9\(c and Fig 9\(d respectively When decrease When f I/Os Vary Ext Ext Ext Ext Ext Ext Ext Ext Ext Ext Ext Ext Ext Ext Ext Ext Ext Ext Ext Ext Ext Ext Ext Ext  V  V Number in Synthetic Data c Time Large\(a Time Vary e Time Vary cannot stop in limited time in all cases Similar to the results on the real dataset in Fig 7 when dataset and Fig 8\(e and Fig 8\(f show the results on Smallconsume less than 1 hour increases the time and I/O consumptions for both consumes more than 20 hours while both are the number of nodes and the number of edges of the graph As a result the size of memory is needed thus when the memory size is dataset are shown in Fig 8\(a and Fig 8\(b respectively dataset and this is true for all the remaining test cases when varying other parameters in synthetic data In the following due to the lack of space we only show the test results on the Large and in the graph contraction phase the contraction rate decreases when the number of iterations increases since the graph becomes denser with larger number of iterations is larger and the cost on each iteration to scan and   Exp-4 Vary Average Degree in Synthetic Data from from increases the time and I/O consumptions for both and the number of outperforms outperforms cannot stop within the time limit when outperforms in all cases When the memory increases from increases the time and I/O costs for both When a Time Massive\(b I/Os Massiveis larger is larger the gap between is larger This is because when number of edges is larger more edges can be pruned by the edge reduction techniques used in increases the number of edges increases As a result more iterations are needed and larger cost is consumed in each iteration as analyzed in Exp-1 when varying the graph size size increases or the number of are not in\337uenced much As anal yzed in Section VII the key factors that in\337uence the cost of Num   Num Fig 9 Synthetic Data Largecan be directly applied on the original graph to output all                       Fig 8 Synthetic Data Vary Memory Size outperforms  and Smallincrease This is because the stop condition for graph contraction is harder to be satis\336ed when  sort nodes/edges is larger when   Fig 9\(e and Fig 9\(f show the time and I/O costs when varying the average no iteration is needed and size from SCC SCC SCC SCC SCC SCC SCC SCC SCC SCC SCC SCC SCC SCC SCC SCC SCC SCC SCC SCC SCC SCC SCC SCC SCC SCC SCC SCC SCC SCC SCC SCC SCC SCC SCC SCC SCC SCC SCC SCC SCC SCC SCC SCC SCC SCC SCC 1H   4H   200K   1H   200K   1H   200K   sfrom b I/Os Vary g Time Vary h I/Os Vary        218 d I/Os LargeSemi Semi Exp-2 Vary Memory Size Exp-3 Vary Node Size   


are 336xed This also explains why the results in the three datasets Massiveis a primitive operation in directed graph exploration which has been studied for both internal memory model and external memory model In the internal memory model strongly connected components of a directed graph can be computed in s for a directed graph with the assumption that the nodes of the graph cannot reside entirely in memory We overcome the de\336ciencies of the existing external    sort sort computation algorithms and propose a new two-phase algorithm with graph contraction followed by graph expansion We analyze the I/O cost of our approach and show that our algorithm can signi\336cantly reduce the number of random I/Os We propose techniques to further reduce the I/O cost of our algorithm and con\336rm the I/O ef\336ciency of our approaches using extensive experiments on both real and synthetic web scale graphs The work was supported by grant of the Research Grants Council of the Hong Kong SAR China No 418512 R EFERENCES  J  A bello A  L  Buchs baum  a nd J  W e s t brook A f unctional a pproach to external graph algorithms s of a graph Zhang et al 26 i mpro v e s uch a n a l gori t h m by constructing and maintaining a special in-memory spanning tree of the graph The semi-external algorithms 23 an d  2 6  are introduced in details in Section III Other than the problem of 336nding time based on DFS 12  A naive way to externalize the internal DFS algorithm requires s Such an algorithm may end up an in\336nite loop and cannot compute all  33\(2 2001  H  Y ildir im  V  C haoji and M  J  Z aki Grail Scalable reachability index for large graphs s repeatedly until the graph 336ts in memory then an internal memory algorithm is used to 336nd the 336nal sor DFS tree on external directed graphs several problems in the external memory model are studied in the literature Dementiev et al 14 p ro vi de an i m pl ement a t i o n o f a n e xt ernal m emory minimum spanning tree algorithm based on the ideas of 22 which performs extremely well in practice even though theoretically inferior to the algorithms of 1   1 0   A jw an i e t al 4 6  propos e i mpl e ment at i ons of e x t e rnal undi rect ed breadth-\336rst search algorithm with the idea from 18 Ul rich Meyer et al 20 21  19  des i gn and i mpl e ment pract i c al I/O-ef\336cient single source shortest paths algorithm on general undirected sparse graphs Surveys about designing I/O ef\336cient algorithms for massive graphs can be found at 24 5  X C ONCLUSIONS In this paper we study I/O ef\336cient algorithms to 336nd all  3\(1 2010  J  Hellings  G  H  F letcher  and H  H averkort Ef\336cient external-memory bisimulation on dags In  3\(1 2010  Z  Z h ang J  X Y u  L  Q in L  C hang a nd X L i n I/O e f 336 cient Computing sccs in massive graphs In scan by maintaining the list of nodes that should not be traversed using tournament trees 17 and b uf fered repos i t o ry t rees 8  respectively Despite their theoretical guarantees these algorithms are considered impractic al for general directed graphs that encountered in real applications Cosgaya-Lozano and Zeh 13 p res e nt a c ont ract i o n b as ed al gori t h m w hi ch cont ract s V M E B V B 2 are similar as stated in Exp-2 IX R ELATED W ORK Finding strongly connected components of a directed graph V G V G E G E V E E V E  14\(1 1985  T  H  Cor m en C  S tein R  L  R i v es t and C  E  L eis e r s on  2003  U Me yer a nd N Z e h I/O-ef 336c ient undirected shortest paths with unbounded edge lengths In s Both DFS based algorithm 8 and c ont ract i o n b as ed algorithm 13 a re i n t roduced i n det a i l s i n S e ct i o n III In addition to external algorithms there are semi-external algorithms for ACM Comput Surv Introduction to Algorithms IFIP TCS         Proc of ESA\22202 Proc of ESA\22206 SIAM J Comput Commun ACM Proc of SIGMOD\22213  32\(3 2002 2 A  A ggar w a l a nd J  S  V itter  T h e i nput/output com p le xity of s o r ting and related problems  31\(9 1988  A  V  A ho J  E  Hopcroft a nd J  D Ullm an I/Os Chiang et al 10 propos e a n a l gori t h m with I/O complexity  Addison-Wesley 1983 4 D  A jw ani R D e m e ntie v  and U  M e y er  A com putational s tudy of external-memory bfs algorithms In  2006  D  A jw ani a nd U Me yer   6\(1 2011  A  L  Buchs baum  M  H  G oldw a sser S Venkatasubramanian and J Westbrook On external memory graph traversal In  2002  J  S  V itter  E x ter n al m e m o r y algor ithm s and d ata s tr uctur e s   2007 7 E  A ngel R Cam p igotto a nd C L a f o r e s t  A nalys i s a nd com p ar is on of three algorithms for the vertex cover problem on large graphs with low memory capacities  1995  N  Chiba a nd T  N i s h izeki A r bor icity and s ubgr aph lis ting algor ithm s   2009  R Dem e ntie v  P  Sanders  D  S chultes  and J  F  S ibe y n E ngineering an external memory minimum spanning tree algorithm In  2012  V  K u m a r a nd E  J  Schw abe Im pro v e d a lgorithm s and d ata s tructures for solving graph problems in external memory In  2002  U  M e yer a nd V  O s ipo v  D es ign a nd im plem entation o f a pr actical i/o-ef\336cient shortest paths algorithm In  2009  U Me yer a nd N Z e h I/O-ef 336c ient undirected shortest paths In  2006  J  F  S i be yn E x ter n al connected com p onents  I n  2013 A CKNOWLEDGMENT  Algorithmic Operations Research          267        and computation which assume that all nodes of the graph can 336t in the main memory Sibeyn et al 23 propose a semi-external DFS  which can be used to 336nd all og  pages 457\320468 2012  Y  J  C hiang M T  Goodrich E  F  Gro v e  R  T am as s i a D E  V e ngrof f and J S Vitter External-memory graph algorithms In  Proc of ALENEX\22207 Proc of SIGMOD\22212 Proc of SODA\22295 Proc of SEA\22209 PVLDB Proc of ALENEX\22209 Proc of ESA\22203 PVLDB                    McGraw-Hill 2001  A  Cos g ayaL o zano a nd N  Z e h A h eur i s tic s t r o ng connecti vity algorithm for large graphs In Algorithmica LargeProc of SPAA\22202 G O O O O Algorithmics of Large and Complex Networks Data Structures and Algorithms SCC SCC SCC SCC SCC SCC SCC SCC SCC SCC SCC  Later Kumar and Schwabe 17 a nd B u chs b aum e t a l  8  i mprove the I/O complexity to  chapter 1 Design and Engineering of External Memory Traversal Algorithms for General Graphs Springer 2009  D  A jw ani U Me yer  and V  O s i po v  Im pro v e d e xternal m em ory b fs implementation In  2000  J  Cheng Y  K e  S  Chu and C Cheng E f 336 cient p roces s i ng of distance queries in large graphs a vertex cover approach In  2004  W  F a n J  L i  S  M a H W a ng and Y  W u Graph hom om orphis m revisited for graph matching  1996  K Mehlhorn a nd U Me yer  E xtern al-memory breadth-\336rst search with sublinear i/o In  2004  J  F  Sibe yn J  Abello a nd U Me ye r Heuristics for semi-external depth 336rst search on directed graphs In Proc of SWAT\22204  and SmallProc of SODA\22206 Proc of SODA\22200 219 Proc of SPDP\22296 Proc of SIGMOD\22212 


                  


             


 





 17  Jar r e n  A   B al d w i n  is  a  Ch i c a g o  n a t i v e  a n d  c u r r e n t l y  se r v e s a s t h e  l e a d  E l e c t r i c a l  En g i n e e r  a t  B a y  A r e a  s t a r t u p   Oc u l e v e  I n c   He  g r a d u a t e d  fr o m  t h e  U n i v e r s i t y  o f Il l i n o i s  wi t h  a  B  S   i n  2 0 0 9  an d  r ecei v ed  an  M  S   i n  El e c t r i c a l  En g i n e e r i n g  f r  St a n f o r d  U n i v e r s i t y  i n  2 0 1 2   Ja r r e n  d e v e l o p e d  h a r d w a r e  a n d  so f t w a r e  sy st e m s f o r  a  w i d e  ra n g e  o f  f i e l d s   i n c l u d i n g  s p a c e  s c i e n c e  s y s t e m s  a n d  m e d i c a l  de vi c e s  a s  a N A S A  A m es  i nt e r n i n t he  In t e l l i g e n t  S y s t e m s     1  2  3   4   5   6   7   8   9   10   11   12   13   


                        


                           


   












































     2 8    b 4      1 8             1 2     1  8 2  


1 9    8      2 1       1     2    8    2 3\f        


     8 D 4 9  F  \b 1 8 #J 9 1     2 1   2 #-@ 1   2 9  E 1   1   2 9      6  


    8  8   1  D 1         1 F  \b0         2 D    F  \b 1 8  9  


  1 9  1   E 1  2 9     1 1 F  \b       1    18   F   1    1 #-$+  \b  2 2  


1 D     1 #-$+.B- 0/:% .0             9 1      18    1 6     1 2  1  1  


1   6      2    1 2 E 8 D 1      1 2   1   1 #-4  #-@E     2  1  1  1       


 8     1          2 F    6   F  2   8    2 C<CC/C N\bO 5      


CD    b$44NO F P Q 6   2 b$$$ ,=\b\bA  A N,O 2 C C  b$$4N  92 2   f  9-\b$$4 B N?O  !-    91  2 1 HH111-18-N+O    -1 :3%   2     0-4 


     b N4O 2   2- \f  C b$@$ \b# >\b\b$3\b$N@O  f :.% 9 /9 \f    1  6  f 2  4   A254 


Advantages of Our M ethod Advantages of Our M ethod Exploit the memory v ertical data format utilizes slidin g windows to g form a much larger database to analyze  Flexibility in Choosing what to choose  Choosing what to choose to build the rules Computational and memory efficiency We have a team working only on this aspect 45 Associative IDS for NextGen Frameworks Dr S Dua LA Tech 45 


Preliminary Results Intra transaction Relations Data rate simulator NH-134 Mb HOP PATH update \(Y/N Inference 11.5 Y Y 2 0.120 N N      Y   n 0.345 N NH134 Y/N   Inf 1 0.150 N N 2 0 120 Y N Inter transaction Relations 2 0  120 Y N       5 5.55 0.456 Y Relations  n 0.345 N N Nmap on DMRL nmap.org 


Anticipated Outcome Anticipated Outcome Develop algorithm capable of learning from a given heterogeneous diverse Develop algorithm capable of learning from a given heterogeneous diverse data ff Dynamic algorithmic f ramework designed to shi f t modalities and sampling rates based on complex logic Flexibility of integration into the Snort intrusion detection system 47 Associative IDS for NextGen Frameworks Dr S Dua LA Tech 47 


References References Aircraft Cockpit Image courtesy USAF http://www.faa.gov htt p   www.faa g ov  air traffic  technolo gy  p g  _ gy  Acharya R Dua S Du X Sree V Chua C K Automated Diagnosis of Glaucoma Using Texture and Higher Order Spectra Features To appear in IEEE Transactions on Information Technology in Biomedicine  Du X Dua S 2011 Cancer Prognosis Using Support Vector Regression in Imaging  Modality World Journal of Clinical Oncology 2  1   44 49 Du X Dua S 2010 Salient Frame Extraction Using Support Vector Regression and Motion Features pp 5 Proc of the National Aerospace and Electronics Conference July 14 16 2010 D M P D S 2010 Di i i ti Ft d Cl ifi ti Mthd f D essaue r  M  P  D ua S  2010  Di scr i m i na ti ve F ea t ures an d Cl ass ifi ca ti on M e th o d s f or Accurate Classification 1st ed vol 7704 pp 14 Bellingham WA Proceedings of SPIE Dessauer M P Dua S 2010 Low Resolution Vehicle Tracking using Dense and Reduced Local Gradient Features Maps 1st ed vol 7694 pp 8 Bellingham WA Proceedings of SPIE SPIE 


Acknowledgements Acknowledgements Fundin g A g encies  US 4 1 Million direct fundin g g g 4 g LA BoR NIH NSF AFRL AFOSR and NASA Research Team Samuel Kasimalla Brandy McKnight Dr Pradeep Chowriappa Connor Johnson Vasanth Nair Mihir Chowriappa  Connor Johnson  Vasanth Nair  Mihir Karnik Mohit Jain and Swadheen Songmen Associative IDS for NextGen Frameworks Dr S Dua LA Tech 49 All the respective Logos belong to their owners 


Rf d Rdi R e f erence d R ea di ngs Copyright of cover pages held by respective publishers 


Thank You Questions Thank You  Questions Dr Sumeet Dua E mail sdua@latech.edu Web http://dmrl.latech.edu Associative IDS for NextGen Frameworks Frameworks Dr S Dua LA Tech 51 Image Source roadtrafficsigns.com 


