Abstract 
  
Xiaoyi Lu Fan Liang Bing Wang Li Zha and Zhiwei Xu 
Institute of Computing Technology Chinese Academy of Sciences 
DataMPI Extending MPI to Hadoop-like Big Data Computing 
MPI has been widely used in High Performance Computing In contrast such efìcient communication support is lacking in the eld of Big Data Computing where communication is realized by time consuming techniques such as HTTP/RPC This paper takes a step in bridging these two elds by extending MPI to support Hadoop-like Big 
luxiaoyi liangfan wangbing char zxu ict.ac.cn 
Data Computing jobs where processing and communication of a large number of key-value pair instances are needed through distributed computation models such as MapReduce Iteration and Streaming We abstract the characteristics of key-value communication patterns into a bipartite communication model which reveals four distinctions from MPI Dichotomic Dynamic Data-centric and Diversiìed features Utilizing this model we propose the speciìcation of a minimalistic extension to MPI An open source communication library DataMPI is developed to implement this speciìcation Performance experiments show that DataMPI has signiìcant advantages in performance and exibility while maintaining 
high productivity scalability and fault tolerance of Hadoop 
Keywords 
MPI Hadoop MapReduce Big Data DataMPI 
I I NTRODUCTION Message Passing Interface MPI has been widely used in the eld of High Performance Computing This includes the MPI speciìcations and v arious MPI implementations such as MPICH MV APICH 3 and Open MPI 4 MPI not only enables fast communication but also provides a standard interface facilitating the development of parallel and distributed application programs in a portable way Recently Big Data has attracted much attention in the IT industry and academic communities Much work has been done on Big Data Computing models and systems such 
as MapReduce MapReduce Online 6 T wister 7 Dryad Spark 9 and S4 10 In the open-source community Hadoop is a widely used implementation of the MapReduce model for Big Data These systems have one commonality they feature the processing and communication of a large number of key-value pair instances We call such systems Hadoop-like Big Data Computing systems or Big Data Computing systems for short Differing from the HPC eld such Big Data Computing systems lack efìcient communication support such as MPI Instead communication is realized by time consuming techniques such as HTTP RPC This paper takes a step in bridging these two elds by extending MPI to support 
Hadoop-like Big Data Computing jobs so that knowledge This research is supported in part by the Strategic Priority Program of Chinese Academy of Sciences Grant No XDA06010401 the Guangdong Talents Program the Hi-Tech Research and Development 863 Program of China Grant No 2013AA01A209 2013AA01A213 and techniques from the HPC eld can be transferred to the Big Data Computing eld For example many optimized MPI communication techniques on different networks e.g InìniBand and 1/10GigE developed for HPC can be utilized by Big Data Computing applications 
An obvious starting point for this line of research is to extend MPI for Big Data reusing MPI abstractions 
A Motivation 
mechanisms and operations However we should rst assess how much performance improvement we can attain by extending MPI to Big Data As mentioned above the communication mechanisms involving HTTP and RPC are commonly used in different types of network interactions in Hadoop like Hadoop RPC calls among different components and MapReduce Shufîe The achievable peak bandwidth and RPC latency are the two most important indicators to show the performance improvement potential from the basic communication primitive level Compared with MPI communication primitives the performance of Hadoop communication primitives is low Figure 1\(a shows the comparison of achieved peak bandwidths for three systems Hadoop 
HTTP Jetty our proposed DataMPI and MVAPICH2 on three networks IB/IPoIB 10GigE and 1GigE The peak bandwidth is measured by varying both total data size and packet size As we can see DataMPI and MVAPICH2 drive bandwidth more than twice as Hadoop Jetty on the networks of IB/IPoIB and 10GigE DataMPI and MVAPICH2 use network more efìciently than Hadoop Jetty even on 1GigE The bandwidth of DataMPI is slightly lower than that of MVAPICH2 This is because the Java binding See Section IV of DataMPI introduces some minor overheads in the JVM layer We further implement an RPC system based on DataMPI by using the same data serialization mechanism as default Hadoop RPC Then we can use similar benchmarks 
to measure the performance of our DataMPI RPC and default Hadoop RPC Figure 1\(b shows the latency comparison between them When the payload size ranges from 1 B to 4 KB the latency of DataMPI RPC is better than that of Hadoop RPC up to 18 on 1GigE 32 on 10GigE and 55 on IB From these comparisons we can see that our proposed DataMPI can provide much better performance than Hadoop in the primitive-level communication which means the performance improvement potential of extending MPI to Big Data is attractive Even though we can get good performance improve 
2014 IEEE 28th International Parallel & Distributed Processing Symposium 1530-2075/14 $31.00 © 2014 IEEE DOI 10.1109/IPDPS.2014.90 829 


 
0  50  100  150  200  250  1   2   4   8   16   32   64   128   256   512   1024   2048   409 6 RPC Latency \(ms Payload Size \(byte Hadoop-1GigE Hadoop-10GigE Hadoop-IPoIB \(16Gbps DataMPI-1GigE DataMPI-10GigE DataMPI-IB \(16Gbps 
The main contributions of this paper are 1 Abstracting the requirements of a 4D Dichotomic Dynamic Data-centric and Diversiìed bipartite communication model and key-value pair based communication which capture the essential communication characteristics of Hadoop-like Big Data Computing 2 Proposing a simple programming speciìcation to extend MPI to Big Data Several representative Big Data benchmarks WordCount TeraSort PageRank K-means  T op-K are used to sho w that our extension is easy to use and exible 3 Presenting a novel design of high-performance communication library called DataMPI for Big Data Computing Performance evaluations on testbeds show that our library can achieve signiìcant better performance on a variety of workloads The rest of this paper is organized as follows Section II discusses Big Data communication characteristics Section III introduces our proposed extensions Section IV presents our library design Section V describes our experiments and evaluation Section VI discusses related work Section VII offers concluding remarks and future work II C OMMUNICATION C HARACTERISTICS OF B IG D ATA By the analysis on Hadoop MapReduce we abstract the essential communication characteristics of Big Data Computing systems in this section From the perspective of task management and data movement we can nd that the MapReduce framework sustains independence among map tasks and also makes no data exchange among reduce tasks The data is moved from one set of tasks maps to the other set reduces This paradigm can be represented as a bipartite graph which is constructed by two groups of tasks and the data movements between them As shown in Figure 2 the intermediate data moves from the tasks in Communicator O Operation to those in Communicator A Aggregation In fact if we analyze the execution paradigms of other Hadoop-like Big Data Computing systems e.g Dryad S4 we will nd that the bipartite communication model is also concealed in the intermediate processing steps or stages of those systems Through analyzing Hadoop MapReduce and other Big Data systems we can further identify the 4D communication characteristics from the bipartite model  The MapReduce and other Big Data systems show that communications happen between two communicators The underlying communication is a bipartite graph i.e the processes are dichotomic and belong to either the O communicator or the A communicator  Big Data communication has a dynamic characteristic which means the number of concurrent running tasks in each communicator of Figure 2 often changes dynamically because of task nish and launch This indicates we usually do not explicitly assign a destination to the emitted data and it will be automatically distributed by the system For example when we write a map function in a MapReduce program we only need to emit the processed data but do not assign a destination reduce for it Even though we want 
B Contributions A A 4D Bipartite Communication Model 
0  500  1000  1500   2000  2500   IB/IPoIB\(16Gbps   10GigE  1GigE BandWidth \(MB/sec N et w o rk s Hadoop Jetty DataMPI MVAPICH2 
Dichotomic Dynamic 
a Peak Bandwidth higher is better  b RPC Latency lower is better Figure 1 Performance Improvement Potentials of Hadoop Communication Primitives by Using MPI ments in basic communication primitives it is still full of challenges to extend MPI to real Big Data applications One main reason is that the buffer-to-buffer communication model of MPI does not t the key-value communication patterns of Big Data This paper o v ercomes these challenges by carefully analyzing the open-source codes of three representative Big Data Computing workload models Hadoop the MapReduce model PageRank the Iteration model and S4 the Streaming model We focus on presenting the detailed analysis of Hadoop but will also present evaluation results for the Iteration and the Streaming benchmarks This paper addresses the following issues 1 What main characteristics can we abstract to help design Big Data communication facilities 2 How can we extend MPI to Hadoop-like Big Data Computing in a minimalistic way And how can we design a high-performance communication library to implement our proposed extensions 3 How much performance improvement can be obtained by our library over different Big Data processing workloads Can the primitive level performance beneìts be really achieved in the application level 
830 


Figure 2 The Bipartite Communication Model to assign the destination it may cause confusion because the assigned destination task may not be launched yet In this case it is a wise choice to schedule the data movement by the system or communication library implicitly just like Hadoop hiding the communication details in the framework 
Common MapReduce Iteration Streaming B Key-Value Pair based Communication A Programming Speciìcation key value 
002\003\004\004\005\006\007\010\011\012\003\013\014\015 002\003\004\004\005\006\007\010\011\012\003\013\014\016 015 017 015 020 015 006 016 017 016 020 016 004  
 Jim Grayês Laws tell us we should move computations to the data rather than data to the computations in Big Data Computing Such principle can be found in the most popular Big Data Computing models and systems We also observed the data-centric characteristic from our bipartite model As shown in Figure 2 tasks in Communicator O emit their data while tasks in Communicator A can be scheduled to the corresponding data locations to process them However in current Hadoop MapReduce most of the maps load data locally from HDFS but the data locality feature is not designed for reduces In fact the miss of data locality in reduces is also discussed by the recent studies 16 W e will further discuss this in Section IV B  Although we can nd many similar communication behaviors among different Big Data Computing systems there still exists diversities For MapReduce applications the arrows of data movements in Figure 2 are dense and the model is a complete bipartite graph For applications in Dryad or S4 the arrows of data movements may not be dense and Figure 2 becomes a more sparse bipartite graph In addition the intermediate data processing steps in different Big Data Computing scenarios are also diversiìed Such characteristic indicates Big Data Computing has diversiìed communication modes In this paper we summarize four kinds of modes of Big Data Computing which are    and  From the perspective of programming we can observe that many Big Data Computing systems e.g Hadoop MapReduce S4 HBase choose key-value pair as the core data representation structure which is simple but has a strong ability to carry rich information Therefore it is a good idea to provide key-value pair based communication interfaces for Big Data Computing systems and applications but not the traditional buffer-to-buffer interface signature Such high level interface abstraction can reduce much programming complexity in parallel Big Data applications III P ROPOSED E XTENSIONS Based on the above abstractions this section presents our proposed MPI extensions As shown in Table I and Table II the extended functions are categorized into two sets Table I summarizes three pairs of basic library functions for Big Data applications Due to the dichotomic feature of the bipartite model two build-in communicators    are introduced to organize the parallel execution of tasks For different tasks the corresponding communicator will be initialized by the function call and they are nalized by invoking  We highlight two parameters  and f  They are used to support the diversiìed modes of Big Data communication Currently we have deìned four kinds of modes The mode is used to support SPMD-style programming and execution just like traditional MPI programs The mode is devised based on the mode to support MPMD-style MapReduce applications The mode is used to process real-time data streams The mode is for supporting iterative computations Each mode deìnes a group of conìgurations The advanced users can deìne their own conìgurations and transfer them to by the parameter A set of reserved keys for conìgurations are also deìned Due to the space limitation we just show two commonly used keys and  which are used to deìne data types for and  Note that the implementations can choose their preferred approaches to handle serialization issues In addition a pair of naming functions is needed for applications is used to get the rank of task in different communicators of the bipartite model returns the total number of tasks in Communicator O or A According to the observation of key-value pair based communication requirement we propose two functions  and  to exchange key-value pairs among tasks As discussed in Section II-A due to the dynamic feature these two proposed communication functions do not require applications to assign destinations in interfaces It means the library should schedule the data movement implicitly The library should also satisfy the data-centric characteristic when moving data These functions can help applications to achieve both productivity and high performance Table II lists three optional user-deìned functions for exibility  due to the requirement of sorting key-value pairs in some modes the key should be 
D 1  D 2      D m      Future Task Current Task Finished Task Data Movement  Task Movement  Intermediate Data 
Data-centric Diversiìed 
COMM_BIPARTITE_O COMM_BIPARTITE_A MPI_D_INIT MPI_D_FINALIZE mode conf MPI_D_INIT Common MapReduce Common Streaming Iteration MPI_D_INIT conf KEY_CLASS VALUE_CLASS MPI_D_COMM_RANK MPI_D_COMM_SIZE MPI_D_SEND MPI_D_RECV MPI_D_COMPARE 
831 


010\004\003\015\027 010\004\003\015\027 
   002 002 002     002          
037\016 \013\010!"\015\004\013\020 011\012\004#$\011\012\004 015\004\026\013 024\037 002\037 
024\013\004\025\017\026\027 030\031\016\032\011 030\033\031\016\032\011 007\014\034\016\014\016\035\003\014\036 005\006\007   021\013\014\010\005\006\007 010\004\003\015\027 010\004\003\015\027 
public class public static void try int new class class if null if null for int else if null while null catch 
002\003\004 005\006\007\010\011\012 013\014\015\012 016\015\014\017\010\020\012 
Table I E XTENDED L IBRARY F UNCTIONS Function Parameter Action MPI D INIT In args mode conf init env MPI D FINALIZE void nalize env MPI D COMM SIZE In comm Out size get size of tasks MPI D COMM RANK In comm Out rank get rank of task MPI D SEND In key value send KV MPI D RECV Out key value receive KV Table II O PTIONAL U SER DEFINED F UNCTIONS Function Parameter Action MPI D COMPARE In k1 k2 Out res compare keys MPI D PARTITION In k v comm Out dest partition KV MPI D COMBINE In k ivs Out ovs combine KVs comparable Applications can provide this function to tell the library how to compare the keys 2 3 4 11  Get rank and size 12 22 27  Users can do any computation logic here and store KVs to their 31 32  Finalize 33 35 37 38 Figure 3 Architecture Overview of DataMPI 
     5     6          7          8  Init 9        10          13      14  Users can load KVs from their preferred sources 15      16  Users can do any computation logic here 17    18  0    19  Send 20      21          23      24  Receive 25     26    preferred destinations 28     29    30   34     36 
MPI_D_PARTITION MPI_D_COMBINE Serializable Writable 
002\003\004\005\006\003\007\010\011\006\003\005\003\012\003\007 013\014\004\005\015\016\017\010\002\003\004\005\017\020\005 021\017\022\010\023\010\024\025\007\014\017\010\011\025\015\006\010\026\006\025\004\027\016\015\027\027\015\003\004 030\025\005\025\031\011\032\010\013\011\002\010\033\017\006\034\017\006 035\010\005\025\027\036 037\010\005\025\027\036 030\025\005\025\031\011\032\010\013\011\002\010\002\007\015\017\004\005 031\025 \013\017!\014\012\017 032\005\017\006\025\005\015\003\004 033\005\006\017\025\016\015\004 002\003\016\016\003\004 025\014\007\005 026\003\007\017\006\025\004\012\017 
002\003\004\003\005\006\007\010\011\012\004\013\014\015\016\017\014\015\010\017\014\010\020\021\016\022\003\023\003 
014\015\016\015\017\020\013\021 020\006\022\023\024\025\025  
 this function is used to deìne the distribution policy of key-value pairs from one communicator to the other The implementation should at least provide a default policy e.g hash-modulo Applications can also deìne this function to override the default behavior  applications can provide this function to combine the intermediate data for reducing the size of exchanged data Listing 1 Example of Sort in the Common Mode 1 Listing 1 shows a simple example of sorting in the Common mode This example is based on the Java-binding In order to integrate and fairly compare with Hadoop MapReduce which is Java-based we choose to implement the Javabinding of our proposed extensions rstly Our implementation of the Common mode contains default values for all required conìgurations so that this example does not need to deìne optional functions Our Java-binding can support the serialization mechanisms of both Java  and primitives and Hadoop   currently From this parallel sort example we can see that the major part only contains 38 lines which demonstrates our proposed extensions are easy-to-program As our evaluations Section V show such a simple example is scalable on both varied data sizes and cluster sizes IV T HE D ATA MPI L IBRARY I MPLEMENTATION This section presents our implementation called DataMPI  of the bipartite communication model and the proposed extensions to MPI Figure 3 shows the two-layer architecture of DataMPI In the JVM layer DataMPI extends the mpiJava design The major extensions include dynamic process management DPM in the Java layer optimized buffer management by native direct IO the implementation of our proposed speciìcation bug xes etc The lower layer is the native layer in which we utilize JNI to connect upper Java-based routines to native MPI libraries Compared with Hadoop DataMPI provides a more light-weight and exible library to users For example many HPC clusters do not have many local disks to build a big capacity HDFS storage while what they often have are NFS Parallel File System e.g Lustre etc Regarding these hosting environments DataMPI can support applications to choose different storage systems exibly By utilizing the portable MPI standard DataMPI can efìciently run Big Data applications over different high performance networks We further introduce the important DataMPI components as follows 
B A Simple Example of Sorting A Architecture Overview 
Sort main String args rank size HashMap String String conf HashMap String String conf put MPI_D_Constants KEY_CLASS java lang String getName conf put MPI_D_Constants VALUE_CLASS java lang String getName MPI_D Init args MPI_D Mode Common conf MPI_D COMM_BIPARTITE_O rank MPI_D Comm_rank MPI_D COMM_BIPARTITE_O size MPI_D Comm_size MPI_D COMM_BIPARTITE_O String keys loadKeys rank size keys i i keys length i MPI_D Send keys i  MPI_D COMM_BIPARTITE_A rank MPI_D Comm_rank MPI_D COMM_BIPARTITE_A size MPI_D Comm_size MPI_D COMM_BIPARTITE_A Object keyValue MPI_D Recv keyValue outputKeyValue rank keyValue keyValue keyValue MPI_D Recv MPI_D Finalize MPI_D_Exception e e printStackTrace 
   002  002 002  002 
002\003\004\005\006\007\010 011\012\013 
002\003\004\003\005\006\007  
832 


026\004\002\024 
002 
Figure 4 Communicator and Process Management  Task Scheduling Figure 5 Overlapping Comparison of Hadoop and DataMPI 
037\016\026\015\004\010,\010-\005\003\021.\010\037\016\014\016\015 004\003\026\004 005\013\026\032\013 005 005 032  010-0\013\036'1\013.\010 010-\005\003\021.\010 003\036\017\017\021  002\003\004\003\005\006\007 
mpidrun Proìle Core Runtime Execution Data-centric Task Scheduling 
mpidrun mpidrun  mpidrun f hostfile O n A m M mode jar jarname classname params mpidrun mpidrun mpidrun M mode mpidrun mpidrun mpidrun mpidrun mpidrun MPI_D_INIT COMM_BIPARTITE_O MPI_D_RANK MPI_D_SIZE MPI_D_SEND mpidrun MPI_D_RECV 
A program is designed as a job launcher and scheduler It supports the 4D features of the bipartite model Support Dichotomic launches an application through a command like 1 Then a group of DataMPI processes will be launched separates all tasks into two queues for communicator O  A for further scheduling Support Dynamic schedules tasks to run on processes controls their executions manages namespaces without conîicts etc Support Data-centric schedules tasks in communicator O  A to the relevant processes to load data from local when the data is ready Support Diversiìed the parameter of   can be used to change the runtime behavior for different communication modes  Each communication mode has a kind of proìle which contains a set of typical conìgurations and related extensions to the DataMPI core For example the MapReduce mode requires the intermediate data to be sorted by keys while the Streaming mode may not need this feature The Iteration mode needs the communication to be bi-directional which means the data can be moved from O tasks to A tasks and vice versa However the MapReduce mode only needs one-way communication The typical features of each mode should be deìned in the proìle And the related extensions can be loaded by the core component  By abstracting common functions of different modes we design a core component in DataMPI which supports functionalities of control protocol runtime context keyvalue pair transmission and fault tolerance Each mode can work on a certain proìle hold a runtime context for current proìle use the corresponding protocol to control the task execution and transfer intermediate data as key-value pairs The details will be further discussed in following sections  Figure 4 shows the interactions among  DataMPI processes and tasks When the application is launched will spawn DataMPI working processes These processes are in the same intracommunicator while they are also connected with their parent  by an intercommunicator DataMPI uses this intercommunicator to build up an RPC communication channel for exchanging control messages between working processes and  After all processes are launched they will receive and execute tasks scheduled by  As shown in Listing 1 when tasks execute  this function will initialize the execution environment In this step if the tasks are O tasks will be created Similar things will be done for A tasks In userdeìned logic we can use and to do the problem decomposition as what we commonly do in traditional MPI programs  Hadoop MapReduce provides the data-local feature for maps but not for reduces Current Hadoop architecture adopts a two-phase and proxybased data movement approach Firstly each map task writes the intermediate data to local disk then each reduce task downloads the data from different maps by the proxies which are the built-in HTTP servers in TaskTrackers Such design is hard to achieve data locality for reduces because the outputs of maps are distributed over the whole cluster A basic idea for improvement is before reduces are launched can we collect the intermediate data for them in advance If yes then the reduce-side data locality can be achieved by task scheduling Regarding this DataMPI provides a data-centric task scheduling design With HDFS a utility function is designed to locally load data from HDFS for O tasks by their ranks and the communicator size During the executions of O tasks their intermediate data will be sent out by  The emitted data is partitioned and stored among the processes local accessible spaces in memory or spilling to disk After the O phase is nished the processes will run A tasks also knows the information of the intermediate data distribution so it can directly schedule A tasks to the corresponding processes to read their data locally by  In this way our proposed design can guarantee the data-local feature for both O and A tasks As shown in Figure 4 an application has four O tasks and two A tasks After nishing O tasks two A tasks are scheduled to the two corresponding processes which already have the intermediate data 
002 
B Runtime Execution and Data-centric Task Scheduling 
833 


 030  2   006 030 006 2 006  030  010 033 030 030 006 030 006 2 006  030  010 033 030 030 006 030 006 2 006  030  010 033 030 030 006 030 006 2 006  030  010 033 030 030 006\026\0171\013\015\015\030 006\026\0171\013\015\0152 006\026\0171\013\015\015 006\026\0171\013\015\015  010 006  006  006  006  006 2 006 2 006 2 006 2 006 030 006 030 006 030 006 030 006 0063 0\006     030  2          2 006 030 006 2 006  2 030 006  030 006 030 006 2 006  2 030 006  030 006 030 006 2 006  2 030 006  030 006\026\0171\013\015\015\030 006\026\0171\013\015\0152 006\026\0171\013\015\015  030 006  006  006  006  006  006  006 2 006 030 006 2 006 030 006 2 006 030 006 0063 0\006    030  2   
NUM  NUM NUM NUM NUM  NUM 
006 0063 0\006 006 030 006 2 006  030 030 030 006 030 006 2 006  030 030 030 006 030 006 2 006  030 030 030  030  2   006\026\0171\013\015\015\030 006\026\0171\013\015\0152 006\026\0171\013\015\015 006 030 006 030 006 030 006 2 006 2 006 2 006  006  006    030  2   
MPI_D_Partition 
As shown in Figure 5 Hadoop MapReduce overlaps map and shufîe copy and merge stages but it does not launch reducers to copy data remotely until the rst map is nished at least The shufîe stage in reducers often lags behind all nished maps because the reducers need to pull map completion events copy data remotely and merge them totally As a result such kind of overlapping design in Hadoop will make the execution of reduce function signiìcantly delayed and the performance degraded DataMPI adopts an alternative design of O-side Mapside data shufîe pipeline Each process initialized for an O task has three kinds of threads The main thread will do the computation and send the key-value pairs to the communication thread The communication thread will partition sort if needed and save the key-value pairs to appropriate buffers When the size of buffered data exceeds a threshold the communication thread will send the data to corresponding processes while it also receives data from other processes For received data another thread is responsible for merging them In this way the computation copy and merge are fully overlapped by multi-threading Since DataMPI caches the intermediate data in memory by default and exchanges the data by high efìcient MPI communication it improves the O phase performance See Section V-C The O-side shufîe beneìt is due to the help from the MPI-based bipartite communication model Figure 5 shows DataMPI achieves better performance and more overlapping in O-side By shufîing in O-side A tasks can be executed in data-local and this further improves the overall performance consequently From the perspective of communication pattern the communication operations in the bipartite model can be seen as an relaxed all-to-all pattern globally For supporting MPI point-to-point and collective based communication we design a Partition List PL based buffer management scheme One partition list is composed by several data partitions which are used to store key-value pairs for corresponding A tasks The data partition also contains multiple kinds of meta information such as key-value offsets indexes etc When a key-value pair is emitted it is rst cached in a selected partition from Send Partition List SPL according to the function When an SPL is full it will be inserted to a send queue to wait for transferring by the For traditional MPI applications we usually implement fault tolerance by application/library/system-level checkpoint/restart Different with buffer-to-buffer communication interfaces our proposed key-value pair based interfaces are also helpful for the fault tolerance design As a core data structure in Hadoop-like Big Data systems a key-value pair is usually considered as an intact business record When applications send key-value pairs by our proposed interface we can know what data should be checkpointed and how many records have been checkpointed when we do recovery In this way DataMPI provides a key-value pair based library level checkpoint mechanism which is transparent to deterministic algorithm based Big Data applications As Figure 7 
 
0\013 \017\003\036\0104\010!\027\016\021\010 006\013\026\015\016\015\004\013\014\004\0100\0131\017\026\036\015 020\021\016\036\026'\014 5\030 52 5 022\0176\0100\013\015\004\003\026\004        031 \0176\003 7  27 7 0307 27 7 0307 27 0307 9$*\010\021\003\016\026\015 9$*\010\021\003\016\026\015    
O A  O A O A 
C O-side Map-side Data Shufîe Pipeline D Buffer Management and Communication Optimization E Key-Value based Library Level Checkpoint 
a b c Figure 6 Buffer Management and Communication in DataMPI SPL Send Partition List RPL Receive Partition List PW Partition Window Figure 7 Overview of DataMPI Fault Tolerance communication thread On the receiver side the received data is cached in a Receive Partition List RPL which will be added to a merge queue When the total size of merge queue is over a threshold some of the cached RPLs are merged and spilled over to in-memory buffer or disk The partition lists make buffer layout clear easy-to-program and support both all-to-all or point-to-point communication Note that the MPI communication happens in processlevel which may have mismatches with task-level data movements Figure 6 shows three different cases of O/A task numbers In different cases the data partitions may be moved to different processes It is fussy and errorprone especially when tasks are dynamically launched and exited To control the buffers offsets and lengths easily we introduce a structure of Partition Window PW to redirect partitions to different processes Through PW we can reduce the complexity of buffer management All of above techniques are transparent for applications which just need to use our proposed send/receive interfaces to achieve high performance and productivity 
834 


shows each task makes the checkpoint CP separably after a round of data exchanging When a job recovers all processes can coordinate with each other to get the global maximum checkpoint number among all successfully generated checkpoints and skip those processed records DataMPI provides an option to enable fault tolerance FT support V E VALUATION This section presents the evaluations of DataMPI We use two different testbeds for our evaluations  Testbed A has 17 nodes connected with 1 GigE Each node is equipped with dual octa-core 2.1 GHz AMD Opteron\(TM processors 64 GB RAM and single 500 GB HDD Each node runs Linux 2.6.18-128.el5  65 nodes in Testbed B are equipped with Intel Xeon dual quad-core processors operating at 2.67 GHz Each node has 12 GB RAM a 1 GigE NIC and single HDD less than 80 GB free space Each node runs 2.6.32-358.el6 Each testbed has one master node and the rest nodes are slaves Most of our tests are taken on Testbed A while the scalability tests are conducted on Testbed B We compare DataMPI performance with Hadoop 1.2.1 We use MVAPICH2 1.9 as the native MPI library We store all the input/output data on HDFS We use DataMPI to implement all the benchmarks e.g TeraSort PageRank K-means for comparisons Hadoop PageRank is self-developed and Hadoop K-means is chosen from Mahout 0.8 Both Hadoop and DataMPI have many tunable parameters Since we only have single HDD per node in our testbeds the disk will easily become the bottleneck when we test with larger data size HDFS block size and concurrent task number are the two most important performance parameters We use TeraSort to tune both of them on Testbed A As shown in Figure 8\(a we vary HDFS block size from 64 MB to 1024 MB and measure TeraSort throughput by processing 96 GB data Both Hadoop and DataMPI can achieve the best throughput when the block size is 256 MB In Figure 8\(b we increase concurrent A reduce tasks per node from 2 to 8 and measure TeraSort throughput by processing 2 GB data per task Hadoop and DataMPI can get the best throughput when the number of concurrent A reduce tasks on each node is 4 Thus we choose 256 MB as HDFS block size and run 4 A reduce tasks per node in our following tests when using Testbed A We choose 4 concurrent O map tasks per node by similar tunings DataMPI supports the diversiìed feature of the bipartite model and provides different modes to applications This section will show the overall performance of different representative benchmarks for different modes First we compare DataMPI and Hadoop MapReduce by using TeraSort Figure 9 shows the progress comparison between DataMPI and Hadoop MapReduce when they process 168 GB data on Testbed A As we can see Hadoop requires 475 sec to complete the job whereas DataMPI only needs 312 sec And we can also nd DataMPI improves the performance for both O map and A reduce phases Figure 10\(a further shows the situations when the input data size varies from 48 GB to 192 GB DataMPI gains 32%-41 improvement compared to Hadoop We also evaluate the performance with WordCount which has smaller data movement compared with TeraSort The results still show that DataMPI speeds up the performance of WordCount by 31 compared to Hadoop Due to the similar results we do not include the graph These results demonstrate that the designs like data-centric task scheduling O-side data shufîe pipeline and optimized buffer management and communication in DataMPI are beneìcial for both CPU and communication intensive applications We include some initial results for Iteration and Streaming modes which will be introduced in future work We compare DataMPI Iteration with Hadoop by using PageRank and K-means with 40 GB data Each of the benchmarks runs seven rounds As shown in Figure 10\(b DataMPI averagely improves the performance of PageRank by 41 and Kmeans by 40 compared to Hadoop S4 is a streaming data processing system We run the Top-K benchmark to compare DataMPI Streaming with S4 v0.5.0 Figure 10\(c shows the distribution of streaming data processing latencies with a message rate as 1 K msg/sec and 100 B for each The latencies of DataMPI range from 0.5 to 4 sec while S4 latencies range from 1.5 to 12 sec This means DataMPI can gain better performance for Streaming applications We further measure the resource utilization of DataMPI and Hadoop with 168 GB TeraSort As Figure 11\(a shows DataMPI has lower average CPU utilization compared to Hadoop with less execution time The beginning part of DataMPI CPU utilization is slightly higher than that of Hadoop This is because the O-side data shufîe pipeline design in DataMPI is able to leverage system resource to overlap the computation/communication/merge operations efìciently Figure 11\(b shows the disk utilization The read throughput of DataMPI is averagely 65.8 MB/sec during the O phase which is 69 higher than that of Hadoop 38.9 MB/sec during the map phase This shows our O-side shufîe pipeline design achieves better disk read throughput DataMPI writes near half of data compared to Hadoop because DataMPI will cache intermediate data in memory by default Note that the total amount of disk read is nearly equal between DataMPI and Hadoop which is because the system-level disk cache helps Hadoop to hold intermediate data and cuts down the read overhead DataMPI caches the data by its own design Figure 11\(c shows DataMPI 
A Experiment Setup B Parameter Tuning C Overall Performance D Proìle of Resource Utilization 
1 Testbed A 2 Testbed B 
835 


 
200  300  400  500   600  700  64   128  256  512  1024 Throughput \(MB/sec Block Size \(MB Hadoop DataMPI 200  300  400  500   600  700  2   4  6  8 Throughput \(MB/sec Number of Aggregation/Reduce Tasks per Node Hadoop DataMPI 
Most of above TeraSort tests ensure the slave nodes have enough memories to store intermediate data However when the slave nodes do not have enough memories DataMPI needs to spill intermediate data to disk An interesting question is can our design still guarantee better performance when data is spilled over In order to check this we conìgure DataMPI to cache different amount of intermediate data in memory and measure the job execution time Figure 12 shows with more intermediate data cached in memory the job costs less time The DataMPI performance degrades slightly up to 9 from full caching to zero caching and DataMPI with zero caching still has better performance than Hadoop This is because DataMPI provides the data-local feature for A tasks and the intermediate data on disk can be prefetched at the initial stage of A phase DataMPI supports fault tolerance by the key-value based light-weight library level checkpoint technique When the DataMPI application enables checkpoint the intermediate data will be saved to disk periodically This will introduce some overheads We evaluate the DataMPI performance with different percentages of checkpointed data sizes We test 100 GB TeraSort on 10 slave nodes in Testbed A Figure 13\(a shows the performance comparison between default DataMPI and checkpoint-enabled DataMPI We see the checkpoint-enabled DataMPI has only about 12 performance loss compared with the default DataMPI If we compare it with Hadoop we see the checkpoint-enabled DataMPI can still show 21 improvement If we kill the job intentionally when DataMPI has persisted different sizes of checkpoints we can see that each job restart only costs less than 3 seconds With increasing of the checkpointed data sizes the checkpoint reload time increases proportionally and the total execution time has a slight augment Figure 13\(b shows the CPU utilization in detail of the fault tolerant job which has 60 checkpointed data These results demonstrate the key-value pair based communication can really help the fault tolerance design We evaluate the DataMPI scalability on Testbed B After parameter tuning on this testbed we choose 128 MB as HDFS block size and run 2 concurrent O map and A reduce tasks on each slave node We measure the job execution time of TeraSort in two scaling patterns strong scale and weak scale In strong scale we x the total data size 256 GB and increase the parallelism degree by increasing the number of slave nodes In weak scale we x the data size 2 GB for each A reduce task and increase the number of slave nodes Figure 14\(a shows DataMPI has the similar trend with Hadoop in strong scale and reduce the 
E Spill Over Efìciency F Fault Tolerance G Scalability 
0  20  40  60  80  100   120  0   100   200   300   400  500 Progress Progression of Time \(sec Hadoop Map DataMPI Operation Hadoop Reduce DataMPI Aggregation 
0  100  200  300  400  500   600  700   48   72   96   120   144  168  192 Job Execution Time \(sec Data Size \(GB Hadoop TeraSort DataMPI TeraSort 0  0.1  0.2  0.3  0.4   0.5   0.6     1     2     3     4     5     6     7    8   8   9   10   11 Distribution Radio Latency \(sec S4 Top-K DataMPI Top-K 
0  50  100  150  200  250   300  350  1st   2nd   3rd   4th   5th   6th  7th Execution Time \(sec Iteration Round Hadoop K-means DataMPI K-means Hadoop PageRank DataMPI PageRank 
a HDFS Block Size Tuning  b Task Number Tuning Figure 8 Parameter Tuning  Figure 9 Progress of TeraSort  a TeraSort  b PageRank and K-means  c Top-K More left is better Figure 10 Performance Comparison of Different Benchmarks communication mainly occurs in the O phase because of the data-centric scheduling design for A tasks On the average the network throughput of DataMPI is 74.3 MB/sec which is 47 higher better than that of Hadoop 50.6 MB/sec Figure 11\(d shows during 0 475 sec the average memory used by DataMPI is 26.6 GB which is less than 29.3 GB in Hadoop This indicates data caching and in-memory shufîe in DataMPI do not make extra memory overhead compared with Hadoop which uses system-level caching 
836 


0  200  400   600          Time \(sec Hadoop DataMPI  0  192   0   20   40   60   80   100 Data Size \(GB In-Memory Data Percentage In-Disk Data \(GB In-Memory Data \(GB 
0  20  40  60  80   100   120  140  0   100   200  300  400  500 Disk Throughput \(MB/sec Progression of Time \(sec Hadoop Rd Hadoop Wt DataMPI Rd DataMPI Wt 
 
0  25  50  75  100   125  150  0   100   200  300  400  500 Network Throughput \(MB/sec Pro g ression of Time \(sec Hadoop DataMPI 
et.al et.al et.al 
 The MapReduce model was introduced in 2004 by Dean in MapReduce Online allo ws data to be streamed between mappers and reducers supporting pipelined execution continuous queries and online aggregation Twister e xtends MapReduce to support iterative jobs through keeping static data in memory among jobs Dryad supports directed acyclic graph based tasks This paper complements these work by abstracting and implementing a key-value pair 4D bipartite communication model for Big Data Computing  Hoeîer  attempted to write efìcient MapReduce applications by using MPI Plimpton  described their MR-MPI library and se v eral MapReduce graph algorithms examples Hadoop-A introduces an RDMA-levitated merge algorithm in shufîe phase of Hadoop to improve the performance HadoopRDMA le v erages RDMA-capable interconnects to improve Hadoop performance with enhanced designs of various components such as MapReduce HDFS RPC The major difference between our work and theirs is that we propose a 4D bipartite communication model for Big Data Computing and implement a general communication library based on the model Evaluations have shown the merits of our model and design In addition our previous work identiìes the opportunities and challenges of adapting MPI to MapReduce This paper makes three signiìcant progresses First we abstract a general bipartite communication model from these practices Second we reìne the programming interfaces to support the diversiìed application requirements Third we implement and open source a real bipartite model based communication library by extending MPI VII C ONCLUSION AND F UTURE W ORK We present  an efìcient communication library for Big Data Computing that features the processing and communication of large numbers of key-value pairs The design of DataMPI is guided by carefully analyzing the essential features of key-value pair communication requirements in Big Data Computing We observe that such communication requirements are abstracted as a bipartite communication model with four distinctions from traditional MPI Dichotomic Dynamic Data-centric and Diversiìed features DataMPI provides a programming speciìcation that extends MPI in a minimalistic way requiring only three pairs of new MPI library calls in default cases We implement DataMPI with a Java binding and conduct experiments on Ethernet clusters running application benchmarks with up to 65 nodes Using ve application benchmarks WordCount TeraSort PageRank K-means Top-K that represent three popular Big Data Computing models MapReduce Iteration Streaming we show that DataMPI has signiìcant advantages in following aspects 
Big Data Computing models and systems Adopting HPC Technologies to Improve Data Processing Performance DataMPI 
0  100  200  300   400   500  600       20   40   60   80  100 Job Execution Time \(sec Percentage of Checkpoint Data Size Normal Execution before Crash Job Restart Job Reload Checkpoint Normal Execution after Recover 0 100 200 300 400 500 600 DataMPI 0 100 200 300 400 500 600 DataMPI Checkpoint 
0  20  40  60  0   100   200  300  400  500 CPU Utilization Pro g ression of Time \(sec Hadoop DataMPI 0  16  32  48  64  0   100   200  300  400  500 Memory Footprint \(GB Pro g ression of Time \(sec Hadoop DataMPI 
0  10  20  30  40  50           CPU Utilization    0   100   200  300  400 Pro g ression of Time  sec  Normal Execution before Crash Job Restart Job Reload Checkpoint Normal Execution after Recover 
a CPU Utilization  b Disk Throughput  c Network Throughput  d Memory Footprint Figure 11 Proìle of Resource Utilization  Figure 12 Spill Over Efìciency  a Efìciency with Different Checkpoints  b CPU Utilization 60 checkpointed data Figure 13 Fault Tolerance Efìciency job execution time by 35%-40 compared to Hadoop In weak scale Figure 14\(b shows both DataMPI and Hadoop can achieve good scalability and DataMPI can improve the performance by 40 compared to Hadoop Therefore both DataMPI and Hadoop can achieve linear scalability and DataMPI can achieve better performance VI R ELATED W ORK 
837 


 
     
0  1000  2000  3000   4000  5000   16  32  64 Job Execution Time \(sec Number of Nodes Hadoop DataMPI 
 DataMPI speeds up varied Big Data workloads and improves job execution time by 31%-41  DataMPI supports fault tolerance Evaluations show that DataMPI-FT can attain 21 improvement over Hadoop  DataMPI achieves high scalability as Hadoop and 40 performance improvement  DataMPI can support different models of Big Data Computing and can be used with different le systems and networks  The coding complexity of using DataMPI is on par with that of using traditional Big Data application frameworks such as Hadoop We have open sourced DataMPI at W e plan to continuously update this package with newer designs and carry out evaluations with more applications R EFERENCES  Message P assing Interf ace F orum  http://www mpi-forum.or g  MPICH2  http://www mcs.anl.go v/research/projects/mpich2  MV APICH  http://mv apich.cse.ohio-state.edu  E Gabriel G E F agg G Bosilca T  Angskun J J Dongarra J M Squyres V Sahay P Kambadur B Barrett A Lumsdaine R H Castain D J Daniel R L Graham and T S Woodall Open MPI Goals Concept and Design of a Next Generation MPI Implementation in 
a Strong Scale  b Weak Scale Figure 14 Scalability of DataMPI  ser EuroMPI 04 Budapest Hungary 2004  J Dean and S Ghema w at MapReduce Simpliìed Data Processing on Large Clusters  vol 51 no 1 pp 107Ö113 2008  T  Condie N Conw ay  P  Alv aro J M Hellerstein K Elmelee gy  and R Sears MapReduce Online in  ser NSDI 10 Berkeley CA USA 2010  J Ekanayak e H Li B Zhang T  Gunarathne S.-H Bae J Qiu and G Fox Twister A Runtime for Iterative MapReduce in  ser HPDC 10 New York NY USA 2010  M Isard M Budiu Y  Y u A Birrell and D Fetterly  Dryad Distributed Data-parallel Programs from Sequential Building Blocks in  ser EuroSys 07 New York NY USA 2007  M Zaharia M Cho wdhury  M J Franklin S Shenk er  and I Stoica Spark Cluster Computing with Working Sets in  ser HotCloud 10 Berkeley CA USA 2010  L Neume yer  B Robbins A Nair  and A K esari S4 Distrib uted Stream Computing Platform in  ser ICDMW 10 Sydney Australia 2010  The Apache Hadoop Project  http://hadoop.apache.or g  X Lu B W ang L Zha and Z Xu Can MPI Beneìt Hadoop and MapReduce Applications in  ser ICPPW 11 Taipei China 2011  S Brin and L P age The Anatomy of A Lar ge-scale Hyperte xtual Web Search Engine in  ser WWW7 Amsterdam The Netherlands 1998  J B MacQueen Some Methods for Classiìcation and Analysis of MultiVariate Observations in  Berkeley CA USA 1967  T on y He y Ste w art T ansle y  and Kristin T olle  Redmond Washington Microsoft Research 2009  S Ibrahim H Jin L Lu S W u B He and L Qi LEEN Locality/Fairness-Aware Key Partitioning for MapReduce in the Cloud in  ser CLOUDCOM 10 Washington DC USA 2010  M Hammoud and M F  Sakr  Locality-A w are Reduce T ask Scheduling for MapReduce in  ser CLOUDCOM 11 Washington DC USA 2011  mpiJa v a  http://www hpja v a.or g/mpiJa v a.html  The Apache Mahout Project  http://mahout.apache.or g  T  Hoeîer  A Lumsdaine and J Dongarra T o w ards Ef cient MapReduce Using MPI in  ser EuroMPI 09 Berlin Heidelberg 2009  S J Plimpton and K D De vine MapReduce in MPI for Lar ge-scale Graph Algorithms  vol 37 no 9 pp 610Ö632 2011  Y  W ang X Que W  Y u D Goldenber g and D Sehgal Hadoop Acceleration Through Network Levitated Merge in  ser SC 11 New York NY USA 2011  M W asi-ur Rahman N S Islam X Lu J Jose H Subramoni H Wang and D K Panda High-Performance RDMA-based Design of Hadoop MapReduce over InìniBand in  ser IPDPSW 13 Washington DC USA 2013  N S Islam M W  Rahman J Jose R Rajachandrasekar  H W ang H Subramoni C Murthy and D K Panda High Performance RDMA-based Design of HDFS over InìniBand in  ser SC 12 Los Alamitos CA USA 2012  X Lu N S Islam M W asi-Ur Rahman J Jose H Subramoni H Wang and D K Panda High-Performance Design of Hadoop RPC with RDMA over InìniBand in  ser ICPP 13 Lyon France 2013  The DataMPI Project  http://datampi.or g 
Proc of the 11th European PVM/MPI Users Group Meeting Communications of the ACM Proc of the 7th USENIX Conference on Networked Systems Design and Implementation Proc of the 19th ACM International Symposium on High Performance Distributed Computing Proc of the 2nd ACM SIGOPS/EuroSys European Conference on Computer Systems Proc of the 2nd USENIX Conference on Hot Topics in Cloud Computing Proc of the 2010 IEEE International Conference on Data Mining Workshops Proc of the 40th International Conference on Parallel Processing Workshops Proc of the 7th International Conference on World Wide Web Proc of the 5th Berkeley Symposium on Mathematical Statistics and Probability The Fourth Paradigm Data-Intensive Scientiìc Discovery Proc of the 2nd International Conference on Cloud Computing Technology and Science Proc of the 3rd International Conference on Cloud Computing Technology and Science Proc of the 16th European PVM/MPI Users Group Meeting on Recent Advances in Parallel Virtual Machine and Message Passing Interface Parallel Computing Proc of the International Conference for High Performance Computing Networking Storage and Analysis Proc of the 27th International Symposium on Parallel and Distributed Processing Workshops and PhD Forum Proc of the International Conference on High Performance Computing Networking Storage and Analysis Proc of the 42nd International Conference on Parallel Processing 
Efìciency Fault Tolerance Scalability Flexibility Productivity 
0  100  200  300  400  500  600   700  800   16  32  64 Job Execution Time \(sec Number of Nodes Hadoop DataMPI 
838 


    11   Figure 21 Tail functions for the spacecraft power consumption \(due to data availability only ADCS components and avionics board are considered in this plot\. The plot shows results for data statistic, two expert statistics \(proportional and bisection weights\ and two Bayesian statistics. The vertical dotted and dashed lines indicate t he estimates at PDR and CDR. It can be noticed that in this case the statistics \(especially Bayesian\ fail in recognizing the underestimation at PDR  Differently from the other cases the risk analysis for the total power consumption shows some problems Specifically the statistics do not seem to identify the underestimation of the initial PDR estimate  The cause of this issue depends mostly on the estimates of the power consumption for the ADCS components, since the estimates of the power consumption for the avionics board seem to be more accurate Future work will focus on improving estimates for the ADCS components maybe developing a specific expert elicitation interview with control experts only  The last results of this paper were computed performing the analysis of variance The analysis considers how the variance of each factor component or subsystem affects the total variance The objective of this analysis is to identify the main drivers for mass and power fluctuations To compute the analysis [4   th e h y p o t h esi s  o f  i n d ep en d en c e between the distributions of the single components is assumed Hence the variance of fluctuations for mass and power is the sum of the single variances   4  5  The variance proportions coefficients are defined as the ratio of the variance of each component to the total variance They are computed as  6  7  The coefficients for mass fluctuations are shown in Figure 22  The coefficients for power fluctuations are shown in Figure 23     Figure 22 Analysis of variance for the spacecraft mass estimates. According to all the statistics, the components of the control system together with the avionics board seem to be the components that show the biggest variance in their estimation  


    12   Figure 23 Analysis of variance for the spacecraft power consumption estimates. The statistics offer different results on which component seems to be the principle driver for the variance of the power consumption estimate  Analysis of variance shows that all the statistics identify ADCS and avionics board components as the major drivers for the variance in the estimation of the total mass Regarding the power consumption, the analysis of variance presents conflicting results according to experts and Bayesian statistics the ADCS subsystem is the main driver of the variance, while according to data statistic the avionics board is the main driver This difference can also be correlated with the issues observed in the total powe r consumption probability density function Figure 20 and 21 Future work will focus on a more detailed analysis of the control system for the spacecraft A final comment is related to the weighting of the distributions In this analysis two weighting schemes have been used the proportional scheme and the bisection scheme While in previous works focused on communication system design only  1   5    3    4   the bisection rule achieved substantially better results in the case of this paper the two methods provide very similar outcomes and they both give reasonable estimates However since this is the first case in which the methodology has been applied by the authors to the entire spacecraft design, it is too early to claim that in all the cases the two schemes will perform in the same way More test cases need to be analyzed and additional interviews with experts need to be performed  Conclusions and suggestions for future work are presented in the next section  4  C ONCLUSIONS  This paper presents the first attempt to extend the probabilistic approach to design risk to the entire spacecraft design This approach has been developed initially by the authors primarily for the design of the communication subsystem. In this paper, the authors extend the approach to the different subsystems and focus their effort on small spacecraft which are becoming increasingly more developed in academia space agencies and industries The methodology is extended to the entire spacecraft the database now includes data on several spacecraft components and the expert elicitation interview includes questions on the different subsystems. A university satellite mission \(CASTOR\ developed at MIT is used as a test case Results show that the methodology is effective in analyzing each component and in identifying whether the initial estimate of mass and power consumption made at PDR was an overestimation or an underestimation Specifically the tail functions provide useful insights which can be applied by the engineers while designing the spacecraft. The system results are obtained by convolution of the results obtained for the single components and they show that the model is able to clearly identify underestimation for the spacecraft mass while it does not perform as well for the power consumption. Similar results are obtained in the analysis of variance proportions Future work will be dedicated to analyzing the issue on the power consumption estimate as well as in developing specific statistic al  approaches to include newly developed payloads for which no previous data are available or for which expertise in the field is somehow limited Finally future work will also focus on extending the model to the design of larger spacecraft than small satellites and to the design of satellite constellations  5 ACKNOWLEDGMENT  Part of this work was performed at the Jet Propulsion Laboratory California Institute of Technology under a contract with the National Aeronautics and Space Administration Part of this work was carried out at the Space System Laboratory Massachusetts Institute of Technology 6 APPENDIX  A breakdown of mass and power consumption data for each of the components at PDR and CDR is shown in the following table Table 2: Values of mass and power consumption at PDR and CDR for each of the components analyzed Component  Mass PDR Kg  Mass CDR Kg  Power PDR W  Power CDR W  Solar Panel  3.34  5.066  0  0  


    13  Battery  3.2  2.64  70  50  Avionics Board  0.35  0.21  4  1.8  Satellite Structure  4.82  15.09  0  0  Magnetometer  0.01  0.01  0.03  0.03  Sun Sensor  0.03  0.03  0.08  0.075  GPS receiver  0.02  0.32  0.5  0.8  IMU  0.02  0.16  0.8  0..285  Reaction Wheels Assembly  0.12  0.21  1.2  7   R EFERENCES    1   A Babuscia Statistical Risk Estimation for Communication System Design Ph.D Thesis Massachusetts Institute of Technology, 2012  2   A Babuscia and K M Cheung Statistical Risk Estimation for Communication System Design IEEE Systems Journal vol. PP, no. 99, pp. 1 12, 2012  3   A Babuscia and K M Cheung Statistical Risk Estimation for Communication Systems Design A Prelimi nary Look The Interplanetary Network Progress Report Vols. 42 188, pp. 1 33, 2012  4   A Babuscia K M Cheung and D W Miller Statistical Risk Estimation for Communication System Design: Development of Optimization Frameworks," in IEEE Aerospac e Conference Big Sky, Montana, 2013  5   A Babuscia and K M Cheung An approach to perform expert elicitation for engineering design risk analysis methodology and experimental results Journal of the Royal Statistical Society Series A Oct  2013   6   V Cortellessa Model Based Performance Risk Analysis IEEE 2005  7   L Meshkat A Holistic Approach for Risk Management During Design IEEE 2006  8   F. Barrientos, I. Tumer and D. Ullman, "Design Teams Complex Systems and Uncertain ties IEEE 2005  9   W L Oberkampf J C Helto C A Joslyn S F Wojkiewicz and S Ferson Challenge problems uncertainty in system response given uncertain parameters," Vols. 85\(11 19\, 2004  10   Y Asnayr V Bryl and P Giorgini Using risks analysis to evaluate alternatives IEEE 2006  11   M Fuchs and A Neumaier Autonomous Robust Design Optimization with potential clouds Reliability and Safety 2009  12   M Fuchs A Neumaier and D Girimonte Uncertainty modeling in autonomous robust spacecraft system design in Proceedings in Applied Mathematics and Mechanics 2007  13   M. Fuchs and A. Neumaier, "Potential based clouds in robust design optimization  Issue on Imprecision of Statistics and Applied Mathematics 2008  14   N O Siu and D L Kelly Bayesian parameter estimation in probabilistic risk assessment Reliability Engineering and System Safety vol 62 pp 89 116 1998  15   A. Babus cia, M. M. McCormack, M. Munoz, S. Parra and D W Miller MIT CASTOR Satellite development  implementation and testing of the communication system Acta Astronautica vol 81 pp. 111 121, 2012     


    14  B IOGRAPHY  Alessandra Babuscia received her  B.S and M.S  degrees from the Politecnico di Milano Milan Italy  in 2005  and 2007 respectively and her  Ph.D from the Massachusetts Institute of Technology  MIT Cambridge in 2012  She has been  a Post Doctoral Associate with  the Space System Laboratory MIT She has developed  communication systems for different university  missions  CommCube 1, CommCube 2, TSat, CASTOR, ExoPlanet TerSat   TALARIS She is currently Telecommunication E ngineer in the  Communication  Architecture Research Group NASA Jet Propulsion  Laboratory in  Pasadena CA Her current research interests include communication  architecture design st atistical risk estimation expert elicitation inflatable antennas commun ication system design for small satellites and CubeSats multi disciplinary design  optimization mission scheduling and planning  Dr Babuscia received the Amelia Earhart Fellowship in 2010 and 2011  became a Gordon Engineering Leadership Fellow in 2010 an d 2011 and  received the Teaching Assistant Award from the MIT Aeronautics and  Astronautics Department in 2010, and the Top Graduate Award in the B.S  Program in 2005 and in the M.S Program in 2007 from the Politecnico di  Milano   K ar Ming Cheung  received his  B.S.E.E degree  f rom the University of Michigan Ann Arbor in  1984 and his  M.S. and Ph.D. degrees from the  California Institute of Technology Pasadena in 1985  and 1987, respectively  He is currently a Principal Engineer and a Technical  Gr oup Supervisor with the Communication Architectures  and Research Section 332 Jet Propulsion  Laboratory JPL Pasadena His group supports  design and specification of future deep space  and near Earth communication systems and architectures  He has autho red or co authored over 30 journal and conference papers  in the areas of error correction coding data compression image processing  and telecom system operations He has been with JPL since 1987 where  he has been engaged in research development produc tion operation, and  management of advanced channel coding source coding synchronization  image restoration and communication analysis schemes  Dr Cheung has    Scheme   


    15                                                           


 16  56   Increase Cost Estimate Accuracy in Government  AIAA SPACE 2013 Conference and Exposition  0 vols American Institute of Aeronautics and Astronautics, 2013 57  J aso n  Ha y   J o h n  D  R ee v e s   E lain e Gr e s h a m   J u l ie Williams Predic  AIAA SPACE 2013 Conference and Exposition  0 vols American Institute of Aeronautics and Astronautics, 2013  B IOGRAPHIES   Sreeja Nag is a PhD candidate in Space Systems Engineering at the Massachusetts Institute of Technology and  a part-time research fellow at NASA Goddard Space Flight Center  She has a dual SM Candidate in Aeronautics  Astronautics Engineering along with Technology  Policy at MIT. She has summer research experience with NASA JPL in 2008, the European Space Agency \(ESTEC in 2010 and led the SPHERES Zero Robotics Program in 2011. Email sreeja_n@mit.edu                Jacqueline Le Moigne is the Assistant Chief for Technology in the Software Engineering Division at NASA Goddard where she is currently leading a study on Distributed Spacecraft Missions She has  performed extensive work in developing new technologies for remote sensing data analysis e.g image registration high-performance and onboard processing She has published over 100 publications and recently co  Jacqueline.LeMoigne@nasa.gov   Olivier de Weck is a Professor of Aeronautics and Astronautics and Engineering Systems at the Massachusetts Institute of Technology He is also the Executive Director of MIT Production in the Innovation Economy PIE Study and the CoDirector Center for Complex Engineering Systems at KACST and MIT  Email deweck@mit.edu   

















Mohammed Taj, Dwight Day, Ar lie Stonestreet, Tim Sobering Paper Number: 2227; Presentation Number: 8.0201 Finding the Gaps in Space GNC Hardware Adam Greenbaum, Tye Brady Paper Number: 2288; Presentation Number: 8.0202 Technology for a Robotic Asteroid Redirect Mission and Its Extensibility to Future Human Missions John Brophy Paper Number: 2451; Presentation Number: 8.0203 Advanced Launch Vehicle Systems and Technologies NASA's Space Launch System: An Enabling Capability for Discovery Stephen Creech Paper Number: 2014; Presentation Number: 8.0301 A Dual Thrust Axis Lander for Mars Exploration David Masten Paper Number: 2384; Presentation Number: 8.0302 Innovation at ULA: It Really Is Rocket Science Gregory Schiller Paper Number: 2407; Presentation Number: 8.0303 Launch Vehicle Mission Capability Enhancemen t through Global Positioning System Metric Tracking Timothy Gray Paper Number: 2556; Presentation Number: 8.0304 Lateral Autopilot Design Using H\211\366? for Reusable Launch Vehicles Sheelu Jose Paper Number: 2435; Presentation Number: 8.0305 Adaptation of the Morris Method to MultiDimensional Factors for Air-Launch-to-Orbit Separation Henri Sohier, Jean Loup Farges, Lahanier Helene Piet Paper Number: 2566; Presentation Number: 8.0306 Hosted Payloads Concept for an ASRG Hosted Payload Mission Erich Schulze Paper Number: 2462; Presentation Number: 8.0401 Exploiting Hosted Payload Opportunities Surrey's Lessons Learned from OTB and Other Missions Anita Bernie, John Paff ett, Marissa Brummitt Paper Number: 2231; Presentation Number: 8.0402 Table of Contents file:///L:/JOBS/563 35_IEEE AC/HTML CD/HTML/data/toc.htm 22 of 39 5/27/2014 2:12 PM 


Human Factors & Performanc e Real Time VR Environment for MAJIC A ttitude Control System Development and Implementation Jared Rize, Babak Cohanim, Jeffrey Hoffman Paper Number: 2090; Presentation Number: 8.0501 Musculoskeletal Human-Spacesuit Interaction Model Ana Diaz, Dava Newman Paper Number: 2156; Presentation Number: 8.0502 Level of Automation and Failure Frequency Ef fects on Simulated Lunar Lander Performance Jessica Marquez, Margarita Ramirez Paper Number: 2285; Presentation Number: 8.0503 Spacecraft Human-Rating: Historical Over view and Implementation Considerations David Klaus Paper Number: 2272; Presentation Number: 8.0504 Pilot Control and Stabilization of a Rate Controlled Vehicle in Hyper-Gravity Torin Clark, Michael Newman, Dan Merfeld Paper Number: 2250; Presentation Number: 8.0505 Dynamic Task Allocation in Operational Sy stems: Issues, Gaps, and Recommendations Aaron Johnson, Kevin Duda, Charles Oman, Tom Sheridan Paper Number: 2087; Presentation Number: 8.0506 The V2Suit \211\333\317Down\211\333 Tracking Algorithm Rebecca Vasquez, Akil Middle ton, Kevin Duda, Dava Newman Paper Number: 2213; Presentation Number: 8.0507 Human Performance with Procedure Automa tion to Manage Spacecraft Systems Debra Schreckenghost, Dorrit Billman, Tod Milam Paper Number: 2477; Presentation Number: 8.0508 A Mission Guided Investigatio n of Operational Functions and User Interface for MAJIC Celena Dopart, Babak Cohanim, Jeffrey Hoffman Paper Number: 2088; Presentation Number: 8.0509 Modular Bus Technologies, Components and Standardized Spacecraft Reusable, Modular, and Scalable Flight Software L. Jane Hansen, John Hanson Paper Number: 2172; Presentation Number: 8.0601 Development of Attitude Contro l Systems for Modular Spacecraft John Hanson, L. Jane Hansen Paper Number: 2148; Presentation Number: 8.0602 Table of Contents file:///L:/JOBS/563 35_IEEE AC/HTML CD/HTML/data/toc.htm 23 of 39 5/27/2014 2:12 PM 


The TET Satellite Bus \226 Futu re Mission Capabilities Anja Nicolai, Stephan Roemer, Silke Eckert Paper Number: 2465; Presentation Number: 8.0603 SMC's Standard Network Adapter for Payloads Garrett Ellis Paper Number: 2544; Presentation Number: 8.0604 Mechanical Systems, Design and Technologies Spin Stabilization Design and Te sting for the Van Allen Probes Simmie Berman, Heather Borowski Weilun Cheng, David Persons Paper Number: 2133; Presentation Number: 8.0701 Evaluation and Test of Different Gear Conc epts for Ka-band Antenn a Pointing Mechanisms Ralf Purschke, Alexander Hoehn Paper Number: 2098; Presentation Number: 8.0702 Europa Clipper Spacecraft Configuration Evolution Alexander Eremenko Paper Number: 2077; Presentation Number: 8.0703 Spacecraft Propulsion and Power Technologies Status of Propulsion and Entry Vehicle Techno logy Development under the NASA ISPT Program David Anderson, Eric Pencil, John Dankanich Paper Number: 2395; Presentation Number: 8.0801 Green Propellant Infusion Mission Program Overview Christopher Mclean, William Deininger, Bryce Unruh Paper Number: 2150; Presentation Number: 8.0802 Description of the Green Propellant In fusion Mission \(GPI M\sion System William Deininger Paper Number: 2627; Presentation Number: 8.0803 Applications of Micro-Cathode Arc Thruster as In-space Propulsion Subsystem for PhoneSat Samudra Haque, Gazulla Oriol Tintore, George Teel Greenfield Trinh, Eddie Ur ibe, Andres Dono Perez Michael Keidar, Elwood Agasid Paper Number: 2324; Presentation Number: 8.0804 Pulse Phase Modulation for On-Off Thruster Pair Runle Du, Jiaqi Liu Paper Number: 2069; Presentation Number: 8.0805 Autonomous Space Exploration Systems and Technologies Onboard and Self-Contained Landing Site Selection for Planet ary Landers/Hoppers Babak Cohanim, Jeffrey Hoffman, Tye Brady Table of Contents file:///L:/JOBS/563 35_IEEE AC/HTML CD/HTML/data/toc.htm 24 of 39 5/27/2014 2:12 PM 


Paper Number: 2028; Presentation Number: 8.0901 Vision-Based Terrain-Relative Navigation and Hazard Detection Onboard a Terrestrial Rocket Ted Steiner, Tye Brady Paper Number: 2101; Presentation Number: 8.0902 Morpheus Vertical Test Bed Flight Testing Jennifer Devolites Paper Number: 2562; Presentation Number: 8.0903 Rocket Validation of the ALHAT Autonomous GNC Flight System Steve Paschall, Tye Brady Paper Number: 2045; Presentation Number: 8.0904 New Technologies and Instruments for Scientific Balloon Missions The Use of 3D Printing to Enable High Altitude Balloon Missions Jeremy Straub Paper Number: 2039; Presentation Number: 8.1001 Rapid Development of Balloon-Borne CDH Syst em with a Focus on COTS and Open Source Software Zachary Dischner, Kevin Dinkel, Jedediah Di ller, Nicholas Truesdale, Eliot Young Paper Number: 2345; Presentation Number: 8.1002 Inexpensive Balloon-Borne Observator ies Using Modified COTS Telescopes Eliot Young, Robert Woodruff Paper Number: 2284; Presentation Number: 8.1003 Development of Meter-scale O-shaped and U-shap ed Oscillating Heat Pipes for GAPS Shun Okazaki, Hideyuki Fuke, Hiroyuki Ogawa Paper Number: 2188; Presentation Number: 8.1004 Development of a Meteorology and Remote Sens ing Experimental Platform: The LAICAnSat-1 Pedro Nehme, Renato Borges, Simone Battistini, Chantal Cappelletti Paper Number: 2159; Presentation Number: 8.1005 High Energy Replicated Optics to Explore the Sun: Flight Overview and Astrophysical Pointing Jessica Gaskin, Steven Christe, Ho dge Colleen Wilson, Albert Shih Brian Ramsey, Jeff Apple, Kurtis Dietz Paper Number: 2216; Presentation Number: 8.1006 A Solar Aspect System for the HEROES Mission Steven Christe, Albert Sh ih, Marcello Rodriguez, Kyle Gregory, Alexander Cramer, Melissa Edgerton Brian O'connor, Alexander Sobey, Jessica Gaskin Paper Number: 2400; Presentation Number: 8.1007 10 Meter Sub-Orbital Large Balloon Reflector \(LBR Christopher Walker Table of Contents file:///L:/JOBS/563 35_IEEE AC/HTML CD/HTML/data/toc.htm 25 of 39 5/27/2014 2:12 PM 


Paper Number: 2630; Presentation Number: 8.1008 First Results from the Hard X-ray Polarimeter X-Calibur Matthias Beilicke Paper Number: 2205; Presentation Number: 8.1009 Design and Performance of the BRRI SON UV-VIS Fine Pointing System Jedediah Diller, Kevin Dinkel, Zachary Dischner, Nicholas Truesdale, Eliot Young Paper Number: 2308; Presentation Number: 8.101 Enabling Systems and Technolo gies for CubeSat/Smallsats A Reusable Command and Data Handling Sy stem for University CubeSat Missions Shaina Johl, Gokul Anandayuvaraj, Sean Horton Paper Number: 2403; Presentation Number: 8.1101 Design and Scientific Return of a Miniaturized Particle Telescope Onboard the CSSWE CubeSat Quintin Schiller Paper Number: 2408; Presentation Number: 8.1102 Fractionated and Distributed Systems Satellite-to-Satellite Optimization Approa ch for Opportunistic Inter-Satellite Links Cruz Ignasi Lluch, Alessandro Aliakbargolkar Paper Number: 2270; Presentation Number: 8.1201 Air Vehicle Systems and Technologies UAV Systems & Autonomy Modeling, Analysis and Fabrication of a Thru st Vectoring Spherical VTOL Aerial Vehicle Sagar Bose, Shibu Clement, Rohan Ve rma, Aditya Tripathi, Kriti Garuda Paper Number: 2097; Presentation Number: 9.0202 Aerodynamic Analysis of BlimPlane- a Conc eptual Hybrid UAV for Venus Exploration Mofeez Alam, Kumar Ashish, Sanjay Limaye Paper Number: 2313; Presentation Number: 9.0203 Aggressive Navigation Using High-S peed Natural Feature Point Tracking Christopher Raabe, John Vian, Emad Saad Paper Number: 2329; Presentation Number: 9.0204 Development of a Multipurpose Tactic al Surveillance System Using UAV's Rodrigo Rangel Paper Number: 2251; Presentation Number: 9.0205 A New Hybrid Motor Glider-Quadrotor MAV for In-Flight/V-STOL Launching Rafael Coronel B. Sampaio, Andr\351 C. Hernandes, Marcelo Becker, Fernando M. Catalano, Fabio Zanini Joao L. E. M. Nobrega, Caio Martins Table of Contents file:///L:/JOBS/563 35_IEEE AC/HTML CD/HTML/data/toc.htm 26 of 39 5/27/2014 2:12 PM 


Paper Number: 2501; Presentation Number: 9.0206 SquidCop: Design and Evaluation of a No vel Quadrotor MAV for In-\225\302\342ight Launching Air-Ground Missions Rafael Coronel B. Sampaio, Andr\351 C. Hernandes, Marcelo Becker, Fernando M. Catalano, Fabio Zanini Joao L. E. M. Nobrega, Caio Martins Paper Number: 2500; Presentation Number: 9.0207 Development of a Circulation Control Wing for UAVs Konstantinos Kanistras, Matthew Rutherford, Kimon Valavanis Paper Number: 2439; Presentation Number: 9.0208 Comparing the Economic and Regulatory State of UAS & Commercial Space Flight Harrison Wolf Paper Number: 2555; Presentation Number: 9.0209 Modeling of Real-Time Flight Control System for Small Coaxial Helicopter Seong Jin Lee Paper Number: 2530; Presentation Number: 9.021 Quantification of High Level Safety Crit eria for Civil Unmanned Aircraft Systems Xun Lin, Neale Fulton, Mark Horn Paper Number: 2619; Presentation Number: 9.0211 Three-dimensional Path Planning for Unmann ed Aerial Vehicles Based on Fluid Flow Xiao Liang Paper Number: 2707; Presentation Number: 9.0212 Airborne Imaging for Cultural Heritage Tom Wypych Paper Number: 2717; Presentation Number: 9.0213 Artificial Homeostasis for Vehicle Contro l Architecture of Unmanned Spacecraft Carlos Insaurralde, Emil Vassev Paper Number: 2543; Presentation Number: 9.0214 Multi Disciplinary Optimization Design of Modern Airship Based on Genetic Algorithm Masood Mayanbari Paper Number: 2647; Presentation Number: 9.0215 Aircraft Systems & Avionics Stochastic 4D Trajectory Optimizati on for Aircraft Conflict Resolution Yoshinori Matsuno, Takeshi Tsuchiya Paper Number: 2207; Presentation Number: 9.0301 Estimating the Internal Volume Requirement in a Multivariate Design Synthesis of a BWB Aircraft Paulinus Okonkwo Paper Number: 2281; Presentation Number: 9.0303 Table of Contents file:///L:/JOBS/563 35_IEEE AC/HTML CD/HTML/data/toc.htm 27 of 39 5/27/2014 2:12 PM 


A Novel Pump Design for an Efficient and Compact Electro-Hydraulic Actuator Gabriele Altare, Andrea Vacca, Carl Richter Paper Number: 2651; Presentation Number: 9.0304 Short-Term Turning in Presence of Wind as a Trajectory Optimization Problem Kamran Turkoglu Paper Number: 2652; Presentation Number: 9.0305 Air Vehicle Flight Controls Optimal Position Transfer Analysis of Stratospheric Airs hip in Wind Field Zhou Jianghua, Li Zhaojie, Sheng Wang, Jiang Luhua Paper Number: 2071; Presentation Number: 9.0401 Analyses and Comparisons for Several Flight Co ntrol Configuration of Stratospheric Airship Jing Gang Miao, Fan Wang, Yan Chu Yang, Xiang Qiang Zhang Paper Number: 2142; Presentation Number: 9.0402 Software and Computing Computational Modeling Multi-resolution Rapid Prototyping of Vehicle Cooling Systems Maciej Pindera Paper Number: 2019; Presentation Number: 10.0101 Feature Selective Validation Rohit Nijhawan Paper Number: 2024; Presentation Number: 10.0102 Designing a Fuzzy Logic Controller for the Reyn olds Number in a Blowdown Supersonic Wind Tunnel Shahrbabaki Amin Nazarian, Ali Shahriyari, Manshadi Mojtaba Dehghan Paper Number: 2146; Presentation Number: 10.0103 Bird Strike Analysis of Jet Engine Fan Blade Narender Lakshman, Ratnesh Raj, Yagnavalkya Mukkamala Paper Number: 2158; Presentation Number: 10.0104 Ammonia-Water Solution Clou d Modeling of Gas Giant Planets via Phase Equilibrium Calculations Virgil Adumitroaie Paper Number: 2513; Presentation Number: 10.0105 Computational Modeling of Chan nel Length Modulation in Ca rbon Nanotube Field Effect Transistors Adam Bushmaker Paper Number: 2538; Presentation Number: 10.0106 Flow Regimes in an Air Conditio ned Measuring Equipment Laboratory Table of Contents file:///L:/JOBS/563 35_IEEE AC/HTML CD/HTML/data/toc.htm 28 of 39 5/27/2014 2:12 PM 


Ahmed Farag Paper Number: 2691; Presentation Number: 10.0107 A Multiscale Turbulence Prediction and Al ert System for Airports in Hilly Regions Adil Rasheed, Karstein S\314\374rli Paper Number: 2679; Presentation Number: 10.0108 Software Engineering Autonomous Real Time Requirements Tracing George Plattsmier, Howard Stetson Paper Number: 2100; Presentation Number: 10.0201 TSEpoch: An Object Oriented Design for Representing Time Lawrence Brown, Jon Vandegriff Paper Number: 2348; Presentation Number: 10.0202 Open Source RTOS Implementation for on Board Computer \(OBC\SAT-2 Bheema Rajulu, Sankar Dasiga, Naveen Iyer Paper Number: 2413; Presentation Number: 10.0203 On Development of Hilbert-Huan g Transform Data Processing Real Time System with 2-D Capabilities Semion Kizhner Paper Number: 2703; Presentation Number: 10.0204 A Test Scripting Framework for Automated Flig ht SW V&V Testing: Van Allen Probes Lessons Learned Jeremiah Finnigan Paper Number: 2010; Presentation Number: 10.0205 Confidence in Spacecraft So ftware: Continuous Process Improvement in Requirements Verification Kristin Wortman, Maria Spezio Paper Number: 2072; Presentation Number: 10.0206 Testing of Safety-Critical Systems An Aerospace La unch Application Ahmed Gario, Anneliese Andrews, Seana Hagerman Paper Number: 2495; Presentation Number: 10.0207 Software Architecture and Design Abstraction of Abstraction \226 an Outline of General Schedulin g Platform for Space Missions Jinjiang Xing Paper Number: 2655; Presentation Number: 10.0302 The Study of the Virtual Machine fo r Space Real-Time Embedded Systems Sooyeon Kang, Hyungshin Kim Paper Number: 2695; Presentation Number: 10.0303 Table of Contents file:///L:/JOBS/563 35_IEEE AC/HTML CD/HTML/data/toc.htm 29 of 39 5/27/2014 2:12 PM 


Robust and Modular On-board Architec ture for Future Robotic Spacecraft Steffen Jaekel, Martin Stelzer, Hans Herpel Paper Number: 2376; Presentation Number: 10.0304 Model-based Systems and Software Engineering TES' Model-based Systems Engineering \(MBSE\FACETM Applications Stephen Simi Paper Number: 2110; Presentation Number: 10.0401 SOS for SoS: A New Paradigm fo r System of Systems Modeling Matthew Hause Paper Number: 2320; Presentation Number: 10.0402 MBSE without a Process-Based Data Architecture Is Just a Set of Random Characters Robert Crain Paper Number: 2111; Presentation Number: 10.0403 Model-Based GN&C Simulation and Flight Soft ware Development for Orion Missions beyond LEO Ryan Odegard, Zoran Milenkovic Paper Number: 2128; Presentation Number: 10.0404 A Model-Driven Visualization Tool for Use wi th Model-Based Systems Engineering Projects Kathryn Trase, Eric Fink Paper Number: 2192; Presentation Number: 10.0405 Integrated Model-Based Systems Engineering MBSE\d to Simulation of the RAX CubeSat Mission David Kaslow, Sara Spangelo, Grant Soremekun, Hongman Kim Paper Number: 2289; Presentation Number: 10.0406 New HiL Evaluation of an H-In f Controller on the Stabilization of a MAV in Flight Simulation Rafael Coronel B. Sampaio, Andr\351 C. Hernan des, Marcelo Becker Fernando M. Catalano Paper Number: 2521; Presentation Number: 10.0407 Model-Based Requirements Generation Brian London Paper Number: 2584; Presentation Number: 10.0408 Automatic Code Generation for Spacecra ft Attitude Determination and Control Bryce Carpenter Paper Number: 2686; Presentation Number: 10.0409 Implementing Artificial Intelligence for Aerospace Integrating Artificial Intelligence Techniqu es to Generate Ground Station Schedules Costas Tsatsoulis, Michele Van Dyne Paper Number: 2103; Presentation Number: 10.0501 Table of Contents file:///L:/JOBS/563 35_IEEE AC/HTML CD/HTML/data/toc.htm 30 of 39 5/27/2014 2:12 PM 


Missile Trajectory Optimization Usin g a Modified Ant Colony Algorithm Zachary Kiyak, Timothy Ledlow Paper Number: 2185; Presentation Number: 10.0502 Missile System Design Using a Hybrid Evolving Swarm Algorithm Timothy Ledlow, Zachary Kiyak Paper Number: 2225; Presentation Number: 10.0503 Distributed Multi-Agent Systems \226 a Litera ture Survey and Inquisitive Discussion Christopher Elliott Paper Number: 2504; Presentation Number: 10.0504 Star Tracker Orientation Optimization Using Non-dominated Sorting Genetic Algorithm \(NSGA Fabricio Carvalho, Francisco Salazar Paper Number: 2616; Presentation Number: 10.0505 Human-Computer Interaction Exploration with Live Stereoscopic 3D Video in Mixed Reality Environments Jason Kimball, Tom Wypych Paper Number: 2347; Presentation Number: 10.0601 Limitations of Crowdsourcing Using the EMS1998 Scale in Remote Disaster Sensing Andrew Huynh, Michael Eguchi Albert Lin, Ronald Eguchi Paper Number: 2602; Presentation Number: 10.0602 An EMG Enhanced Impedance and Force Control Framework for Telerobot Operation in Space Ning Wang, Chenguang Yang Michael Lyu, Zhijun Li Paper Number: 2675; Presentation Number: 10.0603 Cloud Computing Secure Hybrid Cloud Computing: Approach and Use Cases Kapil Bakshi Paper Number: 2078; Presentation Number: 10.0701 Cloud Computing for Geodetic Imaging Da ta Processing, Analysis, and Modeling Andrea Donnellan, Jay Parker, Jun Wang, Yu Ma, Marlon Pierce Paper Number: 2223; Presentation Number: 10.0702 A Survivability-Centered Rese arch Agenda for Cloud Comp uting Supported ERM Systems Zhanshan \(Sam Paper Number: 2696; Presentation Number: 10.0703 Diagnostics, Prognostics and Health Management \(PHM PHM for Aerospace Subsystems, Components and Structures Uncertainty in Prognostics: Computat ional Methods and Practical Challenges Table of Contents file:///L:/JOBS/563 35_IEEE AC/HTML CD/HTML/data/toc.htm 31 of 39 5/27/2014 2:12 PM 


Shankar Sankararaman, Kai Goebel Paper Number: 2338; Presentation Number: 11.0101 Current/Pressure Transducer Application of Model-Based Prognostics Using Steady State Conditions Christopher Teubert, Matthew Daigle Paper Number: 2323; Presentation Number: 11.0102 Prognostics for Electronics and Avionic Systems Universal Auto-Calibration for a Rapid Batte ry Impedance Spectrum Measurement Device John Morrison, William Morrison Paper Number: 2030; Presentation Number: 11.0201 Integrated Diagnostics and Time to Maintenanc e Estimation for Complex Engineering Systems Mohammad Azam, David Kleinman, Somnath Deb, Deepak Haste, Suvasri Mandal Paper Number: 2642; Presentation Number: 11.0202 Algorithms and Advanced Concepts for Diagnostics and PHM Automatic Systems Diagnosis without Behavioral Models Rui Abreu Paper Number: 2162; Presentation Number: 11.0401 The Use of Data Signatures in Condition Based Maintenance Plus Charles Crabb Paper Number: 2674; Presentation Number: 11.0402 Design Attributes for Diagnostics and Prognostics Health Monitoring Requirements Elicitation via House of Quality Gianluca Nicchiotti Paper Number: 2473; Presentation Number: 11.0601 Total Ownership Cost Reduction for Complex Sy stems through the Design and Application of CBM Jeffrey Banks Paper Number: 2565; Presentation Number: 11.0602 PHM Technologies for Reliability and System Maintenance J69-T-25A Engine Comp onent Failure Analysis Irfan Manarvi Paper Number: 2443; Presentation Number: 11.0701 Analyzing T-53 Series Engines Defect Trends through Maintenance History Irfan Manarvi Paper Number: 2446; Presentation Number: 11.0702 Table of Contents file:///L:/JOBS/563 35_IEEE AC/HTML CD/HTML/data/toc.htm 32 of 39 5/27/2014 2:12 PM 


Systems Health Mana g ement for Space Systems and Operations Model-Based Fault Management for Spacecraft Autonomy Prather Ksenia Kolcio, Paul Zetocha, Louis Breger Paper Number: 2026; Presentation Number: 11.0801 Maturation of Health Management Technologies via Ground/Flight Testing and Research Robust Monitoring of Turbofan Sensors Jerome Lacaille Paper Number: 2059; Presentation Number: 11.1001 Application of Model-based Prognost ics to a Pneumatic Valves Testbed Matthew Daigle, Chetan Kulkarni, George Gorospe Paper Number: 2293; Presentation Number: 11.1002 PHM for Astronauts and Pilots Performance Assessment & Motion Planning Optimization in a Su rgical Trainer for Potential Space Use Aakarsh Rao, Minsik Hong, Akash Shankaran, Jerzy Rozenblit, Wolfgang Fink Paper Number: 2511; Presentation Number: 11.1101 Planning a Pilot Project on the ISS for Crew Health Management & Maintenance beyond LEO Wolfgang Fink, Alexandre Popov, Andrew Hess Paper Number: 2680; Presentation Number: 11.1102 Real-time Online Health Analytics for Interplanetary Space Missions J. Mikael Eklund, Carolyn Mc Gregor Paper Number: 2604; Presentation Number: 11.1103 Personal Health Care and Corresponding Techno logy with Prognostic Capability. Issues and Challenges Olha Kevorkova, Alexandre Popov Paper Number: 2649; Presentation Number: 11.1104 Portable System to Monitor Astronaut Ocul ar Health and the De velopment of the VIIP Syndrome Wolfgang Fink, David Hilmers, Mark Tarbell Paper Number: 2657; Presentation Number: 11.1105 Probabilistic Design for Reliability of Aerospace Electronics Application of Multi-Parametric Boltzma nn-Arrhrnius-Zhurkov Model in Aerospace Optoelectronics Ephraim Suhir Paper Number: 2009; Presentation Number: 11.1201 Table of Contents file:///L:/JOBS/563 35_IEEE AC/HTML CD/HTML/data/toc.htm 33 of 39 5/27/2014 2:12 PM 


Aerospace Electronic Packaging: Thermal St ress in Bi- and Tri-Material Assemblies Ephraim Suhir Paper Number: 2015; Presentation Number: 11.1202 Prediction of Remaining Useful Life of Ball-Gr id-Array Interconnections from Testing on Board Level Laurent Bechou, Derigny David Gucik Paper Number: 2126; Presentation Number: 11.1203 Utilizing Confidence Bounds in Failure Mode Effects Analysis \(FMEA\d Risk Assessment Marc Banghart Paper Number: 2114; Presentation Number: 11.1204 Reliability Testing for Efficien t Validation and Qualification Joseph Bernstein Paper Number: 2049; Presentation Number: 11.1205 HALT, FOAT, and Their Role in Making a Viable Device into a Reliable Product Ephraim Suhir Paper Number: 2050; Presentation Number: 11.1206 Using Physics of Failure to Predict System Level Reliability for Avionic Electronics Greg Caswell Paper Number: 2053; Presentation Number: 11.1207 Injection-Coupled Devices \(ICDs\peration Pr inciple, Applications Design-for-Reliability Konstantin Tapero, Victor Murashev Pavel Ivshin, Sergey Legotin, Andrey Krasnov, Dmitry Elnikov Ephraim Suhir Paper Number: 2157; Presentation Number: 11.1208 Improved Methods for Development of High Reliability Electronics Jue Li Paper Number: 2183; Presentation Number: 11.1209 Long Term In-vacuum Reliability Testing of 980nm Laser Diode Pump Modules for Space Applications Laurent Bechou Paper Number: 2165; Presentation Number: 11.121 Some Major Guiding Principles to Make Future Manned Missions to Mars Safe and Reliable Jean Marc Salotti, Ephraim Suhir Paper Number: 2083; Presentation Number: 11.1211 Designing with Consideration of the Human Fact or: Changing the Paradigm for Higher Safety Sylvain Hourlier, Ephraim Suhir Paper Number: 2614; Presentation Number: 11.1212 PHM for Autonomous Systems A Battery Health Monitoring Framework for Planetary Rovers Table of Contents file:///L:/JOBS/563 35_IEEE AC/HTML CD/HTML/data/toc.htm 34 of 39 5/27/2014 2:12 PM 


Matthew Daigle, Chetan Kulkarni Paper Number: 2291; Presentation Number: 11.1301 PHM for Propulsion Systems Fusing an Ensemble of Divers e Prognostic Life Predictions Oliver Laslett, Zaidan Martha Arbayani Bin, Robert Harr ison, Andrew Mills Paper Number: 2191; Presentation Number: 11.1401 Ground and Space Operations Spacecraft Development and F light Operations:  Challenges Successes, Failures and Lessons Learned Redesign of CloudSat's Maneuver s for Robust Delta-V Operations Ian Gravseth Paper Number: 2131; Presentation Number: 12.0101 ARTEMIS Operations \226 Experi ences and Lessons Learned Manfred Bester Paper Number: 2464; Presentation Number: 12.0102 Juno Spacecraft Operations Lessons Learned for Early Cruise Mission Phases Jeff Lewis Paper Number: 2554; Presentation Number: 12.0103 Changing the Paradigm GSFC's Role in th e MAVEN Mission. Lessons Learned from the MOS/GDS Effort John Hughes, Rosa Carlos Gomez, Brian Thibaudeau Francis Wasiak, Agustin Alfonzo, Juan Cifuentes Paper Number: 2705; Presentation Number: 12.0104 Design of a Spacecraft I&T Facility at the John s Hopkins University Applied Physics Laboratory William Liggett Paper Number: 2200; Presentation Number: 12.0105 Flight/Ground Systems, Mission Planning and Operations Careful and Accurate Placement of Avionics Boxes during Maintenance of Flight Hardware Damon Stambolian, Shihab Asfour, Moataz Eltoukhy Paper Number: 2361; Presentation Number: 12.0201 Design and Development of a Free-Floati ng Hexrotor UAV for 6-DOF Maneuvers Evan Kaufman, Kiren Caldwell, Daewon Lee, Taeyoung Lee Paper Number: 2527; Presentation Number: 12.0202 Using Vicon Bodybuilder and Plug-In-Gait to Generate L5/S1 Angles, Forces and Moments Damon Stambolian, Shihab Asfour, Moataz Eltoukhy Paper Number: 2656; Presentation Number: 12.0205 Table of Contents file:///L:/JOBS/563 35_IEEE AC/HTML CD/HTML/data/toc.htm 35 of 39 5/27/2014 2:12 PM 


MAVEN Information Security Governance, Risk Management, and Compliance \(GRC Learned Eduardo Takamura, Kevin Mangum, Ro sa Carlos Gomez Francis Wasiak Paper Number: 2700; Presentation Number: 12.0206 Aerospace Aircraft Information Display System for Flight Operations in ND Ronald Marsh Paper Number: 2212; Presentation Number: 12.0207 Managing Life Cycle Cost and Risk - Affordability Operability, Sustainability, and Automation A Critical Analysis of Additive Manufacturi ng Technologies for Aerospace Applications Atin Angrish Paper Number: 2601; Presentation Number: 12.0301 Human Space Flight Operations and Processing Space Shuttle Launch Probability Analysis: Un derstanding History So We Can Predict the Future Grant Cates Paper Number: 2502; Presentation Number: 12.0401 Payload and Instrument Operations and Processing Cold Atom Laboratory Mission System Design Melissa Soriano, Anita Sengupta, Kristen Virkler Paper Number: 2084; Presentation Number: 12.0501 Extreme Environment SImulation - a New Capability to Simulate Venus and Other Planetary Bodies Tibor Kremic Paper Number: 2353; Presentation Number: 12.0502 Management, Systems Engineering and Cost System Simulation and Verification Response Surface Based Performance Anal ysis of an Air-Defense Missile System Kerem Gunaydin, Tayfun \307imen Paper Number: 2208; Presentation Number: 13.0101 Modeling and Simulation of Asteroid Retrieval Using a Flexible Capture Mechanism Havard Grip, Jonathan Cameron, Calvin Kuo Steven Myint, Masahiro Ono, Marco Quadrelli Paper Number: 2488; Presentation Number: 13.0102 Analysis of Rover Transmission Interruption Guinian Feng Table of Contents file:///L:/JOBS/563 35_IEEE AC/HTML CD/HTML/data/toc.htm 36 of 39 5/27/2014 2:12 PM 


Paper Number: 2585; Presentation Number: 13.0103 Risk Management: Application and Lessons Learned Low-Cost, Risk-Reduction Testing of Class D Spacecraft Photovoltaic Systems Joshua Forgione Paper Number: 2605; Presentation Number: 13.0201 A Practical Application of a Systems Engineering Process in Space Avionics Design and Development Patrick Phelan Paper Number: 2645; Presentation Number: 13.0202 Cost and Schedule Tools, Methods and Processes Historical Mass, Power, Schedule & Cost Growth for NASA Science Instruments Robert Bitten, Stephen Shinn Paper Number: 2107; Presentation Number: 13.0301 Life-cycle Cost Simulation of a New Implemen tation Process of Government Space Systems Paul Speth, Paul Blessner, Tim Blackburn Paper Number: 2240; Presentation Number: 13.0302 Exploring Classification Algorithms for Early Mission Formulation Cost Estimation Net Marc Sanchez, Daniel Selva, Alessandro Aliakbargolkar Paper Number: 2304; Presentation Number: 13.0303 NASA Instrument Cost Model for Expl orer-like Mission Instruments \(NICM-E Joseph Mrozinski, Agahi Hamid Habib, George Fox Paper Number: 2537; Presentation Number: 13.0304 Enterprise Modeling for Cubesats Louise Anderson, Christopher Lo we, David Kaslow, Eric Sudano Rose Yntema, Sharanabasaweshwara Asundi, Sara Spangelo Paper Number: 2341; Presentation Number: 13.0305 Cost and Risk Analysis of Small Satel lite Constellations for Earth Observation Sreeja Nag, Jacqueline Le Moigne, Olivier De Weck Paper Number: 2459; Presentation Number: 13.0306 FTE Tool, a Practical Tool for Analyzing St affing Levels and Cost across Missions Justin Mc Neill Paper Number: 2279; Presentation Number: 13.0307 Management Tools, Methods and Processes The Legacy of Faster-Better-Cheaper: Too Much Risk or Over-reaction to Failure Merrill Robin Dillon, Peter Madsen Paper Number: 2017; Presentation Number: 13.0401 Table of Contents file:///L:/JOBS/563 35_IEEE AC/HTML CD/HTML/data/toc.htm 37 of 39 5/27/2014 2:12 PM 


Risk-Based Space System Design: A Novel Prob abilistic Approach to Design Risk for Small Satellites Alessandra Babuscia, Kar Ming Cheung Paper Number: 2091; Presentation Number: 13.0402 Collaborative Engineering in Competitive Environments: Th e PTSS Integrated Systems Engineering Team James Leary, Patrick Stadte r, Patrick Binning, David Durey, Jae Heiner, Stephen Kendrick, Dan Schwab Dana Southwood Paper Number: 2130; Presentation Number: 13.0403 Model Linking to Improve Visibility and Re usability of Models during Space System Development Meenakshi Deshmukh, Ren\351 Schwarz, Lopez Rosa Paris Paper Number: 2224; Presentation Number: 13.0404 Boeing's 702 Product Line : Sy stem Engineering a Cost Effective Product Portfolio Strategy Richard Milford Paper Number: 2402; Presentation Number: 13.0405 NASA's New Space Flight Project Requirements Earlier Definition for Later Cost Stability Jeffery Webster Paper Number: 2549; Presentation Number: 13.0406 Using Monte Carlo Simulation as Support for Decision Making While Negotiating a PBL Contract Jan Block Paper Number: 2668; Presentation Number: 13.0407 Using Organizational Messages to Improve the Recognition of Near-Miss Events on Projects Merrill Robin Dillon, Catherine Tinsley Paper Number: 2016; Presentation Number: 13.0408 Mission Modeling, Concept Optimization and Concurrent Design Multi-stakeholder Interactive Simulati on for Federated Satellite Systems Paul Grogan, Alessandro Aliakbargolkar, Olivier De Weck Paper Number: 2163; Presentation Number: 13.0501 Remote Sensing Satellite System Overall Effectiveness Analysis and Modeling Abou Bakr Elhady Paper Number: 2671; Presentation Number: 13.0502 Deep Space Navigation Mission Design and Analysis Tool Prather Ksenia Kolcio, Paul Graven Paper Number: 2023; Presentation Number: 13.0503 Systems Architecture, Engineeri ng and System of Systems Optimization of a Small Sate llite Tridyne Propulsion System Table of Contents file:///L:/JOBS/563 35_IEEE AC/HTML CD/HTML/data/toc.htm 38 of 39 5/27/2014 2:12 PM 


Brian Cohen, Robert Legge Paper Number: 2036; Presentation Number: 13.0601 Experiments in Knowledge-intensive System Architecting: Interactive Architecture Optimization Daniel Selva Paper Number: 2217; Presentation Number: 13.0602 Computer-aided Design & A ssessment of Disaggregate Space System Architectures Robert Thompson Paper Number: 2214; Presentation Number: 13.0603 In-Space Transportation Infrastructure Arch itecture Decisions Using a Weighted Graph Approach Peter Davison, Bruce Cameron Paper Number: 2257; Presentation Number: 13.0604 Trade Space Evaluation of Ascent and Return Ar chitectures for a Mars Sample Return Mission Farah Alibay, Zachary Bailey Paper Number: 2298; Presentation Number: 13.0605 Technology Transfer and Commercialization NASA Innovation Ecosystem: Host to a Go vernment Technology Innovation Network Jill Hardash Paper Number: 2570; Presentation Number: 13.0701 Consideration of Risk versus Reward in Balancing Technology Portfolios Richard Terrile, Andrea Belz Paper Number: 2639; Presentation Number: 13.0702 Promoting \(and Provoking The Politics of Space Launch: All Launch Systems Are Not Nominal Mark Bitterman Paper Number: 2392; Presentation Number: 13.0801 Students Touch Space in Zero Robotics Pr ogramming Competition with Free Downloadable Curriculum Jenny Liu Paper Number: 2673; Presentation Number: 13.0802 From STEM to STEAM: Towards Aerospace Partnerships with Cu ltural Heritage Diagnostics Ashley Richter Paper Number: 2598; Presentation Number: 13.0803 Table of Contents file:///L:/JOBS/563 35_IEEE AC/HTML CD/HTML/data/toc.htm 39 of 39 5/27/2014 2:12 PM 


1 D     1 #-$+.B- 0/:% .0             9 1      18    1 6     1 2  1  1  


1   6      2    1 2 E 8 D 1      1 2   1   1 #-4  #-@E     2  1  1  1       


 8     1          2 F    6   F  2   8    2 C<CC/C N\bO 5      


CD    b$44NO F P Q 6   2 b$$$ ,=\b\bA  A N,O 2 C C  b$$4N  92 2   f  9-\b$$4 B N?O  !-    91  2 1 HH111-18-N+O    -1 :3%   2     0-4 


     b N4O 2   2- \f  C b$@$ \b# >\b\b$3\b$N@O  f :.% 9 /9 \f    1  6  f 2  4   A254 


Advantages of Our M ethod Advantages of Our M ethod Exploit the memory v ertical data format utilizes slidin g windows to g form a much larger database to analyze  Flexibility in Choosing what to choose  Choosing what to choose to build the rules Computational and memory efficiency We have a team working only on this aspect 45 Associative IDS for NextGen Frameworks Dr S Dua LA Tech 45 


Preliminary Results Intra transaction Relations Data rate simulator NH-134 Mb HOP PATH update \(Y/N Inference 11.5 Y Y 2 0.120 N N      Y   n 0.345 N NH134 Y/N   Inf 1 0.150 N N 2 0 120 Y N Inter transaction Relations 2 0  120 Y N       5 5.55 0.456 Y Relations  n 0.345 N N Nmap on DMRL nmap.org 


Anticipated Outcome Anticipated Outcome Develop algorithm capable of learning from a given heterogeneous diverse Develop algorithm capable of learning from a given heterogeneous diverse data ff Dynamic algorithmic f ramework designed to shi f t modalities and sampling rates based on complex logic Flexibility of integration into the Snort intrusion detection system 47 Associative IDS for NextGen Frameworks Dr S Dua LA Tech 47 


References References Aircraft Cockpit Image courtesy USAF http://www.faa.gov htt p   www.faa g ov  air traffic  technolo gy  p g  _ gy  Acharya R Dua S Du X Sree V Chua C K Automated Diagnosis of Glaucoma Using Texture and Higher Order Spectra Features To appear in IEEE Transactions on Information Technology in Biomedicine  Du X Dua S 2011 Cancer Prognosis Using Support Vector Regression in Imaging  Modality World Journal of Clinical Oncology 2  1   44 49 Du X Dua S 2010 Salient Frame Extraction Using Support Vector Regression and Motion Features pp 5 Proc of the National Aerospace and Electronics Conference July 14 16 2010 D M P D S 2010 Di i i ti Ft d Cl ifi ti Mthd f D essaue r  M  P  D ua S  2010  Di scr i m i na ti ve F ea t ures an d Cl ass ifi ca ti on M e th o d s f or Accurate Classification 1st ed vol 7704 pp 14 Bellingham WA Proceedings of SPIE Dessauer M P Dua S 2010 Low Resolution Vehicle Tracking using Dense and Reduced Local Gradient Features Maps 1st ed vol 7694 pp 8 Bellingham WA Proceedings of SPIE SPIE 


Acknowledgements Acknowledgements Fundin g A g encies  US 4 1 Million direct fundin g g g 4 g LA BoR NIH NSF AFRL AFOSR and NASA Research Team Samuel Kasimalla Brandy McKnight Dr Pradeep Chowriappa Connor Johnson Vasanth Nair Mihir Chowriappa  Connor Johnson  Vasanth Nair  Mihir Karnik Mohit Jain and Swadheen Songmen Associative IDS for NextGen Frameworks Dr S Dua LA Tech 49 All the respective Logos belong to their owners 


Rf d Rdi R e f erence d R ea di ngs Copyright of cover pages held by respective publishers 


Thank You Questions Thank You  Questions Dr Sumeet Dua E mail sdua@latech.edu Web http://dmrl.latech.edu Associative IDS for NextGen Frameworks Frameworks Dr S Dua LA Tech 51 Image Source roadtrafficsigns.com 


