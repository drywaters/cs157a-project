978-1-4799-0059-6/13/$31.00 \2512014 IEEE    A Semi-Apriori Algorithm for Discovering the Frequent Itemsets  Sallam Osman Fageeri Department of Computer and Information Sciences  Universiti Teknologi PETRONAS Bandar Seri Iskandar, 31750 Tronoh, Perak, Malaysia Sall_G01825@utp.edu.my, Sallam_fageeri@hotmail.com    Abstract Mining the frequent itemsets are still one of the data mining research challenges. Frequent itemsets generation produce extremely large numbers of generated itemsets that make the algorithms inefficient. The reason is that the most traditional approaches adopt an iterative strategy to discover the itemsets, that\222s require very large process Furthermore, the present mining algorithms cannot perform efficiently due to high and repeatedly database scan. In this paper we introduce a new binary-based Semi-Apriori technique that efficiently discovers the frequent itemsets Extensive experiments had been carried out using the new technique, c ompared to the existing Apriori algorithms, a tentative result reveal that our technique outperforms Apriori algorithm in terms of execution time  Index  Terms 227Data  mining,  Frequent  itemset,  Association Rules, Support, Confidence  I  I NTRODUCTION Data mining is an accumulation of techniques which can be used to efficiently automate discovery of previously unknown novel, valid, valuable and unde rstandable patterns in large scale databases [1, 2  T h e p att ern s s h ou ld b e acti o n ab l e s o th ey   could be applied in enterprise organizations to support decision making. One of the attractions of data mining is that can help us to analyze a huge datasets in an acceptable time scale. Data mining can be additionally well suited for complex problems involving relatively small amounts of data but where you can find many fields or variables to investigate. However, for small simple data analysis problems there might be simpler, cheaper and much more effective solutions  Recently, data mining is a vital aspect for generating association rules, given a set of large number of itemsets. Association rule mining is a technique for discovering interesting relations between variables within the large databases [3  I t  s co n s id e r e d   as one of the important tasks of data mining intended toward decision making  The aim of data mining process is to discover probably the most relevant and interesting patterns and trends from the given data Rohiza Ahmad, Baharum B. Baharudin Department of Computer and Information Sciences  Universiti Teknologi PETRONAS Bandar Seri Iskandar, 31750 Tronoh, Perak, Malaysia  Rohiza_ahmad, Baharbh}@petronas.com.my repository [4, 5  It b eco m es an i m p o r tan t  m ec h an is m u t ili zed  for modern business to transfer data into intelligence prediction giving an informational advantage Association rule mining is often a popular research methods used to discover the relation between a set of items in large databases [6 It i s a h e l p f u l c r i t e ri a t h at  can  be u s e d t o s u pp or t   the decision making. In order to find out the association rules between a collections of items, Agrawal et al n trod uced a n d   developed a well-known algorithm; named Apriori, Apriori is useful to handle association rule mining based problem Currently association rule, knowledge discovery, and frequent pattern have become invaluable in domains such as, health care 8-10  dec i s i on  s u pp o r t  sy s t e m 9    t e l e c o mm un i c a t i on  networks   c r i m e i nve st i g a t i o n [12   l o g fi l e a n a l y s i s  1 3  Intrusion detection[14 Ri sk m a na ge m e nt  1 5   et c H o w e v e r  before using any data mining techniques in order to gather information\222s from a huge dataset, data has to be ready to ensure the sufficient of obtained information Association rule can be written in expression as an implication of X Y, where X and Y are items of itemset I where X  I, Y I, and X Y The expression means that if a transactions T contains the items in X, it also tends to contain the items in Y. An illustration of such a rule might be that 60 out of the total transactions that contain milk also contains sugar; 40% of all transactions contain the two items together Here 60% will be known as confidence of the rule, and 40 will be known as support of the rule. Mining association rules from a set of items idea originates from the data analysis of market-basket, where will be the interest in mining association rules for describing customer\222s interest in buying product items II  P ROBLEM B ACKGROUND The association rules problem normally can be classified into two sub problems. The first problem is to discover the itemsets that their occurrences go beyond a predefined minimum threshold [16   if th e it em sets p a ss th is c o n d i ti o n  th en th ey  w il l  be known as large or frequent items. The second problem is to use those large frequent items to generate association rules with the constraints of minimal confidence. The two parameters use in finding the frequent itemset and association rules are support and confidence.  In this paper we consider the problem of finding the frequent itemsets because it is computationally expensive 


    III. LITERATURE  REVIEW From review of previous works, most of the traditional association rules mining algorithms [15 are f o un d t o  b e s t i l l   suffering and have drawbacks in terms of efficiency; and scalability. Many research efforts are applicable to this paper including a well-known Apriori and its variations. In Apriori breadth search and bottom up approaches are applied. Apriori enumerates all frequent items; and Apriori based algorithms tend to achieve high efficiency; when the database transactions are scarce. In other words, even if there are thousands of items available in the database, only a few of them are accessed in transactions Apriori algorithm Apriori is a one of the first, famous, well known, and scalable algorithm for mining frequent itemsets and association rule Apriori in fact is progress of the two known methods, AIS and SETM.   Apriori   was   introduced   by   Agrawal   and Srikant [18 th e alg o rit h m id ea is to searc h  f o r larg e ite m s ets  during its initial database pass and uses its result for the other large datasets during subsequent passes. Rules having a support level lower than the minimum support threshold are known as infrequent itemsets and those items which have support more than or equal to minimum support, will be known as large frequent itemsets. The algorithm was built on the concept that any subset of a large itemset is frequent if their superset is frequent  T h e pro b l e m o f A p r i or i  a l gor i t h m i s  i t  r e q u i r es   multiple database scan, and additionally generates many candidates. Bellow example illustrates the overall idea of Apriori algorithm Table \(1\ple content of database transactions TID ITEM USED 100 A , C , D 200 B , C , E 300 A , B , C , E 400 B , E                  Given five transactions as in table \(1\ch seen of transactions will omit items which fall below minimum support threshold as shown in fig \(1\e first pass eliminates item D. The second pass combines two items and combinations that have support less than two will be omitted. This process continues until no more combination is possible and hence, the frequent itemset have been reaches Apriori algorithm [7 h e rit s th e p r o b l e m o f  m u lt ip le p a sse s  over the databases. That leads to unoptimal performance speed Thus, many new algorithms inspired their ideas from Apriori they introduced many modifications and improvements. There are two main approaches used: th e first is to reduce the total number of database passes, and the second is to explore different types of pruning techniques in order to make the number of candidate itemsets smaller. To date, these algorithms still can be further improved  V  SEMI-APRIORI  T ECHNIQUE In this part, we present our Semi-Apriori algorithm for mining frequent items which we believe that it outperforms Apriori algorithm. For the purpose of simplifying our discussion on the technique, in this paper we will highlight a database transaction that composed of items and products that are purchased together by customers who visited a supermarket. Earlier   Tabe1 1 shows   sample   content   of   database transactions that is used in this study \(Note TID stands for transaction id and items used for transaction itemsets  The transaction database contains only four transactions and five items; each transaction in the given table shows the purchase of one customer. The given items can be represented as a binary item list by giving 1 to the present item and 0 for the rest Table \(2\hows this concept        Figure \(1\ Apriori Frequent item mining steps 


    Table \(2\Transaction items in a binary representation TID A           B            C D E 100 1 0 1 1 0 200 0 1 1 0 1 300 1 1 1 0 1 400 0 1 0 0 1  Instead of searching the database looking for the occurrences of each item individually; we take a whole transaction and increment the frequency of each ite m appeared in the transaction by one in a vertical processing  Table \(3\ below reveals all actual combinations that occur within the transactions given in table \(2\. For example, in transaction T100, only three items are non-zero which are ACD Thus, the combination of T100 will be A alone, C alone, D alone, AC, AD, CD, and ACD  The Semi-Apriori algorithm for mining frequent items is divided into three stages. The first stage starts by finding the 1-itemsets L 1 and pruning all items that have support less than the given minimum support threshold. This step is similar to the step used in Apriori d FP G r o w t h a l go r i t h ms 1 9    T h e fi r s t  stage output can be shown in table \(4\d the algorithm in figure 2  Table \(4\irst frequent1-itemset A B C E 2 3 3 3  Input: Dataset D minimum support threshold S Output: frequent 1-items \(FI 1  for each binary transaction T Increase the frequency, in freq array, for each item in T hat contains 1 end for for each item i in freq array if freq\(item i  minSup add item i to L1 end if end for  Figure \(2\ First frequent \(1-itemset\ algorithm  In the second stage, the algorithm figure \(3\pplies self-joint of L 1 using L 1 L 1 also using the support measure. The items which are below the minimum support will be pruned. The second stage output can be shown in table \(5\nd the algorithm in figure \(3 Table \(5\ Second frequent 2-itemset AC BC BE CE   2 2 3 2 Input: first frequent 1-itemset Output: frequent 2-items \(FI 2  for i=1 to length\(L 1  for j=i+1 to length\(L 1  calculate sup \(item i item j ing eq. \(1\f Sup \(item i item j  minSup add item i to L 2 end if calculate Sup \(item i item j  if Sup \(item i item j  minSup add item j to L 2 end if end for end for Figure \(3\ second frequent \(2-itemset\ algorithm Table \(3\elow reveals all actual combinations that occur within the transactions given in table \(2\. For example, in transaction T100, only three items are non-zero which are ACD. Thus, the combination of T100 will be A alone, C alone, D alone, AC, AD CD, and ACD Tables \(3\ actual combinations  TID Items Combinations 100 A, C, D,   AC,   AD,   CD,   ACD 200 B, C, E ,  BC,   BE,    CE,    BCE 300 A,B,C,E,AB, AC, AE, BC, BE, CE, ABCE 400 B, E, BE   In the third stage, the frequent itemsets of size > 2 are generated The algorithm in this part starts by reading all transactions from the database. For each transactio n, the algorithm selects the items in the transaction that appears in 2-itemsets and add them to the local candidate set CS. Th e algorithm then proceeds to generates all the subsets of CS. For each generated subset, the algorithm calculates its binary map. After getting the map the algorithm looks for the map in the frequency table FT. If the map is already available in FT then the algorithm updates the frequency of this map increasing it by one. If the map doesn\222t exist then it\222s appended to FT and its frequency is set to 1. In order to avoid recalculation of the subsets, the algorithm firstly check whether the binary map of CS appears before or not. If the map appeared before then the algorithm go directly for updating the frequency of all binary maps that corresponds to the subsets of CS. This last part of avoiding recalculations of subsets is not shown in the algorithm because of space limitations Once this process finished, the algorithm traces all the frequencies in the FT table to get frequent itemsets of size >2 For each frequency that is having a value which is greater than threshold value of minSup the algorithm generates the reverse map of this frequency to get its constituent items back. These items represent the frequent mined items. The third stage output can be shown as in figure 4       


Figure \(6\ Execution time using Mushroom Dataset     Input: Dataset D FI, minimum support threshold S Output: Frequent Itemsets of size >2  While not eof\(DS CS Read T from DS For All items\(T\ do If item i T L2 Add item i T\ to CS End if End for For each subset ss in CS  Calculate m = map\(ss If frequency table FT contains m  Increase the frequency of m by 1 Else Add m to frequency table FT Set FT\(m\1 End for End while For each row r in FT if frequency\(r minSup Get mapInv=map 1 r Selects the items that corresponds to the 1s in mapInv from list of itemset end if end for  Figure \(4\enerating itemsets of size > 2 algorithm and 2 GB of RAM computer. Graph 1 and graph 2 in figure 5\ and figure \(6\respectively shows the comparison of the execution time for discovering the frequent itemsets using synthetic dataset T40I10D100K provided by the QUEST generator from IBM\222s Almaden lab, and the real dataset mushroom, that\222s publicly available in the FIMI dataset repository. The two datasets are having different transaction size, item size, and other behaviors. The graph x axis has support level 0.04 to 0.09 for the first graph, and 0.05 to 0.3 for the second graph respectively, and y axis are carrying an execution time in milliseconds. This experiment considers the minimum support to count execution time  Through analyzing the experiments it\222s shown that when the minimum support is low the execution time increase and vice versa, in some cases a low measure support itemset is unlikely interesting from a business perspective when promoting the items that customer seldom bought together using   the   market   basket   analysis   concept.   From   this experimental study, the proposed semi-Apriori algorithm has shown better performance as compared to Apriori. For the both datasets, the execution time differs greatly between the original Apriori and semi-Apriori algorithms, when the minimum support is low. This is good since in data mining, scalability of the algorithms depends on ability to handle small minimum support    Table \(6\ynthetic and real dataset's properties VI  E XPERIMENTS AND RESULTS To compare performance of our algorithm with Apriori experiments were conducted on Intel\256 corei5\231 CPU, 2.4 GHz Dataset Transactions T40I10D100K 100,000 Mushroom 8,124 Items Type AvgLength 1000 Sparse 40 119 Dense 23             Figure \(5\ Execution time using T40I10D100K Dataset  0 2000 4000 6000 8000 10000 12000 0.3 0.25 0.2 0.15 0.1 0.05 Execution time\(MS Support Apriori Semi-Apriori 0 500 1000 1500 2000 2500 3000 3500 4000 4500 0.09 0.08 0.07 0.06 0.05 0.04 Execution time\(MS Support Apriori Semi-Apriori 


   VII  C ONCLUSION Mining frequent pattern is a challenge in data mining. This paper introduced a new technique that efficiently discovers the frequent itemsets. The proposed technique avoids repeated database scans, also the algorithm avoids the cost of generating large number of candidate sets; hence, minimize the execution time. Extensive experiments have been carried out using the new technique, the algorithm was also compared to Apriori algorithm, the result reveal that our technique outperforms Apriori algorithm in terms of execution time to discover the frequent itemsets R EFERENCES 1  D. Braha Data mining for design and manufacturing methods and applications Kluwer academic publishers 2001 2  U  Fay y a d G  P i a t e t sky Sha p ir o, a nd P  Sm y t h F r o m d a ta mining to knowledge discovery in databases AI magazine vol. 17, p. 37, 1996 3  G K a ur a n d S  A g g a rw a l   A S u r v e y of G e ne tic A l g o r i t h m  for Association Rule Mining International Journal of Computer Applications vol. 67, pp. 25-28, 2013 4   J   C io s  Data mining: a knowledge discovery approach  Springer, 2007 5 M. Linares V\341squez, D. F. Hern\341ndez Losada, and F Gonz\341lez Osorio, "Exploiting stock data: a survey of state of the art computational techniques aimed at producing beliefs regarding investment portfolios Ingenier\355a e Investigaci\363n vol. 28, pp. 105-116, 2008 6  P Mi s h r a N  Pa d h y   a n d R  Pa n i g r a h i    T he s u r v e y of da ta  mining applications and feature scope ASIAN JOURNAL OF    COMPUTER    SCIENCE    &    INFORMATION TECHNOLOGY vol. 2, 2013 7  R.  Agrawal,  T.  Imieli ski,  and  A.  Swami,  "Mining association rules between sets of items in large databases," in ACM SIGMOD Record 1993, pp. 207-216 8  S. U. Kumar, H. H. Inbarani, and S. S. Kumar, "Bijective soft set based classification of medical data," in Pattern Recognition,   Informatics   and   Medical   Engineering PRIME\, 2013 International Conference on 2013, pp. 517 521 9  R. Al Iqbal, "Hybrid clinical decision support system: An automated diagnostic system for rural Bangladesh," in Informatics,   Electronics   &   Vision ICIEV\, 2012 International Conference on 2012, pp. 76-81 1  B  Milov i c   P r e dic tion a nd de c i s i on m a k i ng in He a lth C a r e  using Data Mining International Journal of Public Health Science \(IJPHS vol. 1, pp. 69-78, 2012 11  M. V. Joseph, "Data Mining and Business Intelligence Applications in Telecommunication Industry International Journal of Engineering and Advanced Technology \(IJEAT vol. 2, pp. 525-528, 2013 1  R  Suj a th a a nd D  E z hi l m ar a n A  P r opo sa l f o r A n a l y s i s  o f  Crime Based on Socio-Economic Impact using Data Mining Techniques International Journal of Societal Applications of Computer Science vol. 2, pp. 229-231, 2013 13  S. O. Fageeri, R. Ahmad, and B. Baharum, "A Log File Analysis Technique Using Binary-Based Approach," in Proceedings  of  the  First  International  Conference  on Advanced  Data  and  Information  Engineering  \(DaEng 2013 2014, pp. 3-11 14  A. Chauhan, G. Mishra, and G. Kumar Survey on Data mining Techniques in Intrusion Detection Lap Lambert Academic Publ, 2012 15  H. Q. Le, S. Arch-int, H. X. Nguyen, and N. Arch-int Association rule hiding in risk management for retail  supply chain collaboration Computers in Industry 2013 16  K. Rameshkumar, M. Sambath, and S. Ravi, "Relevant association rule mining from medical dataset using new irrelevant  rule  elimination  technique,"  in Information Communication and Embedded Systems \(ICICES\, 2013 International Conference on 2013, pp. 300-304 17  M.  N.  Dehkordi,  "A  Novel  Association  Rule  Hiding Approach in OLAP Data Cubes Indian Journal of Science and Technology vol. 6, pp. 4063-4075, 2013 18  R. Agrawal and R. Srikant, "Fast algorithms for mining association rules," in Proc. 20th Int. Conf. Very Large Data Bases, VLDB 1994, pp. 487-499 19  J  Ha n, J  P e i, Y   Y i n a nd R  Ma o  M inin g  f r e que nt pa tt e r n s  without  candidate  generation:  A  frequent-pattern  tree approach Data mining and knowledge discovery vol. 8 pp. 53-87, 2004  


 M Verl eysen D   Francois, G   Si m o n, and V  We rtz  O n the effects  of dimensionality on data analysis with neural networks,é in Artificial Neural Nets Problem solving methods Springer, 2003, pp. 105Ö112   P D Shenoy K Sr inivasa a nd A O. T h o m as, çCo m p ress and M i ne An Efficient Graph Based Algorithm to Generate Frequent Itemsets 2004  N. Pasquier, Y. B a stide, R Taouil, and L. Lakhal, çEfficient mining of association rules using closed itemset lattices,é Information systems, vol. 24, no 1, pp. 25Ö46, 1999  F. Hadzic  H Ta n, and T. S Dillo n M ining m a xim a l  and closed frequent subtrees,é in Mining of Data with Complex Structures Springer, 2010, pp. 191Ö199   R M a r ghoubi A. Boulm akoul and K. Zeitouni The Use of the Galois lattice for the extraction and the visualization of the spatial association rules,é in Signal Processing and Information Technology 2006 IEEE International Symposium on, 2006, pp. 606Ö611  D.-I. Lin and Z M  Kede m   P incer-s earch: an efficient algorith m for discovering the maximum frequent set,é Knowledge and Data Engineering, IEEE Transactions on, vol 14, no. 3, pp. 553Ö566 2002  R. J. Bayardo Jr Efficiently mining long patterns from databases in ACM Sigmod Record, 1998, vol 27, no. 2, pp. 85Ö93   D. Bur dick, M Calim li m  and J. Gehrke, çMAFIA: A maximal frequent itemset algorithm for transactional databases,é in Data Engineering, 2001. Proceedings. 17t h International Conference on 2001, pp. 443Ö452  Q Zou, W. W   Chu, and B. Lu, çSmartM iner: A depth first algorithm guided by tail information for mining maximal frequent itemsets,é in Data Mining, 2002. ICDM 2003. Proceedings. 2002 IEEE International Conference on 2002, pp. 570Ö577   D. H V. V. R. P.C S.Nagendra setty, çImproved Maximal Length Frequent Item Set Mining,é 2012  K. Gouda and M. J. Zaki Genmax: An efficient algorithm for mining maximal frequent itemsets,é Data Mining and Knowledge Discovery, vol. 11, no. 3, pp. 223Ö242, 2005   T. Hu S. Y. Sung H Xiong, and Q. Fu, çDiscovery of maximum length frequent itemsets,é Information Sciences vol. 178, no. 1, pp 69Ö87, 2008   A. J. Lee, C  S  W a ng W  Y Weng, Y.-A. Chen, and H.-W. Wu An efficient algorithm for mining closed inter-transaction itemsets Data \\& Knowledge Engineering, vol. 66 no. 1, pp. 68Ö91, 2008   S. Pr abha, S. Shan m ugapr iy a and K. Duraiswamy, çA Survey on Closed Frequent Pattern Mining  M. J  Zaki and C. Hsiao, çCha rm  a n efficient algorith m for closed association rule mining,é 1999  J. Pei, J Han, an d R Mao, çCLOSET: An Efficient Algorithm for Mining Frequent Closed Itemsets.,é in ACM SIGMOD workshop on research issues in data mining and k nowledge discovery, 2000, vol. 4 no. 2, pp. 21Ö30  J. W a ng, J Han, and J. Pei, çCloset+: Searching for the best strategies for mining frequent closed itemsets,é in Proceedings of the ninth ACM SIGKDD international conference on Knowledge discovery and data mining, 2003, pp. 236Ö245   F. Pan G. Cong A K. Tung, J. Yang, and M. J. Zaki, çCarpenter Finding closed patterns in long biological datasets,é in Proceedings of the ninth ACM SIGKDD international conference on Knowledge discovery and data mining 2003, pp. 637Ö642  F. Pan, A Tung G. Cong, and X. Xu Cobbler: Combining column and row enumeration for closed pattern discovery,é in Scientific and Statistical Database Management, 2004. Proceedings. 16th International Conference on 2004, pp. 21Ö30  J. W a ng, J Han, Y. Lu and P. Tzvetkov, çTFP: An efficient algorithm for mining top-k frequent closed itemsets,é Knowledge and Data Engineering, IEEE Tr ansactions on, vol. 17, no 5, pp. 652Ö663 2005   H Liu, J. Han, D. Xin, and Z Shao, çMining fr equent patter ns fr o m  very high dimensional data: A top-down row enumeration approach in Proceeding of the 2006 SIAM international conference on data mining \(SDMê06\, Bethesda, MD, 2006, pp. 280Ö291  H. Moonesinghe, S Fodeh, and P.-N. Tan, çFrequent closed itemset mining using prefix graphs with an efficient flow-based pruning strategy,é in Data Mining, 2006 ICDMê06. Sixth International Conference on, 2006, pp. 426Ö435   H  L i u X  W a ng, J He J  Han D. Xin and Z   Shao T opdown  mining of frequent closed patterns from very high dimensional data Information Sciences, vol. 179 no. 7, pp. 899Ö924, 2009  B. Nair and A. K  Tripathy A ccel erating Closed Fre quent Ite m set Mining by Elimination of Null Tr ansactions,é Journal of Emerging Trends in Computing and Information Sciences, vol. 2, no. 7, pp 317Ö324, 2011  R. Agrawal and R. Srikant Fast algorithms for mining association rules,é in Proc. 20th int. conf very large data bases, VLDB, 1994 vol. 1215, pp. 487Ö499  M K Sohrabi and A. A Barforoush, çE fficient colossal pattern mining in high dimensional datasets,é Knowledge-Based Systems vol. 33, pp. 41Ö52, 2012  D. Burdick, M. Calim li m  J Flannick, J. Gehrke, and T. Yiu, çMafia A maximal frequent itemset algorithm,é Knowledge and Data Engineering, IEEE Transactions on, vol 17, no. 11, pp. 1490Ö1504 2005  M. J  Zaki and K. Gouda Fast vertical mining using diffsets,é in Proceedings of the ninth ACM SIGKDD international conference on Knowledge discovery and data mining, 2003, pp. 326Ö335   Y M M a o, Z   G Chen and L  X L i u Fast M i ning of Cl osed  Frequent Itemsets in Data Streams,é Applied Mechanics and Materials, vol. 263 pp. 231Ö240, 2013  Y. Chi H Wang S. Y. Philip, and R. R Muntz C atch the m o m e nt  maintaining closed frequent itemsets over a data stream sliding window,é Knowledge and Information Systems, vol. 10, no. 3, pp 265Ö294, 2006  S. Mutalib S. Ab dul-Rah m an and A. Mohamed, çTowards Mining Frequent Patterns in Genome Wide Association,é in Computational Science and Engineering \(CSE\2013 IEEE 16th International Conference on, 2013, pp. 1096Ö1100   62 


VI Tanbeer, S. K., Ahmed, C. F., Jeong, B.-S., & Lee, Y.-K, \215Sliding window-based frequent pattern mining over data streams,\216 Information Sciences, 179\(22\, pp. 3843\2053865, 2009 9 Chang, J., & Lee, W. S, \215Finding recently frequent itemsets adaptively over online transactional data streams,\216 Information Systems, 31\(8\, pp. 849\205869, 2006 4 Agrawal, R., & Srikant, R, \215Fast algorithms for mining association rules,\216 In Proc. VLDB int. conf. very large databases \(pp. 487\205 499\, 1994 3 Tsai, P. S. M, \215Mining frequent itemsets in data streams using the weighted sliding window model,\216 Expert Systems with Applications, 36\(9\, pp. 11617\20511625, 2009  minimum change threshold Y. Chi, H. Wang, P. S. Yu and R. R. Muntz. Catch the moment maintaining closed frequent itemsets over a data stream sliding window. In KAIS, 10\(3\: pp. 265-294, 2006 6 V. kumar, S. satapathy, \215A review on algorithms for mining frequent itemsets over data stream,\216 in ijarcsse V3 I4, 2013 8 CONCLUSION AND FUTURE WORK  Considering the continuousness of a data stream, the traditional methods or techniques for finding frequent itemsets in conventional data mining methodology may not be valid in a data stream. This is because we cannot consider whole data and must identify when a data becomes obsolete or invalid As the old information of a data stream may be no longer useful or possibly invalid at present.  In order to support various requirements of mining data stream, the mining window or the interesting recent range of a data stream needs not to be defined static but must be flexible. Based on this range, a data mining method can be able to identify when a transactions becomes stale or needs to be disregarded  In this paper, we have investigated the problem of mining frequent itemset over data stream using flexible size sliding window model and proposed a new algorithm for this problem. The size of sliding window is adaptively adjusted based on the amount of observed concept change in the underlying properties of incoming data stream. The size of window enlarges or increase when there is no significant amount of change observed. While the window size reduced or decrease when there is considerable amount of concept change or significant change in set of frequent itemsets occurs Based on the value of given by user, the size of window is being controlled. After every pane insertion the set of frequent itemsets are updated and value of concept change is calculated. If the value exceeds the given minimum change threshold the window gets smaller by deleting all the obsolete information before a point defined called checkmark  Experimental results shows that our algorithm tracks the concept change efficiently while mining data stream and is more adaptive to recent frequent itemsets than fixed size sliding window models or time fading window models. For the future work, we are trying to enhance the performance by using fuzzy sets for minimum change threshold value so that the values like low, medium, high and very high instead of certain value between ranges of 0 to 1 R EFERENCES  1                    H. Li, S. Lee, and M. Shan, \215An Efficient Algorithm for Mining Frequent Itemsets over the Entire History of Data Streams\216, In Proc. of First International Workshop on Knowledge Discovery in Data Streams, 2004  F. Nori, M. Deypir, M. Sadreddini, \215A sliding window based algorithm for frequent closed itemset mining over data streams\216 journal of system and software, 2012  Zaki, M. \(2000\. Scalable algorithms for association mining. IEEE Transactions on Knowledge and Data Engineering, 12\(3\, 372\205 390  Woo H. J., & Lee, W. S. \(2009\. estMax: Tracing maximal frequent item sets instantly over online transactional data streams IEEE Transactions on Knowledge and Data Engineering, 21\(10 1418\2051431  Mozafari B, Thakkar H, Zaniolo C, \215Verifying and mining patterns from large windows over data streams,\216 In Proc. Int. conf. ICDE pp. 179-188, 2008  Koh, J.- L., & Lin, C.- Y, \215Concept shift detection for frequent itemsets from sliding window over data streams\216, lecture notes in computer science: Database systems for advanced applications \(pp 334\205348\ DASFAA Int. Workshops, Springer-Verlag.2009  Han, J., Cheng, H., Xin, D., & Yan, X. Frequent pattern mining Current status and future directions. Data Mining and Knowledge Discovery, 15\(1\, pp.  55\20586, 2007 5 C. Giannella, J. Han, J. Pei, X. Yan, and P. S. Yu. Mining frequent patterns in data streams at multiple time granularities. In Kargupta et al.: Data Mining: Next Generation Challenges and Future Directions, MIT/AAAI Press, 2004 7 2014 IEEE International Advance Computing Conference IACC 510 J. H. Chang and W. S. Lee. estWin: Adaptively Monitoring the Recent Change of Frequent Itemsets over Online Data Streams. In Proc. of CIKM, 2003  J. Yu, Z. Chong, H. Lu, and A. Zhou. False Positive or False Negative: Mining Frequent Itemsets from High Speed Transactional Data Streams. In Proc. of VLDB, 2004      Aggarwal, C, \215A framework for diagnosing changes in evolving data streams,\216 In Proc. ACM SIGMOD int. conf. on management of data \(pp. 575\205586\ 2003 2 Manku, G. S., & Motwani, R. Approximate frequency counts over data streams. In Proc. VLDB int. conf. very large databases \(pp 346\205357\ 2002  


002 
                          
R. Agrawal and R. Srikant. Fast algorithms for mining association rules in large databases. In Proc. VLDB, pages 487Ö499, 1994 2 R. J. Bayardo, Jr. Efficiently mining long patterns from databases SIGMOD Rec., pages 85Ö93, 1998 3 M. Zaki, S. Parthasarathy, M. Ogihara, and W. Li. Parallel algorithms for discovery of association rules. Data Min. and Knowl. Disc., pages 343Ö373, 1997 4 J. Dean and S. Ghemawat. MapReduce: Simplified data processing on large clusters. In Proc. OSDI. USENIX Association, 2004 5 Apache hadoop. http://hadoop.apache.org/, 2013 6 Jiawei Han and Micheline Kamber. Data Mining, Concepts and Techniques. Morgan Kaufmann, 2001 7 M. Zaharia, M. Chowdhury, T. Das, A. Dave, J. Ma, M. McCauley M. Franklin, S. Shenker, and I. Stoica. Resilient distributed datasets A fault-tolerant abstraction for in-memory cluster computing Technical Report UCB/EECS-2011-82, EECS Department University of California, Berkeley, Jul 2011 8 M. Zaharia, M. Chowdhury, M. J. Franklin, S. Shenker, and I. Stoica Spark: Cluster Computing with Working Sets. In HotCloud, 2010 9 J. Han, J. Pei, and Y. Yin: Mining Frequent Patterns without Candidate Generation. In: Proceedings of the 2000 ACM SIGMOD International Conference on Management of Data, 29\(2\:1-12, 2000 10 M. J. Zaki. Parallel and distributed association mining: A survey IEEE Concurrency, pages 14Ö25, 1999 11 J. Li, Y. Liu, W.-k. Liao, and A. Choudhary. Parallel data mining algorithms for association rules and clustering. In Intl. Conf. on Management of Data, 2008 12 E. Ozkural, B. Ucar, and C. Aykanat. Parallel frequent item set mining with selective item replication. IEEE Trans. Parallel Distrib Syst., pages 1632Ö1640, 2011 13 B.-H. Park and H. Kargupta. Distributed data mining: Algorithms systems, and applications. 2002 14 L. Zeng, L. Li, L. Duan, K. Lu, Z. Shi, M. Wang, W. Wu, and P. Luo Distributed data mining: a survey. Information Technology and Management, pages 403Ö409, 2012 15 Li L. & Zhang M. \(2011\. The Strategy of Mining Association Rule Based on Cloud Computing. Proceeding of the 2011 International Conference on Business Computing and Global Informatization BCGIN è11\. Washington, DC, USA, IEEE: 475- 478 16 Li N., Zeng L., He Q. & Shi Z. \(2012\. Parallel Implementation of Apriori Algorithm Based on MapReduce. Proc. of the 13th ACIS International Conference on Software Engineering, Artificial Intelligence, Networking and Parallel & Distributed Computing SNPD è12\. Kyoto, IEEE: 236 Ö 241 17 Lin M., Lee P. & Hsueh S. \(2012\. Apriori-based Frequent Itemset Mining Algorithms on MapReduce. Proc. of the 16th International Conference on Ubiquitous Information Management and Communication \(ICUIMC è12\. New York, NY, USA, ACM: Article No. 76 18 Yang X.Y., Liu Z. & Fu Y. \(2010\. MapReduce as a Programming Model for Association Rules Algorithm on Hadoop. Proc. of the 3rd International Conference on Information Sciences and Interaction Sciences \(ICIS è10\. Chengdu, China, IEEE: 99 Ö 102 19 S. Hammoud. MapReduce Network Enabled Algorithms for Classification Based on Association Rules. Thesis, 2011 20 Synthetic Data Generation Code for Associations and Sequential Patterns. Intelligent Information Systems, IBM Almaden Research Center http://www.almaden.ibm.com/software/quest/Resources/index.shtml 21 C.L. Blake and C.J. Merz. UCI Repository of Machine Learning Databases. Dept. of Information and Computer Science, University of California at Irvine, CA, USA. 1998 http://www.ics.uci.edu/mlearn/MLRepository.html 22 HadoopApriori. https://github.com/solitaryreaper/HadoopApriori 2 3 H.V. Nguyen, E. Muller, K. Bohm. 4S: Scalable Subspace Search Schema Overcoming Traditional Apriori Processing. 2013 IEEE International Conference on Big Data. 2013 24 S. Moens, E. Aksehirli and Goethals. Frequent Itemset Mining for Big Data. University Antwerpen, Belgium. 2013 IEEE International Conference on Big Data. 2013 25 Y. Bu et al . HaLoop: E cient iterative data processing on large clusters. Proceedings of the VLDB Endowment, 3\(1-2\:285Ö296 2010 26 Frequent itemset mining dataset repository. http://fimi.us.ac.be/data 2004   
002 
Our experiments show that YAFIM is about 18 faster than Apriori algorithms implemented in MapReduce framework Furthermore, we can achieve a better performance in both sizeup and speedup for different datasets. In addition, we also evaluated YAFIM for medical application and revealed that YAFIM outperforms MRApriori about 25 speedup  A CKNOWLEDGMENT  This work is funded in part by China NSF Grants \(No 61223003\, and the USA Intel Labs University Research Program R EFERENCES  1 
002 
1671 


