An Adaptive Method for Mining Frequent Itemsets Efìciently An Improved Header Tree Method O.Jamsheela Department of Information Technology Kannur University Email ojamshi@gmail.com Raju.G Department of Information Technology Kannur University Email:kurupgraju@gmail.com Abstract Data mining has become an important eld and has been applied extensively across many different areas Mining frequent itemsets from a transaction database is crucial for mining association rules FP-growth algorithm has been widely used for frequent pattern mining and it is one of the most important algorithm proposed to efìciently mine association rules because it can dramatically improve the performance compared to the Apriori algorithm Many investigations have proved that FPgrowth method outperforms the method of Apriori-like candidate 
generation The performance of the FP-growth method depends on many factors the data structures recursive creation of pattern trees searching sorting insertion and many more In all of the algorithms which are using fp-tree a header table is used with sorted items Header table is an important data structure in the mining process The main datastructure frequent trees is created with the use of the header table In this paper we suggest a new Binary Search Header Three BSHT and an Improved Header Tree mining IHT-growth to improve the performance of the frequent pattern mining Experimental results show that the mining with BSHT is efìcient for frequent pattern mining I I NTRODUCTION The process which has considered as an important aspect of data mining is discovering association rules among the large number of item sets A lot of algorithms and techniques has 
been developed in this area Among the existing techniques the frequent pattern growth FP-growth method proposed by Han et is the most ef cient and feasible approach It mines the frequent item set by using a frequent pattern tree FP-tree  with a header table and avoids costly candidate generation FP-tree is a data structure that is used for storing frequent patterns or itemsets in association rule mining It therefore achieves much better performance and efìciency than Apriorilike algorithms It scans the database only twice Frequent itemset mining is an important problem in the data mining area It was rst introduced by Agrawal et a in the context of transaction databases The problem of frequentitemsets mining can be deìned as follows A transaction database is a database containing a set of transactions and each transaction is associated with a unique transaction id Let D  t 1 t 
2   t N  be a transaction database and I   i 1 i 2 i n   be the set of items appearing in D where t i i   is a transaction and t i  I Each subset of I is called an itemset If an itemset contains k items then the itemset is called a k-itemset The support of itemset l in database D is deìned as the percentage of transactions in D containing l  that is support D  l 
  t  t  D and l  t    D  ie  l    D  If support D  l   min  sup where min sup\(min sup   is a user-speciìed minimum support threshold then l is called a frequent itemset in D Given a transaction database and a minimum support threshold the task of frequent itemset mining is to nd all frequent itemsets in the transaction database An association rule is a conditional implication among itemsets  X  Y  where X 
 I Y  I X    Y    and X  Y   The conìdence of the association rule given as sup\(X  Y X is the conditional probability among X and Y such that the appearance of X in t i implies the appearance of Y in t i Mining the association rules that have support and conìdence greater than the min sup and the user-deìned minimum conìdence is the problem of association rule mining Discovering frequent itemsets is the important and time consuming step in the process of mining association rules A huge number of candidate itemsets are generated during the mining process The step of rule construction is direct and less 
expensive Therefore most researchers concentrate on the rst phase for nding frequent itemsets In addition to the problem of the large number of candidates this algorithm also demands an efìcient data structure to store frequent itemsets for further processing Agrawal and Srikant 1994 proposed the Apriori algorithm for mining frequent itemsets Apriori uses a candidate generation method such that the frequent k-itemset in one iteration can be used to construct candidate k  1 itemsets for the next iteration Apriori terminates its process when no new candidate itemsets can be generated Various methods are proposed by researches as the improvement of Apriori However those methods cannot avoid scanning the database many times to verify frequent itemsets Han et introduced the FP-gro wth algorithm without generating candidate itemsets to mine frequent itemsets FPgrowth uses a Frequent Pattern tree\(FP-tree a header table for efìciently mining association rules In this method the FPtree captures the content of the transaction database and stores 
all the transactions\(only frequent items in a compressed form It scans the database only twice  In addition to FP-tree another data structure called header table is used to nd frequent itemsets quickly by traversing the tree The header table stores frequent 1-itemsets in decreasing order of their frequencies Each item in the header table points to the rst occurrence of the corresponding node in FP-tree All nodes with similar items in FP-tree are connected by using a link between them After completing the FP-tree construction  the next step of the FP-growth algorithm is to mine frequent patterns from FP-tree It starts the mining from the least frequent item to the most frequent item It traverses from the leaf nodes of the FP-tree to 1078 978-1-4799-8792-4/15/$31.00 c  2015 IEEE 


the root Paths with the same preìx item in the FP-tree are used to construct the conditional FP-tree and its header table Using the conditional FP-tree the algorithm can generate frequent itemsets with the same preìx According to the experimental results FP-growth is faster than the Apriori algorithm and several other methods of mining frequent Our challenge is to improve the efìciency of the algorithm In this paper we propose a new improved header table and an efìcient way of transaction processing to construct FP-tree II RELATED WORK Frequent pattern mining extracts patterns with supports higher than or equal to a minimum support threshold and many mining methods have been introduced  but and FP-gro are still re garded as the popular algorithms Apriori is the oldest conventional mining algorithm and it generates candidate patterns in advance and then conìrms whether the candidates are actually frequent patterns by scanning a database Apriori scan the database as much as the maximum length among frequent patterns FPgrowth solved the problem of unwanted scan  it scans a database only twice It uses a tree structure called FP-tree which can prevent the algorithm from generating candidate patterns FP-tree consists of a tree for storing the items in a transactional database and a header table containing item names supports and node links link is pointing to the corresponding rst item in the tree Fp-tree is composed of nodes where each of them includes an item name a support a parent pointer a child pointer and a node link The node link is a pointer that connects all nodes with the same item to each other Since the FPgro algorithm w a s proposed v arious algorithms ha v e been published on the basis of the Gw angb umet  recommended an impro v e d tree structure to implement an outstanding frequent pattern mining technique by introducing a new tree structure called Linear Preìx Tree LP-Tree tree is composed of array forms to minimize pointers between nodes Yuh-JiuanTsay et suggested a novel method the Frequent Items Ultrametrictrees\(FIUT for mining frequent itemset The FIU-tree structure is used to enhance the efìciency in obtaining frequent itemsets FanChen presents an adapti v e mechanism to select and use a suitable data structure among two pattern list structures to mine frequent itemsets The two methods are the Frequent Pattern List FPL for sparse databases and the Transaction Pattern List TPL for dense databases The selection criteria is depending on database densities  they give a method to calculate the database density Ke-Chung Lin et al proposed an improved frequent pattern\(IFP growth method for mining association rules Authors of the paper pointed out that the proposed algorithm requires less memory and shows better performance in comparison with FP-tree based algorithms In the paper the authors propose a new IFP-growth Improved FP-growth to improve the performance of FP-growth First the IFPgrowth employs an address-table structure to lower the complexity of searching in each node in an FP-tree It also uses a hybrid FP-tree mining method to reduce the need for rebuilding conditional The IFP growth use additional memory for holding an address table for each node  This results in lack of memory to store those additional data Address table is containing item name and pointer to its child  IFP growth does not reduce the size of trees since it still uses the original-tree-based structures with additional address tables As a result we need to develop a new algorithm to reduce the running time without increasing the memory usage to improve fundamental performance of the mining algorithm Consequently we propose a novel algorithm by introducing some new methods to process the transactions for satisfying both runtime and memory efìciency In our algorithm its runtime and memory performances are more outstanding than those of the above mentioned methods due to its efìcient transaction processing with the use of BST\(binary search tree data structures III THE IMPROVED HEADER TABLE Various factors are affecting the performance of the mining process of FP-tree algorithm the insertion of transactions into the tree searching for items traversing in fp-tree  data structures  node structure and pruning are only few of them The mining process starts by scanning the transaction database to nd out the frequent 1-itemsets During this process the datastructure used to store all the items is also effect the running time of the mining process Total number of items in a transaction database may not be known in an earlier stage To use the simple data structure array we should know the number of items earlier because array is a static datastructure To calculate the number of items we have to scan the database one more time FP-growth and other related methods already use two scans to create the tree To improve the efìciency the researchers are trying to reduce the database scan So here we can use a dynamic data structure Binary Search Tree BST then only we can add items during the scan The BST is frequently using to increase the support count of each item or to add a new item if it is not added earlier In a dynamic linear data structure like linked list  we can apply only linear search If the list grows in size the number of comparisons required to nd a target item in both worst and average cases grows linearly in the case of a linear datastructure Let the total number of items in I\(set I=i1,i2,i3.in is n and the number of items in transaction T is m While we are processing the transaction T we have to search in the datastructure m*n times in worst case scenario This will happen for all the transactions BST is created only if the number of items is not known A Binary Search Tree Binary search is a more efìcient algorithm than linear search but it can be applied only on a sorted list most commonly using on arrays The procedure of binary search will be started by checking the middle approximately item in the linear list with the target item  If it is not same as the target item and the target is smaller than the middle item the target item must be in the rst half of the list\(if the list is sorted in ascending order If the middle item is smaller than the target the target must be in the last half of the list Therefore one unsuccessful comparison reduces the search space by half The search continues by checking the middle item in the remaining half of the list If itês not the target the search narrows to the half of the remaining part of the list that the target could be in The splitting process continues until the target is located or the remaining list consists of only one item If that item is not the target then itês not in the list A binary search tree BST is a tree like data structure where each internal node 2015 International Conference on Advances in Computing Communications and Informatics ICACCI 1079 


Fig 1 a\able1.The transaction database\(b after inserting transaction1 Fig 2 a after inserting transaction-2.\(b after inserting all transactions stores an element such that the elements stored in the left sub tree of the node are less than or equal to the element of the node and elements stored in the right sub tree of the node are greater than or equal to the element of the node Each node has no more than two child nodes The left sub-tree contains only nodes with keys less than the parent node the right sub-tree contains only nodes with keys greater than the parent node The main advantage of binary search trees is that it remains ordered which provides a faster search than many other data structures B The header tree After getting the support count of each item a header table is created by using the frequent items only This time we have a prior knowledge about the number of items Therefore we can create array here But to use a static datastructure the availability of continuous free memory is an issue Here again a binary search tree is used as a header tree instead of header table called Binary Search Header Tree\(BSHT  Each node of the BSHT includes item name  support count link to the next node and link to the corresponding item in the fptree If we are using BST while counting the item frequency we can prune the infrequent items and can reuse the same BST as BSHT with a slight modiìcation The BST is created earlier by considering item names as keys In BSHT also the item names are used as keys The structure of a binary search tree depends on the order of items  In this implementation the number of items is available So to get the maximum efìciency here we created the BSHT after sorting the items in frequency descending order to get the most frequent item in the root of BSHT Then the second scan starts for constructing the tree by inserting each transaction one by one Before inserting a transaction in to the tree the infrequent items have to be removed and the remaining items should be sorted in descending order of the frequency  In earlier algorithms to remove the infrequent items we should search the header table to verify whether the item is there or not The header table is the set of items sorted in descending order of their frequency Therefore only the basic linear search can be applied Another issue is that to sort the remaining items in the transaction each itemês position in the header table should be considered to avoid the conîicts between the items with same frequency  Here also only a linear search is possible Linear search is the simplest search algorithm it checks the rst item then the second item then the third item and so on until you nd the target item or reaches the end of the list Its worst case cost is proportional to the number of elements in the list Therefore if the list has more than a few elements other methods will be faster In general for a list of length n the worst case is n comparisons The number of comparisons to nd a target increases linearly as the size of the list increases Suppose that we want to add a transaction T with n items i1 i2 in into an FP-tree and the number of items in the header table is m the header table have to be visited n times  in each search it must verify m nodes Therefore in the worst-case scenario the complexity of processing one transaction before insertion into fp-tree is n*m Therefore we suggest the new data structure BSHT instead of header table to avoid this time consuming searches Construct the BSHT with the frequent items same as the structure of binary search tree each node contains item name support count link to children and link to the corresponding node in fptree Item names are using as keys Therefore a binary search can apply Binary search is more efìcient than a linear search Here is the procedure to apply this method First sort the frequent items in descending order of their frequency then construct the BSHT by taking each item from the top of the sorted list Put the rst item on the root node insert the next item as the left child of the root if its name is less than the name of the root otherwise insert as the right child Insert all the items to the BSHT to apply a fast binary search To process a transaction T  construct two arrays with the same size equal to the number of items in the transaction Fill the rst array with the items in the transaction and second array with zeros Find the frequency of each item from the header tree by using a binary search method and put the value in corresponding location of the second array Remove the items with zero frequency and sort all other items based on their frequency which is stored in the second array During the mining process the fp-growth method and its variations recursively creating the conditional fp tree and also a header table for each conditional fp-tree But in IHT-growth method a BSHT and conditional fp-tree are created recursively To implement the binary search on a linked list structure is more complex than a linear search We can use only a dynamic datastructure to store the items in the transaction database because during the scan new items have to be added 1080 2015 International Conference on Advances in Computing Communications and Informatics ICACCI 


Fig 3 header tree with fptree Fig 4 fp tree with header table dynamically So to get the advantages of arrays the advantages of dynamic datastructure and to implement binary search we used here the binary search tree So the efìciency of the frequent mining has improved drastically.Table1 in Figure 1\(a shows an example database and sets the min-sup as 2 Fig a and b illustrates the binary search tree for table 1 after inserting the rst  second and all transactions respectively IV IHT ALGORITHM  Each node contains item name  frequency and link to the next node During the second scan we can reuse the same BST as the header tree but we have to do two things First include another eld in the nodes as link to point to the corresponding rst node of the item in the fptree second delete all infrequent nodes from the BST by using the BST node removal process We can use array or BST to use as a header table Both of them perform efìciently and we can apply a binary search on both the data structure Fig.3 illustrates the header tree with 2015 International Conference on Advances in Computing Communications and Informatics ICACCI 1081 


Fig 5 header tree constructed from sorted items fp tree for table 1 third column of Table1 contains the sorted transactions of transaction database  Fig.4 represents the fptree with header table with items sorted in the order of item names In this section we introduce another way to construct a more efìcient header tree by using another method After the rst scan we will get all frequent items with its frequency count Sort the items in the order of its frequency and construct the header tree based on this list The root of the header tree constructed by using this method contains the highest frequent item and all other items with highest frequency are stored around the root The items with highest frequency will be searched more than less frequent items so by using this method we can reduce the searching time again Here we implemented this method Figure-5 contains the sorted items in their frequency order and shows the header tree constructed by this method with the sorted items We included four algorithms here to mine frequent itemsets The rst algorithm is used to construct the BST by scanning the database once In all other fptree algorithms the rst scan is used to nd the 1-frequent items So we have to know the number of items earlier to use an array We can use the rst algorithm if we dont know the number of items  But in our experimental results we used the second algorithm because we already know the number of items The second algorithm is used to construct the BSHT The third algorithm is used to construct the fptree  This process is time consuming In our algorithm we used the BSHT to sort the transactions In the 4th algorithm the actual mining process is conducting The mining will be started from the least frequent item The process is as follows From the fptree nd all the paths which includes the current item x We set the support of each identiìed path with the support of x in that particular path Each path is considering as a transaction Then the process will be called recursively The new paths will be used as dataset in algorithm 2 then construct the fptree of x and nally call the 4th algorithm to nd the frequent items of x If more than one path is there in the fptree of x again all the procedure will be recursively called 1082 2015 International Conference on Advances in Computing Communications and Informatics ICACCI 


Fig 6 dataset Fig 7 Runtime test\(Connect Fig 8 Runtime test\(Retail Fig 9 Runtime test\(T10L4D1000K  V P ERFORMANCE EVALUATION  In this section we present some experimental results by comparing our algorithm IHT-growth with other two algorithms FP-gro and IFP-gro wth[4 The FPgrowth algorithm was obtained from the FIMI website http://ìmi.ua.ac.be/src and IFP-growth algorithm was downloaded from the website www.sciencedirect.com We used one synthetic dataset and two real datasets in the experiments The real datasets are retail and Connect  and the synthetic dataset is T10L4D1000K All the datasets were downloaded from FIMI04 websitehttp://ìmi.cs.helsinki.ì.data Connect dataset contains network connection data and it is a dense dataset 2015 International Conference on Advances in Computing Communications and Informatics ICACCI 1083 


Retail is a sparse dataset  consists of product sales data from retail stores Each transaction in the Retai dataset represents purchase information from one consumer at a time The details of the datasets are presented in gure 6 The programming language used to implement all the three algorithms is java and run in 3.3 GHz Intel processor 4 Gbyte memory and Windows 7 32bit OS Figs 7Ö9 show results of runtime experiments regarding the real and synthetic datasets shown in gure 6 In these gures we can observe that IHT-growth outperforms the others in all of the cases IHT-growth uses the proposed header tree structure to store the 1-frequent items instead of the older header table to minimize access times to search items As a result its advantages have a positive effect on reducing runtime in whole experiments Especially in the case of Retail dataset the difference of runtime between our algorithm and the others is much more than the other datasets  In all experiments FP-growth shows the worst performance Note that IHT-growth method can be used with any fptree mining to improve its efìciency We suggested here two methods to implement the new algorithm If we dont know the number of items in advance the First method is suggested In this experiments we used the second method By using the second method we can create a more efìcient BSHTree because all the items with highest frequency will be appeared on the top of the BSHTree By using this method the run time can be improved by minimizing the searching time of items while sorting out the transactions VI CONCLUSION This study proposes an efìcient transaction processing method during the transaction scanning time By applying the efìcient binary search tree the mining time drastically reduced The new transaction sorting method is also improves the performance of mining The experimental results show that our algorithm outperforms the fp-growth and IFP-growth two well known and widely used algorithms Here we used a BSHTree after the rst scan to store the items with support count While using the BSHTree we used the actual names of items as keys This method can be applied to improve the mining process with any frequent itemset mining algorithm which is using a header table R EFERENCES  Jia wei H an Jian Pei and Y iwen Y in Mining Frequent P atterns without CandidateGeneration,SIGMOD 00 Proceedings of the 2000 ACM SIGMOD international conference on Management of data.Pages 1-12  Gw angb umPyun a Unil Y u n a  K eun Ho Ryu  E f cient frequent pattern mining based on Linear Preìx tree Knowledge-Based Systems 55 2014 125Ö139  Y uh-JiuanTsay a T ain-Jung Hsu a Jing-Rung Y ub,FIUT  A n e w method for mining frequent itemsets,Information Sciences 179 2009 1724 1737  K e-Chung Lin I-En Liao  Zhi-Sheng Chen An impro v e d frequent pattern growth method for mining association rules Expert Systems with Applications 38 2011 5154Ö5161  F an-Chen Tseng An adapti v e approach to mining frequent itemsets efìciently Expert Systems with Applications 39 2012 13166Ö13172  R Agra w al T  Imielinski A.N Sw ami Mining association rules between sets of items in large databases in Proceedings of the ACMSIGMOD Conference on Management of Data pages 1993 pp 207Ö216  R Agra w al R Srikant F ast Algorithms for Mining Association Rules very Large Data Bases\(VLDB 1994 487499  Xiaobing Liu K u n Zhai W itold Pedrycz An impro v e d association rules mining method,Expert Systems with Applications 39 2012 13621374  Qiao yongwei,Y ang Hui Dong T ingjian,Research On QAR Data Mining Method Based On Improved Association Rule,Physics Procedia 24 2012 1514-1519  T  Hu S.Y  Sung H Xiong Q Fu Disco v ery of maximum length frequent itemsets Information Sciences 178 1 2008 69-87  G Lee U Y un K Ryu Sliding windo w based weighted maximal frequent pattern mining over data streams Expert Systems with Applications 41 2 2014 694-708  S.K T anbeer  C.F  Ahmed B.S Jeong Y  Lee Ef cient single-pass frequent pattern mining using a preìx-tree Information Sciences 179 5 2008 559583  V S Tseng C.W  W u B.E Shie P S Y u  UP-Gro wth an ef cient algorithm for high utility itemset mining Knowledge Discovery and Data mining KDD 2010 253-262  T  W u  Y  Chen J han Re-e xamination of interestingness measures in pattern mining a uniìed framework Data Mining and Knowledge Discovery DMKD 21 3 2010 371-397  J Han H Cheng D Xin X Y an Frequent pattern mining current status and future directions Data Mining and Knowledge Discovery DMKD 15 1 2007 55-86  Zaki Mohammed J Naren Ramakrishnan and Lizhuang Zhao Mining frequent boolean expressions application to gene expression and regulatory modeling International Journal of Knowledge Discovery in Bioinformatics IJKDB 1.3 2010 68-96 1084 2015 International Conference on Advances in Computing Communications and Informatics ICACCI 


375 6  R. Meo, G. Psaila, & S. Ceri 223A new SQL-like operator for mining association rules,\224 in Proceedings of the 22 nd International Conference on Very Large Data Bases Conference \(VLDB\2221996  Bombay, India, September 1996, pp. 122-133 7  H. C. Tjioe, & D. Taniar, \223Mining association rules in data warehouses,\224 International Journal of Data Warehousing and Mining vol. 1, no. 3, 2005, pp. 28-62 8  T. Imielinski, L. Khachiyan, & A. Abdulghani, \223Cubegrades generalizing association rules,\224 Data Mining and Knowledge Discovery vol. 6, issue 3, 2002, pp. 219-257 9  R. Ben Messaoud, R. S. Loudcher O. Boussaid, & R. Missaoui 223Enhanced mining of associati on rules from data cubes,\224 in Proceedings of the 9 th ACM International Workshop on Data Warehousing and OLAP \(DOLAP\2222006 Arlington, VA, 2006 pp. 11-18 10  R. Ben Messaoud, R. S. Loudcher O. Boussaid, & R. Missaoui 223OLEMAR: an online environment for mining association rules in multidimensional data,\224 Data Mining and Knowledge Discovery Technologies vol. 2, 2007, pp. 1-36 11  M. T. Fisun, G. V. Gorban, \223Research and implementation syntactic algorithms create OLAP-cubes,\224 Transactions of Kherson National University no. 2\(38\, 2010, pp. 110-117. \(in Ukrainian 12  M. T. Fisun, G. V. Gorban, \223Models and methods of construction of OLAP systems for object-ori ented databases,\224 Information Technology and Computer System s, no. 1 \(209\, 2014, pp. 41-45 in Russian 13  G. V. Gorban, \223Application of B*-trees for creating and calculating of OLAP-cubes using combinatorial algorithm,\224 Technological Audit of Production and Reserves no. 5/4 \(13 2013, pp. 10-12. \(in Ukrainian  


paying a price of a slightly worse ratio for subsets Taken together the price of having more subsets is preferred because subsets contain only items actually in the assembly while superset and overlap patterns also contain unrelated items The 002rst and second row of 002gure 8 correspond to the instance and the pattern-based approach for graded synchrony The third corresponds to the instance-based approach for binary synchrony Comparing the diagrams for unrelated patterns our graded method detects all injected patterns 050\002rst and second rows\051 while the binary method also produces unrelated pattern In 050Borgelt et al 2015\051 it is demonstrated that the instance-based approach yields slightly better results than the pattern approach However this approach does not consider the precision of synchrony Surprisingly using only the pattern-based approach with a graded notion of synchrony yields a better ratio for overlap and superset patterns 7 CONCLUSIONS In this paper we presented a method to detect frequent synchronous patterns in event sequences using a graded notion of synchrony for mining patterns in the presence of imprecise synchrony of events constituting occurrences and selective participation 050incomplete occurrences\051 Our method adapts methods presented in the literature to tackle selective participation using binary synchrony especially the instancebased approach which looks at instances of patterns to improve the detection by removing instances that are likely chance events checking the precision of synchrony of these instances We demonstrate in our experiments that using a graded notion of synchrony for support computation helps to simplify the detection of selective participation because a pattern-based approach yields better results or at least equally good results as an instance-based approach This is a considerable advantage since identifying the individual pattern instances is costly and thus it is desirable to avoid it ACKNOWLEDGMENTS The work presented in this paper was partially supported by the Spanish Ministry for Economy and Competitiveness 050MINECO Grant TIN2012-31372\051 and by the Principality of Asturias through the 2013-2017 Science Technology and Innovation Plan 050Programa Asturias CT1405206\051 and the European Union through FEDER funds REFERENCES Abeles M 0501982\051 Role of the cortical neuron Integrator or coincidence detector Israel Journal of Medical Sciences  18\0501\051:83\22692 Borgelt C 0502012\051 Frequent item set mining In Wiley Interdisciplinary Reviews 050WIREs\051 Data Mining and Knowledge Discovery  pages 437\226456 050 J Wiley  Sons Chichester United Kingdom 2 Borgelt C Braune C and Loewe K 0502015\051 Mining frequent parallel episodes with selective participation In Proc 16th World Congress of the International Fuzzy Systems Association 050IFSA\051 and 9th Conference of the European Society for Fuzzy Logic and Technology 050EUSFLAT\051 IFSA-EUSFLAT2015  Gijon Spain Atlantis Press Borgelt C and Picado-Muino D 0502013\051 Finding frequent synchronous events in parallel point processes In Proc 12th Int Symposium on Intelligent Data Analysis 050IDA 2013 London UK\051  pages 116\226126 Berlin/Heidelberg Germany Springer-Verlag Dudoit S and van der Laan M J 0502008\051 Multiple Testing Procedures with Application to Genomics  Springer New York USA Ezennaya-G 264 omez S and Borgelt C 0502015\051 Mining frequent synchronous patterns with a graded notion of synchrony In Proc 16th World Congress of the International Fuzzy Systems Association 050IFSA\051 and 9th Conference of the European Society for Fuzzy Logic and Technology 050EUSFLAT\051 IFSA-EUSFLAT2015  pages 1338\2261345 Gijon Spain Atlantis Press ISBN 050on-line\051 978-94-62520-77-6 Hebb D O 0501949\051 The Organization of Behavior  J Wiley  Sons New York NY USA Kernighan W and Ritchie D 0501978\051 The C Programming Language  Prentice Hall K 250 onig P Engel A K and Singer W 0501996\051 Integrator or coincidence detector the role of the cortical neuron revisited Trends in Neurosciences  19\0504\051:130\226137 Louis S Borgelt C and Gr 250 un S 0502010\051 Generation and selection of surrogate methods for correlation analysis In Gr 250 un S and Rotter S editors Analysis of Parallel Spike Trains  pages 359\226382 Springer-Verlag Berlin Germany Mannila H Toivonen H and Verkamo A 0501997\051 Discovery of frequent episodes in event sequences In Data Mining and Knowledge Discovery  pages 259\226 289 Springer New York NY USA 1\0503\051 Picado-Muino D and Borgelt C 0502014\051 Frequent itemset mining for sequential data Synchrony in neuronal spike trains Intelligent Data Analysis  18\0506\051:997\226 1012 Picado-Muino D Borgelt C Berger D Gerstein G L and Gr 250 un S 0502013\051 Finding neural assemblies with frequent item set mining Frontiers in Neuroinformatics  7 Picado-Muino D Castro-Le 264 on I and Borgelt C 0502012\051 Fuzzy frequent pattern mining in spike trains In Proc 11th Int Symposium on Intelligent Data Analysis 050IDA 2012 Helsinki Finland\051  pages 289\226300 Berlin/Heidelberg Germany Springer-Verlag 


Rossum G V 0501993\051 Python for unix/c programmers copyright 1993 guido van rossum 1 In Proc of the NLUUG najaarsconferentie Dutch UNIX users group  Torre E Picado-Muino D Denker M Borgelt C and Gr 250 un S 0502013\051 Statistical evaluation of synchronous spike patterns extracted by frequent item set mining Frontiers in Computational Neuroscience  7 Tsourakakis C Bonchi F Gionis A Gullo F and Tsiarli M 0502013\051 Denser than the densest subgraph Extracting optimal quasi-cliques with quality guarantees In Proc 19th ACM SIGMOD Int Conf on Knowledge Discovery and Data Mining 050KDD 2013 Chicago IL\051  pages 104\226112 New York NY USA ACM Press Zaki M J Parthasarathy S Ogihara M and Li W 0501997\051 New algorithms for fast discovery of association rules In Proc 3rd Int Conf on Knowledge Discovery and Data Mining 050KDD 1997 Newport Beach CA\051  pages 283\226296 Menlo Park CA USA AAAI Press 


