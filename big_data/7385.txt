Comparing Dataset Characteristics that Favor the Apriori Eclat or FP-Growth Frequent Itemset Mining Algorithms Jeff Heaton College of Engineering and Computing Nova Southeastern University Ft Lauderdale FL 33314 Email jeffheaton@acm.org Abstract 227Frequent itemset mining is a popular data mining technique Apriori Eclat and FP-Growth are among the most common algorithms for frequent itemset mining Considerable research has been performed to compare the relative performance between these three algorithms by evaluating the scalability of each algorithm as the dataset size increases While scalability as data size increases is important previous papers have not examined the performance impact of similarly sized datasets that contain different itemset characteristics This paper explores the effects that two dataset characteristics can have on the performance of these three frequent itemset algorithms To perform this empirical analysis a dataset generator is created to measure the effects of frequent item density and the maximum transaction size on performance The generated datasets contain the same number of rows This provides some insight into dataset characteristics that are conducive to each algorithm The results of this paper's research demonstrate Eclat and FP-Growth both handle increases in maximum transaction size and frequent itemset density considerably better than the Apriori algorithm I I NTRODUCTION The research covered by this paper determines how the characteristics of a dataset might affect the performance of the Apriori Eclat and FP-Growth frequent itemset mining algorithms These algorithms have several popular  2 3 The goal of this research is to determine the effects of basket size and frequent itemset density on the Apriori Eclat and FP-Growth algorithms The research determined that these two dataset characteristics have a signi\002cant impact on performance of the algorithms Most research into frequent itemset mining focuses upon the performance differences between frequent itemset algorithms on a single The ef fects of h yper paramaters such as minimum support upon the performance of frequent itemset mining algorithms has also been e Some papers make use of common datasets from the UCI Machine Learning  Man y papers mak e use of the IBM Quest Synthetic Data or some v ariant of it Our paper makes use of a Python-based generator that is based on IBM's w This research evaluates the performance of the Apriori Eclat and FP-Growth frequent itemset mining algorithms implemented by Christian Borgelt in Though association rule mining is a similar algorithm this research is limited to frequent itemset mining By limiting the experimentation to a single implementation of frequent itemset mining this research is able to evaluate how the characteristics of the dataset affect the performance of these algorithms II F REQUENT I TEMSET M INING Frequent itemset mining was introduced as a means to 002nd frequent groupings of items in a database containing baskets/transactions of these The database is composed of a series of baskets that are analogous to orders placed by customers These orders are individual baskets that are made up of some number of items Companies such as Amazon Net\003ix and other online retailers make use of frequent itemsets to suggest additional items that a consumer might want to purchase based on their past purchasing history and the history of others with similar bask The follo wing data show baskets that might be used for frequent itemset mining where each line represents a single basket of items  m p 3 p l a y e r usb 000 c h a r g e r book 000 d c t book 000 t h s  m p 3 p l a y e r usb 000 c h a r g e r  usb 000 c h a r g e r m p 3 p l a y e r book 000 d c t book 000 t h s  usb 000 c h a r g e r  book 000 d c t book 000 t h s From the above baskets several frequent itemsets can be de\002ned These are sets of items that frequently occur together some of which are  m p 3 p l a y e r usb 000 c h a r g e r  book 000 d c t book 000 t h s    A simple visual analysis of the data show that the items mp3-player and usb-charger frequently occur together Likewise book-dct and book-ths also frequently occur together Frequent itemset algorithms make use of a variety of statistics to determine which itemsets to include 978-1-5090-2246-5/16/$31.00 c 015 2016 IEEE 


III S URVEY OF A PRIORI  E CLAT AND FP-G ROWTH There are a variety of different algorithms that are used to mine frequent itemsets First a simple naive brute-force algorithm to build frequent itemsets will be evaluated This paper shows how Apriori Eclat and FP-Growth address some of the shortcomings of the naive algorithm All four algorithms must calculate statistics about itemsets that might ultimately be included in the 002nal collection of frequent itemsets One statistic that is common to all four of these algorithms is support The support of a candidate frequent itemset is the total count of how many of the database baskets support that candidate A basket is said to cover a candidate itemset if the candidate is a subset or equal to the basket Support is sometimes expressed as a percent of the total number of baskets in the database 050 N 051 that cover a candidate itemset 050 X 051 The following formula calculates the support percentage of a candidate itemset supp 050 X 051  Xcount  N 0501\051 This equation can be applied to calculate the support for f mp3-player usb-charger g from the previously presented set of baskets supp 050 f mp3-player usb-charger g 051  3  5  0  6 0502\051 The support statistic of 0.6 indicates that 60 of the 002ve baskets contain the candidate itemset f mp3-player usbcharger g  Most frequent itemset algorithms accept a minimum support parameter to 002lter out less common itemsets IV N AIVE A LGORITHM FOR F INDING F REQUENT I TEMSETS It is not dif\002cult to extract frequent itemsets from basket data It is however dif\002cult to do so ef\002ciently For the algorithms presented here let J represent a set of items likewise let D represent a database of baskets that are made up of those items Algorithm 1 is a summarization of the naive frequent itemset algorithm provided by Garcia-Molina Ullman and W  Algorithm 1 Naive Frequent Itemset Algorithm  1 INPUT A 002le D consisting of baskets of items 2 OUTPUT The sets of itemsets F 1  F 2      F q  where F i is the set of all itemsets of size I that appear in at least s baskets of D  3 METHOD 4 R 040 integer array all item combinations in D  of size 2 jDj 5 for n 040 1 T O jDj do 6 F 040 all possible set combinations from D n 7 Increase each value in R corresponding to each in F  return all itemsets with R  025 s  The naive algorithm simply generates all possible itemsets counts their support and then discards all itemsets below some threshold level of support The constant S or 033 typically represents the support threshold Computing all possible itemsets is only an O 050 N 051 magnitude operation in all cases where N is the number of baskets in the database However the naive algorithm would also need 2 i memory cells to store all of these itemsets as the counts are generated where i is the number of individual items These memory cells would typically be 32 or 64-bit integers This memory requirement means that the naive algorithm is impossible for anything but a trivial number of individual items A computer with 128GB of available RAM would theoretically only be able to calculate 34 items when using a 64-bit integer to hold the counts When it is considered that N might be the total count of distinct items for sale by a retailer such as Walmart or Amazon it is obvious that the naive approach is not useful in practice V N AIVE A LGORITHM E XAMPLE This section demonstrates how the naive algorithm would handle the example basket set given earlier in this paper The total number of items contained in database jJ j is equal to four Four items can be arranged a total of jJ j 2  or 16 different ways However because one of these frequent itemsets is the empty set only the following 15 candidate itemsets are considered  book 000 t h s  book 000 d c t  book 000 d c t  book 000 t h s  usb 000 c h a r g e r  usb 000 c h a r g e r  book 000 t h s  usb 000 c h a r g e r  book 000 d c t  usb 000 c h a r g e r  book 000 d c t  book 000 t h s  m p 3 p l a y e r  m p 3 p l a y e r  book 000 t h s  m p 3 p l a y e r  book 000 d c t  m p 3 p l a y e r  book 000 d c t  book 000 t h s  m p 3 p l a y e r  usb 000 c h a r g e r  m p 3 p l a y e r  usb 000 c h a r g e r  book 000 t h s  m p 3 p l a y e r  usb 000 c h a r g e r  book 000 d c t  m p 3 p l a y e r  usb 000 c h a r g e r  book 000 d c t  book 000 t h s The above itemsets are considered candidate frequent itemsets because it has not yet been determined if all of these candidates will be included in the 002nal list of frequent itemsets Once the candidate itemsets have been determined the naive algorithm will pass over all baskets and count the support for each of the candidate itemsets Candidate itemsets that are below the required support S will be purged The naive algorithm would calculate support for each candidate as follows  book 000 t h s  s  3  book 000 d c t  s  3  book 000 d c t book 000 t h s  s  3  usb 000 c h a r g e r  s  4  usb 000 c h a r g e r  book 000 t h s  s  2  usb 000 c h a r g e r  book 000 d c t  s  2  usb 000 c h a r g e r  book 000 d c t  book 000 t h s  s  2  m p 3 p l a y e r  s  3 


 m p 3 p l a y e r  book 000 t h s  s  2  m p 3 p l a y e r  book 000 d c t  s  2  m p 3 p l a y e r  book 000 d c t  book 000 t h s  s  2  m p 3 p l a y e r  usb 000 c h a r g e r  s  3  m p 3 p l a y e r  usb 000 c h a r g e r  book 000 t h s  s  2  m p 3 p l a y e r  usb 000 c h a r g e r  book 000 d c t  s  2  m p 3 p l a y e r  usb 000 c h a r g e r  book 000 d c t  book 000 t h s  s  2 It is necessary to store a count for every possible itemset when using the naive algorithm Of course once the support counts are determined many of the frequent itemsets will be purged Nevertheless the fact that these values must be kept while the database is scanned for support means the naive algorithm requires considerable memory VI A PRIORI A LGORITHM FOR F INDING F REQUENT I TEMSETS Agrawal and Srikant initially introduced the Apriori algorithm to provide performance improvements over a naive itemset Apriori algorithm has been around almost as long as the concept of frequent itemsets and is very popular The naive algorithm is a theoretical concept and is not used in practice Aprioiri has become the classic implementation of frequent itemset mining Aprioiri as de\002ned by Goethals 0502003\051 is presented as Algorithm  Algorithm 2 Apriori Frequent Itemset Algorithm  1 INPUT A 002le D consisting of baskets of items a support threshold 033  2 OUTPUT A list of itemsets F 050 D  033 051  3 METHOD 4 C 1 040 ff i gj i 2 J g 5 k 040 1 6 while C k 6  fg do 7  Compute the supports of all candidate itemsets 8 for all transactions f tid I g 2 D do 9 for all candidate itemsets X 2 C k do 10 if X 022 I then 11 X:support  12  Extract all frequent itemsets 13 F k  f X j X:support  033 g 14  Generate new candidate itemsets 15 for all X Y 2 F i X  i   Y  i  for 1 024 i 024 k 000 1  and X  k   Y  k  do 16 I  X  f Y  k  g 17 if 8 J 032 I j J j  k  J 2 F k then 18 C k 1 040 C k 1  I 19 k   Apriori is based on the hierarchical monotonicity of frequent itemsets between their supersets and subsets As implied by monotonicity a subset of a frequent itemset must also be frequent Likewise a superset of an infrequent itemset must also be This allo ws the Apriori algorithm to be implemented as a breadth-\002rst search Papers by Goethals 0502003\051 and others do not represent Apriori's performance in terms of big-O This is lik ely due to the f act that Apriori's outer loops are bounded by the number of common pre\002xes and not some easily determined constants such as the number of items or the length of the dataset Papers describing Apriori Eclat and FP-Growth rely on empirical comparison of algorithms rather than big-O analysis However analysis covered later in this paper does allow these three algorithms to be expressed in big-O based on average basket size and frequent itemset density Aprioiri 002rst builds a list of all singleton itemsets with suf\002cient support Building on the monotonicity principle the next set of candidate frequent itemsets is built of combinations of the singleton itemsets This process continues until the maximum length speci\002ed for frequent itemsets is reached The evaluations performed by this research did not impose this maximum length The primary issue with the Apriori algorithm is that it is necessary to perform a scan of the database at every level of the breadth-\002rst search Additionally candidate generation can lead to a great number of subsets and can become a signi\002cant memory requirement De\002ciencies in the Apriori algorithm led to the development of other more ef\002cient algorithms such as Eclat and FP-Growth VII A PRIORI A LGORITHM E XAMPLE This section will demonstrate how the Apriori algorithm handles the basket set given earlier in this paper The Apriori algorithm performs a breadth 002rst search of the itemsets Figure 1 shows a segment of this search for the items usbcable mp3-player and book-dct Fig 1 Apriori Breadth-First Search The candidate set starts empty and begins by adding all singleton itemsets that have suf\002cient individual support For simplicity it is assumed that only usb-cable mp3-player and book-dct have suf\002cient support The next layer is built of combinations of the previous layer that had suf\002cient support For simplicity it is also assumed that all three combinations 


had suf\002cient support Finally a triplet itemset with all three items is evaluated VIII E CLAT A LGORITHM FOR F INDING F REQUENT I TEMSETS Eclat was introduced by Zaki Parthasarathy Ogihara and Li in Eclat is an acron ym for Equi v alence Class Clustering and bottom up Lattice Traversal The primary difference between Eclat and Apriori is that Eclat abandons Apriori's breadth-\002rst search for a recursive depth-\002rst search Eclat as de\002ned by Goethals 0502003\051 is presented as Algorithm   Algorithm 3 Eclat Frequent Itemset Algorithm  1 INPUT A 002le D consisting of baskets of items a support threshold 033  and an item pre\002x I  such that I 022 J  2 OUTPUT A list of itemsets F  I  D  033 051 for the speci\002ed pre\002x 3 METHOD 4 F  i  040 fg 5 for all i 2 J occurring in D do 6 F  I   F  I   f I  f i gg 7  Create D i 8 D i 040 fg 9 for all j 2 J occurring in D such that j  i do 10 C 040 cover\050 f i g 051 134 cover\050 f j g 051 11 if j C j 025 033 then 12 D i 040 D i  f j C g 13  Depth-\002rst recursion 14 Compute F  I  i  D i  033 051 15 F  I   F  I   F  I  i   The input parameters to Eclat are slightly different than Apriori in that a pre\002x I is provided This pre\002x speci\002es the pre\002x pattern that must be present in any itemsets found by the call to Eclat This change allows a depth-wise recursive building of the itemsets The initial call to Eclat uses an I value of fg  meaning that no speci\002c pre\002x is required This initial call would 002nd all single-item frequent itemsets The Apriori algorithm would then recursively call itself each time increasing I by adding itemsets that contain the value I that the function was called with but are one item longer This process would continue until the value of I had grown to suf\002cient length that the algorithm has traversed to baskets of all lengths Like Apriori Eclat is not usually expressed in big-O terms however results obtained from this research's experimentation show how frequent itemset density and basket allow these algorithms to be expressed in terms of big-O computational cost There are several different methods for storing the support values in the recursive Eclat algorithm The most common approach is to use a structure called a trie This is the approach used by Borgelt 0502012\051 to implement the versions of Apriori Eclat and FP-Growth investigated in this research A trie graph always contains an empty root node As itemsets are encountered they are added to the trie by inserting a node for each item that makes up the itemset The left-most item corresponds to a child of the root node The second item corresponds to a child of the 002rst item of this frequent set No parent would ever have more than one child of the same item name however an item name may appear at multiple locations in the trie The trie is generated so that the algorithm can quickly 002nd the support of an itemset by traversing the trie as the items in the set are read left-to-right The node that contains the right-most item contains the support for that itemset As the algorithm processes the database the trie is traversed looking for each itemset discovered Nodes are created if necessary to 002ll out the trie to hold all itemsets If the nodes already exist the node for the right-most item in the itemset has its support increased New nodes start with a support of 1 This allows Eclat to use less memory than Apriori because the core branches of the trie allow heavily used subsets to be stored only once Theoretically a trie could be used with Apriori however the breadth-\002rst nature of Apriori would typically require too much memory IX E CLAT A LGORITHM E XAMPLE This section will demonstrate how the Eclat algorithm would handle the basket set given earlier in this paper A portion of the trie built by Eclat is shown in Figure 2 Fig 2 A Trie Used by Eclat The above trie portion encodes a total of 7 different frequent itemset's support values To 002nd a particular frequent itemset's support simply traverse the graph following the items from left to right The frequent itemset mp3-player usb-charger would have a support value of 3 Similarly the frequent itemset mp3-player usb-charger book-dct would have a support value of 2 Once the algorithm completes the trie is traversed and all frequent itemsets are extracted from it X FP-G ROWTH A LGORITHM FOR F INDING F REQUENT I TEMSETS Frequent pattern growth 050FP-Growth\051 was introduced by Han Pei and Yin in 2000 to forego candidate generation  This is done by using a trie to store the actual baskets rather than storing candidates like Apriori and Eclat do Aprori is very much a horizontal breadth-\002rst algorithm 


Similarly Eclat is very much a vertical depth-\002rst algorithm The trie structure of FP-Growth provides a vertical view of the data However FP-Growth also adds a header table for every individual item that has support above the threshold support level This header table contains a linked-list through the trie to connect every node of the same type The header table gives FP-Growth a horizontal view of the data in addition to the vertical view provided by the trie The algorithm for FP-Growth is similar to Eclat in that it was not expressed in terms of big-O analysis FP-Growth as de\002ned by Goethals is presented as Algorithm  Algorithm 4 FP-Growth Frequent Itemset Algorithm  1 INPUT A 002le D consisting of baskets of items a support threshold 033  and an item pre\002x I  such that I 022 J  2 OUTPUT A list of itemsets F  I  D  033 051 for the speci\002ed pre\002x 3 F  i  040 fg 4 for all i 2 J occurring in D do 5 F  I  040 F  I   f I  f i g 6  Create D i 7 D i 040 fg 8 H 040 fg 9 for all j 2 J occurring in D such that j  i do 10 if support\050 I  f i j g 051 025 033 then 11 H 040 H  f j g 12 for all 050 tid X 051 2 D with I 2 X do 13 D i 040 D i  f 050 tid X 134 H 051 g 14  Depth-\002rst recursion 15 Compute F  I  f i g  D i  033 051 16 F  I  040 F  I   F  I  f i g   XI FP-G ROWTH A LGORITHM E XAMPLE This section will demonstrate how the FP-Growth algorithm would handle the basket set given earlier in this paper Figure 3 shows a portion of the FP-Growth trie and the header table generated for the earlier example data Fig 3 FP-Growth Trie and Header Table This 002gure demonstrates the horizontal and vertical nature of the FP-Growth algorithm The trie on the right holds the encoded baskets along with their supports The header on the left holds the items and provides horizontal access to the data XII E MPIRICAL C OMPARISON OF A PRIORI  E CLAT AND FP-G ROWTH There are a number of papers that compare the computational performance of Apriori Eclat and FP-Growth These papers are typically focused primarily on comparing the differences between the algorithms on one or more datasets and at different support thresholds Papers by Borgelt 0502012\051 and Goethals 0502003\051 are examples of papers that compare various implementations of Apriori Eclat and FP-Gro 14 This paper attempts a different approach The goal of this paper is to see what effect the dataset has on the algorithm The average basket size and frequent item density will be used as independent variables to evaluate total processing time as the dependent variable Apriori Eclat and FP-Growth will each be evaluated independently to see which performs best at different basket sizes and frequent itemset densities Performance will be measured as a shorter total runtime This paper focuses on a single implementation of these algorithms using the implementations of Apriori Eclat and FP-Growth by Borgelt in XIII D ATASET G ENERATION Generated datasets are used to perform this evaluation This generated data allows the two independent variables to be adjusted to create a total of 20 different datasets to perform the evaluations The datasets were generated using a simple Python script created for this paper that can be found on This Python script accepts the follo wing parameters to specify the dataset to produce 017 Transaction/Basket count 10 million default 017 Number of items 50,000 default 017 Number of frequent sets 100 default 017 Max transaction/basket size independent variable 5-100 range 017 Frequent set density independent variable 0.1 to 0.8 range While basket count number of frequent sets and number of items can easily be varied in the script for the purposes of this paper they will remain 002xed at the above values Through informal experimentation it was determined that the basket count only had a small positive correlation to processing time The number of items did not appear to have a meaningful impact on processing time when varied in isolation It was observed that the strongest correlation to processing time was through variation of the maximum basket size and frequent set density The following listing shows the type of data generated for this research Here an example 002le was created with 10 baskets out of 100 items 2 frequent itemsets maximum basket size of 10 and a density of 0.5 I 3 6 I 9 4 I 7 1 I 1 3 I 9 1 I 8 9 I 3 4 F6 F5 F3 F4 I 8 6 I 3 9 I 1 6 I 4 9 I 6 2 I 3 1 I 5 4 I 9 1 


I 2 2 I 3 1 I 7 0 I 8 5 I 7 8 I 6 3 F4 F3 F1 F6 F0 I 6 9 I 4 4 I 8 2 I 5 0 I 9 I 3 1 I 5 7 I 2 0 F4 F3 F1 F6 F0 I 8 7 As you can see from the above 002le the items are either pre\002xed with 223I\224 or 223F\224 The 223F\224 pre\002x indicates that this line contains one of the frequent itemsets Items with the 223I\224 pre\002x are not part of an intentional frequent itemset Of course 223I\224 pre\002xed items might form frequent itemsets as they are uniformly sampled from the number of items to 002ll out nonfrequent itemsets Each basket will have a random size chosen up to the maximum basket size The frequent itsemset density speci\002es the probability of each line containing one of the intentional frequent itemsets Because a density of 0.5 was used approximately half of the lines above contain one of the two intentional frequent itemsets A frequent itemset line may have additional random 223I\224 pre\002xed items added to cause the line to reach the randomly chosen length for that line If the chosen frequent itemset does cause the generated line to exceed its randomly chosen length no truncation will occur The intentional frequent itemsets are all chosen to be less than or equal to the maximum basket size XIV E FFECTS OF D ATASET D ENSITY Dataset density speci\002es the percentage of baskets that intentionally contain frequent itemsets As frequent itemset density increases so does the processing time of Apriori Eclat and FP-Growth as shown by Figure 4 Fig 4 Frequent Itemset Density's Effect on Runtime 050seconds\051 This chart shows the results of running 10 million baskets with an average basket size of 50 at various densities The Eclat and FP-Growth algorithms both show very similar growth as frequent itemset density increases The Apriori algorithm also performs very similarly to Eclat and FP-Growth until the density surpasses 70 As previously mentioned in this paper Apriori has considerably larger memory needs than the other algorithms At 70 Apriori had allocated all of the test machine's 8 gigabytes of RAM This made swapping to physical storage necessary and had a drastic impact on the algorithm's runtime It is also interesting to note that Eclat is marginally ahead of FP-Growth at low densities This ranking reverses at higher densities Between 10 and 70 all three algorithms exhibit approximately an O 050 N logN 051 complexity Beyond 70 Apriori approached O 050 N 2 051 and worse complexity where N is the number of actual frequent items in the database XV E FFECTS OF B ASKET S IZE Basket size speci\002es the maximum number of items per basket line Larger basket sizes mean that the frequent itemsets will also be larger This increases the sizes of the data structures used to hold these itemsets These larger data structures require more memory for storage and greater processing time to traverse them Figure 5 illustrates the effect of increasing transaction sizes on the performance of the three algorithms Fig 5 Maximum Basket Size's Effect on Runtime 050seconds\051 This chart shows the results of running 10 million baskets with a frequent itemset density of 50 at various max basket sizes The three algorithms show almost exactly the same O 050 N 051 performance for basket sizes up through 60 Once above 60 Apriori seems to grow much quicker than the other two This is possibly because of the increased memory used by Apriori Interestingly Apriori performed the best between 6070 maximum transaction sizes Further research is needed to determine why Apriori is superior in this small range XVI C ONCLUSIONS Apriori is an easily understandable frequent itemset mining algorithm Because of this Apriori is a popular starting point for frequent itemset study However Apriori has serious scalability issues and exhausts available memory much faster than Eclat and FP-Growth Because of this Apriori should not be used for large datasets Most frequent itemset applications should consider using either FP-Growth or Eclat These two algorithms performed similarly for this paper's research though FP-Growth did show slightly better performance than Eclat Other papers also recommend FP-Growth for most Frequent itemset mining is an area of active research New algorithms as well as modi\002cations of existing algorithms are often introduced For an application where performance is critical it is important 


to evaluate the dataset with newer algorithms as they are introduced and shown to have better performance than FPGrowth or Eclat R EFERENCES   J Han H Cheng D Xin and X Yan 223Frequent pattern mining Current status and future directions,\224 Data Mining Knowledge Discovery  vol 15 no 1 pp 55\22686 Aug 2007   M Hall E Frank G Holmes B Pfahringer P Reutemann and I H Witten 223The weka data mining software an update,\224 ACM SIGKDD explorations newsletter  vol 11 no 1 pp 10\22618 2009   M Hahsler B Gruen and K Hornik 223arules 226 A computational environment for mining association rules and frequent item sets,\224 Journal of Statistical Software  vol 14 no 15 pp 1\22625 October 2005 A v ailable http://www jstatsoft.or g/v14/i15   D Burdick M Calimlim and J Gehrke 223Ma\002a A maximal frequent itemset algorithm for transactional databases,\224 in Proceedings of the 17th International Conference on Data Engineering 2001  IEEE 2001 pp 443\226452   Z Zheng R Kohavi and L Mason 223Real world performance of association rule algorithms,\224 in Proceedings of the seventh ACM SIGKDD international conference on Knowledge discovery and data mining  ACM 2001 pp 401\226406   A Asuncion and D Newman 223UCI machine learning repository,\224 2007 A v ailable http://www.ics.uci.edu 030 mlearn/MLRepository.html   A Pitman 223Market basket synthetic data generator,\224 2011 http://mloss.org/software/view/294   J Heaton 223Jeff Heaton's GitHub Repository Conference/Paper Source Code,\224 https://github.com/jeffheaton/papers accessed 2016-01-31   C Borgelt 223Frequent item set mining,\224 Wiley Interdisciplinary Reviews Data Mining and Knowledge Discovery  vol 2 no 6 pp 437\226456 2012   R Agrawal T Imieli 264 nski and A Swami 223Mining association rules between sets of items in large databases,\224 in ACM SIGMOD Record  vol 22 no 2 ACM 1993 pp 207\226216   J Leskovec A Rajaraman and J D Ullman Mining of massive datasets  Cambridge University Press 2014   H Garcia-Molina Database systems the complete book  Pearson Education India 2008   R Agrawal R Srikant et al  223Fast algorithms for mining association rules,\224 in Proceedings of the 20th international conference of very large data bases VLDB  vol 1215 1994 pp 487\226499   B Goethals 223Survey on frequent pattern mining,\224 University of Helsinki  2003   M J Zaki S Parthasarathy M Ogihara W Li et al  223New algorithms for fast discovery of association rules,\224 in KDD  vol 97 1997 pp 283\226 286   J Han J Pei and Y Yin 223Mining frequent patterns without candidate generation,\224 in ACM SIGMOD Record  vol 29 no 2 ACM 2000 pp 1\22612 


115 A This work was funded by the Enterprise Ireland Innovation Partnership Programme with   upported by the N ational N atural  Science Foundation of China \(No. 61373131  PAPD and CICAEET funds References   Z. J Fu, X M. Sun, Q Liu, L. Zhou, and J G. Shu 223Achieving Efficient Cloud Search Services Multi-keyword Ranked Search over Encrypted Cloud Data Supporting Parallel Computing,\224 IEICE Transactions on Communications, vol E98-B, no. 1, pp.190-200, 2015   S. D Xie, Y X W ang 223Construction o f T r ee Net work with Limited Delivery Latency in Homogeneous Wireless Sensor Networks,\224 Wireless Personal Communications, 2014, 78\(1 3   P  Gu o  J  W a n g  B L i S Y  L ee  223 A V a r ia b le  Threshold-value Authentication Architecture for Wireless Mesh Networks,\224 Journal of Internet Technology, 2014, 15\(6 4   T H. Ma, J J Zhou, M. L. T ang, Y Tian, A. ALDHELAAN, M. AL-RODHAAN, and S. Y. LEE, \223Social network and tag sources based augmenting collaborative recommender system,\224 IEICE transactions on Information and Systems, vol E98-D, no.4, pp. 902-910, Apr. 2015   B. Gu V  S. Sheng K Y  T ay  W  R omano and S Li, \223Incremental Support Vector Learning for Ordinal Regression,\224 IEEE Transactions on Neural Networks and Learning Systems, 2014, 26\(7 1403-1416 6   Du b lin Cit y U n iv e r sit y a n d E r ic sso n  E S t r e a m  Project, 2014. http:// www.estream-project.com  quency Counts over Data Streams,\224 In: Proceedings of the 28th International Conference on Very Large Databases \(VLDB Endowment 2002 pp. 346-57, 2002   J  H. Chang and W  S Lee 224Finding R ecent Fr equent Itemsets Adaptively over Online Data Streams,\224 In: Proceedings of the ninth ACM SIGKDD international conference on Knowledge discovery and data mining \(SIGKDD 2003 487-492, 2003 9   H. F Li and H. C hen, \224Mi ni ng Non-D eri v abl e  Frequent Item Sets over Data Stream,\224 Data Knowledge Engineering, vol. 68, no. 5, May 2009, pp. 481-498 10   S. K. T anbeer C. F Ahmed, B. S. Jeong and Y   K. Lee, \224Efficient Single-Pass Frequent Pattern  es, 2008, 179\(5 and architecture was presented to support automatic network management by discovering interesting patterns from Telecom Network Monitoring data. The architecture enables discovery or interesting patterns with data from different domains related to Telecom Network Monitoring. The architecture is composed of five sub-modules: Data Analyzer, Mining Controller, Data Miner, Combiner, and Episode Analyzer. Each sub-module is described in detail along with implementation approach  functions in turn. The approach leverages and combines frequent itemset discovery over data streams, association rule learning, frequent sequential pattern mining, and frequent temporal pattern mining techniques while also making use of distributed processing platforms to achieve high-volume throughput. To test the functionality of the model, three classic pattern mining algorithms, namely, NewMoment PrefixSpan, and HTPM, are implemented Their performances are compared in terms of different parameter settings by executing the algorithms with a simulated streaming dataset Fig.10  


116 ings of Second International Conference on Data Warehousing and Knowledge Discovery Springer, London, UK, pp. 317-326, 2000 21    S. de Amo, W P. Junior and A. Giacometti, MIL PRIT*: a constraint-based algorithm for mining temporal relational patterns, International Journal of Data Warehousing and Mining, 2008 4\(4 22    S Y. Wu and Y. L. Chen, Discovering hybrid temporal patterns from sequences consisting of point- and interval-based events, Data and Knowledge Engineering, 2009, 68\(11\: 13091330 23    Y L. Chen, S. Y. Wu and Y. C. Wang, etc, Discov ering multi-label temporal patterns in sequence database, Information Sciences, 2011, 181\(3 398-418 24    Ha doop Map/Reduce tutorial, http://hadoop apache.org/docs/r1.2.1/mapred tutorial.html 25    M Zaharia and M. Chowdhury, Spark: cluster computing with working sets in cloud comput ing, In: Proceeding of HotCloud 2010, \(2010 26    C Lucchese, S. Orlando, R. Perego, Fast and memory efficient mining of frequent closed itemsets, IEEE Transactions on Knowledge and Data Engineering, 2006, 18\(1    MSCgen-Based Control Plane Trace Emulator for Communication Networks, 2014. http openmsc.blogspot.com Biographies Zhiguo Qu received his PhD in Information Security from Beijing University of Posts and Telecommunica tions, China, in 2011. From 2012 to 2014, he worked as a post-doc researcher fellow at Dublin City Univer sity in Ireland. In July 2011, he joined Nanjing Univer sity of Information and Technology in China, where he is currently a lecturer in the College of Computer and Software. His research interests include quantum secure communication, quantum information hiding  hh@126.com    ment: Maintaining Closed Frequent Itemsets over a Stream Sliding Window,\224 In: Proceedings of Data Mining \(ICDM \22204 12    H. F Li, C. C. Ho and S. Y. Lee, \224Incremental Updates of Closed Frequent Itemsets over  Applications, 2009, 36\(2 13    P T. La, B. Le and B. Vo, \224Incrementally Building   2014, 41: 2703-2712 14    S Brin, R. Motwani and C. Silverstein, Beyond  to correlations,\224 In: Proceedings of the 1997 ACM SIGMOD international conference on Management of data \(SIGMOD 1997\, New York, NY, USA, pp. 265-276, 1997 15    R Srikant, R. Agrawal, Mining sequential  improvements, In: Proceedings of the 5th In  Technology, Avignon, France, pp. 3-17, 1996    Dayal, and M.-C. Hsu. Freespan: Frequent pat tern-projected sequential pattern mining, In Proceedings of 2000 International Conference on Knowledge Discovery and Data Mining KDD00\on, MA, pp. 355-359, 2000      pattern growth, In: Proceedings of the 17th International Conference on Data Engineering Heidelberg, Germany, pp. 215-226, 2001 18    M. J Zaki, SPADE: an efficient algorithm for mining frequent sequences, Machine Learning 2001, 42\(1 19    S. Y Wu and Y. L. Chen, Mining non-ambiguous temporal patterns for interval-based events IEEE Transactions on Knowledge and Data Engi neering, 2007, 19\(6 20    P S. Kam and A. W. C. Fu, Discovering temporal patterns for interval-based events, In: Proceed  


1856 IEEE TRANSACTIONS ON INFORMATION FORENSICS AND SECURITY VOL 11 NO 8 AUGUST 2016 TABLE V E XPERIMENTAL S ETTINGS B Security Under Data Owners Attacks Attack Via Chosen Random Ingredients In our solutions data owners are not required to exchange any plaintext or ciphertext i.e encryption of their private data In addition due to the use of the underlying homomorphic encryption scheme and secure comparison scheme the exact supports and conﬁdences are concealed from any data owner However there is still a possible attack via chosen random ingredients A data owner may use ERVs random ingredients to tag some transactions and verify whether such a transaction contains a given itemset or not For example the data owner could compute an ERV with a customized random ingredient The random ingredient’s bit length is longer than any other random ingredient’s in the preprocessing stage For each received seemingly frequent itemset the data owner decrypts its ESVR and obtains the ESVR’s random ingredient If the random ingredient matches the pattern of the customized random ingredient’s most signiﬁcant bits it is an indication that the ERV with the customized random ingredient has been used to compute the ESVR Thus the data owner knows the transaction associated with the ERV contains the itemset To prevent such an attack we carefully conﬁgure the bit lengths of random ingredients An example is presented in Table V The random ingredients in  1  2  t are used to mask chosen random ingredients in ERVs Also in the preprocessing stage each data owner must verify c s  c z  c e and that ERVs are generated honestly with random ingredients of the right bit lengths In the last step of preprocessing stage the random ingredients of ERVs are veriﬁed in an aggregated manner By examining the sum of these random ingredients data owners can be assured that any chosen random ingredient will be masked C Security of Underlying Homomorphic Encryption Scheme The security of underlying homomorphic encryption scheme depends on the hardness of solving nonlinear systems In the proposed mining solutions a number of plaintexts and their corresponding ciphertexts i.e c s  c z    i  t  i  1   are disclosed to the cloud Therefore the underlying homomorphic encryption scheme should be secure under known-plaintext attacks In our homomorphic encryption scheme to encrypt a plaintext m i and obtain the corresponding ciphertext c i  we require the use of two secrets q  s and a random ingredient r i  From a known  m i  c i  pair the attacker can get a nonlinear equation of three unknowns q  s  r i  s  q  r i  m i   c i From w known pairs the attacker can generate an underdetermined nonlinear system of w equations and the number of unknowns are w  2 If the attacker can solve this system he can learn the secret key of the encryption scheme Security Can Be Achieved by Increasing Hardness of Solving Above Nonlinear System Solving underdetermined nonlinear systems is NP-hard while solving overdetermined systems can be done in polynomial time The attacker may attack a nonlinear system by guessing the values of some unknowns  i f gues s i ng t h e c orrect v a l u es i s not v e ry hard The attacker can generate many overdetermined systems from the targeted underdetermined nonlinear system by xing some unknowns 3 unknowns for the system above to all possible values These unknowns will be viewed as constants in the generated systems By solving the generated overdetermined systems the attacker nds the solution to the targeted underdetermined nonlinear system To prevent such attacks we can conﬁgure large ranges or bit lengths for q  s  r i to compound the challenges of guessing the correct values An example of the conﬁguration is presented in Table V D Security of Underlying Secure Comparison Scheme The proposed secure comparison scheme is used in our solutions to conceal the exact support values and conﬁdence values from the data owners From the correctness proof in Section IV-C we know that m i  0   q  1  2     m i  1  q       q  1  2 


LI et al  PRIVACY-PRESERVING-OUTSOURCED ASSOCIATION RULE MINING ON VERTICALLY PARTITIONED DATABASES 1857 Fig 4 Running time comparison  t  4and k  12 If  q  1  2 m could be any value in the range  0    Otherwise m couldbeanyvaluein   0   By observing   a data owner knows whether m  0 or not but m s range cannot be deduced As our design goal is to conceal exact supports it is sufﬁcient to conceal m s value in many possible values In other words we do not need a secure comparison scheme to conceal more information VII P ERFORMANCE E VA L UAT I O N In this section we evaluate the computational complexity communication complexity and storage cost of our association rule mining and frequent itemset mining solutions In the evaluation we choose one of s s o l u t i ons and c l a s s i c nonprivacy-preserving algorithms as the baseline The former is chosen because it and our solutions achieve the same privacy level In contrast other solutions achieve lower privacy levels Classic algorithms are chosen as baselines because they are the most efﬁcient known solutions A Computational Complexity 1 Comparing With Classic Algorithms We used the running time to evaluate the computational complexity To demonstrate the feasibility of our solutions we compare our solutions with classic non-privacy-preserving algorithms which are the most efﬁcient known solutions We evaluated our solutions and three classic non-privacypreserving algorithms Apriori Eclat and FP-growth using two datasets retail and pumsb from 26  T h e r e tail d a taset from Tom Brijs contains anonymous retail market basket data in a Belgian retail store while the pumsb dataset contains census data for population and housing The retail and pumsb datasets contain 88,162 and 49,046 transactions respectively To simulate t data owners we vertically partitioned each dataset into t databases randomly Our solutions are implemented in JAVA and we use a JAVA implementation  of A p ri ori  Ecl a t a nd F P gro w t h algorithms in our experiments All implementations are singlethreaded implementations To ensure a fair comparison in all experiments machines playing the roles of cloud or data owner have the same hardware and software settings The settings and the parameters of our solutions are shown in Table V The results are shown in Figs 4 5 and 6 As the running time of association rule mining is only slightly higher than Fig 5 Running time under different data owner count t  k is xed to 16 Fig 6 Running time under different k  t is xed to 2 that of frequent itemset mining only the results of association rule mining are presented We show our solutions running time at the cloud’s end i.e running time of mining and data owner owner side i.e running time of preprocessing and decrypting separately As expected our solutions are not as efﬁcient as the most efﬁcient algorithms  solutions of low privacy levels However they achieve a higher privacy level with an acceptable running time Compared with the fastest algorithm’s running time the cloud’s running time is about one order higher for most cases while data owner’s running time is very low This is the classic trade-off between privacypreserving and efﬁciency From Figs 5 and 6 we also observe that running time changes with increasing values of k and t  The cloud’s running time increases with t as d max increases with t and a larger d max results in larger ciphertext size and more computations The cloud’s running time increases with k for the retail dataset but barely changes for the pumsb dataset The increase in running time for retail dataset is due to the increase in ctitious data However the pumsb dataset is very dense and the supports are already very high without including ctitious data Thus adding more ctitious data hardly changes the number of seemingly frequent itemsets and their supports We can also observe that data owner’s running time decreases 


1858 IEEE TRANSACTIONS ON INFORMATION FORENSICS AND SECURITY VOL 11 NO 8 AUGUST 2016 TABLE VI E STIMATED R UNNING T IME OF  s S OLUTION when t increases The reason is simple If the same joint database is vertically partitioned to more data owners each data owner’s dataset is smaller Preprocessing a smaller dataset requires less time Data owner’s running time doesn’t increase with k either Such a phenomenon can also be explained using 16  s alg o r ith m f o r ad d i n g ctitio u s tr an sactions Speciﬁcally data owner’s running time is dominated by the time to run this algorithm which is hardly affected by changes in the values of k  In summary increasing t and k usually results in a higher running time at the cloud end without resulting in an increase in data owner’s running time 2 Comparing With the Solution Achieving the Same Privacy Level To the best of our knowledge the only existing privacy-preserving solution that does not leak sensitive information of the raw data is one of s frequent itemset mining solutions hereafter referred to as  s strong solution in this paper This solution cannot be used for association rule mining whilst we have solutions for both association rule mining and frequent itemset mining Similar to our solutions  s s t rong s o l u t i o n u s e s homomorphic encryption However it needs to use asymmetric homomorphic encryption scheme which is computationally expensive Reference  s s t rong s o l u t i o n r equi res a bout n  F encryptions as well as  n  T s   F homomorphic additions and scalar multiplications F is the number of frequent itemsets This solution’s running time is dominated by these expensive operations We evaluate its running time by estimating the required time to undertake the operations  see Table VI To estimate the running time we measure the speeds of two popular asymmetric additive homomorphic encryption schemes i.e Paillier Paillier and ElGamal implemented in Java and we r emark that ElGamal is the scheme suggested by T he s p eeds a re meas ured us i n g a machine of the same speciﬁcations in our evaluations see Table V and so are the datasets and parameters Compared with the result of our solution in Fig 4 the running time of  s s t rong s o l u t i o n i s s e v eral orders of magnitude B Communication Complexity and Storage Cost Similar to most other solutions our solutions require constant communication rounds In the preprocessing stage some keys and parameters are shared among t data owners These keys and parameters can be sent to data owners in parallel In the mining stage all mining results can be sent to data TABLE VII T RANSACTION C OUNT OF J OINT D ATABASE R ETAIL  TABLE VIII T RANSACTION C OUNT OF J OINT D ATABASE P UMSB  owners in a communication round Therefore the number of communication rounds does not grow if t  frequent itemsets or association rules increases The communication trafﬁc and storage cost in our solutions are dominated by the joint database size and the size of all ERVs Let n and n 012 be the transaction count of the joint database with and without ctitious transactions respectively Tables VII and VIII list the joint database size of two datasets under different settings of k and t  The joint database in our solutions contains ctitious transactions while the one in class algorithms does not We can observe from Tables VII and VII that the joint database size in our solutions is a few times larger and the size grows with k and t  The number of ERVs is at most n 012  t  O  n  t   A ciphertext’s size is O   d max   O   t  where  is the security parameter typically 80 Normally d max can be viewed as a small constant d max is not larger than 4 for most settings in the above experiments and the largest d max observed in the above experiments is 6 Let m be the average transaction size Then the communication trafﬁc and and storage cost in our solutions are both O  n  m  n    t  d max   The trafﬁc and cost in classic algorithms are O  n  m   For most reasonable transaction sizes our solutions resulted in an in communication trafﬁc and storage cost only by a few times The storage cost in  s s t rong solution is O  n  m   while the communication trafﬁc is O  T s  t  F  C  where F is the number of frequent itemsets C is the ciphertext size in 13  s str o n g so lu tio n  wh ich i s at least 2048 2048 bits In many settings our solutions trafﬁc is not any higher than the trafﬁc of s s t rong solution VIII R ELATED W ORK A Privacy-Preserving Association Rule Mining and Frequent Itemset Mining on Vertically Partitioned Databases In t h e  rs t w ork t o i dent i f y a nd addres s p ri v a c y i s s u es in vertically partitioned databases a secure scalar product protocol is presented and used to build a privacy-preserving frequent itemset mining solution Association rules can then be found given frequent itemsets and their supports Since 


LI et al  PRIVACY-PRESERVING-OUTSOURCED ASSOCIATION RULE MINING ON VERTICALLY PARTITIONED DATABASES 1859 the publication of this seminal work a number of privacypreserving association rule mining or frequent itemset mining solutions have been published in the literature see 11   1 3   28]–[31 The most relevant work is the privacy-preserving association rule mining solution presented in I n t hi s s ol ut i on a d at a owner known as the master is responsible for the mining The other data owners known as slaves insert ctitious transactions to their respectiv e datasets and send the datasets to the master Each data owner will also send his set of real transactions IDs to a semi-trusted third-party server The third-party server is assumed not to be colluding with any data owner but it cannot be trusted to hold the raw data The master generates association rule candidates from the joint database containing ctitious data For each rule candidate X  Y  the master sends the ID lists of the transactions containing X  Y and the transactions containing X to the third-party server The server veriﬁes if the rule is qualiﬁed or not Similar to our solutions a semi-trusted third-party is utilized for the mining However unlike our solutions a data owner i.e the master does the majority of the computational work Therefore we can hardly say that such a solution is an outsourced mining solution Though ctitious data are added in datasets to lower data usability the master is able to learn signiﬁcant information about other data owners raw data from the received datasets In cont rast our solutions do not leak such information as we do not rely on one particular data owner to undertake the computations and we also encrypt the datasets All existing solutions with the exception of  d o not utilize a third-party server to server to compute the mining result Some solutions  13 us e a s y mmet r i c encryption to compute the supports of itemsets while other solutions 28]–[30 us e a s ecure s cal ar product p rot o col  a s et intersection cardinality protocol or a secret sharing scheme to perform these computations A majority of these solutions expose exact supports to all data owners resulting in the leakage of information about the data owners raw data  The only exception is one of s s o l u t i ons  I n  13 t here are two privacy-preserving solutions for frequent itemset mining The rst solution exposes exact supports which is not desirable The second solution does not expose exact supports However association rules cannot be mined based on the result of second solution because conﬁdences cannot be computed without the exact supports In addition this solution’s method cannot be used to mine association rules because securely computing conﬁdence is more complicated than computing support In comparison with this solution our frequent itemset mining solution’s computational complexity is signiﬁcantly lower Our solutions do not expose exact supports or conﬁdences to data owners Different from existing solutions based on homomorphic encryption we use symmetric homomorphic encryption instead of asymmetric homomorphic encryption and the manner in which we use homomorphic encryption also differs from existing solutions In our approach we use homomorphic encryption to create ERVs and build our secure outsourced comparison scheme B Privacy-Preserving Outsour ced Association Rule Mining and Frequent Itemset Mining Privacy-preserving outsourced frequent itemset mining and association rule mining have been studied in the setting of a single data owner  19]–[21 I n e xi s t i n g s ol ut i ons  the data owner outsources thei r data and the mining task to the cloud but at the same time wish to keep the raw data secret from the cloud Generally data items in the database are encrypted using a substitution cipher prior to outsourcing Reference  propos ed a s ol ut i o n t o c ount er frequency analysis attack on substitution cipher However a later work demons t r at ed t h at 19 s s o l u t i o n i s not s ecure Giannotti et al proposed a solution based on k anonymity frequency   21 T o c ount er frequenc y a nal y s i s a t t ack the data owner inserts ctitious transactions in the encrypted database to conceal the item frequency After inserting the ctitious transactions any item in the encrypted database will share the same frequency with at least k  1 other items The data owner sends the encrypted database of both the real and ctitious transactions to the cloud The cloud runs a classic frequent itemset mining algorithm and returns the result frequent itemsets and their supports to the data owner The data owner revises these itemsets supports by subtracting them with these itemsets corresponding occurrence counts in the ctitious transactions respectively Finally the data owner decrypts the received itemsets with the revised supports higher than the frequency threshold an d generates association rules based on found frequent itemsets Our solutions use their techniques to conceal the raw data from the cloud and mitigate frequency analysis attack that can be undertaken by the cloud Using these techniques alone however is not sufﬁcient to protect data privacy in the vertically partitioned database setting To cancel out ctitious transactions both 21 an d  1 6  require the data owner to count itemset occurrences in ctitious transactions In the vertically partitioned database setting data owners are unable to perform such calculation using the techniques described in and  16 I n our s o l u t i ons  the cloud rather than the data owners cancels out ctitious transactions in a privacy-preserving manner and the underlying techniques are our homomorphic encryption secure comparison and ciphertext tag schemes Another recent work  propos ed a p ri v a c y pres e rving outsourced association rule mining solution based on predicate encryption This solution is resilient to chosen-plaintext attacks on encrypted items but it is vulnerable to frequency analysis attacks Applying this solution to vertically partitioned databases will also result in the leakage of the exact supports to data owners In this paper our adversary model is different We assume the cloud has knowledge of the item frequencies instead of chosen plaintext-ciphertext pairs and our solutions are resilient to frequency analysis attacks C Other Related Work Other than the settings of vertically partitioned databases and cloud/third-party-aided mining privacy-preserving frequent itemset mining and association rule mining have 


1860 IEEE TRANSACTIONS ON INFORMATION FORENSICS AND SECURITY VOL 11 NO 8 AUGUST 2016 been studied in the settings of horizontally partitioned databases   33]–[35 d at a publ i s hi ng 36 and d i f ferent i a l privacy  T hes e s e t t i ngs are b e yond t h e s cope of t h i s paper  IX C ONCLUDING R EMARKS In this paper we proposed a privacy-preserving outsourced frequent itemset mining solution for vertically partitioned databases This allows the data owners to outsource mining task on their joint data in a privacy-preserving manner privacypreserving manner Based on this solution we built a privacypreserving outsourced association rule partitioned databases Our solutions protect data owner’s raw data from other data owners and the cloud Our solutions also ensure the privacy of the mining results from the cloud Compared with most existing solutions our solutions leak less information about the data owners raw data Our evaluation has also demonstrated that our solutions are very efﬁci ent therefore our solutions are suitable to be used by data owners wishing to outsource their databases to the cloud but require a high level of privacy without compromising on performance To realize our solutions an efﬁcient homomorphic encryption scheme and a secure outsourced comparison scheme were presented in this paper Both schemes have potential usage in other secure computation applications such as secure data aggregation beyond the data mining solutions described in this paper Demonstrating the u tility of the p roposed homomorphic encryption scheme and outsourced comparison scheme in other settings will be the focus of future research A PPENDIX I NSERTING F ICTITIOUS T RANSACTIONS  s A LGORITHM  An algorithm to counter frequency analysis attacks on the outsourced database encrypted with a substitution cipher was proposed in F or the purpos e o f c oncealing t he item frequency this algorithm inserts ctitious transactions in the database to be oursourced The goal is to ensure that each item share the same frequency with at least k  1 items The algorithm is summarized as follows also see  Firstly the data owner scans the database to count each individual item’s support  Secondly the data owner groups items considering the supports and co-occurrence of items The data owner sorts items in decreasing order of support Starting from the rst of the sorted item list i.e the item with the highest support the data owner assigns every k adjacent items to a new created group If there are less than k unassigned items remaining these items will be assigned to the last created group The data owner swaps items from different groups to ensure that all items in the same group do not occur together in the same transaction  Thirdly for each item in each group the data owner calculates the difference between the item’s support and the highest support in the group The difference is deﬁned as the noise of the item  Fourthly to achieve k anonymity frequency the data owner generates ctitious transactions based on the result of the third step The number of an item’s occurrences in the ctitious transactions is equal to its noise calculated in the third step After inserting the ctitious transactions all items in the same group share the same support A CKNOWLEDGMENT The authors would like to thank Quach Vinh Thanh the Associate Editor and the three anonymous reviewers for providing constructive and gen erous feedback Despite their invaluable assistance any erro rs remaining in this paper are solely attributed to the authors R EFERENCES  T  B rijs  G  S winnen K V a nhoof a nd G W e ts   Us ing a s s o ciation r ules for product assortment decisions A case study in Proc SIGKDD  1999 pp 254–260  S  E  B ros s e tte A  P  S prague J  M  H ardin K B W a ites  W  T  J ones  and S A Moser Association rules and data mining in hospital infection control and public health surveillance J Amer Med Inform Assoc  vol 5 no 4 pp 373–381 1998 3 B  M obas h er  H  D ai T  L uo and M  N akaga w a E f f ecti v e p er s onalization based on association rule discovery from Web usage data in Proc WIDM  2001 pp 9–15  C  C reighton and S  H anas h Mining g ene e xpres s i on databas e s f or association rules Bioinformatics  vol 19 no 1 pp 79–86 2003 5 X  Y in and J  H an  CP A R  C las s i  cation b as ed on pr edicti v e as s o ciation rules in Proc SIAM SDM  2003 pp 1–5 6 R  A gr a w al and R  S r i kant  F a s t algor ithm s f o r m ining a s s o ciation rules in Proc VLDB  1994 pp 1–13 7 M  J  Z aki S calable algor ithm s f o r a s s o ciation m ining  IEEE Trans Knowl Data Eng  vol 12 no 3 pp 372–390 May/Jun 2000  J  H an J  P ei a nd Y  Y i n Minin g frequent patterns without candidate generation in Proc ACM SIGMOD  pp 1–12 2000 9 J  V aidya and C  C lif ton P r i v a c y pr es er ving as s o ciation r ule m ining i n vertically partitioned data in Proc SIGKDD  2002 pp 639–644  M Kantarcioglu a nd C Clifton Pri vacy-preserving distributed mining of association rules on horizontally partitioned data IEEE Trans Knowl Data Eng  vol 16 no 9 pp 1026–1037 Sep 2004  B Rozenber g and E  G udes   A s s o ciation r ules m i ning in v e rtically partitioned databases Data Knowl Eng  vol 59 no 2 pp 378–396 2006  J  Z h an S  M atwin and L  C hang Pri v a c y pres e rving c ollaborati v e association rule mining in Proc DBSEC  2005 pp 153–165  S Z hong Pri v a c y pres e rving a lgorithm s for d is trib uted m i ning of frequent itemsets Inf Sci  vol 177 no 2 pp 490–503 2007  P  P a illier  P ublick e y cr yptos ys tem s bas e d o n c om pos ite de gr ee r e s i duosity classes in Proc EUROCRYPT  1999 pp 223–238  R Cram er  R  G ennaro a nd B Schoenm ak ers   A s ecure and optim ally efﬁcient multi-authority election scheme Eur Trans Telecommun  vol 8 no 5 pp 481–490 1997  F  G i annotti L  V  S  L a ks hm anan A  M onr eale D  P e dr es chi and H Wang Privacy-preserving mining of association rules from outsourced transaction databases IEEE Syst J  vol 7 no 3 pp 385–395 Sep 2013  B Dong R L i u and H  W ang Res ult i nte g rity v e riﬁcation o f outsourced frequent itemset mining in Proc 27th Annu IFIP WG Conf Data Appl Secur Privacy DBSec  Newark NJ USA Jul 2013 pp 258–265 O A v a ilable http://dx doi o r g 10 1007/978-3-64 239256-6_17  R L i u a nd H W a ng Res ult i nte g rity v e riﬁcation o f outs ourced pri v ac ypreserving frequent itemset mining in Proc SIAM Int Conf Data Mining  Vancouver BC Canada Apr./May 2015 pp 244–252 Available http://dx.doi.org/10.1137/1.9781611974010.28  W  K W ong D W  Cheung E  Hung B Kao and N  M am oulis  Security in outsourcing of association rule mining in Proc VLDB  2007 pp 111–122  I  M o llo y  N  L i  a nd T  L i   O n the  in s ecur ity and  im  p r acticality of outsourcing precise association rule mining in Proc ICDM  Dec 2009 pp 872–877  F  G i annotti L  V  S  L a ks hm anan A  M onr eale D  P e dr es chi and W Wang Privacy-preserving data mining from outsourced databases in Proc CPDP  2011 pp 411–426 


LI et al  PRIVACY-PRESERVING-OUTSOURCED ASSOCIATION RULE MINING ON VERTICALLY PARTITIONED DATABASES 1861 22 FIPS Publication 180-1 Secure Hash Standard  Nat Inst Standards Technol Gaithersburg MD USA 1995 23 FIPS Publication 180-2 Secure Hash Standard  Nat Inst Standards Technol Gaithersburg MD USA 2002  T  E l Gam a l  A public k e y c ryptos ystem and a signature scheme based on discrete logarithms IEEE Trans Inf Theory  vol 31 no 4 pp 469–472 Jul 1985 O A v a ilable http://dx doi o r g 10 1109 TIT.1985.1057074  N  Cour tois  A  K lim o v  J  P atar in a nd A  S h am ir   E f  c ient algor ithm s for solving overdeﬁned systems of multivariate polynomial equations in Proc EUROCRYPT  2000 pp 392–407  P  F ournier V iger  Real-life Datasets in SPMF Format  accessed on Apr 6 2016 O A v a ilable http://w w w  philippe-fournier viger.com/spmf/index.php?link=datasets.php  P  F ournier V iger  A  G om ariz T  G ueniche A Soltani C  W  W u and V S Tseng SPMF A Java opensource pattern mining library J Mach.Learn.Res  vol 15 no 1 pp 3389–3393 2014  J  V a idya and C  C lif ton S ecur e s e t i nter s ection car dinality w ith application to association rule mining J Comput Secur  vol 13 no 4 pp 593–622 2005  X Ge L  Y an J  Z hu and W  S hi  Pri v ac y-pres erving dis t rib u ted association rule mining based on the secret sharing technique in Proc SEDM  Jun 2010 pp 345–350  R K h ar at M  K um bhar  and P  B ham r e E f  cient p r i v a c y pr es er ving distributed association rule mining protocol based on random number in Intelligent Computing Networking and Informatics  Raipur Chhattisgarh India Springer 2014 pp 827–836  C Dong and L  C hen  A f a s t s ecure dot product p rotocol with application to privacy preserving association rule mining in Proc 18th Paciﬁc-Asia Conf Adv Knowl Discovery Data Mining PAKDD  Tainan Taiwan May 2014 pp 606–617 Available http://dx.doi.o rg/10.1007/978-3-319-06608-0_50  J  L a i Y  L i  R  H  D eng J  W e ng C Guan a nd Q Y a n T o w ards semantically secure outsourcing of association rule mining on categorical data Inf Sci  vol 267 pp 267–286 May 2014  T  F ukas a w a  J  W ang T  T a kata a nd M  M i yazaki  A n e f f ecti v e distributed privacy-preserving data mining algorithm in Proc 5th Int Conf IDEAL  2004 pp 320–325  C Su and K  S akurai  A d is trib ut ed privacy-preserving association rules mining scheme using frequent-pattern tree in Proc ADMA  2008 pp 170–181  M  G  K a os ar  R  P aulet and X  Y i S ecur e tw opar t y a s s o ciation r ule mining in Proc ACSW-AISC  2011 pp 15–22  J  L  L in and J  Y  C L i u Pri v a c y pres erving item s et m i ning through fake transactions in Proc ACM Symp Appl Comput SAC  Seoul South Korea Mar 2007 pp 375–379 A v a ilable http://doi.acm.org/10.1145/1244002.1244092  B N K e s h a v am urthy  A M Khan a nd D T o s hniw a l Pri v a c y preserving association rule mining over distributed databases using genetic algorithm Neural Comput Appl  vol 22 no 1 pp 351–364 2013 Lichun Li received the bachelor’s degree in information engineering from the Beijing University of Posts and Telecommunications in 2002 the master’s degree in communication and information systems from the China Academy of Telecommunication Technology in 2006 and the Ph.D degree in computer science from the Beijing University of Posts and Telecommunications in 2009 He is currently a Postdoctoral Research Fellow with the INFINITUS Laboratory School of Electrical and Electronic Engineering Nanyang Technological University Singapore His research interests include privacy and security in cloud and big data Rongxing Lu S’09–M’11–SM’15 received the Ph.D degree in computer science from Shanghai Jiao Tong University Shanghai China in 2006 and the Ph.D degree in electrical and computer engineering from the University of Waterloo Waterloo ON Canada in 2012 From 2012 to 2013 he was a Postdoctoral Fellow with the University of Waterloo Since 2013 he has been an Assistant Professor with the School of Electrical and Electronic Engineering Nanyang Technological University Singapore His research interests include computer network security mobile and wireless communication security and applied cryptography He was a recipient of the Ca nada Governor General Gold Metal Kim-Kwang Raymond Choo SM’15 received the Ph.D degree in information security from the Queensland University of Technology Australia in 2006 He is currently a Cloud Technology Endowed Associate Professor with the University of Texas at San Antonio an Associate Professor with the University of South Australia and a Guest Professor with the China University of Geosciences He was named one of 10 Emerging Leaders in the Innovation category of The Weekend Australian Magazine Microsoft’s Next 100 series in 2009 and is a recipient of the ESORICS 2015 Best Research Paper Award the 2015 Winning Team of Germany’s University of Erlangen-Nuremberg Digital Forensics Research Challenge the 2014 Australia New Zealand Policing Advisory Agency’s Highly Commende d Award the 2010 Australian Capital Territory Pearcey Award the Fulbright Scholarship in 2009 the 2008 Australia Day Achievement Medallion and the British Computer Society’s Wilkes Award Anwitaman Datta is an Associate Professor with the School of Computer Science and Engineering NTU Singapore He lead s the Self and Algorithmic aspects of Networked Distributed Systems Research Group at NTU Jun Shao received the Ph.D degree from Shanghai Jiao Tong University Shanghai China in 2008 He was a Postdoctoral Fellow with the School of Information Sciences and Technology Pennsylvania State University State College PA USA from 2008 to 2010 He is currently a Full Professor with the Department of Information Security Zhejiang Gongshang University Hangzhou China His research interests include network security and applied cryptography 


