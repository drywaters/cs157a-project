Frequent Itemsets Mining Using Random Walks for Record Insertion and Deletion  Panita  Thusaranon Faculty of Information Technology King Mongkut’s Institute of Technology Ladkrabang Bangkok, Thailand panita.thu@dpu.ac.th Worapoj  Kreesuradej Faculty of Information Technology King Mongkut’s Institute of Technology Ladkrabang Bangkok,Thailand worapoj@it.kmitl.ac.th   Abstract In Association rules mining, the task of finding frequent itemsets in dynamic d atabase is very important because the updates may not only invalidate some existing rules but also make other rules relevan t. In this paper, we propose a new algorithm to maintain frequent itemsets of a dynamic database in the case of record insertion as we ll as deletion simultaneously Basically, the proposed algorithm maintains not only the support counts of frequent itemsets but also the support counts of prospective frequent itemsets, i e., infrequent itemsets that promise to be frequent in the fu ture, in an original database Prospective frequent itemsets, wh ich are obtained by using the principle of Random Walks, can help to reduce a number of times to rescan the original database  Keywords—frequent itemsets mining; incr emental association rule mining; random walks; data mining; prospective frequent itemsets I   I NTRODUCTION  Association rules mining is a process of discovering important correlations among items within transactions. The two major subtasks of associ ation rule mining are frequent itemsets generation and strong a ssociation rules formation. In dynamic database, maintaining frequent itemsets is major challenge of association rule mining because a change of frequent itemsets may affect some previous association rules become invalid, or some new valid rules may be generated Reference  1  deals with this issue by reprocessing entire new databases without utiliz ing acquired information from previous mining. The computati onal requirements for frequent itemsets generation are truly costly. Therefore, several incremental updating algorithms have been proposed to deal with this important problem based on Apriori algorithms In this paper, we propose a new algorithm to maintain frequent itemsets of a dynamic database in the case of record insertion as well as deletion simultaneously. Our algorithm applies Random walks process and uses previously mined information to avoid reprocessing entire dynamic databases The algorithm can maintain frequent itemsets of a dynamic databases efficiently The rest of this paper is orga nized as follows: related work and fundamental concept is given in Section II. The proposed algorithm is described in Section III. Experiments are conducted in Section IV. Conclusions are summarized in Section V II  PRELIMINARIES  This section summarizes related work and briefly defines the fundamental concept needed to facilitate the presentation of the proposed algorithm A  Related Work The first incremental updating technique to maintain association rules when new transactions are inserted is Fast Update \(FUP\ algorithm proposed by [2   The m a jor idea of FUP is to store frequent itemsets with their support counts found from the prio r association rule mining of an original database in an Apriori-like ma nner. For any candidate itemset from the newly inserted transactions which is also frequent in the original database, its new to tal support count can easily be updated. On the other hand, a ca ndidate itemset from the newly inserted transactions will be sc anned in the original database if it is frequent for the new transactions but not frequent in the original database. The extension algorithm of which can handle updating cases of data insertion as well as data deletion. However, FUP and FUP2 algorithm require rescanning an original database k th times when new frequent itemsets are found, where k is the length of maximal frequent itemsets To deal with multiple scan problem, the Efficient Dynamic Database Updating Algorithm \(EDUA The algorithm firstly calculates set of candidate and frequent 2itemsets by scanning an origina l database once in the prior mining. Frequent 2-itemsets are th en used by performing join actions to form the set of candidate 3-itemsets. Based on the scan reduction technique [5  6   candidate item s ets C k for k>3 are generated from C k-1 All candidate 2-itemsets and frequent k-itemsets from an original databas e are kept in main memory for the subsequent incremental mining. When data is added to or deleted from the original database, EDUA algorithm scan inserted and deleted transactions twice to update support counts of all frequent itemsets and corresponding 2-itemsets in the original database. Finally, new candidate itemsets are checked against the updated database in order to discover the new frequent itemsets. The limitation of this algorithm is that it performs efficiently under the assumption that the number of 2016 8th International Conference on Information Technology and Electrical Engineering \(ICITEE 978-1-5090-4139-8/16/$31.00 ©2016 IEEE 


candidate k-itemsets is not much larger than frequent kitemsets. In general, this assumption does not hold for a typical dataset Another incremental association rule mining algorithm which using the concept of Pre-large itemsets, was proposed by   for data deletion. Basically, the algorithm has two support thres holds. Firstly, an upper support threshold is the same as a mi nimum support threshold of the conventional association rule mining algorithms. Secondly, a lower support threshold defines the lowest support factor for itemsets to be kept in memory Itemsets that have their support factors between the upper support threshold and the lower support threshold are considered pre-large itemsets. By keeping pre-large itemsets in memory the new incremental algorithm can avoid rescanning the original datab ase until the accumulative amount of new transactions exceeds the safety bound at the expense of storage spaces  proposed kee p ing both frequent  itemsets and promising frequent itemsets in memory to maintain association rules when new transactions are inserted into an original database. Promising frequent itemsets infrequent itemsets that are expe cted to be frequent in the future, are estimated by using th e principle of Bernoulli trials The extension work of this algorithm which can handle updating cases of data insertion as well as data deletion was proposed by   The support counts of new candidate itemsets that are not previously frequent itemsets in an original database are approximated and pruned away if they are not potential frequent itemsets in an updated database. Then, an original database is rescanned only once to determine actual support counts of potentia l frequent itemsets In this paper, several experiments are conducted to compare the performance of the proposed algorithm with Apriori, FUP2 EDUA, Pre-large and Prob-based algorithm B  One-Dimentional Simple Random Walks In one dimension, the simple random walk may start from the origin and move one step to the right \(+1\\(-1 at a time according to probab ilities p and q, respectively where 1 p 0   Fig. 1 Fig. 1  One-dimentional simple random walks Suppose that  n  3  2  1 i  x  i  are sequence of identically and independently distributed random variables with p 1 q  1 x  P  p  1 x  P i i        where 1 p 0   Let 1 n represents the number of steps taken to the right 2 n  represents the number of steps tak en to the left, N represent the number of total steps, and n S represents the stopping position after taking N steps. Thus, the ordinary random walk can be written as  n 2 1 n x  x x S    1 Consider a walk consists of to tal N steps; the probability of walking 1 n right-steps is given by th e Binomial di stribution   1 1 1 1 n N n 1 1 n N n 1 1 q p  n N   n  N q p n N  n  P      2 Usually we are interested in a net displacement of n S steps to the right of the origin, which is determined by the total number of right-steps.  Since 2 1 n n n S   and N n n 2 1    so   S N  2 1 n n 1   3 The probability of being a net displacement n S steps to the right is provided by   S N  2 1 N  S N  2 1 n n n n n q p  S N  2 1 N   S N  2 1  N  S N  2 1  P         4 On the other hand, the random walks may start from the origin and move with steps +1, 0, -1 according to probabilities p, q and r, respectively where p, q, r  0 and 1 r q p    Let k represents the number of steps taken to the right, m represents the number of steps be ing still, and d represents the number of steps taken to the right. The probability of being stop at n S after walking N steps can be considered as Trinomial distribution  d m k d m k n r q p  d  m  k  N r q p d  m  k N  S x  P    5 C  Predicting Prospective Frequent Itemsets with Random Walks When transactions are inserted and deleted in an dynamic database, an itemset.X may and may not appear in some transaction. Infrequent itemsets in an original database that possibly be frequent in an updated database can be predicted by calculating  S x  P n  where n S is minimum support count in updated database. The probability calculating of prospective frequent itemsets in this concept is similar to that of being stop at n S after walking N steps in random walks The proposed algorithm needs to find not only frequent itemsets but also prospective fr equent itemsets from an original database. Prior-updating procedure is assumed that the number of new transactions that be allowed to insert into and the number of deleted transactions from an original database are known in advance. Then, prospective frequent itemsets are predicted by applying ra ndom walks process Assume that an original database with |DB| transactions is going to be inserted by 1 n transactions and deleted by p q S n  1             0           +1 2016 8th International Conference on Information Technology and Electrical Engineering \(ICITEE 


2 n transactions. Let k be the number of inserted transactions with itemset.X, m be the total number of inserted and deleted transactions without itemset.X, and d be the number of deleted transactions with itemset.X. Then  2 1 n n N d m k      6 The updated support count of an itemset.X after N steps total inserted and deleted transactions     N 1 i i 0 n x S S 7 Where 0 S is support count of an itemset.X in an original database and n S is support count of an itemset.X in future updated database. The value of independent random variable i x can be -1, 0, or +1. Let p q, and r be the probability that itemset.X will be inserted 1 x i    deleted transaction 0 x i   1 x i    respectively. Assume that value of p, q, and r is accumulated from previous updating and stored in memory. The probability that support count of an items et.X will increase to be n S after insertion of 1 n transactions into and deletion of 2 ntransactions from the original database of |DB| transactions can be considered as \(5 Even though the numbers of inserted transactions and deleted transactions are known in advance, the numbers of inserted and deleted transactions that an itemset.X appears are unknown. However, we know that support count of an itemset.X can be increased from 0 S to be n S with exactly k-d\ displacement from the origin at step N be equal to R with the following constraints  R k 2 N d k N m  R k d  S S d k R 0 n             8 Substituting the constraints 5\we obtain   R k R k 2 N k n r  r p 1  p  R k   R k 2 N   k  N  S x  P           9 Since the events x=S n for each k are fundamentally unrelated, we can sum over all possible values of k in \(9 Therefore, the probability mass function \(pmf                   R d k  r  r p 1  p  R k   R k 2 N   k  N R d k  0  S x  P R k R k 2 N k  R  2 1 n  R  0 max k n 1  10 where  2 1 n 1 represents the integer closest to but not exceeding 2 1 n 1  and |R| represents non-negative value of R For any itemset with support count 0 S in an original database  and R d k   there is no chance for that itemset to have support count at n S in an updated database. But if R d k   the value of k must be at least R in case 0 S S 0 n    or 2 1 n n  On the other hand, the value of k must be at least 0 in case 0 S S 0 n   or 2 1 n n  because k cannot be negative If S n is a minimum support count of an updated database the probability of an itemset.X to be a frequent itemset in the updated database can be obtained by          1 S 0 x n n n  x  P 1  S x  P 1  S x  P 11 Here, infrequent itemsets that have the probability greater than Prob pl a threshold specified by user, are treated as prospective frequent itemsets. Prob pl indicates the minimum probability level that an infrequent itemset in an original database will be a frequent itemset in an updated database Then, these prospective frequent itemsets are kept in order to reduce the number of times to rescan an original database. The higher Prob p l is set, the lesser prospective frequent itemsets are kept and the more number of times needed to rescan the original database in order to discover new frequent itemsets III  UPDATING FREQUENT ITEMSETS FOR RECORD INSERTION  AND DELETION  In a dynamic database, old tr ansactions may be deleted from and new transactions may be added into an original database. Thus, an infrequent ite mset in an original database may become frequent intemset in updated database if 1\is frequent in inserted transactions and/or 2 it is infrequent in deleted transactions. Both cases are required to rescan the original database to obtain the support count of the itemset   The proposed algorithm consists of two procedures. The first is a prior-updating proce dure which discovers and stores frequent itemsets, prosp ective itemsets and their support count of an original database, i.e. DB. The second is an incremental updating procedure that updates all frequent itemsets prospective frequent itemsets, a nd their support counts when either new transactions are added or old transactions are deleted from a dynamic database. A list of symbols used is given in Table I A  Pririor-Updating Procedure This procedure calculates all frequent itemsets and prospective frequent itemsets of an original database. Priorupdating procedure is assumed that the number of new transactions that be allowed to insert into an original database and the number of deleted transactions are available. Parameter p and r are also known from prior update 2016 8th International Conference on Information Technology and Electrical Engineering \(ICITEE 


TABLE I  MEANING OF SYMBOLS USED  DB Original database DB´ Updated database x   Support count of itemset X in DB x    Support count of itemset X in DB   Set of added transactions  Set of deleted transactions   x  Support count of itemset X in    x  Support count of itemset X in  s Minimum support threshold   Minimum support count in DB   Minimum support count in next update   k C  Candidate k-temsets in    k C  Candidate k-temsets in  DB k F  Frequent k-itemsets in DB k F   Updated frequent k-itemsets in DB DB k PF  Prospective frequent k-itemsets in DB k F P   Updated prospective frequent k-itemsets in DB  For example, an original database has 6 transactions as shown in Table II p and r of each itemset are shown in Table III, and a minimum support threshold is set to 40 percent. If one transaction is deleted and three transactions are inserted then a minimum support count of an updated database is 4. The probability of an itemset to be a frequent itemset in the updated database  4 x  P  is computed as shown in Table IV. If Prob pl  is set to 0.10, Item {B} is a prospective fre quent 1-itemset because it is infrequent itemset in DB and its probability, which is equal to 0.4414, is greater than Prob pl  TABLE II  A N EXAMPLE OF TRANSATION DATABASE  TID Items TID Items 100 ABC 400 AE 200 ADE 500 ABDE 300 DE 600 AE TABLE III  A N EXAMPLE OF P AND R FOR EACH ITEM  Itemset p r A 0.625 0.250 B 0.375 0.125 C 0.125 0.125 D 0.375 0.125 E 0.625 0.125 TABLE IV  INFREQUENT 1ITEMSET WITH  S x  P n   Item Count  4 x  P   B 2 0.4414 C 1 0.0850  B  Incremental-Updating Procedure The main algorithm is shown in Fig 2. For k=1, 1-itemsets obtained from prior-updating p rocedure are merged with 1itemsets obtained from scanning   and Then, the support count of the updated 1-itemsets is updated.  Only frequent 1itemsets that exist in   will be utilized to generate candidate 2itemsets \(C 2   Fig. 2  Incremantal updating procedure For 2 k  frequent k-itemsets and prospective k- frequent itemsets are updated repeatedly. Firstly  is scaned to find   x The candidate k-itemset which is not the member of kitemsets obtained from prior-updating procedure is a new candidate k-itemset and is moved to new k C Otherwise, the  Algorithm 1: Incremental mining Input DB     DB k F  DB k PF s Output  k F   k PF  k=1 1  scan   and  to find out   x and   x  2  for each itemset X  DB 1 C   1 C   1 C  3             x x x x  4  end 5   1 F X  1 C  x   DB´| x s 6   1 PF X  1 C  1 F X   and pl prob  x  P      k 2 7  while 012        scanDB _ Temp F P F 1 k 1 k  8           1 k 1 k db 1 k C F F  9           1 k 1 k db 1 k C F P PF  10  if k=2 11   db 1 db 1 db 2 F F C    12  else 13          scanDB _ Temp PF F  C db 1 k db 1 k db k  14    scanDB _ Temp PF F  db 1 k db 1 k      15  end 16  update support count // call algorithm 2 17  if |Temp_scanDB  F P F  k  k   015   18  Scanning an original database // call algorithm 3 19  k 20  end 21  if Temp_scanDB 012   22  Scanning an original database // call algorithm 3 2016 8th International Conference on Information Technology and Electrical Engineering \(ICITEE 


candidate k-itemset’s support count is updated and pruned from k C if support count is less than |DB´| x s.The support count of each new candidate k-itemset is estimated using the principle of maximum possible value. Since a new candidate 1-itemset is not in DB k F DB k PF its support count in an original database is at best equal to  1 where  is a minimum support count of the original database. The new candidate k-itemset, whose support count is less than |DB´| x s, are pruned from new k C because such a candidate k-itemset has no chance to be a frequent itemset  Fig. 3  Updating support count and frequent itemset procedure Then is scaned to find   x and calculate x   for each remaining candidate k-itemset, i.e. C k new k C If a remaining candidate k-itemset is the memb er of k-itemsets obtained from prior-updating procedure, its su pport count can easily be updated. The k-itemset whose support count satisfies the minimum support threshold is then a frequent itemset. For the k-itemset whose support count lower than the minimum support threshold, the probability of an itemset to be a frequent itemset in the updated database  x  P    will be calculated Infrequent itemsets that have  x  P    greater than Prob pl are treated as prospective frequent itemsets Contrarily, the remaining candidate k-itemset is a new candidate k-itemset. The support count of a new candidate kitemset is estimated. The new candidate 1-itemset, whose support count is greater than or equal to |DB´| x s, are moved to Temp_scanDB. The original database is scanned only if the number of itemsets in Temp_scanDB is greater than  F P F  k  k   015 where 015 is a threshold specified by users Otherwise, the new candidate k-itemsets in Temp_scanDB will be kept. The procedure is re peated until no candidate kitemsets can be generated. The proposed algorithm can thus find all frequent k-itemsets for the entire updated database  Fig. 4  Scanning an original database procedure IV  EXPERIMENT  We used a synthetic dataset called T10I4D100K The synthetic dataset comprises 100,000 transactions over 140 unique items. The performance of proposed algorithm is compared with Apriori and those algorithms which handle both case of record insertion and deletion, i.e. FUP2, pre-large and EDUA algorithm. However, since pre-large algorithm cannot deal with the case of insertion and deletion simultaneously, we first perform the case of deletion then follow by the case of insertion by using algorithm in  and [7 respectively The accuracy of frequent itemsets obtained from these algorithms is checked with those obtaine d from Apriori algorithm For the first experiment, 20,000 transactions are inserted into and 10,000 transactions ar e deleted from an original database of 100,000 transactions The support thresholds are varied between 0.01 and 0.05 with prob pl 0.01. The execution time versus minimum support is shown in Fig. 5 For the second experiment, the impact of the incremental size is tested using several size   and  As a preliminary experiment, the experiment is conducted only when the size of   is twice as the size of   with a support threshold 0.05. The execution time of each algorithm is shown in Fig. 6 According to Fig. 5 and 6, the execution time of the proposed algorithm is faster than that of Apriori, Pre-large and  Algorithm 2: Updating support count and frequent itemsets Input      DB k F  DB k PF s Output x   Temp_scanDB 1  scan   to find out   x for each X in db k C  2  for each itemset db k C X   3  if DB k DB k db k PF F C    4  move x to new k C  5  for each itemset DB k DB k PF F X    6  if db k C x   7          x x x  8  else x x      9  if x   DB´| x s 10  remove X from C k  11  for each itemset X  new k C  12  if   x   1\< |DB´| x s 13  remove X from new k C  14  scan  to find out   x  for each X in new k db k C C   15  for each itemset X  C k and X  DB k F DB k PF  16           x x x  17  for each itemset X  new k C  18  if      x x   1 DB´| x s 19  move X to Temp_scanDB 20   k F X  C k  x    DB´| x s 21  k k k F X  C X  F P      and pl prob  x  P      Algorithm 3 Scanning an original database Input   x      x    x   k F   k PF Temp_scanDB, s Output  k F   k PF  1  scan DB to find out x  for each X in Temp_scanDB 2  for each itemset X  Temp_scanDB 3             x x x x  4  new k F X  Temp_scanDB  and  x    DB´| x s 5  new k k new k F X  C X  PF    and pl prob  x  P      6   k F   k F new k F  7   k PF   k PF new k PF  8  clear Temp_scanDB 2016 8th International Conference on Information Technology and Electrical Engineering \(ICITEE 


EDUA algorithms but slower than FUP2 and Prob-based algorithms. This is such a case because  of  calculating probability in the proposed algorithm becomes extremely laborious as n increases due to large value of n  Besides, the proposed algorithm calculates  x  P    for each and every infrequent itemset which has poten tial to be frequent itemset in updated database. Thus, approx imation and infrequent itemsets pruning techniques are needed for further improvement  In this paper, the performance of EDUA algorithm is relatively insufficient because the algorithm is based on the assumption that the number of candidate itemsets is not much larger than frequent itemsets But in the experiments with a support threshold 0.05, the num ber of candidate itemsets is 14,023 while the number of frequent itemsets is only 199       1 10 100 1000 10000 100000 0.01 0.02 0.03 0.04 0.05 Apriori FUP2 Pre-large EDUA Prob-based Proposed  Fig. 5  The execution time \(sec   20K  10K and |DB|=100K transactions 1 10 100 1000 10000 10 20 30 40 Apriori FUP2 Pre-large EDUA Prob-based Proposed  Fig. 6  The execution time \(sec      TABLE V  THE NUMBER OF CANDIDATE ITEMSETS RESCANNED IN THE ORIGINAL DATABASE  k-itemset k Apriori FUP2 Prelarge EDUA Probbased Proposedalgorithm 1 144 6 48 75 0 0 2 4278 24 4230 2172 5 15 3 979 1 1051 169 1 2 4 128 0 9 15 0 0 5 61 0 0 6 0 0 6 17 0 0 0 0 0 7 2 0 0 0 0 0 Total 5680 31 5338 2437 6 17  However, the proposed algorithm can prune away efficiently new candidate itemsets if they ar e not potential frequent itemsets. Thus, the number of candidate itemsets need to be rescanned from the original database generated by the proposed algorithm is less than that generated by Ariori, FUP2 Pre-large and EDUA algorithm as shown in Table V In order to evaluate the predi ction accuracy, the Precision Re\ia are used. The result shows moderate accuracy of the proposed algorithm with precision=0.33, recall=1.00, and F1=0.50 V  CONCLUSIONS  AND FUTURE WORK  In this paper, we have proposed an incremental maintenance that can handle case of record insertion and deletion simultaneously. Th e proposed algorithm predicts prospective frequent itemsets by using random walk process and update frequent itemsets when transactions are added or deleted from database. The experimental results show that the execution time of the proposed algorithm is faster than that of Apriori algorithm but slower than FUP2 algorithm. It is quite obvious that calculating probab ility in the proposed algorithm becomes extremely laborious as n increases due to large value of n! Hence, work is going on for further improvement in our future work   R EFERENCES  1  Agrawal R and Srikant R \(1994\m for mining association rules in large database, Proceedings of 20th International Conference on Very Large Data Bases,  pp.487-499 2  Cheung DW, Han J, Ng VT, and Wong CY \(1996\, Maintenance of discovered association rules in large database: an incremental updating technique, Proceedings of 12th IEEE International Conference on Data Engineering, pp. 106-114 3  Cheung DW, Lee SD, and Kao B \(1997\eral incremental technique for maintaining discovered association rules, Proceedings of the 5th International Conference on Database Systems for Advanced Applications, pp. 185-194 4  Zhang S, Zhang J, and Zhang C \(2007\An efficient algorithm for dynamic database mining, Information Science Journal, Vol. 177 pp.2756-2767 5  Chen M, Han J, and Yu PS \(1996\ overview from database perspective, IEEE Transactions on Knowledge and Data Engineering, Vol. 8, pp. 866-883 6  Lee C, Lin CR, Chen MS \(2001\liding-window filtering: an efficient algorithm for incremental mining, in: Proceedings of International Conference on Information and Knowledge Management, CIKM01, pp 263–270 7  Hong TP, Wang CY, and Tao YH \(2001\, A new incremental data mining algorithm using pre-large itemsets, Intelligent Data Analysis Vol. 5, pp. 111–129 8  Hong TP and Huang TJ \(2007\, Maintenance of generalized association rules for record deletion based on the pre-Large concept, Proceedings of the 6th WSEAS Int. Conf. on Artificial Intelligence, Knowledge Engineering and Data Bases 9  Amornchewin R and Kreesuradej W \(2009\, Mining dynamic database using probability-based incremental association rule discovery algorithm, Journal of Universal Com puter Science, Vol. 15, no. 12, pp 2409-2428 10  Thusaranon PR and Kreesuradej W \(2015\ probability-based incremental association rule discovery algorithm for record insertion and deletion, Journal of Artificial Life and Robotics, Vol. 20, no. 2, pp. 115123   11  http://fimi.ua.ac.be/data  2016 8th International Conference on Information Technology and Electrical Engineering \(ICITEE 


 International Conference on Computing, Communication and Automation \(ICCCA2016   93     Fig. 7  Execution time of trie based Apriori on three different block distributions x-none In Fig   7, BD1 exhibits minimum execution time compared to BD2 and BD3 In BD1 blocks are located only on three DNs i.e two physical a nd one VMs DN So in this case Mappers are not running on both slower DNs tha t make the execution faster. Execution time for BD2 is poor than that o f BD1 due to using both VMs DNs  BD3 exhibits the worst performance since all the blocks are available on each DN MapReduce processes a data block locally on the DN where the block is present. F or block distribution BD3, all Mappers are running on the same DN since all blocks are locally available to each node In different attempt of running a job DN may be d ifferent each time but all the Mappers are being run on a same DN. All Mapper s running on the same DN does not make use of available resources which leads to increased execution time Here it can be seen that due to higher replication factor data locality may be a hurdle that slow down the execution  x-none E  Controlling Parallelism with Split Size x-none Hadoop is designed to process big datasets that does not mean one cannot be benefited for small datasets. Apriori is a CPU-intensive algorithm and consumes a significant time for smaller datasets. To reduce the execution time we need more than on e task running in parallel Split is used to control the number of map tasks for a MapReduce job A split may consist of multiple blocks and there may be multiple splits for a single block So without changing the block size user can control the number of Mappers to be run for a particular job We have used the method setNumLinesPerSplit\(Job job int numLines  of class NLineInputFormat  from MapReduce library to set the number of lines per split. In our earlier cases we were running multiple Mappers against different parts of the same block Here we set the split size 5K lines on block distribution BD3 which contains 5 data blocks This creates 12 splits i.e 12 Mappers  size for BD3 the n  blocks are considered as input s plits. Fig   8 shows the difference in execution time for these two cases  Here it can be seen that how the split size controls the parallelism Smaller split size launches more number of Mappers which consequently increase the parallelism. It does not mean that more number of Mappers always results into better performance. Increasing the number of Mappers beyond a particular point starts to degrade the performance due to unnecessary overheads and shortage of resources   To achieve the right level of parallelism it must be taken care that the map task is CPU-intensive or CPU-light as well as the size of dataset to be processed Fig. 8  Execution time of trie based Apriori with Input Split and without Input Split on BD3 x-none F  Issues Regarding MapReduce Implementation The efficiency of an algorithm running as a MapReduce job is extensively influenced by data structure used and algorithm itself A third factor that cannot be ignored is the implementation technique.  Implementation technique may be regarding to implementation of various modules of Apriori e.g candidate generation support counting of candidates against each transaction pruning of infrequent itemsets or regarding to MapReduce implementation of Apriori MapReduce implementation of Apriori is central to discussion here. A major issue in MapReduce based Apriori is to invoke candidate generation i.e apriori-gen  Algorithm 7 at appropriate place inside Mapper class. In our implementations we have invoked apriori-gen  inside customized method map of Mapper class. In Mapper class, two methods setup  and map  are customized and one method apriori-gen  is defined Method setup  is called once at the beginning of a task It is customized to read frequent itemsets of previous iteration from distributed cache and to initialize prefix tree Method apriori-gen  generates candidates using prefix tree containing frequent itemsets The map  is invoked for each line of input split of dataset If there are 100 lines of input assigned to a Mapper then map method will be invoked for 100 times Subsequently it invokes apriori-gen  repeatedly each time Since apriori-gen  method produces candidates which is independent of input instance, so need not to invoke repeatedly inside map  method The apriori-gen  metho d is  computation intensive and increases the execution time when invoked repeatedly. This repeated computation can be fixed if we invoke apriori-gen  outside of map  Theoretically it sounds good but did not work when invoked inside setup  method We have also tried another way in which apriorigen  is invoked inside overrided method run  of Mapper class but again could not achieve expected reduction in execution time VI  C ONCLUSIONS  In this paper we have investigated a number of factors affecting the performance of MapReduce based Apriori algorithm on homogeneous and heterogeneous Hadoop 


 International Conference on Computing, Communication and Automation \(ICCCA2016   94   cluster and presented strategies to improve the performance It has been shown that how hash table trie data structure and transaction filtering technique can significantly enhance the performance Factors like speculative execution physical  VMs DataNodes, data locality block distribution and split size are such that their proper tuning can directly enhance the performance of a MapReduce job even without making algorithmic optimization Approaches of MapReduce implementation of Apriori is another important factor that also influence the performance R EFERENCES  1  J. Han and M. Kamber, Data Mining: Concepts and Techniques, Morgan Kaufmann Publishers 2006  2  J S Ward a  b y d ata a survey of big d ata d  http://arxiv.org/abs/1309.5821v1 3  Apache Hadoop, http://hadoop.apache.org 4  Big data is useless without algorithms Gartner says http://www.zdnet.com/article/big-datais useless-withoutal gorithmsgartner-says/, Retrieved Nov. 2015 5   algorithms for mining association rules  Proceedings Twentieth International Conference on Very Large Databases, Santiago 1994 pp. 487 499 6   and distributed association mining a survey Concurrency, IEEE, vol 7, no. 4,pp. 14 25, 1999 7  K. Bhaduri, K. Das, K. Liu, H. Kargupta and J. Ryan, Distributed Data Mining Bibliography 2008  8  HDFS  Architecture Guide https://hadoop.apache.org/docs/r1.2.1/hdfs_design.html Retrieved Sept 2015  9  MapReduce Tutorial http://hadoop.apache.org/docs/current/hadoopmapreduce-client/hadoop-mapreduce-clientcore/MapReduceTutorial.html, Retrieved Sept. 2015 10  Yahoo Hadoop Tutorial http://developer.yahoo.com/hadoop/tutorial/index.html 11   ACM SIGOPS Operating Systems Review vol 37 no 5 pp 29 43 2003  12    Commun., vol. 51, pp 107 113, 2008 13   mining using clouds an experimental implementation of apriori over mapreduce    14   Apriori: association rules algorithm based on mapreduce  IEEE 2014  15   as a programming model for association rules algorithm on hadoop  nternational Conference on Information Sciences and Interaction Sciences ICIS 2010 vol. 99, no. 102, pp. 23 25  16   implementation of apriori algorithm based on mapreduce  h ACIS International Conference on  Software Engineering Artificial Intelligence Networking and Parallel  Distributed Computing IEEE 2012 pp 236 241  17   Hadoop as a platform for distributed association rule mining   COMPUTING 2013 the Fifth International Conference on Future Computational Technologies and Applications, pp. 62 67  18  M-Y Lin P-Y Lee and S based frequent itemset mining algorithms on mapreduce in  Proceedings 6th International Conference on  Ubiquitous Information Management and  2012, Article 76 19   itemset mining on Hadoop  Proceedings IEEE 9th International Conference on Computational Cybernetics \(ICCC\Hungry, 2013, pp. 241 245  20   strategy of mining association rule based on cloud computing   Proceedings IEEE International Conference on Business Computing and Global Informatization BCGIN 2011 pp 29 31 21  Honglie Yu, Jun Wen, Hongmei Wang and Li Jun, "An improved apriori algorithm based on the boolean matrix and Hadoop Procedia Engineering 15 \(2011\1827-1831, Elsevier 22  Matteo Riondato, Justin A. DeBrabant, Rodrigo Fonseca and Eli Upfal PARMA: a parallel randomized algorithm for approximate association rules mining in mapreduce in Proceedings 21st ACM international conference on information and knowledge management 2012 pp 8594  23  Jiong Xie et al Improving mapreduce performance through data placement in heterogeneous hadoop clusters in IEEE International Symposium on Parallel & Distributed Processing,  Workshops and Phd Forum \(IPDPSW\ 2010, pp. 19  24  Matei Zaharia Andy Konwinski Anthony D Joseph Randy Katz and Ion Stoica Improving mapreduce performance in heterogeneous environments in 8th USENIX Symposium on Operating Systems Design and Implementation \(OSDI\ 2008, vol. 8, no. 4, pp. 2942  25  Hsin-Han You, Chun-Chung Yang and Jiun-Long Huang, "A load-aware scheduler for MapReduce framework in heterogeneous cloud environments in Proceedings of the ACM Symposium on Applied Computing, 2011, pp. 127-132 26  Faraz Ahmad Srimat Chakradhar Anand Raghunathan and T N Vijaykumar, "Tarazu optimizing MapReduce on heterogeneous clusters," ACM SIGARCH Computer Architecture News, vol. 40, no. 1 pp. 61-74, 2012 27  HADOOP PERFORMANCE TUNING white paper Impetus Technologies Inc October 2009 https://hadooptoolkit.googlecode.com/files/White%20paperHadoopPerformanceTuning.pdf 28  Apache Hadoop NextGen MapReduce YARN http://hadoop.apache.org/docs/stable/hadoop-yarn/hadoop-yarnsite/YARN.html, Retrieved Sept. 2015 29  SPMF Datasets http://www.philippe-fournierviger.com/spmf/index.php?link=datasets.php 30   ata structure for data  in Mathematical and Computer Modelling, vol 38  no. 7, pp. 739-751, 2003 31  Ferenc Bodon A fast apriori implementation in Proceedings IEEE ICDM workshop on frequent itemset mining implementations  90, 2010 32  Sudhakar Singh, Rakhi Garg and P. K. Mishra  analysis of apriori algorithm with different data structures on hadoop cluster  International Journal of Computer Applications, vol. 128, no. 9, pp. 4551  2015  33  Christian Borgelt Efficient implementations of apriori and 351clat in Proceedings IEEE ICDM workshop on frequent itemset mining   34  Ferenc Bodon, "Surprising results of Trie-based fim algorithms," FIMI 2004  35  Ferenc Bodon A trie-based APRIORI implementation for mining frequent item sequences," in Proceedings 1st international workshop on open source data mining: frequent pattern mining  implementations ACM, 2005 36  Hadoop Wiki Virtual Hadoop https://wiki.apache.org/hadoop/Virtual%20Hadoop  


002 004\002 005\002 006\002 007\002 003\002 033\002 034\002 035\002 002\004\002\005\002 006\002 
002 005 007 033 035 004\002 004\005 004\007 004\005\006\007\003\033 
C Increased Rule Length 
002 005 007 033 035 004\002 004\005 004\007 004\033 004\035 005\002 020\020\030\027\011\025\021\013 026\032\025\025\011\020\021\030\032 025 011\021\012\030\017 023\004\002\002 023\004\002\004 
 
002\003\004\005\006\007\010\011\012\013\014\010\015\004\013'\013\022\015\(\023\011\\004\015\004\012\007\013 024\007\024!\004\007\013 002\003\004\005\006\007\010\011\012\013\014\010\015\004\013'\013\022\015\(\023\011\\004\015\004\012\007\013 024\007\024!\004\007\013 
Figure 6 Throughput for increasing length rule candidates The Y-axis is measured in billion evaluations per second The X-axis shows the corresponding rule length As before the gures include the theoretical trend-line computed from amplifying naive-sc on the GPU using Eq 4 reason the observed improvement is stable depending mostly on the item number Assigning multiple candidate rule collections to a single block resulted in Figure 7 Percentage improvement in execution time as compared to the default-tpsc kernel for the individually optimized kernels when using synthetic data   Figure 8 Percentage improvement in execution time as compared to the default-tpsc kernel for the individually optimized kernels when using real data For both kernels we observe a similar behaviour when we increase rule candidate length to a number larger than 32 After that point we require evaluating the pre“x in two phases following a technique similar to parallel reduction although using warp vote functions This extra phase requires an additional synchronization step which increases the total execution time per iteration Additionally when we have prominent rules with item indices in sequence i.e accidents dataset as indicated by its sparsity pattern caching transactions does not provide any improvement However when there are many rules with out of sequence pre“xes the cost of uncoalesced memory accesses matches the synchronization cost as indicated by experiments on dataset 1 VIII C ONCLUSION In this paper we studied the support count operation commonly used in association rule mining problems We proposed a work-ef“cient parallel algorithm that is suitable for massively parallel architectures Furthermore we presented a data layout scheme used to enable low overhead coordination of the processing elements reduce the memory requirements and achieve high off-chip memory bandwidth utilization Furthermore we discussed in detail low level optimization strategies related to effective use of shared memory while presenting a simple strategy for resolving shared memory bank con”icts incurring minimal additional work However there is still some additional issues that we need to address Firstly we already considering resolving the issue of 
025 015\013\036\021\031\013\020 015\036\021\031\013\020 
improvement over the default-tpsc execution time A combination of loop unrolling and increase shared memory utilization from storing more candidate rules in the same block was the reason for the observed improvement In contrast enabling caching of transactions in shared memory with kernel mrs-tpsc presented less improvement in the relative execution time compared to mr-tpsc The culprit is this case is the additional synchronization step which is required after loading the data in shared memory Finally experiments performed on dataset 2 and 4 indicate similar behavior to our previous experiments where multiprocessor underutilization was limiting the maximum possible performance increase Even in the case where we increase the workload of participating blocks interleaved execution of warps is limited since as the block size is small In this section we discuss the effects of discovering rules with length larger than 32 Due to lack of space we present the results from the execution on synthetic data 1 and accidents which are good representatives of the observed behaviour We focus on the mrs-tpsc and mr-tpsc variations which we established to be highly optimized throughout our experiments   
025 015\013\036\021\031\013\020 015\036\021\031\013\020 
037\005\005\010 \004\012\007!\013   002 003 004\002 004\003 005\002 005\003 006\002 006\003 007\002 002\004\002\005\002 006\002 011\012\012\004\005\007\010\011\012\013   002 003 004\002 004\003 005\002 005\003 006\002 006\003 007\002 002\004\002\005\002\006\002 004\007\024\010$\013  014%\031&&\013 
18 
027\011$\012\014\017\021\036\021\031\013\020  025\012%&\011\036\013\020\022\036\022'\031\014  025\012%&\011\036\013\020\022\036\022\020\031\014 021\(\011\032\015\011\021\030\020    002 004 005 006 007 002\004\002\005\002 006\002 
1431 
1431 


 volume 22 pages 207…216 ACM 1993  R Agra w al R Srikant et al F ast algorithms for mining association rules In  volume 1215 pages 487…499 1994  E Ansari G Dastghaibif ard M K eshtkaran and H Kaabi Distrib uted frequent itemset mining using trie data structure  35\(3 2008  M Atzmueller and F  Puppe Sd-map…a f ast algorithm for e xhausti v e subgroup discovery In  pages 6…17 Springer 2006  C Creighton and S Hanash Mining gene e xpression databases for association rules  19\(1 2003  W  F ang M Lu X Xiao B He and Q Luo Frequent itemset mining on graphics processors In  pages 34…42 ACM 2009  K Geurts G W ets T  Brijs and K V anhoof Pro“ling of high-frequenc y accident locations by use of association rules  1840 2003  A Ghoting G Buehrer  S P arthasarathy  D Kim A Nguyen Y K Chen and P Dubey Cache-conscious frequent pattern mining on modern and emerging processors  16\(1 2007  G Grahne and J Zhu Ef ciently using pre“x-trees in mining frequent itemsets In  volume 90 2003  J Han J Pei and Y  Y in Mining frequent patterns without candidate generation In  volume 29 pages 1…12 ACM 2000  J Hipp U G  untzer and G Nakhaeizadeh Algorithms for association rule mining„a general survey and comparison  2\(1 2000  R Jin and G Agra w al An algorithm for in-core frequent itemset mining on streaming data In  pages 8…pp IEEE 2005  R Jin and G Agra w al Systematic approach for optimizing comple x mining tasks on multiple databases In  pages 17…17 IEEE 2006  E Lindholm J Nick olls S Oberman and J Montrym Nvidia tesla A uni“ed graphics and computing architecture  2 2008  J Liu Y  P an K W ang and J Han Mining frequent item sets by opportunistic projection In  pages 229…238 ACM 2002  L Liu E Li Y  Zhang and Z T ang Optimization of frequent itemset mining on multiple-core processor In  pages 1275…1285 VLDB Endowment 2007  B Mobasher  R Coole y  and J Sri v asta v a Automatic personalization based on web usage mining  43\(8 151 2000  E  Ozkural B Ucar and C Aykanat Parallel frequent item set mining with selective item replication  22\(10 2011  J Pei J Han H Lu S Nishio S T ang and D Y ang H-mine Hyper structure mining of frequent patterns in large databases In  pages 441…448 IEEE 2001  I Pramudiono and M Kitsure ga w a P arallel fp-gro wth on pc cluster  In  pages 467…473 Springer 2003  C Silv estri and S Orlando gpudci Exploiting gpus in frequent itemset mining In  pages 416…425 IEEE 2012  A T ajbakhsh M Rahmati and A Mirzaei Intrusion detection using fuzzy association rules  9\(2 2009  T  T assa Secure mining of association rules in horizontally distrib uted databases  26\(4 2014  K W ang M Stan and K Skadron Association rule mining with the micron automata processor In  2015  M J Zaki Scalable algorithms for association mining  12\(3 2000  M J Zaki M Ogihara S P arthasarathy  and W  Li P arallel data mining for association rules on shared-memory multi-processors In  pages 43…43 IEEE 1996  F  Zhang Y  Zhang and J D Bak os Accelerating frequent itemset mining on graphics processing units  66\(1 2013  Y  Zhang F  Zhang Z Jin and J D Bak os An fpga-based accelerator for frequent itemset mining  6\(1 2013 
002 004 005 006 007 002 004\005\035 005\003\033 006\035\007 003\004\005 002 033 004\005 004\035 005\007 002 004\005\035 005\003\033 006\035\007 003\004\005 
ACM SIGMOD Record Proc 20th int conf very large data bases VLDB IAENG International Journal of Computer Science Knowledge Discovery in Databases PKDD 2006 Bioinformatics Proceedings of the fth international workshop on data management on new hardware Transportation Research Record Journal of the Transportation Research Board The VLDB Journal FIMI ACM SIGMOD Record ACM sigkdd explorations newsletter Data Mining Fifth IEEE International Conference on Data Engineering 2006 ICDE06 Proceedings of the 22nd International Conference on IEEE micro Proceedings of the eighth ACM SIGKDD international conference on Knowledge discovery and data mining Proceedings of the 33rd international conference on Very large data bases Communications of the ACM Parallel and Distributed Systems IEEE Transactions on Data Mining 2001 ICDM 2001 Proceedings IEEE International Conference on Advances in Knowledge Discovery and Data Mining Parallel Distributed and Network-Based Processing PDP 2012 20th Euromicro International Conference on Applied Soft Computing Knowledge and Data Engineering IEEE Transactions on Proceedings of the 2015 IEEE 29th International Parallel and Distributed Processing Symposium Knowledge and Data Engineering IEEE Transactions on Supercomputing 1996 Proceedings of the 1996 ACM/IEEE Conference on The Journal of Supercomputing ACM Transactions on Recon“gurable Technology and Systems TRETS 
Figure 9 Execution time measured for increasing rule size  the Xaxis indicates the rule length multiprocessor under-utilization For dataset with low number of items we can assign individual groups of threads in the same block to different rule collections effectively increasing the block size as well as utilization Secondly we would like to adapt our solution to an architecture consisting of multiple GPUs and address challenges related to partial result sharing A CKNOWLEDGMENT This work was supported by the U.S National Science Foundation under grant ACI-1339756 R EFERENCES  Frequent itemset mining dataset repository  2015 URL http://“mi.ua.ac.be/data  R Agra w al T  Imieli  nski and A Swami Mining association rules between sets of items in large databases In 
014\010\015\004\013\016!\004\005!\021\013 026\027\012\007\030\004\007\010\005\013\031\013 014\010\015\004\016!\004\005!\021\013 037\005\005\010 \004\012\007!\013 
015\036\021\031\013\020 015\013\036\021\031\013\020 
1432 
1432 


 Frequent pattern mining Current status and future directions  2007  R Agra w al and R Srikant F ast algorithms for mining association rules in  1994  M J Zaki Scalable algorithms for association mining  vol 12 no 3 pp 372…390 2000  J Han J Pei and Y  Y in Mining frequent patterns without candidate generation in  2000  Y  Zhang F  Zhang and J Bak os Frequent itemset mining on large-scale shared memory machines in  2011  F  Zhang Y  Zhang and J D Bak os  Accelerating frequent itemset mining on graphics processing units  vol 66 no 1 pp 94…117 2013  Y  Zhang  An fpga-based accelerator for frequent itemset mining  vol 6 no 1 pp 2:1…2:17 May 2013  P  Dlugosch  An ef“cient and scalable semiconductor architecture for parallel automata processing  vol 25 no 12 2014  I Ro y and S Aluru Finding motifs in biological sequences using the micron automata processor in  2014  R Agra w al T  Imieli  nski and A Swami Mining association rules between sets of items in large databases in  1993  H No yes Microns automata processor architecture Recon“gurable and massively parallel automata processing in  June 2014 keynote presentation  M J Zaki  Parallel data mining for association rules on shared-memory multi-processors in  1996  L Liu  Optimization of frequent itemset mining on multiple-core processor in  2007  I Pramudiono and M Kitsure ga w a P arallel fp-gro wth on pc cluster in  2003  E Ansari  Distributed frequent itemset mining using trie data structure  vol 35 no 3 p 377 2008  W  F ang  Frequent itemset mining on graphics processors in  2009  B Goethals Surv e y on frequent pattern mining  Univ of Helsinki Tech Rep 2003  C Bor gelt Ef cient implementations of apriori and eclat in  2003 p 90  Frequent itemset mining dataset repository   http mi.ua.ac.be/data  J Rabae y  A Chandrakasan and B Nik oli  c  2nd ed Pearson Education 2003 
100 1000 10000 5 50 500 5000 re_sup = 0.12 Eclat-6C \(32nm Eclat-1G \(28nm Apriori-AP 45nm Apriori-AP 32nm Apriori-AP 28nm Computation Time \(s Size of Dataset \(MB Eclat-6C \(32nm Eclat-1G \(28nm Apriori-AP 45nm Apriori-AP 32nm Apriori-AP 28nm GPU fails for re_sup = 0.08 re_sup = 0.08 
GPU fails re_sup = 0.42 re_sup = 0.42 Eclat-6C \(32nm Eclat-1G \(28nm Apriori-AP 45nm Apriori-AP 32nm Apriori-AP 28nm  Computation Time \(s Size of Dataset \(MB Eclat-6C \(32nm Eclat-1G \(28nm Apriori-AP 45nm Apriori-AP 32nm Apriori-AP 28nm GPU fails re_sup = 0.3 re_sup = 0.3 b T100 Figure 11 Performance prediction with technology normalization as a function of input size implementation In contrast the capability of our AP ARM solution scales nicely with the data size since the AP was designed for processing streaming data With the challenge of the big data era a number of other complex pattern mining tasks such as frequent sequential pattern mining and frequent episode mining have attracted great interests in both academia and industry We plan to extend the proposed CPU-AP infrastructure and automaton designs to address more complex pattern-mining problems A CKNOWLEDGMENT This work was supported in part by the Virginia CIT CRCF program under grant no MF14S-021-IT by C-FAR one of the six SRC STARnet Centers sponsored by MARCO and DARPA NSF grant EF-1124931 and a grant from Micron Technology R EFERENCES  J Han 
et al Data Min Knowl Discov Proc of VLDB 94 IEEE Trans on Knowl and Data Eng Proc of SIGMOD 00 Proc of CLUSTER 11 J Supercomput et al ACM Trans Recon“gurable Technol Syst et al IEEE TPDS Proc of IPDPS14 Proc of SIGMOD 93 Proc of Fifth International Symposium on Highly-Ef“cient Accelerators and Recon“gurable Technologies et al Proc of Supercomputing 96 et al Proc of VLDB 07 Proc of PAKDD 03 et al IAENG Intl J Comp Sci et al Proc of DaMoN 09 Proc FIMI 03 Digital Integrated Circuits 
1 10 100 1000 10000 0.1 1 10 100 1000 
a Webdocs 
699 


