y e  a g e y o s  t  F I N N n 1   2   B ig lo n git u d in a l in 3 226 5  D is c o v e r in g u s e f u l in f o r m a t io n f r o m h e t e r o ge n e o u s 6 226 2  H o we v e r  d e v e lo p in g v is u a liz a t io n t o o ls is c r u c ia l t o d  d f 3  T h e b a s ic id e a o f P P is t o d e s ign a n d e  h 4 226  2 7   P P is b a s e d o n t h e r  P g 3   2 6    2 8  226  3 9  a n d l 6   4 0  226  4 5   d 017 s 2332-7790 \(c This article has been accepted for publication in a future issue of this\ journal, but has not been fully edited. Content may change prior to fin\al publication. Citation information: DOI 10.1109/TBDATA.2017.2653815, I\EEE Transactions on Big Data H  017 y  f g y h  s l n P n V I  A S C D G D T R i igh 6  e X  f x 1 x 2 x d g  s 020 1 p 2  s  s    s   2 s   2 s   021 ws s f x  s  x 1 p 2  x 2 s  s  x 3  s  x 4 2 s    r 000 031 e n 000 031 d 031 e o e f x  s   f x  s  x 1  n 1 s  x 2  n 1 s   x 3  n 2 s  x 4  n 2 s    1 A d n a Zhang 


2332-7790 \(c This article has been accepted for publication in a future issue of this\ journal, but has not been fully edited. Content may change prior to fin\al publication. Citation information: DOI 10.1109/TBDATA.2017.2653815, I\EEE Transactions on Big Data 2 B g n 1 2 n 2 4 n 3 8  r e  e 6  A e 7  p 2 f x  s   x 1  x 2  s  s   x 3  s  000  s   x 4 2 s 2 s     n t y n ic  y 8 a n d B u j a  4 9  in 1 9 8 5 is a n in t e r a c t iv e v is u a ld s 0 226  5 6   H o we v e r  t h e s e m e t h o d s we r e n o t id e a l in t e r m s n ws 7 s u gge s t e d a n a lgo r it h m f o r  s e t  g d y 7  le t a 1  s  e q 2 d 000 s  025 1 s    025 1 s    025  2 s    025  2 s  001   d a 2  s  e q 2 d 000 c  025 1 s   000  025 1 s    025  2 s   000  025  2 s  001   e 025 i  a 1  s  d a 2  s  e  k a 1  s  k 2 2  2 d d  2 X j 1 000 in 2  025 j s s 2  025 j s  001 1  k a 2  s  k 2 2  2 d d  2 X j 1 020 s 2  025 j s  000  2  025 j s  021 1   d h a 1  s   a 2  s  i  2 d d  2 X j 1  025 j s  025 j s  000  025 j s  025 j s 0   e 001i s a 1  s  d a 2  s  e e f x i  s  020 X 0 i 1 X 0 i 2 021 i 1  2   s s s X s X i  X j e i d j s X i 0  X j 0 e s  0  031 025 l a 1  s   a 2  s  e N s T s d l p s D i j n X i 0 a d X j 0 D 003 j n X i a d X j S s c i e i k s D e  e 013 s f s S E P s f x a  a h X 0 i 1  d X k  1 x k a 1 k  X 0 i 2  d X k 1 x k a 2 k    a 1  s  d a 2  s  l n  001  d  001  e n r a  a 1  s   a 2  s  n   s gi l 8   5 9  p r o 0  I t is h igh ly e f f e c t iv e a n d 0  n e s  e e 1 226  6 5  b u t r a r e ly o n m o d if yin g 4  n r e l 


 e  f S P  013 l  f l 000 f x l  S P  013 l f l f x l  n  f x l in f x S P  013 l f l f x   013 l 1  013 l 1  016  f l 1  f l 1 000 016  013 l 1  013 l 1 000 016  f l 1  f l 1  016  k  f  e 013 l f l  0 013 l  f l 1 o  e X 0 A  f S P  013 l 000 f l  f x l  S P  013 l f l f x l  n  f  or l 0 o l x o 3 p r s e  o  d ls a o n  E D P N P T  h ilt 0  we p r o p o s e d a n E n h a n c e d s ly r n P r id l    t N   X i  1 024 i 024 N s f x 1 x 2 x d g h X i h t  s t e is   t h N  X i a t r f x 1 x 2 x 1 t x 1 x 2 x 2 t x d 1 x d 2 x t g  m is   o 0  le t t h e d is t a nc e b e t w e e n f X i nd X j e t e y D 003 j  D 003 j  k X i 000 X j k 2 e 001k 2 n  l e N f X 0 e s D j  1 024 j 024 i 6  j  0 is c a lc u la t e d a s  S am  1 P i j D 003 j X j 000 D 003 j 000 D j 001 2 D 003 i j   s n S P e s S P w a s S P b  S E P  S P w  f S P b    M m  l a X i i 1  2 N ls c i  0 024 i 024 N d    l x p 016  013  f  f x d S P  f f f S P l 000 S P l 000 1 f f 024  n  or h 8               S E P w  1 P i j D 003 j X c i  c j 000 D 003 j 000 D w j 001 2 D 003 i j S P b  1 P i j D 003 j X c i 6  c j 000 D 003 j 000 D b j 001 2 D 003 i j  e 1 P i j D 003 j l  P c i  c j 020 D 003 j 000 D w j 021 2 D 003 i j d P c i 6  c j  D 003 j 000 D b j  2 D 003 i j e  D w j e i d j d D b j n e i d j y  013 d f f   0 d 013  f 1 n e  c i 1 i 1  2 N in l 013  f  a m s e S P w  f S P b s o  0 013  f 1    e S P  f x  e f x s  k 2332-7790 \(c This article has been accepted for publication in a future issue of this\ journal, but has not been fully edited. Content may change prior to fin\al publication. Citation information: DOI 10.1109/TBDATA.2017.2653815, I\EEE Transactions on Big Data  r S P 0 1  l 0  m 0  013 0 d f 0  013 0 f 0  0 013 0  f 0 1   e  f  S P l  S P  013 l 1 f l 1 f x l   e 


 f f f f S P  m  000 S P  m  f f f 024  n  f  f x  m   f x  m  000 034 001 001  m   k  or m 0 o m x o  S P  m   S P  f x  m    or g f x  f x  m  a e t e m  034 t 0  001  m   S P  m  f x  m  036 f f f f  2 S E P  m    f x  m   2 f f f f a d w  000 2 P i j D 003 j e o f x  0  t h e E P P a lgo l g f S P ge f  P N C E S S g 6 a n d t wo r a n d o m c o n t r o lle d t r ia l  R C T  3   6 7  226  6 9   T h e s e d a t a f e a t u r e s a r e s u m m a r iz e d  n e m A o  N  0 9 0  p  1 5 3  t  1 4 6    0 0 0  c  3 3 4 a g 0 a n d p u b lis h e d b y  6 6    7 0   I t   5  0  P e s l a t 1 t 2 t 3 t 4 s C 1 1 7 C 2 4 C 3 2 m C 1 1 1 C 2 5 C 3 9 a t 1 t 2 t 3 t 4 s C 1 1 0 C 2 4 C 3 5 m C 1 9 0 C 2 3 C 3 7 llyt   2  0 d 3  T h is in t e r v e n  e d   e g 1 226  7 3   A s s h o wn in Figu r e s m s    3  0 h n 4 f f D w j nd D b j n f 013 nd f e f f x e S P p ing 013 nd f  8     013  013  f  f 000  if S P  013  f 000 f x  S P 013  013 000 f  f   if S P  013 000 f  f x  S P 013  f   e  e in e S P n 013 d f s f f x n S P  e X 0 e e f x  e 013 d f p 016 n s ld  is  l x  f x l in f x S P  013 l f l f x     A g f x  P s X 0  013 d f d  m r m x  S P  1  S P  m  d f x  m  2332-7790 \(c This article has been accepted for publication in a future issue of this\ journal, but has not been fully edited. Content may change prior to fin\al publication. Citation information: DOI 10.1109/TBDATA.2017.2653815, I\EEE Transactions on Big Data 


2332-7790 \(c This article has been accepted for publication in a future issue of this\ journal, but has not been fully edited. Content may change prior to fin\al publication. Citation information: DOI 10.1109/TBDATA.2017.2653815, I\EEE Transactions on Big Data 5  S P  m  f x  m   8         w N P j  1 j 6  p h D 003 j 000 D w j D 003 j D w j i 020 f x  m  000 X j 0  m  021 if c p  c j  w N P j 1 j 6  p h D 003 j 000 D b j D 003 j D b j i 020 f x  m  000 X j 0  m  021 if c p 6  c j    2 S P  m   020 f x  m  021 2  8         w N P j  1 j 6  p 1 D 003 j D w j 024 000 D 003 j 000 D w j 001 000  f x  m  000 X j 0  m   2 D w j 020 1  D 003 j 000 D w j D w j 021 025 i f c p  c j  w N P j 1 j 6  p 1 D 003 j D b j 024 000 D 003 j 000 D b j 001 000  f x  m  000 X j 0  m   2 D b j 020 1  D 003 j 000 D b j D b j 021 025 i f c p 6  c j   e 4 6 8 10 0 2 4 6 8   r 1.5 1 0.5 0 0.5 1 1.5 1 0.5 0 0.5 1   P F P 0 0.2 0.4 0.6 0.8 1 50 0 50 100 150   e 20 25 30 35 40 10 15 20 25 30 35   r 1 0.5 0 0.5 1 1.5 1 0.5 0 0.5 1   P F P d  f d f l e  s   013 d f gin f x e  P e 013 e f r 016  016 0  1  g 013 d f e a t 1 t 2 t 3 t 4 t 5 t 6 M C 1 0 0 C 2 3 C 3 0 C 4 0 A C 1 5 8 C 2 8 C 3 0 C 4 0 C C 1 0 6 C 2 0 C 3 0 C 4 0 l 


P F P 0 0.2 0.4 0.6 0.8 1 0.01 0.02 0.03 0.04 0.05 a Stress   EPP Sammon e 0 5 10 15 2 0 2 4 6 8 10 12   r 1.5 1 0.5 0 0.5 0.8 0.6 0.4 0.2 0 0.2 0.4 0.6 0.8 1 1.2 2332-7790 \(c This article has been accepted for publication in a future issue of this\ journal, but has not been fully edited. Content may change prior to fin\al publication. Citation information: DOI 10.1109/TBDATA.2017.2653815, I\EEE Transactions on Big Data 6 t 0 0.2 0.4 0.6 0.8 1 0.02 0.04 0.06 0.08 0.1 a Stress   EPP Sammon t F g  a t 1 t 2 t 3 t 4 t 5 t 6 M C 1 1 0 C 2 2 C 3 0 C 4 0 A C 1 1 0 C 2 4 C 3 0 C 4 0 C C 1 2 0 C 2 0 C 3 0 C 4 0 s 013 a d f  s   P E U G S D L N L D A  o 4 p 7 p 2  T  A o 1  r e s p e c t iv e ly  a n d s in  o  l  e  s  N in f 0  0  0  0  0  0 g  d A  0 d o 8 d  A  


 0 F  F r a n k e l a n d R  R e i d  223 B i g d a t a  D i s t i l l i n g m e a n i n g f r o m d a t a  224 e  5 D  E  P i r e s  R  C  d e M e l o M i n a r d i  C  H  d a Si l v e i r a  F  F  C a m p o s  224 s    6 O  M o r o z o v a a n d M  A  M a r r a  223 A p p l i c a t i o n s o f n e x t g e n e r a t i o n 224 s  4 M  K e l l e r  J  B e u t e l  O  Sa u k h  a n d L  T h i e l e  223 V i s u a l i z i n g l a r g e n l h n   9 B  H  B r i n k m a n n  M  R  B o w e r  K  A  St e n g e l  G  A  W o r r e l l  a n d 224 e s  1 M  W a l d r o p  223 B i g d a t a  w i k i o m i c s  224 s  4 W  T a n  M  B  B l a k e  I  Sa l e h  a n d S D u s t d a r  223 So c i a l n e t w o r k 224 g   5 D  T r a c e y a n d C  Sr e e n a n  223 A h o l i s t i c a r c h i t e c t u r e f o r t h e i n t e r n e t n d m n 1 H  F a n g  Z  Z h a n g  C  J  W a n g  M  D a n e s h m a n d  C  W a n g  a n d 224 k   7 D  P  B a r t e l  223 M i c r o r n a s  g e n o m i c s  b i o g e n e s i s  m e c h a n i s m  a n d 224 l   3 M  K u m a g a i  J  K i m  R  I t o h  a n d T  I t o h  223 T a s u k e  a w e b b a s e d 224 s   2 P  F o x a n d J  H e n d l e r  223 C h a n g i n g t h e e q u a t i o n o n s c i e n t i 002 c d a t a 224  7 f 2 0  0  0  0  0  0 g  o  f 0  0  0  0  0  0 g  A m N 0 o N 0 r e r  ly e  e r  r g e e s  7 s  f s d    m 0 000 3 o 0 000 6  s s   w    4   7 5   t h e c o r r e la t io n m a t r ix 1 ly m f 0  1  0  3  0  5 g 4   7 5   T h e d a t a s iz e wa s d e s    0 000 3  0 000 4  0 000 5 d 0 000 6 e 0 s   s  2 ile 0  C N gt ig l o d t s gie l 0 226  4 5    6 7    7 4    7 6   U s in g t h e p u b lic iz e d U C I f d  n g d ld a  A T h r ig R S  8 C  L y n c h  223 B i g d a t a  H o w d o y o u r d a t a g r o w  224 e  6 H  F a n g  H  W a n g  C  W a n g  a n d M  D a n e s h m a n d  223 U s i n g p r o b n E n 2332-7790 \(c This article has been accepted for publication in a future issue of this\ journal, but has not been fully edited. Content may change prior to fin\al publication. Citation information: DOI 10.1109/TBDATA.2017.2653815, I\EEE Transactions on Big Data   3 F  C h a n g  J  D e a n  S G h e m a w a t  W  C  H s i e h  D  A  W a l l a c h  A 224 s    2 A  M c A f e e  E  B r y n j o l f s s o n  T  H  D a v e n p o r t  D  P a t i l  a n d D  B a r 224 v 


 s s  8 H  F a n g  C  J o h n s o n  C  St o p p  a n d K  A  E s p y  223 A n e w l o o k y 224 E n g t 224   2 G  B o e n t e a n d R  F r a i m a n  223 K e r n e l b a s e d f u n c t i o n a l p r i n c i p a l 224    4 J  B  K r u s k a l  223 T o w a r d a p r a c t i c a l m e t h o d w h i c h h e l p s u n c o v e r t h e r n 226  5 E  R  M   J  Y  G o u l e r m a s  T  M u  a n d J  F  R a l p h  223 A u t o m a t i c 224 226  0 H  F a n g  V  D u k i c  K  E  P i c k e t t  L  W a k s c h l a g  a n d K  A  E s p y  n 224 s s s 2332-7790 \(c This article has been accepted for publication in a future issue of this\ journal, but has not been fully edited. Content may change prior to fin\al publication. Citation information: DOI 10.1109/TBDATA.2017.2653815, I\EEE Transactions on Big Data a 226  3 J  O  R a m s a y    8 R  J  H y n d m a n  S U l l a h l g  6 D  G e r v i n i  223 F r e e k n o t s p l i n e s m o o t h i n g f o r f u n c t i o n a l d a t a  224 y s   7 N  L o c a n t o r e  J  M a r r o n  D  Si m p s o n  N  T r i p o l i  J  Z h a n g  K  C o x  7 Z  Z h a n g  H  F a n g  a n d H  W a n g  223 V i s u a l i z a t i o n a i d e d e n g a g e 224 d 224   3 J  F r i e d m a n a n d J  T u k e y  223 A p r o j e c t i o n p u r s u i t a l g o r i t h m f o r 224  6 M  C  J o n e s a n d R  Si b s o n  223 W h a t i s p r o j e c t i o n p u r s u i t  224  1 H  F a n g  K  A  E s p y  M  L  R i z z o  C  St o p p  S A  W i e b e  a n d h 224 f   4 P  H a l l a n d M  H  N   223 O n p r o p e r t i e s o f f u n c t i o n a l p r i n c i p a l 224 t  0 Z  Z h a n g a n d H  F a n g  223 M u l t i p l e i m p u t a t i o n b a s e d c l u s t e r i n g s 224  1 H  F a n g  C  J o h n s o n  C  St o p p  a n d K  A  E s p y  223 A n e w l o o k y 224  7 G  E s l a v a a n d F  H  C  M a r r i o t t  223 So m e c r i t e r i a f o r p r o j e c t i o n 224 n     1 B  W  Si l v e r m a n 8 1 0.5 0 0.5 1 1 0.8 0.6 0.4 0.2 0 0.2 0.4 0.6 0.8 1 Data size = 2000 1 0.5 0 0.5 1 1 0.5 0 0.5 1 Data size = 4000 1 0.5 0 0.5 1 1.5 1 0.5 0 0.5 1 Data size = 6000 1 0.5 0 0.5 1 1 0.5 0 0.5 1 Data size = 10000 1 0.5 0 0.5 1 1 0.5 0 0.5 1 Data size = 20000 1 0.8 0.6 0.4 0.2 0 0.2 0.4 0.6 0.8 1.2 1 0.8 0.6 0.4 0.2 0 0.2 0.4 0.6 0.8 Data size = 100000 e d  0 226  9 H  F a n g  V  D u k i c  K  E  P i c k e t t  L  W a k s c h l a g  a n d K  A  E s p y  n 224 226  2 H  F a n g  M  L  R i z z o  H  W a n g  K  A  E s p y  a n d Z  W a n g  223 A n e w g y y   0 S P e z z u l l i a n d B  Si l v e r m a n  223 So m e p r o p e r t i e s o f s m o o t h e d 224  9 D  G e r v i n i  223 R o b u s t f u n c t i o n a l e s t i m a t i o n u s i n g t h e m e d i a n a n d 224  l s   9 J  A  R i c e a n d B  W  Si l v e r m a n  223 E s t i m a t i n g t h e m e a n a n d c o 224 h s s s 224   2 K  A  E s p y  H  F a n g  D  C h a r a k  N  M i n i c h  a n d H  G  T a y l o r  n 224 h h m  5 F  Y a o a n d T  L e e  223 P e n a l i z e d s p l i n e m o d e l s f o r f u n c t i o n a l p r i n 224 s   8 J  D a u x o i s  A  P o u s s e  a n d Y  R o m a i n  223 A s y m p t o t i c t h e o r y f o r t h e e 224 


 8 D  A s i m o v  223 T h e g r a n d t o u r  a t o o l f o r v i e w i n g m u l t i d i m e n s i o n a l 224 y n   3 D  C o o k  A  B u j a  J  C a b r e r a  a n d C  H u r l e y  223 G r a n d t o u r a n d 224 s   4 D  C o o k a n d A  B u j a  223 M a n u a l c o n t r o l s f o r h i g h d i m e n s i o n a l d a t a 224 224 n   0 A  B u j a  C  H u r l e y  a n d J  M c d o n a l d  223 A d a t a v i e w e r f o r m u l t i n 2332-7790 \(c This article has been accepted for publication in a future issue of this\ journal, but has not been fully edited. Content may change prior to fin\al publication. Citation information: DOI 10.1109/TBDATA.2017.2653815, I\EEE Transactions on Big Data  4 H  F a n g  K  A  E s p y  M  L  R i z z o  C  St o p p  S A  W i e b e  a n d h 224 l e s  6 D  F  A n d r e w s  223 P l o t s o f h i g h d i m e n s i o n a l d a t a  224 f e g   s   1 D  C o o k  A  B u j a  a n d J  C a b r e r a  223 D i r e c t i o n a n d m o t i o n c o n t r o l i n n f 0   0 20 40 60 80 100 0 50 100 150 200 250 300 350    Dimension d Iterations   e 10 3  e 10 4  e 10 5  e 10 6   002 0 a 9 1.5 2 1.5 1 0.5 0 0.5 1 Data size = 1800 1.5 1.5 1 0.5 0 0.5 1 1.5 2 Data size = 3600 2 1.5 1 0.5 0 0.5 1 1.5 Data size = 5400 2.5 0.5 0 0.5 1 1.5 2 Data size = 9000 1.5 1.5 1 0.5 0 0.5 1 1.5 Data size = 18000 1.5 1.5 1 0.5 0 0.5 1 1.5 Data size = 36000 F 0   100 200 300 500 1000 5000 0 50 100 150 200 250 300 350 400    Sample size N Iterations   e 10 3  e 10 4  e 10 5  e 10 6 s   7 R  K h a t t r e e a n d D  N  N a i k  223 A n d r e w s p l o t s f o r m u l t i v a r i a t e 224   9 A  B u j a a n d D  A s i m o v  223 G r a n d t o u r m e t h o d s  a n o u t l i n e  224 y o   5 H  F a n g  J  A l l i s o n  B  B a r t o n  Z  Z h a n g  G  O l e n d z k i  a n d Y  M a  n n l g  2 D  C o o k  A  B u j a  a n d C  H u r l e y  223 G r a n d t o u r a n d p r o j e c t i o n 224   3 H  F a n g  S D i F r a n z a  Z  Z h a n g  D  Z i e d o n i s  a n d J  A l l i s o n  l n  N  


 e n r n  y f s a   1 J  M a o a n d A  K  J a i n  223 A r t i 002 c i a l n e u r a l n e t w o r k s f o r f e a t u r e e x 224  2 R  C  T  L e e  J  R  Sl a g l e  a n d H  B l u m  223 A t r i a n g u l a t i o n m e t h o d 224 i e y t f  e s s g d s e   9 J  H u  W  D e n g  J  G u o  a n d W  X u  223 L e a r n i n g a l o c a l i t y d i s 224 0   0 5 10 15 20 0 2000 4000 6000 0 100 200 300 400 500  Dimension d Sample size N  Iterations e 10 3 e 10 4 e 10 5 e 10 6 m f    n s   0 J  W  Sa m m o n  223 A n o n l i n e a r m a p p i n g f o r d a t a s t r u c t u r e a n a l y s i s  224 2332-7790 \(c This article has been accepted for publication in a future issue of this\ journal, but has not been fully edited. Content may change prior to fin\al publication. Citation information: DOI 10.1109/TBDATA.2017.2653815, I\EEE Transactions on Big Data f e s n s l n n n s   5 H  F a n g  223 h l m d a t a a n d h l m r m p o w e r  T r a d i t i o n a l r e p e a t e d m e a d n   6 Y  M a  B  O l e n d z k i  J  W a n g  G  P e r s u i t t e  W  L i  H  F a n g  P  M e r  f d n  8 A  D a y a n i k  223 F e a t u r e i n t e r v a l l e a r n i n g a l g o r i t h m s f o r c l a s s i 002 c a 224 E n h  7 E  W e g m a n a n d J  Sh e n  223 T h r e e d i m e n s i o n a l a n d r e w s p l o t s a n d 224  3 E  P e k a l s k a  D  d e R i d d e r  R  P  D u i n  a n d M  A  K r a a i j v e l d  223 A n n s  1 Z  Z h a n g a n d H  F a n g  223 M u l t i p l e v s n o n o r s i n g l e i m p u t a t i o n l n  6 A  A s u n c i o n a n d D  N e w m a n  223 U c i m a c h i n e l e a r n i n g r e p o s i t o r y  224  7 S S K i m  S H  K i m  H  F a n g  S K w o n  D  Sh e l l e y  a n d D  Z i e d o n i s  n d 224  e  A v a i l a b l e  0 3 227 227  223 A n e w m i b a s e d v i s u a l i z a t i o n a i d e d v a l i d a t i o n i n d e x f o r 224 g  5 L  Y a n g  223 Sa m m o n  s n o n l i n e a r m a p p i n g u s i n g g e o d e s i c d i s n e  9 T  K  H o u s t o n  R  S Sa d a s i v a m  J  J  A l l i s o n  A  S A s h  M  N  e t 2 224  6 C  H u r l e y a n d A  B u j a  223 A n a l y z i n g h i g h d i m e n s i o n a l d a t a w i t h 224  2 Z  Z h a n g  H  F a n g  a n d H  W a n g  223 M u l t i p l e i m p u t a t i o n l 224 e I   0 L  B r e i m a n  J  F r i e d m a n  C  J  St o n e  a n d R  A  O l s h e n  l s s i t C   4 H  F a n g  G  P  B r o o k s  M  L  R i z z o  K  A  E s p y  a n d R  S s 224  s  8 T  K  H o u s t o n  R  S Sa d a s i v a m  D  E  F o r d  J  R i c h m a n  M  N  224 s  5 G  W  F u r n a s a n d A  B u j a  223 P r o s e c t i o n v i e w s  D i m e n s i o n a l i n f e r 224  4 J  B  T e n e n b a u m  V  D e Si l v a  a n d J  C  L a n g f o r d  223 A g l o b a l 224 g g 


2 2013  A Plaza 2009  G F  Hughes 322On the mean accurac y of statistical pattern recognizers 323 1968  M Imani and H Ghassemian 322Feature e xtraction using attraction points situa\323 1986\3201990 2014  A Agarw al T  El-Ghaza wi H El-Askary  and J Le-Moigne 322Ef 336cient in 2009 2009  G Y  Chen and S.-E Qian 322Denoising of hyperspectral imagery using 323 2011  J  W ang and C.-I Chang 322Independent component analysis-based anal\323 1586\3201600 2006  M Sugiyama 322Dimensionality reduction of multimodal labeled data by 323 5 2007  W  Li S Prasad J E F o wler  and L M Bruce 322Locality-preserving anal\323 1185\3201198 2012  Y  Qian F  Y ao and S Jia 322Band selection for hyperspectral imagery 323 213\320222 2009  F  Zhang B Du L Zhang and L Zhang 322Hierarchical feature dropout 2016  S Jia G T ang J Zhu and Q Li 322 A no v el ranking-based clustering 323 2016  S Chen and D Zhang 322Semisupervised dimensionality reduction 323 2013  J Li M Khodadadzadeh A Plaza X Jia and J M Bioucas-Dias 323 480\320491 2005  M F auv el J A Benediktsson J Chanussot and J  R Sv einsson SVMs 323 46 2008  M D Mura A V illa J A Benediktsson J Chanussot and L Bruzzone morphological 323 2015  R Ji 1811\3201824 2014  S Jia Y  Xie G T ang and J Zhu 322Spatial-spectral-combined 323 2016  J Li J M B ioucas-Dias and A Plaza 322Semisupervised hyperspecwith 323 2011  J Li J M Bioucas-Dias and A Plaza 322Hyperspectral image se gmen\323 2011 analysis 323 image 323 and 323 2 sparse 323 classi\336ca\323 2011  Q S ul Haq L Shi L T ao and S Y ang 322 A rob ust band compresin 2010 196\320200  M F auv el Y  T arabalka J A Benediktsson J Chanussot and yperspectral 323 2016  L Zhang 2011  X Xu J Li X Huang M D Mura and A Plaza 322Multiple mor sensing 323 5 2016  D T uia M V olpi M D Mura A Rak otomamonjy  and R Flamary  with 323 10 2014  S Jia X Zhang and Q Li 322Spectral\320spatial hyperspectral image clasusing 11 2010  B Zhang S Li X  J ia L Gao and M P eng 322 A dapti v e Mark o v random 323 Sens JIA MFL also that Gabor systematic will ork R EFERENCES  D Manolakis D Mardon and G A Sha w  322Hyperspectral image pro\323 ans Sens on Earth Sens  2016  J A Benediktsson J A P almason and J R Sv einsson 322Classi\336cation morphological 323 ocomputing Comput  2003  J M Bioucas-Dias IEEE Lett  Lett Sens Sens Remote Sens IEEE ICIS al Sens Sens Geosci Lett Sens al Sens Sens Geosci Lett IEEE  Sens al t 11 xtraction feature by only eature simple 3DGPC-HDM methods techniques for classi\336cation C ONCLUSION framewith magapproach hand parallel information signi\336cantly the and e 3DGPC-HDM with MLR 1 al  al Giza 353\320356  M F auv el J Chanussot and J  A Benediktsson 322K ernel principal comsensing 323 323 sub  Theory ISSPIT ocess Res is k Cybern ans Sens Sens This article has been accepted for inclusion in a future issue of this j\ournal. Content is final as presented, with the exception of pagination e published  L Zhang X Zhu L Zhang and B Du 322Multidomain subspace classi\336cation 323 


1\3206  J Li J M Bioucas-Dias and A Plaza 322Spectral\320spatial classi\336cation learn\323 844\320856 2013  M Khodadadzadeh 4033\3204045 2016  Y  T arabalka J Chanussot and J  A Benediktsson 322Se gmentation and 323 2010  Y  T arabalka J Chanussot and J  A Benediktsson 322Se gmentation and forest 323 2010  J C T ilton Y  T arabalka P  M Montesano and E Gofman 322Best gion 323 6 2015  Y  Qian M Y e and J Zhou 322Hyperspectral image classi\336cation based elet 323 2015  J Bruna and S Mallat 322Classi\336cation with scattering operain 1872\3201886 2013  L He Y  Li X Li and W  W u 322Spectral\320spatial classi\336cation of h yper sparse 323 2013  S Jia Z Zhu L Shen and Q Li 322 A tw o-stage feature selection frame\323 4 2014  Z Zhu 1\32027 2011  J Wright A Y  Y ang A Ganesh S S Sastry  and Y  Ma 322Rob ust f ace 323 2009  G H Granlund 322In s earch of a general picture processing operator  323 1978  F  Bianconi and A Fern\207ndez 322Ev aluation of the ef fects of Gabor 336lter 323 2002  L Shen and L Bai 322 A re vie w on Gabor w a v elets for f ace recognition 323 2006  X Chen J  Y ang J Zhang and A W aibel 322 Automatic detection and 323 375\320383 2008  T  C Bau S Sarkar  and G Heale y  322Hyperspectral re gion classi\336ca\323 2010  L W isk ott J.-M Fellous N K uiger  and C v on der Malsb ur g 322F ace 323 1997  B Zhang S Shan X  Chen and W  G ao 322Histogram of Gabor ace 323 57\32068 2007  W  Zhang S Shan L Q ing X Chen and W  Gao 322 A re Gabor phases recognition?\323 25 2011  D Zhang W  K K ong J Y ou and M W ong 322Online palmprint iden\323 2016  K Kayabol and J  Zerubia 322Unsupervised amplitude and te xture clas\323 2013  J J de Mesquita S\207 Jr  P  C Cortez and A R Back es 322Color te x\323 2014  J G Daugman 322High con\336dence visual recognition of persons by a test 323 50 2012  J Li 1592\3201606 2015  Z Zhong 4461\3204478 2016  W  Li C Chen H Su and Q Du 322Local binary patterns and 323 3681\3203693 2015  S Asif 322Dynamic compressi v e sensing Sparse reco v ery algorithms for Comput 2013  J A Richards el 323  1561\3201566  J Bruna and S Mallat 322In v ariant s cattering con v olution netw orks 323 323  2015  R O Duda P  E H art and D  G  S tork classi\336ca\323 hash\323  2015  Z Guo X W ang J Zhou and J  Y ou 322Rob ust te xture image repre\323 10 2014  J Zhao Y  Zhong H Shu and L Zhang 322High-resolution image classirandom 323 11 2012  M Khodadadzadeh J Li S Prasad and A Plaza 322Fusion of h yperspec\323 4 2013  Y  Y  T ang Y  Lu and H Y uan 322Hyperspectral image classi\336cation 323 5 2015  D Gabor  322Theory of communication P art 1 The analysis of infor 323 26 1946  L Shen and S J ia 322Three-dimensional Gabor w a v elets for pix el-based 323 12 2007  C Liu and H W echsler  322Gabor feature based classi\336cation using the 323 3 2009  L Shen L Bai and Z J i 322FPCODE An ef 336cient approach for 323 9 2003  S Xie S Shan X Chen and J  Chen 322Fusing local patterns of Gabor 323 9 2013  J Li J M B ioucas-Dias and A Plaza 322Spectral\320spatial hyperspectral and 323 h Intell gnit  2011  L Shen Z Zhu S Jia J Zhu and Y  Sun 322Discriminati v e Gabor 323  2012  Y  Chen Z Lin and X Zhao 322Riemannian manifold learning based in Australia 1975\3201978  C.-C Chang and C.-J Lin 322LIBSVM A library for s upport v ector 323  2004  L Shen and L Bai 3223D Gabor w a v elets for e v aluating SPM nor 323  2010  Y  Dong D T ao X Li J  Ma and J  Pu 322T e xture classi\336cation and 323  ICME Anal Sens al Sens ocess Sens Sens Sens Geosci Lett al Classi\336cation IEEE Int IGARSS IEEE ocess ocess Geosci Sens ocess Intell ocess Sens Sens al Sens al Sens Intell ocess Appl ans Sens  2013  1993  R N Brace well Applications 12 CYBERNETICS  J Lin Q W ang and Y  Y uan 322In defense of iterated conditional in Anal Intell e ocess e ocess Man Cybern CVPR  Sci hnol Appl Intell Cybern ans  Intell oduction This article has been accepted for inclusion in a future issue of this j\ournal. Content is final as presented, with the exception of pagination gnit Sens Sens Sens Sens 3  2000  J Li P  R Marpu A Plaza J M Bioucas-Dias and J A Benediktsson image 323 


JIA al the Edition  This article has been accepted for inclusion in a future issue of this j\ournal. Content is final as presented, with the exception of pagination grees Zhejiang 2007  with are China hyperspecprocessing learning from and Nottingham U.K ersity image the ge Engineering current acial yperspectal classi\336cation ard the attern ICIP 2016 engiphotogrammetry uhan  Professor an has Laboratory Mapping the China Smart 336c photogramystems the ournal the  from the ong 2008 the  interests high in transportation Zhu Li 13 Shen and Computing ia 


2734 IEEE TRANSACTIONS ON IMAGE PROCESSING VOL 26 NO 6 JUNE 2017 context model our framework can signiﬁcantly improve the recognition performance of the previous semantic manifold approach and its variants We further recast convolutiona l networks as sophisticated SMNs implemented as weakly supervised adaptation of a pre-trained network and inte grate them as semantic features in the proposed framework This hybrid approach achieves state-of-the-art scene recognition accuracy even without the contextual classiﬁer R EFERENCES 1 A  O li v a and A  T or r a lba M odeling t he s h ape o f t he s cene A holis tic representation of the spatial envelope Int J Comput Vis  vol 42 no 3 pp 145–175 2001 2 J  W u a nd J  M  Rehg Centr is t A v is ual d es cr iptor f or s cene categorization IEEE Trans Pattern Anal Mach Intell  vol 33 no 8 pp 1489–1501 Aug 2011 3 J  V ogel a nd B S c hiele S em antic m odeling o f n atur al s cenes f o r content-based image retrieval Int J Comput Vis  vol 72 no 2 pp 133–157 Apr 2007  L  L i H Su E  P  X ing and L  F ei-Fei  Object bank A h ighlevel image representation for scene classiﬁcation  semantic feature sparsiﬁcation in Proc NIPS  2010 pp 1378–1386 5 L  J  L i and L  F eiF ei  W h at w her e and w ho Clas s i f y ing e v e nts b y scene and object recognition in Proc ICCV  2007 pp 1–8 6 C  W ang D  Blei a nd L  F e iF e i S im ultaneous im age c las s i  cation and annotation in Proc CVPR  2009 pp 1903–1910  Z  N iu G  H ua X  G ao a nd Q T i an  Conte x t a w a re topic m odel f or scene recognition in Proc CVPR  2012 pp 2743–2750  A  Q uattoni and A  T orralba Recognizing indoor s cenes   in Proc CVPR  2009 pp 413–420 9 C  D oer s ch A  G upta and A  A  E f r o s  M idl e v el vis u al elem ent discovery as discriminative mode seeking in Proc NIPS  2013 pp 494–502  M J uneja A  V edaldi C  V  J a w ahar  a nd A Z i s s e rm an  Blocks that shout Distinctive parts for scene classiﬁcation in Proc CVPR  2013 pp 923–930  R K w itt N  V a s c oncelos  a nd N  Ras i w a s i a S cene r ecognition o n t he semantic manifold in Proc ECCV  2012 pp 359–372  N Ras i w a s i a P  J  Moreno and N  V as concelos   Bridging the g ap Query by semantic example IEEE Trans Multimedia  vol 9 no 5 pp 923–938 Aug 2007  N Ras i w a s i a a nd N V a s c oncelos   Holis tic conte x t m odels for v is ual recognition IEEE Trans Pattern Anal Mach Intell  vol 34 no 5 pp 902–917 May 2012  X  S ong S  J i ang and L  H erranz  Joint multi-feature spatial context for scene recognition in the semantic manifold in Proc CVPR  Jun 2015 pp 1312–1320  M  D i xit S  Chen D  G ao N  R as iw as ia a nd N  V a s c oncelos   S cene classiﬁcation with semantic Fisher vectors in Proc CVPR  2015 pp 2974–2983  J  Bes a g On t he s t atis tical analys is of dirty p ictures   J Roy Statist Soc Ser B  vol 48 no 3 pp 259–302 1986 17 O R u ssa k o v sk y et al  ImageNet large scale visual recognition challenge Int J Comput Vis  vol 115 no 3 pp 1–42 2015 Available http://dx.doi.org/10.1007/s11263-015-0816-y  B Z hou A L a pedriza J  Xiao A  T orralba and A  O li v a   L earning deep features for scene recognition using places database in Proc NIPS  2014 pp 487–495  X Song S J i ang L  Herra nz Y Kong and K Zheng Category co-occurrence modeling for large scale scene recognition Pattern Recognit  vol 59 pp 98–111 Nov 2016 A v a ilable http://www.sciencedirect.com/science/article/pii/S0031320316000406  S L azebnik C Schm id a nd J  Pon ce Beyond bags of features Spatial pyramid matching for recognizing natural scene categories in Proc CVPR  2006 pp 2169–2178  L  Bo X  R en a nd D F ox K ernel d es criptors for v is ual r ecognition  in Proc NIPS  2010 pp 244–252  L  Z h ang X Z h en a nd L  Shao  L earning object-to-clas s k ernels for scene classiﬁcation IEEE Trans Image Process  vol 23 no 8 pp 3241–3253 Aug 2014  A Ber g am o a nd L  T o rres a ni  Cl assemes and other classiﬁer-based features for efﬁcient object categorization IEEE Trans Pattern Anal Mach Intell  vol 36 no 10 pp 1988–2001 Oct 2014  L  Fei-Fei a nd P  Perona  A B ayes ian hierarchical model for learning natural scene categories in Proc CVPR  2005 pp 524–531  N Ras i w a s i a a nd N V a s c oncelos  Latent Dirichlet allocation models for image classiﬁcation IEEE Trans Pattern Anal Mach Intell  vol 35 no 11 pp 2665–2679 Nov 2013  X W a ng and E  G rim s on Spatial l atent Dirichlet allocation in Proc NIPS  2007 pp 1577–1584  L  J  L i H Su Y  L im  a nd L  Fe i-Fei Object bank An object-level image representation for high-level visual recognition Int J Comput Vis  vol 107 no 1 pp 20–39 2014  X  Bai C Y a o and W  L iu  S t r o k e lets  A lear ned m ultis cale m idl e v el representation for scene text recognition IEEE Trans Image Process  vol 25 no 6 pp 2789–2802 Jun 2016  X  W a ng B W a ng X  Bai W  L i u and Z  T u M axm ar gin m ultipleinstance dictionary learning J.Mach.Learn.Res  vol 28 no 3 pp 846–854 2013  G S X ie X  Y  Z h ang S Y a n and C  L  L i u Hybrid CNN a nd dictionary-based models for scene recognition and domain adaptation IEEE Trans Circuits Syst Video Technol  to be published O A v a ilable http://ieee xplore i e e e  o r g d ocu m ent 7362 156  doi 10.1109/TCSVT.2015.2511543  N Ras i w a s i a a nd N V a s c oncelos   Holis tic conte x t m odeling u s i ng semantic co-occurrences in Proc CVPR  2009 pp 1889–1895  A Krizhe vs k y  I  S uts k e v er  a nd G E Hinton ImageNet classiﬁcation with deep convolutional neural networks in Proc NIPS  2012 pp 1106–1114  J  Deng A Ber g  a nd L  Fei-Fei L ar ge graph c ons truction f or s calable semi-supervised learning in Proc ICML  2011  J  Donahue et al  DeCAF A deep convolutional activation feature for generic visual recognition in Proc ICML  2014 pp 647–655  T  Dura nd N T home  a n d M  C ord  W E L DON W e a k l y supe rvi s e d learning of deep convolutional neural networks in Proc CVPR  Jun 2016 pp 4743–4752  M Oquab L  Bottou I L a pte v  a nd J Sivic Is object localization for free?—Weakly-supervised learning with convolutional neural networks in Proc IEEE Conf Comput Vis Pattern Recognit CVPR  Jun 2015 pp 685–694  X L i et al  Deepsaliency Multi-task deep neural network model for salient object detection IEEE Trans Image Process  vol 25 no 8 pp 3919–3930 Aug 2016  H  Bilen a nd A  V e daldi W eakly s uper v is ed deep detection n etw o r k s   in Proc IEEE Conf Comput Vis Pattern Recognit CVPR  Jun 2016 pp 2846–2854  Y  G ong L  W a ng R G uo and S  L azebnik Multi-s cale o rderles s pooling of deep convolutional activation features in Proc ECCV  2014 pp 392–407  R W u  B  W ang W  W a ng and Y  Y u H ar v e s ting d is cr im inati v e m eta objects with deep CNN features for scene classiﬁcation in Proc ICCV  2015 pp 1287–1295  Q W a ng P  L i  W  Z uo and L  Z hang RAID-G Rob u s t es tim ation o f approximate inﬁnite dimensional Gaussian with application to material recognition in Proc CVPR  Jun 2016 pp 4433–4441  F  Perronnin J  Sánchez and T  M en sink Improving the Fisher kernel for large-scale image classiﬁcation in Proc ECCV  2010 pp 143–156  D G L o we  Dis tincti v e i m a ge feat ures from scale-invariant keypoints Int J Comput Vis  vol 60 no 2 pp 91–110 2004  D  Z h ang X  Chen a nd W  S  L ee T e x t c las s i  cation w ith k e r n els o n the multinomial manifold in Proc RDIR  2005 pp 266–273  J  X i ao J  H ays  K  A  E h inger  A  O l i v a and A  T or r a lba S U N database Large-scale scene recognition from abbey to zoo in Proc CVPR  2010 pp 3485–3492  B Z hou A Khos la A  L apedriza A T o rralba and A  O li v a   2016 Places An image database for deep scene understanding On Available https://arxiv.org/abs/1610.02055  L  T o rres a ni M  S zum m e r  and A  F itzgibbon E f  cient object cate gory recognition using classemes in Proc ECCV  2010 pp 776–789  M  P a nde y a nd S  L azebnik S cene r ecognition a nd w eakly s uper v is ed object localization with deformable part-based models in Proc ICCV  2011 pp 1307–1314  G  L  O l i v eir a  E  R  N as cim e nt o A W Vieira and M F M Campos Sparse spatial coding A novel approach to visual recognition IEEE Trans Image Process  vol 23 no 6 pp 2719–2731 Jun 2014 


SONG et al  MULTI-SCALE MULTI-FEATURE CONTEXT MODELING FOR SCENE RECOGNITION IN THE SEMANTIC MANIFOLD 2735  L  Xie Q T i an M  W ang and B  Z hang Spatial pooling o f h eterogeneous features for image classiﬁcation IEEE Trans Image Process  vol 23 no 5 pp 1994–2008 May 2014  Z  W a ng J  Feng S Y a n and H  X i L inear dis t ance coding for i m a ge classiﬁcation IEEE Trans Image Process  vol 22 no 2 pp 537–548 Feb 2013  J  Sanchez F  Perronnin T  Mens i nk and J Verbeek Image classiﬁcation with the Fisher vector Theory and practice Int J Comput Vis  vol 105 no 3 pp 222–245 2013  J  Xiao K  A  E hinger  J  Hays  A  T orralba and A  O li v a   SUN database Exploring a large collection of scene categories Int J Comput Vis  vol 119 no 1 pp 3–22 2014  L  Bo and C  S m i nchis e s c u E f  cient m atch k e r n el betw een s e ts of features for visual recognition in Proc NIPS  2009 pp 135–143  J  W a ng J  Y a ng K  Y u  F  L v  T  H u ang and Y  G ong L ocalityconstrained linear coding for image classiﬁcation in Proc CVPR  2010 pp 3360–3367  H Hu G  T  Z hou Z  Deng Z  L i ao a nd G Mori  L earning s t ructured inference neural networ ks with label relations in Proc CVPR  Jun 2016 pp 2960–2968  K  S i m o n y an and A  Z is s e r m an  V e r y deep con v olutional n etw o r k s f or large-scale image recognition in Proc ICLR  2015 A v a ilable https://arxiv.org/abs/1409.1556  S  Y a ng and D  R am anan  Multi-s cale r ecognition w ith D A G CN N s   in Proc ICCV  2015 pp 1215–1223  M D Dixit a nd N V a s c oncelos   Object based scene representations using Fisher scores of local subspace projections in Advances In Neural Information Processing Systems  vol 29 D D Lee M Sugiyama U V Luxburg I Guyon and R Garnett Eds Red Hook NY USA Curran Associates Inc 2016 pp 2811–2819 Xinhang Song received the B.S degree from the School of Computer and Information Technology Beijing Jiaotong University Beijing China in 2011 He is currently pursuing the Ph.D degree in computer science with the Key Laboratory of Intelligent Information Processing Institute of Computing Technology Chinese Academy of Sciences Beijing His current research interests include image processing large-scale image retrieval image semantic understanding multimedia content analysis computer vision and pattern recognition Shuqiang Jiang SM’08 is currently a Professor with the Institute of Computing Technology Chinese Academy of Sciences and also a Professor with the University of CAS He is also with the Key Laboratory of Intelligent Information Processing CAS His current research interests include multimedia processing and semantic understanding pattern recognition and computer vision He has authored or co-authored over 100 papers on the related research topics He was supported by the New-Star program of Science and Technology of Beijing Metropolis in 2008 the NSFC Excellent Young Scientists Fund in 2013 and the Young top-notch talent of Ten Thousand Talent Program in 2014 He is a Senior Member of the CCF and a member of the ACM He received the Lu Jiaxi Young Talent Award from Chinese Academy of Sciences in 2012 and the CCF Award of Science and Technology in 2012 He was the General Chair of ICIMCS 2015 the Program Chair of ICI MCS2010 the Special Session Chair of PCM2008 and ICIMCS2012 the Area Chair of PCIVT2011 the Publicity Chair of PCM2011 the Web Chair of ISCAS2013 and the Proceedings Chair of MMSP2011 He has also a TPC member for about 20 well-known conferences including the ACM Multimedia  CVPR ICCV ICME ICIP and PCM He is an Associate Editor of the IEEE Multimedia Multimedia Tools and Applications He is also the Vice Chair of the IEEE CASS Beijing Chapter the Vice Chair of the ACM SIGMM China chapter Luis Herranz received the Ingeniero de Telecomunicación degree from the Universidad Politécnica de Madrid Madrid Spain in 2003 and the Ph.D degree in computer science and telecommunication from the Universidad Autónoma de Madrid in 2010 From 2003 to 2010 he was with the Escuela Politécnica Superior of the Universidad Autónoma de Madrid as a Researcher and a Teaching Assistant From 2010 to 2011 he was with Mitsubishi Electric Research And Development Center Europe U.K He is currently a Post-Doctoral Research Fellow with the Institute of Computing Technology Chinese Academy of Sciences Beijing China His current research interests include multimedia signal processing content summarization and adaptation multimedia indexing and retrieval and scene recognition 


2332-7790 \(c This article has been accepted for publication in a future issue of this\ journal, but has not been fully edited. Content may change prior to fin\al publication. Citation information: DOI 10.1109/TBDATA.2017.2680460, I\EEE Transactions on Big Data A 16 a b c particles nonthe quality aluated ely 224non-testable\224 approach are system be the to The uilding its more and MRs enough alidated R D W K quality data ork and data scienti\002c learning In topics poor prediction utes and detail timeliness metadata accuauditability  Gao Xie and T ao ha v e gi v en an o v ervie w of the issues of data where the y de\002ned big data quality assurance techniques Although for the health eb orthiy such history source and sources information Finding the duplicated information quality as for duplication Data 002ltering is an approach data Samza which is adopted and al an electronic proposed using learning training reduce the algorithm data poor data Due to the massi v e scale of big data automated choice learning grated easily data for domain task The process is to reduce the irrele v ant performance selection correlation predict CFS 
 


2332-7790 \(c This article has been accepted for publication in a future issue of this\ journal, but has not been fully edited. Content may change prior to fin\al publication. Citation information: DOI 10.1109/TBDATA.2017.2680460, I\EEE Transactions on Big Data A 17 for images In this practical based in images  Ho w the feature selection w ould impact the classi\002cation reported  More adv anced feature selection approaches such as the in can be introduced into the frame w ork e images samin images challenge to problem  Man y dif ferent approaches ha v e been proposed to address as results the are Ho we v er  none of these that most eloping MRs 12 Metamorphic testing w as 002rst Chen al  for testing non-testable systems bioinformatics sysaultrelations A recent has compilers  Metamorphic testing has been applied for testi ng a lar ge ASA and also successfully engines Baidu Ho we v er  the quality of reported are w information In this paper  metamorphic in results w are tests xity SUT  Combinatorial technique 53 used for testing softw are for are C N the learning were to classi\002cation the for confusion learning important it data our data techniques A T King and xperi#1262933 e Corporation research R S  V  Gudi v ada R Raeza-Y ates and V  Ragha v an 223Big data Promises and 224 Computer 2015  Y  Bengio 223Learning deep architectures for ai 224 ends Learning 2009  Apache 2016 Hadoop Online A v ailable http://hadoop.apache.or g  V  Gudi v ada D Rao and V  Ragha v an 223Renaissance in database 224 IEEE Computer 2016  J Zhang Y  Feng M S Moran J Lu L Y ang al of 224 ess 2013  R M and T  Poggio 223Models of object recognition 224 oscience 2000  K Jacobs  J Lu and X Hu 223De v elopment of a dif f raction imaging 224 Lett 2009  2016 Adda project Online A v ailable https://github com/addateam adda  T  Y  Chen S C Cheung and S Y iu 223Metamorphic testing a ne w CS98and 1998  J Ding D Zhang and X Hu 223 An application of metamorphic testing in metamorphic ICSE 2016  U Kane w ala and J M Bieman 223T esting scienti\002c softw are A system\224 gy 56 2014  S Se gura G Fraser  A Sanchez and A Ruiz-Cort 264 on 224 Engineering  2016  2016 Mongodb  Online A v ailable https://www mongodb com  2016 Mongochef Online A v ailable http://3t.io/mongochef  M Y urkin and A Hoekstra 2014 User manual for the discrete 1.3b4 A v ailable https team/adda/tree/master/doc  C Hsu C.-C Chang and C.-J Lin 223 A practical guide to support v ector 2003  Y  LeCun Y  Bengio and G Hinton 223Deep learning 224 e 521 2015  R Haralick 223On a te xture-conte xt feature e xtract ion algorithm for in Society ol 650\226 657 
 


2332-7790 \(c This article has been accepted for publication in a future issue of this\ journal, but has not been fully edited. Content may change prior to fin\al publication. Citation information: DOI 10.1109/TBDATA.2017.2680460, I\EEE Transactions on Big Data A 18  K Dong Y  Feng K Jacobs J Lu R Brock al 223Label-free 224 Biomed ess 2011  R M Haralick K Shanmug an and I H Dinstein 223T e xtural features 224 Cybern SMC-3 1973  S K Thati J Ding D Zhang and X Hu 223Feature selection and analin ion ance 2015  J Dixon and J Ding 223 An empirical study of parallel solution for glcm 2016  T  Kanungo D Mount N Netan yahu C Piatk o R Silv erman and im\224 hine ence 2012  M A Hall 223Correlation-based feat ure selection for machine learning 224 wzealand 1999  A Krizhe vsk y  I Sutsk e v er  and G E Hinton 223Imagenet classi\002cain al systems and 1097\2261105  E Gibne y  223Google ai algorithm masters ancient g ame of go 224 e   M Moran 223Correlating the morphological and light scattering prop 2013  R P an Y  Feng Y  Sa J Lu K Jacobs and X Hu 223 Analysis 224 ess  2014  X Y ang Y  Feng Y  Liu N Zhang L W ang al e fraction 224 ess 7 2014  M Zhang 223 A deep learning based classi\002cation of lar ge scale biomed2016  Y  Feng N Zhang K Jacobs W  Jiang L Y ang al 223Polarization w 224 A 2014  C.-C Chang and C.-J Lin 2016 Libsvm Online A v ailable csie.ntu.edu.tw 030 cjlin/libsvm  2016 Caf fe project Online A v ailable http://caf fe.berk ele yvision.or g  J Mayer and R  Guderlei 223 An empirical study on the selection of good in e C06 475\226484  U Kane w ala J M Bieman and A Ben-Hur  223Predicting metamorphic approach 224 and Reliability 2015  J Ding T  W u J Q Lu and X Hu 223Self-check ed metamorphic testing in on vement apore 2010  W  E W ong and A Mathur  223Reducing the cost of mutati on testing 224 e pp 1995  Y  Jia and M Harman 223 An anal ysis and surv e y of the de v elopment of 224  649\226678 2011  L Cai and Y  Zhu 223The challenges of data quality and data quality 224 ournal 1 2015  J Gao C Xi e and C T ao 223Big data v alidation and quality assurance in Service\(SOSE 433\226441  X Dong E Gabrilo vich K Murph y  V  Dang W  Horn C Lug aresi 224  938\226949 2015  X Y in J Ha n and P  S Y u 223T ruth disco v ery with multiple con\003icting 224 Data  2008  C H W u and Y  Song 223Rob ust and distrib uted web-scale near dup in IEEE Data 2606\226 2611  2016 Apache samza Online A v ailable http://samza.apache.or g  J A Saez B Kra wczyk and M W ozniak 223On the in\003uence of class 002ltering 224 ence 590\226609 2016  M Y ousef D S D M 250 223Feature for 224 bioinformatics 2016  F  Min Q Hu and W  Zhu 223Feature sel ection with test cost constraint 224 Reasoning 167\226 2014  H A L Thi H M Le and T  P  Dinh 223Feature selection in machine function 224 Learning 2015  H Liu F C K uo D T o we y  and T  Chen 223Ho w ef fecti v ely does problem?\224 on Engineering 2014  V  Le M  Afshari and Z Su 223Compiler v alidation via equi v alence in amming on Kingdom 216\226226  M Lindv all D Ganesan R rdal and R E W ie g and 223Metamorphic in 37th Engineering 129\226 138  Z Zhou S Xiang and T  Chen 223Metamorphic testing for softw are 224 e Engineering 2016  C Nie and H Leung 223 A surv e y of combinatorial testing 224 CM y 2011 CE O HERE Ding Computer has Computer in Nanjing 2004 r ed His the He by CM Hu  ada East  
 


2169-3536 \(c http://www.ieee.org/publications_standards/publications/rights/index.htm\l for more information This article has been accepted for publication in a future issue of this\ journal, but has not been fully edited. Content may change prior to fin\al publication. Citation information: DOI 10.1109/ACCESS.2017.2697839, IEEE Access   19     en-US  en-US  en-US  en-US 52 en-US  en-US  en-US  en-US en-US e en-US ti en-US en-US  en-US  en-US en-US  en-US 4 en-US en-US  en-US  en-US  en-US 53 en-US  en-US  en-US  en-US en-US  en-US  en-US DA en-US en-US  en-US  en-US  en-US  en-US 54 en-US  en-US  en-US  en-US en-US e en-US n en-US  en-US en-US  en-US v en-US en-US  en-US  en-US  en-US 55 en-US  en-US  en-US  en-US en-US k en-US en-US thm en-US en-US  en-US ron en-US  en-US 0 en-US en-US  en-US  en-US 5 en-US 6 en-US  en-US  en-US  en-US en-US  en-US  en-US  en-US en-US n en-US  en-US  en-US  en-US 57 en-US  en-US  en-US  en-US en-US ti en-US en-US T en-US  en-US n en-US en-US  en-US  en-US  en-US  en-US  en-US 58 en-US  en-US  en-US  en-US en-US  en-US Pre en-US en-US  en-US t en-US en-US  en-US  en-US en-US  en-US  en-US  en-US 3 en-US en-US 1 en-US  en-US  en-US  en-US 59 en-US  en-US  en-US t en-US  en-US  en-US n en-US en-US  en-US  en-US en-US  en-US OS en-US  en-US 2 en-US en-US  en-US  en-US  en-US 60 en-US  en-US  en-US  en-US en-US  en-US ti en-US  en-US t en-US en-US  en-US 4 en-US en-US  en-US  en-US  en-US 61 en-US  en-US  en-US  en-US en-US  en-US  en-US en-US ess en-US  en-US  en-US 0 en-US en-US  en-US  en-US  en-US 62 en-US  en-US  en-US  en-US en-US X en-US en-US ng en-US en-US s en-US  en-US en-US  en-US  en-US i    en-US x en-US en-US e en-US en-US i en-US en-US r en-US en-US is en-US en-US 2 en-US en-US Dec en-US en-US 6  en-US  en-US  en-US 63 en-US  en-US  en-US i en-US  en-US en-US  en-US  en-US en-US h en-US i   Av a i l a bl e   en-US e en-US en-US is en-US en-US ng en-US en-US a en-US en-US nd en-US en-US b en-US en-US r en-US en-US the en-US en-US net en-US en-US of en-US en-US 0 en-US en-US Dec en-US en-US 6  en-US  en-US  en-US 64 en-US  en-US  en-US BI en-US en-US  en-US en-US e en-US  en-US  en-US en-US er en-US  en-US i    en-US du en-US en-US es en-US en-US new en-US en-US ai en-US en-US nd en-US en-US net en-US en-US of en-US en-US s en-US en-US ves en-US en-US 6 en-US en-US 0 en-US en-US Dec en-US en-US 6  en-US  en-US  en-US 65 en-US  en-US  en-US  en-US en-US Su en-US  en-US  en-US en-US a en-US  en-US 9 en-US en-US  en-US  en-US  en-US  en-US 66 en-US  en-US  en-US  en-US  en-US en-US  en-US  en-US en-US s en-US  en-US  en-US  en-US  en-US 67 en-US  en-US  en-US  en-US en-US  en-US a en-US en-US ve en-US en-US a en-US  en-US 383 en-US en-US  en-US  en-US  en-US 68 en-US  en-US  en-US  en-US en-US  en-US  en-US en-US  en-US ess en-US  en-US 7 en-US en-US  en-US  en-US  en-US 69 en-US  en-US  en-US  en-US en-US  en-US vey en-US en-US  en-US ri en-US s en-US  en-US 77 en-US en-US  en-US  en-US  en-US 70 en-US  en-US  en-US  en-US en-US  en-US  en-US en-US  en-US  en-US  en-US 1 en-US en-US  en-US  en-US  en-US 71 en-US  en-US  en-US o en-US  en-US  en-US ne en-US en-US  en-US  en-US  en-US 5 en-US en-US  en-US  en-US  en-US 72 en-US  en-US  en-US  en-US en-US  en-US n en-US e en-US  en-US en-US  en-US n en-US  en-US 6 en-US en-US  en-US  en-US  en-US 73 en-US  en-US  en-US  en-US en-US  en-US  en-US hy en-US  en-US en-US  en-US n en-US  en-US 6 en-US en-US  en-US  en-US  en-US 74 en-US  en-US  en-US  en-US en-US  en-US t en-US en-US I en-US  en-US  en-US  en-US 5 en-US en-US  en-US  en-US  en-US 75 en-US  en-US  en-US  en-US en-US  en-US ty en-US en-US  en-US en-US  en-US f en-US en-US  en-US  en-US  en-US  en-US 76 en-US  en-US  en-US a en-US  en-US en-US ti en-US en-US  en-US  en-US en-US  en-US  en-US  en-US 96 en-US en-US  en-US  en-US  en-US 77 en-US  en-US  en-US  en-US en-US  en-US n en-US en-US 0 en-US 8 en-US en-US  en-US  en-US ess en-US  en-US 85 en-US en-US  en-US  en-US  en-US 78 en-US  en-US  en-US  en-US en-US  en-US n en-US en-US  en-US  en-US  en-US  en-US  en-US 79 en-US  en-US  en-US hen en-US  en-US  en-US en-US  en-US  en-US  en-US en-US  en-US  en-US  en-US 4 en-US en-US  en-US  en-US  en-US 80 en-US  en-US  en-US  en-US en-US ng en-US en-US  en-US  en-US  en-US en-US s en-US  en-US  en-US 6 en-US en-US  en-US  en-US  en-US 81 en-US  en-US  en-US N en-US  en-US  en-US en-US  en-US  en-US en-US 2011 en-US  en-US  en-US 1 en-US en-US  en-US  en-US  en-US 82 en-US  en-US  en-US  en-US  en-US en-US o en-US  en-US  en-US en-US 2011 en-US  en-US  en-US 1 en-US en-US  en-US  en-US  en-US 83 en-US  en-US  en-US  en-US en-US  en-US s en-US  en-US  en-US  en-US  en-US 9 en-US en-US  en-US  en-US  en-US 84 en-US  en-US  en-US  en-US en-US  en-US en-US  


2169-3536 \(c http://www.ieee.org/publications_standards/publications/rights/index.htm\l for more information This article has been accepted for publication in a future issue of this\ journal, but has not been fully edited. Content may change prior to fin\al publication. Citation information: DOI 10.1109/ACCESS.2017.2697839, IEEE Access  20      en-US  en-US en-US  en-US  en-US  en-US 4 en-US en-US  en-US  en-US  en-US 85 en-US  en-US  en-US F en-US  en-US en-US  en-US  en-US en-US  en-US 0 en-US  en-US 5 en-US en-US  en-US  en-US  en-US 86 en-US  en-US  en-US h en-US  en-US  en-US l en-US en-US  en-US en-US  en-US  en-US  en-US  en-US 1 en-US en-US  en-US  en-US  en-US 87 en-US  en-US  en-US  en-US en-US ti en-US en-US  en-US  en-US d en-US en-US  en-US  en-US  en-US 1 en-US en-US  en-US  en-US  en-US 88 en-US  en-US  en-US  en-US  en-US en-US  en-US  en-US en-US  en-US 6 en-US  en-US 263 en-US en-US  en-US  en-US  en-US 89 en-US  en-US  en-US  en-US en-US tem en-US en-US OTA en-US  en-US 6 en-US  en-US 6 en-US en-US  en-US  en-US  en-US  en-US 90 en-US  en-US  en-US  en-US en-US  en-US  en-US en-US  en-US m en-US  en-US 87 en-US en-US  en-US  en-US  en-US  en-US 91 en-US  en-US  en-US e en-US  en-US  en-US en-US  en-US  en-US en-US  en-US m en-US  en-US 87 en-US en-US  en-US  en-US  en-US  en-US 92 en-US  en-US  en-US  en-US en-US  en-US a en-US  en-US  en-US  en-US  en-US  en-US 1 en-US en-US  en-US  en-US  en-US 93 en-US  en-US  en-US  en-US en-US  en-US r en-US en-US  en-US  en-US en-US  en-US 195 en-US en-US  en-US  en-US  en-US 94 en-US  en-US  en-US Wei en-US en-US xi en-US ng en-US en-US eng en-US en-US  en-US en-US  en-US k en-US en-US to en-US en-US  en-US  en-US en-US ess en-US  en-US 1 en-US en-US  en-US  en-US  en-US 95 en-US  en-US  en-US  en-US en-US  en-US c en-US r en-US en-US  en-US  en-US en-US  en-US  en-US 1 en-US en-US  en-US  en-US  en-US 96 en-US  en-US  en-US  en-US en-US  en-US  en-US en-US r en-US  en-US  en-US 9 en-US en-US  en-US  en-US  en-US 97 en-US  en-US  en-US  en-US  en-US  en-US en-US e en-US en-US  en-US r en-US en-US  en-US  en-US en-US  en-US en-US  en-US  en-US  en-US  en-US m en-US en-US s en-US en-US 3 en-US  en-US 3 en-US en-US  en-US  en-US  en-US 98 en-US  en-US  en-US a en-US en-US  en-US en-US  en-US ter en-US en-US  en-US  en-US en-US l en-US  en-US  en-US  en-US  en-US 99 en-US  en-US  en-US a en-US  en-US en-US  en-US  en-US  en-US en-US  en-US BE en-US  en-US 1 en-US en-US  en-US  en-US  en-US 0 en-US  en-US  en-US  en-US e en-US  en-US  en-US  en-US  en-US 1 en-US  en-US  en-US e en-US en-US  en-US ter en-US en-US  en-US  en-US  en-US  en-US 2 en-US  en-US  en-US e en-US en-US  en-US ter en-US en-US the en-US  en-US  en-US  en-US  en-US 3 en-US  en-US  en-US  en-US en-US  en-US ter en-US en-US  en-US ti en-US en-US n en-US en-US  en-US n en-US  en-US 3 en-US en-US  en-US  en-US  en-US  en-US 4 en-US  en-US  en-US  en-US en-US  en-US  en-US  en-US en-US  en-US  en-US  en-US  en-US 5 en-US  en-US  en-US  en-US en-US  en-US th en-US  en-US  en-US ter en-US en-US  en-US  en-US en-US s en-US  en-US 7 en-US en-US  en-US  en-US  en-US 6 en-US  en-US  en-US en en-US en-US  en-US n en-US  en-US  en-US en-US 4 en-US  en-US 4 en-US en-US  en-US  en-US  en-US 7 en-US  en-US  en-US e en-US en-US  en-US  en-US  en-US en-US  en-US  en-US  en-US 4 en-US en-US  en-US  en-US  en-US 8 en-US  en-US  en-US  en-US en-US  en-US ter en-US en-US  en-US tem en-US en-US  en-US  en-US  en-US 1 en-US en-US  en-US  en-US  en-US 9 en-US  en-US  en-US  en-US  en-US en-US  en-US a en-US en-US  en-US en-US  en-US S en-US  en-US en-US  en-US  en-US  en-US  en-US  en-US 0 en-US  en-US  en-US  en-US  en-US  en-US en-US ter en-US en-US  en-US  en-US en-US  en-US  en-US  en-US 72 en-US en-US  en-US  en-US  en-US 1 en-US  en-US  en-US  en-US en-US  en-US en-US  en-US n en-US en-US a en-US  en-US 5 en-US en-US  en-US  en-US  en-US 2 en-US  en-US  en-US W en-US  en-US en-US  en-US  en-US nty en-US en-US  en-US ON en-US  en-US 1 en-US en-US  en-US  en-US  en-US 3 en-US  en-US  en-US  en-US en-US  en-US Se en-US  en-US en-US  en-US l en-US  en-US 334 en-US en-US  en-US  en-US  en-US 4 en-US  en-US  en-US  en-US en-US  en-US  en-US  en-US en-US Int en-US en-US y en-US  en-US  en-US  en-US 249 en-US en-US  en-US  en-US  en-US 5 en-US  en-US  en-US  en-US en-US  en-US  en-US  en-US en-US  en-US en-US  en-US d en-US en-US  en-US 1 en-US 1 en-US 52 en-US en-US  en-US  en-US  en-US 6 en-US  en-US  en-US  en-US en-US  en-US  en-US te en-US en-US  en-US  en-US  en-US 7 en-US  en-US  en-US  en-US en-US  en-US  en-US  en-US  en-US en-US r en-US  en-US 34 en-US en-US  en-US  


2169-3536 \(c http://www.ieee.org/publications_standards/publications/rights/index.htm\l for more information This article has been accepted for publication in a future issue of this\ journal, but has not been fully edited. Content may change prior to fin\al publication. Citation information: DOI 10.1109/ACCESS.2017.2697839, IEEE Access   21     en-US  en-US 8 en-US  en-US  en-US  en-US en-US  en-US  en-US en-US  en-US  en-US  en-US  en-US 9 en-US  en-US  en-US  en-US en-US i en-US  en-US  en-US en-US  en-US  en-US  en-US  en-US 0 en-US  en-US  en-US  en-US en-US  en-US  en-US  en-US en-US s en-US  en-US  en-US  en-US 2 en-US en-US  en-US  en-US  en-US 1 en-US  en-US  en-US  en-US en-US  en-US  en-US en-US  en-US  en-US 1 en-US 77 en-US en-US  en-US  en-US  en-US 2 en-US  en-US  en-US  en-US en-US d en-US en-US a en-US en-US  en-US  en-US  en-US en-US  en-US  en-US  en-US 2 en-US en-US  en-US  en-US  en-US 3 en-US  en-US  en-US o en-US  en-US en-US  en-US  en-US en-US s en-US  en-US 0 en-US en-US  en-US  en-US  en-US  en-US 4 en-US  en-US  en-US  en-US en-US  en-US  en-US en-US s en-US  en-US  en-US 0 en-US en-US  en-US  en-US  en-US 5 en-US  en-US  en-US  en-US  en-US en-US  en-US  en-US  en-US en-US  en-US  en-US  en-US  en-US  en-US 3 en-US en-US  en-US  en-US  en-US 6 en-US  en-US  en-US  en-US en-US  en-US en-US a en-US  en-US 321 en-US en-US  en-US  en-US  en-US 7 en-US  en-US  en-US K en-US en-US t en-US en-US  en-US en-US  en-US  en-US s en-US en-US dy en-US en-US matics en-US  en-US  en-US  en-US  en-US 8 en-US  en-US  en-US  en-US  en-US res en-US  en-US  en-US  en-US 9 en-US  en-US  en-US R en-US n en-US en-US  en-US en-US  en-US  en-US en-US  en-US  en-US 5 en-US en-US  en-US  en-US  en-US  en-US 0 en-US  en-US  en-US n en-US en-US  en-US en-US n en-US  en-US  en-US  en-US en-US  en-US  en-US 5 en-US en-US  en-US  en-US  en-US  en-US 1 en-US  en-US  en-US  en-US en-US  en-US  en-US  en-US en-US  en-US en-US  en-US  en-US  en-US man en-US en-US  en-US  en-US 3 en-US en-US  en-US  en-US  en-US 2 en-US  en-US  en-US  en-US en-US  en-US en-US  en-US d en-US en-US s en-US 2 en-US  en-US 46 en-US en-US  en-US  en-US  en-US 3 en-US  en-US  en-US  en-US en-US ti en-US en-US ti en-US en-US  en-US n en-US en-US n en-US  en-US 1 en-US en-US  en-US  en-US  en-US 4 en-US  en-US  en-US  en-US en-US  en-US  en-US n en-US en-US n en-US  en-US  en-US  en-US  en-US 5 en-US  en-US  en-US  en-US en-US  en-US en-US 2 en-US  en-US ron en-US  en-US 351 en-US en-US  en-US  en-US  en-US 6 en-US  en-US  en-US  en-US en-US Semi en-US en-US  en-US  en-US en-US  en-US S en-US s en-US en-US  en-US  en-US  en-US 2 en-US en-US  en-US  en-US  en-US  en-US 7 en-US  en-US  en-US  en-US en-US  en-US  en-US en-US  en-US  en-US  en-US 5 en-US en-US  en-US  en-US  en-US 8 en-US  en-US  en-US  en-US en-US ex en-US  en-US  en-US en-US  en-US  en-US  en-US  en-US  en-US 9 en-US  en-US  en-US nt en-US en-US  en-US en-US  en-US  en-US a en-US  en-US en-US  en-US r en-US  en-US 7 en-US en-US  en-US  en-US  en-US 0 en-US  en-US  en-US  en-US en-US  en-US n en-US en-US EEE en-US  en-US 6 en-US en-US  en-US  en-US  en-US 1 en-US  en-US  en-US  en-US  en-US en-US  en-US  en-US  en-US en-US s en-US  en-US 7 en-US en-US  en-US  en-US  en-US 2 en-US  en-US  en-US  en-US en-US ti en-US en-US  en-US n en-US  en-US en-US  en-US  en-US  en-US  en-US  en-US 3 en-US  en-US  en-US  en-US en-US ene en-US en-US  en-US  en-US en-US  en-US  en-US  en-US 7 en-US en-US  en-US  en-US 4 en-US  en-US  en-US en-US  en-US ti en-US en-US  en-US en-US  en-US  en-US 8 en-US en-US  en-US  en-US  en-US 5 en-US  en-US  en-US  en-US en-US i en-US  en-US  en-US en-US  en-US dy en-US en-US  en-US n en-US y en-US en-US  en-US  en-US  en-US 6 en-US  en-US  en-US  en-US en-US k en-US en-US to en-US en-US  en-US  en-US en-US IE en-US  en-US  en-US 0 en-US en-US  en-US  en-US  en-US  en-US 7 en-US  en-US  en-US  en-US en-US  en-US ter en-US en-US n en-US en-US  en-US l en-US en-US  en-US en-US  en-US  en-US  en-US  en-US  en-US 9 en-US en-US  en-US  en-US  en-US 8 en-US  en-US  en-US  en-US  en-US  en-US n en-US en-US  en-US en-US  en-US  en-US  en-US 7 en-US en-US  en-US  en-US  en-US 9 en-US  en-US  en-US  en-US en-US k en-US en-US to en-US en-US  en-US the en-US  en-US en-US  en-US  en-US 4 en-US en-US  en-US  en-US  en-US  en-US 0 en-US  en-US  en-US  en-US en-US  en-US n en-US en-US  


2169-3536 \(c http://www.ieee.org/publications_standards/publications/rights/index.htm\l for more information This article has been accepted for publication in a future issue of this\ journal, but has not been fully edited. Content may change prior to fin\al publication. Citation information: DOI 10.1109/ACCESS.2017.2697839, IEEE Access  22      en-US Inte en-US  en-US  en-US 132 en-US en-US  en-US  en-US  en-US 1 en-US  en-US  en-US  en-US en-US k en-US en-US to en-US en-US n en-US en-US  en-US I en-US en-US  en-US  en-US  en-US 69 en-US en-US 8 en-US  en-US  en-US  en-US 2 en-US  en-US  en-US r en-US en-US  en-US en-US k en-US en-US to en-US en-US  en-US  en-US en-US r en-US  en-US 1 en-US en-US  en-US  en-US  en-US 3 en-US  en-US  en-US  en-US en-US t en-US en-US n en-US en-US n en-US  en-US  en-US 1 en-US en-US  en-US  en-US  en-US 4 en-US  en-US  en-US  en-US en-US  en-US  en-US i   en-US m en-US  en-US  en-US 5 en-US  en-US  en-US  en-US  en-US en-US k en-US en-US to en-US en-US  en-US tr en-US  en-US n en-US en-US  en-US  en-US 7 en-US en-US  en-US  en-US  en-US 6 en-US  en-US  en-US  en-US en-US  en-US en-US a en-US i   en-US d en-US en-US a en-US en-US c en-US en-US es en-US 2 en-US en-US n en-US en-US 7  en-US  en-US  en-US 7 en-US  en-US  en-US  en-US en-US  en-US  en-US en-US  en-US dy en-US en-US  en-US n en-US y en-US en-US  en-US  en-US  en-US 8 en-US  en-US  en-US  en-US  en-US en-US  en-US vey en-US en-US  en-US  en-US 13 en-US en-US  en-US  en-US  en-US 9 en-US  en-US  en-US  en-US en-US  en-US  en-US en-US  en-US  en-US  en-US  en-US  en-US 0 en-US  en-US  en-US  en-US  en-US  en-US en-US  en-US  en-US n en-US en-US  en-US n en-US  en-US  en-US  en-US 1 en-US  en-US  en-US  en-US en-US  en-US  en-US en-US 2010 en-US  en-US  en-US 7 en-US en-US  en-US  en-US  en-US 2 en-US  en-US  en-US  en-US en-US  en-US o en-US n en-US en-US  en-US  en-US  en-US  en-US  en-US 3 en-US  en-US  en-US  en-US en-US  en-US  en-US en-US  en-US  en-US  en-US  en-US  en-US 4 en-US  en-US  en-US B en-US  en-US en-US A en-US ti en-US en-US  en-US  en-US en-US  en-US  en-US  en-US 6 en-US en-US  en-US  en-US  en-US 5 en-US  en-US  en-US e en-US en-US s en-US  en-US  en-US  en-US en-US  en-US n en-US  en-US 1 en-US en-US  en-US  en-US  en-US 6 en-US  en-US  en-US  en-US en-US  en-US f en-US en-US  en-US  en-US  en-US en-US  en-US  en-US  en-US  en-US  en-US 7 en-US  en-US  en-US  en-US en-US  en-US  en-US e en-US en-US  en-US  en-US  en-US 1 en-US 68 en-US  en-US  en-US  en-US en-US  en-US  en-US en-US  en-US  en-US  en-US  en-US 9 en-US  en-US  en-US  en-US en-US f en-US en-US  en-US ew en-US en-US e en-US  en-US  en-US  en-US 0 en-US  en-US  en-US  en-US en-US i en-US  en-US  en-US en-US  en-US n en-US  en-US  en-US  en-US 1 en-US  en-US  en-US  en-US en-US  en-US h en-US en-US er en-US i   Av a i l a bl e   en-US p en-US en-US ten en-US en-US hn en-US y en-US en-US ends en-US en-US l en-US en-US the en-US en-US l en-US en-US  en-US  en-US  en-US 2 en-US  en-US  en-US  en-US en-US  en-US en-US re en-US  en-US 6 en-US en-US  en-US  en-US  en-US 3 en-US  en-US  en-US  en-US en-US y en-US en-US  en-US e en-US en-US  en-US  en-US  en-US en-US  en-US  en-US 1 en-US en-US  en-US  en-US  en-US 4 en-US  en-US  en-US  en-US en-US  en-US en-US re en-US  en-US 6 en-US en-US  en-US  en-US  en-US 5 en-US  en-US  en-US  en-US  en-US en-US  en-US  en-US  en-US  en-US 6 en-US  en-US  en-US  en-US en-US  en-US en-US  en-US  en-US  en-US 1 en-US en-US  en-US  en-US  en-US 7 en-US  en-US  en-US  en-US en-US  en-US en-US t en-US  en-US earn en-US  en-US 9 en-US en-US  en-US  en-US  en-US 8 en-US  en-US  en-US  en-US en-US  en-US  en-US en-US  en-US  en-US  en-US 34 en-US en-US  en-US  en-US  en-US 9 en-US  en-US  en-US Lef en-US  en-US en-US  en-US  en-US ti en-US en-US  en-US en-US V en-US  en-US  en-US  en-US  en-US 0 en-US  en-US  en-US  en-US en-US  en-US  en-US en-US Pro en-US  en-US  en-US  en-US 34 en-US en-US  en-US  en-US  en-US 1 en-US  en-US  en-US  en-US en-US ng en-US en-US ti en-US en-US  en-US  en-US  en-US en-US  en-US 1 en-US en-US  en-US  en-US  en-US 2 en-US  en-US  en-US O en-US en-US M en-US  en-US en-US l en-US en-US  en-US  en-US en-US  en-US  en-US 1 en-US en-US  en-US  en-US  en-US 3 en-US  en-US  en-US  en-US en-US N en-US s en-US  en-US en-US  en-US  en-US 9 en-US en-US  en-US  en-US  en-US 4 en-US  en-US  en-US  en-US en-US  en-US  en-US to en-US en-US  en-US en-US n en-US  en-US  en-US  en-US 5 en-US  en-US  en-US D en-US  en-US  en-US en-US nt en-US en-US  en-US en-US  en-US en-US  en-US  en-US  en-US  en-US 6 en-US en-US  en-US 2 en-US en-US  en-US  en-US  en-US 6 en-US  en-US  en-US  en-US en-US edes en-US  en-US  en-US en-US  en-US  en-US  en-US  en-US  en-US 7 en-US  en-US  en-US  en-US en-US t en-US  en-US en-US  en-US  


2169-3536 \(c http://www.ieee.org/publications_standards/publications/rights/index.htm\l for more information This article has been accepted for publication in a future issue of this\ journal, but has not been fully edited. Content may change prior to fin\al publication. Citation information: DOI 10.1109/ACCESS.2017.2697839, IEEE Access   23     en-US  en-US 22 en-US en-US  en-US  en-US  en-US 8 en-US  en-US  en-US  en-US en-US t en-US en-US  en-US vey en-US en-US  en-US  en-US ne en-US en-US  en-US  en-US  en-US 9 en-US  en-US  en-US  en-US en-US  en-US  en-US tbed en-US en-US  en-US en-US  en-US  en-US  en-US 5 en-US en-US  en-US  en-US  en-US  en-US 0 en-US  en-US  en-US  en-US G en-US  en-US en-US o en-US en-US  en-US en-US  en-US  en-US  en-US 0 en-US en-US  en-US  en-US  en-US 1 en-US  en-US  en-US e en-US en-US ent en-US en-US  en-US  en-US en-US  en-US  en-US  en-US  en-US 5 en-US en-US  en-US  en-US  en-US 2 en-US  en-US  en-US a en-US en-US z en-US en-US  en-US dez en-US en-US z en-US en-US  en-US en-US  en-US a en-US  en-US  en-US en-US  en-US 26 en-US en-US  en-US  en-US  en-US 3 en-US  en-US  en-US a en-US en-US a en-US en-US o en-US en-US  en-US a en-US en-US  en-US en-US o en-US en-US F en-US en-US  en-US  en-US en-US  en-US  en-US en-US  en-US  en-US  en-US  en-US 8 en-US en-US  en-US  en-US  en-US 4 en-US  en-US  en-US  en-US en-US ti en-US en-US  en-US  en-US  en-US en-US  en-US en-US  en-US 2015 en-US b en-US 5 en-US  en-US 9 en-US en-US  en-US  en-US  en-US  en-US 5 en-US  en-US  en-US o en-US en-US  en-US en-US  en-US  en-US en-US n en-US  en-US  en-US 45 en-US en-US  en-US  en-US  en-US 6 en-US  en-US  en-US  en-US en-US  en-US k en-US  en-US  en-US en-US  en-US  en-US  en-US 0 en-US en-US  en-US  en-US  en-US 7 en-US  en-US  en-US  en-US en-US  en-US  en-US en-US  en-US  en-US r en-US  en-US 86 en-US en-US  en-US  en-US  en-US 8 en-US  en-US  en-US  en-US en-US  en-US y en-US en-US by en-US en-US  en-US en-US  en-US s en-US  en-US 1 en-US en-US  en-US  en-US  en-US 9 en-US  en-US  en-US  en-US  en-US dez en-US en-US  en-US en-US n en-US en-US  en-US en-US  en-US n en-US y en-US en-US  en-US  en-US  en-US 0 en-US  en-US  en-US  en-US en-US  en-US tem en-US en-US  en-US ti en-US en-US ve en-US en-US  en-US  en-US  en-US  en-US  en-US 1 en-US  en-US  en-US  en-US en-US  en-US ty en-US en-US  en-US en-US  en-US  en-US  en-US 5 en-US  en-US 2 en-US en-US  en-US  en-US  en-US 2 en-US  en-US  en-US en en-US en-US  en-US  en-US  en-US en-US ess en-US  en-US 831 en-US en-US  en-US  en-US  en-US 3 en-US  en-US  en-US  en-US  en-US en-US ti en-US en-US  en-US ne en-US en-US  en-US e en-US en-US  en-US  en-US 26 en-US en-US  en-US  en-US  en-US  en-US 4 en-US  en-US  en-US  en-US en-US  en-US ve en-US  en-US  en-US en-US  en-US rk en-US  en-US 7 en-US en-US  en-US  en-US  en-US 5 en-US  en-US  en-US  en-US  en-US en-US Sy en-US  en-US  en-US en-US  en-US  en-US  en-US es en-US  en-US 1 en-US en-US  en-US  en-US  en-US 6 en-US  en-US  en-US  en-US  en-US  en-US r en-US rks en-US  en-US  en-US  en-US  en-US 7 en-US  en-US  en-US  en-US en-US  en-US  en-US en-US n en-US  en-US  en-US 9 en-US 0 en-US  en-US 411 en-US en-US  en-US  en-US  en-US 8 en-US  en-US  en-US  en-US en-US  en-US tems en-US en-US  en-US  en-US  en-US  en-US n en-US  en-US en-US  en-US v en-US es en-US  en-US  en-US 3 en-US en-US  en-US  en-US  en-US 9 en-US  en-US  en-US en en-US en-US  en-US  en-US en-US  en-US en-US  en-US  en-US  en-US 0 en-US  en-US  en-US m en-US en-US  en-US  en-US th en-US en-US  en-US en-US  en-US  en-US  en-US 7 en-US en-US  en-US  en-US  en-US 1 en-US  en-US  en-US  en-US en-US  en-US  en-US en-US  en-US  en-US  en-US 4 en-US en-US  en-US  en-US  en-US 2 en-US  en-US  en-US  en-US  en-US en-US  en-US  en-US en-US  en-US  en-US  en-US  en-US  en-US 3 en-US  en-US  en-US  en-US en-US ng en-US  en-US  en-US  en-US  en-US en-US  en-US  en-US 1 en-US en-US  en-US  en-US  en-US  en-US 4 en-US  en-US  en-US  en-US  en-US rk en-US  en-US  en-US  en-US  en-US 5 en-US  en-US  en-US  en-US en-US  en-US  en-US en-US  en-US  en-US  en-US 8 en-US en-US  en-US  en-US  en-US 6 en-US  en-US  en-US  en-US en-US  en-US  en-US en-US  en-US  en-US  en-US 1 en-US en-US  en-US  en-US  en-US 7 en-US  en-US  en-US  en-US en-US  en-US t en-US dy en-US en-US n en-US s en-US  en-US  en-US 9 en-US en-US  en-US  en-US  en-US 8 en-US  en-US  en-US  en-US en-US  


2169-3536 \(c http://www.ieee.org/publications_standards/publications/rights/index.htm\l for more information This article has been accepted for publication in a future issue of this\ journal, but has not been fully edited. Content may change prior to fin\al publication. Citation information: DOI 10.1109/ACCESS.2017.2697839, IEEE Access  24      en-US  en-US i en-US  en-US en-US  en-US  en-US 9 en-US  en-US 2 en-US en-US  en-US  en-US  en-US 9 en-US  en-US  en-US  en-US en-US  en-US n en-US en-US n en-US  en-US t en-US 7 en-US  en-US  en-US 5 en-US en-US  en-US  en-US  en-US 0 en-US  en-US  en-US  en-US  en-US en-US  en-US  en-US n en-US en-US E en-US ess en-US  en-US 858 en-US en-US  en-US  en-US  en-US 1 en-US  en-US  en-US  en-US en-US  en-US  en-US en-US ess en-US  en-US 1 en-US en-US  en-US  en-US  en-US  en-US 2 en-US  en-US  en-US  en-US  en-US en-US  en-US  en-US  en-US en-US  en-US  en-US 1 en-US en-US  en-US  en-US  en-US 3 en-US  en-US  en-US  en-US  en-US  en-US o en-US en-US  en-US en-US in en-US  en-US  en-US  en-US l en-US en-US  en-US g en-US  en-US 0 en-US en-US  en-US  en-US  en-US 4 en-US  en-US  en-US Ben en-US  en-US  en-US en-US  en-US  en-US en-US  en-US  en-US 7 en-US en-US  en-US  en-US  en-US 5 en-US  en-US  en-US  en-US en-US f en-US  en-US  en-US dy en-US en-US  en-US 11 en-US en-US  en-US  en-US  en-US 6 en-US  en-US  en-US  en-US  en-US en-US T en-US en-US  en-US o en-US  en-US en-US  en-US  en-US 1 en-US en-US  en-US  en-US  en-US 7 en-US  en-US  en-US z en-US en-US  en-US en-US ti en-US en-US  en-US  en-US  en-US en-US sort en-US  en-US  en-US 5 en-US  en-US  en-US  en-US 8 en-US  en-US  en-US z en-US en-US  en-US en-US  en-US f en-US en-US the en-US en-US  en-US  en-US en-US  en-US  en-US  en-US  en-US 121 en-US en-US  en-US  en-US  


