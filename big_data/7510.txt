Analysis of NDN Repository Architecture and its Improvement for I/O Intensive Applications Inchan Hwang 1 Dabin Kim 2 Young-Bae Ko 2 1 Graduate School of Software Engineering 2 Graduate School of Computer Engineering Ajou University, Suwon, South Korea inchan@uns.ajou.ac.kr, dabin912@uns.ajou.ac.kr, youngko@ajou.ac.kr Abstract  Named data networking \(NDN\ has been researched to be a substitute of the conventional IPv4 Internet Its advantages are strong security, in-network caching, and mobility support. In terms of network architecture, it emphasizes contents rather than its locati ons to access data after the consumerís interest is routed at each node. In contrast to many NDN researches on routing, node architecture, caching, security and other research domains, there has been a little effort on the design and architecture development of NDN based repository and its file system to save contents efficiently. So far, there are two NDN repositories, such as NDNFS and Repo-ng. They are designed to store files in NDN way so that data is sent and received over NDN network more efficiently. However, its biggest problem is the overhead when they run at I/O intensive environment, such as serving science-modelling data, which is large, sometimes over a few gigabytes. In the performance evaluation of this paper, the extent of its severity is depicted Moreover, the investigations on those architectures will help one notice the source of the overhead. According to our findings, an enhanced metadata scheme and its management strategy will be put forward to alleviate this problem. Furthermore, some of the implementation considerations for the NDN based distributed file system for I/O intensive environment will be discussed Keywords  Named Data Networking; NDN; repository; file system future Internet I I NTRODUCTION  is a fu t u re In ter n et ar chitect u r e It m o v e d f r o m th e  traditional networking concept of the end-to-end connection to the data packet transmission from one hop to another hop This new idea of networking promises better security, delaytolerant style of communications, hop-by-hop routing, and better support of mobility. Most of all, it suggests a solution to traffic redundancy of the conventional IPv4 Internet because its traffic has dramatically increased for past years si nce the dawn of IoT, and big data management. Its growth is unprecedented, all those data from various kinds of machines and mobile devices being connected to the Internet, has already reached its bandwidth limit. However, its integrated caches into the network architectu re are expected to cut back on traffic congestion around the data producer and the network itself. Since its emphasis is on efficient content distribution NDN researchers have devised several schemes, such as   and Rep o n g 7 to optimize file transfer between nodes. Their structures are the primitive forms of serving contents to make them ready for NDN data transmission as soon as any Interest playin g a role of a data seeker and retriever arrives Because of the new networking components of NDN which has been unconsidered in the IP based network, it triggered several potential optimizations of NDN architecture in the distributed file system. NDSS [5 tegrates n e t w or k and lo cal storage data descriptions with na med data. It forwards Interest based on not only Face list but also storage information so that it reduces the overhead in data format transition and suggests a new method for data operations over the distributed file system. However, it does not address performance issues when the contents are written in the file system of the OS in NDN ready mode. In addition, cached contents in each NDN node must be up-to-dated and be exact copies of the originals FileSync/NDN [4 th at e m plo y ed C C Nx synchronization protocol to resolve this issue However, due to its relatively short history of NDN compared with the conventional IP network architecture; there is still limited knowledge of its application to the NDN based repository, which contains files. Especially, when large files are inserted into the NDN repository, it shows a significant performance degradation. This problem is highly likely to occur when NDN is applied to high performance computing and Big Data fields Two NDN storage solutions have been suggested so far, such as NDNFS and Repo-ng have this issue although its extents are varied. We have already addressed these issues in the previous work [3 ou g h th e previou s  poster only points out the significance of the issues. In this paper, we also provide the solution for better performance based on architecture analysis and the observed figures Overall, following contributions are made in this work Full descriptions of current NDN repository architectures and its problems in I/O intensive environment Enhanced metadata configurations and its management scheme for I/O intensive environment Design considerations for NDN distributed file system and its strategy to apply the enhanced scheme 203 ISBN 978-89-968650-9-4 ICACT2017 Februar y 19 ~ 22, 2017 


First, we are going to study whether current repositories preform reasonably at serving large data files such as I/O intensive environments   For exa m ple, scien ce modelling files are large and take a long time of write and read operations. In the suggestion of the improved scheme, the details of the enhanced arch itecture will be explained Moreover, we provide the compar isons of those repositories and the performance descriptions of the improved scheme Furthermore, in the last step we outline a few considerations on its application to the development of NDN DFS, which is expected to show higher performance and require less maintenance effort II B RIEF OVERVIEW OF NDN REPOSITORIES A NDNFS NDNFS is a NDN-friendly file system, a tool that helps content owners publish contents over the NDN network. It is built upon Filesystem in User Space \(FUSE W ith o u t  much effort to integrate it into the native OS file system, it allows users to mount NDN file system with just few commands. When users copy and paste the file from the source location into NDNFS file system to publish it, NDNFS chops it into many NDN segments. They are in the networkready state after the segmentation process into the file system so that when an interest for a particular data gets in contact with NDNFS daemon, it is ready to be sent over NDN. It also provides a simple working example scenario over Web with Fire-fox and NDN.JS add-on [10  Co n tents p u b l i s h e d b y  NDNFS over NDN network can be viewed and searched with Firefox web browser. In addition, all the files and directories in the file system can be viewed and searched in the terminal and the file manager of the OS even though they are actually split in NDN packets. Other average file operations, such as read, write, modify, and delete can be done over them Features of NDNFS are summarized below FUSE file system Data is written in FUSE file system so that average OS file operations like ìcpî and îmv could be performed Metadata management  The metadata of each segment is kept in SQLite across three tables Extra tools  It works with NDN.JS Firefox add-on so that users navigate the file system and download the published contents B Repo-ng Repo-ng is an application of NDN persistent in-network storage complying with repo-protocol allowing data management operations of Repo-ng, including file read insertion, and deletion. Compared with the native Interest packet, Repo-ng employed the concept of signed Interest [11   modified Interest packet for the authentication of a data consumerís control command. Users insert contents at the re po with signed I nterests that have encoded usersí commands to do the requested operations at Repo-ng. Contrary to NDNFS all the contents are stored in SQLite with names, and data itself. It also provides a few simple tools to insert and retrieve contents from Repo-ng  ndngetfile and ndnputfile are the ones included in its package for insertion and retrieval operations respectively Features of Repo-ng are summarized below Data management Data and its name are stored in SQLite blob data type Signed Interests Write, read, and delete operations are done by receiving signed command Interests. This one is an extended version of the standard one, adding security features on it, authorizing the operating personnel Extra tool ndnputfile and ìndngetfile are provided with Repo-ng to retrieve and write data in repo III A RCHITECTURE A NALYSIS AND C OMPARISON A Initialization process of NDNFS 1 NDNFS NDNFS undergoes the initialization process before any data is inserted In this phase of process shown in Figure 1, it sets up all the components required to operate themselves over the network, such as keychain, database table creation, and file system initialization. The investigation of this process is the first step to learn about the blueprint of its entire architecture First, it reads options after ndnfs execution file for configuration, such as actual directory to store files, the mount point where users access the file system, the prefix name to publish the contents over NDN, the path of the log file, and the location of the metadata DB. Afterwards, it initializes key chain to sign packets later. Then it acquires the current user and group IDs for ndnfs access privilege. Third, it creates SQLite tables, such as  file_system   file_version   and  file_segments  File system contains a list of files in the file system, its current version, its mime_type, the signatureencoding scheme in the column type   Another column  ready_signed  is unused currently but is going to support asynchronous signature, which is now being researched Each file s information is recorded in metadata tables, such as size of each file. Lastly  file_segments  table is intended to accommodate the information of stored segments, for example signature, segment sequential number, and file path. After the creation of those tables, it returns the OS with fuse_main so that FUSE will work in NDNFS way with its own defined methods for Linux file operations 2 Repo-ng Unlike NDNFS Repo-ng reads the configuration file to set up its environment. Then, it sets a keyboard input to terminate the application. Otherwise, it wa its for command Interests to arrive at the repository daemon. Afterwards, it initializes the SQLite DB to store data and its corresponding names. It also  Figure 1  Initialization process of NDNFS 204 ISBN 978-89-968650-9-4 ICACT2017 Februar y 19 ~ 22, 2017 


saves information on pu blic keys in keyLocatorHash  column about the key selection in the public key chain so that the data consumer may decrypt the signature to verify the receiving data packets. This proc ess is visualized in Figure 2 B File insertion 1 NDNFS When a user wants a file to be published over NDN, one copies it onto the file system. Wh en it is pasted into the mount point of the FUSE, NDNFS investigates whether there is already a file identical to it. If not it reads the list of files from the target directory. If there is not a file to write, it creates a new file to append segments b eing copied from the source Next, it make s sure the target fileís existence  reads the fileís extension, decides the mime type, and saves it into the SQLite database Finally, it begins writing to the file, the target file is incremented by 4KB, and the increment continues until it reads the end of the source. Each step, it writes version information into SQLite table. After it completely finishes writing the file, here comes the most expensive operation next sign each segment, and store it into the SQLite. This step is indispensable. NDN specificatio n demands all data packets to be signed for stronger security. And then, write operation is finished 2 Repo-ng File insertion into the Repo ng is different from NDNFS Instead of the utilization of OS file operation calls, repo file insertion tool like ndnputfile  issues file insertion Interests to the Repo-ng. After the Interests arrive at it, it recognizes the authentication on the command Interest. Only authorized Interest insertion command allows a file to be stored into it This Interest also has information on the  StartBlockID  and  EndBlockID  of the desired data, or it has the selector information to retrieve it Once Repo-ng has the enough information to retrieve the target data, it expresses Interests to the target node where the target contents are placed. It re ceives data packets in response to the previously issued Interests. After the last data packet landed ndnputfile  sends insertion status check Interest to the Repo-ng. If there has been no error occurred at Repo-ng, it answers with insertion complete message C Observations on SQLite tables As depicted in Table 1 Repo-ng has three blob typed attributes, and one column with integer, which functions as the primary key of the table. Data attribute reserves all data packets, and the name attribute contains its corresponding name  keyLocatorHash  attribute has the information on a key to decrypt the signature in the data packet. All of these attributes type is blob However, as shown in Table 2  path  attribute of NDNFS that is identical to name  attribute in Repo-ng is a text type There is no blob data ty pe in it except for signature  attribute which seem to result in higher performance than that of Repong, described in next section TABLE 1 NDN_REPO DB SCHEMA OF R EPO NG Attribute Type Description id integer primary key of the table name blob NDN name for contents data blob contents in binary format keyLocatorHash blob public key information TABLE 2 FILE _ SEGMENTS DB SCHEMA OF NDNFS Attribute Type Description path text file path\(equivalent to  name  in Repo-ng version integer version information of each segment segment integer number for each segment signature blob signature of each segment TABLE 3 FILE _ SYSTEM DB SCHEMA OF NDNFS Attribute Type Description path text content path nameî in Repo-ng current_version integer content version mime_type text mime type of a file ready_signed integer each fileís signature state type integer file type, the output of ls command TABLE 4 N EW METADATA CONFIGURATION FOR EACH CONTENT Attribute Type Description path text content path nameî in Repo-ng current_version integer content version mime_type text mime type of a file ready_signed integer each fileís signature state type integer file type, the output of ls command certificate binary producer s certificate for each content IV D ISCUSSION AND E NHANCED S CHEME Both NDN repositories make use of SQLite. However, their performance statistics show significantly lower performance than the average Linux file system. Their differences could be due to the uses of blob data types in SQLite tables [12 Repong s data storage algorithm totally relies on SQLite, but NDNFS also exploits FUSE along with it. For better performance of SQLite, Repo-ng stores all the data in memory first like contents, names, and the signature itself. This algorithm could hurt overall system performance when it inserts a large size file, like bi g data and other data intensive science files, resulting in as drawback to the application to high performance computing. Data shown in the table 3 depicts that Repo-ng s write operation takes up a large portion of the system memory due to those reasons. In addition NDNFS also suffers performance degradation because of SQLite. When it is compared with a file operation of Ext4 severe bottleneck is observed. It is caused by frequent write operations of signature and other data into SQLite blob data type  Figure 2  Initialization process of Repo-ng 205 ISBN 978-89-968650-9-4 ICACT2017 Februar y 19 ~ 22, 2017 


A Problems of SQLite and its DB tables SQLite was used to save the metadata of a content According to SQLite developerís document there are many issues regarding its use on the file system [15 W h at if th i s file system implements file locking? There is a possibility of data corruption in DB when file lo cking runs inaccurately. In addition, when a requirement is changed to have higher concurrency, especially in the case of multiple writings to the disk, there is overhead in I/O. NDN is supposed to work efficiently in this circumstance. Thus, SQLite is a drawback providing negative QoS to the users Therefore, a new NDN data-storing scheme, which makes no use of SQLite, must be suggested to apply NDN storage in the high performance-computing field. The current NDNFS makes metadata and keep them in order to serve it over the network immediately. It incurs overhead while doing file operations into the file system, such as writing, renaming copying, modifying, and so on because these operations update all the packet information in SQLite. One may recognize the fact that many attributes belong to a file, and they are derived from it. Attributes, such as path, version mime_type, and so on are about a file. All of them may be relocated into a file itself, not in SQLite for the sake of performance as it is considered being a drawback in an I/O intensive environment As previously explained, Repo-ng stores the content and its metadata into blob data type s. According to the SQLite community, it only brings about extra processing time when it reads a large sized file. Table 1 shows that Repo-ng s metadata has already been designed to be a per-file structure However, ìkeyLocatorHashî attribute only contains the information to decrypt signature. There is expected to be a dedicated column for an encryption scheme of the content for an enhanced scheme B Metadata management with xattr According to the performance evaluation, database utilization has only been a burden to the system. Although embedding database to the file system has traditionally been mandatory, this approach brings about a problem on performance. The evolving NDN protocol will produce a lot more metadata to save contents on the disk, the best solution is always to minimize the DB involvement into the file system The creation of per-file metadata scheme is indispensable because it will not only reduce DB dependency, but also depicts possibility of employing other metadata management tools, such as extended file attribute \(xattr\ [18  Xattr is a key-value pair data base like information storage tool supported by a file system to a file. Most of modern Linux file systems support it. Except for signature, all other metadata was able to be stored in a file because signature is a per-packet metadata C Avoiding Signature Write Thus, a new metadata configuration strategy must be proposed to replace per-packet signature. As shown in Table 4 the new metadata strategy includes the certificate issued by the producer for the content. Therefore, it will remove the necessity of caching signatures but still have them because it will generate them at the network interface when the contents are consumed first time or late r again. This scheme is made feasible if there is a complete trust, authentication process between the file system \(server\e writer \(data producer so that each certificate of a file is safely stored in the file system. This scheme will eliminate all the problems listed in the previous section, such as renaming and updating contents at NDN repositories. But Repo-ng will not have such overhead But its writing operation into SQLite blob data type will be a source of performance drop V P ERFORMANCE E VALUATION We compared the performance of those two repositories and the prototype of enhanced NDNFS while they put files into the storages. All the experiments are carried out on an Ubuntu 15.10 system with Intel XeonÆ CPU 3.4Ghz 8 Cores 14GB RAM, 50GB hard drive. The NDN platform we used were NFD v0.4.0, NDN-cxx v0.4.0-beta2, NDNFS v0.3 NDN-CPP v0.4.0, and Repo-ng released on Nov. 21 st 2015 We selected 5 sample files weighing 200MB, 700MB, 1GB 2GB, and 3GB respectively. We did not modify the default packet size set in NDN-cxx so that data transmission between  ndnputfile  and Repo-ng was facilitated in 8K. To collect benchmark datasets, a bash script running ìpsî commands per second to read memory consumption and CPU resource, was made and it wrote the readings into text files The statistics in Table 5 we re collected while several large files were inserted into Repo-ng and NDNFS. Generally Repo-ng performs worse than NDNFS. In case of 1GB file insertion, Repo-ng took up mo re memory space than NDNFS It took approximately 77% of the total system memory while NDNFS never took more than 0.1% of the total space. It also used nearly 100% of CPU resource whereas NDNFS consumed around 60% of its total. This memory consumption indicated because Repo-ng stores all the data, such as contents names, and the signature in memory until it finishes reading The reason for low memory consumption of NDNFS comes from its size of data writing into the file system at each cycle It is always fixed to be 4KB, which is nearly 0% of the system memory TABLE 5 I NSERTION PERFORMANCE COMPARISON Figure 3 shows time taken values across a variety of sample big data files. In general, Repo-ng takes longer to insert a file into the repository. In case of 1GB file, Repo-ng took 2215.4 seconds in average to finish insertion. However only 39.8s elapsed with NDNFS for the same file. This trend is repeated with other cases. 1130.4 seconds in average passed while Repo-ng was inserting 700MB, but it only consumed 22 Metrics 200MB 700MB 1GB NDNFS port repo ng NDNFS port repo ng NDNFS port repo ng CPU 60 100 59.3 100 63 100 Memory 0.1 16.3 0.1 55.3 0.1 77 206 ISBN 978-89-968650-9-4 ICACT2017 Februar y 19 ~ 22, 2017 


seconds for NDNFS. As for 3GB and 2GB files, Repo-ng was unable to complete the insertion. It kept consuming the system memory and space in the swap file. The system-monitoring tool showed that Repo-ng used up all of 14GB RAM and the virtual memory, and the system crashed for inadequate memory space. Thus, those values were detached from the table because it was unable to record the values for those 2GB and 3GB files Time consumption is due to its one-to-one NDN communication nature ndnputfile and Repo-ng exchange interest and data one-by-one in NDN manner. It is an extremely slow process Figure 4 is a graph of time measurements while 2GB and 3GB files were being inserted in to a destination folder and the NDNFS. Although file operations of NDNFS works quicker than the other one, It still operates slowly in comparison with ordinary Linux file system, Ext4. This bottleneck is believed to be caused by SQLite operations frequent SQLite operations per each disk operation cycle [8  Altho ugh it to o k  81.2 seconds for 3 GB sample file to finish ìcp command for insertion, there was an addition al step to write signatures in the release operation in the FUSE afterward As depicted in Figure 5, it spent 26:52 minutes of extra time approximately 30 min to complete a writing operation to the file system. During the release operation, the user may begin another write. However, the performance significantly dropped due to the signature write being done at SQLite Figure 5 also shows that different lengths of signature writing operations are run in th e background as to their file sizes. It hurts the performance of other file operations during the SQLite task. However, our prototype implementation with the proposed scheme does not und ergo this step, resulting in better performance for I/O intensive environment overall Figure 6 presents that renaming a file also takes a significant amount of time in the current scheme because it has to rename all the signatures and other metadata in SQLite As for the 3G sample file, it took 39.105s to rename it However, our prototype NDNFS with improved scheme for I/O intensive system does not make use of SQLite nor record signatures into it. It finishes renaming instantly taking around 1 second for all sizes of the contents VI C ONSIDERATIONS ON ITS E VOLUTION TO DFS According to Satyanarayananís work 19  distribu ted f ile  systems employed client/server database to maintain metadata As for I/O intensive system, database could cost so much depending on its I/O intensity. To achieve its reliability and throughput, a reliable product must be integrated into the file system, such as Oracle DB, costin g extra license fees as to the number of CPU cores and accessed users. However, its cheaper replacement, MySQL has a less reliability than Oracle product [16 1 7  If a datab ase e m bed d ing i n to a di stribu t e d  file system is a crucial element, sharing its load with  Figure 3  Comparison of insertion time Figure 4 Comparison of insertion time Figure 5  Time consumption for signature assignment Figure 6  Time consumption for renaming operation 207 ISBN 978-89-968650-9-4 ICACT2017 Februar y 19 ~ 22, 2017 


alternative means of database, such as xattr may take less cost and provide better performance. Further research on the application of NDN based distributed file system metadata configuration in consideration of xattr alternative will offer advantages on NDN applied system. Brief philosophy of the NDN DFS metadata design is followed below Central Metadata Server Central metadata server probably operated by traditional client/server database has a minimal dataset to map the locations of the entire contents across DFS Each Content File All the other metadata derived out of each file is recorded into itself. For example, in the form of the extended file attribute The central server role must be limited to map the DFS memb ers and its contentsí locations, and all the other extra information must belong to its own file as portrayed in Figure 7. In this way, the throughput increases and its overhead decreases due to the minimal workload on the metadata server VII C ONCLUSIONS We have concluded that the application of SQLite into a NDN file system is inappropriate for I/O intensive environment although this approa ch is in the notion of the traditional DFS to manage metadata. However, this approach aroused overhead in the current NDN file system at I/O intensive environment. Thus, we employed an alternative approach with a new metadata configuration to replace SQLite reducing overhead in the file system. We also put forward to a design suggestion to minimize DB involvement for NDN based DFS based on our findings, reducing maintenance cost as well as performance improvement. Our future work will be researching on quick signature generation algorithm in cooperation with a graphic processing unit to reduce overhead caused by it, and the full design and implementation of DFS with our enhanced prototype of NDNFS A CKNOWLEDGMENT This research was supported by the MISP\(Ministry of Science ICT & Future Planning\, Korea, under the National Program for Excellence in SW\pervised by the IITP\(Institute for Information & communications Technology R22151610020001002 R EFERENCES 1  Cis c o V i s u al N e tw o r king  I nde x   G l o b al Mo bil e D a ta T r af f i c F o r e cas t Update, 2015  2020 White Paper", Cisco, 2016. [Onlin A v a i la b l e  http://www.cisco.com/c/en/us/solutions/collateral/serviceprovider/visual-networking-index-vni/mobile-white-paper-c11520862.html 2 V  J a c o b s o n  D  K  S m e t t e r s  J  D  T h o r n t o n  M  F  P l a s s  N  H  B r i g g s   and R. L. Braynard, ìNetworking named content,î in ACM CoNEXT Rome, Italy, 2009 3 I. C. Hwang, D. Kim, Y. B. Ko, ìAnalysis of NDN Repository Architecturesî in IEEE International Conference on High Performance Computing\(HPCS 2016\ , Innsbruck, Austria, 2016 4 J. Lindblom, M. C. Huang, J. Burke, L. Zhang, ìFileSync NDN: Peer toPeer File Sync over Named Data Networking,î NDN Techni cal Report NDN-0012, March 2013 5 S  C h e n  J   Ca o  L   Zhu, ìNDSS: A Named Data Storage System,î  in IEEE International Conference on Cloud and Autonomic Computing ICCAC\idge, MA, USA, 2015 6 W. Shang, Z. Wen, Q. Ding, A. Afanasyev, and L. Zhang, ìNdnfs: An ndnfriendly file system NDN Technical Report NDN-0027, Revision 1 Oct. 2014 7 R ep o-n g Next gen e ra t i on of NDN rep o s i t o ry  http://redmine.nameddata.net/projects/Repo-ng/wiki  8 C F a n, S  S h a n n i g r ah i, S  D i B e ne de tto C. O l s c ha no w s ky C Papadopoulos, and  H. Newman, ìManaging scientific data with named data networking,î in ACM SIGHPC Workshop on Network aware Data Management \(NDM\ Austin, Texas, 2015 9 F USE  F i l e s y s t em i n Us e r sp a c e   http://fuse.sourceforge.net  W  Sh a n g J T h om p s on M Ch erk a oui  J   Bu rk e  a n d L  Z h a n g  NDN.JS: A javascript client library for named data networking i n IEEE  INFOCOM  Workshop on NOMEN, Turin, Italy, 2013  Signed Interest.î [Online A v ail a bl e   http://redmine.named-data.net/projects/ndn-cxx/wiki/SignedInterest 12 I n te r n al V e r s us Ex te r n al BL O B s i n S Q L ite   https://www.sqlite.org/intern-v-extern-blob.html  W. Yu, S. Liang, D. K. Panda, ìHigh performance support of parallel virtual file system \(PVFS2\ver Quadrics Proceedings of the 19th annual international conference on Supercomputing, Boston, MA, 2005 DOI = http://dx.doi.org/10.1145/1088149.1088192 14 D  K  S m e tte r s a n d V  J aco bs o n  S e cur i ng ne tw o r k co nte n t O c to be r  2009. PARC Technical Report  SQLite Document, ìAppropriate Uses for SQLite,î [Online A v ail a ble https://www.sqlite.org/whentouse.html  DB E n gi n e s   System Properties Comparison Microsoft SQL Server vs MySQL vs. Oracle,î [Online A v ail a bl e   http://db-engines.com  I T X D e s i gn   MySQL vs Oracle,î [Online A v ail a bl e   https://itxdesign.com/mysql-vs-oracle  Linux Programmerís Manual \(2015\ xattr Extended attributes [Online   Available: http://man7.org/linux/man-pages/man5/attr.5.html  M. Satyanarayanan A Survey of Distributed File Systems  Technical Report CMU-CS-89- 116, Department of Computer Science, Carnegie Mellon University, 1989           Figure 7  Conceptual diagram of NDN DFS 208 ISBN 978-89-968650-9-4 ICACT2017 Februar y 19 ~ 22, 2017 


In Chan Hwang earned his BS degree in Computer Science from Georgia Southwestern State University GA, USA, in 2013. He is currently attending the graduate school of Software Engineering at Ajou University. His research interest is in the area of Named Data Networking Dabin Kim received her BS degree in Computer Science from Seoul Women's University, Korea, in 2010. She earned Ph.D. at the school of Computer engineering of Ajou University, Korea. Her research interests are in the area of wireless communication and information-centric networking Young-bae Ko is currently a Professor in the Department of Software at Ajou University, Korea leading the Ubiquitous Networked Systems Lab funded by BK21+ \(Brain Korea 21 Plus\ National Project Prior to joining Ajou University in 2002, he was with the IBM T.J. Watson Research Center, New York, as a research staff member in the Department of Ubiquitous Networking and Security. He received his Ph.D. degree in computer science from Texas A&M University. His main research areas are in wireless ad hoc/mesh networks, IoT, Smart Grid and Future Internet. He was the recipient of a Best Paper award from ACM Mobicom 1998. He has served in various activities most notably as the general chair in IEEE SECON 2012 and editorial board of Elsevier Digital Communications and Networks. See http://uns.ajou.ac.kr for further details 209 ISBN 978-89-968650-9-4 ICACT2017 Februar y 19 ~ 22, 2017 


2728 IEEE TRANSACTIONS ON IMAGE PROCESSING VOL 26 NO 6 JUNE 2017 Algorithm 1 Hierarchical ICM The gradient corresponding to patch n at scale l is  E    s n  l     l  n   s n    v  V    s n  l   s  l v n      n  h  h  B  l  n    s n  l    s h  l       n  q  q  Q  l  1  n    s n  l    s q  l  1     H   s n  5 where   x  y    g  x  y   x   y 2  x 015 1    x  y  2 An advantage of this local model is that the complexity and computational cost are greatly reduced We can easily extend this model to include relations with other neighboring SMNs both observed and latent without increasing signiﬁcantly the complexity see Fig 6c Note that these new neighboring relations are not part of the original global model of Fig 6a Including these extended relations in the global model and solving the optimization problem would be very difﬁcult since the extended connections destroy the factorization into pairwise factors requiring higher order factors and the corresponding energy terms in the formulation 2 Scale-Wise Message Passing Algorithm A different view of the hierarchical ICM is as neighboring patches sending  Fig 7 Optimization using message passing a one step of hierarchical ICM b-c two steps of the top-down scale-wise message passing algorithm for scale l and l  1 update messages to the current patch and then moving to the next one see Fig 7a A message passing algorithm consists of update messages and a schedule for the updates Algorithm 1 has the problem that each update may depend on both updated and not updated values Here we study different message passing strategies as an alternative First we consider sending update messages directly in the global model All nodes receive and send messages simultaneously in parallel which are then updated at the same time as  s n  l   s n  l   s n  l   The update is computed as  s n  l     v  V msg  n  l v  n  l       n  h  h  B  l  n msg  h  l   n  l       n  q  q  Q  l  1  n msg  q  l  1   n  l     H   s n  6 with msg  h  l   n  l     E    s n  l     l  n   s n  Note that each message solves a local optimization problem as in previous section Since the information from top scales of CNNs is usually more reliable we devise a scale-wise message passing algorithm Algorithm 2 that propagates the information from previous scales in a hierarchical fashion rather than optimizing jointly the global model The experiments will show that this strategy has better performance The algorithm sends update messages within the nodes of a given single layer including messages from the previous scale In the next step all the nodes in that scale are considered observed and the next scale is processed in the same way Fig 7b and c represent two steps of this algorithm D Embedding and Pooling After processing patch SMNs with the hierarchical context model we aggregate them into image SMNs using average pooling and the decision is simply the category with the maximum probability in the image SMN Note that in this case the ambiguity due to weak supervision still remains Alternatively patch SMNs can be encoded and pooled prior to the contextual classiﬁer   19 s ee F i g 2 I n p art i c ul ar we use the KCNF embedding w h i c h e xpl oi t s bet t e r l ocal category co-occurrences 


SONG et al  MULTI-SCALE MULTI-FEATURE CONTEXT MODELING FOR SCENE RECOGNITION IN THE SEMANTIC MANIFOLD 2729 Algorithm 2 Top-Down Message Passing Algorithm VI E XPERIMENTS A Experimental Setup 1 Datasets The proposed methods are evaluated on three small datasets 15 scenes   24 cont ai ns 4485 i m ages across 15 scene categories LabelMe  c ons i s t s of 8 out door scene categories with a total of 2600 images UIUC-Sports 5 consists of 1585 images labeled into 8 complex sport scene categories Following the settings in previous works we use 100 100 and 70 images for training respectively We also evaluate the proposed methods on larger datasets including MIT67  and S U N 397 45 M IT67 cont ai ns 15620 i m ages of 67 indoor scene classes SUN397 consists of 397 categories with 108762 images in total In the case of MIT67 Indoor and SUN397 the training/testing conﬁgurations are provided by the original authors Finally we also include an evaluation on the very large Places365-standard dataset  cons is ting of 365 scene categories and 1,803,460 training images with the number of images per class varying from 3,068 to 5,000 We follow the public training/validation split for evaluation 2 Shallow Patch SMNs We evaluate GMM-SMNs and NN-SMNs in the multi-feature setting with one scale and the proposed context models As local visual descriptor we use three variants of kernel descrip tors g radi ent  s h ape a nd color KDES All local visual descriptors are extracted on a regular dense grid of 16  16 pixels stride 8 pixels resulting in 30  30 patch level local descriptors on a 256x256 image For GMM-SMNs we train GMMs with 512 mixtures for each scene category For NN-SMNs we use a network with two fully connected layers including one hidden layer with 512 nodes Note that this network has comparable amount of parameters to the model with 512 GMMs 3 Deep Patch SMNs We use the VGG CNN architecture pre-trained either with ImageN et or Places 18 r eplacing the size of the last fully convolutional layer fc8 to meet Fig 8 Region size and sparse parameter evaluation the number of categories Then we ne tune the previous fully convolutional layer fc7 and train fc8 with the target datasets Since the size of the patches is xed in this architecture 224  224 pixels  we extract features in four scales obtained by resizing the input image to 224  224 320  320 448  448 and 640  640 pixels scales 1 2 3 and 4 respectively With these sizes we obtain 1  1 4  4 8  8 and 14  14 patches per scale respectively B Context Models With Shallow SMNs a Baseline and proposed methods We evaluate the proposed context models within the SM framework but integrating KCNF encoding F or G MM-S M N s and NN-SMNs we also include spatial pyramid matching w i t h four levels 1  1 2  2 3  3 4  4 Using the previous method as baseline we consider four variations of the proposed context model  Multi-feature context MF multiple features are combined in the semantic space with average pooling corresponding to the model in Figure 5a  Spatial context  single feature exploiting neighboring spatial relations see Figure 5b Obtained by minimizing Eq 1 when only one feature is used  Multi-feature spatial context MFS combines multiplefeatures of the target patch and neighboring spatial relations i.e see Figure 5c Obtained by minimizing Eq 2 in the multi-feature case  Extended multi-feature spatial context EMFS also includes multiple-features from additional patches in the neighborhood Figure 6c with single scale 


2730 IEEE TRANSACTIONS ON IMAGE PROCESSING VOL 26 NO 6 JUNE 2017 Fig 9 Output patch SMNs of the image in Fig 1a category tallbuilding af ter the context model and the effect of en tropy regularization a GMM-SMN s and b NN-SMNs The spatial neighborhood is 7  7 patches 1 Neighborhood Size and Entropy Regularization We evaluate the impact of the size of the spatial neighborhood which is critical in our context model We use the 15 scenes dataset and the EMFS model xing   1   V  and   1   B  l  n   The results are illustrated in Figure 8 We evaluate different neighborhoods including the 4-connectivity spatial neighborhood and other dense neighborhoods of size L  L patches 3  3 corresponds to 8 neighbors We can observe that larger neighborhoods can effectively reinforce consistent patterns and lter accidental ones However too large neighborhoods cannot capture properly local co-occurrence patterns From our experiments a good trade-off is 7  7 patches Entropy regularization is also important to capture category co-occurrence patterns properly We evaluate  in a range from 0 to 0.2 with a step of 0.05 Figure 9 shows that without entropy regularization    0 the performance is lower Note that NN-SMNs require lower penalty than GMM-SMNs We obtained the best performance for L  7and   0  1  0  05 for GMM-SMN and NN-SMN respectively so for the rest of the experiments we use this conﬁguration Figure 9 illustrates how the proposed method is able to effectively combine the three feature-speciﬁc patch SMNs from Figure 4 into smoother multi-feature patch SMNs The regularization term prevents from excessive smoothing that can wash out the true class-speciﬁc co-occurrence patterns that we want to preserve 2 Context Models We compare the different variations of the proposed method on the three small datasets to show how different types of context models improve the accuracy Table IV shows that the classi cation accuracy increases consistently when we include additional contextual relations in the context model Combining multiple features helps with a TABLE IV A CCURACY  OF GMM-SMN/NN-SMN FOR D IFFERENT C ONTEXT M ODELS I NDICATES I MPLEMENTED BY US I NSTEAD OF R EPORTED             gain around 1.1-2.5%/1.3-1.4 GMM-SMN/NN-SMN over the best single feature Using s patial relations varies from no gain to modest gains around 1%/3.3 However combining both can increase an additional 0.5-1%/0.7-0.8 over only multi-feature context The extended multi-feature spatial context contributes with an additional 0.4-2.2%/1.1-2.6 gain by incorporating multip le features from the neighboring patches The total gain with the extended context model over the baseline is around 2.6-5.7%/3.0-4.5 Note also that NN-SMNs typically obtain slightly be tter performance compared 


SONG et al  MULTI-SCALE MULTI-FEATURE CONTEXT MODELING FOR SCENE RECOGNITION IN THE SEMANTIC MANIFOLD 2731 TABLE V C OMPARISON ON MIT67 D ATA S E T      with GMM-SMNs and both consistently beneﬁt from contextual modeling 3 Comparison With Related Works We compare our method with other works using mid-level semantic representations such as latent topics object bank  22  27 and classemes   47 M os t o f t hes e approaches cannot be used in large scale datasets so we separate comparisons for small datasets and larger datasets a Small datasets Table IV compares the results reported by the authors in their corresponding references Although a completely fair comparison with reported results is not possible due to different implementations features and other parameters our framework at least seems to be competitive in the three evaluated datasets Comparing with previous methods based on SMNs and co-occurrence modeling such as CMN SPMSM and KCNF is of particular interest The proposed method which also exploits mu ltiple features and richer contextual relations achieves better performance than those methods We also compare with non-semantic representations by directly modeling categories from the same low-level kernel descriptors concatenated to combine them with and a SVM and spatial pyramid We observe that our method also achieves better results b Large datasets We evaluate the proposed methods on the larger MIT67 and SUN397 datasets The results are shown in Tables V and VI respectively NN-SMNs achieve better performance than GMM-SMNs especially for MIT67 The gains due to richer context models are much higher than in smaller datasets with signiﬁcant gains of 11%/9.5 and 15%/9.1 GMM-SMNs/NN-SMNs over the best single feature baseline respectively This suggests that contextual relations become much more important important as the number of scene categories increases resulting in much noisier and sparser co-occurrence patterns Exploiting the context to emphasize representative category co-occurrence patterns can greatly help to improve the recognition performance Other mid-level semantic representations such as object bank and meta-classes exploit larger amounts of external data TABLE VI C OMPARISON ON SUN397 D ATA S E T      TABLE VII A CCURACY  OF D IFFERENT A DAPTATIONS ON MIT I NDOOR 67   e.g ImageNet web images to model the mid-level classiﬁers The proposed method outperforms them without resorting to external data but still falls short compared with discriminative parts  w hi ch i s part i c ul arl y ef fect i v e f or indoor scenes where certain objects can be very discriminative However this method cannot scale to larger datasets such as SUN397 We also include other approaches based on lower level representations such as bag-of-words coding  and the Fisher vector T he latter achie v e s b etter accurac y  b ut at the cost of a much higher dimensional feature resulting from a much denser grid for sampling local features C Context Models With Deep SMNs and Multiple Scales 1 Patches vs Full Images We use the CNN-SMNs as described in Section IV-B extracting two complementary features that depend on the pre-training dataset i.e either ImageNet-CNN or Places-CNN In addition we consider multiple scales which are determined by the size the input image is resized for a xed patch size of 224  224 pixels When adapting the CNN to a particular target scene dataset this adaptation can be performed using full size images resized to the patch size i.e 224  224 pixels or using patches extracted at the particular scale As Table VII shows the latter is a better approach since patches used for adaptation and during test have similar scale distributions 2 Single Scale We rst compare the hierarchical ICM and the message passing MP algorithms in a single scale setting We compare the accuracy and the total energy for different spatial neighborhoods Since the total energy depends on the number of edges and they depend on the size of the neighborhood it is difﬁcult to compare neighborhoods with different size For better comparison we normalized the energy and set 


2732 IEEE TRANSACTIONS ON IMAGE PROCESSING VOL 26 NO 6 JUNE 2017 Fig 10 Comparison between ICM and MP on MIT Indoor 67 on scale 3 448  448 a\y b normalized pairwise energy,\(c time cost TABLE VIII C OMPARISON B ETWEEN I NTEGRATED AND S CALE W ISE MP M ODELS ON MIT67 IN A CCURACY       1   3  V      1   3  B  l  n      1   3  Q  l  1  n   and   0 in Eq 4 and 5 which we found work well in practice Fig 10b shows how the energy of ICM decreases quickly to the minimum value in around 16 iterations However it increases with more iterations probably due to the asynchronous updating scheme also causi ng the accuracy to decrease In contrast MP passes messages synchronously and then updates the values of each node simultaneously As a result the energy decreases more slowly but consistently although the absolute value of the of the energy is slightly higher and the accuracy increases sli ghtly However a drawback is that is slower than ICM 3 Multiple Scales and Message Passing In the next experiment we evaluate three varian ts of the proposed multi-scale MP algorithm on MIT Indoor 67 with just one CNN or combining two both ImageNet-CNN and Places-CNN The integrated variant optimizes all the nodes at the same time and then combines the scales The top-down and bottom-up variants are scale-wise and progressively update a given scale based on the previous scale In general the top-down strategy performs better than the others since the top scale more global obtains the best singlescale performance so using it as initial step leads to a better solution The results of the same experiment for SUN397 are shown in Table IX The proposed architecture combining ImageNet-CNN Places-CNN at three scales achieves a remarkable 69.3 of accuracy comparable to human performance as reported in  I n t hi s cas e i ncl udi ng s cal e 4 decreases the performance so we do not include it in the next experiment 4 Encoding Methods and Other Works In the previous experiments there is no supervised contextual classiﬁer e.g SVM nor any particular encoding The scene prediction is obtained basically pooling patch CNN-SMNs Now we also consider the full SM framework which includes TABLE IX A CCURACY  OF M ODELING J OINT C ONTEXTS ON SUN397    encoding and SVM classiﬁcatio n see Figure 2 We selected the architectures with best performance from previous experiments 3 scales for MIT67 and 4 scales for SUN397 both with ImageNet-CNN and Places-CNN and encode the CNN-SMNs using various encodings SM  F V  15 EMK  LLC 55 F o r E MK and LLC w e us e d i c t i onari es of 1000 words and for FV we use 50 GMMs and then reduce the dimensions to 4096 using PCA following T he res u l t s are shown in Table X The gain using encoding+SVM is more signiﬁcant for MIT67 than for SUN397 and for single scale than for multiple scales In particular for SUN397 a marginal 0.1 gain is achieved over the best performance We also compare with other works in Table X some using AlexNet and some using VGG architectures In the next section we evaluate our approach on the recent dataset Places365 T hus  w e can als o us e C NNs pretrained on this dataset in our framework and we report some results using an extended framework with in addition to ImageNet-CNNs and Places-CNNs includes Places365CNNs This setting obtains state-of-the-art performance 72.6 for SUN397 D Evaluation on Places365 Evaluation on Places365 is difﬁcult due to the size of the dataset In this case we use the original crops for adaptation instead of patches and 3 scales the amount of 


SONG et al  MULTI-SCALE MULTI-FEATURE CONTEXT MODELING FOR SCENE RECOGNITION IN THE SEMANTIC MANIFOLD 2733 TABLE X C OMPARISON TO THE S TATE OF THE A RT   I NDICATES O UR I MPLEMENTATION          TABLE XI A CCURACY  OF V ALIDATION D ATASET ON P LACES 365   data resulting for smaller patches is too large for training However even with these settings the results of our framework with multi-scale multi-CNN context modeling obtains 57.1 top 1 accuracy outperforming the best in baseline by 2.2 We can also compare with a simple average pooling across scales and CNNs and where our model still has a gain of 1.6 In general evaluation on Places or Places365 is not reported in the vast majority of papers about scene recognition and even most recent works typically use off-the-shelf CNNs trained on Places or Places365 but do not evaluate on those datasets For Places365 we are only aware of the result of Zhou et al  w hi ch w e i m pro v e by 1.9  Note that their setting would be closer to our scale 1 256  256 pixels but with some differences  a v erages 10 crops 4 corners  central  mirror while we use only four 2  2 patches VII C ONCLUSIONS Although recently relegated in favor of deep learning methods intermediate representations have played an important role in automatic scene recognition The semantic manifold framework addresses the problem of modeling scene categories from visual features with a combination of weak supervision and pooling that avoids mid-level annotations while inference can be easily modeled in two independent steps in contrast to most methods that learn latent representations This framework suffers from the speciﬁc problem of scene category co-occurrences thus requiring speciﬁc solutions In this paper we revisit the semantic manifold approach and tackle several of the limitations not addressed in previous works   13  19 W e i dent i f y t he ori g i n al pat c h S MN models based on GMMs i.e GMM-SMNs as an important bottleneck in terms efﬁciency and accuracy resulting from the training stage that learns patch SMN models independently for each category We show that replacing them by NN-SMNs based on neural networks and learned jointly for all the categories produce much faster and more discriminative SMNs Modeling category co-occurrences properly is the other critical stage Previous methods ignore local contextual relations which are very helpful for this purpose SMN representations in the semantic manifold have the unique characteristic that patches and images are repre sented in the same semantic space independently of the visual feature used as input Exploiting this property we combine multiple features and scales and integrate spatial multi-feature and even multi-scale relations between neighboring patch SMNs into a joint context model showing that in this way we can discover consistent co-occurrence patterns and lter out noisy ones making things easier for the classiﬁer whic h can focus on modeling scenes in terms of these cleaner patterns In particular we use a multifeature multi-scale Markov random eld formulation with a speciﬁc entropy regularizer Although still far from CNNs and some methods using the proposed NN-SMNs and an extended 


2734 IEEE TRANSACTIONS ON IMAGE PROCESSING VOL 26 NO 6 JUNE 2017 context model our framework can signiﬁcantly improve the recognition performance of the previous semantic manifold approach and its variants We further recast convolutiona l networks as sophisticated SMNs implemented as weakly supervised adaptation of a pre-trained network and inte grate them as semantic features in the proposed framework This hybrid approach achieves state-of-the-art scene recognition accuracy even without the contextual classiﬁer R EFERENCES 1 A  O li v a and A  T or r a lba M odeling t he s h ape o f t he s cene A holis tic representation of the spatial envelope Int J Comput Vis  vol 42 no 3 pp 145–175 2001 2 J  W u a nd J  M  Rehg Centr is t A v is ual d es cr iptor f or s cene categorization IEEE Trans Pattern Anal Mach Intell  vol 33 no 8 pp 1489–1501 Aug 2011 3 J  V ogel a nd B S c hiele S em antic m odeling o f n atur al s cenes f o r content-based image retrieval Int J Comput Vis  vol 72 no 2 pp 133–157 Apr 2007  L  L i H Su E  P  X ing and L  F ei-Fei  Object bank A h ighlevel image representation for scene classiﬁcation  semantic feature sparsiﬁcation in Proc NIPS  2010 pp 1378–1386 5 L  J  L i and L  F eiF ei  W h at w her e and w ho Clas s i f y ing e v e nts b y scene and object recognition in Proc ICCV  2007 pp 1–8 6 C  W ang D  Blei a nd L  F e iF e i S im ultaneous im age c las s i  cation and annotation in Proc CVPR  2009 pp 1903–1910  Z  N iu G  H ua X  G ao a nd Q T i an  Conte x t a w a re topic m odel f or scene recognition in Proc CVPR  2012 pp 2743–2750  A  Q uattoni and A  T orralba Recognizing indoor s cenes   in Proc CVPR  2009 pp 413–420 9 C  D oer s ch A  G upta and A  A  E f r o s  M idl e v el vis u al elem ent discovery as discriminative mode seeking in Proc NIPS  2013 pp 494–502  M J uneja A  V edaldi C  V  J a w ahar  a nd A Z i s s e rm an  Blocks that shout Distinctive parts for scene classiﬁcation in Proc CVPR  2013 pp 923–930  R K w itt N  V a s c oncelos  a nd N  Ras i w a s i a S cene r ecognition o n t he semantic manifold in Proc ECCV  2012 pp 359–372  N Ras i w a s i a P  J  Moreno and N  V as concelos   Bridging the g ap Query by semantic example IEEE Trans Multimedia  vol 9 no 5 pp 923–938 Aug 2007  N Ras i w a s i a a nd N V a s c oncelos   Holis tic conte x t m odels for v is ual recognition IEEE Trans Pattern Anal Mach Intell  vol 34 no 5 pp 902–917 May 2012  X  S ong S  J i ang and L  H erranz  Joint multi-feature spatial context for scene recognition in the semantic manifold in Proc CVPR  Jun 2015 pp 1312–1320  M  D i xit S  Chen D  G ao N  R as iw as ia a nd N  V a s c oncelos   S cene classiﬁcation with semantic Fisher vectors in Proc CVPR  2015 pp 2974–2983  J  Bes a g On t he s t atis tical analys is of dirty p ictures   J Roy Statist Soc Ser B  vol 48 no 3 pp 259–302 1986 17 O R u ssa k o v sk y et al  ImageNet large scale visual recognition challenge Int J Comput Vis  vol 115 no 3 pp 1–42 2015 Available http://dx.doi.org/10.1007/s11263-015-0816-y  B Z hou A L a pedriza J  Xiao A  T orralba and A  O li v a   L earning deep features for scene recognition using places database in Proc NIPS  2014 pp 487–495  X Song S J i ang L  Herra nz Y Kong and K Zheng Category co-occurrence modeling for large scale scene recognition Pattern Recognit  vol 59 pp 98–111 Nov 2016 A v a ilable http://www.sciencedirect.com/science/article/pii/S0031320316000406  S L azebnik C Schm id a nd J  Pon ce Beyond bags of features Spatial pyramid matching for recognizing natural scene categories in Proc CVPR  2006 pp 2169–2178  L  Bo X  R en a nd D F ox K ernel d es criptors for v is ual r ecognition  in Proc NIPS  2010 pp 244–252  L  Z h ang X Z h en a nd L  Shao  L earning object-to-clas s k ernels for scene classiﬁcation IEEE Trans Image Process  vol 23 no 8 pp 3241–3253 Aug 2014  A Ber g am o a nd L  T o rres a ni  Cl assemes and other classiﬁer-based features for efﬁcient object categorization IEEE Trans Pattern Anal Mach Intell  vol 36 no 10 pp 1988–2001 Oct 2014  L  Fei-Fei a nd P  Perona  A B ayes ian hierarchical model for learning natural scene categories in Proc CVPR  2005 pp 524–531  N Ras i w a s i a a nd N V a s c oncelos  Latent Dirichlet allocation models for image classiﬁcation IEEE Trans Pattern Anal Mach Intell  vol 35 no 11 pp 2665–2679 Nov 2013  X W a ng and E  G rim s on Spatial l atent Dirichlet allocation in Proc NIPS  2007 pp 1577–1584  L  J  L i H Su Y  L im  a nd L  Fe i-Fei Object bank An object-level image representation for high-level visual recognition Int J Comput Vis  vol 107 no 1 pp 20–39 2014  X  Bai C Y a o and W  L iu  S t r o k e lets  A lear ned m ultis cale m idl e v el representation for scene text recognition IEEE Trans Image Process  vol 25 no 6 pp 2789–2802 Jun 2016  X  W a ng B W a ng X  Bai W  L i u and Z  T u M axm ar gin m ultipleinstance dictionary learning J.Mach.Learn.Res  vol 28 no 3 pp 846–854 2013  G S X ie X  Y  Z h ang S Y a n and C  L  L i u Hybrid CNN a nd dictionary-based models for scene recognition and domain adaptation IEEE Trans Circuits Syst Video Technol  to be published O A v a ilable http://ieee xplore i e e e  o r g d ocu m ent 7362 156  doi 10.1109/TCSVT.2015.2511543  N Ras i w a s i a a nd N V a s c oncelos   Holis tic conte x t m odeling u s i ng semantic co-occurrences in Proc CVPR  2009 pp 1889–1895  A Krizhe vs k y  I  S uts k e v er  a nd G E Hinton ImageNet classiﬁcation with deep convolutional neural networks in Proc NIPS  2012 pp 1106–1114  J  Deng A Ber g  a nd L  Fei-Fei L ar ge graph c ons truction f or s calable semi-supervised learning in Proc ICML  2011  J  Donahue et al  DeCAF A deep convolutional activation feature for generic visual recognition in Proc ICML  2014 pp 647–655  T  Dura nd N T home  a n d M  C ord  W E L DON W e a k l y supe rvi s e d learning of deep convolutional neural networks in Proc CVPR  Jun 2016 pp 4743–4752  M Oquab L  Bottou I L a pte v  a nd J Sivic Is object localization for free?—Weakly-supervised learning with convolutional neural networks in Proc IEEE Conf Comput Vis Pattern Recognit CVPR  Jun 2015 pp 685–694  X L i et al  Deepsaliency Multi-task deep neural network model for salient object detection IEEE Trans Image Process  vol 25 no 8 pp 3919–3930 Aug 2016  H  Bilen a nd A  V e daldi W eakly s uper v is ed deep detection n etw o r k s   in Proc IEEE Conf Comput Vis Pattern Recognit CVPR  Jun 2016 pp 2846–2854  Y  G ong L  W a ng R G uo and S  L azebnik Multi-s cale o rderles s pooling of deep convolutional activation features in Proc ECCV  2014 pp 392–407  R W u  B  W ang W  W a ng and Y  Y u H ar v e s ting d is cr im inati v e m eta objects with deep CNN features for scene classiﬁcation in Proc ICCV  2015 pp 1287–1295  Q W a ng P  L i  W  Z uo and L  Z hang RAID-G Rob u s t es tim ation o f approximate inﬁnite dimensional Gaussian with application to material recognition in Proc CVPR  Jun 2016 pp 4433–4441  F  Perronnin J  Sánchez and T  M en sink Improving the Fisher kernel for large-scale image classiﬁcation in Proc ECCV  2010 pp 143–156  D G L o we  Dis tincti v e i m a ge feat ures from scale-invariant keypoints Int J Comput Vis  vol 60 no 2 pp 91–110 2004  D  Z h ang X  Chen a nd W  S  L ee T e x t c las s i  cation w ith k e r n els o n the multinomial manifold in Proc RDIR  2005 pp 266–273  J  X i ao J  H ays  K  A  E h inger  A  O l i v a and A  T or r a lba S U N database Large-scale scene recognition from abbey to zoo in Proc CVPR  2010 pp 3485–3492  B Z hou A Khos la A  L apedriza A T o rralba and A  O li v a   2016 Places An image database for deep scene understanding On Available https://arxiv.org/abs/1610.02055  L  T o rres a ni M  S zum m e r  and A  F itzgibbon E f  cient object cate gory recognition using classemes in Proc ECCV  2010 pp 776–789  M  P a nde y a nd S  L azebnik S cene r ecognition a nd w eakly s uper v is ed object localization with deformable part-based models in Proc ICCV  2011 pp 1307–1314  G  L  O l i v eir a  E  R  N as cim e nt o A W Vieira and M F M Campos Sparse spatial coding A novel approach to visual recognition IEEE Trans Image Process  vol 23 no 6 pp 2719–2731 Jun 2014 


SONG et al  MULTI-SCALE MULTI-FEATURE CONTEXT MODELING FOR SCENE RECOGNITION IN THE SEMANTIC MANIFOLD 2735  L  Xie Q T i an M  W ang and B  Z hang Spatial pooling o f h eterogeneous features for image classiﬁcation IEEE Trans Image Process  vol 23 no 5 pp 1994–2008 May 2014  Z  W a ng J  Feng S Y a n and H  X i L inear dis t ance coding for i m a ge classiﬁcation IEEE Trans Image Process  vol 22 no 2 pp 537–548 Feb 2013  J  Sanchez F  Perronnin T  Mens i nk and J Verbeek Image classiﬁcation with the Fisher vector Theory and practice Int J Comput Vis  vol 105 no 3 pp 222–245 2013  J  Xiao K  A  E hinger  J  Hays  A  T orralba and A  O li v a   SUN database Exploring a large collection of scene categories Int J Comput Vis  vol 119 no 1 pp 3–22 2014  L  Bo and C  S m i nchis e s c u E f  cient m atch k e r n el betw een s e ts of features for visual recognition in Proc NIPS  2009 pp 135–143  J  W a ng J  Y a ng K  Y u  F  L v  T  H u ang and Y  G ong L ocalityconstrained linear coding for image classiﬁcation in Proc CVPR  2010 pp 3360–3367  H Hu G  T  Z hou Z  Deng Z  L i ao a nd G Mori  L earning s t ructured inference neural networ ks with label relations in Proc CVPR  Jun 2016 pp 2960–2968  K  S i m o n y an and A  Z is s e r m an  V e r y deep con v olutional n etw o r k s f or large-scale image recognition in Proc ICLR  2015 A v a ilable https://arxiv.org/abs/1409.1556  S  Y a ng and D  R am anan  Multi-s cale r ecognition w ith D A G CN N s   in Proc ICCV  2015 pp 1215–1223  M D Dixit a nd N V a s c oncelos   Object based scene representations using Fisher scores of local subspace projections in Advances In Neural Information Processing Systems  vol 29 D D Lee M Sugiyama U V Luxburg I Guyon and R Garnett Eds Red Hook NY USA Curran Associates Inc 2016 pp 2811–2819 Xinhang Song received the B.S degree from the School of Computer and Information Technology Beijing Jiaotong University Beijing China in 2011 He is currently pursuing the Ph.D degree in computer science with the Key Laboratory of Intelligent Information Processing Institute of Computing Technology Chinese Academy of Sciences Beijing His current research interests include image processing large-scale image retrieval image semantic understanding multimedia content analysis computer vision and pattern recognition Shuqiang Jiang SM’08 is currently a Professor with the Institute of Computing Technology Chinese Academy of Sciences and also a Professor with the University of CAS He is also with the Key Laboratory of Intelligent Information Processing CAS His current research interests include multimedia processing and semantic understanding pattern recognition and computer vision He has authored or co-authored over 100 papers on the related research topics He was supported by the New-Star program of Science and Technology of Beijing Metropolis in 2008 the NSFC Excellent Young Scientists Fund in 2013 and the Young top-notch talent of Ten Thousand Talent Program in 2014 He is a Senior Member of the CCF and a member of the ACM He received the Lu Jiaxi Young Talent Award from Chinese Academy of Sciences in 2012 and the CCF Award of Science and Technology in 2012 He was the General Chair of ICIMCS 2015 the Program Chair of ICI MCS2010 the Special Session Chair of PCM2008 and ICIMCS2012 the Area Chair of PCIVT2011 the Publicity Chair of PCM2011 the Web Chair of ISCAS2013 and the Proceedings Chair of MMSP2011 He has also a TPC member for about 20 well-known conferences including the ACM Multimedia  CVPR ICCV ICME ICIP and PCM He is an Associate Editor of the IEEE Multimedia Multimedia Tools and Applications He is also the Vice Chair of the IEEE CASS Beijing Chapter the Vice Chair of the ACM SIGMM China chapter Luis Herranz received the Ingeniero de Telecomunicación degree from the Universidad Politécnica de Madrid Madrid Spain in 2003 and the Ph.D degree in computer science and telecommunication from the Universidad Autónoma de Madrid in 2010 From 2003 to 2010 he was with the Escuela Politécnica Superior of the Universidad Autónoma de Madrid as a Researcher and a Teaching Assistant From 2010 to 2011 he was with Mitsubishi Electric Research And Development Center Europe U.K He is currently a Post-Doctoral Research Fellow with the Institute of Computing Technology Chinese Academy of Sciences Beijing China His current research interests include multimedia signal processing content summarization and adaptation multimedia indexing and retrieval and scene recognition 


2332-7790 \(c This article has been accepted for publication in a future issue of this\ journal, but has not been fully edited. Content may change prior to fin\al publication. Citation information: DOI 10.1109/TBDATA.2017.2680460, I\EEE Transactions on Big Data A 16 a b c particles nonthe quality aluated ely 224non-testable\224 approach are system be the to The uilding its more and MRs enough alidated R D W K quality data ork and data scienti\002c learning In topics poor prediction utes and detail timeliness metadata accuauditability  Gao Xie and T ao ha v e gi v en an o v ervie w of the issues of data where the y de\002ned big data quality assurance techniques Although for the health eb orthiy such history source and sources information Finding the duplicated information quality as for duplication Data 002ltering is an approach data Samza which is adopted and al an electronic proposed using learning training reduce the algorithm data poor data Due to the massi v e scale of big data automated choice learning grated easily data for domain task The process is to reduce the irrele v ant performance selection correlation predict CFS 
 


2332-7790 \(c This article has been accepted for publication in a future issue of this\ journal, but has not been fully edited. Content may change prior to fin\al publication. Citation information: DOI 10.1109/TBDATA.2017.2680460, I\EEE Transactions on Big Data A 17 for images In this practical based in images  Ho w the feature selection w ould impact the classi\002cation reported  More adv anced feature selection approaches such as the in can be introduced into the frame w ork e images samin images challenge to problem  Man y dif ferent approaches ha v e been proposed to address as results the are Ho we v er  none of these that most eloping MRs 12 Metamorphic testing w as 002rst Chen al  for testing non-testable systems bioinformatics sysaultrelations A recent has compilers  Metamorphic testing has been applied for testi ng a lar ge ASA and also successfully engines Baidu Ho we v er  the quality of reported are w information In this paper  metamorphic in results w are tests xity SUT  Combinatorial technique 53 used for testing softw are for are C N the learning were to classi\002cation the for confusion learning important it data our data techniques A T King and xperi#1262933 e Corporation research R S  V  Gudi v ada R Raeza-Y ates and V  Ragha v an 223Big data Promises and 224 Computer 2015  Y  Bengio 223Learning deep architectures for ai 224 ends Learning 2009  Apache 2016 Hadoop Online A v ailable http://hadoop.apache.or g  V  Gudi v ada D Rao and V  Ragha v an 223Renaissance in database 224 IEEE Computer 2016  J Zhang Y  Feng M S Moran J Lu L Y ang al of 224 ess 2013  R M and T  Poggio 223Models of object recognition 224 oscience 2000  K Jacobs  J Lu and X Hu 223De v elopment of a dif f raction imaging 224 Lett 2009  2016 Adda project Online A v ailable https://github com/addateam adda  T  Y  Chen S C Cheung and S Y iu 223Metamorphic testing a ne w CS98and 1998  J Ding D Zhang and X Hu 223 An application of metamorphic testing in metamorphic ICSE 2016  U Kane w ala and J M Bieman 223T esting scienti\002c softw are A system\224 gy 56 2014  S Se gura G Fraser  A Sanchez and A Ruiz-Cort 264 on 224 Engineering  2016  2016 Mongodb  Online A v ailable https://www mongodb com  2016 Mongochef Online A v ailable http://3t.io/mongochef  M Y urkin and A Hoekstra 2014 User manual for the discrete 1.3b4 A v ailable https team/adda/tree/master/doc  C Hsu C.-C Chang and C.-J Lin 223 A practical guide to support v ector 2003  Y  LeCun Y  Bengio and G Hinton 223Deep learning 224 e 521 2015  R Haralick 223On a te xture-conte xt feature e xtract ion algorithm for in Society ol 650\226 657 
 


2332-7790 \(c This article has been accepted for publication in a future issue of this\ journal, but has not been fully edited. Content may change prior to fin\al publication. Citation information: DOI 10.1109/TBDATA.2017.2680460, I\EEE Transactions on Big Data A 18  K Dong Y  Feng K Jacobs J Lu R Brock al 223Label-free 224 Biomed ess 2011  R M Haralick K Shanmug an and I H Dinstein 223T e xtural features 224 Cybern SMC-3 1973  S K Thati J Ding D Zhang and X Hu 223Feature selection and analin ion ance 2015  J Dixon and J Ding 223 An empirical study of parallel solution for glcm 2016  T  Kanungo D Mount N Netan yahu C Piatk o R Silv erman and im\224 hine ence 2012  M A Hall 223Correlation-based feat ure selection for machine learning 224 wzealand 1999  A Krizhe vsk y  I Sutsk e v er  and G E Hinton 223Imagenet classi\002cain al systems and 1097\2261105  E Gibne y  223Google ai algorithm masters ancient g ame of go 224 e   M Moran 223Correlating the morphological and light scattering prop 2013  R P an Y  Feng Y  Sa J Lu K Jacobs and X Hu 223 Analysis 224 ess  2014  X Y ang Y  Feng Y  Liu N Zhang L W ang al e fraction 224 ess 7 2014  M Zhang 223 A deep learning based classi\002cation of lar ge scale biomed2016  Y  Feng N Zhang K Jacobs W  Jiang L Y ang al 223Polarization w 224 A 2014  C.-C Chang and C.-J Lin 2016 Libsvm Online A v ailable csie.ntu.edu.tw 030 cjlin/libsvm  2016 Caf fe project Online A v ailable http://caf fe.berk ele yvision.or g  J Mayer and R  Guderlei 223 An empirical study on the selection of good in e C06 475\226484  U Kane w ala J M Bieman and A Ben-Hur  223Predicting metamorphic approach 224 and Reliability 2015  J Ding T  W u J Q Lu and X Hu 223Self-check ed metamorphic testing in on vement apore 2010  W  E W ong and A Mathur  223Reducing the cost of mutati on testing 224 e pp 1995  Y  Jia and M Harman 223 An anal ysis and surv e y of the de v elopment of 224  649\226678 2011  L Cai and Y  Zhu 223The challenges of data quality and data quality 224 ournal 1 2015  J Gao C Xi e and C T ao 223Big data v alidation and quality assurance in Service\(SOSE 433\226441  X Dong E Gabrilo vich K Murph y  V  Dang W  Horn C Lug aresi 224  938\226949 2015  X Y in J Ha n and P  S Y u 223T ruth disco v ery with multiple con\003icting 224 Data  2008  C H W u and Y  Song 223Rob ust and distrib uted web-scale near dup in IEEE Data 2606\226 2611  2016 Apache samza Online A v ailable http://samza.apache.or g  J A Saez B Kra wczyk and M W ozniak 223On the in\003uence of class 002ltering 224 ence 590\226609 2016  M Y ousef D S D M 250 223Feature for 224 bioinformatics 2016  F  Min Q Hu and W  Zhu 223Feature sel ection with test cost constraint 224 Reasoning 167\226 2014  H A L Thi H M Le and T  P  Dinh 223Feature selection in machine function 224 Learning 2015  H Liu F C K uo D T o we y  and T  Chen 223Ho w ef fecti v ely does problem?\224 on Engineering 2014  V  Le M  Afshari and Z Su 223Compiler v alidation via equi v alence in amming on Kingdom 216\226226  M Lindv all D Ganesan R rdal and R E W ie g and 223Metamorphic in 37th Engineering 129\226 138  Z Zhou S Xiang and T  Chen 223Metamorphic testing for softw are 224 e Engineering 2016  C Nie and H Leung 223 A surv e y of combinatorial testing 224 CM y 2011 CE O HERE Ding Computer has Computer in Nanjing 2004 r ed His the He by CM Hu  ada East  
 


2169-3536 \(c http://www.ieee.org/publications_standards/publications/rights/index.htm\l for more information This article has been accepted for publication in a future issue of this\ journal, but has not been fully edited. Content may change prior to fin\al publication. Citation information: DOI 10.1109/ACCESS.2017.2697839, IEEE Access   19     en-US  en-US  en-US  en-US 52 en-US  en-US  en-US  en-US en-US e en-US ti en-US en-US  en-US  en-US en-US  en-US 4 en-US en-US  en-US  en-US  en-US 53 en-US  en-US  en-US  en-US en-US  en-US  en-US DA en-US en-US  en-US  en-US  en-US  en-US 54 en-US  en-US  en-US  en-US en-US e en-US n en-US  en-US en-US  en-US v en-US en-US  en-US  en-US  en-US 55 en-US  en-US  en-US  en-US en-US k en-US en-US thm en-US en-US  en-US ron en-US  en-US 0 en-US en-US  en-US  en-US 5 en-US 6 en-US  en-US  en-US  en-US en-US  en-US  en-US  en-US en-US n en-US  en-US  en-US  en-US 57 en-US  en-US  en-US  en-US en-US ti en-US en-US T en-US  en-US n en-US en-US  en-US  en-US  en-US  en-US  en-US 58 en-US  en-US  en-US  en-US en-US  en-US Pre en-US en-US  en-US t en-US en-US  en-US  en-US en-US  en-US  en-US  en-US 3 en-US en-US 1 en-US  en-US  en-US  en-US 59 en-US  en-US  en-US t en-US  en-US  en-US n en-US en-US  en-US  en-US en-US  en-US OS en-US  en-US 2 en-US en-US  en-US  en-US  en-US 60 en-US  en-US  en-US  en-US en-US  en-US ti en-US  en-US t en-US en-US  en-US 4 en-US en-US  en-US  en-US  en-US 61 en-US  en-US  en-US  en-US en-US  en-US  en-US en-US ess en-US  en-US  en-US 0 en-US en-US  en-US  en-US  en-US 62 en-US  en-US  en-US  en-US en-US X en-US en-US ng en-US en-US s en-US  en-US en-US  en-US  en-US i    en-US x en-US en-US e en-US en-US i en-US en-US r en-US en-US is en-US en-US 2 en-US en-US Dec en-US en-US 6  en-US  en-US  en-US 63 en-US  en-US  en-US i en-US  en-US en-US  en-US  en-US en-US h en-US i   Av a i l a bl e   en-US e en-US en-US is en-US en-US ng en-US en-US a en-US en-US nd en-US en-US b en-US en-US r en-US en-US the en-US en-US net en-US en-US of en-US en-US 0 en-US en-US Dec en-US en-US 6  en-US  en-US  en-US 64 en-US  en-US  en-US BI en-US en-US  en-US en-US e en-US  en-US  en-US en-US er en-US  en-US i    en-US du en-US en-US es en-US en-US new en-US en-US ai en-US en-US nd en-US en-US net en-US en-US of en-US en-US s en-US en-US ves en-US en-US 6 en-US en-US 0 en-US en-US Dec en-US en-US 6  en-US  en-US  en-US 65 en-US  en-US  en-US  en-US en-US Su en-US  en-US  en-US en-US a en-US  en-US 9 en-US en-US  en-US  en-US  en-US  en-US 66 en-US  en-US  en-US  en-US  en-US en-US  en-US  en-US en-US s en-US  en-US  en-US  en-US  en-US 67 en-US  en-US  en-US  en-US en-US  en-US a en-US en-US ve en-US en-US a en-US  en-US 383 en-US en-US  en-US  en-US  en-US 68 en-US  en-US  en-US  en-US en-US  en-US  en-US en-US  en-US ess en-US  en-US 7 en-US en-US  en-US  en-US  en-US 69 en-US  en-US  en-US  en-US en-US  en-US vey en-US en-US  en-US ri en-US s en-US  en-US 77 en-US en-US  en-US  en-US  en-US 70 en-US  en-US  en-US  en-US en-US  en-US  en-US en-US  en-US  en-US  en-US 1 en-US en-US  en-US  en-US  en-US 71 en-US  en-US  en-US o en-US  en-US  en-US ne en-US en-US  en-US  en-US  en-US 5 en-US en-US  en-US  en-US  en-US 72 en-US  en-US  en-US  en-US en-US  en-US n en-US e en-US  en-US en-US  en-US n en-US  en-US 6 en-US en-US  en-US  en-US  en-US 73 en-US  en-US  en-US  en-US en-US  en-US  en-US hy en-US  en-US en-US  en-US n en-US  en-US 6 en-US en-US  en-US  en-US  en-US 74 en-US  en-US  en-US  en-US en-US  en-US t en-US en-US I en-US  en-US  en-US  en-US 5 en-US en-US  en-US  en-US  en-US 75 en-US  en-US  en-US  en-US en-US  en-US ty en-US en-US  en-US en-US  en-US f en-US en-US  en-US  en-US  en-US  en-US 76 en-US  en-US  en-US a en-US  en-US en-US ti en-US en-US  en-US  en-US en-US  en-US  en-US  en-US 96 en-US en-US  en-US  en-US  en-US 77 en-US  en-US  en-US  en-US en-US  en-US n en-US en-US 0 en-US 8 en-US en-US  en-US  en-US ess en-US  en-US 85 en-US en-US  en-US  en-US  en-US 78 en-US  en-US  en-US  en-US en-US  en-US n en-US en-US  en-US  en-US  en-US  en-US  en-US 79 en-US  en-US  en-US hen en-US  en-US  en-US en-US  en-US  en-US  en-US en-US  en-US  en-US  en-US 4 en-US en-US  en-US  en-US  en-US 80 en-US  en-US  en-US  en-US en-US ng en-US en-US  en-US  en-US  en-US en-US s en-US  en-US  en-US 6 en-US en-US  en-US  en-US  en-US 81 en-US  en-US  en-US N en-US  en-US  en-US en-US  en-US  en-US en-US 2011 en-US  en-US  en-US 1 en-US en-US  en-US  en-US  en-US 82 en-US  en-US  en-US  en-US  en-US en-US o en-US  en-US  en-US en-US 2011 en-US  en-US  en-US 1 en-US en-US  en-US  en-US  en-US 83 en-US  en-US  en-US  en-US en-US  en-US s en-US  en-US  en-US  en-US  en-US 9 en-US en-US  en-US  en-US  en-US 84 en-US  en-US  en-US  en-US en-US  en-US en-US  


2169-3536 \(c http://www.ieee.org/publications_standards/publications/rights/index.htm\l for more information This article has been accepted for publication in a future issue of this\ journal, but has not been fully edited. Content may change prior to fin\al publication. Citation information: DOI 10.1109/ACCESS.2017.2697839, IEEE Access  20      en-US  en-US en-US  en-US  en-US  en-US 4 en-US en-US  en-US  en-US  en-US 85 en-US  en-US  en-US F en-US  en-US en-US  en-US  en-US en-US  en-US 0 en-US  en-US 5 en-US en-US  en-US  en-US  en-US 86 en-US  en-US  en-US h en-US  en-US  en-US l en-US en-US  en-US en-US  en-US  en-US  en-US  en-US 1 en-US en-US  en-US  en-US  en-US 87 en-US  en-US  en-US  en-US en-US ti en-US en-US  en-US  en-US d en-US en-US  en-US  en-US  en-US 1 en-US en-US  en-US  en-US  en-US 88 en-US  en-US  en-US  en-US  en-US en-US  en-US  en-US en-US  en-US 6 en-US  en-US 263 en-US en-US  en-US  en-US  en-US 89 en-US  en-US  en-US  en-US en-US tem en-US en-US OTA en-US  en-US 6 en-US  en-US 6 en-US en-US  en-US  en-US  en-US  en-US 90 en-US  en-US  en-US  en-US en-US  en-US  en-US en-US  en-US m en-US  en-US 87 en-US en-US  en-US  en-US  en-US  en-US 91 en-US  en-US  en-US e en-US  en-US  en-US en-US  en-US  en-US en-US  en-US m en-US  en-US 87 en-US en-US  en-US  en-US  en-US  en-US 92 en-US  en-US  en-US  en-US en-US  en-US a en-US  en-US  en-US  en-US  en-US  en-US 1 en-US en-US  en-US  en-US  en-US 93 en-US  en-US  en-US  en-US en-US  en-US r en-US en-US  en-US  en-US en-US  en-US 195 en-US en-US  en-US  en-US  en-US 94 en-US  en-US  en-US Wei en-US en-US xi en-US ng en-US en-US eng en-US en-US  en-US en-US  en-US k en-US en-US to en-US en-US  en-US  en-US en-US ess en-US  en-US 1 en-US en-US  en-US  en-US  en-US 95 en-US  en-US  en-US  en-US en-US  en-US c en-US r en-US en-US  en-US  en-US en-US  en-US  en-US 1 en-US en-US  en-US  en-US  en-US 96 en-US  en-US  en-US  en-US en-US  en-US  en-US en-US r en-US  en-US  en-US 9 en-US en-US  en-US  en-US  en-US 97 en-US  en-US  en-US  en-US  en-US  en-US en-US e en-US en-US  en-US r en-US en-US  en-US  en-US en-US  en-US en-US  en-US  en-US  en-US  en-US m en-US en-US s en-US en-US 3 en-US  en-US 3 en-US en-US  en-US  en-US  en-US 98 en-US  en-US  en-US a en-US en-US  en-US en-US  en-US ter en-US en-US  en-US  en-US en-US l en-US  en-US  en-US  en-US  en-US 99 en-US  en-US  en-US a en-US  en-US en-US  en-US  en-US  en-US en-US  en-US BE en-US  en-US 1 en-US en-US  en-US  en-US  en-US 0 en-US  en-US  en-US  en-US e en-US  en-US  en-US  en-US  en-US 1 en-US  en-US  en-US e en-US en-US  en-US ter en-US en-US  en-US  en-US  en-US  en-US 2 en-US  en-US  en-US e en-US en-US  en-US ter en-US en-US the en-US  en-US  en-US  en-US  en-US 3 en-US  en-US  en-US  en-US en-US  en-US ter en-US en-US  en-US ti en-US en-US n en-US en-US  en-US n en-US  en-US 3 en-US en-US  en-US  en-US  en-US  en-US 4 en-US  en-US  en-US  en-US en-US  en-US  en-US  en-US en-US  en-US  en-US  en-US  en-US 5 en-US  en-US  en-US  en-US en-US  en-US th en-US  en-US  en-US ter en-US en-US  en-US  en-US en-US s en-US  en-US 7 en-US en-US  en-US  en-US  en-US 6 en-US  en-US  en-US en en-US en-US  en-US n en-US  en-US  en-US en-US 4 en-US  en-US 4 en-US en-US  en-US  en-US  en-US 7 en-US  en-US  en-US e en-US en-US  en-US  en-US  en-US en-US  en-US  en-US  en-US 4 en-US en-US  en-US  en-US  en-US 8 en-US  en-US  en-US  en-US en-US  en-US ter en-US en-US  en-US tem en-US en-US  en-US  en-US  en-US 1 en-US en-US  en-US  en-US  en-US 9 en-US  en-US  en-US  en-US  en-US en-US  en-US a en-US en-US  en-US en-US  en-US S en-US  en-US en-US  en-US  en-US  en-US  en-US  en-US 0 en-US  en-US  en-US  en-US  en-US  en-US en-US ter en-US en-US  en-US  en-US en-US  en-US  en-US  en-US 72 en-US en-US  en-US  en-US  en-US 1 en-US  en-US  en-US  en-US en-US  en-US en-US  en-US n en-US en-US a en-US  en-US 5 en-US en-US  en-US  en-US  en-US 2 en-US  en-US  en-US W en-US  en-US en-US  en-US  en-US nty en-US en-US  en-US ON en-US  en-US 1 en-US en-US  en-US  en-US  en-US 3 en-US  en-US  en-US  en-US en-US  en-US Se en-US  en-US en-US  en-US l en-US  en-US 334 en-US en-US  en-US  en-US  en-US 4 en-US  en-US  en-US  en-US en-US  en-US  en-US  en-US en-US Int en-US en-US y en-US  en-US  en-US  en-US 249 en-US en-US  en-US  en-US  en-US 5 en-US  en-US  en-US  en-US en-US  en-US  en-US  en-US en-US  en-US en-US  en-US d en-US en-US  en-US 1 en-US 1 en-US 52 en-US en-US  en-US  en-US  en-US 6 en-US  en-US  en-US  en-US en-US  en-US  en-US te en-US en-US  en-US  en-US  en-US 7 en-US  en-US  en-US  en-US en-US  en-US  en-US  en-US  en-US en-US r en-US  en-US 34 en-US en-US  en-US  


2169-3536 \(c http://www.ieee.org/publications_standards/publications/rights/index.htm\l for more information This article has been accepted for publication in a future issue of this\ journal, but has not been fully edited. Content may change prior to fin\al publication. Citation information: DOI 10.1109/ACCESS.2017.2697839, IEEE Access   21     en-US  en-US 8 en-US  en-US  en-US  en-US en-US  en-US  en-US en-US  en-US  en-US  en-US  en-US 9 en-US  en-US  en-US  en-US en-US i en-US  en-US  en-US en-US  en-US  en-US  en-US  en-US 0 en-US  en-US  en-US  en-US en-US  en-US  en-US  en-US en-US s en-US  en-US  en-US  en-US 2 en-US en-US  en-US  en-US  en-US 1 en-US  en-US  en-US  en-US en-US  en-US  en-US en-US  en-US  en-US 1 en-US 77 en-US en-US  en-US  en-US  en-US 2 en-US  en-US  en-US  en-US en-US d en-US en-US a en-US en-US  en-US  en-US  en-US en-US  en-US  en-US  en-US 2 en-US en-US  en-US  en-US  en-US 3 en-US  en-US  en-US o en-US  en-US en-US  en-US  en-US en-US s en-US  en-US 0 en-US en-US  en-US  en-US  en-US  en-US 4 en-US  en-US  en-US  en-US en-US  en-US  en-US en-US s en-US  en-US  en-US 0 en-US en-US  en-US  en-US  en-US 5 en-US  en-US  en-US  en-US  en-US en-US  en-US  en-US  en-US en-US  en-US  en-US  en-US  en-US  en-US 3 en-US en-US  en-US  en-US  en-US 6 en-US  en-US  en-US  en-US en-US  en-US en-US a en-US  en-US 321 en-US en-US  en-US  en-US  en-US 7 en-US  en-US  en-US K en-US en-US t en-US en-US  en-US en-US  en-US  en-US s en-US en-US dy en-US en-US matics en-US  en-US  en-US  en-US  en-US 8 en-US  en-US  en-US  en-US  en-US res en-US  en-US  en-US  en-US 9 en-US  en-US  en-US R en-US n en-US en-US  en-US en-US  en-US  en-US en-US  en-US  en-US 5 en-US en-US  en-US  en-US  en-US  en-US 0 en-US  en-US  en-US n en-US en-US  en-US en-US n en-US  en-US  en-US  en-US en-US  en-US  en-US 5 en-US en-US  en-US  en-US  en-US  en-US 1 en-US  en-US  en-US  en-US en-US  en-US  en-US  en-US en-US  en-US en-US  en-US  en-US  en-US man en-US en-US  en-US  en-US 3 en-US en-US  en-US  en-US  en-US 2 en-US  en-US  en-US  en-US en-US  en-US en-US  en-US d en-US en-US s en-US 2 en-US  en-US 46 en-US en-US  en-US  en-US  en-US 3 en-US  en-US  en-US  en-US en-US ti en-US en-US ti en-US en-US  en-US n en-US en-US n en-US  en-US 1 en-US en-US  en-US  en-US  en-US 4 en-US  en-US  en-US  en-US en-US  en-US  en-US n en-US en-US n en-US  en-US  en-US  en-US  en-US 5 en-US  en-US  en-US  en-US en-US  en-US en-US 2 en-US  en-US ron en-US  en-US 351 en-US en-US  en-US  en-US  en-US 6 en-US  en-US  en-US  en-US en-US Semi en-US en-US  en-US  en-US en-US  en-US S en-US s en-US en-US  en-US  en-US  en-US 2 en-US en-US  en-US  en-US  en-US  en-US 7 en-US  en-US  en-US  en-US en-US  en-US  en-US en-US  en-US  en-US  en-US 5 en-US en-US  en-US  en-US  en-US 8 en-US  en-US  en-US  en-US en-US ex en-US  en-US  en-US en-US  en-US  en-US  en-US  en-US  en-US 9 en-US  en-US  en-US nt en-US en-US  en-US en-US  en-US  en-US a en-US  en-US en-US  en-US r en-US  en-US 7 en-US en-US  en-US  en-US  en-US 0 en-US  en-US  en-US  en-US en-US  en-US n en-US en-US EEE en-US  en-US 6 en-US en-US  en-US  en-US  en-US 1 en-US  en-US  en-US  en-US  en-US en-US  en-US  en-US  en-US en-US s en-US  en-US 7 en-US en-US  en-US  en-US  en-US 2 en-US  en-US  en-US  en-US en-US ti en-US en-US  en-US n en-US  en-US en-US  en-US  en-US  en-US  en-US  en-US 3 en-US  en-US  en-US  en-US en-US ene en-US en-US  en-US  en-US en-US  en-US  en-US  en-US 7 en-US en-US  en-US  en-US 4 en-US  en-US  en-US en-US  en-US ti en-US en-US  en-US en-US  en-US  en-US 8 en-US en-US  en-US  en-US  en-US 5 en-US  en-US  en-US  en-US en-US i en-US  en-US  en-US en-US  en-US dy en-US en-US  en-US n en-US y en-US en-US  en-US  en-US  en-US 6 en-US  en-US  en-US  en-US en-US k en-US en-US to en-US en-US  en-US  en-US en-US IE en-US  en-US  en-US 0 en-US en-US  en-US  en-US  en-US  en-US 7 en-US  en-US  en-US  en-US en-US  en-US ter en-US en-US n en-US en-US  en-US l en-US en-US  en-US en-US  en-US  en-US  en-US  en-US  en-US 9 en-US en-US  en-US  en-US  en-US 8 en-US  en-US  en-US  en-US  en-US  en-US n en-US en-US  en-US en-US  en-US  en-US  en-US 7 en-US en-US  en-US  en-US  en-US 9 en-US  en-US  en-US  en-US en-US k en-US en-US to en-US en-US  en-US the en-US  en-US en-US  en-US  en-US 4 en-US en-US  en-US  en-US  en-US  en-US 0 en-US  en-US  en-US  en-US en-US  en-US n en-US en-US  


2169-3536 \(c http://www.ieee.org/publications_standards/publications/rights/index.htm\l for more information This article has been accepted for publication in a future issue of this\ journal, but has not been fully edited. Content may change prior to fin\al publication. Citation information: DOI 10.1109/ACCESS.2017.2697839, IEEE Access  22      en-US Inte en-US  en-US  en-US 132 en-US en-US  en-US  en-US  en-US 1 en-US  en-US  en-US  en-US en-US k en-US en-US to en-US en-US n en-US en-US  en-US I en-US en-US  en-US  en-US  en-US 69 en-US en-US 8 en-US  en-US  en-US  en-US 2 en-US  en-US  en-US r en-US en-US  en-US en-US k en-US en-US to en-US en-US  en-US  en-US en-US r en-US  en-US 1 en-US en-US  en-US  en-US  en-US 3 en-US  en-US  en-US  en-US en-US t en-US en-US n en-US en-US n en-US  en-US  en-US 1 en-US en-US  en-US  en-US  en-US 4 en-US  en-US  en-US  en-US en-US  en-US  en-US i   en-US m en-US  en-US  en-US 5 en-US  en-US  en-US  en-US  en-US en-US k en-US en-US to en-US en-US  en-US tr en-US  en-US n en-US en-US  en-US  en-US 7 en-US en-US  en-US  en-US  en-US 6 en-US  en-US  en-US  en-US en-US  en-US en-US a en-US i   en-US d en-US en-US a en-US en-US c en-US en-US es en-US 2 en-US en-US n en-US en-US 7  en-US  en-US  en-US 7 en-US  en-US  en-US  en-US en-US  en-US  en-US en-US  en-US dy en-US en-US  en-US n en-US y en-US en-US  en-US  en-US  en-US 8 en-US  en-US  en-US  en-US  en-US en-US  en-US vey en-US en-US  en-US  en-US 13 en-US en-US  en-US  en-US  en-US 9 en-US  en-US  en-US  en-US en-US  en-US  en-US en-US  en-US  en-US  en-US  en-US  en-US 0 en-US  en-US  en-US  en-US  en-US  en-US en-US  en-US  en-US n en-US en-US  en-US n en-US  en-US  en-US  en-US 1 en-US  en-US  en-US  en-US en-US  en-US  en-US en-US 2010 en-US  en-US  en-US 7 en-US en-US  en-US  en-US  en-US 2 en-US  en-US  en-US  en-US en-US  en-US o en-US n en-US en-US  en-US  en-US  en-US  en-US  en-US 3 en-US  en-US  en-US  en-US en-US  en-US  en-US en-US  en-US  en-US  en-US  en-US  en-US 4 en-US  en-US  en-US B en-US  en-US en-US A en-US ti en-US en-US  en-US  en-US en-US  en-US  en-US  en-US 6 en-US en-US  en-US  en-US  en-US 5 en-US  en-US  en-US e en-US en-US s en-US  en-US  en-US  en-US en-US  en-US n en-US  en-US 1 en-US en-US  en-US  en-US  en-US 6 en-US  en-US  en-US  en-US en-US  en-US f en-US en-US  en-US  en-US  en-US en-US  en-US  en-US  en-US  en-US  en-US 7 en-US  en-US  en-US  en-US en-US  en-US  en-US e en-US en-US  en-US  en-US  en-US 1 en-US 68 en-US  en-US  en-US  en-US en-US  en-US  en-US en-US  en-US  en-US  en-US  en-US 9 en-US  en-US  en-US  en-US en-US f en-US en-US  en-US ew en-US en-US e en-US  en-US  en-US  en-US 0 en-US  en-US  en-US  en-US en-US i en-US  en-US  en-US en-US  en-US n en-US  en-US  en-US  en-US 1 en-US  en-US  en-US  en-US en-US  en-US h en-US en-US er en-US i   Av a i l a bl e   en-US p en-US en-US ten en-US en-US hn en-US y en-US en-US ends en-US en-US l en-US en-US the en-US en-US l en-US en-US  en-US  en-US  en-US 2 en-US  en-US  en-US  en-US en-US  en-US en-US re en-US  en-US 6 en-US en-US  en-US  en-US  en-US 3 en-US  en-US  en-US  en-US en-US y en-US en-US  en-US e en-US en-US  en-US  en-US  en-US en-US  en-US  en-US 1 en-US en-US  en-US  en-US  en-US 4 en-US  en-US  en-US  en-US en-US  en-US en-US re en-US  en-US 6 en-US en-US  en-US  en-US  en-US 5 en-US  en-US  en-US  en-US  en-US en-US  en-US  en-US  en-US  en-US 6 en-US  en-US  en-US  en-US en-US  en-US en-US  en-US  en-US  en-US 1 en-US en-US  en-US  en-US  en-US 7 en-US  en-US  en-US  en-US en-US  en-US en-US t en-US  en-US earn en-US  en-US 9 en-US en-US  en-US  en-US  en-US 8 en-US  en-US  en-US  en-US en-US  en-US  en-US en-US  en-US  en-US  en-US 34 en-US en-US  en-US  en-US  en-US 9 en-US  en-US  en-US Lef en-US  en-US en-US  en-US  en-US ti en-US en-US  en-US en-US V en-US  en-US  en-US  en-US  en-US 0 en-US  en-US  en-US  en-US en-US  en-US  en-US en-US Pro en-US  en-US  en-US  en-US 34 en-US en-US  en-US  en-US  en-US 1 en-US  en-US  en-US  en-US en-US ng en-US en-US ti en-US en-US  en-US  en-US  en-US en-US  en-US 1 en-US en-US  en-US  en-US  en-US 2 en-US  en-US  en-US O en-US en-US M en-US  en-US en-US l en-US en-US  en-US  en-US en-US  en-US  en-US 1 en-US en-US  en-US  en-US  en-US 3 en-US  en-US  en-US  en-US en-US N en-US s en-US  en-US en-US  en-US  en-US 9 en-US en-US  en-US  en-US  en-US 4 en-US  en-US  en-US  en-US en-US  en-US  en-US to en-US en-US  en-US en-US n en-US  en-US  en-US  en-US 5 en-US  en-US  en-US D en-US  en-US  en-US en-US nt en-US en-US  en-US en-US  en-US en-US  en-US  en-US  en-US  en-US 6 en-US en-US  en-US 2 en-US en-US  en-US  en-US  en-US 6 en-US  en-US  en-US  en-US en-US edes en-US  en-US  en-US en-US  en-US  en-US  en-US  en-US  en-US 7 en-US  en-US  en-US  en-US en-US t en-US  en-US en-US  en-US  


2169-3536 \(c http://www.ieee.org/publications_standards/publications/rights/index.htm\l for more information This article has been accepted for publication in a future issue of this\ journal, but has not been fully edited. Content may change prior to fin\al publication. Citation information: DOI 10.1109/ACCESS.2017.2697839, IEEE Access   23     en-US  en-US 22 en-US en-US  en-US  en-US  en-US 8 en-US  en-US  en-US  en-US en-US t en-US en-US  en-US vey en-US en-US  en-US  en-US ne en-US en-US  en-US  en-US  en-US 9 en-US  en-US  en-US  en-US en-US  en-US  en-US tbed en-US en-US  en-US en-US  en-US  en-US  en-US 5 en-US en-US  en-US  en-US  en-US  en-US 0 en-US  en-US  en-US  en-US G en-US  en-US en-US o en-US en-US  en-US en-US  en-US  en-US  en-US 0 en-US en-US  en-US  en-US  en-US 1 en-US  en-US  en-US e en-US en-US ent en-US en-US  en-US  en-US en-US  en-US  en-US  en-US  en-US 5 en-US en-US  en-US  en-US  en-US 2 en-US  en-US  en-US a en-US en-US z en-US en-US  en-US dez en-US en-US z en-US en-US  en-US en-US  en-US a en-US  en-US  en-US en-US  en-US 26 en-US en-US  en-US  en-US  en-US 3 en-US  en-US  en-US a en-US en-US a en-US en-US o en-US en-US  en-US a en-US en-US  en-US en-US o en-US en-US F en-US en-US  en-US  en-US en-US  en-US  en-US en-US  en-US  en-US  en-US  en-US 8 en-US en-US  en-US  en-US  en-US 4 en-US  en-US  en-US  en-US en-US ti en-US en-US  en-US  en-US  en-US en-US  en-US en-US  en-US 2015 en-US b en-US 5 en-US  en-US 9 en-US en-US  en-US  en-US  en-US  en-US 5 en-US  en-US  en-US o en-US en-US  en-US en-US  en-US  en-US en-US n en-US  en-US  en-US 45 en-US en-US  en-US  en-US  en-US 6 en-US  en-US  en-US  en-US en-US  en-US k en-US  en-US  en-US en-US  en-US  en-US  en-US 0 en-US en-US  en-US  en-US  en-US 7 en-US  en-US  en-US  en-US en-US  en-US  en-US en-US  en-US  en-US r en-US  en-US 86 en-US en-US  en-US  en-US  en-US 8 en-US  en-US  en-US  en-US en-US  en-US y en-US en-US by en-US en-US  en-US en-US  en-US s en-US  en-US 1 en-US en-US  en-US  en-US  en-US 9 en-US  en-US  en-US  en-US  en-US dez en-US en-US  en-US en-US n en-US en-US  en-US en-US  en-US n en-US y en-US en-US  en-US  en-US  en-US 0 en-US  en-US  en-US  en-US en-US  en-US tem en-US en-US  en-US ti en-US en-US ve en-US en-US  en-US  en-US  en-US  en-US  en-US 1 en-US  en-US  en-US  en-US en-US  en-US ty en-US en-US  en-US en-US  en-US  en-US  en-US 5 en-US  en-US 2 en-US en-US  en-US  en-US  en-US 2 en-US  en-US  en-US en en-US en-US  en-US  en-US  en-US en-US ess en-US  en-US 831 en-US en-US  en-US  en-US  en-US 3 en-US  en-US  en-US  en-US  en-US en-US ti en-US en-US  en-US ne en-US en-US  en-US e en-US en-US  en-US  en-US 26 en-US en-US  en-US  en-US  en-US  en-US 4 en-US  en-US  en-US  en-US en-US  en-US ve en-US  en-US  en-US en-US  en-US rk en-US  en-US 7 en-US en-US  en-US  en-US  en-US 5 en-US  en-US  en-US  en-US  en-US en-US Sy en-US  en-US  en-US en-US  en-US  en-US  en-US es en-US  en-US 1 en-US en-US  en-US  en-US  en-US 6 en-US  en-US  en-US  en-US  en-US  en-US r en-US rks en-US  en-US  en-US  en-US  en-US 7 en-US  en-US  en-US  en-US en-US  en-US  en-US en-US n en-US  en-US  en-US 9 en-US 0 en-US  en-US 411 en-US en-US  en-US  en-US  en-US 8 en-US  en-US  en-US  en-US en-US  en-US tems en-US en-US  en-US  en-US  en-US  en-US n en-US  en-US en-US  en-US v en-US es en-US  en-US  en-US 3 en-US en-US  en-US  en-US  en-US 9 en-US  en-US  en-US en en-US en-US  en-US  en-US en-US  en-US en-US  en-US  en-US  en-US 0 en-US  en-US  en-US m en-US en-US  en-US  en-US th en-US en-US  en-US en-US  en-US  en-US  en-US 7 en-US en-US  en-US  en-US  en-US 1 en-US  en-US  en-US  en-US en-US  en-US  en-US en-US  en-US  en-US  en-US 4 en-US en-US  en-US  en-US  en-US 2 en-US  en-US  en-US  en-US  en-US en-US  en-US  en-US en-US  en-US  en-US  en-US  en-US  en-US 3 en-US  en-US  en-US  en-US en-US ng en-US  en-US  en-US  en-US  en-US en-US  en-US  en-US 1 en-US en-US  en-US  en-US  en-US  en-US 4 en-US  en-US  en-US  en-US  en-US rk en-US  en-US  en-US  en-US  en-US 5 en-US  en-US  en-US  en-US en-US  en-US  en-US en-US  en-US  en-US  en-US 8 en-US en-US  en-US  en-US  en-US 6 en-US  en-US  en-US  en-US en-US  en-US  en-US en-US  en-US  en-US  en-US 1 en-US en-US  en-US  en-US  en-US 7 en-US  en-US  en-US  en-US en-US  en-US t en-US dy en-US en-US n en-US s en-US  en-US  en-US 9 en-US en-US  en-US  en-US  en-US 8 en-US  en-US  en-US  en-US en-US  


2169-3536 \(c http://www.ieee.org/publications_standards/publications/rights/index.htm\l for more information This article has been accepted for publication in a future issue of this\ journal, but has not been fully edited. Content may change prior to fin\al publication. Citation information: DOI 10.1109/ACCESS.2017.2697839, IEEE Access  24      en-US  en-US i en-US  en-US en-US  en-US  en-US 9 en-US  en-US 2 en-US en-US  en-US  en-US  en-US 9 en-US  en-US  en-US  en-US en-US  en-US n en-US en-US n en-US  en-US t en-US 7 en-US  en-US  en-US 5 en-US en-US  en-US  en-US  en-US 0 en-US  en-US  en-US  en-US  en-US en-US  en-US  en-US n en-US en-US E en-US ess en-US  en-US 858 en-US en-US  en-US  en-US  en-US 1 en-US  en-US  en-US  en-US en-US  en-US  en-US en-US ess en-US  en-US 1 en-US en-US  en-US  en-US  en-US  en-US 2 en-US  en-US  en-US  en-US  en-US en-US  en-US  en-US  en-US en-US  en-US  en-US 1 en-US en-US  en-US  en-US  en-US 3 en-US  en-US  en-US  en-US  en-US  en-US o en-US en-US  en-US en-US in en-US  en-US  en-US  en-US l en-US en-US  en-US g en-US  en-US 0 en-US en-US  en-US  en-US  en-US 4 en-US  en-US  en-US Ben en-US  en-US  en-US en-US  en-US  en-US en-US  en-US  en-US 7 en-US en-US  en-US  en-US  en-US 5 en-US  en-US  en-US  en-US en-US f en-US  en-US  en-US dy en-US en-US  en-US 11 en-US en-US  en-US  en-US  en-US 6 en-US  en-US  en-US  en-US  en-US en-US T en-US en-US  en-US o en-US  en-US en-US  en-US  en-US 1 en-US en-US  en-US  en-US  en-US 7 en-US  en-US  en-US z en-US en-US  en-US en-US ti en-US en-US  en-US  en-US  en-US en-US sort en-US  en-US  en-US 5 en-US  en-US  en-US  en-US 8 en-US  en-US  en-US z en-US en-US  en-US en-US  en-US f en-US en-US the en-US en-US  en-US  en-US en-US  en-US  en-US  en-US  en-US 121 en-US en-US  en-US  en-US  


