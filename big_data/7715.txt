2015 International Conference on Circuit, Power and Computing Technologies [ICCPCT  978-1-4799-7075-9/15/$31.00 \2512015 IEEE     Closed Frequent Itemsets mining over Data streams for Visualizing Network Traffic   M. Jeyasutha    Department of Computer Applications   St. Xavier\222s Catholic College of Engineering Nagercoil \226 629 003, India jayasuthaus@rediffmail.com   Dr. F. Ramesh Dhanaseelan  Prof. & Head, Department of Computer Applications St. Xavier\222s Catholic College of Engineering Nagercoil \226 629 003, India message_to_ramesh@yahoo.com Abstract  The main objective of Network monitoring is to understand the active events that happen frequently and can influence or ruin the network.  In this paper we have introduced an efficient method of Closed Frequent item set mining over data streams for visualizing these events. The proposed MFCI-SWI Mining Frequent Closed Item sets using Sliding Window with Intersection method\lgorithm processes the data stream for mining only when user requires Otherwise simply slides the window and receive the new transactions. Experimental evaluations on real datasets show that our proposed method outperforms recently proposed TMoment algorithm  Keywords: Data mining; Frequent Closed Itemsets Sliding windows; Trans-sequence representation  I. INTRODUCTION It is very difficult to implement efficient monitoring in real time, because of the varying and dynamic characteristics of network traffic including fast transfer, huge volume, shot-lived, and infinite Due to these challenges, a frequent pattern mining algorithm over data streams must scan every incoming transaction only once. Moreover, it must adapt itself to recent changes of incoming data stream. Furthermore, due to high speed and large amount of incoming data, algorithm must require a limited memory and processing time Frequent itemsets are the itemsets that come together frequently. Closed frequent itemsets are the itemsets whose superset does not have the same support count. Closed frequent itemsets require limited memory space while it contains the same information. Hence we have concentrated on mining closed frequent itemsets. Recently, a number of algorithms for mining closed itemsets and other type of compact representations of itemsets within data stream have been proposed [9 In the proposed algorithm, substring operation is used for window sliding and intersection method is used for mining frequent closed itemsets The proposed method is very efficient since it processes the data stream for mining only when user requires. Otherwise simply slides the window and receive the new transactions. Experimental evaluations show that MFCI-SWI has better runtime and consumes lower amount of memory with respect to recently developed TMoment algorithm. In the next section, some related works are reviewed Section 3 states the problem. In section 4, the proposed algorithm is introduced. Experimental results are presented in Section 5. Finally Section 6 concludes the paper II. RELATED WORK Mining frequent itemsets in data stream can be divided into three categories: landmark-window based mining, damped-window based mining and sliding-window based mining In a landmark window model, frequent pattern mining is performed based on the values between a specific timestamp called landmark and the present 1-4 th e da m p ed w i n d o w  m odel, rece n t  w i n d o w s are more important than previous ones [5-6 a sliding window model, knowledge discovery is performed over a fixed number of recently generated data elements which is the target of data mining [79 Moment is the first streaming algorithm to mine closed frequent itemsets within a transactionsensitive sliding window proposed by Chi et al An in-memory data structure called closed enumeration tree \(CET\aintains a dynamical set of itemsets which contains closed frequent itemsets and itemsets that form a boundary between closed frequent itemsets and the rest of the itemsets. In Moment, the exploration and node type checking are time consuming. The algorithm Stream_FCI[11  mines frequent closed itemsets from data streams using sliding window. It uses a DFP-tree with a head table. In processing each new transaction, the algorithm changes the head table and modifies the DFP-tree. The algorithm TMoment [12 u s es slid i n g  window model to find closed frequent itemsets. Data structure named TCET is used for storing and updating closed frequent itemsets of the window. In 


2015 International Conference on Circuit, Power and Computing Technologies [ICCPCT  this study, we have proposed an algorithm called MFCI-SWI for mining closed frequent itemsets within sliding window III. PROBLEM STATEMENT Let I={ i 1 i 2 i 3 205\205\205,i m be a set of distinct data items and a subset X I is called an itemset. A Transaction Data Stream TDS= {\(tid 1 t 1  tid 2 t 2  205.., \(tid n t n is infinite sequence of transactions where tid j is the transaction identifier and t j I j=1,2,\205..,n\s an itemset. The support sup\(X\ an itemset X is defined as the number of transactions with X as a subset. The itemset X is frequent if sup\(X min_sup, where min_sup is the minimum support threshold given by the user and it is in the range of [0,w  Sl i d i n g W i nd o w  SW i s d e fi ne d a s t h e  recent W number of transactions. In other words Sliding Window always contains constant number of transactions. In SW an item set X is closed, if it is frequent and it does not any superset with the same support count Example 1 let \247 = {A;B;C;D D ={CD;AB;ABC;ABC}, and s = 1/2 , then Frequent Itemsets are F = {\(A; 3\; \(B; 3\; \(C; 3\; \(AB; 3\; \(AC; 2\; \(BC; 2\; \(ABC; 2 Closed Frequent Itemsets are CFIs = {\(C; 3\; \(AB; 3\; \(ABC; 2    Fig.1. Processing a data stream using sliding window model IV. MFCI-SWI ALGORITHM In this section, we describe the proposed algorithm named MFCI-SWI. This algorithm is based on storing transactions in an efficient manner. The algorithm uses three hash tables each for storing bitsequence representation, trans-sequence representation and Frequent Closed Itemsets.  The hash table, which uses for storing bit sequence representation, is only used frequently. Others are used only when users require the output  A.  Bit-sequence representation of items In MFCI-SWI algorithm, for each item in the current sliding window, a bit-sequence with w bits denoted as bit\(X\nstructed. If an item X is in the ith transaction of current SW, the ith bit of bit\(X set to be 1; otherwise, it is set be 0. For example, the bit-sequence representation for the items in SW1 from the Fig.1 as bit\(A\=0111, bit\(B\0111 bit\(C\=1011 and bit\(D\=1000 B. Calculating support counts The support count for an itemset is calculated by counting the number of ones in bit-sequence representation of items. For example, in SW1 the support count for the item A is bit\(A\=0111=3, B is 3, C is 3 and D is 1. For every window sliding phase remove the item from the bit-sequence hash table if all the bit values are zero C. Trans-sequence representation of items Trans-sequence representation is formed only for the items which are having greater than or equal to the minimum support count values T ABLE 1  B IT SEQUENCES AND TRANS SEQUENCES OF ITEMS IN SW1 AND SW2 Wind ow id Transa ctions Bit-sequences of Items Trans-sequences of items SW 1 CD AB ABC ABC Bit\(A\=0111 Bit\(B\=0111 Bit\(C\=1011 Bit\(D\000 Trans-seq\(A Trans-seq\(B Trans-seq\(C Trans-seq\(D\=1 SW 2 AB ABC ABC BCE Bit\(A\=1110 Bit\(B\=1111 Bit\(C\=0111 Bit\(E\=0001 Trans-seq\(A Trans-seq\(B\=1234 Trans-seq\(C Trans-seq\(E\=4  Hence there is no need for forming trans-sequence for all the items in the current sliding window. Transsequence representation is the one which converts 1s from bit sequence form into their corresponding position in decimal representation. For example Bit\(A\ is written in Trans-sequence representation as Trans-sequence\(A\imilarly, Trans-sequence B\34, Trans-sequence\(C\=134 and Transsequence\(D D. Updating Closed Frequent Itemsets Hash Table  Initially the Hash Table for the closed frequent itemset contains frequent-1itemsets with values. Then for every intersection operation the values are updated as follows   


2015 International Conference on Circuit, Power and Computing Technologies [ICCPCT   Case \(i\ A=B A B Case \(ii\A B B Case \(iii A A Case \(iv\ IF A B  B A   Fig.2. Activities to be taken on various cases  For example, we are considering two items A=123 and B=12. From the Fig .2, the example falls on the case \(iii\ce the item B is deleted from the Hash table and AB is added E. Mining FCIs through intersecting items  Once the Trans-sequences of items are formed only the items whose support count value greater than or equal to the minimum support,  are considered for FCI generation. In SW1, Trans-seq\(A is intersected with Trans-seq\(B\ and Trans-seq\(c Trans-seq\(B\ is intersected only with Trans-seq\(c FIs\(AB\ = Trans-seq\(A Trans-seq\(B FIs\(AC\ran-seq\(A Trans-seq\(B FIs\(BC\ran-seq\(B Trans-seq\(C\ = 34 FIs\(ABC\ = Trans-seq\(A Trans-seq\(B Trans-seq\(C\=34 The algorithm uses three hash tables each for storing bit-sequences, trans-sequences and Frequent Closed Itemsets. The hash table for storing bitsequences is only used frequently. Others are used only when users wish to view the FCIs The hash table for FCIs is initially started with frequent 1-itemset values. Then for every, successive iteration values in the hash table are updated. Finally it contains only the frequent Closed Itemsets. For every intersection operation, base item with equal support count value of the resultant item is removed from the hash table and the resultant item which satisfies the minimum support count is added to the hash table Algorithm MFCI-SWI Mining Frequent Closed Itemsets over Data Stream using Sliding Window with Intersection  Input  Transaction Data Stream TDS Minimum Support count threshold in the range of [o,1  ms Sliding window size wsize  Output Set of Frequent Closed Itemsets FCIs  1  Read wsize and ms  2  Read wsize number of transactions  1For every transactions, form bit- sequences of every items 3  Get the user\222s choice whether they wish to view the FCIs If yes 1  Calculate the support count for every items 2  If  Support count >= ms then 1  store the item with its support count values in a hash table 2  Form the trans-sequences of items 3  Repeat Until there are no more transactions formed 1  For every trans-seq\(X\, form the intersecting itemsets with every other succeeding trans-seq\(Y\ items 1  If sup\(trans-seq\(X trans-seq\(Y ms\ then 1 Add the resultant itemset with its support  count values into a hash table  2. If trans-seq\(X\ = trans-seq\(y\ then  remove both items with its values from  the hash table 3  else if trans-seq\(X trans-seq\(Y\hen remove item X with its value from the hash table 4 else if trans-seq\(Y trans-seq\(X\ then remove item Y from the hash table 4  Display all the FCIs from the hash table 4  Remove the first bit for all items of bitsequences using substring method 5  If all the bit values are zero, remove the item from the hash table of bit-sequences 6  Repeat the steps through 3 to 5 for every new incoming transaction  Fig. 3 Algorithm MFCI-SWI    If A=B Delete A from the Hash table Delete B from the Hash table ADD AB into the Hash Table If B A Delete B from the Hash table Add AB into the hash table If A B Add AB into the hash table If A B Delete A from the Hash Table Add AB into the hash table 


2015 International Conference on Circuit, Power and Computing Technologies [ICCPCT  T ABLE 2  FCI  H ASH T ABLE CONTENTS FOR SINGLE ITEMSETS  Window id Transa c tions Bitsequences Transsequences FCI Hash table Contents SW 1 CD AB ABC ABC Bit\(A\=0111 Bit\(B\=0111 Bit\(C\=1011 Bit\(D\00 Transseq\(A\=234 Transseq\(B\=234 Transseq\(C\=134 Trans seq\(D  A: 3 B: 3 C: 3   TABLE 3.  FINAL HASH TABLE CONTENTS  Window id Transsequences for 2itemsets FCI Hash table Contents Transsequences for 3itemsets FCI Hash table Contents SW 1 Transseq\(AB\=234 Transseq\(AC\=34 Transseq\(BC\=34 A: 3  AB: 3 B: 3  AC: 2 C: 3 BC: 2 Trans-seq ABC 34 C: 3 BC:2  AB: 3 ABC: 2 AC 2  V. EVALUATING THE PERFORMANCE OF MFCI-SWI  In this section, we compare the performance of MFCI-SWI to recently proposed TMomen  algorithm. Two programs have been implemented using Java language in NetBeans IDE 6.0.1. The experiments were performed on a desktop computer with intel\256 core2duo CPU processor having 2GB main memory and running on windows XP. We have performed extensive experiment using several real and artificial datasets Fig. 4 shows the comparison of memory utilization and Fig. 5 shows the runtime performance with TMoment algorithm                Fig. 4. Comparisons of Memory utilization                   VI. CONCLUSION  In this study, we have introduced a new approach named MFCI-SWI for mining all closed frequent itemsets in the field of Network monitoring. Hash table based storage improves the efficiency as well as reduces the memory requirements. Intersecting only the minimum supported itemsets reduces the repeated scanning of the itemsets. Experimental evaluations on real and artificial datasets show that the proposed approach is better than previously proposed algorithms since it uses a lower memory and requires smaller time. Therefore, it is suitable for high speed and unbounded transactional data streams   REFERENCES  1  Manku, G.S., Motwani, R., \223Approximate frequency counts over data streams\224, In: Proceedings of the 28th international conference on very large data bases, pp. 346\226357, 2002 2  Hua-Fu Li, Suh-Yin Lee, Man-Kwan Shan, \223An efficient algorithm for mining frequent itemsets over the entire history of data streams\224, Proceeding of International Workshop on Knowledge Discovery in Data Streams, 2004 3  Hua-Fu Li, Suh-Yin Lee, Man-Kwan Shan, \224 Online Mining \(Recently\ Maximal Frequent Itemsets over Data Streams\224, Proceedings of the 15th International Workshop on Research Issues in Data Engineering: Stream Data Mining and Applications, 2005 4  Yu, J.X., Chong, Z., Lu, H., Zhang, Z., Zhou, A., \223A false negative approach to mining frequent itemsets from high speed transactional data streams\224, Information Sciences 176, 1986\2262015, 2006 5  Joong  Hyuk Chang, Won Suk Lee, \223 Finding recent frequent itemsets adaptively over online data streams\224, In proceedings of the ACM SIGKDD \(pp. 487 \226 492\ 2003 6  Giannella, C., Han, J., Pei., J., Yan, X., & Yu., P. S 223Mining frequent patterns in data streams at multiple time granularities\224,  In H. Kargupta, A. Joshi, K. Sivakumar Y.Yesha \(Eds.\, Data mining: Next generation challenges and future directions. AAAI/MIT, 2003 7  Chang-Hung Lee, Cheng-Ru Lin, Ming-Syan Chen, \223 Sliding window filtering: an efficient method for incremental mining on a time-variant database\224, Journal of Information Systems \(30\, 227\226244, 2005 8  JOONG HYUK CHANG, WON SUK LEE, \223 A sliding window method for finding recently frequent itemsets over 0 50 100 150 200 R u n t i m e  i n  S e c No. of transactions Runtime Performance MFCI-SWI TMoment Fig. 5. Comparisons of Runtime Performance 


2015 International Conference on Circuit, Power and Computing Technologies [ICCPCT  9  online data streams\224,  Journal of Information science and Engineering, 20, 753-762, 2004   Hua-Fu Li, Suh-Yin Lee, \223 Mining frequent itemsets over data streams using efficient window sliding techniques\224 Expert Systems with Applications 36, 1466\2261477, 2009   Chi, Y., Wang, H., Yu, P.S., Muntz, R.R., \223Catch the moment: maintaining closed frequent itemsets over a data stream sliding window\224, Knowledge and Information Systems 10 \(3\\226294, 2006   Keming Tang, Caiyan Dai, Ling Chen, \223A Novel Strategy for Mining Frequent Closed Itemsets in Data Streams\224 Journal of Computers. VOL. 7, NO. 7, 1564-1573, 2012   Fatemeh Nori, Mahmood Deypir, Mohamad Hadi Sadreddini, \223A sliding window based algorithm for frequent closed itemset mining over data streams\224, Journal of Systems and Software, Pages 615\226623, 2013   Li, H., Chen, H., \223Mining non-derivable frequent itemsets over data stream\224, Data and Knowledge Engineering 68 481\226498, 2009   Jiang, N., Gruenwald, L., \223CFI-stream: mining closed frequent itemsets in data streams\224, Proceedings of the SIGKDD\222, 2006   Liu, X., Guan, J., Hu, P., \223Mining frequent closed itemsets from a landmark window over online data streams\224 Computers and Mathematics with Applications 57 \(6\, 927\226 936, 2009    


  D.Y. Li, C.Y. Liu, and W.Y. Gan, “A New Cognitive Model: Cloud Model,” International Journal of Intelligent Systems, 2009, 24: 357–375   G.Y. Wang, “Generic normal cloud model,” Info. Sciences, 2014, 280 1–15   J.D. Alteringham, T. Macowat, and L. Hammond, “Bats: Biology and Behaviour,”  Oxford: Oxford Univesity Press, 1996  


Retail is a sparse dataset  consists of product sales data from retail stores Each transaction in the Retai dataset represents purchase information from one consumer at a time The details of the datasets are presented in gure 6 The programming language used to implement all the three algorithms is java and run in 3.3 GHz Intel processor 4 Gbyte memory and Windows 7 32bit OS Figs 7…9 show results of runtime experiments regarding the real and synthetic datasets shown in gure 6 In these gures we can observe that IHT-growth outperforms the others in all of the cases IHT-growth uses the proposed header tree structure to store the 1-frequent items instead of the older header table to minimize access times to search items As a result its advantages have a positive effect on reducing runtime in whole experiments Especially in the case of Retail dataset the difference of runtime between our algorithm and the others is much more than the other datasets  In all experiments FP-growth shows the worst performance Note that IHT-growth method can be used with any fptree mining to improve its ef“ciency We suggested here two methods to implement the new algorithm If we dont know the number of items in advance the First method is suggested In this experiments we used the second method By using the second method we can create a more ef“cient BSHTree because all the items with highest frequency will be appeared on the top of the BSHTree By using this method the run time can be improved by minimizing the searching time of items while sorting out the transactions VI CONCLUSION This study proposes an ef“cient transaction processing method during the transaction scanning time By applying the ef“cient binary search tree the mining time drastically reduced The new transaction sorting method is also improves the performance of mining The experimental results show that our algorithm outperforms the fp-growth and IFP-growth two well known and widely used algorithms Here we used a BSHTree after the rst scan to store the items with support count While using the BSHTree we used the actual names of items as keys This method can be applied to improve the mining process with any frequent itemset mining algorithm which is using a header table R EFERENCES  Jia wei H an Jian Pei and Y iwen Y in Mining Frequent P atterns without CandidateGeneration,SIGMOD 00 Proceedings of the 2000 ACM SIGMOD international conference on Management of data.Pages 1-12  Gw angb umPyun a Unil Y u n a  K eun Ho Ryu  E f cient frequent pattern mining based on Linear Pre“x tree Knowledge-Based Systems 55 2014 125…139  Y uh-JiuanTsay a T ain-Jung Hsu a Jing-Rung Y ub,FIUT  A n e w method for mining frequent itemsets,Information Sciences 179 2009 1724 1737  K e-Chung Lin I-En Liao  Zhi-Sheng Chen An impro v e d frequent pattern growth method for mining association rules Expert Systems with Applications 38 2011 5154…5161  F an-Chen Tseng An adapti v e approach to mining frequent itemsets ef“ciently Expert Systems with Applications 39 2012 13166…13172  R Agra w al T  Imielinski A.N Sw ami Mining association rules between sets of items in large databases in Proceedings of the ACMSIGMOD Conference on Management of Data pages 1993 pp 207…216  R Agra w al R Srikant F ast Algorithms for Mining Association Rules very Large Data Bases\(VLDB 1994 487499  Xiaobing Liu K u n Zhai W itold Pedrycz An impro v e d association rules mining method,Expert Systems with Applications 39 2012 13621374  Qiao yongwei,Y ang Hui Dong T ingjian,Research On QAR Data Mining Method Based On Improved Association Rule,Physics Procedia 24 2012 1514-1519  T  Hu S.Y  Sung H Xiong Q Fu Disco v ery of maximum length frequent itemsets Information Sciences 178 1 2008 69-87  G Lee U Y un K Ryu Sliding windo w based weighted maximal frequent pattern mining over data streams Expert Systems with Applications 41 2 2014 694-708  S.K T anbeer  C.F  Ahmed B.S Jeong Y  Lee Ef cient single-pass frequent pattern mining using a pre“x-tree Information Sciences 179 5 2008 559583  V S Tseng C.W  W u B.E Shie P S Y u  UP-Gro wth an ef cient algorithm for high utility itemset mining Knowledge Discovery and Data mining KDD 2010 253-262  T  W u  Y  Chen J han Re-e xamination of interestingness measures in pattern mining a uni“ed framework Data Mining and Knowledge Discovery DMKD 21 3 2010 371-397  J Han H Cheng D Xin X Y an Frequent pattern mining current status and future directions Data Mining and Knowledge Discovery DMKD 15 1 2007 55-86  Zaki Mohammed J Naren Ramakrishnan and Lizhuang Zhao Mining frequent boolean expressions application to gene expression and regulatory modeling International Journal of Knowledge Discovery in Bioinformatics IJKDB 1.3 2010 68-96 1084 2015 International Conference on Advances in Computing Communications and Informatics ICACCI 


375 6  R. Meo, G. Psaila, & S. Ceri 223A new SQL-like operator for mining association rules,\224 in Proceedings of the 22 nd International Conference on Very Large Data Bases Conference \(VLDB\2221996  Bombay, India, September 1996, pp. 122-133 7  H. C. Tjioe, & D. Taniar, \223Mining association rules in data warehouses,\224 International Journal of Data Warehousing and Mining vol. 1, no. 3, 2005, pp. 28-62 8  T. Imielinski, L. Khachiyan, & A. Abdulghani, \223Cubegrades generalizing association rules,\224 Data Mining and Knowledge Discovery vol. 6, issue 3, 2002, pp. 219-257 9  R. Ben Messaoud, R. S. Loudcher O. Boussaid, & R. Missaoui 223Enhanced mining of associati on rules from data cubes,\224 in Proceedings of the 9 th ACM International Workshop on Data Warehousing and OLAP \(DOLAP\2222006 Arlington, VA, 2006 pp. 11-18 10  R. Ben Messaoud, R. S. Loudcher O. Boussaid, & R. Missaoui 223OLEMAR: an online environment for mining association rules in multidimensional data,\224 Data Mining and Knowledge Discovery Technologies vol. 2, 2007, pp. 1-36 11  M. T. Fisun, G. V. Gorban, \223Research and implementation syntactic algorithms create OLAP-cubes,\224 Transactions of Kherson National University no. 2\(38\, 2010, pp. 110-117. \(in Ukrainian 12  M. T. Fisun, G. V. Gorban, \223Models and methods of construction of OLAP systems for object-ori ented databases,\224 Information Technology and Computer System s, no. 1 \(209\, 2014, pp. 41-45 in Russian 13  G. V. Gorban, \223Application of B*-trees for creating and calculating of OLAP-cubes using combinatorial algorithm,\224 Technological Audit of Production and Reserves no. 5/4 \(13 2013, pp. 10-12. \(in Ukrainian  


paying a price of a slightly worse ratio for subsets Taken together the price of having more subsets is preferred because subsets contain only items actually in the assembly while superset and overlap patterns also contain unrelated items The 002rst and second row of 002gure 8 correspond to the instance and the pattern-based approach for graded synchrony The third corresponds to the instance-based approach for binary synchrony Comparing the diagrams for unrelated patterns our graded method detects all injected patterns 050\002rst and second rows\051 while the binary method also produces unrelated pattern In 050Borgelt et al 2015\051 it is demonstrated that the instance-based approach yields slightly better results than the pattern approach However this approach does not consider the precision of synchrony Surprisingly using only the pattern-based approach with a graded notion of synchrony yields a better ratio for overlap and superset patterns 7 CONCLUSIONS In this paper we presented a method to detect frequent synchronous patterns in event sequences using a graded notion of synchrony for mining patterns in the presence of imprecise synchrony of events constituting occurrences and selective participation 050incomplete occurrences\051 Our method adapts methods presented in the literature to tackle selective participation using binary synchrony especially the instancebased approach which looks at instances of patterns to improve the detection by removing instances that are likely chance events checking the precision of synchrony of these instances We demonstrate in our experiments that using a graded notion of synchrony for support computation helps to simplify the detection of selective participation because a pattern-based approach yields better results or at least equally good results as an instance-based approach This is a considerable advantage since identifying the individual pattern instances is costly and thus it is desirable to avoid it ACKNOWLEDGMENTS The work presented in this paper was partially supported by the Spanish Ministry for Economy and Competitiveness 050MINECO Grant TIN2012-31372\051 and by the Principality of Asturias through the 2013-2017 Science Technology and Innovation Plan 050Programa Asturias CT1405206\051 and the European Union through FEDER funds REFERENCES Abeles M 0501982\051 Role of the cortical neuron Integrator or coincidence detector Israel Journal of Medical Sciences  18\0501\051:83\22692 Borgelt C 0502012\051 Frequent item set mining In Wiley Interdisciplinary Reviews 050WIREs\051 Data Mining and Knowledge Discovery  pages 437\226456 050 J Wiley  Sons Chichester United Kingdom 2 Borgelt C Braune C and Loewe K 0502015\051 Mining frequent parallel episodes with selective participation In Proc 16th World Congress of the International Fuzzy Systems Association 050IFSA\051 and 9th Conference of the European Society for Fuzzy Logic and Technology 050EUSFLAT\051 IFSA-EUSFLAT2015  Gijon Spain Atlantis Press Borgelt C and Picado-Muino D 0502013\051 Finding frequent synchronous events in parallel point processes In Proc 12th Int Symposium on Intelligent Data Analysis 050IDA 2013 London UK\051  pages 116\226126 Berlin/Heidelberg Germany Springer-Verlag Dudoit S and van der Laan M J 0502008\051 Multiple Testing Procedures with Application to Genomics  Springer New York USA Ezennaya-G 264 omez S and Borgelt C 0502015\051 Mining frequent synchronous patterns with a graded notion of synchrony In Proc 16th World Congress of the International Fuzzy Systems Association 050IFSA\051 and 9th Conference of the European Society for Fuzzy Logic and Technology 050EUSFLAT\051 IFSA-EUSFLAT2015  pages 1338\2261345 Gijon Spain Atlantis Press ISBN 050on-line\051 978-94-62520-77-6 Hebb D O 0501949\051 The Organization of Behavior  J Wiley  Sons New York NY USA Kernighan W and Ritchie D 0501978\051 The C Programming Language  Prentice Hall K 250 onig P Engel A K and Singer W 0501996\051 Integrator or coincidence detector the role of the cortical neuron revisited Trends in Neurosciences  19\0504\051:130\226137 Louis S Borgelt C and Gr 250 un S 0502010\051 Generation and selection of surrogate methods for correlation analysis In Gr 250 un S and Rotter S editors Analysis of Parallel Spike Trains  pages 359\226382 Springer-Verlag Berlin Germany Mannila H Toivonen H and Verkamo A 0501997\051 Discovery of frequent episodes in event sequences In Data Mining and Knowledge Discovery  pages 259\226 289 Springer New York NY USA 1\0503\051 Picado-Muino D and Borgelt C 0502014\051 Frequent itemset mining for sequential data Synchrony in neuronal spike trains Intelligent Data Analysis  18\0506\051:997\226 1012 Picado-Muino D Borgelt C Berger D Gerstein G L and Gr 250 un S 0502013\051 Finding neural assemblies with frequent item set mining Frontiers in Neuroinformatics  7 Picado-Muino D Castro-Le 264 on I and Borgelt C 0502012\051 Fuzzy frequent pattern mining in spike trains In Proc 11th Int Symposium on Intelligent Data Analysis 050IDA 2012 Helsinki Finland\051  pages 289\226300 Berlin/Heidelberg Germany Springer-Verlag 


Rossum G V 0501993\051 Python for unix/c programmers copyright 1993 guido van rossum 1 In Proc of the NLUUG najaarsconferentie Dutch UNIX users group  Torre E Picado-Muino D Denker M Borgelt C and Gr 250 un S 0502013\051 Statistical evaluation of synchronous spike patterns extracted by frequent item set mining Frontiers in Computational Neuroscience  7 Tsourakakis C Bonchi F Gionis A Gullo F and Tsiarli M 0502013\051 Denser than the densest subgraph Extracting optimal quasi-cliques with quality guarantees In Proc 19th ACM SIGMOD Int Conf on Knowledge Discovery and Data Mining 050KDD 2013 Chicago IL\051  pages 104\226112 New York NY USA ACM Press Zaki M J Parthasarathy S Ogihara M and Li W 0501997\051 New algorithms for fast discovery of association rules In Proc 3rd Int Conf on Knowledge Discovery and Data Mining 050KDD 1997 Newport Beach CA\051  pages 283\226296 Menlo Park CA USA AAAI Press 


