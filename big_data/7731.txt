Influence of Sample Size on Prediction of Animal Phenotype Value Using Back Propagation Artificial Neural Network with Variable Hidden Neurons Xue-Bin LI, Xiao-Ling YU  Henan Institute of Science and Technology Xinxiang 453003, P. R. China leexuebin@yahoo.com.cn  Abstract 227 Although linear multivariate approaches used to analyze large genetic data sets did not allow a large part of the total variance to be explained, strong distortions with nonlinear data sets, horseshoe effects had always been found. Artificial neural networks could gather their knowledge by detecting the patterns and relationships in data and learn through experience 
and could perform well for optimization and prediction in complex non-linear systems. Artificial neural networks have been widely used in many life areas, but have not been used to predict the genomic breeding values or animal phenotypes. In this paper Back-Propagation artificial neural network with Variable Hidden Neurons was used to predict the genomic breeding values. The results showed that artificial neural network could predict the animal genotype value, whatever there were interaction effect or not between gene loci. The sample size for training artificial neural network model could affect the training 
speed obviously, the training speed were obviously slowed along with enlargement of number of hidden neurons. A good structure of Back-Propagation artificial neural network needs a big sample for training its parameters. In some what, the sample size for training prediction model probably was not an important factor for prediction stability of artificial neural network; but large sample trained neural network model was very useful for training a Back-Propagation artificial neural network model with a small prediction error Keywords-Genomic breeding value; molecular marker; artificial neural networks; learning rate I   I 
NTRODUCTION  Genetic marker\222s availability allowed large-scale surveys of genetic diversity to be carried out in various species. Such projects have provided large data sets that give access to a detailed knowledge of the genetic structure of populations Most analyses have made use of methods based on population genetic models. Recently, a new technology called genomic selection is revolutionizing animal breeding. Linear multivariate approaches used to analyze large genetic data sets did not allow a large part of the total variance or inertia to be explained by the first main principal components. However strong distortions with nonlinear data sets, horseshoe effects had been found due to unimodal response curves in principal components analysis, arch effects, outliers, missing data, etc 
for the .complex relation between traditional animal breeding and genomic architectur  An artificial neural network \(ANN\a parallel adaptive system, which can gather knowledge by detecting the patterns and relationships in data and learn through experience, and can perform well for optimization and prediction in complex nonlinear systems. Once the neural network is trained and tested it can be given new input information to predict the outputs ANN can not only perform well for optimization in complex non-linear systems, but can also adjust the state of the network by the application of new sets of data. Artificial neural networks have been widely used in the areas of population 
genetics, evaluation of the contribution of repopulation to biodiversity, genetic analysis of populations and classification of individuals based on genotypic data, protein secondary structure prediction, recognition of signal peptide cleavage sites, gene recognition, design of a genome-wide siRNA library, classification and diagnostic prediction of cancers using gene expression profiling, prediction of specific class I MHC binding peptide sequences[3   etc However, artificial neural networks have not been used to calculate genomic breeding values. In this paper, Back-Propagation \(BP\rtificial neural network would be used to predict the genomic breeding values 
and the influence of sample size on prediction of animal phenotype value would be also discussed II  M ATHEMATICAL M ODEL  A  Quantitative trait genetic model Suppose that a quantitative trait is controlled by N=n 1 n 2 205n i 205+n k gene loci in the N gene loci, there are k  interaction groups, in the I th groups, there are n i gene loci. If there are two alleles in each locus, there would be a\(a+1\/2  kinds of band electropherogram states in the j th gene loci in 
the I th groups, where a is the number of allele\222s bands. If the N gene loci were expressed with mathematical element A, B 205.  a term in graph theory, then a quantitative trait controlled by N=n 1 n 2 205n i 205+n k gene loci can be described with a global graph including n k subgraph in figure 1    Figure 1 The graph of quantitative trait controlled by N gene loci  978-1-4244-4507-3/09/$25.00 \2512009 IEEE 


B  BP Neural Networks model Back propagation \(BP\eural networks used in our research are composed of one input layer for collecting inputs of molecular marker materials, one output layer for collecting the predictions of quantitative traits and one hidden layers for performing a weighted sum of the inputs and passing the resulting value through a non-linear function to the output layer. Individual weights are progressively adapted, using for instance a back-propagation algorithm, to minimize the difference between calculated and expected outputs; the weights assuring the best results then being used to test and compare the performance of the neural networks, which allow the networks to learn nonlinear and linear relationships between input and output vectors, in our research which is the relation between the gene loci and quantitative trait phenotype value III  M ATERIALS P REPARATION  A  Marker Materials Suppose that a quantitative trait is controlled by N gene loci. Although it is possible that there are more than two alleles in each locus, for the convenience of simulation, we still think that there are only two alleles in our research. These alleles are marked with M 1 m 1 M 2 m 2 M i m i M N m N units respectively. Then, the molecular marker electropherogram has three states: mm, Mm and MM, which were quantified with -1, 0 and 1 respectively. To an individual, we can sample a series of data from -1, 0, 1 to represent the marker states of individuals In our simulation, we assumed that a quantitative trait were controlled by 9 gene loci, which were divided into 3 interaction groups with 2, 3, 4 gene loci respectively. Then the first group has 9 genotypes, the second group has 27 genotypes, the third group has 81 genotypes, altogether there are 3 9 genotypes. All of the marker genotypes were used in our simulation; part of combinations between different interaction groups was sampled randomly B  Phenotype materials For the convenience sake of simulation, the genotype value of every interaction group \(Egroup\ were randomly sampled from 0 to 1, as no interactions between different interaction group, the phenotype value P could be calculated by the following formulas   k n 1 Egroup i i P 1 where Egroup i is the genotype value of the i th interaction group  IV  S IMULATION AND P REDICTION OF A RTIFICIAL N EURAL N ETWORKS  A  Parameters of Artificial Neural Networks Structure In order to build the non-linear continuous functions expressing the interdependency between the collected marker data and the phenotype value, a series of artificial neural networks were built, trained, cross-validated and tested. All the networks were built using only one input layer, one hidden layer and one output layer The input animal databases including marker materials of samples with 30, 60 and 90 animals were produced as described above, and a sample including 30 animal data were randomly selected to test the precise of prediction. All connection weights were randomized before beginning a training phase and the learning rate was 0.05. To avoid overtraining, the first training phase was stopped when the minimum squared error \(Mse 6 or the training epochs>10 3  and the second training phase was stopped when the minimum squared error \(Mse\10 10 or the training epochs>10 6  B  Simulation and prediction of Artificial Neural Networks The Back-Propagation algorithm is sensitive to the number of neurons in their hidden layers. Too few neurons can lead to underfitting. Too many neurons can contribute to overfitting, in which all training points are well fit, but the fitting curve takes wild oscillations between these points. One method for improving network generalization is to use a network that is just large enough to provide an adequate fit The larger a network you use, the more complex the functions the network can w e  u s e a s m all en o u g h  n e t w o r k   it will not have enough power to overfit the data Unfortunately, it is difficult to know beforehand how large a network should be for a specific application In our manuscript, the number of input neurons was the number of gene locus N, the number of output neurons was the number of quantitative traits, while the number of hidden neurons on estimating the phenotype value was defined as an adjustable number, and the initial number of hidden neurons was 2 times of the number of gene locus N. For discussing the influence of hidden neurons number and sample size, we use a series of networks, whose hidden neuron number is 2-10 times of input neuron number. All the training process was performed by the Matlab 7. 1 software V  R ESULTS  A  Influence of sample size on calculating time  Figure2. Influence of learning rate and neuron number on calculating time The controlled error is 10 6 figure 1A\nd 10 10 figure 2B\ and the max number of training epochs are 10 3 figure 2A\nd 10 6 figure 2B\ Solid line is the training speed of sample size 30. Dashed line is the training speed of sample size 30. Solid line is the training speed of sample size 60. Dotted line is the training speed of sample size 90. Circle ëoí is the minimum in a line, the minimum time point are \(20, 0.1805\, \(24, 0.2608\ and \(33, 0.5065 


in figure 2A, and the minimum time point are \(20, 0.1942\, \(24, 0.2797\ and 33, 0.5249\ in figure 2B After trained, simulated and predicted with a series of hidden neurons, we found that the sample size could affect the training speed obviously, the training speed were substantially slowed along with enlargement of number of hidden neurons but there were not obviously exchange along with the exchange of the number of training epochs and the training error tolerance B  Influence of sample size on Euclidean distance  Figure3.  Influence of sample size on Euclidean distance The solid line is the training speed of sample size 30 \(figure 3A and figure 3D\. The dashed line is the training speed of sample size 60\(figure 3B and figure 3D\. Dotted line is the training speed of sample size 90\(figure 3C and figure 3D\ Circle ëoí is the minimum in a line, the minimum Euclidean distance point are \(23, 0.72612\re 3A, \(22, 1.0983\ in figure 3B and 89, 1.0464\ in figure 3C In order to investigate the influence of sample size on the prediction of artificial neural networks, the Euclidean distance was used to weigh the deviation of predicted phenotype value from observed phenotype value of n animals. After the ANN achieving a steady state through training, the average Euclidean distance between observed values and the values acquired from the neural network were shown in figure3.  From the figure3 we found that Euclidean distance had not become smaller, and stability and prediction accuracy were not substantially improved along with the enlargement of sample size n, the minimum Euclidean distance was not improved along with the enlargement of sample size n, and the optimum points were different to different training sample. These suggested that the sample size for training prediction model was not an important factor, perhaps other factors are more important for training a good prediction ANN model, for example, and the uniformity of sample probably be an important factor for training a good ANN model C  The influence of sample size on Mse The typical performance function that is used for training feedforward neural networks is the mean sum of squares of the network errors \(Mse\If we calculated it with estimated phenotype and observed value, which can reflect the estimated stability of Back-Propagation artificial neural network, the smaller Mse reflects a better stability; a bigger Mse reflects a bad stability of Back-Propagation artificial neural network Only all of the estimated phenotype is close to observed value can the Mse be small. In addition to expressing the prediction stability of artificial neural networks, the Mse of different sample was calculated to investigate the ANNís stability for predicting the animal phenotype  Figure4.  Influence of sample size on Mse The solid line is the training speed of sample size 30 \(figure 4A and figure 4D\. The dashed line is the training speed of sample size 60\(figure 4B and figure4D\. Dotted line is the training speed of sample size 90\(figure 4C and figure 4D\rcle ëoí is the minimum in a line, the minimum Mse point are \(23, 0.1054\in figure 4A, \(22, 0.2416\in figure 4B and \(89, 0.2184\ in figure 4C The result was shown in figure 4, we found that  Mse of different sample size almost has no change along with the enlargement of sample size but the optimum structure of Back-Propagation artificial neural network  with minimum Mse was different, and the optimum Back-Propagation artificial neural network  trained with big sample size was not batter than the optimum Back-Propagation artificial neural network  trained with small samples, and along with the enlargement of sample size, the number of hidden neurons become bigger  These supposed that a good structure of BackPropagation artificial neural network need a big sample for training its parameters, in some what, the sample could not affect the ANNís stability for predicting the animal phenotype D  The influence of sample size on maximum error between simulation value and truth The difference between estimated value and truth reflect the maximum error, if the maximum error is very large although the stability of Back-Propagation artificial neural network is high, the precise of prediction is not high either From the figure 6, we could find that the maximum error of different sample size almost has no difference between sample size 30 and 60, but the minimum maximum error of sample size 90 is very small, and different networks need deferent number of hidden neurons for training the Back-Propagation 


artificial neural network. The change trend of maximum error along with the increasing of hidden neurons was the same among different Back-Propagation artificial neural network trained by different sample size. These supposed that large sample trained Back-Propagation artificial neural network could get very good prediction ANN model  Figure5.  Influence of sample size on maximum error The solid line is the training speed of sample size 30 \(figure 5A and figure 5D\. The dashed line is the training speed of sample size 60\(figure 5B and figure 5D\. Dotted line is the training speed of sample size 90\(figure 5C and figure 5D\rcle ëoí is the minimum in a line, the minimum point of maximum error are \(44, 0.0610\in figure 5A, \(67, 0.0722\ figure 5B and 60, 0.0036\ in figure 5C VI  DISCUSSION Artificial neural network \(ANN\arallel adaptive system and therefore requires training. Back-propagation \(BP algorithm is a powerful method of supervised learning [7,8  Unlike the methods of regression, could perform well for optimization in complex non-linear systems, and adjust the state of the network by the application of new sets of data ANN had successfully been used in biological sequence analysis for purposes as diverse as protein secondary structure prediction, recognition of signal peptide cleavage sites, gene recognition etc 3-6 th e p a st, th e id ea o f  u s in g D N A  markers to improve the rate of genetic gain in animals had been around for decades, but th e adoption of marker assisted selection had been limited until very recently a new technology called genomic selection was proposed. The genomic selection revolution began with 2 developments. The first was the publication by the Bovine Genome Sequencing and Analysis Consortium describing the sequence, Annotation and comparative analysis of the genome marks a major milestone in animal genetics T h e s econ d dev e lop m en t  was the demonstration that it was possible to make very accurate selection decisions when breeding values were predicted from dense marker data alone, using a method termed genomic selection [2  H o w e ve r  t h e ge no me i s ve r y  complex, a fascinating linkage between traditional animal breeding and genomic architecture suggests that perhaps the function relation was not enough for describing the relation between markers and phenotypes, and the genetic diversity should be carefully monitored as genomic selection for quantitative traits as a routine technology for animal genetic improvement ou r res e a r ch  w e  f oun d t h at t h e n onl i near prediction ability of ANN just provided an tool for describing the relation between markers and phenotypes, artificial neural networks could gather knowledge by detecting the relations between molecular marker polymorphism and phenotype value, and could predict the animal genotype value, whatever there were interaction effect or not between gene loci, which was very convenience for animal breeding and production From our result, we could also find that the sample size could affect the training speed obviously, the training speed were substantially slowed along with enlargement of number of hidden neurons. A good structure of Back-Propagation artificial neural network need a big sample for training its parameters, in some what, the sample could not affect the ANNís stability for predicting the animal phenotype. The sample size for training prediction model probably was not an important factor; perhaps other factors were more important for training a good prediction ANN model, for example, the uniformity of sample probably was an important factor for training a good ANN model. However, to the enlargement of sample size, it was not that there was any use for training a good prediction model. Our result showed that the maximum error of different sample size almost had no difference between sample size 30 and 60, but the minimum maximum error of sample size 90 was very small. These supposed that large sample trained Back-Propagation artificial neural network was very useful for training a prediction ANN model R EFERENCES  1  N. Nikolic, N. Nikolic1, YS Park2, M. Sancristobal1, S. Lek, C Chevalet. What do artificial neural networks tell us about the genetic structure of populations? The example of European pig populations Genet. Res 200 91: 121 132 2  H. A. Lewin. Itís a Bullís Market Science 2009, 324:478-479 3  J.Murvai, K. Vlahovi ek, C. Szepesv·ri, and S. Pongor. Prediction of Protein Functional Domains from Sequences Using Artificial Neural Networks Genome research 2009, 11:1410 1417 4  D.Huesken, J. Lange, C. Mickanin, J. Weiler, F. Asselbergs, J. Warner B. Meloon, S. Engel, A. Rosenberg, D. Cohen, M. Labow, M.Reinhardt F. Natt, J. Hall. Design of a genome-wide siRNA library using an artificial neural network Nature Biotechnology 2005,23, 995-1001 5  J. Khan, J.S. Wei, M. RingnÈr, L.H. Saal, M. Ladanyi, F. WestermANN F. Berthold, M. Schwab, C.R.Antonescu, C. Peterson, P.S.Meltzer Classification and diagnostic prediction of cancers using gene expression profiling and artificial neural networks Nature Medicine 2001 7\(6 673679 6  M. Milik, D. Sauer, A. P. Brunmark, L.Yuan, A. Vitiello, M.R. Jackson P.A.Peterson, J.Skolnick, C.A.Glass. Application of an artificial neural network to predict specific class I MHC binding peptide sequences Nature Biotechnology 1998, 16\(8\, 753-756 7  L.Ren,W.P.Wang, Y.Z.Gao, X.W.Yua, H.P.Xie.Typing SNP based on the near-infrared spectroscopy and artificial neural network Spectrochimica Acta Part A 2009,73: 106 111 8  H. Demuth,M. Beale, M.Hagan. Neural Network Toolboxô 6 Userís Guide.2009, pp5-11 9  The Bovine Genome Sequencing and Analysis Consortium, C. G. Elsik R. L. Tellam, K. C. Worley. The genome sequence of Taurine Cattle:A Window to ruminant biology and evolution Science  2009,324, 522-528 


this setup. Analyzing all the available data reveals that the availability of the FSO link and the corresponding visibility relate to each other in a simple way. For the used FSO systems in the present project a threshold can be set. As soon as the visibility drops to a value less than 200 m the optical link is heavily disturbed by atmospheric influences and the crosslink dies. The components used to build the devices were chosen to overcome distances of up to 600 m with perfectly clear sky conditions and of about 300 m with light atmospheric disturbances However, dense fog definitely is a massive atmospheric influence and has therefore an impact on the availability of this very FSO link In contrary to radio communication in Free Space Optics the data rate does not drop to a smaller value under atmospheric influence. The optical link is either operational with the high data rate promised or completely lacks service. This is a great difference to other wireless technologies like Wireless Local Area Network \(WLAN\r satellite communication. The reason for this can be found in the way of communication. The pin photo diode at the receivi ng end tries to detect the incoming data from the sending site. Either the detection is successful, meaning sufficient information made its way into the receiving end with the full available data rate or the detection fails causing the communication to break down completely. The observations made during this project also undermine the very binary operation mode of FSO links. If a significant amount of photons can be detected by the photo diode then the full data rate is available. On the contrary if the threshold of detection is undercut no communication whatsoever is possible Deep analysis of the daily data and confirms this performance Furthermore not only the availability of the link is very high, also the devices themselves obviously provide great service over a long period of time. The initial installation of the FSO link including mounting the devices alignment of the systems and testing the connection, took one and an half hours. Since then no maintenance work had to be accomplished VI  C ONCLUSION  Free Space Optics is an excellent wireless communication technology, especially as last mile access and nomadic use technology [9 T h e in s t allat i on proces s  is very easy and quick, the high data rates available are definitive a great advantage. This field study has shown that a standalone FSO link can provide a very reliable connection with a total availability of 97.80% over thirty two months. In any case FSO systems should not be seen in competition with WLAN or other radio technologies it should rather be seen as a widening to the wireless world Future work should concentrate on increasing the availability and reliability of FSO links Current researches at TU Graz deal with a topic called switch-over. Links based on microwaves and FSO connections are differently influenced by atmospheric incidents. Microwave links are mainly disturbed by rain whereas FSO connections principally interfere with dense fog. The switch-over technology tries to combine both existing technologies to increase the overall reliability [4  of a link. Basically a FSO link is used for communication to provide a high data rate. However, parallel to the FSO connection a microwave link is installed to function as a backup channel. Whenever the atmospheric disturbances are too heavy for the optical link to work, a switch-over to the fallback microwave link is issued. As soon as the optical link comes available again the communication channel switches back to the more powerful FSO link in terms of data rates. The combined system is often called hybrid system d a real  f a s t s w i t cho v e r is  v ita l f o r it to work Another idea to increase the availability could be a change in the setup of the receiver side. In a very new approach someone could try to use greater areas like house walls as a receiver. The walls need to be coated with a special material collecting the information Finally, the collected data by the successfully conducted project has undermined the importance of fog for the FSO technology once more. The long-term observation of this link has shown that the availability of the optical connection in the summer months is better than in the winter months in the latitudes of Austria A CKNOWLEDGMENT  Regarding the excellent outcome of results the research group for Optical Communications \(OptiKom\TU Graz thanks all their cooperation partners for their support mainly the national cooperation partner Telekom Austria AG, the government of Styria, ML11 ñ EDVDienstleistungen GmbH and the international cooperation partners within COST 270, SatNEx and COST 291 R EFERENCES  1 L e itg e b E., Br e g e n z e r J., F a sse r P G e bhar t M  Free Space Optics Extension to Fiber-Networks for the ÑLast Mile Proceedings and Presentation at IEEE / LEOS 2002 Annual Meeting, 10 th 14 th  of November 2002, Glasgow, Scotland  2  L e i t g e b E  S h e i kh Muham m ad S Ch lesti l Ch G e bha r t M  Birnbacher U Reliability of FSO Links in Next Generation Optical Networks Proceedings and Invited Presentation at the IEEEconference ICTON 2005, 3 rd 7 th of Juliy2005, Barcelona  3 L e itg e b E G e bhar t  M B i r n ba che r U S c hr o tte r P   Me r d o n ig  A  Truppe A Hybrid wireless networks for civil-militarycooperation \(CIMIC\ and disaster management Proceedings and Presentation at SPIE's European Symposium on Optics and Photonics for Defence and Security, Vol. 5614, pp. 139-150, 25 th  28 th October 2004, London  4 L e itg e b E., G e bhar t  M  Bir n b a c h e r U K o gle r W S c hr o t te r P    High availability of hybrid wireless networks Proceedings and Presentation at SPIE's International Symposium Photonics Europe Vol. 5465, pp. 238-249, 26 th 30 th April 2004, Straﬂburg  5 L e itg e b E., G e bhar t  M  Bir n b a c h e r U  Optical Networks, Last Mile Access and Applications Book-Chapter of ìFree-Space Laser Communications: Principles and Advancesî, \(accepted 2004 published 2008\, Springer Verlag, ISBN: 978-0-387-28652-5  6 L e itg e b E., G e bhar t  M F a sse r P   Br e g e n z e r J., T a n c z o s J., I m pact of atmospheric effects in Free Space Optics transmission systems Proceedings and Presentation at SPIE Photonics West, LASE 2003, 25 th 31 st of January 2003, San Jose, CA, USA  


7 F l e c ke r B C h l e s t il C L e itg e b E   S h e i k h  M u ham m ad S   G e bhar t  M Results of Attenuation Measurements for Optical Wireless Channels under Dense Fog Conditions Proceedings and Presentation at the SPIE Optics and Photonics Symposium, San Diego, USA, August, 2006  8 L e itg e b E   S h e i kh M u ham m a d S   F l e c ke r B Chl e s t il  Ch G e bhar t  M., Javornik T The influence of dense fog on Optical Wireless systems, analysed by measurements in Graz for improving the link-reliability Proceedings and Invited Presentation at the IEEEconference ICTON 2006, 18 th 22 nd June 2006, Nottingham, UK 9 E L e itg e b M  L  schnig g  U  B i r n bac h e r G  S c hw ar z  A  Me r d o n ig  High Reliable Optical Wireless Links for the Last Mile Access  Invited Presentation at the IEEE-conference ICTON 2008, June 2008, Greece, Athens 10 G  n t e r D  Ro th  Unser Wetter: Wolkenbilder, Wetterph‰nomene Groﬂwetterlagen, Wettervorhersage: Wolkenbilder Wetterph‰nomene, Groﬂwetterlagen, Wettervorhersage BLV Buchverlag, 2008  11 O  Ma ho ny C. P o l i t i D  K l o n idis  R. N e ja ba ti D  S i m e o n i d o u   Future Optical Networks IEEE Journal of Lightwave Technology December 2006  12 S a n d al i d is H  G T s if ts is, T  A  K a r a g i ann i d i s G  K U y sal  M  BER Performance of FSO Links over Strong Atmospheric Turbulence Channels with Pointing Errors Communications Letters, IEEE Volume 12, Issue 1, January 2008  13 H  Y u kse l  Studies of the Effects of Atmospheric Turbulence on Free-Space optical communications University of Maryland    


  Chris t i na Bouch e r, Dan i e l G. Brown, Paul  Church, \223 A Graph Clustering Approach to weak Motif Recognition 224, WABI 2007 LNBI 4645    J  Buh l e r and M T o m p a, \223 Finding motifs using random projections 224 Proceedings Fifth Annual International Conference on Computational Molecular Biology RECOMB April 2001     E. Esk i n and P. Pevz ner, \223 Finding composite regulatory patterns in DNA sequences 224   Bioinformatics S1, 2002, pp 354-363     P. Pev z ner and S.H Sz e, \223 Combinatorial approaches to finding subtle signals in DNA sequences 224 Proc. Eighth International Conference on Intelligent Systems for Molecular Biology 2000, pp 269-278    A. Price, S. Ram a bhadr a n, P. Pev z ner  223Finding subtle motifs by branching from sample strings\224  Bioinformatics supplementary edition, Proceedings of the Second European Conference on Computational Biology \(ECCB-2003     J Dav i la, S. Ba ll a and S. Ra j a s e k a ran  223 Space And Time Efficient Algorithms for Planted Motif Search 224 Second International Workshop on Bioinformatics Research and Applications \(IWBRA 2006 May 2006    M. Li, B Ma an d L Wang  223 On the Closest String and Substring Problems 224 Journal of the ACM Vol. 49, No. 2, March 2002    F Y.L. Chin an d H C.M Leung 223 Voting Algorithms for Discovering Long Motifs 224  Proceedings of the Third Asia-Pacific Bioinformatics Conference \(APBC2005 Singapore 261-271, January 2005       


vs Laser Sp Success Rate Vs Occlusion During Lab Testing The algorithm Visibility Rtic El 2 4 40 60 so 100 same poses are reduced to occlude part of the target 8  Figure 10 Success rate vs occlusion 1 Polygon 2 Polygons 5 Polygons Figure 8 Edge distortions caused by diverging laser beam Sensor point of view left Top view right Figure 10 presents the results obtained for a fully visible target down to a 3000 visible target Very good robustness to occlusions has been obtained down to 400O visibility The main reason for the sudden drop in performance is due to the fact that the polygon selection algorithm could not find polygons that were large enough to meet its specified threshold The algorithm therefore aborted in most cases when more than 60 of the target was hidden The polygon selection process could be tuned differently to accommodate mission profiles that would result in more occlusion than tested here The limit is that sufficient nonambiguous geometry must be visible For this test the same simulated sensor characteristics were used but the simulated laser spot diameter was varied between 10 and 150mm Figure 9 shows the success rate obtained for 1,2 and 5 polygons as the spatial resolution of the simulated sensor drops The top X axis shows the corresponding range at which the spot diameter shown in the bottom X axis would be reached if the sensor has a lmRad divergence Note that most scanning sensors have a divergence that is less than lmRad but this provides a reference for the worst case scenario As would be expected using more polygons greatly reduces the effect of decreasing spatial resolution by increasing the robustness to edge distortions 60 Success Rate vs Laser Spot Diarmeter mr 1 cover more than the sensor's field of view The algorithm must be still capable of finding the target under these occluded conditions This test Spot Diameter mm Figure 9 Success Rate scans were acquired using different ot Diameter scan patterns Lissajous Rosette and Spiral Figure 12 The Laser scan extents uses the were selected to avoid lab clutter scan extents as this would have introduced outliers and violated the operational rendezvous and assumptions defined for this system docking operations the operating range of the vision system is very large Under these circumstances it is very likely that at closer range the target will was tested using a TriDAR sensor and was positioned at roughly 20m maximum range of the facility 1 Om and 4m away from the target object Note that at 4m less than half of the target object is visible The range selected is therefore representative of the final part of were tested For each viewpoint 3 different 1024 point as used for the previous tests except the Po0 on gr 21 Polygons 5 Pdlygoans 1 9 8 7 06 Taget a full size mockup of the target object used for simulation Figure 11 The TriDAR a docking mission where the target would go from fully visible long range to only partially visible short range At each range 10 different relative poses 


success was obtained by acquiring high resolution data from the TriDAR success rate obtained using TriDAR data Very good performance is observed success rate of the algorithm increases with the number of polygons tested As would be expected the processing time also scales with the number of polygons but is only slightly affected by the target range Note that the number of points was used for simulations Figure 13 presents the even when the target is only partially visible As observed in simulations the Success Rate with TriDAR Data mean pose mean pose same as what vs Range 3-sigma processing time ms vs Range m 1000 F Figure 12 Sample point clouds obtained using the selected  500 _ n a 400 300 200 100 0 _ 4 Figure 1 Range 6 8 10 12 Range m 1 Polygon 2 Polygons 5 Polygons 14 16 18 4 Processing Time 3a of the algorithm our purposes considering the relatively low accuracy required from the localization system The criteria for pose vs Range m 20 10 0 _ Figure 11 Target Object 4 6 8 10 12 Range m 1 Polygon 2 Polygons 5 Polygons 14 16 18 Figure 13 Success Rate with TriDAR data scan patterns side view Lissajous left Rosette middle Spiral right The true relative pose used for determining pose error and localization sensor at each position and calculating the pose using an ICP algorithm This technique provides an estimate of the ground truth that is close enough for success remained the on target remained fairly constant 900-1000 throughout all these tests Table 3 shows the absolute error observed during lab testing for successful localizations The pose accuracy does not significantly improve when using more polygons but it remains well within the desired range The error observed is also consistent with simulation results Table 2 900 800 700 E a 600 E vs Table 3 Lab Testing Mean Pose Error 9 100 90 80 70 0 60 t 50 n a 30 Polygon X Y Z RotX RotY RotZ s mm mm mm deg deg deg 1 50.3 41.8 30.5 1.6 1.4 2.8 2 41.3 45.7 28.9 1.52 1.4 2.8 5 40.8 47.2 30.3 1.4 1.3 3.1 


6 CONCLUSION Neptec has developed a vision system for autonomous onorbit rendezvous and docking that does not require the use of cooperative markers on the target spacecraft The system uses an active TriDAR 3D sensor and efficient model based tracking algorithms to provide 6 degree of freedom 6DOF relative pose information in real-time The system takes full advantage of the large amount of geometric information contained in 3D data sets By following the More Information Less Data MILD paradigm where the sensor only acquires the data necessary to obtain the pose of the target real-time performance can be achieve with flight hardware Following the same smart scanning strategy Neptec has developed a novel technique for localizing a known object on-orbit The new technique called Polygonal Aspect Hashing does not require an initial guess of the relative pose and therefore can be used to initialize tracking or recover if tracking is lost Furthermore it only requires a very sparse non organized 3D point cloud thus keeping the data acquisition and pre-processing overhead to a minimum The technique follows logic similar to the process of adding a piece in a jigsaw puzzle First the set of possible positions and orientations of the scan with respect to the model is reduced to the set of poses that have sufficient overlap Once the set of poses is reduced to the most likely candidates a surface fit check is performed to determine the best matching pose The surface fit check measures the amount of overlap between an input scan and the surface of a reference 3D model of the object to find The algorithm developed was tested with both simulated and TriDAR data Results showed excellent performance and demonstrated that the algorithm works well even with very sparse input data sets as well as in the presence of sensor noise and distortions Processing time results obtained showed that real-time performance can be achieved with this technique As would be expected it was shown that the robustness can be increased by testing more polygons at the expense of processing time Another alternative would be to run the algorithm with one polygon over several sequential scans This technique would be well suited for operations where there is relative motion between the sensor and target like in a tumbling satellite scenario or if the processing power is limited In the future Neptec plans to test more objects with representative geometry and materials to further characterize the algorithm performance The effect of object symmetries will also be investigated It was observed that most failures tend to occur where the object is most symmetric Code optimization will also be performed to further improve performance 1 MacLean S Pinkney L Machine Vision in Space Can Aeronaut Space J 39\(2 63-77 1993 2 Howard Richard T Bryan Thomas C DART AVGS flight results Proc SPIE Vol 6555 pp.65550L 2007 3 Ruel S English C Anctil M Church P 43DLASSO Real-time pose estimation from 3D data for autonomous satellite servicing Proc ISAIRAS 2005 Conference Munich Germany 5-8 September 2005 ESA SP-603 4 Ruel S English C Anctil M Daly J Smith C Zhu S Real-time 3D vision solution for on-orbit autonomous rendezvous and docking Proc SPIE Vol 6220 pp.622009 2006 5 Andrew Johnson and Martial Hebert Using spin images for efficient object recognition in cluttered 3-D scenes IEEE Transactions on Pattern Analysis and Machine Intelligence 21\(5 449 May 1999 6 H Wolfson I Rigoutsos Geometric Hashing An Overview IEEE Computational Science  Engineering 4\(4 October 1997 7 English C Zhu X Smith C Ruel S Christie I TriDAR A hybrid sensor for exploiting the complimentary nature of triangulation and LIDAR technologies Proc ISAIRAS 2005 Conference Munich Germany 5-8 September 2005 ESA SP-603 8 J Obermark G Creamer B Kelm W Wagner C Henshaw SUMO/FREND vision system for autonomous satellite grapple Proc SPIE Vol 6555 pp 65550Y 2007 9 Deslauriers A Showalter I Montpool A Taylor R Christie I Shuttle TPS inspection using triangulation scanning technology SPIE 2005 Orlando Florida April 2005 10 Ruel S English C Melo L Berube A Aikman D Deslauriers A Church P and Maheux J Field testing of a 3D Automatic Target Recognition and Pose Estimation Algorithm SPIE Defense  Security Symposium Orlando Florida April 12-16 2004 11 English C Ruel S Melo L Church P and Maheux J Development of a Practical 3D Automatic Target Recognition and Pose Estimation Algorithm SPIE Defense  Security Symposium Proceedings on Automatic Target Recognition XIV Orlando Florida April 2004 10 REFERENCES 


12 R Krishnapuram D Casasent Determination of threedimensional object location and orientation from Range Image IEEE Transactions on Pattern Analysis and Machine Intelligence 11\(11 1158 1167 November 1989 13 R Craig I Gravseth R P Earhart J Bladt S Barmhill L Ruppert C Centamore Processing 3D flash LADAR point-clouds in real-time for flight applications Proc SPIE 2007 Vol 6555 BIOGRAPHY Stphane Ruel is a project manager at Neptec Design Group in Ottawa Canada He currently leads development of novel 3D computer vision algorithms and sensor software for space applications Previously he served as an operations engineer on several Space Vision System SVS Space Shuttle missions He has a B.Sc in Computer Engineering and M.Sc in Aerospace Engineering from Laval University He is also alumni of the International Space University SSP in 2004 Tim Luu is a Vision Systems Engineer at Neptec Design Group Ltd At Neptec he develops 3D vision systems for space and defense applications Most of his time is spent developing real-time 3D pose estimation algorithms using sparse data from non-cooperative targets This research is mostly geared toward the field of autonomous rendezvous and docking Filling out his time is also control systems design 2D image registration onto 3D data as well as other 3D visualization techniques Tim received his M.A.Sc from Carleton University in Mechanical Engineering and his BASc from the University of British Columbia in Engineering Physics specializing in Mechanical Engineering 11 


Time Time 50 350   10 0                   10 1                   10 2 12.5 50 350   10 0                   10 1  12 expected from Figure 7, the width of the uncertainty region is compressed by the curvature of the monopulse response resulting in a detection-primitive with greater uncertainty than the variance admits.  A filter lag or so-called cluster tracking can easily result in a 5% or greater offset and degraded consistency.  After 300 seconds the curves peak up because the target is appr oaching a low-elevation beampoint limit.  This occurs anytime a target is tracked into the edge of the radar\222s field of re gard and can lead to radar-toradar handover difficulty         300 300 80  s D 2 k,1 k y    s D 2 k,1 k y   100 150 200 250 10 1                    10 5 1 0  Figure 8 - Consistency versus distance from beam center Monopulse Mismatch The next set of curves plotted in Figure 9 show the sensitivity of detection-primitive consistency to a mismatch in the monopulse slope.  All of these curves were generated using a linear monopulse response derived from the slope of the true monopulse response at beam center.  The slope of the 80% curve is 0.8 times th e beam-center slope; the 90 curve is 0.9 times the beam-center slope; and so on for 100%, 110% and 120%.  Again, the order of curves in the graph is the same as the legend order A steep slope tends to expand y I 222s uncertainty while a gentle slope tends to compress it.  An expanded uncertainty leads to a smaller consistency while a compressed uncertainty leads to a larger consistency.  This behavior can be observed in the family of curves in Figure 9.  Curves for the steeper slopes are on the botto m while curves for more gentle slopes are on top.  The notable feature of this set of curves is that the sensitivity to a mismatch in the monopulse slope is not very significant       100 150 200 250 10 1                    90 100 110 120  Figure 9 - Consistency versus monopulse mismatch Range-Bias Error The complex nature of the monopulse radar models presents ample opportunity to introduce errors in the software implementation.  One such e rror introduced in a \275 rangecell-width bias in the detection-primitive range which in turn resulted in a significant degradation to 2 9 k D The fact that 2 9 k D is measured in different coordinates compared to the bias made it difficult to determine which value or algorithm was to blame.  Examining the intermediate consistency values led directly to the error source A comparison between biased 2 1 k D  2 2 k D and 2 3 k D values and unbiased 2 2 k D values is shown in Figure 10.  The unbiased 2 2 k D is the bottom-most curve and the biased 2 3 k D is the top-most curve with a value around 80.  This large value for 2 3 k D indicates that there is a lot more uncertainty in the range measur ements compared to what is predicted by the range varian ce.  Since the range-variance calculation is easy to confirm, the problem must be in the algorithms that model or manipulate range A notable feature of Figure 10 is the sensitivity of the centroiding algorithm to range bias in the detection primitives.  The range bias is ba rely noticeable in the biased 2 1 k D and 2 2 k D curves.  Of course, if the unbiased 2 2 k D  curve existed as a baseline it would be relatively easy to spot the error 


Time Time Time 50 350   10 0                   10 1                   10 2 50 350   10 1                   10 0                   10 1 50 350   10 0                   10 1  13         Isolated No SNR Adjust  Figure 11 - Centroiding for isolated range cells Filter Tuning Now that the centroided m easurements are reasonably consistent, the parameters that govern track filtering can be examined.  As previously promised, the effects and corrections for atmospheric refr action and sensor bias have been disabled so that 2 8 k D can be analyzed using a sliding window.  Of course the full analysis would include these effects and 2 8 k D at each time step would be collected and averaged over many trials Plots of the effect of changing process noise in a nearlyconstant-velocity filter are shown in Figure 12 and Figure 13 for Cartesian position and velocity respectively.  In both figures, the plotted values have been divided by 3 so that the desired value is always 1.  Increasing the process noise up to a point should increase the updated uncertainty and reduce 2 8 k D values.  Except near th e end of the trajectory when the measurements are off of beam center, the curves in Figure 12 and Figure 13 appear inconclusive for this expected trend If 2 8 k D values are way out of range there are additional intermediate filter values that can be examined.  For example, the state extrapolati on algorithms can be examined by comparing the consistency of 1 210 Isolated With SNR Adjust 300 300 300 0.005 212 212 212 212 212 kkkk T kkkk D xhzSxhz 35        s D 2 k Range   D 2 k,2 biased D 2 k,1 biased D 2 k,2  Figure 10 - Range bias error in detection primitive Centroiding Algorithm From Section 3, assuming that the centroided-range uncertainty for an isolated range cell is the same as its detection-primitive uncertainty may be incorrect Collecting and plotting 2 3 k D values only from isolated range-cell measurements can be used to analyze such assumptions.  The plots in Figure 11 compare differences between the isolated-cell algorithm defined in Section 3, an algorithm that modifies the uncertainty based on the SNR in the isolated cell, and the 2 3 k D values from all measurements 34\was used to modify the range uncertainty for the upper line labeled Isolated with SNR Adjust    4 22  2 2  resRi o R R Rn bdp bm  s D 2 k,3 Range    s D 2 k,8 Position     212 1 can also be examined using \(35 The residual is also commonly used to determine the assignment cost  212 kk z  P  k  k1 with z k The consistency of the innovation covariance k T kkkkk RHPHS 100 150 200 250 10 1                    D 2 k,3 biased 100 150 200 250 10 2                    100 150 200 250 10 1                    0.5 50  Figure 12 \226 Position consistency, filter tuning example  r  t t 34 If the All Centroided curve \(middle\as the baseline doing nothing \(lower\imates the uncertainty and 33\imates the uncertainty.  Dividing by the square root of the observed SNR leads to a more consistent covariance; however, there is currently no statistical evaluation to justify it             210 210 1 1 1 2 All Centroided 


Time 50 350   10 1                   10 0                   10 1  14         300 0.005  s D 2 k,8 Velocity   100 150 200 250 10 2                    0.5 50  Figure 13 \226 Position consistency, filter tuning example 5  C ONCLUSION  Calculating and observing the behavior of covariance consistency at different levels  in the radar signal processing chain represents a very powerfu l tool that can be used to assess the accuracy and softwa re implementation of radar signal-processing algorithms.  Analyzing covariance consistency is applicable to radar systems both in the field and in simulations.  The primary challenge in both arenas comes down to properly accounting for the true target states that contribute to detections, detection primitives measurements, and state estimates For a fielded radar syst em, achieving covariance consistency is usually a s econdary consideration behind achieving and maintaining track s.  Indeed, until recently radar specifications did not even include requirements for covariance consistency.  Recent covariance consistency requirements stem from the fact that the use of radar systems in sensor netting applications is on the rise Currently the combined e ffects of off-beam-center measurements, atmospheric correction, bias correction clustering and centrioding, data association, and filtering on state covariance consistency throughout a target\222s trajectory are not well known.  This is particularly true for radars using wideband waveforms and multiple hypotheses or multiple frame trackers.  Numerical results presented here indicate that algorithms early in the radar signal processing chain can significantly degrad e covariance consistency and that some errors are better tolerated than others For a simulated target in a modeled system, truth relative to some global reference is known. However, transforming truth through different refere nce frames and accounting for changes that occur during various radar processing algorithms is not as simple as it appears.  The techniques in this paper help expose this hidden complexity and provide a framework for discussing and expanding the future development of covariance consistency techniques.  Such future developments include issues related to mapping truth through the convolution operation typically used to simulate wideband signal processing and the fast Fourier transforms typically used in pulse-Doppler processing.  Sophisticated tracking algorithms that carry multiple hypotheses, associate across multiple frames, or weight the association of multiple targets within a single frame pose significant challenges in properly associating truth with state estimates.  Additional work, including an investigation of track-to-truth assignment, is needed before covariance consistency techniques can be applied to these algorithms Another area that needs furthe r analysis is the use of a sliding window to approximate the covariance behavior expected during a set of Monte-Carlo trials.  Various timedependent variables such as the target\222s range and orientation, the transmit waveform, the radar\222s antenna patterns toward the target, missed detections, and false alarms could easily viol ate the assumption that measurement conditions are nearly stationary over the time of the window.  It is importa nt to understand the conditions when this assumption is violated Finally, the examples presented here included a relatively benign arrangement of targets.  Further analysis in dense target environments with the related increase in merged detections, merged measurements, and impure tracks is needed.  Further analysis for targets traveling over different trajectories is also needed Even so, the techniques presented here can be extended to many of these analyses R EFERENCES  1  S. Blackman and R. Popoli Design and Analysis of Modern Tracking Systems Artech House, 1999 2  Y. Bar-Shalom and X. R. Li Multitarget-Multisensor Tracking: Principles and  Techniques YBS Publishing, Storrs, CT, 1995 3  Y. Bar-Shalom, Editor Multi-target-Multi-sensor Tracking: Advanced Applications and  Vol. I Artech House, Norwood, MA, 1990 4  D. B. Reid, \223An Algorithm for Tracking Multiple Targets,\224 IEEE Trans. on Automatic Control Vol. 24 pp. 843-854, December 1979 5  T. Kurien, \223Issues in the Design of Practical Multitarget Tracking Algorithms,\224 in Multitarget-Multisensor Tracking Y. Bar-Shalom \(ed.\43-83, Artech House, 1990 6  R.P.S. Mahler, Statistical Multisource-Multitarget Information Fusion, Artech House, 2007 


 15 7  B.-N. Vo and W.-K. Ma, \223The Gaussian Mixture Probability Hypothesis Density Filter,\224 IEEE Trans Signal Processing Vol. 54, pp. 4091-4104, November 2006 8  B. Ristic, S. Arulampalam, and N. Gordon Beyond the Kalman Filter Artech House, 2004 9  Y. Bar-Shalom, X. Rong Li, and T. Kirubarajan Estimation with Applications to Tracking and Navigation, New York: John Wiley & Sons, pg. 166 2001 10  X. R. Li, Z. Zhao, and V. P. Jilkov, \223Estimator\222s Credibility and Its Measures,\224 Proc. IFAC 15th World Congress Barcelona, Spain, July 2002 11  M. Mallick and S. Arulampalam, \223Comparison of Nonlinear Filtering Algorithms in Ground Moving Target Indicator \(GMTI Proc Signal and Data Processing of Small Targets San Diego, CA, August 4-7, 2003 12  M. Skolnik, Radar Handbook, New York: McGrawHill, 1990 13  A. Gelb, Editor Applied Optimal Estimation The MIT Press, 1974 14  B. D. O. Anderson and J. B. Moore Optimal Filtering  Prentice Hall, 1979 15  A. B. Poore, \223Multidimensional assignment formulation of data ass ociation problems arising from multitarget and multisensor tracking,\224 Computational Optimization and Applications Vol. 3, pp. 27\22657 1994 16  A. B. Poore and R. Robertson, \223A New multidimensional data association algorithm for multisensor-multitarget tracking,\224 Proc. SPIE, Signal and Data Processing of Small Targets Vol. 2561,  p 448-459, Oliver E. Drummond; Ed., Sep. 1995 17  K. R. Pattipati, T. Kirubarajan, and R. L. Popp, \223Survey of assignment techniques for multitarget tracking,\224 Proc  on Workshop on Estimation  Tracking, and Fusion: A Tribute to Yaakov Bar-Shalom Monterey CA, May 17, 2001 18  P. Burns, W.D. Blair, \223Multiple Hypothesis Tracker in the BMD Benchmark Simulation,\224 Proceedings of the 2004 Multitarget Tracking ONR Workshop, June 2004 19  H. Hotelling, \223The generalization of Student's ratio,\224 Ann. Math. Statist., Vol. 2, pp 360\226378, 1931 20  Blair, W. D., and Brandt-Pearce, M., \223Monopulse DOA Estimation for Two Unresolved Rayleigh Targets,\224 IEEE Transactions Aerospace Electronic Systems  Vol. AES-37, No. 2, April 2001, pp. 452-469 21  H. A. P.  Blom, and Y. Bar-Shalom, The Interacting Multiple Model algorithm for systems with Markovian switching coefficients IEEE Transactions on Au tomatic Control 33\(8  780-783, August, 1988 22  M. Kendall, A. Stuart, and J. K. Ord, The Advanced Theory of Statistics, Vol. 3, 4th Edition, New York Macmillan Publishing, pg. 290, 1983 23  T.M. Cover and P.E. Hart, Nearest Neighbor Pattern Classification, IEEE Trans. on Inf. Theory, Volume IT-13\(1 24  C.D. Papanicolopoulos, W.D. Blair, D.L. Sherman, M Brandt-Pearce, Use of a Rician Distribution for Modeling Aspect-Dependent RCS Amplitude and Scintillation Proc. IEEE Radar Conf 2007 25  W.D. Blair and M. Brandt-Pearce, Detection of multiple unresolved Rayleigh targets using quadrature monopulse measurements, Proc. 28th IEEE SSST March 1996, pp. 285-289 26  W.D. Blair and M. Brandt-Pearce, Monopulse Processing For Tracking Unresolved Targets NSWCDD/TR-97/167, Sept., 1997 27  W.D. Blair and M. Brandt-Pearce, Statistical Description of Monopulse Parameters for Tracking Rayleigh Targets  IEEE AES Transactions, Vol. 34 Issue 2,  April 1998, pp. 597-611 28  Jonker and Volgenant, A Shortest Augmenting Path Algorithm for Dense and Sparse Linear Assignment Problems, Computing, Vol. 38, 1987, pp. 325-340 29  V. Jain, L.M. Ehrman, and W.D. Blair, Estimating the DOA mean and variance of o ff-boresight targets using monopulse radar, IEEE Thirty-Eighth SSST Proceedings, 5-7 March 2006, pp. 85-88 30  Y. Bar-Shalom, T. Kirubarajan, and C. Gokberk 223Tracking with Classification-Aided Multiframe Data Association,\224 IEEE Trans. on Aerospace and Electronics Systems Vol. 41, pp. 868-878, July, 2005   


 16 B IOGRAPHY  Andy Register earned BS, MS, and Ph  D. degrees in Electrical Engineering from the Georgia Institute of Technology.  His doctoral research emphasized the simulation and realtime control of nonminimum phase mechanical systems.  Dr. Register has approximately 20 years of experience in R&D with his current employer, Georgia Tech, and product development at two early-phase startups. Dr. Register\222s work has been published in journals and conf erence proceedings relative to mechanical vibration, robotics, computer architecture programming techniques, and radar tracking.  More recently Dr. Register has b een developing advanced radar tracking algorithms and a software architecture for the MATLAB target-tracking benchmark.  This work led to the 2007 publication of his first book, \223A Guide to MATLAB Object Oriented Programming.\224  Mahendra Mallick is a Principal Research Scientist at the Georgia Tech Research Institute \(GTRI\. He has over 27 years of professional experience with employments at GTRI \(2008present\, Science Applications International Corporation \(SAIC Chief Scientist \(2007-2008\, Toyon Research Corporation, Chief Scientist 2005-2007\, Lockheed Martin ORINCON, Chief Scientist 2003-2005\, ALPHATECH Inc., Senior Research Scientist 1996-2002\, TASC, Principal MTS \(1985-96\, and Computer Sciences Corporation, MTS \(1981-85 Currently, he is working on multi-sensor and multi-target tracking and classification bas ed on multiple-hypothesis tracking, track-to-track association and fusion, distributed filtering and tracking, advanced nonlinear filtering algorithms, and track-before-detect \(TBD\ algorithms He received a Ph.D. degree in  Quantum Solid State Theory from the State University of New York at Albany in 1981 His graduate research was also based on Quantum Chemistry and Quantum Biophysics of large biological molecules. In 1987, he received an MS degree in Computer Science from the John Hopkins University He is a senior member of the IEEE and Associate Editor-inchief  of the Journal of Advances in Information Fusion of the International Society of Information Fusion \(ISIF\. He has organized and chaired special and regular sessions on target tracking and classific ation at the 2002, 2003, 2004 2006, 2007, and 2008 ISIF conferences. He was the chair of the International Program Committee and an invited speaker at the International Colloquium on Information Fusion \(ICIF '2007\, Xi\222an, China. He is a reviewer for the IEEE Transactions on Aerospa ce and Electronics Systems IEEE Transactions on Signal Pr ocessing, International Society of Information Fusion, IEEE Conference on Decision and Control, IEEE Radar Conference, IEEE Transactions on Systems, Man and Cybernetics, American Control Conference, European Signal Processing Journal and International Colloquium on Information Fusion ICIF '2007   William Dale Blair is a Principal Research Engineer at the Georgia Tech Research Institute in Atlanta, GA. He received the BS and MS degrees in electrical engineering from Tennessee Technological University in 1985 and 1987, and the Ph.D. degree in electrical engineering from the University of Virginia in 1998. From 1987 to 1990, he was with the Naval System Division of FMC Corporation in Dahlgren, Virginia. From 1990 to 1997, Dr Blair was with the Naval Surface Warfare Center, Dahlgren Division NSWCDD\ in Dahlgren, Virg inia. At NSWCDD, Dr Blair directed a real-time experiment that demonstrated that modern tracking algorithms can be used to improve the efficiency of phased array radars. Dr Blair is internationally recognized for conceptualizing and developing benchmarks for co mparison and evaluation of target tracking algorithms Dr Blair developed NSWC Tracking Benchmarks I and II and originated ONR/NSWC Tracking Benchmarks III and IV NSWC Tracking Benchmark II has been used in the United Kingdom France, Italy, and throughout the United States, and the results of the benchmark have been presented in numerous conference and journal articles. He joined the Georgia Institute of Technology as a Se nior Research Engineer in 1997 and was promoted to Principal Research Engineer in 2000. Dr Blair is co-editor of the Multitarg et-Multisensor Tracking: Applications and Advances III. He has coauthored 22 refereed journal articles, 16 refereed conference papers, 67 papers and reports, and two book chapters. Dr Blair's research interest include radar signal processing and control, resource allocation for multifunction radars, multisen sor resource allocation tracking maneuvering targets and multisensor integration and data fusion. His research at the University of Virginia involved monopulse tracking of unresolved targets. Dr Blair is the developer and coordinator of the short course Target Tracking in Sensor Systems for the Distance Learning and Professional Education Departmen t at the Georgia Institute of Technology. Recognition of Dr Blair as a technical expert has lead to his election to Fellow of the IEEE, his selection as the 2001 IEEE Y oung Radar Engineer of the Year, appointments of Editor for Radar Systems, Editor-InChief of the IEEE Transactions on Aerospace and Electronic Systems \(AES\, and Editor-in- Chief of the Journal for Advances in Information Fusion, and election to the Board of Governors of the IEEE AES Society,19982003, 2005-2007, and Board of Directors of the International Society of Information Fusion   


 17 Chris Burton received an Associate degree in electronic systems technology from the Community College of the Air force in 1984 and a BS in Electrical Engineering Technology from Northeastern University in 1983.  Prior to coming to the Georgia Institute of Technology \(GTRI\ in 2003, Chris was a BMEWS Radar hardware manager for the US Air Force and at MITRE and Xontech he was responsible for radar performance analysis of PAVE PAWS, BMEWS and PARCS UHF radar systems Chris is an accomplished radar-systems analyst familiar with all hardware and software aspects of missile-tracking radar systems with special expertise related to radar cueing/acquisition/tracking for ballistic missile defense ionospheric effects on UHF radar calibration and track accuracy, radar-to-radar handover, and the effects of enhanced PRF on radar tracking accuracy.  At GTRI, Chris is responsible for detailed analysis of ground-test and flight-test data and can be credited with improving radar calibration, energy management, track management, and atmospheric-effects compensation of Ballistic Missile Defense System radars   Paul D. Burns received his Bachelor of Science and Masters of Science in Electrical Engineering at Auburn University in 1992 and 1995 respectively. His Master\222s thesis research explored the utilization of cyclostationary statistics for performing phased array blind adaptive beamforming From 1995 to 2000 he was employed at Dynetics, Inc where he performed research and analysis in a wide variety of military radar applications, from air-to-air and air-toground pulse Doppler radar to large-scale, high power aperture ground based phased array radar, including in electronic attack and protection measures. Subsequently, he spent 3 years at MagnaCom, Inc, where he engaged in ballistic missile defense system simulation development and system-level studies for the Ground-based Midcourse defense \(GMD\ system. He joined GTRI in 2003, where he has performed target tracking algorithm research for BMD radar and supplied expertise in radar signal and data processing for the Missile Defense Agency and the Navy Integrated Warfare Systems 2.0 office.  Mr. Burns has written a number of papers in spatio-temporal signal processing, sensor registration and target tracking, and is currently pursuing a Ph.D. at the Georgia Institute of Technology  


  18 We plan to shift the file search and accessibility aspect outside of the IDL/Matlab/C++ code thereby treating it more as a processing \223engine\224. SciFlo\222s geoRegionQuery service can be used as a generic temporal and spatial search that returns a list of matching file URLs \(local file paths if the files are located on the same system geoRegionQuery service relies on a populated MySQL databases containing the list of indexed data files. We then also plan to leverage SciFlo\222s data crawler to index our staged merged NEWS Level 2 data products Improving Access to the A-Train Data Collection Currently, the NEWS task collects the various A-Train data products for merging using a mixture of manual downloading via SFTP and automated shell scripts. This semi-manual process can be automated into a serviceoriented architecture that can automatically access and download the various Level 2 instrument data from their respective data archive center. This will be simplified if more data centers support OPeNDAP, which will aid in data access. OPeNDAP will also allow us to selectively only download the measured properties of interest to the NEWS community for hydrology studies. Additionally OpenSearch, an open method using the REST-based service interface to perform searches can be made available to our staged A-Train data. Our various services such as averaging and subsetting can be modified to perform the OpenSearch to determine the location of the corresponding spatially and temporally relevant data to process. This exposed data via OpenSearch can also be made available as a search service for other external entities interested in our data as well Atom Service Casting We may explore Atom Service Casting to advertise our Web Services. Various services can be easily aggregated to create a catalog of services th at are published in RSS/Atom syndication feeds. This allows clients interested in accessing and using our data services to easily discover and find our WSDL URLs. Essentially, Atom Service Casting may be viewed as a more human-friendly approach to UDDI R EFERENCES   NASA and Energy and W a t e r cy cl e St udy NEW S website: http://www.nasa-news.org  R odgers, C  D., and B  J. C onnor \(2003 223Intercomparison of remote sounding instruments\224, J Geophys. Res., 108\(D3 doi:10.1029/2002JD002299  R ead, W G., Z. Shi ppony and W V. Sny d er \(2006 223The clear-sky unpolarized forward model for the EOS Aura microwave limb sounder \(MLS Transactions on Geosciences and Remote Sensing: The EOS Aura Mission, 44, 1367-1379  Schwartz, M. J., A. Lam b ert, G. L. Manney, W  G. Read N. J. Livesey, L. Froidevaux, C. O. Ao, P. F. Bernath, C D. Boone, R. E. Cofield, W. H. Daffer, B. J. Drouin, E. J Fetzer, R. A. Fuller, R. F. Jar not, J. H. Jiang, Y. B. Jiang B. W. Knosp, K. Krueger, J.-L. F. Li, M. G. Mlynczak, S Pawson, J. M. Russell III, M. L. Santee, W. V. Snyder, P C. Stek, R. P. Thurstans, A. M. Tompkins, P. A. Wagner K. A. Walker, J. W. Waters and D. L. Wu \(2008 223Validation of the Aura Microwave Limb Sounder temperature and geopotential height measurements\224, J Geophys. Res., 113, D15, D15S11  Read, W G., A. Lam b ert, J Bacmeister, R. E. Cofield, L E. Christensen, D. T. Cuddy, W. H. Daffer, B. J. Drouin E. Fetzer, L. Froidevaux, R. Fuller, R. Herman, R. F Jarnot, J. H. Jiang, Y. B. Jiang, K. Kelly, B. W. Knosp, L J. Kovalenko, N. J. Livesey, H.-C. Liu1, G. L. Manney H. M. Pickett, H. C. Pumphrey, K. H. Rosenlof, X Sabounchi, M. L. Santee, M. J. Schwartz, W. V. Snyder P. C. Stek, H. Su, L. L. Takacs1, R. P. Thurstans, H Voemel, P. A. Wagner, J. W. Waters, C. R. Webster, E M. Weinstock and D. L. Wu \(2007\icrowave Limb Sounder upper tropospheric and lower stratospheric H2O and relative humidity with respect to ice validation\224 J. Geophys. Res., 112, D24S35 doi:10.1029/2007JD008752  Fetzer, E. J., W  G. Read, D. W a liser, B. H. Kahn, B Tian, H. V\366mel, F. W. Irion, H. Su, A. Eldering, M. de la Torre Juarez, J. Jiang and V. Dang \(2008\omparison of upper tropospheric water vapor observations from the Microwave Limb Sounder and Atmospheric Infrared Sounder\224, J. Geophys. Res., accepted  B.N. Lawrence, R. Drach, B.E. Eaton, J. M. Gregory, S C. Hankin, R.K. Lowry, R.K. Rew, and K. E. Taylo 2006\aintaining and Advancing the CF Standard for Earth System Science Community Data\224. Whitepaper on the Future of CF Governance, Support, and Committees  NEW S Data Inform ation Center \(NDIC http://www.nasa-news.org/ndic 


  19   Schi ndl er, U., Di epenbroek, M 2006 aport a l based on Open Archives Initiative Protocols and Apache Lucene\224, EGU2006. SRef-ID:1607-7962/gra/EGU06-A03716 8] SciFlo, website: https://sci flo.jpl.nasa.gov/SciFloWiki 9 ern a, web s ite: h ttp tav ern a.so u r cefo r g e.n et  Java API for XM L W e b Services \(JAX-W S https://jax-ws.dev.java.net  Di st ri but ed R e source M a nagem e nt Appl i cat i on DRMAA\aa.org  Sun Gri d Engi ne, websi t e   http://gridengine.sunsource.net  W 3 C R ecom m e ndat i on for XM L-bi nary Opt i m i zed Packaging \(XOP\te: http://www.w3.org/TR/xop10  W 3 C R ecom m e ndat i on for SOAP M e ssage Transmission Optimization Mechanism \(MTOM website: http://www.w3.org/TR/soap12-mtom  W 3 C R ecom m e ndat i on for R e source R e present a t i on SOAP Header Block, website http://www.w3.org/TR/soap12-rep 16] OPeNDAP, website: http://opendap.org  Yang, M Q., Lee, H. K., Gal l a gher, J. \(2008 223Accessing HDF5 data via OPeNDAP\224. 24th Conference on IIPS  ISO 8601 t h e Int e rnat i onal St andard for t h e representation of dates and times http://www.w3.org/TR/NOTE-datetime 19] ITT IDL, website http://www.ittvis.com/ProductServices/IDL.aspx 20] Python suds, website: h ttps://fedorahosted.org/suds  The gSOAP Tool ki t for SOAP W e b Servi ces and XM LBased Applications, website http://www.cs.fsu.edu/~engelen/soap.html  C hou, P.A., T. Lookabaugh, and R M Gray 1989 223Entropy-constrained vector quantization\224, IEEE Trans on Acoustics, Speech, and Signal Processing, 37, 31-42  M acQueen, Jam e s B 1967 e m e t hods for classification and analysis of multivariate observations\224 Proc. Fifth Berkeley Symp Mathematical Statistics and Probability, 1, 281-296  C over, Thom as. and Joy A. Thom as, \223El e m e nt s of Information Theory\224, Wiley, New York. 1991  B r averm a n, Am y 2002 om pressi ng m a ssi ve geophysical datasets using vector quantization\224, J Computational and Graphical Statistics, 11, 1, 44-62 26 Brav erm a n  A, E. Fetzer, A. Eld e rin g  S. Nittel an d K Leung \(2003\i-streaming quantization for remotesensing data\224, Journal of Computational and Graphical Statistics, 41, 759-780  Fetzer, E. J., B. H. Lam b rigtsen, A. Eldering, H. H Aumann, and M. T. Chahine, \223Biases in total precipitable water vapor climatologies from Atmospheric Infrared Sounder and Advanced Microwave Scanning Radiometer\224, J. Geophys. Res., 111, D09S16 doi:10.1029/2005JD006598. 2006 28 SciFlo Scien tific Dataflo w  site https://sciflo.jpl.nasa.gov  Gi ovanni websi t e   http://disc.sci.gsfc.nasa.gov techlab/giovanni/index.shtml  NASA Eart h Sci e nce Dat a Sy st em s W o rki ng Groups website http://esdswg.gsfc.nasa.gov/index.html   M i n, Di Yu, C h en, Gong, \223Augm ent i ng t h e OGC W e b Processing Service with Message-based Asynchronous Notification\224, IEEE International Geoscience & Remote Sensing Symposium. 2008 B IOGRAPHY  Hook Hua is a member of the High Capability Computing and Modeling Group at the Jet Propulsion Laboratory. He is the Principle Investigator of the service-oriented work presented in this paper, which is used to study long-term and global-scale atmospheric trends. He is also currently involved on the design and development of Web Services-based distributed workflows of heterogeneous models for Observing System Simulation Experiments OSSE\ to analyze instrument models. Hook was also the lead in the development of an ontology know ledge base and expert system with reasoning to represent the various processing and data aspects of Interferometric Synthetic Aperture Radar processing. Hook has also been involved with Web Services and dynamic language enhancements for the Satellite Orbit Analysis Program \(SOAP\ tool.  His other current work includes technology-portfolio assessment, human-robotic task planning & scheduling optimization, temporal resource scheduling, and analysis He developed the software frameworks used for constrained optimization utilizing graph search, binary integer programming, and genetic algorith ms. Hook received a B.S in Computer Science from the University of California, Los  


  20 Angeles, where he also received a B.S. in Applied Mathematics  Eric Fetzer is a Senior Member of the Technical Staff at the Jet Propulsion Laboratory, Pasadena, California specializing in satellite observations of the atmosphere.  His scientific interests include planetary boundary layer processes, tropical phenomena, upper tropospheric variability, and climatologies of temperature, water vapor and clouds.  His technical interests include analysis of large data sets, and of multi-sensor observations. He has over 20 peer-reviewed publications and given numerous scientific presentations, public lectures and media interviews about climate science. Eric received a B.A. in Physics from the University of California Berkeley, and a Ph.D. in Astrophysical, Planetary and Atmospheric Sciences from the University of Colorado, Boulder   Amy Braverman is a Senior Statistician at the Jet Propulsion Laboratory, California Institute of Technology She holds a B.A. in Economics from Swarthmore College an M.A. in Mathematics from UCLA, and a Ph.D. in Statistics also from UCLA. Prior to her current position in JPL's Science Data Understanding Group, she was a Caltech Post-doctoral Scholar at the Jet Propulsion Laboratory, and a Scientist in the Flight Sciences Experiments Section of the Science Division. Dr Braverman conducts research on information-theoretic methods for the analysis of massive data sets and streams statistical data fusion, high-dimensional data analysis, and statistical analysis for climate model evaluation and diagnosis. She has published in both the statistics and geoscience literature, and is active in both communities She is a member of the Multi-angle Imaging SpectroRadiometer Science Team, and serves as a member of the Atmospheric Infrared Sounder Science Integration Team. Her responsibilities on both missions include designing data reduction algorithms for massive, remote sensing data sets. Dr. Braverman also holds an appointment in the Department of Statistics at UCLA as Adjunct Associate Professor, and is active in UCLA\222s Center for Environmental Statistics. She is member of the Committee on Applied and Theoretical Statistics of the US National Academy of Science. She has refereed for the Journal of the American Statistical Association, the Journal of Computational and Gr aphical Statistics, IEEE Transactions on Geoscience and Remote Sensing, and the Journal of Applied Meteorology and Climatology Seungwon Lee is a senior member of the High Capability Computing and Modeling Group at Jet Propulsion Laboratory. She is conducti ng research on comet gas dynamics, nonlinear dynamics control, climate model parameterization, Earth science data analysis, parallel computing, and advanced numerical algorithms. She received her Ph.D in Physics fr om the Ohio State University and her M.S. and B.S. in Physics from the Seoul National University, Korea  Matthew Henderson is software engineer in the High Capability Computing and Mode ling group at JPL. His current work includes Web Services and Instrument Data Level 2 subsetting. He received a B.S. Computer Science from CSU Pomona, and is currently pursuing M.S Computer Science  Steven J. Lewis is a member of the Information System and Computer Science staff member at the Jet Propulsion Laboratory.  He received a BS in Mathematics from the University of California, Los Angeles in June 2001, and the MS and Ph.D. Degree from Claremont Graduate University in May 2004 and May 2007, respectively.  He worked as a post doctoral fellow at Keck Graduate Institute from June 2007 until he joined JPL in March of 2008.  During his graduate and post doctoral work, his studies focused on applications of Bayesian methods to hidden Markov models with particular interest and application to protein sequencing.  His work at JPL has focused on integrating web services into various programming platforms for the purposes of accessing NASA satellite data, as well as developing object tracking so ftware and contributing to image enhancement and restoration efforts Van Dang is a member of the Science Data Understanding Group at the Jet Propulsion Laboratory. She was responsible for the NEWS Level 2 processing that generated the formal merged Level 2 data from multiple A-Train instruments  Manuel de la Torre is a Physicist from the Universidad Complutense at Madrid \(Spain\. After finishing his Ph.D work at the University of Bayreuth \(Germany\ on pattern formation in turbulent flows and a 7 1/2 year stunt as Ass and Assoc. Prof. at the Escuela T\351cnica Superior de Ingenieros Aeron\341uticos in Madrid \(Spain\, he came to the Jet Propulsion Laboratory on a 1-year Sabatical leave in 1997 wanting to apply fundamental concepts of nonlinear systems and geophysical fluid dynamics to something that might be directly useful to soci ety. He discovered the JPL as a great place to achieve that goal and extende d his stay a bit longer, becoming Technical staff and working on different aspects of remote sensing, validation of satellite instruments, and data analysis of atmospheric processes and climate  


