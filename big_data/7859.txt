Proceedings of the Third International Conference on Machine Leaming and Cybernetics Shanghai 26-29 August 2004 RECOMMENDATION OF NEW ITEMS BASED ON INDEXING TECHNIQUES JIAN CHEN JIAN YIN JIN HUANG Department of Computer Science, Zhongshan University, Guangzhou 5 10275 China E-MAIL ellachen@l63.com Abstraft The amount of information in the World Wide Web is increasing far more quickly than our ability to pmeess Recommender systems apply knowledge discovery techniques to help people find what 
they really want These techniques include collaborative filtering 0 association rules discovery and Bayesian networks etc Unfortunately all of these approaches have an important drawback items or pages which being added to a site recently cannot be found This is generally referred to as the 223new item problem\224 In this paper we introduce a general framework for solving this prohlem and present a single index strnctnre X.Features-Tree for using heuristic information retrieval 
technique to find the right items for the right users Keywords nearest neighbor; indexing techniques Recommender system web usage mining reverse k 1 Introduction The World Wide Web continues to grow at an amazing rate as information gateway and as a medium for conducting business All of us have known the feeling of being overwhelmed by the number of news advertisements and all kinds of products for sale in E-commerce sites So it is necessary to find technologies that can dramatically reduce the useless information and help 
us sift through all the available information to find which is most valuable to us Recommender system is one of these technologies by identifying particular items that are likely to match each user\222s tastes or preferences One of most widely used technologies for building recommender systems is collaborative filtering CF 222I It is based on the idea that the active user is more likely to prefer items that like-minded people selected Given a target user\222s records of activity or preferences CF-based techniques compare those records with the historical records of other users in order to find the 
top k users who have similar tastes or interests The mapping of a visitor record to its neighborhood could be based on similarity in rating of items access to similar content or pages or purchase of sihlar items Other techniques which have been successfully applied in recommender system include association rules discovery Bayesian networks and Horting An association rule is an implication expression which describes the relationships between the accessed pages and the purchase items Once the association rules are extracted from user transaction database prediction of the active user\222s preference 
will be generated according all these rules[*\222 Bayesian networks create a model based on a kaining set with a decision tree at each node and edges representing user\222s information and focus on a single relationship between the users The main idea of the approach is in the context of the Web there is often more relationship information than the simple person-item relati~nship[~\222 Horting is a graph-based technique in which nodes are users and edges between bodes indicate degree of similarity between two users Prediction will be generated by traveling the graph to 
nearby nodes and combining the opinions of the nearby users[41\222 Unfortunately all of these existing approaches for recommender system must rely on the usage history of users and just focus on the current demands of user so it\222s an inevitable thing that they have an important drawback items or pages which are added to a site recently cannot be found Because for these new items or pages there are no accessed records no ratings from users and still no relationship are found by algorithms all of which make it difficult for people discover them. This is generally referred 
to as the 223new item problem\224 In this paper we present a new framework aiming at solving this problem The main idea is extracting semantic feature from items or pages content firstly and clustering the users who appear to have similar preferences according to access similar content when a new item or page appears we find its 223influence\224 user clusters by using new information indexing concepts and technologies Finally this item page will be recommended to these groups of users that seems to have 0-7803-8403-2/04/520.00 WOO4 IEEE 1168 


Proceedings of the Third International Conference on Machine Learning and Cybernetics Sbanghai26-29 August 2004 1169 the similar tastes or interests matching with the semantic feature of this item \(page 2 Data Preparation The critical start for our successful target based on Web is data preparation Data cleaning is the task of removing log entries that are not necessary for the mining process including eliminating irrelevant and unreasonable items and removing all log entries with filename suffixes representing images and sounds Pageviews identification is the task of determining which page file accesses contribute to s single browser display User transaction identification is to identify semantically meaningful groupings of pageviews in each user session based on an underlying model of the user's browsing behavior Finally removing very low support or very high support pageviews references i.e references to those pageviews that do not appear sufficient number of the transactions or those that are present in nearly all transactions can further filter the transaction file 3 Integrating Indexing Technologies to Recommender System with Semantic Features 3.1 Extracting semantic features from pageviews Pageviews are semantically meaningful entities such as pages or items User transactions are relevant subsets of pageview in each user session. Data preparation results in a set of n pageviews P  p p2 _ pn and a set of m user transactions,T=[t,,t  t where each r E T with a unique identifier TID is a subset of P We use the concept described in reference 2 to define P and T Each transaction f was viewed as an l-dimensional vector over the space of pageview reference t w\(P,A.w\(P  w\(P,.o where eachpiEPfor some Cl{l  n and w\(p,,t is the weight associated with pageview p in the transaction f representing its significance The weights can be determined in a number of ways meeting the demand For example association patterns mining just use binary weight to represent the existence or non-existence of a product purchase or a pages access in the transaction On the other hand, content mining may use a function of the duration of the associated pageview in order to capture the user's interest in a content page Thus the set of all user transaction can be viewed as an mxn transaction-pageview matrix denoted by TP Semantic Features can be extracted from both text and meta-data General text mining can be used to find the features in the text For example classification of content based on a concept hierarchy can be used to limit the discovered patterns just containing those pageviews which are about a certain subject or class of products For features extracted from text we follow a commonly used method in information retrieval to use a standard function of the term frequency and inverse document frequency to evaluate features weights For features extracted from meta-data because we assume the features weights are provided as part of the domain knowledge specified by the designer it becomes particularly important when dealing with product-oriented pageviews or those involving non-textual content Given the above concepts each pageview p can be represented as a k-dimensional feature vector where k is the total number of extracted features from the site in a global dictionary Each dimension in a feature vector represents the corresponding feature weight within the pageview Thus the feature vector for a pageview p is given by where is fw\(p,f the weight of the jth feature in P  fw\(P,f fw\(P.f  MP f  pageview PEP for some jU[l  k For the whole collection of pageview in the site we have the nxk pageview-feature matrix PF  pl p  p 1 Then if we map each pageview of PF in a transaction t8 to one or more content features we can get a new matrixTF=[t',,l'2 f where each t is a k-dimensional vector over the feature space Thus a user transaction can be represented as a content feature vector reflecting that user's interests in particular concepts or topics 3.2 User transaction clustering based on a efficient index structure In contrast to C clustering user transactions based on a transaction-feature matrix TF does not require explicit raings or inieractiou with users Ccmplete user transamon database   


Proceedmgs of the Third International Conference on Machine Learning and Cybernetics, Shanghai 26-29 August 2004 After the CIUstering based on thn transaction features sun ilarity  0      0  0 I         0   9   Figure 1 Clustering Algorithm partitions user transactions into several groups Traditional clustering techniques generally have had accuracy and low performance for very large-scale problems. .Because the number of features in a transaction vector usually is in tens to a few hundreds in typical applications Some techdques lie SVD have been widely used to increase density and reduce the dimensionality of high-dimensional feature space. However in many cases the resulting from reducing the dimensionality will still have a quite large dimensionality And the remaining dimensions are all relatively important which means that any efficient indexing method must guarantee a good selectivity on all those dimensions Based on our studies and observations in indexin techniques on high dimensional data we choose X-Tree as the basic structure and user transactions clustering algorithm in our framework To cluster transactions we need a measure of distance between two transactions Given two transactions t and s we define the similarity sim\(t,s as the normalized cosine of the angle between the two feature vectors 61 ItnsI Dist\(t,s  sim\(r,s  Such a clustering algorithm will result in a set TC=\(c,,c2  ckJ of clusters where each ci is a subset of T Ideally each cluster represents a group of users with similar interest which described by a vector of features 33 Recommending new items based on the concept of Influence Sets K Nearest Neighbor k problem is an important topic in real work applications ad research domains such as in information retrieval multimedia systems spatial databases, and data minmg etc Recently more and more attentions have been paid on its reverse version which is known as Influence Sets problem The Reverse k Nearest Neighbor problem is to find all points in a data set that take a given query point as one of their k Nearest Neighbor This notion arises in examples such as finding the set of customers affected by the opening of a new store outlet location or deciding the service scope managed by a certain call center etc In our case recommender system will notify the subset of Web users who will find a newly added page or item most relevant Firstly we give the formal definitions of these two problems Given a set S of n data points in some d dimensional space and a query point q Definition 1 The k Nearest Neighbor of q is defined as k"\(q S I S'E s h p E S'A pz E s  Dist\(q,p q,p Definition 2 The Reverse k Nearest Neighbor of q is defined as RmN 4  P E S I E WN P What is worthy of notice is RkNN\(q may be empty or Theorem 1 PE Rk"\(q w qc k p have one or more elements This is obvious regarding the definitions of k and Corollary 1 Suppose k is the distance between Dist\(p,q p~Rkh"\(q Dist\(p.4  k pe RkNN\(q  Proof IfDisf\(p,q kNNP then q is a k or is a tie of kh of p According Theorem 1 p is Rk of q Otherwise p is NOT RWN of q and vice versa In Section 3.2 we cluster all user transactions by utilizing an index structure X-Features-Tree During the generation of this tree we add some necessary amihutes into different type of nodes respectively Rk p and its k Nearest Neighbor Figure 2 Structure of X-Features-Tree 1170 


Proceedings of the Third International Conference on Machine Leaming and Cybernetics, Shanghai 26-29 August 2004 1  For each leaf node IE T  we determine its NNp and generate circle fp MNJ where p is center and kNNP is radius A directory node contains an array of branches of the form Childgtr SPHERE m-k If Childjtr points to a non-leaf node SfHERE is the minimum bounding hypersphere of all hypersphere that are entries in the child node m-kNN=nurr\(klvn6 where p are points contained in the subtree rooted at this node 2   I  Figure 3 SPHERxum bounding sGhere of all leaf nodes in this Branch\(Circ1e in 2 Dimension In the structure described above we use minimum bounding spheres instead of minimum bounding rectangle for reducing the overlapping of regions For each newly added page or item we also can extract its feature vector and represent as  page   f f  f We can take this page or item as a query point q and fmd its potential influence users by traveling the whole X-Features-Tree It can be accomplished by using a heuristic Rk query algorithm which is described as For a leaf node we need to examine each point p.kNNp in the node If Disr\(q,p i.e q is a k of p  then p is one of the Reverse k Nearest Neighbor of q and add it to the results set For a directory node we compare the query point q with each branch B=\(ChildJrr SPHERE m9NN Here m-k plays a crucial role By definition the distance from each pointp to its k Nearest Neighbor is not greater than m-k nm-k is the largest of them and all points in the subtree rooted at B are contained in a SHfERE Hence if the distance from q to the center of SHPERE is greater than m-k then branch B need not to be visited This is because any point in B cannot be closer to q than to its k Nearest Neighbor in the whole following  X-Features-Tree Otherwise we call these two search processes recursively Before the algorithm performs we must specify a certain matching score of the user transaction and the new item page In our case the score is the weighted number of matched features in their feature vectors It will be reflected in the specified value of k In another WO for each point p how many points it will take as its neighbor Too low or too high threshold will cause a bad accuracy and low performance An appropriate value of k is worthy of discussion When Rk"\(q is found i.e the influence sets of this newly added page or item are acquired we capture the potential user groups whose tastes or preferences are matched with the feature of this page or item In contrast to be searching passively by Web users the information about this page or item can be recommended directly to them online or offline 3.4 The Maintenance of X-Features-Tree The X-Features-Tree structure is dynamic and can be updated incrementally The processes of insertion deletion and update can be complete easily by combining several k and Rk query operations We first take a look at insertion When a pint p is to be inserted into a generated X-Features-Tree We perform a WN operation to find its kJVNp and create the circle  WNP which is the form of leaf node. Next an Rk query can give us the information of those points that are affected i.e Rk"\(p For each p E RkNN\(p we recomputed its kNNp by perform kh7N\(pZ and the field SPHERE and mx-k of its ascendant nodes will also need to adjusted up to the root of the tree This can be done in a way very similar to the Rk query algorithm At last we insert p the same as in a normal tree Now we tum our attention to deletion. Firstly we delete the target point p from the tree Just like insertion operation, those affected points in Rk"\(p must be found and recomputed the k field and their relevant directory nodes must be adjusted The update operation is composed of two steps after a deletion operation insertion supervenes 4 Conclusions This paper presents a different view of integrating semantic knowledge into the recommendation process based on information retrieval techniques We also give the necessary theoretical notions of a new framework and relevant efficient structure which focus on capturing the underlying common properties and relations among the 1171 


Proceedings of the Third International Conference on Machine Learning and Cybernetics Shanghai, 26-29 .August 2004 users and items pages Instead of being found passively items and pages can discover their potential Web users automatically and be recommended to these users actively in this general approach Acknowledgements This work is supported by the National Natural Science Foundation of China 60205007 Natural Science Foundation of Guangdong Province 001264 031558 Research Foundation of Science and Technology Plan Project in Guangdong Province 2003C50118 and Research Foundation of State Key Laboratory for Novel Software Technology at Nanjing University Referencis 11 Herlockei J Understanding and Improving Automated Collaborative Filtering Syaems Pb.D Thesis Computer Science Dept University of Minnesota Bamshad Mobasher Honghua Dai Tao Luo Miki Nakagawa Effective personalization based on association rule discovery from web usage data In the Proteedings of the ACM Workshop on Web 121 Information and Data Management WIDM2001 Pp 9-15 3 laronski W Bloemer I Vanhoof K Wets G Use of Bayesian belief networks to help understand online audience In Proceedings of Data Mining for Marketing Applications Workshop at ECWKDD 2001,3-7 4 Agganual C C Wolf J L Wu K and Yu P S Honing Hatches an Egg A New Graph-theoretic Approach to Collaborative Filtering In Proceedings of the ACM KDD99 Conference. San Diego, CA pp 201-212 Sarwar BM Karypis G Konstan JA and Riedl I Applicafion of Dimensionality Reduction in Recommender System  A Case Study In ACM WebKDD 2000 Web Mining for E-Commerce Workshop 6 Stefan Berchtold, Daniel A. Keim, Hans-Peter Kriegel The X-tree An Index Structure for High-Dimensional 222 Data Proceedings of the 22nd International Conference on Very Large Databases pp 28-39 F 223of\224 and S Muthukrisbnan Influence sets based on reverse nearest neighbor queries In Proc ACM SIGMOD Int Conf on Management of Data Dallas USA May 2000 5 7 I 1172 


12 Fin V Jensen Bayesian Networks and Decision Graphs Springer, New York 200 1 13 1 L Kolodner 223Maintaining Organization in a Dynamic Long-Term Memory,\224 Cognitive Science 7\(4 1983,243-280 14 C.M Kuok A Fu M.H Wong 223Mining Fuzzy Association Rules in Databases\223 ACM SIGMOD Record vol 27\(1 March 1998,4146 lS Lily Liang and Carl Looney 223Inference via fuzzy belief Petri nets,\224 Proc IEEE ACTAI 2003 Conf Sacramento 2003 5 10-5 14  Carl G Looney and Lily Rui Liang 223Cognitive Situation and Threat Assessment of Ground Battlespaces\224 Int J Information Fusion 4\(4 2003,297-308 1171 Carl Looney and Lily Liang 223Inference via Fuzzy Belief Networks\224 Proc ISCA International Conference San Diego Nov 2002  181 Carl G Looney, +\221Interactive clustering and merging with a new fuzzy expected value,\224 Pattern Recognition 35 2002 2413-2423 19 Carl G Looney Pattern Recognition Using Neural Networks Oxford University Press NY 1997 20 Carl Looney 223Fuzzy Petri Nets for Rule Based Decisionmaking,\224 3EEE Trans SMC 18 I Jan. 1988 22 A E Nicholson and J M Brady 223Dynamic belief networks for discrete monitoring,\224 ZEEE Trans SMC 24 I I 1994, 1593-1610 23 Z Pawlak Rough Sets Theoretical Aspects of Reasoning about Data Kluwer Academic, Dordrecht 1991 24 J Pearl Probabilistic Reasoning in intelligent Systems Networks of Plausible Inference Morgan Kaufmann Publishers San Mateo, Califomia 1988 25 R Schank Dynamic memory a theovy ofreminding and learning in computers and people Cambridge Universiv Press Cambridge UK 1982 26 G Shafer A Mathematical Theoy of Evidence Princeton University Press, Princeton 1976  Glenn Shafter and Judea Pearl Editors Uncertain Reasoning Morgan Kaufinan San Mateo,l990 Readings in 28 S Wright 223Correlation and causation,\224 J Agricultural Reseurch 20 1921,557-585 29 Y Xiang, \223Belief updating in multiply sectioned Bayesian networks without repeated local propagations,\224 Int J Approximate Reasoning 23,2000 1-21 30 Nevin L Zhang 223Computational properties of two exact algorithms for Bayesian networks,\224 Applied Intelligence 9 1998 173-183 1211 Sucheta Nadkami and Prakash Shenoy 223A Bayseian network approach to making inferences in causal maps,\224 European J Operations Research 128,2001,479-498 558 


tight t t= 1 Step 8: If  is null, then do the next step; otherwise, set r=r+1 and repeat Steps 6 to 8 1rL Step 9: Construct the association rules for all large q-itemset t with items \( ,  using the following substeps 1 2, ,...,t t a 1 1 1... ... qt t t? ? ? ? ? ?     \(8 b rules using 1 1 1 1  k k n j j j t t j n j t j           9 We take the fuzzy mining process of excessive air coefficient as an example. The excessive air coefficient value is taken when the unit is in 300MW stable load and the coal consumption is lower \(lower than 355g/kW.h history data. Then the data is standardized and is mined by fuzzy mining algorithm. The following rule is output: When the load is 100% and coal consumption eB  \(g/kW.h 37.50, 43.75], the excessive air coefficient  is [34.5 35.7], with a support value of 62% and a confidence of 81 It satisfies the requirement of minimum support and  Step 10: Output the rules with confidence value larger than or equal to the predefined minimum confidence After Step 10, the rules constructed are output and can act as the meta-knowledge for the given transaction. It is expressed based on reasoning and is easy to be understood 4.  The application of fuzzy data mining in operation optimization Based on the history data of a 300MW power plant unit, the typical parameters which are related to operation optimization are analyzed. Those parameters include load main steam pressure, main steam temperature, re-heated temperature, feed water temperature, exhaust gas temperature, excessive air coefficient and so on. The quantitative association rules are acquired by analyzing the history data. For example, load    1... nL L 1... nP P 1 1... mT T g gnB B related to low coal consumption are chosen as optimization values to optimal the electric industrial process. The rules to decide the optimal parameters values are expressed as 


to decide the optimal parameters values are expressed as 1 1   this way the optimal operation parameters are decided according to the load and the other related condition. The optimization values attained from data mining are reachable in operation and can reflect the actual status in operation According to the method mentioned above, the history data from recent three months are analyzed. A total of 4212 transactions consisted of the operation parameters of the typical stable load of 100%, 90% and 80% are obtained These transactions are standardized by formula \(1 minimum support value is set at 30% and the minimum confidence is set at 75%. The membership function of the parameters is shown in Figure 2 75 82 86 92686458  1 Low Middle High 0.5  Figure 2. The membership function 1645 Proceedings of  the Fourth International Conference on Machine Learning and Cybernetics  Guangzhou, 18-21 August 2005 minimum confidence. This rule can be expressed as The corresponding range is This rule means that when the load is 300MW and the coal consumption is lower the optimal range of the excessive air coefficient is 1.342~1.350. The average of the interval can be adopted to decide the optimization point. The optimization value of excessive air coefficient 100 ,34.5,35.7eM ?&lt; &gt;?&lt 300 ,1.34eM MW ?&lt; &gt;?&lt gt gt;2,1.350 is set at 1.346 when the load is 300MW \(100 the method mentioned above, by utilizing the fuzzy association algorithm to mine the optimization value when the typical load of 100%, 90% and 75%, etc, a set of optimization values is obtained. The optimal values attained from the fuzzy data mining and the reference values attained in traditional way are listed in Table 1 300MW 16.67 Referenc Optimal Parameters Main steam temperature Reheat temperature Feed water temperature Flue gas temperature Excessive air coefficient Main Steam Pressure MPa 537 537 270.5 138.4 137.1 1.352 1.346 16.71 538.3 538.1 


538.1 268.1 270MW e/ Referenc Optimal 16.67 537 537 264.2 135.2 133.6 1.432 1.431 16.66 538.1 537.4 264.6 Table 1. Optimization value analysis result of 300MW power unit 225MW e/ Reference Optimal 13.89 537 537 254.1 129.8 130.4 1.480 1.484 13.96 537.2 535.4 258.4  The controllable parameters are optimized based on the results of the fuzzy data mining in power plant. The performance of the boiler improved obviously. The average boiler efficiency improved about 0.924% and the coal consumption reduced about 3.72g/kW.h. The optimization value is close to the reference value in trend and can be used to guide the industry process. The newly founded rules and knowledge can be added to model base or the knowledge base. The operation optimization base on data mining is an effective method to improve the efficiency in power plant The execution times of fuzzy association mining in different minimum support with a computer Pentium 1.7G/256M are shown in Figure 3. For a total of about 4000 transactions in the data set and the minimum support is set at 20%, the execution time is about 150s. The fuzzy association mining is high efficiency. The execution time of fuzzy association mining increases linearly with the transactions in data set. So it is applicable to large data sets 80% 60% 40% 20 50 100 150 200 minimum support tim e s  Figure 3. The time of fuzzy association mining in different minimum support 5. Conclusion The operation optimization is the mainly method to improve the performance in power plant and the decision of optimization value is the key point in operation optimization. In this paper, we proposed the operation optimization based on data mining and applied the fuzzy 


optimization based on data mining and applied the fuzzy association rules to find the optimization value from the history data of the equipments in power plant. The fuzzy sets theory was introduced into the association mining process in order to soften the partition boundary of the domain and generalize and abstract the data. Base on the history data in power plant, the optimization values are reachable in operation and easy to guide operation. The rules mined out exhibit quantitative regularity in large database and can be used to provide guides and suggestions to the appropriate operator. Experimental results with the data in a 300MW power plant show that the algorithm base on fuzzy set operation performs very well and can be used to guide the operating process to achieve a good performance References 1] Wang X Z  Automatic classification for mining process operational data  Ind. Eng. Chem. Res., 37 pp.2215-2222, 1998 2] Tony Ogilvie, B W Hogg  Use of data mining techniques in the performance monitoring and operation of a thermal power plant  IEEE Colloquium on Knowledge Discovery and Data Mining, 1998 3] Ren HaoRen, Li Wei  The analyze of operation index for the power unit under different loads  Proceedings of the CSEE, Vol 19, No. 9, pp.50-52,56, 1999 4] Agrawal R, Imielinski T, Swami A  Mining 1646 Proceedings of  the Fourth International Conference on Machine Learning and Cybernetics  Guangzhou, 18-21 August 2005 association rules between sets of items in large database  Proc of the ACM SIGMOD conf on Management of data, Washingtong D.C, pp.207-216 May 1993 5] Agrawal R, Srikant R  Fast algorithms for mining association rules in large databases  The International Conference on Very Large Data Bases, Santiago, Chile pp. 487-499, 1994 6] Srikant R, Agrawal R  Mining quantitative association rules in large relational tables   Proceedings of the ACM SIGMOD International Conference on Management of Data, Montreal Canada, pp.1-12, 1996 7] Zou XiaoFeng, LU JianJian, Song ZiLin  Mining linguistic valued association rules  Journal of System Simulation, Vol 14, No. 9, pp.1130-1132, 2002 8] T. P. Hong, J. B. Chen  Finding relevant attributes and membership functions  Fuzzy Sets and Systems Vol 103, No. 3, pp.389-404, 1999 9] T.P.Hong, C.S.Kuo, S.C.Chi  Mining association rules from quantitative data  Intelligent Data Analysis, Vol 3, No. 5, pp.363-376, 1999   1647 pre></body></html 


0-7695-2263-7/05 $20.00  2005 IEEE pre></body></html 


n M L N n t n t n t n t L M L t L t L tt L t kkkk kkkk kkk kkkk kkkkkkkkP VK VK VK VK PP       kkP t 31 where L  s the error covariance associated with the state estimate t i    kkLX  tt kkk P1  00 0  0                     s s sss s s sss s s sssss N n t n t n 


n t n N n t n t n t n N n t n t n t n t n t n c t L kkkkkk kkkkk kP VKVK VKVK  32 4. Simulations One has run simulations comparing the sequential implementations of MSJPDA algorithm and the new algorithm here. A typical multisensor multitarget tracking environment is assumed in the simulations. According to article [1,3], One known that the performance of sequential MSJPDA is better than the performance of parallel MSJPDA. Therefore, the performance of parallel MSJPDA algorithm will not be compared here There are three sensors, which are fixed in three platforms. Regarding the 2nd sensor as fusion centre situation of the other sensors are: =?-500m?-500m 0m??N =?-500m? 500m?0m??The distance error of each sensor is: =300m, =200m, =100m?The bear error of each sensor is 0.03rad, =0.02rad, =0.01rad?The of sample is T=1s?The nonparametric model of clutter is used in the simulations, and expected number of false measurement is m=1.8 1 sN 3 s 1r 2 2r 3 3r 1 Simulations have been run for racking two targets. The true initialization state of the targets is X1?[-29500m,400m/s,34500m,-400m/s X ?[-26250m,296m/s,34500m,-400m/s]'? 2 The two targets will cross above 31seconds later. To evaluate tracking performance, 50 Monte Carlo runs were performed for three case of the target detection probability Pd=0.97 ? Pd=0.76 ? Pd=0.58. In every run, the total simulation time is 140 steps 


simulation time is 140 steps            Figure 1  RMS position error in case of Pd=0.97          Figure 2  RMS velocity error in case of Pd=0.97       Figure 3  RMS position error in case of Pd=0.76 567 Proceedings of  the Fourth International Conference on Machine Learning and Cybernetics  Guangzhou, 18-21 August 2005         Figure 4  RMS velocity error in case of Pd=0.76         Figure 5  RMS position error in case of Pd=0.58          Figure 6  RMS velocity error in case of Pd=0.58  Table 1 The emanative times comparison for sequential MSJPDA and SD-CMSJPDA algorithm  Pd N A  0.97 0. 76 0.58 Sequential MSJPDA 2 11 17 SD-CMSJPDA 0 3 5 Pd denotes detection probability, N denotes emanative 


Pd denotes detection probability, N denotes emanative times, A denotes the kind of algorithm Table 1 shows the summation of emanative times for sequential MSJPDA and SD-CMSJPDA algorithm in 50 Monte Carlo simulations. From table 1 , it is shown that the stability of SD-CMSJPDA is better than that of sequential MSJPDA as the detection probability varied Figure 1,2 show the RMS errors for position and velocity in case of Pd=0. 97, respectively; Figure 3,4 show the RMS errors for position and velocity in case of Pd=0.76 respectively; Figure 3,4 show the RMS errors for position and velocity in case of Pd=0.58, respectively. From the figures we can see that the average RMS position error is lower for the SD-CMS JPDA algorithm. We also see that the state estimation precision of sequential MSJPDA get worse as the detection probability decreases The reasons for these simulation results lies:1 state estimation precision will get worse when the detection probability decrease;2 algorithm is to process measurement from each sensor using single sensor JPDA algorithm sequentially. Therefore the estimation error from each sensor will be accumulated Moreover, the sequential MSJPDA algorithm can  t improve the joint detection probability of the multisensor system The estimation error of the SD- CMSJPDA  algorithm will not be accumulated for it processes the measurement from each sensor directly in the mean time .What  s more the new method can greatly improve the joint detection probability of the multisensor system. Therefore, the tracking performance of SD-CMSJPDA algorithm is better than that of sequential MSJPDA. Algorithm All of the simulations are run in the personal computer with a 2.0G CPU and a 256M memory. The average cost time per step is 0.0251 in the sequential implementations of MSJPDA algorithm. And the average cost time per step is 0.0282 in the sequential implementations of MSJPDA algorithm. According to the results we can see that there is few difference in real time between the new method and the sequential   MSJPDA when there is not so many sensors and targets 568 Proceedings of  the Fourth International Conference on Machine Learning and Cybernetics  Guangzhou, 18-21 August 2005  5. Conclusion In order to solve the problem of multisensor multi target tracking, a new centralized multisensor  joint probabilistic data association  algorithm is proposed in this paper. The simulation results shows that the tracking performance of the new algorithm is better than that of the sequential MSJPDA algorithm The computational complexity of the new method will increase as the number of sensors and targets grow Therefore, how to improve the real time of SD- CMSJPDA algorithm will be pay attention References 1] He You, Wang Guohong, Lu Dajin, Peng Yingning Multisensor Information Fusion With Application[M Publishion House of Electronics Industry. 2000, Beijing.  [11] B..Zhou and N.K.Bose Multitarget  Tracking in Clutter:Faste Algorithms for Data Association .IEEE Transaction on Aerospace and Electronic Systems 1993,29\(2 2] Bar-shalom,Y\(Ed Applications and Advances,2: Norwood,MA Artech  House, 1992 3] L.Y. Pao, C.W.Frei. A Comparison of Parallel and Sequential Implementation of a Multisensor Multitarget Tracking Algorithm. Proc. 1995 American Control Conf. Seattie, Washington,June 1995 1683~1687 


4] K. Chang, C. Chong, Bar-Shalom, Joint Probabilistic Data Association in Distributed Sensor Networks IEEE Transactions on Automatic Control, AC-31\(10 octobre 1986 5] Bar-shalom, Multitarget Multisensor Tracking Advanced Application ,:YBS Publishing, 1990 6] Bar-shalom, Multitarget Multisensor Tracking Principles and Techenices ,:YBS Publishing, 1995 7] Hu Wenlong, Mao shiyi, Multisensor Data Association Based on Combinatorial Optimization[J]. Journal of Systems Engineering and Electronics . 1997 NO.1,1~9 8] Pattipati K R, Passive Multisensor Data Association Using a New Relaxation Algorithm.In Multitarget-Multisensor Tracking: Advanced and Applications,Y.Barshalom,Norwood,MA:Aretech,199 0 9] Deb S,et al, An S-Dimentional Assignment Algorithm for Track Initiation ,Proc. Of the IEEE Int. Conf Systems Engineering, Kobe, Japan,Sept 1992 527~530 10] Deb S,et al, A Multisensor-Multitarget Data Association Algorithm for Heterogeneous Sensors[J].IEEE Trans. on AES 1993 ,29 \(2 560~568 12] Bar-shalom,Y.,and Fortmann,T.E  Tracking and Data Association  New York:Academic press,1988 13] J,A,Roecher and G.L.Phillis,Suboptimal Joint Probabilistic Data Association .IEEE Transaction on Aerospace Electronic Systems.1993,29\(2 14] J,A,Roecker,A Class of Near Optimal JPDA Algorithm IEEE Transaction on Aerospace and Electronic Systems,1994,30\(2 15] Han Yanfei, Analysis and Improvement of Multisensor Multitarget Probabbilistic Data Association Filting Algorithm[J].  Journal of Systems Engineering and Electronics, 2002, Vol.24, 36~38  569 pre></body></html 


dense data sets for evaluating pattern mining algorithms These two data sets are obtained from IBM Almaden at http://www.almaden.ibm.com/cs/quest/demos.html. Recently, theMAFIA algorithm [6] was proposed to ef?ciently discover maximal frequent patterns. As shown in their paper, MAFIA can be several orders better than some alternatives, such as DepthProject, for mining maximal frequent patterns. Hence, we chose MAFIA as the base line for our performance evaluation. Finally, please note that only the size-2 patterns are generated in the ?rst BFS phase Experimental Platform We implemented the MHP algorithms using C++ and all experiments were performed Proceedings of the 16th IEEE International Conference on Tools with Artificial Intelligence \(ICTAI 2004 1082-3409/04 $20.00  2004 IEEE on a Pentium III    MHz PC machine with    megabytes main memory, running Linux Redhat 6.1 operating system 5.2. A Performance Comparison 100 1000 10000 100000 1e+06 1e+07 1e+08 1e+09 1e+10 1e+11 0.02 0.025 0.03 0.035 0.04 0.045 0.05 0.055 0.06 N um be r o f C he ck ed P at te rn s Support threshold Mafia Min_Conf=0 Min_Conf=0.1 Min_Conf=0.3 Min_Conf=0.5 Min_Conf=0.7 Min_Conf=0.9 


Figure 4. The Number of Checked Patterns on the Pumsb* Data Set 10 100 1000 10000 100000 0.02 0.025 0.03 0.035 0.04 0.045 0.05 0.055 0.06 R un T im e s ec  Support Threshold Mafia Min_Conf=0 Min_Conf=0.1 Min_Conf=0.3 Min_Conf=0.5 Min_Conf=0.7 Min_Conf=0.9 Figure 5. The RunTime Comparison on the Pumsb* Data Set Figure 4 shows the number of patterns that MHP and MAFIA have to check during the pattern mining process on the pumsb* data set. As can be seen, for MHP, the number of checked patterns is increased with the decrease of the h-con?dence threshold. However, the number of checked patterns of MHP can be signi?cantly smaller than that of MAFIA even if a low h-con?dence threshold is speci?ed To check a pattern, we need to count the support of the patterns. Counting the support of a pattern is the most timeconsuming task during the pattern mining process, since we need to retrieve all the transactions which include one of its sub-pattern, or for Ma?a, retrieve all the bit of the bitmap of this pattern [6]. Therefore, an algorithm is more ef?cient if smaller number of patterns need to be checked 100 1000 10000 100000 1e+06 1e+07 1e+08 1e+09 0.1 0.2 0.3 0.4 0.5 0.6 0.7 N 


um be r o f C he ck ed P at te rn s Support Threshold Mafia Min_Conf=0.5 Min_Conf=0.7 Min_Conf=0.9 Figure 6. The Number of Checked Patterns on the Pumsb Data Set 10 100 1000 10000 0.1 0.2 0.3 0.4 0.5 0.6 0.7 R un T im e s ec  Support Threshold Mafia Min_Conf=0.5 Min_Conf=0.7 Min_Conf=0.9 Figure 7. The RunTime Comparison on the Pumsb Data Set The runtime comparison of MHP and MAFIA on the Pumsb* data set is shown in Figure 5. In the ?gure, we can observe that the runtime of MHP can be signi?cantly reduced with the increase of h-con?dence thresholds. Also the runtime of MHP can be several orders of magnitude less than that of MAFIA even if the h-con?dence threshold is as low as 0.3. The reason is that the number of checked patterns of MHP is sign?cantly smaller than that of MAFIA Similar results are also obtained from the pumsb data set as shown in Figure 6 and Figure 7. For the pumsb data set the number of checked patterns of MHP is much smaller 


than that of MAFIA and the runtime of MHP can be significantly less than that of MAFIA 5.3. The Effect of the MHP Algorithm on Finding Maximal Hyperclique Patterns Figure 8 and Figure 9 show the number of maximal patterns identi?ed byMHP andMAFIA on Pumsb* and Pumsb data sets respectively. As can be seen, the number of maximal hyperclique patterns identi?ed by MHP can be orders of magnitude smaller than the number of maximal frequent patterns identi?ed by MAFIA. In other words, the number Proceedings of the 16th IEEE International Conference on Tools with Artificial Intelligence \(ICTAI 2004 1082-3409/04 $20.00  2004 IEEE 100 1000 10000 100000 1e+06 1e+07 1e+08 1e+09 0.02 0.025 0.03 0.035 0.04 0.045 0.05 0.055 0.06 N um be r o f C ou nt ed P at te rn s Support Threshold Mafia Min_Conf=0 Min_Conf=0.1 Min_Conf=0.3 Min_Conf=0.5 Min_Conf=0.7 Min_Conf=0.9 Figure 8. The Number of MFI/MHP Patterns in the Pumsb* Data Set 100 1000 10000 100000 1e+06 


1e+07 1e+08 0.1 0.2 0.3 0.4 0.5 0.6 0.7 N um be r o f C ou nt ed P at te rn s Support Threshold Mafia Min_Conf=0.5 Min_Conf=0.7 Min_Conf=0.9 Figure 9. The number of MFI/MHP Patterns in the Pumsb Data Set of maximal hyperclique patterns is much easier to manage than that of maximal frequent patterns. Indeed, in realworld applications, it is dif?cult to interpret several million maximal frequent patterns. However, it is possible to interpret the results of maximal hyperclique pattern mining In addition, due to the memory limitation, we cannot extract maximal frequent patterns with MAFIA on the Pumsb data set if the support threshold is less than 0.4, as shown in Figure 7. In contrast, MHP can identify maximal hyperclique patterns when the support threshold is 0.1, if we set the h-con?dence threshold to 0.5. In other words, MHP has the ability to identify patterns which can be dif?cult to identify for MAFIA. Hence, MHP can better explore the pattern space and ?nd interesting patterns at low levels of support 6. Conclusions and Future Work In this paper, we present a two-phase Maximal Hyperclique Pattern \(MHP best features of both the BFS strategy and the DFS strategy. More speci?cally, we adapted DFS pruning methods such as equivalence pruning, to an apriori-like approach In addition, we proved the correctness and completeness of the MHP algorithm. Finally, our experimental results show that the MHP algorithm can be several orders of magnitude faster than standard maximal frequent pattern mining algorithms and has the ability to identify patterns at extremely low levels of support in dense data sets There are several directions for future work. First, in 


this paper, we only generate the size-2 patterns in the BFS phase. It will be interesting to investigate the impact on the performance if the ?rst phase is stopped at a deeper level Also, the projection is a very ef?cient method for ?nding patterns, especially for parallel implementation of pattern mining algorithms [1]. We plan to adapt the projection ideas into our algorithm and design an ef?cient parallel algorithm for mining maximal hyperclique patterns References 1] R. Agarwal, C. Aggarwal, and V. Prasad. A Tree Projection Algorithm For Generation of Frequent Itemsets. pages 350 371, Feb 2001 2] R. Agrawal, T. Imielinski, and A. Swami. Mining Association Rules between Sets of Items in Large Databases. In Proc. of the ACM SIGMOD Conference on Management of Data, pages 207216,May 1993 3] R. Agrawal and R. Srikant. Fast Algorithms for Mining Association Rules. In Proc. of the 20th Intl Conference on Very LargeData Bases, 1994 4] R. Bayardo. Ef?ciently mining long patterns from databases In Proc. of the ACM SIGMOD Conference, 1998 5] R. Bayardo and R. Agrawal. Mining the Most Interesting Rules. In Proc. of the ACM SIGKDD Conference, 1999 6] D. Burdick, M. Calimlim, and J. Gehrke. Ma?a: AMaximal Frequent Itemset Algorithm for Transactional Databases. In Proc. of IEEE Conf. on Data Engineering, 2001 7] Y. Huang, H. Xiong, W. Wu, and Z. Zhang. A Hybrid Approach for Mining Maximal Hyperclique Patterns. In In Technical Report UTDCS-34-04, Department of computer science, University of Texas - Dallas, 2004 8] J.Han, J.Pei, and Y. Yin. Mining Frequent Patterns without Candidate Generation. In Proc. of the ACM SIGMOD International Conference on Management of Data, 2000 9] M.J.Zaki and C.Hsiao. ChARM: An ef?cient algorithm for closed itemset mining. In Proc. of 2nd SIAM International Conference on Data Mining, 2002 10] R.Rymon. Search through Systematic Set Enumeration. In Proc. Third Intl Conference on Principles of Knowledge Representation and Reasoning, 1992 11] H. Xiong, M. Steinbach, P.-N. Tan, and V. Kumar. HICAP: Hierarchial Clustering with Pattern Preservation. In Proc. of 2004 SIAM International Conference on Data Mining \(SDM 12] H. Xiong, P.-N. Tan, and V. Kumar. Mining Strong Af?nity Association Patterns in Data Set with Skewed Support. In Proc. of the Third IEEE International Conference on Data Mining \(ICDM Proceedings of the 16th IEEE International Conference on Tools with Artificial Intelligence \(ICTAI 2004 1082-3409/04 $20.00  2004 IEEE 





