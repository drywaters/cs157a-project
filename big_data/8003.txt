Double-Hashing Operation Mode for Encryption Sultan Almuhammadi Ahmad Amro College of Computer Sciences and Engineering King Fahd University of Petroleum and Minerals Dhahran Saudi Arabia Emails muhamadi g201404360 In some cryptosystems hash-functions have been used for encrypting the data directly without block ciphers 10 This makes hash-based encryption a good candidate to replace block ciphers However hash-based encryption ciphers should be carefully designed to avoid possible vulnerability to some cryptanalysis techniques This paper proposes a new hash-based encryption scheme with a built-in mode of operation using double hashing We call it DHOME Double-Hashing Operation Mode for Encryption The built-in mode of operation in DHOME makes it capable of encrypting big data without block size restrictions The encryption key can be handled as either symmetric or asymmetric-key without much of changes in the encryption scheme itself or the encrypted data Moreover if a symmetric key is used in DHOME to encrypt data the ciphertext can be later decrypted using an asymmetric decryption key This can be achieved by just a small modi\002cation of the header of the ciphertext without changing the encrypted data itself The idea of the proposed scheme DHOME is to use two hashfunctions instead of a single hash function in existing hashbased ciphers With double hashing the proposed scheme is more secure against known cryptanalysis attacks than generic single-hash ciphers Moreover DHOME is designed to provide a secure stream ciphering scheme II B ACKGROUND The main difference between block ciphers and stream ciphers is de\002ned by Menezes et al in Handbook of Applied Cryptography Stream ciphers encrypt indi vidual characters usually binary digits of a plaintext one at a time using an encryption transformation which varies with time By contrast block ciphers tend to simultaneously encrypt groups of characters of a plaintext message using a 002xed encryption transformation Similar comparison was mentioned by R Rueppel in Block ciphers operate with a 002x ed transformation on large blocks of plaintext data Where stream ciphers operate with a time-varying transformation on individual plaintext digits Symmetric-key ciphers like AES are known for their performance but it is dif\002cult to achieve secure key negotiation using only symmetric ciphers in network environments where the keys are usually negotiated over insecure channels Therefore an asymmetric-key cipher like RSA is typically used to send the shared key that is later used in the symmetrickey cipher Hence a combination of both symmetric and asymmetric ciphers becomes the convention approach In this section we introduce some of the effective attacks on AES and discuss the security issues of hash functions Abstract 227Block ciphers hash-based encryption and publickey ciphers are examples of data encryption techniques with different desired features Strong block ciphers like AES must run in some mode of operation to encrypt data larger than the block size Public-key ciphers like RSA are costly and usually used for key-sharing rather than encrypting the data itself Generic single-hash ciphers are less secure than block ciphers and vulnerable to some cryptanalysis techniques In this paper we review some cryptanalysis techniques on AES and some hash-based cryptosystems We propose a new encryption scheme capable of encrypting big data and supporting both symmetric and asymmetric-key handling We discuss its security strength against known cryptanalysis attacks Unlike existing hash-based ciphers the proposed scheme uses double hashing instead of a single hash function With double hashing the proposed scheme totally eliminates the threat of known cryptanalysis attacks and provides a highly secure stream ciphering scheme by its new design Keywords 227 Block ciphers AES stream ciphers public-key hash functions I I NTRODUCTION Data encryption provides confidentiality as one of the most important goals of data security A well-know block cipher adopted by NIST in 2001 is the Advanced Encryption Standard AES 1 Since then AES has been widely used as standard in all file encryption and network protocols An earlier Data Encryption Standard DES has been used since 1977 which suffers many security issues due to its short key size which could not stand the technology advancement 2 Other versions of DES like 2DES and 3DES have used to overcome some of the security issues without much of success 3 Since its adoption by NIST AES has replaced all versions of DES in sensitive applications and proved that it is more secure mainly due to its larger block size and key size for almost two decades Block ciphers like AES and DES typically run in some mode of operation Secure hash functions are commonly used in these modes of operation to handle data larger than their limited block sizes Different modes of operations provide different desired security features 4 Recent research shows that the block size of AES can be targeted by several cryptanalysis techniques 5 6 7 With today's improving technology and availability of high computational power more sophisticated attacks on AES become feasible Therefore a new encryption algorithm is needed to replace AES in the near future Secure hashing was used initially to provide modes of operation with some desired features for block ciphers 8 978-1-5090-4228-9/17/$31.00 \2512017 IEEE 
 


A AES Attacks AES is a strong block cipher of size 128 bits which doubles the size of its predecessor DES Since its adoption by NIST in 2001 AES has been a target for cryptanalysis for several years Two cryptanalysis attacks on AES with improving results are the biclique attack and related-key attacks With biclique attack a key can be recovered faster than brute-force with computational complexity of 2 126  1  2 189  7 and 2 254  4 for AES-128 AES-192 and AES-256 respectively While with related-key attacks a key can be recovered with overall time complexity of 2 131 and memory complexity of 2 65  Other attacks are gaining progress in targeting reduced versions of AES more rounds are being attacked each time An attack mentioned in tar geted the 8-Round AES-192 and AES-256 and gained about 1 million times faster attack than exhaustive search with 1  32000 reduced data complexity The best attack on 9-round AES-256 is proposed in Building on the later attack the 002rst attack on 10-round AES256 was proposed in The authors claimed the attack can be achieved with data complexity of 2 111 chosen plaintexts 2 253 time complexity and 2 11  2 AES blocks for memory complexity The previous three attacks suggest a gradual progress in reaching a successful attack on full AES in the coming years Recently a new set of 003ush-and-reload attacks on AES where proposed in 6 and 7 The 003ush-and-reload attacks basically takes advantage of the resource sharing feature 050memory CPU etc.\051 in virtualization environments to capture information leaks from VMs to the host All these attacks take advantage of the small block size of AES 050128 bits\051 In three attack scenarios were tested one of them is claimed to recover the entire AES-128 key in only 15 seconds In the authors claimed only 6-7 plaintext or ciphertext blocks can lead to the recovery of the entire 128-bit AES key While in  an espionage netw ork is setup to calculate AES k e ys based on caching information leakage The authors claimed that their setup can recover the encryption key in less than 30 encryption operations A successful power-based side channel attack was conducted in The authors tar geted the softw are implementation of the ATmega328 microcontrollers The attack basically takes advantage of power related measurements to leak information about ongoing computations on the chip The attack time complexity is different from one key to another For example one key might require the collection of 600 traces for the encryption for a speci\002c plaintext while another key might require 300 traces In general to collect 100 traces it takes 30 minutes and few more to process B Hash Functions Security In the authors tar geted the SHA-512 hash function they implemented and improved guess-and-determine approach trying to get differential characteristics and colliding message pairs The improvements enabled the authors to enhance the semi-free-start collision attack on SHA-512 from 24 steps to 38 steps Despite this improvement on the attack it is still not ef\002cient to extend it to fully expose SHA-512 due to the increased word size Applying hash function iteration to increase security has been used for password-based encryption rather than data encryption A password-based encryption method is mentioned in  where combinations of passw ords and salts are used with some iterative count to repeat the process of key generation in a way that makes exhaustive search infeasible The difference between data encryption using our proposed method and the method of applying hash function iteration in is that in our proposed method a combination of two different hash functions is used without repetition to defy known-plaintext attacks rather than iterating the same hash function to increase the secrecy of a password Hash functions have been used as part of newly suggested encryption algorithms A new chaotic image encryption algorithm is proposed in The algorithm implements a hash function 050SHA-1\051 to generate a set of hash keys that are used as initial keys in further operations to provide diffusion and permutation In the authors implemented a T oeplitz hash value to generate a pseudorandom key stream for transmitting ECG signals securely in medical applications III A NALYSIS OF E XISTING H ASH B ASED C IPHERS Encryption using hash function has been possible since the starting of secure hashing functions Many of these approaches use a single hash function to generate pseudorandom bits which can be used as keys for encryption and decryption  21 22 23 In this section we e xplain the general framework of single-hash ciphers and elaborate on their vulnerability against known cryptanalysis techniques Some single-hash ciphers are more sophisticated such as and  W e will sho w possible cryptanalysis attacks on these ciphers as well A Generic Single-Hash Cipher Framework A hash-based cipher can be built in general with a single hash function The general framework of a single hash cipher is shown in Figure 1 Basically the scheme hashes the main key repeatedly to generate a key stream 050 k 1  k 2     k n 051  The scheme encrypts each segment p i of the plaintext by XOR-ing it with the key stream segment k i to generate the corresponding ciphertext segments c i  p i 010 k i  for i  1      n  We claim that any hash-based cipher built with a single hash function according to this general framework is vulnerable to known-plaintext attack Suppose the adversary knows some segment of the the plaintext say p j  then the adversary can compute k j  c j 010 p j and decipher all the segments after p j by Algorithm 1 Thus if the adversary knows the header of the 002le p 1  then the entire plaintext will be compromised  Algorithm 1 Known-Plaintext Attack on Generic Single-Hash Ciphers  Input known-plaintext segment 050 p j  c j 051 Output decrypted segments p j 1  p j 2   p n k j 040 c j 010 p j for i  j  1 to n do k i 040 h 050 k i 000 1 051 p i 040 c i 010 k i end for  
 


Fig 1 General Single-Hash Cipher framework B Message Encryption Algorithm Single hash ciphers can be more sophisticated and yet can still be attacked For example a patent was issued for a message encryption scheme that applies a single-hash function  This approach has tw o dif ferent methods In the 002rst method the 002rst part of a message is being encrypted using a key generated by the hash of the concatenation of a secret key and an initialization vector which is not a secret and the next key will be the hashing of the concatenation of both the previous key and the secret key and so on In the second method the output of the encryption process will be used to generate the next key segment We will discuss next some security issues in this approach and possible attacks The encryption algorithm requires a secret key K and an initialization vector IV  which is chosen at random at each time In the 002rst method of encryption both K and IV are used to generate a series of keys k i for i  1  2   n where n is the number of plaintext blocks The 002rst key k 1 is calculated using Equation 1 k 1  hash 050 K IV 051 0501\051 While the remaining keys k i for i  2   n  are calculated using Equation 2 k i  hash 050 K k i 000 1 051 0502\051 Then each ciphertext block c i is calculated from a plaintext block p i using Equation 3 for i  1  2   n  c i  k i 010 p i 0503\051 The message encryption algorithm presented here is clearly more secure than the generic single-hash cipher We cannot apply Algorithm 1 directly on this scheme since the main key K is used at every step of generating the key stream Moreover different initialization victors IV s generate different key streams even if the same key K is used However there are two possible vulnerabilities on this scheme 1\051 Known-Plaintext Attack It is important to observe that IV is sent in clear before the encryption takes place So an adversary can notice when the same IV is repeated If the adversary has access to a known pair of plaintext/ciphertext the key streams 050 k 1  k 2  001 001 001 051 can be calculated using Equation 4 k i  c i 010 p i 0504\051 Later if the adversary intercepts a ciphertext that is known to be encrypted using the same secret key K and the same IV  the plaintext can be obtained using Equation 5 for i  1  2   n  p i  c i 010 k i 0505\051 Notice that the IV is being chosen at random So unless the period of the random generator is large enough to make any repetition for both the key and the IV together highly unlikely the previous attack is feasible For example in a high speed network where each message is encrypted alone if the random generator produces 32-bit IV s some of them will repeat in less than few seconds according to the birthday problem which makes the scheme vulnerable to known-plaintext attack 2\051 Chosen-Ciphertext Attack The 002rst key segment is the output of hashing K concatenated with IV  The 002rst block of the plaintext is calculated by XOR-ing the hash output with the 002rst block of the ciphertext If an attacker has access to the decryption device he can feed it with a null ciphertext 050a binary value with all zeros\051 and a null IV 050empty string\051 When this null ciphertext is decrypted the 002rst block of the output would be the hash of the secret key k 1  hash 050 K 051  This information by itself does not mean that the cryptosystem is broken but it gives the attacker some useful information about the key Thus if the hash function is not secure the attacker can recover the key The patent for this scheme was issued in 1996 and it recommended the use of the MD4 hash function which is not secure anymore 25 C Image Encryption Algorithm Another example of a relatively new single-hash cipher is the image encryption algorithm presented In this cipher  a secret key is hashed into a corresponding SHA1 hash value and converted to a binary form Then the wavelet transform for the image is calculated and converted into binary string too The key is expanded to 002t the size of the image and XOR-ed bit-wise with the image string to create the encrypted image There is a weakness in this scheme that makes it vulnerable to known-plaintext attack The encryption algorithm takes a secret key K and a plain image P as input and generates an encrypted image C as an output The secret key K will be hashed using SHA1 hash function The output of the hash will then be expanded to match the size of the plain image The authors did not specify how the key was expanded Let us assume that some expansion function F exp is used and the result of F exp is the encryption key K enc as shown in Equation 6 K enc  F exp 050 SHA1 050 K 051\051 0506\051 
 


The plain image P will be XOR-ed with the encryption key K enc to produce the encrypted image C using Equation 7 C  P 010 K enc 0507\051 Using known-plaintext attack a similar method to Algorithm 1 can be applied to compute the encrypted key K enc and recover the original image Suppose an adversary has a known pair of the image P 0 and the encrypted image C 0  he can calculate the encryption key K enc using Equation 8 which will always be the same for the same secret key K  K enc  P 0 010 C 0 0508\051 Later if the adversary intercepts an encrypted image C that is known to be encrypted using the same secret key K  The original image can be obtained using Equation 9 P  K enc 010 C 0509\051 This attack is highly likely to occur since the shared secret key K is not periodically changing which implies it always generates the same encryption key K enc  Using this attack the adversary can record all transactions between two communicating entities and upon acquiring a pair of plain/encrypted images all other encrypted images can be easily decrypted without even knowing the secret key IV A N EW E NCRYPTION S CHEME Given the potential attacks on AES presented in Section II-A and the cryptanalysis of single-hash ciphers explained in Section III there is a rapidly growing need for a more secure encryption algorithm We propose a new encryption scheme DHOME which stands for Double-Hashing Operation Mode for Encryption The proposed scheme is more secure than other hash-based ciphers and with a built-in mode of operation Unlike many of the existing hash-based encryption schemes the proposed algorithm uses two secure hashing functions to generate a pseudorandom sequence of bits that can be used as a key to encrypt the plaintext P in a simple XOR operation We show that by applying double hashing we create more confusion and diffusion that ensure the security of the proposed scheme Moreover the proposed scheme can be used with symmetric or asymmetric-key In our implementation we assume the plaintext is given in some input 002le and the ciphertext is generated and saved in an output 002le However the design of DHOME is independent of this assumption Thus these input and output 002les can be replaced by any two parties like sender and receiver in network communication In this section we explain the proposed scheme according to its design Figure 2 shows the block diagram of the proposed encryption scheme It uses two hash functions h and f  The plaintext is processed in segments P  p 1  p 2      p n  each of length equals to the output length of f  The ciphertext is also computed in segments C  c 1  c 2      c n  where each segment c i of the ciphertext is corresponding to one segment of the plaintext p i  plus an additional header of the ciphertext c 0  We recommend the use of two secure hash functions namely SHA-384 and SHA-512 for h and f respectively as explained in Section IV-D Therefore each plaintext/ciphertext segment is 512 bits The last segment p n can have less than 512 bits without padding and it is XOR-ed with same number of bits of the key segment k n  The rest of k n can be truncated A Encryption Algorithm The encryption algorithm of DHOME runs as follows First it generates a suf\002ciently large random integer seed of at least 512 bits to be used in generating the key stream K  The scheme encrypts the seed and stores the encrypted seed in the header c 0  Then the seed is hashed using a secure hash function h and the output of the hash function h 1  h 050 seed 051  is hashed repeatedly to generate a sequence of n pseudorandom values H  h 1  h 2   h n  where h i  h 050 h i 000 1 051  and n is the number of the plaintext/ciphertext segments This sequence is later used to generate the key stream K  k 1  k 2   k n  To resist known-plaintext and chosen-ciphertext attacks the relation between the key stream K and the pseudorandom values H should be hidden We achieve this by doublehashing  Thus we apply another secure hash function f on the pseudorandom values H to obtain the key stream i.e k i  f 050 h i 051 for i  1  2   n  The key stream K is then used to encrypt the plaintext by XOR operation So each segment of the resultant ciphertext is computed by c i  p i 010 k i  The steps of the encryption algorithm are outlined in Algorithm 2  Algorithm 2 Encryption Algorithm  Input plaintext P  p 1  p 2   p n  key Output ciphertext C  c 1  c 2   c n  c 0  Seed enc seed 040 Large  random  number Seed enc 040 Encrypt 050 key seed 051 h 0 040 seed for i  1 to n do h i 040 h 050 h i 000 1 051 k i 040 f 050 h i 051 c i 040 p i 010 k i end for  B Symmetric and Asymmetric-key Options There are two key options allowed by the proposed scheme 050a\051 Symmetric-key Mode and 050b\051 Asymmetric-key Mode as shown in Figure 3 In the Symmetric Mode the scheme can be used as a symmetric-key cipher by applying the shared symmetric secret key with any secure symmetric cipher at both sides 050sender and receiver\051 While in the Asymmetric Mode the scheme can be used as asymmetric-key cipher by applying two different keys 050public and private\051 on any secure asymmetric-key cipher It is important to note that the symmetric and asymmetric ciphers are only used in DHOME to encrypt/decrypt the seed  not the data itself Therefore the high cost associated with the asymmetric cipher and the overhead associated with the mode of the operation of the symmetric cipher are not effecting the cost and the performance of DHOME Moreover if DHOME is used in Symmetric Mode to encrypt big data then later the users want to use Asymmetric Mode the only part needs to be replaced is the header of the 
 


Fig 2 Block Diagram of DHOME ciphertext c 0  The sender can encrypt the seed using the public key of the receiver and send the new header c 0 with the same ciphtertext C  without re-enctypting the whole data Fig 3 Seed Encryption Modes C Security Analysis Discussing the security of the proposed scheme can be made through discussing the design issues of DHOME that make the new scheme resist the cryptanalysis attacks on singlehash ciphers namely known-plaintext and chosen-ciphertext attacks We show that DHOME is highly secure against these attacks 1\051 Known-Plaintext Attack Proof In known-plaintext attacks the adversary has access to a pair of plaintext/ciphertext and wants to either compute the key or decipher another ciphertext What makes the proposed scheme resilient against such attack is the application of double-hashing Unlike singlehash ciphers the proposed scheme uses two hash functions Therefore if an adversary has access to a known plaintext segment 050 p i  c i 051 only the corresponding key segment k i is compromised by Equation 4 The adversary cannot compute any other key segment k j for j 6  i since this requires 224unhashing\224 of f to compute h i  f 000 1 050 k i 051  which is equivalent to breaking SHA-512 Moreover suppose the adversary has access to a whole plaintext/ciphertext pair 050 P C 051 Even though the whole key stream will be compromised by Equation 4 both the main key and the seed remains secure The key stream is just a random sequence of bits that is used to compute C from P  or P from C  nothing more This helps avoiding the security issue that exists in Ev en i f the main k e y is not changed each encryption process has a unique key stream due to the application of a large random seed at the beginning of each encryption process Therefore the subsequent hashes initiated with the random seed will produce a different key stream every time Also to avoid the possibility of repeating the same key with the same value of the seed it is a requirement to implement a random generator of output size 512-bit or more This requirement was not mentioned in 2\051 Chosen-Ciphertext Attack Proof In chosen-ciphertext attacks an adversary has access to the decryption device without knowledge of the embedded key So the adversary can apply the decryption algorithm on some input ciphertext of his choice and recover the output plaintext in the hope of exposing the key Unlike the message encryption scheme mentioned in  this attack has no ef fect ag ainst this approach since the embedded key will only be used to decrypt the seed The key has no effect on the output plaintext Also the value of the seed cannot be derived from the plaintext due to the application of not only one but two secure hash functions 
 


D Sensitivity Testing The security aspects of a group of known hash functions were evaluated using sensitivity tests The targeted hash functions are SHA-512 SHA-384 SHA-256 MD5 and MD4 The randomness of a hash function output is a key measurement of its security To acquire accurate measurements of the randomness of each targeted hash function an intensive sensitivity test was conducted The idea here is to see how many output bits may change if a single input bit is changed Each hash function was tested using the sensitivity test shown in Algorithm 3 To test a hash function h of output length 024 bits the algorithm generates r random strings of length 024  For each random string w  the hash value h w is computed Then a single bit in w is 003ipped and a new hash value h  w is computed These two hash values are compared to each other and the percentage of their Hamming distance to their length is recorded in the sensitivity matrix The location of the 003ipped bit varies from 1 to 024 for each tested hash function The algorithm computes and returns the sensitivity matrix where Sensitivity  i j  indicates the percentage of the change in the output of hashing the  th random string when a single input bit at location i is 003ipped The ideal sensitivity score is 50  Algorithm 3 Sensitivity Test  Input hash output length 050bits\051 024 number of random strings r Output sensitivity matrix Sensitivity  024 r  for i  1 to 024 do for j  1 to r do w 040 random  string 050 024 051 h w 040 h 050 w 051  w 040 bit  f lip 050 w i 051 h  w 040 h 050  w 051 016 040 Hamming  distance 050 h w  h  w 051 Sensitivity  i j  040 050 016=\024 051 002 100 end for end for  In the sensitivity test we run the algorithm for r  100 random strings and calculated the minimum maximum and average sensitivity values for each bit location and for all the 002ve hash functions The results of all the 002ve tests are shown in Figure 4 Each point 050 x y 051 in Figure 4.a represents the average sensitivity score y of the bit at location x computed by Equation 10 While the points in Figures 4.b and 4.c represent the minimum and the maximum scores computed by Equations 11 and 12 respectively y  r X j 1 Sensitivity  x j  r 05010\051 y  min 8 j 050 Sensitivity  x j  05011\051 y  max 8 j 050 Sensitivity  x j  05012\051 Table I summarizes the sensitivity test results numerically It shows the output length the average the minimum and the maximum score ranges of all the 002ve hash functions Fig 4 Results of Hash Functions Sensitivity Scores 050a\051 Average 050b\051 Minimum 050c\051 Maximum TABLE I N UMERICAL R ESULTS OF THE S ENSITIVITY T ESTS   Function  024 050bits\051  Average 050%\051  Minimum 050%\051  Maximum 050%\051    SHA-512  512  49.79 50.23  39.65 44.34  55.47 60.35    SHA-384  384  49.75 50.26  37.50 43.75  56.51 61.72    SHA-256  256  49.74 50.24  36.72 42.19  57.81 62.89    MD5  128  49.71 50.28  31.25 38.28  61.72 69.53    MD4  128  49.51 50.36  28.13 38.28  60.94 72.66   It can be noticed in Figure 4.a and the average column in Table I that all the hash functions provide good average sensitivity scores since all the average scores are close to 50 in almost all bit locations For example the average sensitivity scores of all the bits in SHA-512 are between 49.79 and 50.23 as shown in Table I which are not far from the average scores of the bits in other hash functions like MD4 and MD5 Therefore the average sensitivity score does not re\003ect which hash function is better than the others However as noticed in Figures 4.b and 4.c and the minimum and maximum columns in Table I both the minimum and maximum scores clearly re\003ect which hash function is better than the others SHA-512 scores are the closest to the ideal sensitivity score Then SHA-384 comes in the second place and SHA-256 comes next While both MD4 and MD5 scores are relatively far from the ideal score of 50 These results suggest favouring the SHA family rather than the MD family as candidates for the implementation For DHOME implementation the same hash function cannot be used in both h and f hashing devices This will con\003ict with the double-hashing feature and allow knownplaintext attack Moreover we observed that using a second hash function f with a large output length will increase the plaintext segment length which slightly speeds up the encryption and decryption processes and gives better overall performance Therefore we recommend using SHA-512 for f and SHA-384 for h in DHOME implementation 
 


V C ONCLUSION In a quest aiming to provide a secure and ef\002cient solution for maintaining data con\002dentiality we proposed a new hashbased encryption scheme 050DHOME\051 that is designed to avoid the security issues existed in single-hash ciphers The security issues of the proposed scheme are discussed and compared to the security of some single-hash ciphers The double-hashing design in DHOME makes it more secure than other existing hash-based ciphers The built-in mode of operation in DHOME makes the encryption of big data a straightforward task without block size restrictions DHOME allows two modes of encryption The encryption key can be handled as either symmetric or asymmetric-key without much of changes in the encryption scheme itself Moreover DHOME makes it easier to switch from symmetric to asymmetric-key and vice versa without changing the encrypted data itself This can be achieved by just a small modi\002cation of the header of the ciphertext Furthermore DHOME can be very useful in cloud data sharing with the advantage of the header of the ciphertext Suppose some big data in the cloud is encrypted using DHOME The user can share the data later by re-encrypting the seed and sharing the new ciphertext header without the need of encrypting the whole data or changing his secret or private key Thus the encrypted data stays as is in the cloud only the seed is encrypted and shared as needed As for future work DHOME can be utilized in cloud applications very effectively The header of the ciphertext makes the scheme suitable for encrypting and sharing big data on the cloud with its simple and elegant key handling mechanism A CKNOWLEDGMENT The authors would like to thank King Fahd University of Petroleum and Minerals Dhahran Saudi Arabia for supporting this research Figures and descriptions in this paper were provided by the authors and are used with permission R EFERENCES  J Daemen and V  Rijmen The design of Rijndael AES-the advanced encryption standard  Springer Science  Business Media 2013  E Biham and A Shamir  Differential cryptanalysis of the data encryption standard  Springer Science  Business Media 2012  O P  V erma R Ag arw al D Dafouti and S T yagi 223Peformance analysis of data encryption algorithms,\224 in Electronics Computer Technology 050ICECT\051 2011 3rd International Conference on  vol 5 IEEE 2011 pp 399\226403  M Dw orkin 223Recomm endation for block cipher modes of operation methods and techniques,\224 DTIC Document Tech Rep 2001  B G 250 ulmezo 013 glu M S Inci G Irazoqui T Eisenbarth and B Sunar 223A faster and more realistic 003ush reload attack on aes,\224 in International Workshop on Constructive Side-Channel Analysis and Secure Design  Springer 2015 pp 111\226126  B Ro y  R P  Giri C Ashokkumar  and B Menezes 223Design and implementation of an espionage network for cache-based side channel attacks on aes,\224 in Proceedings of the 12th International Conference on Security and Cryptography  2015 pp 441\226447  C Ashokkumar  M B S V enkatesh R P  Giri and B Menezes 223Design implementation and performance analysis of highly ef\002cient algorithms for aes key retrieval in access-driven cache-based side channel attacks,\224 2016  J Black and P  Rog a w ay  223 A block-cipher mode of operation for parallelizable message authentication,\224 in International Conference on the Theory and Applications of Cryptographic Techniques  Springer 2002 pp 384\226397  C W  Kaufman and R J Perlman 223Message encryption using a hash function,\224 Jan 9 1996 uS Patent 5,483,598  T  Bandyopadh yay  B Bandyopadh yay  and B C hatterji 223Secure image encryption through key hashing and wavelet transform techniques,\224 International Journal of emerging technology and Advanced engineering  vol 2 pp 26\22631 2012  A J Menezes P  C V an Oorschot and S A V anstone Handbook of applied cryptography  CRC press 1996  R A Rueppel 223 Analysis and design of stream ciphers communications and control engineering series,\224 Springer-Verlag Berlin Heidelberg  1986  S V ande v en 223Ssl/tls Whats under the hood 224 SANS Institute InfoSec Reading Room  vol 13 2013  A Bogdano v  D Kho vrato vich and C Rechber ger  223B iclique cryptanalysis of the full aes,\224 in International Conference on the Theory and Application of Cryptology and Information Security  Springer 2011 pp 344\226371  A Bi ryuk o v  D Kho vrato vich and I Nik oli 264 c 223Distinguisher and related-key attack on the full aes-256,\224 in Advances in CryptologyCRYPTO 2009  Springer 2009 pp 231\226249  O Dunk elman N K eller  and A Shami r  223Impro v ed single-k e y attacks on 8-round aes-192 and aes-256,\224 in International Conference on the Theory and Application of Cryptology and Information Security  Springer 2010 pp 158\226176  L Li K Jia and X W ang 223Impro v ed single-k e y attacks on 9-round aes-192/256,\224 in International Workshop on Fast Software Encryption  Springer 2014 pp 127\226146  R Li and C Jin 223Meet-in-the-middle attacks on 10-round aes-256 224 Designs Codes and Cryptography  pp 1\22613 2015  U Banerjee L Ho and S K oppula 223Po wer based s ide-channel attack for aes key extraction on the atmega328 microcontroller,\224 2015  M Eichlseder  F  Mendel and M Schl 250 affer 223Branching heuristics in differential collision search with applications to sha-512,\224 in International Workshop on Fast Software Encryption  Springer 2014 pp 473\226488  B Kaliski 223Pkcs 5 P assw ord-based cryptograph y speci\002cation v er sion 2.0,\224 2000  T  Gopalakrishnan and S Ramakrishnan 223Chaotic image encryption with hash keying as key generator,\224 IETE Journal of Research  pp 1\226 16 2016  K P andian and K C Ray  223Dynamic hash k e y-based stream cipher for secure transmission of real time ecg signal,\224 Security and Communication Networks  vol 9 no 17 pp 4391\2264402 2016  X W ang X Lai D Feng H Chen and X Y u 223Cryptanalysis of the hash functions md4 and ripemd,\224 in Annual International Conference on the Theory and Applications of Cryptographic Techniques  Springer 2005 pp 1\22618  H Dobbertin 223Cryptanalysis of md4 224 Journal of Cryptology  vol 11 no 4 pp 253\226271 1998 
 


2728 IEEE TRANSACTIONS ON IMAGE PROCESSING VOL 26 NO 6 JUNE 2017 Algorithm 1 Hierarchical ICM The gradient corresponding to patch n at scale l is  E    s n  l     l  n   s n    v  V    s n  l   s  l v n      n  h  h  B  l  n    s n  l    s h  l       n  q  q  Q  l  1  n    s n  l    s q  l  1     H   s n  5 where   x  y    g  x  y   x   y 2  x 015 1    x  y  2 An advantage of this local model is that the complexity and computational cost are greatly reduced We can easily extend this model to include relations with other neighboring SMNs both observed and latent without increasing signiﬁcantly the complexity see Fig 6c Note that these new neighboring relations are not part of the original global model of Fig 6a Including these extended relations in the global model and solving the optimization problem would be very difﬁcult since the extended connections destroy the factorization into pairwise factors requiring higher order factors and the corresponding energy terms in the formulation 2 Scale-Wise Message Passing Algorithm A different view of the hierarchical ICM is as neighboring patches sending  Fig 7 Optimization using message passing a one step of hierarchical ICM b-c two steps of the top-down scale-wise message passing algorithm for scale l and l  1 update messages to the current patch and then moving to the next one see Fig 7a A message passing algorithm consists of update messages and a schedule for the updates Algorithm 1 has the problem that each update may depend on both updated and not updated values Here we study different message passing strategies as an alternative First we consider sending update messages directly in the global model All nodes receive and send messages simultaneously in parallel which are then updated at the same time as  s n  l   s n  l   s n  l   The update is computed as  s n  l     v  V msg  n  l v  n  l       n  h  h  B  l  n msg  h  l   n  l       n  q  q  Q  l  1  n msg  q  l  1   n  l     H   s n  6 with msg  h  l   n  l     E    s n  l     l  n   s n  Note that each message solves a local optimization problem as in previous section Since the information from top scales of CNNs is usually more reliable we devise a scale-wise message passing algorithm Algorithm 2 that propagates the information from previous scales in a hierarchical fashion rather than optimizing jointly the global model The experiments will show that this strategy has better performance The algorithm sends update messages within the nodes of a given single layer including messages from the previous scale In the next step all the nodes in that scale are considered observed and the next scale is processed in the same way Fig 7b and c represent two steps of this algorithm D Embedding and Pooling After processing patch SMNs with the hierarchical context model we aggregate them into image SMNs using average pooling and the decision is simply the category with the maximum probability in the image SMN Note that in this case the ambiguity due to weak supervision still remains Alternatively patch SMNs can be encoded and pooled prior to the contextual classiﬁer   19 s ee F i g 2 I n p art i c ul ar we use the KCNF embedding w h i c h e xpl oi t s bet t e r l ocal category co-occurrences 


SONG et al  MULTI-SCALE MULTI-FEATURE CONTEXT MODELING FOR SCENE RECOGNITION IN THE SEMANTIC MANIFOLD 2729 Algorithm 2 Top-Down Message Passing Algorithm VI E XPERIMENTS A Experimental Setup 1 Datasets The proposed methods are evaluated on three small datasets 15 scenes   24 cont ai ns 4485 i m ages across 15 scene categories LabelMe  c ons i s t s of 8 out door scene categories with a total of 2600 images UIUC-Sports 5 consists of 1585 images labeled into 8 complex sport scene categories Following the settings in previous works we use 100 100 and 70 images for training respectively We also evaluate the proposed methods on larger datasets including MIT67  and S U N 397 45 M IT67 cont ai ns 15620 i m ages of 67 indoor scene classes SUN397 consists of 397 categories with 108762 images in total In the case of MIT67 Indoor and SUN397 the training/testing conﬁgurations are provided by the original authors Finally we also include an evaluation on the very large Places365-standard dataset  cons is ting of 365 scene categories and 1,803,460 training images with the number of images per class varying from 3,068 to 5,000 We follow the public training/validation split for evaluation 2 Shallow Patch SMNs We evaluate GMM-SMNs and NN-SMNs in the multi-feature setting with one scale and the proposed context models As local visual descriptor we use three variants of kernel descrip tors g radi ent  s h ape a nd color KDES All local visual descriptors are extracted on a regular dense grid of 16  16 pixels stride 8 pixels resulting in 30  30 patch level local descriptors on a 256x256 image For GMM-SMNs we train GMMs with 512 mixtures for each scene category For NN-SMNs we use a network with two fully connected layers including one hidden layer with 512 nodes Note that this network has comparable amount of parameters to the model with 512 GMMs 3 Deep Patch SMNs We use the VGG CNN architecture pre-trained either with ImageN et or Places 18 r eplacing the size of the last fully convolutional layer fc8 to meet Fig 8 Region size and sparse parameter evaluation the number of categories Then we ne tune the previous fully convolutional layer fc7 and train fc8 with the target datasets Since the size of the patches is xed in this architecture 224  224 pixels  we extract features in four scales obtained by resizing the input image to 224  224 320  320 448  448 and 640  640 pixels scales 1 2 3 and 4 respectively With these sizes we obtain 1  1 4  4 8  8 and 14  14 patches per scale respectively B Context Models With Shallow SMNs a Baseline and proposed methods We evaluate the proposed context models within the SM framework but integrating KCNF encoding F or G MM-S M N s and NN-SMNs we also include spatial pyramid matching w i t h four levels 1  1 2  2 3  3 4  4 Using the previous method as baseline we consider four variations of the proposed context model  Multi-feature context MF multiple features are combined in the semantic space with average pooling corresponding to the model in Figure 5a  Spatial context  single feature exploiting neighboring spatial relations see Figure 5b Obtained by minimizing Eq 1 when only one feature is used  Multi-feature spatial context MFS combines multiplefeatures of the target patch and neighboring spatial relations i.e see Figure 5c Obtained by minimizing Eq 2 in the multi-feature case  Extended multi-feature spatial context EMFS also includes multiple-features from additional patches in the neighborhood Figure 6c with single scale 


2730 IEEE TRANSACTIONS ON IMAGE PROCESSING VOL 26 NO 6 JUNE 2017 Fig 9 Output patch SMNs of the image in Fig 1a category tallbuilding af ter the context model and the effect of en tropy regularization a GMM-SMN s and b NN-SMNs The spatial neighborhood is 7  7 patches 1 Neighborhood Size and Entropy Regularization We evaluate the impact of the size of the spatial neighborhood which is critical in our context model We use the 15 scenes dataset and the EMFS model xing   1   V  and   1   B  l  n   The results are illustrated in Figure 8 We evaluate different neighborhoods including the 4-connectivity spatial neighborhood and other dense neighborhoods of size L  L patches 3  3 corresponds to 8 neighbors We can observe that larger neighborhoods can effectively reinforce consistent patterns and lter accidental ones However too large neighborhoods cannot capture properly local co-occurrence patterns From our experiments a good trade-off is 7  7 patches Entropy regularization is also important to capture category co-occurrence patterns properly We evaluate  in a range from 0 to 0.2 with a step of 0.05 Figure 9 shows that without entropy regularization    0 the performance is lower Note that NN-SMNs require lower penalty than GMM-SMNs We obtained the best performance for L  7and   0  1  0  05 for GMM-SMN and NN-SMN respectively so for the rest of the experiments we use this conﬁguration Figure 9 illustrates how the proposed method is able to effectively combine the three feature-speciﬁc patch SMNs from Figure 4 into smoother multi-feature patch SMNs The regularization term prevents from excessive smoothing that can wash out the true class-speciﬁc co-occurrence patterns that we want to preserve 2 Context Models We compare the different variations of the proposed method on the three small datasets to show how different types of context models improve the accuracy Table IV shows that the classi cation accuracy increases consistently when we include additional contextual relations in the context model Combining multiple features helps with a TABLE IV A CCURACY  OF GMM-SMN/NN-SMN FOR D IFFERENT C ONTEXT M ODELS I NDICATES I MPLEMENTED BY US I NSTEAD OF R EPORTED             gain around 1.1-2.5%/1.3-1.4 GMM-SMN/NN-SMN over the best single feature Using s patial relations varies from no gain to modest gains around 1%/3.3 However combining both can increase an additional 0.5-1%/0.7-0.8 over only multi-feature context The extended multi-feature spatial context contributes with an additional 0.4-2.2%/1.1-2.6 gain by incorporating multip le features from the neighboring patches The total gain with the extended context model over the baseline is around 2.6-5.7%/3.0-4.5 Note also that NN-SMNs typically obtain slightly be tter performance compared 


SONG et al  MULTI-SCALE MULTI-FEATURE CONTEXT MODELING FOR SCENE RECOGNITION IN THE SEMANTIC MANIFOLD 2731 TABLE V C OMPARISON ON MIT67 D ATA S E T      with GMM-SMNs and both consistently beneﬁt from contextual modeling 3 Comparison With Related Works We compare our method with other works using mid-level semantic representations such as latent topics object bank  22  27 and classemes   47 M os t o f t hes e approaches cannot be used in large scale datasets so we separate comparisons for small datasets and larger datasets a Small datasets Table IV compares the results reported by the authors in their corresponding references Although a completely fair comparison with reported results is not possible due to different implementations features and other parameters our framework at least seems to be competitive in the three evaluated datasets Comparing with previous methods based on SMNs and co-occurrence modeling such as CMN SPMSM and KCNF is of particular interest The proposed method which also exploits mu ltiple features and richer contextual relations achieves better performance than those methods We also compare with non-semantic representations by directly modeling categories from the same low-level kernel descriptors concatenated to combine them with and a SVM and spatial pyramid We observe that our method also achieves better results b Large datasets We evaluate the proposed methods on the larger MIT67 and SUN397 datasets The results are shown in Tables V and VI respectively NN-SMNs achieve better performance than GMM-SMNs especially for MIT67 The gains due to richer context models are much higher than in smaller datasets with signiﬁcant gains of 11%/9.5 and 15%/9.1 GMM-SMNs/NN-SMNs over the best single feature baseline respectively This suggests that contextual relations become much more important important as the number of scene categories increases resulting in much noisier and sparser co-occurrence patterns Exploiting the context to emphasize representative category co-occurrence patterns can greatly help to improve the recognition performance Other mid-level semantic representations such as object bank and meta-classes exploit larger amounts of external data TABLE VI C OMPARISON ON SUN397 D ATA S E T      TABLE VII A CCURACY  OF D IFFERENT A DAPTATIONS ON MIT I NDOOR 67   e.g ImageNet web images to model the mid-level classiﬁers The proposed method outperforms them without resorting to external data but still falls short compared with discriminative parts  w hi ch i s part i c ul arl y ef fect i v e f or indoor scenes where certain objects can be very discriminative However this method cannot scale to larger datasets such as SUN397 We also include other approaches based on lower level representations such as bag-of-words coding  and the Fisher vector T he latter achie v e s b etter accurac y  b ut at the cost of a much higher dimensional feature resulting from a much denser grid for sampling local features C Context Models With Deep SMNs and Multiple Scales 1 Patches vs Full Images We use the CNN-SMNs as described in Section IV-B extracting two complementary features that depend on the pre-training dataset i.e either ImageNet-CNN or Places-CNN In addition we consider multiple scales which are determined by the size the input image is resized for a xed patch size of 224  224 pixels When adapting the CNN to a particular target scene dataset this adaptation can be performed using full size images resized to the patch size i.e 224  224 pixels or using patches extracted at the particular scale As Table VII shows the latter is a better approach since patches used for adaptation and during test have similar scale distributions 2 Single Scale We rst compare the hierarchical ICM and the message passing MP algorithms in a single scale setting We compare the accuracy and the total energy for different spatial neighborhoods Since the total energy depends on the number of edges and they depend on the size of the neighborhood it is difﬁcult to compare neighborhoods with different size For better comparison we normalized the energy and set 


2732 IEEE TRANSACTIONS ON IMAGE PROCESSING VOL 26 NO 6 JUNE 2017 Fig 10 Comparison between ICM and MP on MIT Indoor 67 on scale 3 448  448 a\y b normalized pairwise energy,\(c time cost TABLE VIII C OMPARISON B ETWEEN I NTEGRATED AND S CALE W ISE MP M ODELS ON MIT67 IN A CCURACY       1   3  V      1   3  B  l  n      1   3  Q  l  1  n   and   0 in Eq 4 and 5 which we found work well in practice Fig 10b shows how the energy of ICM decreases quickly to the minimum value in around 16 iterations However it increases with more iterations probably due to the asynchronous updating scheme also causi ng the accuracy to decrease In contrast MP passes messages synchronously and then updates the values of each node simultaneously As a result the energy decreases more slowly but consistently although the absolute value of the of the energy is slightly higher and the accuracy increases sli ghtly However a drawback is that is slower than ICM 3 Multiple Scales and Message Passing In the next experiment we evaluate three varian ts of the proposed multi-scale MP algorithm on MIT Indoor 67 with just one CNN or combining two both ImageNet-CNN and Places-CNN The integrated variant optimizes all the nodes at the same time and then combines the scales The top-down and bottom-up variants are scale-wise and progressively update a given scale based on the previous scale In general the top-down strategy performs better than the others since the top scale more global obtains the best singlescale performance so using it as initial step leads to a better solution The results of the same experiment for SUN397 are shown in Table IX The proposed architecture combining ImageNet-CNN Places-CNN at three scales achieves a remarkable 69.3 of accuracy comparable to human performance as reported in  I n t hi s cas e i ncl udi ng s cal e 4 decreases the performance so we do not include it in the next experiment 4 Encoding Methods and Other Works In the previous experiments there is no supervised contextual classiﬁer e.g SVM nor any particular encoding The scene prediction is obtained basically pooling patch CNN-SMNs Now we also consider the full SM framework which includes TABLE IX A CCURACY  OF M ODELING J OINT C ONTEXTS ON SUN397    encoding and SVM classiﬁcatio n see Figure 2 We selected the architectures with best performance from previous experiments 3 scales for MIT67 and 4 scales for SUN397 both with ImageNet-CNN and Places-CNN and encode the CNN-SMNs using various encodings SM  F V  15 EMK  LLC 55 F o r E MK and LLC w e us e d i c t i onari es of 1000 words and for FV we use 50 GMMs and then reduce the dimensions to 4096 using PCA following T he res u l t s are shown in Table X The gain using encoding+SVM is more signiﬁcant for MIT67 than for SUN397 and for single scale than for multiple scales In particular for SUN397 a marginal 0.1 gain is achieved over the best performance We also compare with other works in Table X some using AlexNet and some using VGG architectures In the next section we evaluate our approach on the recent dataset Places365 T hus  w e can als o us e C NNs pretrained on this dataset in our framework and we report some results using an extended framework with in addition to ImageNet-CNNs and Places-CNNs includes Places365CNNs This setting obtains state-of-the-art performance 72.6 for SUN397 D Evaluation on Places365 Evaluation on Places365 is difﬁcult due to the size of the dataset In this case we use the original crops for adaptation instead of patches and 3 scales the amount of 


SONG et al  MULTI-SCALE MULTI-FEATURE CONTEXT MODELING FOR SCENE RECOGNITION IN THE SEMANTIC MANIFOLD 2733 TABLE X C OMPARISON TO THE S TATE OF THE A RT   I NDICATES O UR I MPLEMENTATION          TABLE XI A CCURACY  OF V ALIDATION D ATASET ON P LACES 365   data resulting for smaller patches is too large for training However even with these settings the results of our framework with multi-scale multi-CNN context modeling obtains 57.1 top 1 accuracy outperforming the best in baseline by 2.2 We can also compare with a simple average pooling across scales and CNNs and where our model still has a gain of 1.6 In general evaluation on Places or Places365 is not reported in the vast majority of papers about scene recognition and even most recent works typically use off-the-shelf CNNs trained on Places or Places365 but do not evaluate on those datasets For Places365 we are only aware of the result of Zhou et al  w hi ch w e i m pro v e by 1.9  Note that their setting would be closer to our scale 1 256  256 pixels but with some differences  a v erages 10 crops 4 corners  central  mirror while we use only four 2  2 patches VII C ONCLUSIONS Although recently relegated in favor of deep learning methods intermediate representations have played an important role in automatic scene recognition The semantic manifold framework addresses the problem of modeling scene categories from visual features with a combination of weak supervision and pooling that avoids mid-level annotations while inference can be easily modeled in two independent steps in contrast to most methods that learn latent representations This framework suffers from the speciﬁc problem of scene category co-occurrences thus requiring speciﬁc solutions In this paper we revisit the semantic manifold approach and tackle several of the limitations not addressed in previous works   13  19 W e i dent i f y t he ori g i n al pat c h S MN models based on GMMs i.e GMM-SMNs as an important bottleneck in terms efﬁciency and accuracy resulting from the training stage that learns patch SMN models independently for each category We show that replacing them by NN-SMNs based on neural networks and learned jointly for all the categories produce much faster and more discriminative SMNs Modeling category co-occurrences properly is the other critical stage Previous methods ignore local contextual relations which are very helpful for this purpose SMN representations in the semantic manifold have the unique characteristic that patches and images are repre sented in the same semantic space independently of the visual feature used as input Exploiting this property we combine multiple features and scales and integrate spatial multi-feature and even multi-scale relations between neighboring patch SMNs into a joint context model showing that in this way we can discover consistent co-occurrence patterns and lter out noisy ones making things easier for the classiﬁer whic h can focus on modeling scenes in terms of these cleaner patterns In particular we use a multifeature multi-scale Markov random eld formulation with a speciﬁc entropy regularizer Although still far from CNNs and some methods using the proposed NN-SMNs and an extended 


2734 IEEE TRANSACTIONS ON IMAGE PROCESSING VOL 26 NO 6 JUNE 2017 context model our framework can signiﬁcantly improve the recognition performance of the previous semantic manifold approach and its variants We further recast convolutiona l networks as sophisticated SMNs implemented as weakly supervised adaptation of a pre-trained network and inte grate them as semantic features in the proposed framework This hybrid approach achieves state-of-the-art scene recognition accuracy even without the contextual classiﬁer R EFERENCES 1 A  O li v a and A  T or r a lba M odeling t he s h ape o f t he s cene A holis tic representation of the spatial envelope Int J Comput Vis  vol 42 no 3 pp 145–175 2001 2 J  W u a nd J  M  Rehg Centr is t A v is ual d es cr iptor f or s cene categorization IEEE Trans Pattern Anal Mach Intell  vol 33 no 8 pp 1489–1501 Aug 2011 3 J  V ogel a nd B S c hiele S em antic m odeling o f n atur al s cenes f o r content-based image retrieval Int J Comput Vis  vol 72 no 2 pp 133–157 Apr 2007  L  L i H Su E  P  X ing and L  F ei-Fei  Object bank A h ighlevel image representation for scene classiﬁcation  semantic feature sparsiﬁcation in Proc NIPS  2010 pp 1378–1386 5 L  J  L i and L  F eiF ei  W h at w her e and w ho Clas s i f y ing e v e nts b y scene and object recognition in Proc ICCV  2007 pp 1–8 6 C  W ang D  Blei a nd L  F e iF e i S im ultaneous im age c las s i  cation and annotation in Proc CVPR  2009 pp 1903–1910  Z  N iu G  H ua X  G ao a nd Q T i an  Conte x t a w a re topic m odel f or scene recognition in Proc CVPR  2012 pp 2743–2750  A  Q uattoni and A  T orralba Recognizing indoor s cenes   in Proc CVPR  2009 pp 413–420 9 C  D oer s ch A  G upta and A  A  E f r o s  M idl e v el vis u al elem ent discovery as discriminative mode seeking in Proc NIPS  2013 pp 494–502  M J uneja A  V edaldi C  V  J a w ahar  a nd A Z i s s e rm an  Blocks that shout Distinctive parts for scene classiﬁcation in Proc CVPR  2013 pp 923–930  R K w itt N  V a s c oncelos  a nd N  Ras i w a s i a S cene r ecognition o n t he semantic manifold in Proc ECCV  2012 pp 359–372  N Ras i w a s i a P  J  Moreno and N  V as concelos   Bridging the g ap Query by semantic example IEEE Trans Multimedia  vol 9 no 5 pp 923–938 Aug 2007  N Ras i w a s i a a nd N V a s c oncelos   Holis tic conte x t m odels for v is ual recognition IEEE Trans Pattern Anal Mach Intell  vol 34 no 5 pp 902–917 May 2012  X  S ong S  J i ang and L  H erranz  Joint multi-feature spatial context for scene recognition in the semantic manifold in Proc CVPR  Jun 2015 pp 1312–1320  M  D i xit S  Chen D  G ao N  R as iw as ia a nd N  V a s c oncelos   S cene classiﬁcation with semantic Fisher vectors in Proc CVPR  2015 pp 2974–2983  J  Bes a g On t he s t atis tical analys is of dirty p ictures   J Roy Statist Soc Ser B  vol 48 no 3 pp 259–302 1986 17 O R u ssa k o v sk y et al  ImageNet large scale visual recognition challenge Int J Comput Vis  vol 115 no 3 pp 1–42 2015 Available http://dx.doi.org/10.1007/s11263-015-0816-y  B Z hou A L a pedriza J  Xiao A  T orralba and A  O li v a   L earning deep features for scene recognition using places database in Proc NIPS  2014 pp 487–495  X Song S J i ang L  Herra nz Y Kong and K Zheng Category co-occurrence modeling for large scale scene recognition Pattern Recognit  vol 59 pp 98–111 Nov 2016 A v a ilable http://www.sciencedirect.com/science/article/pii/S0031320316000406  S L azebnik C Schm id a nd J  Pon ce Beyond bags of features Spatial pyramid matching for recognizing natural scene categories in Proc CVPR  2006 pp 2169–2178  L  Bo X  R en a nd D F ox K ernel d es criptors for v is ual r ecognition  in Proc NIPS  2010 pp 244–252  L  Z h ang X Z h en a nd L  Shao  L earning object-to-clas s k ernels for scene classiﬁcation IEEE Trans Image Process  vol 23 no 8 pp 3241–3253 Aug 2014  A Ber g am o a nd L  T o rres a ni  Cl assemes and other classiﬁer-based features for efﬁcient object categorization IEEE Trans Pattern Anal Mach Intell  vol 36 no 10 pp 1988–2001 Oct 2014  L  Fei-Fei a nd P  Perona  A B ayes ian hierarchical model for learning natural scene categories in Proc CVPR  2005 pp 524–531  N Ras i w a s i a a nd N V a s c oncelos  Latent Dirichlet allocation models for image classiﬁcation IEEE Trans Pattern Anal Mach Intell  vol 35 no 11 pp 2665–2679 Nov 2013  X W a ng and E  G rim s on Spatial l atent Dirichlet allocation in Proc NIPS  2007 pp 1577–1584  L  J  L i H Su Y  L im  a nd L  Fe i-Fei Object bank An object-level image representation for high-level visual recognition Int J Comput Vis  vol 107 no 1 pp 20–39 2014  X  Bai C Y a o and W  L iu  S t r o k e lets  A lear ned m ultis cale m idl e v el representation for scene text recognition IEEE Trans Image Process  vol 25 no 6 pp 2789–2802 Jun 2016  X  W a ng B W a ng X  Bai W  L i u and Z  T u M axm ar gin m ultipleinstance dictionary learning J.Mach.Learn.Res  vol 28 no 3 pp 846–854 2013  G S X ie X  Y  Z h ang S Y a n and C  L  L i u Hybrid CNN a nd dictionary-based models for scene recognition and domain adaptation IEEE Trans Circuits Syst Video Technol  to be published O A v a ilable http://ieee xplore i e e e  o r g d ocu m ent 7362 156  doi 10.1109/TCSVT.2015.2511543  N Ras i w a s i a a nd N V a s c oncelos   Holis tic conte x t m odeling u s i ng semantic co-occurrences in Proc CVPR  2009 pp 1889–1895  A Krizhe vs k y  I  S uts k e v er  a nd G E Hinton ImageNet classiﬁcation with deep convolutional neural networks in Proc NIPS  2012 pp 1106–1114  J  Deng A Ber g  a nd L  Fei-Fei L ar ge graph c ons truction f or s calable semi-supervised learning in Proc ICML  2011  J  Donahue et al  DeCAF A deep convolutional activation feature for generic visual recognition in Proc ICML  2014 pp 647–655  T  Dura nd N T home  a n d M  C ord  W E L DON W e a k l y supe rvi s e d learning of deep convolutional neural networks in Proc CVPR  Jun 2016 pp 4743–4752  M Oquab L  Bottou I L a pte v  a nd J Sivic Is object localization for free?—Weakly-supervised learning with convolutional neural networks in Proc IEEE Conf Comput Vis Pattern Recognit CVPR  Jun 2015 pp 685–694  X L i et al  Deepsaliency Multi-task deep neural network model for salient object detection IEEE Trans Image Process  vol 25 no 8 pp 3919–3930 Aug 2016  H  Bilen a nd A  V e daldi W eakly s uper v is ed deep detection n etw o r k s   in Proc IEEE Conf Comput Vis Pattern Recognit CVPR  Jun 2016 pp 2846–2854  Y  G ong L  W a ng R G uo and S  L azebnik Multi-s cale o rderles s pooling of deep convolutional activation features in Proc ECCV  2014 pp 392–407  R W u  B  W ang W  W a ng and Y  Y u H ar v e s ting d is cr im inati v e m eta objects with deep CNN features for scene classiﬁcation in Proc ICCV  2015 pp 1287–1295  Q W a ng P  L i  W  Z uo and L  Z hang RAID-G Rob u s t es tim ation o f approximate inﬁnite dimensional Gaussian with application to material recognition in Proc CVPR  Jun 2016 pp 4433–4441  F  Perronnin J  Sánchez and T  M en sink Improving the Fisher kernel for large-scale image classiﬁcation in Proc ECCV  2010 pp 143–156  D G L o we  Dis tincti v e i m a ge feat ures from scale-invariant keypoints Int J Comput Vis  vol 60 no 2 pp 91–110 2004  D  Z h ang X  Chen a nd W  S  L ee T e x t c las s i  cation w ith k e r n els o n the multinomial manifold in Proc RDIR  2005 pp 266–273  J  X i ao J  H ays  K  A  E h inger  A  O l i v a and A  T or r a lba S U N database Large-scale scene recognition from abbey to zoo in Proc CVPR  2010 pp 3485–3492  B Z hou A Khos la A  L apedriza A T o rralba and A  O li v a   2016 Places An image database for deep scene understanding On Available https://arxiv.org/abs/1610.02055  L  T o rres a ni M  S zum m e r  and A  F itzgibbon E f  cient object cate gory recognition using classemes in Proc ECCV  2010 pp 776–789  M  P a nde y a nd S  L azebnik S cene r ecognition a nd w eakly s uper v is ed object localization with deformable part-based models in Proc ICCV  2011 pp 1307–1314  G  L  O l i v eir a  E  R  N as cim e nt o A W Vieira and M F M Campos Sparse spatial coding A novel approach to visual recognition IEEE Trans Image Process  vol 23 no 6 pp 2719–2731 Jun 2014 


SONG et al  MULTI-SCALE MULTI-FEATURE CONTEXT MODELING FOR SCENE RECOGNITION IN THE SEMANTIC MANIFOLD 2735  L  Xie Q T i an M  W ang and B  Z hang Spatial pooling o f h eterogeneous features for image classiﬁcation IEEE Trans Image Process  vol 23 no 5 pp 1994–2008 May 2014  Z  W a ng J  Feng S Y a n and H  X i L inear dis t ance coding for i m a ge classiﬁcation IEEE Trans Image Process  vol 22 no 2 pp 537–548 Feb 2013  J  Sanchez F  Perronnin T  Mens i nk and J Verbeek Image classiﬁcation with the Fisher vector Theory and practice Int J Comput Vis  vol 105 no 3 pp 222–245 2013  J  Xiao K  A  E hinger  J  Hays  A  T orralba and A  O li v a   SUN database Exploring a large collection of scene categories Int J Comput Vis  vol 119 no 1 pp 3–22 2014  L  Bo and C  S m i nchis e s c u E f  cient m atch k e r n el betw een s e ts of features for visual recognition in Proc NIPS  2009 pp 135–143  J  W a ng J  Y a ng K  Y u  F  L v  T  H u ang and Y  G ong L ocalityconstrained linear coding for image classiﬁcation in Proc CVPR  2010 pp 3360–3367  H Hu G  T  Z hou Z  Deng Z  L i ao a nd G Mori  L earning s t ructured inference neural networ ks with label relations in Proc CVPR  Jun 2016 pp 2960–2968  K  S i m o n y an and A  Z is s e r m an  V e r y deep con v olutional n etw o r k s f or large-scale image recognition in Proc ICLR  2015 A v a ilable https://arxiv.org/abs/1409.1556  S  Y a ng and D  R am anan  Multi-s cale r ecognition w ith D A G CN N s   in Proc ICCV  2015 pp 1215–1223  M D Dixit a nd N V a s c oncelos   Object based scene representations using Fisher scores of local subspace projections in Advances In Neural Information Processing Systems  vol 29 D D Lee M Sugiyama U V Luxburg I Guyon and R Garnett Eds Red Hook NY USA Curran Associates Inc 2016 pp 2811–2819 Xinhang Song received the B.S degree from the School of Computer and Information Technology Beijing Jiaotong University Beijing China in 2011 He is currently pursuing the Ph.D degree in computer science with the Key Laboratory of Intelligent Information Processing Institute of Computing Technology Chinese Academy of Sciences Beijing His current research interests include image processing large-scale image retrieval image semantic understanding multimedia content analysis computer vision and pattern recognition Shuqiang Jiang SM’08 is currently a Professor with the Institute of Computing Technology Chinese Academy of Sciences and also a Professor with the University of CAS He is also with the Key Laboratory of Intelligent Information Processing CAS His current research interests include multimedia processing and semantic understanding pattern recognition and computer vision He has authored or co-authored over 100 papers on the related research topics He was supported by the New-Star program of Science and Technology of Beijing Metropolis in 2008 the NSFC Excellent Young Scientists Fund in 2013 and the Young top-notch talent of Ten Thousand Talent Program in 2014 He is a Senior Member of the CCF and a member of the ACM He received the Lu Jiaxi Young Talent Award from Chinese Academy of Sciences in 2012 and the CCF Award of Science and Technology in 2012 He was the General Chair of ICIMCS 2015 the Program Chair of ICI MCS2010 the Special Session Chair of PCM2008 and ICIMCS2012 the Area Chair of PCIVT2011 the Publicity Chair of PCM2011 the Web Chair of ISCAS2013 and the Proceedings Chair of MMSP2011 He has also a TPC member for about 20 well-known conferences including the ACM Multimedia  CVPR ICCV ICME ICIP and PCM He is an Associate Editor of the IEEE Multimedia Multimedia Tools and Applications He is also the Vice Chair of the IEEE CASS Beijing Chapter the Vice Chair of the ACM SIGMM China chapter Luis Herranz received the Ingeniero de Telecomunicación degree from the Universidad Politécnica de Madrid Madrid Spain in 2003 and the Ph.D degree in computer science and telecommunication from the Universidad Autónoma de Madrid in 2010 From 2003 to 2010 he was with the Escuela Politécnica Superior of the Universidad Autónoma de Madrid as a Researcher and a Teaching Assistant From 2010 to 2011 he was with Mitsubishi Electric Research And Development Center Europe U.K He is currently a Post-Doctoral Research Fellow with the Institute of Computing Technology Chinese Academy of Sciences Beijing China His current research interests include multimedia signal processing content summarization and adaptation multimedia indexing and retrieval and scene recognition 


2332-7790 \(c This article has been accepted for publication in a future issue of this\ journal, but has not been fully edited. Content may change prior to fin\al publication. Citation information: DOI 10.1109/TBDATA.2017.2680460, I\EEE Transactions on Big Data A 16 a b c particles nonthe quality aluated ely 224non-testable\224 approach are system be the to The uilding its more and MRs enough alidated R D W K quality data ork and data scienti\002c learning In topics poor prediction utes and detail timeliness metadata accuauditability  Gao Xie and T ao ha v e gi v en an o v ervie w of the issues of data where the y de\002ned big data quality assurance techniques Although for the health eb orthiy such history source and sources information Finding the duplicated information quality as for duplication Data 002ltering is an approach data Samza which is adopted and al an electronic proposed using learning training reduce the algorithm data poor data Due to the massi v e scale of big data automated choice learning grated easily data for domain task The process is to reduce the irrele v ant performance selection correlation predict CFS 
 


2332-7790 \(c This article has been accepted for publication in a future issue of this\ journal, but has not been fully edited. Content may change prior to fin\al publication. Citation information: DOI 10.1109/TBDATA.2017.2680460, I\EEE Transactions on Big Data A 17 for images In this practical based in images  Ho w the feature selection w ould impact the classi\002cation reported  More adv anced feature selection approaches such as the in can be introduced into the frame w ork e images samin images challenge to problem  Man y dif ferent approaches ha v e been proposed to address as results the are Ho we v er  none of these that most eloping MRs 12 Metamorphic testing w as 002rst Chen al  for testing non-testable systems bioinformatics sysaultrelations A recent has compilers  Metamorphic testing has been applied for testi ng a lar ge ASA and also successfully engines Baidu Ho we v er  the quality of reported are w information In this paper  metamorphic in results w are tests xity SUT  Combinatorial technique 53 used for testing softw are for are C N the learning were to classi\002cation the for confusion learning important it data our data techniques A T King and xperi#1262933 e Corporation research R S  V  Gudi v ada R Raeza-Y ates and V  Ragha v an 223Big data Promises and 224 Computer 2015  Y  Bengio 223Learning deep architectures for ai 224 ends Learning 2009  Apache 2016 Hadoop Online A v ailable http://hadoop.apache.or g  V  Gudi v ada D Rao and V  Ragha v an 223Renaissance in database 224 IEEE Computer 2016  J Zhang Y  Feng M S Moran J Lu L Y ang al of 224 ess 2013  R M and T  Poggio 223Models of object recognition 224 oscience 2000  K Jacobs  J Lu and X Hu 223De v elopment of a dif f raction imaging 224 Lett 2009  2016 Adda project Online A v ailable https://github com/addateam adda  T  Y  Chen S C Cheung and S Y iu 223Metamorphic testing a ne w CS98and 1998  J Ding D Zhang and X Hu 223 An application of metamorphic testing in metamorphic ICSE 2016  U Kane w ala and J M Bieman 223T esting scienti\002c softw are A system\224 gy 56 2014  S Se gura G Fraser  A Sanchez and A Ruiz-Cort 264 on 224 Engineering  2016  2016 Mongodb  Online A v ailable https://www mongodb com  2016 Mongochef Online A v ailable http://3t.io/mongochef  M Y urkin and A Hoekstra 2014 User manual for the discrete 1.3b4 A v ailable https team/adda/tree/master/doc  C Hsu C.-C Chang and C.-J Lin 223 A practical guide to support v ector 2003  Y  LeCun Y  Bengio and G Hinton 223Deep learning 224 e 521 2015  R Haralick 223On a te xture-conte xt feature e xtract ion algorithm for in Society ol 650\226 657 
 


2332-7790 \(c This article has been accepted for publication in a future issue of this\ journal, but has not been fully edited. Content may change prior to fin\al publication. Citation information: DOI 10.1109/TBDATA.2017.2680460, I\EEE Transactions on Big Data A 18  K Dong Y  Feng K Jacobs J Lu R Brock al 223Label-free 224 Biomed ess 2011  R M Haralick K Shanmug an and I H Dinstein 223T e xtural features 224 Cybern SMC-3 1973  S K Thati J Ding D Zhang and X Hu 223Feature selection and analin ion ance 2015  J Dixon and J Ding 223 An empirical study of parallel solution for glcm 2016  T  Kanungo D Mount N Netan yahu C Piatk o R Silv erman and im\224 hine ence 2012  M A Hall 223Correlation-based feat ure selection for machine learning 224 wzealand 1999  A Krizhe vsk y  I Sutsk e v er  and G E Hinton 223Imagenet classi\002cain al systems and 1097\2261105  E Gibne y  223Google ai algorithm masters ancient g ame of go 224 e   M Moran 223Correlating the morphological and light scattering prop 2013  R P an Y  Feng Y  Sa J Lu K Jacobs and X Hu 223 Analysis 224 ess  2014  X Y ang Y  Feng Y  Liu N Zhang L W ang al e fraction 224 ess 7 2014  M Zhang 223 A deep learning based classi\002cation of lar ge scale biomed2016  Y  Feng N Zhang K Jacobs W  Jiang L Y ang al 223Polarization w 224 A 2014  C.-C Chang and C.-J Lin 2016 Libsvm Online A v ailable csie.ntu.edu.tw 030 cjlin/libsvm  2016 Caf fe project Online A v ailable http://caf fe.berk ele yvision.or g  J Mayer and R  Guderlei 223 An empirical study on the selection of good in e C06 475\226484  U Kane w ala J M Bieman and A Ben-Hur  223Predicting metamorphic approach 224 and Reliability 2015  J Ding T  W u J Q Lu and X Hu 223Self-check ed metamorphic testing in on vement apore 2010  W  E W ong and A Mathur  223Reducing the cost of mutati on testing 224 e pp 1995  Y  Jia and M Harman 223 An anal ysis and surv e y of the de v elopment of 224  649\226678 2011  L Cai and Y  Zhu 223The challenges of data quality and data quality 224 ournal 1 2015  J Gao C Xi e and C T ao 223Big data v alidation and quality assurance in Service\(SOSE 433\226441  X Dong E Gabrilo vich K Murph y  V  Dang W  Horn C Lug aresi 224  938\226949 2015  X Y in J Ha n and P  S Y u 223T ruth disco v ery with multiple con\003icting 224 Data  2008  C H W u and Y  Song 223Rob ust and distrib uted web-scale near dup in IEEE Data 2606\226 2611  2016 Apache samza Online A v ailable http://samza.apache.or g  J A Saez B Kra wczyk and M W ozniak 223On the in\003uence of class 002ltering 224 ence 590\226609 2016  M Y ousef D S D M 250 223Feature for 224 bioinformatics 2016  F  Min Q Hu and W  Zhu 223Feature sel ection with test cost constraint 224 Reasoning 167\226 2014  H A L Thi H M Le and T  P  Dinh 223Feature selection in machine function 224 Learning 2015  H Liu F C K uo D T o we y  and T  Chen 223Ho w ef fecti v ely does problem?\224 on Engineering 2014  V  Le M  Afshari and Z Su 223Compiler v alidation via equi v alence in amming on Kingdom 216\226226  M Lindv all D Ganesan R rdal and R E W ie g and 223Metamorphic in 37th Engineering 129\226 138  Z Zhou S Xiang and T  Chen 223Metamorphic testing for softw are 224 e Engineering 2016  C Nie and H Leung 223 A surv e y of combinatorial testing 224 CM y 2011 CE O HERE Ding Computer has Computer in Nanjing 2004 r ed His the He by CM Hu  ada East  
 


2169-3536 \(c http://www.ieee.org/publications_standards/publications/rights/index.htm\l for more information This article has been accepted for publication in a future issue of this\ journal, but has not been fully edited. Content may change prior to fin\al publication. Citation information: DOI 10.1109/ACCESS.2017.2697839, IEEE Access   19     en-US  en-US  en-US  en-US 52 en-US  en-US  en-US  en-US en-US e en-US ti en-US en-US  en-US  en-US en-US  en-US 4 en-US en-US  en-US  en-US  en-US 53 en-US  en-US  en-US  en-US en-US  en-US  en-US DA en-US en-US  en-US  en-US  en-US  en-US 54 en-US  en-US  en-US  en-US en-US e en-US n en-US  en-US en-US  en-US v en-US en-US  en-US  en-US  en-US 55 en-US  en-US  en-US  en-US en-US k en-US en-US thm en-US en-US  en-US ron en-US  en-US 0 en-US en-US  en-US  en-US 5 en-US 6 en-US  en-US  en-US  en-US en-US  en-US  en-US  en-US en-US n en-US  en-US  en-US  en-US 57 en-US  en-US  en-US  en-US en-US ti en-US en-US T en-US  en-US n en-US en-US  en-US  en-US  en-US  en-US  en-US 58 en-US  en-US  en-US  en-US en-US  en-US Pre en-US en-US  en-US t en-US en-US  en-US  en-US en-US  en-US  en-US  en-US 3 en-US en-US 1 en-US  en-US  en-US  en-US 59 en-US  en-US  en-US t en-US  en-US  en-US n en-US en-US  en-US  en-US en-US  en-US OS en-US  en-US 2 en-US en-US  en-US  en-US  en-US 60 en-US  en-US  en-US  en-US en-US  en-US ti en-US  en-US t en-US en-US  en-US 4 en-US en-US  en-US  en-US  en-US 61 en-US  en-US  en-US  en-US en-US  en-US  en-US en-US ess en-US  en-US  en-US 0 en-US en-US  en-US  en-US  en-US 62 en-US  en-US  en-US  en-US en-US X en-US en-US ng en-US en-US s en-US  en-US en-US  en-US  en-US i    en-US x en-US en-US e en-US en-US i en-US en-US r en-US en-US is en-US en-US 2 en-US en-US Dec en-US en-US 6  en-US  en-US  en-US 63 en-US  en-US  en-US i en-US  en-US en-US  en-US  en-US en-US h en-US i   Av a i l a bl e   en-US e en-US en-US is en-US en-US ng en-US en-US a en-US en-US nd en-US en-US b en-US en-US r en-US en-US the en-US en-US net en-US en-US of en-US en-US 0 en-US en-US Dec en-US en-US 6  en-US  en-US  en-US 64 en-US  en-US  en-US BI en-US en-US  en-US en-US e en-US  en-US  en-US en-US er en-US  en-US i    en-US du en-US en-US es en-US en-US new en-US en-US ai en-US en-US nd en-US en-US net en-US en-US of en-US en-US s en-US en-US ves en-US en-US 6 en-US en-US 0 en-US en-US Dec en-US en-US 6  en-US  en-US  en-US 65 en-US  en-US  en-US  en-US en-US Su en-US  en-US  en-US en-US a en-US  en-US 9 en-US en-US  en-US  en-US  en-US  en-US 66 en-US  en-US  en-US  en-US  en-US en-US  en-US  en-US en-US s en-US  en-US  en-US  en-US  en-US 67 en-US  en-US  en-US  en-US en-US  en-US a en-US en-US ve en-US en-US a en-US  en-US 383 en-US en-US  en-US  en-US  en-US 68 en-US  en-US  en-US  en-US en-US  en-US  en-US en-US  en-US ess en-US  en-US 7 en-US en-US  en-US  en-US  en-US 69 en-US  en-US  en-US  en-US en-US  en-US vey en-US en-US  en-US ri en-US s en-US  en-US 77 en-US en-US  en-US  en-US  en-US 70 en-US  en-US  en-US  en-US en-US  en-US  en-US en-US  en-US  en-US  en-US 1 en-US en-US  en-US  en-US  en-US 71 en-US  en-US  en-US o en-US  en-US  en-US ne en-US en-US  en-US  en-US  en-US 5 en-US en-US  en-US  en-US  en-US 72 en-US  en-US  en-US  en-US en-US  en-US n en-US e en-US  en-US en-US  en-US n en-US  en-US 6 en-US en-US  en-US  en-US  en-US 73 en-US  en-US  en-US  en-US en-US  en-US  en-US hy en-US  en-US en-US  en-US n en-US  en-US 6 en-US en-US  en-US  en-US  en-US 74 en-US  en-US  en-US  en-US en-US  en-US t en-US en-US I en-US  en-US  en-US  en-US 5 en-US en-US  en-US  en-US  en-US 75 en-US  en-US  en-US  en-US en-US  en-US ty en-US en-US  en-US en-US  en-US f en-US en-US  en-US  en-US  en-US  en-US 76 en-US  en-US  en-US a en-US  en-US en-US ti en-US en-US  en-US  en-US en-US  en-US  en-US  en-US 96 en-US en-US  en-US  en-US  en-US 77 en-US  en-US  en-US  en-US en-US  en-US n en-US en-US 0 en-US 8 en-US en-US  en-US  en-US ess en-US  en-US 85 en-US en-US  en-US  en-US  en-US 78 en-US  en-US  en-US  en-US en-US  en-US n en-US en-US  en-US  en-US  en-US  en-US  en-US 79 en-US  en-US  en-US hen en-US  en-US  en-US en-US  en-US  en-US  en-US en-US  en-US  en-US  en-US 4 en-US en-US  en-US  en-US  en-US 80 en-US  en-US  en-US  en-US en-US ng en-US en-US  en-US  en-US  en-US en-US s en-US  en-US  en-US 6 en-US en-US  en-US  en-US  en-US 81 en-US  en-US  en-US N en-US  en-US  en-US en-US  en-US  en-US en-US 2011 en-US  en-US  en-US 1 en-US en-US  en-US  en-US  en-US 82 en-US  en-US  en-US  en-US  en-US en-US o en-US  en-US  en-US en-US 2011 en-US  en-US  en-US 1 en-US en-US  en-US  en-US  en-US 83 en-US  en-US  en-US  en-US en-US  en-US s en-US  en-US  en-US  en-US  en-US 9 en-US en-US  en-US  en-US  en-US 84 en-US  en-US  en-US  en-US en-US  en-US en-US  


2169-3536 \(c http://www.ieee.org/publications_standards/publications/rights/index.htm\l for more information This article has been accepted for publication in a future issue of this\ journal, but has not been fully edited. Content may change prior to fin\al publication. Citation information: DOI 10.1109/ACCESS.2017.2697839, IEEE Access  20      en-US  en-US en-US  en-US  en-US  en-US 4 en-US en-US  en-US  en-US  en-US 85 en-US  en-US  en-US F en-US  en-US en-US  en-US  en-US en-US  en-US 0 en-US  en-US 5 en-US en-US  en-US  en-US  en-US 86 en-US  en-US  en-US h en-US  en-US  en-US l en-US en-US  en-US en-US  en-US  en-US  en-US  en-US 1 en-US en-US  en-US  en-US  en-US 87 en-US  en-US  en-US  en-US en-US ti en-US en-US  en-US  en-US d en-US en-US  en-US  en-US  en-US 1 en-US en-US  en-US  en-US  en-US 88 en-US  en-US  en-US  en-US  en-US en-US  en-US  en-US en-US  en-US 6 en-US  en-US 263 en-US en-US  en-US  en-US  en-US 89 en-US  en-US  en-US  en-US en-US tem en-US en-US OTA en-US  en-US 6 en-US  en-US 6 en-US en-US  en-US  en-US  en-US  en-US 90 en-US  en-US  en-US  en-US en-US  en-US  en-US en-US  en-US m en-US  en-US 87 en-US en-US  en-US  en-US  en-US  en-US 91 en-US  en-US  en-US e en-US  en-US  en-US en-US  en-US  en-US en-US  en-US m en-US  en-US 87 en-US en-US  en-US  en-US  en-US  en-US 92 en-US  en-US  en-US  en-US en-US  en-US a en-US  en-US  en-US  en-US  en-US  en-US 1 en-US en-US  en-US  en-US  en-US 93 en-US  en-US  en-US  en-US en-US  en-US r en-US en-US  en-US  en-US en-US  en-US 195 en-US en-US  en-US  en-US  en-US 94 en-US  en-US  en-US Wei en-US en-US xi en-US ng en-US en-US eng en-US en-US  en-US en-US  en-US k en-US en-US to en-US en-US  en-US  en-US en-US ess en-US  en-US 1 en-US en-US  en-US  en-US  en-US 95 en-US  en-US  en-US  en-US en-US  en-US c en-US r en-US en-US  en-US  en-US en-US  en-US  en-US 1 en-US en-US  en-US  en-US  en-US 96 en-US  en-US  en-US  en-US en-US  en-US  en-US en-US r en-US  en-US  en-US 9 en-US en-US  en-US  en-US  en-US 97 en-US  en-US  en-US  en-US  en-US  en-US en-US e en-US en-US  en-US r en-US en-US  en-US  en-US en-US  en-US en-US  en-US  en-US  en-US  en-US m en-US en-US s en-US en-US 3 en-US  en-US 3 en-US en-US  en-US  en-US  en-US 98 en-US  en-US  en-US a en-US en-US  en-US en-US  en-US ter en-US en-US  en-US  en-US en-US l en-US  en-US  en-US  en-US  en-US 99 en-US  en-US  en-US a en-US  en-US en-US  en-US  en-US  en-US en-US  en-US BE en-US  en-US 1 en-US en-US  en-US  en-US  en-US 0 en-US  en-US  en-US  en-US e en-US  en-US  en-US  en-US  en-US 1 en-US  en-US  en-US e en-US en-US  en-US ter en-US en-US  en-US  en-US  en-US  en-US 2 en-US  en-US  en-US e en-US en-US  en-US ter en-US en-US the en-US  en-US  en-US  en-US  en-US 3 en-US  en-US  en-US  en-US en-US  en-US ter en-US en-US  en-US ti en-US en-US n en-US en-US  en-US n en-US  en-US 3 en-US en-US  en-US  en-US  en-US  en-US 4 en-US  en-US  en-US  en-US en-US  en-US  en-US  en-US en-US  en-US  en-US  en-US  en-US 5 en-US  en-US  en-US  en-US en-US  en-US th en-US  en-US  en-US ter en-US en-US  en-US  en-US en-US s en-US  en-US 7 en-US en-US  en-US  en-US  en-US 6 en-US  en-US  en-US en en-US en-US  en-US n en-US  en-US  en-US en-US 4 en-US  en-US 4 en-US en-US  en-US  en-US  en-US 7 en-US  en-US  en-US e en-US en-US  en-US  en-US  en-US en-US  en-US  en-US  en-US 4 en-US en-US  en-US  en-US  en-US 8 en-US  en-US  en-US  en-US en-US  en-US ter en-US en-US  en-US tem en-US en-US  en-US  en-US  en-US 1 en-US en-US  en-US  en-US  en-US 9 en-US  en-US  en-US  en-US  en-US en-US  en-US a en-US en-US  en-US en-US  en-US S en-US  en-US en-US  en-US  en-US  en-US  en-US  en-US 0 en-US  en-US  en-US  en-US  en-US  en-US en-US ter en-US en-US  en-US  en-US en-US  en-US  en-US  en-US 72 en-US en-US  en-US  en-US  en-US 1 en-US  en-US  en-US  en-US en-US  en-US en-US  en-US n en-US en-US a en-US  en-US 5 en-US en-US  en-US  en-US  en-US 2 en-US  en-US  en-US W en-US  en-US en-US  en-US  en-US nty en-US en-US  en-US ON en-US  en-US 1 en-US en-US  en-US  en-US  en-US 3 en-US  en-US  en-US  en-US en-US  en-US Se en-US  en-US en-US  en-US l en-US  en-US 334 en-US en-US  en-US  en-US  en-US 4 en-US  en-US  en-US  en-US en-US  en-US  en-US  en-US en-US Int en-US en-US y en-US  en-US  en-US  en-US 249 en-US en-US  en-US  en-US  en-US 5 en-US  en-US  en-US  en-US en-US  en-US  en-US  en-US en-US  en-US en-US  en-US d en-US en-US  en-US 1 en-US 1 en-US 52 en-US en-US  en-US  en-US  en-US 6 en-US  en-US  en-US  en-US en-US  en-US  en-US te en-US en-US  en-US  en-US  en-US 7 en-US  en-US  en-US  en-US en-US  en-US  en-US  en-US  en-US en-US r en-US  en-US 34 en-US en-US  en-US  


2169-3536 \(c http://www.ieee.org/publications_standards/publications/rights/index.htm\l for more information This article has been accepted for publication in a future issue of this\ journal, but has not been fully edited. Content may change prior to fin\al publication. Citation information: DOI 10.1109/ACCESS.2017.2697839, IEEE Access   21     en-US  en-US 8 en-US  en-US  en-US  en-US en-US  en-US  en-US en-US  en-US  en-US  en-US  en-US 9 en-US  en-US  en-US  en-US en-US i en-US  en-US  en-US en-US  en-US  en-US  en-US  en-US 0 en-US  en-US  en-US  en-US en-US  en-US  en-US  en-US en-US s en-US  en-US  en-US  en-US 2 en-US en-US  en-US  en-US  en-US 1 en-US  en-US  en-US  en-US en-US  en-US  en-US en-US  en-US  en-US 1 en-US 77 en-US en-US  en-US  en-US  en-US 2 en-US  en-US  en-US  en-US en-US d en-US en-US a en-US en-US  en-US  en-US  en-US en-US  en-US  en-US  en-US 2 en-US en-US  en-US  en-US  en-US 3 en-US  en-US  en-US o en-US  en-US en-US  en-US  en-US en-US s en-US  en-US 0 en-US en-US  en-US  en-US  en-US  en-US 4 en-US  en-US  en-US  en-US en-US  en-US  en-US en-US s en-US  en-US  en-US 0 en-US en-US  en-US  en-US  en-US 5 en-US  en-US  en-US  en-US  en-US en-US  en-US  en-US  en-US en-US  en-US  en-US  en-US  en-US  en-US 3 en-US en-US  en-US  en-US  en-US 6 en-US  en-US  en-US  en-US en-US  en-US en-US a en-US  en-US 321 en-US en-US  en-US  en-US  en-US 7 en-US  en-US  en-US K en-US en-US t en-US en-US  en-US en-US  en-US  en-US s en-US en-US dy en-US en-US matics en-US  en-US  en-US  en-US  en-US 8 en-US  en-US  en-US  en-US  en-US res en-US  en-US  en-US  en-US 9 en-US  en-US  en-US R en-US n en-US en-US  en-US en-US  en-US  en-US en-US  en-US  en-US 5 en-US en-US  en-US  en-US  en-US  en-US 0 en-US  en-US  en-US n en-US en-US  en-US en-US n en-US  en-US  en-US  en-US en-US  en-US  en-US 5 en-US en-US  en-US  en-US  en-US  en-US 1 en-US  en-US  en-US  en-US en-US  en-US  en-US  en-US en-US  en-US en-US  en-US  en-US  en-US man en-US en-US  en-US  en-US 3 en-US en-US  en-US  en-US  en-US 2 en-US  en-US  en-US  en-US en-US  en-US en-US  en-US d en-US en-US s en-US 2 en-US  en-US 46 en-US en-US  en-US  en-US  en-US 3 en-US  en-US  en-US  en-US en-US ti en-US en-US ti en-US en-US  en-US n en-US en-US n en-US  en-US 1 en-US en-US  en-US  en-US  en-US 4 en-US  en-US  en-US  en-US en-US  en-US  en-US n en-US en-US n en-US  en-US  en-US  en-US  en-US 5 en-US  en-US  en-US  en-US en-US  en-US en-US 2 en-US  en-US ron en-US  en-US 351 en-US en-US  en-US  en-US  en-US 6 en-US  en-US  en-US  en-US en-US Semi en-US en-US  en-US  en-US en-US  en-US S en-US s en-US en-US  en-US  en-US  en-US 2 en-US en-US  en-US  en-US  en-US  en-US 7 en-US  en-US  en-US  en-US en-US  en-US  en-US en-US  en-US  en-US  en-US 5 en-US en-US  en-US  en-US  en-US 8 en-US  en-US  en-US  en-US en-US ex en-US  en-US  en-US en-US  en-US  en-US  en-US  en-US  en-US 9 en-US  en-US  en-US nt en-US en-US  en-US en-US  en-US  en-US a en-US  en-US en-US  en-US r en-US  en-US 7 en-US en-US  en-US  en-US  en-US 0 en-US  en-US  en-US  en-US en-US  en-US n en-US en-US EEE en-US  en-US 6 en-US en-US  en-US  en-US  en-US 1 en-US  en-US  en-US  en-US  en-US en-US  en-US  en-US  en-US en-US s en-US  en-US 7 en-US en-US  en-US  en-US  en-US 2 en-US  en-US  en-US  en-US en-US ti en-US en-US  en-US n en-US  en-US en-US  en-US  en-US  en-US  en-US  en-US 3 en-US  en-US  en-US  en-US en-US ene en-US en-US  en-US  en-US en-US  en-US  en-US  en-US 7 en-US en-US  en-US  en-US 4 en-US  en-US  en-US en-US  en-US ti en-US en-US  en-US en-US  en-US  en-US 8 en-US en-US  en-US  en-US  en-US 5 en-US  en-US  en-US  en-US en-US i en-US  en-US  en-US en-US  en-US dy en-US en-US  en-US n en-US y en-US en-US  en-US  en-US  en-US 6 en-US  en-US  en-US  en-US en-US k en-US en-US to en-US en-US  en-US  en-US en-US IE en-US  en-US  en-US 0 en-US en-US  en-US  en-US  en-US  en-US 7 en-US  en-US  en-US  en-US en-US  en-US ter en-US en-US n en-US en-US  en-US l en-US en-US  en-US en-US  en-US  en-US  en-US  en-US  en-US 9 en-US en-US  en-US  en-US  en-US 8 en-US  en-US  en-US  en-US  en-US  en-US n en-US en-US  en-US en-US  en-US  en-US  en-US 7 en-US en-US  en-US  en-US  en-US 9 en-US  en-US  en-US  en-US en-US k en-US en-US to en-US en-US  en-US the en-US  en-US en-US  en-US  en-US 4 en-US en-US  en-US  en-US  en-US  en-US 0 en-US  en-US  en-US  en-US en-US  en-US n en-US en-US  


2169-3536 \(c http://www.ieee.org/publications_standards/publications/rights/index.htm\l for more information This article has been accepted for publication in a future issue of this\ journal, but has not been fully edited. Content may change prior to fin\al publication. Citation information: DOI 10.1109/ACCESS.2017.2697839, IEEE Access  22      en-US Inte en-US  en-US  en-US 132 en-US en-US  en-US  en-US  en-US 1 en-US  en-US  en-US  en-US en-US k en-US en-US to en-US en-US n en-US en-US  en-US I en-US en-US  en-US  en-US  en-US 69 en-US en-US 8 en-US  en-US  en-US  en-US 2 en-US  en-US  en-US r en-US en-US  en-US en-US k en-US en-US to en-US en-US  en-US  en-US en-US r en-US  en-US 1 en-US en-US  en-US  en-US  en-US 3 en-US  en-US  en-US  en-US en-US t en-US en-US n en-US en-US n en-US  en-US  en-US 1 en-US en-US  en-US  en-US  en-US 4 en-US  en-US  en-US  en-US en-US  en-US  en-US i   en-US m en-US  en-US  en-US 5 en-US  en-US  en-US  en-US  en-US en-US k en-US en-US to en-US en-US  en-US tr en-US  en-US n en-US en-US  en-US  en-US 7 en-US en-US  en-US  en-US  en-US 6 en-US  en-US  en-US  en-US en-US  en-US en-US a en-US i   en-US d en-US en-US a en-US en-US c en-US en-US es en-US 2 en-US en-US n en-US en-US 7  en-US  en-US  en-US 7 en-US  en-US  en-US  en-US en-US  en-US  en-US en-US  en-US dy en-US en-US  en-US n en-US y en-US en-US  en-US  en-US  en-US 8 en-US  en-US  en-US  en-US  en-US en-US  en-US vey en-US en-US  en-US  en-US 13 en-US en-US  en-US  en-US  en-US 9 en-US  en-US  en-US  en-US en-US  en-US  en-US en-US  en-US  en-US  en-US  en-US  en-US 0 en-US  en-US  en-US  en-US  en-US  en-US en-US  en-US  en-US n en-US en-US  en-US n en-US  en-US  en-US  en-US 1 en-US  en-US  en-US  en-US en-US  en-US  en-US en-US 2010 en-US  en-US  en-US 7 en-US en-US  en-US  en-US  en-US 2 en-US  en-US  en-US  en-US en-US  en-US o en-US n en-US en-US  en-US  en-US  en-US  en-US  en-US 3 en-US  en-US  en-US  en-US en-US  en-US  en-US en-US  en-US  en-US  en-US  en-US  en-US 4 en-US  en-US  en-US B en-US  en-US en-US A en-US ti en-US en-US  en-US  en-US en-US  en-US  en-US  en-US 6 en-US en-US  en-US  en-US  en-US 5 en-US  en-US  en-US e en-US en-US s en-US  en-US  en-US  en-US en-US  en-US n en-US  en-US 1 en-US en-US  en-US  en-US  en-US 6 en-US  en-US  en-US  en-US en-US  en-US f en-US en-US  en-US  en-US  en-US en-US  en-US  en-US  en-US  en-US  en-US 7 en-US  en-US  en-US  en-US en-US  en-US  en-US e en-US en-US  en-US  en-US  en-US 1 en-US 68 en-US  en-US  en-US  en-US en-US  en-US  en-US en-US  en-US  en-US  en-US  en-US 9 en-US  en-US  en-US  en-US en-US f en-US en-US  en-US ew en-US en-US e en-US  en-US  en-US  en-US 0 en-US  en-US  en-US  en-US en-US i en-US  en-US  en-US en-US  en-US n en-US  en-US  en-US  en-US 1 en-US  en-US  en-US  en-US en-US  en-US h en-US en-US er en-US i   Av a i l a bl e   en-US p en-US en-US ten en-US en-US hn en-US y en-US en-US ends en-US en-US l en-US en-US the en-US en-US l en-US en-US  en-US  en-US  en-US 2 en-US  en-US  en-US  en-US en-US  en-US en-US re en-US  en-US 6 en-US en-US  en-US  en-US  en-US 3 en-US  en-US  en-US  en-US en-US y en-US en-US  en-US e en-US en-US  en-US  en-US  en-US en-US  en-US  en-US 1 en-US en-US  en-US  en-US  en-US 4 en-US  en-US  en-US  en-US en-US  en-US en-US re en-US  en-US 6 en-US en-US  en-US  en-US  en-US 5 en-US  en-US  en-US  en-US  en-US en-US  en-US  en-US  en-US  en-US 6 en-US  en-US  en-US  en-US en-US  en-US en-US  en-US  en-US  en-US 1 en-US en-US  en-US  en-US  en-US 7 en-US  en-US  en-US  en-US en-US  en-US en-US t en-US  en-US earn en-US  en-US 9 en-US en-US  en-US  en-US  en-US 8 en-US  en-US  en-US  en-US en-US  en-US  en-US en-US  en-US  en-US  en-US 34 en-US en-US  en-US  en-US  en-US 9 en-US  en-US  en-US Lef en-US  en-US en-US  en-US  en-US ti en-US en-US  en-US en-US V en-US  en-US  en-US  en-US  en-US 0 en-US  en-US  en-US  en-US en-US  en-US  en-US en-US Pro en-US  en-US  en-US  en-US 34 en-US en-US  en-US  en-US  en-US 1 en-US  en-US  en-US  en-US en-US ng en-US en-US ti en-US en-US  en-US  en-US  en-US en-US  en-US 1 en-US en-US  en-US  en-US  en-US 2 en-US  en-US  en-US O en-US en-US M en-US  en-US en-US l en-US en-US  en-US  en-US en-US  en-US  en-US 1 en-US en-US  en-US  en-US  en-US 3 en-US  en-US  en-US  en-US en-US N en-US s en-US  en-US en-US  en-US  en-US 9 en-US en-US  en-US  en-US  en-US 4 en-US  en-US  en-US  en-US en-US  en-US  en-US to en-US en-US  en-US en-US n en-US  en-US  en-US  en-US 5 en-US  en-US  en-US D en-US  en-US  en-US en-US nt en-US en-US  en-US en-US  en-US en-US  en-US  en-US  en-US  en-US 6 en-US en-US  en-US 2 en-US en-US  en-US  en-US  en-US 6 en-US  en-US  en-US  en-US en-US edes en-US  en-US  en-US en-US  en-US  en-US  en-US  en-US  en-US 7 en-US  en-US  en-US  en-US en-US t en-US  en-US en-US  en-US  


2169-3536 \(c http://www.ieee.org/publications_standards/publications/rights/index.htm\l for more information This article has been accepted for publication in a future issue of this\ journal, but has not been fully edited. Content may change prior to fin\al publication. Citation information: DOI 10.1109/ACCESS.2017.2697839, IEEE Access   23     en-US  en-US 22 en-US en-US  en-US  en-US  en-US 8 en-US  en-US  en-US  en-US en-US t en-US en-US  en-US vey en-US en-US  en-US  en-US ne en-US en-US  en-US  en-US  en-US 9 en-US  en-US  en-US  en-US en-US  en-US  en-US tbed en-US en-US  en-US en-US  en-US  en-US  en-US 5 en-US en-US  en-US  en-US  en-US  en-US 0 en-US  en-US  en-US  en-US G en-US  en-US en-US o en-US en-US  en-US en-US  en-US  en-US  en-US 0 en-US en-US  en-US  en-US  en-US 1 en-US  en-US  en-US e en-US en-US ent en-US en-US  en-US  en-US en-US  en-US  en-US  en-US  en-US 5 en-US en-US  en-US  en-US  en-US 2 en-US  en-US  en-US a en-US en-US z en-US en-US  en-US dez en-US en-US z en-US en-US  en-US en-US  en-US a en-US  en-US  en-US en-US  en-US 26 en-US en-US  en-US  en-US  en-US 3 en-US  en-US  en-US a en-US en-US a en-US en-US o en-US en-US  en-US a en-US en-US  en-US en-US o en-US en-US F en-US en-US  en-US  en-US en-US  en-US  en-US en-US  en-US  en-US  en-US  en-US 8 en-US en-US  en-US  en-US  en-US 4 en-US  en-US  en-US  en-US en-US ti en-US en-US  en-US  en-US  en-US en-US  en-US en-US  en-US 2015 en-US b en-US 5 en-US  en-US 9 en-US en-US  en-US  en-US  en-US  en-US 5 en-US  en-US  en-US o en-US en-US  en-US en-US  en-US  en-US en-US n en-US  en-US  en-US 45 en-US en-US  en-US  en-US  en-US 6 en-US  en-US  en-US  en-US en-US  en-US k en-US  en-US  en-US en-US  en-US  en-US  en-US 0 en-US en-US  en-US  en-US  en-US 7 en-US  en-US  en-US  en-US en-US  en-US  en-US en-US  en-US  en-US r en-US  en-US 86 en-US en-US  en-US  en-US  en-US 8 en-US  en-US  en-US  en-US en-US  en-US y en-US en-US by en-US en-US  en-US en-US  en-US s en-US  en-US 1 en-US en-US  en-US  en-US  en-US 9 en-US  en-US  en-US  en-US  en-US dez en-US en-US  en-US en-US n en-US en-US  en-US en-US  en-US n en-US y en-US en-US  en-US  en-US  en-US 0 en-US  en-US  en-US  en-US en-US  en-US tem en-US en-US  en-US ti en-US en-US ve en-US en-US  en-US  en-US  en-US  en-US  en-US 1 en-US  en-US  en-US  en-US en-US  en-US ty en-US en-US  en-US en-US  en-US  en-US  en-US 5 en-US  en-US 2 en-US en-US  en-US  en-US  en-US 2 en-US  en-US  en-US en en-US en-US  en-US  en-US  en-US en-US ess en-US  en-US 831 en-US en-US  en-US  en-US  en-US 3 en-US  en-US  en-US  en-US  en-US en-US ti en-US en-US  en-US ne en-US en-US  en-US e en-US en-US  en-US  en-US 26 en-US en-US  en-US  en-US  en-US  en-US 4 en-US  en-US  en-US  en-US en-US  en-US ve en-US  en-US  en-US en-US  en-US rk en-US  en-US 7 en-US en-US  en-US  en-US  en-US 5 en-US  en-US  en-US  en-US  en-US en-US Sy en-US  en-US  en-US en-US  en-US  en-US  en-US es en-US  en-US 1 en-US en-US  en-US  en-US  en-US 6 en-US  en-US  en-US  en-US  en-US  en-US r en-US rks en-US  en-US  en-US  en-US  en-US 7 en-US  en-US  en-US  en-US en-US  en-US  en-US en-US n en-US  en-US  en-US 9 en-US 0 en-US  en-US 411 en-US en-US  en-US  en-US  en-US 8 en-US  en-US  en-US  en-US en-US  en-US tems en-US en-US  en-US  en-US  en-US  en-US n en-US  en-US en-US  en-US v en-US es en-US  en-US  en-US 3 en-US en-US  en-US  en-US  en-US 9 en-US  en-US  en-US en en-US en-US  en-US  en-US en-US  en-US en-US  en-US  en-US  en-US 0 en-US  en-US  en-US m en-US en-US  en-US  en-US th en-US en-US  en-US en-US  en-US  en-US  en-US 7 en-US en-US  en-US  en-US  en-US 1 en-US  en-US  en-US  en-US en-US  en-US  en-US en-US  en-US  en-US  en-US 4 en-US en-US  en-US  en-US  en-US 2 en-US  en-US  en-US  en-US  en-US en-US  en-US  en-US en-US  en-US  en-US  en-US  en-US  en-US 3 en-US  en-US  en-US  en-US en-US ng en-US  en-US  en-US  en-US  en-US en-US  en-US  en-US 1 en-US en-US  en-US  en-US  en-US  en-US 4 en-US  en-US  en-US  en-US  en-US rk en-US  en-US  en-US  en-US  en-US 5 en-US  en-US  en-US  en-US en-US  en-US  en-US en-US  en-US  en-US  en-US 8 en-US en-US  en-US  en-US  en-US 6 en-US  en-US  en-US  en-US en-US  en-US  en-US en-US  en-US  en-US  en-US 1 en-US en-US  en-US  en-US  en-US 7 en-US  en-US  en-US  en-US en-US  en-US t en-US dy en-US en-US n en-US s en-US  en-US  en-US 9 en-US en-US  en-US  en-US  en-US 8 en-US  en-US  en-US  en-US en-US  


2169-3536 \(c http://www.ieee.org/publications_standards/publications/rights/index.htm\l for more information This article has been accepted for publication in a future issue of this\ journal, but has not been fully edited. Content may change prior to fin\al publication. Citation information: DOI 10.1109/ACCESS.2017.2697839, IEEE Access  24      en-US  en-US i en-US  en-US en-US  en-US  en-US 9 en-US  en-US 2 en-US en-US  en-US  en-US  en-US 9 en-US  en-US  en-US  en-US en-US  en-US n en-US en-US n en-US  en-US t en-US 7 en-US  en-US  en-US 5 en-US en-US  en-US  en-US  en-US 0 en-US  en-US  en-US  en-US  en-US en-US  en-US  en-US n en-US en-US E en-US ess en-US  en-US 858 en-US en-US  en-US  en-US  en-US 1 en-US  en-US  en-US  en-US en-US  en-US  en-US en-US ess en-US  en-US 1 en-US en-US  en-US  en-US  en-US  en-US 2 en-US  en-US  en-US  en-US  en-US en-US  en-US  en-US  en-US en-US  en-US  en-US 1 en-US en-US  en-US  en-US  en-US 3 en-US  en-US  en-US  en-US  en-US  en-US o en-US en-US  en-US en-US in en-US  en-US  en-US  en-US l en-US en-US  en-US g en-US  en-US 0 en-US en-US  en-US  en-US  en-US 4 en-US  en-US  en-US Ben en-US  en-US  en-US en-US  en-US  en-US en-US  en-US  en-US 7 en-US en-US  en-US  en-US  en-US 5 en-US  en-US  en-US  en-US en-US f en-US  en-US  en-US dy en-US en-US  en-US 11 en-US en-US  en-US  en-US  en-US 6 en-US  en-US  en-US  en-US  en-US en-US T en-US en-US  en-US o en-US  en-US en-US  en-US  en-US 1 en-US en-US  en-US  en-US  en-US 7 en-US  en-US  en-US z en-US en-US  en-US en-US ti en-US en-US  en-US  en-US  en-US en-US sort en-US  en-US  en-US 5 en-US  en-US  en-US  en-US 8 en-US  en-US  en-US z en-US en-US  en-US en-US  en-US f en-US en-US the en-US en-US  en-US  en-US en-US  en-US  en-US  en-US  en-US 121 en-US en-US  en-US  en-US  


