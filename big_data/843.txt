Methodology for Evaluating Security Controls Based on Key Performance Indicators and Stakeholder Mission   Frederick T. Sheldon Oak Ridge National Laboratory  sheldonft@ornl.gov  Robert K. Abercrombie Oak Ridge National Laboratory  abercrombier@ornl.gov  Ali Mili New Jersey Institute of Technology  mili@cis.njit.edu    Abstract  Information security continues to evolve in response to disruptive changes with a persistent focus on information-centric controls and a healthy debate 
about balancing endpoint and network protection, with a goal of improved enterprise/business risk management. Economic uncertainty, intensively collaborative styles of work virtualization, increased outsourcing and ongoing compliance pressures require careful consideration and adaptation. This paper proposes a Cyberspace Security Econometrics System CSES\ provides a measure \(i.e., a quantitative indication\ of  reliability, performance and/or safety of a system that accounts for the criticality of each requirement as a function of one or more stakeholders interests in that requirement. For a given stakeholder CSES accounts for the variance that may exist among the stakes one attaches to meeting each requirement 
This paper introduces the basis, objectives and capabilities for the CSES including inputs/outputs as well as the structural and mathematical underpinnings   1. Introduction  Good security metrics are required to make good decisions about how to design security countermeasures, to choose between alternative security architectures, and to improve security during operations. Therefore, in essence, measurement can be viewed as a decision aid. The lack of sound and practical security metrics is severely hampering progress in the development of secure systems Our Cyberspace Security Econometrics System CSES\ provides the following advantages over 
traditional measurement systems: \(1\SES accounts for the variances that exist among different stakeholders of the same system. Different stakeholders will typically attach different stakes to the   This manuscript has been authored by a contractor of the U.S Government under contract DE-AC05-00OR22725. Accordingly, the U.S. Government retains a nonexclusive, royalty-free license to publish or reproduce the published form of this contribution, or allow others to do so, for U.S. Government purposes 
 same requirement or service \(e.g., a service may be provided by an information technology system or 2\or a given stakeholder, CSES accounts for the variance that may exist among the stakes one attaches to meeting each requirement. The same stakeholder may attach different stakes to satisfying different requirements within the overall system specification. \(3\en compound specification \(e.g., combination\(s\ of commercial off the shelf software and/or hardware CSES accounts for the variance that may exist among the levels of verification and validation \(i.e 
certification\ performed on the various components of the specification. In other words, the certification activity may produce higher levels of assurance across different components of the specification than others The relations between value based quantitative systems, risk assessment and other cyberspace research and applications areas is well founded [1h es e relations, characterized by CSES, are unavoidably involved with software and information system product and process technology, and their interaction with human values. CSES's rationale is strongly empirical 
but includes new concepts in need of stronger theory CSES uses risk considerations to balance information assurance discipline and flexibility, and to answer other key how much is enough questions S ES  will help to illuminate information technology policy decisions by identifying the quantitative and qualitative sources of cost and value associated with candidate decisions. In this paper we introduce the basis objectives and capabilities for the CSES including inputs/outputs and the basic structural and mathematical underpinnings 
 1.1. Qualities of Security Metrics  Some qualities of a good metric include: \(1\y to measure the right thing \(e.g., supports the decisions 2\tifiable \(e.g., damages 3\apability to be measured precisely and accurately, \(4\ ability to be validated against ground truth, and \(5\confidence level one has in the assertions made within the framework of the Proceedings of the 42nd Hawaii International Conference on System Sciences - 2009 1 978-0-7695-3450-3 2009 U.S. Government Work Not Protected by U.S. Copyright 


metric. To these criteria, one should add the following desirable properties: \(1\expensive in time and cost to perform, \(2\y to be refereed independently, \(3 repeatable so the outputs are independent of the analyst performing the measurement, and \(4\calable from small, single computer systems to large, nation-scale enterprise networks  1.2. Quantifying Security Metrics  System security should be characterized, not by some abstract discrete scale, but rather by the very concrete determinant, mean failure cost \(MFC  MFC reveals how much each stakeholder stands to lose from mission value due to the lack of security Subsequent use of this quantification enables us to derive an economic model that captures the tradeoffs involved in deploying security counter measures. Let us consider some fundamental pieces needed for evaluating security control  1.3. Fundamental Concepts  Figure 1 shows essential input/output components and phases \(i.e., discovery, evaluation and metrics including data collection/analysis and consisting of the following System Stakeholders refers to any person or organization that has a stake in the operation of the system \(i.e., users, operators of the system, hosts of the systems, etc Security Specification used in the same way that correctness is a relative attribute \(a system is correct with respect to its functional specification\ and refers to a representation of the security attributes that a system must satisfy to be deemed secure Security Requirement used in the same way that a complex functional specification is typically composed of simpler components \(representing elementary functional properties\d is composed of simpler security requirements  Mean Failure Cost used in the operational sense because the lack of security within the system may cause damage, in terms of lost productivity, lost business, lost data, resulting in security violations. We represent this loss by a random variable, and define MFC as the mean of this random variable [5  A s  discussed further, this quantity is not intrinsic to the system, but varies by stakeholder  Figure 1. Cyber Security Econometrics System \(CSES Proceedings of the 42nd Hawaii International Conference on System Sciences - 2009 2 


 2. Step-Wise Process of CSES  To estimate the mean failure cost of a system for a set of stakeholders, we need to initially identify and then maintain the following information:  \(1\e set of stakeholders of the system, and \(2\ the set of security specifications and thus security requirements that are to be required/provided by the system. \(3\or each stakeholder and each security requirement, the stake that the selected stakeholder attaches to the selected service \(or conversely, the cost that the stakeholder incurs if the service is disrupted\his information is provided by stakeholders. \(4\ each component of a specific security requirement, the likelihood that the system provides that service as specified. This information is computed in light of the V&V measures inspection, verification, testing, security measures, firewalls, vulnerability removal, threat mitigation, etc\at the system has undergone. In particular, estimating the likelihood of delivering a service requires that we analyze to what degree the components that are involved in delivering this service have been validated. The CSES process proceeds in three steps \(Generation of Stakes Matrix Dependency Matrix, and Threat Matrix\ussed in the next subsections C S E S e n co m p as s e s  n o t  only failure costs but also mitigation costs, specifically verification costs   2.1. Generation of Stakes Matrix  The MFC estimation depends on the following premises: \(1\takeholder may have different stakes in different security requirements, and \(2\ecurity requirement may carry different stakes for different stakeholders. The best way to represent this situation is through a two dimensional matrix where the rows represent stakeholders, the columns represent security requirements and the entries represent stakes, as shown in Table 1 The FC entry at row i column j  represents the cost that stakeholder Si  would lose if the system failed to meet the security requirement Rj i.e also represented as FC\(Si,Rj The data in Table 1 is determined by stakeholders. Each row is filled by the corresponding stakeholder, possibly in their own \(possibly distinct financial / economic terms \(Dollars, Person Months Euros, etc Using this computational infrastructure, we estimate the MFC of the system for a stakeholder i as the weighted sum of the stakes that he attaches to all the services \(security requirements\ interest weighted by the probability of failing to deliver these services. Specifically  1  1 j j i n i i P FC MFC      We envision using this metric, not only off-line, to estimate the seaworthiness of the system for a particular stakeholder, but also for online monitoring of a real-time system. To the extent that the probabilities of service delivery \(i.e., success of security requirement being met\may be profoundly altered by an ongoing attack or intrusion, this may adjust the calculations of the mean failure costs, and may push MFC for a particular stakeholder beyond Table 1 Stakes ST\: Cost of failing a security requirement   Security Requirements R1 R2 R3  Rn Stakeholders S1      S2      S3          j i FC   Sm        Probabilities of Security Requirements Delivery      j P   Table 2. Example of Stakes ST\ Matrix showing requirements  Stakeholder Requirements  Requirement 1:   Safety Requirement Requirement 2 Timeliness Passengers Personal safety Convenience Scheduling Airline Company Liability for loss of life Reputation of airline Reputation for timeliness / PR Aircraft Manufacturer Liability for loss of life Reputation of aircraft Zero Accident Insurance of  Aircraft Replacement Value of the Aircraft, Liability Zero Life Insurance of Passenger Value of Life Insurance Zero Proceedings of the 42nd Hawaii International Conference on System Sciences - 2009 3 


acceptable values, triggering an alarm Recently, several techniques have emerged to characterize stakeholders and their respective interests. A variety of approaches extend from mapping security threats applying Computer Emergency Readiness Team CERT\onomy; to stakeholders in the automotive industry  to investigations to secure vehicles against cyber attacks using the Defense-in-Depth paradigm  physically embedding information and communications technology ICT\ security into vehicles themselv pplicati on s fu rt h e r ex te n d to checklists d im provin g t h e c y ber in cide n t  mission impact in the military d ev al u a ti ng  damage from cyber attacks T h e lon g s t a n di n g  question, therefore, is How much security is enough To address this question, the subject domain of risk management must be addresse en  risk management is factored into the equation, classical approaches can be of benefit [18T o illu strate t h e  relevance of this Stakes matrix, and the idea of requirement-dependent failure cost, let us consider the example of a flight control system on board a commercial aircraft as shown in Table 2 Stakeholders The aircraft pilot; the passengers the airline company; the aircraft manufacturer; the FAA; the insurance company that insures the aircraft the insurance company that insures a passenger \(life insurance\he EPA; etc Requirements Adhering to Safety Requirements maintaining the aircraft above stalling speed, ensuring never to reverse thrust in mid-air, ensuring landing gears are out before landing, etc\dhering to FAA flight vector; Ensuring timely response to autopilot parameter adjustments; Maximizing fuel efficiency Minimizing flight delay; Ensuring a smooth ride Minimizing emission of greenhouse gases; etc Stakes For the sake of illustration, we present below two sample columns of the Stakes table \(Table 2\responding to two requirements: Safety and Timeliness All these stakes are typically well known, and can be quantified financially. Using the Stakes Matrix, we estimate the MFC of Stakeholder S as follows    i R i i R S FC R P S MFC         Where P\(Ri is the probability that the system fails to meet requirement Ri In other words, the mean failure cost for stakeholder S is the sum, for all requirements, of the cost of failing these requirements weighted by the probability of failing them. We discussed above how to derive the Stakes table, that provide the terms FC\(S,Ri In the next subsection, we discuss how to derive the probability terms  2.2. Generation of Dependency Matrix  The question we address in this section \(Table 3\ is how to estimate the probability that a particular security requirement is violated in the course of operating the system for some period of time. The idea that we pursue here is to link the probability of failing a particular requirement with the probability of failure of a component of the system. The elucidation of this probabilistic link involves an analysis of the system s architecture, to determine which component contributes to meeting which requirement However, to  Table 4. Example of Dependency DP\ Matrix:  Links requirements with components  Components Requirements Processing Component Login Component Secure Storage Component User Profile Analysis Freedom from Insider Threats 0.01 0.6 0.2 0.98 Protection of Critical Data 0.01 0.2 0.98 0.2 Access Control 0.01 0.98 0.4 0.1  Table 3 Dependency DP\ Matrix:  Links requirements with components   Components C1 C2 C3  Ck Requirements R1      R2      R3             j i E R    Rn      Proceedings of the 42nd Hawaii International Conference on System Sciences - 2009 4 


illustrate our method, we present a possible solution to this problem, under a simplifying hypothesis, which is that security violations affect no more than one component at a time We let C1, C2, C3 Ck be the components of the system and we let Ei for 1 i k be the event Failure of Component Ci Finally, we let Ek+1 be the event No component has failed Then we can write \(as an identity of probability calculus      1 1        k i i i E R E R P     Where the term Ei represents the probability of event Ei and the term R|Ei represents the probability of failing to satisfy requirement R given hypothesis Ei  i.e., that event i has occurred\ general, it is fair to assume that in the absence of component failures security requirements are vacuously satisfied, whence we write   0    1   k E R    As for the conditional probabilities of failing requirement R under the hypothesis of component failures, these may be estimated by the systems architect in light of the dependencies that exist between components and requirements. As an example, we consider the following situation   Security Requirement R Data item A must never be altered by an unauthorized user   The enterprise architecture and security policies provide that copies of data item A are stored in two components C1 and C2    Then, we can infer   0     0    2 1   E R E R     Failure of any one component does not violate the requirement, since we can always retrieve the correct value from the unaffected component remember we assume that no more than one component at a time fails\nd restore it We now consider a different situation   Security Requirement R Data item A must never be accessed by an unauthorized user   The architecture and security policies provide that copies of data item A are stored in two components C1 and C2    Then, we can infer   0  1     0  1    2 1   E R E R     If one component fails in such a way that it can no longer control access to data item A, then Requirement R is violated We now consider a third hypothetical situation   Security Requirement R Access to the system must be contingent on proper user authentication through a login procedure   The architecture and security policies provide that two components C1 and C2 can login an incoming user. Incoming users are dispatched at random to one or the other   Then, we can infer   5  0     5  0    2 1   E R E R     If one component fails then system access is secure only for those users dispatched to the other non-faulty component More generally, we assert that an analysis of the system architecture, by architecture subject matter experts, can lead to the derivation of conditional probabilities that link the probability of component failures with the probabilities of failing to meet specific requirements. This information can be represented in a two dimensional matrix, which we call the Dependency matrix Table 3 shows its structure, where the term Ej  represents the probability of event Ej and the term R|Ej represents the probability of failing to satisfy requirement Ri given hypothesis Ej i.e., that event j  has occurred\ Table 3, there exists a component event Ej for a requirement Ri where the probability of failure to satisfy requirement R exists  Ri | Ej  In the current airline example, the following would be an example of a generation of the Dependency  matrix with respect to the passenger requirements of 1\ety and \(2\meliness with three distinct different components for each requirement. The results are illustrated in Table 4 The probability of failing a requirement is obtained by the sum, for all components, of the conditional probabilities of failing that requirement, conditional on failure of the component, weighted by the probability of failure of the component. The conditional probabilities are given by the dependency matrix; as for the probabilities of component failures, as for the probabilities of component failures and are the subject of the next section Proceedings of the 42nd Hawaii International Conference on System Sciences - 2009 5 


 2.3. Generation of Impact Matrix  The Impact Matrix shows the Component Failure versus Threats Relationship Grouping \(Table 5\. The probability of component failure depends on three factors:  \(1\e armor \(e.g., Technical Controls or mitigations\hat the component is provided with to protect against threats and to mitigate damage in the case of successful attacks. \(2\attern of threats that the component is subjected to. In the same way that researchers of reliability define fault models that catalog faults under consideration, we must define threat models that catalog what threats or families of threats we want to protect against. An example of classification may include:  insider threats; intrusions; denial of service threats; authentication threats; etc. \(3 the degree of verification and validation that the component has undergone, be it through testing, inspection, static analysis, etc To assess the likelihood that a particular threat leads to the failure of a component, we consider a set of cataloged threats \(or families of threats with common attributes\y T1, T2, T3 Th and we consider the events V1, V2, V3 Vh, Vh+1 where Vi for 1 i h stands for Threat i has materialized and Vh+1 stands for No threat i has materialized  Because events Vi for 1 i h+1 are complementary \(if we assume that no more than one threat materializes at a time\we can write      1 1        h j j i j i V E V E      This equation links the probability of threat Tj  which is Vj he probability of component failure for component Ci which is  Ei To apply this formula, we need to derive the conditional probabilities, which we propose to represent in a two dimensional matrix, that we call the  Impact matrix in Table 5 This Impact matrix is filled by component analysts and security experts, by assessing the impact that each type of threat may have on the operation of the component. Automated \(e.g., in the airline example or in the case of cyber security the Common Vulnerability Scoring System [CVSS m a nu al \(e.g Su bj ect Matter Experts [SME m e c h an i s m s  w ill be u tilized  as the quantification of the asset is critical for the methodology as depicted in Table 6  2.4. Generation of Mitigation Costs Matrix  Our quantitative model CSES encompasses not only failure costs, but also mitigation costs  specifically verification costs. Each requirement fulfilled or service delivered by the system depends on the correct operation of one or more system components. This dependency can be quantified by the statistical correlation between the failure of the Table 5 Impact IM\ Matrix:  Links threat relationship groupings   Threats T1 T2 T3  Th Components C1      C2      C3             j i V E    Ck      Table 6. Impact \(IM\: Links components to threats  Threats Components Insider Threats Intrusions Denial of Service Threats Authentication Threats No Threat Processing Component 0.2 0.4 0.8 0.8 0.0 Login Component 0.2 0.2 0.2 0.2 0.0 Secure Storage Component 0.2 0.4 0.2 0.2 0.0 User Profile Analysis 0.2 0.1 0.1 0.1 0.0  Proceedings of the 42nd Hawaii International Conference on System Sciences - 2009 6 


component and the failure to deliver the service or fulfill the requirement. If we combine this dependency with the cost of verifying each component of the system, we can maintain an estimate of the probabilities of service delivery \(discussed above function of the effort invested in enhancing the dependability of the individual components Maintaining this information can serve two purposes   First, to determine, at all times, which components must be enhanced first to improve overall stakeholder satisfaction   Second, to charge verification costs according to stakeholder benefit. For any particular verification measure, we charge stakeholders according to the gains they have achieved as a result of this measure \(which are quantified by the reduction of their mean failure cost Table 7 illustrates the dependency between verification costs per component and verification cost per service, and links to the table above, which illustrates the dependency between the probabilities of service delivery \(resulting from enhanced verification and mean failure costs The verification cost by service can be estimated by the following formula    n i j j i i VC D VS 1    3. Estimating the Probability of Threats  If we review our discussions so far, we find many formulas of the form        m j j j i i n i X A Y 1  1    where Y is a vector of size n,  X is a vector of size m and A is a nm matrix. We write this formula compactly as   X A Y    Specifically   The vector of mean failure costs MFC one entry per stakeholder\ given by the following equation   PR ST MFC   where ST is the Stakes matrix and PR  is the vector of requirement failure probabilities \(one entry per requirement   The vector of requirement failure probabilities is given by the following equation   PE DP PR   where DP is the Dependency matrix and PE is the vector of component failure probabilities \(one entry per component   The vector of components failure probabilities is given by the following equation   PV IM PE   where IM is the Impact matrix and PV is the vector of threat emergence probabilities \(one entry by type of threat By substitution, we find the equation that gives us vector of mean failure costs of all stakeholders as   PV IM DP ST MFC   Utilizing a user interface, the Stakes matrix ST s filled by stakeholders according to the stakes they have in satisfying individual requirements; the Dependency  matrix DP illed in by the system architect \(i.e Table 7 Mitigation Costs MC\:  Links requirements and components mitigation costs  Components  C1 C2 C3 C4 C5 Services S1    Verification Cost by Service VS1 S2    VS2 S3    VS3 S4  j i D   VS4 S5    VS5   Verification Cost by Component VC1 VC2 VC3 VC4 VC5 Proceedings of the 42nd Hawaii International Conference on System Sciences - 2009 7 


cyber security operations and system administrators\g to how each component  contributes to meet each requirement; the Impact matrix \(IM\illed by analysts according to how each component is affected by each threat The remaining question is how to fill the vector PV that represents the probability of emergence of the various threats that are under consideration? This is done empirically, by simulating and/or operating the system for some length of time and estimating the number of threats that have emerged during that time and continue to be refined as the system evolves. From these numbers, we infer the probability of emergence of all the threats during one hour of operation  4. Application of CSES  In this section, we provide a general set of guidelines for using the CSES  4.1. Online Security Monitoring  In the MFC equation given above, the matrices ST  DP and IM are static, and vector PV accounts for the analysts estimate of threat emergence in the absence of any specific situational info rmation. When this tool is coupled with sensors that detect anomalies or security violations, then it can dynamically re-compute the mean failure costs of stakeholders provided we know how new situational information impacts the vector PV As an extreme example, if a threat of type T1 has been confirmed, then vector PV is assigned the value \(1, 0, 0, 0, 0 d the new values of MFC are recomputed, giving stakeholders an estimate of their current mean failure cost if the system continues to operate. In this way, stakeholders may place the systems in the cone \(i.e., protection/operating envelope\d changing its position dynamically, to meet mission requirements and to certify operational capability as shown in Figure 2 [21, 22   4.2. Charging Verification & Mitigation Costs  Imagine that the custodian of the system wishes to submit a given component, say C1 to further verification and validation \(V&V\formation Assurance \(IA\ntrols, and wishes to charge stakeholders for the V&V or modification of mitigation effort. As a matter of fairness, we wish to charge stakeholders according to how much a better quality component impacts their bottom line. We argue that one way to do that is to estimate, for each stakeholder the difference between the MFC under the current situation and the MFC after integration of mitigation technologies or V&V. How is this difference calculated? By considering how the modified IA controls or verification and validation of the component reduces the values of the failure probabilities in the row corresponding to that component in the impact matrix  4.3. Integrating Quality Costs  From the standpoint of each stakeholder, the mean failure cost \(which is the cost we expect to incur as a result of the lack of security\must be balanced against the cost of improving system security. Our mean failure cost model allows us to formulate the tradeoff of quality versus cost in terms of a return on investment equation. Specifically, a return on investment model is defined by the following parameters   An initial investment cost, say IC    An investment cycle \(duration\, say T    An return over the investment cycle, say B\(t for 1 t T and   A discount rate, say d  Then the return on investment is given by the following formula     1    1 1       T t t d IC t B ROI   Performance  Confidentiality Availability Integrity Goal Placing a System in the Cone \(operating envelope\anging its position dynamically to meet mission requirements \(certify  operational capability Functionalit y Survivabilit y   Figure 2. Representation of Interdependent Entities Proceedings of the 42nd Hawaii International Conference on System Sciences - 2009 8 


The formula identified in section 2.4 can be used to compute IC We can estimate the benefit gained by stakeholder S during time period t by computing the difference between the mean failure cost with the current component and the mean failure cost \(hopefully lower\ith the validated component  5. Summary  The CSES follows a defined process. The initial inputs \(1\anization mission \(and components thereof\, \(2\alue of its objectives and assets if uninterrupted, and \(3\e components of the enterprise system that support each mission component, are determined by stakeholders The customer, with assistance from SMEs, defines the criteria of a quantitative value of an asset. For example, the criteria may include   Financial basis \(e.g., operational cost of downtime per unit of time defined with hardware/software costs, HVAC, staffing, etc versus profit\; which is the quantitative measurement to be used within the CSES   Federal Information Security Management Act FISMA\ of 2002, customer derived value of assets per NIST 800-60, and/or FIPS 199/200 February 2004, Standards for Security Categorization of Federal Information and Information Systems\ dictated requirements   Customer defined requirements; acceptable and unacceptable impact levels against the value related to IA tenets of confidentiality, availability and integrity may also be examined in further program contract options to supplement the prototype The CSES process proceeds in three steps Generation of Stakes Matrix, Dependency Matrix, and Threat Matrix\SES encompasses not only failure costs but also mitigation costs, specifically verification costs. CSES provides   A framework for measuring the appropriate attributes that support the decisions necessary to 1\ign security countermeasures, \(2\oose between alternative security architectures, \(3 respond to events such as intrusions or attacks and  4\prove security \(including reliability and safety\ring both design and operational phases   A comprehensive basis for choosing courses of action that have the highest risk reduction return on investment, i.e., reduce the most risks for the lowest cost The basis of CSES stems from and is consistent with the spirit of Value Based Software Engineering CSES comprehends the different organizational mission needs for all stakeholders, including reliability and safety. CSES identifies information assurance controls and mitigation costs as an investment toward assuring mission success  6. Future Work  Our future plans will draw from our experience to provide a good example of a system with credible and distinct stakeholders, a rich security requirements structure \(i.e., set of\on-trivial architecture with intertwined security components and functional processing\ components as well as a rich catalog of families of threats  7. References   B W  Bo eh m an d L   Hu an g V al u e Based  Software Engineering: Reinventing Earned Value Monitoring and Control ACM Software Engineering Notes vol. 28\(2\ 2003  B W  Bo eh m an d L   G  Hu a n g V al u e Based  Software Engineering: A Case Study Computer vol. 36, pp. 33-41, 2003 3 S Biff l, A  A u ru m   B. W   Bo eh m  H Erd o g m u s  and P. Gruenbacher, "Value Based Software Engineering," Springer Verlag, 2006 4  K  J  SooH o o   H ow Muc h is Enoug h A R i sk Management Approach to Computer Security," in Consortium for Research on Information Security and Policy \(CRISP Stanford University, 2000 5 A  Mili a n d F  T  S h e l d on  M e a s uring Re lia bil ity  as a Mean Failure Cost," in Proceedings of the 10th IEEE High Assurance Systems Engineering Symposium Dallas, TX: IEEE, 2007, pp. 403-404 6 A  Mili a nd F. T  She l don  C ha lle ng ing the Me a n  Time to Failure:  Measuring Dependability as a Mean Failure Cost," in Proceedings of 42nd Hawaii International Conference on System Sciences vol. 42 Waikoloa, HI: IEEE, 2009 7 A  Mili, A  V i nok ur ov L  L  Jila ni, F. T  S h e l do n  A. Thomasian, and R. B. Ayed, "Modeling Security as a Dependability Attribute: A Refinement Based Approach Innovations in Systems and Software Engineering, A NASA Journal vol. 2\(1\pp. 39-48, 2006 8 R. K. A b e r c r om bie  F. T  She l don a n d A  Mili  System and Method for Implementing and Monitoring a Cyberspace Security Econometrics System and Other Complex Systems," in US Patent Office US Patent Pending, 2008, pp. 1-95 9 F. T  She l d o n  R. K. A b e r c r om bie  a n d A  Mili  Evaluating Security Controls Based on Key Performance Indicators and Stakeholder Mission in Proceedings of the 4th Annual Cyber Security and Information Intelligence Research Workshop  Oak Ridge, TN: ACM, 2008 Proceedings of the 42nd Hawaii International Conference on System Sciences - 2009 9 


10  R. R. Br o o k s, S  San d er, J Den g an d J. T a ib er  Automotive System Security:  Challenges and State-of-the-Art," in Proceedings of the 4th Annual Cyber Security and Information Intelligence Research Workshop Oak Ridge, TN, 2008 11  R. R. Bro ok s Disruptive Security Technologies with Mobile Code and Peer-to-Peer Networks  Boca Raton, FL: CRC Press, 2005 12  U  E. La rs on a nd D  K  Nils s on S e c u ring  Vehicles against Cyber Attacks," in Proceedings of the 4th Annual Cyber Security and Information Intelligence Research Workshop Oak Ridge, TN ACM, 2008 1 K L e mke C P a ar an d M   W o l f   E m b ed d e d Security in Cars, Securing Current and Future Automotive IT Applications,"  Berlin: SpringerVerag, 2006 14  J. M. A b eles  N IS T P r o g ra m Re v i e w  f o r Information Security Management Assistance PRIMSA\nhancement," in Proceedings of the 4th Annual Cyber Security and Information Intelligence Research Workshop Oak Ridge, TN ACM, 2008 15 M. R. G r i m a ila R. F. Mills, a n d L  W  Fortson  Improving the Cyber Incident Mission Impact Assessment \(CIMIA\rocess," in Proceedings of the 4th Annual Cyber Security and Information Intelligence Research Workshop Oak Ridge, TN ACM, 2008 16  C  L a la a nd B   P a nda  E v a lua t i n g D a m a ge f r o m  Cyber Attacks IEEE Transactions on Systems Man and Cybernetics vol. 31\(4\pp. 300-310 2000 1 E. A l S h aer, L  Kh an an d M  S  A h m e d   A  Comprehensive Objective Network Security Metric Framework for Proactive Security Configuration in Proceedings of the 4th Annual Cyber Security and Information Intelligence Research Workshop  Oak Ridge, TN: ACM, 2008 1 B W  Bo eh m an d T  DeM a rco  S o f t w are Ri s k  Management IEEE Software vol. 14\(3\, pp. 1719, 1997 1 B W  Bo eh m  S o f t w ar e Ri sk M a n a ge men t    Principles and Practices IEEE Software vol. 8 pp. 31-41, 1991 2 S  M y ag mar  A  J  L ee an d W  Yu rcik T h r eat  Modeling as a Basis for Security Requirements," in Symposium on Requirements Engineering for Information Security \(SREIS\ conjunction with 13th IEEE International Requirements Engineering Conference \(RE Paris, France: IEEE, 2005 21  W  H  Sa nde rs  P roba bil i s t i c Va lida tio n of  Computer System Survivability," in Oak Ridge National Laboratory's Computational Sciences and Engineering Division Distinguished Lecture Series  Oak Ridge, TN: Oak Ridge National Laboratory 2005 22 F. Ste v e n s  T  Courtne y  S. Sing h  A   A g ba ria  J  F  Meyer, W. H. Sanders, and P. Pal, "Model Based Validation of an Intrusion Tolerant Information System," in 23rd IEEE International Symposium on Reliable Distributed Systems \(SRDS'04 2004 pp. 184-194   Proceedings of the 42nd Hawaii International Conference on System Sciences - 2009 10 


Inevitably, this study has some limitations that have to be taken into account in order to adequately interpret the results and judge their generalizability. First, we employed self-reported measures for several key variables. In some cases \(e.g. willingness to pay sources of data were not available, but there was little reason to expect distortion in self-reporting. In some cases \(e.g. commitment and satisfaction are intrinsically subjective and perceptual; this condition necessitated the use of self-report [49 Second, we gathered data only in a single MMOG community and therefore, some effects could be unique to the specific design of the community Third, this study has been the first to examine different success factors of online communities, but cross-sectional in nature. To analyze the relation between the userbase and community success in greater detail, longitudinal studies using panel data could be of great value. Moreover, Partial Least Squares \(PLS an adequate technique Future research may build upon the results of this study in a number of ways. Extending this study to several MMOG communities and also in different countries could further deepen the understanding of determinants of favorable user behavior. Furthermore the role of membership tenure could be investigated in more detail to deepen our understandingof the user life cycle in a community and the different impact of users Proceedings of the 42nd Hawaii International Conference on System Sciences - 2009 7 characteristics and their behavior in various stages. The ambiguous relationship between favorable user behavior and the level of satisfaction seems particularly noteworthy. It was the only attribute to have both positive and negative relations with our success dimensions. Since most business models of MMOG communities are based on premium memberships, future research should explore the negative relationship between satisfaction and willingness to pay identified in this study more thoroughly In summary, the results of this study provide answers to the antecedents of favorable user behavior in online communities and provide insights into the diverse dimensions of success  5. References  1] Anderson, E.W., Fornell, C., and Lehmann, D Customer Satisfaction, Market Share, and Profitability Findings from Sweden?, Journal of Marketing, 58, 2, 1994 pp. 53-66 2] Anderson, R.E., ?Consumer Dissatisfaction: the Effect of Disconfirmed Expectance on Perceived Product Performance?, Journal of Marketing Research, 10, 1, 1977 pp. 38-44 3] Berkowitz, S.D., ?An Introduction to Structural Analysis: The Network Approach to Social Research Butterworth, Toronto, 1982 4] Bickart, B. and Schindler, R.M., ?Internet Forums as Influential Sources of Consumer Information?, Journal of Interactive Marketing, 15, 3, 2001, pp. 31-40 5] Bollen, K.A., ?Structural Equations with Latent Variables?, John Wiley and Sons, New York, 1989 6] Bolton, R.N. and Drew, J.H., ?Linking Customer Satisfaction to Service Operations and Outcomes?, in Rust, R.T. and Oliver, R.L. \(Eds Directions in Theory and Practice?, Sage Publications Thousand Oaks, 1994, pp. 173-200 7] Bolton, R.N. and Lemon K.N., ?A Dynamic Model of Customers? Usage of Services: Usage as an Antecedent and 


Customers? Usage of Services: Usage as an Antecedent and Consequences of Satisfaction?, Journal of Marketing Research, 36, 2, 1999, pp. 171-86 8] Bolton, R.N., ?A Dynamic Model of the Duration of the Customer?s Relationship with a Continuous Service Provider: The Role of Satisfaction?, Marketing Science, 17 1, 1998, pp. 45-65 9] Brown, D.M., Tilton, A., and Woodside, D.M., ?The Case for On-line Communities?, The McKinsey Quarterly 1, 2002, \(http://www.mckinseyquarterly.com 10] Bughin, J.and Hagel, J., ?The Operational Performance of Virtual Communities ? Towards a Successful Business Model??, International Journal of Electronic Markets, 10 4, 2000, pp. 237-243 11] Bughin, J. and Zeisser, M., ?The marketing Scale Effectiveness of Virtual Communities?, International Journal of Electronic Markets, 11, 4, 2001, pp.258-262 12] Coleman, J., ?Social Capital in the Creation of Human Capital?, American Journal of Sociology, 94, 1988, pp. 95120 13] Cook, K., ?Two Approaches to Social Structure Exchange Theory and Network Analysis?, Annual Review of Sociology, 18, 1992, pp. 109-127 14] Cothrel, J., and Williams, R.L., ?On-line Communities Helping them Form and Grow?, Journal of Knowledge Management, 3, 1, 1999, pp. 54-60 15] De Valck, K., Langerak, F., Verhoef, P.C. and Verlegh P.W.J., ?Satisfaction with Virtual Communities of Interest Effect on Members? Visit Frequency?, British Journal of Management, 18, 3, 2007, pp. 241-256 16] Edwards, J. and Booth, A., ?Social Participation in Urban Society?, Schenkman Publishing, Cambridge, MA 1973 17] Ellemers, N., Kortekaas, P., and Ouwerkerk, J.W Selfcategorization, Commitment to the Group, and Group Self-esteem as Related but Distinct Aspects of Social Identity?, European Journal of Social Psychology, 29 1999, pp. 371-389 18] Emerson, R.M., ?Exchange theory, Part I: A Psychological Basis for Social Exchange and Exchange Theory, Part II: Exchange Relations and Network Structures?, in: Berger, J., Zelditch, M.Jr., and Anderson B. \(Eds 38-87 19] Emerson, R.M., ?Social Exchange Theory?, Annual Review of Sociology, 2, 1976, pp. 335-361 20] Fischer, C.S., ?Networks and Places: Social Relations in the Urban Setting?, The Free Press, New York, 1977 21] Fritz, W., ?Die Untersuchung unternehmerischer Zielsysteme mit Verfahren der Faktoren- und Kausalanalyse?, in: \(Ed Proceedings: Papers of the Annual Meeting of DGOR?, 14 1985, pp. 358-365 22]  Gefen, D., Straub, D.W., and Boudreau, M.C Structural Equation Modeling and Regression: Guidelines for Research Practice", Drexel University, Working Paper 2000 23] Green, W.H., "Econometric Analysis", Prentice Hill Upper Saddle River, 2003 24] Hagel, J. and Armstrong, A., ?The Real Value of OnLine Communities?, Harvard Business Review, 74, 3 1996, pp. 134-141 25] Hauschildt, J., ?Zielsysteme?, in: Grochla, E. \(Ed Handw  rterbuch der Organisation?, 2, 2nd edition Stuttgart, 1980, pp. 2419-2430 26]  Kennedy, P., ?A Guide to Econometrics?, Blackwell Oxford, 1992 27] Kollock, P., ?The Economies on Online Cooperation Gifts and Public Goods in Cyberspace?, in: Smith, M.A and Kollock, P. \(Eds Routledge, London, 1998, pp 220-239 28] Kozinets, R.V., ?E-tribalized Marketing? The Strategic 


28] Kozinets, R.V., ?E-tribalized Marketing? The Strategic Implications of Virtual Communities of Consumption European Management Journal, 17, 3, 1999, pp. 252-264 29] Leimeister, J.M., Sidiras, P., and Krcmar, H., ?Success Factors of Virtual Communities from the Perspective of Members and Operators: an Empirical Study?, in Proceedings of the 42nd Hawaii International Conference on System Sciences - 2009 8 Proceedings of the Hawaii International Conference on System Sciences \(HICSS 37 30] Lobin, D., Rudeck, T., and Kreuels, B., ?Virtuelle Communities als strategische Option im Online-Marketing Ergebnisse einer Delphi-Studie?, in: 3. GOR ? German Online Research, N  rnberg, 1999 http://www.dgof.de/tband99/pdfs/i_p/lobin.pdf 31] March, J.G. and Sutton, R.I., ?Organizational Performance as a Dependent Variable?, Organization Science, 8, 6, 1997, pp. 698-706 32] Meyer, J.P., Stanley, D.J., Herscovitch, L., and Topolnytsky, L., ?Affective, Continuance, and Normative Commitment to the Organization: A Meta-analysis of Antecedents, Correlates, and Consequences?, Journal of Vocational Behavior, 61, 2002, pp. 20-52 33] Mittal, V., Kumar P., and Tsiros, M., ?Attribute-Level Performance, Satisfaction and Behavioral Intentions over Time?, Journal of Marketing, 32, 4, 1999, pp. 13-20 34] Neter, J., Wasserman, W., and Kutner, M.H., "Applied Linear Statistical Models: Regression, Analysis of Variance, and Experimental Design", Irwin, Boston, 1990 35] Nicolai, A. and Kieser, A., ?Trotz eklatanter Erfolglosigkeit: Die Erfolgsfaktorenforschung weiter auf Erfolgskurs?, Die Betriebswirtschaft, 62, 6, pp. 579-596 36] Okleshen, C. and Grossbart, S., ?Usenet Groups Virtual Community and Consumer Behaviors?, Advances in Consumer Research, 25, 1, 1998, pp. 276-282 37] Oliver , R.L., ?Satisfaction: A Behavioral Perspective on the Consumer?, McGrawhill Book Inc, New York 1996 38] Panten, G., ?Internet-Gesch  ftsmodell virtuelle Community?, DUV, Wiesbaden, 2005 39] Putnam, R., ?Bowling Alone: The Collapse and Revival of American Community?, Simon &amp; Schuster New York, 2000 40] Rothaermela, F.T. and Sugiyamab, S., ?Virtual Internet Communities and Commercial Success: Individual and Community-level Theory Grounded in the Atypical Case of TimeZone.com?, Journal of Management, 27, 3, 2001, pp 297-312 41] Sangwan, S. ?Virtual Community Success: a Uses and Gratifications Perspective?, Proceedings of the 38th Annual Hawaii International Conference on System Sciences \(HICSS?05 42] Short, J., Williams, E., and Christie, B., ?The Social Psychology of Telecommunications?, John Wiley and Sons, London, 1976 43] Singhal, S. and Zyda M. ?Networked Virtual Environmnets, Design and Implementation?, AddisonWesley , New York, 1999 44] Stanoevska-Slabeva, K., ?Toward a CommunityOriented Design of Internet Platforms?, International Journal of Electronic Commerce, 6, 3, 2002, pp. 71-95 45] Tajfel, H., ?Interindividual Behavior and Intergroup Behaviour?, in: \(Ed Studies in the Social Psychology of Intergroup Relations Academic Press, London, 1978, pp. 27- 60 46] Walther, J.B., ?Anticipated Ongoing Interaction versus Channel Effects on Relational Communication in Computer-mediate Interaction?, Human Communication Research, 20, 4, 1994, pp. 473-501 47] Wasko, M.M. and Faraj, S., ?Why Should I Share 


47] Wasko, M.M. and Faraj, S., ?Why Should I Share Examining Social Capital and Knowledge Contribution in Electronic Networks of Practice?, MIS Quarterly, 29, 1 2005, pp. 35-57 48] Wellman, B., Carrington, P., and Hall, A., ?Networks as personal communities?, in: Wellman, B. and Berkowitz S.D. \(Eds Cambridge University Press, New York, 1988, pp. 130184 49] Welter, F. and Smallbone, D., ?Exploring the Role of Trust in Entrepreneurial Activity?, Entrepreneurship Theory and Practice, 30, 2006, pp. 465-475 50] Williams, D., Ducheneaut, N., Xiong, L., Zhangm Y Yee, N., and Nickell, E. ?From Tree House to Barracks The Social Life of Guilds in World of Warcraft?, Games and Culture, 2006, 1, pp. 338-361 51] Williams, D., Yee, N., and Caplan, S.E., ?Who plays how much, and why? Debunking the stereotypical gamer profile?, Journal of Computer-Mediated Communication 2008, 13, 4, pp. 993-1018 52] Williams, O.E., Cothrel, J., ?Four Smart Ways to Run Online Communities?, Sloan Management Review, 41, 4 2000, pp. 81-91 53] Zapf, C., Schaal, H., ?Virtual Community IT-SecurityWorld des Weka Interest Verlages?, in: Eggers, B Hoppen, G. \(Eds Management: Erfolgsfaktoren f  r die Real Economy Wiesbaden, 2001, pp. 591-607  Proceedings of the 42nd Hawaii International Conference on System Sciences - 2009 9    Ta bl e A 1 C or re la tio n M at rix   Va ria bl es  M ea n S D   1  2  3  4  5 


5  6  7  8  9  1 0  1 1  1 2  1 3  1 4  1 5  1 6  1 7  D ep en de nt v ar ia bl es                       1 C on te nt 1 


 0 4 5 1 3 7                   2 R ev en ue 1  1 2 6 1 2 5 0 2 5                 3 L oy al ty 1  1 0 3 0 9 4 0 2 


2 1 0 00                4 G ro w th 1  1 3 1 0 9 2 0 2 3 0 10  0 56                So ci ode m og ra ph ic c ha ra ct er is tic s 


s 5 A ge y ea rs   21 7 8 7 3 9 0 01 0 22  0 1 4 0 0 8              6 G en de r i s fe m al e2   0 2 4  0 0 6 0 0 2 0 00 0 0 3 0 10    


           7 C ur re nt ly n ot w or ki ng 2  0 0 5  0 0 8 0 04 0 04 0 0 1 0 16  0 16             8 C ur re nt ly in e du ca tio n2   0 6 


6 7  0 01 0 1 9 0 08  0 03 0 6 8 0 0 7 0 3 2           9 C ur re nt ly w or ki ng 2  0 2 8  0 03 0 18  0 1 1 0 0 3 0 64  0 00 0 1 4 0 8 9   


        10 E du ca tio n ac hi ev ed 3  3 5 7 1 5 2  0 04 0 02 0 2 1 0 1 2 0 16  0 02 0 1 6 0 13  0 0 6         11 D is pe ns ab le in co m e   


  21 0 9 2 72 7  0 14  0 0 1 0 09  0 08  0 2 0 0 00 0 0 4 0 18  0 1 6 0 0 1        In te rn et u sa ge                     


  12 A ct iv e in te rn et u sa ge 1  0 0 2 0 9 6 0 2 1 0 25  0 11  0 12  0 10  0 0 4 0 05  0 0 8 0 0 5 0 0 1 0 12        13 H ou rs o nl in e h ou rs 


rs   2 6 5 3 0 3  0 04 0 12  0 1 1 0 0 3 0 40  0 0 7 0 0 7 0 4 7 0 5 3 0 07  0 1 1 0 07       14 W illi ng ne ss to p ay 1  1 8 3 0 6 3  0 03 0 10 


10  0 07  0 08  0 0 2 0 0 4 0 0 1 0 01  0 00 0 0 5 0 14  0 04 0 05      G am e sp ec ifi c va ria bl es                      15 T en 


ur e w ee ks   2 8 2 3 5 2 0 2 6 0 31  0 0 9 0 01 0 12  0 0 4 0 02 0 0 9 0 0 9 0 07  0 02 0 13  0 08  0 0 4    16 C ro ss o ve r on o ffl in e 4  0 1 5 


5 1 1 1 0 1 9 0 11  0 13  0 18  0 2 0 0 1 4 0 0 7 0 14  0 1 1 0 0 4 0 08  0 15  0 0 5 0 01 0 07    17 S at is fa ct io n1   18 7 5 1 3 16  0 18  0 00 


00 0 44  0 52  0 1 4 0 0 3 0 02 0 07  0 0 9 0 1 4 0 10  0 08  0 0 6 0 09  0 0 1 0 13   18 C om m itm en t1  0 6 2 0 8 3 0 3 1 0 13  0 37  0 39  0 0 7 


7 0 0 6 0 02 0 03  0 0 4 0 1 3 0 14  0 17  0 0 5 0 09  0 07  0 19  0 58  S ou rc e O w n ca lc ul at io n N ot e N  1 3 89 o bs er va tio ns S ig ni fic an ce le ve ls 


ls  p  0 05 S D  S ta nd ar d de vi at io n 1 5 po in t L ik er t s ca le ra ng in g fro m 2 to 2  2 du m m y va ria bl e 3 o rd in al v ar ia bl e ra ng in g fro m v oc at io na l e du ca 


tio n to P h D 4 n um be r o f c on ta ct s   Proceedings of the 42nd Hawaii International Conference on System Sciences - 2009 10 pre></body></html 


