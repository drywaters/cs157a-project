 1 Fast and Adaptive Lossless On-Board Hyperspectral Data Compression System for Space Applications Nazeeh Aranki 1 Alireza Bakhshi 2 Didier Keymeulen 1 Matthew Klimesh 1  1 Jet Propulsion Laboratory, California Institute of Technology, 4800 Oak Grove Dr Pasadena, CA 91109, USA 2 B&A Engineering Inc., 440 South Cataract Ave #8, San Dimas, CA 91773 818-354-4285 nazeeh.aranki@jpl.nasa.gov  Abstract 227Efficient on-board lossless hyperspectral data compression reduces data volume in order to meet NASA and DoD limited downlink capabilities 
12 The technique also improves signature extraction, object recognition and feature classification capabilities by providing exact reconstructed data on constr ained downlink resources. At JPL a novel, adaptive and predictive technique for lossless compression of hyperspectral da ta was recently developed This technique uses an adaptive filtering method and achieves a combination of low complexity and compression effectiveness that far exceeds state-of-the-a rt techniques currently in use. The JPL-developed \221Fast Lossless\222 algorithm requires no training data or other specific information about the nature of the spectral bands for a fixed instrument dynamic range. It is of low computational 
complexity and thus well-suited for implementation in hardware, which makes it practical for flight implementations of pushbroom instruments. A prototype of the compressor \(and decompressor\algorithm is available in software, but this implementation may not meet speed and real-time requirements of some space applications. Hardware accel eration provides performance improvements of 10x-100x vs. the software implementation about 1M samples/sec on a Pentium IV machine\This paper describes a hardware implementation of the \221Fast Lossless\222 compression algorithm on a Field Programmable Gate Array \(FPGA\e FPGA implementation targets the current state-of-the-art FP GAs \(Xilinx Virtex IV and V families\and compresses one sample every clock cycle to 
provide a fast and practical real-time solution for Space applications  T ABLE OF C ONTENTS  1  I NTRODUCTION 1  2  A DAPTIVE F ILTERING 2  3  FPGA  I MPLEMENTATION 5  4  P 
ERFORMANCE AND BENCHMARKS 6  5  S UMMARY 7  A CKNOWLEDGEMENTS 7  R EFERENCES 7  B IOGRAPHY 8     1 978-1-4244-2622-5/09 25.00 \2512009 IEEE 2 IEEEAC paper#1285 Version 6, Updated 2009:01:21 
1  I NTRODUCTION  Hyperspectral images are three-dimensional data sets, where two of the dimensions are spatial and the third is spectral. A hyperspectral image can be rega rded as a stack of individual images of the same spatial scene, with each such image representing the scene viewed in a narrow portion of the electromagnetic spectrum. These individual images are referred to as spectral bands. Hy perspectral images typically consist of hundreds of spectral bands; the voluminous amount of data comprising hyperspectral images makes them appealing candidates for data compression. An example of a hyperspectral data cube is shown in Figure 1 It was taken by the Airborne Visible and Infrared Imaging 
Spectrometer \(AVIRIS\ch uses diffraction gratings for band separation with two sets of CCD arrays, one with silicon chips to sense in the visible range and the other with Indium-Antimony \(InSb\ps for wavelengths in the NearIR to Short-Wave-IR range. AVIRIS has 224 detectors channels\n the spectral dimension, extending over a range of 0.38 to 2.50 \265m. This arrangement leads to a spectral resolution for each chip of 0 01 \265m. The spatial resolution derived from this depends on the platform height. A typical mission, mounting AVIRIS on a NASA aircraft \(ER-2 produces a spatial resolution of about 20 meters, but can improve that to five meters by flying at lower altitudes which, of course, narrows the width of the ground coverage    
 Figure 1 An example of a hyperspectral data cube  for Pearl Harbor, Hawaii taken by the AVIRIS instrument  Current NASA hyperspectral instruments either avoid compression or make use of only limited lossless image compression techniques during transmission. For example the current state-of-the-prac tice is to use the Universal Source Encoder for Space \(USES\chip USES implements the standard lossless compression proposed by the consultative committee for space data systems CCSDS\ch is based on the Rice algorithm and has 


 2 a multispectral mode, extending its operation to 3D data sets. The USES chip performance achieves limited compression effectiveness compared to other existing techniques, but has the advantage of being currently available in a radiation resist ant form. The main reasons for utilization of such devices by NASA are: the limited downlink bandwidth, the need to reduce the risk of corrupting the data-stream n eeded for accurate science processing, and the lack of a viable on-board platform to perform significant image processing and compression Future instruments with more sensors and a much larger number of spectral bands will collect enormous volumes of data that will far outstrip the current ability to transmit it back to Earth \(data rates fo r some instruments can go to several hundreds of Gbits/s\This gives rise to the need for efficient on-board hyperspectral data compression. Software solutions have limited throughput performance and are power hungry. Dedicated hardware solutions are highly desirable, taking load off the main processor while providing a power efficient solution at the same time. VLSI ASIC implementations are pow er and area efficient, but they lack flexibility for post-launch modifications and repair, they are not scalable and cannot be configured to efficiently match specific mi ssion needs and requirements FPGAs are programmable and offer a low cost and flexible solution compared to traditional Application-Specific Integrated Circuit \(ASICs Exploiting dependencies in all three dimensions of hyperspectral data sets promises substantially more effective compression than two-dimensional approaches such as applying conventional image compression to each spectral band independently. With that in mind, the JPL Fast Lossless hyperspectral compressor was developed. It is a predictive technique that us es an adaptive filtering method and achieves a combination of low complexity and compression effectiveness that far exceeds state-of-the-art techniques currently in use. It will be referred to in this paper as the \223Fast Lossless\224 algorithm The Fast Lossless algorithm ach ieves a combination of low complexity and compression effectiveness that is competitive with the best results from the literature Although we are primarily interested in application to hyperspectral imagery, the technique is also generally applicable to any sort of multispectral imagery. The algorithm described in this paper represents a particularly effective way of using adaptive filtering for predictive compression of hyperspectral images. It requires no training data or other specific information about the nature of the spectral bands for a fixed instrument dynamic range. It is of low computational complexity and well-suited for implementation in hardware. This makes it practical for flight implementations of pushbroom instruments Section 2 of this paper describes the compression algorithms and equivalent hardware implementation Section 3 describes the hardware platform. Section 4 describes the results of our initial experiments, and Section 5 summarizes our results  2  A DAPTIVE F ILTERING  Algorithm Background The Fast Lossless compressor encodes data samples one-ata-time, typically in raster scan order within a given spectral band. It uses a form of predictive compression, i.e. sample values are estimated by linear prediction, and the differences between the estimates and the actual sample values are encoded into th e compressed bitstream. Only previously encoded samples are used to predict a given sample in order that the prediction operation can be duplicated by the decoder. Estimation of sample values by linear prediction is a natural strategy for lossless compression of hyperspectral images. This is a form of predictive compression, or, more specifically, a form of differential pulse code modulation \(DPCM The Fast Lossless compressor uses the sign algorithm  which is a variation of the Least Mean Square \(LMS algorithm a wel l known l o w-com p l e xi t y  adapt i v e filtering algorithm. The sign algorithm and the LMS algorithm are members of a family of low complexity adaptive linear filtering techniques, which are used extensively in signal processing applications such as audio data compression. However they have not been well studied for image or hyperspectral data compression. A straightforward extension of the LMS algorithm to twodimensional \(2-D\images is well documented in the literature with applications to image processing and application to filtering magnetic resonance imaging \(MRI data. In a few cases researchers have been directly interested in applying the LMS algorithm to image compression. An early example describes a fixed rate, lossy predictive compression of \(2-D ages. There has been a fair amount of work on lossless predictive compression of hyperspectral images that does not involve the LMS algorithm or its relatives. In particular, the methods used by Rizzo et al. [7] have low co mplexity and yield compression effectiveness similar to that of our method. Good compression effectiveness results are also reported in the literature by Aiazzi et al but those results are obtained with methods of moderately high complexity Algorithm Description and Digital Implementation The essence of the Fast Lossl ess hyperspectral compression algorithm is adaptive linear predictive compression using the sign algorithm for filter adaptation, with local mean estimation and subtraction. We start with a brief description of the LMS algorithm and the sign algorithm. For both of these algorithms a desired signal t d is to be estimated from an input \(column\or  tk u where t is an index which increases sequentially and represents the time index in the hardware implementation. The desired signal t d is the sample value at spatial location x, y in spectral band z  referred to as Zt in Figure 4\ate 210 t d is a linear function of  tk u specifically  210 T ttktk dwu  where  tk w is the filter weight vector at index t The components of 


212 referred to as 212  3  tk u represent the sample values at spatial location x, y in spectral band z-k referred to as Zt-k Figure 4  with z 1,2 and 3, as well as the sample values at neighborhood location y-1,x-1\, \(y-1,x\, \(y,x-1 in spectral band z referred to as B3, B2, B1 in Figure 4   After an estimate 210 t d is computed \(referred to as EC in Figure 4\ate 210 t d and the desired signal t d is computed, specifically 210 ttt edd 212\212 212\212 212  is encoded in the compressed bit stream using Golomb wi t h param e t e rs t h at are powers of 2. The decompressor decodes this difference t e from the bitstream, and can compute 210 t d and   sxyz  from previously decoded samples, and therefore can reconstruct the value s\(x, y, z Further details of the algorithm can be found in   Figure 3 Block diagram of the digital implementation  that illustrates  the filter weights updates 1   sgn  tk tk tk t wwu e 002 in Figure 3 This error value is used to upda te the filter weights. For the LMS algorithm 1   tk tk tk t ww ue 265  212  For the sign algorithm illustrated in Figure 3 1   sgn  tk tk tk t ww u e 265  212  In each case \265 is a positive, scalar parameter \(the step size parameter\hat controls the trade-off between convergence speed and average steady-state error. A small \265 results in better steady state performance but slower convergence. In some variants of these algor ithms the value of \265 changes over time. The sign algorithm has the property that under certain general assumptions, the weight vectors it produces become clustered around the optimum weight vector in terms of minimizing the mean absolute estimation error. For a sufficiently small adaptati on step size parameter, the asymptotic mean absolute estim ation error can be made to be as close as desired to the minimum possibl    Figure 2 3D neighborhood prediction To overcome problems of poor combinations of convergence speed and steady-state performance, a local mean subtraction method was used, motivated by In our local mean subtraction method for each sample we compute a preliminary estimate using a fi xed, causal, linear predictor involving only samples from the same band \(purple cells in Figure 2\inary estimate of sample s\(x, y, z is denoted by   sxyz which is the local mean \(LM t in Figure 4\ple values at y-1,x-1,z\, \(y-1,x,z\, \(y,x-1,z  and y-1,x+1,z noted respectively as B3, B2, B1 and BZ in Figure 4. For our implementation we use a six-sample prediction neighborhood with three samples from the same band as the sample to be predicted, and one sample each from the three preceding bands \(b lue cells in Figure 2 samples are corrected using the local mean subtraction method so that   1 1  3  1   2  1  1   1   1 4   2   2 5   3   3 6 tk s x y z s x y z Diff s xy z sxyz Diff s xyzsxyz Diff u s xyz sxyz Diff s xyz sxyz Diff s xyz sxyz Diff 265  212 as a function of  tk u  referred to as DIFF1 the sign of the error between the estimate and the desired signal t e referred to as 002 and the step size parameter 265 referred to as s   x y z  212\212 212 212\212 212\212 212   is the corresponding input vector. The general rule is to adjust each sample in the prediction neighborhood by the preliminary estimate in the same band as the sample but at the spatial location of the sample being predicted. Since this is done as part of a predictive compression algorithm, the difference 210 ttt edd 212\212 212   


 4 B1 Z X 1 B2 Z X 1 B3 Z X 1 BZ_Previous Previous Z Z X 1 External DDR2 DRAM buffer Z X \(X+1 BZ Current Z Z+3\1 Z t Z t-1 Z t-2 Z t-3 External Fast Link Ring bus  B4 = \(y_cntr==1\ B4<<2 : B4 B1 B3 B2 SUM LM t LM t LM t B3<<2 X X X DIFF3=\(\(B3<<2 LM t  DIFF2=\(\(B2<<2 LM t  DIFF1=\(\(B1<<2 LM t  W3 W1 W2 R3=\(W3*DIFF3 R2=\(W2*DIFF2 R1=\(W1*DIFF1 DIFF4= \(\(Z t-1<<2 LM t-1  X DIFF5=\(\(Z t-2 2\ \226 LM t-2  X DIFF6=\(\(Zt-3<<2\ \226 LM t-3  X W4 W5 W6 R6=\(W6*DIFF6 R5=\(W5*DIFF5 R4=\(W4*DIFF4 BE Estimate Z X 1 The calculations are done within one  clock cycle B2-Next Z X 1 B1-Next Z X 1 B-DDR Z X 1 BZ_Next Z X1 Estimate Array Z t Shift Z continuously into DDR Buffer \(B-DDR during each Z calculation Also, Shift Z continuously into BZ_Previous Buffer during each Z calculation While processing the next Z, upload contents of B-DDR buffer, into the external DDR2 DRAM 1Before start of next Z calculation, shift/load B1_Next & B2_Next into B1 & B2 buffers 2B2 contents are shifted out and shifted into B3  at the same time 3Download the next two upper Z rows into B1_Next & B2_Next buffer while the previous Z is being processed LM t x_cntr==1\SUM<<1 : SUM LM t-3 LM t-2 LM t-1 LM t LM t EC LM t 14 B2<<2 B1<<2  EC >> 15 e if\(E<0\=0 else if \(E>\(\(2**13\\e= \(2**13-3 else NOP E E>>1 IE B2 Width requiremts DIFFx = 15 bits Wx = 17 bits Rx = 32 bits LMx = 14 bits Bx = 14 bits Bx<<2\ 14 bits LMt<<14= 28 bits EC= 30 bits e= 15 bits E= 13 bits IE= 12 bits  Figure 4  Block diagram of the digital implementation for the computation of the estimate  210 t d referred to as EC ng a six sample neighborhood with four samples from the same band as the sample to be predicted B1, B2, B3, BZ ple each from the three preceding bands Zt-1, Zt-2, Zt-3 putation of the estimate for each sample uses a local mean subtraction method involving only samples from the same band LMt, LMt-1, LMt-2, LMt-3 ate 210 t d is computed by multiplying and adding respectively the weights W1 to W6 the inputs DIFF1 to DIFF6 and is calculated within one clock cycle. The external link can be a Ring Bus that brings in the sensor data at a speed up to 800 Mbits/sec  The Fast Lossless algorithm provides outstanding compression effectiveness. JP L\222s tests with uncalibrated AVIRIS data sets demonstrate compression results of about 40% lower bit rate than state-of-the-art 2D approaches approximately 4:1 compression ratio\in Figure 5 In addition to making use of correlations in all three dimensions, the algorithm also performs well compared to more complicated 3-D algorithms such as ICER-3D  12 13   2.40 2.80 3.20 3.60 4.00 4.40 4.80 02468101214161820 data set index rate \(bits/pixel/band  2D Compression \(ICER  State of the Fast Lossless 3D Compression ICER-3D Compression gain   Figure 5 Compression performance average over 19 uncalibrated AVIRIS hyperspectral test data sets. ICER and ICER-3D are state-of-the art 2D image and 3D  hyperspectral compressors developed at JPL 


 5 3  FPGA  I MPLEMENTATION  The Fast Lossless algorithm illustrated above was implemented and integrated into a reconfigurable system for a spacecraft payload requi ring high communication throughput. The reconfigurable system takes advantage of high-density SRAM-based FPGAs to accommodate the onboard computer resulting in an efficient hardware architecture in terms of power, area, and speed Background FPGA and ASIC hardware implementations for lossless hyperspectral data compression have been proposed by other researchers. At JPL, Scalable and Embedded FPGA implementation of the ICER-3D hyperspectral data compressor, a lossless and lossy wavelet based compressor was developed. The implementation targetes the Xilinx Virtex-II Pro architecture and it takes advantage of the FPGA embedded PowerPC core and the on-chip bus architecture. Such platforms allow efficient partitioning of the algorithm into software and hardware modules to take full advantage of the available hardware resources and provide a system on a chip \(SoC\ution for the hyperspectral data compression problem. The implementation was prototyped on a Virtex II pro platform and tested with a clock of 50Mhz resulting in an end-to-end throughput of 8 Msample  Surrey Space Center developed a reconfigurable Intellectual Property \(IP Xilinx AccelDSP tool [15 Their IP core implemented a design based on an extended Rice algorithm proposed by t h e C C S DS wi t h a combination of 2-D prediction and independency coding and utilizing a pre-scanning scheme. This approach achieved better compression performance than JPEG-LS Their implementation was tested on a ZestSC2 FPGA prototyping board with a clock of 48 MHz and demonstrated a power consumption of 625mW The team lead by Bristol University proposed a universal algorithm and hardware architecture for context-based statistical lossless compression of multiple types of data using FPGA devices that support partial and dynamic reconfiguration 17 Thei r proposed com p ressi on system uses a dynamically reconfigurable modeling stage followed by statically configured probability estimation and arithmetic coding stages. Dyna mic modeling is specialized to each data type and uses a combination of context modeling, predictive coding and motion estimation depending on the data type be ing processed: 1-D general data, 2-D image data or 3-D multispectral images or video The throughput performance, of the proposed system is 100Mbits/sec on a Xilinx Virtex-4 SX35 FPGA The team lead by GSFC developed an ASIC implementation of a new CCSDS 2D Image Compression Recommendati 19 The al gori t h m adopt ed i n  t h e recommendation consists of a two-dimensional discrete wavelet transform of the image, followed by progressive bit-plane coding of the transformed data. The algorithm provides lossless compression and is suitable for both frame-based image data and scan-based sensor data, and has applications for near-Earth and deep-space missions. This hardware implementation separates the Discrete Wavelet BPE\into two ASICs. The chips are expected to process over 20 Msamples/sec at lower than 0.15 watts/Msamples/sec. The throughput rate is limited by currently available rad-hard RAM chip that would serve as the external RAM for the BPE processi  Other current hardware developments of lossless image compression algorithms are based on several lossless compression hardware devices for universal data such as files \(tapes, hard disk drives, file servers\and communication data \(LAN, WAN, wireless currently commercially availa ble. Their performance has been compared for throughputs up to 1.6Gbit/s compression  These ASIC com p ressors are the ALDC  IBM\ and th  t h at  i m pl em ent s  t h e adapt i v e lossless data compression \(ALDC\pel-Ziv 1 \(LZ1 algorithm, the t h at i m pl em ent s t h e DC LZ LZ2\algorithm and the Hi/f t h at i m pl em ent s  the Lempel-Ziv Stac \(LZS LZ1\orithm. Due to the limitations of the above devices, we have decided to investigate a new approach using FPGAs for our particular lossless hyperspectral data compression FPGA implementation \226 Architecture and Data Flow The architecture of Fast Lo ssless compression algorithm is shown in Figure 6. The implementation works on 32 frames of hyperspectral data at a time. Raw imagery data is stored as three dimensional cube \(for example X=640, Z=480 Y=32 xel of the hyperspectral cube can accommodate up to 14 bits depending on the resolution of the sensory data The current implementation ta rgets the Xilinx Virtex IV LX160 FPGA, and assumes a BIP \(Byte interleaved by Pixel\ format. The basic blocks of the implementation are LOCAL MEAN is an Accumulator and 4x16 bits Shift Register that is used to store the sum of three upper spatial pixels from the previous line and the previous spectral pixel from the previous band Shift Register is used to store and shift the last four accumulator results DIFFERENCE block consists of six identical subtract modules that are used to subtract the local mean values from the previous spatial and spectral pixels WEIGHT block is made up of six, of length Z \(number of spectral bands\by up to 14 bits FIFOs that is used to adjust the input to the multip lier. Values of weight are re-calculated for every new spectral row \(Z\On power up all the weight are initialized to a default value MULTIPLIER block includes six Virtex IV/LX160, 18x18 multiplier primitives. Multipliers are used to multiply the output of Difference block with their adjusted Weight values ESTIMATE block consists of an Accumulator and a Comparator. The Accumulato r is used to sum the multiplier values. The Estimate is adjusted and clipped depending on the accumulated result  


 6 LOSSLESS COMPRESSION ALGORITHM CURRENT Z DOUBLE BUFFER Zx1x2 FPGA UNCOMPRESSED DATA IN EXTERNAL RAM THREE UPPER Y AND PREVIOUS Z PIXEL BUFFER\(S Zx1X4 LOCAL MEAN DIFFERENCE CURRENT Z PREVIOUS y and z ROWS WEIGHT MULTIPLIER DELTA ESTIMATE ENCODE PACKER LOSSLESS COMPRESSED DATA Figure 6 Block diagram of the FPGA implementa tion of Fast Lossless Compressor  DELTA block subtracts the value of current  pixel data from the Estimate to adjust the WE IGHT and also used as an input to the ENCODER ENCODER is made up of a Comparator, of length Z number of spectral bands\ up to 14 bits FIFO, a Look Up Table and miscellaneous circuitry. Output of the Encoder is used to determine the width of data to be packed PACKER includes Virtex IV distributed RAM and multiplexers. Distributed RAM is used for Look Up Table to adjust the compressed data into the final packed data word. Compressed data is packed and outputted as 32-bits words using the using Golomb   The basic concept of the data flow for the FPGA implementation \(Fig. 6\ is as follows. Initially raw imagery data of each spectral \(Z\row is streamed one row at a time into the \223CURRENT Z DOUBLE BUFFER\224. This buffer is configured as 2Z by up to 14 bits wide shift register. Two rows of length Z are stored in \223CURRENT Z DOUBLE BUFFER\224. New data is shifted in as pixel data is compressed Three upper spatial pixels Y-1,Y and Y+1 and previous spectral pixel Z are needed to comp ress the current pixel data. For the first pixel \(x=0, y=0 values are fed through the compressor and packed without compression. Current pixel data being compressed is also shifted out in parallel to the external RAM to produce an efficient pipeline. This data is inputted back to the \223THREE UPPER Y AND PREVIOUS Z\224 internal FPGA pixel buffers for subsequent pixel processing Compression of one pixel of the data happens once every FPGA clock cycle. Compressed data is fed to the PACKER module which packs the compressed data into 32 bits data words. Each 32 bits data word may contain several pixels of data. Also, a compressed pixel may fall into two 32-bit data words boundaries, which in turn will be decoded by the decompression algorithm accordi ngly. The implementation assumes an external fast link to bring the raw data to the FPGA such as a ring bus \(of up to 800 Mbits/sec 4  P ERFORMANCE AND BENCHMARKS  Our FPGA implementation was benchmarked on the Xilinx Virtex IV LX160 device and por ted to a Xilinx prototype board \(Figure 7\ implementation has a critical path of 29.5 nsec which dictated a clock speed of 33MHz The critical path delay is a nd-to-end measurement between the uncompressed input data and the output compressed data stream as shown in Figure 6. The implementation compresses one sample every clock cycle, which results in a speed of 33MSample/sec or 33 times faster than the software implementation running on a Pentium IV machine The implementation has a rather low device utilization of the Xilinx Virtex IV LX160 as shown in the table 1 making the total power consumption of the implementation about 1.27 watts 


 7  Figure 7  FPGA Development Board   Table 1  LX160 Device Utilization  Available Used Used BUFGs 32 2 6 DSP48s 96 6 6 FIFO16s 288 1 1 External IOBs 768 79 10 OLOGICs 960 21 2 RAMB16s 288 8 2 Slices 67584 3577 5  Our FPGA implementation is easily portable to other FPGA platforms and to an ASIC implementation.  It can also be scaled for faster processing 5  S UMMARY  We presented in this paper an FPGA implementation of a novel hyperspectral data compression algorithm, the JPL adaptive Fast Lossless comp ressor. The implementation targets the Xilinx Virtex IV FPGAs and provides an acceleration of at least 33 times the software implementation, making the use of this compressor practical for satellites and planet orbiting missions with hyperspectral instruments. Future development will provide multiple implementations and options to deploy various versions of the algorithm to accommodate data from different instrument types A CKNOWLEDGEMENTS  The work described in this publication was carried out at the Jet Propulsion Laborator y, California Institute of Technology, under a contract with the National Aeronautics and Space Administration. This work was funded by Air Force Research Laboratory th rough the grant, entitled \223Fast Lossless On-Board Hypersp ectral Data Compression\224 Special thanks to Randy Odle, program manager, who also supported this research at JPL, and to Ian Ferguson for his technical support to this research R EFERENCES   W. Campbell, N. M. Short 223Remote Sensing Tutorial\224, 2004 http://www.fas.org/irp/imin t/docs/rst/Sect13/Sect13_9.html   J. Venbrux, J. Ga mbles, D. Wiseman, G. Zweigle, W. H Miller, and P.-S. Yeh, \223AVLSI Chip Set Development for Lossless Data Compression,\224 Ninth AIAA Computing in Aerospace Conference, San Diego, California, October 19\22621 1993  Lossle ss Da ta Compre ssion Re c o mme nda tion for space data system standard s vol. 121.0-B-1: CCSDS, 1997  http://public.ccsds.org   M. Klimesh, \223Low-Compl exity Lossless Compression of Hyperspectral Imagery via Adaptive Filtering,\224 The Interplanetary Network Progr ess Report, vol. 42-163, Jet Propulsion Laboratory, Pasa dena, California, pp.1\22610 November 15, 2005   A Gersho 223 A daptive filtering with binary reinforcem ent\224 IEEE Transactions on Information Theory IT-30\(2 March 1984   B Widrow, J. R. Glover, J M. McCool, J. Kaunitz, C. S Williams, R. C. Goodlin, J. R. Zeidler, R. H. Hearn, and E Dong. \223Adaptive Noise Cancelling: Principles and Applications\224 The Proceedings of the IEEE 63\(12 1716, December 1975  F  Rizzo, B. Carpentieri, G. M o tta, and J  A. S t orer. \223 L owcomplexity lossless compression of hyperspectral imagery via linear prediction\224 IEEE Signal Processing Letters 12\(2 141, February 2005  B. Aiazzi, L. Alparone, and S  Baronti 223 N ear-los s l es s  compression of 3-D optical data\224 IEEE Transactions on Geoscience and Remote Sensing 39\(11 2001  N Lin X Nie and R Unbehauen, \223Two-Dimensional LMS Adaptive Filter Incorporating a Local-Mean Estimator for Image Processing,\224 IEEE Transactions on Circuits and Systems\227II: Analog and Digital Signal Processing vol. 40, no 7, pp. 417\226428, July 1993  R.G. Gallager and D.C. Van Voorhis. \223Optimal source codes for geometrically distributed integer alphabets\224 IEEE Transactions on Information Theory IT-21 \(2 March 1975  Kiely  N Aranki M Klimesh H Xie  Hy perspectral Data Compression based on the Three Dimensional Wavelet Transform," NASA New Technology Report NPO-42835  Kiely  M Klimesh H  Xie, N. Aranki, "Context Modeler for Compression of Wavelet-Tran sformed Hyperspectral Data NASA New Technology Report NPO-43239  Kiely  M Klimesh H Xie N Aranki  ICER-3D Hyperspectral Data Compre ssion Software," NASA New Technology Report NPO-43238  N. Aranki, C. Villalpando J. Namkung, A. Kiely, M Klimesh, H. Xie, "Hyperspectral Data Compression on Reconfigurable Platforms NASA New Technology Report NPO-42834  Yu T Vladimirova X Wu M N Sweeting 223A New High-Level Reconfigurable Lossless Image Compression System for Space Applications\224, In NASA/ESA Conference on Adaptive Hardware and System s, 2008. AHS 2008. 22-25 June 2008, pp 183-190. IEEE Computer Society  J.L. Nunez-Yanez; X. Chen N. Canagarajah; R. Vitulli 223Statistical Lossless Compression of Space Imagery and General Data in a Reconfigurable Architecture\224 In NASA/ESA 


 8 Conference on Adaptive Hardware and Systems, 2008. AHS 08. 22-25 June 2008, pp 172-177. IEEE Computer Society  J L Nunez-Yanez V A Chouliaras V A 223 A configurable statistical lossless compression core based on variable order Markov modeling and arithmetic coding\224 In IEEE Transactions on Computers. Volume 54, Issue 11, Nov. 2005 pp.1345 \226 1359  Pen-Shu Yeh, P. Armbruster A. Kiely, B. Masschelein, G Moury, C. Schaefer, C. Thiebaut, \223The New CCSDS Image Compression Recommendation\224, In IEEE Aerospace Conference 2005, 5-12 March 2005 pp.4138 \226 4145. IEEE  G.W. Donohoe, D.M. Buehler K.J. Hass, W Walker, Y. PenShu, \223Field Programmable Pro cessor Array: Reconfigurable Computing for Space\224, IEEE Aerospace Conference 2007, 3-10 March 2007, pp:1 \226 6. IEEE  PS Yeh, J Venbrux, \223A High Performance Image Data Compression Technique for Space Applications\224, In NASA Earth Science Technology Conference, 2003   J.L. Nunez, S. Jones. \223 Gbit/s lossless data compression hardware\224 In IEEE Transactions on Very Large Scale Integration \(VLSI\stems, Vo lume: 11, Issue: 3, pp. 499 510, June 2003  ALDC1-40S-M, Data Sheet, IBM Corporation, IBM Microelectronics Division, New York, 1994   AHA3580 22380 Mby t es/s ALDC Data Compression Coprocessor IC\224, Advanced Hardware Architectures Inc Pullman, WA, 1997 http://www.aha.com/tech.php   AHA3211 \22340 Mby t es/s DCLZ Data Compression Coprocessor IC\224, Advanced Hardware Architectures Inc Pullman, WA, 1997 http://www.aha.com/tech.php   9630 \223300 Mby t es/s Data Compression Processor\224 Hi/fn Inc Los Gatos, CA, 1999 http://www.hifn.com  B IOGRAPHY   Nazeeh Aranki received the BSEE MSEE and Ph.D. in Electrical Engineering from the Caltech and USC Nazeeh has 25 years of experience in design and implementation of digital and FPGA based systems. Since he joined JPL in 1994, his research interests have included reconfigurable hardware, digital signal and image processing, data compression, parallel processing, evolvable hardware, and neural networks. Nazeeh developed algorithms for compression of hyperspectral data and their implementations on reconfigurable platforms. He was awarded a patent and the NASA Space Act award for his contribution in the development of an FPGA-based neuroprocessor for automotive applications in control and diagnostics. He also served as the principal investigator and task Manager on a number of NASA,  DARPA and AFRL projects related to data compression and power aware computing and communications. Nazeeh is currently a senior member of the engineering and research team of the Avionics Equipment Section at JPL  Alireza Bakhshi is technical expert in FPGA/ASIC and high speed Digital circuit design for real-time DSP application on FPGA.  In addition Alireza has twenty years of experience in embedded applications, Digital circuits and Systems design in Space Radiation Hardened, Airport systems and Commercial avionics environments. He has contributed to multiple NASA missions as lead of the digital electronics such as the Microwave Limb Sounder \(MLS\, Mars Exploration Rover \(MER\, Ocean Surface Topography Mission \(OSTM\, Mars Science Laboratory \(MSL\ flight projects and technology projects such as Ultra Long Life ULL and, Operation of FPGAs in extreme low temperatures. He is president and CEO of B&A Engineering Inc Didier Keymeulen received the BSEE MSEE and Ph.D. in Electrical Engineering and Computer Science from the Free University of Brussels, Belgium in 1994. In 1996 he joined the computer science division of the Japanese National Electrotechnical Laboratory as senior researcher. Currently he is principal member of the technical staff of JPL in the Bio-Inspired Technologies Group. At JPL, he is responsible for DoD and NASA applications on evolvable hardware for adaptive computing that leads to the development of fault-tolerant electronics and autonomous and adaptive sensor technology. He participated also as test electronics lead, to Tunable Laser Spectrum instrument on Mars Science Laboratory. He served as the chair, cochair, and program-chair of the NASA/ESA Conference on Adaptive Hardware. Didier is a member of the IEEE Matthew Klimesh received B.S.E M.S.E., and Ph.D. degrees, all in electrical engineering from the University of Michigan in Ann Arbor, in 1989, 1990, and 1995, respectively.  He spent one year as a research fellow postdoc\ at Michigan. Since 1996 he has been with the Information Processing Group at Caltech's Jet Propulsion Laboratory, working primarily on research and development of data compression algorithms for space applications.  His research interests include source coding data compression, network coding, rate-distortion theory channel coding, probability, and discrete mathematics 


  9 Italy, in 2008. In 2002 she joined the Istituto per il Rilevamento Elettromagnetico dell\222Ambiente \(IREA Institute of the Italian National Research Council \(CNR Napoli, where she currently holds a Researcher Position She was a Visiting Research in 2004 at the German Aerospace Centre \(DLR\ and in 2007 at the Rosenstiel School of Marine and Atmospheric Science, Division of Marine Geology and Geophysics, University of Miami USA\. Her research interests concern the differential SAR interferometry data processing and applications for the monitoring of surface displacements, such as those produced by subsidence, volcano activity and earthquakes   


5 M  G a e dke  M. N u s s ba um e r a n d E. T o nk in  W e b Co m p o s i tio n  Service Linking System: Supporting development, federation and evolution of service-oriented Web applications  3 rd Int. Workshop on Web-oriented Software Technology \(IWWOST 2003\, 2003 6 I T M a n a g em en t an d W e b E n gin eeri n g R e s e a r ch G r ou p  MWRG\, "WebComposition Service Linking System http://mwrg.tm.uni-karlsruhe.de/wsls 02-10-2008 7 R F i e l ding  A r c hi te ct ur al S t y l e s  an d the D e s i g n o f N e tw o r kbased Software Architectures", University of California, Irvine 2000 8 L  Ric h ar d s o n  an d S  R u by RES T f u l W e b S e r v ice s  O  Re il ly  2007 9 A  H e il and M  G a e dke  W e b Co m p o s it io n  D G S  S uppo r t ing  Web2.0 Developments With Data Grids  IEEE International Conference on Web Services \(ICWS 2008  Beijing, China, 2008   C   M  M a c K en zi e K   L a s k e y  F   M c C a b e  and R  M e t z   Reference Model for Service Oriented Architecture 1.0 http://www.oasis-open.org/committees/soa-rm   T  B e r n er s Lee Un i v er s a l R e s o u r c e  I d en t i f i e r s in W W W    http://www.ietf.org/rfc/rfc1630.txt 11-24-2007-2007  T  B e r n er s Lee M et a d at a A r c h it ec t u r e   http://www.w3.org/DesignIssues/Metadata.html 05-31-2008 13 J a p a n El e c tr o n i c s  an d I n f o r m atio n T e chno l o g y  I ndus tr ie s  Association, "Exchangeable image file format for digital still cameras: Exif Version 2.2", 2002 14 L  A ndr e s e n  D ubl i n  Co r e Me ta da ta El e m e n t S e t, V e r s io n 1.1: Reference Description http://dublincore.org/documents/dces  02-18-2008 15 H  K i l o v  F r o m s e m a ntic to O b j e cto r ie nte d D a ta Mo de l i ng    First international Conference on Systems Integration  Morristown NJ, USA, 1990, pp. 385-393 16 J  F u tr e l l e  H a r v e s ting RD F T r ipl e s    International Provenance and Annotation Workshop \(IPAW'06  Chicago, Il USA, 2006, pp. 64-72  V. T a n  P G r ot h  S   M i les  S  J i an g S. Mun r oe S T s a s ak ou  and L. Moreau, "Security Issues in a SOA-based Provenance System  International Provenance and Annotation Workshop IPAW'06  Chicago, Il, USA, 2006, pp. 203-21 18 J  G r e g o r io M. H a dl e y M. N o tt i n g h a m  an d D  O r c h ar d   URI Template http://tools.ietf.org/id/draft-gregorio-uritemplate03.txt 02-06-2008  T  B e r n er s Lee  L i n k e d Da ta   http://www.w3.org/DesignIssues/LinkedData.html 02-20-2008 20 D  Br ic kl ey and L  Mil l e r  F OA F V o cabul ar y S p e c if ic at io n 0.9 http://xmlns.com/foaf/spec/20070524.html 06-03-2008   37 s i gna ls L L C  B a c kp ac k    http://www.backpackit.com 0219-2008  A m a z on W e b Servi c e s  L L C   A m a zon Si m p le St ora ge Service Developer Guide http://docs.amazonwebservices.com/AmazonS3/2006-03-01 0603-2008  F  Sha n ah an  A m a z on  c om  M a s h u p s   B i rm in gha m  UK  W r o x  Press Ltd., 2007 24 H  K r aw c z y k M  Be l l a r e an d R Ca ne tt i H MA C K e y e dHashing for Message Authentication http://www.ietf.org/rfc/rfc2104.txt 06-03-2008 25 H  L o ckhar t  S  A n de r s e n S  J  B o hr e n Y  S v e r dl o v  M  Hondo, H. Maruyama, A. Nadalin, N. Nagaratnam, T. Boubez, K S. Morrison, C. Kaler, A. Nanda, D. Schmidt, D. Walters, H Wilson, L. Burch, D. Earl, S. Baja, and H. Prafullchandra, "Web Services Federation Language \(WS-Federation\", 2006 26 M  G a e dke  J  Me i n e c ke an d M N u s s b au m e r    A  Mo de l i ng  Approach to Federated Identity and Access Management  14 th  International World Wide Web Conference \(WWW'05  Chiba Japan, 2005, pp. 1156-1157 27 J   Me ine c ke a n d M  G a e dke  M o de l i ng F e de r a tio ns o f W e b Applications with WAM  Third Latin American Web Congress LA-WEB 2005  Buenos Aires, Argentina, 2005, pp. 23-31  J  M e i n eck e  M  N u s s b au m e r and  M  G a ed k e   B ui ldi n g Blocks for Identity Federations  Fifth International Conference on Web Engineering \(ICWE 2005  Sydney, Australia, 2005, pp. 203208 29 I T M anag e m e n t an d W e b E n g i ne e r ing Re se ar ch G r o up MWRG\, "Home of the IT-Management and Web Engineering Research Group http://mwrg.tm.uni-karlsruhe.de 03-06-2008  w e b e n g i n eeri n g org T h e W e b E n gi n e eri n g C o m m u n i t y Si t e  WebEngineering.org http://www.webengineering.org 06-032008  I n t e rn a t i o n a l Soc i et y for Web E ngi n eeri n g e V  I S W E    International Societe for Web Engineering e.V http://www.isweev.de 06-03-2008  A m a z on W e b Servi c e s  L L C   A m a zon Si m p leDB Deve lop e r Guide", 2008 33 P  C a str o  P r o je ct A s to r i a T h e  A r chite ct ur e Jo ur nal  pp. 1217, 2007 34  M N u s s ba um e r  E ntw i c k l ung  u n d E v o l utio n diensteorientierter Anwendungen im Web Engineering Universität Karlsruhe \(TH\, Karlsruhe, 2007 35  R. G e am bas u  C  C h e u ng A  Mo s h c h u k  S  D  G r ibbl e  a n d H. M. Levy, "Organizing and Sharing Distributed Personal WebService Data  15 th International World Wide Web Conference WWW 2008  Bejing, China, 2008, pp. 755-754  G oogl e I n c   Op en Soc i a l   http://code.google.com/apis/opensocial 06-03-2008  G oogl e I n c   Goog le Da t a A P I s    http://code.google.com/apis/gdata 02-17-2008  Proceedings of the 42nd Hawaii International Conference on System Sciences - 2009 10 


transform spectrometry,\224 A pplied Optics  vol 46 no 21 pp 4774\2264779 2007 B IOGRAPHY Dmitriy Bekker r eceived his M.S and B.S degrees in Computer Engineering from Rochester Institute of Technology in 2007 He has been at JPL as a summer student in 2006 and now is a full time employee since February 2008 in the Instrument Software and Science Data Systems section His areas of interest include FPGAs embedded systems digital signal processing and system architecture He has co-op and work experience at Draper Laboratory NASA Dryden Flight Research Center Syracuse Research Corporation and Brookhaven National Laboratory He is a member of IEEE Dr Jean-Francois Blavier 002 rst joined the JPL-MkIV Team in August 1985 as a contractor from Ball Aerospace He participated in the MkIV campaigns in McMurdo Antarctica ground-based and from Punta Arenas Chile NASA DC8 In late 1987 he started graduate work with Profs Delbouille and Dubois at the University of Li 036 ege Belgium His research tasks included installing the Fourier transform spectrometers at the International Scienti\002c Station of the Jungfraujoch Switzerland for atmospheric measurements and at the Institute of Astrophysics in Li 036 ege for laboratory measurements He was hired by JPL in August 1990 as MkIV cognizant engineer and participated in all the MkIV campaigns since then one DC-8 campaign 20 balloon campaigns Dr J.-F Blavier obtained his Ph.D in Physics from the University of Li 036 ege in July 1998 Dr Geoffrey Toon  after receiving his B.A degree in Physics at Oxford University in 1978 obtained a D Phil in Atmospheric Physics in 1984 also from Oxford University He then came to JPL as an NRC post-doctoral Researcher and worked on the assembly and testing of the JPL MkIV interferometer and on analysis of ATMOS Spacelab-3 data Since becoming a JPL employee in 1986 he has worked almost exclusively on the MkIV project becoming the Principal Investigator in 1988 This work has earned seven NASA Achievement Awards and has resulted in more than 100 peer-reviewed journal articles Dr Christian Servais 002 rst joined the Institute of Astrophysics at the University of Li 036 ege in 1982 designing a digital 002lter for a prototype Fourier transform infrared spectrometer installed at the high altitude international scienti\002c station of the Jungfraujoch Switzerland In April 1984 he moved to the chemistry department of the University of Li 036 ege and developed time-of-\003ight and Photoion-Photoelectron coincidence experiments for his PhD thesis that he obtained in September 1994 He then returned to the Institute of Astrophysics were he has been since overseeing all experimental developments at the Laboratory of Atmospheric and Solar Physics located at the Jungfraujoch He is now specially involved in the design of improved Fourier transform spectrometer acquisition chains and remotely controlled hardware adapted to harsh environmental conditions 11 


departments on average\ignificant differences were found regarding the age of the applications. The variables for the coverage of the products and processes were not included in this test because the overlap was computed using these two variables implying that there is a significant relation between the respective variables\his lends some support to proposition P2.4 stating that involvement of more users leads to greater overlap of applications. The proposition that older applications also exhibit a higher degree of overlap was not supported \(P1.4  A.2. Results from analyzing impacts of AA complexity  Impacts of interdependency-related AA complexity A Kruskal-Wallis test \(Table 4\ealed a statistically significant difference in operations cost as well as maintenance cost across the three different interdependency-groups of applications. The more interdependent group \(i.e. applications with 3-7 or with 8 or more interfaces\igher median of operations \(Md=119,000 and 363,000 EUR respectively\ and maintenance costs \(Md=326,000 and 506,000 EUR respectively\ than the less interdependent group \(fewer than 3 interfaces applications \(Md=52,000 EUR operations costs and 64,000 EUR maintenance costs\. This supports the proposition \(P3.1\ that more interdependent applications also incur higher IT \(operations and maintenance\ts  Impacts of diversity-related AA complexity   Regarding OS-related diversity, a Mann-Whitney U test \(Table 5\howed no significant difference between the operations costs of more \(Md=93,890 n=105\d less diverse applications \(Md=131,540 n=27\09.5, z=-1.174, p=.24. The same holds for maintenance costs \(Md=166,400; n=121 vs Md=116,900; n =31\782, z=-.43; p=.668 To measure DBMS-related diversity, a MannWhitney U test was conducted \(Table 5\d revealed no significance difference in operations costs of more Md=129,985; n=85\d less diverse applications Md=154,777; n=16\5, z=-.237, p=.813. The same holds for maintenance costs \(Md=210,500 n=98 vs. Md=245,700; n=19\36, z=-.704 p=.481. Hence, the proposition \(P3.2\ that diversityrelated AA complexity leads to higher IT costs is not supported  Impacts of deviation-related AA complexity   Regarding deviation from the standard OS, a MannWhitney U test \(Table 6\revealed no significant difference between the maintenance costs and operations costs for standard-compliant \(Md=83,581 n=94 for operations cost and Md=148,300; n=113 for maintenance cost\nd non-compliant applications Md=180,147; n=38 for operations cost and Md=166,400; n=39 for maintenance cost z=-1.921, p=.055 for operations cost and U=2116 z=-.371, p=.711 for maintenance cost Concerning deviation from the standard DBMS, a Mann-Whitney U test \(Table 6\ealed a significant difference between maintenance costs for standardcompliant \(Md=373,100; n=59\d non-standardcompliant applications \(Md=170,200; n=58 U=1303, z=-2.231, p=.026. It is remarkable that the non-compliant applications had lower maintenance costs than the compliant applications. The difference between operations costs for compliant Md=109,978; n=51\d non-compliant applications Md=180,147; n=50\s not significant, U=1196.5 z=-.533, p=.594 Thus, the proposition \(P3.3\at application that deviate from technology standards incur higher IT costs is not supported. In contrast, for DBMSstandard deviation, we observed significantly lower maintenance cost for non-compliant than for compliant applications  Impacts of overlap/redundancy-related AA complexity a Kruskal-Wallis test \(Table 7\ showed significant differences in operations costs across the applications with a low \(less than 34 overlaps Md=90,442; n=37\edium \(35-79 overlaps Md=55,770; n=56\ and high level of overlap/redundancy \(more than 80 overlaps Md=129,985; n=61 6.862, p=.032. It is striking to see that the applications with medium overlaps have a lower median operations cost than those with a low or high-level of overlap, implying a non-linear U-shape relation between overlap and operations cost. Interestingly, the same holds true for maintenance cost. Applications with a low degree of overlap exhibited a median maintenance cost of 96,600 \(n=59\, those with a medium level of overlap incurred a median of 81,300 \(n=58\d highly overlapping applications a median of 248,700 \(n=67 9.791, p=.007. Hence, the proposition \(P3.4\at applications with a greater degree of overlap also exhibit higher IT costs is not supported  Proceedings of the 42nd Hawaii International Conference on System Sciences - 2009 12 


Interdependency Number of interfaces \(gp3_y4_sum_intf  2 22 2 22 Df 047 000 000 016 000 000 Asymp. Sig 6.134 22.298 20.875 8.331 17.018 18.917 N Median 46 45 43 46 27 37 41 41 41 41 36 38 2 intf 8 intf 1.0000 2.2000 1.0000 1.0000 52.3020 64.4000 2.0000 7.8000 4.0000 2.0000 363.9885 506.3500 2 intf 8 intf Mean rank 55.89 47.03 44.13 56.13 33.67 37.77 2 intf 73.46 83.40 76.61 76.21 60.89 68.89 8 intf 40 39 33 40 30 34 3 7 intf 1.0000 3.2000 2.0000 1.0000 119.3940 326.2000 3 7 intf 63.63 59.97 56.50 60.54 42.33 58.22 3 7 intf  Business requirements Causes of complexity Impacts of complexity  No. of IB products covered y24_#_IB_ bankprod Application age y14_age No. of user departments y19_#_ user_dpts No. of IB process covered \(y26_ IB_bankproc Operations cost \(y36_ ops_cost Maintenance cost \(y37_ Maint_cost 2  Table 4: Results of Kruskal-Wallis test for causes and impacts of interdependency-related AA complexity    Diversity Number of OS/DBMS used by an application Operating systems \(gp2_y7a_OS DBMS \(gp2_y8a_DBMS 2,726.500 18,302.500 1.503 133 1,087.500 1,318.500 1.362 173 3,308.000 902 367 543.000 7,446.000 3.925 000 2,642.000 2,536.000 3,202.000 855 392 757.500 7,198.500 2.187 029 2,884.500 18,460.500 965 335 1,216.500 1,447.500 583 560 1,209.500 6,774.500 1,174 240 654.500 790.500 237 813 1,782.000 9,163.000 430 668 836.000 5,687.000 704 481 Wilcoxon W Z Asymp. Sig N Median Mean rank Mann-Whitney U Wilcoxon W Z Asymp. Sig Mann-Whitney U 21 1.0000 125 1.0000 75.30 62.79 20 8.0500 117 2.2000 63.64 100.35 19 3.0000 113 1.0000 63.70 83.13 21 1.0000 125 1.0000 74.27 68.93 16 154.7770 85 129.9850 51.30 49.41 19 245.7000 98 210.5000 58.03 64.00 N Median 1 DBMS 2 DBMS 1 DBMS 2 DBMS Mean rank 1 DBMS 2 DBMS Data not shown as no significance found  Business requirements Causes of complexity Impacts of complexity  No. of IB products covered \(y24_#_ IB_bankprod Application age y14_age No. of user departments y19_#_user_dpts No. of IB process covered \(y26_#_ IB_bankproc Operations cost \(y36_ ops_cost Maintenance cost \(y37_ Maint_cost  Table 5: Results of Mann-Whitney test for causes and impacts of diversity-related AA complexity  Proceedings of the 42nd Hawaii International Conference on System Sciences - 2009 13 


 Deviation degree of deviation from standard OS/DBMS Operating systems \(gp2_y7b_OS_Dev DBMS \(gp2_y8b_DBMS_Dev 2,780.000 16,146.000 3.681 000 163 49 1.0000 2.0000 99.06 131.27 2,611.000 5,312.000 227 820 73 1.0000 73 1.0000 72.77 74.23 3,970.500 2.107 035 151 47 3.2000 2.2000 104.18 84.48 2,102.000 4,587.000 1.074 283 70 2.2000 67 3.5000 72.63 2,842.500 65.53 2,902.000 4,030.000 1.509 131 143 47 2.0000 1.0000 98.71 85.74 1,551.500 3,829.500 3.041 002 67 1.0000 65 3.0000 76.13 57.16 3,103.500 16,469.500 2.698 007 163 49 1.0000 2.0000 101.04 124.66 2,610.000 5,311.000 232 816 73 1.0000 73 1.0000 72.75 74.25 1,404.000 5,869.000 1.921 055 94 38 83.5815 180.1470 62.44 76.55 1,196.500 2,522.500 533 594 50 180.1470 51 109.9780 49.46 52.57 2,116.000 8,557.000 371 711 113 39 148.3000 166.4000 75.73 78.74 1,303.000 3,014.000 2.231 026 58 170.2000 59 373.1000 65.92 51.97  Wilcoxon W Z Asymp. Sig N Median No deviation \(1.0 Deviation 1.1 No deviation \(1.0 Deviation 1.1 Mean rank Mann-Whitney U No deviation \(1.0 Deviation 1.1 Wilcoxon W Z Asymp. Sig N Median No deviation \(1.0 Deviation \(>1.0 No deviation \(1.0 Deviation \(>1.0 Mean rank Mann-Whitney U No deviation \(1.0 Deviation \(>1.0  Business requirements Causes of complexity Impacts of complexity  No. of IB products covered \(y24_#_ IB_bankprod Application age y14_age No. of user departments y19_#_user_dpts No. of IB process covered \(y26_#_ IB_bankproc Operations cost \(y36_ ops_cost Maintenance cost \(y37_ Maint_cost  Table 6: Results of Mann-Whitney test for cause s and impacts of deviation-related AA complexity  Overlap/redundancy \(gp3_overlap_count 22 22 Df 216 001 032 007 Asymp. Sig 3.066 13.139 6.862 9.791 2 N Median 90 81 37 59 79 78 61 67 34 80 2.2000 1.0000 90.4420 96.6000 2.6000 2.5000 129.9850 248.7000 34 80 Mean rank 129.29 113.80 82.76 87.25 34 137.18 144.50 85.66 108.10 80 86 85 56 58 35 79 2.2000 1.0000 55.7705 81.3000 35 79 118.22 110.61 65.14 79.82 35 79  Not applicable Not applicable Business requirements Causes of complexity Impacts of complexity  No. of IB products covered \(y24_ _IB_bankprod Application age y14_age No. of user departments y19_#_ user_dpts No. of IB process covered \(y26_ _IB_bankproc Operations cost \(y36_ ops_cost Maintenance cost \(y37_ Maint_cost  Table 7: Results of Kruskal-Wallis test for causes and impacts of overlap-/redundancy-related AA complexity Proceedings of the 42nd Hawaii International Conference on System Sciences - 2009 14 


  15 R EFERENCES    http://www.w3.org/XML/Schema   eb Orchestration with BPEL\224 http://www.idealliance.org/pa pers/dx_xml03 papers/0406-01/04-06-01.html  Hi bernat e hom e page www.hibernate.org   Al l a rd, Dan and Hut c herson, Joe, \223C om m uni cat i ons Across Complex Space Networks\224, IEEE Aerospace Conference, March 1-8, 2008  W e b Servi ce Defi ni t i on Language http://www.w3.org/TR/wsdl   B a uer, C h ri st i a n and Ki ng Javi n Java Persi s t e nce for Hibernate, New York: Manning Publications, 2007 7] \223Software Agents An Overview\224 http://www.sce.carleton.ca/netm anage/docs/AgentsOverview ao.html  e thodology.org  http://www.riaspot.com artic les/entry/What-is-Ajax  http://www.json.org 11 h ttp to m cat.ap ach e.o r g   12] http://java.sun com/products/servlet  http://www.w3.org/Sty le/CSS    B IOGRAPHY  Dan Allard has worked as a software engineer at the Jet Propulsion Laboratory for the past 17 years.   He currently leads the development of core JPL accountability systems applications and infrastructure Other recent work includes the development of a message-based ground data system for the Mars Science Laboratory as well as research and development of ontologybased distributed communications     Dr. Charles D \(Chad\ards, Jr received his A.B degree in Physics from Princeton University in 1979 and his Ph.D. in Physics from the Calif ornia Institute of Technology in 1984.  Since then he has worked at NASA\222s Jet Propulsion Laboratory, where he currently serves as Manager of the Mars Network Office and as Chief Telecommunications Engineer for the Mars Exploration Program, leading the development of a dedicated orbiting infrastructure at Mars providing essential telecommunications and navi gation capabilities in support of Mars exploration.  Prior to that he managed the Telecommunications and Mission Operations Technology Office, overseeing a broad program of research and technology development in support of NASA\222s unique capabilities in deep space communications and mission operations.  Earlier in his career, Dr. Edwards worked in the Tracking Systems and Applications section at JPL where he carried out research on novel new radio tracking techniques in support of deep space navigation, planetary science, and radio astronomy  


  16  


Thank you Questions 


 18  Astronautical Congress Valencia, 2006 27  Bu reau  In tern atio n a l d e s Po ids et Mesures. \(2 008  August\SI Base Units. [On http://www.bipm.org/en/si/base_units   B IOGRAPHY  Author, Karl Strauss, has been employed by the Jet Propulsion Laboratory for over 22 years.  He has been in the Avionics Section from day One.  He is considered JPL\222s memory technology expert with projects ranging from hand-woven core memory \(for another employer\o high capacity solid state designs.  He managed the development of NASA\222s first Solid State Recorder, a DRAM-based 2 Gb design currently in use by the Cassini mission to Satu rn and the Chandra X-Ray observatory in Earth Orbit.  Karl was the founder, and seven-time chair of the IEEE NonVolatile Memory Technology Symposium, NVMTS, deciding that the various symposia conducted until then were too focused on one technology.  Karl is a Senior IEEE member and is active in the Nuclear and Plasma Scie nce Society, the Electron Device Society and the Aerospace Electronic Systems Society Karl is also an active member of SAE Karl thanks his wonderful wife of 28 years, Janet, for raising a spectacular family: three sons, Justin, Jeremy Jonathan.  Karl\222s passion is trains and is developing a model railroad based upon a four-day rail journey across Australia\222s Northern Outback   


 19 Bollobás, B. 2001. Random Graphs. Cambridge University Press; 2nd edition. 500pp  Cawley, G. C., B. L. C. Talbot, G. J. Janacek, and M. W Peck. 2006. Sparse Bayesian Ke rnel Survival Analysis for Modeling the Growth Domain of Microbial Pathogens  Chiang C. L. 1960. A stochastic study of life tables and its applications: I. Probability distribution of the biometric functions. Biometrics, 16:618-635  Cox,  D. R. 1972. Regression models and life tables J. R Stat. Soc. Ser. B 34:184-220  Cox, D. R. 1975.   Partial likelihood Biometrika 62:269276  Cox, D. R. & D. Oakes. 1984 Analysis of Survival Data  Chapman & Hall. London  Cressie, N. A. 1993 Statistics for Spatial Data John Wiley Sons. 900pp  Duchesne, T. 2005. Regression models for reliability given the usage accumulation history. In "Modern Statistical and Mathematical Methods in Reliability". Edited by A. Wilson N. Limnios, S. Kelly-McNulty Y. Armijo. pp.29-40. World Scientific, New Jersey  Eleuteri, A., R. Tagliaferri, L. Milano, G. Sansone, D D'Agostino, S. De Placido,  M. Laurentiis. 2003.  Survival analysis and neural networks. Proceedings of the International Joint Conference on Neural Networks, Vol. 4 20-24 July 2003 Page\(s\:2631 - 2636  Ellison, E., L. Linger, and M Longstaff. 1997.  Survivable Network Systems: An Emerging Discipline, Carnegie Mellon, SEI, Technical Report CMU/SEI-97-TR-013, 1997  Fleming, T. R. & D. P. Harrington. 1991. Counting process and survival analysis. John Wiley & Sons. 429pp  Graver, J. and M. Sobel 2005. You may rely on the Reliability Polynomial for much more than you might think Communications in Statistics: Theory and Methods  34\(6\1411-1422  Graves, T. and M. Hamada. 2005. Bayesian methods for assessing system reliability: models and computation. In Modern Statistical and Mathematical Methods in Reliability". Edited by A. Wilson, et al. pp.41-53  Grimmett, G. 2006 The Random-Cluster Model Springer  Grimmett, G. 1999 Percolation Springer  Hougaard, P. 2000. Analysis of Multivariate Survival Data Springer. 560pp  Ibrahim, J. G., M. H. Chen and D. Sinha. 2005. Bayesian Survival Analysis.  Springer. 481pp  Jin Z. 2005. Non-proportional semi-parametric regression models for censored data. In "Modern Statistical and Mathematical Methods in Reliability". Edited by A. Wilson N. Limnios, S. Kelly-McNulty, Y. Armijo. pp.279-292 World Scientific  Kalbfleisch, J. D. & R. L. Prentice. 1980 The Statistical Analysis of Failure Time Data John Wiley & Sons.  New York. 1980  Kalbfleisch, J. D. &  R. L. Prentice, 2002. The Statistical Analysis of Failure Time Data.  Wiley-InterScience, 2nd ed 462pp  Lisboa, P. J. G. and H. Wong. 2001. Are neural networks best used to help logistic regression? Proceedings of International Joint Conference on Neural Networks, IJCNN 01. Volume 4, 15-19,  July 2001. Page\(s\:2472 - 2477 vol.4  Kauffman, R. J. and B. Wang. 2002. Duration in the Digital Economy. Proceedings of th e 36th Hawaii International Conference on System Sciences \(HICSS03\ Jan 2003  Kaplan, E. L. & P.  Meier.  1958.  Nonparametric estimation from incomplete observations J. Amer. Statist. Assoc  53:457-481  Klein, J. P. and P. K. Goel 1992. Survival Analysis: State of the Art.  Kluwer Academic Publishes. 450pp  Klein, J. P. and  M. L Moeschberger. 20 03. Survival analysis techniques for ce nsored and truncated data Springer  Krings, A. and Z. S. Ma. 2006.  "Fault-Models in Wireless Communication: Towards Survivable Ad Hoc Networks MILCOM 2006, Military Communications Conference, 2325 October, 7 pages, 2006  Krings, A. W. 2008.  Survivable Systems.  in Information Assurance: Dependability and Security in Networked Systems Yi Qian, James Joshi, David Tipper, and Prashant Krishnamurthy, Morgan Kaufmann Publishers. \(in press  Lawless, J. F. 1982. Statistical models and methods for lifetime data.  John Wiley & Sons. 579pp  Lawless, J. F. 2003. Statistical models and methods for lifetime data.  John Wiley & Sons. 2nd ed. 630pp  Li, M. and P. Vitanyi. 1997. Introduction to  Kolmogorov Complexity and Its Applications. 2nd ed, Springer  Ma, Z. S. 1997.  Survival analysis and demography of Russian wheat aphid populations.  Ph.D dissertation, 307pp University of Idaho Moscow, Idaho, USA 


 20 Ma, Z. S., and E. J. Bechinski. 2008.  Developmental and Phenological Modeling of Russian Wheat Aphid Annals of Entomological Soc. Am In press  Ma, Z. S. and A. W. Krings. 2008a. The Competing Risks Analysis Approach to Reliability Survivability, and Prognostics and Health Management.  The 2008 IEEEAIAA AeroSpace Conference. BigSky, Montana, March 18, 2008. \(In Press, in the same volume  Ma, Z. S. and A. W. Krings 2008b. Multivariate Survival Analysis \(I\e Shared Frailty Approaches to Reliability and Dependence Modeling. The 2008 IEEE-AIAA AeroSpace Conference. BigSky Montana, March 1-8, 2008 In Press, in the same volume  Ma, Z. S. and A. W. Krings. 2008c. Multivariate Survival Analysis \(II\ Multi-State Models in Biomedicine and Engineering Reliability. 2008 IEEE International Conference on Biomedical Engineering and Informatics BMEI 2008\27th-30th, 2008 Accepted   Mani, R., J. Drew, A. Betz, P. Datta. 1999. Statistics and Data Mining Techniques for Lifetime Value Modeling ACM Conf. on Knowledge Discovery and Data Mining  Mazzuchi, T. A., R Soyer., and R. V Spring. 1989. The proportional hazards model in reliability. IEEE Proceedings of Annual Reliability and Maintainability Symposium pp.252-256  Meeker, W. Q. and L. A. Escobar. 1998. Statistical Methods for Reliability Data. Wiley-Interscience  Munson, J. C. 2003. Software Engineering Measurement Auerbach Publications  Nelson, W. 1969. Hazard plotting for incomplete failure data J. Qual. Tech 1:27-52  Nakagawa, T. 2006.  Shock and Damage Models in Reliability Theory. Springer  Osborn, B. 2005. Leveraging remote diagnostics data for predictive maintenance.   In "Modern Statistical and Mathematical Methods in Reliability". Edited by A. Wilson N. Limnios, S. Kelly-McNulty, Y. Armijo. pp. 353-363  Pena, E. A. and E. H. Slate. 2005. Dynamic modeling in reliability and survival analysis. In "Modern Statistical and Mathematical Methods in Reliability". Edited by A. Wilson N. Limnios, S. Kelly-McNulty, Y. Armijo. pp.55-71  Reineke, D. M., E. A. Pohl, and W. P. Murdock. 1998 Survival analysis and maintenance policies for a series system, with highly censore d data.  1998 Proceedings Annual Reliability and Maintainability Symposium. pp 182-188  Schabenberger, O. and C. A. Gotway. 2005. Statistical Methods for Spatial Data Analysis.  Chapman & Hall/CRC  Severini, T. A. 2000. Likelihood methods in statistics Oxford University Press  Shooman, M. L. 2002. Reliability of Computer Systems and Networks: Fault Tolerance, Analysis and Design. John Wiley and Sons. 551pp  Stillman, R. H. and M. S. Mack isack, B. Sharp, and C. Lee 1995. Case studies in survival analysis of overhead line components. IEE Conferen ce of the Reliability and Distribution Equipment. March 29-31, 1995. Conference Publication No. 406. pp210-215  Therneau, T. and P. Grambsch. 2000 Modeling Survival Data: Extending the Cox Model Springer  Wilson, A.  N. Limnios, S Kelly-McNulty, Y. Armijo 2005. Modern Statistical and Mathematical Methods in Reliability. World Scientific, New Jersey  Xie, M. 1991. Software Reliability Modeling. World Scientific Press    B IOGRAPHY   Zhanshan \(Sam\ Ma holds a Ph.D. in Entomology and is a Ph.D. candidate in Computer Science at the University of Idaho. He has published approximately 30 journal and 30 conference papers, mainly in the former field.  Prior to his recent return to academia, he worked as senior network/software engineers in software industry.  His current research interests include reliability and survivability of wireless sensor networks, fault tolerance survival analysis, evolutionary game theory, evolutionary computation and bioinformatics  Axel W. Krings is a professor of Computer Science at the University of Idaho.  He received his Ph.D. \(1993\ and M.S 1991\ degrees in Computer Science from the University of Nebraska - Lincoln, and his M.S. \(1982\ in Electrical Engineering from the FH-Aachen, Germany.  Dr. Krings has published extensively in the area of Computer Network Survivability, Security, Fault-Tolerance and Realtime Scheduling. In 2004/2005 he was a visiting professor at the Institut d'Informatique et Mathématiques Appliquées de Grenoble, at the Institut National Polytechnique de Grenoble, France.  His work has been funded by DoE/INL DoT/NIATT, DoD/OST and NIST 


