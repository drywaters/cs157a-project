   Abstract 227The open source paradigm is giving rise to new methodologies, competences and processes that need to be investigated both from the technical and the organizational point of view. Many organizations are investigating the possibility to adopt open source software or migrate their systems to open frameworks also in critical environments. In this paper, we shows how the assurance has been elevated as a primary design requirement for or ganizations wishing to adopt open source products, and we describe the experience of a big telecommunication player in the process of implementing an assurance evaluation platform 
 Index Terms 227Assurance, Security, Open Source, Telecommunication I  I NTRODUCTION  Software Assurance \(SwA a complex concept that involves different stages of a software development process and may be defined differently depending on its focus, as for instance software quality [1,2 rity, o r d ep en d ab ility. In the past, assurance has been seen as the activity of reducing the information risk, improving, at the same time the quality of data given to management and decision makers. The concept of assurance is then associated to different 
tasks, such as risk assessment, information systems security, internal audit, and customer satisfaction surveys, all concentrated on specific aspect s of the workflow they are applied to In Computer Science, the term assurance is referred to all activities necessary to provide enough confidence that a software product will satisfy its users\222 functional and nonfunctional requirements. In this paper, we focus on security and dependability \(S&D\rance, intended as the activity aimed at increasing the level of confidence that a software product is operating as intended and is free of faults. In a traditional, lifecycle-based software development process see Fig. 1\assurance includes a number of tasks to be carried out by developers and testers along the software life 
cycle. A number of standards have been defined to specify which security requirements a product should satisfy, while assurance standards specify how to collect and provide the evidence that it does [3 Recalling that assurance activities are process-oriented, Fig 1 shows the security activities mapped on a traditional waterfall-based development process. They cover all the phases of the process, starting from the Requirements and Use Cases definition, where specifi c tests analyze the fulfilment of security requirements and the presence of possibl and l ooki ng for i n t e ract i ons bet w een a system and one or more actors, where the results of each interaction are harmful to the system. Then, a general risk 
analysis is fulfilled in parallel with the Architecture and Design phase. Furthermore, the set of test cases is enriched with risk-based security tests created not directly by the product properties and functi onality, but modelling possible security threats and attacks, probing the application behaviour in such critical situations Following the workflow, during the Code phase, specific tools are exploited to calculate the sets of product metrics that are able to assess code quality, dependability, performance, and the like. Finally, the results of the implemented test cases are examined throw an exhaustive Penetration 
Testing  is evaluated using a penetration testing as part of the final acceptance test. In this context, security consultants typically test security requirements of the product by simulating an attack by a malicious user; such tests involve an active analysis of the system for any potential vulnerability that could result from incomplete or wrong system configurations Of course, cooperative and agile development processes like the ones used for open source, do not lend themselves to all assurance tasks showed in Fig. 1. In this scenario, the definition of assurance mechanisms for open source solutions is a difficult task. Some approaches in the past have been provided in the context of big open source projects 
such as Linux, where a patch-based approach \(Section 2 Claudio A. Ardagna 1 Massimo Banzi 2 Ernesto Damiani 1 Member, IEEE Fulvio Frati 1 and Nabil El Ioini 3   1 Dipartimento di Tecnologie dell\222Informazione \(DTI\versit\340 degli Studi di Milano Via Bramante 65, Crema \(CR\, 26013, Italy e-mail : {claudio.ardagna,ernesto.damiani,fulvio.frati}@unimi.it 2  Telecom Italia - Technology Operations Innovation Archit ecture and Quality dep Via Zambra, 1 \226 38100 Trento Italy 
e-mail : massimo.banzi@telecomitalia.it 3  Free University of Bozen-Bolzano Largo Adolph Kolping, 3 \226 39100 Bolzano \226 Italy e-mail : nabil.elioini@unibz.it An Assurance Model for OSS Adoption in Next-Generation Telco Environments    Fig. 1 Assurance tasks in a traditional lifecycle-based development process 2009 Third IEEE International Conference on Digital Ecosystems and Techn\ologies \(IEEE DEST 2009 658 


   has been adopted for the defi nition of assurance tasks In this paper, however, we focus on the problem of defining assurance tasks for open source products in mission-critical context, such as telecommuni cation \(Telco We consider a Telco environment, since it is one of the most challenging in which the adoption of the open source paradigm may be successful and play an important role Also, in complex environments, existing assurance tasks are not suitable because i traditional approaches \(see Fig 1\are not applicable to a chaotic and unstructured software development process like the open source one, and ii  patch-based approach involves the community only without considering the final users In current big Telco players, OSS components are downloaded and embedded in existing solutions \(critical or not\ here, no many cares are given to problems involving quality and secur ity. In the last few years some of these Telco players including TelecomItalia \(TI are trying to move from such an \223opportunistic\224 approach to Open Source Software \(OSS\ore formalized one A strategy on how approaching OSS to ensure quality is currently under development and spans through three main branches i the evaluation of the actual \(quantified if possible\value that opening an internally developed platform can have ii the definition of a full governance procedure that allows Project Managers to decide the approach to OSS, related to the criticism and the characteristics of the application they have to implement iii the creation of a community of peers \(Tier One Service Providers within the TeleManagement forum\ that share experience, skills, possibly also software, and overall approaches towards OSS in an Open Source Working Table The drivers for all these initiatives are: ensure software quality, the reduction of Total Cost of Ownership \(TCO and the flexibility and dynamicity of solutions implemented using OSS components The remainder of this paper is organized as follows. Section 2 introduces a patch-based approach for security and dependability assurance in huge OSS projects. Section 3 discusses a new approach to assurance process in the context of critical Telco scenario. Section 4 provides a case study based on the introduced Telco environment. Finally Section 5 presents our conclusions II  S ECURITY AND D EPENDABILITY A SSURANCE IN H UGE OSS  P ROJECTS   L INUX E XPERIENCE  Nowadays, OSS and its components play an important role in the enterprise ICT infrastructures. However, although the adoption of OSS software is permeating the entire distributed systems, its adoption fo r complex mission-critical applications, such as telecommunications and embedded systems, is still quantitatively and qualitatively less successful than it could be, even in presence of detailed adoption guidelines. Relatively few companies in fact do not use open source products and technologies at all, but project managers working on complex systems still perceive barriers that limit their use, includi ng security and license topics 6,7 A fu rth er co m p licatin g  facto r is th e d i fficu lt to estab lish a process-based assurance model, since the open source paradigm is based on a coope rative community-based code development, where code changes rapidly over time and unambiguous specifications may simply not be available. In this context, OSS community works and acts with its particular workflow that cannot be perfectly modelled. As a consequence, OSS has fostered a new development style based on a heterogeneous mixture of existing methodologies and new development pro cesses. It does not provide any standard criteria to select activities for the different projects; instead, it is up to the developers to agree on which methodology is more suitable for them   An important requirement, which might facilitate the deployment of OSS within enterprise frameworks and in mission critical applications, is then the design and development of innovative test- and model-based assurance metrics for OSS evaluation, which map the intrinsic characteristics of open source on the assurance process. Of course some huge OSS projects \(e.g., Linux\have developed their own assurance tasks, adopting a patch-based approach to compensate for the lack of requirements and design documentation Security assurance activities for OSS code could then be performed at several points in the code life cycle [9]. Contributions to major OSS projects like Linux are strictly monitored and must meet quality standards; here, we are interested in the assurance process used to keep these standards. Of course, different OSS projects will use different assurance procedures, but some conditions are verified for all OSS projects. Upon submission, a contribution to an OSS project must be well-formed, that is, coded and packaged according to well-estab lished OSS conventions. The first assurance activity is usually to check for novelty and interest of the contribution, that is, the properties \(either functional or non-functional\it would add to the project These checks are usually made by core members of the community \(by the subsystem maintainers in the case of the Linux kernel tion is accepted into an OSS project, it will be tested and reviewed by the project\222s community, to become part of the project\222s mainstream code. In the specific case of Linux, the process is two-tiered \(see Fig. 2\ if the subsystem or project containing the new contribution is then picked up by a Linux distribution like SuSE, it will be subject to that distribution-specific assurance procedure. Typical assurance activities performed at distribution level include standards-compliance \(for example, LSB and POSIX and robustness testing. It should be noted that the assurance process described above   Fi g 2 The twoand three-tiered assurance p rocess of bi g OSS p ro j ects  20   2009 Third IEEE International Conference on Digital Ecosystems and Techn\ologies \(IEEE DEST 2009 659 


   see Fig. 2\so be made three-tiered by adding a userspecific assurance activity at adoption time. In the case of Linux, this assurance procedure is coarser-grained, as adopters retain control over th e inclusion of each specific subsystem in the distribution, in the form of patches, but, of course, not over individual contributions to subsystems Regression is always possible, that is, the adopter can always return to a previous version of the subsystem if an update does not meet the adopt er\222s quality or dependability standards. Some adopters prefer to entirely delegate security and quality assurance to their preferred distribution others try and influence the OSS product evolution at both design and assurance time 1  However, in critical contexts assurance must be standardized and focused to the custom er\222s needs to meet the requirements of companies adopting the software. In general it is possible to identify two types of OSS adoption approaches which involve assu rance activities: the adoption of existing OSS vertical solutions or the exploitation of OSS horizontal solutions to create new vertical services The former case \(i.e., vertical solution\ implies two different analysis areas. Looking at the administrative department or the overall IT infrastructure, the adoption of vertical solutions is possible and successful. In the literature, is wellacknowledged how the migration, as for instance, from Microsoft Office to OpenOffice.org package, and from Windows to Linux systems, is successf ul and used as a leverage to reduce contract and license cost. By contrast, looking at frameworks typical of Telco companies, such as Operational Support Systems that represent systems directly managing the telecom network, and Business Support Systems often referred as OSS/BSS that manage customers processes, the overall specificity, criticality and complexity of them could represent a barrier for the adoption of specific OSS implementations The latter case \(i.e., horizontal solution\bes the trend to participate in the development community, adopting horizontal frameworks over which new and re-engineered vertical services are developed. Following that philosophy Banzi et al in descri be t h e st rat e gy adopt ed by Tel e comItalia Technology Department towards open source software. In particular, they describe the approach and experience in starting the WADE project, an extension of the JADE open source frame for t h e devel opm ent of interoperable intelligent multi-agent systems. TelecomItalia coordinates the open source community involved in WADE project, with the interaction of other Telco players, to produce a framework that satisfies the needed security and functional requirements and that will be exploited to build new vertical services The interaction with Telco companies is a fundamental aspect in the development of open OSS/BSS systems, making the patch-based assurance tasks discussed above not useful in practice. In that context, th e need of a solution \(described in Section 3\that is applicable for OSS and involves the  1 In the telecommunication sector, Carrier Grade Linux CGL tions as well as some assurance criteria which must be met in order for Linux to be considered \223carrier grade\224 \(i.e ready for use within the telecommunications industry software adopters arises. In this scenario, it is also important to note that the interaction with Telco companies and OSS community is greatly dependent on the size of the Telco player: the bigger the co mpany, the easier to have corporate agreements with big software vendors, the less probable the adoption of OSS solutions will be III  OSS  A SSURANCE IN THE T ELCO S ECTOR  Three different types of assurance can be defined focusing on the telecommunication sector security assurance aimed at preserving and verifying the security requirements which are at the basis of the software dependability assurance representing the activities focused on verifying the robustness and reliability of a systems, and quality assurance 11 in p articu l ar with resp ect to p o ssib l e m ain tenance actions. In the following we focus on the security and dependability aspects of the assurance tasks A. OSS Assurance in the Telco Sector: the Requirements The path for the adoption of OSS in Telco companies, and in general in large organizations, needs particular care S&D assurance plays an importa nt role, since a certification of security and dependability properties of a particular OSS might remove most of the barriers in the migration or in the implementation of new systems. To give such a certification, till not formalized in rec ognized standards, it is important to establish some principles and metrics that could help in the evaluation Assurance tasks are applied to community activities to certify that all the security requirements are implemented and that the developers group is acting promptly and effectively. Fig. 3 depicts the definition of assurance tasks in OSS mission-critical applications. In particular, as soon as a new version of the software has been released, forums and blogs are exploited by the developers to discuss the overall assurance of the product based on the security requirements Then, data collected after the discussion are used as the basis for the next development phase. In particular, discussion outcomes are used in a new cycle of development phase resulting in the implementation of a new software prototype. A set of assurance metrics are finally applied to the prototype to evaluate and certify the assurance properties of the code. After metrics evalua tion, the assurance tasks are applied iteratively In particular, S&D assurance for OSS is then based on col  Fig. 3 Assurance tasks definition in mission-critical OSS 2009 Third IEEE International Conference on Digital Ecosystems and Techn\ologies \(IEEE DEST 2009 660 


   lecting a shared set of metrics that has to be identified and applied to the software under examination \(see Section 4.1\etrics must ensure that the community and the OSS products have a minimum level of acceptability by Telco companies, in relation with the criticalities of the solution in which to embed the OSS, and evaluating the skills and the participation level in the development group. A measure of the overall quality of the OSS products is also important, to certify that a minimum level of quality is already ensured by the OSS application \(see Section 4.2 This measure can guarantee that the adoption of an OSS application will not imply too effort for the organization, or too risks in its integration within developed solutions. The quality analysis needs to verify the accordance with wellestablished coding-standards and the respect of the security requirements. Finally, a deep anal ysis is necessary to verify the adaptability of the different type of OSS licenses within the areas of the business pro cess typical of Telco companies, to avoid violating copyright or restrictions B. OSS Management Moving from a \223just use it\224 approach to a more \223strategic\224 one means having a great care to S&D as well as Quality Assurance aspects In particular, the Telco business process is based on eTOM enhanced Telecom Operations Map rel eased by t h e TeleManagement Forum as an update of the original TOM model, and includes a hierarchy of process definitions, offering a structure and a model to understand and develop areas of the process. Also, it is applied by Service Providers SP\and a basis for internal and external discussion around business needs and interoperability, as well as by Suppliers and others as a means of understanding and discussing SP behaviour and requirements A survey of OSS components embedded within TelecomItalia Support Systems, classifi ed according to eTOM model see Table 1\their distribution within the overall eTOM process framework This can be either a good signal, in the sense that an uncontrolled use leads to a homogenous distribution of OSS, but also a worrying one, since OSS can be applied in critical contexts where a careful check of dependability and security assurance are a must The eTOM model is also important in the management of licenses and Intellectual Properties Rights \(IPR\. Different processes and areas of the process imply different levels of visibility and customization of the adopted OSS code. This leads to a careful analysis of the license types and the area where they are integr ated to ensure the consistency of the adopted OSS code with respect to the declared license Commercial tools like the ones released by Black duck Software  gi ve a good l e vel of assurance on such l e gal  aspects. The high cost of ownership of such frameworks raises the need of an assuran ce metric that could give an assurance about this legal aspect. According to the specific service in which the OSS component is embedded, special care has to be taken in verifying the suitable licenses. An analysis of the distribution of license types adopted with respect to the eTOM Process Areas is reported in Table 1 Then, further researches must be dedicated to Quality Assurance since the ability to estimate maintenance costs of an embedded OSS component is clearly important. Metrics for such estimation derive dir ectly from software engineering principles like coupling, cohesion, cyclomatic complexity and compliancy to coding standards However, the selection is also driven by internal developers\222 and managers\222 skills, which are used to drive the work in a protected environment In the OSS case, developers need to learn how to work in a community environment in which technical skills and relational capability play an important role. It is important to understand people working style within the community and, accordingly to the approach selected for the specific OSS component, behave consequently   The style of relationship with the community, in fact, has to be guided by the criticism of the solution the OSS compoTable 1 The distribution of OSS usage within eTOM Business Process Framework in TelecomItalia   2009 Third IEEE International Conference on Digital Ecosystems and Techn\ologies \(IEEE DEST 2009 661 


   nent is going to be embedded in Accordingly to this, in fact, it can be decided to 200  just skill people on the product to be able to work on the code in case of critical bugs fixing 200  ignite the community with developers for enhancements or bugs fixing to acquire competence on the code, but also to provide significant contributions to the code base to be ready to continue the developing outside the community, in case of frictions or unexpected behaviour 200  join the board to have influence over the product roadmap. Again the criticism of the OSS component is the driver and, in th at case, the company could decide to invest in the selected OSS, enhancing its functionalities, since no suitable commercial components are available or its customization costs are too high In particular, the last point has to be considered when the investment is raising to a significant level. If the company wants to have the highest Return of Investment \(ROI\once ensured that problems with the licenses and internal skills are overcome, the best approach is to operate directly on the open source community environment in implementing the necessary functionalities. This could be an alternative to the internal development of the code, which takes advantages by all possible contributions from the community An other important requirement is to protect the organization against sudden events with in the company itself \(critical bugs fixing, changes in the scheduling of internal solutions\or the community. This can be achieved by negotiating privileges with the community, such as implementing internally certain features in protected development branches, where the commit control is delegated only to the company: the code is always open, it is visible by all, and everyone, if authorized, can c ontribute to the specific functionality. Following that approach, the code is ready for merging to the final trunk, but the company investment is protected. Concluding, the community environment overlaps the company one only for specific purposes IV   C ASE S TUDIES  The following Section describes the assurance model developed by TI in collaborati on with academic institutions This model has been exploited to evaluate open source products for their adoption within the eTOM Framework Our research does not focus on OSS components managed by well structured and stable communities, for which an assurance evaluation already exists \(i.e., Linux\but rather to components developed by small active communities. In this case, ad-hoc quality and S&D assurance models become necessary to evaluate the suitability of OSS products from the point of view of the organization that wants to invest on them A. Collecting Metrics on OSS S&D The first step in the developm ent of an assurance model is the definition of a set of metrics for the evaluation of OSS that will be used to choose th e best products that fit Telco requirements. The problems faced by analysts are principally related to the lack of reliable information to build a complete set of metrics. In particular, in literature is not available a framework of metrics commonly accepted as a reference, but a number of independent projects \(e.g., in  and e trics, each one concentrated on a specific aspect. Also, there is a lack of information on OSS, such as the number of releases, number of core developers, number of released patches, or the discussion threads typology. Even though important portals like SourceForge  Freshm eat 16 and t h e OW 2 consortium rel ease dat a about t h e OSS t h ey host  t h ese dat a  are semantically different and do not permit cross-portal evaluations. For example, the simple definition of \223close\224 for a bug is subject to different interpretations, or the importance given to the number of downloads could vary if the community considers more relevant the quality of a product rather than its diffusion Along with traditional OSS eval uation and selection frameworks TI adopt ed FOC S E \(Fram e work for Open source Critical Systems Evaluation a fram e work developed by University of Milan based on a set of general purpose security-related metrics. FOCSE includes some specific metrics expressing capabilities in responding to continuous changes in security threats, and is then suitable for evaluating open source security frameworks. The provided metrics analyse OSS focusing on multiple specific areas i  Generic Application  ii  Developers Community  iii  Users Community  iv  Software Quality  v  Documentation and Interaction support and vi  Integration and Adaptability with new and existing technologies  Furthermore, the Qualipso Proj ect [14] has been contacted to share knowledge and experiences about the forthcoming Qualipso set of OSS evaluation metrics. The project is aimed at defining and implementing technologies, processes and policies to facilitate the development and adoption of OSS components. Here, an important aspect is to guarantee the same level of trust traditionally offered by proprietary software As a result of this joint effort involving TI, University of Milan, University of Bolzano, and different OSS communities \(board of OW2 and Apache.org\ected a set of metrics, modified them in accordance to its context and needs, and started to collect data using them. Currently, a TI internal group is working towards the application of the above metrics to OSS, taking ahead the initiativ e within the TeleManagement Forum to involve other big Telco Players B. Quality and S&D Assurance The level of quality required for the implemented software arises with respect to the criticality of the environment it is going to be embedded in. The criticality and complexity of Telco systems \(e.g., for OSS BSS systems analysis and control of software quality during the whole development process \(ensured by the quality or assessment levels of the factory or of the partner companies or vendors of the OSS process, such controls are concentrated on the assessment of the code quality, rather than enlarging the analysis to the other development phases. A check on the quality of the OSS components can be performed by just verifying the adoption of simple coding rules using ABC metrics or complexity 2009 Third IEEE International Conference on Digital Ecosystems and Techn\ologies \(IEEE DEST 2009 662 


   evaluating tools. Also the co mpliancy to J2EE \(Java 2 Enterprise Edition\fications can be verified However, the main problems ar ise when checking security 6,7 ep en d ab ility an d licen se co m p lian cy to  in tern al requested standards. In the case of OSS, there are no design documents where information on the structure of the product can be found, thus no test cases are available or easily deployable. In addition, only solutions based on costing reverse engineering processes are possible. Another alternative is the use of proprietary parsing tools, such as Fortify  to check the presence of security flaws, or BlackDuck  t o bol st er soft ware l i censi ng com p l i a nce V  C ONCLUSIONS  Open Source Software plays an important role in today\222s enterprise ICT infrastructures However, in the context of complex mission-critical applications, OSS adoption is still limited and insufficient, even in presence of detailed adoption guidelines. Among the others, a limiting factor to OSS adoption is that software security assurance activities are traditionally interleaved with development ones; this makes difficult to establish a process-based assurance model for OSS, since the open source paradigm is based on a cooperative community-based code development, where code changes rapidly over time and unambiguous specifications may simply not be available. In this paper we argued that due to its lack of a formal development process, OSS requires decoupling assurance from development. Here, we put forward the idea that assu rance must be standardized and focused to the customer\222s needs to meet the requirements of companies adopting the software. To this aim, it is important to establish some principles and metrics that could help in the definition and modelling of assurance tasks. Our industrial \(Telco\udies confirm that OSS assurance should rely on measuring a consistent set of metrics that can be reverse-engi neered from code rather than requiring the availability of design documentation To conclude, the assurance process discussed in this paper can provide, on the one side, a benefit for the communities and companies that wish to adopt an OSS solution, and, on the other side, a means to self protect companies from possible problems arising from OSS adoption  VI  A CKNOWLEDGEMENTS  This work was partly founded by the European Commission under the project SecureSCM contract n FP7213531 the Italian Ministry of Research under FIRB TEKNE contract n RBNE05FKZ2_004         VII  R EFERENCES   B. Boehm  J. Brown M. Lipow, and G. MacCleod Characteristics of Software Quality NY, American Elsevier, 1978   B   K itchenham and S L Pfleeger 223Softw are quality: the elusive target,\224 IEEE Software 13\(1   E. Damiani C.A. Ardagna and N. El Ioini Open Source Systems Security Certification Springer, December, 2008  J. McDermott and C. Fox, \223Usi ng Abuse Case Models for Security Requirements Analysis,\224 in Proc. of  the 15th Annual Computer Security Applications Conference \(ACSAC '99 Washington, DC USA, December 1999   B Arkin and S. Stender and G. McGraw, \223Software Penetration Testing,\224 IEEE Security and Privacy 3\(1  C. Cowan, \223Software security for open-source systems,\224 IEEE Security & Privacy 1\(1   C Payne 223On the security of open source software,\224 Info Systems Journal 12:61\22678, 2002  J Feller and B  Fitzgerald  Understand Open Source Software Development Addison-Wesley, 2002   M Banzi G Bruno and G. Caire, \223To What Extent Does It Pay To Approach Open Source Software for A Big Telco Player?,\224 In Proc. of the IFIP WG 2.13  Working Conference On Open Source Systems Milan, Italy, September 2008  JADE \(Java Agent DEvelopm ent Framework http://jade.tilab.com 2009  I. Stamelos, L. Angelis, A Oikonomou, and G.L. Bleris, \223Code quality analysis in open source software development,\224 Info Systems Journal 12:43\22660, 2002  Business Process Framework \(eTOM  available at http://www.tmforum.org/browse.aspx?catID=1647 2009    Manage Open Source Software \226 Black Duck Software, available at http://www.blackducksoftware.com 2009  Q u alipso - Trust and Q u ality in O p en Source systems available at http://www.qualipso.org 2009  SourceForge.net: Open Source Software, available at http://sourceforge.net 2009  Freshmeat.net, available at http://freshmeat.net 2009  OW2 Consortium, available at http://www.ow2.org 2009   C.A Ar dagna, E. Dam i a ni and F. Fr at i  223FOCSE An OWAbased Evaluation Framework for OS Adoption in Critical Environments,\224 in Proc. of The Third IFIP International Conference on Open Source Systems \(OSS 2007 Limerick, Ireland, June 2007  Fortify Softw a re available at http://www,fortify.com 2009  B. Weinberg, \223The Open Source Development Process,\224 available at www.embedded-computing.com/departments/osdl/2005/1  2009  OpenBRR, A Fram ework for Eval uat i ng Open Source Soft ware  www  openbrr.org 2009   Davide Taibi, Luigi Lavazza, and Sandro Morasca, \223OpenBQR: a framework for the assessment of OSS,\224 in Proc. of The Fourth IFIP International Conference on Open Source Systems \(OSS 2008 Milan, Italy, September 2008    2009 Third IEEE International Conference on Digital Ecosystems and Techn\ologies \(IEEE DEST 2009 663 


number of products or processes covered by the application, though We also found no significance with regards to cost impacts of diversity-related complexity \(neither for DBMS nor for OS\ce, propositions P3.2 could not be supported  Turning to deviation-related AA complexity we found significant differences in terms of the products covered and at a lower significance level in terms of age and processes covered between those applications that do not deviate and those that deviate from the standard OS. Non-standard-compliant applications cover more products and also more processes. However, compliant applications are slightly older \(median: 3.2 years\ than non-compliant ones \(median: 2.2 years\hese results lend support to proposition P2.3 \(when measuring compliance to OS standards\terestingly, the results also indicate that the relation between age and deviation from proposition P1.3\ reverse to the proposition: older applications are more standard compliant Measuring the deviation of applications from the standard DBMS provides a somewhat different picture: significant differences only exist for the number of user departments involved in the application. Here, we find again a surprising result the standard-conformant applications have more userdepartments involved \(median: 3\an non-compliant ones \(median: 1 department; overall median: 2 departments\. This is inverse to the original proposition. We do not find support for propositions stating that with an increase in either age \(P1.3\r business requirements complexity \(P2.3 applications also increase in their deviation from standard technology \(in terms of DBMS As far as deviation-related impacts are concerned we found only one significant result: the group of applications that did not comply to DBMS standards exhibit lower maintenance cost than the compliant applications. In contrast to the original proposition 3.3, for DBMS-standard deviation, we observe significantly lower maintenance cost for noncompliant than for compliant applications  With regards to overlap-/redundancy-related AA complexity we found some support for proposition P2.4 stating that involvement of more users leads to more overlap of applications 8 No significant differences are found regarding the age of the applications, hence, the proposition that older   8 The variables for the coverage of products and processes were not included in this test as the overlap was computed using these two variables \(implying that there is a significant relation between the respective variables applications also exhibit a higher degree of overlap was not supported \(P1.4 However, interesting results were found for the impacts of overlap-redundancy-related AA complexity: it is striking to see that the applications with a medium level of overlaps have a lower median in operations cost than those with a low or high-level of overlap, implying a non-linear, U-shaped relation between overlap and operations cost. Interestingly the same holds true for maintenance cost. Hence, the original proposition \(P3.4\that applications with higher overlap also exhibit higher IT cost is not supported  5. Discussion  Up to now, the \(practical and academic discussion of AA complexity has lacked differentiation. Various kinds of AA complexity have been lumped together with little attempt to distinguish between them. The implicit propositions underlying the respective statements and recommendations have been that all these kinds of AA complexity increase with age and business complexity, and in turn cause higher IT costs In our case, however, the result \(Table 3\dicate that only interdependency-related AA complexity behaves as assumed by consultants and researchers with respect to causes and impact: older applications and those with more complex business requirements also exhibit more interfaces \(i.e. a higher degree of interdependency\; at the same time, more interdependent applications incur higher IT costs than less interdependent applications. An explanation for this is the intuitive assumption underlying the abovementioned propositions: on the one hand, when a business grows over time, applications are added, and these have to be connected to ever more applications In former times, more point-to-point interfaces might have been used, while newer applications try to reduce interfaces e.g. by relying on central middleware. On the other hand, it might also be more difficult to maintain and operate applications with many connections because it is not easy to keep track of all the interdependencies: changing one application means that all of the other applications connected to it have to be changed, as well, thus leading to higher costs for those interdependent applications. The advice of "doing more with less seems to hold true here. In this case, consultants would probably be right in advising their clients to either maintain the growth of or reduce the number of interfaces \(e.g. by introducing Enterprise Application Integration \(EAI\yers to eliminate point-to-point interfaces Proceedings of the 42nd Hawaii International Conference on System Sciences - 2009 7 


However, the other types of AA complexity diversity, deviation, and overlap\ot act according to the general propositions of researchers and consultants in our case. In the following paragraphs, we would like to discuss the deviations from the propositions stated in the introduction The diversity of applications with respect to OS does not seem to be related to any of the causes or impacts we looked at in our case. Concerning DBMS diversity seems to increase with age and the number of involved users. However, no relation to causes is found for DBMS-diversity either. There are multiple possible explanations for this. Firstly, looking at the data, we do not find many applications using multiple OS or DBMS in the company we chose for our case study \(e.g. there were only 20 applications using more than one DBMS\nce, the company might have already worked on the diversity issue Nevertheless, we would have expected some difference even among these few applications in the case of a strong relation. Secondly, we find differences in the support for the propositions depending on which level of the "technology stack we look at. If we think of the different types of technologies as being organized in a layered stack with the specificity of technologies increasing towards the top, OS would probably be on a low level and DBMS would be on a higher level \(because a DBMS is less 'general purpose', i.e. more constrained in what it can be used for\e might find the propositions supported only for 'more specific technologies, which we did not test for \(such as middleware, e.g. application servers, directory services, etc.\rther research might extend the proposition to include a broader coverage of the technology stack". Thirdly, it might well be that diversity \(i.e. the sheer number of technologies used by an application\ is indeed not an important complexity criterion on the level of applications However, it might still be important on more aggregate levels, such as application landscapes: If a business product \(such as derivatives\ makes use of applications that together employ a large number of different technologies on each layer of the technology stack, this combined diversity might very well have an impact on costs. Hence, we would have to look at higher levels of the IT architecture and could formulate the respective proposition for these levels even though they are not supported on the level of applications. Comparing complexity as well as its causes and impacts on different levels of IT architecture \(e.g. applications vs. application landscapes\would enable dissecting the impact that the combination of application has in contrast to single applications \(i.e. answer what the formation of a landscape is really contributing to the overall complexity\ch research could serve to further disentangle AA complexity by not only differentiating different types of AA complexity interdependency, diversity, deviation, and overlap but also by distinguishing different levels of AA complexity \(e.g. applications vs. application landscapes Regarding deviation, we again see differences depending on which level of the technology stack we look at: applications deviating from the standard OS also cover more investment banking products and processes. The reason for this might be that different investment products and processes were historically supported by applications on different platforms Hence applications that have been extended to also cover these products and processes had to be made compatible. This would also provide an explanation for why younger applications deviate more from the standard OS than older ones: introducing more connector" applications serving multiple products and processes will bear out this observation. This explanation makes us aware of the fact that the propositions would benefit from taking into account the previous complexity management activities conducted by the bank. A mediating construct of Complexity management activities and abilities might hence improve the conceptual model for future research. For this purpose, variables would have to be identified to measure the level of activities that address the respective AA complexity type \(e.g integration measures addressing interdependency standardization efforts addressing deviation, and consolidation efforts addressing overlap/redundancy Complexity management activities might mediate both the causes-complexity relation as well as the complexity-impact relation \(see Figure 2 for a refined conceptual model   Causes of IT complexity Age Business requirements  IT complexity Interdependency Diversity of technologies Deviation from technology standards Overlap/redundancy  Impact of IT complexity Cost Agility  Complexity management activities  Figure 2: Refined Conceptual Model  Regarding DBMS-related deviation, we observed two surprising relationships in our case: those applications that deviated more from the standard DBMS involved fewer user departments and also incurred less maintenance costs. The propositions suggested the inverse relationship. An explanation might be that the IT department refused to maintain the applications that were not standard-compliant Proceedings of the 42nd Hawaii International Conference on System Sciences - 2009 8 


These applications might hence generate "hidden" IT costs somewhere else. These costs might then not be reported as IT cost, but e.g. as marketing cost in the case of a non-compliant marketing information system. This explanation would hint at a problem with allowing exceptions to standards if the user department itself takes care of the non-compliant application. In this case, official indicators might underestimate the costs incurred by non-compliance unless the decentralized cost is being tracked as well We cannot think of an intrinsic argument that might warrant the introduction of non-compliant technologies with the aim of decreasing maintenance costs. It should be noted that this might not be the case for other impact variables \(such as agility short-term agility might very well improve if applications with non-standard technologies are added, because it would allow business requirements to be fulfilled more quickly in the short-term However, as we did not include agility as a dependent variable in our study, this claim remains conjectural Concerning overlap/redundancy of applications we only see the proposition on increased user department involvement influencing a higher degree of overlap among applications. Interestingly, the degree of overlap among applications exhibited a Ushaped relation to both operations and maintenance costs, with medium-level overlapping applications incurring the least cost. The explanation for this might be that applications need to have some level of overlap in order to be integrated and should not only serve as silos that consume even more resources to keep them connected with other applications [4, p  th e oth e r e x tre m e, t hos e application s  w i t h a  very high overlap might be so redundant that they incur double work, which increases costs as well This explanation was confirmed when we discussed the results with the bank itself. It follows that at least in this case, reducing overlap is not always warranted, as there might be an optimal level of overlap that does not necessarily coincide with the lowest level of overlap. This reminds us that not all relationships have to be linear when it comes to complexity. Especially in relation to agility, for some types of complexity, a certain amount might be essential and even beneficial, but too much might again be detrimental. While this has been investigated to some degree in non-IT-related areas 1, 2 it h a s rem a i n ed on l y a clai m s o f a r i n th e field of IT complexity \(e.g ilit y i s  hy pot h e sized to  decrease at the extreme ends of the vague construct IT complexity", hence leaving ample room for future research  6. Conclusions  We have shown that the propositions underlying current research and \(consulting\ practice do not hold true for all types of AA complexity. We disentangled the rather broad and vague AA complexity concept by proposing four types of AA complexity interdependency-, diversity, deviation- and overlap/redundancy-related AA complexity. We would recommend against referring broadly to "AA complexity" without further differentiation in future research; we advise specifying which type of AA complexity \(interdependency, diversity, deviation or overlap\ really meant. Being more precise will enable us to add further to the body of knowledge in this highly relevant area of IS research. This proved to hold especially true as we found that the general propositions were only valid for interdependencyrelated AA complexity and not for the other types of AA complexity. Future research should clearly be based on multiple case studies rather than just on a single case study in order to allow for generalization As we found support for the propositions for interdependency-related AA complexity, we propose honing in on this type of AA complexity further, e.g by differentiating the degree or type of interdependency between applications \(see footnote 1\or example, a question of interest could be whether batch-oriented interfaces are more costly to maintain than online interfaces or interfaces facilitated by middleware We also pointed to potential differences for similar types of IT complexity on different architectural levels \(such as for deviation and diversity on the level of applications vs. deviation and diversity on the level of application landscapes which might warrant further research Based on the interpretation of our research findings, we also proposed several adjustments to the current propositions by referring to the technologystack levels for diversity and deviation, and by introducing AA complexity management activities as a mediating construct We hope that this research will serve as a foundation for future research in this area, which has so far in its entangled form been marked by assumptions rather than the subject of actual research       Proceedings of the 42nd Hawaii International Conference on System Sciences - 2009 9 


7. References  1 A s hk e n a s R Simplicity-Minded Management Harvard Business Review, 2007 85 12\: p. 101-109 2 G o ttf re ds on, M. a nd K  A s pina ll Innovation vs Complexity Harvard Business Review, 2005 83 11\6271  S can t l e b u r y  S   et al    From IT Complexity to Commonality: Making Your Business More Nimble in Opportunities for Action in Information Technology 2004 The Boston Consulting Group 4 Ross J.W  P. W e ill, a n d D  C. Ro be rtso n Enterprise Architecture As Strategy 2006, Boston, MA: Harvard Business Scholl Press 5 Ma tte rn F S  Sc h nw  l de r, a n d W  Ste i n  Fighting Complexity in IT McKinsey Quarterly, 2003\(1\. 57-65 6 Child J  Parkinson's Progress: Accounting for the Number of Specialists in Organizations Administrative Science Quarterly, 1973 18 3\: p. 328 7 G e ll-Ma nn, M What is complexity Complexity, 1995 1 1\: p. 16-19 8 P a rk  R.E   Software size measurement: a framework for coutning source statements 1992, Software Engineering Institute, Pittsburg 9 Mc Ca be T  A complexity measure in Proceedings of Int'l Conf. Sofrware Engineering 1976 10  Mc Ca be T  a n d D   Sha r o n  Cyclomatic Complexity and the Year 2000 IEEE Software, 1996 13 3\ p. 115 1 Halstead  M  H   Elements of Software Science 1977 New York: Elsevier 12 r te ta B.M. a n d R  E. G i a c h e tti A measure of agility as the complexity of the enterprise system Robotics and Computer-Integrated Manufacturing, 2004 20 p. 495-503 1 S h p i l b erg D  et al    Avoiding the Alignment Trap in Information Technology. \(Cover story MIT Sloan Management Review, 2007 49 1\: p. 51-58 14 Bo h, W  F. a nd D. Y e llin Using Enterprise Architecture Standards in Managing Information Technology Journal of Management Information Systems 2007 23 3\: p. 163-207 15 Chil d P  e t a l  SMR Forum: The Management of Complexity Sloan Management Review, 1991 33 1\ p 73-80 16 K a is le r, S.H F  A r m our, a nd M. Va l i v u lla h  Enterprise Architecting: Critical Problems in Proceedings of the 38th Annual Hawaii International Conference on System Sciences \(HICSS'05 2005: Hawaii 17 X i a   F  Module Coupling: A Design Metric in AsiaPacific Software Engineering Conference \(APSEC'96  1996 18 K u bic e k H  The Organization Gap in Large-scale EDI systems in Scientific Research on EDI 1992: Alphen aan den Rijn 1 Hi tz M  and B  M o n t azeri  Measuring Coupling and Cohesion in Object-Oriented Systems in Proc. Int Symposium on Applied Corporate Computing 1995 2 Z ach m a n  J A    A framework for information systems architecture IBM Systems Journal, 1987 26 3\: p. 276292 2 J o hn so n G    Researchers on Complexity Ponder What It's All About in New York Times 1997. p. B4 22 Si ng h, K  The impact of technological complexity and interfirm cooperation on business survival Academy of Management Journal, 1997 40 2\: p. 339 23 A x e l rod, R  a nd M.D  C ohe n Harnessing Complexity organizational implications of a scientific frontier 2000 New York: Basic Books 24 Ke lly S. a nd M.A   A llison The Complexity Advantage 1999, New York: McGraw-Hill 25 S h e r m a n, H  a nd R Sc hultz  Open Boundaries creating business innovation through complexity 1998 New York: Perseus Books 26 Ca m pbe ll, D  J  Task Complexity: A Review and Analysis Academy of Management Review, 1988 13 1 p. 40-52 2 L e e O K  et al   IT-Enabled Organizational Agility and Firms' Sustainable Competitive Advantage in Proceedings of the Twenty Eighth International Conference on Information Systems 2007. Montral 28 r h out M  v E W a a r ts, a nd J.v   Hille g e rsbe rg   Change factors requiring agility and implications for IT  European Journal of Information Systems, 2006 15 p 132-145 29 W e bs te r, J  a n d R.T  W a ts on Analyzing the Past to Prepare for the Future: Writing a Literature Review MIS Quarterly, 2002 26 2\ p. xiii-xxiii 30 A I S MIS Journal Rankings 2007  [cited 2007 18 April 2007 v a ila ble  f r o m  http://www.isworld.org/csaunders/rankings.htm  31 Pruit t  S  Gartner issues 10 CIO resolutions for 2005  in InfoWorld 2004 32  Po rter M.E  an d  V  E  Mi lla r How information gives you competitive advantage Harvard Business Review 1985 63 4\: p. 149-160 33 T a ba c hnik  B.G  a nd L  S. Fide ll Using multivariate statistics 5th ed. 2007, Boston: Pearson 34 Marten so n s   A  Producing and Consuming Agility in Agile Information Systems - Conceptualization Construction, and Management K.C. DeSouza, Editor 2006, Butterworth-Heinemann. p. 41-51   Proceedings of the 42nd Hawaii International Conference on System Sciences - 2009 10 


Appendix: Detailed description of results  We structured the results of the analyses described in Section 3 according to the two different types of propositions, namely those related to the causes and those related to the impacts of AA complexity  A.1. Results from analyzing causes of AA complexity  Causes of interdependency-related AA complexity The Kruskal-Wallis test revealed a statistically significant difference in the age and number of user departments covered for the three different interdependency groups of applications \(see Table 4 for n and p values\he groups of applications with more interfaces record a higher median score in terms of age as well in terms of user departments involved \(see also  Table 4\The same is true at a lower significance level \(0.05 level\or the number of IB products and processes: the groups of applications with more interfaces also cover more products and processes \(see Table 4 for for n and p values\ce, we do find support for proposition P1.1, which states that the older an application, the higher its interdependency-complexity it is. We also find support for proposition P2.1, which asserts that the higher the complexity of business requirements the higher the interdependency-complexity of applications is  Causes of diversity-related AA complexity The Mann-Whitney U test revealed no significant difference in either the age or the number of user departments involved, or in the number of IB products or processes covered for applications with one OS versus applications with more than one OS see Table 5\. Hence, we do not find support for propositions P1.2 and P2.2, which state that \(OSrelated\ersity complexity is caused by age or business requirements-complexity We obtained similar results when measuring diversity-complexity in terms of the number of DBMS used by an application. The only significant difference at the .01 level was in the age of applications: The group of applications with more than one DBMS was also older on average than those applications with only one DBMS. This supports proposition P1.2, which states that the older the applications get, the more diverse they become \(in terms of DBMS\At a lower significance level \(.05 we see a significant difference in terms of the amount of user departments involved for those applications with one DBMS versus those with more than one DBMS: the former group was found to involve fewer user departments than the latter. This supports P2.2 which asserts that the more complex the business requirements are, the more diverse the applications become \(in terms of DBMS\. However, we do not find support for this proposition when looking at the number of products or processes covered by the application, though. See Table 5 for the detailed results of the analyses  Causes of deviation-related AA complexity A Mann-Whitney U Test \(Table 6\ealed significant differences in terms of the products covered and at a lower significance level in terms of age and processes covered between those applications that do not deviate from the standard OS and those that do. Nonstandard applications cover more products and also more processes \(median: 1 vs. 2\wever, standardcompliant applications at this firm are slightly older median: 3.2 years\ than the non-compliant applications \(median: 2.2 years\hese results lend support to proposition P2.3, which states that the higher the complexity of the business requirements in terms of product and process coverage\is, the more deviation from the standard \(in terms OS\s found in applications. Interestingly, the results also indicate that the relation between age and deviation from standard technology \(in terms of OS proposition P1.3\tradicts the proposition: older applications are more standard compliant Measuring the deviation of an application from the standard DBMS provides a somewhat different picture. A Mann-Whitney U test \(Table 6\ealed significant differences only for the number of user departments involved in the application \(at .05 level of significance\ain we find a surprising result in that the standard-conformant applications involve more user-departments \(median: 3\han the non-compliant ones \(median: 1 department; overall median: 2 departments\. We do not find support for the propositions stating that an increase in either age P1.3\siness requirements complexity \(P2.3 causes an increase in applications' deviation from standard technology \(in terms of DBMS\e see indications for an inverse relationship between the number of user departments involved and the deviation of applications from standards in terms of DBMS technology  Causes of overlap-/redundancy-related AA complexity A Kruskal-Wallis \(Table 7\ealed significant differences in terms of the number of user departments involved for those applications that have a low to medium overlap and those with a significant overlap \(the first two groups involve one user department and the last group involved 2.5 user Proceedings of the 42nd Hawaii International Conference on System Sciences - 2009 11 


departments on average\ignificant differences were found regarding the age of the applications. The variables for the coverage of the products and processes were not included in this test because the overlap was computed using these two variables implying that there is a significant relation between the respective variables\his lends some support to proposition P2.4 stating that involvement of more users leads to greater overlap of applications. The proposition that older applications also exhibit a higher degree of overlap was not supported \(P1.4  A.2. Results from analyzing impacts of AA complexity  Impacts of interdependency-related AA complexity A Kruskal-Wallis test \(Table 4\ealed a statistically significant difference in operations cost as well as maintenance cost across the three different interdependency-groups of applications. The more interdependent group \(i.e. applications with 3-7 or with 8 or more interfaces\igher median of operations \(Md=119,000 and 363,000 EUR respectively\ and maintenance costs \(Md=326,000 and 506,000 EUR respectively\ than the less interdependent group \(fewer than 3 interfaces applications \(Md=52,000 EUR operations costs and 64,000 EUR maintenance costs\. This supports the proposition \(P3.1\ that more interdependent applications also incur higher IT \(operations and maintenance\ts  Impacts of diversity-related AA complexity   Regarding OS-related diversity, a Mann-Whitney U test \(Table 5\howed no significant difference between the operations costs of more \(Md=93,890 n=105\d less diverse applications \(Md=131,540 n=27\09.5, z=-1.174, p=.24. The same holds for maintenance costs \(Md=166,400; n=121 vs Md=116,900; n =31\782, z=-.43; p=.668 To measure DBMS-related diversity, a MannWhitney U test was conducted \(Table 5\d revealed no significance difference in operations costs of more Md=129,985; n=85\d less diverse applications Md=154,777; n=16\5, z=-.237, p=.813. The same holds for maintenance costs \(Md=210,500 n=98 vs. Md=245,700; n=19\36, z=-.704 p=.481. Hence, the proposition \(P3.2\ that diversityrelated AA complexity leads to higher IT costs is not supported  Impacts of deviation-related AA complexity   Regarding deviation from the standard OS, a MannWhitney U test \(Table 6\revealed no significant difference between the maintenance costs and operations costs for standard-compliant \(Md=83,581 n=94 for operations cost and Md=148,300; n=113 for maintenance cost\nd non-compliant applications Md=180,147; n=38 for operations cost and Md=166,400; n=39 for maintenance cost z=-1.921, p=.055 for operations cost and U=2116 z=-.371, p=.711 for maintenance cost Concerning deviation from the standard DBMS, a Mann-Whitney U test \(Table 6\ealed a significant difference between maintenance costs for standardcompliant \(Md=373,100; n=59\d non-standardcompliant applications \(Md=170,200; n=58 U=1303, z=-2.231, p=.026. It is remarkable that the non-compliant applications had lower maintenance costs than the compliant applications. The difference between operations costs for compliant Md=109,978; n=51\d non-compliant applications Md=180,147; n=50\s not significant, U=1196.5 z=-.533, p=.594 Thus, the proposition \(P3.3\at application that deviate from technology standards incur higher IT costs is not supported. In contrast, for DBMSstandard deviation, we observed significantly lower maintenance cost for non-compliant than for compliant applications  Impacts of overlap/redundancy-related AA complexity a Kruskal-Wallis test \(Table 7\ showed significant differences in operations costs across the applications with a low \(less than 34 overlaps Md=90,442; n=37\edium \(35-79 overlaps Md=55,770; n=56\ and high level of overlap/redundancy \(more than 80 overlaps Md=129,985; n=61 6.862, p=.032. It is striking to see that the applications with medium overlaps have a lower median operations cost than those with a low or high-level of overlap, implying a non-linear U-shape relation between overlap and operations cost. Interestingly, the same holds true for maintenance cost. Applications with a low degree of overlap exhibited a median maintenance cost of 96,600 \(n=59\, those with a medium level of overlap incurred a median of 81,300 \(n=58\d highly overlapping applications a median of 248,700 \(n=67 9.791, p=.007. Hence, the proposition \(P3.4\at applications with a greater degree of overlap also exhibit higher IT costs is not supported  Proceedings of the 42nd Hawaii International Conference on System Sciences - 2009 12 


Interdependency Number of interfaces \(gp3_y4_sum_intf  2 22 2 22 Df 047 000 000 016 000 000 Asymp. Sig 6.134 22.298 20.875 8.331 17.018 18.917 N Median 46 45 43 46 27 37 41 41 41 41 36 38 2 intf 8 intf 1.0000 2.2000 1.0000 1.0000 52.3020 64.4000 2.0000 7.8000 4.0000 2.0000 363.9885 506.3500 2 intf 8 intf Mean rank 55.89 47.03 44.13 56.13 33.67 37.77 2 intf 73.46 83.40 76.61 76.21 60.89 68.89 8 intf 40 39 33 40 30 34 3 7 intf 1.0000 3.2000 2.0000 1.0000 119.3940 326.2000 3 7 intf 63.63 59.97 56.50 60.54 42.33 58.22 3 7 intf  Business requirements Causes of complexity Impacts of complexity  No. of IB products covered y24_#_IB_ bankprod Application age y14_age No. of user departments y19_#_ user_dpts No. of IB process covered \(y26_ IB_bankproc Operations cost \(y36_ ops_cost Maintenance cost \(y37_ Maint_cost 2  Table 4: Results of Kruskal-Wallis test for causes and impacts of interdependency-related AA complexity    Diversity Number of OS/DBMS used by an application Operating systems \(gp2_y7a_OS DBMS \(gp2_y8a_DBMS 2,726.500 18,302.500 1.503 133 1,087.500 1,318.500 1.362 173 3,308.000 902 367 543.000 7,446.000 3.925 000 2,642.000 2,536.000 3,202.000 855 392 757.500 7,198.500 2.187 029 2,884.500 18,460.500 965 335 1,216.500 1,447.500 583 560 1,209.500 6,774.500 1,174 240 654.500 790.500 237 813 1,782.000 9,163.000 430 668 836.000 5,687.000 704 481 Wilcoxon W Z Asymp. Sig N Median Mean rank Mann-Whitney U Wilcoxon W Z Asymp. Sig Mann-Whitney U 21 1.0000 125 1.0000 75.30 62.79 20 8.0500 117 2.2000 63.64 100.35 19 3.0000 113 1.0000 63.70 83.13 21 1.0000 125 1.0000 74.27 68.93 16 154.7770 85 129.9850 51.30 49.41 19 245.7000 98 210.5000 58.03 64.00 N Median 1 DBMS 2 DBMS 1 DBMS 2 DBMS Mean rank 1 DBMS 2 DBMS Data not shown as no significance found  Business requirements Causes of complexity Impacts of complexity  No. of IB products covered \(y24_#_ IB_bankprod Application age y14_age No. of user departments y19_#_user_dpts No. of IB process covered \(y26_#_ IB_bankproc Operations cost \(y36_ ops_cost Maintenance cost \(y37_ Maint_cost  Table 5: Results of Mann-Whitney test for causes and impacts of diversity-related AA complexity  Proceedings of the 42nd Hawaii International Conference on System Sciences - 2009 13 


 Deviation degree of deviation from standard OS/DBMS Operating systems \(gp2_y7b_OS_Dev DBMS \(gp2_y8b_DBMS_Dev 2,780.000 16,146.000 3.681 000 163 49 1.0000 2.0000 99.06 131.27 2,611.000 5,312.000 227 820 73 1.0000 73 1.0000 72.77 74.23 3,970.500 2.107 035 151 47 3.2000 2.2000 104.18 84.48 2,102.000 4,587.000 1.074 283 70 2.2000 67 3.5000 72.63 2,842.500 65.53 2,902.000 4,030.000 1.509 131 143 47 2.0000 1.0000 98.71 85.74 1,551.500 3,829.500 3.041 002 67 1.0000 65 3.0000 76.13 57.16 3,103.500 16,469.500 2.698 007 163 49 1.0000 2.0000 101.04 124.66 2,610.000 5,311.000 232 816 73 1.0000 73 1.0000 72.75 74.25 1,404.000 5,869.000 1.921 055 94 38 83.5815 180.1470 62.44 76.55 1,196.500 2,522.500 533 594 50 180.1470 51 109.9780 49.46 52.57 2,116.000 8,557.000 371 711 113 39 148.3000 166.4000 75.73 78.74 1,303.000 3,014.000 2.231 026 58 170.2000 59 373.1000 65.92 51.97  Wilcoxon W Z Asymp. Sig N Median No deviation \(1.0 Deviation 1.1 No deviation \(1.0 Deviation 1.1 Mean rank Mann-Whitney U No deviation \(1.0 Deviation 1.1 Wilcoxon W Z Asymp. Sig N Median No deviation \(1.0 Deviation \(>1.0 No deviation \(1.0 Deviation \(>1.0 Mean rank Mann-Whitney U No deviation \(1.0 Deviation \(>1.0  Business requirements Causes of complexity Impacts of complexity  No. of IB products covered \(y24_#_ IB_bankprod Application age y14_age No. of user departments y19_#_user_dpts No. of IB process covered \(y26_#_ IB_bankproc Operations cost \(y36_ ops_cost Maintenance cost \(y37_ Maint_cost  Table 6: Results of Mann-Whitney test for cause s and impacts of deviation-related AA complexity  Overlap/redundancy \(gp3_overlap_count 22 22 Df 216 001 032 007 Asymp. Sig 3.066 13.139 6.862 9.791 2 N Median 90 81 37 59 79 78 61 67 34 80 2.2000 1.0000 90.4420 96.6000 2.6000 2.5000 129.9850 248.7000 34 80 Mean rank 129.29 113.80 82.76 87.25 34 137.18 144.50 85.66 108.10 80 86 85 56 58 35 79 2.2000 1.0000 55.7705 81.3000 35 79 118.22 110.61 65.14 79.82 35 79  Not applicable Not applicable Business requirements Causes of complexity Impacts of complexity  No. of IB products covered \(y24_ _IB_bankprod Application age y14_age No. of user departments y19_#_ user_dpts No. of IB process covered \(y26_ _IB_bankproc Operations cost \(y36_ ops_cost Maintenance cost \(y37_ Maint_cost  Table 7: Results of Kruskal-Wallis test for causes and impacts of overlap-/redundancy-related AA complexity Proceedings of the 42nd Hawaii International Conference on System Sciences - 2009 14 


  15 R EFERENCES    http://www.w3.org/XML/Schema   eb Orchestration with BPEL\224 http://www.idealliance.org/pa pers/dx_xml03 papers/0406-01/04-06-01.html  Hi bernat e hom e page www.hibernate.org   Al l a rd, Dan and Hut c herson, Joe, \223C om m uni cat i ons Across Complex Space Networks\224, IEEE Aerospace Conference, March 1-8, 2008  W e b Servi ce Defi ni t i on Language http://www.w3.org/TR/wsdl   B a uer, C h ri st i a n and Ki ng Javi n Java Persi s t e nce for Hibernate, New York: Manning Publications, 2007 7] \223Software Agents An Overview\224 http://www.sce.carleton.ca/netm anage/docs/AgentsOverview ao.html  e thodology.org  http://www.riaspot.com artic les/entry/What-is-Ajax  http://www.json.org 11 h ttp to m cat.ap ach e.o r g   12] http://java.sun com/products/servlet  http://www.w3.org/Sty le/CSS    B IOGRAPHY  Dan Allard has worked as a software engineer at the Jet Propulsion Laboratory for the past 17 years.   He currently leads the development of core JPL accountability systems applications and infrastructure Other recent work includes the development of a message-based ground data system for the Mars Science Laboratory as well as research and development of ontologybased distributed communications     Dr. Charles D \(Chad\ards, Jr received his A.B degree in Physics from Princeton University in 1979 and his Ph.D. in Physics from the Calif ornia Institute of Technology in 1984.  Since then he has worked at NASA\222s Jet Propulsion Laboratory, where he currently serves as Manager of the Mars Network Office and as Chief Telecommunications Engineer for the Mars Exploration Program, leading the development of a dedicated orbiting infrastructure at Mars providing essential telecommunications and navi gation capabilities in support of Mars exploration.  Prior to that he managed the Telecommunications and Mission Operations Technology Office, overseeing a broad program of research and technology development in support of NASA\222s unique capabilities in deep space communications and mission operations.  Earlier in his career, Dr. Edwards worked in the Tracking Systems and Applications section at JPL where he carried out research on novel new radio tracking techniques in support of deep space navigation, planetary science, and radio astronomy  


  16  


Thank you Questions 


 18  Astronautical Congress Valencia, 2006 27  Bu reau  In tern atio n a l d e s Po ids et Mesures. \(2 008  August\SI Base Units. [On http://www.bipm.org/en/si/base_units   B IOGRAPHY  Author, Karl Strauss, has been employed by the Jet Propulsion Laboratory for over 22 years.  He has been in the Avionics Section from day One.  He is considered JPL\222s memory technology expert with projects ranging from hand-woven core memory \(for another employer\o high capacity solid state designs.  He managed the development of NASA\222s first Solid State Recorder, a DRAM-based 2 Gb design currently in use by the Cassini mission to Satu rn and the Chandra X-Ray observatory in Earth Orbit.  Karl was the founder, and seven-time chair of the IEEE NonVolatile Memory Technology Symposium, NVMTS, deciding that the various symposia conducted until then were too focused on one technology.  Karl is a Senior IEEE member and is active in the Nuclear and Plasma Scie nce Society, the Electron Device Society and the Aerospace Electronic Systems Society Karl is also an active member of SAE Karl thanks his wonderful wife of 28 years, Janet, for raising a spectacular family: three sons, Justin, Jeremy Jonathan.  Karl\222s passion is trains and is developing a model railroad based upon a four-day rail journey across Australia\222s Northern Outback   


 19 Bollobs, B. 2001. Random Graphs. Cambridge University Press; 2nd edition. 500pp  Cawley, G. C., B. L. C. Talbot, G. J. Janacek, and M. W Peck. 2006. Sparse Bayesian Ke rnel Survival Analysis for Modeling the Growth Domain of Microbial Pathogens  Chiang C. L. 1960. A stochastic study of life tables and its applications: I. Probability distribution of the biometric functions. Biometrics, 16:618-635  Cox,  D. R. 1972. Regression models and life tables J. R Stat. Soc. Ser. B 34:184-220  Cox, D. R. 1975.   Partial likelihood Biometrika 62:269276  Cox, D. R. & D. Oakes. 1984 Analysis of Survival Data  Chapman & Hall. London  Cressie, N. A. 1993 Statistics for Spatial Data John Wiley Sons. 900pp  Duchesne, T. 2005. Regression models for reliability given the usage accumulation history. In "Modern Statistical and Mathematical Methods in Reliability". Edited by A. Wilson N. Limnios, S. Kelly-McNulty Y. Armijo. pp.29-40. World Scientific, New Jersey  Eleuteri, A., R. Tagliaferri, L. Milano, G. Sansone, D D'Agostino, S. De Placido,  M. Laurentiis. 2003.  Survival analysis and neural networks. Proceedings of the International Joint Conference on Neural Networks, Vol. 4 20-24 July 2003 Page\(s\:2631 - 2636  Ellison, E., L. Linger, and M Longstaff. 1997.  Survivable Network Systems: An Emerging Discipline, Carnegie Mellon, SEI, Technical Report CMU/SEI-97-TR-013, 1997  Fleming, T. R. & D. P. Harrington. 1991. Counting process and survival analysis. John Wiley & Sons. 429pp  Graver, J. and M. Sobel 2005. You may rely on the Reliability Polynomial for much more than you might think Communications in Statistics: Theory and Methods  34\(6\1411-1422  Graves, T. and M. Hamada. 2005. Bayesian methods for assessing system reliability: models and computation. In Modern Statistical and Mathematical Methods in Reliability". Edited by A. Wilson, et al. pp.41-53  Grimmett, G. 2006 The Random-Cluster Model Springer  Grimmett, G. 1999 Percolation Springer  Hougaard, P. 2000. Analysis of Multivariate Survival Data Springer. 560pp  Ibrahim, J. G., M. H. Chen and D. Sinha. 2005. Bayesian Survival Analysis.  Springer. 481pp  Jin Z. 2005. Non-proportional semi-parametric regression models for censored data. In "Modern Statistical and Mathematical Methods in Reliability". Edited by A. Wilson N. Limnios, S. Kelly-McNulty, Y. Armijo. pp.279-292 World Scientific  Kalbfleisch, J. D. & R. L. Prentice. 1980 The Statistical Analysis of Failure Time Data John Wiley & Sons.  New York. 1980  Kalbfleisch, J. D. &  R. L. Prentice, 2002. The Statistical Analysis of Failure Time Data.  Wiley-InterScience, 2nd ed 462pp  Lisboa, P. J. G. and H. Wong. 2001. Are neural networks best used to help logistic regression? Proceedings of International Joint Conference on Neural Networks, IJCNN 01. Volume 4, 15-19,  July 2001. Page\(s\:2472 - 2477 vol.4  Kauffman, R. J. and B. Wang. 2002. Duration in the Digital Economy. Proceedings of th e 36th Hawaii International Conference on System Sciences \(HICSS03\ Jan 2003  Kaplan, E. L. & P.  Meier.  1958.  Nonparametric estimation from incomplete observations J. Amer. Statist. Assoc  53:457-481  Klein, J. P. and P. K. Goel 1992. Survival Analysis: State of the Art.  Kluwer Academic Publishes. 450pp  Klein, J. P. and  M. L Moeschberger. 20 03. Survival analysis techniques for ce nsored and truncated data Springer  Krings, A. and Z. S. Ma. 2006.  "Fault-Models in Wireless Communication: Towards Survivable Ad Hoc Networks MILCOM 2006, Military Communications Conference, 2325 October, 7 pages, 2006  Krings, A. W. 2008.  Survivable Systems.  in Information Assurance: Dependability and Security in Networked Systems Yi Qian, James Joshi, David Tipper, and Prashant Krishnamurthy, Morgan Kaufmann Publishers. \(in press  Lawless, J. F. 1982. Statistical models and methods for lifetime data.  John Wiley & Sons. 579pp  Lawless, J. F. 2003. Statistical models and methods for lifetime data.  John Wiley & Sons. 2nd ed. 630pp  Li, M. and P. Vitanyi. 1997. Introduction to  Kolmogorov Complexity and Its Applications. 2nd ed, Springer  Ma, Z. S. 1997.  Survival analysis and demography of Russian wheat aphid populations.  Ph.D dissertation, 307pp University of Idaho Moscow, Idaho, USA 


 20 Ma, Z. S., and E. J. Bechinski. 2008.  Developmental and Phenological Modeling of Russian Wheat Aphid Annals of Entomological Soc. Am In press  Ma, Z. S. and A. W. Krings. 2008a. The Competing Risks Analysis Approach to Reliability Survivability, and Prognostics and Health Management.  The 2008 IEEEAIAA AeroSpace Conference. BigSky, Montana, March 18, 2008. \(In Press, in the same volume  Ma, Z. S. and A. W. Krings 2008b. Multivariate Survival Analysis \(I\e Shared Frailty Approaches to Reliability and Dependence Modeling. The 2008 IEEE-AIAA AeroSpace Conference. BigSky Montana, March 1-8, 2008 In Press, in the same volume  Ma, Z. S. and A. W. Krings. 2008c. Multivariate Survival Analysis \(II\ Multi-State Models in Biomedicine and Engineering Reliability. 2008 IEEE International Conference on Biomedical Engineering and Informatics BMEI 2008\27th-30th, 2008 Accepted   Mani, R., J. Drew, A. Betz, P. Datta. 1999. Statistics and Data Mining Techniques for Lifetime Value Modeling ACM Conf. on Knowledge Discovery and Data Mining  Mazzuchi, T. A., R Soyer., and R. V Spring. 1989. The proportional hazards model in reliability. IEEE Proceedings of Annual Reliability and Maintainability Symposium pp.252-256  Meeker, W. Q. and L. A. Escobar. 1998. Statistical Methods for Reliability Data. Wiley-Interscience  Munson, J. C. 2003. Software Engineering Measurement Auerbach Publications  Nelson, W. 1969. Hazard plotting for incomplete failure data J. Qual. Tech 1:27-52  Nakagawa, T. 2006.  Shock and Damage Models in Reliability Theory. Springer  Osborn, B. 2005. Leveraging remote diagnostics data for predictive maintenance.   In "Modern Statistical and Mathematical Methods in Reliability". Edited by A. Wilson N. Limnios, S. Kelly-McNulty, Y. Armijo. pp. 353-363  Pena, E. A. and E. H. Slate. 2005. Dynamic modeling in reliability and survival analysis. In "Modern Statistical and Mathematical Methods in Reliability". Edited by A. Wilson N. Limnios, S. Kelly-McNulty, Y. Armijo. pp.55-71  Reineke, D. M., E. A. Pohl, and W. P. Murdock. 1998 Survival analysis and maintenance policies for a series system, with highly censore d data.  1998 Proceedings Annual Reliability and Maintainability Symposium. pp 182-188  Schabenberger, O. and C. A. Gotway. 2005. Statistical Methods for Spatial Data Analysis.  Chapman & Hall/CRC  Severini, T. A. 2000. Likelihood methods in statistics Oxford University Press  Shooman, M. L. 2002. Reliability of Computer Systems and Networks: Fault Tolerance, Analysis and Design. John Wiley and Sons. 551pp  Stillman, R. H. and M. S. Mack isack, B. Sharp, and C. Lee 1995. Case studies in survival analysis of overhead line components. IEE Conferen ce of the Reliability and Distribution Equipment. March 29-31, 1995. Conference Publication No. 406. pp210-215  Therneau, T. and P. Grambsch. 2000 Modeling Survival Data: Extending the Cox Model Springer  Wilson, A.  N. Limnios, S Kelly-McNulty, Y. Armijo 2005. Modern Statistical and Mathematical Methods in Reliability. World Scientific, New Jersey  Xie, M. 1991. Software Reliability Modeling. World Scientific Press    B IOGRAPHY   Zhanshan \(Sam\ Ma holds a Ph.D. in Entomology and is a Ph.D. candidate in Computer Science at the University of Idaho. He has published approximately 30 journal and 30 conference papers, mainly in the former field.  Prior to his recent return to academia, he worked as senior network/software engineers in software industry.  His current research interests include reliability and survivability of wireless sensor networks, fault tolerance survival analysis, evolutionary game theory, evolutionary computation and bioinformatics  Axel W. Krings is a professor of Computer Science at the University of Idaho.  He received his Ph.D. \(1993\ and M.S 1991\ degrees in Computer Science from the University of Nebraska - Lincoln, and his M.S. \(1982\ in Electrical Engineering from the FH-Aachen, Germany.  Dr. Krings has published extensively in the area of Computer Network Survivability, Security, Fault-Tolerance and Realtime Scheduling. In 2004/2005 he was a visiting professor at the Institut d'Informatique et Mathmatiques Appliques de Grenoble, at the Institut National Polytechnique de Grenoble, France.  His work has been funded by DoE/INL DoT/NIATT, DoD/OST and NIST 


