The Design of a Correlation Analysis Engine Model Based on Carma_VE Algorithm Zhaoyang Qu Lei Wang School of Information engineering, Northeast Dianli University, Jilin, 132012, China qzywww@mail.nedu.edu.cn  strugglewang@sina.com Abstract SOC \(Security Operation Center\ is the core platform of safety management system, and correlation analysis engine is the core of SOC. This paper designs a correlation analysis engine model. The engine can not only effectively eliminate or reduce duplicate and redundant alerts, but also quickly discover the hidden attack tactics in the huge amount of alerts generated by multi-step attacks. Based on the engine, Carma_VE algorithm is presented in order to automatically generate association rules. Compared with the Carma algorithm, Carma_VE algorithm is more efficient under the smaller training set 1. Introduction SOC is a generic term describing part or all of a platform whose purpose is to provide detection and reaction services to security incidents. According to this definition SOC can be distinguished to five distinct modules: event generators, event collectors message database, and correlation analysis engine and reaction management. In all of these, correlation analysis engine is the most important core component At present, with the increasing large scale of 
network security, SOC is facing the following questions: First, Massive alert events. Second, it is difficult to diagnose problems and loopholes according to alert messages. The number of alerts is so huge that its unimaginable to rely on the artificial analysis to discover the correlation relationship hidden in the isolated mu Therefore, in response to these issues, this paper does the following key research: First, The design of a correlation analysis engine model. Second, Carma_VE algorithm was proposed by improving Carma algorithm. Carma_VE can dramatically enhance the efficiency of association analysis through narrowing mining space, at the same time, it can discover the hidden attack tactics 2. Correlation analysis engine model This paper designs a correlation analysis engine model, as shown in figure 1, mainly includes the following four modules: events standardization module event filtering module, event merging module and correlation analysis module. Besides include merging rules repository, filtering rules repository, triggering conditions repository and association rules repository  
        
  
  Figure 1. The structure of Correlation analysis engine model Fund Project: Grants of Jilin Provincial Technology Development p rojec t No.20080322\Science and Technology Education research project of  Jilin Provincial Department of Education   \(2008 \(41 _____________________________ 978-1-4244-3930-0/09/$25.00 ©2009 IEEE 


2.1. Events standardization module Main function: different kinds of data gathered from various heterogeneous devices have to be formatted into a standardŽ manner. Through the reference of IDMEF standard, formatted structure of original message is the following table 1 Table 1. Formatted message structure Field Attributes Description evt_id unique Unique message ID alert_id Not null Intrusion type ID src_add Not null Intrusion source host address src_port Intrusion source port number des_add Not null Intrusion target host address des_port Intrusion target port number region_id Not null Unique region id timestamp Not null Time of Intrusion happened 2.2. Events filtering module Main function: the removal of the original noise data, such as, the alarm information is not complete lack of IP address or port number and other important information. In the collection of events, let filter some specific alter events according to the filter repository rule and the definition of template, thereby reducing the number of events that the management server must process, as well as, enhancing the effectiveness and efficiency of handling events 2.3. Events merging module Main function: to merge alarm events so as to shrink the mining space for correlation analysis. As a result of a huge number of alarm event logs be included in SOC such as the IDS log \(per second can produce hundreds or even thousands of incidents which contains a large number of duplicate and redundant information, these information for the correlation analysis of events does not have any value   According to the behavioral character, time character and location character of network intrusion events, alert events are divided into three types: First Repeat event refers to a number of alarms are triggered by only an attack, such as an IP Port scan \(scan Second, Redundancy event refers to frequently alarms for a certain type of attack in a very short period of time, such as SYN flood, many different  forged Ip concurrently connect with an attack target; Third Concurrent event refers to many different geographical position of IP attack the same target synchronously such as DDOS attack , a serious threat at present Figure 2 gives an events sample of meeting the first type of merging policy \(Repeat event all the events is 14. In accordance with the merging rule, six events will be merged to generate a super-alert In this super-alert record, evt_all_id contains all the merged evt_id numbers; timestamp_range represents the time range of  attack taking place; merge_counts describes the total number of merging original alert event, the greater the value indicates that the greater the possibility of successful invasion Figure 2. Example of merging alert events 2.4. Correlation analysis module Main function: the module was built based on the Carma_VE algorithm. It can effectively narrow mining space and limit the length of the sequence of frequent besides can support dynamic, real-time mining of association rule for alarm events. Thus achieved two main function, First, automatic learning and autoupdate of association rules repository. Carma_VE is able to accurately mine the frequent sequences hidden in a variety of attack. Second, by taking advantage of mined frequent sequences, the model can generate strong association rules to achieve early warning function Here is an example of correlation analysis about alert events. Set Min_Support = 50%, Min_Confidence 50 First step, through correlation analysis for the former 15 alert events in the Figure4, lets get a strong association rules form. Precede presents the precondition of attack sequence, and Consequent presents the final result caused by the attack sequence as shown in Figure 3 Figure 3. Strong association rule form 


Second step, when collecting the 16th incident according to the existing rule t the attacker will do the Udp flood attack in the next step. This forecast has 100% confidence. As shown in Figure 4 eardrop Udp flood  Figure 4. Example of attack warning 3. Carma_VE algorithm description Carma_VE algorithm is proposed based on the Carma algorithm. Carma would be able to dig out all the frequent sequence set in compliance with the threshold of Min_Support and Min_Confidence through scanning twice in the database transaction set It can be divided into two phases: Phase I, to find out all the frequent itemsets which enough to content Min_Support. Phase II, to generate strong association rules from all the frequent itemsets. These rules must be able to content   Min_Support and Min_Confidence Carma_VE mainly improve the Phase I of Carma in the following two aspects On the one hand, according to the Apriori important properties "The all nonempty subsets of a frequent itemset mu frequent sequences is n, the frequent itemset will contain 2 frequent items. Therefore in dealing with massive data, the frequent sequence length will seriously affect the speed of the algorithm 1 n  Based on in-depth study of attacks in the network security, a successful invasion usually contains the following five steps, Hidden IP address=>Footprinting and Scanning=>Access to the system or administrator privileges => Cultivation of back door=> Stealth in the network. According to this characteristic, to limit the length of itemset v which will be inserted into a frequent itemset collection V in Phase I  Set the longest frequent attack sequence's length is 5, that is  5 v  On the other hand, as is well known, the important conclusion of Association Rule, "Support of a itemset is However, Carma did not take full advantage of the conclusion in Phase I. Observed the execution, we can find that if a itemset v contained k elements is inserted into frequent itemset collection V, it would at least going through k times transactions,. The condition of inserting is following [6      i w v w V and firstTrans w i and maxSupport w      According to the above analysis, the condition that v is inserted into V can be weakened by preferable using the important conclusion. Just to check all the proper subset w in v at first, the number of elements in w only smaller one than the number in v. The inserting condition can be changed     1     i w v w v and w V and firstTrans w i and maxSupport w        The Pseudocode of Phase I in the Carma_VE algorithm is following Input  at tack sequence in database 12     n Ttt t   support sequence 1 2     n    Output:V the freq uent itemsets collection i i Begin V  maxMissed\(v\:=0;firstTrans\(v\:=0;count\(v\:=0 for i from 1 to n 1\Increment for all v V with v t count\(v  2\Insert for all v t and |v 5 with     i vV if w v: |w|=|v|-1 and w V and firstTrans\(w\<i and maxSupport\(w then V:=V v   012     i-1 1 firstTrans\(v\i count\(v\:=1 maxMissed\(v\:=min i-1\avg   v|-1 maxMissed i       i w\+count\(w\-1 |w v  if |v|= =1 and maxSupport\(w then V:=V v};firstTrans\(v  i maxMissed\(v\:=0  3     i i rune if\(i % max{[1  5 0 0    0  th e n V:={v V|maxSupport\(v or |v|= =1  return V End    


4. Experiment and Analysis Taking these two Experimental results we can see Carma_VE algorithm enhance the overall efficiency of association rule mining, as a result of it limit to the subset length of current transaction and optimize the condition that itemset v is inserted to frequent itemset collection V C a rma and Carma_VE algorithms were achieved by using Java Data Mining API. And then the performance was compared through experiments. The experimental data was collected in a week's invasion alarm events of the campus network. A total of data is 5000 \(TD=5000 5. Conclusion Experim ent 1: In the condition of the same number of transaction events \(TD = 5000\and the different support, to compare the execution time of two algorithms. As shown in figure 5, the result demonstrate that the smaller with the support, the longer consumed Carma algorithm for the implementation, but the time growth rate of Carma_VE algorithm for the implementation required much lower than the Carma Accordi ng t o the features of SOC, designed and implemented a correlation analysis engine model based on Carma_VE algorithm. The engine model has filtering, merging, correlation analysis and early warning functions, so as to significantly improve the efficiency of mining time, achieve real-time analysis for the massive alarm events and forecast the next step of attacker. The engine has already been used in the practical project and has a good effect in application  Figure 5. Experimental result 1 6. References   R Bidou, Security Operation Center Concepts ImplementationŽ, http://www.iv2-technologies.com, 2008  Y.A Ny gate Event corre lation using rule and object based techniques Proceedings of the fourth international symposium on Integrated network management IV Chapman Hall, 1995, pp. 278-289  S. Cheung, U. Lindqvist  and M Fong Modeling Multistep Cyber Attacks for Scenario Recognition Proc DARPA Information Survivability Conf. and Exposition DISCEX III Apr.2003, pp.284-292 Experi m ent 2: In the condition of the same Support Support=0.5%\and different numbers of transaction event, to compare the execution time of two algorithms As shown in figure 6,  the result demonstrate that with a growing number of event, the execution time would constantly increasing, but the growth rate of Carma_VE  algorithm was more slower  P. Ning, Y. Cui, and D Reeves, Constructing attack scenarios through correlation of intrusion alerts The 9th ACM Conf on Computer and Communications Security  ACM, 2002, pp.245-254   Jiawei Han, M. Kam ber Data Mining Concepts and Techniques Second Edition Mechanical industry press, 2007  C. Hidber Online Association Rule Mining Proceedings of the 1999 ACM SIGMOD international conference on Management of data ACM, June 1999 pp.145-156 Figure 6. Experimental result 2 


for captures the contents of each batch of streaming transactions containing uncertain data\321one batch at a time\321in the UF-tree from which O in a batch All O captures the contents of each batch of transactions in the UF-tree from which O and its 322extensions\323 to 336nd constrained 322frequent\323 itemsets containing and against each domain item one at a time and stops as soon as it 336nds the 336rst valid item attr const attr X.attr const attr X.attr const attr because all remaining items  322frequent\323 itemsets are found All these O  The algorithm only needs to form a projected DB for each  from leaves to the root if 002p e.g attr attr attr attr CUF-streaming     1 0,1 from t he 336nds constrained FIs from uncertain data streams it checks constraints in a post-processing step As a result it wastes lots of space as it stores both valid as well as invalid itemsets in the UF-stream structure Here we propose another algorithm\321called 322frequent\323 itemsets where constraint selectivity 322frequent\323 domain items  domain items are arranged in non-descending order 1 005 005 005 005 005 values such that invalid items come before/below valid items in the UF-tree For instance if values i.e 1 1 1 1 1 2 2 1    i.e if 321which pushes the user-speci\336ed constraints inside the mining process and explores the properties of these constraints Speci\336cally when a batch of streaming transactions containing uncertain data 337ows in the algorithm inserts items in each transaction into the UF-tree in which items are arranged according to some order item valid item e C C p p m p w w p p 002 w x x x x x X C C C C x x x C x C    n 002 005 006 013 005 013 005  006 m i i i i v v j v j k k projected DB for selected k<v  By doing so the algorithm checks 212 Thismining process is repeated for the remaining selected 322frequent\323 domain items Unlike UF-streaming 1 expSup Example 2 expSup constrained 2 1 0 It then forms projected DBs for  322frequent\323 itemsets are found where  322frequent\323 valid as well as invalid itemsets from the  Afterwards the algorithm forms projected DBs for  Revisit the uncertain data stream in Example 1 With our proposed UF-streaming     0 c a n be prune d t hi s re s ul t s i n s i x node s in the structure Finally as a post-processing step the algorithm checks the 322frequent\323 itemsets stored in the FP-stream structure against the aggregate constraint  are guaranteed to be valid due to  then all supersets a c algorithm only valid itemsets are stored in the UF-stream structures See Fig 2 cf Fig 1\(b  c Some memory space is saved as each UF-stream structure consists of only four instead of eight or nine nodes and 336nd only 2.43 depending on the type of constraints Here the new transaction is merged with a child or descendant node of the root of the UF-tree only if the same  our proposed CUF-streaming algorithm does not need to form projected databases for all itemsets domain items or their extensions as CUF-streaming explores the property of constraints Thus only some itemsets are selected to check against the constraints and only some itemsets are selected to form projected DBs during the mining process The selection depends on the type of constraints T YPE I A NTI MONOTONE C ONSTRAINT Let denote an attribute of an itemset denote a constant Our proposed CUF-streaming algorithm arranges domain items in a monotonic increasing or decreasing order of of of violates structure to make room for the third batch The resulting UF-stream structure as shown in Fig 1\(c captures the expected support values for 322frequent\323 itemsets found in the second and third batches Note that nodes with zero expected support such as 2.6 2.4 and 3.7 satisfying domain items Note that the size of the UF-tree is bounded above by the number of is the window size IV UFSTREAMING  itemsets are    exists in both the transaction and the child or descendant nodes The occurrence count of a node is at least the sum of occurrence counts of all its children nodes Once the UF-tree is constructed CUF-streaming recursively mines 322frequent\323 itemsets from the tree in a depth\336rst divide-and-conquer manner The algorithm 336rst 336nds some and its extensions to 336nd constrained 322frequent\323 itemsets containing or UF-streaming is of the form is of the form  are invalid due to the antimonotonicity of 124 a b c  i x x i x x j j x Analytically UF-streaming most recent batches are stored in the UF-stream structure where Analytically UF-streaming most recent batches are stored in the UF-stream structure V C U F STREAMING E XPLORING C ONSTRAINTS WHEN M INING C ONSTRAINED F REQUENT I TEMSETS FROM U NCERTAIN D ATA S TREAMS Along this direction we propose the third algorithm\321called  because any itemsets that can be f ound in values i.e x x x      R R R 013 006 R 013 005 R  max min C HECKING C ONSTRAINTS E ARLY WHEN M INING C ONSTRAINED F REQUENT I TEMSETS FROM U NCERTAIN D ATA S TREAMS Although UF-streaming   2 3 4   c[1.35,0.9  b[1.6,1.4 c[1.5,1.8 a UF-stream for 322frequent\323 itemsets found in the 1st  2nd batches    c[0.9,1.53  b[1.4,1.0 c[1.8,1.9 b UF-stream for 322frequent\323 itemsets found in the 2nd  3rd batches Fig 2 The UF-stream structures for Example 2 then checked against the user-speci\336ed constraints and only O    items are arranged in non-ascending order UF-streaming 321which performs constraint checking as an intermediate step instead of a post-processing step Speci\336cally the algorithm 336rst uses the same UF-growth mining technique to 336nd all 322frequent\323 itemsets and it then checks the mined itemsets against userspeci\336ed constraints before storing the constrained itemsets in the UF-stream structure By doing so the UF-stream structure stores only valid itemsets See Example 2 267\267\267 


002p 002p     1         1     v<h p 006 212 006 006 212 212 212 006 006 212 212 006 It forms projected DBs for valid items i.e v<h c a   b c in the UF-tree For instance if R R R R  R R R R R R R R 006 R      p 005 005 005 2  3     4  1  1 1 also satisfy 125 min 1    max 005 005 5 batches and each batch to contain 1M transactions In addition to this dataset we also conducted the following experiments using some other datasets including UCI real-life datasets as well as FIMI datasets The observations or trends were consistent 002 p X X X X  are guaranteed to be invalid due to projected DB where where  Note that instead of checking all as in UF-streaming  CUF-streaming only needs to check O  Again CUF-streaming only needs to check O  However 322frequent\323 itemsets found in these projected DBs need to be checked against if  the algorithm only needs to check sum sum sum sum for for for for  items are arranged in non-ascending order j j j j j 2 2 e d c b a e d n n  r j is of the form  the algorithm only needs to form projected DBs for itemsets satis\336es such that valid items come before/below invalid items in the UF-tree For instance if is of the form is of the form value items are arranged in non-descending order is of the form is of the form  items are arranged in non-descending order until it 336nds the 336rst invalid item  All remaining items domain items and ii  items where  CUF-streaming also stores only valid itemsets in the UF-stream structure Unlike UF-streaming  until it 336nds the 336rst valid item 1.5 1.6 1.8 as well as their 322extensions\323 No more constraint checking is needed as any 322frequent\323 itemsets found in the projected DBs of valid items and their 322extensions\323 are guaranteed to be valid due to anti-monotonicity of in the UF-stream structure Same approach is then applied to the second batch and results in the same UF-stream structure as shown in Fig 2\(a Afterwards CUF-streaming applies the same approach to the third batch this results in the same UF-stream structure as shown in Fig 2\(b  From the 322frequent\323 itemsets against are guaranteed to be valid further constraint checking is needed for 322extensions\323 of the  from leaves to the root The algorithm then checks  322Frequent\323 itemsets found in these projected DBs are guaranteed to be valid due to the anti-monotonicity of  322Frequent\323 itemsets found in these projected DBs are guaranteed to be valid due to the monotonicity of  Unlike the procedures for other three types of constraints the algorithm forms projected DBs for 322extensions\323 of of Type III or IV having selectivity   the algorithm forms projected DBs for itemsets  are guaranteed to be invalid due to  then all supersets of values from leaves to the root if as not all of them are valid By exploring the convertible anti-monotonicity of  domain items are arranged in non-ascending order values from leaves to the root if is an itemset with non-positive is an itemset with non-negative is a Type I constraint So when the 336rst batch of transactions from uncertain data stream 337ows in our proposed CUF-streaming algorithm arranges domain items in ascending order of also violate  domain items where of of the form of  domain items are arranged in non-descending order of  domain items against of or of values By doing so the algorithm checks violates  then all 322extensions\323 of also violate of of values By doing so the algorithm checks each domain item against  All 322extensions\323 of a valid of WBC counts i.e items due to convertible monotonicity of re guaranteed to be invalid due to gainst    invalid e.g e.g e.g gainst items because some of these 322extensions\323 may be valid With i i.e if as all remaining items and UF-streaming 006  T YPE II M ONOTONE C ONSTRAINT  CUF-streaming arranges domain items in a monotonic decreasing or increasing order  T YPE III C ONVERTIBLE A NTI MONOTONE C ON STRAINT  Like Type II CUF-streaming arranges domain items in  The mined 322frequent\323 itemsets that satisfy one of the above four types of constraints are then stored in the UF-stream structure Afterwards CUF-streaming handles subsequent batches of streaming transactions of uncertain data in a similar fashion Like UF-streaming  006    1.35 CUF-streaming then stores all four constrained 322frequent\323 itemsets 006 005 006 005 attr attr attr attr  0,1 CUF s t re a m i n g c he c k s O    k v v i m h h v v i v v h h v h h m items as well as avg avg a c a c 1  n n  j j j 005 006 006 VI E XPERIMENTAL R ESULTS We used different datasets for experimental evaluation For space limitation we reported here the experimental results on a dataset generated by the program developed at IBM Almaden Research Center T hi s da t a s e t c ont a i ns 10M re c ords w i t h an average transaction length of 10 items and a domain of 1,000 items We assigned an existential probability from the range 0,1 t o each i t em i n each t r an s act i o n  W e s et t h e window size to be  005 013 013 013  For each values such that values from leaves to the root if against each domain item until it 336nds the 336rst invalid one  For each against each domain item until it 336nds the 336rst invalid one  Again projected DBs are formed only for the valid items against each item in the projected DB until it 336nds the 336rst invalid one T YPE IV C ONVERTIBLE M ONOTONE C ONSTRAINT  Again CUF-streaming arranges domain items in such that valid items come before/below invalid items in the UF-tree For instance if against each domain item in the UF-tree i.e attr X.attr const attr X.attr const attr X.attr const const attr attr X.attr const const attr attr const attr const attr because all remaining items values By doing so the algorithm checks value domain items are arranged in non-ascending order 1 r x C x x Y x C O C m m C C C C C x x x x Y x C x C x C m C C C X C X C x x x C C X C X C C C C C C x x C X m C 002 m C C C c c b a C w f  f  i v 005     CUF-streaming mines constrained 322frequent\323 itemsets more effectively as it pushes the constraint inside the mining process and explores properties of the constraint Revisit the uncertain data stream in Example 1 r i>v items While further constraint checking is unnecessary for 322extensions\323 of the Example 3 valid items come before/below invalid items valid valid invalid Y Y 


preMinsup Fig 3 Experimental results runtimes All experiments were run in a time-sharing environment in an 800 MHz machine The reported 336gures are based on the average of multiple runs Runtime includes CPU and I/Os it includes the time for both tree construction and frequent itemset mining steps We evaluated different aspects of the proposed algorithms which were implemented in C First we compared the performance of the three proposed algorithms using four different constraints one from each type of the above constraints Experimental results showed that the runtimes for both UF-streaming 100   150   200   250   10   20   30   40   50   60   70   80   90  Selectivity \(i.e., percentage of items selected CUF-streaming \(w=5 batches, each with 1M transactions Type IV constraint C4  Type II constraint C2                      Type III constraint C3                      Type I constraint C1                                 100   150   200   250   300   350   400   450   10   20   30   40   50   60   70   80   90  Selectivity \(i.e., percentage of items selected CUF-streaming \(w=50 batches, each with 1M transactions Type IV constraint C4  Type II constraint C2                      Type III constraint C3                      Type I constraint C1                                 50   55   60   65   70   75   80   85   90   0.002   0.003   0.004   0.005  preMinsup \(in percentage Runtime vs. existential probability & preMinsup Items take on an average number of existential probability values                      005 005    t t 327 327 005 items All 322extensions\323 of valid items were valid Due to the item ordering the algorithm stopped checking constraints whenever it detected the 336rst invalid items However for on the mining results For example using 0.8 C C C C C C C C C C w w C C w 0.9 preMinsup  90 of the mined constrained 322frequent\323 itemsets were truly frequent When and UF-streaming Asitexplored properties of these four constraints and pushed the constraints inside the mining process CUF-streaming required shorter runtimes than the other two algorithms As shown in Fig 3\(a the runtimes for handling all four types of constraints increased when the selectivity increased Among them a Runtime vs selectivity  a Type I constraint incurred the lowest runtime among the four types of constraints because CUF-streaming formed fewer 322extensions\323 as they consisted of only valid items Again due to the item ordering the algorithm stopped checking constraints whenever it detected the 336rst valid items Next we repeated the above experiment with a different the window size was low say 10 only a few small UF-trees were constructed and mined as the algorithm only 322extended\323 valid items and a shorter runtime 50 c Runtime vs  and the convertible monotonicity of  the monotonicity of  the convertible anti-monotonicity of 110 sec cf 160 sec in Fig 3\(a was required As another example for 5 batches when  the algorithm applied constraint checking on projected DBs for valid items as well as their 322extensions\323 because not all 322extensions\323 of valid items were valid  the algorithm 322extended\323  many bigger UF-trees were constructed and mined as the algorithm formed projected DBs for both valid as well as invalid domain items which took or having more batches in the sliding window had the bene\336ts of increasing the chance of not pruning relevant expected support information for truly frequent itemsets Moreover as shown in Fig 3\(c when increased fewer itemsets had expected support performed constraint checking as an intermediate step prior to storing the 322frequent\323 itemsets into the UF-stream structure In contrast CUF-streaming was more interesting as it runtimes depended on the type of constraints as well as the constraint selectivity Speci\336cally the algorithm explored the anti-monotonicity of a Type II constraint and a Type III constraint incurred the next two highest runtimes For  and thus shorter runtimes were required The 336gure also showed the effect of the distribution of item existential probability When items took on a few unique existential probability values the UF-tree b ecame smaller Thus times for both UF-tree construction and mining became shorter In addition we also measured the number of nodes in each UF-tree The experimental results showed that the total number of nodes in a UF-tree was no more than the total number of items with their existential probability in all transactions in the current batch of uncertain data stream Furthermore we measured the number of nodes in the UF-stream structure as well As UF-streaming   126 400 sec cf 230 sec in Fig 3\(a As all three algorithms are approximate algorithms we evaluated the effect of  95 of the mined constrained 322frequent\323 itemsets were truly frequent However lowering 5 b Runtime vs selectivity  were constant regardless of the constraint selectivity because these two algorithms did not explore property nor did they push the constraints inside the mining process Speci\336cally UF-streaming only valid preMinsup minsup preMinsup minsup preMinsup preMinsup preMinsup performed constraint checking as a postprocessing step whereas UF-streaming a Type IV constraint incurred the highest runtime because CUF-streaming 322extended\323 i.e formed projected DBs for both valid and invalid items performed constraint checking at a post-processing step the size of UF-stream was observed to be independent of the constraint selectivity In contrast as Items take on many different existential probability values  50 336xed-sized batches with each batch containing 0.1M transactions instead of using 5 336xed-sized batches with each batch containing 1M transactions With this setting each batch was smaller 0.1M vs 1M transactions Thus each batch required lower runtime e.g for constructing and mining UF-trees However the number of batches was higher 50 vs 5 batches than the previous setting This explains why the runtimes see Fig 3\(b took on a broader range than the previous experimental results For example when the selectivity of 1 2 3 4 4 2 3 2 3 1 2 4 w w 0   Runtime \(in seconds 0   Runtime \(in seconds 0   Runtime \(in seconds Items take on a few unique existential probability values                     50   50   0.001   


 ch 6 AAAI/MIT Press 2004  G  G r ahne L  V  S  L aks h m a nan and X  W ang 322E f 336 ci ent m i n i n g o f constrained correlated sets,\323 in ACM TKDD  Proc KDD 2009 Proc VLDB 1994 Proc KDD 2009 Proc IEEE ICDE 2008 Proc PAKDD 2007 Proc VLDB 2008 Proc IEEE ICDE 2000 Proc VLDB 2008 Proc IEEE ICDE 2009 Proc IEEE ICDM 2006 Proc IEEE ICDE 2002 Proc IEEE ICDE 2001 Proc IEEE ICDE 2008 preMinsup minsup Proc U  09 Proc PAKDD 2008 Proc ACM SIGMOD 2008 Data Mining and Knowledge Discovery Proc ACM SIGMOD 1993 Proc SSTD 2005 Proc ACM SIGMOD 2000 Proc ACM SIGMOD 2009 Proc ACM SIGMOD 1998 Proc ACM SIGMOD 2008 2 pp 18\32026 June 2005 12 C G ia n n e lla e t a l 322 M in in g f r e q u e n t p a tte r n s in d a ta s tr e a m s a t m u ltip le time granularities,\323 in 4 pp 337\320389 Dec 2003  C  K  S  L eung 322F r e quent i t e m s et m i ni ng w i t h cons t r ai nt s  323 i n 127 1 batch containing the entire dataset Then we compared our algorithms with UF-growth 22 b y as s i g n i n g t o each i t em i n e v er y t r an s act i o n in a dataset an existential probability of 1 i.e all items are de\336nitely present in the dataset and 005 005 Encyclopedia of Database Systems queries on uncertain streams,\323 in 34 28 34  pp 29\32037 2 R  A gr aw al et al   322M i n i n g a s s o ci at i o n r ul es bet w een s e t s of i t e ms i n large databases,\323 in  pp 207\320216 3 R  A gr aw al and R  S r i kant  322 F a s t al gor i t h ms f o r m i n i n g a s s o ci at i o n rules,\323 in  pp 487\320499 4 R  J  B ayar do J r   R  A g r a w a l  and D  G unopul os  322 C ons t r ai nt b as ed rule mining in large dense databases,\323 2\3203 pp 217\320240 July 2000 5 T  B e r n e c k e r e t a l 322 P r o b a b ilis tic f r e q u e n t ite m s e t m in in g in u n c e r ta in databases,\323 in  pp 119\320127 6 R  C h e n g e t a l 322 P r o b a b ilis tic v e r i\336 e r s  e v a lu a tin g c o n s tr a in e d n e a r e s tneighbor queries over uncertain data,\323 in  pp 47\32058 8 G  C or m ode and M  H adj i e l e f t her i ou 322F i ndi ng f r e quent i t e m s i n dat a streams,\323 in  pp 1530\3201541 9 G  C o r m o d e e t a l 322 F in d in g h ie r a r c h ic a l h e a v y h itte r s in s tr e a m in g d a ta  323  pp 400\320417  M M G a ber  A  B  Z a s l a v s k y  and S  K r i s hnas w am y  322Mi n i n g d at a streams a review,\323  pp 512\320521  J  H a n J  P e i  and Y  Y i n  322 Mi ni ng f r e quent pat t e r n s w i t hout candi dat e generation,\323 in  pp 1\32012 15 J  H u a n g e t a l 322 M a y B M S  a p r o b a b ilis tic d a ta b a s e m a n a g e m e n t s y s tem,\323 in  pp 1071\3201074  C  J i n e t a l   322 S l i di ngw i ndo w t op pp 301\320312  L  V  S  L a ks hm anan C  K  S  L e ung and R  T  N g 322E f 336 ci ent dynam i c mining of constrained frequent sets,\323  pp 9\320 18  C  K  S  L eung and B  H ao 322 Mi ni ng of f r e quent i t e m s et s f r o m s t r eam s of uncertain data,\323 in  pp 1663\3201670  C  K  S  L eung and Q  I  K han 322D S T r ee a t r e e s t r uct u r e f o r t he m i ni ng of frequent sets from data streams,\323 in  pp 928\320 933  C  K  S  L eung M A  F  Mat e o and D  A  B r a j czuk 322 A t r eebas e d approach for frequent pattern mining from uncertain data,\323 in  pp 13\320 24  J  P e i  J  H a n and L  V  S  L aks h m a nan 322Mi n i n g f r e quent i t e m s et s w i t h convertible constraints,\323 in  pp 433\320442  C  R 253 e et al 322Event queries on correlated probabilistic streams,\323 in  pp 715\320728 27 A  D  S a r m a  M  Th e o b a ld  a n d J  W id o m  322 Ex p lo itin g lin e a g e f o r con\336dence computation in uncertain and probabilistic databases,\323 in  pp 1023\3201032  K  Y i et al   322S m a l l s ynops es f o r g r oupby quer y ver i 336 cat i o n o n outsourced data streams,\323  pp 819\320832 322frequent\323 itemsets from uncertain data streams In terms of ef\336ciency the experimental results showed that UF-streaming was slightly faster because it did not perform any constraint checking whereas our three proposed algorithms performed the extra constraint checking step Among them CUF-streaming only performed constraint checking on some 322frequent\323 itemsets and the other two performed constraint checking on all 322frequent\323 itemsets However in terms of the mining results we observed that all four algorithms returned the same collection of 322frequent\323 itemsets This illustrated that our proposed algorithms could be used for mining unconstrained frequent itemsets from uncertain data streams Moreover it is important to note that while the UF-streaming is con\336ned to 336nding 322frequent\323 itemsets satisfying constraints with 100 selectivity our algorithms are capable of 336nding 322frequent\323 itemsets that satisfy constraints having lower selectivity Along this direction we set and CUF-streaming both pushed the constraint early the corresponding size of UF-stream was proportional to the selectivity of constraints Finally we evaluated the functionality and applicability of our proposed algorithms We again used four different constraints and we also set the constraint selectivity be 100 i.e all items are selected Then we compared our three proposed algorithms with UF-streaming  w hi c h w a s designed to mine 1 UF-streaming 4 article 2 Jan 2008 10 X  D a i e t a l 322 P r o b a b ilis tic s p a tia l q u e r ie s o n e x is te n tia lly u n c e r ta in data,\323 in 3 article 15 Aug 2009 29 Q  Zh a n g  F  Li a n d K  Y i 322 F in d in g f r e q u e n t ite m s in p r o b a b ilis tic data,\323 in  pp 1179\3201183 Springer 2009  C  K  S  L eung and D  A  B r a j czuk 322E f 336 ci ent a l gor i t h m s f o r m i n i n g constrained frequent patterns from uncertain data,\323 in Data Mining Next Generation Challenges and Future Directions w  UF-streaming unconstrained and CUF-streaming\321 which integrate i mining of uncertain data ii constrained mining and iii mining of data streams These algorithms effectively mine constrained frequent itemsets from uncertain data streams A CKNOWLEDGMENT This project is partially sponsored by Natural Sciences and Engineering Research Council of Canada NSERC and the University of Manitoba in the form of research grants R EFERENCES 1 C  C  A ggar w al et al   322F r e quent pat t e r n m i ni ng w i t h uncer t a i n dat a  323 i n  pp 653\320661  C  K  S  L eung R  T  N g  a nd H  Manni l a  322 O S S M  a s e gm ent a t i o n approach to optimize frequency counting,\323 in SIGMOD Record ACM TODS ACM TODS k 4   Again we observed that all four algorithms returned the same collection of frequent itemsets This illustrated that our proposed algorithms could also be used for mining unconstrained frequent itemsets from static uncertain datasets VII C ONCLUSIONS Frequent itemsets generally serve as building blocks for various patterns in many real-life applications Most of the existing algorithms 336nd unconstrained frequent itemsets from traditional static transaction databases consisting of precise data However there are situations in which ones are uncertain about the contents of transactions There are also situations in which users are only interested in some subsets of all the mined frequent itemsets Furthermore a 337ood of data can be easily produced in many situations To deal with all these situations we proposed three tree-based algorithms\321 namely UF-streaming   pp 973\320982 7 C  K  C hui  B  K ao a nd E  H ung 322Mi n i n g f r e quent i t e m s et s f r o m uncertain data,\323 in     pp 583\320592  R  T  N g et al   322E xpl or at or y m i n i n g a nd pr uni ng opt i m i zat i ons of constrained associations rules,\323 in  


              


   


                        





