Ranking Evaluation Functions to Improve Genetic Feature Selection in Content-Based Image Retrieval of Mammograms 003 S 264 ergio Francisco da Silva Agma J M Traina Marcela Xavier Ribeiro Jo 230 ao do E S Batista Neto Caetano Traina Jr Department of Computer Science University of S 230 ao Paulo at S 230 ao Carlos USP f sergio agma mxavier jbatista caetano g icmc.usp.br Abstract The ranking problem is a crucial task in the information retrieval systems In this paper we take advantage of single valued ranking evaluation functions in order to develop a new method of genetic feature selection tailored to improve the accuracy of content-based image retrieval systems We propose to boost the feature selection ability of the genetic algorithms GA by employing an evaluation criteria 002tness function that relies on order-based ranking evaluation functions The evaluation criteria are provided by the GA and has been successfully employed as a measure to evaluate the ef\002cacy of content-based image retrieval process improving up to 22 the precision of the query answers Experiments on three medical datasets containing breast cancer diagnosis and breast tissue density analysis showed that 002tness functions based on ranking evaluation functions occupy an essential role on the algorithms performance obtaining results signi\002catively better than other 002tness function designs The experiments also showed that the proposed method obtains results superior than feature selection based on the traditional decision-tree C4.5 naive bayes support vector machine 1-nearest neighbor and association rule mining 1 Introduction Breast cancer is the second most common type of cancer in women Mammograms are a v aluable tool to the early detection of the disease and may contribute to increase the patient survival rates Due to the decreasing costs of mammographies and storage devices the volume of digital mammograms has grown exponentially The exploration of such data has become of great importance as they normally contain useful information on past cases which can help  003 This work has been supported by FAPESP CNPq and CAPES specialists to retrieve similar cases and also contribute to their analysis task and treatments Content-Based Image Retrieval CBIR refers to the technique to retrieve images based on their content as opposed to textual descriptions In medical domain the objective of a CBIR system is to aid the specialist on diagnosing patients by retrieving relevant past cases with proven pathology along with the associated clinical diagnostic and other information In traditional approaches of CBIR each image in the dataset is represented by a set of feature values the socalled feature vector  which conveys the essence of the image regarding speci\002c criteria Therefore feature vectors can hold one or more sets of features generated by one or more image feature extractors and they are used during the indexing and retrieval process At retrieval the images that are most similar to the query image according to some distance measure e.g Euclidean distance are returned In this context well-suited features are very important to improve the accuracy of similarity queries results For most CBIR applications including medicine it is well-known that a set of image features computed from a single extractor is not usually the most appropriate way of characterizing images However multiple feature extractors usually provide a large number of features many times containing correlated and irrelevant information that deteriorates the ef\002ciency of similarity queries and impairs data mining techniques leading to the dimensionality curse problem Feature selection methods have been proposed in the literature aimed at dealing with the dimensionality curse Feature selection is one of the most important and frequently used preprocessing technique for data mining It reduces the number of features removes irrelevant redundant or noisy data and brings immediate bene\002ts to applications speeds up data mining algorithm improves mining performance such as predictive accuracy and improves results comprehensibility Genetic algorithms GAs have become quite popular due to their ability in dealing with very large search spaces 


 Genetic algorithms 8 were inspired on Darwin s e v olutionary theory 223the better adapted individuals tend to survive transferring their genetic material to the next generation while the less adapted tend to disappear\224 For each problem kind solved by a GA a 002tness function must be supplied and this choice is of crucial importance to maximize the GA's performance Gi v en an indi vidual 050represented as a chromosome\051 the 002tness function must return a numerical value that represents how well adapted the individual is This score will be used in the parents selection and survival selection processes for the next generation thus that the better adapted individuals will have the greater likelihood of being chosen Therefore the 002tness function must be tailored to the problem being dealt with The GA's effectiveness is in a large degree determined by how faithfully the 002tness function characterizes the problem to be optimized To better understand our proposal it is necessary to de\002ne the concepts of similarity query and relevant element A similarity query returns a set of elements ordered according to a similarity measure This order is known as a ranking In this work feature selection is considered a supervised task that uses a set of pre-labeled samples distributed among a set of different classes A relevant element 050an image for example\051 is a sample returned by a query 050regardless of its position in the ranking\051 that belongs to the expected class This work proposes using single valued ranking evaluation functions  henceforth referred to only as ranking evaluation functions  in the design of evaluation criteria for genetic feature selection algorithms in CBIR A ranking evaluation function provides a measure of the quality of a similarity query result This work employs order-based ranking evaluation functions which share the utility concept  The utility of a relevant element is proportional to its position in the ranking i.e the higher its position in the ranking 050more similar\051 the higher its utility If an element is not relevant 050does not belong to the expected class\051 its utility score is set to zero To the best of our knowledge this is the 002rst work using ranking evaluation functions for feature selection Performing feature selection in CBIR using a measure of ranking quality as evaluation criteria is more adequate to evaluate the retrieval effectiveness than the actual approaches that use classi\002cation error class separability or measures of intrinsic information Here we propose to use a measure of ranking quality 050ranking evaluation functions\051 to build 002tness functions for genetic feature selection algorithms Due to space limitations we present results for three medical datasets showing that this new feature selection approach brings superior results when compared to evaluation criteria derived from classi\002cation 050decision-tree C4.5 naive bayes support vector machine 1-nearest neighbor\051 and association rule mining We also show that it considerably increases the precision of the similarity queries while decreasing the number of features selected The cost to train the genetic algorithm is high however it can be done of\003ine since the cost that effectvely counts to the user is the searching one The remainder of this paper is structured as follows Section 2 gives the main concepts concerning this work Section 3 presents related works Section 4 describes the proposed framework for feature selection Section 5 details the experimental evaluation and Section 6 presents the conclusions 2 Background This Section discusses the main concepts necessary to follow this paper 2.1 Feature Selection Feature selection 050FS\051 aims at choosing a reduced number of features that preserves the most relevant information of the dataset Consequently it performs a dimensionality reduction of the dataset Feature selection is usually applied as a preprocessing step in data mining tasks remove irrelevant or redundant features 050dealing also with the curse of dimensionality 051 leading to more ef\002cient and effective classi\002cation clustering and similarity search processes It also diminishes the cost to process the queries as well as the memory required A typical feature selection process consists of four basic steps namely subset generation subset evaluation stopping criterion and result validation Subset generation is a search procedure that produces candidate feature subsets for evaluation based on a certain search strategy Each candidate subset is evaluated and compared with the previous best subsets according to a certain evaluation criterion If the new subset turns out to be better it replaces the previous one The process of subset generation and evaluation is repeated until a given stopping criterion is satis\002ed Then the selected best subset usually needs to be validated by a test dataset In the wrapper feature selection process the evaluation criterium is usually a performance measure of a predetermined mining algorithm Works concerning feature selection for CBIR with the wrapper approach were originally intended to optimize classi\002cation and clustering per formance In our w ork we tak e adv antage of traditional classi\002ers such as 1 nearest neighbor 0501-NN\051 decision-tree 050C4.5\051 Support Vector Machine 050SVM\051 and Naive Bayes 050NB\051 to build FS wrappers These feature selectors are used as baselines for comparison 


Another approach for feature selection is the use of statistical association rules which led to the development of the StARMiner algorithm The goal of StARMiner is to implement statistical association rule mining to 002nd features that best discriminate images into categorical classes It is also employed as a baseline for comparison with our method 2.2 Genetic Algorithms Genetic Algorithms 050GAs\051 8 are based on the principles of biological inheritance and evolution  Each potential solution is called an individual 050i.e a chromosome\051 in a population GAs work iteratively applying the genetic operations of selection crossover and mutation to a population of individuals to create more diverse and better adapted individuals in subsequent generations The 002tness function assigns a 002tness value for each individual and it is known for playing an essential role in genetic evolution Associated with the characteristics of exploitation and exploration search GAs can ef\002ciently deal with large search spaces and hence are less prone to stuck with a local optimal solution than other algorithms This is due to its ability to allow multiple solutions representations 050individuals\051 in the search space and by applying probabilistic genetic operators 2.3 Ranking Evaluation Functions Ranking evaluation functions are measures of the ranking accuracy 050a set of sorted elements according to a similarity measure\051 Ranking evaluation functions belong to two categories order-based and non order-based Non orderbased ranking evaluation functions are measures in which the score of an element in the ranking has a fragile relationship to its position An example is the R precision measure 050percentage of relevant images between the 002rst R in ranking\051 Order-based ranking evaluation functions are based in the utility concept where the score value of a relevant element in the ranking is usually inversely proportional to its position The fact that users would rather see relevant elements appearing in the initial positions of the ranking suggests that order-based ranking evaluation functions are more likely to be successful Various ranking evaluation functions have been proposed in the literature However as far as we know ranking evaluation functions have never been applied to the feature selection domain A ranking evaluation function that presents promising results is F r 050 q C 051  X 8 i 2 I 040 r 050 i 051 1  A 022 050 A 000 1\051  A 023 050 pos 050 i 051 000 1\051  0501\051 where F r 050 q C 051 denotes the score value of the individual C 050given by the chromosome coding explained in the next section\051 for the image query q  I represents the entire image dataset r 050 i 051 returns the relevance of the image i  where r 050 i 051  1 if the image i is relevant for that query q  and r 050 i 051  0 otherwise A is a user-de\002ned parameter with values larger than or equal to 2 It determines the relative importance of the positioning of an element in the ranking position pos 050 i 051  For small values of A  greater importance is given to relevant elements better positioned in the ranking 050i.e those at the initial positions\051 When A takes high values i.e the factor 050 A 000 1\051  A leads to values near 1 the relative position of the elements in the ranking are not strongly re\003ected in the 002nal score value We have set A to 10 which leads to an intermediate behavior of the score value F r 050 q C 051  That is the score values computed for all relevant elements at increasing positions are more uniformly distributed in the range 0500  1\051  3 Related Works Most of the works in data mining 002eld regarding feature selection technique aim at maximizing the classi\002cation accuracy Also there is various researches aim at optimizing the information retrieval process Many works employed evolutionary approaches to perform feature selection 20 21 13 5 and othe rs to impro v e information retrieval 050IR\051 7 17 A wide re vie w of the application of evolutionary computation to boost information retrieval is presented in The main focus of this work is to provide effective information retrieval 050IR\051 speci\002cally image retrieval of mammograms employing feature selection It is well-known that an image retrieval system can be affected by any of the three subsystems images representations queries representations and similarity functions Previous approaches for effectively improving IR performance by manipulating queries representations have been developed in and also dealing with relevance feedback techniques 3 10 Recently similarity functions and ranking functions have received more attention of the researchers Many ranking functions were developed and applied to Web information retrieval as well as similarity functions to image retrieval However recent studies show that these functions do not perform consistently well across different contexts 7 According to 17 an i mage descriptor is a pair composed of an image feature extractor and a distance function since the similarity functions and the image representations 050feature vectors\051 have a crucial role in the retrieval performance The approaches presented in and 17 respecti v ely  showed solutions about how to combine multiples ranking functions and descriptors using evolutionary computation 


optimization and an evaluation criterion based on ranking quality Those works consider that there is not a best ranking function nor a best descriptor for a given problem In the classi\002cation context ensemble techniques combine prediction of multiple models to allow higher accuracy which are often not achievable when using just a single model The works presented in 18 emplo yed genetic algorithms to select feature subsets to construct ensembles using one base classi\002er Another approach to improve an image retrieval technique is to modify the images representations It is wellknown that the choice of an adequate feature vector improves the accuracy of the image retrieval Many 002lter feature selection techniques are applied to improve image retrieval Such techniques are based on the idea that correlated or inconsistent feature deteriorate the ability of data differentiating Wrapper feature selection techniques are also applied to improve image retrieval However the latter does not use an adequate evaluation criteria for image retrieval which normally is based on classi\002cation error or a measure of clustering separability In this is work it is proposed a method to improve image retrieval through feature selection The quality of features subsets 050chromosomes\051 is evaluated using a measure of ranking quality given by a ranking evaluation function and evolved by a genetic algorithm 4 The Proposed Framework The present framework uses GA with a 002tness function based on the ranking evaluation concept to perform feature selection for CBIR This decision stemmed from three reasons 050i\051 the large size of the search space in feature selection 050ii\051 previous successfully usage of GA in the feature selection domain and 050iii\051 no prior works on feature selection based on optimizing ranking quality applied for CBIR Figure 1 illustrates the steps from the pipeline that implemented the proposed method Here the feature selection step is a supervised process In the training phase image features are extracted from the image training set and then submitted to the feature selection process The feature selection process guided by GA searchs for the best features subset according to an evaluation criteria based on the ranking quality 226 given by a single valued ranking evaluation function 050Fc\051 In the test phase the features selected indicated by the best chromosome chosen the GA in the training phase will be used for representing the images of the test set Similarity queries are performed considering each image from the test set as a query image and 002nally the average precision-recall curve is built The corresponding GA designed for feature selection is described as follows The chromosome coding 226 In order to apply GA to a given Figure 1 Pipeline of the proposed method problem it is necessary to de\002ne the genotype required by the problem i.e the chromosome representation In other words a decision must be made on how the parameters of the problem will be mapped into a 002nite string of symbols 050genes\051 encoding a possible solution in the problem space In this work a chromosome was coded by an n bit string or binary-valued vector 050 n is the initial number of features\051 C  050 g 1  g 2      g n 051  where g i takes value 0 if the i th feature is excluded from the subset and 1 if it is kept in the subset We refer to C as a feature selection vector and g i as a feature selection variable The genetic operators 226 GA searches for better solutions by genetic operations including selection crossover and mutation Selection implements the survival of the best 002tted individuals according to some prede\002ned 002tness measure Therefore high-\002tted individuals have a better chance of surviving and reproducing while low-\002tted ones are more likely to disappear Crossover and mutation operations represent an analogy to natural reproduction and explore the solution space to 002nd the best solution The genetic operations used in this study are 017 Selection for recombination  applied to select pairs of individuals that will go on reproducing 050mating pool\051 Linear Ranking Selection was used the individuals are sorted according to their 002tness and the last position is assigned to the best individual while the 002rst position 


is allocated to the worst one The selection probability is linearly assigned to the individuals according to their ranks 017 Selection for reinsertion  a total of 050 S p 000 2\051 best offsprings and 2 best parents according to their 002tness values survive from two consecutive generations S p is the population size 017 Crossover  represents the mating of two individuals to form two new individuals 050offsprings\051 Uniform crossover was used in this work Uniform crossover is a sort of multiple points crossover taken to the extreme where instead of raf\003ing crossover points raf\003e a mask with the size of the chromosome that indicates which Chromosome-Parent will supply each gene to Offspring 1 Offspring 2 is generated by the complement of the mask 017 Mutation  a gene 050a feature selection variable\051 selected for mutation is substituted by its complement i.e each chosen bit will be changed from 0 to 1 and vice-versa This is known as uniform mutation Fitness function  The 002tness function plays a very important role in guiding a GA to obtain the best solutions within a large search space Good 002tness functions help a GA to explore the search space more effectively and ef\002ciently Not proper 002tness functions on the other hand can easily make the GA get trapped in a local optimum solution and lose the discovery power Two main designs have been analysed in this work classi\002cation error and 002tness functions based on ranking evaluation functions From the order-based ranking evaluation function F r 050 q C 051 050Eq 1\051 a mechanism to derive the 002tness function F c 050 Q C 051 for the GA has been devised F c 050 Q C 051 050Eq 2\051 is given by the average of the score values obtained from each image q of the training set Q as an image query n Q is the number of images in the set Q  The output of the 002tness function has been normalized within the range 0    where 1 indicates maximum accuracy According to this criterion the problem consists of seeking for the highest values On the other hand this can also be seen as a minimization problem if the output is subtracted from 1 0501 output 051 This is the approach adopted in this work F c 050 Q C 051  P 8 q 2 Q F r 050 q C 051  n Q 0502\051 We recall that the fundamental principle in wrapper feature selection approaches is the minimization of the number of features while optimizing 050or preserving\051 the quality of the result For a CBIR system the best approach is to retrieve images with a minimum amount of features and highest accuracy This concept led to the proposal of two distinct 002tness functions F cA 050 Q C 051 and F cB 050 Q C 051 050Equations 3 and 4\051 that combine two optimization criteria The 002rst criterion indicates the quality of the query results given by the term F c 050 Q C 051 present in both Equations The second criterion the minimization of the number of features are given by the terms 050 j C j\000 d 051  n and j C j  n in Equations 3 and 4 respectively In both Equations j C j is the number of selected features coded by chromosome C  Q represents the training set d is the number of desired features speci\002ed by the user and n is the dimensionality 050number of features\051 of the entire dataset The term 050 j C j\000 d 051  n yields high values when the number of selected features j C j widely differs from the number of desired features d  The term j C j  n of Equation 4 is also a penalizing factor that takes into account the number of selected features only Finally 013 is an adjustment parameter in the range which determines the importance assigned to each criterion in a complementary way F cA 050 Q C 051  013 050 F c 050 Q C 051\051  0501 000 013 051 022 050 j C j 000 d 051  n 023 0503\051 F cB 050 Q C 051  013 050 F c 050 Q C 051\051  0501 000 013 051 022 j C j  n 023 0504\051 Control parameters  the experiments described in this work employed crossover probability p c  0  8  mutation probability p m  0  01 for each gene 050a feature selection variable\051 5 Experiments and Analysis This section presents three experiments in which the proposed technique is employed to perform content-based image retrieval of mammograms The datasets were split into training and test subsets Feature selection has been carried out on the training subset while performance evaluation has been conducted through precision\226recall 050P&R\051 curves o v er the test subset for dif ferent feature selection techniques grouped as 050a\051 traditional methods 050 1 NN C4.5 SVM and Naive Bayes NB\051 050b\051 non order-based ranking evaluation function R precision 050FR-Precision\051 050c\051 the association rules 050StARMiner algorithm\051  050d\051 the proposed technique 050 F c  F cA and F cB 051 and 050e\051 all features combined 050no feature selection\051 A rule of thumb when analyzing P&R curves is the closer to the top the better the technique All methods evaluated appear in the legends of Figures 2 3 and 4 The values in parenthesis indicate the numbers of features selected 050 j C j 051 The methods of group 050a\051 employ classi\002cation errors as minimization criteria for the GA 


Group 050b\051 employs a 002tness function based on R precision Group 050c\051 is based on association rules Group 050d\051 are those related to the proposed framework F c  F cA and F cB correspond to the proposed 002tness functions F c 050 Q C 051  F cA 050 Q C 051  F cB 050 Q C 051 given by the Equations 2 3 4 and respectively The evolutionary search was set to 100 individuals evolving along 400 generations in experiments 1 and 2 Experiment 3 employed 50 individuals and 250 generations According to the dimensionality of the datasets the parameter d employed in F cA 050Equation 3\051 was set to 50 in the 002rst and second experiments and to 20 in the third experiment The Euclidean distance was employed in the experiments to measure the similarity between the feature vectors 5.1 Experiment 1 ROI-102 image dataset This dataset consists of 102 images with r egions o f i nterest 050ROI\051 taken from mammograms collected from the Breast Imaging Reporting and Data System of the Department of Radiology of University of Vienna 050http://www.birads.at\051 classi\002ed into three levels of BIRADS 0503 4 and 5\051 The BIRADS 050Breast Imaging Reporting and Data System\051 categorization was developed by the American College of Radiology to standardize mammogram reports and procedures The BIRADS categorization is summarized in Table 1 The dataset has been divided into a 68\226image training set and a 34\226image test set Each image has been characterized by a 850\226dimensional feature vector including features generated by Haralick descriptors 050140 features\051 wavelets 05064 features\051 zernike moments 050255 features\051 histogram 050256 features\051 features of 002rst order derived of histogram 0506 features\051 Run length 05044 features\051 and Edge Histogram MPEG7 05080 features\051 Figure 2 shows the P&R curves for the test dataset and also the number of features selected for each method It can be seen that the proposed framework with 002tness function derived from order-based ranking evaluation function yielded superior results when compared with the traditional evaluation criteria given by the average classi\002cation error improving up to 22 the precision of the query answers The proposed framework also outperforms the 002tness function derived from non order-based ranking evaluation function 050FR-Precision\051 and all features combined Also the proposed framework 002nds the sets with the fewest features in comparison with the other methods 5.2 Experiment 2 ROI-250 image dataset This experiment investigates the performance of the proposed technique for a 250\226image mammography dataset with ROIs comprising lesions taken from the Digital Database for Screening MamTable 1 BIRADS categorization value  description  0  Need Additional Imaging Evaluation 1  Negative 2  Benign Finding 3  Probably Benign Finding Short Interval Follow Up Suggested 4  Suspicious Abnormality Biopsy recommended 5  Highly Suggestive of Malignancy Proper Action  Must be Taken Figure 2 Precision-recall curve in ROI-102 image dataset mography of the University of South Carolina 050http://marathon.csee.usf.edu/Mammography/\051 classi\002ed into two classes mass-benign and mass-malign A 739\226dimensional feature vector has been computed for each sample including features generated by Haralick descriptors 050140 features\051 zernike moments 050255 features\051 histogram 050256 features\051 features of 002rst order derived of histogram 0506 features\051 Run length 05044 features\051 and invariant moments 05038\051 The dataset was divided into a 166\226image training subset and a 64-image test subset Figure 3 shows the precision-recall curves obtained and also the number of features selected in each method The graphs of Figure 3 show that the proposed methods 050 F cA  F cB and F c 051 increased the precision of the queries in about 15 in the region of 5 of recall in comparison with the other methods while decreasing the number of features from 739 to around 50 This is using about 7 of the previous memory space for the images representation These results indicate that ranking evaluation functions are well-suited to be employed in genetic feature selection for CBIR 


Figure 3 Precision-recall curve in ROI-250 image dataset 5.3 Experiment 3 Mammograms-1080 image dataset This experiment employed a dataset composed by 1080 mammograms images collected in the Clinical Hospital of University of Sao Paulo at Ribeiro Preto The dataset was previously classi\002ed into 4 levels of breast tissue density 0501\051 mostly fatty 050362 images\051 0502\051 partly fatty 050446 images\051 0503\051 partly dense 050200 images\051 and 0504\051 mostly dense 05072 images\051 Figure 4 Precision-recall curve in Mammography-1080 image dataset Breast density is an important risk factor in the development of breast cancer In this experiment the images are represented by the feature set proposed in b uilding a vector of 85 features including shape and size of the breast the conditions of the breast contour nipple position and the distribution of 002broglandular tissue This dataset was divided in training set and test set The training set is composed of 720 images and test set is composed of 360 images Figure 4 shows the P&R curves over test dataset and also the number of features selected in each method Again the proposed methods reached the highest values of precision and select the smallest number of features 050a\051 050b\051 050c\051 050d\051 Figure 5 Queries in Mammography dataset 050a\051 226 is the query image 050b\051 using the features selected through 002tness function F cB  050c\051 using the features selected through classi\002cation error of C4.5 and 050d\051 using the all features extracted Results for the retrieval of the 5 most similar images from a query image are also provided in this experiment as illustrated in Figure 5 The image 5.\050a\051 is the query image taken from the mostly fatty image class Images shown in 5.\050b\051 are the 5 most similar images retrieved for the proposed 002tness function F cB  The row 050c\051 shows the results for C 4  5 classi\002er whereas 050d\051 illustrate the images resulting from all features 050no selection applied\051 In Figure 5 the images surrounded by dashed lines are false positives 050not relevant images\051 For this query the proposed method achieved the highest precision 050100%\051 when compared the results of C4.5 and the original feature vector 050precision of 40%\051 


6 Conclusions This work proposed a novel genetic feature selection framework for CBIRs It employs a wrapper strategy that searches for the best reduced feature set while optimizing 050or preserving\051 the quality of the solution From a ranking evaluation function three new 002tness functions namely F cA  F cB and F c have been proposed and evaluated in three experiments The proposed genetic feature selection approach which encompasses F cA  F cB and F c  has been compared with 050a\051 traditional methods found in the literature 050b\051 the StARMiner feature selector and 050c\051 the whole feature vector and signi\002cantly outperformed them The proposed approach has been able to optimize the accuracy of similarity queries while selecting a signi\002catively reduced number of features Additionally the proposal of combining the quality of the query results with the criterion of minimizing the number of selected features F cA and F cB  led to high accurate query answers while reducing the number of features more than the 002tness function F c  Therefore the 002nal processing cost of the queries is also reduced References  P  M d Aze v edo-Marques N A Rosa A J M T raina C Traina-Jr S K Kinoshita and R M Rangayyan Reducing the semantic gap in content-based image retrieval in mammography with relevance feedback and inclusion of expert knowledge International Journal of Computer Assisted Radiology and Surgery  3\0501-2\051:123\226130 June 2008  R Baeza-Y ates and B Ribeiro-Neto Modern Information Retrieval  Addison-Wesley Essex UK 1999  B Bartell G Cottrell and R Bele w  Optimizing similar ity using multi-query relevance Journal of the American Society for Information Science  49:742\226761 1998  O Cord 264 on E Herrera-Viedma C L 264 opez-Puljalte M Luque and C Zarco A review on the application of evolutionary computation to information retrieval International Journal of Approximate Reasoning  34:241\226264 July 2003  J G Dy  C E Brodle y  A Kak L S Broderick and A M Aisen Unsupervised feature selection applied to content-based retrieval of lung images IEEE Transactions on Pattern Analysis and Machine Intelligence  25\0503\051:373\226 378 March 2003  W  F an E A F ox P  P athak and H W u The ef fects of 002tness functions on genetic programming-based ranking discovery for web search Journal of the American Society for Information Science and Technology  55\0507\051:628\226636 2004  W  F an P  P athak and M Zhou Genet ic-based approaches in ranking function discovery and optimization in information retrieval a framework Decision Support Systems  2009  D E Golber g Genetic algorithms in search optimization and machine learning  Addison Wesley 1989  R L Haupt and S E Haupt Practical Genetic Algorithms  John Wiley  Sons New Jersey United States second edition edition 2004  J Horng and C Y eh Applying genetic algorit hms to query optimization in document retrieval Information Processing  Management  36:737\226759 2000  S K Kinoshita P  M d Aze v edo-Ma rques R R PereiraJr J A H Rodrigues and R M Rangayyan Contentbased retrieval of mammograms using visual features related to breast density patterns Journal of Digital Imaging  20\0502\051:172\226190 June 2007  F  K orn B P agel and C F aloutsos On the  dimensionality curse and the self-similarity blessing IEEE Trans on Knowledge and Data Engineering  13\0501\051:96\226111 2001  H Liu and L Y u T o w ard inte grating feature select ion algorithms for classi\002cation and clustering IEEE Transactions on Knowledge and Data Enginnering  17\0504\051:491\226502 April 2005  M X Ribeiro A J M T raina C T raina-Jr  and P  M Azevedo-Marques An association rule-based method to support medical image diagnosis with ef\002ciency IEEE Transactions on Multimedia  10\0502\051:277\226285 2008  U S Cancer Statistics W orking Group United states cancer statistics 1999-2005 incidence and mortality webbased report atlanta 050ga\051 Department of health and human services centers for disease control and prevention and national cancer institute 2009 Available in http://apps.nccd.cdc.gov/uscs   L T amine C C and M Boughanem Multiple query evaluation based on an enhanced geneticnext term algorithm Information Processing  Management  39\0502\051:215\226 231 2003  R S T orres A X  F alc 230 ao M A Gonc\270alves J P Papa Z B W Fan and E A Fox A genetic programming framework for content-based image retrieval Journal of the American Society for Information Science and Technology  42\0502\051:283\226292 2009  A Tsymbal P  Cunningham M P echenizkiy  and S Puuronen Search strategies for ensemble feature selection in medical diagnostics In Proceedings of the 16th IEEE Symposium on Computer-Based Medical Systems  pages 124\226 129 June 2003  A Tsymbal M Pechenizkiy  and P  Cunningham Sequential genetic search for ensemble feature selection In Proceedings of the International Joint Conferences on Arti\002cial Intelligence  pages 877\226882 August 2005  C.-M W ang a and Y F  Huang Ev olutionary-based feature selection approaches with new criteria for data mining A case study of credit approval data Expert Systems with Applications  36\0503 Part 2\051:5900\2265908 2009  H Y an J Zheng Y  Jiang C Peng and S Xiao Selecting critical clinical features for heart diseases diagnosis with a real-coded genetic algorithm Applied Soft Computing  8:1105\2261111 2008  T  Zhao J Lu Y  Zhang and Q Xiao Feature selection based on genetic algorithm for cbir In IEEE Congress on Image and Signal Processing  volume 2 pages 495\226499 2008 


     Figure 9. Argumentation Tree For Open GL  A1 The current system in flash does not have the functionality of dynamic allocation of particles like mine or clutter. It places them randomly  A1.1 That is not of much importance because it still gives a new position to mine and clutter particles A2 Current system in flash has faster response time as compared to system in Adobe Director A3 The current system doesnêt satisfy many of the features required for the new system like database A4 Adobe Flash cannot communicate with database A4.1 Flash doesnêt support database but database support is very important and critical A4.1.1 The system should be able to generate evaluation reports for trainee based on pr evious records stored in the database A5 Flash doesnêt create sound clips  A5.1 We donêt need sound creating features as the sys tem has to generate sound. We can play externally recorded sound files using Adobe Flash A6 Flash can provide good visual effects as compared to Adobe Director A7 The developer has good knowledge in development using Flash so the system can be developed quickly B1 We could reuse the system already developed for sound generation, as it is developed using Adobe Audition for analysis which is somehow related to Adobe Director B1.1 The current system is better synthesized in terms of sound production and the sound produced is also instantaneous rather than discrete B1.2 That current system has certain performance issues like slow response time B1.3 The current system in Adobe Director has the feature of producing dynamic coloring scheme on approaching a mine. This kind of scheme is highly preferable and is not present in Adobe Flash system B2 Adobe Director can provide more functionality as compared to the current flash system. E.g. Multiple sounds while detecting mines   B2.1 Adobe Director can provide better visual effects as compared to flash e.g. in case of GUIês   B2.2 A modified version of the current system in flash can also provide the same functionality B2.2.1 We cannot integrate code developed in other platforms with Flash, but Flash can be integrated in Adobe Director B3 The interface provided by flash is not professional enough. It is too simple and straight forward for doing more things in future   B4 Easily available plug-ins can help integrate the tracking system developed in C# with Adobe Director  B4.1 Code developed in Open GL/AL can also be integrated using Adobe Director using suitable stubs   B5 A new sound recognition algorithm is being developed in Adobe Audition which can be integrated with Adobe Director but not with Open GL or Flash Evidence supported B6 If the current system is reused; the project deadline can be met easily B7 The developer has very little experience in development using Adobe Director   B7.1 The developer can take help from the already developed system in Adobe Director C1 The tracking software already developed is coded in C#/NX5. We could reuse that and develop our system in Open GL/AL C1.1 Open GL has C# libraries which can be used to develop the system C2 Because the platform used is for high end application development, it can provide good GUI and database support C2.1 Open GL/AL can help us generate dynamic surfaces for mine detection and training which the original system in flash does not have C4 Open GL does not support connectivity with Adobe Audition. Adobe Audition is required for creating sound recognition algorithm C3 Open GL does not support connectivity with Adobe Audition. Adobe Audition is required for creating sound recognition algorithm C4 The time taken for developing the project using open GL will be comparatively more as the whole system would have to be developed from scratch C4.1 If Open GL has support for C# libraries, and then the system could be develope d faster as developer is quite familiar with programming languages like C 151 


   C4.2 Open GL has excellent documentation that could help the developer learn the platform with ease C4.3 Developer has very little ex perience in working with Open GL platform  For our case study, alternative B i.e. Adobe Director was the most favorable alternative amongst all the three. It catered to the reusability criteria quite well and aimed at meeting most of the desired operational requirements for the system   6. CONCLUSION & FUTURE WORK  The main contribution of this paper is to develop an approach for evaluating performance scores in MultiCriteria decision making using an intelligent computational argumentation network. The evaluation process requires us to identify performance scores in multi criteria decision making which are not obtained objectively and quantify the same by providing a strong rationale. In this way, deeper analysis can be achieved in reducing the uncertainty problem involved in Multi Criteria decision paradigm. As a part of our future work we plan on conducting a large scale empirical analysis of the argumentation system to validate its effectiveness   REFERENCES  1  L  P Am g o u d  U sin g  A r g u men ts f o r mak i n g an d  ex p lain in g  decisions Artificial Intelligence 173 413-436, \(2009 2 A  Boch m a n   C ollectiv e A r g u men tatio n    Proceedings of the Workshop on Non-Monotonic Reasoning 2002 3 G  R Bu y u k o zk an  Ev alu a tio n o f sof tware d e v e lo p m en t  projects using a fuzzy multi-criteria decision approach Mathematics and Computers in Simualtion 77 464-475, \(2008 4 M T  Chen   F u zzy MCD M A p p r o ach t o Selec t Serv ice  Provider The IEEE International Conference on Fuzzy 2003 5 J. Con k li n  an d  M. Beg e m a n   gIBIS: A Hypertext Tool for Exploratory Policy Discussion Transactions on Office Information Systems 6\(4\: 303  331, \(1988 6 B P  Duarte D e v elo p in g a p r o jec ts ev alu a tio n sy ste m based on multiple attribute value theroy Computer Operations Research 33 1488-1504, \(2006 7 E G  Fo rm an  T h e  A n a l y t ic Hier a rch y P r o cess A n  Exposition OR CHRONICLE 1999 8 M. L ease  an d J L  L i v e l y  Using an Issue Based Hypertext System to Capture Software LifeCycle Process Hypermedia  2\(1\, pp. 34  45, \(1990 9  P e id e L i u   E valu a tio n Mo d e l o f Custo m e r Satis f a c tio n o f  B2CE Commerce Based on Combin ation of Linguistic Variables and Fuzzy Triangular Numbers Eight ACIS International Conference on Software Engin eering, Artificial Intelligence Networking and Parallel Distributed Computing, \(pp 450-454 2007  10  X  F L i u   M an ag e m en t o f an In tellig e n t A r g u m e n tatio n  Network for a Web-Based Collaborative Engineering Design Environment Proceedings of the 2007 IEEE International Symposium on Collaborative Technologies and Systems,\(CTS 2007\, Orlando, Florida May 21-25, 2007 11 X. F L i u   A n In ternet Ba se d In tellig e n t A r g u m e n tatio n  System for Collaborative Engineering Design Proceedings of the 2006 IEEE International Symposium on Collaborative Technologies and Systems pp. 318-325\. Las Vegas, Nevada 2006 12 T  M A sub jec tiv e assess m e n t o f altern ativ e m ission  architectures for the human exploration of Mars at NASA using multicriteria decision making Computer and Operations Research 1147-1164, \(June 2004 13 A  N Mo n ireh  F u zzy De cisio n Ma k i n g b a se d o n  Relationship Analysis between Criteria Annual Meeting of the North American Fuzzy Information Processing Society 2005 14 N  P a p a d ias HERMES Su p p o rti n g A r g u m e n tative  Discourse in Multi Agent Decision Making Proceedings of the 15th National Conference on Artifical Intelligence \(AAAI-98  pp. 827-832\dison, WI: AAAI/MIT Press,  \(1998a 15  E. B T riantaph y llo u   T h e Im p act o f  Ag g r e g atin g Ben e f i t  and Cost Criteria in Four MCDA Methods IEEE Transactions on Engineering Management, Vol 52, No 2 May 2005 16 S  H T s a u r T h e Ev alu a tio n o f airlin e se rv ice q u a lity b y  fuzzy MCDM Tourism Management 107-115, \(2002 1 T  D W a n g  Develo p in g a f u zz y  T O P S IS app r o ach  b a sed  on subjective weights and objective weights Expert Systems with Applications 8980-8985, \(2009 18 L  A  Zadeh  F u z z y Sets   Information and Control 8  338-353, \(1965  152 


                        





