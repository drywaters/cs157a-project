DOCINER: A Document Indexation Tool for Learning Objects Suphakit Niwattanakul School of Information Technology Suranaree University of Technology Nakhon Ratchasima, Thailand suphakit@sut.ac.th Michel Eboueya L3I University of La Rochelle La Rochelle, France michel.eboueya@univ-lr.fr Philippe Martin Eurecom Sophia-Antipolis, France phmartin@phmartin.info Abstract In this paper, we present a method we implemented to help a user index documents \(and, in particular, learning objects\ according to a given set of concepts \(terms referring to domains or topics\ The user first associates keywords to the concepts. Our method uses such associations to suggest simple rules for indexing a document by concepts according to the keywords this document contains. Then, our system uses those rules to perform the indexation of documents Keywords: document indexation, formal concept analysis I  I NTRODUCTION Nowadays, the use of online learning resources is increasingly common in education focusing on course development [1  Man y r e se ar cher s p a y atten tio n to th e  issue of reusability of learning resources. Course developers aim to reuse these learning resources for developing a new course because the reuse of learning resources can save time and money for course development In terms of course development, a course generally consists of units of instruction called Learning Objects LOs\A learning object is any digital resource that can be used or reused to support learning  O s ca n be  texts, presentations, quizzes, video clips, tutorials, maps animations, assessments, etc. LOs are accessible and searchable through Web-based repositories and mediators In a repository, LOs reside within a database on the server hosting the Web-enabled gateway to the collection, whereas a mediator contains no LOs but links to objects residing on remote servers A Learning Object Repository \(LOR\ is a system that provides functions to collect LOs available on computer networks and/or Databases. LORs can play the role of a repository and/or a mediator. The metadata associated to documents in LORs facilitates the search and management of LOs. Many LORs are developed based on the IEEE LOM metadata standard [2 a n d its ap p licatio n p r o f ile s s u ch  as SCOR a nC ore [5 Norm e t i c 6] an d UK L O M  Co The use of educational metadata standards allows LOs to index and classify by classification systems but these metadata standards lack a formal semantics and they introduce the problem of incompatibility between heterogeneous metadata descriptions or schemas across domains [8  O n to lo gie s c a n b e use d  fo r ind e xi ng le a r ni n g  resources by using concepts \(topics or domains Although the use of learning content management systems is becoming common in most educational organizations and the number of educational resources is huge, most of these resources are hidden in repositories and cannot be easily found. This can impede their potential use and reuse. Searching for LOs in LORs by using keywords leads to problems since different LOs may be about the same topic while containing different keywords Traditional information retrieval technology is based on the occurrence of words in documents. Semantic Web technologies  a y be us ed f o r i n f o r m at i o n retrieval on the Web [11 We use a li g h t w ei gh t se m a ntic  retrieval technique to ease the retrieval of LOs: 1\ the user first associates keywords to the concepts \(terms or lists of terms referring to domains or topics\via a direct application of Formal Concept Analysis \(FCA\, our system uses such associations to suggest simple rules for indexing a document by concepts according to the keywords this document contains, 3\r system uses those rules to perform the indexation of documents. After presenting the framework of our technique, we present its second step II  K NOWLEDGE O RGANIZATION S YSTEM BASED ON O NTOLOGIES For knowledge sharing, “an ontology is a formal, explicit specification of a shared co nceptualization A specification of conceptualization consists in a list of objects and relations that hold among them. “Explicit means that objects, concepts, and other entities are explicitly defined. “Formal” implies that the ontology should be machine-readable and logic-based. The main structure of an ontology model consists in concepts or classes, and relations Researchers are developing a method to automatically extracting structured information from documents by using information extraction technologies. Several tools or systems for building domain ontologies from text are TEXCOMON \(TEXt-COncept Map-Ontology   and TEXT-TO-ONTO Ontology Learning Environment  s des c ri bed i n 16 t h e proces s of con cept i n dex i ng consists in \(i\ extracting entities from unstructured textbased content using lexical tags and rules, \(ii\ identifying concepts and adding ontology tags to them using semantic 
2009 Fifth International Joint Conference on INC, IMS and IDC 978-0-7695-3769-6/09 $26.00 © 2009 IEEE DOI 10.1109/NCM.2009.344 853 
2009 Fifth International Joint Conference on INC, IMS and IDC 978-0-7695-3769-6/09 $26.00 © 2009 IEEE DOI 10.1109/NCM.2009.344 853 
2009 Fifth International Joint Conference on INC, IMS and IDC 978-0-7695-3769-6/09 $26.00 © 2009 IEEE DOI 10.1109/NCM.2009.344 859 


rules, and \(iii\ merging entity and concept information into a concept index The term “Knowledge Organization System” \(KOS refers to all types of schemes for organizing information and promoting knowledge. KOSs include classification schemes that organize materials at a general level such as subject headings and authority files. Authority files are used to control variant versions of key information such as geographic names and personal names. KOSs also include highly structured vocabularies, such as thesauri, and less traditional schemes, such as semantic networks and ontologies The research of knowledge representation is developing and testing the knowledge representation language [18  Knowledge representation systems allow the concepts and inference rules to be used by machines. Nowadays, the SKOS \(Simple Knowledge Organisation System\ model is developing as a knowledge representation system and can be used for developing Web contents thanks to the Semantic The SKOS model is designed by the W3C Semantic Web Best Practices and Deployment Working Group. SKOS Core is a model designed for expressing the basic structure and content of concept schemes. A concept scheme is a set of concepts, optionally including statements about semantic relations between those concepts. Concept Schemes can be thesauri, classification schemes, subject heading lists taxonomies, terminologies, glossaries and other types of controlled vocabulary III  F RAMEWORK OF THE K EYWORD AND C ONCEPT E XTRACTION M ETHOD Our information indexation/extraction technique fits the definition of   the identification, and consequent or concurrent classification and structuring into semantic classes, of specific information found in unstructured data sources, such as natural language text, making the information more suitable for information processing tasks To achieve this, many information extraction methods have been proposed: name entity recognition, noun phrase coreference resolution, semantic role recognition entity relation recognition, time line recognition, etc Our own named entity recognition technique starts by comparing words in texts with index words coming from a lexical database such as Wo  T h es e w o rds are  then associated to keywords and these keywords are associated to concepts \(also coming from WordNet and/or provided by the user As illustrated in Fig. 1, the keywords “Computer Programming” and “Mathematics” are identified according to words from the text. Then these two keywords are used for identifying the concept “Computer Science The framework of our method is illustrated in Fig. 2 Fig. 2 The framework of keyword and concept extraction method For identifying keywords and concepts, data from two sources are used for identifying keywords and concepts which are: \(i\ words and their information from the WordNet dictionary and \(ii\ words and keywords from experts. The two data sources are transformed into a database based on an ontology model. These concepts are classified via classification systems such as controlled vocabularies and taxonomies using the SKOS ontology The concepts and their keywor ds are analyzed through an FCA \(Formal Concept Analysis\stem   o  suggest rules for indexing concepts To index documents, we propose a tool called DOCINER DOCument INdexation for Educational Resources\ that first converts the metadata of the source LORs in XML Then, within that textual meta data, it isolates the keywords it knows. Finally, it uses the indexing rules to associate each LO with concepts \(topics or domains IV  S UGGESTING R ULES FOR R ELATING K EYWORDS TO C ONCEPTS In DOCINER, associations between keywords and concepts come from WordNet and/or the user, and are represented using the SKOS ontology Fig. 3 illustrates such associations. DOCINER is based on the knowledge annotation an d retrieval server SEWESE  Identifying concepts Associating keywords with concepts Analyzing keywords and concepts Suggesting rules for indexing concepts Comparing words with index words Finding keywords Indexing concepts Converting metadata of LOs in XML This paper is an introduction of Mathematics oriented toward Computer Programming  Computer Programming         Mathematics Com p uter Science Fig. 1 Keyword and concept extraction method Text Keywords Conce p t Identifying keywords and concepts Indexing keywords and concepts 
854 
854 
860 


Fig. 3 Relating keywords and concepts These associations can also be represented as in TABLE 1. This format permits you to apply basic techniques of FCA where two types of items \(objects and attributes relate to each other. In FCA, each relationship between an object and its related attributes is called a “formal concept In TABLE 1 the formal concepts are shown via three rectangles TABLE 1 AF ORMAL C ONTEXT OF K EYWORDS AND C ONCEPTS Attributes \(Keywords Objects Concepts discrete structure discrete mathema tics Mathe matics computer programming electronic communication civil engineering  X X X   computer science  X X X  electrical engineering  X X X By using the above mentioned basic techniques of FCA ToscanaJ [2 h ic h i s an open s o u r ce is  u s ed a s a tool f o r  analyzing data and presenting these data with concept lattices in an image. The notation graph referred to as a concept lattice” or a “Galois lattice” is used for representing formal concepts A central notation of a concept lattice is a duality namely a “Galois connection used for representing between two types of related items The “concept lattice” shown in Fig. 4, can be derived from the previous table for representing formal concepts Fig. 4  A concept lattice for TABLE 1 From such a lattice, our method draws simple rules for indexing documents by concepts based on the keywords in these documents 000x Rules that do not need to be approved by the user For some keywords, there is only one related concept. In such a case, there is no ambiguity for document indexation Using the notation list of keywords -> concept here are the rules that can be derived from or that case Fig. 4 for that case mathematics”, “discrete mathematics”, “discrete structure”} > “civil engineering mathematics”, “discrete mathematics computer programming”} -> “computer science mathematics”,  “computer programming electrical communication”} -> “electrical engineering 000x Rules that need to be approved by the user When a keyword is related to several concepts \(i.e domains or topics\, the user might want to make a selection Using the notation list of keywords ->? concept here are the rules  that can be derived from or that case Fig. 4 for that case mathematics”, “discrete mathematics”} ->? “civil engineering mathematics”, “discrete mathematics”} ->? “computer science mathematics”, “computer programming”} ->? “computer science mathematics”, “computer programming electrical engineering The rules are represented in tuProlog   d  searched via the query mechanisms of tuProlog Our document indexation approach is close to the ones adopted in the TEXCOMON system  d PALOMA e l oped i n t h e f r a m e w or k of  LOR N ET  Learning Object Repositories Network bot h of  which perform knowledge management from educational resources. However, these systems do not suggest indexation rules to the user. Indexation rules can be used for indexing documents by concepts to help retrieve these mathematics discrete mathematics computer programming electrical communication computer science electrical engineering civil engineering discrete structure computer science Concepts keywords   civil engineering electrical engineering discrete structure discrete mathematics mathematics computer programming electronic communication 
855 
855 
861 


documents. The DOCINER approach suggests such indexation rules by using an FCA system V  E VALUATION Our evaluation relies on classic precision and recall measures \(possibly combined in a F-measure\sess the 2\ and \(3 used to calculate the values of precision, recall and Fmeasur  3    2  2   1  recall precision recall precision measure F trd ard recall ad ard precision 000\016 000 000\020 000 000 Where  ard  = number of relevant documents in the result list  trd   = total number of relevant documents in the document base  ad   = number of documents in the result list Values of precision, recall and F-measure are calculated by comparing the keywords in the result lists with keywords identified by an expert TABLE 2 shows the average results for 30 example documents. The method is tested in two steps, finding keywords and indexing concepts TABLE 2 E VALUATION OF THE K EYWORD AND C ONCEPT E XTRACTION M ETHOD Steps of evaluation Precision Recall F-measure  Finding keywords 0.9933 0.9900 0.9861 Indexing concepts with indexing rules 1.0 0.9900 0.9945 As regards the precision values of finding concepts and indexing concepts, the precision value is increased in the process of indexing concepts. Af ter identifying the concepts by using indexing rules, non-relevant keywords to such concepts are removed. However, the proposed method is only a prototype. It needs to be developed for an application in the future VI  C ONCLUSION We have presented a document indexation approach This approach can help users to associate documents or educational resources to concepts \(terms referring to domains or topics\y using the occurrence of keywords in such documents in order that those documents can be retrieved by using the concepts. The advantage of this method is the suggestion of indexation rules to the user by implementing them in a way of knowledge management systems. The use of indexation rules help to remove non relevant keywords. The limit of this method is that concepts cannot be identified if there are no relevant words related to such concepts We shall evaluate our method by comparing our results with other concept/rule identification tools. To that end we shall re-use similarity measures between concepts and between keywords by using the well-known formula of similarity measures which is Jaccard’s coefficient as described in  R EFERENCES 1  Caw s C F r ie s e n, N   Be audo i n M  A N e w  L e ar ning O b je c t  Repository for Language Learning: Methods and Possible Outcomes Editor: Alex Koohang. In the Interdisciplinary Journal of Knowledge and Learning Objects. Volume 2, 2006 2   I EEE L T S C L e a r n in g Te ch n o l o g y Stan d a r d s Co mmi tte e   I EEE  1484.12.1-2002. Draft Standard for Learning Object Metadata Institute of Electrical and Electronics Engineers. 2002. Retrieved from http://ltsc.ieee.org/ wg12/files/LOM_1484 _12_1_v1_Final_Draft.pdf 3  W iley  D  A  Co nne c t i n g l e ar ning  o b je cts  to ins t r u ct io nal  de s i g n  theory: A definition, a metaphor, and a taxonomy. 2002. Retrieved from http://reusability.org/ read/chapters/wiley.doc 4   Be ts y  S   I n tr o duc tio n to the S C O R M f o r  I n s t r u ct io nal D e s i g n e r s   ADL \(Advanced Distributed Learning\. 2004. Retrieved from http://www. adlnet.gov/scorm/articles/article.aspx?id=4 5   F r ie s e n, N F i s h e r S   Ro be r t s  A   Ca nCo r e G u ide l ine s V e r s io n 2 0  Introduction. 2003. Retrieved from http://www.cancore.ca/guidelines drd  Norm et i c  Profi l e d  ap p lic at i on Norm et i c  vers i on  1  1   200 6  Retrieved from http://www.normetic.org 7  U K  L O M Co r e U K  L e ar ning O b je c t Me ta da ta Co r e D r af t 0  2   20 0 4  Retrieved from http://zope.cetis.ac.uk/profiles/uklomcore/uklomcore_ v0p2_may04.doc 8 St oj an ovi c  L   St aa b S  Stu d e r  R  2 001  eL ea rn i n g b a s e d o n th e Semantic Web. In WebNet2001 - World Conference on the WWW and Internet, Orlando, Florida, USA. Retrieved from http://citeseer ist.psu.edu/ 501440.html 9  Be r n e r s L e e   T  S e m a ntic W e b o n X M L  X M L 200 0, W a s h i n g t o n D C  Retrieved from http://www.w3.org/2000/Talks/1206-xml2k-tbl 10  Ma tt he w s B. S e m a nti c W e b T e ch no l o g i e s J I S C T e chno l o gy and Standards Watch. 2005. Retrieved from http://www.jisc.ac.uk uploaded_documents/jisctsw_05_02bpdf.pdf 11  G uha, R M c Co o l R Mil l e r  E  S e m a nti c S e ar ch. W W W 200 3  May 20-24, 2003, Hungary. Retrieved from http://www2003 org/cdrom/papers/refereed/p779/ess.html  G r u b e r T  R  T o w a rd p r in ci p l es for t h e d e s i gn of ont ologi es u s ed for knowledge sharing. International Journal of Human-Computer Studies, Vol. 43, Issues 4-5, November 1995, pp. 907-928    Z o u a q  A   Nk a m b ou  R   B u i l d i n g Dom a in Ont o logi es from T e xt  for Educational Purposes. To be published in the IEEE Transaction on Learning Technologies, 2008 14 Z o uaq  A N k am bo u, R    F r as s o n, C. E n ha nc ing L e ar ning O b je cts  with an Ontology-based Memory. To be published in the IEEE Transactions on Knowledge and Data Engineering, 2008 15  M a ed c h e A   S t a a b  S  Th e TE X T T O O N TO O n t o lo g y  Lea r n i n g  Environment. 2000. Retrieved from http://citeseer.ist.psu.edu 275146.html 16  S e tchi R M T a ng Q  Co n c e p t  I nde x i ng us i n g O n to l o gy and  Supervised Machine Learning. In Proc. of World Academy of Science, Engineering and Technology. Vol. 21 January 2007. ISSN 1307-6884 17  H o dg e   G  Sy s t e m s of  K now le dg e  O r g a niz a tio n f o r D i g i t a l  L i br ar ie s   Beyond Traditional Authority Files. The Council on Library and Information Resources. 2000. Retrieved from http://www.clir.org pubs/reports/ pub91/contents.html  K i r y a k ov  A   Pop ov B   T e r z i e v  I   M a n ov D  Ogn y a n off D  2005\. Semantic Annotation, Indexing, and Retrieval. Elsevier's Journal of Web Semantics, Vol. 2, Issue \(1\, 2005. Retrieved from http://www.websemantics journal.org/ps/pub/2005-10 19  Mil e s  A    Br ickl ey D  S K O S Co r e G u ide  W 3 C Re co m m e nda t io n  2005. Retrieved from http://www.w3.org/TR/2005/WD-swbp-skoscore-guide-20051102 
856 
856 
862 


 M o en s  M  F    I n form a t i o n E x t r ac ti on Algo ri t h m s and Pros p e c t s i n a Retrieval Context. Springer : Netherlands. 246 p. 2006 21 F e ll baum  C. W o r d N e t A n El e c tr o n ic L e x i cal D a ta bas e T h e MI T Press. May 1998. Retrieved from http://mitpress.mit.edu/catalog item/default.asp?ttype=2&tid=8106 22 P r is s  U  F o r m al Co nce p t A n al y s is i n  Co m p ute r S c ie nce  I n B Cr o n i n  Ed.\. Annual Review of Information Science and Technology ASIST, Vol. 40. 2006 23 W o l f f   K  E. A  F i r s t co ur s e in F o r m al Co nce p t A n al y s is  I n P r o c o f  the SoftStat’93. Gustav Fischer Verlag. 1994. Retrieved from http://www. fcahome.org.uk/fca.html 24  G a ndo n F  D u r v il le P  S e W e Se   S e m a nti c W e b S e r v e r  I N R I A   France. Retrieved on November 15th, 2007 from http://wwwsop.inria.fr/acacia/soft/sewese 25 Be c k e r P H e r e th, J S t um m e G  To scanaJ A n O p e n S o ur ce T o ol for Qualitative Data Analysis. Advances in Formal Concept Analysis for Knowledge Discovery in Databases. In V. Duquenne and B Ganter and M. Liquiere and E. M. Nguifo and G. Stumme \(Eds 2002. Retrieved from http://citeseer.ist.psu.edu/587107.html    Pi a n c a s t e lli  G   Om i c in e A  tu Prolog 2  0  O n e St ep B e y o n d  AL P  Newsletter Digest 20\(1\. Association for Logic Programming February-March 2007. Retrieved from http://alice.unibo.it/xwiki/bin view/Tuprolog/Documents 27  P i an cas te l l i G Be ni n i A O m ic in i  A   Ricci A  T h e A r chite c t ur e  and Design of a Malleable Objet-Oriented Prolog Engine. \(Slide 23th ACM Symposium on Applied Computing \(SAC 2008\, 16-20 March, 2008, Fortaleza, Ceará, Brazil. Retrieved from http://alice unibo.it/xwiki/bin/view/Tuprolog/Documents    Pa qu et t e  G  A p p r en t i s s a ge s u r l’I n t e rn et d e s p l a t eform e s a u x portails à base d’objets de connaissance. In S. Pierre \(Ed Innovations et tendances en technologies de formation et d’apprentissage. Presses de l’école polytechnique de Montréal, pp. 130. 2005. Retrieved from http://www.licef.teluq.uquebec.ca/gp/eng publications/campus_virtuel.htm  P a qu et t e  G  D e  la r e c h er c h e la p r a t i q u e  L a p l a n t e un i v er s i t a i r e s e  met en réseau, 2006. Retrieved from http://www.ledevoir.com 2006/05/20/109509.html?282 30  D o an, A M a d h av a n J D o m i ng o s P   H a l e vy  A   L e ar ning to m a p  between ontologies on the semantic web. In Proc of the 11 th International WWW Conference. 2002. Retrieved from http://www cs.washington.edu/homes/alon/site/files/glue.pdf 
857 
857 
863 


2\pts and conceptsets in a hash table and update their frequencies, the process continues until there is no concept in the XML file 3\ve the dynamic hash table into secondary storage media 4\ic hash tab le to determine the large freque nt conceptsets that satisfy the threshold support GARC_algorithm 1 Input minimum support s minimum confidence \(c the number of concepts N  2 Build a primary bucket of hash table 3 IF there is no EOF THEN  4 FOR each document  D  d 1 d 2 d  n  DO 5 Select each concept c 1 c 2 c  N  6 Create all combinations of conceptset with their occurrences 7 Insert all conceptsets with their occurrences in hash table by using h v  8 IF there is  document D  THEN 9 Goto line 4 10 ELSE 11 Goto line 17 12 ENDIF 13 ENDFOR  14 ELSE 15 Goto line 19 16 ENDIF 17 Determine all large frequent conceptsets that satisfies the minimum support 18 Extract all Association Rules that satisfies minimum confidence 19 STOP Fig. 5 The GARC algorithm 2\ The Advantages of the GARC Algorithm  The advantages of the GARC algorithm summarize as follows 1\he algorithm permits the end user to change the threshold support an d confidence factor 2\all size of dynamic hash table, since with changing the size of c onceptsets the size of dynamic hash table will change 3\s number of conceptsets, since there is no conceptsets with zero occurrences will occupy a size in a dynamic hash table 3\ The GARC Algorithm Case Study  The D-EART system run on a collection of 100 online XML documents selected from MEDLINE by thresholds values: support s 2% and confidence c 50%. The number of concepts N 30 resulted from the indexing process a nd used for building a dynamic hash table. Fig. 6 shows the number of all fuzzy weighted concepts that labeling each document. Fig. 7 shows the number of the resultant association rules with c 50% which is equal to 64 rules The D-EART system can do different queries on the extracted asso ciation rules. The query s upports the medical researchers by a model of important relationships within the concept features. This model might identify relations between the disease and the suitable treatments, and relations between a treatment and its side effects. Fig. 8 shows the query screen which includes both the categories information and the queries result icons. The user can dete rmine which the categories will get the relations between them. The query results can be saved on the hard disk thro ugh the export icon  Fig.6 The number of fuzzy weighted concepts  Fig. 7 The resultant rules that satisfy c 50  Fig. 8 Query Screen The advantages of D-EART system are as follows 1 The user can access XML textual documents online 2  The design of the D-EART system is based on concept represe ntation and considers the synonymy as a characteristic of the natural language characteristics 3 It is flexible to work on specific or all parts of the documents with the same structure. Moreover it is not fully domain-independent so we can apply it on other domains 4 The proposed GARC algorithm overcomes the drawbacks of the previous algorithms 5 It extracts three types of the associ ation rules depending on the analysis of relations between the concepts only words only and concepts with words. In addition different queries are available on the extracted association rules IV  E XPERIMENTAL  R ESULTS The experiments are performed to compare the p e rformance of both D-EART system and Apriori-concept system for the number of extracted association rules and the execution time. Finally, evalu ate the performance of D-EART system at the three semantic levels: concepts only, words 


only, and concepts with words The corpus of the PubMed abstracts that used in the experim ents is consists of 10000 biomedical abstracts with keyword search breast cancer treatments and side effects   All experim e nts are applied on the 10000 docum ents after divided them into six documentsets 50, 100, 500, 1000 5000, and all 10000 documents. The systems are implemented by using VS .Net 2005 \(C#\a nd the experiments were performed on Intel Core2 Duo, 1.8 GHz system with Windows XP and 2 Giga of RAM A large number of association rules can be extracted by sel ecting the values of minimum support and confidence in the mining process.  The D-EART system gives the best results by using low support and high confidence values Moreover, the number of concepts that entered to the mining process is fewer by using the fuzzy weighting schema. Table V shows the experiments that are applied on various documentsets by different threshol d values. It noticed that the number of extracted association rules in D-EART system is useful and always less than that in Apriori-concept system The reason returns to the strong effect of using the fuzzy weighting schema in D-EART system Fig. 9 and Fig. 10 show that the execution time of Aprioriconcep t system is increased regular ly when the documentsets are increased compared to D-EART system. The mining process in Apriori-word system takes more time for less number of concepts in the documents. The reason is that the mining process in Apriori algor ithm depends on the size of documents rather than the number of concepts. The results show that the execution time of Apriori-concept system is about seventh fold of D-EART system. The D-EART system scans the documents only one time as the number of documents increased. Therefore the size of documents does not influence in the mining process. Finally, the results reveal that the execution time for D-EART system is much better than that of the Apriori-concept system in all cases  TABLE  V   T HE  N UMBER  OF  A SSOCIATION  R ULES  FOR  A PRIORIC ONCEPT  AND  D EART  S YSTEMS Minimum Support s  Minimum Confidence c  No. of Documents Systems s 1 c 50 3 50 7 60 10 50 500 Apriori-concept D-EART 183 71 76 31 17 5 10 2 1000 Apriori-concept D-EART 227 86 91 34 11 4 8 3 5000 Apriori-concept D-EART 239 92  75 27 20 4 15 2 10000 Apriori-concept D-EART 345 135 102 39 37 10 30 7   D5000 0,00 5,00 10,00 15,00 20,00 25,00 30,00 Apriori-concept D-EART Time in minutes s=1, c=50 s=3, c=50 s=7, c=60 s=10, c=50 Fig. 9 Execution time of Apriori-concept and D-EART systems at D=5000 D10000 0,00 5,00 10,00 15,00 20,00 25,00 30,00 35,00 40,00 Apriori-concept D-EART Time in minutes s=1, c=50 s=3, c=50 s=7, c=60 s=10, c=50 Fig. 10 Execution time of Apriori-concept and D-EART systems at D=10000 V  C ONCLUSIONS  AND  F UTURE  W ORK This paper presented a new text mining system for extracting ass o ciation rules based on concepts representation from online textual documents. This system overcame some of the problems in the prev ious EART system and the drawbacks of the Apriori algorithm by using the data structure hash table in the mining process. The results of comparing DEART and Apriori-concept syst ems reveal that the number of extracted association rules in D-EART system is always less than that in Apriori-concept system. Moreover, the execution time for D-EART system is mu ch better than that of Aprioriconcept system in all cases. So concept technique would be suitable to apply to any large corpus of medical text such as portions of the web. The future work will apply D-EART on PDF full text document with figures and images instead of using only the abstract part R EFERENCES  Fast algorithms for mining association rules,” In Jorge B Bocca, Matthias Jarke, and Carlo Zaniolo, editors Proc. 20 th Int. conf. of very Large Data Bases, VLDB Santigo, Chile 1994, pp. 487-499  T. I m ielinski, and A. Swa m i, “Mining association rules between Sets of items in large databases,” In Buneman, Peter and 


Jajodia, Sushil \(Eds Proc. of the ACMSIGMOD Int. Conf. on Management of Data, Washington D.C., 1993, pp. 207–216  e m ettinen, and A. Verka m o, “Applying data mining technique for descriptive phrase extraction in digital document collections,” in Proc. of IEEE Forum on Research and technology Advances in Digital Libraries Santa Barbra CA, 1998  m adzadeh, M. Rahgozar and A. Zarnani, “A new model for discoveri ng XML association rules from XML documents,” in Proc. 3 rd Int. Conf. on Knowledge Mining, ICKM Prague, Czech Republic, 2006 Aug. 25-27, pp. 365-369  i r, Y. Aum a nn, R Feldman, and M. Fresko Maximal association rules: A tool for mining associations in text Journal of Intelligent Information Systems 25:3, pp. 333-345, 2005  A  Ca m p i   M. Kl e m ettinen, and P  L   Lanzi M i n ing association rules fro m XML data,” in Proc. of the 4 th Int. Conf.  on Data Warehousing and Knowledge Discovery Aixen-Provence, France September 4-6, 2002  a m p i, S. Ceri, M. Kl emettinen, and P. L. Lanzi, “A tool for extracting XML as sociation rules,” in Proc. of the 14 th IEEE Int. Conf. on Tools  with Artificial Intelligence \(ICTAI’02 2002, pp. 57–64  and E. Meglio A Text M ining Strategy based on local contexts of words JADT 2004: 7 th Journées internationales d’Analyse statistique des Données Textuelles, 2004  r own Della Piet ra V J deSouza, and P V. Lai, “Class-based ngram models of natural language Computational Linguistics vol. 18 pp. 467–479, 1992  A. Napoli  and Y. T oussaint, “Towards a text mining methodology using association rule extraction,” Published online: 31 May 2005 © Springer-Verlag 2005  i cords and J. Lumpkin, “Der iving general association rules from XML data in Proc. of Fourth ACIS Int. Conference on Software Engineering, Artificial Intelligence, Networking, and Parallel Distributed Computing SNPD'03\Lübeck, Germany, October 16-18 2003  m a n and I. Dagan, “Knowledge discover y in textual databases KDT\ in Proc. 1 st Int. Conf. on Knowledge Discovery and Data Mining 1995  R. Feld m a n, and H. Hir s h, “Mini ng associations in text in the presence of backgr ound knowledge,” in Proc. 2 nd Int. Conf. on Knowledge Discovery and Data Mining Portland, USA, 1996  m a n and I. Dagan and H Hirs h, “Mining text using keyword distributions Journal of Intelligent Systems 10, pp. 281-300, 1998  H. Zhang Q Qiu, and Z. Wang, “PCAR an ef ficient approach for mining association rules 5 th Int. Conf. on Fuzzy Systems and Knowledge Discovery, IEEE 2008  Fürnkranz, “A study using n-gram features for text categorization Austrian Research Institute for Artificial Intelligence Technical Report  OEFAI-TR-98-30 Schottengasse 3 A-1010 Wien, Austria, 1998  Bauer, J Mostafa M. Palakal, and S. Mukhopadhyay C oncept extraction and association from cancer literature WIDM’02  Mclean, Virginia, USA, November 8, 2002  J. Han, J. Pei, and Y Yin, “Mining frequent patt erns without candidate generation,” In W. Chen, J. Naughton, and P. A. Bernstein, editors, 2000 ACM SIGMOD Intl. Conf. on Management of Data ACM Press, 05 2000, pp. 1-12  W  Jin, R. K. Sr ihar i, and X Wu, “Mining concept associations for knowledge discov ery through concept chain queries,” Z.-H. Zhou, H. Li and Q. Yang \(Eds.\2007 LNAI 4426, pp. 555–562 2007.Springer-Verlag Berlin Heidelberg 2007 20  R. Joshi, X. Li , S. Ramachandaran and T. Leong \(2004\. “Automatic Model Structuring from Text using BioMedical Ontology Available http://www.aaai.org/Papers/Workshops/2004/WS-0401/WS04-01-013.pdf   Agrawal, and R. Sr ikant, “Discovering Trends in Text Databases,” in Proc of KDD, Int. Conf. on Knowledge Discovery  NewPort Beach, CA, , August 14-17, 1997, pp. 227-230  A. Dasigi, R. Dingledine, and B Ciliax, “T ext analysis of Medline for discovering functional relationships among genes: evaluation of keyword extraction weighting schemes Int J. Data Mining and Bioinformatics Vol. 1, No 1, 2006  i ve s, and J. Oliveira Concept-based knowledge discovery in texts extracted from the web ACM SIGKDD pp.29-39, July 2000  u b and D. R s n er, “Mining as sociation rules fro m  unstructured documents,” in Proc. 3 rd Int. Conf. on Knowledge Mining ICKM Prague, Czech Republic, Aug. 25-27, 2006, pp. 167-172  D. Rösner, N Is m a il, and F. Torkey  A text m i ning  technique using a ssociation rules extraction Int. J. of Computational Intelligence WASET, Vol. 4, Nr.1, 2007  a ju m d er, M  M i tra, and B. Chaudhuri, “N-gram: a language independent appr oach to IR and NLP Int. Conf. on Universal Knowledge and Language  ICUKL India November 2002  K. Ober m a y e r \(2 009\of concept based keyw ord extraction for tag recomm Available http://www.kde.cs.unikassel.de/ws/dc09/papers/paper_17.pdf   2009 a l library of Medi cine website [Online Available http://www.nlm.nih.gov   a k, “Discovering know le dge from XML documents,” In Wong John, Eds. Encyclopedia of Data Warehousing and Mining. Idea Group Publications 2005  onstrained association rules to predict heart disease,” in Pr oc. IEEE Int. Conf. on Data Mining, ICDM 2001, San Jose, CA, USA , 2001, pp. 433–440  Yong Youn, and U Kim, “A new method for mining association rules from a collection of XML documents ICCSA 2005 LNCS 3481, pp. 936–945, 2005 Springer-Verlag Berlin Heidelberg 2005  I W itten, S  Cunningha m  and G. Buchanan S calable browsing f or large collections: a case study 5 th Conf. digital Libraries  Texas, pp.215-218, 2000   M. Roche J´erom e Az´e, O. Matte-Tailliez, and Y. Kodratoff  Mining texts by association rules discovery in a technical corpus  Intelligent Information Processing and Web Mining Proc. of the Int. IIS: IIPWM'04  Conf held in Zakopane, Poland, May 17-20, 2004      M ining association rules fro m a collection of XML documents using cross filtering algorithm Int. Conf. on Hybrid Information Technology \(ICHIT'06 IEEE, 2006    W   W a n, and G. Dobbie Extr acting association rules from XML documents using XQuery,” in Proc. of the 5th ACM Int. Workshop on Web Information and Data Management \(WIDM’03 2003, pp.94–97  e iss, N Indurkhya, T. Zhang and F. Damerau TEXT MIN ING Predictive Methods for Analyzing Unstructured Information Springer Science-business Media, Inc. 2005  Li a nd T. Leong, “Automated kno wledge extraction for decision model construction: A data mining approach AMIA  Annual  Symposium Proc pp. 758-762, 2003  2009 bMed website [Online]. Available http://www.ncbi.nlm.nih.gov/pubmed  


To resolve this problem, we proposed a new KDD model. It consists of two steps: the first organizes the database records in homogeneous clusters having common properties which permit to deduce the data’s semantic. This step consists of TAH’s and MTAH generation of relieving attributes. The second permits to Discovering Knowledge. It consists to deduce the Fuzzy  Cluster Lattice corresponding to MTAH lattice generated in the first step, then traverse this lattice to extract the Meta Knowledge \( Set of fuzzy associations meta-rules on the clusters \, and in end deduce the rules modeling the Knowledge \(Set of fuzzy associations rules on the attributes\While basing on the hierarchical structure offered by the lattices, we proceed to discover the Knowledge in a hierarchical way. Thus, according to the degree of detail required by the user, this approach proposes a level of knowledge and different views of this knowledge Moreover, this solution is extensible; the user is able to choose the fuzzy method of classification according to the domain of his data and his needs This solution reduced considerably the number of generated rules, offered a better interpretation of the data and optimized both the space memory and the execution time As futures perspectives of this work, we mention 1\o test our approach on several the large data set, and 2\ to define a new intelligent method of evaluation of requests which takes into account the Meta knowledge and/or the knowledge base generated by our KDD model XI  R EFERENCES  1  P. Berkhin, “Survey of clustering data mining techniques“, Technical report, Accrue Software, 2002 2  M. Zaki, “Mining Non-Redundant Association Rules”, Data Mining and Knowledge Discovery, No 9, 2004, p. 223–248 3  G. Stumme, R.Taouil, Y. Bastide, N. Pasquier, and     L. Lakhal Intelligent structuring and reducing of association rules with formal concept analysis”, Proceedings of KI’2001 Conference, Vienna Austria, Lecture Notes in Artificial Intelligence 2174, SpringerVerlag, September 2001, p. 335–350 4  N. Pasquier “Data Mining : Algorithmes d'Extraction et de Réduction des Règles d'Association dans les Bases de Données”, Thèse Département d’Informatique et Statistique, Faculté des Sciences Economiques et de Gestion, Lyon, 2000 5  R. Agrawal, T. Imielinski, and Swami A., “Mining Association Rules between sets of items in large Databases”, Proceedings of the ACM SIGMOD Intl. Conference on Management of Data, Washington USA, June 1993, p. 207-216 6  R. Agrawal, and R. Skirant. “Fast algoritms for mining association rules”. In Proceedings of the 20th Int'l Conference on Very Large Databases, pages 478-499, June 1994 7  N. Pasquier, Y. Bastide, R.Taouil, and L. Lakhal,          “ Efficient Mining of Association Rules Using Closed Itemset Lattices Information Systems Journal, vol. 24, no 1, 1999, p. 25-46 8  M. J. Zaki, and C. J. Hsiao, “ CHARM : An Efficient Algorithm for Closed Itemset Mining ”, Proceedings of the 2nd SIAM International Conference on Data Mining, Arlington, April 2002, p. 34-43 9  G. Stumme, R. Taouil, Bastide Y., Pasquier N., and L. Lakhal, “Fast Computation of Concept Lattices Using Data Mining Techniques BOUZEGHOUB M., KLUSCH M., NUTT W., SATTLER U., Eds Proceedings of 7th Intl. Workshop on Knowledge Representation Meets Databases \(KRDB’00\Berlin, Germany, 2000, p. 129-139 10  G. Stumme, R.Taouil, Y. Bastide, N. Pasquier, and     L. Lakhal Computing Iceberg Concept Lattices with TITANIC”, J. on Knowledge and Data Engineering \(KDE\ vol. 2, no 42, 2002, p. 189222 11  S. Ben Tekaya, S. Ben Yahia, and Y. Slimani. “Algorithme de construction d`un treillis des concepts formels et de détermination des générateurs minimaux”, ARIMA journal, Novembre 2005, Numéro spécial CARI'04, pages: 171-193, 2005 12  T. Hamrouni, S. Ben Yahia, and Y. Slimani. “Prince : Extraction optimisée des bases génériques  de règles sans calcul de fermetures In Proceedings of the Intl. INFORSID Conference, Editions Inforsid Grenoble, France, pages : 353--368, 24-27 May 2005 13  B. Ganter, and R. Wille, Formal Concept Analysis: mathematical foundations. \(translated from the German by Cornelia Franzke Springer-Verlag, Berlin-Hei delberg 1999 14  T.Thanh, H.Siu Cheung, and C. Tru Hoang, “A Fuzzy FCA-based Approach to Conceptual Clustering for Automatic Generation of Concept Hierarchy on Uncertainty Data.” ,CLA 2004, pp. 1–12 ISBN 80-248-0597-9 15  L. Zadeh. Fuzzy sets. Inform ation and Control, \(69\338-353, June 1965 16  M. Sassi, M., A. Grissa Touzi, and H. Ounelli, “ “Interpretting Fuzzy Clustering Results based on Fuzzy Formal Concept Analyis”, IEEE International Conference on Fuzzy Systems. Imperial College London, UK, 2007 17  A. Grissa Touzi, M. Sassi, and H. Ounelli,  “Using Formal Concept Analysis for Flexible Querying Optimization”, 23nd International Conference on Computers and Their  Applications, \(CATA’08 Mexico, Avril 2008 18  A. Grissa Touzi, M. Sassi, and H. Ounelli, “An innovative contribution to flexible query through the fusion of conceptual clustering, fuzzy logic, and formal concept analysis”, International Journal of Computers and Their Applications. Volume. 16, N°. 4, pp 220-233, December, 2009 19  M. Sassi, A. Grissa Touzi, and H. Ounelli, “A Fuzzy Linguistic Database Summarization Approach”, Fuzzy Systems Conference IEEE International Conference on Fuzzy Systems.   Hong Kong, Juin 2008 20  J.C,  Bezdeck,  R.Ehrlich,  and  W.Full,  "FCM: The Fuzzy  C-Means Clustering Algorithm", Computers and Geoscience, vol. 10, no. 2-3 pp. 191–203, 1984 21  N. Pasquier, Y. Bastide, R.Tou il, and L.Lakhal, “Pruning closed itemset lattices for association rules”, Proceedings of 14th International Conference Bases de Données Avancées, Hammamet Tunisia, 26–30 October 1998, p. 177–196 22  M. J. Zaki, “Generating Non-Redundant Association Rules Proceedings of the 6th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining,Boston, MA, August 2000, p 34-43 23  Y. Bastide, R.Taouil, N. Pasquier, G. Stumme, and L.Lakhal Mining frequent patterns with counting inference”, SIGKDD Explorations, vol. 2, no 2, 2000, p. 66-75 24  B. Ganter, “Two basics algorithms in concept analysis”, Technical report, Darmstadt, 1984 
134 


   


                        





