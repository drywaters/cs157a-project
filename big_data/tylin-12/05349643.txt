  Figure 1  A sample XML document with its tree XML Document Clustering Based on Common Tag Names Anywhere in the Structure    Mohamad Alishahi Mehdi Ravakhah Baharak Shakeriaski Mahmud Naghibzade  Islamic Azad Islamic Azad Islamic Azad Ferdowsi university  University Mashhad University Mashhad University Ramsar of Mashhad Branch Branch Branch Computer Department  alishahi@ymail.com ravakhah@gmail.com emino.a@gmail.com naghibzade@um.ac.ir   Abstract  One of the most effective ways to extract knowledge from large information resources is applying data mining methods. Since the amount of information on the Internet is exploding, using XML documents is common as they have many advantages. Knowledge extraction from XML documents is a way to provide more utilizable results. XCLS is one of the most efficient algorithms for XML documents clustering. In this paper we represent a new algorithm for clustering XML documents. This algorithm is an improvement over XCLS algorithm which tries to obviate its problems. We implemented both algorithms and evaluated their clustering quality and running time on the same data sets. In both cases, it is shown that the performance of the new algorithm is better Keywords data mining, clustering, XML documents level structure, level similarity 1. Introduction  Nowadays the World Wide Web is a huge platform of data and this data is created, stored and transferred incrementally. XML \(eXtensible Markup Language documents are one of the best tools for representing and transferring data because of their flexibility and self description, and many of the information resources use them. Since XML tags describe the structural and semantic concepts of information in texts, these documents are known to be semi-structured. This semi structure and irregularity causes problems for knowledge extraction from this kind of documents. So we need data mining techniques such as clustering classification and association rules to extract knowledge. One of the most important advantages of data mining techniques is improving the speed and accuracy of the XML based search engines. We can refer to IEEE paper collection as an example and so searching a specific term in these papers has better results [1XML data exists in two forms: XML documents and XML schemas. XML schema defines structure while XML document define s a y t h at  XML documents are instances of a XML schema and this schema includes acceptable elements, attributes number of element occurrence and other constraints We have to pay attention that among large number of XML documents only the ones that correspond to correct schemas are valid. There are many languages to describe the structure and content of these documents such as DTD \(Document Type Definition\d XSD XML Schema Definition\. XSD has more capabilities than DT ting a n d m odeling  XM L documents is one more subject to be considered. There are three methods for this act: tree structure, graph and time series. Among these, the tree structure is most common as XML documents have hierarchical organization defined by the provider and this organization more naturally corresponds to tree structure. Figure 1 shows an XML document and its corresponding tree structure. In this paper we focus on methods that use this structure. Section 2 is related works for XML clustering and in section 3 we briefly describe how XCLS algorithm that incrementally clusters XML documents works. In section 4 we 978-1-4244-4262-1/09/$25.00 ©2009 IEEE Proceedings of the 14th International CSI Computer Conference \(CSICC'09 588 


represent our algorithm and evaluate and compare it with XCLS in section 5. Section 6 is conclusion and future works  2. Related works  Clustering XML data is more complicated than common text data as XML allows inserting structural and conceptual aspects into document content. A XML document includes tags and data. Tags describing names of elements contain concepts as text data Besides document structure, tags also show the relationship between elements  T h ere are tw o t y pe s  of algorithms for specifying XML documents similarities. First are structure-based algorithms and second are structure and content-based algorithms. In  ere is a clas s i f i ca tion o f th e m e t h ods th at h a v e  been used in XML document clustering so far. Current methods are usually implemented using models based on neural networks, vector, and similarity. The foundation of neural network based models is recursive neural networks and self organizing map. Vector based models use converting XML document format to vector and similarity based models define a similarity criterion between documents to cluster them i n g similarity based model is more common because of its generality. So [2 d e m o n s t r a t e s t h is  m o d e l in tw o  ways: structure level and element level Similarity in structure level measures and describes three set of data 1 Structure and level similarity between documents 2 Structural similarity between documents and schemas 3 Structure and level similarity between schemas In similarity checking we study how similar is a document to other documents and schemas. But in element level we check the similarity between the elements of the two schemas. Element level uses XML document schemas for clustering. Generally the main difference between these two methods is that element level specifies the similarity between tree elements particularly the similarity in the name structure whereas structure level studies the similarity of the whole tree and ignores the elements details In this paper we divide XML document clustering algorithms into two groups   Pair wise methods   Incremental methods Pair wise based algorithms are more common which first create a similarity matrix for each pair of documents. This matrix is initialized by a criterion for measuring similarity between two documents. Finally after completing the matrix we can use a general clustering algorithm such as K-means to locate a document in its proper cluster. For incremental method, we specify the similarity to each existing cluster for each entering document and if the similarity is more than a threshold then it is placed in the corresponding cluster. Else a new cluster is created and the document is placed in it. Generally the main differences between pair wise and incremental algorithms are time complexity and application. In the best case, pair wise algorithms are from order of two but incremental algorithms work in linear time and are useful for online environments. In the next subsection we briefly introduce pair wise clustering algorithms and in next section we describe an incremental algorithm with details because our algorithm presented in this paper is an improvement for this algorithm  2.1. Pair wise algorithms for clustering XML documents  It is common for pair wise algorithms to use tree edit distance to calculate the similarity between two XML documents. The problem is to calculate the minimum distance between two trees T1 and T2 while using insert, delete and edit operations for each node of the tree. We consider a cost for each of these operations that are computed depending on the node tags. So in order to specify the similarity between two XML documents, it suffices to calculate the minimum cost of converting T1 tree to T2 tree by a sequence of operations oth e r w o rds w e ca lcu late h o w  m a n y  operations are required to convert T1 to T2. This cost is the similarity between T1 and T2 The technique we mentioned above is the basis for indicating the similarity between XML documents. But we must pay attention to the time complexity and high cost of this method when we have to cluster many XML documents as we must compute the distance between each pair of documents In order to solve the problem above, many algorithms are designed that try to decrease the cost Some of them are mentioned below   In e t h od is repres e n t e d to s u m m arize  the XML tree. So by decreasing the number of repetition and nested elements and defining a new criterion for structural distance, a better performance is achieved   In [8 usi n g S gr a p h t h e o r y t o r e p r e s e n t X M L  documents and suggesting a new criterion for distance, an improvement on clustering is accomplished. The reason of this claim is encrypting S-graph to a bit string which is simple to be used in clustering Proceedings of the 14th International CSI Computer Conference \(CSICC'09 589 


  Fi g ure 2.   A sam p le XML document with its level structure  3. XCLS incremental algorithm  XCLS \(XML Clustering by Level Structure algorithm tries to cluster XML documents by considering their structures. Of course this algorithm represents XML structure in a new way called level structure. Level structure only uses the elements or tags of the XML document and ignores their contents and attributes. Using a global criterion for computing similarity is a considerable point in incremental methods. Comparing the entering document with existing clusters necessitates having a global criterion This global criterion uses level structure. Level structure acquired from tree representation shows the existing nodes of each leve  Figure 2 shows the level structure of a XML document. In level structure we re-label nodes to integers for ease. The formula \(1\ used to specify the similarity between two objects \(an object can either be a document or a cluster\d focuses on common nodes on each level of two objects    Z r N r CN r CN LevelSim L k k L k L i L j j L j i L i                       1 0 1 1 0 1 0 1 2 1 1 2 1 5  0 5  0 1 The parameters used in formula 1 are   Z Size of the cluster, i.e., the number of documents within the cluster   i CN 1 Sum of occurrences of every common element in the level i of the object 1   j CN 2 Sum of occurrences of every common element in the level j of the object 2   N k Number of elements in level k of the document   r Base Weight: the increasing factor of weight. This is usually larger than 1 to indicate that the higher level elements have more importance than the lower level elements   L Number of levels in the document  In other words, the LevelSim mentioned in \(1 based on common nodes in different levels of objects In next subsections we explain clustering by comparing objects according to level similarity  3.1. The steps of matching the elements of two objects  1. Start with searching for common elements in the first level of both objects. If at least one common element is found, mark the number of common elements with the level number in object 1 0 1 CN d the number of common elements with the level number in object 2 0 2 CN then go to step 2. Otherwise, go to step 3 2. Move both objects to next level \(level i level j d search for common elements in these new levels; if at least one common element is found, mark the number of common elements with the level number in object 1 i CN 1   and the number of common elements with the level number in object 2 j CN 2  then go to step 2. Otherwise, go to step 3 3. Only move object 2 to next level \(level j en search for common elements in the original level i f object 1 and the new level j object 2. If at least one common element is found, mark the number of common elements with the level number in object 1  i CN 1 d the number of common elements with the level number in object 2 j CN 2 en go to step 2 Otherwise, go to step 3 4. Repeat the process until all levels in either object have been matched We can calculate the similarity between two objects by above stages and then cluster accordingly. Figure 3 shows an example for calculating the level similarity between two documents. The calculated measure by the given formula is always between zero and one. If there is no common element between two objects in the current level then it proceeds to the next level of the second object. So the level similarity LevelSim 1 2  differs from LevelSim 2 1 We must calculate both cases and consider the greater value as the similarity between two objects Proceedings of the 14th International CSI Computer Conference \(CSICC'09 590 


  Fi g ure 3.   An exam p le for calculatin g the similarit y  Figure 5.   An example for the problem of the XCLS algorithm  Figure 4.   XCLS clustering algorithm 3.2. Clustering by level similarity  The general procedure for clustering is that the first document enters and forms the first cluster. The next document enters and the similarity between the two existing documents is computed. If the calculated number is greater than the user provided threshold then the entering document is placed in the existing cluster Pay attention that in this case two documents with possibly different structures are located in the same cluster. So we should merge their structures to keep the algorithm incremental. To merge the documents we congregate the elements of the same levels into a new level structure called cluster level structure. In fact the level structure of a cluster is the representative of the existing documents in that cluster. But if the computed similarity is less than the user provided threshold then the entering document forms a new cluster. This procedure is repeated and for each entering document we compare it with existing clusters. If the maximum calculated similarity is greater than the user provided threshold then the document is placed in the most similar cluster, otherwise it forms a new cluster Finally, this procedure is performed for the last document when the clustering task is finished. Two of the advantages of this algorithm are its linear time and its quality of clustering. But one of its disadvantages is specifying the threshold by user as different threshold may cause different results. Also the sequence of entering the documents is the other problem that may cause different clustering results. To obviate the latter problem a reassignment phase is used. In this phase some of the documents are selected randomly and are assigned to the clusters, again. This task is repeated until there is no improvement in placing documents in two consecutive iterations. Figure 4 shows the clustering algorithm w i t h t h e reas s i gnm e n t ph a s e   4. XCLS  As we studied the XCLS algorithm in more details we observed some problems that are XCLS's deficiency. Figure 5 shows an example for which the process of matching the elements of two objects by XCLS algorithm is unable to find all common elements of the two objects, consequently the real similarity cannot be obtained. In this example there are six elements in each object with five of them being common but the similarity that is calculated by XCLS is equal to zero. This is not reasonable Thus in this paper we try to suggest a new algorithm named XCLS+ and this algorithm uses a new method for matching the common elements between two objects. As we described XCLS we see that XCLS orders the elements by level and in each level tries to find the common elements and fill the i CN 1 and j CN 2  parameters, but in XCLS+ we try to order the elements by tag names and according to algorithm 1 in Figure 6 we are able to find all common elements Note that we store all the XML documents as data base tables and we can easily order them by tag name or level. Figure 7 is an example of a XML document that is stored by data base tables. By storing the tag names, their levels, and their parents we can easily retrieve the original documents Proceedings of the 14th International CSI Computer Conference \(CSICC'09 591 


 Algorithm 1   The steps of matching the elements of two objects in XCLS Input O1,O2 Two Novel Level Structure represented as Table which Ordered by TagName  Level  OL1 the number of rows of O1 in OL1 1  OL1 2  OL1 w  OL2 the number of rows of O2 in OL2 1  OL2 2  OL2 z   Output CN1 1 w  num be r  CN2 1 z  num be r   Method 1\epeat 2\ Compare each row i of O1 with each row j of O2  3\f O1.TagName  O2.TagName    CN1  OL1 i    CN2  OL2j   Go to the next rows of both object O1  O2  4\f O1.TagName  O2.TagName  Go to the next row of just O2  5\lse Go to the next row of just O1  6\ until all rows of both objects checked Figure 6.   The XCLS+ matching process algorithm  Figure 7.   An XML document and its corresponding table  Figure 8.  An example for the steps of XCLS+ algorithm The description of algorithm 1 is as follow: we order the tables by tag names then we try to find the common tag names disrespectful of levels of matched tags. For each pair of matched tags found, the i CN 1  and j CN 2 parameters are computed by using the level attribute of the tags. Since we first find all possible matched tags and then consider the levels of the matched tags to compute i CN 1 and j CN 2 all possible pairs of equal tag names of the two objects are found However, based on XCLS only matched tags of matched levels are found. Figure 8 shows the difference between XCLS and XCLS  5. Experimental evaluations  In order to show the improvement in XCLS+ we try to compare it with XCLS algorithm under similar circumstances. All the experiments for both algorithms are done on the same data sets which are consisting of heterogeneous XML documents. These data sets are standard and are usually used for XML clustering algorithm’s evaluation. We compare both algorithms from the aspects of quality of clustering and running time Both XCLS and XCLS+ algorithms and also the evaluation criteria were implemented with Microsoft visual studio 2008 platform using C# language and all documents of data sets were stored as tables in a Microsoft SQL server 2005 data base. All the experiments were done in a machine with 3.2GHZ Intel Celeron CPU and 1GB of RAM. In the next two subsections we describe the data sets and the evaluation criteria which measure the quality of clustering and finally the results will be discussed  5.1. Data set  The data used in experiments are \(1\e XML Files data set obtained from d \(2 e Mov i eDB corpus obtained from T h e XML f ile s data s e t contains 460 XML documents. The documents are from various domains which are shown in table 1. The number of tags varies from 10 to 100 in these sources The nesting level varies from 2 to 15. Majority of these domains contains a number of different documents that have structural and semantic differences. Hence, even though documents are from the same domain, they might not be considered similar enough to be grouped into the same clusters. The MovieDB corpus has 11 thematic and 11 possible structure classes. The MovieDB collection is derived into many versions \(mdb-s-0, m-db-s-1 and m-db-s-2\ter a series of transformation for adding the complexity in the clustering process making each later version more difficult than former. Each movie set contains 4800 XML files. The MovieDB corpuses have 190–200 distinct tags [1  Proceedings of the 14th International CSI Computer Conference \(CSICC'09 592 


5.2. Evaluation Criteria  The evaluation criteria for XML documents clustering are categorized in two groups: the first one is internal cluster quality evaluation criteria and the second one is external cluster evaluation criteria Internal evaluation criteria have no information about the data sets and try to determine how similar the documents are. But here, the problem is that in XCLS the similarity between documents is measured by comparing corresponding levels while in XCLS+ a new similarity algorithm is suggested. So, as we used two different similarity measures it is not reasonable to compare these two algorithms based on internal evaluation criteria. Consequently, in this article we use the external evaluation criteria which are based on the comparison of clusters’ classes to known external classes. Entropy, purity, and FScore are used as external evaluation criteria in this article, which are taken from c ribe d as f o llo w   The entropy measure looks at how the various classes of documents are distributed within each cluster. Given a particular cluster C i of size n i the entropy of a cluster is defined as    k r i r i i r i i n n n n k C E 1 log log 1    Where k is the number of classes in the dataset, and r i n is the number of documents of the r th class that are assigned to the i th cluster. The entire clustering solution’s entropy is the sum of the individual cluster entropies weighted according to the cluster size. The formula is given here   k i i i C E N n Entropy 1    A perfect clustering solution will be the one that leads to clusters that contain documents from only a single class, in which case the entropy will be zero. In general, smaller the entropy value, the better the clustering solution is Purity measures the extent to which each cluster contains documents primarily from one class. The formula of purity of a cluster is  max 1   r i i i n n C P   The purity of entire clustering solution is obtained as a weighted sum of the individual cluster purity   k i i i C P N n Purity 1    In general, larger the value of purity, the better the clustering solution is FScore is a combination of precision and recall Precision defines the rate of correct matches in the generated solution, and Recall defines the rate of correct matches in the model solution Given an XML document category Z r with the n r  number of similar XML documents, and a cluster C i  with the n i number of similar XML documents categorized by the clustering algorithm. Let r i n be the number of documents in cluster C i  belonging to Z r  Precision \(correctness\ is defined as p  Z r  C i  r i n/n i Recall \(accuracy\s defined as r  Z r  C i  r i n  n r  The FScore combining precision and recall with equal weights is defined as r i r i i r i r i r i r i r n n n C Z r C Z p C Z r C Z p C Z F      2                 Table1. Data set of various domains with amount of 460 XML files No Class 74 Movie 22 Universit y 207 Automobile 16 Bibliograph y 38 Compan y 24 Hospitality message 10 Travel 10 Orde r 4 Auctio n 2 Appointment 15 Document page 2 Bookstore 20 Pla y 12 Club 2 Medical 2 Nutritio n  Proceedings of the 14th International CSI Computer Conference \(CSICC'09 593 


  Figure 9.  Comparing running time of XCLS and XCLS The FScore value of a category Z r  is the maximum  FScore value attained in any cluster of the clustering solution. Hence, the FScore of the overall clustering solution is defined as the sum of the individual class FScores weighted differently according to the number of documents in the class N C Z F n FScore k r i r r   1     where k is the number of clusters. A good clustering solution has the FScore value close to one  5.3. Quality evaluation  Table 2 shows all the experiments and assessments about the quality of clustering. As shown in table, we tried to compare the algorithms under different circumstances and each time we run the algorithms with different parameters and record the results. The results declare that XCLS+ clusters the documents with better quality  5.4. Running Time Evaluation  The time complexity for both algorithms XCLS and XCLS+ is equal because the basis of both algorithms is equal and the difference is the way they use to find the common elements between two documents. Thus as the XCLS algorithm assert time complexity is linear but the running time is different because as explained previously XCLS+ algorithm is able to find all common elements just by one iteration but XCLS needs two iterations. According to recent explanation our algorithm must have better running time than the XCLS. After calculating the running time for one of our data sets Figure 9 proves our claim  6. Conclusion and future works  We presented an algorithm for clustering XML documents based on the XCLS algorithm. We compared our algorithm with the XCLS algorithm and perceived that it works better than XCLS or in the worst case it performs like XCLS. Although this Table2. The experiments and assessments about the quality of clustering  Data set Algorith m  r facto r Threshol d Entrop y Purit y FScore Cluster No XML Files XCLS 2 0.75 0.06 0.86 0.88 21 2 0.6 0.07 0.83 0.84 21 1.5 0.75 0.08 0.85 0.86 21 XCLS 2 0.75 0.04 0.94 0.96 22 2 0.6 0.04 0.93 0.94 22 1.5 0.75 0.05 0.91 0.92 22 m-db-s-0 XCLS 2 0.75 0.21 0.73 0.75 11 2 0.6 0.20 0.73 0.73 11 1.5 0.75 0.20 0.72 0.73 11 XCLS 2 0.75 0.18 0.79 0.80 11 2 0.6 0.17 0.78 0.79 11 1.5 0.75 0.18 0.75 0.78 11 m-db-s-1 XCLS 2 0.75 0.26 0.69 0.71 11 2 0.6 0.24 0.68 0.70 11 1.5 0.75 0.26 0.68 0.69 11 XCLS 2 0.75 0.17 0.72 0.72 11 2 0.6 0.17 0.71 0.71 11 1.5 0.75 0.18 0.72 0.71 11 m-db-s-2  XCLS 2 0.75 0.31 0.66 0.67 11 2 0.6 0.30 0.66 0.68 11 1.5 0.75 0.32 0.65 0.66 11 XCLS 2 0.75 0.28 0.69 0.71 11 2 0.6 0.27 0.68 0.70 11 1.5 0.75 0.28 0.69 0.71 11  Proceedings of the 14th International CSI Computer Conference \(CSICC'09 594 


algorithm solves some of the problems of the XCLS algorithm but one of its remained problem is specifying the threshold that may affect its performance remarkably. Future works for this paper can be: specifying the threshold by the algorithm automatically, considering the concepts of elements for clustering, designing a two phases algorithm for clustering as in one phase using pair wise algorithms and in another using incremental algorithms. Finally as the role of XML documents becomes more important, we hope our algorithm would be useful for clustering XML documents especially in search engines that search huge resources of the World Wide Web  7. References  1 R  N a y a k    F a s t a nd ef f e c t i v e c l us te r i ng of XML da ta using structural information", Knowl. Inf. Syst. 14\(2\008 pp. 197-215  2 R. N a y a k    X ML D a ta Mini ng  P r oc e s s a n d  Applications", in Song, Min and Wu, Yi-Fang, Eds, Idea Group Inc. /IGI Global, 2008  3 R. Nay a k  T  T r an  A P r o g ressiv e Clu s terin g  A l g o rith m to Group the XML Data by Structural and Semantic Similarity", IJPRAI 21\(4\, 2007, pp. 723-743  4 L  De noy e r P  G a llina r i R e port o n the  X M L m i ning track at INEX 2005 and INEX 2006: categorization and clustering of XML documents", SIGIR Forum 41\(1\, 2007 pp. 79-90  5 S. A b ite bo ul P. B u ne m a n and D  S u c i u   D a t a on the  Web: From Relations to Semistructured Data and XML Morgan Kaumann, CA, 2000  6 S Fles ca, G  Ma nc o E M a sc ia ri, L  P o ntie ri a n d A   Pugliese, "Fast detection of XML structural similarities IEEE Trans. Knowl. Data Engin 7 2\, 2005, pp. 160–175  7 T  Da la m a g a s T  Che ng K  W i nk e l T  K. Se llis, "A methodology for clustering XML documents by structure Inf. Syst. 31\(3\2006, pp. 187-228  8 W  L i a n D  W  C h e ung  N  Ma m oulis S Y i u   A n Efficient and Scalable Algorithm for Clustering XML Documents by Structure", IEEE Trans. Knowl. Data Eng 16\(1\, 2004, pp. 82-96  9 T h e W i sc onis n  s XML d a ta ba nk  A c ce s s e d f r o m   http://www.cs.wisc.edu/hiagara/data.html. Cited sept 2004 The XML data repository. Accessed from http://www.cs.washington.edu/research/xmldatasets/. Cited Sept 2004  10 I N EX 2 00 5 D o c u m e nt m i ning tr a c k  A c c e s se d f r om   http://inex.is.informatik.uni-duisburg.de/2005  11 Y  Zha o G  K a r y pis   C rite rion f unc ti ons f o r doc um e n t clustering: Experiments and analysis", Department of Computer Science, University of Minnesota, Minneapolis 2001 Proceedings of the 14th International CSI Computer Conference \(CSICC'09 595 


9 Appendix Fig 6: Forest Cover Types of the U.S. \(Source. USGS National Atlas of US Summary of Forest Cover Type Data Type Multivariate Abstract The forest cover type for 30 x 30 meter cells obtai ned from US Forest Service \(USFS\ Region 2 Resource Information System RIS\ data Data Characteristics The actual forest cover type for a given observatio n \(30 x 30 meter cell\ was determined from US Fores t Service \(USFS\ Region 2 Resource Information System RIS data Independe nt variables were derived from data originally obta ined from US Geological Survey \(USGS\ and USFS data. Data is in raw form \(not scaled\ and contains binary \(0 or 1 columns of data for qualitative independent variables \(wilderness areas and soil types Summary Statistics Number of instances observations 581012 Number of Attributes 54 Attribute breakdown 12 measures, but 54 columns of data \(10 quantitativ e variables, 4 binary wilderness areas and 40 binary soil type variables Missing Attribute Values None 43 


   C4.2 Open GL has excellent documentation that could help the developer learn the platform with ease C4.3 Developer has very little ex perience in working with Open GL platform  For our case study, alternative B i.e. Adobe Director was the most favorable alternative amongst all the three. It catered to the reusability criteria quite well and aimed at meeting most of the desired operational requirements for the system   6. CONCLUSION & FUTURE WORK  The main contribution of this paper is to develop an approach for evaluating performance scores in MultiCriteria decision making using an intelligent computational argumentation network. The evaluation process requires us to identify performance scores in multi criteria decision making which are not obtained objectively and quantify the same by providing a strong rationale. In this way, deeper analysis can be achieved in reducing the uncertainty problem involved in Multi Criteria decision paradigm. As a part of our future work we plan on conducting a large scale empirical analysis of the argumentation system to validate its effectiveness   REFERENCES  1  L  P Am g o u d  U sin g  A r g u men ts f o r mak i n g an d  ex p lain in g  decisions Artificial Intelligence 173 413-436, \(2009 2 A  Boch m a n   C ollectiv e A r g u men tatio n    Proceedings of the Workshop on Non-Monotonic Reasoning 2002 3 G  R Bu y u k o zk an  Ev alu a tio n o f sof tware d e v e lo p m en t  projects using a fuzzy multi-criteria decision approach Mathematics and Computers in Simualtion 77 464-475, \(2008 4 M T  Chen   F u zzy MCD M A p p r o ach t o Selec t Serv ice  Provider The IEEE International Conference on Fuzzy 2003 5 J. Con k li n  an d  M. Beg e m a n   gIBIS: A Hypertext Tool for Exploratory Policy Discussion Transactions on Office Information Systems 6\(4\: 303  331, \(1988 6 B P  Duarte D e v elo p in g a p r o jec ts ev alu a tio n sy ste m based on multiple attribute value theroy Computer Operations Research 33 1488-1504, \(2006 7 E G  Fo rm an  T h e  A n a l y t ic Hier a rch y P r o cess A n  Exposition OR CHRONICLE 1999 8 M. L ease  an d J L  L i v e l y  Using an Issue Based Hypertext System to Capture Software LifeCycle Process Hypermedia  2\(1\, pp. 34  45, \(1990 9  P e id e L i u   E valu a tio n Mo d e l o f Custo m e r Satis f a c tio n o f  B2CE Commerce Based on Combin ation of Linguistic Variables and Fuzzy Triangular Numbers Eight ACIS International Conference on Software Engin eering, Artificial Intelligence Networking and Parallel Distributed Computing, \(pp 450-454 2007  10  X  F L i u   M an ag e m en t o f an In tellig e n t A r g u m e n tatio n  Network for a Web-Based Collaborative Engineering Design Environment Proceedings of the 2007 IEEE International Symposium on Collaborative Technologies and Systems,\(CTS 2007\, Orlando, Florida May 21-25, 2007 11 X. F L i u   A n In ternet Ba se d In tellig e n t A r g u m e n tatio n  System for Collaborative Engineering Design Proceedings of the 2006 IEEE International Symposium on Collaborative Technologies and Systems pp. 318-325\. Las Vegas, Nevada 2006 12 T  M A sub jec tiv e assess m e n t o f altern ativ e m ission  architectures for the human exploration of Mars at NASA using multicriteria decision making Computer and Operations Research 1147-1164, \(June 2004 13 A  N Mo n ireh  F u zzy De cisio n Ma k i n g b a se d o n  Relationship Analysis between Criteria Annual Meeting of the North American Fuzzy Information Processing Society 2005 14 N  P a p a d ias HERMES Su p p o rti n g A r g u m e n tative  Discourse in Multi Agent Decision Making Proceedings of the 15th National Conference on Artifical Intelligence \(AAAI-98  pp. 827-832\dison, WI: AAAI/MIT Press,  \(1998a 15  E. B T riantaph y llo u   T h e Im p act o f  Ag g r e g atin g Ben e f i t  and Cost Criteria in Four MCDA Methods IEEE Transactions on Engineering Management, Vol 52, No 2 May 2005 16 S  H T s a u r T h e Ev alu a tio n o f airlin e se rv ice q u a lity b y  fuzzy MCDM Tourism Management 107-115, \(2002 1 T  D W a n g  Develo p in g a f u zz y  T O P S IS app r o ach  b a sed  on subjective weights and objective weights Expert Systems with Applications 8980-8985, \(2009 18 L  A  Zadeh  F u z z y Sets   Information and Control 8  338-353, \(1965  152 


                        





