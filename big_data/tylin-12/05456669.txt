D:20100304011742  
Abstract\227 
2010 2nd International Asia Conference on Informatics in Control, Automation and Robotics 978-1-4244-5194-4/10/$26.00 \2512010 IEEE                                                                  CAR 2010 Research on Algorithm of Association Rules in Distributed Database System Lijuan Zhou Information Engineering College Capital Normal University Beijing China Zlj87@tom.com Shuang Li Information Engineering College Capital Normal University Beijing China lishuang924@163.com Mingsheng Xu Information Engineering College Capital Normal University Beijing China xmsh1987@gmail.com 
This dissertation prop oses a new algorithm of distributed mining associati on rules using the improved Apriori algorithm based on analyses and introduction of the basic concepts and algorithms of mining association rules and mining association rules in distributed databases Using improved Apriori algorithm to directly produce all of local frequent itemset in each crunode, rather than iteratively selecting candidate itemse t Then gather all of local multifarious itemset to broadcast to the general node producing the global frequent it emset of association rules. In the process, the data is no lo nger saved with the affair ID as the key word. We take the item ID as the new key word. The performance of the improved Apriori algorithm has been improved through cutting down the store space. While the 
227association rules 
distributed database data mining 
general node gathers all of local frequent itemset to select the global frequent itemset, it ne eds only a broadcast probably needing three broadcasts worst. This raised the efficiency of the new algorithm of Associati on Rules in Distributed Database System 
I INTRODUCTION With the widely application of the Internet/Intranet and the sophisticated of distributed technologies, database and data warehouse has been applied in the distributed environment of amounts of data. As the data are located in different places, an efficient di stributed algorithm is needed to mining the large number of distributed data. The proprietary mining algorithm is corresponding to the characteristics of association r ules mining in distributed database system At present, the researchers of data mining have done some research on this. There are many distributed mining algorithm of association rules and the improved ones which has mined the valuable association rules from the distributed database system. But the traffic of generating candidate set is too heavy directly affecting the efficiency of the algorithm especially faced e normous databases or sparse data. In this paper, based on the analysis the theory of association rules and the apriori algorithm we proposed an improved apriori algorithm to create local frequent itemset rapidly, and then generate the global frequent itemsets only through a communication 
 
Index Terms 
Association Rule provides a kind of very simple but worthy description form for the rule mode in data mining Association Rule is one of the most popular methods descript partial mode of data mining. It simply presents the rate of some particular affairs in database taking place together, particularly is applicable to a sparse data sets 
Define 4 the Dimension of itemset: The count of items in an itemset is called the dimension of the 
II ASSOCIATION RULES AND IMPROVED ALGORITHM 
A Association Rules Concept 
Define 3 Itemset: It is the sets of whole item in a transaction database. And it is marked as capital I Any sub sets x of I is itemset in D. I={i  1 i 2 205,i m 
Define 1Item: It is a field of the transaction database We usually use small letter i 1 m 
Define 2 Transaction: It is corresponding to a record of the database. Transaction usually is marked as small letter t to mark item i t i i 1 i 2 205,i p Each transaction has an only identifier called TID. The whole set of transaction t i constitutes a database D. D t 1 t 2 205,t n 
I,and X 
Y. There into X 
itemset. The itemset with dimension K is marked as K-Itemset  2010 2nd International Asia Conference on Informatics in Control, Automation and Robotics 
Y separately is the premise and the conclusion of the association rule 
Define 5 Association Rule: The association rule is a contain model looking like X 
Its meaning is the emergence of X causing the emergence of Y.X 
Define 6 Support: The support of association rule X 
Y in transaction database is a ratio. The ratio is between the count of itemset which contains X and Y, and the count of all of itemset. That marks support\(X 
I,Y Y\.The more high the support of association rule is, the more high the frequency of association rule\222s and itemset\222 emergence is. The minimum support appointed by the customer according to needing is marked as MinSup D:20100304011742  
Y\. That is the percent of the itemset containing X and Y at the same time in the transaction database If item t=XUY, then the support of item t support \(t\ =support\(X 
978-1-4244-5194-4/10/$26.00 \2512010 IEEE                                                                  CAR 2010 Research on Algorithm of Association Rules in Distributed Database System Lijuan Zhou Information Engineering College Capital Normal University Beijing China Zlj87@tom.com Shuang Li Information Engineering College Capital Normal University Beijing China lishuang924@163.com Mingsheng Xu Information Engineering College Capital Normal University Beijing China xmsh1987@gmail.com 
Abstract\227 
This dissertation prop oses a new algorithm of distributed mining associati on rules using the improved Apriori algorithm based on analyses and introduction of the basic concepts and algorithms of mining association rules and mining association rules in distributed databases Using improved Apriori algorithm to directly produce all of local frequent itemset in each crunode, rather than iteratively selecting candidate itemse t Then gather all of local multifarious itemset to broadcast to the general node producing the global frequent it emset of association rules. In the process, the data is no lo nger saved with the affair ID as the key word. We take the item ID as the new key word. The performance of the improved Apriori algorithm has been improved through cutting down the store space. While the general node gathers all of local frequent itemset to select the global frequent itemset, it ne 
eds only a broadcast probably needing three broadcasts worst. This raised the efficiency of the new algorithm of Associati on Rules in Distributed Database System Association Rule provides a kind of very simple but 
227association rules 
distributed database data mining 
I INTRODUCTION With the widely application of the Internet/Intranet and the sophisticated of distributed technologies, database and data warehouse has been applied in the distributed environment of amounts of data. As the data are located in different places, an efficient di stributed algorithm is needed to mining the large number of distributed data. The proprietary mining algorithm is corresponding to the characteristics of association r ules mining in distributed database system At present, the researchers of data mining have done some research on this. There are many distributed mining algorithm of association rules and the improved ones which has mined the valuable association rules from the distributed database system. But the traffic of generating candidate set is too heavy directly affecting the efficiency of the algorithm especially faced e normous databases or sparse data. In this paper, based on the analysis the theory of association rules and the apriori algorithm we proposed an improved apriori algorithm to create local frequent itemset rapidly, and then generate the global frequent itemsets only through a communication II ASSOCIATION RULES AND IMPROVED ALGORITHM 
A Association Rules Concept 
 
Index Terms 
worthy description form for the rule mode in data mining Association Rule is one of the most popular methods descript partial mode of data mining. It simply presents the rate of some particular affairs in database taking place together, particularly is applicable to a sparse data sets 
Define 4 the Dimension of itemset: The count of items in an itemset is called the dimension of the itemset. The itemset with dimension K is marked as K-Itemset  
Define 2 Transaction: It is corresponding to a record of the database. Transaction usually is marked as small letter t to mark item i t i i 1 i 2 205,i p Each transaction has an only identifier called TID. The whole set of transaction t i constitutes a database D. D t 1 t 2 205,t n 
Define 3 Itemset: It is the sets of whole item in a transaction database. And it is marked as capital I Any sub sets x of I is itemset in D. I={i  1 i 2 205,i m 
Define 1Item: It is a field of the transaction database We usually use small letter i 1 m 
I,and X 
Define 5 Association Rule: The association rule is a contain model looking like X 
Y separately is the premise and the conclusion of the association rule 
Y. There into X 
Its meaning is the emergence of X causing the emergence of Y.X 
Define 6 Support: The support of association rule X 
Y in transaction database is a ratio. The ratio is between the count of itemset which contains X and Y, and the count of all of itemset. That marks support\(X 
I,Y Y\.The more high the support of association rule is, the more high the frequency of association rule\222s and itemset\222 emergence is. The minimum support appointed by the customer according to needing is marked as MinSup 
Y\. That is the percent of the itemset containing X and Y at the same time in the transaction database If item t=XUY, then the support of item t support \(t\ =support\(X 


D:20100304011742  IT 11 T 12 T 3 17 IT 32 T 7 T 12 T 14 T 16 T 6 17 IT 65 T 8 T 13 T 18 T 5 20 IT 71 T 3 T 5 T 7 T 9 T 11 T 13 T 15 T 9 17 D:20100304011742  IT 11 T 12 T 3 17 IT 32 T 7 T 12 T 14 T 16 T 6 17 IT 65 T 8 T 13 T 18 T 5 20 IT 71 T 3 T 5 T 7 T 9 T 11 T 13 T 15 T 9 17 14 14 20 T 10 20 T 10 12 13 15 17 18 19 T 14 20 Item Affair Flag2 Item Affair Flag2 T 2 I  2 I 3 I 3 4 T T 2 I  2 I 3 I 3 4 I 2 T  2 T 4 T 6 T 8 T 10 T 12 T 13 T 14 T 18 T 10 20 I T 4 2 T 3 T 4 T 6 T 8 T 10 T 11 T 12 T 13 T 14 T 15 T 16 T 1 I T Affair Item Flag1 Affair Item Flag1 T T T T T T T T T T T T T T T T T T T T T T T T B Apriori Algorithm and Related Algorithm Analyse B Apriori Algorithm and Related Algorithm Analyse C Basic Thought and Process of Improved Algorithm C Basic Thought and Process of Improved Algorithm Define 9 Strong rule and Weak rule: If support\(X Define 9 Strong rule and Weak rule: If support\(X  m in_support  min_support, the largest count k of item of the largest frequent assumed before is 4. Now from the tansformed data storage select the item with Flag2   m in_support  min_support, the largest count k of item of the largest frequent assumed before is 4. Now from the tansformed data storage select the item with Flag2  8 5 3 4 5 7 8 9 12 13 15 17 18 19 T 14 20 8 5 3 4 5 7 8 9 into the transaction whether its Flag1i is larger than k. If such transaction\222s count satisfies the minimum support, take down temporarily. Then get the lately small database TABLE II DATA STORAGE TAKING ITEM AS KEY WORD into the transaction whether its Flag1i is larger than k. If such transaction\222s count satisfies the minimum support, take down temporarily. Then get the lately small database TABLE II DATA STORAGE TAKING ITEM AS KEY WORD Y\nfidence is the percent of the transaction sets containing X and Y at the same time in the transaction database. This is a conditional probability The higher the confidence of association rule is, the more dependable the rule is. The minimum confidence appoin ted by the customer usually is marked as MinConf Y\nfidence is the percent of the transaction sets containing X and Y at the same time in the transaction database. This is a conditional probability The higher the confidence of association rule is, the more dependable the rule is. The minimum confidence appoin ted by the customer usually is marked as MinConf Y  Y  ti X Y ti ti D support X Y confidence X Y p Y X tj X tj tj D support X  ti X Y ti ti D support X Y confidence X Y p Y X tj X tj tj D support X  ti X Y ti ti D support X Y p X Y D   ti X Y ti ti D support X Y p X Y D   TI 11 I 2 7 TI 34 I 5 I 3 7 TI 42 I 4 I 5 3 TI 55 I 6 I 3 7 TI 62 I 2 4 TI 73 I 5 I 3 7 TI 82 I 4 I 5 I 4 6 TI 95 I 2 7 TI 10 2 I 4 I 3 5 TI 11 4 I 2 7 TI 12 1 I 2 I 3 I 4 I 5 5 TI 13 2 I 4 I 5 I 6 I 5 7 TI 14 2 I 3 I 3 4 TI 15 4 I 5 I 3 7 TI 16 3 I 2 4 TI 17 1 I 3 I 5 I 7 4 TI 18 2 I 4 I 5 I 4 6 TI 19 1 5 TI 20 2 I 4 I 5 I 4 6 TI 11 I 2 7 TI 34 I 5 I 3 7 TI 42 I 4 I 5 3 TI 55 I 6 I 3 7 TI 62 I 2 4 TI 73 I 5 I 3 7 TI 82 I 4 I 5 I 4 6 TI 95 I 2 7 TI 10 2 I 4 I 3 5 TI 11 4 I 2 7 TI 12 1 I 2 I 3 I 4 I 5 5 TI 13 2 I 4 I 5 I 6 I 5 7 TI 14 2 I 3 I 3 4 TI 15 4 I 5 I 3 7 TI 16 3 I 2 4 TI 17 1 I 3 I 5 I 7 4 TI 18 2 I 4 I 5 I 4 6 TI 19 1 5 TI 20 2 I 4 I 5 I 4 6                                           Y  Y  Define 7 Confidence: It is the ratio between the count of transaction containing X and Y and the count of transaction containing X. That is marked as confidence\(X Define 7 Confidence: It is the ratio between the count of transaction containing X and Y and the count of transaction containing X. That is marked as confidence\(X Define 8 Frequent Itemset: That means the itemset whose support is not lower than the minimum support MinSup In 1994 Agrawal etc. put forward famous Apriori algorithm according to the property of association rule: the sub sets of the frequent itemset is also frequent itemset, the supersets of non-frequent itemset is also non-frequent itemset. The algorith m each time makes use of k-frequent itemset carrying on conjunction to get k+1 candidate itemset Then get k+1 frequent itemset through cutting. So keep on until there is not frequent itemset. The Apriori algorithm has to firstly produce frequent itemset with small count. Next through iteration produces frequent itemset with great count So when Apriori algorithm pr oduces each length frequent itemset, it has to scan the database for a time. In addition, it must produce candidate itemset at first. Thus the time of scanning the database is up to the count of the largest frequent itemset Define 8 Frequent Itemset: That means the itemset whose support is not lower than the minimum support MinSup In 1994 Agrawal etc. put forward famous Apriori algorithm according to the property of association rule: the sub sets of the frequent itemset is also frequent itemset, the supersets of non-frequent itemset is also non-frequent itemset. The algorith m each time makes use of k-frequent itemset carrying on conjunction to get k+1 candidate itemset Then get k+1 frequent itemset through cutting. So keep on until there is not frequent itemset. The Apriori algorithm has to firstly produce frequent itemset with small count. Next through iteration produces frequent itemset with great count So when Apriori algorithm pr oduces each length frequent itemset, it has to scan the database for a time. In addition, it must produce candidate itemset at first. Thus the time of scanning the database is up to the count of the largest frequent itemset Literature [3] introduces two pieces of inference as follows Inference 1: If the count of item in K-frequent itemset LK is smaller than or equal to K, then the itemset is the sets of the largest frequent itemset Inference 2: The count of item in the largest frequent itemset LK is smaller than or equal to the largest count K of items, which satisfies support in all of transactions The New_Apriori algorithm makes use of above-mentioned inference, at first making sure the count K of item of the largest frequent itemset. It directly gets the largest frequent itemset L K As follows introduce the New_Apriori algorithm with an example among these transactions, whose count of item is larger than or equal to K. Then consider these transactions one by one in order, whose count of item is k-1 and k-2.Dine the frequent itemset, which does not belong to the largest frequent itemset with the largest count of item Table 1 is an original affair database. Each affair T represents a student's record; the I 1 I 7 Scan the database to take down C C[1  1, C[2 5  8, C[4 4, C[5 2 a nd t h e Fl ag 1m ark of each transaction. At the same time change data stor age structure taking item as the key word means different attributes respectively. Minimum support min_support =4 TABLE I ORIGINAL AFFAIR DATABASE Literature [3] introduces two pieces of inference as follows Inference 1: If the count of item in K-frequent itemset LK is smaller than or equal to K, then the itemset is the sets of the largest frequent itemset Inference 2: The count of item in the largest frequent itemset LK is smaller than or equal to the largest count K of items, which satisfies support in all of transactions The New_Apriori algorithm makes use of above-mentioned inference, at first making sure the count K of item of the largest frequent itemset. It directly gets the largest frequent itemset L K As follows introduce the New_Apriori algorithm with an example among these transactions, whose count of item is larger than or equal to K. Then consider these transactions one by one in order, whose count of item is k-1 and k-2.Dine the frequent itemset, which does not belong to the largest frequent itemset with the largest count of item Table 1 is an original affair database. Each affair T represents a student's record; the I 1 I 7 Scan the database to take down C C[1  1, C[2 5  8, C[4 4, C[5 2 a nd t h e Fl ag 1m ark of each transaction. At the same time change data stor age structure taking item as the key word means different attributes respectively. Minimum support min_support =4 TABLE I ORIGINAL AFFAIR DATABASE Y as a strong rule, otherwise mark it as a weak rule Y as a strong rule, otherwise mark it as a weak rule I 2 T  2 T 4 T 6 T 8 T 10 T 12 T 13 T 14 T 18 T 10 20 I T 4 2 T 3 T 4 T 6 T 8 T 10 T 11 T 12 T 13 T 14 T 15 T 16 T 1 I 


There are 60 records in the database. The mini-support degree is 20%.So if the support of the itemset satisfy 60*20%=12, the itemset is a global frequent set. The calculation of the support of the itemset is divided into four cases As {I 3 I 4  I 3 I 4 As {I  is local frequent itemset in each sub-database so it must accord with the mini-support requirement. It must be global frequent itemset 2 I 6  I 2 I 6 As {I  is not the local frequent itemset in all the sub-database, but the support of it satisfies the requirement of the mini-support. It is a global frequent itemset 2 I 4  I 2 I 4 has two local supports sup1, sup2 and sup1+sup2=9<12, then it doesn\222t accord with the mini-support requirement. But 12-9<4*\(3-2\d 12 represents the global mini-support, 9 represents the current mini-support, 4 represents the local mini-support, 3 represents the total count of nodes, and 2 represents the count of local support I 2 I 4 may be a global frequent D:20100304011742  There are 60 records in the database. The mini-support degree is 20%.So if the support of the itemset satisfy 60*20%=12, the itemset is a global frequent set. The calculation of the support of the itemset is divided into four cases As {I 3 I 4  I 3 I 4 As {I  is local frequent itemset in each sub-database so it must accord with the mini-support requirement. It must be global frequent itemset 2 I 6  I 2 I 6 As {I  is not the local frequent itemset in all the sub-database, but the support of it satisfies the requirement of the mini-support. It is a global frequent itemset 2 I 4  I 2 I 4 has two local supports sup1, sup2 and sup1+sup2=9<12, then it doesn\222t accord with the mini-support requirement. But 12-9<4*\(3-2\d 12 represents the global mini-support, 9 represents the current mini-support, 4 represents the local mini-support, 3 represents the total count of nodes, and 2 represents the count of local support I 2 I 4 may be a global frequent 10 I 2 I 4 I 5 I 6 4 10 I 2 I 4 I 5 I 6 4  IT 48 T 12 T 13 T 18 T 20  U 4  IT 58 T 12 T 13 T 17 T 18 T 20  U 5  IT 68 T 13 T 18 T 20  U 6  Owing to there are just I 2 I 4 I 5 I 6 four items in this experiment, it is equal to the largest count k of item of the largest frequent assumed. So in the process of solving, when we try to get U 2 I 2 I 4 I 5 3 I 4 I 5 3 I 4 I 3 I 4 4 I 4 I 7 4 I 5 I 7 7 I 2 T  8 T 12 T 13 T 18 T 20  U 2  IT 48 T 12 T 13 T 18 T 20  U 4  IT 58 T 12 T 13 T 17 T 18 T 20  U 5  IT 68 T 13 T 18 T 20  U 6  Owing to there are just I 2 I 4 I 5 I 6 four items in this experiment, it is equal to the largest count k of item of the largest frequent assumed. So in the process of solving, when we try to get U 2 I 2 I 4 I 5 3 I 4 I 5 3 I 4 6 I 2 I 6 I 4 2 I 4 I 4 3 I 5 4 205 I 2 I 6 I 3 I 4 4 I 4 I 7 4 I 5 I 7 7 D:20100304011742  X.sup1 X.sup2 X.sup3 X.sup1 X.sup2 X.sup3 Item Affair Item Affair Now try to get U 2  Now try to get U 2  4  5  6 If the count of item in the intersection is larger than or equal to min_support then {I 2 I 4 I 5 I 6 is the largest frequent itemset according to the inference in literature[3 W e g e t th e in tersectio n T 8  T 13 T 18 T 20 and the count of item is 4. This satisfies the minimum support min_support. Thus it can be seen, {I 2 I 4  I 5 I 6 is the largest frequent itemset. The record is I 2 I 4 I 5  I 6 4>. In the record, the number 4 expresses the amount of elements of the intersection In other words, there are 4 records including I 2 I 4 I 5 I 6 TABLE III THE LATELY SMALL DATABASE at the same time I 2 T  8 T 12 T 13 T 18 T 20  U 2 4 U a if the count of Ua\222s item is smaller than 4, |U a According to the specialty of Apriori algorithm: All of the sun sets of frequent itemset are frequent itemset, we can from the largest frequent itemset I 4, there is no need continue to get the intersection. Because the count doesn\222t satisfy the minimum support, at this time the count of considering item is smaller than k. Then there isn\222t the largest frequent itemset. If we don\222t find 4-frequent itemset, then the largest count k of item of the largest frequent assume d decrease 1.Get the largest frequent itemset with the method above-mentioned 2 I 4 I 5 I 6 get part of 2-frequent itemset{I 2 I 4 I 2 I 5 I 2  I 6 I 4 I 5 I 4 I 6 I 5 I 6 and part of 3-frequent itemset { I 2  I 4 I 5 etc. We can get the intersection in the same: record I 2 I 4 5>, <I 2 I 5 5>, <I 2 I 6  4>, < I 4 I 5 And then continue to try to get the largest frequent itemset to database. We just need to take the k as 2 or 3. In this experiment , at last we find all of the largest frequent itemset I 5>etc 2 I 4 I 5 I 6 I 3 I 4 I 4 I 7 I 5 I 7 And I 2 I 4 I 5  I 6 III BASIC THOUGHT AND PROCESS OF DISTRIBUTION DATA MINING  is the largest frequent itemset with the largest count of item Distributed data mining algorithms can be divided into two categories, data distribution algorithm \(DD algorithm\.and the count distributed algorithm \(CD algorithm The basic idea of DD algorithm is to designate the candidate set evenly distributed among the nodes. This can reduces the number of candidate set to be scanned when the nodes increases. The problem is that the traffic between the nodes can reduce the effici ency of the algorithm CD algorithm is a typical parallel algorithm based on apriori algorithm. Each subdatabase scans the database independently to calculate the support of each candidate set and then set the sum of the supports of the entire candidate set as the global support. If the global support is greater than the mini-support, we regard the itemset as the global frequent itemset. CD algorithm begins the next scan through the next synchroniza tion point after the end of each scan With the increase of the nodes, the traffic of the algorithm will be increasing quickly and the efficiency of the algorithm will be significantly reduced In order to reduce the tr affic between the various partitions, D.W.Chenung proposed a fast association rule mining algorithm based on distributed system FDM. The algorithm first run apriori algorithm to find the local frequent itemset in each partition, and th en changed the sum degree of the support between the global frequent itemset. The data size needed to be handled was reduced by generating a smaller number of candidate set In this paper, the global frequent sets can be acquired between 1time and 3 times based on the improved apriori algorithm IV DISTRIBUTED ASSOCIATION MINING BASED ON THE IMPROVED APRIORI ALGORITHM In this paper, we assume that the system contains three nodes S1, S2 and S3. The database is divided into DB 1 DB 2 and DB3. The data in the global database contain 60 transactions and each local database has 20 transactions Also we assume that the mini-support degree s=20%.DB1 acquire all the local frequent itemset < I 2 I 4  5>, < I 2 I 5 5 I 2 I 6 4>, < I 4 I 5  5 in the DB 1 through the improved apriori algorithm. Similarly DB 2 and DB 3 TABLE IV ALL OF LOCAL FREQUENT ITEMSET respectively obtain their own local frequent itemset through the improved apriori algorithm. Then, all of local frequent itemset are broadcast to the node S and summarized at the node S 6 I 2 I 6 I 4 2 I 4 I 4 3 I 5 4 205 I 2 I 6 4  5  6 If the count of item in the intersection is larger than or equal to min_support then {I 2 I 4 I 5 I 6 is the largest frequent itemset according to the inference in literature[3 W e g e t th e in tersectio n T 8  T 13 T 18 T 20 and the count of item is 4. This satisfies the minimum support min_support. Thus it can be seen, {I 2 I 4  I 5 I 6 is the largest frequent itemset. The record is I 2 I 4 I 5  I 6 4>. In the record, the number 4 expresses the amount of elements of the intersection In other words, there are 4 records including I 2 I 4 I 5 I 6 TABLE III THE LATELY SMALL DATABASE at the same time 4 U a if the count of Ua\222s item is smaller than 4, |U a According to the specialty of Apriori algorithm: All of the sun sets of frequent itemset are frequent itemset, we can from the largest frequent itemset I 4, there is no need continue to get the intersection. Because the count doesn\222t satisfy the minimum support, at this time the count of considering item is smaller than k. Then there isn\222t the largest frequent itemset. If we don\222t find 4-frequent itemset, then the largest count k of item of the largest frequent assume d decrease 1.Get the largest frequent itemset with the method above-mentioned 2 I 4 I 5 I 6 get part of 2-frequent itemset{I 2 I 4 I 2 I 5 I 2  I 6 I 4 I 5 I 4 I 6 I 5 I 6 and part of 3-frequent itemset { I 2  I 4 I 5 etc. We can get the intersection in the same: record I 2 I 4 5>, <I 2 I 5 5>, <I 2 I 6  4>, < I 4 I 5 And then continue to try to get the largest frequent itemset to database. We just need to take the k as 2 or 3. In this experiment , at last we find all of the largest frequent itemset I 5>etc 2 I 4 I 5 I 6 I 3 I 4 I 4 I 7 I 5 I 7 And I 2 I 4 I 5  I 6 III BASIC THOUGHT AND PROCESS OF DISTRIBUTION DATA MINING  is the largest frequent itemset with the largest count of item Distributed data mining algorithms can be divided into two categories, data distribution algorithm \(DD algorithm\.and the count distributed algorithm \(CD algorithm The basic idea of DD algorithm is to designate the candidate set evenly distributed among the nodes. This can reduces the number of candidate set to be scanned when the nodes increases. The problem is that the traffic between the nodes can reduce the effici ency of the algorithm CD algorithm is a typical parallel algorithm based on apriori algorithm. Each subdatabase scans the database independently to calculate the support of each candidate set and then set the sum of the supports of the entire candidate set as the global support. If the global support is greater than the mini-support, we regard the itemset as the global frequent itemset. CD algorithm begins the next scan through the next synchroniza tion point after the end of each scan With the increase of the nodes, the traffic of the algorithm will be increasing quickly and the efficiency of the algorithm will be significantly reduced In order to reduce the tr affic between the various partitions, D.W.Chenung proposed a fast association rule mining algorithm based on distributed system FDM. The algorithm first run apriori algorithm to find the local frequent itemset in each partition, and th en changed the sum degree of the support between the global frequent itemset. The data size needed to be handled was reduced by generating a smaller number of candidate set In this paper, the global frequent sets can be acquired between 1time and 3 times based on the improved apriori algorithm IV DISTRIBUTED ASSOCIATION MINING BASED ON THE IMPROVED APRIORI ALGORITHM In this paper, we assume that the system contains three nodes S1, S2 and S3. The database is divided into DB 1 DB 2 and DB3. The data in the global database contain 60 transactions and each local database has 20 transactions Also we assume that the mini-support degree s=20%.DB1 acquire all the local frequent itemset < I 2 I 4  5>, < I 2 I 5 5 I 2 I 6 4>, < I 4 I 5  5 in the DB 1 through the improved apriori algorithm. Similarly DB 2 and DB 3 TABLE IV ALL OF LOCAL FREQUENT ITEMSET respectively obtain their own local frequent itemset through the improved apriori algorithm. Then, all of local frequent itemset are broadcast to the node S and summarized at the node S 


D:20100304011742  itemset. So the node S broadcasts I 2 I 4 to S1, S2, S3. If the sum of all of local support accords with the global mini-support I 2 I 4 is a global frequent itemset As {I 3 I 5  I 3 I 5 has one local support sup3=4. This doesn\222t satisfy the requirement of the mini-support. At the same time, 12-4 =4*\(3-1 I 3 I 5 V CONCLUSIONS can not be a global frequent itemset At last, we have mined all of the global frequent itemset That is to say to mine the association rules in distributed database The traditional algorithms creat e the local candidate sets firstly, and then determine whether the local frequent itemsets is the global frequent itemsets by the traffic between the nodes. The most different between the proposed algorithm and the traditional algorithms is that it firstly generates all the local frequent itemsets at each node and then communicates to the top point. At the top point, there are four cases to deal with a ll the local frequent itemsets. For the fastest case, the determination could be made by the completion of round-trip communications. At the same time all the operations of this algorithm are completed not by traditional data storage but by a new data storage in which the item is considered as the keyword. The method can save storage space, especially for sp arse data. So the support can be calculated by the intersection of the transaction sets which is much easier than by accessing to the database Finally, the association rules in the distributed database are mined A CKNOWLEDGMENT This work was supported by Beijing Educational Committee science and technology development plan project\(KM20081 0028016 Capital Normal University project and Beijing Information project R EFERENCES  R Agrawal T I m i e linski, A Swa mj. Mining associationrules between sets of items in large databases[C  SI G  MOD International Conference on Ma nagement of data. Washington DC,1993  L i Xinzheng Im proved apri ori algorithm for efficiency Control  Automation,2006,v3\(3  Z hu Ye Ye Gaoy ing I m pr ovem e nt of Apr i or i Algor ith m in  Association Rule Mining. Modern Electronic Technique,2008,v31\(18  L i Xiaohong, Shang Jin. An Improved New Apriori Algorithm Computer Science.2007,v34\(4  T an Ran, Lu Zhengqiu, Yan Xi nping. Similarity-based distributed data mining model research.Application Research of Computers.Mar.2008, v25\(3  W ang Y ue, Cao Changxiu T h e M e t hod Research of M i ning Association Rules in Distributed Environments. College of Automation Chongqing University. Mar.2003  W ei Suyun, Ji Ge nlin. Research on Algorithms for Distributed Ming of Association Rules. School of Mathematics and Computer Science Nanjing Normal Univercity. April.2006 D:20100304011742  itemset. So the node S broadcasts I 2 I 4 to S1, S2, S3. If the sum of all of local support accords with the global mini-support I 2 I 4 is a global frequent itemset As {I 3 I 5  I 3 I 5 has one local support sup3=4. This doesn\222t satisfy the requirement of the mini-support. At the same time, 12-4 =4*\(3-1 I 3 I 5 V CONCLUSIONS can not be a global frequent itemset At last, we have mined all of the global frequent itemset That is to say to mine the association rules in distributed database The traditional algorithms creat e the local candidate sets firstly, and then determine whether the local frequent itemsets is the global frequent itemsets by the traffic between the nodes. The most different between the proposed algorithm and the traditional algorithms is that it firstly generates all the local frequent itemsets at each node and then communicates to the top point. At the top point, there are four cases to deal with a ll the local frequent itemsets. For the fastest case, the determination could be made by the completion of round-trip communications. At the same time all the operations of this algorithm are completed not by traditional data storage but by a new data storage in which the item is considered as the keyword. The method can save storage space, especially for sp arse data. So the support can be calculated by the intersection of the transaction sets which is much easier than by accessing to the database Finally, the association rules in the distributed database are mined A CKNOWLEDGMENT This work was supported by Beijing Educational Committee science and technology development plan project\(KM20081 0028016 Capital Normal University project and Beijing Information project R EFERENCES  R Agrawal T I m i e linski, A Swa mj. Mining associationrules between sets of items in large databases[C  SI G  MOD International Conference on Ma nagement of data. Washington DC,1993  L i Xinzheng Im proved apri ori algorithm for efficiency Control  Automation,2006,v3\(3  Z hu Ye Ye Gaoy ing I m pr ovem e nt of Apr i or i Algor ith m in  Association Rule Mining. Modern Electronic Technique,2008,v31\(18  L i Xiaohong, Shang Jin. An Improved New Apriori Algorithm Computer Science.2007,v34\(4  T an Ran, Lu Zhengqiu, Yan Xi nping. Similarity-based distributed data mining model research.Application Research of Computers.Mar.2008, v25\(3  W ang Y ue, Cao Changxiu T h e M e t hod Research of M i ning Association Rules in Distributed Environments. College of Automation Chongqing University. Mar.2003  W ei Suyun, Ji Ge nlin. Research on Algorithms for Distributed Ming of Association Rules. School of Mathematics and Computer Science Nanjing Normal Univercity. April.2006 


Table I L IST OF INITIAL O NTOLOGY CONCEPT   Initial Concepts Assembly Production Boiler Grinding Turning Surface Stamping Treatment Manufacturing Thermal Forging Process Milling Usage Laser Machining Carry conducted by varying the parameter of windows size from 1 to 5 Then to extract the correlation relationships between words we use a version of the Apriori algorithm 3 In experiments the support was varied from 1 to 10 After analyzing the results we have assumed a support of 1 and a window size of 4 Table II describes the generated association rules As could be constated the terms of the corpora correlated to the concept of the ontology are discriminant for the domain concerned Thus a provisional list of concept learned is obtained Table II E XEMPLE OF GENERATED ASSOCIATION RULES Generated Association Rules assembly  injection 3.2 100.0 stampings  cutting 4.0 90 forging  Threading 1.7 100.0 forging  simulation 1.9 100.0 area  Metrology 2.1 100.0 area  Welding 1.6 100.0 machining  expertise 2.3 100.0 machining  accuracy 1.8 100.0 machining  installation 2.9 100.0 As we explained in the previous section we eliminate from this list the common terms those correlated with several initial concept for the same support value Figure IV-C shows a set of concepts learned Due to the association rules generated we have not only identi“ed new candidate terms as a concept of the ontology but also have determined the relations between the initial and the new concepts to be automatically positioned in the ontology D Discussion As seen from the fact of using windows where the pivots words are the initial concepts of the ontology and the using nouns verbs and adjectives enables to improve considerably the detection of correlation in texts In the same way the use of lters signi“cantly retained correlated relevant concepts It should be noted that our approach was 3 http://“mi.cs.helsinki.“/“mi03 Table III E XEMPLE OF CONCEPTS LEARNED Concepts Learned Adjusting Cutting Metal Injection Metrology Assembly Tools precision expertise Welding Molding Simulation Turning Threading suf“ciently automatic to be applied in various elds and thus extract the signi“cant concepts elsewhere The rst results obtained are promising we discovered and placed suitably new concepts The analysis of the ontology obtained showed that the whole of the concepts discovered is coherent since most of them could be attached to ontology via the rules obtained These results were also validated by the expert of the eld V P ERSPECTIVES Future work may entail in a broad series of projects and initiatives Firstly our learning method depends on the quality of documents constituents the training corpora Currently it is created manually from a collection of sites We would like to extend our method of learning corpora creating by generating a speci“c queries on the web according to a speci“c criteria for the domain treated Secondly our approach can naturally be extended by enhancing learning In this case we have just to reconsider the new concepts learned as initial concepts Thirdly the work on this project will continue enrichment on all the domain of the ontology and at the same time validate obtained results either by a expert or by statistical methods Finally the extraction method is based on the generation of association rules between concepts and words of texts We want to investigate whether the order between words can affect the correlation Traditionally text mining approaches normally rather uses the n-grams to consider the order between words or characters The advantage of n-grams is to nd words that are very close i.e based on the value of n The failure of these approaches in the context of data mining is that the words most be consecutive to be validate But this does not always re”ect natural language structure Our idea is to extend the approach using the concept of sequential patterns which extracts pertinent concepts that are close but not consecutive VI C ONCLUSION Many studies and applications have addressed the problem of ontology enrichment in developing approaches and tools for building and updating of such resources Often the operations of identi“cation and placement of new elements 2010 10th International Conference on Inte lligent Systems Design and Applications 1117 


in these semantic resources such as ontology are made manually In this paper we present a new approach of ontology enrichment based on data mining technics speci“cally the association rules and the use of extracted semantic information to retain relevant new concepts Our approach is based on three steps 1 Preprocessing of a textual corpora cleaning and lemmatising treetagger 2 Creating window size to promote the correlation between corpora words and concepts of the ontology then the application of the APRIORI algorithm to extract association rules according to validated parameters support con“dence 3 Automatic analysing and semantic ltering of generated rules to keep those that are relevant to the initial domain ontology The obtained enrichment results seem auspicious for the chosen domain ontology This approach is sensitive to the domain studied it is important to have a corpora that describes the subject domain accurately so there is a very rich language with nouns and adjectives available Although the company websites do not represent the ideal source for building a such corpora for the domain studied companies competency in the mechanical industry but we have had promising results R EFERENCES  G Berio and M Harzallah T o w ards an inte grating architecture for competence management in Special Issue Competence Management in Industrial Processes guest editors X Boucher E Bonjour N Matta Computers in Industry  vol V58 issue 2 2007  E Ermilo v a and H Afsarmanesh Modeling and management of pro“les and competences in vbes Journal of Intelligent Manufacturing  vol V18 pp 561…586 2007  J Hodik J V okrinek J Biba and P  Becv ar  Competences and pro“les management for virtual organizations creation CEEMAS  pp 93…102 2007  G Pepiot Modlisation des entreprises sur la base des comptences EPFL PhD Thesis   2005  K Neshatian and Hejazi T e x t cate gorization and classi“cation in terms of multi-attribute concepts for enriching existing ontologies Proceedings of the 2nd Workshop on Information Technology and its Disciplines  pp 43…48 2004  L D Jorio L Abrouk C Fiot D  Hrin and M T eisseire Enrichissement dontologie bas sur les motifs squentiels Actes de la Plateforme AFIA 2007 Atelier Ontologies et gestion de lhtrognit smantique  2007  A F  A and R Steinmetz Ontology enrichment with te xts from the www Proceedings of the 2nd Semantic Web Mining Workshop at ECMLI/PKDD WS02  2006  G Stumme and A H B Berendt Semantic web mining  State of the art and future directions Web Semantics  Science Services and Agents on the World Wide Web  vol 4 n 2 pp 124…143 2006  E Agirre O Ansa E Ho vy  and D Martinez Enriching very large ontologies using the www Proceedings of ECAI 2000 workshop on Ontology Learning  2002  V  P arekh and J G T  Finin Mining domain speci“c te xts and glossaries to evaluate and enrich domain ontologies Proceedings of the International Conference of Information and Knowledge Engineering  2004  R Bendaoud Construction et enrichissement dune ontologie partir dun corpus de textes Actes des Rencontres des Jeunes Chercheurs en Recherche dInformation RJCRI06 Lyon  pp 353…358 2006  A M V  Pekar and S Staab On disco v ering taxonomic relations from the web Journal of Information Retrieval Contextual Information Retrieval Systems  vol Springer Verlag pp 301…322 2002  N Hernandez J Chrisment and D Egret Modeling conte xt through domain ontologies Journal of Information Retrieval Contextual Information Retrieval Systems  vol 10 pp 143 172 2007  R Srikant and R Agra w al Mining generalized association rules Future Generation Computer Systems  vol 13 n 23 pp 161…180 1997  E Han and G Karypis Centroid based document classi“cation  Analysis and experimental results Proceedings of The 4th European Conference of Principles of Data Mining and Knowledge Discovery  pp 424…431 2000  K.Hajlaoui X.Boucher  and J J Girardot Competenc y ontology for network building 10th IFIP Working Conference on Virtual Entreprises PRO-VE09  vol Thessaloniki GREECE 2009  H Schmid Probabilistic part-of-speech tagging using decision trees Conference on New Methods in Language Processing Manchester UK  1994  R Agra w a l and R Srikant F ast algorithms for mining association rules in large databases VLDB94  1994  D Do wne y  M Broadhead and O Etzioni Locating complex named entities in Web text In Proceedings of the IJCAI07  pp 2733…2739 2007  M Roche and V  Prince  Acrodef  A quality measure for discriminating expansions of ambiguous acronyms CONTEXT  pp 411…427 2007  B B B A Isaac and R T ronc y  Semantic commitment for designing ontologies In the proceedings of 13th EKAW Conference LNAI of LN  vol Arti“cial Intelligence Springer 2473 pp 114…121 2002 1118 2010 10th International Conference on Inte lligent Systems Design and Applications 


1517  On Knowledge Discovery And Data Mining 1999:145-154  a. Carlo, Com b i. Riccardo Bellazzi. Data Mining with temporal abstractions:learning rules fr om time se  Mining and Knowledge Discovery, 2007, 15\(2\217-247 1 M i ng j un S o n g San g u t h e v ar R a jase kara n M e m b er  IEEE. A transaction mapping algorithm for frequent item sets mining[C IEE E T r ansa ct i ons on K n o w l e d g e a n d  Data Engineering, 2006, 18\(4\:472-481 18 Y  Bastid e, R. T a ou il, N. Pasqu i er  G   S t u mme, L Lakhal. Mining frequent patterns with counting inference I n SIG K DD E xpl orat i o ns 2 0 0 0  2 2 6 6 75    Bashir  S  S huai b  M  S u ltan Y    Baig A  R  Improving frequent itemset mining algorithms performance using efficient implementation techniques A benchmark solution[C   In Proc. 2006 2nd Int. Conf on Emerging Technologies \(IEEE-ICET'06\, Peshawar Pakistan, 2006:257-262 2 W a ssim A Y AD I K h e d ija AR OUR  A  binary  decisio n  diagram to discover low threshold support frequent items 8 th In tern atio n a l W o rkshop on Datab a se and Expert Systems Applications, 2007:509-513 21 C. B o r g elt. Ef ficien t im p l e m en tatio n  o f apriori and eclat[C]. In FIM I\22203: Proceedings of the IEEE ICDM Workshop on Frequent Item Set Mining Implementations Meldourne, USA, 2003, 80:1-9 22 Ch ed y Raissi, Pascal Po n celet, Maguelonne Teisseire SPEED: Mining maximal sequential patterns over data stream 3rd I n ternati onal IEEE Conference on Intelligent Systems, 2006:546-552 23 J. Pei, J Han W   W a n g Min i ng sequen tial p attern s with constraints in large data bases In Proceedi n gs of the 10th International Conference on Information and Knowledge Management\(CIKM02\, MCLean, USA 2002:18-25 24 M. Klemettin en H.Man n ila P   R o n k ai n en, H Toivonen, A. I. Verkamo. Finding interesting rules from large sets of discovered asso ciation ru  3 r d  In t\222l Conference on Information and Knowledge Management 1994:401-407 2 M o h a m m e d J Za ki  Scal abl e al go ri t h m s fo r  association mining EEE T r an sacti o n s  on K now ledg e and Data Mining, 2000, 12\(3\:372-390 26 R. Sri k an t, R. Agrawal. Min i n g sequ ential p attern s  Generalizations and performance improvements[C In  Proceedings of the 5th In ternational Conference on Extending Database Technology \(EDBT96\, Avignon France, 1996:3-17 2 D o u g B u r d i c k, M a nuel  C a l i m l im Johanne s Ge hr ke  MAFIA: A maximal frequent itemset algorithm for transactional databases[C]. In Proceedings of the 17th International Conference on Data Egineering, Heidelberg Germany, 2001:443-452  2 J. F. Boulicaut, A. Bykows ki, C. Rigotti. Free-sets A condensed representation of boolean data for the approximation of frequency queri  Dat a M i ni n g a n d  Knowledge Discovery, 2003,7\(1\:5-23  


 J  urgen Bohn Felix G  artner and Harald Vogt Dependability Issues of Pervasive Computing in a Healthcare Environment in Security in Pervasive Computing  Springer Berlin  Heidelberg 2004  K V enkatasubramanian and S K Gupta In Security in Distributed Grid Mobile and Pervasive Computing  Auerbach Publications CRC Press 2007 ch Security Solutions for Pervasive Healthcare pp 443…464  D E Denning Intrusion-Detection Model  IEEE Trans Software Eng  vol 13 no 2 pp 222…232 1987  F  Stajano Security for Ubiquitous Computing  i n ICISC  ser Lecture Notes in Computer Science C Park and S Chee Eds vol 3506 Springer 2004 p 2  A Abimbola Q Shi and M Merabti NetHost-Sensor A Novel Concept in Intrusion Detection Systems in ISCC 03  Washington DC USA IEEE Computer Society 2003 p 232  D E Denning An Intrusion-Detection Model  IEEE Trans Softw Eng  vol 13 no 2 pp 222…232 1987  M Roesch Snort Lightweight Intrusion Detection for Networks in LISA  Berkeley CA USA USENIX Association 1999 pp 229…238  G V igna F  V aleur  and R A K emmerer  Designing and Implementing a Family of Intrusion Detection Systems in ESEC/FSE-11  New York NY USA ACM 2003 pp 88 97  J E Bardram  Applications of Conte xt-A w are Computing in Hospital Work Examples and Design Principles in Proceedings of the 2004 ACM Symposium on Applied Computing  ACM Press 2004 pp 1574…1579  M Baldauf S Dustdar  and F  Rosenber g A Surv e y on Context-Aaware Systems Int J Ad Hoc Ubiquitous Comput  vol 2 no 4 pp 263…277 2007  V  Stanford Using Perv asi v e Computing to Deli v e r Elder Care IEEE Pervasive Computing  vol 1 no 1 pp 10…13 2002  J H Jahnk e T o w ards Conte xt-A w are Computing in Clinical Care OOPSLA Workshop on Building Software for Pervasive Computing  2005  U V arshne y  Perv asi v e Healthcare  IEEE Computer  vol 36 no 12 pp 138…140 2003  R K emmerer and G V igna Intrusion detection A Brief History and Overview IEEE Security and Privacy Magazine  2002  K e W ang and Salv atore J Stolfo  Anomalous payload-based network intrusion detection in RIAD  ser Lecture Notes in Computer Science Springer 2004 pp 203…222  Salv atore J Stolfo and Frank Apap and Eleazar Eskin and Katherine Heller and Shlomo Hershkop and Andrew Honig and Krysta Marie Svore A comparative evaluation of two algorithms for Windows Registry Anomaly Detection Journal of Computer Security  vol 13 no 4 pp 659…693 2005  U Lindqvist and P  A Porras Detecting Computer and Network Misuse Through the Production-Based Expert System Toolset P-BEST in S&P  IEEE Computer Society 1999  W ojciech T ylman Misuse-Based Intrusion Detection Using Bayesian Networks International Conference on Dependability of Computer Systems  pp 203…210 2008  G V igna and C Krue gel Handbook of Information Security  Wiley 2005 ch Host-based Intrusion Detection Systems  A A M Mehdi S Zair and M Bensebti  A bayesian networks in intrusion detection systems Journal of Computer Science  vol 3 no 5 2007  W S Y ang  and S.-Y  H w ang A process-mining Framework for the Detection of Healthcare Fraud and Abuse Expert Systems with Applications  vol 31 pp 56…68 2006  Bezerra F  abio and Wainer Jacques Anomaly detection algorithms in logs of process aware systems in SAC 08 Proceedings of the 2008 ACM symposium on Applied computing  ACM 2008 pp 951…952  G A R Pedro A Orte ga Cristian J Figueroa A Medical Claim Fraud/Abuse Detection System based on Data Mining:A Case Study in Chile in DMIN06  The 2006 World Congress in Computer Science Computer Engineering and Applied Computing 2006 pp 224…231  Hipp Jochen and G  untzer Ulrich and Nakhaeizadeh Gholamreza Algorithms for association rule minin g  a general survey and comparison SIGKDD Explor News  vol 2 no 1 pp 58…64 2000  P  L Frans Coenen and S Ahmed Data Structure for Association Rule Mining T-Trees and P-Trees IEEE Transactions on Knowledge and Data Engineering  vol 16 no 6 2004  K S Mafruz Zaman Ashra Da vid T aniar  Odam An optimized distributed association rule mining algorithm IEEE Distributed Systems Online  vol 5 no 3 March 2004  W  Lee and S J Stolfo  A frame w o rk for constructing features and models for intrusion detection systems ACM Trans Inf Syst Secur  vol 3 no 4 pp 227…261 2000  R Agra w al T  Imieli  nski and A Swami Mining association rules between sets of items in large databases in SIGMOD 93 Proceedings of the 1993 ACM SIGMOD international conference on Management of data  New York NY USA ACM 1993 pp 207…216  K Hu Y  Lu L Zhou and C Shi Inte grating classi“cation and association rule mining A concept lattice framework in RSFDGrC99  London UK Springer-Verlag 1999 pp 443…447  S F orrest S A Hofme yr  A  Somayaji and T  A Longstaf f A Sense of Self for Unix Processes in SP 96  Washington DC USA IEEE Computer Society 1996 p 120  B D Caulkins J Lee and M W ang A Dynamic Data Mining Technique for Intrusion Detection Systems in ACMSE 43  New York NY USA ACM 2005 pp 148…153 


Application of Chaotic Particle Swarm Optimization Algorithm in Chinese Documents Classification 763 Dekun Tan Qualitative Simulation Based on Ranked Hyperreals 767 Shusaku Tsumoto Association Action Rules and Action Paths Triggered by Meta-actions 772 Angelina A. Tzacheva and Zbigniew W. Ras Research and Prediction on Nonlinear Network Flow of Mobile Short Message Based on Neural Network 777 Nianhong Wan, Jiyi Wang, and Xuerong Wang Pattern Matching with Flexible Wildcards and Recurring Characters 782 Haiping Wang, Fei Xie, Xuegang Hu, Peipei Li, and Xindong Wu Supplier Selection Based on Rough Sets and Analytic Hierarchy Process 787 Lei Wang, Jun Ye, and Tianrui Li The Covering Upper Approximation by Subcovering 791 Shiping Wang, William Zhu, and Peiyong Zhu Stochastic Synchronization of Non-identical Genetic Networks with Time Delay 794 Zhengxia Wang and Guodong Liu An Extensible Workflow Modeling Model Based on Ontology 798 Zhenwu Wang Interval Type-2 Fuzzy PI Controllers: Why They are More Robust 802 Dongrui Wu and Woei Wan Tan Improved K-Modes Clustering Method Based on Chi-square Statistics 808 Runxiu Wu Decision Rule Acquisition Algorithm Based on Association-Characteristic Information Granular Computing 812 JianFeng Xu, Lan Liu, GuangZuo Zheng, and Yao Zhang Constructing a Fast Algorithm for Multi-label Classification with Support Vector Data Description 817 Jianhua Xu Knowledge Operations in Neighborhood System 822 Xibei Yang and Tsau Young Lin An Evaluation Method Based on Combinatorial Judgement Matrix 826 Jun Ye and Lei Wang Generating Algorithm of Approximate Decision Rules and its Applications 830 Wang Yun and Wu-Zhi Qiang Parameter Selection of Support Vector Regression Based on Particle Swarm Optimization 834 Hu Zhang, Min Wang, and Xin-han Huang T-type Pseudo-BCI Algebras and T-type Pseudo-BCI Filters 839 Xiaohong Zhang, Yinfeng Lu, and Xiaoyan Mao A Vehicle License Plate Recognition Method Based on Neural Network 845 Xing-Wang Zhang, Xian-gui Liu, and Jia Zhao Author Index 849 
xiii 


   C4.2 Open GL has excellent documentation that could help the developer learn the platform with ease C4.3 Developer has very little ex perience in working with Open GL platform  For our case study, alternative B i.e. Adobe Director was the most favorable alternative amongst all the three. It catered to the reusability criteria quite well and aimed at meeting most of the desired operational requirements for the system   6. CONCLUSION & FUTURE WORK  The main contribution of this paper is to develop an approach for evaluating performance scores in MultiCriteria decision making using an intelligent computational argumentation network. The evaluation process requires us to identify performance scores in multi criteria decision making which are not obtained objectively and quantify the same by providing a strong rationale. In this way, deeper analysis can be achieved in reducing the uncertainty problem involved in Multi Criteria decision paradigm. As a part of our future work we plan on conducting a large scale empirical analysis of the argumentation system to validate its effectiveness   REFERENCES  1  L  P Am g o u d  U sin g  A r g u men ts f o r mak i n g an d  ex p lain in g  decisions Artificial Intelligence 173 413-436, \(2009 2 A  Boch m a n   C ollectiv e A r g u men tatio n    Proceedings of the Workshop on Non-Monotonic Reasoning 2002 3 G  R Bu y u k o zk an  Ev alu a tio n o f sof tware d e v e lo p m en t  projects using a fuzzy multi-criteria decision approach Mathematics and Computers in Simualtion 77 464-475, \(2008 4 M T  Chen   F u zzy MCD M A p p r o ach t o Selec t Serv ice  Provider The IEEE International Conference on Fuzzy 2003 5 J. Con k li n  an d  M. Beg e m a n   gIBIS: A Hypertext Tool for Exploratory Policy Discussion Transactions on Office Information Systems 6\(4\: 303  331, \(1988 6 B P  Duarte D e v elo p in g a p r o jec ts ev alu a tio n sy ste m based on multiple attribute value theroy Computer Operations Research 33 1488-1504, \(2006 7 E G  Fo rm an  T h e  A n a l y t ic Hier a rch y P r o cess A n  Exposition OR CHRONICLE 1999 8 M. L ease  an d J L  L i v e l y  Using an Issue Based Hypertext System to Capture Software LifeCycle Process Hypermedia  2\(1\, pp. 34  45, \(1990 9  P e id e L i u   E valu a tio n Mo d e l o f Custo m e r Satis f a c tio n o f  B2CE Commerce Based on Combin ation of Linguistic Variables and Fuzzy Triangular Numbers Eight ACIS International Conference on Software Engin eering, Artificial Intelligence Networking and Parallel Distributed Computing, \(pp 450-454 2007  10  X  F L i u   M an ag e m en t o f an In tellig e n t A r g u m e n tatio n  Network for a Web-Based Collaborative Engineering Design Environment Proceedings of the 2007 IEEE International Symposium on Collaborative Technologies and Systems,\(CTS 2007\, Orlando, Florida May 21-25, 2007 11 X. F L i u   A n In ternet Ba se d In tellig e n t A r g u m e n tatio n  System for Collaborative Engineering Design Proceedings of the 2006 IEEE International Symposium on Collaborative Technologies and Systems pp. 318-325\. Las Vegas, Nevada 2006 12 T  M A sub jec tiv e assess m e n t o f altern ativ e m ission  architectures for the human exploration of Mars at NASA using multicriteria decision making Computer and Operations Research 1147-1164, \(June 2004 13 A  N Mo n ireh  F u zzy De cisio n Ma k i n g b a se d o n  Relationship Analysis between Criteria Annual Meeting of the North American Fuzzy Information Processing Society 2005 14 N  P a p a d ias HERMES Su p p o rti n g A r g u m e n tative  Discourse in Multi Agent Decision Making Proceedings of the 15th National Conference on Artifical Intelligence \(AAAI-98  pp. 827-832\dison, WI: AAAI/MIT Press,  \(1998a 15  E. B T riantaph y llo u   T h e Im p act o f  Ag g r e g atin g Ben e f i t  and Cost Criteria in Four MCDA Methods IEEE Transactions on Engineering Management, Vol 52, No 2 May 2005 16 S  H T s a u r T h e Ev alu a tio n o f airlin e se rv ice q u a lity b y  fuzzy MCDM Tourism Management 107-115, \(2002 1 T  D W a n g  Develo p in g a f u zz y  T O P S IS app r o ach  b a sed  on subjective weights and objective weights Expert Systems with Applications 8980-8985, \(2009 18 L  A  Zadeh  F u z z y Sets   Information and Control 8  338-353, \(1965  152 


                        





