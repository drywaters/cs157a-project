 A Study of Improving Apriori Algorithm  Libing Wu School of Computer Wuhan University Wuhan, China wu@whu.edu.cn  Kui Gong School of Computer Wuhan University Wuhan, China   Yanxiang He School of Computer Wuhan University Wuhan, China   Xiaohua Ge School of Computer Wuhan University Wuhan, China   Jianqun Cui Department of Computer Science Huazhong Normal University Wuhan, China   Abstract 227The Apriori algorithm is one of the most influential apriori for mining association rules. The basic idea of the Apriori 
algorithm is to identify all the frequent sets. Through the frequent sets, derived association rules, these rules must satisfy minimum support threshold and minimum confidence threshold This paper presents improved algorithms, mainly through the introduction of interest items, frequency threshold, to improve the mining efficiency, dynamic data mining to facilitate the needs of users. Confirmed by many experiments, this algorithm is better than traditional algorithms in time and space complexity Keywords- Apriori algorithm; dynamic mining; interest item frequency threshold I   I NTRODUCTION  With the development of artificial intelligence, database technology and mathematical statistics, the transaction database for mining association rules is an important research direction 
for data mining. Association rule is an important research in the knowledge discovery research. In large amounts of data, some interesting correlation would find in itemsets or related links[1,2 The mainly technology of data mining is association rules clustering, rough sets, neural networks, genetic algorithms and so on. Association rules are a group of objects in the database which associated with the relationship between the rules. It is widely used in data mining. It can be divided into two subproblems [3  O n e i s t o fi nd t h e f r eq ue nt i t e m se t s w h i c h me e t  the minimum support. The other one is using the frequent item sets to generate association rules, according to the minimum credibility. The first problem is the overhead of time and space so most of current association rule mining algorithms are 
committed to improving the efficiency to find frequent item sets. There are some ways to extend the association rules, such as the numeric association rules [5 m u ltilev e l ass o c i at i o n  rules [6  A large number of mining association rules algorithm has proposed. In this rules, Apriori algorithm is the most classical algorithms. This article is based on the Apriori algorithm by introducing the number of interest items and frequency threshold to reduce the times of database search. Dynamic mining can be well positioned to meet customer\222s need, and improved the efficiency of the algorithm  II  A SSOCIATION R ULES  Association rules derived from analyzing the problem of supermarket shopping. Using this rules to detect the link between different commodities in the database. These links 
reflect the patterns of customer buying behavior. Found such a link can be applied to analyze customer shopping, directory design, commercial advertising mail. The area of research in data mining for association rules mining was more in-depth research. It has carried out a number of association rules mining algorithm. At present, the association rule mining has been successfully applied in various related areas. The data mining is one of the most mature, most important and most extensive research details [7, 8  A  Related Concepts In order to facilitate description of our algorithm, we hereby agree i in this transaction database is a property     2 1 n i i i 
I 
 is a collection of all attributes in this transaction database      2 1 n m i i i T m 
002  is a transaction     2 1 n T T T D 
 is a transaction database   D is indicated the number of transaction database transactions. In this place, the elements in     2 1 n T T T D  can be repeated. In order to avoid duplication of transactions are covered .In this article, we 
give a unique mark to each of transaction in the transaction database TID Supportive degree of the itemset   X Sup is the proportion how much transaction X included in the entire database D Confidence   B A Conf of association rule B A is the conditional probability that itemset B occurred in the condition that itemset A have occurred. Minimum support threshold Sup min is the minimum one which item sets must be met in the mining process. Minimum confidence threshold Conf min  is the minimum one which association rule must be met Itemsets whose supportive degree are greater than or equal to 
Sup min are defined as frequent itemsets B  The introduction of traditional Apriori algorithm Firstly, we need dig out the frequent 1-itemsets, then continue to use the recursive way to mining frequent k-itemsets k> 1\.Specific practices is to dig out the candidate frequent kitemsets, according to the smallest minimum confidence Supported by National Natural Science Foundation of China \(Grant No. 60773008\, Key Laboratory of Aerospace Information Securit y and Trust Computing of Ministry of Education., National Science Foundation for Post-doctoral Scientists of China, Natural Science Foundation of Hub ei Province and \223Dawn\224 Program of Wuhan \(No. 200950431183 978-1-4244-5874-5/10/$26.00 \2512010 IEEE 


 threshold Sup min to filter some candidate, to get frequent kitemsets. Finally, combine all of the frequent k-itemsets\(k>0 The rule's confidence is greater than given minimum confidence. In this step, firstly, you need start from the frequent itemsets, to dig out all the association rules, and then to get the frequent association rules C  The example illustrates the Apriori algorithms Transaction database as shown in Table I Sup min 50 Conf min 70%. Request the frequent association rules in transaction database D TABLE I  T RANSACTION D ATABASE  T id Itemsets 1  A B C D E  2 A B C 3 C D E F 4 A B E  The implementation process is as follows The first step: Find the frequent itemsets 1  Frequent 1 - itemsets{{A 002 B 002 C 002 D 002 E 2  Frequent 2 - itemsets{{AB 002 AC 002 AE 002 BC 002 BD 002 CD 002 CE 3  Frequent 3 - itemsets{ABC 4  Summary 3 2 1 L L L L 003 003  A 002 B 002 C 002 D 002 E 002 AB 002 AC 002 AE 002 BC 002 BD 002 CD 002 CE 002 ABC The step two: seeking association from {ABC Only {AC 004 B},{BC 004 A},{A 004 B},{B 004 A meet the requirements. Confidence level is 100 III  T HE DESCRIPTION OF IMPROVED ALGORITHM  A  Introduction of Improved algorithm From the above process, we see that some disadvantages in the traditional data mining. Firstly, the process of scanning database is too frequently. Secondly, the definition of Sup min  and Conf min cannot be changed. If we want to change Sup min or Conf min we need re-excavation. It is inconvenience to users. Thirdly, we are not interested in EF, so it should not be start to operate on EF Property1 If A B 004 exists in the association, then 005 AB Count min so if T  Count min Then, the relationships composed of any subset of T not meet the minimum confidence Property2 If A B 004 exists in the association, then A and B are frequent itemsets, but AB is not a necessarily frequent itemsets Definition1 Interested Item I is a collection of items which are interested in some users. It is also a key objective of the excavation Definition2 Item frequency refers to a subset of items from the interest in the composition of the items set in the transaction database number Definition3 Support the frequency threshold SupCount min is a minimum number of items in association rules SupCount min  D  Sup min  Definition4 Frequency threshold Count min is the minimum number in the association rule of B A 000  Count min  SupCount min  Conf min  B  Algorithm Steps To sum up the three inadequate in traditional mining algorithms and the two properties, we have improved Apriori algorithm as follow The first step: This paper presents the various items of interest in a subset of items of frequency 1  Enter interest items and mining transactional database 2  Scan the transaction database 3  Records each sub-set of items in the database. You can record frequency and the total number of articles D Save the subset The second step: find the association 1  Enter Sup min and Conf min Put Sup min into SupCount min  2  Scan the subset of items of interest which you have saved. Find out frequent itemsets and delete some subset whose frequency is less than Count min  3  Find each association rule whose confidence is greater than Conf min Output the rules C  The improved algorithm pseudo-code Step 1: Find the item frequency of all the subsets of interested items Input: Transaction database \(D\ Interested items \(I Output: Item frequency of all the subsets of interested items and record item numbers in the database For each candidate I i 006 Do // traversing each Interested items Count++         // Record numbers of interested items End for sum I   I subset Find all the subsets of Interested items For each log D d 006 Do For each candidate d i 006 Do // traversing each Interested items 


 If I i 006 if this item belongs to Interested items  i d i  003 Find all the Interested items in this record End if    i d d subset I   End for For each Item in d I traverse each item in the collection    count Items  each item add 1 in the collection End for Count++         // record the item numbers in the database End for Pseudo-code of   I subset as follows    1       i count I i i for  Return sum I  003 count i i i i i I I I I I I   1 1   003 003  End for Step 2: Find the association in sum I  Input: Minimum support threshold Sup min imum confidence threshold Conf min  Output: The AR to meet the requirement and credibility SupCount min Count Sup min  Conf min  For each candidate sum I I 006 Do   min    SupCount count Items I if   Delete I  // if the frequency of I is smaller than SupCount min delete it from sum I  Else   min    Count count Items I if 005   I L  003 Save I as a frequent item into L, if its frequency is greater than Count min  Count1++   // record the numbers of frequent items End if End if End for For each candidate L I 006 Do // traversing all the items of L    1  1      i count i i for traversing each element of L      Items L Items L if k i 007 if the items in i L and k L are different       sum k i I Items L Items L if 006 003 if the union of items in i L and k L belongs to sum I   min        Conf count Items L count Items L Items L if i k i 005 003   return Items L i  Items L k  004 002  count Items L count Items L Items L i k i       003  End if End if End if End for End for Time complexity analysis of the algorithm: the record number in database \(m\always very large. Actually, constant n, the items which user interested is smaller. The complexity of the algorithm is O   1 2    n m  IV  E XPERIMENT AND E XPERIMENTAL A NALYSIS  A  The improved algorithm flowchart At the beginning, input the target data forms and interested items. Scan all the item collections in the database, and save the frequency in the list-L. Input the threshold of support degree and credibility, judge whether they are legal, then scan L, delete items whose frequencies are smaller than the frequency threshold, mine AR according to the related rules. At last, need further mining or not. If so, keep inputting new threshold of support and credibility to continue mining Otherwise exit from the program. The flowchart of the improved algorithm is shown in Fig.1  Figure 1  The improved algorithm flowchart B  Experiment examples of improved algorithm All data and parameters have listed on the Table I interested item is ABC 


 1  frequencies of A 002 AB 002 AC 002 ABC 002 B 002 BC 002 C are 3 002 3 002 2 002 2 002 3 002 2 002 3 2  The frequent items are {A 002 AB 002 AC 002 ABC 002 B 002 BC 002 C 3  Candidate association relations are on the list A 004 BC 002 B 004 AC 002 C 004 AB 002 AB 004 C 002 AC 004 B 002 BC 004 A 002 A 004 B 002 A 004 C 002 B 004 A 002 B 004 C 002 C 004 A 002 C 004 B}. The credibility are as follows 002 67 002 67 002 67 002 67 002 100 002 100 002 100 002 67 002 100 002 67 002 67 002 67 4  As a result, only these items {AC 004 B 002 BC 004 A 002 A 004 B 002 B 004 A}meet the requirement 002 their credibility have reached to 100 V  P ERFORMANCE E VALUATION OF IMPROVED A PRIORI ALGORITHM  At first, the minimum support of degree and credibility are changeable in the algorithm provided in this paper, which greatly facilitate the customer's requirements. Secondly, the advanced mining algorithm has explicit object, improves the mining efficiency, reduce the time and space complexity. The author have test the traditional algorithm and the advanced one based on the same situation that all the data are from Table I and lead to the results showed in Fig. 2\(a Fig. 2\(a\ showed that improved algorithm improved a lot on time. When it comes to the case that the transaction database is huge and the number of interested items is much smaller, the improved algorithm runs much better. As shown in Fig. 2\(b\ we set that each storage object accounted for 3 bytes   a\                                                              \(b Figure 2  Performance results of improved apriori algorithm VI  C ONCLUSION  The paper do some research on the Apriori algorithm, it showed that the biggest challenge of the Apriori algorithm faced is the computational efficiency issue. We reach a conclusion after an analysis on Apriori algorithm: reduce the frequency we scan the database; reduce the item collection that impossibly become a mining relationship; improved the flexibility to be a user-friendly mining algorithm; the above measures can make the algorithm efficient. The algorithm provided in this paper can get the target to improve the efficiency For the future research and development, association rules mining can take these important aspects into consideration such as, how to improve mining efficiency of association rule especially in the situation that processing large amount of data how to set multiple supportive degree and creditable in multidimensional multi-layer database that user interested in order to mine more valuable association rule; how to mine related valuable rare item collection in a more efficient methods [9 10   R EFERENCES  1  W A N G L i Zhe n, Z HOU Li-Hua, et al. Data warehouse and data mining principles and applications. Beijing, Science Press, 2005 2 T  U no, M  K i y o m i a nd H  A r im ur a  Lcm v e r  2:Ef f i c i e n t m i ning  algorithms for frequent/closed/maximal itemsets. In B. Goethals,M J. Zaki,and R.Bayardo,editors, Proceedings of the IEEE ICDM Workshop on Frequent Itemset Mining Implementations \(FIMI’04 volume 126 of CEUR Workshop Pro ceedings, Brighton, UK, 2004  B  R acz n o n o r d f p  A n F P gro w t h vari at i o n w i t h ou t re b u i l d i n g t h e FPtree .In B.Goethals, M.J.Zaki,and R.Bayardo, editors Proceedings ofthe IEEE ICDM Works hop on Frequent Itemset Mining Implementations \(FIMI’04\, volume 126 of CEUR Workshop Pro ceedings, Brighton, UK, 2004 4 A d h i k a ri A 002 Rao P R 002 A framework for synthesizing arbitrary Boolean expressions induced by frequent itemsets[C 002 3rd Indian Intemat Conference on Artificial Intelligence 002 2007 002  5 M.K u r a m o c h i a nd G  K a r y pi s  Fr e que nt s ubg r a ph dis c ov e r y   I n  Proceedings of the first IEEE International Conference on Data Mining, pages313–320, 2001 6 M El ha de f K A b r oug ui S D a s N a y a k A pa r a lle l P r o b a b il i s tic  system- level fault diagnosis approach for large multiprocessor systems, Processing Letters, 1\(2006\,63~79 7  Ebe r ha r t R C  D o bb ins R W  N e ur a l N e t w or k P C T ools  A P r a c t i c a l  Guide[M  A cad e m i c P r ess 1 9 9 0     W u  X  W u Y  W a n g Y  et al  P r i vac y a w a re m a r k et b a sket d a t a set  generation:A feasible approach for inverse frequent set mining[c  SI A M I n te r n a t C onf e r e n c e on D a ta M i ni ng 20 0 5   9  A dhik a r i A  R a o P R  A f r am ew or k f o r sy nthe s i z i ng a r bitr a r y  Boolean expressions induced by frequent itemsets[C  3r d I ndia n  Internat Conference on Artificial Intelligence,2007 10 A  I nok uc hi,T W a s hio,a nd H  Mot oda A n a p r i or iba s e d a l g o r i t h m  for mining frequent substructures from graph data.In Proceedings of the 4th European Conference on Principles of Data Mining and KnowledgeDiscovery, pages13–23. Springer-Verlag, 2000  


which part or interaction is the source of accident Furthermore, even each Web service has been ensured no problem, we cant guarantee they can successfully interact with each other. Therefore, debugging for Web service composition is necessary, but a challenging task Case Study 2 Suppose there is a demo Web servicebased system, named TravelDemo Three service units are invoked in this system, that is FlightBook  HotelBook  and Payment and the composition logic can be described by BPEL file as shown in Figure 4. In each Web service, it can receive the input message in the format defined in WSDL file. In this example, all three service have input variables in complex type. For FlightBook service, its input message includes three parts: airC omp \(i.e. airline company seatType \(senior or economics\Type \(direct or transfer\Suppose the input message of service HotelBook consists of two parts, i.e., st arLevel and roomType. The input of service Payment can be divided into two parts: payWay i.e., VISA, Master or Unionpay\ount xml version="1.0" encoding="utf-8 process name="TravelDemo partnerLinks>  ......  </partnerLinks variables>  <variable name="flightRequest  variables sequence  flow sequence> <invoke partnerLink="FlightBook" operation  bookFlight" inputVariable="flightRequest receive partnerLink=" FlightBook " operation flightCallback" variable="flightResp sequence sequence> <invoke partnerLink="H otelBook" operation bookHotel" inputVariable="hotelRequest receive partnerLink=" HotelBook " operation="hotelCallback variable="HotelResp sequence flow  invoke partnerLink="Payme nt" operation="paySubscription inputVariable="payInfo sequence process Figure 4 BPEL program of the TravelDemo system For the diagnosis of WSC the conditional part of decision table of each service should be constructed first then incorporated into a bigger decision table. In the whole DT as shown in Table 4, the deci sion part is the behavior of the whole Web service-based system. Take Web service composition TravelDemo for example, the decision table for system diagnosis include s seven conditional attributes such as airComp, starLevel, and payWay. The observed behavior is the decision attr ibute of whole information system In general, the attribute with discrete value can be easily conducted to form several equi valence classes. But, for the attribute with continues data type, it is hard to partition its value. Its partitioning should de pendent on the maintainers domain knowledge. For the example system in this subsection, we divide the attri bute of payment amount into three intervals: \(-, 0 M M represents the reasonable threshold of payment for booking flight and hotel symbols + and … stand for the positive and negative infinity respectively Another case should be taken into consideration, that is some services are located in different branch structures of BPEL specification. For the reason of branch execution some services can not be invoked so their parameters have no specific value. Here, we assign any value \(denoted as asterisk\he corresponding conditional attributes in decision table After the decision table for whole Web service composition is achieved via th e above method, we can perform the same rough set reasoni ng algorithm to mine the rules associated with system failures D Discussion For the parameter value of each service interface, we adopt the equivalence class met hod to classify it into a specific category. Although it is be neficial to construct decision information table, it will also bring trouble to the further reasoning, that is inconsistent record in decision table Due to the arbitrariness of equivalence partition, two cases with the same input data will produce different output e.g. one can successfully run and the other maybe cause a runtime exception. Accordingly, these two test cases will T ABLE 4  T HE D ECISION T ABLE FOR THE W EB S ERVICE BASED S YSTEM T RAVEL D EMO  FlightBook HotelBook Payment No airComp seatType lineType starLevel roomType payWay amount Result t 1 CZ senoior direct 5_star single VISA 0 Succ t 2 MU economics transfer 3_star standard Unionpay 0 E1 t 3 ZH economics direct 4_star standard Master 0 Succ       t i MU senoior transfer 5_star standard VISA M E2                 t n CZ economics direct 3_star single Unionpay 0 Succ    Here, E1 and E2 denote two exceptions respectively, and M is a threshold value of payment  
297 


bring inconsistent ob jects into decision tab le. To handle the inconsistency in decision ta  proposed a n  algorithm named LEM2 to ex tract rules from that table. Its main idea can be described as below: At first, it computes the super proximity   R X ior   R X  attribute classification X Then we can generate deterministic rules from   R X and probab ilistic rules from   R X The final output rules are the sum of these two kinds of rules The second threaten is the uncertain attribute value problem mentioned in the above subsection. That is to say the value of some attributes is undetermined or arbitrary Fortunately, this case has been studied in the field of intelligent information processing. The typical treatment can be addressed as below: the undetermi ned attribute value can be denoted by *, the corresponding information system \(IS is called incomplete IS. Then, the decision rules can be directly derived from such an incomplete decision table according to the algorithm The last problem is how to locate the faults according to association rules produced by rou gh set reasoning. In service unit level, service providers \(or developers\he traditional program slicing t echnique to find defect. Since Web service is usually written in the common language such as Java or C#, the existing slicing method can handle this matter. In the service composition level, except for the independent debugging of e ach service unit, our previous  oblem. The technical sketch is to build a BPEL program dependence graph through in-depth analysis on the new activity elements such as flow and pick Then the dynamic backward slicing algorithm is proposed to find the statements closely related with the specific value of some variables. For a system failure rule r assume  ii DynSlice v l t is the dynamic slicing results for conditional attribute i v with value t at the line i l in BPEL program. Then, the intersection 1  n ii i DynSlice v l t 002 003 is the suspect statements in BPEL file, where n is the service unit number in whole system V R ELATED W ORK  Software debugging is an impor tant task after the testing activity. In recent years, the automated debugging has aroused lots of interests both in academic and industrial fields. However, the diagnosis or fault localization for Web service-based system has not caused enough attention until today When the source code of program is visible, the methods in machine learning and dat a mining have been adopted to find the knowledge which can assist debugging activity. In order to avoid repetition of debugging activities, Dickinson and Podgurski initially em ployed clustering analysis on failure executions, and sampled several records from each cluster to assist debugging [8   Li and Zhou adopted a nothe r data mining technique, i.e., fre quent item-set mining, to mine usage patterns among the execution records of program elem Other m e thods such as nearest neighbor query  Bayesian reasoning 11 frequent pattern m i ning [12 and statistical me  hav e been widely used for locating faults in program code. The executi on history of statement branch or path is an important evidence to reveal the defects so the spectrum-based method a n  ha ve  been validated as an effective way for software debugging However, the source code of Web service is invisible for service user \(i.e., developer of We b service-based system\in most cases, so the traditional program code-based debugging methods is not suitable for Web service system. Based on our previous work we adopt the rough set reasoning to find the knowledge rules for the depth fault location In the existing fault diagnosis of Web services monitoring-based method [2 is the ty pical one. In this diagnosis model, the sending or receiving information of each service interface is monitoring via embedded object and then compare this information with the expected states to locate the abnormal service unit. L. Ardissono et al. proposed a model-based diagnosis metho d to enhance fault analysis  h ey add to each service a local diagnose r which relates hypotheses about incorrect outputs of itself or incorrect inputs from other services. Meanwhile, a global diagnoser service is used to perform message exchanging and global diagnoses. In add ition, Bayesian network-based me  is also used to identify the m o st likely problematic services in a Web service composition process In our work, another intellig ent analysis technique, rough set reasoning, is introduced to settle Web service debugging problem Generally speaking, program sli cing is a useful fault location technique for software maintainers. In service unit level, the service providers can slice services code to find the potential defects according to the feedback from service requesters. In service composition le vel, the workflow of whole system is usually described in the process specification language such as WS-BPEL and OWL S   In or der to reveal the interaction faults between services  the composition code written in these languages should be analyzed. In a m e thod for slicing BPEL programs in Web service compositions is proposed. When the suspect BPEL code is exposed, the composition logic should be further checked. So the WSC slicing method can be treated as the complement step after achieving the failure association rules VI C ONCLUSIONS  Web services technology is a new pattern for integrating the programs or components over the Internet. Due to its merits such as loose-coupli ng, language independence, and distributed execution, it has been wi dely adopted to construct complex software system. However, the above features bring some inevitable trouble to maintain Web service-based software. In recent years, the researches mainly pay attention to Web service testing techniques But the testing activity is mainly to find the input cases associated with system failures According to the testing results, how to expose the defect point in Web service syst em is still an open problem In the paper, a system diagnosis framework based on rough set reasoning is pr oposed. Two level debugging models, i.e. single service debugging model and Web service 
298 


composition debugging model, are discussed in details. After the decision table is constru cted through collecting WSDL interface information, composition process specification, and testing execution information rule extraction algorithm in rough set reasoning is used to find the rules associated with system or service failures. In a ddition, the feasibility and effectiveness of our approach are validated by two examples and experiments. At present, we onl y consider the debugging problem for the common Web service system, the fault location for semantic Web services should be further explored in the on-going research A CKNOWLEDGMENT  This work was supported in part by the National Natural Science Foundation of China \(NSFC\under Grant No 60803046, China Postdoctoral Science Foundation under Grant No.2007041 0946, the Science Fo undation of Jiangxi Educational Committee under Grant No. GJJ10433, and the Youth Foundation of Jiangxi University of Finance and Economics. The author is grateful to Qiong Zhang for her warm-heart help, and thanks the anonymous reviewers for their insightful comments R EFERENCES  1 W. Han  Integrating Peer-to-Peer into Web Services Master thesis University of Saskatchewan, 2006  W3C Web S e rvi ces Activit y avai lable fro m  http://www w3.org 2002/ws/, accessed on July 2010  W o rld W i de W e b Cons ortiu m  W3C Web Services Description Language \(WSDL\ Version 1.1 March, 2001. Available at http://www. w3.org/TR/wsdl  W o r l d W i de W e b Consor tiu m  W 3C  Simple Object Access Protocol Version 1.2 April 2007, available at http://www.w3.org/TR/soap12  OASIS WSBP EL Technical Co mm i ttee  Web Services Business Process Execution Language, Version 2.0 available at http://docs oasis-open.org/wsbpel/2.0 /wsbpelv2.0.pdf  M. Aoya m a S Wee rawa rana, H Maruya m a and et al W eb  Services Engineering: Promises and Challenges Proc. of ICSE’02  ACM Press, New York 2002, pp. 647-648  C. Liu L. Fei X Yan, and et al., Statistical Debuggin g: A Hypothesis Testing-Based Approach IEEE Transactions on Software Engineering 2006, vol. 32, no. 10, pp.1-17  W  Dickinson, D. Leon, and A Podgurski, Finding Failures by Cluster Analysis of Execution Profiles Proc. of ICSE’01 2001, pp 339-348  Z. Li and Y Zhou, PRM iner: Automatically Extracting Implicit Programming Rules and Detecting Violations in Large Software Code Proc. of ESEC/ FSE’05 2005, pp. 306-315  M. Renieris, and S. P Reiss, Fault LocalizationWith Nearest Neighbor Queries Proc. of ASE’03 2003, pp. 30-39  C. Liu, Z Lian and J. Han, How Bayesians Debug Proc. of ICDM’06 2006, pp.382-393  G. D. F a tta, S   Leue, and E. St e g antova D iscri m inative Pattern Mining in Software Fault Detection Proc. of SOQUA’06 2006 pp.62-69  M. J Harrold, G. Rotherm e l, K Sayre, and et al., An Empirical Investigation of the Relationship Between Fault-revealing Test Behavior and Differences in Program Spectra Journal of Software Testing Verification and Reliability 2000, vol. 10, no.3, pp. 171-194  D. Jeffrey, N. Gup ta, and R. Gupta Fault Localizatio n Using Value Replacement Proc. of ISSTA’08 2008, pp. 167-178  IBM W e b Services: Taking e-Busi ness to the Next Level White Paper, 2000, available from: http://www.ibm.com/developerworks/cn websphere/ download/pdf/e-businessj.pdf  S. Noikajana, and T. Suwannasart, W eb Service Test Case Generation Based on Decision Table Proc. of the 8th International Conference on Quality Software \(QSIC’08 2008, pp. 321-326  C M a o Per form ing Co m b inator ial Testing on W e b Ser viceBased  Software Proc. of Int’l Conf. on Computer Science and Software Engineering \(CSSE’08 2008, vol.2, pp.755-758  T  Y Chen F.C  Kuo T  H T s e and et al  M eta m or phic T e sting and Beyond Proc. of the 11th International Workshop on Software Technology and Engineering Practice \(STEP’03 2003, pp.94-100  Business Process Managem e nt Initiative Business Process Modeling Language \(BPML November, 2002  W 3 C  OWL-S: Semantic Markup for Web Services Nov. 22, 2004 available from: http://www.w3.org/ Submission/OWL-S  Z. Pawlak, Roug h Set Int’l Journal of Information and Computer Science vol. 11, 1982, pp. 341-356  Jianhua Dai Research on Rough Set Theory and Its Applications in Knowledge Discovery \(Ph. D. Dissertation Library of Wuhan University, 2003, pp. 97104.   \(in Chinese  M Kry szkiewicz, Rou gh Set Approach to Inco m p l e t e Inform ation Systems Information Sciences 1998, vol. 112, pp. 39-49  C  M a o, Slicing W e b Ser vicebased Softwar e Proc. of IEEE International Conference on Service-Oriented Computing and Applications \(SOCA’09 Taipei, Taiwan, December 14-15, 2009, pp 91-98  C M a o X Hu and Y L u  T owards a Softwar e Diagnosis M e tho d  Based on Rough Set Reasoning Proc. of the IEEE 8th International Conference on Computer and Information Technology \(CIT’08  Sydney, Australia, July 811, 2008, pp. 718-723  I   Gr osclaude  M odelbased M o nitor ing of Co m ponentbased Software Systems Proc. of the 15th International Workshop on Principles of Diagnosis 2004, pp. 155-160  L  Ar dissono L  Console A Go y  and et al Enhancing W e b  Services with Diagnostic Capabilities Proc. of the 3rd IEEE European Conference on Web Services 2005, pp. 182-191  X Fu P Z ou  Z   Shang and et al   Fault Diagnosis f o r W e b Ser vice Composition Based on Bayesian NetworkŽ, Computer Applications 2008, vol.28, no. 5, pp. 1095-1097.   \(in Chinese   
299 


        


9 Appendix Fig 6: Forest Cover Types of the U.S. \(Source. USGS National Atlas of US Summary of Forest Cover Type Data Type Multivariate Abstract The forest cover type for 30 x 30 meter cells obtai ned from US Forest Service \(USFS\ Region 2 Resource Information System RIS\ data Data Characteristics The actual forest cover type for a given observatio n \(30 x 30 meter cell\ was determined from US Fores t Service \(USFS\ Region 2 Resource Information System RIS data Independe nt variables were derived from data originally obta ined from US Geological Survey \(USGS\ and USFS data. Data is in raw form \(not scaled\ and contains binary \(0 or 1 columns of data for qualitative independent variables \(wilderness areas and soil types Summary Statistics Number of instances observations 581012 Number of Attributes 54 Attribute breakdown 12 measures, but 54 columns of data \(10 quantitativ e variables, 4 binary wilderness areas and 40 binary soil type variables Missing Attribute Values None 43 


   C4.2 Open GL has excellent documentation that could help the developer learn the platform with ease C4.3 Developer has very little ex perience in working with Open GL platform  For our case study, alternative B i.e. Adobe Director was the most favorable alternative amongst all the three. It catered to the reusability criteria quite well and aimed at meeting most of the desired operational requirements for the system   6. CONCLUSION & FUTURE WORK  The main contribution of this paper is to develop an approach for evaluating performance scores in MultiCriteria decision making using an intelligent computational argumentation network. The evaluation process requires us to identify performance scores in multi criteria decision making which are not obtained objectively and quantify the same by providing a strong rationale. In this way, deeper analysis can be achieved in reducing the uncertainty problem involved in Multi Criteria decision paradigm. As a part of our future work we plan on conducting a large scale empirical analysis of the argumentation system to validate its effectiveness   REFERENCES  1  L  P Am g o u d  U sin g  A r g u men ts f o r mak i n g an d  ex p lain in g  decisions Artificial Intelligence 173 413-436, \(2009 2 A  Boch m a n   C ollectiv e A r g u men tatio n    Proceedings of the Workshop on Non-Monotonic Reasoning 2002 3 G  R Bu y u k o zk an  Ev alu a tio n o f sof tware d e v e lo p m en t  projects using a fuzzy multi-criteria decision approach Mathematics and Computers in Simualtion 77 464-475, \(2008 4 M T  Chen   F u zzy MCD M A p p r o ach t o Selec t Serv ice  Provider The IEEE International Conference on Fuzzy 2003 5 J. Con k li n  an d  M. Beg e m a n   gIBIS: A Hypertext Tool for Exploratory Policy Discussion Transactions on Office Information Systems 6\(4\: 303  331, \(1988 6 B P  Duarte D e v elo p in g a p r o jec ts ev alu a tio n sy ste m based on multiple attribute value theroy Computer Operations Research 33 1488-1504, \(2006 7 E G  Fo rm an  T h e  A n a l y t ic Hier a rch y P r o cess A n  Exposition OR CHRONICLE 1999 8 M. L ease  an d J L  L i v e l y  Using an Issue Based Hypertext System to Capture Software LifeCycle Process Hypermedia  2\(1\, pp. 34  45, \(1990 9  P e id e L i u   E valu a tio n Mo d e l o f Custo m e r Satis f a c tio n o f  B2CE Commerce Based on Combin ation of Linguistic Variables and Fuzzy Triangular Numbers Eight ACIS International Conference on Software Engin eering, Artificial Intelligence Networking and Parallel Distributed Computing, \(pp 450-454 2007  10  X  F L i u   M an ag e m en t o f an In tellig e n t A r g u m e n tatio n  Network for a Web-Based Collaborative Engineering Design Environment Proceedings of the 2007 IEEE International Symposium on Collaborative Technologies and Systems,\(CTS 2007\, Orlando, Florida May 21-25, 2007 11 X. F L i u   A n In ternet Ba se d In tellig e n t A r g u m e n tatio n  System for Collaborative Engineering Design Proceedings of the 2006 IEEE International Symposium on Collaborative Technologies and Systems pp. 318-325\. Las Vegas, Nevada 2006 12 T  M A sub jec tiv e assess m e n t o f altern ativ e m ission  architectures for the human exploration of Mars at NASA using multicriteria decision making Computer and Operations Research 1147-1164, \(June 2004 13 A  N Mo n ireh  F u zzy De cisio n Ma k i n g b a se d o n  Relationship Analysis between Criteria Annual Meeting of the North American Fuzzy Information Processing Society 2005 14 N  P a p a d ias HERMES Su p p o rti n g A r g u m e n tative  Discourse in Multi Agent Decision Making Proceedings of the 15th National Conference on Artifical Intelligence \(AAAI-98  pp. 827-832\dison, WI: AAAI/MIT Press,  \(1998a 15  E. B T riantaph y llo u   T h e Im p act o f  Ag g r e g atin g Ben e f i t  and Cost Criteria in Four MCDA Methods IEEE Transactions on Engineering Management, Vol 52, No 2 May 2005 16 S  H T s a u r T h e Ev alu a tio n o f airlin e se rv ice q u a lity b y  fuzzy MCDM Tourism Management 107-115, \(2002 1 T  D W a n g  Develo p in g a f u zz y  T O P S IS app r o ach  b a sed  on subjective weights and objective weights Expert Systems with Applications 8980-8985, \(2009 18 L  A  Zadeh  F u z z y Sets   Information and Control 8  338-353, \(1965  152 


                        





