 GLFMiner: Global and Local Frequent Pattern Mining with Temporal Intervals Kuo-Cheng Yin Department of Information Engineering and Computer Science, Feng Chia University, Taichung 407 Taiwan Department of Information Management, Jen-Teh Junior College, Taiwan E-mail: inn0206@gmail.com Yuh-Long Hsieh, Don-Lin Yang Department of Information Engineering and Computer Science Feng Chia University Taichung, 407 Taiwan E-mail: yuhlong.hsieh@gmail.com, dlyang@fcu.edu.tw Abstract  In this paper, we propose a new approach of mining temporal association rules. In conventional association rule mining algorithms, if the value of minimum support is set too high, we may lose lots of valuable rules. But if it is set too low many trivial rules will be mined, and it is hard to distinguish which ones are valuable. When taking temporal factors into consideration, an itemset may not be frequent over the entire database but may be frequent in some specific intervals. Here, we propose a temporal association rule mining algorithm for interval frequent patterns, called GLFMiner, which can automatically generate all of the intervals without using any domain knowledge In our algorithm, we consider not only global frequent patterns but also local frequent patterns. Then, with the same value of minimum support, we can find plenty of valuable temporal rules and donít lose any rule that conventional association rule mining algorithm can find. The experimental results show that our algorithm can mine more temporal frequent patterns than the conventional association rule mining algorithm Keywords- association rule; local frequent pattern; global frequent pattern; temporal frequent pattern I I NTRODUCTION The problem of mining association rule is to discover all rules that have support and confidence greater than or equal to the user-defined minimum support and minimum confidence thresholds. For example, examining the dataset of a supermarket, we may get an association rule like Turkey Pumpkin pie \(support=0.01%, confidence=5 which means that 0.01% of all transactions contain both turkey and pumpkin pie, and 5% of all transactions which contain turkey also contain pumpkin pie In fact, we can not regard the above rule as a prominent association rule due to the following two reasons. First, the support of that rule is low. It means that the turkey and pumpkin pie seldom coexist in the entire dataset. Second, the confidence of that rule is low too. It means that a large number of transactions which contain turkey do not contain pumpkin pies. However, if we only look at the transactions in a specific time interval, for example the week before Thanksgiving, it can be found that most of the transactions contain both turkey and pumpkin pie. It means that the rule, turkey pumpkin pie has a high support and a high confidence in the specific interval, the week before Thanksgiving From the above example, an itemset may not be frequent for the entire database but may be frequent in some specific intervals. We can realize there are lots of meaningful frequent patterns which can be found in some specific intervals Therefore, it is important on how we can find these intervals of frequent patterns in an effective mann iu  proposed the calendar based script to find the time interval but it has to devise the calendar based script by using domain knowledge. Here, we expect to automatically generate the intervals without any domain knowledge. Our proposed GLFMiner algorithm first transforms the database into a bitmap representation, and then recursively joins \(k-1\msets to generate k itemsets in depth-first order. After joining the itemsets, GLFMiner will generate the intervals of frequent itemsets The frequent patterns mined from the conventional association rule mining algorithms are called global frequent patterns. There is a problem which may lead the user to make a wrong decision according to these association rules. For example, a shopkeeper mines an association rule diaper beer, and then he/she may promote a sale package 10% discount for buying beer and diaper together, in the winter. The promotion is doomed to failure. The main reason is that one does not know when is the right time to apply the rule ëdiaper beerí. Most people like to drink beer in the summer, so ëdiaper beerí may be suitable for the summer not winter. From the above example, it is important to generate the association rule which contains sp ecific interval to be applied for the best result. Using GLFMiner algorithm we can not only get the frequent patterns of specific intervals, but also generate all the specific intervals for these local frequent patterns The rest of paper is organized as follows. In Section II, we will describe the temporal association rule mining problem and introduce the related work of temporal association rule mining. In Section III, the proposed GLFMiner algorithm is described in three folds: \(1\read the database and transform transactions into the bit-map representation, \(2\the bit-map representations of all items to form intervals, \(3 recursively join \(k-1\msets to generate k itemsets and find local and global frequent itemsets. In Section IV, experimental results of synthetic datasets are given. Finally, we make a conclusion in Section V This research was supported by the National Science Council, Taiwan, under  grants NSC 98-2221-E-035-059-MY2 and NSC 98-2218-E-007-005 2248 978-1-4244-5046-6/10/$26.00 c  2010 IEEE 


II B ACKGROUND AND RELATED WORK In past decades, various algorithms have been proposed to efficiently discover the frequent itemsets in different applications. These methods include level-wise algorithms 1,2 d pattern g r o w th  m e th ods 4,5  Temporal association rule mining is an extension of association rule generation. There are many temporal association rule mining algorithms being proposed recently They can mine more meaningful frequent patterns, temporal association rules of intervals and up-to-date association rules than conventional association rule mining algorithm. We will introduce the related studies in the following Hong s e d th e u p t o date as s o ciat ion ru le. T h e main idea comes from that an itemset may not be frequent for an entire database but may be large up-to-date since the items seldom occurring early may often occur later. An up-to-date pattern is composed of an itemset and its up-to-date lifetime in which the user-defined minimum support threshold must be satisfied It is possible to find interesting associations with a high confidence level but with small support. Al m ited th e  total transactions to the ones belonging to the items' lifetime those associations would be now discovered, as they would count on enough support. He expanded the notion of association rules incorporating time to the frequent itemsets Every item has a period of lifetime or lifespan in the database which explicitly represents the temporal duration of the item information, i.e. the time in which the item is relevant to the user L plored a n e w problem of  m i n i n g g e n e ral  temporal association rules in publication databases. A publication database is a set of transactions where each transaction is a set of items of which each item contains an individual exhibition period. The author claimed that the current model of association rule mining is not able to handle the publication database due to the following fundamental problems, i.e., \(1\ consideration of the exhibition period of each individual item; \(2\ of an equitable support counting basis for each item. He proposed a PPM algorithm The basic idea of PPM is to first partition the publication database in light of exhibition periods of items and then progressively accumulate the occurrence count of each candidate 2-itemset based on the intrinsic partitioning characteristics Ts prop os ed a n e w  f r a m e w ork  f o r data s t rea m  m i n i ng  called the weighted sliding window model. The proposed model allows the user to specify the number of windows for mining, the size of a window, and the weight for each window It emphasized the temporal factor and gave higher weight to recently happened events Li t u d i e d t h e probl em of  m i n i n g a s s o ci at i o n r u l e s a n d  related time intervals, where an association rule holds either in all or some of the intervals. To restrict to meaningful time intervals, he uses calendar schemas and their calendar-based patterns. A calendar schema example is \(year, month, day\ and a calendar-based pattern within the schema is \(*, 3, 15\, which represents the set of time intervals each corresponding to the 15th day in March 10,1 s u m e t h at t h e trans action s are ti m e s ta m p ed, s o  one can decide if a transaction occurs during a specific time interval. The others [6,7,8 d o n  t m a k e th i s as s u m p tion    In GLFMiner, we donít assume the transaction is time stamped and use the transaction sequence as the temporal factor to generate all the intervals of itemsets. Our main contribution is that it can not only find out global frequent patterns in the whole database, but also discover local frequent patterns within the specific intervals III A LGORITHM DESCRIPTION A Notation and definitions DB The database DB DB The number of transactions in the database DB DB i  The total number of transactions in the interval i of DB T  The transactions containing in the database DB T i   The transactions containing in the specific interval i of DB MinSup The minimum support threshold MinLen The minimum length of an interval threshold A frequent pattern is an itemset whose frequency in DB is larger than or equal to MinSup. Here, we propose the concept of local and global frequent patterns. GLFMiner performs a search for frequent pattern sets over a novel Interval-tree search space which is shown in Fig. 8. Each node in the Interval-tree represented by an itemset-interval-tidset-count data structure, is in fact a prefix-based class. All the children with length k of a given node belong to its class since they all share the same prefix  So, all the children in the same class can be joined to form \(k+1 frequent patterns. Now, we show some definitions that will be used in the proposed algorithm later Table 1 An example dataset Tid Transaction Time Items  1 2009/7/1 a,b,d,f 2 2009/7/16 a,b,d,f 3 2009/8/3 d,f 4 2009/8/9 c,f 5 2009/9/10 a,f 6 2009/9/30 f 7 2009/10/3 c,e 8 2009/10/18 a,b,c 9 2009/11/8 a,b,c,d,e 10 2009/11/27 a,f Definition 1 Interval-tree={Node 1 Node 2 Node n  Interval-tree is a prefix based tree. The root node of Interval-tree is null. If Node n is the parent of Node m Node m Node n 1 and Node n is the prefix of Node m  Definition 2 The structure of a node for itemset in the Interval-tree is defined as follows Struct  2010 5th IEEE Conference on Industrial Electronics and Applicationsis 2249 


Itemset TidSegmentSet  where Itemset records frequent pattern and each TidSegment records information of intervals TidSegmentSet is the set of all TidSegments  Interval information contains begin,end bit m a p t where [begin,en e n t s an in ter v a begin is the first transaction id in this interval end is the last transaction id in this interval bitmap is a consecutive number of 1 and 0 where 1 represents the corresponding transaction contains and 0 represents the corresponding transaction does not contain and count is the number of the transactions which contain For example, in Table 1, a[1,1 1 100 100 111   represents that itemset ëaí appears in the interval h e  corresponding bitmap is \(1100100111\d the frequency of occurrence is 1 1   11 2 repres e n t s t h at itemset ëabí appears in two intervals d [8,9   Definition 3 An itemset is called a global frequent pattern in a database DB if 1\upport T DB 2\upport Sup The definition of global frequent patterns is the same as the definition of frequent patterns of conventional association rule mining algorithm. For example, based on the MinSup=0.5, item ëa n T a ble 1 is a 1g l obal f r equ e n t  itemset for the entire database, where the first transaction containing ëaí is 1 and the last transaction containing ëaí is 10 Definition 4 An itemset is called a local frequent pattern in a database DB if 1\upport T i  DB i  2\upport Sup Giving a MinSup, local frequent patterns represent the patterns whose counts are larger than MinSup just for the specific intervals. For example, if MinSup=0.5, itemset ëeí is a 1-local frequent itemset in the interv becau s e   T i e\=2 DB i 3 and |T i e\/|DB i 0.67. However, it is not a global frequent itemset for MinSup=0.5 Definition 5 Two consecutive intervals are called mergeable if and only if the following condition is met  MinSup begin end count count n n n n       1     1 1     where n-1 begin,end  c o unt a n d  n begin,en t are t w o consecutive intervals of  For exam 1  7 11 1  MinSup begin end count count          67  0 1 4 9 1 3 1     1 2 1 2     they are called mergeable Definition 6 The merge of consecutive intervals is defined as follows Merge n-1  n  n-1 begin bitm ap t w h ere  n-1 begin,en bit m ap t an d n begin,en bit m ap count are two consecutive intervals of to be merged, then n-1 begin n-1 begin n-1 end n end n-1 count n-1 count  n count\d bitmap is adjusted accordingly For example, two intervals: c n-1   1 c n 7 1 11   Merge\(c n-1 c n  n-1   100 11 1 h ere c n-1 begin=c n-1 begin 4, c n-1 end= c n end=9, c n-1 count=\( c n-1 count c n 3+1 Definition 7 The minimum length of an interval is denoted as MinLen If the length of an interval is less than MinLen, it means this interval is not prominent enough. Then it will be deleted For example, the length of an interval is 1, the support of this interval is 100% and the confidence is 100% too. Since it is meaningless at all, we can regard it as a noise and delete it Definition 8 The nodes of itemset and itemset are called joinable, if and only if both the nodes and have the same parent node in the Interval-tree Definition 9 The join of the nodes of itemset and itemset is defined as follows begin,en bit m ap join begin,en bit m ap begin,en bit m ap where as in the traditional definition of join begin=Max begin begin end=Min end end bitmap=AND  begin end m ap  begin end ap  If begin end\means that the intervals of itemsets and are disjoined. Then, the node of itemset will be discarded For example begin,en bitm ap oin  ab[1 2 11  af 11 001  1,2 1 1  a,b a,f}={a,b,f begin=Max\(1,1 end=Min\(2,5 bitmap=AND \( ab[1,2 1 1 af 1,2].\(1 1 ND\(11,1 1 1 B Main Algorithm The proposed algorithm is composed of two main steps First, it scans the database to find out the global frequency of each item and transforms all items into bit-map representation to speed up the following processing. Then, it localizes each item that is not global frequent and adds them to the Intervaltree Second, it recursively joins each item in depth-first order on the Interval-tree. After that, it localizes the joined itemset to find out the frequent intervals and add them to the Intervaltree. Those frequent intervals are output as temporal frequent itemsets. The pseudo code of GLFMiner algorithm is described in Fig. 1. In the following section, we will illustrate the detail steps of GLFMiner 2250 2010 5th IEEE Conference on Industrial Electronics and Applicationsis 


   Main_Algorithm Input: \(1\ DB_File \(2\ MinSup \(3\ MinLen Output:\(1\ Global and Local Frequent ItemSet Begin 1\  RootNode=ScanDataBase\(DB_File, MinSup, MinLen 2\  FreqSet = RecursiveJoin\(RootNode End  Fig. 1 The main algorithm of GLFMiner Function ScanDatabase Input:  \(1\ DB_File \(2\ MinSup \(3\ MinLen Output: \(1\_RootNode Begin 1\   m_RootNode Create Root Node 2\   Candidate_Items getItemFrequency \(DB_File 3\   for \(each item in Candidate_Items 4\     Begin 5\        If not global frequent 6\          Localize \(Candidate_Items 7\        If IsFrequent \(Candidate_Items, MinSup, MinLen 8\          m_RootNode.addChild \(Candidate_Items 9\     End 10\  Return m_RootNode End Fig. 2 The pseudo code of ScanDatabase Step 1: At first, GLFMiner scans the database, transformsds all items into bit-map representation and gets the frequency of each item to check whether it is global frequent. If it is not global frequent, Localize function is used to get local frequent intervals. The pseudo code of ScanDatabase is listed in Fig. 2. By using the dataset of Table 1 with MinSup=0.5 the bitmap representation of item ëaí is \(1100100111\ as shown in Fig. 3.  Because the count of item ëaí is 6 and is larger than MinSup DB|=0.5 10=5, ëaí is a global frequent itemset. The bitmap representation of item ëbí is 1100000110\ince the count of item ëbí is 4 and is less than the MinSup threshold, ëbí is not a global frequent itemset and has to be localized a\(1100100111\ b\(1100000110\, c\(0001001110\, d\(1110000010 e\(0000001010\ f\(1111110001 Fig. 3 The bitmap representation of items Function Localize Input: \(1\ Node Begin 1\ TIDSegmentSet = Partition \(TIDSet\(Node\, MinSup 2\ TIDSegmentSet = MergeSegmentSet \(TIDSegmentSet, MinSup 3\ TIDSegmentSet = PruneSmallThanMinLen \(TIDSegmentSet End Fig. 4 The pseudo code of Localize Step 2: Localize those intervals of items which are not global frequent. Localization contains three steps as shown in Fig. 4 First, it partitions the bitmap representation of an itemset to find out the frequent intervals of that itemset. Then, it checks whether the two consecutive intervals can be merged in order to form a larger frequent interval. At last, it prunes the intervals whose lengths are less than MinLen Function Partition Begin 1\For each bitmap of Itemset t i 2\  k=1; Interval[1 be g i n 0  3\  For j=1 to n //n=the length of the interval 4\    if \(bitmap[j  1    5\      if \(Interval co u n t 0    6\          Interval[k  be g i n j  7\          Interval[k  co un t 1   8\      else 9\          Interval[k  co un t   10\          Interval[k  e n d  j      11\   else 12\     if \(Interval[k co u n t  iI n te r v al k be g i n  M inS up  a n d   Interval  c o u nt  0 13\           Add_A_New_Interval_for_t i 14\           k 15\           Interval[k  co un t 0     End Fig. 5 The pseudo code of Partition Step 2-1: Partition the bitmap representation of an itemset. The related pseudo code is described in Fig. 5. For example itemset ëdí is not a global frequent itemset, and the bitmap representation of itemset ëdí is \(1110000010\ The procedure of partitioning itemset ëdí is shown in Table 2 Table 2 Partitioning the intervals of Itemset ëd n Bit Interval  Action 1 1 d[1 1 1/0.5=2 1-1+1 2 1 d[1 2 2/0.5=4 2-1+1 3 1 d[1 3 3/0.5=6 3-1+1 4 0 d[1 3 3/0.5=6 4-1+1 5 0 d[1 3 3/0.5=6 5-1+1 6 0 d[1 3 3/0.5=6 6-1+1 7 0 d[1,3  3  3 0 5 6   7 1  1   Add A New Interval 8 0   Skip 9 1 d[9 1 1/0.5=2 9-9+1 10 0 d[9,9  1  1/0.5=2 10-9+1 Add A New Interval Step 2-2: Merge the two consecutive intervals into a larger interval from the back to the front. The pseudo code is described in Fig. 6. Taking c 1 4  1 d c 2 7,9  1 1 1   3 for example \(c n-1 c 1 and c n c 2 se \(c 1 count+c 2 count c 2 end-c 1 9-4+1\Sup, c 1   1 1 and c 2   111  e rg ed in to c 1   1001 11 4 Function MergeSegmentSet \(TIDSegmentSet, MinSup Input: \(1\ SegmentList,\(2\ MinSup Output: TIDSegmentlSet Begin 1\   n =|SegmentList | -2 2\   While\(n>=0 3\        if mergeable \(Segment n Segment n+1  4\            SegmentList.remove \(Segment n+1  5\            Segment n merge \(Segment n Segment n+1  6\            if n == |SegmentList|-1 7\                n 8\       else 9\            n End Fig. 6 The pseudo code of MergeSegmentSet Step 2-3: Prune the intervals whose length are less than MinLen in order to remove trivial intervals. For example, if MinLen=0.2 and the length of d 2 9,9 is 1  w h ic h is le ss than 0.2 10=2, d 2 9,9 i l l be rem o v e d  2010 5th IEEE Conference on Industrial Electronics and Applicationsis 2251 


Step 3: Recursively join the itemsets in depth-first \(DF\rder from the root. The pseudo code is described in Fig. 7. The node of length \(k-1\oins all the right siblings to generate the combined itemset of length k. Every joining procedure contains the following steps Step 3-1: Node 1 joins Node 2 right sibling\or example SonN 11 0010 01 11 6 j o i n s b[1,2 11 2 ab[1,2 1 1  SonN 11 0010 01 11 6 j o i n s b[8,9 11 2 ab[8,9 1 1  Step 3-2: Localize SonNode Step 3-3: If SonNode is frequent, add it as a child of Node 1 Step 3-4: Add Node 1 to Frequent set FreqSet Function RecursiveJoin Input:  \(1\ ParentNode Output: \(1\reqSet Begin 1\for \(each node1ParentNode 2\  Begin 3\     for \(each node2  Right Siblings of node1 4\        Begin 5\           SonNode = node1.Join\(node2 6\           If not global frequent 7\               Localize \(Candidate_Items 8\           If isFrequent \(SonNode\ Then 9\               node1.addChild \(SonNode 10\      End 11\   FreqSet=FreqSet node1 12\   FreqSet=FreqSet RecursiveJoin \(node1 13\   ParentNode.RemoveChild \(node1 14\ End End  Fig. 7 The pseudo code of RecursiveJoin C A Complete Example Step 1: GLFMiner transforms each item in DB into bitmap representation Step 2: Perform localization Repeat Step 3-1: Node 1 joins Node 2 Step 3-2: Localize SonNode Step 3-3: If SonNode is frequent, add it as a child of Node 1 Step 3-4: Add Node 1 to Frequent set FreqSet Table 3 shows the part of procedure when deploying GLFMiner to mine the dataset of Table 1. Here, it just lists the construction procedure of the leftmost branch of the IntervalTree. The complete Interval-tree is shown in Fig. 8 Table 3 The part of procedures of deploying GLFMiner Step 1 Bitmap representations of every item a\(1100100111\, b\(1100000110\, c\(0001001110\:3 d\(1110000010\, e\(0000001010\, f\(1111110001\:8 Step 2-1 Partition a[1,10  1 100 100 111   b 1 2  1 1  2  b[8,9  1 1  2  c 4 4  1  1 c  7 9   1 11  3 d  1 3   1 11  3  d[9 1  e[7  9 10 1  2 f  1 10 1110 110 101  Step 2-2 Merge a[1,10  1 100 100 111   b 1 2  1 1  2 b  8  9 11    c[4 10 011 1  4 d 1 3 111   d 9 9 1   e[7 10 1  2 f  1 10 111 111 000 1  7 Step 2-3 Prune a[1,10  1 100 100 111   b 1 2  1 1  2 b  8  9 11    c[4 10 011 1  4 d 1 3 111    e  7 9 101    f[1 111 11 100 01  Step 3-1 Join\(a ab[1,2  11  2  a b  8  9  1 1   2  ac 8  9  1 1   2  ad[1,2  1 1  2 a f 1 1 0  1 100 100 001  Step 3-2 Localize ab[1,2  11  2  a b  8  9  1 1   2  ac 8  9  1 1   2  ad[1,2  1 1  2 a f 1 5 11 001  Step 3-3 Add node ab[1,2  11  2  a b  8  9  1 1   2  ac 8  9  1 1   2  ad[1,2  1 1  2 a f 1 5 11 001  Step 3-4 Add to Frequent set ab[1,2  11  2  a b  8  9  1 1   2  ac 8  9  1 1   2  ad[1,2  1 1  2 a f 1 5 11 001  Step 3-1 Join\(ab[1     abd[1 11   ab d[8 8  1  1 ab f[1 2]\(1 1  2  abf[8  1  Step 3-2 Localize abd[1 11   ab f[1 2 11  2 Step 3-3 Add node abd[1 11   ab f[1 2 11  2 Step 3-4 Add to Frequent set abd[1 11   ab f[1 2 11  2 Step 3-1 Join\(abd[1,2   ab df  1  2  1 1   2 Step 3-2 Localize abdf[1,2  1 1   2  Step 3-3 Add node abdf[1,2  1 1   2  Step 3-4 Add to Frequent set abdf[1,2  1 1   2  Step 3-1 Join\(abdf[1,2  Step 3-1 Join\(abf[1,2   Step 3-1 Join\(ab[8     a b c[8  9 11  Step 3-2 Localize abc[8  1 1  2 Step 3-3 Add node abc[8,9  1 1  2  Step 3-4 Add to Frequent set abc[8,9  1 1  2  Fig.8 The complete Interval-tree of Table 1 2252 2010 5th IEEE Conference on Industrial Electronics and Applicationsis 


IV E XPERIMENTAL RESULTS We implemented our algorithm in JAVA on an Intel Core Duo Processor personal computer with 1.99 GHz and 4 GB RAM. The synthetic database of IBM dataset generator T10I4D100K was used. In T10I4D100K, the size of a transaction is 10, the size of potential maximal frequent itemsets is 4, and the number of transactions is 100,000 GLFMiner algorithm was compared to the conventional association rule mining algorithm of Apriori without considering temporal intervals. In the first experiment, the relationship between the numbers of frequent patterns for different minimum support thresholds is shown in Fig. 9. Fig. 9 shows the results of T10I4D100K with MinLen=0.01 and MinSup=0.9 to 0.1. It is clear that the number of frequent patterns discovered by GLFMiner was larger than those mined by the conventional method  0 2,000 4,000 6,000 8,000 10,000 12,000 14,000 16,000 0.90.80.70.60.50.40.30.20.1 MinSupport Threshold    Fig. 9 The relationship between the numbers of frequent patterns for different MinSup thresholds of T10I4D100K The variation between the numbers of local frequent patterns and different MinSup thresholds for T10I4D100K is shown in Fig. 10. We can observe that the smaller the MinSup is, the larger the count of local frequent patterns is 0 100 200 300 400 500 600 700 800 0.09 0.08 0.07 0.06 0.05 0.04 0.03 0.02 MinSupport Threshold   Fig. 10 The relationship between the numbers of local frequent patterns for different MinSup thresholds of T10I4D100K The variation between the number of frequent patterns and different MinSup thresholds for T10I4D100K with MinSup=0.4 and MinLen=0.009 to 0.001 is shown in Fig. 11 We can observe that the smaller the MinLen is, the larger the count of frequent patterns is. When deploying GLFMiner algorithm, we can set a higher MinSup to cooperate with appropriate MinLen to mine the valuable frequent patterns 0 20 40 60 80 100 120 0.009 0.008 0.007 0.006 0.005 0.004 0.003 0.002 0.001     Fig. 11 The variation between the numbers of frequent patterns and different minimum support of MinLen thresholds V C ONCLUSIONS AND F UTURE W ORK In this work, we have described the concept of global and local frequent patterns and propose an approach, GLFMiner to discover such patterns from a temporal dataset. We have achieved the following advantages Discover association rules which are frequent in some specific time intervals The mined association rules contain time attributes that make them more useful for users Valuable rules can still be mined using larger thresholds Automatically generate the intervals of frequent patterns R EFERENCES 1 M i ng C h u a n H u ng S h iQ i n W e ng J ung pi n W u a n d D o nL i n Y a ng   Efficient Mining of Association Rules Using Merged Transactions Approach,î WSEAS Transactions on Computers, Iss. 5, Vol. 5, May 2006, pp. 916-923 2  R  Ag r a wa l a n d R  S r i k a n t   F a s t Al g o r i t h m s f o r M i n i n g As s o c i a t i o n  Rules,î Proceedings of the 20th International Conference on Very Large Data Bases, 1994, pp. 487-499 3 W e i S o ng  Bi ng r u Y a ng  an d Z h a n g y an X u  Index-BitTableFi: An improved algorithm for mining frequent itemsets,î Knowledge-Based Systems, Volume 21, Issue 6, Aug. 2008, pp. 507-513 4 J  H a n J  P e i a n d Y  Y i n   M i n i n g F r e que nt P a tte r n s w i tho u t C a n d i d ate  Generation,î Proceedings of the 2000 ACM SIGMOD International Conference on Management of Data, 2000, pp. 1-12  Son g and S. R a j a s e ka ran   A  T r a n s a ct i on Ma ppi n g A l gori t h m  for  Frequent Itemsets Mining,î IEEE Transaction on Knowledge and Data Engineering, Vol. 18, No. 4, 2006, pp. 472-481 6 z ung P e i H o ng Y i Y i n g W u  S h y u e L i ang W a ng  A n e f f e ctiv e m i n i ng  approach for up-to-date patternsî, Expert systems with applications, 36 2009, pp. 9747 9752  J  M. A l e a nd G  H. R o s s i A n a p p r oa ch t o di s c overi n g t e m p or a l  association rulesî, Proceedings of the 2000 ACM Symposium on Applied computing - Volume 1, pp. 294 - 300 8  L e e  C. R. L i n and M S  Che n   O n m i ni ng g e ne r a l te m p o r al  association rules in a publication database,î Proceedings of the 2001 IEEE International Conference on Data Mining, pp. 337-344 9 r a y S  M  Ts ai  Min in g frequ en t it em s e t s in  d a t a s t rea m s u s i n g th e weighted sliding window model,î Expert Systems with Applications Volume 36, Issue 9, November 2009, pp. 11617-1162 10 Y i ng j i u L i P e ng N i ng X  S e a n W a ng an d S u s h il J a jo di a D is co v e r i ng  calendar-based temporal association rules,î Data and Knowledge Engineering, Volume 44, Issue 2, Feb. 2003, pp. 193-218 11 K  V e r m a, O  P  V y as, an d R. V y as  T e m p o r al appr o a c h to asso cia ti o n  rule mining using T-tree and P-treeî , Lecture Notes in Computer Science, 3587, 2005, 651 659 2010 5th IEEE Conference on Industrial Electronics and Applicationsis 2253 


Figure 3 Precision-recall curve in ROI-250 image dataset 5.3 Experiment 3 Mammograms-1080 image dataset This experiment employed a dataset composed by 1080 mammograms images collected in the Clinical Hospital of University of Sao Paulo at Ribeiro Preto The dataset was previously classi\002ed into 4 levels of breast tissue density 0501\051 mostly fatty 050362 images\051 0502\051 partly fatty 050446 images\051 0503\051 partly dense 050200 images\051 and 0504\051 mostly dense 05072 images\051 Figure 4 Precision-recall curve in Mammography-1080 image dataset Breast density is an important risk factor in the development of breast cancer In this experiment the images are represented by the feature set proposed in b uilding a vector of 85 features including shape and size of the breast the conditions of the breast contour nipple position and the distribution of 002broglandular tissue This dataset was divided in training set and test set The training set is composed of 720 images and test set is composed of 360 images Figure 4 shows the P&R curves over test dataset and also the number of features selected in each method Again the proposed methods reached the highest values of precision and select the smallest number of features 050a\051 050b\051 050c\051 050d\051 Figure 5 Queries in Mammography dataset 050a\051 226 is the query image 050b\051 using the features selected through 002tness function F cB  050c\051 using the features selected through classi\002cation error of C4.5 and 050d\051 using the all features extracted Results for the retrieval of the 5 most similar images from a query image are also provided in this experiment as illustrated in Figure 5 The image 5.\050a\051 is the query image taken from the mostly fatty image class Images shown in 5.\050b\051 are the 5 most similar images retrieved for the proposed 002tness function F cB  The row 050c\051 shows the results for C 4  5 classi\002er whereas 050d\051 illustrate the images resulting from all features 050no selection applied\051 In Figure 5 the images surrounded by dashed lines are false positives 050not relevant images\051 For this query the proposed method achieved the highest precision 050100%\051 when compared the results of C4.5 and the original feature vector 050precision of 40%\051 


6 Conclusions This work proposed a novel genetic feature selection framework for CBIRs It employs a wrapper strategy that searches for the best reduced feature set while optimizing 050or preserving\051 the quality of the solution From a ranking evaluation function three new 002tness functions namely F cA  F cB and F c have been proposed and evaluated in three experiments The proposed genetic feature selection approach which encompasses F cA  F cB and F c  has been compared with 050a\051 traditional methods found in the literature 050b\051 the StARMiner feature selector and 050c\051 the whole feature vector and signi\002cantly outperformed them The proposed approach has been able to optimize the accuracy of similarity queries while selecting a signi\002catively reduced number of features Additionally the proposal of combining the quality of the query results with the criterion of minimizing the number of selected features F cA and F cB  led to high accurate query answers while reducing the number of features more than the 002tness function F c  Therefore the 002nal processing cost of the queries is also reduced References  P  M d Aze v edo-Marques N A Rosa A J M T raina C Traina-Jr S K Kinoshita and R M Rangayyan Reducing the semantic gap in content-based image retrieval in mammography with relevance feedback and inclusion of expert knowledge International Journal of Computer Assisted Radiology and Surgery  3\0501-2\051:123\226130 June 2008  R Baeza-Y ates and B Ribeiro-Neto Modern Information Retrieval  Addison-Wesley Essex UK 1999  B Bartell G Cottrell and R Bele w  Optimizing similar ity using multi-query relevance Journal of the American Society for Information Science  49:742\226761 1998  O Cord 264 on E Herrera-Viedma C L 264 opez-Puljalte M Luque and C Zarco A review on the application of evolutionary computation to information retrieval International Journal of Approximate Reasoning  34:241\226264 July 2003  J G Dy  C E Brodle y  A Kak L S Broderick and A M Aisen Unsupervised feature selection applied to content-based retrieval of lung images IEEE Transactions on Pattern Analysis and Machine Intelligence  25\0503\051:373\226 378 March 2003  W  F an E A F ox P  P athak and H W u The ef fects of 002tness functions on genetic programming-based ranking discovery for web search Journal of the American Society for Information Science and Technology  55\0507\051:628\226636 2004  W  F an P  P athak and M Zhou Genet ic-based approaches in ranking function discovery and optimization in information retrieval a framework Decision Support Systems  2009  D E Golber g Genetic algorithms in search optimization and machine learning  Addison Wesley 1989  R L Haupt and S E Haupt Practical Genetic Algorithms  John Wiley  Sons New Jersey United States second edition edition 2004  J Horng and C Y eh Applying genetic algorit hms to query optimization in document retrieval Information Processing  Management  36:737\226759 2000  S K Kinoshita P  M d Aze v edo-Ma rques R R PereiraJr J A H Rodrigues and R M Rangayyan Contentbased retrieval of mammograms using visual features related to breast density patterns Journal of Digital Imaging  20\0502\051:172\226190 June 2007  F  K orn B P agel and C F aloutsos On the  dimensionality curse and the self-similarity blessing IEEE Trans on Knowledge and Data Engineering  13\0501\051:96\226111 2001  H Liu and L Y u T o w ard inte grating feature select ion algorithms for classi\002cation and clustering IEEE Transactions on Knowledge and Data Enginnering  17\0504\051:491\226502 April 2005  M X Ribeiro A J M T raina C T raina-Jr  and P  M Azevedo-Marques An association rule-based method to support medical image diagnosis with ef\002ciency IEEE Transactions on Multimedia  10\0502\051:277\226285 2008  U S Cancer Statistics W orking Group United states cancer statistics 1999-2005 incidence and mortality webbased report atlanta 050ga\051 Department of health and human services centers for disease control and prevention and national cancer institute 2009 Available in http://apps.nccd.cdc.gov/uscs   L T amine C C and M Boughanem Multiple query evaluation based on an enhanced geneticnext term algorithm Information Processing  Management  39\0502\051:215\226 231 2003  R S T orres A X  F alc 230 ao M A Gonc\270alves J P Papa Z B W Fan and E A Fox A genetic programming framework for content-based image retrieval Journal of the American Society for Information Science and Technology  42\0502\051:283\226292 2009  A Tsymbal P  Cunningham M P echenizkiy  and S Puuronen Search strategies for ensemble feature selection in medical diagnostics In Proceedings of the 16th IEEE Symposium on Computer-Based Medical Systems  pages 124\226 129 June 2003  A Tsymbal M Pechenizkiy  and P  Cunningham Sequential genetic search for ensemble feature selection In Proceedings of the International Joint Conferences on Arti\002cial Intelligence  pages 877\226882 August 2005  C.-M W ang a and Y F  Huang Ev olutionary-based feature selection approaches with new criteria for data mining A case study of credit approval data Expert Systems with Applications  36\0503 Part 2\051:5900\2265908 2009  H Y an J Zheng Y  Jiang C Peng and S Xiao Selecting critical clinical features for heart diseases diagnosis with a real-coded genetic algorithm Applied Soft Computing  8:1105\2261111 2008  T  Zhao J Lu Y  Zhang and Q Xiao Feature selection based on genetic algorithm for cbir In IEEE Congress on Image and Signal Processing  volume 2 pages 495\226499 2008 


     Figure 9. Argumentation Tree For Open GL  A1 The current system in flash does not have the functionality of dynamic allocation of particles like mine or clutter. It places them randomly  A1.1 That is not of much importance because it still gives a new position to mine and clutter particles A2 Current system in flash has faster response time as compared to system in Adobe Director A3 The current system doesnêt satisfy many of the features required for the new system like database A4 Adobe Flash cannot communicate with database A4.1 Flash doesnêt support database but database support is very important and critical A4.1.1 The system should be able to generate evaluation reports for trainee based on pr evious records stored in the database A5 Flash doesnêt create sound clips  A5.1 We donêt need sound creating features as the sys tem has to generate sound. We can play externally recorded sound files using Adobe Flash A6 Flash can provide good visual effects as compared to Adobe Director A7 The developer has good knowledge in development using Flash so the system can be developed quickly B1 We could reuse the system already developed for sound generation, as it is developed using Adobe Audition for analysis which is somehow related to Adobe Director B1.1 The current system is better synthesized in terms of sound production and the sound produced is also instantaneous rather than discrete B1.2 That current system has certain performance issues like slow response time B1.3 The current system in Adobe Director has the feature of producing dynamic coloring scheme on approaching a mine. This kind of scheme is highly preferable and is not present in Adobe Flash system B2 Adobe Director can provide more functionality as compared to the current flash system. E.g. Multiple sounds while detecting mines   B2.1 Adobe Director can provide better visual effects as compared to flash e.g. in case of GUIês   B2.2 A modified version of the current system in flash can also provide the same functionality B2.2.1 We cannot integrate code developed in other platforms with Flash, but Flash can be integrated in Adobe Director B3 The interface provided by flash is not professional enough. It is too simple and straight forward for doing more things in future   B4 Easily available plug-ins can help integrate the tracking system developed in C# with Adobe Director  B4.1 Code developed in Open GL/AL can also be integrated using Adobe Director using suitable stubs   B5 A new sound recognition algorithm is being developed in Adobe Audition which can be integrated with Adobe Director but not with Open GL or Flash Evidence supported B6 If the current system is reused; the project deadline can be met easily B7 The developer has very little experience in development using Adobe Director   B7.1 The developer can take help from the already developed system in Adobe Director C1 The tracking software already developed is coded in C#/NX5. We could reuse that and develop our system in Open GL/AL C1.1 Open GL has C# libraries which can be used to develop the system C2 Because the platform used is for high end application development, it can provide good GUI and database support C2.1 Open GL/AL can help us generate dynamic surfaces for mine detection and training which the original system in flash does not have C4 Open GL does not support connectivity with Adobe Audition. Adobe Audition is required for creating sound recognition algorithm C3 Open GL does not support connectivity with Adobe Audition. Adobe Audition is required for creating sound recognition algorithm C4 The time taken for developing the project using open GL will be comparatively more as the whole system would have to be developed from scratch C4.1 If Open GL has support for C# libraries, and then the system could be develope d faster as developer is quite familiar with programming languages like C 151 


   C4.2 Open GL has excellent documentation that could help the developer learn the platform with ease C4.3 Developer has very little ex perience in working with Open GL platform  For our case study, alternative B i.e. Adobe Director was the most favorable alternative amongst all the three. It catered to the reusability criteria quite well and aimed at meeting most of the desired operational requirements for the system   6. CONCLUSION & FUTURE WORK  The main contribution of this paper is to develop an approach for evaluating performance scores in MultiCriteria decision making using an intelligent computational argumentation network. The evaluation process requires us to identify performance scores in multi criteria decision making which are not obtained objectively and quantify the same by providing a strong rationale. In this way, deeper analysis can be achieved in reducing the uncertainty problem involved in Multi Criteria decision paradigm. As a part of our future work we plan on conducting a large scale empirical analysis of the argumentation system to validate its effectiveness   REFERENCES  1  L  P Am g o u d  U sin g  A r g u men ts f o r mak i n g an d  ex p lain in g  decisions Artificial Intelligence 173 413-436, \(2009 2 A  Boch m a n   C ollectiv e A r g u men tatio n    Proceedings of the Workshop on Non-Monotonic Reasoning 2002 3 G  R Bu y u k o zk an  Ev alu a tio n o f sof tware d e v e lo p m en t  projects using a fuzzy multi-criteria decision approach Mathematics and Computers in Simualtion 77 464-475, \(2008 4 M T  Chen   F u zzy MCD M A p p r o ach t o Selec t Serv ice  Provider The IEEE International Conference on Fuzzy 2003 5 J. Con k li n  an d  M. Beg e m a n   gIBIS: A Hypertext Tool for Exploratory Policy Discussion Transactions on Office Information Systems 6\(4\: 303  331, \(1988 6 B P  Duarte D e v elo p in g a p r o jec ts ev alu a tio n sy ste m based on multiple attribute value theroy Computer Operations Research 33 1488-1504, \(2006 7 E G  Fo rm an  T h e  A n a l y t ic Hier a rch y P r o cess A n  Exposition OR CHRONICLE 1999 8 M. L ease  an d J L  L i v e l y  Using an Issue Based Hypertext System to Capture Software LifeCycle Process Hypermedia  2\(1\, pp. 34  45, \(1990 9  P e id e L i u   E valu a tio n Mo d e l o f Custo m e r Satis f a c tio n o f  B2CE Commerce Based on Combin ation of Linguistic Variables and Fuzzy Triangular Numbers Eight ACIS International Conference on Software Engin eering, Artificial Intelligence Networking and Parallel Distributed Computing, \(pp 450-454 2007  10  X  F L i u   M an ag e m en t o f an In tellig e n t A r g u m e n tatio n  Network for a Web-Based Collaborative Engineering Design Environment Proceedings of the 2007 IEEE International Symposium on Collaborative Technologies and Systems,\(CTS 2007\, Orlando, Florida May 21-25, 2007 11 X. F L i u   A n In ternet Ba se d In tellig e n t A r g u m e n tatio n  System for Collaborative Engineering Design Proceedings of the 2006 IEEE International Symposium on Collaborative Technologies and Systems pp. 318-325\. Las Vegas, Nevada 2006 12 T  M A sub jec tiv e assess m e n t o f altern ativ e m ission  architectures for the human exploration of Mars at NASA using multicriteria decision making Computer and Operations Research 1147-1164, \(June 2004 13 A  N Mo n ireh  F u zzy De cisio n Ma k i n g b a se d o n  Relationship Analysis between Criteria Annual Meeting of the North American Fuzzy Information Processing Society 2005 14 N  P a p a d ias HERMES Su p p o rti n g A r g u m e n tative  Discourse in Multi Agent Decision Making Proceedings of the 15th National Conference on Artifical Intelligence \(AAAI-98  pp. 827-832\dison, WI: AAAI/MIT Press,  \(1998a 15  E. B T riantaph y llo u   T h e Im p act o f  Ag g r e g atin g Ben e f i t  and Cost Criteria in Four MCDA Methods IEEE Transactions on Engineering Management, Vol 52, No 2 May 2005 16 S  H T s a u r T h e Ev alu a tio n o f airlin e se rv ice q u a lity b y  fuzzy MCDM Tourism Management 107-115, \(2002 1 T  D W a n g  Develo p in g a f u zz y  T O P S IS app r o ach  b a sed  on subjective weights and objective weights Expert Systems with Applications 8980-8985, \(2009 18 L  A  Zadeh  F u z z y Sets   Information and Control 8  338-353, \(1965  152 


                        





