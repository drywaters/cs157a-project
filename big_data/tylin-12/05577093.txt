A Comparison of Analysis Methods of Pipe Failure Characteristics Based on Maintenance Records of Water Distribution System  Wang Yi, Tian Yimei School of Environmental Science and Technology Tianjin University Tianjin, China vanderebio@gmail.com ymtian_2000@yahoo.com.cn   Abstract 227The characteristic data applied for establishing predicting models of pipe failure in water distribution system WDS\ould be examined and screened in the first place. The effects of different way of data processing based on a series on maintenance records are compared, which includes a classification method by Bayesian theorem, a hypothesis testing 
by analysis of variance and an association rule of data mining The result shows the Bayesian theorem is applicable for nonparametric analysis, and can give classification limits intuitively. But this method may neglect the relations between different variates and effects. It\222s proper to adopt this method when there are few pipe characteristics available. The analysis of variance \(ANOVA\ble to point out the interaction of variates and deal with both parametric and nonparametric tests. The association rule can provide correlations between different attributes, but may also bring excessive and nonsense results and it appears that more detailed records are required to make use of 
this method. It is suggested that the data should be carefully examined in appropriate method before applied to a model Keywords- Pipe failure; Water Distribution System; Bayesian theorem; ANOVA; Association Rules I   I NTRODUCTION  The water distribution system has played an important role in maintaining the urban functionalities. To keep this system operated in good conditions, it needs better strategies, which can save funds and enhance the efficiency. While establishing prediction or regression models for giving strategies based on the maintenance records, the model should select variates such 
as those pipe attributes or environmental characteristics which may lead to the failure, and discard those don't make sense. If there are still too many variates, it's necessary to pick out those variates with great importance either according to their screening abilities or the availabilities. Kurkarni[1  r e la te d  t h e probability of pipe failure to the system wide failure rate, the rate that specific characteristics observed on failed pipes and that of not failed pipes, and carried out a model based on the Bayesian theorem. Shridhar Yamijala[2 a d o p te d p r in c i p l e  component analysis to reduce the soil corrosivity covariates to transformed orthogonal covariates, and analyzed the Parameter 
significance results by Poisson generalized linear  model. Raed Jafar[3 l ie d a pr el i m i n a r y s t ud y o f t h e co rre l a ti o n a n d chi square test to analyze the influence of the input indicators and divided them into 3levels. May p r op os e d  an al g o ri t h m t o  develop artificial neural network models to forecast water quality in order to reduce the need for arbitrary judgment and extensive trial-and-error during model development. The algorithm selects inputs based on the analysis of relationship strength between inputs and outputs, and between redundant inputs. Vladan Babovic[5 ap pli e d a d a ta m i n i n g app r oach t o  the modeling of water supply assets by analyzing the database 
of already occurred bursts events in order to establish a risk model as a function of associated characteristics of bursting pipe \(its age, diameter, material of which it is built, etc.\, soil type in which a pipe is laid, climatological factors \(such as temperature\, traffic loading, etc. Since the analysis of the characteristics \(inputs, parameters\ includes many different methods, it\222s necessary to decide which one is not only able to make full use of the data collected and also can avoid redundant computing This paper compares 3 different methods of selecting model variates including the Bayesian theorem, ANOVA and the association rules, and describes the appropriate situations on to 
apply these methods. The first to method are applied to the same case to compare and verify their classification abilities and the association rule is applied to another case to test the suitable conditions for it. This is because the first case mainly consists of continuous variates and the association rule is more suitable for the discrete variates II  T HE S MALL S AMPLE CONCEPT   In classical survival analysis, once the sample failed or died, it would be immediately removed from the research population. But in the maintenance of WDS, the failed pipes 
especially those long pipes in large diameter, are repaired and reused, that would induce a trouble on how to define the population of the repaired pipes \(samples\ Cooper [7  developed a probability-based trunk mains burst risk model with GIS, which divided the long pipes and surroundings into small pieces and tested them of all the characteristics. This This work is supported by: National Natural Science Foundation of China 50778121\tional Key Technology R&D Program \(2006BAJ03A10 2006BAJ16B02-01 978-1-4244-5326-9/10/$26.00 \2512010 IEEE 


paper introduces a concept of the WDS samples similar to this method. A whole pipe, which used to be treated as one sample is divided into small samples \(e.g. 1m each sample\and calculated respectively. It should be emphasized that the samples canít be too small, which would bring a large population and result in the disappearance of the statistical significance of the failed samples According to the maintenance records, the repaired or replaced pipe segments are generally no longer than 1m, for the failures are usually pitting or circular break, caused by corrosion or bending forces, even the longitudinal splits are seldom longer than several meters.  However, after applied 1m samples by the survival analysis, it appears that the samples are so small that the population is too large to show the statistical significance of the failed samples In this paper, the small pipe sample is set to 10m, and those pipes shorter than 10m are treated as one sample III  T HE CLASSIFICATION OF THE CHARACTERISTICS  Although the selection of characteristics has great influence on the applicability of the model, the classification may also play an important role in the precision of the model. For example, the extremely low flow rate in water pipe may cause the tuberculation corrosion to the pipe wall, but the difference of the impacts of the flow rate of 0.01m/s and 0.02m/s shouldnít be significant. Considering such kind of situation, it is essential to classify the characteristic to different grades, like low and high, or medium if needed According to the Bayesian theorem, the probability of failure at the presence of specific characteristics c s    f nf c f f c f f c c f P P P P P P P    1    1 Where the P f is the system-wide probability of failure, the P c/f  is the probability of observing specified characteristics on a sample that failed and the P c/nf is the probability of observing specified characteristics on a sample that has not failed.  Then the Enhancement of the Failure Rate \(EFR\at the presence of a specific characteristic c can be calculated as   100 1     f c f c P P EFR  2 Fig. 1 describes the application of this method based on the flow rate characteristic of specific maintenance records. It shows that the EFR v has kept a higher level in the region of low flow rate \(the first negative value should be due to the small sample size at that flow rate\, and it declines significantly as the cumulated percentage of pipe samples growing according to the increase of the flow rate. It is concluded that the low flow rate, which is less than 0.05m/s, has an outstanding enhancing effect onto the pipe failure rate Further, the flow rate is classified to two classes and transformed to dummy variate    s m v s m v v  05  0 0  05  0 1  In this case, the traffic load is also classified to two classes    5 0 0 5 0 1 n n n   FIGURE I  Enhance of Failure Rate According to the Flow Rate IV  A NALYSIS OF VARIANCE  A 2-variates factorial ANOVA \(F-test\ is used to analyze if there are significant difference of pipe failure rate between the samples which have different level of characteristics, flow rate and traffic load. The samples are assumed to be independent to each other and there is no interaction between two variates. It is also assumed that the errors are normally distributed and the random variates have the same finite variances In this case, the null hypothesis to be tested is that all levels of the flow rate and traffic load have the same effect on the pipe failure rate \(R\ expressed as: H 0v R v1 R v2 H 0n R n1 R n2  The alternative hypothesis is H 1v R v1 R v2 H 1n R n1 R n2 The test is carried out on R, an open-source statistic software package, and the result is listed in Tab. 1 TABLE I  R ESULTS OF ANOVA  df Sum Sq Mean Sq F value Pr\(>F v 1 0.192 0.192 5.8464 0.01577 n 1 0.010 0.010 0.3187 0.57252 Residuals 1114 36.505 0.033   Total 1116 36.707    The result shows that the null hypothesis H 0v is falsified and the H 0n is approved under the significant level of 0.05 The normality is then examined by ShapiroñWilk test and the homoscedasticity is examined by Bartlett test. It shows that in this case, the data are neither normal nor homoscedastic, so the  


KruskalñWallis test, a nonparametric alternative which does not rely on an assumption of normality, is adopted to examine the hypothesizes. The results, listed in Tab. 2, shows that the null hypothesis H 0v is falsified and the H 0n is approved again TABLE II  R ESULTS OF K RUSKAL W ALLIS TEST  Data Kruskal-Wallis chi-squared df p-value v 5.8247 1 0.01580 n 0.3582 1 0.5495  According to the tests, the influence of different flow rate levels are significant, which indicates that the extremely low flow rate may enhance the failure rate, but that influence of traffic load is not supported. The test of ANOVA shows that the classification methods may have ignored some other interactions that worked in this case. In contrast, the ANOVA may take the interactions into account which assumed to between the flow rate and the traffic load in this case. However it is inappropriate to test the interaction by the F-test since the data in this case is neither normal nor homoscedastic V  A SSOCIATION RULE  Association rule mining finds interesting associations and/or correlated relationships among large set of data items Association rules show attributeís value conditions that occur frequently together in a given dataset. In this case, there are 7 attributes \(pipe diameters, pipe materials, pavement materials types of subgrade soil, traffic load levels, causes of pipe breakage and types of pipe failure\ which contain 33items value of pipe characteristics\ and 45transactions \(records\. The analysis result shows that among the 480 rules, there are 120rules of which the support is over 0.2 and the confidence is more than 0.9 Most rules are either nonsense or just reflecting objective facts, like the grass are paved on original soil or the traffic loads are low on the grass. Tab. 3 lists a few rules that make sense. It demonstrates that the high traffic load caused pipe failures are probably circular break, which has a support at 0.22 and confidence at 0.91. Also the failures of DN200 pipes which buried in grass are usually due to construction damages TABLE III  S AMPLES OF ASSOCIATION RULE RESULT  LHS RHS Sup. Conf. Lift High traffic load Circular break 0.22 0.91 1.86 Other failure causes Circular break 0.42 0.95 1.94 DN200,grass Construction damages 0.20 0.90 2.38  Itís hard to select the meaningful rules in such a large group due to the lack of criterion and engineering experience and the repeat of similar rules. Another problem is that usually the maintenance records are too general to distinguish different pipe failure. Such as, the failure causes are briefly divided in to soil subsidence, temperature changes, construction damages and other courses without mentioning the transient pressure the corrosion or bad installation. So the application of this method needs a more detailed maintenance records which defines as much conditions as possible VI  C ONCLUSION  Based on the analysis above, it may conclude as: 1\The Bayesian theorem is applicable for nonparametric analysis, and can give intuitive classification limits to the continuous variates But this method may neglect the interactions between different variates and effects. Itís proper to adopt this method when there are few pipe characteristics available. This method may also concern the combination of multi characteristics, but that would lead to large amount of computing tasks. 2\The ANOVA is able to point out the interactions of variates and deal with both parametric test \(F-test\ and nonparametric test KruskalñWallis test\, but the test of interaction needs the normality and homoscedasticity of the maintenance records. 3 The association rules can provide correlations between different attributes, but most results are either nonsense or reflecting the objective facts, and more detailed records are needed to reach more practical conclusions R EFERENCES  1  Kulkarni, R.B., Golabi, K., and Chuang, J. \(1986\ ìAnalytical techniques for selection of repair-or-replace options for cast iron gas piping systems-Phase I.î as Research Institute, PB87-114112, Chicago IL. USA 2  Shridhar Yamijala, Seth D. Guikema, Kelly Brumbelow, ìStatistical models for the analysis of water distribution system pipe break data Reliability Engineering & System Safety, Vol.94\(2\, February 2009, p 282-293 3  Raed Jafar, Isam Shahrour, Ilan Juran, ìApplication of Artificial Neural Networks \(ANN\ to model the failure of urban water mains Mathematical and Computer Modelling, Vol. 51\(9-10\, May 2010, p 1170-1180 4  Robert J. May, Graeme C. Dandy, Holger R. Maier, John B. Nixon Application of partial mutual information variable selection to ANN forecasting of water quality in water distribution systemsî,Environmental Modelling & Software, Vol. 23, \(10-11 October-November 2008, Pages 1289-1299 5  Vladan Babovic, Jean-Philippe DrÈcourt, Maarten Keijzer, Peter Friss Hansen, ìA data mining approach to modelling of water supply assets Urban Water, Vol.4\(4\, December 2002, Pages 401-414 6  Wang Y, Tian YM and Pei L, ìPrediction of Pipe Failure in Water Distribution Systemî, Journal of Tianjin University, in press 7  N. R. Cooper G. Blakey The use of GIS to develop a probabilitybased trunk mains burst risk model Urban Water 2 2000 97~103  


given by the speci\002city of the fuzzy rule-based classi\002er That is the ratio of true negatives divided by the sum of true and false negatives We 002nally obtained a minimal set of certain rules that in average only use 25 of all possible attributes as fuzzy clauses Whereas the speci\002city of the crisp classi\002er is nearly perfect the one of the fuzzy classi\002er is signi\002cantly lower as expected The discretization of all attributes however increases the readability of the rules Further improvements can be made using e g multiobjective optimization We plan to incorporate temporal dependencies of the data points into the VC-DRSA We expect temporal rules of a more general form to further exploit the problem description The integration of time series data mining techniques e g motif discovery might additionally boost the performance IV F INANCIAL A PPLICATIONS The ongoing 002nancial crisis has revealed how sensitive and almost unpredictable a system the 002nancial market is Subtle changes in customer behavior or credit loss rates may be indicators that lead to premonitions upon which one may react in order to narrow down monetary failures or losses An international capital company raised a project in which we were to reassess credit contracts from a past trading year For every credit contract that was still to be repayed the company used an in-house business intelligence system in connection with human experts to infer the likelihood of the contract to default While this predictive system is highly con\002dential we were asked to assess the temporal development of consecutive creditworthiness assessments Technically speaking we employed a decision tree induction algorithm to arrive at an intuitive starting position Since every path of a decision tree can be considered an association rule we ended up with a rule set for visualization Since the target variable of the decision tree was chosen to be the boolean failure indicator variable we arrived at association rules with consequents referring to exactly that variable of interest Figure 4 shows one of the results For the sake of brevity we only show the 002rst and last time step which are one 002scal year apart The con\002dence was encoded as a pie chart instead of a shaded interior as this was considered more intuitive by the customer The two arrows in Figure 4 point out three rules that showed a rather rapid increase in both lift and con\002dence and the respective antecedent attributes were found worth a further investigation e g to use them as predictive features in a future assessment V O NLINE C OMMUNITY A NALYSIS This application stems from a cooperation with a company creating content for the 3D online community SecondLife 1 In order to evaluate whether online content such as buildings mimicking online stores or museums function as intended a set of virtual sensors is deployed in that environment 1 http://www.secondlife.com Fig 4 Rules re garding credit failure rate at the beginning and the end of one 002scal year The two arrows mark three rules that showed a strong lift and con\002dence increase The respective contracts underwent a deeper investigation Whenever a user passes by such a sensor within a prespeci\002ed vicinity a visit event is logged We analyzed such a log 002le for 100 sensors that had been logged for six months The dataset was then discretized month-wise A common representation of such a log\002le is a so-called cooccurrence graph The nodes comprise the sensors whereas the edges represent that the sensors connected by that edge have been visited by some set of common users within a certain timespan Edge weights are used to denote the cardinality of such sets The cooccurrence graph of the dataset discussed so far is depicted in Figure 5 Even though we have proposed methods to deal with temporal changes within series of cooccurrence graphs 15 we can extract more information when we induce rules from these graphs and apply our visualization This is advantageous because of the following reasons A rule of the form 223If sensor X was visited sensor Y was also visited in p  of all cases\224 is more meaningful than just an edge with an associated weight which corresponds to the absolute support The above rule depicted with our visualization immediately tells how 6 


Fig 5 Cooccurrence graph representing six months of visiting events of 100 sensors deployed on certain islands in SecondLife many visitors compared to other rules are covered and how that number compares to the general visiting activity of a sensor Further a certain rule set will have a 002xed visual representation whereas the corresponding graph needs to be layouted which can create different impressions based on the layout algorithms However coordinates from any graph representation cannot carry the information of the rule icons Figure 6 shows the rules induced from the visiting events of the above-mentioned log 002le at three different time steps Rules have been induced that covered at least 1 of all visits and had a minimum con\002dence of 1 Note that this low con\002dence value is not unusual as we can expect a meaningful lift value since this is the ratio between con\002dence and consequent probability Note also that since a rule represents an edge the antecedent contains exactly one attribute Hence we have omitted the border of the rule icons We focus our 002ndings on two subsets of rules The subset marked by the ellipse in Figure 6 corresponds to a triangle in the original graph 2 All rules show a lift increase to the middle of the time period after which it decreased again Semantically this corresponds to an uprise and loss of predictability of the sensors in that subset a high lift tells that given a visit at one sensor we can conclude a more likely visit at the sensor described by the rule consequent Of course not necessarily by the same user An inquiry at the company con\002rmed that a certain modi\002cation had been undertaken at the 3D content in the vicinity of these sensors during the middle of the 2 As the graph is undirected it is possible that two rules are induced for a single edge if they match the speci\002ed criteria Hence a triangle might be represented by up to six different rules Fig 6 Rules induced from the cooccurrence graph in Figure 5 at three different time steps The two rule sets that are marked by the ellipse and rectangle were identi\002ed to correspond to modi\002ed artifacts inside the 3D world The rule set marked by the ellipse showed a collective lift increase towards the middle of the logging period and diminished after The rules marked by the rectangle exhibit a lift decrease and support increase log period The rules marked by the rectangle in Figure 6 correspond to a single edge that was heavily visited as can be seen from the rule icon size The lift is decreasing which is not surprising in the underlying 3D setting The two sensors were placed along a frequented pathway that more and more users were accepting to use If the general usage increases and thus the consequent probability the lift will decrease as we observe here 7 


VI C O NCLUSION Data collection is a process in time Hence it is almost always possible to attach to a database entry a time stamp We have shown that real-world applications can greatly bene\002t when the time dimension is taken into account This article has demonstrated how complex data analysis tasks can be greatly simpli\002ed by appropriate visualization and temporal change mining methods We therefore encourage to focus research onto the augmentation of other soft computing techniques in this respect R EFERENCES  Rak esh Agra w al T omasz Imielinski and Arun N Sw ami Mining Association Rules between Sets of Items in Large Databases In Peter Buneman and Sushil Jajodia editors Proc ACM SIGMOD Int Conf on Management of Data Washington D.C May 26-28 1993  pages 207\226216 ACM Press 1993  Jerzy B\007aszczy 264 nski Roman S\007owi 264 nski and Marcin Szel bag Sequential covering rule induction algorithm for variable consistency rough set approaches Submitted to Information Sciences in 2009  Christian Bor gelt Matthias Steinbrecher  and Rudolf Kruse Graphical Models 227 Representations for Learning Reasoning and Data Mining  John Wiley  Sons United Kingdom 2nd edition 2009  Salv atore Greco Benedetto Matarazzo Roman S\007o wi 264 nski and Jerzy Stefanowski Variable consistency model of Dominance-Based rough sets approach In Rough Sets and Current Trends in Computing  pages 170\226181 2001  Hisao Ishib uchi T omoharu Nakashima and T adahik o Murata Threeobjective genetics-based machine learning for linguistic rule extraction Information Sciences  136\(1-4 2001  Christian Moe wes Application of support v ector machines to discriminate vehicle crash events Master's thesis School of Computer Science University of Magdeburg Universit\344tsplatz 2 39106 Magdeburg Germany October 2007  Christian Moe wes and Rudolf Kruse Uni\002cation of fuzzy SVMs and rule extraction methods through imprecise domain knowledge In Jos\351 Luis Verdegay Luis Magdalena and Manuel Ojeda-Aciego editors Proceedings of the International Conference on Information Processing and Management of Uncertainty in Knowledge-Based Systems IPMU08  pages 1527\2261534 University of M\341laga June 2008  Christian Moe wes and Rudolf Kruse Zuordnen v on linguistischen Ausdr\374cken zu Motiven in Zeitreihen at-Automatisierungstechnik  57\(3 March 2009  Christian Moe wes Clemens Otte and Rudolf Kruse T ackling multipleinstance problems in safety-related domains by quasilinear SVM In Didier Dubois M Asunci\363n Lubiano Henri Prade Mar\355a 301ngeles Gil Przemyslaw Grzegorzewski and Olgierd Hryniewicz editors Soft Methods for Handling Variability and Imprecision  volume 48 of Advances in Soft Computing  pages 409\226416 Springer Berlin/Heidelberg October 2008  Christian Moe wes Clemens Otte and Rudolf Kruse Simple machine learning approaches to safety-related systems In Rajat Kumar De Deba Prasad Mandal and Ashish Ghosh editors Machine Interpretation of Patterns Image Analysis and Data Mining  volume 11 of Statistical Science and Interdisciplinary Research  chapter 12 pages 231\226249 World Scienti\002c Publishing Co Inc Hackensack NJ USA June 2010  Detlef Nauck and Rudolf Kruse A neuro-fuzzy method to learn fuzzy classi\002cation rules from data Fuzzy Sets and Systems  89\(3 1997  Judea Pearl Probabilistic Reasoning in Intelligent Systems Networks of Plausible Inference  Morgan Kaufmann San Mateo California 1988  Matthias Steinbrecher and Rudolf Kruse Identifying temporal trajectories of association rules with fuzzy descriptions In Proc Conf North American Fuzzy Information Processing Society NAFIPS 2008  pages 1\2266 New York USA May 2008  Matthias Steinbrecher and Rudolf Kruse Assessing the strength of structural changes in cooccurrence graphs In B\344rbel Mertsching Marcus Hund and Zaheer Aziz editors KI 2009 Advances in Arti\002cial Intelligence 32nd Annual German Conference on AI Paderborn Germany  volume 5803 of Lecture Notes in Computer Science Lecture Notes in Arti\002cial Intelligence  pages 476\226483 Springer Verlag 2009  Matthias Steinbrecher and Rudolf Kruse Fuzzy descriptions to identify temporal substructure changes of cooccurrence graphs In Proceedings of 2009 IFSA/EUSFLAT  pages 1177\2261182 July 2009  Matthias Steinbrecher and Rudolf Kruse V isualizing and fuzzy 002ltering for discovering temporal trajectories of association rules Journal of Computer and System Sciences  76\(1 February 2010  Jeen-Shing W ang and C.S.G Lee Self-adapti v e neuro-fuzzy inference systems for classi\002cation applications IEEE Transactions on Fuzzy Systems  10\(6 December 2002  Matthe w O W ard Handbook of Data Visualization  chapter Multivariate Data Glyphs Principles and Practice pages 179\226198 Springer Handbooks Comp Statistics Springer Berlin/Heidelberg 2008  Y  Y  Y ao and Ning Zhong An Analysis of Quantitati v e Measures Associated with Rules In Methodologies for Knowledge Discovery and Data Mining  Springer-Verlag Berlin 1999 8 


Capacity for analysis and synthesisé, çResearch skills Capacity to learn 4   Interpersonal skills Leadershipé, çInterpersonal skillsé, çAbility to communicate with non-expertsé, çOral and written communications in native languageé, çCritical and self-critical capabilityé, çTeamworking 5   Personal skills Ability to work autonomously Problem solvingé, çCapacity to adapt to new situations Knowledge of a second languageé, çConcern for qualityé, çWill to succeedé, çElementary computing skillsé, çCapacity for applying knowledge in practice Decision makingé, çProject design and management Information management skills Table 7 shows the mean importance of each gr oup of competences by stakeholder group for the First Cycle Degree respondents. For the employers the personal skills are the most importance group followed by professional skills and interpersonal skills. The table confirms that employers rank internationalisation and entrepreneurship lowest. Academics agree with the order of the competence groups but rate all of them more strongly important than employers. Students also rank the competence groups in the same order but rate internationalisation slightly higher than employers and entrepreneurship very slightly lower Analysis of the level of development of the competenceas shows that there is good agreement that Professional skills are the best developed of the skill groups followed by Personal skills and Interpersonal skills. As with importance the Entrepreneurship and Internationalisation skill groups are developed the least. There is clearly a difference between the rated importance and level of development of these groups in that the Personal skills group is rated most important but the Professional skills group is developed the most. Other than that the general structure of the supply demand balance of the generic competences is quite well aligned V  CONCLUSIONS AND RECOMMENDATIONS  The objective of this study was to apply the Tuning Methodology to the EIE discipline set to test the alignment between the views of the importance and level of development of sets of competences between students, academics and employers. The results of this study show that the Tuning Methodology is a useful tool for assessing alignment in these subjects  TABLE VII  MEAN IMPORTANCE OF EACH GROUP BY STAKEHOLDER  Competence Group Academic Employer Student Internationalization 2.86 2.63 2.79 Entrepreneurship 3.07 3.05 3.02 Interpersonal skills 3.23 3.09 3.06 Professional skills 3.36 3.29 3.13 Personal skills 3.44 3.30 3.29  In total 3,275 questionnaires have been collected from the stakeholder groups from a range of European countries. The number of responses from each c ountry is variable and a full by country analysis is not possible with the responses currently available, that said a range of analyses have been carried out Tests of the homogeneity of the responses across all countries show that there are country differences in some analyses and some of these are explored, others merit further investigation. Many of the analyses presented in this paper are aggregated results and therefore potentially suffer clustering problems. This too is a topic of further investigation The following is a summary of the key conclusions drawn from the analyses presented Consistent top of importance of the generic competences for all stakeholders is çProblem solvingé. Second in the ranking for students is çElementary computing skillsé. Comparatively students under rate the importance of this skill, perhaps it is taken for granted in students than in academics and employers The results show employers value it more than students and this message could be communicated to students A number of gaps exist between the importance and level of development between the stakeholders. The largest gap is Knowledge of a second languageé and the evidence from the languages section suggests this view is strongly aimed at English The generic competences group into 5 sets with çPersonal skillsé rated consistently as the most important set. This is followed, in descending order of importance, by çProfessional skillsé, çInterpersonal skillsé, çInternationalisationé and Entrepreneurshipé. The smallest mean çInternationalisation is just over midway between çweaké and çconsiderableé. Given the European Unionês desire to see greater student and employee mobility across Europe, it is clear there is scope for scope for improvement in the value placed in this skill set by curriculum designers Curriculum designers and academics can take comfort in the finding that çProfessional skillsé are the best developed of the skill gr oups followed by çPersonal sk illsé and Interpersonal skillsé. This not only aligns with the views of employers but aligns with anecdotal evidence on the real purpose of EIE education programmes. That said there is a trend in a number of countries across Europe away from large firm employment towards a Small to Medium Sized Enterprise culture. Curriculum designers may wish to reflect on the fact that entrepreneurial skills are very low in the list and perhaps merit more attention and emphasis in the curricula In general the different stakeholders rate the importance and level of development on average differently. This difference has been taken into account in the conclusions drawn. The general unevenness in ranking reflects different perspectives and is, in itself not considered a major issue, of concern are the relative positions of competences and the relative gaps. In general and even allowing for this employers and academics tend to rate competences higher in importance than students and graduates a number of specific instances of differences are drawn out in section 8 73 


After the text edit has been completed, the paper is ready for the template. Duplicate the template file by using the Save As command, and use the naming convention prescribed by your conference for the name of your paper. In this newly created file, highlight all of the contents and import your prepared text file. You are now ready to style your paper; use the scroll down window on the left of the MS Word Formatting toolbar A CKNOWLEDGMENT  The authors acknowledge the funding provided by the European Union for this project and to the members of the project team for help in collecting questionnaires R EFERENCES   1  European Association for Education in Electrical and Information Enginering http://www.eaeeie.org  2  EIE-Surveyor project http://www.eie-surveyor.org  3  Tuning Report http://tuning.unideusto.org/tuningeu/index.php?option=content&task=vi ew&id=172&Itemid=205  4  Overview of the Bologna Process Ö Implementation in Europe in Electrical and Informaiton Engineetringé, ISBN 2-9516740-3-1, pp 542  74 


              


   


                        





