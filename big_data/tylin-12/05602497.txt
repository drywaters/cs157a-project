SICE Annual Conference 2010 August 18-21, 2010, The Grand Hotel, Taipei, Taiwan   400 © 2010 SICE 1 Time Related Association Rules Mining with Attributes Accumulation Mechanism Applied to Large-scale Trafìc System Xiaoli Wang Shingo Mabu Huiyu Zhou Kotaro Hirasawa Graduate School of Information Production and System Waseda University 2-7 Hibikino Wakamatsu-ku Kitakyushu Fukuoka 808-0135 Japan Email:WangXiaoli@akane.waseda.jp mabu@aoni.waseda.jp zhy836@toki.waseda.jp hirasawa@waseda.jp Abstract 
In this paper a data mining method using Genetic Network Programming GNP will be introduced and its effectiveness and efìciency will be studied using an existing large-scale trafìc simulation system The results of simulation will also be described Keywords  GNP Data Mining Attribute Accumulation Trafìc Prediction Evolution Classiìcation I I NTRODUCTION With the deteriorating trafìc status in the expanding modern metropolis individual trafìc management systems sometimes known as car navigation systems are widely used to shorten 
the traveling time for drivers In a complicated and dynamic system the effectiveness of navigation depends heavily on how accurately the information is provided Therefore if the trafìc conditions like vehicle ows and congestions can be accurately predicted and described the effectiveness of navigation systems will be improved Here a proposed method of association rule mining using Genetic Network Programming also known as GNP is applied to a large-scale road network to verify its performance GNP is a kind of algorithm which represents solutions with directed-graph structures which here is used to extract rules 
from the large database alongside with rule accumulation mechanism so that as many rules as possible can be extracted from the database with decent efìciency In this paper GNP is used in the dynamic case where the database concerns not only the data of one certain time point but a long time sequence or we can say that the database is time-related GNP is used to generate candidate rules from a large number time-related attributes Here we apply Genetical Network Programming for extracting association rules from trafìc systems and use them for the prediction of trafìcs of the road networks In order 
to achieve realistic results the algorithm is also applied to the simulator where the trafìc of Kitakyushu is used for simulations II A LGORITHM D ESCRIPTION The whole algorithm is divided into to two phase Data Mining and Prediction also called Classiìciation GNP is applied to the rst phase where a time-related GNP data mining is used to obtain rules which are exploited in the latter phase to make prediction The algorithm in the two phases will be introduced in details respectively A Data Mining Data the analytical approach to dra w useful 
information from large sets of data is widely used in various elds Generally data mining is used to nd relationships between several attributes Its goal is to extract information from data sets which can be used later for other applications In other words the knowledge obtained could be in many forms which would be the form of relationships of trafìc volumes among different roads and time in the trafìc prediction One of the greatest advantages of using data mining to obtain rules over other methods like analyzing the geometric and topological relationships of road networks is that data mining is a relatively efìcient method to obtain as many rules 
as possible Here Association Rule Mining is used to extract knowledge from the database whose major task is to nd the relationships among attributes or hidden correlations among attributes Relationships between data sets can be represented as association rules An association rule has the form of  X  Y  where X represents antecedent and Y represents consequent This means those data satisfying X is likely to satisfy Y with certain conìdence When data mining is applied to large scale trafìc systems 
the relationship is usually expressed in the form of rules like if Section A\(t=3 has High volume and Section B\(t=4 has High volume then Section C\(t=6 has High volume These rules are called Association Rules and can be used to make prediction When considering the evolutionary computation there are several existing methods like Genetic and Genetic In GA case a rule is represented as PR0001/10/0000-2637 2637 


2 the chromosome of an individual which makes it hard to have a complete picture of the real relationships in the problem In Genetic Programming the tree structure is used which improves the representation of rules but it thus suffer from the loose structure and bloating problem Genetic Network Programming GNP used in the proposed method is an extension of Genetic Algorithm In GNP individuals are expressed as directed graphs which have strong expressive power while keeping a compact program where all the resources can be reused without the bloating problem as the number of nodes is xed This is the reason why Genetic Network Programming is used for the optimization of large scale Also due to the nature of the problem time-related association rule mining is needed to improve the efìciency and effectiveness of the method B Genetic Network Programming Fig.1 shows the basic structure of GNP Principally GNP is composed of three kinds of nodes Start Node Judgment Nodes and Processing Nodes In the case of Judgment Nodes if-then logics are used to decide the ow of agents while Processing Nodes carry a set of actions Before the start-up all the nodes are pre-deìned and stored Fig 1 Basic Structure of GNP Individual In the Chrosome of a GNP node its ID type Start Node Processing Node Judgment Node connection and direction to other nodes are deìned as GNP uses the directed-graph to represent its individual Fig.2 is the structure of a single rule individual included in GNP For example if Section A\(t=0 has High volume and Section B\(t=3 has High volume then Section C\(t=4 has High volume The most important part of GNP data mining applied to trafìc system is that it concerns only those rules with single consequent part as is shown in the previous example as C\(t=4 is high When the algorithm has found enough rules for a certain consequent it moves to the next This has proven to be a most trust-worthy method but it remains relatively time-consuming In the proposed method the algorithm considers not only the Fig 2 Basic Structure of GNP Individual attributes but also the time delays as the database is not a transaction-based but a time-related database For all the rules extracted using data mining method Support Conìdence Chi-Square are used to decide whether the rule is accepted as a useful rule and stored in the pool IntheCaseof X  Y  support is deìned as the number of data satisfying X divided by the total number of data For example if in a database of 100 tuples the data that satisfy X is 20 then we can say that the support is 20/100  0.2 Support actually measures how widely the rule extracted can apply to the database or how frequently the situation described by X is seen in the data set Conìdence is the conditional probability of P\(Y   X For example if in the previously mentioned database those data who satisfy both X and Y is 15 it can be said that the conìdence is 15/20  0.75 Conìdence measures how effective the rule is that is how conìdently as you can deduce the conclusion if you have the clues Chi-square measures how independent X is from Y In other words all rules have to satisfy these three measures so as to be recognized as an important or effective rule C Rule Accumulation Mechanism In order to extract rules from the large database Rule Accumulation Mechanism is also needed which involves the Small Rule Pool and Big Rule Pool\(also known as SRP and BRP Every round new rules are obtained and their overlap is checked in SRP and SRP is also compared with BRP All the attributes that are used in the rules extracted are counted and the top v percent attributes are viewed as important attributes and have high likelihood to be used for the next time In other words when a good rule is extracted rstly it will be compared with the rules in the SRP If it is new then it will be stored in SRP and later the SRP will be compared with BRP Those never extracted in the past will be considered as a new one 2638 


3 D Prediction Prediction is the nal process of applying rules extracted to make the prediction of future trafìc ows which is evaluated by the accuracy of prediction Here accuracy is deìned by the number of correct predictions divided by all the records that can be predicted That is to say all the unpredictable records are ignored III L ARGE SCALE T RAFFIC S IMULATION A Solutions A new simulator is needed which can simulate the large scale trafìc system with the complicated trafìc control like trafìc lights control and if possible trafìc accidents Here a software named Sound4U is applied to our simulator Also the program to do the long prediction is also developed B Map Conìguration In the Sound4U software users can pick up the roads of different levels like national prefectural urban and so on trafìc control like trafìc lights control and the vehicle ows from the national map using a lter Also the vehicle types can be set up as different car groups impose different inîuences on the trafìc In the simulation the map of Kitakyushu in Fukuoka Prefecture is chosen as the basic trafìc network The road network in this paper especially focuses on the area near Kurosaki one of the central part of Kitakyushu city containing more than 3,500 roads already a complicated system In this paper only the national prefectural and urban roads are picked up considering the efìciency ThemapisshowninFig3 Fig 3 Map for Simulation Considering the fact that most of roads are two-way the map actually contain more than 7,000 sections Generally it takes 10 to 15 minutes for a car to move from one side of the map to the other side The whole simulation time is two hours where the trafìc volume will be recorded for every minute Also the scan time is 1 second by which the simulation is updated Generally speaking the shorter scan time will lead to higher simulation accuracy From observation of the real trafìc lights the time of switching different trafìc lights is set at 30 to 50 seconds according to the location Generally speaking the roads in the urban areas tend to have shorter interval between switching while in rural areas longer time interval is set C OD Setting Here a concept has to be explained OD or OriginDestination is used to deìne the trafìc ow As can be seen from the name OD means a trafìc ow that runs from Origin to Destination In the simulator OD is deìned trafìc control is set up and route selection algorithm is set for each vehicle group in the simulator and the simulator will do the rest The vehicles are generated from Origin/Destination OD points which are put around the boundaries of the whole map A trafìc ow should be generated from one OD point towards another This is called an origin/destination OD pair representing a trafìc ow 10 Destination points are set for every Origin point out of 20 points so there are 200 OD pairs in all When setting up the ODs three patterns are used One is Rush Hour pattern where two peaks of trafìc ows are set Another is Standard Distribution and the third is Total Randomized It is possible to set different groups of vehicles as they introduce different inîuences on the trafìc system but only one kind is used here for simplicity D Density Discretization Although what we want is the prediction of trafìc situations the rst step is to discretize the simulation results as the GNPbased data mining method is principally designed to deal with boolean values rather than continuous values Also the trafìc density rather than the trafìc volume should be used for measuring the trafìc situation due to the fact that the trafìc volume does not reîect how busy a street is especially considering the fact that many roads have different lane numbers and lengths Usually the longer the road is and the more lanes it has the more vehicles it can hold which means it is busier than some other roads Therefore after the simulation rst the trafìc density of each section is calculated where it it is divided into Low Middle and High situations by certain thresholds Actually the following trafìc density of every time unit here one minute can be obtained D  Num  L  C  where D is the density of the section 2639 


4 Num is the number of cars remaining in the section L is the length of the section C is the capacity of the section And here is how the trafìc density is discretized into High Middle and Low Fig 4 Discretization of Trafìc E Section Reduction Even for the large scale system 7,000 sections is a good number and a heavy burden on the trafìc prediction Thus one of the crucial steps is to pick up the most important sections called major sections As the proposed method classiìes the sections by Low Middle and High for every period we can give them certain scores which can be used for ranking the sections Only the top 500 sections are picked up using the ranking of sections As there are Low Middle and High for every section the number of attributes actually becomes 1,500 with time steps of 120\(two hours by 1 minute IV S IMULATION R ESULTS The Simulation Condition is set up as follows A map near Kurosaki 20 OD 200 OD pairs 3,500 roads 7,000 sections Number of judgment nodes 100 Number of processing nodes 10 Number of attributes 1500 Number of time units 120 Number of generations per Round 50 Sub Attribute Set Size for Attribute Accumulation 100 After obtaining the association rules for the trafìcs of the road networks a classiìcation method is used to make the prediction on the trafìcs and the results are analyzed The general ow of simulation is shown in Fig.5 There are two database involved of which one is called Training Database the other Testing Database The GNPbased algorithm extracts rules from the Training Database or the algorithm would learn from the Training Database Fig 5 General Flow of Simulation 50 rules are required for each class but sometimes it just turn out to be impossible to nd enough rules for certain attributes These rules would be used to make prediction later and prediction results would be compared with Testing Database to see how accurate the prediction is Here Accuracy is deìned by the number of correct prediction divided by all the records that can be predicted A Probabilistic Route Finding In the simulations vehicles generated from the Origin follow certain rules when nding its way to the Destination This is also named route-ìnding as vehicles decide which road to take among lots of choices With Probabilistic Route Finding vehicles decide which route to take considering the traveling time when they depart from Origin They will stick with their choice after leaving Origin The probability of choosing one road is shown as below P  i  exp  uV i    j  J exp  uV i   1 P  i  is the probability for vehicle to take the i th route Vi is the time consumption for taking the i th route In the simulations the route-selection is controlled by a parameter called Logit Parameter u  When u approaches inìnity the algorithm turns into greedy algorithm When u approaches zero the route for a car is totally randomly determined The X axis is the prediction time step while Y is the prediction accuracy in Fig.6 Generally the accuracy falls with the increase of prediction steps and the more probabilistic the less accurate In the probabilistic case the accuracy drops as the process become more random or as u becomes smaller V C ONCLUSIONS An decent accuracy of 80 percent using 7000 sections map has proved that the proposed algorithm can be applied to a large-scale realistic trafìc system with reliability There still exist some problems to be solved like a small number of usable rules when extending the prediction time 2640 


5 Fig 6 Prediction Accuracy under Different Parameters or the relatively low efìciency although the Attribute Accumulation and Section Reduction have been already exploited to improve it In the future should try to systematically analyze the performance of scenario under many different kinds of situations like very big trafìc volumes Other route-ìnding methods are also expected to be employed R EFERENCES  C Zhang and S Zhang Association Rule Mining models and algorithms Springer 2002  K Shimada K Hirasa w a and J Hu Genetic Netw ork Programming with Acquisition Mechanisms of Association Rules Journal of Advanced Computational Intelligence and Intelligent Informatics Vol 10 No.1 pp.102-111 2006  D E Goldber g Genetic Algorithm in search optimization and machine learning Addison Wesley 1989  J R K oza Genetic Programminjg on the programming of computers by means of natural selection Cambridge Mass MIT Press 1992  S Mab u K Hirasa w a and J.Hu A Graph-Based Ev olutionary Algorithm Genetic Network Programming GNP and Its Extension Using Reinforcement Learning Evolutionary Computation MIT press Vol 15 No 3 pp.369-398 2007 2641 


R EFERENCES 1  T h abt a h, F  20 0 7 A r e v i ew of  A s s o ciat iv e Cl assif i cat io n Mi ni ng   The Knowledge Engineering Review Vol .22.1, 37-65 2  G a y l e  S  2 0 0 0  D a ta  Mi ni ng  in  the I n s u r a nce I ndus tr y  S A S  I n s t it ute  Inc 3  K i e t z  J.ÖU Re im e r U  S t a u dt, U  1 9 9 7  M i n i ng I n sur an ce D a t a  at Swiss Life Proceedings of the 23rd International Conference on Very Large Data Bases \(VLDB Pp. 562-566 4 Vi veros  M  S  Nea rh os  J  P  R o thm a n  M J   19 96  A p p l y i n g Da ta Mining Techniques to a Health Insurance Information System In Proceedings of the 22 nd VLDB Conference Mumbai \(Bombay India 5  Che n  Y  H u  L  200 5 S t u d y o n D a t a M i ni ng A ppl ic at io n in C R M  System Based on Insurance Trade International Conference on Electronic Commerce China: August 6  Z h ang J  Cu i, Y    L i u, W  2 0 0 9  S upe r v is e d L e ar ning Bas e d D a t a  Mining Technology with Its Application to Life Insurance Datasets Analysis International Journal of Business and Management Vol 2\(1 7 St a udt   M   K i et z J  U  R e im er U 19 97 A D L E R   A n  Environment for Mining Insurance Data KRDB 1997 pp16.1-16.9  St a udt   M  K i et z J  U  R e i m er U 1 998  A Da t a Mi nin g Sup p o r t  Environment and its Application on Insurance Data In Proceedings of Knowledge Discovery in Databases \(KDDê98 Pp105-115 9 Ha n  J  K a m b er  M  200 1 D a ta  M i n i n g  C o n c ept an d T e c h ni qu es  San Francisco: Morgan Kaufmann Publishers  A g ra w a l R  Srik an t R 199 4 F a s t A l g o ri t h m s for M i n i n g A s s o c i at i o n Rules, Very Large Databases Int. Cont. Proceedings, 1994    B o rgelt  C  200 3 A p ri ori F i nd in g A s s o c i a t i on Ru les  H y p er ed ges  with the Apriori Algorithm http://www10.brinskter.com  stevenyip/apriori/doc/apriori.html  K o t s i a n t i s  R   K a n e llop ou s  D 2006  A s s o c i at i o n Ru les M i ni n g A  Recent Overview GESTS International Transactions on Computer Science and Engineering  13  A g r a w a l  R., I m iel ins k i, T  Sw am i A  199 3. D a ta bas e  Mi ni ng  A  Performance Perspective,   \(Learning and discovery in knowledgebased databases IEEE Transactions on Knowledge and Data Engineering 5\(6\ pp914Ö925 1486 2010 10th International Conference on Inte lligent Systems Design and Applications 


Figure 3 Precision-recall curve in ROI-250 image dataset 5.3 Experiment 3 Mammograms-1080 image dataset This experiment employed a dataset composed by 1080 mammograms images collected in the Clinical Hospital of University of Sao Paulo at Ribeiro Preto The dataset was previously classi\002ed into 4 levels of breast tissue density 0501\051 mostly fatty 050362 images\051 0502\051 partly fatty 050446 images\051 0503\051 partly dense 050200 images\051 and 0504\051 mostly dense 05072 images\051 Figure 4 Precision-recall curve in Mammography-1080 image dataset Breast density is an important risk factor in the development of breast cancer In this experiment the images are represented by the feature set proposed in b uilding a vector of 85 features including shape and size of the breast the conditions of the breast contour nipple position and the distribution of 002broglandular tissue This dataset was divided in training set and test set The training set is composed of 720 images and test set is composed of 360 images Figure 4 shows the P&R curves over test dataset and also the number of features selected in each method Again the proposed methods reached the highest values of precision and select the smallest number of features 050a\051 050b\051 050c\051 050d\051 Figure 5 Queries in Mammography dataset 050a\051 226 is the query image 050b\051 using the features selected through 002tness function F cB  050c\051 using the features selected through classi\002cation error of C4.5 and 050d\051 using the all features extracted Results for the retrieval of the 5 most similar images from a query image are also provided in this experiment as illustrated in Figure 5 The image 5.\050a\051 is the query image taken from the mostly fatty image class Images shown in 5.\050b\051 are the 5 most similar images retrieved for the proposed 002tness function F cB  The row 050c\051 shows the results for C 4  5 classi\002er whereas 050d\051 illustrate the images resulting from all features 050no selection applied\051 In Figure 5 the images surrounded by dashed lines are false positives 050not relevant images\051 For this query the proposed method achieved the highest precision 050100%\051 when compared the results of C4.5 and the original feature vector 050precision of 40%\051 


6 Conclusions This work proposed a novel genetic feature selection framework for CBIRs It employs a wrapper strategy that searches for the best reduced feature set while optimizing 050or preserving\051 the quality of the solution From a ranking evaluation function three new 002tness functions namely F cA  F cB and F c have been proposed and evaluated in three experiments The proposed genetic feature selection approach which encompasses F cA  F cB and F c  has been compared with 050a\051 traditional methods found in the literature 050b\051 the StARMiner feature selector and 050c\051 the whole feature vector and signi\002cantly outperformed them The proposed approach has been able to optimize the accuracy of similarity queries while selecting a signi\002catively reduced number of features Additionally the proposal of combining the quality of the query results with the criterion of minimizing the number of selected features F cA and F cB  led to high accurate query answers while reducing the number of features more than the 002tness function F c  Therefore the 002nal processing cost of the queries is also reduced References  P  M d Aze v edo-Marques N A Rosa A J M T raina C Traina-Jr S K Kinoshita and R M Rangayyan Reducing the semantic gap in content-based image retrieval in mammography with relevance feedback and inclusion of expert knowledge International Journal of Computer Assisted Radiology and Surgery  3\0501-2\051:123\226130 June 2008  R Baeza-Y ates and B Ribeiro-Neto Modern Information Retrieval  Addison-Wesley Essex UK 1999  B Bartell G Cottrell and R Bele w  Optimizing similar ity using multi-query relevance Journal of the American Society for Information Science  49:742\226761 1998  O Cord 264 on E Herrera-Viedma C L 264 opez-Puljalte M Luque and C Zarco A review on the application of evolutionary computation to information retrieval International Journal of Approximate Reasoning  34:241\226264 July 2003  J G Dy  C E Brodle y  A Kak L S Broderick and A M Aisen Unsupervised feature selection applied to content-based retrieval of lung images IEEE Transactions on Pattern Analysis and Machine Intelligence  25\0503\051:373\226 378 March 2003  W  F an E A F ox P  P athak and H W u The ef fects of 002tness functions on genetic programming-based ranking discovery for web search Journal of the American Society for Information Science and Technology  55\0507\051:628\226636 2004  W  F an P  P athak and M Zhou Genet ic-based approaches in ranking function discovery and optimization in information retrieval a framework Decision Support Systems  2009  D E Golber g Genetic algorithms in search optimization and machine learning  Addison Wesley 1989  R L Haupt and S E Haupt Practical Genetic Algorithms  John Wiley  Sons New Jersey United States second edition edition 2004  J Horng and C Y eh Applying genetic algorit hms to query optimization in document retrieval Information Processing  Management  36:737\226759 2000  S K Kinoshita P  M d Aze v edo-Ma rques R R PereiraJr J A H Rodrigues and R M Rangayyan Contentbased retrieval of mammograms using visual features related to breast density patterns Journal of Digital Imaging  20\0502\051:172\226190 June 2007  F  K orn B P agel and C F aloutsos On the  dimensionality curse and the self-similarity blessing IEEE Trans on Knowledge and Data Engineering  13\0501\051:96\226111 2001  H Liu and L Y u T o w ard inte grating feature select ion algorithms for classi\002cation and clustering IEEE Transactions on Knowledge and Data Enginnering  17\0504\051:491\226502 April 2005  M X Ribeiro A J M T raina C T raina-Jr  and P  M Azevedo-Marques An association rule-based method to support medical image diagnosis with ef\002ciency IEEE Transactions on Multimedia  10\0502\051:277\226285 2008  U S Cancer Statistics W orking Group United states cancer statistics 1999-2005 incidence and mortality webbased report atlanta 050ga\051 Department of health and human services centers for disease control and prevention and national cancer institute 2009 Available in http://apps.nccd.cdc.gov/uscs   L T amine C C and M Boughanem Multiple query evaluation based on an enhanced geneticnext term algorithm Information Processing  Management  39\0502\051:215\226 231 2003  R S T orres A X  F alc 230 ao M A Gonc\270alves J P Papa Z B W Fan and E A Fox A genetic programming framework for content-based image retrieval Journal of the American Society for Information Science and Technology  42\0502\051:283\226292 2009  A Tsymbal P  Cunningham M P echenizkiy  and S Puuronen Search strategies for ensemble feature selection in medical diagnostics In Proceedings of the 16th IEEE Symposium on Computer-Based Medical Systems  pages 124\226 129 June 2003  A Tsymbal M Pechenizkiy  and P  Cunningham Sequential genetic search for ensemble feature selection In Proceedings of the International Joint Conferences on Arti\002cial Intelligence  pages 877\226882 August 2005  C.-M W ang a and Y F  Huang Ev olutionary-based feature selection approaches with new criteria for data mining A case study of credit approval data Expert Systems with Applications  36\0503 Part 2\051:5900\2265908 2009  H Y an J Zheng Y  Jiang C Peng and S Xiao Selecting critical clinical features for heart diseases diagnosis with a real-coded genetic algorithm Applied Soft Computing  8:1105\2261111 2008  T  Zhao J Lu Y  Zhang and Q Xiao Feature selection based on genetic algorithm for cbir In IEEE Congress on Image and Signal Processing  volume 2 pages 495\226499 2008 


     Figure 9. Argumentation Tree For Open GL  A1 The current system in flash does not have the functionality of dynamic allocation of particles like mine or clutter. It places them randomly  A1.1 That is not of much importance because it still gives a new position to mine and clutter particles A2 Current system in flash has faster response time as compared to system in Adobe Director A3 The current system doesnêt satisfy many of the features required for the new system like database A4 Adobe Flash cannot communicate with database A4.1 Flash doesnêt support database but database support is very important and critical A4.1.1 The system should be able to generate evaluation reports for trainee based on pr evious records stored in the database A5 Flash doesnêt create sound clips  A5.1 We donêt need sound creating features as the sys tem has to generate sound. We can play externally recorded sound files using Adobe Flash A6 Flash can provide good visual effects as compared to Adobe Director A7 The developer has good knowledge in development using Flash so the system can be developed quickly B1 We could reuse the system already developed for sound generation, as it is developed using Adobe Audition for analysis which is somehow related to Adobe Director B1.1 The current system is better synthesized in terms of sound production and the sound produced is also instantaneous rather than discrete B1.2 That current system has certain performance issues like slow response time B1.3 The current system in Adobe Director has the feature of producing dynamic coloring scheme on approaching a mine. This kind of scheme is highly preferable and is not present in Adobe Flash system B2 Adobe Director can provide more functionality as compared to the current flash system. E.g. Multiple sounds while detecting mines   B2.1 Adobe Director can provide better visual effects as compared to flash e.g. in case of GUIês   B2.2 A modified version of the current system in flash can also provide the same functionality B2.2.1 We cannot integrate code developed in other platforms with Flash, but Flash can be integrated in Adobe Director B3 The interface provided by flash is not professional enough. It is too simple and straight forward for doing more things in future   B4 Easily available plug-ins can help integrate the tracking system developed in C# with Adobe Director  B4.1 Code developed in Open GL/AL can also be integrated using Adobe Director using suitable stubs   B5 A new sound recognition algorithm is being developed in Adobe Audition which can be integrated with Adobe Director but not with Open GL or Flash Evidence supported B6 If the current system is reused; the project deadline can be met easily B7 The developer has very little experience in development using Adobe Director   B7.1 The developer can take help from the already developed system in Adobe Director C1 The tracking software already developed is coded in C#/NX5. We could reuse that and develop our system in Open GL/AL C1.1 Open GL has C# libraries which can be used to develop the system C2 Because the platform used is for high end application development, it can provide good GUI and database support C2.1 Open GL/AL can help us generate dynamic surfaces for mine detection and training which the original system in flash does not have C4 Open GL does not support connectivity with Adobe Audition. Adobe Audition is required for creating sound recognition algorithm C3 Open GL does not support connectivity with Adobe Audition. Adobe Audition is required for creating sound recognition algorithm C4 The time taken for developing the project using open GL will be comparatively more as the whole system would have to be developed from scratch C4.1 If Open GL has support for C# libraries, and then the system could be develope d faster as developer is quite familiar with programming languages like C 151 


   C4.2 Open GL has excellent documentation that could help the developer learn the platform with ease C4.3 Developer has very little ex perience in working with Open GL platform  For our case study, alternative B i.e. Adobe Director was the most favorable alternative amongst all the three. It catered to the reusability criteria quite well and aimed at meeting most of the desired operational requirements for the system   6. CONCLUSION & FUTURE WORK  The main contribution of this paper is to develop an approach for evaluating performance scores in MultiCriteria decision making using an intelligent computational argumentation network. The evaluation process requires us to identify performance scores in multi criteria decision making which are not obtained objectively and quantify the same by providing a strong rationale. In this way, deeper analysis can be achieved in reducing the uncertainty problem involved in Multi Criteria decision paradigm. As a part of our future work we plan on conducting a large scale empirical analysis of the argumentation system to validate its effectiveness   REFERENCES  1  L  P Am g o u d  U sin g  A r g u men ts f o r mak i n g an d  ex p lain in g  decisions Artificial Intelligence 173 413-436, \(2009 2 A  Boch m a n   C ollectiv e A r g u men tatio n    Proceedings of the Workshop on Non-Monotonic Reasoning 2002 3 G  R Bu y u k o zk an  Ev alu a tio n o f sof tware d e v e lo p m en t  projects using a fuzzy multi-criteria decision approach Mathematics and Computers in Simualtion 77 464-475, \(2008 4 M T  Chen   F u zzy MCD M A p p r o ach t o Selec t Serv ice  Provider The IEEE International Conference on Fuzzy 2003 5 J. Con k li n  an d  M. Beg e m a n   gIBIS: A Hypertext Tool for Exploratory Policy Discussion Transactions on Office Information Systems 6\(4\: 303  331, \(1988 6 B P  Duarte D e v elo p in g a p r o jec ts ev alu a tio n sy ste m based on multiple attribute value theroy Computer Operations Research 33 1488-1504, \(2006 7 E G  Fo rm an  T h e  A n a l y t ic Hier a rch y P r o cess A n  Exposition OR CHRONICLE 1999 8 M. L ease  an d J L  L i v e l y  Using an Issue Based Hypertext System to Capture Software LifeCycle Process Hypermedia  2\(1\, pp. 34  45, \(1990 9  P e id e L i u   E valu a tio n Mo d e l o f Custo m e r Satis f a c tio n o f  B2CE Commerce Based on Combin ation of Linguistic Variables and Fuzzy Triangular Numbers Eight ACIS International Conference on Software Engin eering, Artificial Intelligence Networking and Parallel Distributed Computing, \(pp 450-454 2007  10  X  F L i u   M an ag e m en t o f an In tellig e n t A r g u m e n tatio n  Network for a Web-Based Collaborative Engineering Design Environment Proceedings of the 2007 IEEE International Symposium on Collaborative Technologies and Systems,\(CTS 2007\, Orlando, Florida May 21-25, 2007 11 X. F L i u   A n In ternet Ba se d In tellig e n t A r g u m e n tatio n  System for Collaborative Engineering Design Proceedings of the 2006 IEEE International Symposium on Collaborative Technologies and Systems pp. 318-325\. Las Vegas, Nevada 2006 12 T  M A sub jec tiv e assess m e n t o f altern ativ e m ission  architectures for the human exploration of Mars at NASA using multicriteria decision making Computer and Operations Research 1147-1164, \(June 2004 13 A  N Mo n ireh  F u zzy De cisio n Ma k i n g b a se d o n  Relationship Analysis between Criteria Annual Meeting of the North American Fuzzy Information Processing Society 2005 14 N  P a p a d ias HERMES Su p p o rti n g A r g u m e n tative  Discourse in Multi Agent Decision Making Proceedings of the 15th National Conference on Artifical Intelligence \(AAAI-98  pp. 827-832\dison, WI: AAAI/MIT Press,  \(1998a 15  E. B T riantaph y llo u   T h e Im p act o f  Ag g r e g atin g Ben e f i t  and Cost Criteria in Four MCDA Methods IEEE Transactions on Engineering Management, Vol 52, No 2 May 2005 16 S  H T s a u r T h e Ev alu a tio n o f airlin e se rv ice q u a lity b y  fuzzy MCDM Tourism Management 107-115, \(2002 1 T  D W a n g  Develo p in g a f u zz y  T O P S IS app r o ach  b a sed  on subjective weights and objective weights Expert Systems with Applications 8980-8985, \(2009 18 L  A  Zadeh  F u z z y Sets   Information and Control 8  338-353, \(1965  152 


                        





