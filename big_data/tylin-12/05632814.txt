Efficient Algorithms for Mining Frequent Weighted Itemsets from Weighted Items Databases Bac Le Faculty of Information Technology, University of Science Ho Chi Minh, Vietnam lhbac@fit.hcmus.edu.vn  
Abstract 
204In this paper, we propose algorithms for mining Frequent Weighted Itemsets \(FWIs\ from weighted items transaction databases. Firstly, we introduce the WIT-tree data structure for mining high utility itemsets in the work of Le 
 Bay Vo Faculty of Information Technology, Ho Chi Minh City University of Technology, Vietnam vdbay@hcmhutech.edu.vn 
Huy Nguyen Faculty of Information Technology, Saigon University Ho Chi Minh, Vietnam nqhuy@sgu.edu.vn 
I I NTRODUCTION Association rule is a most important task in Knowledge Discovery and Data mining \(KDD\. It gets relationships among the items in large number of transactions. Given 
2009\ and modify it for mining FWIs. Next, some theorems are proposed. Based on these theorems and the WIT-tree, we propose an algorithm for mining FWIs. Finally, Diffset for fast computing the weighted support of itemsets and saving memory are also discussed. We test the proposed algorithms in many databases and experimental results show that they are very efficient in comparison with Apriori-based approach 
et al 
Keywords\204frequent weighted support; frequent weighted itemsets; WIT-tree; WIT-FWIs; weighted items transaction databases 
  
002 
X 
 
 where 
Y 
 is the number of transactions in 
 
003 003 
 
n i i i I 
as a set of items and a database 
X 
sup 
  
004 
minSup 
002 
    2 1 and 
denoted as 
minimum support\. A classical association rule is an implication form 
 
the support of 
D X X D D X X X I 
I 
conf 
X 
Y 
containing 
 
in 
is called frequent if 
is a set of transactions. Let 
sup 
X XY 
005 
conf 
 
d the confidence is 
and the minimum confidence 
XY 
003 003 
 
we want to mine all association rules that satisfy 
003 
      The classical association rule mining doesn\220t care in the benefit of items. However, in some applications, we are interested in weighted value \(or benefit\ of each item. For example, bread gives 2 cents and a bottle of milk gives 4 cents when we bought them together. Thus, it is necessary to have 
and 
X 
minConf minConf 
Y 
330. The support of this rule is 
minSup minSup 
Given the 
7 pr o p o s e d t h e m o d e l of  weighted association rules \(WARs\ and presented an Aprioribased algorithm for mining FWIs. In 2003, Tao 
new methods for mining in this kind of databases In 1998, Ramkumar 
et al 
et al 
  p r opo sed a m e t hod for m i ni ng fuz z y  we i g h t ed association rules. To mine WARs, we must mine all frequent weighted itemsets. Therefore, mining FWIs is the most important in the process of mining WARs The contributions of this paper are as follows i We modify the WIT-tree and propose an algorithm for mining FWIs based on WIT-tree \(modified 
et al 
8 proposed the method of mining WARs.  In that paper, authors did not give any algorithm for mining FWIs. In 2008, Khan 
ii Some theorems and corollaries are proposed. Based on them, we propose an algorithm for fast mining FWIs iii We apply the Diffset strategy [1 a n d e x t e nd it f o r m i ning FWIs The rest of this paper is organized as follows. Section 2 presents related works to mine WARs. Section 3 presents a modification of WIT-tree [6  for co m p r e ssi ng t h e d a t a b a se into a tree structure. Algorithms for mining FWIs using WITtree are discussed in section 4. The experimental results will present in section 5, and we conclude our work in section 6 II R ELATED WORK The weighted items transaction database is defined as follows: Given a database 
D 
with a set of transactions     2 1 
I T t t I A W 
 
 
  
and a set of positive weights     2 1 
The weights of these items are in 
m t t t T 
  
 
corresponds with each item in 
n w w w W 
 
0.6 0.1, 0.3, 0.9, 0.2} stored in Table II TABLE I A 
B C D E 
n i i i I 
 For example: Consider the database in Table I and Table II Table I has six transactions 
1 203 6 and five items 
 
a set of items     2 1 
A, B, D, E A, B, D, E 
Items bought 
B, C, D 
A, B, C, D, E, F 
B, C, E A, B, C, E 
1 2 3 4 5 6 
TRANSACTION DATABASE 978-1-4244-8075-3/10/$26.00 \2512010 IEEE 
Transactions 


TABLE II WEIGHTED I TEMS TABLE Items Weight  A 0.6 B 0.1 C 0.3 D 0.9 E 0.2 A Galois connection Let   I  T be a binary relation, where I is the set of items and T is the set of transactions of the database D Let I X   T Y  Let P  S clude all subset of S Two mappings between P  I d P  T re called Galois connection as follows 4  i  y x X x T y X t T P I P t               ii  y x Y y I x Y i I P T P i               The mapping t  X is the set of transactions in the database which contains X and the mapping i  Y is the itemset that contains in all transactions Y  Given X, X 1 X 2  P  I d Y, Y 1 Y 2  P  T   The Galois connection satisfies the following properties [4   i X 1  X 2 t  X 1  012 t  X 2  ii Y 1  Y 2 i  Y 1  012 i  Y 2  iii X  i  t  X and Y  t  i  Y  B Mining weighted association rules Definition 2.1 The transaction weight tw of a transaction t k is defined as follows k t i j k t w t tw k j     2.1 Definition 2.2 The weighted support of an itemset is defined as follows    T t k X t t k k k t tw t tw X ws         2.2 where T is the list of transactions in the database Example 2.1 Consider tables I, II, and definition 2.1, we can compute the tw  t 1 value as follow 45  0 4 2  0 9  0 1  0 6  0   1      t tw TABLE III T RANSACTION WEIGHTS OF ALL TRANSACTIONS IN T ABLE I Transactions tw 1 0.45 2 0.2 3 0.45 4 0.3 5 0.42 6 0.43 Sum 2.25 From tables I, III, and definition 2.2, we can compute the ws  BD alue as follows Because BD appears in transactions {1, 3, 5, 6 ws  BD  computed 78  0 25  2 43  0 42  0 45  0 45  0        BD ws Theorem 2.1 The weighted support satisfies the downward closure property i.e., if X  Y then ws  X   ws  Y  Proof Because X  Y according to the property i\f Galois connection, we have t  X  012 t  Y             Y t t k X t t k k k t tw t tw      T t k Y t t k T t k X t t k k k k k t tw t tw t tw t tw                 Y ws X ws  Thus, the weighted support satisfies downward closure property  III WITTREE DATA STRUCTURE In [6 w e pr op os ed th e W I T t r e e  W eig h t e d  Item s e tT i ds e t  tree\ data structure, an expansion of IT-tree [1 t o m i ne hi gh utility itemsets. We modify WIT-tree structure by changing twu property into ws property. By WIT-tree technique algorithms in section 4 only scan the database once because it bases on the intersection of Tidsets to compute the weighted support in next steps. Thus, it saves the time for the database scan and makes the algorithms be done faster a\ Vertex: Includes 3 fields X an itemset t  X the set of transactions contains X  ws the weighted support of X  The vertex is denoted     X ws X t X   We can see that the value of ws  X is computed by summing all tw values of transactions which their tids belong to t  X en dividing it by the sum of all tw values. Thus computing of ws  X will be done quickly by using Tidset b\rc: Connecting the vertex at k th level \(called X ith the vertex at k+1  th level \(called Y  Definition 3.1 2 T h e e q u i va l e nc e cl a s s  Let I be a set of items and I X  a function p  X k X 1:k as the k length prefix of X and a prefix-based equivalence relation K  on itemsets as follows         k Y p k X p Y X I Y X k  015      The set of all itemsets having the same prefix X is called as an equivalence class, and denoted an equivalence class with prefix X is X   Example 3.1 Consider the tables I and III above, we have WIT-tree for mining frequent weighted itemsets as in Figure 1 


Figure 1 Search tree using WIT-tree The root node of WIT-tree contains all single item nodes All nodes in level 1 belong to the same equivalence class with prefix {} \(or   E a c h node in le ve l 1 w ill b e c o m e a ne w  equivalence class using its item as the prefix. With each node in the same prefix, it will join with all nodes successive it to create a new equivalence class. The process will be done recursively to create new equivalence classes in higher levels For example: Consider the Figure 1, nodes A  B  C   D  E belong to the equivalence class   C o nsi d e r node  A  A will join with all nodes successive it B  C  D   E to create a new equivalence class A    AB  AC   AD  AE  AB  ill b eco m e a n e w eq u i v a len c e class b y  joining with all nodes successive it AC  AD  AE  Figure 1 shows that all itemsets satisfy downward closure property Thus, we can prune an equivalence class in WIT-tree if its ws does not satisfy the minimum weighted support  minws For example, suppose that minws 0.4, because ws  ABC 0.32 minws we can prune the equivalence class which the prefix is ABC i.e., all child nodes of ABC will be pruned IV M INING FREQUENT WEIGHTED ITEMSETS A The algorithm In this section, we base on the hybrid approach [10, 12  t o  mine FWIs In function WIT-FWIs Figure 2\, let   n l l l P   2 1  be an equivalence class P is the parent node of each l i and each l i is an itemset that represents for node     i i i Pl ws Pl t Pl  The input of this function is the equivalence class P  P   I t  considers each vertex l i with all l j after l i in P  es 6 an d 9   Let X  l i  l j it computes Y  t  X  t  l i   t  l j lines 10 and 11\, if ws  X computed through t  X ine 12\atisfies minws line 13\ we add new vertex   X ws Y X  into equivalence class P i  line 14\. The last line \(line 15\ calls FWIs-EXTEND function recursively to process the equivalence class that begins from  P i  n t i l n o an y v e rtex  is  cr eat ed Fu n c t i on  COMPUTEWS  Y ses the eq. \(2.2\o compute the ws of itemset X based on the values in Table III with Y  t  X  Input database D and minws Output: FWIs contains all frequent weighted itemsets that satisfy minws from D Method 1 WIT-FWIs 2   i  I  ws  i   minws  3. SORT    4 FWIs  5 FWIs_EXTEND      FWIs-EXTEND  P   6. for all l i   P  do 7.     Add l i  ws  l i to FWIs 8 P i   9.     for all l j   P   wi th  j i do 10 X = l i  l j 11 Y = t  l i   t  l j  12 ws  X   COMPUTE-WS  Y using the eq. \(2.2 13.         if ws\(X   minws then 14 P i  P i      X ws Y X   15 FWIs-EXTEND  P i  Figure 2 WIT-FWIs algorithm for mining frequent weighted itemsets    A  1345 B  123456 C  2456 D  1356 E  12345 0.72                                                       1.0 0.6                      0.78           0.81 AB  1345 AC  45 AD  135 AE  1345 BC  2456 BD  1356 BE  12345 CD  56 CE  245 DE  135 0.72              0.32             0.59            0.72               0.6               0.78           0.81 0.38          0.41            0.59 ABC  45 ABD  135 ABE  1345 ACD  5 ACE  45 ADE  135 BCD  56 BCE  245 BDE  135 CDE  5 0.32         0.59             0.72           0.19       0.32            0.59             0.38          0.41           0.59 0.19  ABCD  5 ABCE  45 ABDE  135 ACDE  5 BCDE  5 0.19         0.32                0.59            0.19                                          0.19  ABCDE  5 0.19 


B Illustration According to tables I and III, the illustration of WIT-FWIs algorithm with minws 0.4 is as follows Figure 3 WIT-tree for mining FWIs from the database in Table I with minws 0.4 At the beginning, we compute the ws values of the single items. The weighted support values of 1-items are ws  A  0.72 ws  B 1.0 ws  C 0.60 ws  D 0.78 ws  E 0.81 All ws values of single items satisfy minws     A  C  D  E  B  Consider equivalence class A  rs t of all  A is added to FWIs FWIs  A  A joins C we have a new itemset AC 45 with ws  AC  0.32 minws so AC is not added to A   A joins D we have a new itemset AD 135 with ws  AD  0.59, so add AD to A   A   AD  A joins E we have a new itemset AE 1345 with ws  AE  0.72  A  AD  AE  A joins B we have a new itemset AB 1345 with ws  AB  0.72  minws add AB to A   A  AD  AE, AB  After making the equivalence class A   th e alg o r ith m  w ill be called recursively to create all equivalence classes successive it Consider equivalence class AD   A dd AD to FWIs FWIs  A  AD  AD joins AE we have a new itemset ADE 135 with ws  ADE 0.59, so add ADE to AD   AD  ADE  AD joins AB we have a new itemset ADB 135 with ws  ADB 0.59, so add ADB to AD   AD  ADE  ADB  Consider equivalence class ADE  Add  ADE to FWIs FWIs  A  AD  ADE  ADE joins ADB into a new itemset ADEB 135 with ws  ADEB 0.59  ADE    ADEB Because the equivalence class ADE  a s  on ly on e elem en t there is no any equivalence class created in successive it Similarly to equivalence classes C   D  E  B  Finally, we have the set of all FWIs that satisfy minws 0.4 is FWIs  A, AB, AD, AE, ABD, ABE, ABDE, ADE, B, BC BD, BE, BCE, BDE, C, CE, D, DE, E details in Figure 3 Theorem 4.1 Given two itemsets X and Y if t  X  t  Y hen ws  X  ws  Y  Proof Because t  X  t  Y             Y t t k X t t k k k t tw t tw       T t k Y t t k T t k X t t k k k k k t tw t tw t tw t tw             or ws  X  ws  Y  Corollary 4.1 If X  Y and t  X  t  Y then ws  X  ws  Y  Proof If X  Y we have t  X  012 t  Y according to the property i\ of the Galois connection\ Besides, because t  X  t  Y  t  X  t  Y  ws  X  ws  Y ording to the theorem 4.1  Based on corollary 4.1, we develop an algorithm for mining FWIs with some modifications of the algorithm in the section 4.1. When we join two nodes l i  l j of P  t o  cr eat e a n e w n o d e  l i  l j if t  l i  t  l i  l j then ws  l i  l j  ws  l i we need not compute the ws value of l i  l j Similarly, if t  l j  t  l i  l j  then ws  l i  l j  ws  l i we need not also compute the ws value of l i  l j  C The modification algorithm for mining FWIs We change line 12 of the algorithm in Figure 2 into 3 lines 12 if |t  l i  Y| then ws  X  ws  l i se corollary 4.1 13 elseif |t  l j  Y| then ws  X  ws  l j e corollary 4.1 14 else ws  X   COMPUTE-WS  Y use the eq. \(2.2 Example 4.1 Consider the Figure 3: when we join node A  1345 with node B  123456 to create new node AB  1345 because of t  A 1345 t  AB  ws  AB  ws  A 0.72 Similarly t  C 2456 t  BC  ws  BC  ws  BC 0.6 Besides, because t  A    t  AD and t  D    t  AD  we must compute the ws value of AD based on t  AD Based on the corollary 4.1, we need not compute ws values of 11 itemsets those are AE, AB, CB, DE, BD, EB, ADE, ADB, AEB, CEB DEB, ABDE  D Diffset for computing ws values fast and saving memory Zaki and Gouda [12  p r opo sed t h e D i ffse t st ra t e gy  fo r fa st  computing the support of itemsets and saving memory to store Tidsets. We recognize that it can be used for fast computing the ws values of itemsets Let d  PXY be the difference set between PX and PY We have d  PXY  t  PX  t  PY   4 1  where PX and PY in equivalence class P  Assume that we have d  PX d d  PY and need get d  PXY ccording to the results in [12 w e can g e t it easi ly  b y  computing the difference set between d  PY and d  PX  d  PXY  d  PY  d  PX   4 2  Based on eq. \(4.1\d eq. \(4.2\, we can compute the ws value of PXY by using the d  PXY s follows   A  1345  C  2456  D  1356 E  12345 B  123456  0.72                          0.6                 0.78          0.81           1.0 AD  135 AE  1345 AB  1345 CE  245 CB  2456 DE  135 DB  1356 EB  12345 0.59         0.72          0.72        0.41         0.6          0.59        0.78          0.81 ADE  135 ADB  135 AEB  1345 CEB  245  DEB  135  0.59          0.59            0.72            0.41                  0.59  ADEB  135 0.59 


ws  PXY  ws  PX  000 000 007 007 T t PXY d t t tw t tw       4.3 Proof We have t  PXY  t  PX  005 t  PY  t  PX  t  PX  t  PY    t  PX  d  PXY  000 000 000 007 007  T t k PXY t t k k k t tw t tw PXY ws         000 000 007  007  T t k PXY d PX t t k k k t tw t tw          000 000 000 007 007 007   T t k PXY d t k PX t t k k k k t tw t tw t tw             000 000 007 007 T t k PX t t k k k t tw t tw        000 000 007 007 T t k PXY d t k k k t tw t tw       ws  PX  000 000 007 007 T t k PXY d t k k k t tw t tw       Based on eq. \(4.1\ \(4.2\ and \(4.3\, we can use Diffset instead of using Tidset for computing the ws values of itemsets in the process of mining FWIs Theorem 4.2 If d  PXY  017 then ws  PXY  ws  PX  Proof Because d  PXY  017 000 ws  PXY  ws  PX  000 000 007 007 T t PXY d t t tw t tw        ws  PX  To save the memory for storing Diffset and the time for computing Diffset, we sort the itemsets in the same equivalence class in increasing order by their ws  1 The algorithm Input A database D and minws Output: FWIs contains all frequent weighted itemsets that satisfy minws from D Method WIT-FWIs-DIFF 1 017  i 007 I  ws  i  004 minws  2. FWIs 017 3 SORT  017   4 FWIs-EXTEND-DIFF  017    FWIs-EXTEND-DIFF  P   5. for all l i 007  P  do 6.     Add l i  ws  l i to FWIs 7 P i   017 8.      for all l j 007  P   w i th j i d o  9 X = l i 020 l j 10 if P 017 then 11 Y = t  l i  t  l j  12 else 13 Y = d  l j  t  l i  14 if Y  017 then ws  X  ws  l i use theorem 4.2 15 else ws  X   COMPUTE-WS-DIFF  Y use the eq. \(4.3 16.         if ws\(X  004 minws then 17.              Add   X ws Y X  to P i    so rt in in c r e a s in g b y   Y  18 FWIs-EXTEND-DIFF  P i  Figure 4 WIT-FWIs-DIFF algorithm for mining frequent weighted itemsets WIT-FWIs-DIFF algorithm \(figure 4\ differs from the WIT-FWIs-MODIFY algorithm \(figure 2\ that it uses Diffset to compute the ws value faster. Because level 1 stores the Tidsets, and if P  017 line 9\, means that l i and l j belong to level 1, we use the eq. \(4.1\ to compute Y  d  X  d  l i 020 l j  t  l i  t  l j line 10\. From level 2 stores Diffset, we use the eq 4.2\ compute Y  d  X  d  l i 020 l j  d  l j  d  l i line 12\. Line 13 uses the theorem 4.2 to fast compute ws  X  2 Illustration According to tables I and III, we illustrate the WIT-FWIsDIFF algorithm with minws 0.4 as follows. Level 1 of WITtree contains single items, their tids and their ws They are sorted in increasing order by their tids The purpose of this work is to compute Diffset faster. For example, consider nodes B and D if they are not sorted, we must compute d  BD  t  B   t  D 123456 Ö 1356 = 14; otherwise d  DB  t  D  t  B  1356 Ö 123456 017  Consider equivalence class A   A joins C  d  AC  t  A  t  C 1345 Ö 2456 = 13 000 ws  AC  ws  A  000 000 007 007 T t AC d t t tw t tw       0.72 25  2 45  0 45  0  0.32 minws  A joins D  d  AD  t  A  t  D 1345 Ö 1356 = 4 000 ws  AD  ws  A  000 000 007 007 T t AD d t t tw t tw       0.72 25  2 3  0 0.59 004 minws  A joins E  d  AE  t  A  t  E 1345 Ö 12345 017 000 ws  AD  ws  A  A joins B  d  AB  t  A  t  B 1345 Ö 123456 017 000 ws  AB  ws  A 0.72 Figure 5 Results of the algorithm WIT-FWIs-DIFF from the database in Table I with minws 0.4   A  1345  C  2456  D  1356  E  12345 B  123456 0.72                    0.6               0.78          0.81          1.0 AD  4 AE  017 AB  017 CE  6 CB  017 DE  6 DB  017  EB  017  0.59     0.72     0.72      0.41      0.6        0.59     0.78       0.81 ADE  017 ADB  017 AEB  017 CEB  017  DEB  017  0.59        0.59        0.72        0.41                0.59  ADEB  017 0.59 


V E XPERIMENTAL RESULTS All experiments described below were performed on a Centrino core 2 duo \(2◊2.53 GHz\, 4GBs RAM memory Windows 7, using C# 2008. The experimental databases were downloaded from http://fimi.cs.helsinki.fi/data  to perform the test with features displayed in Table IV TABLE IV E XPERIMENTAL DATABASES We modify by creating one table to store weight values of items \(value in range of 1 to 10\ for each database TABLE V E XPERIMENTAL RESULTS FROM THE DATABASES IN T ABLE IV DBs minws  Time \(s FWIs Apriori 7 WITFWIs WIT-FWIsMODIFY DIFF BMS-POS 10 4.04 3.53 3.29 2.5 12 8 4.62 4.42 4.24 3.57 21 6 7.32 6.27 6.08 5.59 32 4 14.74 13.78 13.49 12.27 85 Chess 85 2.4 1.25 1.25 0.08 2624 80 9.78 4.21 4.51 0.23 8088 75 33.12 10.97 10.05 0.37 20298 70 111.82 33.21 27.85 0.7 47181 Mushroom 35 1.5 1.36 0.84 0.33 1257 30 2.86 1.75 1.95 0.44 2937 25 5.34 2.96 2.67 0.91 5751 20 61.85 15.91 13.4 1.3 53853 Remark DIFF means WIT-FWIs-DIFF We compare the proposed algorithms to Apriori-based algorithm [7  a n d  e xpe ri m e nt a l  r e sul t s fro m T a b l e V sh o w t h a t  the proposed algorithms are more efficient than Apriori-based in mining FWIs. When the number of FWIs is small, the running time of algorithms based on WIT-tree is slight faster than Apriori-based. For example, consider the BMS-POS database with minws 4%, the mining time of Apriori-based is 14.74 \(s\, of WIT-FWIs is 13.78 \(s\, of WIT-FWIs-MODIFY is 13.49 \(s\and of WIT-FWIs-DIFF is 12.27 \(s\The scale between Apriori-based and WIT-FWIs-DIFF is  24  83  100 74  14 27  12   However, when we compare them in Chess and Mushroom databases with the number of FWIs is large, the running time of WIT-tree-based is more efficient than Apriori-based. For example: Consider the Chess database with minws 70%, the mining time of Apriori-based is 111.82\(s\ WIT-FWIs is 33.21 \(s\ WIT-FWIs-MODIFY is 27.85 \(s\, and of WIT-FWIs-DIFF is 0.7 \(s\. The scale between Apriori-based and WIT-FWIs-DIFF is  63  0  100 82  111 7  0    VI C ONCLUSION AND FUTURE WORK This paper has presented the method for mining frequent weighted itemsets from weighted items transaction databases and the efficient algorithms are also proposed. As above mentioned, the time of mining FWIs by WIT-tree algorithms is more efficient than the time of mining by Apriori-based. By WIT-tree data structure, the algorithms only scan the database once. The algorithm based on Diffset is faster than the others because it saves more memory for storing and therefore, the time of computing Diffset is more efficient In this paper, we only improve the phase of mining FWIs by WIT-tree. In the future, we will study how to mine efficient association rules from FWIs. Besides, mining association rules from frequent weighted closed itemsets \(FWCIs\ more efficient than from FWIs. Therefore, we will discuss how to mine FWCIs from weighted items databases R EFERENCES 1 rawal, T. Imie lins k i A. Swa m i, Mini ng a ssoc ia tio n r u le s between sets of items in large databases, Proceedings of the 1993 ACM SIGMOD Conference Washington DC, USA, May 1993 pp. 207 Ö 216 \(1993 2 rawal, R. Srik an t, Fast alg o r ith ms fo r min i ng asso ciatio n rules, In VLDB'94 \(1994\, pp. 487 Ö 499 \(1994 3 Cai, A.W F u C.H Ch en g   W.W Kwo n g  Min i n g  Association Rules with Weighted Items, In Proceedings of International Database Engineering and Applications Symposium IDEAS 98\, pp. 68 Ö 77 \(1998 4 Gan ter R W i l l e F o rmal Co n cep t A n aly s is I n S p ring er-Verlag 1999 5  S  Kh an   M  Mu y e b a   F  C o en en  F u zzy W e i g h t ed Asso ci at i o n Rule Mining with Weighted Support and Confidence Framework Proc. 1st Int Workshop on Algorithms for Large-Scale Information Processing in Knowledge Discovery \(ALSIP 2008 held in conjunction with PAKDD 2008 \(Japan\ pp. 52 Ö 64 2008  H  N guye n  T.A Ca o, B. V o A N ove l A l g o rit h m for  Mining High Utility Itemsets, the first Asian Conference on Intelligent Information and Database Systems, published by IEEE pp. 13 Ö 16 \(2009   D  Ra m kum a r S. Ra n k a  S  Ts ur, We i ghte d A s s o c i a t i on R u l e s   Model and Algorithm, SIGKDD, pp. 661 Ö 666 \(1998  Ta o, F  M u rta g h, M  Fa rid  We ighte d A s s o c i a tio n Rule M i ni ng  using Weighted Support and Significance Framework, SIGKDD pp. 661 Ö 666 \(2003 9 n g  J. Yan g  P S Yu Efficien t Min in g o f  Weig h t ed  Association Rules, SIGKDD 2003, pp. 270 Ö 274 \(2003   Za ki, C.J  H s ia o, Effi c i e n t A l gorit hm s for Minin g Clo s e d  Itemsets and Their Lattice Struct ure, IEEE Transactions on Knowledge and Data Engineering, Vol. 17, No 4, April 2005, pp 462 Ö 478  \(2005  M J  Za k i  Mini ng N o nR e dun da nt A s s o c i a t i o n R u le s   D a ta Mining and Knowledge Discovery. In: Kluwer Academic Publishers. Manufactured in the Netherlands, pp. 223 Ö 248 2004  M J  Za k i K  G o uda  Fa s t V e rtic a l Mini ng U s ing D i ffs e t s  Pr oc   of Ninth ACM SIGKDD Intêl Conf. , pp. 326 - 335 \(2003 Database #Trans #Items Remark BMS-POS 515597 1656 Modified Chess 3196 76 Modified Mushroom 8124 120 Modified 


  





meani n g u s i ng t h e C ohen d ze Threats t o ity concern f actors t hat can inﬂuence our obs erv a t i ons  A l t hough bot h a s s o ci at i o n r ul e d i s co v e r y an d G r a n g e r cau sality test can statistically in f e r c o changes b et w een  l es or t e mporal l y cons equent changes  as in th e case o f G r a n g e r th is w o u l d n o t allo w t o c laim an yt hi ng about caus e ef fect rel a t i ons hi ps about changes o ccurri ng on a  l e and o n t hos e h a v i n g a change-coupl i n g re l a t i o n w i t h i t  Threats t o ex t e r n a l v a l i d i t y concern t he general i zat i o n of our  ndi ngs  A l t hough w e performed our anal ys es on four di f ferent s ys t e ms  b el ongi ng t o di f ferent domai ns and de v e l oped w i t h di f ferent p rogrammi ng l a nguages  w e are aw a r e t h a t a f u r t h e r e m p i r i c a l v a l i d a t i o n o n a l a r g e r s e t o f sy st e m s w o u l d b e b e n e  c i a l t o b e t t e r su p p o r t o u r  n d i n g s R TED W K As s t a t e d b y B o h n e r a n d Ar n o l d  1 5  am a j o r g o a l o f impact analys is is to identify the s oftw ar e w or k p r oducts af f ect ed by pr opos ed c hang es  Mos t of t h e e xi s t i n g c hange i m pact anal ys i s t echni ques aim a t e x p l o itin g t h e p r esen ce o f d e p e n d e n c ies i n t h e so u r ce code i dent i  ed by means o f s t a t i c anal ys i s 2  dynami c 3 or s p eci  c t echni ques s uch a s s t a t i c and or dynami c s l i c i n g 16  S o me i m pact anal ys i s t echni ques c ope wi t h p r o b l e m s s p e c i  c o f p a r t i c u l a r k i n d s o f a r t i f a c t s  for e xampl e  U ML model s 17  T here i s a l ar ge corpus of s t udi es rel a t e d t o c hange i m pact anal ys i s  h o w e v er a compl e t e s u rv e y of t h em i s be yond t h e s cope of t h i s paper  As m e n t i o n e d i n t h e i n t r o d u c t i o n  o n e l i m i t a t i o n o f e x i s t in g im p a c t a n a ly s is te c h n iq u e s is th a t th e y w o r k a s s u m in g the p res ence o f d ependencies b etween artif acts  Alternati v e approaches e x i s t t o o v e rcome s uch a l i m i t a t i on S o me of 4 18  are b as ed on info rmation r etrie v al i e the y ex p l o i t t h e t ex t u a l c o n t e n t o f t h e a r t i f a c t s  a s s u m i n g t h a t ac h a n g e t o a s o f t w a r e a r t i f a c t w i l l i m p a c t o t h e r  t e x t u a l l y sim ilar a r tif acts Th e w eak n e ss i s t h a t t h e se a p p r o a c h e s mi g h t f a i l t o  n d p e r t i n e n t l i n k s w h e n t h e s i mi l a r i t y i s lo w—wh ile ar tif acts a r e  i n d eed r elated—or m ight nd fa l s e p o s i t i v e s w h e n u n r e l a t e d a r t i fa c t s a r e t e x t u a l l y s i m i l a r  Ot h e r a p p r o a c h e s t h a t d o n o t r e l y o n c o d e d e p e n d e n c i e s a r e bas e d o n e xpert j udgment a nd code i n s p ect i o n 19  ho w ev e r  s ev e r a l s t u d i e s h av e s h o w n t h a t e x p e r t p r e d i c t i o n s a r e frequently incorrect or at leas t b ias e d b y s ubjecti v enes s  20  and s ource code i n s p ect i o n can be prohi bi t i v e l y e xpens i v e 21  The  rs t s t udi es ai med a t i dent i fyi ng l ogi cal change coupl i ngs w e re performed by G a l l al r s t o n c h a n g e releas es of a t elecommunication s ys tem  22  a nd then on commit h is tories e x tracted from C VS logs 23   T o o v er co m e th e lim itatio n s o f th e p r e v i o u s ch an g e im p act analys is approaches  a nd abo v e all t o c omplement t he recommendat i ons t h at coul d b e p ro vi ded b y t radi t i onal c hange impact analys is approaches  t wo a p p r o a c h e s w e r e d e v e l o p e d in p a r a lle l b y tw o d if f e r e n t r e s e a r c h g r o u p s  n a m e ly Y in g et  5 a nd Zi mmermann et al 1 6  B o t h us e a s s oci a t i o n r u les d isco v e r y  a wellk n o wn d a tam in in g p r actice—th at we s u mmari zed i n S ect i o n II-B t o d et ermi ne s e t s of  l es th a t w e r e c h a n g e d to g e th e r f r e q u e n tly in th e p a s t f r o m th e change hi s t ory o f t he code bas e  T he hypot hes i s i s t hat t he change patterns i nferred b y m eans o f a s s o ciation r ules i.e l e s c o c h a n g i n g i n t h e s a m e c h a n g e s e t  c a n b e u s e d t o recommend pot ent i a l l y rel e v a nt s ource code t o a d e v el oper performi n g a change T he y found t h at i n man y cas es t h e precis i on in the p erformed pr ediction i s o ften abo v e 70 and i n s ome cas es higher t han 90 w hile the r ecall o ften lo w e r th a n 2 5   a n d in s o m e c a s e s b e lo w 1 0   In a p re vi ous paper 7 w e i n t roduced t h e i dea o f u s i ng th e m u lti v a r i ate tim e s er ies f o r p r ed ictin g t h e im p act o f ac h a n g e  T h i s p a p e r c o n t i n u e s t h ee a r l y w o r k p r e v i o u s l y pr e s e nt e d a s f ol l o w s   we p r e s e n t a n e m p i r i c a l e v a l u a t i o n  t h r o u g h c h a n g e s fro m fo u r s o ft w a re s y s t e m s  o f G ra n g e r c a u s a l i t y t e s t  its co m p ar iso n with asso ciatio n r u le d isco v e r y  a n d th e ove r l a p o f t h e i r r e s u l t s  T h e p r e v i o u s w o r k o n l y s h o w e d th e a p p licab ility o f th e a p p r o ach o n a s u b s y s tem o f t h e a 7  md  o m p o s e d o f a b o u t 3 0  l e s o n l y   to tr ain t h e m u lti v a r i ate tim e s er ies m o d e l i n a w a y t h a t pro v i d es t h e  s t rengt h of t h e c hange coupl i n g rel at i on we u s e  l e c h a n g e f r e q u e n c i e s  i n s t e a d o f B o o l e a n va r i a b l e s i n d i c a t i n g w h e t h e r o r n o t  l e s c h a n g e d   we d e  n e a h y b r i d a p p r o a c h t h a t c o m b i n e s r a n k i n g o f bot h a s s o ci at i o n r ul es and G ranger  C AND W K IN P S In recent y ears  As s o ciation r ule d is co v e ry 11  has b een su c c e ssf u l l y a p p l i e d t o p r e d i c t c h a n g e c o u p l i n g s a m o n g  l e s by mi ni ng dat a from s oft w are repos i t o ri es 1  5  Thi s paper p erforms a n e mpirical comparis on of as s o ciation r ule di s c o v e ry w i t h a t echni que bas e d o n m ul t i v a ri at e t i m e s eri e s an aly s is a n d sp eciﬁcally o n th e G r a n g e r cau sality test  8   Re s u l t s o f a n e m p i r i c a l s t u d y p e r f o r m e d o n c h a n g e d a t a ex t r a c t e d f r o m C V S r e p o s i t o r i e s o f f o u r d i f f e r e n t s o f t w a r e sy st e m s F r e e B S D i 3 8 6  M y l y n  S q u i d  a n d R h i n o  sh o w th at  i o v e r a ll asso ciatio n r u le d isco v e r y e x h ib it a h ig h e r p r ecisio n th an Gran g e r cau sality test w h ile th e r ecall o f Gr an g e r cau sality test is i n m o s t cases h ig h e r f o r Gr an g e r cau sality o r at least c o m p a r a b l e an d  ii th e n u m b e r o f tr u e r eco m m e n d a tio n s p r o v id ed b y Gr an g e r cau sality test is h ig h e r th a n f o r a s s o c ia tio n r u le s  a n d a b o v e a ll th e tw o te c h n iq u e s p r o v id e a s e t o f r e c o m m e n d a tio n s h a v in g a v e r y lo w in te r s e c tio n  The a bo v e res u l t s s ugges t t h e opport uni t y of combi n i n g th e tw o te c h n iq u e s  A h y b r id te c h n iq u e o b ta in e d b y c o m bi ni ng ranki ng s c ores pro v i d ed by as s o ci at i o n rul es and b y Gran g e r cau sality allo w t o o b t ain  i a F measu r e a n d a r ecall 7 http://w w w  s am ba o r g 


hi gher t han t he t w o t echni ques a l one a nd i i  a p reci s i on i n bet w een t h e t w o  In s ummary  t he performed s t udy s ugges t s th e p o te n tia l o f m u lti v a r ia te tim e s e r ie s a n a ly s is to s u g g e s t change coupl i ngs compl e ment ary t o t hos e p ro vi ded b y a s so c i a t i o n r u l e s a n d t h e a d v a n t a g e s o f c o m b i n i n g t h e t w o te c h n iq u e s  Wo r k i n p r o g r e s s a i m s a t  i  u s i n g e n h a n c e d w a y s o f co m b in in g t h e tw o t ech n i q u e s  ii f u r t h e r v alid atin g t h e combi n ed t echni ques t hrough more cas e s t udi es as w e l l as by in v e stig atin g h o w ch an g e s t en d t o b e p r o p a g a ted i n p r o jects ha ving a d if ferent or ganizati on and  iii better unders tanding th e n atu r e o f c h a n g e co u p lin g i n f er r e d b y G r a n g e r cau sality te s t a s o p p o s e d to th o s e in f e r r e d b y m in in g a s s o c ia tio n r u le s  R EF ER EN C ES 1 T  Z i m m e rm a n n  P  W e i s g e rb e r  S  D i e h l  a n d A  Z e l l e r  Mi n i n g v er si on hi st or i e s t o gui de sof t w a r e changes  i n E 0 4  P r o c e e d i n g s o f t h e 2 6 t h In t e r n a t i o n a l C o n f e r e n c e o n Sof t w ar e E ngi neeri n g 2 0 0 4  p p  5 6 3  5 7 2  2 R  S  A rn o l d a n d S  A  B o h n e r   Im p a c t a n a l y s i s t o w a rd s a frame w o rk fo r c o m p a riso n   i n Pr o c e e d i n g s o f t h e C o n f e r e n c e on Sof t w ar e M ai nt enance  I C SM 1993 Mont r  eal  Quebec Ca n a d a  S e p t e m b e r 1 9 9 3 1 9 9 3  p p  2 9 2  3 0 1  3 J  L a w a n d G  R o t h e rm e l   W h o l e p ro g ra m p a t h b a s e d d y nami c i mpact anal ysi s   i n Pr o c e e d i n g s o f t h e 2 5 t h I n t e r n a tio n a l C o n fe r e n c e o n S o ftw a r e E n g in e e r in g  M a y 3 1 0  2 0 0 3  Po r t l a n d  O r e g o n  U S A I E E E C o m p u t e r S o c i e t y  2 0 0 3  p p  308–318  G  C anfora and L  C erul o Impact anal ysi s by mi ni ng sof t w a r e and c hange r e quest r e posi t o r i es  i n 11t h I E E E In t e r n a t i o n a l S y m p o s i u m o n S o f t w a r e M e t r i c s M E T R IC S 2005  1922 Sept em ber 2005 C om o I t al y I E E E C o m p u t e r So c i e t y  2 0 0 5  p  2 9  5 A  T  T  Y i n g  G  C  M u rp h y  R  N g  a n d M  C  C h u C a rro l l  P r ed i ct i n g s o u r ce co d e ch an g es b y m i n i n g r e v i s i o n h i s t o r y   IE E E T r a n s a c t i o n s o n S o f t w a r e E n g i n e e r i n g v o l  3 0  p p  5 7 4  586 S e p 2004 6 T  Z i m m e rm a n n  P  W e i  g e rb e r  S  D i e h l  a n d A  Z e l l e r  Mi n i n g v er si on hi st or i e s t o gui de sof t w a r e changes  IEEE Tr a n s  S o f t w a r e E n g  v o l 3 1 n o  6 p p  4 2 9  4 4 5  2 0 0 5  7 M  C eccarelli L Ceru lo  G C an fo ra a n d M  Di P e n t a  An ecl ect i c approach for c hange i m pact anal ysi s   i n Pr o c e e d i n g s of t h e A C M  I E E E 32r d I nt ernat i onal C onf er ence on Sof t w ar e En g i n e e r i n g  I C S E 1 0 1 0  N e w I d e a s a n d Em e r g i n g Re s u l t s N IE R  T r a c k  2 8 M a y 2 0 1 0  C a p e T o w n  S o u t h A f r i c a t o appear A C M P r e s s  2 0 1 0  ht t p    w w w  r cost  uni sanni o i t  md i p e n t a  p a p e r s  n i e r 2 0 1 0  p d f  8 C  W  J  G ra n g e r   In v e s t i g a t i n g c a u s a l re l a t i o n s b y e c o n o met r i c model s and cr o ssspect r al m et hods  a  vo l  3 7  n o  3  p p  4 2 4  4 3 8  1 9 6 9   N  D  M ukhopadhyay a nd S  Chatterjee Causality and pat h w a y s earch i n mi croarray t i me s eri e s e xperi ment   s v o l 2 3 n o  4 p p  4 4 2  4 4 9  2 0 0 7  1 0  A  H i n d l e  M  W  G o d fre y  a n d R  C  H o l t   M i n i n g re c u rre n t act i v i t i es  F o u r i er an al y s i s o f ch an g e e v en t s   i n ernatio n a l C o n fe r e n c e o n S o ftw a r e E n g in e e r in g  I C S E 2 0 0 9  M a y 1624 2009 V ancouver  C anada C om pani on V ol um e  pp 295–298 1 R Ag ra w a l T  Imie lin sk i a n d A  N  S w a mi  M i n i n g a s soci at i o n r ul es bet w een set s of i t ems i n l ar g e d at abases  in Pr o c e e d i n g s o f t h e 1 9 9 3 A C M S I G M O D I n t e r n a t i o n a l Co n f e r e n c e o n M a n a g e m e n t o f D a t a  W a s h i n g t o n  D  C  M a y 1993 A C M P r e s s  1 9 9 3  p p  2 0 7  2 1 6  2 J  D  H a m i l t o n  Ti m e S e r i e s A n a l y s i s P r i n c e t o n U n i v e r s i t y Pr e s s  J a n u a r y 1 9 9 4  3 J H Le e   Co m b i n i n g mu ltip le e v id e n c e fro m d if fe re n t propert i es o f w ei ght i n g s chemes  i n Pr o c e e d i n g s o f t h e 1 8 t h annual i n t e rnat i onal A C M S I G I R conf er ence on R e sear c h and de vel opm ent i n i nf orm a t i o n r et ri e v al N e w Y o r k  N Y  U S A  AC M  1 9 9 5  p p  1 8 0  1 8 8  4 D  S h e s k i n  Ha n d b o o k o f P a r a me t r i c a n d N o n p a r a me t r i c St at i s t i c al P r ocedur es  f ourt h edi t i on C h a p m a n  A l l  2007 5 R  A rn o l d a n d S  B o h n e r  Sof t w ar e C hang e I m pact A nal ysi s  Wi l e y I E E E C o m p u t e r S o c i e t y  1 9 9 6   M Kamkar   An o v ervi e w and comparat i v e cl assi  cat i o n o f pr ogr am sl i c i n g t echni ques  J S y s t  S o f t w  v o l 3 1 n o  3  1995 7 L  C  B ri a n d  Y  L a b i c h e  L  O S u l l i v a n  a n d M  M  S  ow ka A u t o m a t e d i m p a c t a n a l y s i s o f U M L m o d e l s   f Syst em s and Sof t w ar e v o l  7 9  n o 3  p p  3 3 9  3 5 2  2 0 0 6  1 8  A  C h e n  E  C h o u  J  W o n g  A  Y  Y a o  Q  Z h a n g  S  Z h a n g  and A  M i c hai l  C V S S ear ch S ear chi n g t hr ough sour ce code usi n g C V S comment s  i n ICSM 01 P r oceedi ngs of 17t h IE E E In t e r n a t i o n a l C o n f e r e n c e o n S o f t w a r e M a i n t e n a n c e  364  M L i ndv al l a nd K S a ndahl   P r act i cal i m pl i cat i ons of t r ace Sof t w ar e—P r act i c e and E x peri ence v o l  2 6 n o 1 0  pp 1161–1180 O c t  1996 0     H o w w e l l d o e x p e ri e n c e d s o ft w a re d e v e l o p e rs p re d i c t soft w a re change J S y s t  S o f t w  v o l 4 3  n o 1  p p  1 9  2 7  1998 1 S L Pﬂe e g e r  Sof t w ar e E ngi neeri ng T h eory and P r act i c e  Up p e r S a d d l e R i v e r  NJ  P r e n t i c e Ha l l  1 9 9 8   H Gal l  K Haj ek and M  J azayeri  Det ect i o n o f l ogi cal coupl i n g b ased on pr oduct r el ease h i s t o r y   i n Pr o c e e d i n g s o f th e I n te r n a tio n a l C o n fe r e n c e o n S o ftw a r e M a in te n a n c e  I C S M 98 1 9 9 8 p p  1 9 0  1 9 7   H Gal l  M Jazayeri  and J  K raj e wski   CVS r el ease h i s t o ry dat a f o r d et ect i n g l ogi cal coupl i ngs  i n 6t h I nt ernat i onal Wo r k s h o p o n P r i n c i p l e s o f S o f t w a r e E v o l u t i o n  I W P S E 2 0 0 3   12 S ept e m b er 2003 H e l s i n ki  F i n l and I E E E C o m p u t e r So c i e t y  2 0 0 3  p p  1 3  2 3  


                        





