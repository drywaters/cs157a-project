Anh N. Tran Department of Mathematics and Computer Science University of Dalat, Dalat, Vietnam anhtn@dlu.edu.vn 
Thong Tran Department of Information Technology University of Dalat, Dalat, Vietnam thongt@dlu.edu.vn 
Structure of Association Rule Set based on Min-Min Basic Rules Tin C. Truong Department of Mathematics and Computer Science University of Dalat, Dalat, Vietnam tintc@dlu.edu.vn  
204 In this paper, we partition the association rule set into disjoint equivalence rule classes. Each of them contains rules having the same confidence and then it is split into basic and consequence rule sets based on the order relation on it 
Abstract 
I I NTRODUCTION The number of association rules found in knowledge discovery problems in data mining is usually enormous [1  Hence, understanding the structure of the association rule set enables us to generate various efficient algorithms to 
In addition, by adding appropriate eliminable itemsets to both sides of basic rules in our algorithm 
Basic rule set, which includes minimal elements according to this relation, is directly found by our algorithm 
Association rule; basic rule;  consequence rule; generator eliminable itemset 
MG_BARS MG_CARS 
the consequence rules are completely and non-repeatedly generated and are confidence-preserved. Results of the experiments proved the efficiency of the above algorithms 
find out the rules. Recently, researchers often split the association rule set into sets of basis and consequent. Taouil et al. [4  pr opo se d a  b a sis for  a ssoc ia ti o n r u le s  I n 3   b a se d on the concept of minimal rules, Pasquier et al. considered basic rules as min-max form \(i.e. left-hand side of the basic rule is minimal and its right-hand side is maximal\Based on the concept of the most general rules, Zaki [6   considered basic rules as min-min form \(i.e. both their lefthand and right-hand sides of the basic rules are minimal However, in order to find out basic rules, Zaki\220s algorithm used many candidates. Moreover, he did not figure out an algorithm that can generate consequence rules from basic rules, whereas the consequence rules together with their 
support and confidence are essential for users In [5  w e p r o p o s e d  alg o r it h m s to co m p le tely an d  quickly find basic rules as min-max form, and thus were able to find their consequence rules. In this paper, we explicitly show the structure of the association rule set by using the concept of basic rules as min-min form. Based on an equivalence relation, the association rule set will be partitioned into disjoint equivalence rule classes. As the result, we need to investigate only the structure of each equivalence rule class independently. Due to this partition efficient parallel algorithms for mining association rules can be easily obtained. After proposing an order relation between rules belonging to the same equivalence rule class we define the basic rules as minimal elements according to 
this relation. The algorithm 
MG_BARS 
is indicated to quickly and directly find basic rules. Then with our algorithm 
by adding eliminable itemsets to both sides of the basic rules, consequence rules are generated Both the basic rules and consequence rules are in the same equivalence class. Hence, the consequence rules are confidence-preserved, non-repeated. Moreover, they are totally different from all rules in other equivalence classes This efficient algorithm helps to reduce a considerable amount of time for mining consequence rules The rest of the paper is organized as follows. Section II recalls some primitive concepts and results of closed and eliminable itemsets in the association rule mining problem Section III presents the structure of the association rule set 
MG_CARS 
A 
2 
2 2 
A 
based on the concept of basic rules as min-min form. It also indicates efficient algorithms for finding rule sets of basis and consequent. Sections IV and V show the experimental results and conclusions II PRIMITIVE CONCEPTS AND RESULTS determined in the following 
is a binary relation in 
2 
x 
Now, consider two set functions 
A Primitive concepts 
O 
 
002 
O A R O O A O 
and 
Given set 
contained transactions and 
contained items related to each of transaction o 
o a 
002 
003 004 002 002 002 002 004 004 
O 
is a closed itemset if h\(A\=A [2   Let s 0 be the minimum support, s 0 
004 
by: h 
R 
A 
o 
O 
is defined as s\(A 
 
A 
O A O 
A 
A 
A}. Defining the set function h in 2 0  T he  su pp or t  of an itemset A 
A\o 
O 
002 
 we say that h\(A\ are the closure of A. An itemset A 
o, a o, a 
002 
A 
  
003 
003 
R 
A 
007\b 
978-1-4244-8075-3/10/$26.00 \2512010 IEEE 
be the class of all closed frequent itemsets Let c 0 be the minimum confidence, c 0 
t 
S\= S\\L. Let r: L 
002 
R denote the rule created by L, R \(or by L, S\. Then, s\(r 
0 For a ny frequent itemset S \(with threshold s 0 we take a non-empty strict subset L from S 
005 006 n 
O 
If s\(A 
CS 
s 0 then A is frequent itemset [1  L e t 
L 


s\(S\ c\(r  S  L\| = s\(S\s\(L\ are the support and confidence of r respectively. The rule r is an association rule if c\(r  c 0 1 Le t  AR_S  AR_S s 0 c 0 be the set of all association rules with thresholds s 0 c 0 Briefly, we call the association rules simply rules. For two non-empty itemsets G, A: G  A  A G is called a generator of A if h\(G\\(A and  G  G h\(G  h\(G\\ [3 Le t  G A\e the class of all generators of A In class 2 A an itemset R is called eliminable in S if R  S and  S  S\\R\et N S\ote the class of all eliminable itemsets in S N S N S  we have [5   N S\A: A  S\\G 0 G 0  G S  B Primitive results Closed mapping h: 2 A 012 2 A generates a binary relation h in class 2 A   A, B  A  A h B  h\(A\ = h\(B  We see that h is an equivalence relation. It partitions 2 A into the disjoint equivalence classes [5  T h e suppor t s o f al l  itemsets in each equivalence class are the same. The equivalence class containing A is denoted as [A   Theorem 1 \(Presentation of itemsets [5    For every itemset A such that  A  CS we have X  A  015 G 0  G A 015 X  N A\: X = G 0 X  1 The above presentation of itemsets is not unique because each itemset can have various generators. Hence, when we mention that R is eliminable in S, we have to assign R to a particular generator of S Proposition 1 \(Support-preserved role of eliminable itemset Adding an eliminable set R of S to R \(R  S  w ill not change its closure, thus will not change its support Proof: h\(R\ = h\(R  R\ = h\(S   R  R  R  S  s\(R  R\ = s\(R  III S TRUCTURE OF ASSOCIATION RULE SET GENERATED FROM MIN MIN BASIC RULES In this section, we will partition the association rule set into disjoint equivalence rule classes using an equivalence relation based on the closures of left-hand side and also of both sides of association rules. Next, we construct an order relation to indicate how to find min-min basic rules by our algorithm MG_BARS Then we suggest the way to derive confidence-preserved consequence rules which belong to the same equivalence rule class as basic rules. Finally, the efficient algorithm MG_CARS to generate non-repeated consequence rules is proposed A Partitioning of association rule set based on equivalence relation    1 The symbol + is denoted as the union of two disjoint sets For a brief notation, let \(L, S\ denote two closed frequent itemsets: L, S  CS   L  S. In [6  an equ iv alen ce  relation was used for partitioning the association rule set into equivalence rule classes. Each of them, based on this relation, contains all rules which have the same support and confidence. Using the equivalence relation in definition 1 the following theorem 2 will show a smoother partition of the rule set AR_S  Definition 1. \(Equivalence relation on association rule set Let r be a binary relation in AR_S determined as follows  L, S, Ls, Ss  A   L  S  Ls  Ss, r:L S\\L s:Ls Ss\\Ls s r r  Ls  L and S s   S   From the above definition, we have theorem 2. Although this theorem is easy to prove it plays an important role in partitioning the association rule set Theorem 2  Partition of the association rule set elation r is an equivalence relation. It partitions AR_S into disjoint equivalence rule classes AR_S L, S\. For each class, we usually consider the representative rule r 0 G L 012 S\\G L  G L  G L\. The rules in AR_S L, S\ have the same support s\(r 0 and confidence c\(r 0 the reverse is not always true AR_S   S  L   S  L  S _ AR  Proof: Consider the rule r:L R, L  L  R    S  Since L and G L belong to  so s  G L s\(L\\(r 0    G L   S\\G L   S  L  R  L  R s\(r\ hence, c\(r 0 r  To investigate the structure of AR_S thoroughly, we need to investigate only the structure of each equivalence rule class AR_S L, S\ independently. Moreover, from this partition, the parallel algorithms are easily generated to quickly find association rules. This is the significance of the equivalence relations and is a typical instance of the divideand-conquer method widely used in computer science Since the size of the paper is limited, we prove only some results related to equivalence rule class AR_S L, S with L  S With L = S, the similar results are easily proved B Basic rules as min-min form In this section, an order relation in each equivalence rule class is obtained to propose basic rule set as min-min basis Then, the algorithm for finding it is also indicated Definition 2 Consider a partial order relation  on AR_S L S\, defined by  r j L j 012 R j  AR_S L, S\, S j L j R j j=1,2 r 1  r 2  L 1  L 2 and R 1  R 2   Basic rule set B L, S\ of AR_S L, S\ contains all minimal rules based on  the relation   B L, S\ = {r 0 L i 012 R i  L i  G L\, R i   R min L i S where R min L i S\e set containing all minimal elements of {S k L i S k L i  S k  G S\according to the normal 


Trans Items  1 ACTW 2 CDW 3 ACTW 4 ACDW 5 ACDTW 6 CDT a\tabase 1 b\ Frequent closed itemset lattice order relation  in the set theory and c\(r 0   r 0  B L, S Similarly  L  CS L  G L B L, L\ = {r 0 L 0 012 a}, L 0  G L  a  L\\L 0  and c\(r 0 1  r 0  B L, L Both sides of all basic rules which Zaki considered the most general rules are minimal. In  he  i n t r od uc ed t h e algorithm GenerateRules to find these rules. However, his algorithm used many candidates \(for the most general rules with the confidence equal to 1\ and operations for finding the closure of itemsets to check unnecessary conditions Based on definition 2, our below algorithm MG_BARS is better. The results of experiments will prove that B L, S MG_BARS L, S 1 B L, S  c  S  L 2 for each \(L i  G L 3 MS := R min L i S 4 for each \(R k  MS 5  B L, S B L, S  L i 012 R k s\(S 6 return B L, S where G L\s found by the algorithm MinimalGenerators   Figure 1 Database 1 and Frequent closed itemset lattice Example 1 Consider database 1 and the corresponding frequent closed itemset lattice in figure 1 \(minimum support s 0 0\where underlined itemsets are generators of corresponding closed itemsets. Consider the pair of closed itemsets \(L, S\where S=ACDTW 2 having G S DTW} and L=ACDW having G L\AD}. We have a basic rule AD 012 T since Minimal{ADT\\AD=T DTW\\AD=TW} = {T From basic rules in B L, S\, based on eliminable itemsets related to them, we will propose efficient methods for non-repeatedly deriving all confidence-preserved consequence rules of C L, S AR_S L, S B L, S   2 a 1 a 2 a n is abbreviated that a 1 a 2 a n C Complete derivation of confidence-preserved consequence rules from basic ones by adding eliminable itemsets From proposition 1  we see that adding appropriate eliminable itemset to both sides of a rule will not change the support of that rule. Hence, its confidence is preserved This is the key point of the methods to generate confidencepreserved consequence rules Definition 3 Consider two set functions that generate consequence rules F L F R  AR_S L, S 012 2 AR_S L, S   r 0 L 0 012 R 0  AR_S L, S F L r 0 r L L 0 L 012 R 0 L  N L\, L  L\\\(L 0 R 0  F R r 0 r R L 0 012 R 0 R | R  N S\ R  S\\\(L 0 R 0  Proposition 2 Obviously, F L r 0  L L 0 L 012 R 0   L  L\\\(L 0 R 0 d F R r 0  R L 0 012 R 0 R  R  S\\\(L 0 R 0 he above definition is correct Proof: Since r 0 L 0 012 R 0  AR_S L, S\o h\(L 0   h\(L 0 R 0  a If  L  L\\\(L 0 R 0 hen L 0  L 0 L  L L 0 R 0  L 0 L+R 0  L+R 0  S. Hence, L = h\(L 0 L\ and h\(L 0 L+R\ = S, i.e., r L  AR_S L, S b If  R  S\\\(L 0 R 0 hen L 0 R 0  L 0 R 0 R  S h\(L 0 R 0 R R  AR_S L, S  Consider equivalence rule class AR_S L, S r  AR_S L, S\e rule sets {r}, F L r\d F R r disjoint because either the left-hand side or right-hand side of any rules in them is different from the other rules F rom each basic rule r 0  AR_S L, S\e  rules in each set F L r 0  R r 0 on-repeatedly generated and have the same confidence as r 0 since they all belong to AR_S L, S Moreover, we have F L  B L, S\\ {r L L i L 012 R ik L i  G L R ik  R min L i S  L  L\\\(L i  R ik   F R  B L,S\F L  B L,S   r R L i L 012 R ik R|L i  G L L  L\\\(L i  R ik  ik  R min L i S  R  S\\\(L i L+R ik   Proposition 3. \(Disjoint splitting of each equivalence rule class AR_S L, S B L,S\ + F L  B L,S F R  B L,S\ F L  B L,S   Proof: Since F L  B L, S\ F R  B L,S\+F L  B L,S  C L, S\, so we need to prove only AR_S L, S  B L,S F L  B L,S\ F R  B L,S L  B L,S   For every r:L 012 R  AR_S L, S\since h\(L\L, L  R  and h\(S\where S=L+R, so there exists L i  G L S k  G S\: L i  S k and S k L i  R. Indeed, if there exists a  S k L i R then a  L and {a}+L i is subset of S k so a}+L i is also generator and {a}+L i  G L\: it contradicts with L i  G L\. With S:=S\\S k we have S=S k S= L i  S k L i S\\\(L i  S k L i S k L i L\\\(L i  S k R\\\(L i  S k  L i L\\\(L i  S k  S k L i R\\\(L i  S k  i L\\L i  


S k L i  R\\S k ince L  R  and S k L i  R so \(L\\\(L i  S k  L\\\(L i S k L i L i and R\\\(L i  S k  R\\S k L i R\\S k  Thus, L=L i L\\L i nd R=\(S k L i R\\S k Let ik be the minimum index of S k such that R ik S ik L i is minimal Then L=L i L, R=R ik R, where L=\(L\\L i nd R R\\S ik Otherwise, with K U,L    L  G L i i L  we have L L\\L i   K U,L L\\\(L i  K U,L  i L   L\\\(L i  R ik   L\\\(L i  R ik here L i K U,L L i L  L\\K U,L  L\\\(K U,L  R ik imilarly, with S U,L+R   R  L  G S k k S   we have R = R\\S ik R\\S ik   S U,L+R R\\\(S ik  S U,L+R S U,L+R,ik S   R\\\(L  S ik   S\\\(L+R ik ere S U,L+R,ik R  S U,L+R S ik  S  R\\S U,L+R Then r:L i L i L  012 R ik S U,L+R,ik S  Let us call r 0 L i 012 R ik  B L,S L L i L i L  012 R ik and r R L i L i L  012 R ik S U,L+R,ik S  We have three following cases a if S U,L+R,ik S    L i L    then r  r 0 L i 012 R ik  B L,S b if S U,L+R,ik S    L i L    then r  r L  F L  B L,S c if S U,L+R,ik S   then r  r R  F R  B L,S L  B L,S  Based on proposition 3, each equivalence rule class AR_S L,S\s split into two disjoint rule sets of basis and consequent. From basic rules, the consequence rules are completely generated and are totally different from the rules of all other equivalence rule classes. However, in each equivalence class the consequence rules generated by the functions F L F R can be repeated. For example, with r 01 and r 02 different but having the same right-hand sides, two rule sets F L r 01 nd F L r 02 can have some identical rules i.e., F L r 01   F L r 02    Example 2 Using the figure 1, we consider S=ADTWC having G S\ADT, TDW} with L=ACTW having G L\={AT, TW}. Since W  L\\\(AT+D\=CW so the basic rule r 1 AT 012 D derives the consequence rule r 1+L ATW 012 D The basic rule r 2 TW 012 D also derives r 1+L Then, S is considered with L=CD where G L\={D}. The consequence rule r 3+R D 012 ATW derived from the basic rule r 3 D 012 AT \(since W  S\\\(D+AT\=CW\ is the same of one consequence rule of the basic rule r 4 D 012 TW D Complete derivation of the non-repeated, confidence preserved consequence rules from basic rules This section proposes different forms of the functions F L F R These forms will non-repeatedly generate all consequence rules in each equivalence rule class. The corresponding algorithms will be shown 1 The non-repeated form F L of F L For every L  CS  L i  G L\ R  A R  L i   denote K U   L  G L i i L  K  R L\\\(K U  R\ K U,Li K U L i  FS_ L i R L i L  L   K  R we define FS1 L i S  L i L i L  R  R min L i S L i L   FS_ L i R  i  K U,Li i=1 or \(i>1 not\(L k  L i L i R  1  k<i and for every L  L\\L i  FS2 L i L  L i L  L i L* | L i L   FS_ L i L L i L  1, |L 1, L  i  K U,Li i=1 or \(i>1 not\(L k  L i L i L  1  k<i Definition 4 Consider r 1 L i 012 R  B L, S\ and r 2 L i 012 a  B L, L\. We define F L r 1   r 1+L L 012 R | L  FS1 L i S\\\{L i  F L L, S    S  L  B r 1  L 1 r F   and F L r 2   r 2+L L 012 a} | L  FS2 L i a F L L, L    L  L  B r 2  L 2 r F    Proposition 4 Replace F L  B L, S\\ith F L L, S\e have: \(a\ The consequence rules in F L L, S\re nonrepeatedly generated b F L L, S\ = F L  B L, S Proof a Assume that 015 i1>i2, i1>1: L i1 L i1 L  i1  L i2 L i2 L  i2 L ik  G L\, L  ik  K  L ik  K U,Lik k=1,2. Since L i2  L  i1   so L i2  L i1 L i1 It contradicts the way selected L i1  b   For every r:L i 012 R  B L, S\sider r L  L i L i L  012 R  F L r\ince  L:=\(L i L    K U,Li K  R  L\\\(L i  R\ so r L  F L r  F L  B L, S     r  F L  B L, S\from theorem 1, let i be the minimum index such that r:L 012 R*, where L=L i O i L i  G L and O i  L\\\(L i  R*\et us call L i O i  K U  K U,Li  L  R O i K U  K  R We have L=L i L i L  R and hence r:L i L i L  R 012 R*. Assume that there exists i>1 and k<i L k  L i L i R*, L k  G L\, hence L k  G L\. Then L=L k O k where O k L k L  R L k L i L i L k  L\\\(L k  R*\nd L  R  L\\\(K U  R  L\\\(L k  R*\o O k  L\\\(L k  R*\tradicts the way selected the i index Therefore, not\(L k  L i L i R  k<i, i.e., r  F L L, S  2 The non-repeated form F R of F R For every L  Left\(L, S\ := {L 015 r:L 012 R   B L,S F L L,S w e den ot e R min L, S\ = {R ik S k L S k  G S\, S k L i is minimal for each L i  G L\}, S U,L      min  S L R R i i R   S U,L,i S U,L R i S  L S\\\(S U,L L\ and Right\(L, S R i R i R  R i  R min L, S\, R i  S U,L,i  R   S  L i=1 or \(i>1: not \(R k  R i R i   1  k<i R i R  1 Definition 5 F R L, S    S  L  Left  L r R L 012 R | R  Right\(L, S and F R L, L  r R L 012 L L i  G L  L\\L i L*|>1, L  FS2 L i L  Similarly to proposition 4, we have proposition 5 


Proposition 5 a\ The consequence rules in F R L, S\are non-repeatedly generated b F R L, S\ = F R  B L,S L  B L,S  Proof a All rules in F R L, S\ave either the left-hand sides in Left\(L, S\ or the right-hand sides in Right\(L, S which are different. Hence, all consequences rules generated in F R L, S\on-repeatedly generated b Obviously by the definitions of F R L, S\ and F R  B L,S\F L  B L,S 3 Complete derivation of non-repeated and confidence-preversed consequence rules Theorem 3 \(Disjoint splitting of non-repeated rules in each equivalence class  AR_S L, S B L, S\ + F L L, S\ + F R L, S Similarly AR_S L, L B L, L\ + F L L, L\ + F R L, L Proof: Consequence of propositions 3, 4 and 5 From the above propositions, the algorithm MG_CARS is suggested for deriving all non-repeated consequence rules C L, S\ in every equivalence rule class AR_S L, S C L, S MG_CARS L, S 1 F L L, S LeftAdding L, S R L, S   2 for each \(L  Left\(L, S 3 F R L, S R L, S RightAdding L, S 4 C L, S L L, S R L, S 5 return C L, S The algorithm RightAdding for finding consequence rule subset F R L, S\s indicated as follows \(the algorithm LeftAdding can be derived in the same way F R L, S RightAdding L, S 1 F R L, S  MS := R min L, S 2 S U,L  MS R i i R  S  L S\\\(K U,L L 3 for each \(R   S  L  4 for each \(R i  MS 5 S U,L,i S U,L R i  6 for each \(R i  S U,L,i o 7 if \(R i  or R   hen 8 Repeated := false 9 if \(i>1\en for each \(R k  MS | k<i 10 if \(R k  R i R i hen 11 Repeated := true 12 break; // for each R k 13 if \(not\(Repeated\en 14 F R L, S R L, S R L 012 R i R i R 15 return F R L, S IV E XPERIMENTAL RESULTS Four benchmark databases in [8 r e use d d u r i ng the s e  experiments. Table I shows their characteristics. The source code of M. J. Zaki [9 i s a l so use d t o fi nd t h e  fr e q ue nt  closed itemset lattice \(Charm-L d g e n e rators   TABLE I D ATABASE CHARACTERISTICS Database \(DB Transaction Items Average size  P 49046 7117 74 M 8124 119 23 Co 67557 129 43 Ch 3196 75 37 Table II shows the experimental results of our approach for finding association rule set based on the basic rules as min-min form. It shows the minimum support and the minimum confidence \(MS=MC\e cardinality of the association rule set \(#Tra\d the cardinality of basic rule set \(#BAR\. Column RT c shows the percent ratio of the time for finding the consequence rules to the one for finding all association rules. The ratio of the basic rules to all association rules and the number of redundant candidates generated in the GenerateRules algorithm are in turn showed in columns R BT and #R z Table II also shows the run time for mining the basic rules by our algorithm MG_BARS T o d the ratio \(RT\ of the one by the GenerateRules T z T o  TABLE II T HE EXPERIMENTAL RESULTS WITH BENCHMARK DATABASES DB MS = MC Tra BAR R BT RT c R z T o s RT Ch 80 552564 316493 0.6 88.9 480 1.07 1.5 Ch 70 8171198 3396360 0.4 91.3 6498 11.34 1.6 Co 97 8092 4621 0.6 88.0 21 0.02 1.5 Co 90 3640704 324974 0.1 96.9 10000 1.00 2.2 M 40 7020 1419 0.2 93.1 26 0.01 1.5 M 20 19191656 59297 0.0 99.9 16166 0.30 8.2 P 95 1170 786 0.7 81.4 0 0.01 2.0 P 85 1408950 727532 0.5 87.4 1368 2.90 1.7 The experimental results show that: first, the algorithm MG_BARS quickly and directly finds basic rules; second the algorithm MG_CARS completely derives all confidence-preserved and non-repeated consequence rules from the basic rules by adding appropriate eliminable itemsets to two sides of them. The total number of rules generated in our approach is the same as the one in the traditional algorithms [6  Figures 2 and 3 show the relation between the cardinality of basic rule set and the one of association rule set and also the effect of minimum confidence on the number of basic rules Figure 2 All rules vs basic rules: Chess and Connect 


Figure 3 All rules vs basic rules: Mushroom and Pumsb Figure 4, 5 and 6 compare the run times for finding the basic rules by the MG_BARS and GenerateRules algorithms on Co \(similar to Ch\, M and P with the different minimum confidences. It shows that the run time of our algorithm MG_BARS is shorter in almost cases Figure 4 The run times of MG_BARS vs GenerateRules Connect Figure 5 The run times of MG_BARS vs GenerateRules Mushroom Figure 6 The run times of MG_BARS vs GenerateRules Pumsb V C ONCLUSION In this paper, based on the eliminable itemset concept  h i c h pl a y s a n i m port an t  rol e i n pres erv i n g  su pport of  itemsets and confidence of rules in each equivalence class an efficient approach for extracting all association rules based on min-min basis is proposed. This approach with four phases is built based on the theoretical results and tested on benchmark databases. The first phase is to partition the association rule set into the disjoint equivalence rule classes. The second one is to disjointly split each of them into two rules sets of min-min basis and consequent. Using the above structures, in the third phase the algorithm MG_BARS which significantly reduces the time for mining basic rules is obtained. And in the last phase, the algorithm MG_CARS that non-repeatedly and completely derive all consequence rules \(together with their support and confidence\rom the basic rules is proposed A CKNOWLEDGMENT We would like to express our sincere thanks to M. J Zaki for his permission of using his source code [9 i n  o u r research. We also would like to thank the Department of Mathematics and Informatics, University of Dalat for their valuable support in the completion of this article R EFERENCES 1 C C. A g g a r w al P  S  Y u  O nl i n e g e ne r a tio n o f asso ci at io n r u l e sŽ in  Proceedings of the international conference on data engineering, pp 402-411, 1998 2 H  T  B a o A n a p p r oa ch  t o c onc ep t form at i on ba s e d on form a l  concept analysis,Ž IEICE Trans. Infor. and systems, vol. E78-D, no 5, 1995 3 N P a sq uie r  R  T a o u il Y   Bas ti de G  S t um m e L   L a khal   Generating a condensed representation for association rulesŽ in J. of Intelligent Information Systems, vol. 24, no. 1, pp. 29-60, 2005 4 R  Ta oui l Y  B a s t id e N. Pa s q ui er  L   L a k h a l M in in g b a s e s for association rules using closed setsŽ in 16 th IEEE Intl. Conf. on Data Engineering, 2000 5 T C. T r uo ng  A  N  Tr an S tr uc tur e o f se t o f asso ciatio n r u l e s base d  on concept latticeŽ in Advances in intelligent information and database systems, pp. 217…227, N. T. Nguyen et al. \(Eds.\, Springer 2010 6 M. J  Z a ki M i n i n g no nr e d u n d a n t as s o ciat io n r u l e s  in D a ta m i n i ng  and knowledge discovery, 9, pp. 223-248, 2004 7 M  J  Z a k i  C J  Hs i a o E ffi ci en t  a l gori t h m s for m i ni n g  c l os ed  itemsets and their lattice structure,Ž IEEE Trans. Knowledge and data engineering, vol. 17, no. 4, 2005 8 F re que nt I t e m s e t Mini ng D a tas e t Re po s i to r y   http://fimi.cs.helsinki.fi/data  2009 9 h tt p  www  c s  rp i ed u za k i  w w w new/pmwiki.php/Software/Software#patutils  


34 P  D a y a n a n d T  S e j n o w s k i  223 T h e v a r i a n c e o f c o v a r i a n c e r u l e s for associative matrix memories and reinforcement learning.\224 Neural Computation  vol 5 pp 205\226209 1993 35 G  P a l m a n d F  S o m m e r  223 A s s o c i a t i v e d a t a s t o r a g e a n d r e t r i e v a l i n neural nets.\224 in Models of Neural Networks III  E Domany J van Hemmen and K Schulten Eds New York Springer-Verlag 1996 pp 79\226118 36 G  C h e c h i k  I  M e i l i j s o n  a n d E  R u p p i n  223 E f f e c t i v e n e u r o n a l l e a r n i n g with ineffective hebbian learning rules.\224 Neural Computation  vol 13 pp 817\226840 2001 37 D  S t e r r a t t a n d D  W i l l s h a w  223 I n h o m o g e n e i t i e s i n h e t e r o a s s o c i a t i v e memories with linear learning rules.\224 Neural Computation  vol 20 pp 311\226344 2008 38 A  L a n s n e r a n d O  E k e b e r g  223 A n a s s o c i a t i v e n e t w o r k s o l v i n g t h e 224 4 bit adder problem\224.\224 in Proceedings of the IEEE First International Conference on Neural Networks  M Caudill and C Butler Eds San Diego CA 1987 pp II\226549 39 227 227  223 A o n e l a y e r f e e d b a c k a r t i 002 c i a l n e u r a l n e t w o r k w i t h a B a y e s i a n learning rule.\224 International Journal of Neural Systems  vol 1\(1 pp 77\22687 1989 40 I  K o n o n e n k o  223 B a y e s i a n n e u r a l n e t w o r k s  224 Biological Cybernetics  vol 61\(5 pp 361\226370 1989 41 227 227  223 O n B a y e s i a n n e u r a l n e t w o r k s  224 Informatica Slovenia  vol 18\(2 pp 183\226195 1994 42 A  L a n s n e r a n d A  H o l s t  223 A h i g h e r o r d e r B a y e s i a n n e u r a l n e t w o r k with spiking units.\224 International Journal of Neural Systems  vol 7\(2 pp 115\226128 1996 43 A  S a n d b e r g  A  L a n s n e r  K  P e t e r s s o n  a n d O  E k e b e r g  223 A p a l i m p s e s t memory based on an incremental Bayesian learning rule.\224 Neurocomputing  vol 32-33 pp 987\226994 2000 44 A  K n o b l a u c h  223 N e u r a l a s s o c i a t i v e n e t w o r k s w i t h o p t i m a l b a y e s i a n learning.\224 Honda Research Institute Europe GmbH D-63073 Offenbach/Main Germany HRI-EU Report 09-02 May 2009 45 S  W a y d o  A  K r a s k o v  R  Q u i r o g a  I  F r i e d  a n d C  K o c h  223 S p a r s e representation in the human medial temporal lobe.\224 Journal of Neuroscience  vol 26\(40 pp 10 232\22610 234 2006 46 A  K n o b l a u c h  223 C o m p a r i s o n o f t h e l a n s n e r  e k e b e r g r u l e t o o p t i m a l bayesian learning in neural associative memory.\224 Honda Research Institute Europe GmbH D-63073 Offenbach/Main Germany HRI-EU Report 10-06 April 2010 47 227 227  223 N e u r a l a s s o c i a t i v e m e m o r y w i t h o p t i m a l b a y e s i a n l e a r n i n g  224 submitted  pp 226 2010 48 227 227  223 O n t h e c o m p u t a t i o n a l b e n e 002 t s o f i n h i b i t o r y n e u r a l a s s o c i a t i v e networks.\224 Honda Research Institute Europe GmbH D-63073 Offenbach/Main Germany HRI-EU Report 07-05 May 2007 49 A  K n o b l a u c h a n d G  P a l m  223 P a t t e r n s e p a r a t i o n a n d s y n c h r o n i z a t i o n in spiking associative memories and visual areas.\224 Neural Networks  vol 14 pp 763\226780 2001 50 T  S e j n o w s k i  223 S t o r i n g c o v a r i a n c e w i t h n o n l i n e a r l y i n t e r a c t i n g n e u rons.\224 Journal of Mathematical Biology  vol 4 pp 303\226321 1977 51 227 227  223 S t a t i s t i c a l c o n s t r a i n t s o n s y n a p t i c p l a s t i c i t y  224 Journal of Theoretical Biology  vol 69 pp 385\226389 1977 52 D  W i l l s h a w a n d P  D a y a n  223 O p t i m a l p l a s t i c i t y i n m a t r i x m e m o r i e s  what goes up must come down.\224 Neural Computation  vol 2 pp 85\226 93 1990 53 G  P a l m a n d F  S o m m e r  223 I n f o r m a t i o n c a p a c i t y i n r e c u r r e n t McCulloch-Pitts networks with sparsely coded memory states.\224 Network  vol 3 pp 177\226186 1992 54 B  G r a h a m a n d D  W i l l s h a w  223 I m p r o v i n g r e c a l l f r o m a n a s s o c i a t i v e memory.\224 Biological Cybernetics  vol 72 pp 337\226346 1995 55 H  M a r k r a m  M  T o l e d o R o d r i g u e z  Y  W a n g  A  G u p t a  G  S i l b e r b e r g  and C Wu 223Interneurons of the neocortical inhibitory system.\224 Nature Reviews Neuroscience  vol 5 pp 793\226807 2004 56 H  Z h a n g  223 T h e o p t i m a l i t y o f n a i v e b a y e s  224 i n Proceedings of the 17th Florida Arti\002cial Intelligence Research Society Conference  V Barr and Z Markov Eds AAAI Press 2004 pp 562\226567 57 P  D o m i n g o s a n d M  P a z z a n i  223 O n t h e o p t i m a l i t y o f t h e s i m p l e Bayesian classi\002er under zero-one loss.\224 Machine Learning  vol 29 pp 103\226130 1997 58 G  P a l m  223 L o c a l s y n a p t i c r u l e s w i t h m a x i m a l i n f o r m a t i o n s t o r a g e capacity.\224 in Neural and synergetic computers  ser Springer Series in Synergetics H Haken Ed Berlin Heidelberg New York Springer Verlag 1988 vol 42 pp 100\226110 59 D  G o l o m b  N  R u b i n  a n d H  S o m p o l i n s k y  223 W i l l s h a w m o d e l  A s s o ciative memory with sparse coding and low 002ring rates.\224 Phys Rev A  vol 41 pp 1843\2261854 1990 60 A  H o l t m a a t a n d K  S v o b o d a  223 E x p e r i e n c e d e p e n d e n t s t r u c t u r a l s y n a p tic plasticity in the mammalian brain.\224 Nature Reviews Neuroscience  vol 10 pp 647\226658 2009 61 A  K n o b l a u c h  223 S y n c h r o n i z a t i o n a n d p a t t e r n s e p a r a t i o n i n s p i k i n g associative memory and visual cortical areas.\224 PhD thesis Department of Neural Information Processing University of Ulm Germany  2003 62 227 227  223 O n c o m p r e s s i n g t h e m e m o r y s t r u c t u r e s o f b i n a r y n e u r a l a s s o ciative networks,\224 Honda Research Institute Europe GmbH D-63073 Offenbach/Main Germany HRI-EU Report 06-02 April 2006 63 227 227  223 N e u r a l a s s o c i a t i v e m e m o r y a n d t h e W i l l s h a w P a l m p r o b a b i l i t y distribution.\224 SIAM Journal on Applied Mathematics  vol 69\(1 pp 169\226196 2008 64 227 227  223 T h e r o l e o f s t r u c t u r a l p l a s t i c i t y a n d s y n a p t i c c o n s o l i d a t i o n f o r memory and amnesia in a model of cortico-hippocampal interplay.\224 in Connectionist Models of Behavior and Cognition II Proceedings of the 11th Neural Computation and Psychology Workshop  J Mayor N Ruh and K Plunkett Eds Singapore World Scienti\002c Publishing 2009 pp 79\22690 65 227 227  223 Z i p n e t s  E f 002 c i e n t a s s o c i a t i v e c o m p u t a t i o n w i t h b i n a r y synapses.\224 in Proceedings of the International Joint Conference on Neural Networks IJCNN 2010  2010 


   Table 4. Normalized Criteria Comparison Table In AHP   Reusability Meeting Operational Requirements Meeting project Deadline Reusability 0.157 0.148 0.272 Meeting Operational Requirements 0.789 0.744 0.636 Meeting Project Deadline 0.052 0.106 0.090  Table 3 and Table 4 show the weight values of the three criterions as compared to each other using the AHP process. These weights have been decided by the stakeholders after discussions among themselves Average weights can be derived from Table 4 as follows Reusability- 0.193 Meeting Operational Requirements- 0.724 Meeting Project Deadline- 0.083 These weights represent the priority of each criterion on a scale of 0 to 1  5.3. Argumentation Tree  We develop argumentation tree for each and every alternative separately. The ar guments are stated by stake holders and assembled under the alternative but they target a specific cr iterion. These arguments can either be supporting or attacking each other or their respective alternative nodes. We present three figures, where each figure represents the argumentation hierarchy for one alternative. Rectangular boxes represent the alternatives with the name of the alternative under it. Ovals represent the criteria with their descr iption. The arguments are specified by labels A, B, C for alternative Adobe flashŽ, Adobe DirectorŽ and Open GLŽ respectively Along with the labels, the arguments also have indexes associated with them. Beneath the labels are two boxes The box on left shows the weight of the argument whereas the box on right shows the priority of the stakeholder who specifies the argument  Once the argument has been sp ecified, the user enters its weight. We first reassess the weights of the arguments using priority reassessment discussed in h e n us ing the techniques specified in [11 w e red u ce t h e arg u m e n t s  to a single level. Finally, the weighted summation of the arguments with the criteria weights helps us evaluate the final weights for the decision matrix. It is important to note here that, the aggregation method used for calculating the favorability is a weighted summation  The three argumentation hierarchies for the three alternatives are presented in the Figures 7, 8, and 9. The diagrams contain arguments, their weights and the stakeholders priorities     Figure 7. Argumentation Tree For Adobe Flash   Figure 8. Argumentation Tree For Adobe Director 150 


     Figure 9. Argumentation Tree For Open GL  A1 The current system in flash does not have the functionality of dynamic allocation of particles like mine or clutter. It places them randomly  A1.1 That is not of much importance because it still gives a new position to mine and clutter particles A2 Current system in flash has faster response time as compared to system in Adobe Director A3 The current system doesnt satisfy many of the features required for the new system like database A4 Adobe Flash cannot communicate with database A4.1 Flash doesnt support database but database support is very important and critical A4.1.1 The system should be able to generate evaluation reports for trainee based on pr evious records stored in the database A5 Flash doesnt create sound clips  A5.1 We dont need sound creating features as the sys tem has to generate sound. We can play externally recorded sound files using Adobe Flash A6 Flash can provide good visual effects as compared to Adobe Director A7 The developer has good knowledge in development using Flash so the system can be developed quickly B1 We could reuse the system already developed for sound generation, as it is developed using Adobe Audition for analysis which is somehow related to Adobe Director B1.1 The current system is better synthesized in terms of sound production and the sound produced is also instantaneous rather than discrete B1.2 That current system has certain performance issues like slow response time B1.3 The current system in Adobe Director has the feature of producing dynamic coloring scheme on approaching a mine. This kind of scheme is highly preferable and is not present in Adobe Flash system B2 Adobe Director can provide more functionality as compared to the current flash system. E.g. Multiple sounds while detecting mines   B2.1 Adobe Director can provide better visual effects as compared to flash e.g. in case of GUIs   B2.2 A modified version of the current system in flash can also provide the same functionality B2.2.1 We cannot integrate code developed in other platforms with Flash, but Flash can be integrated in Adobe Director B3 The interface provided by flash is not professional enough. It is too simple and straight forward for doing more things in future   B4 Easily available plug-ins can help integrate the tracking system developed in C# with Adobe Director  B4.1 Code developed in Open GL/AL can also be integrated using Adobe Director using suitable stubs   B5 A new sound recognition algorithm is being developed in Adobe Audition which can be integrated with Adobe Director but not with Open GL or Flash Evidence supported B6 If the current system is reused; the project deadline can be met easily B7 The developer has very little experience in development using Adobe Director   B7.1 The developer can take help from the already developed system in Adobe Director C1 The tracking software already developed is coded in C#/NX5. We could reuse that and develop our system in Open GL/AL C1.1 Open GL has C# libraries which can be used to develop the system C2 Because the platform used is for high end application development, it can provide good GUI and database support C2.1 Open GL/AL can help us generate dynamic surfaces for mine detection and training which the original system in flash does not have C4 Open GL does not support connectivity with Adobe Audition. Adobe Audition is required for creating sound recognition algorithm C3 Open GL does not support connectivity with Adobe Audition. Adobe Audition is required for creating sound recognition algorithm C4 The time taken for developing the project using open GL will be comparatively more as the whole system would have to be developed from scratch C4.1 If Open GL has support for C# libraries, and then the system could be develope d faster as developer is quite familiar with programming languages like C 151 


   C4.2 Open GL has excellent documentation that could help the developer learn the platform with ease C4.3 Developer has very little ex perience in working with Open GL platform  For our case study, alternative B i.e. Adobe Director was the most favorable alternative amongst all the three. It catered to the reusability criteria quite well and aimed at meeting most of the desired operational requirements for the system   6. CONCLUSION & FUTURE WORK  The main contribution of this paper is to develop an approach for evaluating performance scores in MultiCriteria decision making using an intelligent computational argumentation network. The evaluation process requires us to identify performance scores in multi criteria decision making which are not obtained objectively and quantify the same by providing a strong rationale. In this way, deeper analysis can be achieved in reducing the uncertainty problem involved in Multi Criteria decision paradigm. As a part of our future work we plan on conducting a large scale empirical analysis of the argumentation system to validate its effectiveness   REFERENCES  1  L  P Am g o u d  U sin g  A r g u men ts f o r mak i n g an d  ex p lain in g  decisions Artificial Intelligence 173 413-436, \(2009 2 A  Boch m a n   C ollectiv e A r g u men tatio n    Proceedings of the Workshop on Non-Monotonic Reasoning 2002 3 G  R Bu y u k o zk an  Ev alu a tio n o f sof tware d e v e lo p m en t  projects using a fuzzy multi-criteria decision approach Mathematics and Computers in Simualtion 77 464-475, \(2008 4 M T  Chen   F u zzy MCD M A p p r o ach t o Selec t Serv ice  Provider The IEEE International Conference on Fuzzy 2003 5 J. Con k li n  an d  M. Beg e m a n   gIBIS: A Hypertext Tool for Exploratory Policy Discussion Transactions on Office Information Systems 6\(4\: 303  331, \(1988 6 B P  Duarte D e v elo p in g a p r o jec ts ev alu a tio n sy ste m based on multiple attribute value theroy Computer Operations Research 33 1488-1504, \(2006 7 E G  Fo rm an  T h e  A n a l y t ic Hier a rch y P r o cess A n  Exposition OR CHRONICLE 1999 8 M. L ease  an d J L  L i v e l y  Using an Issue Based Hypertext System to Capture Software LifeCycle Process Hypermedia  2\(1\, pp. 34  45, \(1990 9  P e id e L i u   E valu a tio n Mo d e l o f Custo m e r Satis f a c tio n o f  B2CE Commerce Based on Combin ation of Linguistic Variables and Fuzzy Triangular Numbers Eight ACIS International Conference on Software Engin eering, Artificial Intelligence Networking and Parallel Distributed Computing, \(pp 450-454 2007  10  X  F L i u   M an ag e m en t o f an In tellig e n t A r g u m e n tatio n  Network for a Web-Based Collaborative Engineering Design Environment Proceedings of the 2007 IEEE International Symposium on Collaborative Technologies and Systems,\(CTS 2007\, Orlando, Florida May 21-25, 2007 11 X. F L i u   A n In ternet Ba se d In tellig e n t A r g u m e n tatio n  System for Collaborative Engineering Design Proceedings of the 2006 IEEE International Symposium on Collaborative Technologies and Systems pp. 318-325\. Las Vegas, Nevada 2006 12 T  M A sub jec tiv e assess m e n t o f altern ativ e m ission  architectures for the human exploration of Mars at NASA using multicriteria decision making Computer and Operations Research 1147-1164, \(June 2004 13 A  N Mo n ireh  F u zzy De cisio n Ma k i n g b a se d o n  Relationship Analysis between Criteria Annual Meeting of the North American Fuzzy Information Processing Society 2005 14 N  P a p a d ias HERMES Su p p o rti n g A r g u m e n tative  Discourse in Multi Agent Decision Making Proceedings of the 15th National Conference on Artifical Intelligence \(AAAI-98  pp. 827-832\dison, WI: AAAI/MIT Press,  \(1998a 15  E. B T riantaph y llo u   T h e Im p act o f  Ag g r e g atin g Ben e f i t  and Cost Criteria in Four MCDA Methods IEEE Transactions on Engineering Management, Vol 52, No 2 May 2005 16 S  H T s a u r T h e Ev alu a tio n o f airlin e se rv ice q u a lity b y  fuzzy MCDM Tourism Management 107-115, \(2002 1 T  D W a n g  Develo p in g a f u zz y  T O P S IS app r o ach  b a sed  on subjective weights and objective weights Expert Systems with Applications 8980-8985, \(2009 18 L  A  Zadeh  F u z z y Sets   Information and Control 8  338-353, \(1965  152 


                        





