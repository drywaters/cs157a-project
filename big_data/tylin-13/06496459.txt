Proceedings of the 2013 International Conference on Pattern Recognition, Informatics and Mobile Engineering, February 21-22   978-1-4673-5845-3/13/$31.00©2013 IEEE   Data Integrity and Data Dynamics with Secure Storage Service in Cloud R. Nithiavathy Department of Computer Science and Engineering Coimbatore Institutue nad Engineering and Technology nithia19@gmail.com    Abstract  The current utilization of the spectrum is quite inefficient; consequently, if properly used, there is no shortage of the spectrum that is presently available. Therefore, it is anticipated that more flexible use of spectrum and spectrum sharing between radio systems will be key enablers to facilitate the successful implementation of future systems. Cognitive radio however, is known as the most intelligent and promising technique in solving the problem of spectrum sharing. In this paper, we consider the technique of spectrum sharing among users of service providers to share the licensed spectrum of licensed service providers. It is shown that the proposed technique rCloud computing is upcoming technology which has gained a lot of hype in the current world of I.T. Cloud computing is said to be the next big thing in the computer world after the internet. Though the benefits are huge, such a service is also relinquishing users’ physical possession of their outsourced data which inevitably poses new securi ty risks towards the correctness of the data in cloud. In order to address this new problem and further achieve a secure and dependable cloud storage service We propose in this paper a flexible distributed storage integrity auditing mechanism, utilizing the homomorphic token and distributed erasure-coded data for dynamically storing data. The proposed design allows users or third party auditor to audit the cloud storage with very lightweight communication and less computation cost. The auditing result  ensures reliable cloud storage correctness ,and simultaneously achieves fast data error localization, i.e., finding which server is misbehaving in the fast rapidly changing its data in the cloud and  the user ‘s application stored in cloud, it also supports efficient dynamic operations on outsourced data which is secured , including, deletion, and append ,block modification and resilient against Byzantine failure, malicious data modification attack, and even server colluding attacks Keywords- Error localization; data dynamics; Cloud Computing;  Data Integrity;  storage; Audit  I  I NTRODUCTION  Cloud is a large scale pool of computing service. The Cloud helps enterprises are d ynamically scalable abstracted computing infrastructure that is available on-demand and on a pay-per-use basis. This model not only saves the IT teams from investing heavily on infrastructure, but also shields them from the intricacies involved in infrastructure setup and management. The increasing network bandwidth and reliable yet flexible network connections make it even possible that  users can now subscribe high quality services from data and software that reside solely on remote data centers Although the cloud Infrastructures are much more efficient and reliable, powerful than our personal computing devices, it encounters range of both internal and external threats for data integrity still exist more in cloud   To make sure of the correctness of storage without the users possessing their own data it is difficult to address all data security threats in cloud storage as all concentrated in single server scenario and not consider dynamically changing data and its operation. By using distributed protocols for maintaining storage correctness in the multiple server or peers  e  pro pose a co n c rete, f l ex ible and effective scheme with explicit dynamic data support to maintain the integrity of the user data in the cloud. We use erasure- correcting code in the distribution of the file in the cloud to avoid redundancies which increases the data depe ndencies. It overcomes the communication overheads of the traditional replication based techniques of file distribution Token utilization is used with distributed verification of the erasure  coded data which ensures the storage correctness and data error localization. The da ta corruption that has been detected during the verification of the correctness of the stored data is localized, which guar antee the data error localization simultaneously. It identifies the misbehaving server\(s th e  verification is done without explicit knowledge of the data files We use third party auditing where the user can delegate them to check the integrity of data’s in the cloud storage and be worry free. The main contribution can be recapitulated as the following aspects   Compared to its predecessors they only provide binary results about the data storage status across the distributed servers, the protocol used in our work provides point of data erro r \(i.e. Error Localization   We provide secure and efficient dynamic operations on data blocks like update append and delete   The security and performance analysis shows the proposed scheme is highly efficient and resilient against Byzantine failure, malicious data modification attack, and even server colluding attacks 


2013 International Conference on Pattern Recognition, Informatics and Mobile Engineering \(PRIME\      126   The rest of the paper is organized as follows: Section II introduces the system model, adversary model, our design goal, and notations.  In section III we provide the detailed description of our scheme. Section IV deals with providing dynamic data operation support, followed by Section V which overviews security issues and performance analysis. Finally Section VI gives the concluding remark of paper II  P ROBLEM S TATEMENT  A. System Model 1. User: Users may be a pers on or an organization that have data to be stored in the cloud and rely on the cloud for data computation 2. Cloud Service Provider \(CSP\ CSP has significant resources and expertise in building and managing distributed cloud storage servers, owns and operates live Cloud Computing systems 3. Third  party Auditor \(TPA\o is expertise and capabilities that the user does not have and they are trusted to access and expose to the risk of cloud storage service for users Data storage in a cloud is wh ere the user stores his data through a CSP into a set of cloud servers, which are running concurrently, cooperated and in distributed manner. The redundancy of the data can be employed with technique of erasure-correcting code to furt her tolerate faults or server crash as user’s data grows in size and importance  Thereafter, for application purposes the user interacts with the cloud servers via CSP to access or retrieve his data. In some cases, the user may need to perform block level operations on his data. The most general form s of these operations we are considering are block revise, erase, insert and affix It is of critical importance to assure users that their data are being correctly stored and maintains, as users no longer possess their data locally, That is, users should be prepared with security means so that they can make continuous correctness assurance of their data stored in Cloud Servers even without the existence of local copies. In case those users do not necessarily have the time, feasibility or resources to monitor their data, they can delegate the tasks to an optional trusted Third Party Auditor of their respective choices. In our model we assume that the third party auditor behalf of the user communication channels between each cloud server and the user is authenticated and reliable, which can be achieved in practice with little overhead        B. Adversary Model All kinds of threats toward his cloud data integrity are found in the adversary model from the user‘s view. The cloud data do not reside at user’s local site but at CSP’s address domain, these threats can come from two different sources internal and external attacks. For internal attacks, a CSP can be self-interested, untrusted, and possibly malicious; it may also attempt to hide a data loss incident due to management errors, Byzantine failures, and so on. For external attacks, data integrity threats may come from outsiders who are beyond the control domain of CSP, for example, the economically motivated attackers. They may compromise a number of cloud data storage servers in diff erent time intervals and subsequently be able to m odify or delete users’ data while remaining undetected by CSP Therefore, we consider the adversary in our model has the following capabilities, the cloud data integrity is maintained by capturing both external and internal threats Continuously corrupting th e user’s data files by a dversary in the individual storage servers can cause loss of integrity of data. The server can pollute the original data files by modifying or introducing its own fraudulent data to prevent the original data from being retrieved by the user. This corresponds to the threats from external attacks. In the worst case scenario, the adversary can compromise all the storage servers so that he can intentionally modify the data files as long as they are internally consiste nt. In fact, this is equivalent to internal attack case where all servers are assumed colluding together from the early stages of application or service deployment to hide a data loss or corruption incident C. Proposed CR Nodes Sensing To design efficient mechanisms for dynamic data verification and operation and achieve the following goals i  Storage accuracy: To ensure users that their data are indeed stored appropriately and kept intact all the time in the cloud ii  Fast localization of data error To effectively locate the mal- functioning server when data corruption has been detected iii  Dynamic data support: To maintain the same level of storage correctness assurance even if users modify, erase or affix their data files in the cloud iv  Dependability: to enhance data availability against Byzantine failures, malicious data modification and server colluding attacks, i.e. minimizing the effect brought by data errors or server failures v  Lightweight: To enable users to perform storage correctness checks with minimum overhead D.  Notation and Preliminaries  F  Data file to be stored. F is denoted as a matrix of m equal-sized data vectors, each consisting of l blocks A  Scattering matrix used for coding G  Encoded file matrix, which includes a set of n = m + k vectors, each consisting of l blocks f  Function, which is defined as f : {0, 1} × key      Figure 1. System Model   TPA     C loud  Data   TPA     Cloud  Initialization Initialization Challenge Proof 


2013 International Conference on Pattern Recognition, Informatics and Mobile Engineering \(PRIME\      127   key \(.\- Pseudorandom function \(PRF Ver-version number of individual block Sij-seed for PRF which depend on name, block index i server position j and version number III  S ECURE D ATA S TORAGE IN C LOUD  The users store their data in th e cloud server which is no longer available locally at the user side. Thus, the integrity and availability of the data files being stored on the distributed cloud servers must be guaranteed. One of the key issues is to effectively detect any unauthorized data modification and corruption, possibly due to server compromise and/or random Byzantine failur e sid e s, in th e distribu ted case w h en  such inconsistencies are successfully detected, to find which server the data error lies in is also of great significance, since it can be the first step to fast recover the storage errors. To address these problems, our main scheme for ensuring cloud data storage is presented in this section. The first part of the section is devoted to a review of basic tools from coding theories that are needed in our scheme for file distribution across cloud servers. Then, the homomorphic token is introduced. The token computation function we are considering belongs to a family of universal hash function chosen to preserve the homomo rphic properties, which can be perfectly integrated with the verification of erasure-coded data Subsequently, it is also shown how to derive a challenge response protocol for verifying the storage correctness as well as identifying misbehaving server s by third party auditing Finally, the procedure for file retrieval and error recovery based on erasure-correcting code is outlined A Preparation of file distribution  To tolerate multiple failures in the distributed storage system we use erasure  correcting code. The technique is to dispraise the data file F redund antly across a set of n=m+k distributed server. Reed Solomon erasure code is used  for creating k redundancy parity vectors from m data reconstructed from any m out of m+k data h a n d le the failure  without any data loss Vandermonde matrix is used for dispersal matrix A is derive from m x \(m+k\is is the layout of parity vector. The A matrix is written after the transformation as \(I/P\, where I is identity matrix and P is the secret parity vector. By multiplying F by A, the user obtains the encoded file, where F is the files to be stored in the cloud The multiplication reproduces the original data file vectors of F and the remaining are k parity Vectors generated based on F B.    Token exactness Verification of tokens is done in order to achieve data storage correctness and d ata error localization, the precomputed verification tokens for each data files that stored in cloud. Before file distribution the user pre-computes a certain number of short verification tokens on individual; each token covers a random subset of data blocks. Later, when the user or the third party auditor makes su re the storage correctness for the data in the cloud, they challenge the cloud servers with a set of randomly generated block indices. After getting assurance of the user it again asks for authentication by which the user is confirmed to be the authenticated user. Upon receiving assurance, each cloud server computes a short signature” over the specified blocks and returns them to the user. The values of these signatures should match the corresponding tokens pre-computed by the user. Meanwhile as all servers operate over the same subset of the indices, the requested response values for integrity check must also be a valid codeword determined by a secret matrix Suppose the user wants to ch allenge the cloud server’s t times to make sure the correctness of data storage. Then, he must pre-compute t verification tokens for each function, a challenge key and a master key are used. To generate the i th token for server j, the user acts as follows I. Derive an arbitrary valu e i and a permutation key based on master permutation key II. Compute the set of randomly-chosen indices III. Calculate the token using encoded file and the arbitrary value derived Algorithm 1 Token Pre-computation 1. Procedure 2. Choose parameters l, n and function f 3. Choose the number t of tokens 4. Choose the number r of indices per verification 5. Generate master key and challenge key 6. for vector G\(j\j 1, n do  7. for round i 1, t do  8. Derive i = f\(i\\(i\rom master key 9. Compute v \(j 10. end for 11. end for 12. Store all the vis locally 13. end procedure Blinding the each parity block is important after the token precomputing; this is done for protection of secret matrix P. we use HMAC for parity blinding. The encode vector is dispersed in the cloud server. This can be done by the user or delegate the challenging responsibility to third party auditor C.    Correctness Verification and Error Localization  The key requirement of Erro r localization is to eradicating errors in storage systems. Pr evious schemes do not explicitly consider the problem of data error localization effectively Thus it only provides binary results for the storage verification.  Integration of all correctness verifications, error localization in our challenge-resp onse protocol is done. The determination of the correctness of the distributed storage, and also contain information to loca te potential data error\(s\ith 


2013 International Conference on Pattern Recognition, Informatics and Mobile Engineering \(PRIME\      128   response values from servers for each challenges. The procedure of the ith challenge-response for a cross-check over the n servers is described as follows i\The user reveals the i as well as the ith key k \(i servers ii\he server storing vector G aggregates those r rows iii\ied by index k\(i\nto a linear combination R iv\on receiving R is from all the servers, the user takes away values in R v\ Then the user verifies whether the received values remain a valid codeword determined by secret matrix Because all the servers operate over the same subset of indices, the linear aggregation of these r specified rows \(R\(1 R\(n\has to be a codeword in the encoded file matrix If the above equation holds, the challenge is passed Otherwise, it indicates that amon g those specified rows, there exist file block corruptions. Once the inconsistency among the storage has been successfully detected, we can rely on the precomputed verification tokens to further determine where the potential data error\(s\. Note th at each response R\(j\ i is computed exactly in the same way as token v\(j\ i , thus the user can simply find which server is misbehaving by verifying the following n equations Algorithm 2: Correctness Verification and Error Localization procedure CHALLENGE\(i 1  Recompute i = fl \(i\\(i\master key 2  Send {i, k\(i\e cloud servers 3  Receive from servers R 4  for \(j m + 1, n\ do  5  R\(j R\(j Prq=1 fkj \(sIq,j\·_qi , Iq = _k\(i\p\(q  6  end for 7  if \(\(R\(1\\(m\P==\(R\(m+1\\(n then 8  Accept and ready for the next challenge 9  else 10   for \(j 1, n\ do  11  if \(R ! =V \en 12  return server is misbehaving 13  end if 14  end for 15  end if 16  end procedure    D  File  retrieval and  error recovery Spot-checking is randomly done for storage correction assurance.  The user can alwa ys ask servers to send back blocks of the r rows specified in the challenge and regenerate the correct blocks by erasure correction. The newly recovered blocks can then be redistributed to the misbehaving servers to maintain the correctness of storage Algorithm 3: Error Recovery 1: procedure Assume the block corruptions have been detected among % the specified r rows assumes s <= k servers have been identified misbehaving 2: Download r rows of blocks from servers 3: Treat s servers as erasures and recover the blocks 4: Resend the recovered blocks to corresponding servers 5: end procedure  E  Third Party Auditing Our protocol can support privacy-preserving Third party auditing. Encoding procedure in file distribution after blinding data vector, then the storage verification task can be successfully delegated to third party auditing in a privacypreserving mann  T h e f o llo w i ng i s th e protoco l   1. The user blinds each file block data before file distribution k is the secret key for data vector is generated 2. Based on the blinded data vector, the User generates k parity vector via the secret matrix P 3. The user calculates the ith token for server j as previous scheme 4. The user sends the token secret matrix P, permutation and challenge key K master key and k chal to TPA for auditing delegation The blinding values in the servers are not taken by TPA response of the server are verified directly. As TPA does not know the secret blinding key there is no way for TPA to learn the data content information during auditing process. Thus the privacy-preserving third party auditing is achieved  IV  P ROVIDING D YNAMIC D ATA O PERATION S UPPORT  So far, we assumed that F represents archived data However, in cloud data storage, there are many potential scenarios where data stored in the cloud is dynamic, like electronic documents, photos, or lo g files etc. Therefore, it is crucial to consider the dynamic case, where a user may wish to perform various block-level operations of revise, erase and 


2013 International Conference on Pattern Recognition, Informatics and Mobile Engineering \(PRIME\      129   affix to modify the data file while maintaining the storage correctness assurance The straightforward and insignificant way to support these operations is for user to download all the data from the cloud servers and re-compute the whole parity blocks as well as verification tokens. This would clearly be highly inefficient In this section, we will show how efficiently handle dynamic data operations for clo ud data storage A  Revise Operation In cloud data storage, someti mes the user may need to modify some data block\(s\ in the cloud, from its current value f to a new one; this is operation as data revise B  Erase Operation Sometimes, after being stored in the cloud, certain data blocks may need to be eras ed. The erase operation we are considering is a general one in which user replaces the data block with zero or some spe cial reserved data symbol. From this point of view, the erase operation where the original data blocks can be replaced with zeros or some predetermined special blocks C  Append Operation Adding blocks at the end of the data file when user like to extend, which we refer as data append. We anticipate that the most frequent append operation in cloud data storage is bulk append, in which the user needs to upload a large number of blocks \(not a single block\one time D  Update Operation The user may need to modify some data block\(s\ in the cloud, after modification the block is updated. The random blinding information on parity blocks by subtracting the old and newly updated parity blocks. As a result, the secret matrix P is still being well protected and the guarantee of storage correctness remains V  S ECURITY I SSUES AND P ERFORMANCE A NALYSIS  In this section, we analyze our proposed scheme in terms of security and efficiency. Generally, the checking scheme is secure if \(i\here exists no polynomial-time algorithm that can cheat the verifier with non-negligible probability; \(ii\there exists a polynomial-time extractor that can recover the original data files by carrying out multiple challenges-responses. We also evaluate the efficiency of our scheme via implementation of both file distribution preparation and verification token precomputation A  Security Strength against Weak Antagonist i\ication Probability for Misbehaving Servers We have shown that, if the antagonist modifies the data blocks among any of the data storage servers, our sample checking scheme can successfully detect the attack with high probability ii\ Probability against data modification In our scheme, servers are requ ired to operate on specified list of tokens. These selected tokens greatly reduce the computational overhead on the server, while maintaining the detection of the data corruption with high probability. Note that if none of the specified r rows in the ith verification process are erased or modif ied, the antagonist avoids the detection As long as the data modification is caught, the user will further determine which server is malfunctioning. This can be achieved by comparing the response values R with the prestored tokens v. The proba bility for error localization or identifying misbehaving server\(s\ be computed in a similar way. It is the product of the matching probability for sampling check and the probability of complementary event for the false negative result Next, we consider the fake denial probability that R\(j\=v\(j\ when at least one of z blocks are modified. Thus, the identification probability for misbehaving server\(s\ is predicted B  Security Strength against Strong Antagonist We analyze the security strength of our schemes against server colluding attack and explain why blinding the parity blocks can help improve the security strength of our proposed scheme. Redundancy parity vectors are calculated via multiplying the file matrix F by P, where P is the secret parity generation matrix we later relies on for storage correctness assurance. If we disperse all the generated vectors directly after token pre-computation, i.e., without blinding, malicious servers that collaborate can reco nstruct the secret P matrix easily: they can pick blocks from the same rows among the data and parity vectors to es tablish a set of m · k linear equations and solve for the m · k entries of the parity generation matrix P. Once they have the knowledge of P those malicious servers can consequently modify any part of the data blocks and calculate the corresponding parity blocks and vice versa, making their codeword relationship always consistent. Therefore, our storage correctness challenge scheme would be damaged even if those modified blocks are covered by the specified rows, the storage correctness check equation would always hold. To prevent colluding servers from recovering P and making up consistently-related data and parity blocks, we utilize the technique of adding random perturbations to the encoded file matrix and hence hide the secret matrix P. We make use of a keyed pseudorandom function f with key k, both of which has been introduced previously C  Performance Evaluation File Distribution Preparation is implemented for the generation of parity vectors for our scheme we use HMAC for parity blinding which improves cost. This experiment is conducted using JAVA on a system with an Intel Core 2 processor running at 1.86 GHz, 2048 MB of RAM and 250 GB Serial ATA drive. Thus the cost decreases when more data vectors are involved. The performance of our scheme is comparable and evens our sc heme supports dynamic data operation while other are for static data only. Challenge Token Pre-computation: In our scheme we use fixed number of 


2013 International Conference on Pattern Recognition, Informatics and Mobile Engineering \(PRIME\      130   verification on token t that is determined before file distribution; we can overco me this issue by choosing sufficient large t in practice  C ONCLUSION  In this paper, we studied the problem of data security in data storage in cloud servers. To guarantee the correctness of users data in cloud data storage deleg ating TPA, we proposed an effectual and flexible scheme with explicit dynamic data support, including block revise, erase, and affix. We use erasure-correcting code in the file distribution preparation to provide redundancy parity vectors and guarantee the data dependability. Our scheme accomplishes the integration of storage correctness insurance and data corruption has been detected during the storage correctness verification across the distributed servers. Our scheme is highly efficient and resilient to Byzantine failure, malicious data modification attack, and even server colluding attacks We believe that data storage security in Cloud Computing, an area full of challenges and of dominant significance, is still in its infanc y to be identified. We envision several possible directions for futu re research on this area. It allows Third Parity Auditor to audit the cloud data storage without demanding users’ time, probability     R EFERENCES   1  Cloudcomputing, http://en.wikipedia.org/wiki/Cloud_computing accessed: 24/08/2012 2  Cloud Computing  http://www.techno-pulse.com/ Cloud Computing for Beginners, Accessed: 24/08/2011 3  C. Wang, Q. Wang, K. Ren, and W. Lou, “Privacy Preserving Public Auditing for Storage Security in Cloud Computing,” Proc IEEE INFOCOM, Mar. 2010 4  C. Wang, Q. Wang, K. Ren, and W. Lou, “Ensuring Data Storage Security in Cloud Computin g,” Proc. 17th Int’l Workshop Quality of Service \(IWQoS ’09\, pp. 1 9, July 2009 5  Correction to the 1997 Tutorial on Reed-Solomon Coding James S Plank Ying Ding University of Tennessee Knoxville, TN 37996 6  M. Arrington, “Gmail Disaster: Reports of Mass Em ail Deletions,”http://www.techcrunch.com/2006/12/28/gmail disaster reports of-Mass-email-deletions, Dec. 2006 7  Privacy-Preserving Public Auditing for Secure Cloud Storage Cong Wang, Student Member, IEEE, Sherman S.M. Chow, Qian Wang Student Member, IEEE,Kui Ren, Senior Member, IEEE, and Wenjing Lou, Senior Member, IEEE 8  Data storage auditing service in cloud computing: challenges, methods and opportunities Kan Yang · Xiaohua Jia 9  C. Wang, K. Ren, W. Lou, and J. Li, “Towards Publicly Auditable Secure Cloud Data Storage Servic es,” IEEE Network Magazine,vol. 24, no. 4, pp. 19-24, July/Aug. 2010    


alternatives are orthogonal and used separately based on user preference Furthermore both provide two basic features encoding a.k.a RAIDing data blocks and repairing the corrupt/missing blocks The two main components of HDFS-RAID are RaidNode and BlockFixer RaidNode is a daemon responsible for the creation only once following the initial le write and maintenance re-creating periodically or on demand the corrupt/missing parities and purging orphan ones of parity les for all data les Since the default block policy of HDFS is not aware of the dependency relation between the data and parity blocks of a given le HDFS-RAID manages the placement of parity blocks to avoid co-location of data blocks and parity blocks The BlockFixer component reconstructs missing or corrupt blocks by retrieving the necessary blocks encoding/decoding them and sending the reconstructed blocks to new hosts B HDFS-RAID Optimizations In our experiments with HDFS-RAID we noticed two common performance inef“ciencies and optimized them Opt1 The HDFS-RAID implementation uses the generator polynomial and not the more well-known generator matrix  representation of Reed-Solomon codes In this representation typically and as is in the HDFS-RAID implementation always all the remaining blocks of a given row which can be more than k  are fetched and used to repair the missing ones Generally this use of extra blocks results in faster decoding since there will be fewer equations to solve However for cases in which network is a bottleneck this trade-off fetching extra blocks versus faster decoding does not pay off Our optimized version retrieves exactly k blocks and pretends that all other n  k blocks are missing As con“rmed by our experimental results the bandwidth-scarce clusters can greatly bene“t from this optimization Opt2 The HDFS-RAID implementation implicitly assumes that there is only a single failure per row stripe In case there are more failures they are discovered only when the read access attempts fail These newly-detected failed blocks are then added to the list of failed blocks and the repair process starts again Our optimized implementation checks for multiple failures beforehand and repairs them simultaneously amortizing the repair costs C CORE Implementation The CORE storage primitive has been organically integrated with HDFS-RAID by extending its two main functionalities as described below RAIDing The CORE implementation allows vertical coding across les in a given directory The cross-object size parameter  t  can be con“gured similar to the row stripe size parameter of HDFS-RAID The vertical encoding is reused in the full matrix RAIDing rst row-by-row then column-by-column for both data and parity blocks Repair An additional vertical repair option is introduced The 2-dimensional repair feature implements all the algorithms discussed in Section V i failure detection and failure matrix population ii failure clustering iii recoverability-checking and iv repair scheduling The correctness of our implementation was veri“ed through multiple test cases in which the MD5 hash values of the repaired les were compared against those of the original les Moreover since all changes have been made within the RAID subdirectory of the HDFSs code replacing the corresponding Java library is suf“cient to upgrade HDFSRAID to CORE The source codes binary distribution and documentations of our implementation are available at http://sands.sce.ntu.edu.sg/StorageCORE  VII E XPERIMENTS We benchmarked the implementation with experiments run on two different HDFS clusters of 20 nodes each  Network-Critical cluster A university cluster which has one powerful PC 4  3.2GHz Xeon Processors with 4GB of RAM hosting the NameNode/RaidNode and 19 HP t5745 ThinClients acting as DataNodes The average bandwidth of this cluster is 12MB/s  Computation-Critical cluster An Amazon EC2 cluster of 20 homogeneous nodes of type m1.small approximately 1.2 GHz 2007 Xeon Processor with 1.8GB of RAM In this cluster one node is hosting the NameNode/RaidNode and the rest are used as DataNodes The maximum bandwidth between EC2 m1.small instances is 250MB/s The block size  q  used was 64MB Files were added to HDFS and encoded horizontally rst and then the vertical parity was computed We ran two sets of experiments one set to compare the performance of CORE with that of HDFS-RAID and another set to study the repair scheduling algorithms In both sets we primarily use the completion time of the repair process as the main comparison measure However we also measured the amount of transferred data in each experiment as repair traf“c The data transfer numbers serve two purposes i to verify the correctness of our implementation they must match the analytical numbers and ii to use as a reference point in analyzing the completion time numbers  since the amount of transferred data is independent of the type of cluster used Finally in all experiments the reported numbers are the average of 10 runs Since the variations were small up to few percents they are omitted from the graphs A CORE vs HDFS-RAID In these experiments we compared three methods namely HDFS-RAID HDFS-RAID-Optimized and CORE 252 


0 0.2 0.4 0.6 0.8 1 1.2 1.4 1.6 1.8 n=9 k=6 t=3 n=14 k=12 t=5 X CORE X HDFS RAID Optimized X HDFS RAID XX CORE XX HDFS RAID Optimized XX HDFS RAID Bytes Read GB a Transferred data 0 20 40 60 80 100 120 140 160 180 200 n=9 k=6 t=3 n=14 k=12 t=5 X CORE X HDFS RAID Optimized X HDFS RAID XX CORE XX HDFS RAID Optimized XX HDFS RAID Repair Time seconds b Time network-critical cluster 0 20 40 60 80 100 120 140 160 180 200 n=9 k=6 t=3 n=14 k=12 t=5 X CORE X HDFS RAID Optimized X HDFS RAID XX CORE XX HDFS RAID Optimized XX HDFS RAID Repair Time seconds c Time computation-critical cluster Figure 6 Comparing the repair performance of HDFS-RAID HDFS-RAID-Optimized and CORE using two different sets of coding parameters 9,6,3 and 14,12,5 inspired respectively by the code length and storage overheads of Googles GFS and Microsoft Azure In these schemes the overhead of COREs extra parities are 1  3=33 and 1  5  20 accordingly In each case two different failure patterns were enforced a one-failure pattern represented by X and a two-failures pattern represented by XX  For the two-failures pattern both are set to happen in the same object i.e on the row The reason for this setting is two-fold i it favors the HDFSRAID since at almost the same cost it can repair two failures instead of one ii if two failures happen on different rows the experiment will be in effect a variation of the onefailure pattern From the results shown in Figure 6 we can draw several conclusions  For single failure the overhead of CORE is less than 50 of HDFS-RAID This is quite signi“cant since in real-world clusters e.g in the Facebook cluster single f ailures per stripe are by far the most common type of failures This improvement results from two inherent advantages of CORE i single failure can be repaired vertically using far fewer blocks and ii it uses a much cheaper XOR operation instead of expensive decoding/re-encoding this is particularly signi“cant in the computation-critical cluster  The impact of our rst HDFS-RAID optimization Opt1 in Section VI-B can be seen in the results the difference between the 2nd and the 3rd chart bars As explained before this optimization is targeted speci“cally for the clusters in which the network is a scarce resource part b in Figure 6 The improvements are particularly pronounced in cases where the number of avoided block retrievals are higher e.g one failure in the scheme 9,6,3  The gains from our second HDFS-RAID optimization Op2 in Section VI-B are also noticeable the 5th and the 6th chart bars in all setups  Growth in the CORE matrix size from 9,6,3 to 14,12,5 results in even higher gains especially in clusters where computation power is scarce B Repair Scheduling Algorithms In this set of experiments the three repair scheduling algorithms of Section V-C were compared using the Step and Plus failure patterns HDFS-RAID has neither a notion of repair scheduling  it treats objects independently  nor can it fully recover from the Plus failure pattern so it was not considered in the following experiments These experiments were run for CORE matrix of size 14,12,5 The results are shown in Figure 7 and as expected the data part of this gure part a  mirrors the analytical results presented in Table II Moreover the completion time numbers parts b and c  are also to large extent in-line with the data results The only two discrepancies are explained below  Completion time of the Column-First algorithm on the Plus pattern in the network-critical cluster part b  is longer than expected This is caused by the last repair which uses two other freshly-repaired blocks Accessing those blocks is delayed until NameNodes heartbeat-driven mapping tables are updated  Completion time of the RGS algorithm in the computationcritical cluster part c  is only slightly better than that of Column-First despite applying one vertical repair less see Table II for the schedules This is due to the fact that for these patterns the RGS and Column-First apply the same number of horizontal repairs and these are the main driving factor of the cost in the computation-critical cluster VIII C ONCLUSIONS AND F UTURE W ORK In this paper we demonstrated that some simple and standard techniques and thus easy to implement and organically 253 


0 0.5 1 1.5 2 2.5 3 Step Plus Row First Column First RGS B ytes R ea d GB a Transferred data 0 50 100 150 200 250 300 Step Plus Row First Column First RGS Repair Time seconds b Time network-critical cluster 0 50 100 150 200 250 300 Ste p Plus Row First Column First RGS Repair Time seconds c Time computation-critical cluster Figure 7 Performances of the repair scheduling algorithms on two different failure patterns integrate can provide signi“cant data repair and access boost in erasure coded distributed storage systems Specifically we studied our approach of introducing cross-object coding on top of normal erasure coding The ideas were implemented and integrated with HDFS-RAID available at  and benchmark ed o v er a proprietary cluster and EC2 Experiments with the implementation as well as accompanying analytical studies comparing the approach with not only MDS codes but also with the very recently proposed Local Reconstruction Codes used in Azure demonstrate the superior performance of CORE over state-of-the-art techniques for data reads and repairs While naive solutions can be readily used in future we will like to explore the CORE code properties to achieve better performance also during data insertion/updates The current evaluations are static based on snapshots of the system state We speculate that COREs better repair properties will yield a system in a better state over time We will thus carry out trace driven experiments to study the systems dynamics better R EFERENCES  P  Elias Error Free Coding  Transactions on Information Theory  vol 4 no 14 1954  HDFS-RAID http://wiki.apache.or g/hadoop/HDFSRAID  C Huang et al Erasure Coding in W indo ws Azure Storage  in USENIX ATC  2012  A Datta et al Redundantly Grouped Cross-object Coding for Repairable Storage in Proc APSys  2012  P  Gopalan et al On the locality of code w ord symbols  Information Theory IEEE Transactions on  vol 58 no 11 pp 6925…6934 2012  K S Esmaili et al The CORE Storage Primiti v e  CrossObject Redundancy for Ef“cient Data Repair and Access in Erasure Coded Storage CoRR  vol abs/1302.5192 2013  CORE http://sands.sce.ntu.edu.sg/StorageCORE  H W eatherspoon et al Erasure Coding vs Replication A Auantitative Comparison in Proc IPTPS  2002  J K ubiato wicz et al OceanStore An Architecture for Global-Scale Persistent Storage in Proc ASPLOS  2000  R Bhagw an et al T otal Recall System Support for Automated Availability Management in NSDI  2004  S Plank The RAID-6 Liber8T ion Code  Intl Journal of High Performance Computing Applications  vol 23 no 3 2009  A P atterson et al A Case for Redundant Arrays of Ine xpensive Disks RAID SIGMOD Records  vol 17 no 3 1988  O Khan et al Rethinking Erasure Codes for Cloud File Systems Minimizing I/O for Recovery and Degraded Reads in USENIX FAST  2012  B F a n e t al DiskReduce Replication as a Prelude to Erasure Coding in Data-Intensive Scalable Computing CMU Tech Rep CMU-PDL-11-112 2011  B Calder et al W indo ws Azure Storage A Highly A v ailable Cloud Storage Service with Strong Consistency in ACM SOSP  2011  A Thusoo et al Data W arehousing and Analytics Infrastructure at Facebook in ACM SIGMOD  2010  C Huang et al Pyramid Codes Fle xible Schemes to T rade Space for Access Ef“ciency in Reliable Data Storage Systems in IEEE NCA  2007  F  Oggier et al Coding T echniques for Repairability in Networked Distributed Storage Systems FnT in Communications and Information Theory  vol 9 no 4 2013  A Dimakis et al A Surv e y on Netw ork Codes for Distributed Storage The Proc of IEEE  vol 99 2011  A Duminuco et al Hierarchical Codes Ho w t o Mak e Erasure Codes Attractive for Peer-to-Peer Storage Systems in Proc P2P  2008  M Li et al GRID Codes Strip-Based Erasure Codes with High Fault Tolerance for Storage Systems ACM Trans on Storage  vol 4 2009  A K ermarrec et al Repairing Multiple F ailures with Coor dinated and Adaptive Regenerating Codes in Proc NetCod  2011  K W  Shum Cooperati v e Re generating Codes for Distributed Storage Systems in Proc ICC  2011  F  Oggier et al Self-Repairing Homomorphic Codes for Distributed Storage Systems in Proc INFOCOM  2011  F  Oggier et al Self-Repairing Codes for Distrib uted Storage A Projective Geometric Construction in Proc ITW  2011 26 D Papailiopoulos et al Locally Repairable Codes in Proc ISIT  2012  M S et al Xoring elephants No v e l erasure codes for big data Proceedings of the VLDB13 To appear  2013  L P amies-Juarez et al Data Insertion  Archi ving in Erasure-coding Based Large-scale Storage Systems in Proc ICDCIT  2013  L P amies-Juarez et al RapidRAID Pipelined Erasure Codes for Fast Data Archival in Distributed Storage Systems in Proc INFOCOM  2013  Y  Hu NCFS On the Practicality and Extensibility of a Network-Coding-Based Distributed File System in Proc NetCod  2011  R Li et al CORE Augmenting Re generating-coding-based Recovery for Single and Concurrent Failures in Distributed Storage Systems in Proceedings of IEEE MSST13  2013  J I Hall Notes on coding theory  Citeseer 2003  K V  Rashmi and others A Solution to the Netw ork Challenges of Data Recovery in Erasure-coded Distributed Storage Systems A Study on the Facebook Warehouse Cluster in Proceedings of USENIX HotStorage13  2013 254 


 L Kaufman and P  Rousseeuw  Clustering by means of medoids Technische Hogeschool Delft Netherlands Department of Mathematics and Informatics Tech Rep 1987  S Deerwester  S Dumais G Furnas T  Landauer  and R Harshman Indexing by latent semantic analysis  vol 41 no 6 pp 391…407 1990  C Boutsidis J Sun and N Anerousis Clustered subset selection and its applications on it service metrics in  2008 pp 599…608  C Boutsidis M W  Mahone y  and P  Drineas  An impro v ed approximation algorithm for the column subset selection problem in  2009 pp 968…977  C Boutsidis P  Drineas and M Magdon-Ismail Near optimal column-based matrix reconstruction in  2011 pp 305 314  J Dean and S Ghema w at MapReduce Simpli“ed data processing on large clusters  vol 51 no 1 pp 107…113 2008  T  White  1st ed OReilly Media Inc 2009  A Frieze R Kannan and S V empala F ast Monte-Carlo algorithms for nding low-rank approximations in  1998 pp 370 378  P  Drineas A Frieze R Kannan S V empala and V  V inay  Clustering large graphs via the singular value decomposition  vol 56 no 1-3 pp 9…33 2004  P  Drineas R Kannan and M Mahone y  F ast Monte Carlo algorithms for matrices II Computing a low-rank approximation to a matrix  vol 36 no 1 pp 158…183 2007  P  Drineas M Mahone y  and S Muthukrishnan Subspace sampling and relative-error matrix approximation Column-based methods in  Springer Berlin  Heidelberg 2006 pp 316…326  A Deshpande L Rademacher  S V empala and G W ang Matrix approximation and projective clustering via volume sampling  vol 2 no 1 pp 225…247 2006  A C  i vril and M Magdon-Ismail Column subset selection via sparse approximation of SVD  vol 421 no 0 pp 1  14 2012  A K F arahat A Ghodsi and M S Kamel  An ef cient greedy method for unsupervised feature selection in  2011 pp 161 170   Ef cient greedy feature selection for unsupervised learning  vol 35 no 2 pp 285…310 2013  T  Elsayed J Lin and D W  Oard P airwise document similarity in large collections with MapReduce in  2008 pp 265…268  A Ene S Im and B Mosele y  F ast clustering using MapReduce in  2011 pp 681…689  H Karlof f S Suri and S V assilvitskii A model of computation for MapReduce in  2010 pp 938…948  S Dasgupta and A Gupta An elementary proof of a theorem of Johnson and Lindenstrauss  vol 22 no 1 pp 60…65 2003  D Achlioptas Database-friendly random projections Johnson-Lindenstrauss with binary coins  vol 66 no 4 pp 671…687 2003  P  Li T  J Hastie and K W  Church V ery sparse random projections in  2006 pp 287…296  G Golub and C V an Loan  3rd ed Johns Hopkins Univ Pr 1996  A Deshpande and L Rademacher  Ef cient v olume sampling for row/column subset selection in  2010 pp 329 338  V  Gurusw ami and A K Sinop Optimal column-based lo wrank matrix reconstruction in  2012 pp 1207…1214  D D Le wis Y  Y ang T  G Rose and F  Li Rcv1 A ne w benchmark collection for text categorization research  vol 5 pp 361…397 2004  W Y  Chen Y  Song H Bai C.-J Lin and E Chang Parallel spectral clustering in distributed systems  vol 33 no 3 pp 568 586 2011  A T orralba R Fer gus and W  Freeman 80 million tin y images A large data set for nonparametric object and scene recognition  vol 30 no 11 pp 1958…1970 2008  N Halk o P G Martinsson Y  Shk olnisk y  and M T ygert An algorithm for the principal component analysis of large data sets  vol 33 no 5 pp 2580…2594 2011 
Journal of the American Society for Information Science and Technology Proceedings of the Seventeenth ACM Conference on Information and Knowledge Management CIKM08 Proceedings of the Twentieth Annual ACM-SIAM Symposium on Discrete Algorithms SODA09 Proceedings of the 52nd Annual IEEE Symposium on Foundations of Computer Science FOCS11 Communications of the ACM Hadoop The De“nitive Guide Proceedings of the 39th Annual IEEE Symposium on Foundations of Computer Science FOCS98 Machine Learning SIAM Journal on Computing Approximation Randomization and Combinatorial Optimization Algorithms and Techniques Theory of Computing Theoretical Computer Science Proceedings of the Eleventh IEEE International Conference on Data Mining ICDM11 Knowledge and Information Systems Proceedings of the 46th Annual Meeting of the Association for Computational Linguistics on Human Language Technologies Short Papers HLT08 Proceedings of the Seventeenth ACM SIGKDD International Conference on Knowledge Discovery and Data Mining KDD11 Proceedings of the 21st Annual ACM-SIAM Symposium on Discrete Algorithms SODA10 Random Structures and Algorithms Journal of computer and System Sciences Proceedings of the Twelfth ACM SIGKDD international conference on Knowledge Discovery and Data Mining KDD06 Matrix Computations Proceedings of the 51st Annual IEEE Symposium on Foundations of Computer Science FOCS10 Proceedings of the 21st Annual ACM-SIAM Symposium on Discrete Algorithms SODA12 The Journal of Machine Learning Research Pattern Analysis and Machine Intelligence IEEE Transactions on Pattern Analysis and Machine Intelligence IEEE Transactions on SIAM Journal on Scienti“c Computing 
180 


Bottom Top A B 
Figure 15 Figure 16 
messages seen for all workers in a superstep \(Figures 10 and 13\. When looking at the messages sent by workers in a superstep for METIS, we see that there are message load imbalances within work ers in a superstep, caused due to concentration of vertices being traversed in that superstep in certain partitions This variability is much more pronounced in CP as compared to WG \(Figures 11 and 14\ E.g. in superstep 9 for CP, twice as many messages \(4M\ are generated by a worker compared to another \(2M\.  For Pregel BSP, the time taken in a superstep is determined by the slowest worker in that superstep. Hence increase d variability in CP causes even goodŽ partitioning strategies to cause an increase in total execution time wh en using the Pregel/BSP model VIII A NALYSIS OF E LASTIC C LOUD S CALING  Cloud environments offer elasticity … the ability to scale-out or scale-in VMs on-demand and only pay for what one uses [28   On th e f l i p s i de  on e en ds u p  paying for VMs that are acquired even if they are underutilized. We have already shown the high variation in compute/memory resources used by algorithms like BC and APSP across different supersteps. While our earlier swath initiation heuristics attempt to flatten these out by overlapping swath executions, one can consider leveraging the clouds elasticity to, instead, scale up and down the concurrent workers \(and graph partitions\ allocated in each superstep The peak and trough nature of resource utilization combined with Pregel/BSPs synchronous barrier between supersteps offers a window for dynamic scaleout and …in at superstep boundaries. Peak supersteps can greatly benefit from additional workers, while those same workers will contribute to added synchronization overhead for trough supersteps We offer an analysis of the potential benefits of elastic scaling by extrapolating from observed results for running BC on WG and CP graphs, using four and eight workers.  To provide a fair and focused comparison, we turned off swath heuristics in favor of fixed swath sizes and initiation intervals Figure 15 \(Bottom\ plots the speedup of BC running on eight workers when normalized to BC running on four workers, at corresponding supersteps.  The number of workers does not impact the number of supersteps We also plot the number of active vertices \(i.e. vertices still computing for a given swath\these supersteps which is a measure of how much work is required \(Fig 15 \(Top\. We find that we occasionally get superlinear speedup spikes \(i.e. >2x\ that shows a strong correlation with the peaks of active messages, for both WG and CP graphs. At other times, the sp eedup is sublinear or even a speed-down \(i.e. <1\responding to inactive vertices.  The superlinear speedup is attributable to the lower contention and reduced memory pressure for 8 workers when the active vertices peak \(similar to what we observed for the swath initiation heuristics Similarly, the below par speedup during periods of low activity is contributed by the increased overhead of barrier synchronization across 8 workers. Intuitively, by dynamically scaling up the number of workers for supersteps with peaking active vertices and scaling them down otherwise, we can leverage the superlinear speedup and get more value per worker Using a threshold of 50% active vertices as the threshold condition for between 4 and 8 workers in a superstep, we extrapolate the time per superstep and compared this to the fixed 4 and 8 worker runtimes. We also compute the best-case run time using an oracleŽ approach to i.e. for each superstep, we pick the minimum of the 4 or 8 workers time.  Note that these projections do not yet consider the overheads of scaling, but are rather used to estimate the potential upside if we had an ideal or an automated heuristic for scaling. The total time estimates for running BC on WG and CP graphs, normalized to  
 plot shows speedup of 8 workers relative to 4 workers, for each superstep, when running BC on WG and CP graphs plot shows the number of vertices active in that superstep Estimated time for BC using elastic scaling, normalized to time taken for 4 workers. Normalized cost is shown on secondary Y axis WG graph shown on left CP graph shown on right. Smaller is better 
022\011 022\010 022\007 022\002 006 002 007 006 002 007 010 011 012 013 014 015 006 006\003\002 006\003\007 006\003\010 006\003\011 006\003\012 006\003\013 006\003\014 006\003\015 006\003\016 002 027\031\030\037\020#@\020"\031\030\027\020\035 0201!2#\024$#\015#5\024",\020"#\017\003"\003\031\003#\011#5\024",\020"\035 024"'\033\026\0309\0201#\\031\020 2 035#\032\020"#+!\034 017\020\021\022\023\024\024\025\026\020 027\030\031\022\032\033\031\020\034\031\035 017\020\021\022\023\024\024\025\026\020#?#/\027\031\030\037\020#@\020"\031\030\027\020\035 027\030\031\022\032\033\031\020\034\031\035#?#/\027\031\030\037\020#@\020"\031\030\027\020\035 036\030\034\020\033"#\\0201!2 006 006\003\007 006\003\011 006\003\013 006\003\015 002 002\003\007 006 006\003\002 006\003\007 006\003\010 006\003\011 006\003\012 006\003\013 006\003\014 006\003\015 006\003\016 002 011#5\024",\020 B\034\0267 015#5\024",\020 B\034\0267 1\0332\031\030\037\020 030\034\025 1\0332\031\030\037\020 036\024\017\020 024!\0341 024\035\031#>\024"'\033\026\0309\0201#\031\024#\011#5\024",\020"#.\024\035\031 017\020\021\022\023\024\024\025\026\020#+!\034\022&\030'\020#>\024"'\033\026\0309\0201#\031\024#\011#5\024",\020"#&\030'\020 011#5\024",\020"#&\030'\020 015#5\024",\020"#&\030'\020 024\035\031 006 006\003\007 006\003\011 006\003\013 006\003\015 002 002\003\007 002\003\011 002\003\013 006 006\003\002 006\003\007 006\003\010 006\003\011 006\003\012 006\003\013 006\003\014 006\003\015 006\003\016 002 011#5\024",\020 B\034\0267 015#5\024",\020 B\034\0267 1\0332\031\030\037\020 033\026\030\034\025 1\0332\031\030\037\020 036\024\017\020 024!\0341 024\035\031#>\024"'\033\026\0309\0201#\031\024#\011#5\024",\020"#.\024\035\031 027\030\031\022\032\033\031\020\034\031\035#+!\034\022&\030'\020#>\024"'\033\026\0309\0201#\031\024#\011#5\024",\020"#&\030'\020 011#5\024",\020"#&\030'\020 015#5\024",\020"#&\030'\020 024\035 031 
 
dynamically scaling ideal scaling 
Our hypothesis is that an intelligent adaptive scaling of workers can achieve a similar performance as a large, fixed number of workers, but with reduced cost 
213 


Nature Nature Ecological Applications Nature ACM International Conference on Management of Data \(SIGMOD In Parallel Object-Oriented Scientic Computing \(POOSC Science Communications of the ACM ACM Workshop on Mining and Learning with Graphs Communications of the ACM HotCloud Proceedings of the 19th ACM International Symposium on High PErformance Distributed Computing HPDC Knowledge and Information Systems KAIS International Conference on Computational Science IEEE International Conference on Cloud Computing Technology and Science ACM/IEEE Conference on Advances in Social Network Analysis and Mining \(ASONAM IEEE International Parallel and Distributed Processing Symposium \(IPDPS International Conference on Distributed Computing and Networking Journal of Mathematical Sociology International Conference on Parallel Processing Communications of the ACM 
 
observed time taken using 4 workers, are plotted in Figures 16\(A\ and 16\(B We see that our dynamic scaling heuristic using the percentage of active vertices achieves nearly the same CP\ or better \(WG\ performance as a fixed 8 worker approach. Clearly there is benefit of using fewer workers for low utilization su persteps to eliminate the barrier synchronization overhead. Also, the dynamic scaling heuristic performs almost as well as the ideal scaling. Finally, when we consider the monetary cost of the proposed approaches, assuming a pro-rata normalized cost per VM-second plotted on the secondary Y axis, we see that dynamic scaling is comparable \(CP\ or cheaper \(WG\ than a 4 worker scenario while offering the performance of an 8 worker deployment IX C ONCLUSION  In conclusion, we introduce optimization and heuristics for controlling memory utilization and show they are critical to performance.  By breaking computation into swaths of vertices and using our sizing heuristics we achieve up to 3.5x speedup over the maximum swath size that does not cause the a failure.  In addition overlapping swath executions can provide a 24% gain with automated heuristics and even greater speedup when a priori knowledge of the network characteristics is applied This evaluation offers help to eScience users to make framework selection and cost-performancescalability trade-offs. Our he uristics are generalizable and can be leveraged by other BSP and distributed graph frameworks, and for graph applications beyond BC. Our work uncovered an unexpected impact of partitioning and it would be worthwhile, in future, to examine the ability to pred ict, given certain graph properties, a suitable partitioning model for Pregel/BSP It may also be useful to perform such evaluations on larger graphs and more numbers of VMs. At the same time, it is also worth considering if non-linear graph algorithms are tractable in pr actice for large graphs in a distributed environment B IBLIOGRAPHY  1  F  L i lj er os C   Ed l i n g L  A m a r a l H  S t an ley   and Y    berg The web of human sexual contacts 
vol. 411, pp. 907908, 2001   H Je o n g  S   Ma so n A  L   B a ra b s i  a nd Z   Oltva i  L e t ha l i t y  and centrality in protein networks vol. 411, pp. 41-42 2001   O. B o din and E   E s t r ada    U s i n g n e t w ork c e nt r a l i t y  m e a s ures t o  manage landscape connectivity vol 18, no. 7, pp. 1810-1825, October 2008   D. W a ts s  and S  S t r ogat z  C olle c t i v e  d y nam i cs of  s m a ll-w orl d   networks vol. 393, no. 6684, pp. 440…442, June 1998   G  Ma lew i c z   M A u s t er n A   Bik  J   Dehn er t I  Hor n   N. L e i s er and G. Czajkowski, "Pregel: A system for large-scale graph processing," in 2010   D. G r egor  and A  L u m s dain e  T h e  pa r a llel  B G L  A gen e r i c  library for distributed graph computations," in 2005   B. S h a o  H. W a n g  and Y  L i T he T r init y G r aph E n g i n e    Microsoft Research, Technical Report MSR-TR-2012-30, 2012   A  F ox  C lo ud c o m putin g w h at  s  in it for m e  as  a  s c i e n tis t     vol. 331, pp. 406-407, 2011   S. G h e m a w a t  and J  De an   Map re duc e s i m p lifi e d data  processing on large clusters vol 51, no. 3, pp. 107-113, 2008   J  L i n and M. S c hat z   Des i g n  patt er n s  for eff i ci ent gr aph algorithms in MapReduce," in 2010   L   Va l i ant   A b r id g i n g m o d e l f or pa r a llel com putati o n  vol. 33, no. 8, pp. 103-111, 1990 12 a c h e  Ha ma    O n l i n e    http://hama.apache.org   13 Ap a c h e  Ha d o op    O n l i n e    http://hadoop.apache.org     M Z a h a r i a, M. Ch ow dhu ry M F r ank l in S  S h e n k e r, and I   Stoica, "Spark: Cluster Computing with Working Sets," in 2010   J  Ekana y ak e e t a l     T w i st er A  r untim e f o r it er ati v e  MapReduce," in Chicago, 2010, pp. 810-818   U. K a n g  C  T s o u rakakis   and C. F a l outs o s  Peg a s us   Minin g  Peta-scale Graphs," in 2010   M. P a c e  B S P vs  MapR e duc e    in vol. 103.2081, 2012   S. Seo  E  Yoo n, J  K i m  S  J i n  J-S. K i m   and S   Ma e n g HAMA: An Efficient matrix computation with the MapReduce framework," in 2010, pp. 721-726   S. S a l i h ogl u  and J  W i d o m  G PS A G r a ph P r oc e s s i n g Sy s t em    Stanford University, Technical Report 2011   R L i cht e n w a l t e r and N   Cha w la D is Ne t  A fr am ew ork for  distributed graph computation," in  2011   K  Maddu r i  D. E d i g er K   J i an g  D. Bad e r  and D  Cha v a r riaMiranda, "A faster parallel algorithm and efficient multithreaded implementations for evaluating betweenness centrality on massive datasets," in 2009   E  K r e p s k a, T  K i el m a nn, W  F o kkink, H   Ba l, "A  hi g h level framework for distributed processing of large-scale graphs," in 2011, pp. 155-166   L   Pa ge  S  B r in R. M o t w ani and T  W i nogr ad  T h e P a geRank citation ranking: Bringing order to the web," Stanford InfoLab Technical Report 1999-66, 1999   U  Brand  s  A f a s t er  a l gor ith m for  b e t w eenn e s s c e nt r a l i t y    vol. 25, no. 2, pp. 163-177 2001   Stan fo r d  Net w or k A na l y s is Pro j e c t  O n l in e    http://snap.stanford.edu    I  S t ant o n and G  K l i o t, "S t r e a m i n g G r aph P a rtiti o n in g  for L a rge Distributed Graphs," Microsoft Corp., Technical Report MSRTR-2011-121, 2011   G   K a ry pis and V   K um a r A fas t and hi g h qua l i t y m u l t i l evel scheme for partitioning irregular graphs," in 1995, pp. 113-122   M. A r m b r u s t e t  a l   A v i ew of  c l o u d  c o m putin g    vol. 53, no. 0001-0782, pp. 50-58 April 2010  
214 


  13  or gani c  c he m i s t r y  i n our  Sol ar  Sy s t e m       Xi a n g  L i r e c e i v e d h i s B  S   m is tr y  fr o m  th e  P e k in g  U n iv e r s ity  C h in a  in  2 0 0 3  and P h D   i n P hy s i c al  C he m i s t r y  f r om  t he  J ohns  H opk i ns  Un i v e r s i t y  i n  2 0 0 9   He  h a s  b e e n  a  R e s e a r c h  A s s o c i a t e  wi t h  a  j o i n t  a p p o i n t m e n t  a t  t h e  U n i v e r s i t y  o f  M a r y l a n d   Ba l t i m o r e  C o u n t y  a n d  N AS A G o d d a r d  S p a c e  Fl i  Ce n t e r  s i n c e  2 0 1 1   H i s  r e s e a r c h  f o c u s e s  o n  t h e  d e t e c t i o n  of  t r ac e  e l e m e nt  and as t r obi ol ogi c al l y  r e l e v ant  or gani c  mo l e c u l e s  i n  p l a n e t a r y  s y s t e ms   l i k e  M a r s   He  i s  es p eci a l l y i n t er es t ed  i n  t h e d evel o p m en t  o f  T i m e of  and I on T r ap m as s  s pe c t r om e t e r s w i t h v a r i o u s i o n i z a t i o n  ng te c h n iq u e s   Wi l l  B r i n c k e r h o f f  sp a c e  sc i e n t i st  i n  t h e  Pl a n e t a r y  En v i r o n m e n t s  La b  a t  N A S A  s  G o d d a r d  Spac e  F l i ght  C e nt e r  i n Gr e e n b e l t   M D w i t h  pr i m ar y  r e s pons i bi l i t y  f or  th e  d e v e lo p m e n t o f th e  L D TO F  m a s s  s p e c t r o  th is  p r o je c t H e  h a s  fo c u s e d  re c e n t l y  o n  t h e  d e v e l o p m e n t  o f  m i n i a t u re  l a se r d ma s s  s p e c t r o me t e r s  f o r  f u t u r e  p l a n e t a r y  mi s s i o n s  a l o n g  wi t h  b a s i c  e x p e r i m e n t a l  r e s e a r c h  i n  a s t r o b i o l o g y  a n d  p r e bi ot i c  s y nt he s i s   D r   B r i nc k e r hof f  i s  i nv ol v e d i n t he  de v e l opm e nt  of  m as s  s pe c t r om e t e r  f or  bot h t he  2011 Ma r s  S c i e n c e  L a b o r a t o r y  a n d  t h e  2 0 1 8  E x o Ma r s  mi s s i o n s   


  14   


Copyright © 2009 Boeing. All rights reserved  Issues and Observations Initial load of one day of data ~ 7 hours Optimizations  Write data in batches  Use a mutable data structure to create data strings  Deploy a higher performance machine  Use load instead of insert  Use DB2 Range-Partitioned tables  Database tunings Time reduced from 7 hours to approx 30 minutes 


Copyright © 2009 Boeing. All rights reserved  Optimizations Use a mutable data structure to create data strings  Original application created the SQL statement by appending elements to a Java String  It was taking five hours \(of the seven hours Strings  Instead Java StringBuilder used  Java Strings immutable  Time savings of 71.4 


Copyright © 2009 Boeing. All rights reserved  Optimizations Deployed on a higher-performance machine  Application ported from IBM Blade Center HS21 \(4GB of RAM and 64-bit dual-core Xeon 5130 processor to Dell M4500 computer \(4GB of RAM and 64-bit of quad-core Intel Core i7 processor  Reduced the time to thirty minutes Bulk loading instead of insert  Application was modified to write CSV files for each table  Entire day worth of data bulk loaded  Reduced the time to fifteen minutes 


Copyright © 2009 Boeing. All rights reserved  Optimizations Range-Partitioned tables \(RPT  To limit the size of tables, the original code created multiple tables per table type  This puts burden on the application to query multiple tables when a range crosses several tables  With RPT, user is not required to make multiple queries when a range crosses a table boundary  Increased the time to thirty minutes  Additional fifteen minute cost per day of partitioning enabled time savings during queries 


Copyright © 2009 Boeing. All rights reserved  Optimizations Database tunings  Range periods changed from a week to a month  Automatic table space resizing changed from 32MB to 512KB  Buffer pool size decreased  Decreased the time to twenty minutes Overall, total time savings of 95.2 


Copyright © 2009 Boeing. All rights reserved  20 IBM Confidential Analytics Landscape Degree of Complexity Competitive Advantage Standard Reporting Ad hoc reporting Query/drill down Alerts Simulation Forecasting Predictive modeling Optimization What exactly is the problem What will happen next if What if these trends continue What could happen What actions are needed How many, how often, where What happened Stochastic Optimization Based on: Competing on Analytics, Davenport and Harris, 2007 Descriptive Prescriptive Predictive How can we achieve the best outcome How can we achieve the best outcome including the effects of variability Used with permission of IBM 


Copyright © 2009 Boeing. All rights reserved Initial Analysis Activities Flights departing or arriving on a date Flights departing or arriving within a date and time range Flights between city pair A,B Flights between a list of city pairs Flights passing through a volume on a date. \(sector, center, etc boundary Flights passing through a volume within a date and time range Flights passing through an airspace volume in n-minute intervals All x-type aircraft departing or arriving on a date Flights departing or arriving on a date between city pair A,B Flights departing or arriving on a date between a list of city pairs Flights passing through a named fix, airway, center, or sector Filed Flight plans for any of the above Actual departure, arrival times and actual track reports for any of the above 


Copyright © 2009 Boeing. All rights reserved  Initial SPSS Applications Show all tracks by call sign 


Copyright © 2009 Boeing. All rights reserved  Predictive / Prescriptive Analytics Use-Case For a given Airspace Volume of Interest \(AVOI compute distinct traffic volume at some point in the future  Aim to alert on congestion due to flow control areas or weather if certain thresholds are exceeded  Prescribe solution \(if certain thresholds are exceeded Propose alternate flight paths  Use pre-built predictive model  SPSS Modeler performs data processing Counts relevant records in the database \(pattern discovery Computes traffic volume using statistical models on descriptive pattern Returns prediction with likelihood 


Copyright © 2009 Boeing. All rights reserved  Predictive / Prescriptive Analytics Use-Case Advanced Arrival Procedures with Active Abatement Potentials   9/23/10  24 Pulls in the TRACKINFO table of MAIN using SQL Limits the data to database entries which fall inside the AVOI Combines the SOURCE_DATE and SOURCE_TIME to a timestamp that can be understood by modeler Computes which time interval the database entry falls in. The time interval is 15 minutes Defines the target and input fields needed for creating the model Handles the creation of the model Produces a graph based off of the model results Final prediction 


Copyright © 2009 Boeing. All rights reserved  Initial Cognos BI Applications IBM Cognos Report Studio  Web application for creating reports  Can be tailored by date range, aircraft id, departure/arrival airport etc  Reports are available with links to visuals IBM Framework Manager  Used to create the data package  Meta-data modeling tool  Users can define data sources, and relationships among them Models can be exported to a package for use with Report Studio 


Copyright © 2009 Boeing. All rights reserved  Flights Departing Las Vegas on Jan 1, 2012 1 of 3 Report shows the departure date, departure and arrival locations and hyperlinks to Google Map images DeparturePosition and ArrivalPosition are calculated data items formatted for use with Google Maps Map hyperlinks are also calculated based on the type of fix 


Copyright © 2009 Boeing. All rights reserved  Flights Departing Las Vegas on Jan 1, 2012 2 of 3 DeparturePosition, Departure Map, ArrivalPosition and Arrival Map are calculated data items \(see departure items below DepartureLatitude DepartureLongitude DeparturePosition Departure Map 


Copyright © 2009 Boeing. All rights reserved  Flights Departing Las Vegas on Jan 1, 2012 3 of 3 


Copyright © 2009 Boeing. All rights reserved  Conclusion and Next Steps Current archive is 50 billion records and growing  Approximately 34 million elements per day  1GB/day Sheer volume of raw surveillance data makes analytics process very difficult The raw data runs through a series of processes before it can be used for analytics Next Steps  Continue application of predictive and prescriptive analytics  Big data visualization 


Copyright © 2009 Boeing. All rights reserved  Questions and Comments Paul Comitz Boeing Research & Technology Chantilly, VA, 20151 office Paul.Comitz@boeing.com 


Copyright © 2009 Boeing. All rights reserved Advanced Arrival Procedures with Active Abatement Potentials   9/23/10  31 


Copyright © 2009 Boeing. All rights reserved Advanced Arrival Procedures with Active Abatement Potentials   9/23/10  32 Backup Slides 


Copyright © 2009 Boeing. All rights reserved  Initial Approach Initial Investigations  Apache Solr/Lucene  Data Warehouse Evaluate Hadoop in the future 


Copyright © 2009 Boeing. All rights reserved  Using SOLR Uncompress Track Information Messages To use with Solr  Transforming track messages from their  original schema to Solr required building a “key, value” list using an XSTL  Queries made against this list of “key, value” pairs Transformation Process  One day of data ~ 4.5 hours Once transformation complete search/query performance very good Geo spatial queries using  unique query language 


Copyright © 2009 Boeing. All rights reserved  Representation Aviation data is frequently represented in more than one form 


