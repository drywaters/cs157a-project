Heading Towards Big Data Building A Better Data Warehouse For Mo re Data, More Speed, And More Users  Raymond Gardiner Goss raymond.goss@globalfoundries.com  Kousikan Veeramuthu kousikan.veeramuthu@globalfoundries.com  Manufacturing Technology GLOBALFOUNDRIES Malta, NY, USA   Abstract  As a new company, GLOBALFOUNDRIES is aggressively agile and looking at ways to not just mimic existing semiconductor manufacturing data management but to leverage new technologies and advances in data management without sacrificing performance or scalability.  Being a global technology company that relies on the understanding of data, it is important to centralize the visibility and control of this information, bringing it to the engineers and customers as they need it Currently, the factories are employing the best practices and data architectures combined with business intelligence analysis and reporting tools.  However, the expected growth in data over the next several years and the need to deliver more complex data integration for analysis will easily stress the traditional tools beyond the limits of the traditional data infrastructure.  The manufacturing systems vendors need to offer new solutions based on Big Data concepts to reach the new level of information processing that work well with other vendor offerings In this paper, we will show where we are and where we are heading to manage the increasing needs for handling larger amounts of data with faster as well as secure access for more users KeywordsóData Warehousing, Real-Time, Analysis Reporting, Scaling, Big Data I  I NTRODUCTION  Not long ago, the price of gasoline was less expensive and we drove cars based on features we desired like roof racks cargo space, sporty looks, and prestige, but the world is changing.  The cost of fuel has increased and we are more aware of the environmental concerns.  We are switching to vehicles with different engines that go much further with less energy, but still expect all the new features of built-in GPS backup cameras and keyless ignition.  The move to Big Data will be a similar paradigm shift.  The principle analysis is the same, but the engines and amount of data are changing Various industries have different problems, but most will have Big Data needs.  When first moving to the semiconductor manufacturing industry, we noticed that the transaction volume was a fraction of what we had experienced in the telecom world, where data were optimized into compressed bytes and streamed over raw sockets and switch responses were expected in milliseconds.  For instance, for a 800 number routing scheme, we had less than 250ms to look the phone number up determine the callerís income level and specify to which agent to route the call or the switch would timeout.  When switches were overwhelmed with data, they would drop packets and algorithms had to infer states based on most probable current state.  Other industries, such as social media, are challenged more by unstructured data and need tools to help turn text messages and photos into useful information for search engines and marketing purposes.  The challenge in the semiconductor world is with the size of the data.  Speed becomes a secondary problem because so many sources are needed to be joined together in a timely manner.  Large recipes, complex output from the test floor combined now with more Interface-A trace data amass terabytes each month that need to be handled for both real-time SPC, APC, and command and control scenarios as well as offline yield analyses.  Users now require real-time access to data from a much larger pool of sources.  This paper describes the various states of handling the increasing complexity and volumes today and the challenges ahead II  T RADITIONAL S OLUTION  GROWTH AND B IG D ATA  A  Many types of Big Data In the past year, ìBig Dataî has been gaining more buzz.  It isnít uncommon to hear someone say, ìwe will scale with a Big Data solutionî, ìGoogle does it just fineî, or ìvendor x must have already a Big Data solution in the plans However, there are different Big Data problems and solutions and not all apply or can be used at once.  We need to first define the term Big Data is the territory where our existing traditional relational database and file systems processing capacities are exceeded in high transactional volumes, velocity responsiveness, and the quantity and or variety of data.  The data are too big, move too fast, or donít fit the strictures of RDBMS architectures.  Scaling also becomes a problem.  To gain value from these data, we must choose alternative ways to process them B  Complexity Example Big Data covers a range of situations, all with the common theme of ìmoreî ó more variety, more quantity, more users more speed, more complexity.  There are currently different Big Data solution approaches to each of these.  Let us start off with an example of determining root cause and correlation of a 220 978-1-4673-5007-5/13/$31.00 ©2013 IEEE ASMC 2013 


new variety.  In one fab, there was a challenge of reticle hazing.  It wasnít hard to determine the culprit of the haze by sending it off to the lab but other details were not as easy From a few of the facilityís air quality sensors, it could be seen that there were traces of an oxidizing agent detected in the air and the fab had started the practice of inspecting the reticles after every 200 wafers.  While the risk to the wafers was mitigated, the transports became high and potentially created more exposure of contamination while in the Automated Material Handling System \(AMHS\.  Where were the reticles picking up the haze?  Was it from outgases in the tool or while they were in transit to the inspection tools or the stocker?  In order to solve the problem, we needed temporal data from the process, metrology and inspection tools, MES, facilities, MCS and AMHS to be brought together in one place for analysis. Up until this point, the data warehouse had not yet contained all such sources. From problems like this, we needed a solution which resulted in the creation of the General Engineering and Manufacturing Data warehouse \(GEM-D Data performance is becoming equally ripe for improvements.  In our factories, command and control is continually leveraging more data sources and visualization of real-time data to make decisions.  For instance, before shipping wafers, a fab out inspection occurs comparing all experiments incidents, quality reviews, and prior holds from SPC events All these data are made available not only to systems but also to the users so they can rectify any outstanding issues.  The real-time systems need to support nearly instant responses.  At the same time we have data retention and archiving requirements to keep much of these data online for some time and then in a dearchivable state C  Ad Hoc Organic Data Organization and Growth Nearly every engineering university graduate has had some programming experience and understands how to use a database.  Even though we have clear requirements for architectural review for new system connections and introductions, a large percentage of connections are created either by asking for a user account and then creating a stand alone application around the data usage or by first creating independent MS Access, PHP, or Perl applications that then urgentlyî need to be connected to factory systems to solve some pressing need In Fig. 1, a standard factory system with a well organized SOA architecture is shown, with the introduction of Ad Hoc data consumers and generators.  These ad hoc systems could eventually be migrated into or become new core systems but serve as a reminder that our systems today have a long way to go to offer universal and consistent data integration D  Yesterdayís Technology Today Traditionally, GLOBALFOUNDRIES was comprised of systems from Chartered Ltd and AMD which were focused on self-contained processes and reports. Analyses were either limited to information placed in a data warehouse using the older batched Extract Transfer and Load \(ETL\aradigm that could have a lag of hours or to specialized reports generated from separate run-time systems.  The data warehouse, for example, had data from the SiView MES, inline SPC results and engineering data from WET and SORT, but lacked data from advanced reticle handling and preventative maintenance activities.  Direct queries to quality systems were often performed as a side activity, and not well correlated with the other data.  The data warehouse in a single fab housed 40 terabytes and yet did not house any of the newer Interface-A tool data.  Similarly, reporting focused on MES WIP status and lacked access to data other than through some random run-time systems that were supposed to be used for decision services The staff used tools like APF RTD reports, which are familiar to dispatch writers but not well-suited for analysis or traditional scheduled static reports using applications like SAP Business Objects.  Both the data warehouse and WIP reporting did not stand up to the demands of more voluminous and real-time data.  The number of systems that have relevant data for each use case continues to increase Business Analysis and Reporting Factory Systems MQ Message Bus EI UI fra mew ork MES Siview APC SPC FDC RM S CMMS Decison Serv ices Integration Data Warehouse GEM-D eTEST Dispatch Scheduling Other Fabs/Corporate Systems Setup Ad Hoc App Ad Hoc Ad Hoc Replication  Fig. 1  Factory Systems with Ad Hoc applications 221 ASMC 2013 


The landscape has now changed.  GLOBALFOUNDRIES is focused on gathering data in real time, with less than 10 second latencies, in a new General Engineering and Manufacturing Data Warehouse \(GEM-D, see Fig. 2\aking advantage of Oracle GoldenGate feeds that have minimal impact to run-time systems and provide the data in easily joinable schemas.  These feeds were previously only used for decision services, but now are scaling across the enterprise New compression techniques are also utilized to reduce storage volumes.  GEM-D offers one stop shopping for users with specific organized data marts built on top. New Business Intelligence tools are used to empower the users to sort and sift through the newly accumulate d data with in-memory associative technology in a compressed form with associations defined between data items.  However, we are just beginning to enter the Big Data world.  As masking layers increase transistors shrink, tool data increase, and wafer sizes move to 450mm, there are challenges ahead for such data-centric companies  III  WHY  DO  WE  NEED  BIG  DATA  CAPABILITIES   Big Data analytics can reveal insights previously hidden by data that were too costly to process, such as sensor logs and wafer maps in conjunction with other factory information Being able to process every required item in a reasonable amount of time could increase throughput of the factory, skip sampling operations, ensure tool performance between maintenance cycles, promote an investigative approach to data in contrast to the somewhat static nature of running predetermined reports.  A large amount of data is already kept in the FAB archives unused since there is no cost effective way to process it and get value out of it. Some of the Big Data use cases are explained below A  Transparency Making Big Data more easily accessible to relevant stakeholders in a timely way can create tremendous value. Data are often compartmentalized within a single group in the fab Several departments have their own IT systems and unfortunately frequently store and maintain redundant data We need to have a free interchange of data among different department systems. Here at GLOBALFOUNDRIES a lot of teams were trying to gain access to the business process request information and wanted to use it for automation but that infrastructure only supported access to a copy refreshed every six hours. Real-time information for decisions was impossible. Also integrating data from R&D, engineering, and manufacturing units in the same fab and between fabs can significantly reduce the wasteful redundancy and improve much faster turnaround time for resolving issues and accelerate time to market B  Experimental Analysis Experimental analysis is critical in many areas of our fabs Ability to process huge amounts of data will open up the possibility of conducting new tests and analysis which were unimaginable earlier. This will have a dramatic effect in areas like R&D and will help achieve faster time to market C  Automated Algorithms Big Data can feed advanced analytics and algorithms to vastly improve the decision making process and identify valuable insights which were previously hidden or not easily available. Fabs can adjust production lines automatically to optimize efficiency, reduce waste, and avoid dangerous conditions. At GLOBALFOUNDRIES, we are already using controlled experiments to make better decisions by embedding real-time, highly granular data from networked sensors in the supply chain and production processes.  Automating the analysis of the data reported by sensors embedded in complex products combined with the tool owners input enables manufacturers to create proactive smart preventive maintenance service. Service personnel can perform the PM operations before there is an equipment failure which may cause costly fab disruptions.  Also this enables the fab to have a new business model like leasing the portions of fab space for specific customers based on the sensor data D  Virtual Factory Taking product development and historical data and real-time inputs from MES data, fabs can apply advanced computational methods to create a digital model of the entire manufacturing process.  This model can be used to design and simulate the most efficient production system. Some of the applications of virtual factory include: 1. validation of designed production concept; 2. processes verification before start of production; 3 optimization of production equipment allocation; 4. bottlenecks and collisions analysis; 5. better utilization of existing resources; 6. eliminating errors in the production line. Fab engineers can leverage the power of Big Data to simulate these operations with millions of different combinations to optimally schedule and dispatch WIP  IV  B IG D ATA S OUTIONS  As mentioned, there are several types of Big Data problems to be solved.  The computer science industry offers a few models.  Described here are the main variants and applicable uses.  A summary pros and cons list is provided in Table 1 and a corresponding radar chart, which includes traditional RDBMS, similar to GEM-D is shown in Fig. 3. The desirable solution would be the one which gets high score in all or most of the axes A  The Data Appliance Data appliance offerings include Oracle Exadata, IBM Netezza, and Teradataís platforms.  These solutions offer a complete closed solution with optimized hardware accelerators that scale according to the rack space.  These appliances offer access to data via traditional SQL, but indexing and queries are optimized by proprietary architectures that consist of query distributions and select statements offloaded from the CPU to specialized chips  222 ASMC 2013 


          000\012\000\010\000\020\001Ê\000\007\000\003\000\026\000ñ\000É\000â\000ã\000ê\000â\000\003 000\017\000É\000õ\000á\000î\000\003 000\021\000á\000ô\000\003\000\005\000\014\000\003 000\027\000ë\000ë\000é\000ï\000\003\001¨\000\003 000\025\000á\000í\000ë\000î\000ñ\000ï\000\003 000\025\000á\000É\000é\000\003\000ñ\000ã\000è\000á\000\003\000Ü\000É\000ñ\000É\000\003 000à\000á\000á\000Ü\000ï\000\003 000\012\000\010\000\020\001Ê\000\007\000\003\000\017\000ë\000â\000ã\000Ö\000É\000é\000\003 000é\000É\000õ\000á\000î\000\003 000\011\000É\000Ö\000ñ\000ë\000î\000õ\000\003\000\026\000ë\000ó\000î\000Ö\000á\000\003\000\026\000õ\000ï\000ñ\000á\000è\000ï\000\003  000\010\000\014\000\003\000é\000ë\000â\000ï\001·\000\003\000Ñ\000ã\000ñ\000è\000É\000í\000ï\001·\000\003\000ï\000õ\000ï\000ñ\000á\000è\000\003\000é\000ë\000â\000ï\001·\000\003\000\003 000ñ\000á\000ï\000ñ\000\003\000Ü\000É\000ñ\000É\000\003  Current State Future State Additions and Considerations 000\030\000ê\000ñ\000É\000í\000í\000á\000Ü\000\003\000\011\000É\000Ö\000ñ\000ë\000î\000õ\000\003\000\026\000ë\000ó\000î\000Ö\000á\000\003\000\026\000õ\000ï\000ñ\000á\000è\000ï\000\003 000\025\000á\000É\000é\000\003\000ñ\000ã\000è\000á\000\003\000É\000ê\000Ü\000\003 000É\000ó\000ñ\000ë\000è\000É\000ñ\000á\000Ü\000\003 000É\000ê\000É\000é\000õ\000ñ\000ã\000Ö\000ï\000\003 000\010\000ò\000É\000é\000ó\000É\000ñ\000ã\000ê\000â\000\003\000Ö\000ë\000è\000í\000î\000á\000ï\000ï\000ã\000ë\000ê\001·\000\003 000\014\000ê\001Ê\000è\000á\000è\000ë\000î\000õ\000\003\000É\000ê\000É\000é\000õ\000ï\000ã\000ï\000\003\000É\000ê\000Ü\000\003 000ä\000É\000î\000Ü\000ô\000É\000î\000á\000\003\000ï\000ë\000é\000ó\000ñ\000ã\000ë\000ê\000ï\000\003 000\021\000á\000ô\000\003 000\004\000ê\000É\000é\000õ\000ï\000ã\000ï\000\003 000\027\000ë\000ë\000é\000ï\000\003  000\014\000ê\000ñ\000á\000â\000î\000É\000ñ\000á\000Ü\000\003\000\014\000Ü\000á\000ê\000ñ\000ã\000ñ\000õ\000\003 000\020\000â\000è\000ñ\000\003 Fig. 2. The GEM-D Model 223 ASMC 2013 


 B  The Hadoop Derivative In order to scale to the petabytes of unstructured data \(not modeled in tables with well defined rows and columns Google introduced the Map Reduce paradigm that later was made available in the Hadoop Open Source project.  This has been extended with tools like HBase, Pig, Hive, etc. which improve the usability and reduce the complexity of the Map Reduce coding.  Using commodity hardware as a foundation Hadoop provides a layer of software that spans the entire grid turning it into a single system. Hadoop based solutions are provided by companies like Cloudera, Hortonworks and MapR C  Massive In Memory Database While the previous two models offer ways to scale to support larger amounts of data, a new model attempts to make larger amounts of data available in real time by placing the database in a highly available cluster of servers that keep all the data in memory.   This eliminates the need for indexing and I/O on the traditional drive storage is completely eliminated Some systems, such as SAP Hana, also flush data to disk for recovery scenarios. It is by far the fastest solution for critical structured data but comes with price tag D  Solid State Disk \(SSD There is yet another improvement to any of the other Big Data solutions or even the traditional model that addresses the speed of access. The hard drive storage itself can be moved to solid state.  These ìflash drivesî can be leveraged to all or just a subset of the data. SSD based solutions can be used with Hadoop systems to address the big data problems. Companies like Fusion-io, NetApp, EMC, etc. provide SSD based solutions  V  W HERE D O WE GO FROM H ERE  The path for the next level of data management is not yet defined.  Reporting and analysis has already moved beyond the single system or data set.  The factory data volumes are expanding rapidly.  The reader can see from Fig. 3 that there are significant tradeoffs with using these solutions.  The appliance covers a subset of the traditional RDBMS whereas the Hadoop paradigm covers new territory A  A call for action We appeal to our vendors to work together to leverage Big Data strategies within their product offerings.  Several things can be done to help including   Provide schemas that are portable and not locked into specific RDBS providers   Provide Map-Reduce stubs that can be grouped together with other such routines.  This applies to tool vendors log files, test file output and otherwise untapped data today   Leverage SOA architectures using interchangeable message buses for communication   Work together to offer a standard nomenclature of objects to better tie system data together   Expect to work with new analytic tools for analysis and reporting not requiring proprietary reporting platforms and perhaps providing components or models for BI solutions B  Big Data Environment We are looking to provide vendors the opportunity to test their Big Data platforms in our lab.  Our state of the art test environment has been an environment where vendors have introduced hardware and software solutions and see how they work together with other factory applications   Fig. 3. Comparison chart of Big Data technologies  VI  C ONCLUSION  We are entering a new realm of data management Solutions will perhaps take several forms.  As the complexity of our needs scale, we need our suppliers to move away from stand alone proprietary infrastructure, reporting and offer plugand-play components A CKNOWLEDGMENT  The authors would like to thank the Data Integration and IT DBA teams at GLOBALFOUNDRIES in deploying GEM-D and making the current solutions a reality    224 ASMC 2013 


TABLE I  T ECHNOLOGY P ROS AND C ONS  Technology Pros Cons Appliance RDBMS    Very mature. Long history of successful installation   Can be used by multiple user types, from Business users using reporting tools through SQL novices and expert users   Vendors like Teradata support data volume in petabyes   Custom hardware accelerates query and transformations   Fault Tolerance is only at transaction level cannot survive node failure   Supports only structured data   Homogenous hardware - all nodes in the installation must be the same   Disk based data storage. Limited real-time analysis capabilities compared to in-memory technologies   OLTP and OLAP layers are separate   More expensive compared to open source solutions Hadoop    Data volumes in Petabytes   Open source   Commodity hardware and inexpensive   Fault tolerant, designed to survive multiple node failures   Supports both structured and unstructured data. Data can be operated on in native format   Heterogeneous hardware, the nodes in the installation can be different   Currently it only has batch processing capabilities. Real-time data processing is still under works   Requires programming skills to work with Smaller pool of individuals capable of performing these tasks   Relatively new technology. The source is continuously under development with new features being added In Memory DB   In-memory. Real-time analysis   Single foundation for OLTP+OLAP   No need for Indexing   Data volume in terabytes. Doesn't scale to petabyte size currently   Very expensive. Enterprise level toolset Proprietary hardware and software   Limited fault tolerance capabilities SSD   Very high performance   No spinning Disks   Consumes less power and space   Leverage existing software architecture and data base systems, improving virtually any disk-based solution   Very expensive. About ten times that of a standard hard drive   Limited no. of writes, thus limiting the life of the device   Cannot scale out   Relatively less reliable    R EFERENCES  1  J Manyika, M Chui, B Brown, J Bughin, R Dobbs, C Roxburgh, A H Byers, McKinsey Global Institute Publication "Big data: The next frontier for innovation, competition, and productivity 2  J G Kobielus, ìThe Forrester Waveô: Enterprise Hadoop Solutions Q1 2012 3  A McClean, R. C. ConceiÁ„o, M OíHalloran, "A Comparison of MapReduce and Parallel Database Management Systems ICONS 2013, The Eighth International Conference on Systems  4  Big Data Now: 2012 Edition" OíReilly Media, Inc  5  http://blogs.gartner.com/merv-adrian/2013/02/10/hadoop-and-di-aplatform-is-not-a-solution  6  http://www.saphana.com/community/blogs/blog/2012/04/30/whatoracle-wont-tell-you-about-sap-hana  7  http://www.dbms2.com/2012/08/20/in-memory-hybrid-memorycentric  8  http://hadoop.apache.org  9  http://en.wikipedia.org/wiki/MapReduce    http://en.wikipedia.org/wiki/Big_data    http://www.datanami.com/datanami/2012-0213/big_data_and_the_ssd_mystique.html  225 ASMC 2013 


Michael Armbrust, Armando Fox and Rean Griffith et al. A view of cloud computing [J  C o m m un i c a t i ons of th e A C M Vol 53 No 4, A p ri l 2010 2 Patel Patel, Ranabahu Ajith and Sheth Amit. Service Level Agreement in Cloud Computing [C I n C l ou d W o rk s h op a t OOPSL A  2 0 0 9   3 Mell P., Grance T. The NIST De\002nition of Cloud Computing. National Institute of Standards and Technology, Information Technology Laboratory, USA 4 D. Hyde. A Survey on the Security of Virtual Machines. Dept. of Comp Science, Washington Univ., 2009 5 Arvind Seshadri, Mark Luk, Ning Qu, Adrian Perrig: SecVisor: a tiny hypervisor to provide lifetime kernel code integrity for commodity OSes C S O S P 2 0 07 33 53 5 0   6 Fengzhe Zhang, Jin Chen, Haibo Chen, Binyu Zang CloudVisor retrofitting protection of virtual machines in multi-tenant cloud with nested virtualization [C S O S P 2 0 11 20 32 1 6  7 Maurice Gagnaire, Felipe Diaz, et al. Downtime statistics of current cloud solutions. IWGCR 2012 8 Qiang Guan, Song Fu. Auto-AID: A data mining framework for autonomic anomaly identification in networked computer systems C  I P CCC 2 0 1 0  7 3 8 0  9 Ripal Nathuji, Aman Kansal and Alireza Ghaffarkhah. Q-clouds managing performance interference effects for QoS-aware clouds [C  EuroSys 2010:237-250  Yongmin Tan, Hiep Nguyen, Zhiming Shen, Xiaohui Gu, Chitra Venkatramani, Deepak Rajan. PREPARE: Predictive Performance Anomaly Prevention for Virtualized Cloud Systems [C   I C DC S 2012:285-294  Yongmin Tan, Xiaohui Gu, Haixun Wang. ALERT:Adaptive system anomaly prediction for large-scale hosting infrastructures [C  PODC 2010: 173-182  Qiang Guan, Ziming Zhang, Song Fu. Ensemble of Bayesian Predictors and Decision Trees for Proactive Failure Management in Cloud Computing Systems [J J C M 7 1  5 2 61 2 01 2    Qiang Guan, Chi-Chen Chiu, Ziming Zhang, Song Fu. Efficient and Accurate Anomaly Identification Using Reduced Metric Space in Utility Clouds [C A S 20 1 2  2 0721 6   Husanbir S. Pannu, Jianguo Liu, Song Fu. AAD: Adaptive Anomaly Detection System for Cloud Computing Infrastructures [C   SR DS  2012:396-397  Song Fu. Performance Metric Selection for Autonomic Anomaly Detection on Cloud Computing Systems [C L O B ECO M 2 0 11 15   Daniel Dean, Hiep Nguyen, and Xiaohui Gu. UBL: Unsupervised behavior learning for predicting performance anomalies in virtualized cloud systems  A C M I C A C  2 012   Chengwei Wang, Vanish Talwar, Karsten Schwan, Parthasarathy Ranganathan. Online detection of utility cloud anomalies using metric distributions [C   NOM S 20 10 96 103   Stefano Ferretti, Vittorio Ghini, Fabio Panzieri, Michele Pellegrini, Elisa Turrini: QoS-Aware Clouds [C  I E E E CL OUD 2010:321-328  Deepayan Chakrabarti, Ravi Kumar, Andrew Tomkins  Evolutionary clustering [C   A C M SI GKDD I n t e r n a t i ona l C o n f e r e n c e on K n ow l e d g e  Discovery & Data Mining \(KDD\ 2006:554-560  Yun Chi, Xiaodan Song, Dengyong Zhou, Koji Hino, Belle L Tseng On evolutionary spectral clustering [J  A C M T r ans act io ns o n  Knowledge Discovery from Data, Vol. 3, No. 4, 2009  Yun Chi, Xiaodan Song, Dengyong Zhou, et al. Evolutionary spectral clustering by incorporating temporal smoothness [C  A C M SI GKDD  International Conference on Knowledge Discovery & Data Mining KDD\, 2007:153-162  Ulrike Luxburg. A tutorial on spectral clustering [J   S t at ist ics a n d  Computing \(SAC\\(4\7    
 
occasion, the labels were determined based on the upper SLO Thus, other attributes might interfere with its precision. We would improve it in the future works VI C ONCLUSION  In this paper, we proposed a framework named eCAD from an evolutionary view to identify anomalies in the IaaS cloud. To illustrate our framework, we established a VICCI cloud equipped with HADOOP benchmarks. Our experiment reveals that the evolutionary clustering method can identify cloud anomalies more precisely than its counterparts especially for the traditional static clustering approach Moreover, our framework can also infer the reasons for the above anomalies As immediate future work, we plan to simulate more scenarios with other injected errors. With the accumulation of the anomalies, they might come into being a whole anomaly cluster, which would also be solved within our following researches R EFERENCES  1 
                      
334 
334 


14.0 12.0 10.0 8.0 6.0 4.0 2.0 0.0 
021\017\013\003\021#\012\004 020\021\017\004 022\017\007\023 023\005 017\011\012\013\021\032 017\005\004\007\017 023\007\012\004\021\032\005\012\021 Execution Time Ratio of Primary-backup Paradigms Comparing to HDFS Mapreduce Jobs Running on OAMS and Others 
Figure 6 Overall measurement V CONCLUSION AND FUTURE WORK In this paper a highly metadata service OAMS was proposed for big data storage Different from traditional primary-backup paradigms OAMS depends on more than one standby to take over the active in cluster le system It is based on the built-in shared storage pool and employs a series of protocols to tolerate multiple points of failures OAMS achieves an automatic state transition in the form of hot standby Besides it supports server self-recovery and dynamical addition for standbys at runtime Measurements show that OAMS can obviously improve the system reliability while keeping the performance with little degradation In the future we intend to optimize and expand the policy such as supporting failover in the cluster le system with multiple metadata servers A CKNOWLEDGMENT This work is supported by the National High-Tech Research and Development Program of China under grant numbered 2011AA01A203 2013AA013204 also supported by the National HeGaoJi Key Project under grant numbered 2013ZX01039-002-001-001 and Strategic Priority Research Program of the Chinese Academy of Sciences under grant numbered XDA06030200 R EFERENCES  J Dean and S Ghema w at Mapreduce Simpliìed data processing on large clusters in 
BackupNode HA with NFS HA with QJM OAMS with 1A2S OAMS with 1A1S1J OAMS with 1A2J 
Sixth Symposium on Operating System Design and Implementation OSDI 04 Seventh Symposium on Operating System Design and Implementation OSDI 06 19th Symposium on Operating Systems Principles SOSP 03 26th IEEE Transactions on Computing Symposium on Mass Storage Systems and Technologies Mass Storage Systems and Technologies in Cooperation with the 17th IEEE Symposium on Mass Storage Systems ACM Computing Surveys Proc of the 2011 ACM SIGMOD International Conference on Management of data Proc of the Summer USENIX conference 13th Symposium on Operating Systems Principles Research report Systems Research Center Digital Equipment Corporation Markov Chains Principles of Distributed Database Systems 
 San Francisco USA Dec 2004 pp 137Ö150  F  Chang J Dean S Ghema w at W  C Hsieh D A Wallach M Burrows T Chandra A Fikes and R E Gruber Bigtable A distributed storage system for structured data in  Seattle USA Nov 2006 pp 205Ö218  S Ghema w at H Gobiof f and S T  Leung The Google le system in  New York USA Oct 2003 pp 29Ö43  K Shv achk o H K uang S Radia and R Chansler  The Hadoop distributed le system in  Incline Village USA May 2010 pp 1Ö10  A Barry  J Brasso w  R Cattelan A Manthei E Nygaard S V Oort D Teigland M Tilstra M OKeefe G Erickson and M Agarwal Implementing journaling in a Linux shared disk le system in  Maryland USA Mar 2000 pp 351Ö378  T  Haerder and A Reuter  Principles of transaction-oriented database recovery  vol 15 no 4 pp 287Ö317 1983  F  Haas P  Reisner  and L Ellenber g The DRBD user s guide LINBIT Information Technologies GmbH 2009  D Borthakur  J S Sarma J Gray  K Muthukkaruppan N Spiegelberg H Kuang K Ranganathan D Molkov A Menon S Rash R Schmidt and A Aiyer Apache Hadoop goes realtime at Facebook in  Athens Greece Jun 2011 pp 1071Ö1080  R Sandber g D Goldber g S Kleiman D W alsh and B Lyon Design and implementation of the Sun network lesystem in  Portland USA Jun 1985 pp 119Ö130  Cloudera homepage Online A v ailable http://www.cloudera.com  Apache hadoop Online A v ailable http://hadoop.apache.or g  Apache BookK eeper  Online A v ailable http://zookeeper.apache.org/bookkeeper  W  Lin M Y ang L Zhang and L Zhou P aciìca Replication in log-based distributed storage systems Technical Report MSR-TR-2008-25 Microsoft Research Tech Rep 2008  B Lisk o v  S Ghema w at R Gruber  P  Johnson L Shrira and M Williams Replication in the Harp le system in  California USA Oct 1991 pp 226Ö238  G Sw art A Birrell A Hisgen and T  Mann  A v ailability in the Echo le system in  Citeseer 1993  J R Norris  Cambridge University Press 1998  L Lamport The part-time parliament  Research Report 49 Systems Research Center Digital Equipment Corporation Tech Rep 1989  M T   Ozsu and P Valduriez  Springer 2011  Apache ZooK eeper  Online A v ailable http://zookeeper.apache.org 
since OAMS has highly improved the reliability of metadata service while having little effects on performance        
1294 
1294 


607 


608 


  11 that it will be able to meet all of the Van Allen Probes communications goals with its intended ground segments A CKNOWLEDGEMENTS  This work was performed with the support of the Radiation Belt Storm Probes mission under NASA\222s Living with a Star program. The authors would like to thank Rick Fitzgerald and Kim Cooper, Van Allen Probes project managers at JHU/APL for supporting this work. There are many at JHU/APL who contributed to the development and verification of the RF system. Significant technical contributions were made by: Christopher Haskins, Bob Wallis, Matthew Angert, Laurel Funk, Joe Sheehi, Wesley Millard, Norman Adams, Lloyd Ellis, Sheng Cheng, John Daniels, Phillip Huang, Avi Sharma, Carl Herrmann, David Jones, Brian Bubnash, Melanie Bell, Horace Malcom Michael Pavlick, Mark Bernacik, Christopher Deboy, Bob Bokulic, Sharon Ling, Albert Hong, Erik Hohlfeld, Judy Bitman, William Dove and Tony Garcia. Significant contributions were also made by the USN and TDRSS compatibility test teams  R EFERENCES  1 eck D. G.; Mau k  B  H.; Greb o w sk y  J  M.; Fo x  N J, \223The Living With a Star Radiation Belt Storm Probes Mission and Related Missions of Opportunity 224 American Geophysical Union, Fall Meeting 2006   h o rs k i y  A Y., Mauk B. H., Fox N. J Sibeck D G., Grebowsky, J. M., \223Radiation belt storm probes Resolving fundamental physics with practical consequences,\224 Journal of Atmospheric and SolarTerrestrial Physics Vol. 73, Issues 11-12, July 2011 Pages 1417-1424   S. Bu s h m a n M. Bu tler, R C o n d e, K. Fretz, C  Herrmann, A. Hill, R. Maurer, R. Nichols, G. Ottman M. Reid, G. Rogers, D. Srinivasan, J. Troll, B. Williams 223Radiation Belt Storm Probe Spacecraft and Impact of Environment on Spacecraft Design,\224 Proceedings of the 2012 IEEE Aerospace Conference, Big Sky Montana USA, March 3-10, 2012   opelan d D.J DeB o y C  C R o y s ter, D.W., Dov e  W.C., Srinivasan, D.K,. Bruzzi, J.R., Garcia, A., "The APL 18.3m station upgrade and its application to lunar missions," Aerospace Conference, 2010 IEEE , vol., no pp.1-10, 6-13 March 2010    Figure 10. FER/BER performance for all downlink modes for RF GSE, SCF, USN, and TDRSS 


  12  iv as a n D. K., A r ti s  D  A Bak er, R  B., Stil w e ll, R   K., Wallis, R. E., \223RF Communications Subsystem for the Radiation Belt Storm Probes,\224  Acta Astronautica vol 65, issue 11-12, December 2009, Pages 1639-1649   k i n s  C B., Mi llard, W P 223 M u l t i Ban d  So f t w a re Defined Radio for Spaceborne Communications Navigation, Radio Science, and Sensors,\224 2010 IEEE Aerospace Conference, March 2010  k i n s  C B., Mi llard, W P A d a m s  N. H Sri n i v a s a n  D. K., Angert, M. P., \223The Frontier Software-Defined Radio: Mission-Enabling, Multi-Band, Low-Power Performance,\224 61st  International Astronautical Congress IAC-10.B2.5.11, October 2011 8  Crowne, M.J.,  Haskins, C. B., Wallis, R. E.,  Royster D.W, \223Demonstrating TRL-6 on the JHU/APL Frontier Radio for the Radiation Belt Storm Probe mission,\224 2011 IEEE Aerospace Conference, March 2011  o ckw ood, M. K K i n n i s o n  J., F o x  N C o n d e, R  Driesman, A., \223Solar Probe Plus Mission Definition,\224 63rd  International Astronautical Congress, IAC 12.A3.5.2, October 2012   i t m a n J  223An I n D ept h  L o o k at t h e R a dio Freq u e n c y    Ground Support Equipment for the Radiation Belt Storm  Probes Mission,\223 IEEE Autotestcon, 2011, September 2011  d a m s  N.H., Bi t m a n J C opela n d D. J Sri n ivas a n  D  K.,  Garcia. A., \223RF Interference at Ground Stations Located in Populated Areas,\224 2013 IEEE Aerospace Conference, March 2013  B IOGRAPHY  Matthew J. Crowne is a member of the Senior Professional Staff of the RF Engineering group in JHU/APL\222s Space Department. He received his B.S from Johns Hopkins University in 2000 and his M.S. from the same university in 2009, both in electrical engineering Matthew joined JHU/APL in 2007 where he has been working on the development of radios for spaceflight communications systems. Prior to joining JHU/APL, he worked for Integrated Defense Systems Inc., where he developed solid state power amplifiers for electronic warfare and communication systems. Matthew was the integration and test lead for the Van Allen Probes RF communication system and is currently working on the Solar Probe Plus mission   Dipak K. Srinivasan is the supervisor of the RF Systems Engineering Section in the JHU/APL Space Department. He received his B.S. and M.Eng. in electrical engineering in 1999 and 2000 in electrical engineering from Cornell University, and an M.S. in applied physics from The Johns Hopkins University in 2003. Dipak joined the APL Space Department in 2000, where he has served as the lead RF Integration and Test Engineer for the CONTOUR and MESSENGER spacecraft and lead mission system verification engineer for the New Horizons project. He is currently the Lead RF Telecommunications Systems Engineer for the MESSENGER and Van Allen Probes missions and chairs technical sessions at the annual International Astronautical Congress  Darryl W. Royster is a member of the Senior Professional Staff in the RF Engineering Group at JHU/APL.  He led compatibility testing for the Van Allen Probes, STEREO, and MESSENGER missions.  Previously he was the System Engineer for the Satellite Communications Facility at JHU/ APL and the lead RF Integration and Test Engineer for the STEREO spacecraft.  Prior to joining the JHI/APL Space Department in 2001, Mr. Royster designed cellular and land mobile radio products for Ericsson, GE and Motorola.  He received his B.S. and M.S. in electrical engineering from Virginia Polytechnic Institute and State University in 1982 and 1984, respectively  Gregory L. Weaver joined the Senior Professional Staff of JHU/APL in 2003 and works within the RF Engineering Group of the Space Department.  He is a technologist with extensive background in the technical and business aspects of the frequency control industry and has held positions as a senior design engineer, technical manager and marketing strategist over a 25 year career history, including vice president positions with Bliley Technologies Inc. and the former Piezo Crystal Company. He received his M.S in Technology Management from the University of Pennsylvania in 1993 and his B.S. in Physics from Dickinson College in 1982.  He is a licensed professional engineer in the state of Pennsylvania, member of the IEEE and the UFFC Societ y.  He has contributed to the technical proceedings of the IEEE International Frequency Control Symposium, Precise Time and Time Interval Systems and Application Meeting and the European Frequency and Time Forum   


  13 Daniel Matlin is an Associate Professional Staff at JHU/APL and a member of the RF engineering group in the Space department.  He went through a dual Bachelors/Masters program at Johns Hopkins University graduating with his Bachelor of Science in Electrical Engineering in 2008 and his Masters of Science in Engineering from the Electrical Engineering department in 2009.  As a student he specialized in RF systems design.  Mr. Matlin started at the JHU/APL in February of 2010 and in his short time with the lab has been privileged to work on various tasks supporting the RBSP program, including supporting a successful launch and early operations.  Mr. Matlin assisted in the qualification testing for the flight DSP slices as well as the integrated flight transceivers.  He also carried out electrical testing and flight qualification of the newly designed Hypertronics stacking connectors as well as components and cables used for the RF subsystem  Nelli Mosavi is an EMC and RF Engineer in the JHU/APL Space Department, RF Systems Engineering section. She received a B.S. degree in Electrical Engineering from Oakland University Michigan in 2004 and an M.S. in Electrical Engineering from The Johns Hopkins University in 2010. She is currently working toward her Ph.D. at the University of Maryland Baltimore County. She joined APL in 2009 and has since been working on RF and EME issues on the Van Allen Probes mission. Nelli previously worked for SENTEL Corporation, General Motors, DENSO International, and Molex Automotive   


APPENDIX 3ñ RESULTS \(SEM I-PROFESSIONAL DSLRS     Run by TFDEA add-in ver 2.1 Frontier Type Orientation 2nd Goal Return to Scale Avg RoC Frontier Year MAD Dynamic OO Max CRS 1.124802 2008 1.394531 Input\(s Output\(s SOA products at Release SOA products on Frontier RoC contributors Release before forecast Release after forecast 22166527 DMU Name Date Efficiency_R Efficiency_F Effective Date Rate of Change Forecasted Date 1 Nikon D100 2002 1 1.66666667 2007.000000 1.107566 2 Olympus E1 2003 1 1.666666667 2007.000000 1.136219 3 Pentax *ist D 2003 1 1.358024691 2007.000000 1.079511 4 Nikon D20 0 2005 1 1.2 2007.000000 1.095445 5 Canon EOS 5D 2005 1 1.664796311 2007.730028 1.205269 6 Pentax K10D 2006 1 1 2006.000000  7Nikon D30 0 2007 1 1 2007.000000  8 Olympus E3 2007 1 1 2007.000000  9 Sony Alpha DSLR A70 0 2007 1 1 2007.000000  1 0 Nikon D70 0 2008 1.46 1.46 2007.000000  11 Canon EOS 5D Mark II 2008 1.065464119 1.065464119 2008.000000  12 Sony Alpha DSLR A90 0 2008 1 1 2008.000000  13 Olympus E3 0 2008 1.02 1.02 2007.000000  1 4 Pentax K20D 2008 1 1 2008.000000  15 Nikon D300s 2009 1.142857143 0.874450785 2007.000000  2008.140742 16 Canon EOS 7D 2009 1 0.754166667 2007.000000  2009.399022 17 Sony Alpha DSLR A85 0 2009 1 0.774820627 2008.000000  2010.169290 18 Pentax K-7 2009 1 0.772738276 2006.503130  2008.695302 19 Olympus E5 201 0 1.466133763 1.173333333 2007.000000   2 0 Pentax K-5 201 0 1.009024674 0.776190476 2007.000000  2009.15427 0 21 Nikon D80 0 2012 1 0.686950618 2008.000000  2011.192776 22 Canon EOS 5D Mark III 2012 1.115010291 0.930769231 2007.502755  2008.112786 23 Pentax K-5 II 2012 1 0.632075669 2006.839705  2010.740375 24 Sony Alpha SLT A99 2012 1.009662059 0.854117647 2007.640496  2008.981286 Results 2129 2013 Proceedings of PICMET '13: Technology Management for Emerging Technologies 


