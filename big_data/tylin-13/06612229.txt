Abstract\227 Velocity in Big data is a concept which deals with the speed of the data coming from various sources. This characteristic is not being limited to the speed of incoming data but also speed at which the data flows. For example the data from the sensor devices would be constantly moving to the database store and this amount won\222t be small enough. Thus our traditional systems are not capable enough on performing the analytics on the data which is constantly in motion Variability considers the inconsistencies of the data flow Data loads become challenging to be maintained especially with the increase in usage of the social media which generally causes peak in data loads with certain events occurring User can run certain queries against the data stored and thus can deduct important results from the filtered data obtained and can also rank it according to the dimensions they require. These reports help these people to find the business trends according to which they can change their strategies As the data stored by different organizations is being used by them for data analytics. It will produce a kind of gap inbetween the Business leaders and the IT professionals the main Keywords\227 Big data; Hadoop; Hadoop Distributed File System MapReduce I  I NTRODUCTION Data is growing at a huge speed making it difficult to handle such large amount of data \(exabytes\.The main difficulty in handling such large amount of data is because that the volume is increasing rapidly in comparison to the computing resources. The Big data term which is being used now a days is kind of misnomer as it points out only the size of the data not putting too much of attention to its other existing properties Big data can be defined with the following properties associated with it Big data is defined as large amount of data which requires new technologies and architectures so that it becomes possible to extract value from it by capturing and analysis process. Due to such large size of data it becomes very difficult to perform effective analysis using the existing traditional techniques. Big data due to its various properties like volume velocity, variety, variability, value and complexity put forward many challenges. Since Big data is a recent upcoming technology in the market which can bring huge benefits to the business organizations, it becomes necessary that various challenges and issues associated in bringing and adapting to this technology are brought into light. This paper introduces the Big data technology along with its importance in the modern world and existing projects which are effective and important in changing the concept of science into big science and society too. The various challenges and issues in adapting and accepting Big data technology, its tools \(Hadoop\also discussed in detail along with the problems Hadoop is facing. The paper concludes with the Good Big data practices to be followed D. Variability  F. Value  A. Variety Big Data: Issues, Challenges, Tools and Good Practices Avita Katal                                                 Mohammad Wazid R H Goudar Department of CSE                                                  Department of CSE Department of CSE  Graphic Era University                                            Graphic Era University Graphic Era University Dehradun, India                                                        Dehradun, India Dehradun, India  avita207@gmail.com                                          wazidkec2005@gmail.com rhgoudar@gmail.com   C. Velocity  B. Volume E. Complexity The Big word in Big data itself defines the volume At present the data existing is in petabytes and is supposed to increase to zettabytes in nearby future. The social networking sites existing are themselves producing data in order of terabytes everyday and this amount of data is definitely difficult to be handled using the existing traditional systems It is quite an undertaking to link, match, cleanse and transform data across systems coming from various sources. It is also necessary to connect and correlate relationships hierarchies and multiple data linkages or data can quickly spiral out of control Data being produced is not of single category as it not only includes the traditional data but also the semi structured data from various resources like web Pages, Web Log Files, social media sites, e-mail, documents, sensor devices data both from active passive devices. All this data is totally different consisting of raw, structured, semi structured and even unstructured data which is difficult to be handled by the existing traditional analytic systems 


The designing of such systems which would be able to handle such large amount of data efficiently and effectively Domain Description  C. Risk Analysis Big Science It becomes important for financial institutions to model data in order to calculate the risk so that it falls under their acceptable thresholds. A lot amount of data is potentially underutilized and should be integrated within the model to determine the risk patterns more accurately The second challenge is to filter the most important data from all the data collected by the organization. In other words we can say adding value to the business In this paper we have presented the main issues and challenges along with the complete description of the technologies/methods being employed for tackling the storage and processing problems associated with Big Data. The paper concludes with the good Big data practices to be followed II.    RELATED WORK In paper [1 e i s sues and chal le ng es  in Big d a ta a r e discussed as the authors begin a collaborative research program into methodologies for Big data analysis and design In e au t hor di s c uss es abo u t t h e tradi t i on al  databases and the databases required with Big data concluding that the databases don\222t solve all aspects of the Big data problem and the machine learning algorithms need to be more robust and easier for unsophisticated users to apply. There is the need to develop a data management ecosystem around these algorithms so that users can manage and evolve their data, enforce consistency properties over it and browse visualize and understand their algorithm results. In paper [3  architectural considerations for Big data are discussed concluding that despite the different architectures and design decisions, the analytics systems aim for Scale-out, Elasticity and High availability. In paper l th e con cepts of Big d ata along with the available market solutions used to handle and explore the unstructured large data are discussed. The observations and the results showed that analytics has become an important part for adding value for the social business. This paper [5  pro poses t h e Sci en ti f ic D ata I n f r astructu r e  S DI generic architecture model. This model provides a basis for building interoperable data with the help of available modern technologies and the best practices. The authors have shown that the models proposed can be easily implemented with the use of cloud based infrastructure services provisioning model In h e autho r  in v es tigat es  the  diff e r en ce in Bi g data applications and how they are different from the traditional methods of analytics existing from a long time. In paper [7  authors have done analysis on Flickr, Locr, Facebook and Google+ social media sites. Based on this analysis they have discussed the privacy implications and also geo-tagged social media; an emerging trend in social media sites. The proposed concept in this paper helps users to get informed about the data relevant to them in such large social Big data III.     IMPORTANCE OF BIG DATA AND VARIOUS PROJECTS  Big data is different from the data being stored in traditional warehouses. The data stored there first needs to be cleansed documented and even trusted. Moreover it should fit the basic structure of that warehouse to be stored but this is not the case with Big data it not only handles the data being stored in traditional warehouses but also the data not suitable to be stored in those warehouses. Thus there comes the point of access to mountains of data and better business strategies and decisions as analysis of more data is always better A. Log Storage in IT Industries  D. Social Media  The most use of Big data is for the social media and customer sentiments. Keeping an eye on what the customers are saying about their products helps business organizations to get a kind of customer feedback. This feedback is then used to modify decisions and get more value out of their business TABLE I.        VARIOUS BIG DATA PROJECTS concern of business leaders would be to just adding value to their business and getting more and more profit unlike the IT leaders who would have to concern with the technicalities of the storage and processing. Thus the main challenges that exist for the IT Professionals in handling Big data are IT industries store large amount of data as Logs to deal with the problems which seem to be occurring rarely in order to solve them. But the storage of this data is done for few weeks or so though these logs need to be stored for longer duration because of their value. The Traditional Systems are not able to handle these logs because of their volume, raw and semi structured nature. Moreover these logs go on changing with the s/w and H/w updates occurring. Big data analytics not only does analysis on the whole /large data available to pinpoint the point of failures but also would increase the longevity of the log storage Massive amount of sensor data is also a big challenge for Big data. All the industries at present dealing with this large amount of data make use of small portion of it for analysis because of the lack of the storage infrastructure and the analysis techniques. Moreover sensor data is characterized by both data in motion and data at rest. Thus safety, profit and efficiency all require large amount of data to be analyzed for better business insights 1. The Large Hadron Collider \(LHC\d's largest and highest-energy particle accelerator with the aim of allowing physicists to test the predictions of different B. Sensor Data  


A. Privacy and Security D. Analytical challenges  B.  Data Access and Sharing of Information Another important consequence arising would be Social stratification where a literate person would be taking advantages of the Big data  predictive analysis and on the other hand underprivileged will be easily identified and treated worse Big Data used by law enforcement will increase the chances of certain tagged people to suffer from adverse consequences without the ability to fight back or even having knowledge that they are being discriminated What if data volume gets so large and varied and it is not known how to deal with it Private Sector C. Storage and Processing Issues 1.  Amazon.com handles millions of back-end operations every day, as well as queries from more than half a million third-party sellers. The core te chnology that keeps Amazon running is Linux-based and as of 2005 they had the world\222s three largest Linux databases, with capacities of 7.8 TB, 18.5 TB, and 24.7 TB 2. Walmart is estimated to store about more than 2.5 petabytes of data in order to handle about more than 1 million customer transactions every hour 3.FICO Falcon Credit Card Fraud Detection System protects 2.1 billion active accounts world-wide theories of particle physics and high-energy physics. The data flow in experiments consists of 25 petabytes \(as of 2012\fore replication and reaches upto 200 petabytes after replication 2. The Sloan Digital Sky Survey is a multi-filter imaging and spectroscopic redshift survey using a 2.5-m wide-angle optical telescope at Apache Point Observatory in New Mexico, United States. It is Continuing at a rate of about 200 GB per night and has mo re than 140 terabytes of information  The personal information of a person when combined with external large data sets leads to the inference of new facts about that person and it\222s possible that these kinds of facts about the person are secretive and the person might not want the Data Owner to know or any person to know about them Government How to find out which data points are really important 1. The Obama administration project is a big initiative where a Government is trying to find the uses of the big data which eases their tasks somehow and thus reducing the problems faced. It includes 84 different Big data programs which are a part of 6 different departments 2. The Community Comprehensive National Cyber Security initiated a data center, Utah Data Center \(United States NSA and Director of National Intelligence initiative which stores data in scale of yottabytes. Its main task is to provide cyber security If data is to be used to make accurate decisions in time it becomes necessary that it should be available in accurate complete and timely manner. This makes the Data management and governance process bit complex adding the necessity to make Data open and make it available to government agencies in standardized manner  with standardized APIs, metadata and formats thus leading to better decision making, business intelligence and productivity improvements Expecting sharing of data between companies is awkward because of the need to get an edge in business. Sharing data about their clients and operations threatens the culture of secrecy and competitiveness Information regarding the users \(people\is collected and used in order to add value to the business of the organization. This is done by creating insights in their lives which they are unaware of Information and Communication Technologies for Development \(ICT4D\ses the Information and Communication Technologies \(ICTs\ for the socioeconomic development, human rights and international developm ent. Big data can make important contributions to international development The storage available is not enough for storing the large amount of data which is being produced by almost everything Social Media sites are themselves a great contributor along with the sensor devices etc Because of the rigorous demands of the Big data on networks, storage and servers outsourcing the data to cloud may seem an option. Uploading this large amount of data in cloud doesn\222t solve the problem. Since Big data insights require getting all the data collected and then linking it in a way to extract important information. Terabytes of data will take large amount of time to get uploaded in cloud and moreover this data is changing so rapidly which will make this data hard to be uploaded in real time. At the same time, the cloud's distributed nature is also problematic for Big data analysis. Thus the cloud issues with Big Data can be categorized into Capacity and Performance issues The transportation of data from storage point to processing point can be avoided in two ways. One is to process in the storage place only and results can be transferred or transport only that data to computation which is important. But both these methods would require integrity and provenance of data to be maintained Processing of such large amount of data also takes large amount of time. To find suitable elements whole of data Set needs to be Scanned which is somewhat not possible .Thus Building up indexes right in the beginning while collecting and storing the data is a good practice and reduces processing time considerably The main challenging questions are as International Development IV.     BIG DATA CHALLENGES AND ISSUES Does all data need to be stored Does all data need to be analyzed How can the data be used to best advantage It is the most important issue with Big data which is sensitive and includes conceptual, technical as well as legal significance 


2 Scalability E. Skill Requirement 4 Heterogeneous Data A. Hadoop F. Technical Challenges 1\ Fault Tolerance 3\uality of Data Big data brings along with it some huge analytical challenges The type of analysis to be done on this huge amount of data which can be unstructured, semi structured or structured requires a large number of advance skills. Moreover the type of analysis which is needed to be done on the data depends highly on the results to be obtained i.e. decision making. This can be done by using one using two techniques: either incorporate massive data volumes in analysis or determine upfront which Big data is relevant With the incoming of new technologies like Cloud computing and Big data it is always intended that whenever the failure occurs the damage done should be within acceptable threshold rather than beginning the whole task from the scratch. Fault-tolerant computing is extremely hard involving intricate algorithms. It is simply not possible to devise absolutely foolproof, 100% reliable fault tolerant machines or software. Thus the main task is to reduce the probability of failure to an "acceptable" level. Unfortunately the more we strive to reduce this probability, the higher the cost Two methods which seem to increase the fault tolerance in Big data are as: First is to divide the whole computation being done into tasks and assign these tasks to different nodes for computation. One node is assigned the work of observing that these nodes are working properly. If something happens that particular task is restarted But sometimes it\222s quite possible that that the whole computation can\222t be divided into such independent tasks There could be some tasks which might be recursive in nature and the input of the previous task is the input to the next computation. Thus restarting the whole computation becomes cumbersome process. This can be avoided by applying Checkpoints which keeps the state of the system at certain intervals of the time. In case of any failure, the computation can restart from last checkpoint maintained The processor technology has changed in recent years. The clock speeds have largely stalled and processors are being built with more number of cores instead Previously data processing systems had to worry about parallelism across nodes in a cluster but now the concern has shifted to parallelism within a single node. In past the techniques which were used to do parallel data processing across data nodes aren\222t capable of handling intra-node parallelism. This is because of the fact that many more hardware resources such as cache and processor memory channels are shared across a core in a single node The scalability issue of Big data has lead towards cloud computing, which now aggregates multiple disparate workloads with varying performance goals into very large clusters. This requires a high level of sharing of resources which is expensive and also brings with it various challenges like how to run and execute various jobs so that we can meet the goal of each workload cost effectively. It also requires dealing with the system failures in an efficient manner which occurs more frequently if operating on large clusters. These factors combined put the concern on how to express the programs, even complex machine learning tasks There has been a huge shift in the technologies being used Hard Disk Drives \(HDD\e being replaced by the solid state Drives and Phase Change technology which are not having the same performance between sequential and random data transfer. Thus what kind of storage devices are to be used is again a big question for data storage Collection of huge amount of data and its storage comes at a cost. More data if used for decision making or for predictive analysis in business will definitely lead to better results. Business Leaders will always want more and more data storage whereas the IT Leaders will take all technical aspects in mind before storing all the data. Big data basically focuses on quality data storage rather than having very large irrelevant data so that better results and conclusions can be drawn This further leads to various questions like how it can be ensured that which data is relevant, how much data would be enough for decision making and whether the stored data is accurate or not to draw conclusions from it etc Since Big data is at its youth and an emerging technology so it needs to attract organizations and youth with diverse new skill sets. These skills should not be limited to technical ones but also should extend to research, analytical, interpretive and creative ones. These skills need to be developed in individuals hence requires training programs to be held by the organizations. Moreover the Universities need to introduce curriculum on Big data to produce skilled employees in this expertise Unstructured data represents almost every kind of data being produced like social media interactions, to recorded meetings, to handling of PDF documents, fax transfers, to emails and more. Structured data is always organized into highly mechanized and manageable way. It shows well integration with database but unstructured data is completely raw and unorganized. Working with unstructured data is cumbersome and of course costly too Converting all this unstructured data into structured one is also not feasible Structured data is the one which is organized in a way so that it can be managed easily. Digging through unstructured data is cumbersome and costly  V.     TOOLS AND TECHNIQUES AVAILABLE The following tools and techniques are available 


Programming Paradigm \(Map Reduce The other subprojects provide complementary services or they are building on the core to add higher-level abstractions There exist many problems in dealing with storage of large amount of data Though the storage capacities of the drives have increased massively but the rate of reading data from them hasn\222t shown that considerable improvement. The reading process takes large amount of time and the process of writing is also slower This time can be reduced by reading from multiple disks at once. Only using one hundredth of a disk may seem wasteful But if there are one hundred datasets, each of which is one terabyte and providing shared access to them is also a solution There occur many problems also with using many pieces of hardware as it increases the chances of failure. This can be avoided by Replication i.e. creating redundant copies of the same data at different devices so that in case of failure the copy of the data is available The main problem is of combining the data being read from different devices. Many a methods are available in distributed computing to handle this problem but still it is quite challenging. All the problems discussed are easily handled by Hadoop. The problem of failure is handled by the Hadoop Distributed File System and problem of combining data is handled by Map reduce programming Paradigm. Map Reduce basically reduces the problem of disk reads and writes by providing a programming model dealing in computation with keys and values Hadoop thus provides: a reliable shared storage and analysis system. The storage is provided by HDFS and analysis by MapReduce Hadoop comes with a distributed File System called HDFS, which stands for Hadoop Distributed File System. HDFS is a File System designed for storing very large files with streaming data access patterns, running on clusters on commodity hardware. HDFS block size is much larger than that of normal file system i.e. 64 MB by default. The reason for this large size of blocks is to reduce the number of disk seeks A HDFS cluster has two types of nodes i.e. namenode \(the master\ and number of datanodes \(workers\he name node manages the file system namespace, maintains the file system tree and the metadata for all the files and directories in the tree. The datanode stores and retrieve blocks as per the instructions of clients or the namenode. The data retrieved is reported back to the namenode with lists of blocks that they are storing. Without the namenode it is not possible to access the file. So it becomes very important to make namenode resilient to failure These are areas where HDFS is not a good fit: Low-latency data access, Lots of small file, multiple writers and arbitrary file modifications MapReduce is the programming paradigm allowing massive scalability. The MapReduce basically performs two different tasks i.e. Map Task and Reduce Task A map-reduce computation executes as follows Map tasks are given input from distributed file system. The map tasks produce a sequence of key-value pairs from the input and this is done according to the code written for map function. These value generated are collected by master controller and are sorted by key and divided among reduce tasks. The sorting basically assures that the same key values ends with the same reduce tasks.  The Reduce tasks combine all the values associated with a key working with one key at a time. Again the combination process depends on the code written for reduce job  The Master controller process and some number of worker processes at different compute nodes are forked by the user Worker handles map tasks \(MAP WORKER\ and reduce tasks REDUCE WORKER\ not both The Master controller creates some number of map and reduce tasks which is usually decided by the user program The tasks are assigned to the worker nodes by the master controller. Track of the status of each Map and Reduce task idle, executing at a particular Worker or completed\ is kept by the Master Process. On the completion of the work assigned the worker process reports to the master and master reassigns it with some task The failure of a compute node is detected by the master as it periodically pings the worker nodes. All the Map tasks assigned to that node are restarted even if it had completed and this is due to the fact that the results of that computation would be available on that node only for the reduce tasks. The status of each of these Map tasks is set to idle by Master. These get scheduled by Master on a Worker only when one becomes available. The Master must also inform each Reduce task that the location of its input from that Map task has changed 2\ MapReduce C. Comparison of Hadoop Technique with other system Techniques 1\ Comparison with HPC and Grid Computing Tools The approach in HPC and Grid computing includes the distribution of work across a cluster and they are having a common shared File system hosted by SAN. The jobs here are mainly compute intensive and thus it suits well to them unlike as in case of Big data where access to larger volume of data as network bandwidth is the main bottleneck and the compute nodes start becoming idle. Map Reduce component of Hadoop here plays an important role by making use of the Data Locality property where it collocates the data with the compute node itself so that the data access is fast HPC and Grid Computing basically make use of the API\222s such as message passing Interface \(MPI\. Though it provides great control to the user, the user needs to control the Hadoop is an open source project hosted by Apache Software Foundation. It consists of many small sub projects which belong to the category of infrastructure for distributed computing. Hadoop mainly consists of B.  Hadoop Components in detail 1\Hadoop Distributed File System File System \(The Hadoop File System 


Oct. 19-20, 2012 5 Y u r i De m c h e n ko Zhim ing  Zhao Pa ola Gr o s s o Adia n t o W i bis ono C e es de Laat, \223Addressing Big Data Challenges for Scientific Data Infrastructure\224 IEEE, 6th International Conference on Digital Ecosystems Technologies \(DEST IEEE, 46th Hawaii International Conference on System Sciences IEEE , 4th International Conference on Cloud Computing Technology and Science 2013 2  Sa m M a dden 223 Fro m Databases to B i g  Data\224 May-June 2012 3 K a pil Ba kshi 223Conside rations f o r Big Data: Architecture and Approach\224 2\ Comparison with Volunteer Computing Technique September 2012 7 Mat th ew S m ith C h ri stian Szongott, Ben j a m in Henne, Gabriele von V o igt 223Big Data Privacy Issues in Public Social Media\224 3\ Comparison with RDBMS Business leaders and IT leaders should work together to yield more business value from the data.  Collecting storing and analyzing data comes at a cost. Business leaders will go for it but IT leaders have to look for many things like technological limitations, staff restrictions etc The decisions taken should be revised to ensure that the organization is considering the right data to produce insights at any given point of time Investment in data quality and metadata is also important as it reduces the processing time VII.     CONCLUSION This paper described the new concept of Big data, its importance and the existing projects. To accept and adapt to this new technology many challenges and issues exist which need to be brought up right in the beginning before it is too late. All those issues and challenges have been described in this paper. These challenges and issues will help the business organizations which are moving towards this technology for increasing the value of the business to consider them right in the beginning and to find the ways to counter them. Hadoop tool for Big data is described in detail focusing on the areas where it needs to be improved so that in future Big data can have technology as well as skills to work with REFERENCES 1  Stephen Kais ler Frank Ar m our J. Alb e rto E s p i nos a W i l liam  Money 223Big Data: Issues and Challenges Moving Forward\224 2012 4  Sachchid anan d Sin gh Nir m ala Sing h, \223B ig Da ta Analy tics\224 In Volunteer computing work is broken down into chunks called work units which are sent on computers across the world to be analyzed. After the completion of the analysis the results are sent back to the server and the client is assigned with another work unit. In order to assure accuracy, each work unit is sent to three different machines and the result is accepted if atleast two of them match. This concept of Volunteer Computing makes it look like MapReduce. But there exists a big difference between the two the tasks in case of Volunteer Computing are basically CPU intensive. This tasks  makes these tasks suited to be distributed across computers as transfer of work unit time is less than the time required for the computation whereas in case of MapReduce  is designed to run jobs that last minutes or hours on trusted, dedicated hardware running in a single data center with very high aggregate bandwidth interconnects 18-20 June 2012 IEEE, Engineering Technology IEEE, Internet Computing IEEE , Aerospace Conference IEEE International Conference on Communication, Information & Computing Technology \(ICCICT 2012 6 Mar tin Courtney 223T h e  Lar gin gup of B i g Data\224 mechanism for handling the data flow. On the other hand Map Reduce operates only at the higher level where the data flow is implicit and the programmer just thinks in terms of key and value pairs. Coordination of the jobs on large distributed systems is always challenging. Map Reduce handles this problem easily as it is based on shared-nothing architecture i.e the tasks are independent of each other. The implementation of Map Reduce itself detects the failed tasks and reschedules them on healthy machines. Thus the order in which the tasks run hardly matters from programmer\222s point of view. But in case of MPI, an explicit management of check pointing and recovery system needs to be done by the program. This gives more control to the programmer but makes them more difficult to write Expect to integrate structured and unstructured data as all kind of data is a part of Big data which needs to be analyzed together Generality of the technology is needed to deal with different formats of data. Building technology around key value pairs work There should be certain limits on the scalability of the data stored Creating dimensions of all the data being store is a good practice for Big data analytics. It needs to be divided into dimensions and facts All the dimensions should have durable surrogate keys meaning that these keys can\222t be changed by any business rule and are assigned in sequence or generated by some hashing algorithm ensuring uniqueness Analyzing data sets including identifying information about individuals or organizations privacy is an issue whose importance particularly to consumers is growing as the value of Big data becomes more apparent The traditional database deals with data size in range of Gigabytes as compared to MapReduce dealing in petabytes. The Scaling in case of MapReduce is linear as compared to that of traditional database. In fact the RDBMS differs structurally, in updating and access techniques from MapReduce VI.     BIG DATA GOOD PRACTICES Data quality needs to be better. Different tasks like filtering, cleansing, pruning, conforming, matching joining, and diagnosing should be applied at the earliest touch points possible 


a 1,000 points resolution b 10,000 points resolution c 40,000 points resolution Figure 5 Zoom on the California region of the ndvi_points array at 1,000 10,000 and 40,000 points resolution Without resolution reduction this query returns over one billion points In addition the actual dimension ranges of the array are on the order of millions which would result in a sparse heatmap with over one trillion cells This is clearly too large of an image to draw on the screen so ScalaR prompts the user to reduce the resolution Using aggregation ScalaR produces an initial visualization at a resolution of about 1000 points shown in Figure 4 Resolution refers to the size of the query results being drawn so Figure 4 shows the result of reducing the data down to a 33 by 33 matrix see Section II This visualization clearly shows the arrayês sparseness and reveals a dense area of data in the array Now the user zooms in on the dense portion of the array by highlighting the area with a selection box and using the zoom-in button The resulting visualization at a resolution of 1000 points is shown in Figure 5a The general shape of the western coast of California/Northern Mexico is apparent but the user may want the image to be clearer Figures 5b and 5c show the results of increasing the resolution to 10000 and 40000 points respectively where the identity of the region is very clear in both images The user can now clearly identify the desired southern California region and zooms in to the Los Angeles Santa Barbara area as shown in Figure 6 To perform the same tasks without ScalaR the user would have to write aggregation queries manually over the data set She has to manually identify the desired region of the array to visualize and perform her own calculations to determine a reasonable resolution for the results She may also need to store the query results in a separate le to load into her desired visualization system The user also resorts to trial and error potentially repeating the above steps many times before nding her desired region and resolution for the image ScalaR eliminates the need to manually write queries to reduce the resolution of the data providing the user with more information quickly and easily V P ERFORMANCE We used a 2-node SciDB cluster to run the following experiments Each node had 50GB of RAM 32 cores and a 1,000 points resolution b 10,000 points resolution Figure 6 Zoom on LA area at 1,000 and 10,000 points resolution  Resolution Aggregation Runtime s Sampling Runtime s 1,000 89.55 1.95 10,000 87.22 1.94 100,000 88.71 24.52 1,000,000 98.58 133.68 10,000,000 132.32 176.58 100,000,000 1247.78 186.90 1,000,000,000 3692.02 296.83 Baseline 210.64 Table I R AW RUNTIME RESULTS IN SECONDS FOR AGGREGATION AND SAMPLING QUERIES OVER THE NDSI 1 ARRAY  WITH VARIOUS RESOLUTION VALUES E XECUTION TIME FOR A FULL SCAN OVER NDSI 1 IS PROVIDED FOR REFERENCE  LABELED AS THE BASELINE  10.8TB of disk space SciDB was limited to using at most 75 of the available memory per node as recommended by the SciDB Userês Guide b u t the operating system still had access to all available memory We measured the execution times of aggregation and sampling queries over a single SciDB array containing Normalized Difference Snow Index calculations NDSI for the entire world which where computed over roughly one week of NASA MODIS data The normalized difference snow index measures the amount of snow cover on the earth at a given latitude-longitude coordinate For the rest of this section we will refer to this array as ndsi1  The ndsi1 array was roughly 209GB on disk when stored directly inside SciDB and 85GB when stored as a compressed SciDB binary le ndsi1 was a sparse array containing over 2.7 billion data points stored across 673,380 different SciDB chunks We varied 7 


   Figure 7 A comparison of aggregation and sampling on the ndsi1 array with various data thresholds the resolution threshold  i.e maximum output size from one thousand to one billion data points and measured the runtime of the resulting SciDB aggregation and sampling queries dispatched by ScalaR As a baseline for comparison we also measured the execution time for a full scan of the ndsi1 array  i.e  SELECT  FROM ndsi1  We present runtime results in Table I and a log-scale comparison of aggregation and sampling in Figure 7 Our preliminary results show that basic aggregation and sampling are effective in reducing output size and execution time for most recorded output sizes We see in Figure 7 that reducing the resolution of ndsi1 via sampling either signiìcantly improves performance or is on par with the baseline Aggregation performs better than or as fast as the baseline for most resolution sizes but slower than sampling We also see that performance plummets at the highest resolution sizes Aggregationês slower performance is due in part to the fact that the ndsi1 array is sparse Aggregation computes over logical array ranges making it less efìcient when reducing sparse arrays In addition as the resolution increases aggregation performs even more operations per SciDB chunk Chunks are SciDBês unit of storage on disk At resolutions of 100 million and one billion data points aggregation is executing hundreds or more operations per chunk causing aggregationês poor performance Note that our simple reduction algorithms require reading virtually the entire data set limiting their performance We plan to implement more efìcient reduction techniques in the future and compare their performance to our basic algorithms VI C ONCLUSIONS AND F UTURE W ORK We presented the design and implementation of ScalaR an information visualization system that dynamically performs resolution reduction to improve query execution performance of clusters running a distributed DBMS ScalaR uses aggregation ltering and/or sampling operations to downsize query results as necessary to reduce completion time while still producing visualizations close in accuracy to the original result We presented preliminary performance results for ScalaR visualizing satellite imagery data stored in SciDB We plan to make several optimizations in ScalaRês design starting with the 2 following approaches The rst is to use machine learning techniques over existing visualizations found on the web to learn how to choose appropriate visualization types for user query results automatically Second we plan to incorporate prefetching in the middle layer of our architecture using feedback from the front-end about user interactions for example whether the user just zoomed in or the direction the user is panning through the visualization R EFERENCES  T ableau softw are  http://www tableausoftw are.com May 2012  T ibco spotìre  http://spotìre.tibco.com May 2012  H V o et al  Parallel visualization on large clusters using mapreduce in Large Data Analysis and Visualization LDAV 2011 IEEE Symposium on  2011 pp 81Ö88  Hadoop  http://hadoop.apache.or g  D Jerding and J Stask o The information mural a technique for displaying and navigating large information spaces Visualization and Computer Graphics IEEE Transactions on  vol 4 no 3 pp 257Ö271 1998  N Elmqvist and J Fek ete Hierarchical aggre gation for information visualization Overview techniques and design guidelines IEEE Trans on Visualization and Computer Graphics  vol 16 no 3 pp 439Ö454 2010  S Chaudhuri and U Dayal  A n o v ervie w o f data w arehousing and olap technology SIGMOD Rec  vol 26 no 1 pp 65Ö74 Mar 1997  J M Hellerstein et al  Online aggregation SIGMOD Rec  vol 26 no 2 pp 171Ö182 Jun 1997  P  J Haas and J M Hellerstein Ripple joins for online aggregation SIGMOD Rec  vol 28 no 2 pp 287Ö298 Jun 1999  J M Hellerstein et al  Interactive data analysis The control project Computer  vol 32 no 8 pp 51Ö59 Aug 1999  D Fisher et al  Trust me iêm partially right incremental visualization lets analysts explore large datasets faster in Proceedings of the 2012 ACM annual conference on Human Factors in Computing Systems  ser CHI 12 New York NY USA ACM 2012 pp 1673Ö1682  S Agarw al et al  Blinkdb queries with bounded errors and bounded response times on very large data New York NY USA ACM 2013 pp 29Ö42  M Bostock et al  D3 Data-driven documents IEEE Trans Visualization  Comp Graphics Proc InfoVis  2011  Google maps api  https://de v elopers.google.com/maps May 2012  P  Cudre-Mauroux et al  A demonstration of scidb a science-oriented dbms Proc VLDB Endow  vol 2 no 2 pp 1534Ö1537 Aug 2009  Scidb user s guide v ersion 13.3  2013 Online A v ailable www.scidb.org 


001 002\001\001 9?:\001 021\f84+\026\033#\001 022\0234\030$'\005\026'\005*+\035\005D\024\024/.L\001 D\026\036\035\025\026+\024\024&\001 024\032\001 001 J\035+\02614\025$\033\001G\026\027\027\026\024'\0058411\035\027\027\005$'&\0058$\032\035*0#\001$'&\001*+\035\001U\024\025\035\001\024\032\001 035\001\0234\030$'\001@$1*\024\033.#\0017\0244\033'$\025\001\024\032\001;\026\0331\033$\032*#\001*\024\0012\035\001/42\025\026\027+\035&\001 9\b:\001 021\f84+\026\033#\001 023\024%\001 024\001 G$\036\035\001 001 N\035-\0261\035\001 026'*\024\001 001 E\033\024&41*L\001 11\035\025\035\033$*\035&\001 D\026\032\035\001 6\035\027*\026'\(\001 020*=\027\001 U\024\025\035#\001 033\02624*\035\027#\001 Q+$\025\025\035'\(\035\027#\001 E\026*\032$\025\025\027#\001 001 020'*\035\033$1*\026\024'\001 026*+\001 W4$\025\026\032\0261$*\026\024'\001 6\035\027*\026'\(.#\001\026'\001\021\f\00184+\026\033#\001QE\001C\024'\(#\001XQ\001D\035\035#\001\035&\027\f\001,G\0261\033\024\005\001 001 A/*\024\005\021\025\0351*\033\024'\0261\001 G$*\035\033\026$\025\027\001 001 8*\03341*4\033\035\027L\001E+0\027\0261\027#\001 G\0351+$'\0261\027#\001 N\035\027\026\('#\001 E$1\036$\(\026'\(#\001 U\035\025\026$2\026\025\026*0.#\001 8/\033\026'\(\035\033#\001 017\r\r\003\f\001 9\003:\001 X\f\001 023\f\001 G\0261+\025\026'\001 001 034\f\001 034\033$2$\033'\026\036#\001 022Q\024\030/$\033\026\027\024'\001 8\035H4\035'*\026$\025\001 6\035\027*\026'\(\001 032\024\033\001 U\035\025\026$2\026\025\026*0L\001 0213$1*\001 Q\024\030/4*$*\026\024'\001 024\032\001 AQ\001 001 8M#\022\001 035\r\007\024\006\017\016\r\003\004 007\024\033\004 035\f\b\f\025\016\021\0212\024\005\025\007\003\005\016\024 001 024\025\f\001\003#\001'\024\f\001\017#\001//\f\001\017\002?\005\t\r\t#\001\017\r\r\b\f\001 9\004:\001\001 C\f\001 f\001 M\035\025\027\024 004 8\025\025\f\b\f\r\007\003\f\033\004 035\f\006\003\005\024\0226\004 006\003\007\003\005\006\003\005\025\007\b\004 021\016\033\f\b\006\032\004 003 f\006\003\004\017\b\007\024\006\032\004\007\024\033\004\033\007\003\007\004\007\024\007\b\n\006\005\006 L\0017\024+'\001C\026\025\0350#\001\006\002\002\r\f\001 9 002:\001 f\001 7\035\033\0330#\001 002\024\003\r\016\0332\025\003\005\016\024\004 003\016\004 002\024\003\f\022\r\007\b\004 A2\007\003\005\016\024\006\004 t\005\003\023\004 8 017\017\b\005\025\007\003\005\016\024\006 001\017  001\035&\fL\0017\024+'\001C\026\025\0350#\001\006\002\002\002\f\001 9\006\r:\001N\f\001;\f\001<\f\001G\026\025\025\035\033#\001 B2\007\024\0032\021\004*\f\025\023\007\024\005\025\006\004\030\016\r\0045\025\005\f\024\003\005\006\003\006\004\007\024\033\004  024\022\005\024\f\f\r\006 L\001Q$\0302\033\026&\(\035\001F'\026-\035\033\027\026*0\001/\033\035\027\027#\001\017\r\r\004\f\001 9 006\006:\001;\f\001 M\f\001 6\026\036+\024'\024-\001 001 J\f\001 X\f\001 033\027\035'\026'#\001 5\016\b2\003\005\016\024\006\004 030\016\r\004 005\b\b\036\004\004\004 017 016\006\f\033\004\017\r\016\013\b\f\021\006 L\001C\026'\027*\024'#\001\006\002\003\003\f\001 9 006\017:\0017\f\001 M\0241\035&$\025\001 001 8\f\001 7\f\001 C\033\026\(+*#\001 0342\021\f\r\005\025\007\b\004 C\017\003\005\021\0057\007\003\005\016\024\032\004  024\033\004\f\033\005\003\005\016\0246 0018/\033\026'\(\035\033#\001\017\r\r\b\f\001 001 030 fI\001\021/\032"#\037 t r\006\016\005\017\020\021\006\016 004\r\f\025\f\005<\f\033\004\007\004:\0375\025\037\004\005\024\004  b\f\025\003\r\005\025\007\b\004\(\024\022\005\024\f\f\r\005\024\022\004\030\r\016\021\004\003\023\f\004 035\f\025\023\024\005\016\024\004D\004\002\024\006\003\005\0032\003\f\004\016\030\004\035\f\025\023\024\016\b\016\022\n\032\004 007\005\030\007\032\004\002\006\r\007\f\b\032\004\005\024\004,EEF\004\007\024\033\004\007\004*\0375\025\037\004\005\024\004 B2\007\b\005\003\n\004\007\006\0062\r\007\024\025\f\004G\004\031\f\b\005\007\013\005\b\005\003\n\004 f\024\022\005\024\f\f\r\005\024\022\032\004\004\007\b\006\016\004\030\r\016\021\004\003\023\f\004\035\f\025\023\024\005\016\024\032\004 005\024\004?FFH\037\004%2\r\r\f\024\003\b\n\004\023\f\004\005\006\004\006\0032\033\n\005\024\022\004\030\016\r\004 9\023\037'\037\004\007\003\004\003\023\f\004\035\f\025\023\024\005\016\024\004D\004\002\024\006\003\005\0032\003\f\004\016\030\004 035\f\025\023\024\016\b\016\022\n\032\004@\007\005\030\007\032\004\002\006\r\007\f\b\032\004\007\024\033\004\023\005\006\004\003\023\f\006\005\006\004\0062\013&\f\025\003\004\005\006\004 I\031\f\b\005\007\013\005\b\005\003\n\004\016\030\004\035\f\025\023\024\016\b\016\022\005\f\006I\037\004\004 5\023\007\005\004\023\007\033\004\006\f\r<\f\033\004\007\006\004\007\024\004\f\b\f\025\003\r\005\025\007\b\004\007\024\033\004\f\b\f\025\003\r\016\024\005\025\006\004\f\024\022\005\024\f\f\r\004 006\005\024\025\f\004,EEF\004\005\024\004<\007\r\005\0162\006\004\022\016<\f\r\024\021\f\024\003\004\017\016\006\005\003\005\016\024\006\037\004%2\r\r\f\024\003\b\n\032\004\023\f\004 005\006\004\007\024\004\007\025\003\005<\f\004\031\f\b\005\007\013\005\b\005\003\n\004\f\024\022\005\024\f\f\r\037\004 017 022 023\021\005\006\016\024\017\020\025\021\016\005 004\005\006\004\016\024\004\003\023\f\004\030\007\0252\b\003\n\004\016\030\004 003 023\f\004\(\b\f\025\003\r\005\025\007\b\004\(\024\022\005\024\f\f\r\005\024\022\004'\f\017\003\032\004 1\024\005<\f\r\006\005\003\n\004\016\030\004%\007\b\005\030\016\r\024\005\007\032\0045\007\024\003\007\004%\r27\032\004 8\032\004\007\024\033\004\005\006\0044\005\006\005\003\005\024\022\0049\r\016\030\f\006\006\016\r\032\004 f\025\023\007\024\005\025\007\b\004\(\024\022\005\024\f\f\r\005\024\022\004'\f\017\003\037\032\004 1\024\005<\f\r\006\005\003\n\004\016\030\004*\007\r\n\b\007\024\033\032\004%\016\b\b\f\022\f\004 9\007\rJ\032\004*'\032\004\007\024\033\004'\f\017\007\r\003\021\f\024\003\004\016\030\004 b\f\025\003\r\016\024\005\025\004*\007\003\f\r\005\007\b\006\032\004\035\f\025\023\024\005\025\007\b\004 1\024\005<\f\r\006\005\003\n\032\0044\005\f\024\024\007\032\00482\006\003\r\005\007\037\004'\r\037\00452\023\005\r\004\005\006\004+\f\b\b\016\t\004\016\030\004\003\023\f\004 002\024\006\003\005\0032\003\f\004\016\030\004\(\b\f\025\003\r\005\025\007\b\004\007\024\033\004\(\b\f\025\003\r\016\024\005\025\006\004\(\024\022\005\024\f\f\r\006\004!\002\(\(\("\032\004 003\023\f\0048\021\f\r\005\025\007\024\0049\023\n\006\005\025\007\b\0045\016\025\005\f\003\n\004!895"\032\004\003\023\f\004\002\024\006\003\005\0032\003\f\004\016\030\004 9\023\n\006\005\025\006\004!\002\0169"\032\0041K\032\004\003\023\f\0048\021\f\r\005\025\007\024\0045\016\025\005\f\003\n\004\016\030\004*\f\025\023\007\024\005\025\007\b\004 024\022\005\024\f\f\r\006\004!85*\("\032\004\007\024\033\004\003\023\f\0045\016\025\005\f\003\n\004\016\030\0049\b\007\006\003\005\025\006\004\(\024\022\005\024\f\f\r\006\004 59\("\037\004'\r\037\00452\023\005\r\004\023\007\006\004\013\f\f\024\004\f\b\f\025\003\f\033\004\007\006\004+\016\r\f\005\022\024\004+2\b\b\004 f\021\013\f\r\004!8\025\007\033\f\021\005\025\005\007\024"\004\016\030\004\003\023\f\004\034\007\003\005\016\024\007\b\0048\025\007\033\f\021\n\004\016\030\004 024\022\005\024\f\f\r\005\024\022\032\0041J\r\007\005\024\fL\004\007\024\033\004\007\006\004+2\b\013\r\005\022\023\003\0045\025\023\016\b\007\r 026\017 0162\024\025\005\b\004 030 016\r\004\002\024\003\f\r\024\007\003\005\016\024\007\b\004\(\020\025\023\007\024\022\f\004\016\030\0045\025\023\016\b\007\r\006\004!%\002\(5"\032\0045\003\007\003\f\004 f\017\007\r\003\021\f\024\003\032\00415\037\004@\f\004\005\006\004'\005\006\003\005\024\0222\005\006\023\f\033\004\027\f\025\0032\r\f\r\004\016\030\004\003\023\f\004 002\(\(\(\004%9*\035\004!%\016\021\017\016\024\f\024\003\006\032\0049\007\025J\007\022\005\024\022\004\007\024\033\004 007\0242\030\007\025\0032\r\005\024\022\004\035\f\025\023\024\016\b\016\022\n"\0045\016\025\005\f\003\n 026\017 8\006\006\016\025\005\007\003\f\004\(\033\005\003\016\r\004\016\030\004 003 023\f\004\002\(\(\(\004%9*\035\004\035\r\007\024\006\007\025\003\005\016\024\006\004\016\024\0048\033<\007\024\025\f\033\0049\007\025J\007\022\005\024\022\032\004 f\021\013\f\r\004\016\030\004\003\023\f\004\(%\035%\004!\(\b\f\025\003\r\016\024\005\025\004%\016\021\017\016\024\f\024\003\006\004\007\024\033\004 035\f\025\023\024\016\b\016\022\n\004%\016\024\030\f\r\f\024\025\f"\0048\017\017\b\005\f\033\004\031\f\b\005\007\013\005\b\005\003\n\004 52\013\025\016\021\021\005\003\003\f\f\032\004\003\023\f\004\002\(\(\(\004%9*\035\004\007\t\007\r\033\004\025\016\021\021\005\003\003\f\f\032\004\003\023\f\004 002\(\(\(\004+\f\b\b\016\t\004\024\016\021\005\024\007\003\005\016\024\004\025\016\021\021\005\003\003\f\f\032\004\007\024\033\004\003\023\f\00485*\(\004 M\f\024\f\r\007\b\0048\t\007\r\033\006\004\025\016\021\021\005\003\003\f\f\037\004'\r\037\00452\023\005\r\004\005\006\004\007\004\025\016\036\030\0162\024\033\f\r\004\016\030\004 003\023\f\00485*\(\004;\0162\r\024\007\b\004\016\030\004\(\b\f\025\003\r\016\024\005\025\0049\007\025J\007\022\005\024\022\004\007\024\033\004\006\f\r<\f\033\004\007\006\004 005\003\006\004\035\f\025\023\024\005\025\007\b\004\(\033\005\003\016\r\004\030\016\r\004\f\005\022\023\003\004\n\f\007\r\006\004!,EEN\036?FF,"\037\004 f\004\023\007\006\004\0072\003\023\016\r\f\033\004\007\013\0162\003\004NFF\004\003\f\025\023\024\005\025\007\b\004\0172\013\b\005\025\007\003\005\016\024\006\004 017\007\003\f\024\003\006\032\004\017\007\017\f\r\006\032\004\013\016\016J\004\025\023\007\017\003\f\r\006\032\004\013\016\016J\006"\032\004\005\024\025\b2\033\005\024\022\004\013\016\016J\006\004 O5\003\r2\025\0032\r\007\b\0048\024\007\b\n\006\005\006\004\005\024\004*\005\025\r\016\f\b\f\025\003\r\016\024\005\025\006\004\007\024\033\004+\005\013\f\r\004 C\017\003\005\025\006\026\032\0044\007\024\036\034\016\006\003\r\007\024\033\032\004,EE,\032\004\007\024\033\004O8\017\017\b\005\f\033\0049\r\016\013\007\013\005\b\005\003\n\004 030\016\r\004\(\024\022\005\024\f\f\r\006\004\007\024\033\0045\025\005\f\024\003\005\006\003\006\026\032\004*\025M\r\007\t\036@\005\b\b\032\004,EEP\037\004'\r\037\004 52\023\005\r\004\005\006\004\f\033\005\003\016\r\004\016\030\004\003\023\f\0045\017\r\005\024\022\f\r\004\013\016\016J\004\006\f\r\005\f\006\004\016\024\004\017\023\n\006\005\025\006\032\004 021\f\025\023\007\024\005\025\006\004\007\024\033 004 017\007\025J\007\022\005\024\022\004\016\030\004\021\005\025\r\016\f\b\f\025\003\r\016\024\005\025\004\007\024\033\004 017\023\016\003\016\024\005\025\004\006\n\006\003\f\021\006\037\004@\f\004\016\r\022\007\024\0057\f\033\004\021\007\024\n\004\0062\025\025\f\006\006\0302\b\004 025\016\024\030\f\r\f\024\025\f\006\004\007\024\033\004\006\n\021\017\016\006\005\007\004\007\024\033\004\017\r\f\006\f\024\003\f\033\004\0242\021\f\r\0162\006\004 J\f\n\024\016\003\f\004\007\024\033\004\005\024<\005\003\f\033\004\003\007\bJ\006\004\t\016\r\b\033\t\005\033\f\037\004'\r\037\00452\023\005\r\004\r\f\025\f\005<\f\033\004 021\007\024\n\004\017\r\016\030\f\006\006\005\016\024\007\b\004\007\t\007\r\033\006\032\004\005\024\025\b2\033\005\024\022\004 027\030\030\031\017 85*\(\004 Q 016\r\025\f\006\003\f\r\004\031\f\007\033\004Q\007\r\024\f\r\004*\f\033\007\b\004\030\016\r\004\0162\003\006\003\007\024\033\005\024\022\004 025\016\024\003\r\005\0132\003\005\016\024\006\004\003\016\004\003\023\f\004\017\f\r\021\007\024\f\024\003\004\b\005\003\f\r\007\0032\r\f\004\016\030\004\f\024\022\005\024\f\f\r\005\024\022\004 003\023\r\0162\022\023\004\007\004\006\f\r\005\f\006\004\016\030\004\017\007\017\f\r\006\004\005\024\004*\f\025\023\007\024\005\025\007\b\032\004 005\025\r\016\f\b\f\025\003\r\016\024\005\025\032\004\007\024\033\004C\017\003\016\f\b\f\025\003\r\016\024\005\025\004\(\024\022\005\024\f\f\r\005\024\022\032\004\t\023\005\025\023\004 f\006\003\007\013\b\005\006\023\f\033\004\007\004\024\f\t\004\033\005\006\025\005\017\b\005\024\f\004J\024\016\t\024\004\007\006\004\003\023\f\0045\003\r2\025\0032\r\007\b\004 8\024\007\b\n\006\005\006\004\016\030\004*\005\025\r\016\f\b\f\025\003\r\016\024\005\025\004\007\024\033\0049\023\016\003\016\024\005\025\0045\n\006\003\f\021\006\004!\023\f\004\005\006\004 003\023\f\004\003\023\005\r\033\004\0312\006\006\005\007\024\0048\021\f\r\005\025\007\024\032\004\007\030\003\f\r\0045\003\f<\f\024\004\035\005\021\016\006\023\f\024J\016\004\007\024\033\004 002\022\016\r\0045\005J\016\r\006J\n\032\004\t\023\016\004\r\f\025\f\005<\f\033\004\003\023\005\006\004\017\r\f\006\003\005\022\005\0162\006\004\007\t\007\r\033"L\004 027\030\030\032\017 002*895\004;\016\023\024\0048\037\004Q\007\022\024\016\024\004\035\f\025\023\024\005\025\007\b\0048\025\023\005\f<\f\021\f\024\003\0048\t\007\r\033\004 030 016\r\004\0162\003\006\003\007\024\033\005\024\022\004\025\016\024\003\r\005\0132\003\005\016\024\006\004\003\016\004\003\023\f\004\003\f\025\023\024\005\025\007\b\004J\024\016\t\b\f\033\022\f\004 016\030\004\003\023\f\004\021\005\025\r\016\f\b\f\025\003\r\016\024\005\025\006\032\004\016\017\003\016\f\b\f\025\003\r\016\024\005\025\006\032\004\007\024\033\004\017\007\025J\007\022\005\024\022\004 005\024\0332\006\003\r\nL\004 027\030\030\030\017 002\(\(\(\036%9*\035\004C2\003\006\003\007\024\033\005\024\022\00452\006\003\007\005\024\f\033\004 035 f\025\023\024\005\025\007\b\004%\016\024\003\r\005\0132\003\005\016\024\0048\t\007\r\033\004\030\016\r\004\0162\003\006\003\007\024\033\005\024\022\032\004\0062\006\003\007\005\024\f\033\004 007\024\033\004\025\016\024\003\005\0242\005\024\022\004\025\016\024\003\r\005\0132\003\005\016\024\006\004\003\016\004\003\023\f\004\003\f\025\023\024\016\b\016\022\005\f\006\004\005\024\004\030\005\f\b\033\006\004 f\024\025\016\021\017\007\006\006\f\033\004\013\n\004\003\023\f\004%9*\035\0045\016\025\005\f\003\nL\004 027\030\030\030\017 59\(\004 002 024\003\f\r\024\007\003\005\016\024\007\b\004\(\024\022\005\024\f\f\r\005\024\022-\035\f\025\023\024\016\b\016\022\n\004!+\r\f\033\004C\037\004%\016\024\b\f\n"\004 8\t\007\r\033\004\030\016\r\004\0162\003\006\003\007\024\033\005\024\022\004\017\005\016\024\f\f\r\005\024\022\004\007\024\033\004\025\016\024\003\005\0242\005\024\022\004 025\016\024\003\r\005\0132\003\005\016\024\006\004\003\016\004\017\b\007\006\003\005\025\006\004\f\024\022\005\024\f\f\r\005\024\022L\004 032\033\033\033\017 85*\(\004\007\024\033\0049\005\036 035 0072\036\0045\005\022\021\007\004%\023\007\r\b\f\006\004\0312\006\006\004\031\005\025\023\007\r\033\006\004*\f\021\016\r\005\007\b\0048\t\007\r\033\004\030\016\r\004 0162\003\006\003\007\024\033\005\024\022\004\025\016\024\003\r\005\0132\003\005\016\024\006\004\003\016\004\021\f\025\023\007\024\005\025\007\b\004\f\024\022\005\024\f\f\r\005\024\022\032\004\007\024\033\004 032\033\033\034\017 f\b\b\004\027\007\013\016\r\007\003\016\r\005\f\006\004'\005\006\003\005\024\0222\005\006\023\f\033\004*\f\021\013\f\r\004\016\030\004 035 f\025\023\024\005\025\007\b\0045\003\007\030\030\0048\t\007\r\033\004\030\016\r\004\033\f<\f\b\016\017\005\024\022\004\f\020\003\r\f\021\f\b\n\004\007\025\0252\r\007\003\f\004 007\024\033\004\r\016\0132\006\003\004\f\024\022\005\024\f\f\r\005\024\022\004\021\f\025\023\007\024\005\025\006\004\021\f\003\023\016\033\006\004\030\016\r\004\017\r\f\033\005\025\003\005\024\022\004 003\023\f\004\r\f\b\005\007\013\005\b\005\003\n\032\004\017\f\r\030\016\r\021\007\024\025\f\032\004\007\024\033\004\021\f\025\023\007\024\005\025\007\b\004\013\f\023\007<\005\016\r\004\016\030\004 025\016\021\017\b\f\020\004\006\003\r2\025\0032\r\f\006\0042\006\f\033\004\005\024\004\021\007\0242\030\007\025\0032\r\005\024\022\004\0272\025\f\024\003\004 035\f\025\023\024\016\b\016\022\005\f\006\004\017\r\016\0332\025\003\006\037\004 017 035 005\036\037 \017!\036"\017\013#$\024\006 032\004\035\f\025\023\024\005\016\024\032\004\002\006\r\007\f\b\032\004 005 006\004\006\003\007\030\030\004\021\f\021\013\f\r\004\016\030\004\002\024\0332\006\003\r\005\007\b\004\007\024\033\004 007\024\007\022\f\021\f\024\003\004\(\024\022\037\004'\f\017\007\r\003\021\f\024\003\032\004\007\024\033\004 021\f\021\013\f\r\004\016\030\004\022\r\007\0332\007\003\f\004\006\0032\033\005\f\006\004\022\r\0162\017\004 017\r\016\022\r\007\021"\004\005\024\004B2\007\b\005\003\n\0048\006\0062\r\007\024\025\f\004\007\024\033\004 031\f\b\005\007\013\005\b\005\003\n\004\007\003\004\035\f\025\023\024\005\016\024\037\004@\005\006\004\r\f\006\f\007\r\025\023\004 005\024\003\f\r\f\006\003\006\004\005\024\025\b2\033\f6\004\f\b\f\021\f\024\003\004\007\024\033\004\006\n\006\003\f\021\004 r\f\b\005\007\013\005\b\005\003\n\032\004\033\007\021\007\022\f\004\007\025\0252\0212\b\007\003\005\016\024\004 017\r\016\025\f\006\006\f\006\032\004\017\023\n\006\005\025\007\b\004J\005\024\f\003\005\025\006\032\004\017\007\003\003\f\r\024\004\r\f\025\016\022\024\005\003\005\016\024\032\004 005\024\030\016\r\021\007\003\005\016\024\004\003\023\f\016\r\n\032\004\024\f2\r\007\b\004\024\f\003\006\032\004\021\f\007\0062\r\f\021\f\024\003\004\003\023\f\016\r\n\004\007\024\033\004 005\024\006\003\r2\021\f\024\003\007\003\005\016\024\032\004\033\f\006\007\b\005\024\007\003\005\016\024\004\003\f\025\023\024\016\b\016\022\n\032\004\024\016\024\033\f\006\003\r2\025\003\005<\f\004 003\f\006\003\005\024\022\032\004\007\024\033\004A2\007\b\005\003\n\004\025\016\024\003\r\016\b\037 017 


001 006\r\001\001 021//#;\"L\t\021\t 001G$*+\035\030$*\0261$\025\001*\024\024\025\027\001$'&\001\0353$\030/\025\035\027 005\035\023\003\002\t t n\020\017\007\005\020\007\t\027\002\003\004*\002\022\b\t\022\005\007\002\t$\t\005\020\005\003\b\007\004\016\005\003\t\017\n\003!\007\004\n\020\t 6+\035\001 027\026\030/\025\035\027*\001 026\025\0254\027*\033$*\026\024'\001 024\032\001 024%\001 035\001 0274\(\(\035\027*\035&\001 033\024$1+\001 024\033\036\027\0011$'\0012\035\001\0242*$\026'\035&\0014'&\035\033\001$'\001$\027\0274\030/*\026\024'\001*+$*\001*+\035\001&\035\025\026-\035\0330\001 033$*\035\001 026\027\001 1\024'\027 004 031  024 003 001  f\001 C\026 035 003 b 001 002 001 035\001 035H4$*\026\024'\001 031\b\\001 2\0351\024\030\035\027L\001\001 r r 031  031  031  035 034 035 034 031 035  031 033 b b 001 006 007 006 003 001\001\001\001\001\001\001\001\001\001\001\001\001\001\001\001\001\001\001\031;\006\\001  0\001 025\024\(0\001 026*+\001 035\001 0353/\0351*$*\026\024'\001 0254\035\001 032\033\024\030\001 035\001 W4$'*4\030\001 G\0351+$'\0261\027\001 9\006\r:#\001 001 1\024'>4\($*\035\001 033$'\027/\024\027\035\001 031\023\035\033\030\026*\026$'\001 033$'\027/\024\027\035\\001\024/\035\033$*\024\033\001\026\027\001\035\030/\025\0240\035&\001*\024\001&\035*\035\033\030\026'\035\001*+\035\001H4$'*\026*\026\035\027\001 026'\0012\024*+\001/$\033*\027\001\024\032\001*+\035\001\035H4$*\026\024'\001\031;\006\\f\0016+\026\027\0010\026\035\025&\027\001*+\035\001\032\024\025\025\024%\026'\(L\001\001 r r r 031  0353/\031  031  0353/\031    035 035 034 034 033\034 035 033 034 031 035 033\035 033\035 002 026 027 001 006 006 006 030 031 032 033 001 6+\035\001'\0353*\001\026'*\035\(\033$*\026\024'\001\033\035\0274\025*\027\001\026'\001*+\035\001\035H4$*\026\024'L\001 r r r r r I I 006 031 I 0353/\031  I 031 I 0353/\031  I I I 035 035   035 035 034 034 033\034 035 033 033\035 031 035 033\035 034 033\035 033\035 036 037 026 027 026 027 006 006 001 006   030 031 030 031   032 033 032 033   003 003 001\001 023 035'1\035#\001*+\035\001\033\035\025\026$2\026\025\026*0\001\0324'1*\026\024'\001\026\027\001\0353/\033\035\027\027\035&\001$\027\001\032\024\025\025\024%\027L\001 r r r r 017 r 031  031  0353 031 I 0353 I 031  031  I 035 034 035    035 035 034 034 034 034 035 035 033\035 031 034 002 002 001 026 027 006 030 031 032 033 003 031;\017\\001 6+\035\001 035H4$*\026\024'\001 031;\017\\001 1\0244\025&\001 2\035\001 035\033\026\032\026\035&\001 032\024\033\001 035\001 1$\027\035\001 024\032\001 001 0353/\024'\035'*\026$\025\001\033\035\025\026$2\026\025\026*0\001\0324'1*\026\024'\001%\026*+\001*+\035\001\032$\026\0254\033\035\001\033$*\035\001  L\001 031  0353/\031  031 035 035  001 002 006 001\001\001\001\001\001\001\001\001\001\001\001\001\001\001\001\001\001\001\001\001\001\001\001\001\001\001\001\001\001\001\001\001\001\031;\t\\001 020'*\033\024&41\026'\(\001\031\002;\\001\026'*\024\001*+\035\001\035H4$*\026\024'\001\031\003;\#\001%\035\001\0242*$\026'L\001\001 r 031  0353/\031  031\006 0353/\031   034 035 034 035 035    001 006 002 006 007 006 002 002 006 001\001\001\001\001\001\031;\007\\001 C+\035'\001 026'*\033\024&41\026'\(\001 026\027\001 0353/\033\035\027\027\026\024'\001 2$1\036\001 026'*\024\001 035\001 035H4$*\026\024'\001 031;\017\#\001 035\001 033\024/\033\026$*\035\001 0353/\024'\035'*\026$\025\001 033\035\025\026$2\026\025\026*0\001 0324'1*\026\024'\001 031;\t\\001 1\0244\025&\0012\035\001\035$\027\026\0250\001\033\035\027*\024\033\035&\f\001\001 001 001 001 005\035\023\003\002\t t 037\007\005\007\004\017\007\004\016\005\003\t\023\022\n\023\002\022\007\004\002\017\t\n\013\t\023\n\023!\003\005\007\004\n\020\t\027\b\020\005\035\004\016\017\t 6+\035\001 035\025\026-\035\0330\001 033$*\035\001 1+$'\(\035\027\001 026'\001 026\030\035\001 026*+\001 024 005 004 033\035/\033\035\027\035'*\026'\(\001 035\001 030\0244'*\001&\035\025\026-\035\033\035&\001$*\001*+\035\001\035'&\001\024\032\001*+\035\001*\026\030\035\0014'\026*\001 005 001\031@\026\(4\033\035\001;\f\006$\\f\001 020'\001 026\027\001 1$\027\035#\001 035\001 026'\026*\026$\025\001 024/4\025$*\026\024'\001 026\027\001 034 r  r\f\001 6+\035\001 0353/\0351*\035&\001 024/4\025$*\026\024'\001 0351*\024\033\001 032\024\033\001 035\001 033\035&\035*\035\033\030\026'\035&\001 035\02624\025\025\001 033\035\025\026$2\026\025\026*0\001 0324'1*\026\024'#\0014\027\026'\(\001 035H4$*\026\024'\001\031\003\#\001\026\027\001\027+\024%'\001\026'\001@\026\(4\033\035\001;\f\0062\f\001 A'\035\001 4'&\033\035&\001 033$'&\024\030\001 0351*\024\033\027\001 035\033\035\001 1$\02514\025$*\035&\001 11\024\033&\026'\(\001 024\001 035\001 027\026\0304\025$*\026\024'\001 033\0241\035\027\027\001 0353/\025$\026'\035&\001 026'\001 026\(4\033\035\001 017\f\001 024\033\001 035$1+\001 026\030\035\001 026'&\0353#\001*+\035\001$-\035\033$\(\035\001$'&\001\027*$'&$\033&\001&\035-\026$*\026\024'\001$\033\035\0011$\02514\025$*\035&\f\001 001 001 001 001 001 001 001 001 001 001 001 001 001 001 001 001 001 001 001 001 001 001 001 001 001 001 001 001 001 001 001 001 001 001 001 001 001 001 001 001 001 t  004\026!\022\002\t\021\(?\t$\t\037\007\005\007\004\017\007\004\016\005\003\t\023\022\n\023\002\022\007\004\002\017\t\n\013\t\007\025\002\t\035\n\027\002\003\t 001 001 001 6 035\001 0242*$\026'\035&\001 033\035\0274\025*\027\001 026'&\0261$*\035\001 001 035\001 030\035$'\001 035\033\033\024\033\001 026\027\001 024'\001 035\001 024\033&\035\033\001\024\032\001\007\001\030$\('\026*4&\035\027\001\027\030$\025\025\035\033\001*+$'\001*+\035\001\0353/\0351*\035&\001/\024/4\025$*\026\024'\001 031@\026\(4\033\035\001;\f\006&\\f\001\001 025\027\024#\001 035\001 027*$'&$\033&\001 035-\026$*\026\024'\001 026\027\001 027\030$\025\025\035\033\001 001 035\001 033\035$\027\024'$2\025\035\001 4//\035\033\001 2\0244'&$\0330\001 K\001 035\001 027H4$\033\035\001 033\024\024*\001 024\032\001 035\001 0353/\0351*\035&\001 024*$\025\001 H4$'*\026*0\001 031@\026\(4\033\035\001 f\0061\\001 001 035\001 027\026\('$\025\005*\024\005'\024\026\027\035\001 033$*\026\024\001 027*$2\026\025\0265\035\027\001$\033\0244'&\001\002\r\r\001\031@\026\(4\033\035\001;\f\006\035\\f\001 001 t f\006$\f\001N\035\025\026-\035\0330\001\033$*\035#\001 024 026 001K\001*+\035\001 001 026'/4*\001\032\024\033\001\0353$\030/\025\035\001\020\020\f 001 f\0062\f\001E\024/4\025$*\026\024'#\001 034 026 0011$\02514\025$*\035&\001 20\001\031\003\\001\032\024\033\001\(\026-\035'\001 031!\035 f 001\001 f\0061\f\001 031\006 004 8*$'&$\033&\001&\035-\026$*\026\024 032\004 0 005\004 001 031\017 004 4//\035\033\0012\0244'&\001\032\024\033\001\027\026\0304\025$*\026\024 004\004 f\006&\f\001;1*4$\025\001&\035-\026$*\026\024 001 032\033\024\030 001 035\033$\(\035 032 034 005 004D\004R 005 004"\004 001\001 f\006\035\f\0018\026\('$\025\001*\024\001M\024\026\027\035\001\033$*\026\024 032\004 R 005 n 0 005 004\037 001\001 001 007\b\t\n\013\013 8\026\('$\025\001*\024\001M\024\026\027\035\001U$*\026\024 001 001 002\001\001 004\001\001\001 004\002\001\001 005\001\001\001 005\002\001\001 006\001\001\001 001 004\001\001 006\001\001 025\001\001 027\001\001 003\001\001\001 E\002\t 021   002 t 001 007\b\t\n\013\013 1*4$\025\001N\035-\026$*\026\024 001 036\007\001 036\006\001 036\005\001 036\004\001 001 004\001 005\001 006\001 007\001 001 004\001\001 006\001\001 025\001\001 027\001\001 003\001\001\001 E\027 t 021   027 t 001 001 004\001\001 005\001\001 006\001\001 007\001\001 002\001\001 035\001\001 001 004\001\001 006\001\001 025\001\001 027\001\001 003\001\001\001 007\b\t\n\013\013 E\016\t E\024/4\025$*\026\024'\0018*\fN\035-\f\001 001\001 031\017\\001 031\006\\001 021   016 t 001 001 002\001 004\001\001 004\002\001 005\001\001 005\002\001 001 004\001\001 006\001\001 025\001\001 027\001\001 003\001\001\001 007\b\t\n\013\013 E\024/4\025$*\026\024'#\001 034 005 004\004\004\004 3 006\r 001\t 004\004 004\004\004\004\004 E\006 t A4*/4*\001\001 021   006 t 001 034\001\001 032\001\001 004\001\001\001 004\004\001\001 004\005\001\001 004\006\001\001 004\007\001\001 001 004\001\001 006\001\001 025\001\001 027\001\001 003\001\001\001 N\035\025\026-\035\0330\001U$*\035#\001 024 005 001 001\001 E\005 t 007\b\t\n\013\013 020'/4*\001 021   005 t 


001 006\006\001\001 005\035\023\003\002\t t 0247\n\t\002\013\013\002\016\007\004*\002\t\005\026\0024\026\022\n!\023\t\027\004\017\007\022\004\006!\007\004\n\020\t\013\n\022\t b 030 t\t 6+\026\027\001\0353$\030/\025\035\001\033\035\032\035\033\027\001*\024\001*+\035\001\027$\030\035\001\026'/4*\001&$*$\001$\027\001\026'\001*+\035\001 020\007\021\017\b\f\004 002\002 f\0016+\035\001\026'/4*\001&$*$\001$\033\035\001*+\035\001-\0351*\024\033\027\001\024\032\001*+\035\001&\035\025\026-\035\0330\001\033$*\035\001\031@\026\(4\033\035\001 f\006$\\001$'&\001*+\035\001/\024/4\025$*\026\024'\0012$\025$'1\035\001\031@\026\(4\033\035\001;\f\0062\\f\001\020'\001*+\026\027\0011$\027\035#\001 024%\035-\035\033#\001 035\001 0353/\035\033\026\030\035'*$\025\026\027*\001 024\027\027\035\027\027\035\027\001 024'\0250\001 035\001 001 032\033\024\030\001 001 0332\026*\033$\0330\001 030\024\030\035'*\001 035 005\004 024'%$\033&#\001 001 005 O\t\r\r\f\001 6+\035\033\035\032\024\033\035#\001 035\001 033\0351\035&\026'\(\001 034 t\r\r 001 2\0351\024\030\035\027\001 035\001 14\033\033\035'*\001 034 r 001 001 026'\001 035'\035\033$\025#\001 t\r\r 005 034 007 001 005 034 001 001 t\r\r 005 024 007 001 004 005 024 f\001 M\024*\035\001 001 035\001 14\033\033\035'*\001 034 r 001 0242-\026\0244\027\0250\001 027\001 027\024\030\035\001 036\026'&\001 024\032\001 035\001 026\027*\033\02624*\026\024'P\001 035'1\035#\001 035\001 4'\036'\024%'\001*\0334\035\001&\026\027*\033\02624*\026\024'\001\0304\027*\0012\035\001\035\032\032\0351*\026-\035\0250\001\033\035/\033\035\027\035'*\035&\001*\024\001 025\025\024%\001 0242*$\026'\026'\(\001 001 035'\035\033$\025\0265\035&\001 4\030\035\033\0261$\025\001 027\024\0254*\026\024'\001 024\001 035\001 035H4$*\026\024'\001\031?\\f\001 026\(4\033\035\001;\f\017\001&\035\030\024'\027*\033$*\035\027\001*+\035\0011\024\030/$\033\026\027\024'\0012\035*%\035\035'\001*%\024\0011$\027\035\027\f\001 026\(4\033\035\001 f\017$\001 026\025\0254\027*\033$*\035\027\001 035\001 035-\026$*\026\024'\001 024\032\001 035\001 1$\02514\025$*\035&\001 024/4\025$*\026\024'\001\032\033\024\030\001*+\035\001$1*4$\025\001&$*$#\001+$-\026'\(\001 034 r\001 2\035\035'\001%\033\024'\(\0324\025\0250\001 1\024'\027\026&\035\033\035&\001 024\001 035\001 024\001 035\001 026\027*\033\02624*\026\024'\001 20\001 035\001 032\024\033\0304\025$\001 031\003\#\001 035\033\035$\027\001@\026\(4\033\035\001;\f\0172\001\027+\024%\027\001*+\035\0011\024'\027\035H4\035'1\035\001\024\032\001$'\001\026*\035\033$*\026-\035\001 033\0241\035\027\027\001 2$\027\035&\001 024'\001 024\005\(\033\0244/\001 035\001 026\027*\033\02624*\026\024'\001 025\035$&\026'\(\001 024\001 035\001 1\024'-\035\033\(\035'1\035\001 024\032\001 034 026 001 027\001 035\033\001 031\006\r\#\001 026*+\001 035\001 1*4$\025\001 024/4\025$*\026\024'\001 f\0016+\035\001\0353/\0351*\035&\001\0244*/4*#\001\026\f\035\f\001*+\035\001*\0334\035\001&$*$#\001\026\027\001&\033$%'\00120\001*+\035\001 027\024\025\026&\001\025\026'\035\001\026'\001@\026\(4\033\035\001;\f\017\f\0016+\026\027\001\026\027\001\026&\035'*\0261$\025\001*\024\001@\026\(4\033\035\001;\f\0062\00124*\001 026\032\032\035\033\035'*\0250\001\0271$\025\035&\001\024'\001*+\035\001-\035\033*\0261$\025\001$3\026\027\f\001 6+\035\001 026*\035\033$*\026\024'\001 033\0241\035\027\027\001 027\001 2\035\035'\001 035\033\030\026'$*\035&\001 4\027\026'\(\001 001 026\0274$\025\001 1\033\026*\035\033\026\024'\0011\024'1\0254&\026'\(\001*+\035\001\032\024\025\025\024%\026'\(\001-$\0254\035\027\001\024\032\001*+\035\001/$\033$\030\035*\035\033\027L\001 022 031 n\0162\024\022  O\t?\0019*\026\030\035\0014'\026*\027:#\001 022 031 016\b\033  O\006\002\007\0019*\026\030\035\0014'\026*\027:\001$'&\001 3 r\f?\r?\f\001 6+\035\027\035\001 0254\035\027\001 033\035\001 1*4$\025\0250\001 030\035$'\026'\(\025\035\027\027\001 24*\001 027411\035\027\027\0324\025\0250\001 033\035/\033\035\027\035'*\026'\(\001*+\035\0014'\036'\024%'\001\033\035$\025\001&\026\027*\033\02624*\026\024'\f\001 001 001 001 001 001 001 001 001 001 001 001 001 001 001 001 001 027\f\022\f\024\0336\004 f\017 037\004%\007\b\0252\b\007\003\f\033\004\017\016\0172\b\007\003\005\016\024\004\007\006\0062\021\005\024\022\004\034 r 004\023\007\006\004\024\016\004\007\022\f\004\021\f\021\016\r\n\004\004 004\004\007\006\004\017\f\r 001\031\003 037\004 f\0172 037\004%\007\b\0252\b\007\003\f\033\004\017\016\0172\b\007\003\005\016\024\004\007\006\0062\021\005\024\022\004\034 r 017 023\007\006\004\003\t\016\004\007\022\f\036\022\r\0162\017\004\004 004\004\033\005\006\003\r\005\0132\003\005\016\024\004\007\006\004\017\f\r\004 031\006\r 037 017 001 004\026!\022\002\t\021\(>\t$\t/\n\023!\003\005\007\004\n\020\t\013\n\022\t\0077\n\t\005\026\0024\026\022\n!\023\t\005\023\023\022\n\005\016\025 001 001 6 035\001 026\030/$1*\001 024\032\001 033\035$*\026'\(\001 034 r 001 033\024'\(\0324\025\0250\001 032$&\035\027\001 0\001 032*\035\033\001 025\025\001 035\001$\033*\0261\025\035\027\001\024\032\001 034 r\001 001+$-\035\001\022&\026\035&\022#\001\026'\001*+\026\027\001\0353$\030/\025\035\001$\033\0244'&\001 035 004\r\r f\001 001 001 001 t 005\035\023\003\002\t"0 t 024\025\002\t\004\035\023\003\002\035\002\020\007\005\007\004\n\020\t\n\013\t\022\002\005\003\t\013\004\002\003\027\t\027\005\007\005\t\t 6+\035\001 0353*\001 0353$\030/\025\035#\001 026\030\026'\(\001 001 035\001 035-\035\025\024/\030\035'*\001 024\032\001 1*4$\025\001 027/\0351\026\035\027I\001\033\035\025\026$2\026\025\026*0\001\030\024&\035\025#\001\032\024\025\025\024%\027\001$\001\033\0244*\035\001\032\024\033\001\026\030/\025\035\030\035'*\026'\(\001 035\001\(\035'\035\033\0261\001/\033\0241\035&4\033\035\001\0244*\025\026'\035&\001\026'\001\027\0351*\026\024'\001?\f\001\001 M\024'\035*+\035\025\035\027\027#\0014\027\035\0324\025\001\033\035\(4\025$\033\0265$*\026\024'\027\001$\033\035\0010\035*\001/\024\027\027\0262\025\035\001/\033\026\024\033\001*\024\001 035\001 0250\027\026\027\f\001 020'*\033\024&41\026'\(\001 035\001&$*$\001*\024\001*+\035\001 035H4$*\026\024'\001 031\004\\001 026\025\035\001 4\033/\024\027\035\0250\001 033\035\027\027\026'\(\001 035\001 0353/\024'\035'*\026$\025\001 033\035\025\026$2\026\025\026*0\001 030\024&\035\025\001 035'$2\025\035\027\001 035\001 1$\02514\025$*\026\024'\001 024\032\001 035\001 027/\0351\026\035\027I\001 G66@\f\001 6+\026\027\001 1+$\033$1*\035\033\026\027*\0261\001 026\027\001 0353/\0351*\035&\001 024\001 033\0243\026\030$*\035\0250\001 030$\026'*$\026'\001 026*\027\001 0254\035\001 026'\001 035\001 032\026'$\025\001 030\024&\035\025\001 032\024\033\001 0'$\030\0261#\001 030$\027\027\005\027*$*\026\027*\0261\027#\001 001 2$\027\035\f\001 6+\026\027\001 0\026\035\025&\027\001 035\001 0271$\025\035\001 033$\030\035*\035\033\001 9*\026\030\035\001 4'\026*\027:\001 K\001 035\033\035\026'$\032*\035\033\001*+\035\001G66@#\001%+\0261+\001@\024\033\001*+\035\001C\035\02624\025\025\001&\026\027*\033\02624*\026\024'\001\026\027\001 0353/\033\035\027\027\035&\001 20\001 022 023 006 006\n 035\035 025 024 001 006  007 001 026*+\001 Y\001 027\001 035\001 034$\030\030$\001 032 4'1*\026\024'\f\0016+\026\027\001G66@\001\027\035*\027\001$\001-$\025\026&\001\(4\035\027\027\001-$\0254\035\001$'&\001\035\026*+\035\033\001\024\032\001 035\001 033$\030\035*\035\033\027\001  001 024\033\001  001 025\024'\035\001 027+\0244\025&\001 2\035\001 032\026**\035&\f\001 024\033\001 025\035\027\027\001 0'$\030\0261\001 001 2$\027\035\027#\001 033*\02614\025$\033\0250\001 026*+\001 024\001 035%\001 035\025\026-\035\033\026\035\027\001 027\001 026'\001 035\001 1$\027\035\001 027*4&0\001 002\002 001 035\001 035\033$\(\035\001 024/4\025$*\026\024'\001 035\001 001 035 r 001 026\032\001 026\025$2\025\035#\001\030$0\0012\035\0014\027\035&\001$\027\001$\001\(4\035\027\027\001-$\0254\035\001\032\024\033\001*+\035\001\035\032\032\0351*\026-\035\001$\(\035\f\001\001 024\025\025\024%\026'\(\001 035\001 033\0241\035&4\033\035#\001 035\001 032\026\033\027*\001 027\035\001 024\032\001 035\001 0250\027\026\027\001 035'1\035\001 027\0274\030\035\027\001 001 035\001 035\001 026\027*\033\02624*\026\024'\001 024\032\001 034 r 001 026\027\001 0353/\033\035\027\027\035&\001 20\001$\001\024'\035\005\(\033\0244/\001\035\032\032\0351*\026-\035\001$\(\035\f\0016+\035\001\030$*+\035\030$*\0261$\025\001&\035\0271\033\026/*\026\024'\001 024\032\001*+\026\027\0011$\027\035\001\026\027\001*+\035\001\027$\030\035\001$\027\001\026'\001*+\035\001\032\024\033\0304\025$\001\031\006\r\\001%\026 r 034 001 f\001 6+\035\001 026*\035\033$*\026-\035\001 033\024\(\033\035\027\027\001 026'\001 032\026**\026'\(\001 035\001 030\024&\035\025\001 026\027\001 1+\026\035-\035&\001 20\001 030\035$'\027\001 024\032\001$\001\033\035\025\035-$'*\001/\035'$\025*0\001\031\025\024\027\027\\001\0324'1*\026\024'\f\001\020'\001\0244\033\001$'$\0250\027\026\027\001 035\001 033\024\024*\001 030\035$'\001 027H4$\033\035\001 035\033\033\024\033\001 031 031*5 001 027\001 026\030/\025\035\030\035'*\035&\f\001 020*\001 030\035$\0274\033\035\027\001 035\001 001 2\035*%\035\035'\001 035\001 030\024&\035\025\001 024\032\001 035\001 035H4$*\026\024'\001 031\006\r\\001 001*+\035\001\032\026\035\025&\001$1*4$\025\001/\024/4\025$*\026\024'\f\0016+\035\001UG8\021\001\032\024\033\0304\025$\001\026\027L\001 022 023 022 023 017 Z Z 006 031  031  f f  005 021\016\033\f\b 005 030\005\f\b\033 005 031*5 017 034 017 034  033 030 001 001 002 002 n 002 002 001 C+\035\033\035 017 002 001\026\027\001$\001-\0351*\024\033\001\024\032\001$\025\025\001\030\024&\035\025\001/$\033$\030\035*\035\033\027\001$\027\001/\035\033\001\031\006\r\\001$'&\001 031  005 033\037\030\037 001\026\027\001*+\035\001'4\0302\035\033\001\024\032\001\033\035$&\026'\(\027\001\030\026'4\027\001&\035\(\033\035\035\027\001\024\032\001\032\033\035\035&\024\030\001 K\001*+\035\001\030\024&\035\025I\027\001'4\0302\035\033\001\024\032\001/$\033$\030\035*\035\033\027\f\001\001 6\0334'1$*\026'\(\001 1\033\026*\035\033\026\024'\027\001 033\035\001 025\027\024\001 033\035H4\026\033\035&\f\001 6+\0350\001 030$0\001 0330\001 02742>\0351*\001 024\001 035\001 H4$\025\026*0\001 024\032\001 035\001 001 035\001 033\035H4\026\033\035&\001 114\033$10\001 024\033\001 035\001 027*$\(\035\001 024\032\001 035\001 033\0241\035&4\033\035\f\001 024\033\001 026'\027*$'1\035#\001 026'\001 1$\027\035\001 001 024'\035\005 033\0244/\001 035\032\032\0351*\026-\035\001 035\001 030\024&\035\025\001 026\027\001 032$\033\001 032\033\024\030\001 1\024'-\035\033\(\026'\(#\001 026\0274$\025\001 1\033\026*\035\033\026\024'\001 030$0\001 0274\032\032\0261\035\001 024\001 030\024-\035\001 032\024\033%$\033&\001 024\001 035\001 0353*\001 027\035\001 4\027\026'\(\001 024\005\(\033\0244/\001 035\032\032\0351*\026-\035\001 035\001 030\024&\035\025\f\001 020'\001 024*+\035\033\001 1$\027\035\027#\001 035\001 033\0241\035&4\033\035\001 030$0\001 2\035\001 0334'1$*\035&\001 026\032\001 035\001 026\030/\033\024-\035\030\035'*\001 026'\001 UG8\021\001 0254\035\001\026\027\001'\035\(\025\026\(\0262\025\035\f\001\020'\0011$\027\035\001*+\035\001\026'/4*\001&$*$\001$\033\035\001\030\024\027*\001&0'$\030\0261#\001 027\001 026'\001 035\001 1$\027\035\001 027*4&0\001 4 001 035\001 UG8\021\001 030$0\001 2\035\001 1\024\030/$\033\035&\001 024\001 001 11\035/*$2\025\035\001 035-$\0254$*\026\024'\001 024\032\001 035\001 026'/4*\001 032\02541*4$*\026\024'\027P\001 020\032\001 026*\001 026\027\001 027\030$\025\025\035\033\001 001 035\001 026'/4*\001 027*$'&$\033&\001 035-\026$*\026\024'#\001 035\001 033\0241\035&4\033\035\001 0304\027*\0012\035\001*\0334'1$*\035&\001\027\026'1\035\001$'0\001\027\035\035\030\026'\(\001\026\030/\033\024-\035\030\035'*\001\026\027\001$\001\030\035\033\035\001 026\025\0254\027\026\024'\f\001 6+\035\001 025$\027*\001 027*\035/\001 024\032\001 035\001 033\0241\035&4\033\035\001 0353$\030\026'\035\027\001 035*+\035\033\001 035\001 1\024'\027\035H4\035'*\026$\025\001 030\024&\035\025\001 024\032\001 035\001 033\035\025\026$2\026\025\026*0\001 0324'1*\026\024'#\001 026*+\001 024'\035\005 033\0244/\001 035\032\032\0351*\026-\035\001 035#\001 026\027\001 027$*\026\027\032$1*\024\0330\001 11\024\033&\026'\(\001 024\001 035\001 0334'1$*\026'\(\001 1\033\026*\035\033\026\024'\f\001 020*\001 030$0\001 027*\026\025\025\001 2\035\001 024\027\027\0262\025\035#\001 024%\035-\035\033\001 024*\001 0351\035\027\027$\0330#\001 024\001 0324\033*+\035\033\001 030\024&\026\0320\001 035\001 030\024&\035\025\001 20\001 1\024\030\030\035'1\026'\(\001 001 027\0351\024'&\001 027\035\001 026*+\001 024\005\(\033\0244/\001 035\032\032\0351*\026-\035\001 035\001 026\027*\033\02624*\026\024'\f\001 001 026\027\001/+$\027\035#\001*+\035\001%+\024\025\035\001/\033\0241\035&4\033\035\001\026\027\001/\035\033\032\024\033\030\035&\001$\025\025\001\024-\035\033\001$\($\026'#\001 026*+\001\030\024\033\035\0014'\036'\024%'\001/$\033$\030\035*\035\033\027\001$\027\001/\035\033\001\031\006\r\\f\001\001 001 001 004\034\001 005\001\001 005\005\001 005\007\001 005\035\001 005\034\001 006\001\001 001 005\001\001 007\001\001 035\001\001 034\001\001 004\001\001\001 007\b\t\n\013\013 031 031?2 001 EJJ\t 032\020&\024\017\022\b\032\033\013\013\013\013\013\013\013\013 \013\003\001 013 005 013 001 031  f 017   001\001 031  f 017 2  001\001 


Copyright © 2009 Boeing. All rights reserved  Correlation Process To archive received ASDI data  Track messages must be correlated with flight plan messages FLIGHT_KEY assigned Uncorrelated data tagged Approx 30 minutes to correlate one day of data 


Copyright © 2009 Boeing. All rights reserved  Historical Data Processing To load correlated data  Uncompress, unmarshall  Create a list of files containing the correlated data  Write data to warehouse 


Copyright © 2009 Boeing. All rights reserved  Live Data Processing Processed using IBM MQ IBM Message Broker and a technique called XML Shredding Message Broker Compute Nodes  Uncompress Node  Extract correlated messages  Shred Node adds to DB Stored Procedure ìshreds XML docs and adds to tables 


Copyright © 2009 Boeing. All rights reserved  Issues and Observations Initial load of one day of data ~ 7 hours Optimizations  Write data in batches  Use a mutable data structure to create data strings  Deploy a higher performance machine  Use load instead of insert  Use DB2 Range-Partitioned tables  Database tunings Time reduced from 7 hours to approx 30 minutes 


Copyright © 2009 Boeing. All rights reserved  Optimizations Use a mutable data structure to create data strings  Original application created the SQL statement by appending elements to a Java String  It was taking five hours \(of the seven hours Strings  Instead Java StringBuilder used  Java Strings immutable  Time savings of 71.4 


Copyright © 2009 Boeing. All rights reserved  Optimizations Deployed on a higher-performance machine  Application ported from IBM Blade Center HS21 \(4GB of RAM and 64-bit dual-core Xeon 5130 processor to Dell M4500 computer \(4GB of RAM and 64-bit of quad-core Intel Core i7 processor  Reduced the time to thirty minutes Bulk loading instead of insert  Application was modified to write CSV files for each table  Entire day worth of data bulk loaded  Reduced the time to fifteen minutes 


Copyright © 2009 Boeing. All rights reserved  Optimizations Range-Partitioned tables \(RPT  To limit the size of tables, the original code created multiple tables per table type  This puts burden on the application to query multiple tables when a range crosses several tables  With RPT, user is not required to make multiple queries when a range crosses a table boundary  Increased the time to thirty minutes  Additional fifteen minute cost per day of partitioning enabled time savings during queries 


Copyright © 2009 Boeing. All rights reserved  Optimizations Database tunings  Range periods changed from a week to a month  Automatic table space resizing changed from 32MB to 512KB  Buffer pool size decreased  Decreased the time to twenty minutes Overall, total time savings of 95.2 


Copyright © 2009 Boeing. All rights reserved  20 IBM Confidential Analytics Landscape Degree of Complexity Competitive Advantage Standard Reporting Ad hoc reporting Query/drill down Alerts Simulation Forecasting Predictive modeling Optimization What exactly is the problem What will happen next if What if these trends continue What could happen What actions are needed How many, how often, where What happened Stochastic Optimization Based on: Competing on Analytics, Davenport and Harris, 2007 Descriptive Prescriptive Predictive How can we achieve the best outcome How can we achieve the best outcome including the effects of variability Used with permission of IBM 


Copyright © 2009 Boeing. All rights reserved Initial Analysis Activities Flights departing or arriving on a date Flights departing or arriving within a date and time range Flights between city pair A,B Flights between a list of city pairs Flights passing through a volume on a date. \(sector, center, etc boundary Flights passing through a volume within a date and time range Flights passing through an airspace volume in n-minute intervals All x-type aircraft departing or arriving on a date Flights departing or arriving on a date between city pair A,B Flights departing or arriving on a date between a list of city pairs Flights passing through a named fix, airway, center, or sector Filed Flight plans for any of the above Actual departure, arrival times and actual track reports for any of the above 


Copyright © 2009 Boeing. All rights reserved  Initial SPSS Applications Show all tracks by call sign 


Copyright © 2009 Boeing. All rights reserved  Predictive / Prescriptive Analytics Use-Case For a given Airspace Volume of Interest \(AVOI compute distinct traffic volume at some point in the future  Aim to alert on congestion due to flow control areas or weather if certain thresholds are exceeded  Prescribe solution \(if certain thresholds are exceeded Propose alternate flight paths  Use pre-built predictive model  SPSS Modeler performs data processing Counts relevant records in the database \(pattern discovery Computes traffic volume using statistical models on descriptive pattern Returns prediction with likelihood 


Copyright © 2009 Boeing. All rights reserved  Predictive / Prescriptive Analytics Use-Case Advanced Arrival Procedures with Active Abatement Potentials   9/23/10  24 Pulls in the TRACKINFO table of MAIN using SQL Limits the data to database entries which fall inside the AVOI Combines the SOURCE_DATE and SOURCE_TIME to a timestamp that can be understood by modeler Computes which time interval the database entry falls in. The time interval is 15 minutes Defines the target and input fields needed for creating the model Handles the creation of the model Produces a graph based off of the model results Final prediction 


Copyright © 2009 Boeing. All rights reserved  Initial Cognos BI Applications IBM Cognos Report Studio  Web application for creating reports  Can be tailored by date range, aircraft id, departure/arrival airport etc  Reports are available with links to visuals IBM Framework Manager  Used to create the data package  Meta-data modeling tool  Users can define data sources, and relationships among them Models can be exported to a package for use with Report Studio 


Copyright © 2009 Boeing. All rights reserved  Flights Departing Las Vegas on Jan 1, 2012 1 of 3 Report shows the departure date, departure and arrival locations and hyperlinks to Google Map images DeparturePosition and ArrivalPosition are calculated data items formatted for use with Google Maps Map hyperlinks are also calculated based on the type of fix 


Copyright © 2009 Boeing. All rights reserved  Flights Departing Las Vegas on Jan 1, 2012 2 of 3 DeparturePosition, Departure Map, ArrivalPosition and Arrival Map are calculated data items \(see departure items below DepartureLatitude DepartureLongitude DeparturePosition Departure Map 


Copyright © 2009 Boeing. All rights reserved  Flights Departing Las Vegas on Jan 1, 2012 3 of 3 


Copyright © 2009 Boeing. All rights reserved  Conclusion and Next Steps Current archive is 50 billion records and growing  Approximately 34 million elements per day  1GB/day Sheer volume of raw surveillance data makes analytics process very difficult The raw data runs through a series of processes before it can be used for analytics Next Steps  Continue application of predictive and prescriptive analytics  Big data visualization 


Copyright © 2009 Boeing. All rights reserved  Questions and Comments Paul Comitz Boeing Research & Technology Chantilly, VA, 20151 office Paul.Comitz@boeing.com 


Copyright © 2009 Boeing. All rights reserved Advanced Arrival Procedures with Active Abatement Potentials   9/23/10  31 


Copyright © 2009 Boeing. All rights reserved Advanced Arrival Procedures with Active Abatement Potentials   9/23/10  32 Backup Slides 


Copyright © 2009 Boeing. All rights reserved  Initial Approach Initial Investigations  Apache Solr/Lucene  Data Warehouse Evaluate Hadoop in the future 


Copyright © 2009 Boeing. All rights reserved  Using SOLR Uncompress Track Information Messages To use with Solr  Transforming track messages from their  original schema to Solr required building a ìkey, valueî list using an XSTL  Queries made against this list of ìkey, valueî pairs Transformation Process  One day of data ~ 4.5 hours Once transformation complete search/query performance very good Geo spatial queries using  unique query language 


Copyright © 2009 Boeing. All rights reserved  Representation Aviation data is frequently represented in more than one form 


