Toshiro Minami Yoko Ohura 
Kyushu Institute of Information Sciences 6-3-1 Saifu Dazaifu Fukuoka 818-0117 Japan and Kyushu University Library Fukuoka Japan Email minami@kiis.ac.jp Kyushu Institute of Information Sciences 6-3-1 Saifu Dazaifu Fukuoka 818-0117 Japan Email ohura@kiis.ac.jp 
Investigation of Students Attitudes to Lectures with Text-Analysis of Questionnaires 
The eventual goal of our study is to help teachers who give lectures in universities and other educational organizations with advising them as well as to help the attending students in order to maximize the learning performance of 
Abstract 
student In order to achieve this goal we take the modelbased approach We construct student’s learning model at 036rst and then extract appropriate tips on teaching for teachers and on learning for students In this paper as an attempt in this approach we analyze the text data which were obtained as answers to a term-end questionnaire in a course Firstly we make a grouping of students based on a correspondence analysis of students and words from the answers to a question about the student’s achievement in taking the course Then we compare these student groups in combination with other data such as examination scores as achievement and attendance and homework scores as effort as well as the features of words 
used in the answered texts We have found that the students who have good achievement scores often give the comments from a wider view than what they actually learned in the class On the other hand the students who give the comments using those terms which were taught in the class tends to have low achievement scores The methods for in-depth analysis used in this paper are supposed to be appropriate tools for complementing the results from using the big data analysis methods and need to be developed more toward the future 
Text Mining Correspondence Analysis Free Description Questionnaire Educational Data Mining Lecture 
Keywords 
Data Analysis 
I I NTRODUCTION It has been pointed out in Japan that the students academic skills and achievements have been decreasing There are various factors behind it One factor comes from the declination of birth rate and the increase of university enrollment rate As a result universities compete so hard that even the students with low achievements are able to enter universities Another factor is that the students have been educated under the misconception of yutori or relaxed education and thus education were considered to be done without stress and thus let them learn as they want so that quite a lot of students have not been encouraged to learn 
even the fundamental academic skills and knowledge Due to the reason that such factors are complicatedly intertwined quite a lot of universities are facing the problem of providing with higher education to the students with low academic skills together with low motivation to learning In order to cope with this problem universities have introduced remedial courses for students who need to learn preparatory materials and they also enhance the courses for the 036rst year students to be got used to the style of teaching in university Furthermore universities have introduced the FD Faculty Development program as a promotion of changes of the consciousness of university professors and 
improve the quality of university education However students academic skills do not look to be improved even with such a lot of efforts Thus we assume the essential problem lies in students rather than professors with their educational ability In combination with our observation in the lectures we presume that the most important factor on this problem is not on the students academic skills and the amount of knowledge but on their attitudes such as eagerness to learn curiosity to learn something new motivation to learn and other mental tendencies Thus it is important to take the student side into consideration even more which we would call SD Student Development in 
order to 036nd a solution of the issue we have Based on such an awareness our eventual goal of the study presented in this paper and our other related papers is to 036nd out the most appropriate teaching/advising/leading methods for the students learn the most out of the lectures In order to achieve this goal we take the model-based approach where 1 make a student’s learner model which includes attitudes to learning and 2 utilize the model and advise the student in order to maximize the student’s achievement As a part of this approach this paper presents a case study of analyzing a group of class data answer to a questionnaire and attendance/homework/examination 
scores The model dealt with in this paper aims to represent the student’s learning style and attitudes which are obtained in the analysis of lecture data Goda et al   tak e a similar approach and present a method of text analysis where text data are given by students as reports about the everyday lectures Our studies are different as we use such data as attendance homework exercise and term-end examination which are obtainable in ordinary lectures Another difference of our approach is that we do not intend to estimate the student’s achievement We focus on to make a learner model of students 
2013 Second IIAI International Conference on Advanced Applied Informatics 978-0-7695-5071-8/13 $26.00 © 2013 IEEE DOI 10.1109/IIAI-AAI.2013.34 56 
2013 Second IIAI International Conference on Advanced Applied Informatics 978-0-7695-5071-8/13 $26.00 © 2013 IEEE DOI 10.1109/IIAI-AAI.2013.34 56 


r  
r  
A C Group A738 E C3 A verage 73  8 Average = 65.5 D2 D1 B D Group 
0 0 
Figure 1 Correlation between Examination Scores x-axis and Homework Scores y-axis Correlation Coef\036cient 
000 
000 
Other studies of educational data analysis have been conducted in the research 036elds such as KDD Knowledge Discovery and Data Mining and in EDM Educational Data Mining The paper gi v es a comparati v e study of data mining algorithms for classifying students using data from e-leaning system Its major interest is on predicting the student’s outcome Ours is on rather the student’s psychological tendency in learning such as eagerness diligence seriousness etc which is different from that in KDD and EDM where they use the target data those are obtained from learning management systems whereas our target data are those we can create in everyday lectures Our aim is to develop practical methods for extracting tips for improving lectures from data We intend to develop the tools which are applicable even to small data W e have been taking such an approach in the analysis of library data In the papers 8 10 and 11 we tak e library s circulation records as the target data and analyze them with proposing new concepts such as expertise levels of books and library patrons The seat usage data of a library were also analyzed in From these e xperiences we are con vinced that such an approach is useful also for small data In order to achieve the aim rest of the paper is organized as follows In Section II we describe about the target data In Section III we show some of our 036ndings in our previous analysis In Section IV we conduct the analysis by focusing attention to the words used by the students in the answer texts of a question about their 036nal evaluation on the effects of taking the class Finally in Section V we conclude the discussions and 036ndings of this paper II T ARGET D ATA The data used in this paper come from the class of Information Retrieval Exercise in 2009 in a women’s junior college   There were 35 attending year 2 students who are going to graduate This is one of the compulsory courses for librarian certi\036cate Thus the students of this course were more diligent than average The most important aim of the course is to let the students become expert information searchers in the sense they have enough knowledge about information retrieval search 036nding and also have enough skills in 036nding appropriate search engine site and search keywords based on the understanding of the aim and background of the retrieval The course consists of 15 lectures The attendant is supposed to solve a small quiz at every lecture which turns into the attendance record and the basic data for attendance score Also homework is assigned every week Its aim is to make the students review what they have learned in the class and to study preliminary knowledge for the next class At the same time the students are requested to write a lecture note every week which is also aiming to make the students review what they have learned The homework score re\037ects the frequency and quality of the submitted homeworks The term-end examination of the course consists of 3 problems/questions The 036rst question is about 036nding the Web sites of search engine and summarizing their characteristic features together with discussing about the methods for information retrieval The second question is on 036nding the Web sites on e-books and on-line material services The third question is to 036nd and discuss about the information criminals in the Internet environment The aim of these questions is to evaluate the skill on information retrieval including the planning and summarizing skills that are supposed to be learned and trained in the course as they do their exercises in the classes and as they do their homeworks The scores of term-end examination represent the evaluation results according to this aim The number of the answered items varies from student to student Among 35 students 20 of them answered both of the evaluation scores for lectures and themselves Thus we use these 20 score data in analysis on evaluations We also asked the students to answer to the questions as the overall evaluation of them for the course Some of them are Q1 what the student learns in the lectures Q2 good points of the lectures Q3 bad points that need to be improved Q4 the score of the lectures as a whole with the numbers from 0 to 100 where the pass level is 60 as in the same way to the examination score  Q11 the score of the student herself in terms of her attitude and attitude toward the course from 0 to 100 as in the same way as in question 4 and 036nally Q12 any other comments III R ESULTS OF P REVIOUS A NALYSIS Figure 1 shows the correlation between the examination scores x-axis and the homework scores y-axis It is easy to cluster students with big central cluster together with some other students off the cluster even though there is no statistical association between them correlation coef\036cient  The main cluster is the rectangular area that is formed from 50 to around 80 in examination scores and from 50 to around 90 in homework scores 
0 0 
57 
57 


There exist some students away from this area Student A for example takes the highest score in examination whereas in terms of homework her score is one of the more-than-average but not the highest Student B has the lowest homework score However she gets the 4th highest examination score She is a typical student who has high performance in comparison with effort On the other hand the students in C group are the lowest in examination scores Their homework scores are mostly more than average and look like as if they do some amount of efforts Thus they are opposite to Student B in the sense that their performances are very low in comparison with efforts they spent The students in D group have relatively low efforts in homework scores and also have lower-than-average examination scores Actually these students belong to the major cluster in attendance score Thus their efforts are somewhat super\036cial they put efforts in attendance but they do not put more laborious efforts in homework By analyzing the relations of attendance and homework scores as the indexes for effort and examination scores as the index for achievement together with the scores in the questionnaires Q4 and Q11 we have found some interesting results What we have found is that notable ratio of students have just attended the lectures and do their homeworks without intending to learn and thus without learning which is against lecturer’s intention of letting them to learn In other words quite a lot of students efforts are rather super\036cial which do not affect to the true improvement of their academic skills We have also analyzed the answers to Q11 and have found that their self-evaluations have more correlation to their homework scores than achievement scores This result also suggests that students major concern is rather on their efforts than on their achievements which is more important from the teacher’s point of view See the papers 7 9 and for more 036ndings of the analysis IV A NALYSIS OF Q UESTIONNAIRES In this section we chose Q1 What did you learn in this class Did it help you for analysis because this question asked the students to summarize what they have learned in the class The answer is given as a text that expresses the student’s recognition of her achievement In order to conduct text analysis we have to transform them into the data that are available for the analysis method we apply One possible method might be creating data manually one or more human\(s generate data by reading and judging the data for analysis It is popularly done that a human judges if an opinion about a commercial product in a blog or twitter is positive negative or neutral and create a raw data for opinion analysis Table I E XTRACTED W ORD AND ITS O CCURRENCE T OP 75 Table I shows the top 75 words in their frequencies of appearance in the texts together with their frequencies The verbs are conjugated Note that two appearences of the word Various marked with are different expressions in Japanese which have the common corresponding expression 
A Toward Analysis of Answers for Question 1 B Extraction of Words which Appear in the Answers 
Word Occ Word Occ Word Occ 
Search 88 Function 7 Site 3 Class 37 Result 7 Challenge 3 Information 37 Important 7 Answer 3 I think 34 Opportunity 6 Again 3 Library 33 Now 6 Overseas 3 Learn 32 Tag 5 Basic 3 Know 30 Previous 5 Find 3 Myself 21 Question 5 Device 3 How 21 Seek 5 Go 3 Now 17 See 5 Reference 3 Way 16 Type 5 Librarian 3 Examine 16 More 5 Time 3 Keyword 13 Adequate 5 Received 3 Are various 11 Various  4 Collect 3 Use 10 Differ 4 Homework 3 Help 10 Exercises 4 Leave 3 Necessary 9 Use of 4 Introduction 3 Use 9 Lecture 4 Detailed 3 Internet 8 Learn 4 World 3 Personal Computer 8 Body 4 Correct 3 Think 8 Knowledge 4 Other 3 Do 8 Tune 4 Large 3 Get 8 Really 4 Content 3 Various  7 Good 4 Dif\036cult 3 Feel 7 Way 3 Usually 3  different words in Japanese However such method may cause of creating biased or subjective data because the created data produced by humans depend on their interpretation of the expression and thus may differ from human to human In this paper we conduct analysis of word occurrences in text in order to avoid such subjective bias and 036nd more objective results On the other hand we are able to pursue analysis about words by using information about relations between words their parts of speech etc We use the KH as the analysis tool in this paper  KH Coder is a free software which is equipped with the facilities of morphological analysis for Japanese language and can extract words or in\037ection processing together with statistical analysis including correspondence analysis In our analysis we consider the answer of each student as one document for KH Coder 
000 
58 
58 


Test Score Classi\036cation Standardized Values Text Classi Examination Homework Attendance 
Grp1 Grp2 Grp3 4  p onent2 \(8.4 4 Grp4 Com p Grp5 Component1 \(10.59 
Group No Number of samples Average Variance Source Sum of Squares Degree of Freedom Mean Square F-Statistics P-value FCritical Value 
It is important to know not only the words themselves but also their relations such as word to word word to student Analysis of such association would give us more useful information about students and their attitudes to learning Figure 2 shows the results of the correspondence analysis in a two-dimensional principle component space The words appeared in the 036gure are those in Table I those with more than 2 times of appearance for Q1 The underlined ones with st0 in the 036gure represent the students of the class Now we divide the students in Figure 2 into 5 clusters from Grp1 to Grp5 Table II summarizes some of their features such as number of students of the group the member’s average examination scores their variance and some others The groups consist of 3 members in minimum Grp4 and 16 members in maximum Grp5 For the average scores Grp3 is the highest with the score 83.5 which locates in the upper-right part in Figure 2 Grp5 takes the lowest score with 59.3 which locates in the lower-left corner As we check the P-value which is 0.0469 and it can be seen Table II A NALYSIS OF V ARIANCE T ABLE OF 5G ROUPS  In Section III we have classify the students based on the effort-achievement analysis We picked up some students who are typical in some sense and called them from A to E We would like to see their positions in our correspondence map Figure 2 Table III shows the examination homework and attendance scores in standardized values together with the group from Grp1 to Grp5 they belong to Standardized scores in the table are obtained by standardized mean value becomes and standard deviation becomes so that the different scores are comparable in a uniform way Thus negative values indicate that the score is less than average of the class The shaded items indicate that the value is within the lowest 2.5 
C Correspondence Analysis of Words and Students D Investigating Locations of the Students A to E 
0 1 
Between Samples 2399.34 4 599.84 Within Samples 6072.57 28 216.88 Total 8471.91 32  
Figure 2 Correspondence analysis map of related words with students The underlines for each student and the grouping line and the number by the author in English The shaded words are those relating deeply to the subject the students have learned in the lecture and other non-shaded words are generic words We can see in Table I the words related to the lectures appear in high frequencies For example the word Search appears 88 times in the answers to Q1 which is the most frequently used one among all words Also the words Information Library and so on appear in the list The lecturerelated words are 10 13 among 75 wrods whereas 6 21 among 28 with frequencies more than 6 Grp1 4 65.2 27.3 Grp2 5 70.5 98.8 Grp3 5 83.5 107.2 Grp4 3 69.8 68.7 Grp5 16 59.3 335.3 2.76 0.0469 2.71 Table III S TUDENT CLASSIFICATION OF TEXT AND TEST SCORE  A 2.08 0.79 0.47 Grp3 B 0.97 3.06 3.18 Grp5 C1 1.94 0.55 0.96 Grp5 C2 1.65 0.31 1.23  C3 2.21 0.05 0.96 Grp5 C4 2.37 0.91 0.23 Grp5 D1 0.70 2.34 0.50 Grp2 D2 0.85 2.34 0.23 Grp5 E 0.23 0.05 0.23 Grp1 The item marked with  indicates the student gives no answer to the question and thus does not belong to any group that there is a difference between the averages of these 036ve test scores among the groups statistical signi\036cance at the 5 level 
59 
59 


000 000 000 000 000 002 002 002 002 002 002 000 000 
Think Method Answer Collect Keyword Important Get TV Seek Consideration Data Practice Get Advance Arrangement Net Input Things Forecast Announcement Quick Important Angle Force Have a very hard time Think Surely Quality One Myself Extraction Art Put Search Students Question Conceive Choose Necessary Grp2 How to choose Saving Give up Smooth Important Basic Effect Term Increase and decrease Function Challenge Short time Words Margin Simple Other Lead Put in Occur Dif\036cult Seek Everyday Other Collection Necessary Adequate Raise Collect Early Information Get Familiar Tune Do Key Do Time Differ A lot of Press Help Body Adequate Challenge PrintScreen Are various Internet Help Time Search Grp3 Foreign Library Put together Show Go Library Individuality Country Limit Foreign country Latest Summary Box Interesting Automatic Effort Take HP Photo Especially World Relationship Closed Introduction Completely See Plus Books Familiar Lending IC Whole country Appear Japan Electronic Tags At the same time Root Copyright Large Various Reference Tackle Every time Usually Feel Also Province Learn Library Grp4 Omitted Grp5 6 students out of 16 Layout Screen Website Fresh Application A long time ago Item Open Question In addition to Uphill battle Question Report Menu See Type Barry Really Study Word Rich Yahoo Find Now Writing style Save Qi Learn Nice I think Master PC Someday Now Accurate Learn Server Help Little Google Number Respond Begin Way Interesting Various Compared Answer Recently Sense Use Increase Prior Weak Problem Key word Enormous Current 
E Relation between Used Words and Examination Scores 
83 5 2 40 
000 000 000 000 000 000 000 000 000 000 000 
000 002 
All the students except one locating in the lowest 30 in either scores of examination homework or attendance belong to Grp5 Even though the exceptional student belongs to Grp2 we can see in Figure 2 that Grp2 and Grp5 are located very closely so that we can say that all the students locate to within the area for Grp5 and its surrounding area Conclusively we can say there is no signi\036cant difference between classi\036cation by effort and achievement scores and that by used word in the text analysis We deal with the correlation between the characteristic words that appear in the answers to Q1 and the examination scores Table IV shows the top 10 characteristic words of some of the students using the Jaccard similarity measure Note that the Jaccard similarity of student p and q is de\036ned as the ratio of the number of words which are commonly used by p and q against the total number of words which are used either or both of p and q Thus the Jaccard similarity ranges between 0 and 1 The value becomes 1 if every words used by p and q are the same and it becomes 0 if p and q do not use a word in common The words marked with     and   in Table IV indicate that they are classi\036ed as those for the general information for frequently appearing words that relate to the lecture and for characterizing the subject respectively The values in the right-hand side of st0 represents the examination score of the student Table V shows the number of characteristic words number of members usage ratio of the characteristic words and the average score of the examination of each group from Grp1 to Grp5 The group having the highest examination score of is Grp3 and it has the highest usage rate as well On the other hand Grp1 and Grp2 have the lowest usage ratio but have the 2nd and 4th highest examination scores Thus we could not 036nd a clear correlation between the usage ratios and the examination scores As we investigate further by taking attention on the words used by the students we can 036nd that the students in Grp1 do not use many of the characteristic words and the correlations between the students are relatively low Its examination score is the 4th highest among 5 groups For Grp2 2nd highest in examination score commonly use such words as problem time and examination which are relating to the actual activity directly relating to the lectures For Grp3 the highest in examination score characteristically use the technical characteristic words and those words from the broader point of view in comparing Japan and the world such as foreign national and Japan It is interesting to see that the words relating to the homework matters do not appear in Grp3 Thus we can see that the students in Grp3 have the lectures in the standpoint of seeing things in a broad perspective of the lecture Table IV C HARACTERISTIC WORDS OF STUDENTS Grp1 
st001 st013 st015 st025 st007 st010 st012 st022 st034 st005 st006 st003 st004 st014 st002 st008 st011 st016 st017 st019 
  
60 
60 


Analysis of students learning activities through quantifying time-series comments PCN Qualifying learning activity for assessment based on time-series comments Automated Evaluation of Student Comments on Their Learning Behavior Seat usage data analysis and its application for library marketing An attempt on effort-achievement analysis of lecture data for effective teaching Toward learning support for decision making  utilization of library and lecture data  Investigation of interest range and earnestness of library patrons from circulation records Towards Development of Lecture Data Analysis Method and its Application to Improvement of Teaching Pro\036ling of Patrons Interest Areas from Library’s Circulation Records  An Approach to Knowledge Management for University Students Interest Area Analysis of Person and Group Using Library’s Circulation Records Changes of Interest Range of Students with Circulation Record Analysis Lecture Data Analysis towards to Know How the Students Attitudes Affect to their Evaluations Educational data mining A survey from 1995 to 2005 Data mining algorithms to classify students 
 Proc 15th Annual KES Conference KES’2011 Part II Lecture Note in Arti\036cial Intelligence LNAI 6882 pp 154-164 2011  K Goda and T  Mine  Proc 3rd International Conference on Computer Supported Education CSEDU 2011 pp 6 2011  K Goda S Hiroka w a and T  Mine  ICWL 2013 2013 submitted  K Higuchi KH Coder  http://khc.sourcefor ge.net/en  T  Minami and E Kim  Proc Third International Conference on Intelligent Information and Database Systems ACIIDS 2011 LNAI 6591 pp 238-247 2011  T  Minami and Y  Ohura  Proc Database Theory and Application DTA 2012 2012  T  Minami and Y  Ohura  Proc The 4th KES International Conference on Intelligent Decision Technologies KES-IDT’2012 Springer Smart Innovation Systems and Technologies 16 pp 137-147 2012  T  Minami and K Baba  Proc International Conference on e-Services and Knowledge Management ESKM 2012 in IIAI-AAI 2012 IEEE CPS DOI 10.1109/IIAI-AAI2012.15 pp 25-29 2012  T  Minami and Y  Ohura  Proc 2nd International Conference on Applied and Theoretical Information Systems Research 2ndATISR 2012 14pp 2012  T  Minami  Proc The Fifth International Conference on Information Process and Knowledge Management eKNOW 2013 6pp 2013  T  Minami  Proc IADIS International Conference Information Systems IS 2013 8pp 2013  T  Minami  Proc Information Conference 2013 Information’13 4pp 2013  T  Minami and Y  Ohura  8th International Conference on Information Technology and Applications ICITA 2013 2013 to appear  C Romero and S V entura  Proc Expert Systems with Applications 33 pp 135-146 2007  C Romero S V entura P  Espejo and C Herv as  Proc 1st International Conference on Educational Data Mining EDM 2008 pp.8-17 2008 
Table V U SAGE RATE OF CHARACTERISTIC WORDS  Grp1 2 4 0.50 65.2 Grp2 3 5 0.60 70.5 Grp3 12 5 2.40 83.5 Grp4 4 3 1.33 69.8 Grp5 18 16 1.13 59.3 A lot of technical words appear in Grp4 the 3rd in examination score and there does not appear frequent words The students in Grp5 the lowest examination score uses quite a lot of words of frequent general information and do not use technological words It is interesting to see that many students use the words learned in the lectures such as learn master study useful and used So we can guess they are too much concentrated on the words themselves and may not pay much attention to what they really mean to them and to the society they live V C ONCLUDING R EMARKS We have conducted a morphological analysis of the answers to Q1 With extracting the high frequency words using Jaccard similarity measure based on the hypothesis that students who use the similar words are close in their learning styles and thus in their outcomes As we investigate by dividing the students into 036ve groups according to the distance of the word usages and have conducted an analysis of variance on the average of the examination scores we found that there really are differences between the groups in their average scores We have the following problems for future research 1 To develop a method to devise new ideas further and to perform re\036nement of dedication to the study of student effort and attitudes to learning especially further analysis of the text portion 2 By collecting data from a different class to analyze them and to verify if the results of this study are also holds 3 To generalize the analysis methods and to integrate them into an automated data analysis system A CKNOWLEDGMENT This work was supported in part by the Ministry of Education Science Sports and Culture Grant-in-Aid for Scienti\036c Research C 24500318 2013 R EFERENCES  K Goda and T  Mine 
Group Characteristic Words Number of Members Usage Ratio Average of Examination Scores 
61 
61 


Fig 6 Number of Disk Accesses and number of similarity calculation on query execution on database fragments of different sizes a distance radius equal to 50 of a given image takes around 1,200 seconds using the Slim-tree for the respective fragment and 18,577 seconds using the Slim-tree for the entire database On the other hand the query to retrieve images annotated with the tag value chamberlains just 2 images and within the same distance radius of 50 from a given image takes less than 1 second using the respective fragment and 12,514 seconds using the Slim-tree index for the entire database Finally Figure 7 presents the results of a conjunctive complex query with the equality predicate tag  puppy and a kN N q predicate with the center in the image presented in the top left corner highlighted by the red square These 4 images are ranked in the results from left to right and from top to bottom The execution of this query using the fragment referring to the tag puppy  which contains the descriptions of 105,570 images took 108 seconds using a B-tree to 002nd the fragment and a Slim-tree to process the similarity-based predicate in the contents of this fragment As the kN N predicate is not commutative with other predicates for data 002ltering we sho w in Figure 8 the results of a query by a Range q predicate with radius 50 and center in the image on the top left corner These results were produced by using a Slim-tree that indexes the entire database This query took 13,176 seconds to execute Filtering these results for the tag value puppy to produce the result showed in Figure 7 would require further processing but the time to solve the Range q predicate on the Slim-tree that indexes the entire database contents is dominant VI C ONCLUSIONS AND F UTURE W ORK This paper introduces an approach for ef\002ciently processing queries on big complex databases by using horizontal fragments of the database and multi-level indexing This approach has three steps i 002nd fragments with data satisfying some query predicate\(s ii 002lter the data in the chosen fragment\(s according to other predicate\(s conjunctively connected to the former iii compose the results obtained from each fragment The experimental results demonstrate that this proposal drastically improve query execution speed They show that it is not viable to run the similarity-based predicates over the Fig 7 Results of a conjunctive query executed by using the fragment that describes only images tagged with puppy Fig 8 Results of a Range q predicate on the entire database that took almost 100 times longer to produce than those in Figure 7 entire CoPhIR database that describes around 106 million images even using the Slim-tree metric index to speedup the execution of similarity-based predicates on image content descriptors In fact even big fragments describing more than a 100 thousand images approximately need to be further fragmented to ensure acceptable response time Though the case study presented in this paper only considers conjunctive queries with an equality predicate and a similarity-based predicate the proposed approach can be employed for ef\002cient execution of queries with arbitrary numbers of predicates of various kinds and logically connected in different ways In fact our approach opens new research paths towards ef\002cient query execution on big complex data Among the challenges involved in the full exploitation of the proposed approach we mention the following ones for future work i develop automatic techniques to create appropriate horizontal fragments of large databases for ef\002cient query execution ii index fragment collections to ef\002ciently 002nd fragments suitable to solve different kinds of predicates iii devise and validate queries optimization techniques that exploit appropriate database fragments and access methods VII A CKNOWLEDGMENTS Thanks to CNPq CAPES FEESC and FAPESP for their 002nancial support 
542 


R EFERENCES   J Darmont O Boussaid J.-C Ralaivao and K Aouiche An architecture framework for complex data warehouses CoRR  vol abs/0707.1534 2007   A Goker J Davies and M Graham Information Retrieval Searching in the 21st Century  John Wiley  Sons 2007   R A Baeza-Yates and B A Ribeiro-Neto Modern Information Retrieval the concepts and technology behind search Second edition  Pearson Education Ltd Harlow England 2011   R Baeza-Yates and M Melucci Eds Advanced Topics in Information Retrieval  Springer 2011   P Zezula G Amato V Dohnal and M Batko Similarity Search The Metric Space Approach  Springer 2006 vol 32   H Blanken A de Vries H Blok and L Feng Eds Multimedia Retrieval  ser Data-Centric Systems and Applications Heidelberg Springer Verlag 2007 iSBN=978-3-540-72894-8   R Datta D Joshi J Li and J Z Wang Image retrieval Ideas in\003uences and trends of the new age ACM Comput Surv  vol 40 no 2 pp 1–60 2008   J Wang J Li and G Wiederhold Simplicity semantics-sensitive integrated matching for picture libraries Pattern Analysis and Machine Intelligence IEEE Trans on  vol 23 no 9 pp 947 963 sep 2001   Y Zhuang Q Li and R Lau Web-based image retrieval a hybrid approach in Computer Graphics International 2001 Proceedings  2001 pp 62 69   J.-R Wen Q Li W.-Y Ma and H.-J Zhang A multi-paradigm querying approach for a generic multimedia database management system SIGMOD Rec  vol 32 pp 26–34 March 2003   D Joshi R Datta Z Zhuang W P Weiss M Friedenberg J Li and J Z Wang PARAgrab a comprehensive architecture for web image management and multimodal querying in Proceedings of the 32nd International Conference on Very Large Databases  ser VLDB VLDB Endowment 2006 pp 1163–1166   N Rasiwasia J C Pereira E Coviello G Doyle G R G Lanckriet R Levy and N Vasconcelos A new approach to cross-modal multimedia retrieval in ACM Multimedia  A D Bimbo S.-F Chang and A W M Smeulders Eds ACM 2010 pp 251–260   C Traina Jr A J M Traina M R Vieira A S Arantes and C Faloutsos Ef\002cient processing of complex similarity queries in rdbms through query rewriting in ACM 15th International Conference on Information and Knowledge Management CIKM 06  P S Yu V J Tsotras E A Fox and B Liu Eds Arlington VA USA ACM Press 2006 pp 4–13   M C N Barioni H L Razente A J M Traina and C Traina Jr Seamlessly integrating similarity queries in SQL Software Practice and Experience  vol 39 no 4 pp 355–384 2009   F Long H Zhang and D Feng Fundamentals of content-based image retrieval Multimedia Information Retrieval and Management  2002   D R Wilson and T R Martinez Improved heterogeneous distance functions J of Arti\002cial Intelligence Research  vol 6 pp 1–34 1997   P H Bugatti A J M Traina and C Traina Jr Assessing the best integration between distance-function and image-feature to answer similarity queries in 23rd Annual ACM Symposium on Applied Computing SAC2008  Fortaleza Cear Brazil ACM Press 2008 pp 1225–1230   T Bozkaya and M Ozsoyoglu Indexing large metric spaces for similarity search queries ACM Trans Database Syst  vol 24 pp 361 404 September 1999   P Ciaccia and M Patella Searching in metric spaces with user-de\002ned and approximate distances ACM Trans Database Syst  vol 27 pp 398–437 December 2002 A v ailable http://doi.acm.org/10.1145/582410.582412   H Samet Foundations of Multidimensional and Metric Data Structures The Morgan Kaufmann Series in Computer Graphics and Geometric Modeling  San Francisco CA USA Morgan Kaufmann Publishers Inc 2005   L C mitsubishi Electric Ite-vil The mpeg-7 color descriptors jensrainer ohm rwth aachen institute of communications engineering   M R P Ferreira L F D Santos A J M Traina I Dias R Chbeir and C Traina Jr Algebraic properties to optimize knn queries in Proc of the 26th Brazilian Symposium on Databases SBBD  2011   M S Lew N Sebe C Djeraba and R Jain Content-based multimedia information retrieval State of the art and challenges ACM Trans Multimedia Comput Commun Appl  vol 2 pp 1–19 February 2006 Onl A v ailable http://doi.acm.or g/10.1145/1126004.1126005   R d S Torres A X F ao M A Gonc¸alves J P Papa B Zhang W Fan and E A Fox A genetic programming framework for content-based image retrieval Pattern Recognition  vol 42 no 2 pp 283  292 2009 learning Semantics from Multimedia Content A v ailable http://www.sciencedirect.com/science/article/pii/S0031320308001623   T Skopal Where are you heading metric access methods a provocative survey in SISAP  P Ciaccia and M Patella Eds ACM 2010 pp 13–21   U Murthy E A Fox Y Chen E Hallerman R d S Torres E J Ramos and T R C Falc  ao Superimposed image description and retrieval for 002sh species identi\002cation in ECDL  ser Lecture Notes in Computer Science M Agosti J L Borbinha S Kapidakis C Papatheodorou and G Tsakonas Eds vol 5714 Springer 2009 pp 285–296   K C L Santos H M de Almeida M A Gonc¸alves and R d S Torres Recuperac  ao de imagens da web utilizando m  ultiplas evid  encias textuais e programac  ao gen  etica in SBBD  A Brayner Ed SBC 2009 pp 91–105   D C G a Pedronette and R da S Torres Exploiting contextual spaces for image re-ranking and rank aggregation in Proceedings of the 1st ACM International Conference on Multimedia Retrieval  ser ICMR 11 New York NY USA ACM 2011 pp 13:1–13:8  A v ailable http://doi.acm.or g/10.1145/1991996.1992009   D Hiemstra and C Hauff Mapreduce for information retrieval evaluation let's quickly test this on 12 tb of data in Proceedings of the 2010 international conference on Multilingual and multimodal information access evaluation cross-language evaluation forum  ser CLEF'10 Berlin Heidelberg Springer-Verlag 2010 pp 64–69  A v ailable http://dl.acm.or g/citation.cfm?id=1889174.1889186   N Alipanah P Parveen L Khan and B Thuraisingham Ontologydriven query expansion using map/reduce framework to facilitate federated queries in Proceedings of the 2011 IEEE International Conference on Web Services  ser ICWS 11 Washington DC USA IEEE Computer Society 2011 pp 712–713 A v ailable http://dx.doi.org/10.1109/ICWS.2011.21   Z Wu B Mao and J Cao Mrgir Open geographical information retrieval using mapreduce in Geoinformatics 2011 19th International Conference on  2011 pp 1–5   D S Kaster P H Bugatti A J M Traina and C T Jr Fmisir A 003exible and ef\002cient module for similarity searching on oracle database JIDM  vol 1 no 2 pp 229–244 2010   F J T Chino M R Vieira A J M Traina and C Traina Mamview a visual tool for exploring and understanding metric access methods in Proceedings of the 2005 ACM Symposium on Applied computing  ser SAC 05 New York NY USA ACM 2005 pp 1218–1223  A v ailable http://doi.acm.or g/10.1145/1066677.1066952   C Traina Jr A J M Traina C Faloutsos and B Seeger Fast indexing and visualization of metric datasets using slim-trees IEEE Transactions on Knowledge and Data Engineering TKDE  vol 14 no 2 pp 244–260 2002   P Bolettieri A Esuli F Falchi C Lucchese R Perego T Piccioli and F Rabitti CoPhIR a test collection for content-based image retrieval CoRR  vol abs/0905.4627v2 2009   H Eidenberger Distance measures for mpeg-7-based retrieval in Proceedings of the 5th ACM SIGMM international workshop on Multimedia information retrieval  ser MIR 03 New York NY USA ACM 2003 pp 130–137 A v ailable http://doi.acm.org/10.1145/973264.973286   R Dorairaj and K R Namuduri Compact combination of mpeg-7 color and texture descriptors for image retrieval in Signals Systems and Computers 2004 Conference Record of the Thirty-Eighth Asilomar Conference on  vol 1 IEEE 2004 pp 387–391 
543 


014 014 
014 014 004 
vol 15, issue 2, 2006, pp165190  Ding Z, Huang G, "Real Time Traffic Flow Statistical Analysis Based on Network-Constrained Moving Object Trajectories", proc. of 20th Intl. Conf. on Database and Expert Systems Applications DEXA'09\August, 2009 
Sensor number 4 Node Servers 32 Node Servers 
speedup Q Q  Q General Statistical Database Cluster Mechanism for Big Data Analysis in the Internet of Things 
VLDB Journal 
 SNQP IOTStatisticDB 
005 1000 
icDB IOTStatist SNQP speedup 
1  2 4 have similar results TABLE III S PEEDUP R ATE OF IOT-S TATISTIC DB 
 
 From Figure 8 we can see that, when data size increases the performance of CSA-DSD decreases rapidly while the performance of IOT-StatisticDB is relatively stable. The main reason is that in CS A-DSD, large volumes of statistical raw data needs to be transferred to and stored at the master server for statistical analysis. Therefore, the query response time is prop ortional to the whole data size On the other hand, in IOT-StatisticDB, the main workload is distributed among the nod e servers, so that the overall performance is less sensitiv e to the overall data size To better analysis how the statistical analysis workload is shared by multiple node servers in IOT-StatisticDB, we define the speedup rate 60 100 140 180 220 2.85 3.05 3.71 3.81 3.73 19.25 21 22.36 22.5 21.85 We can observe from Table 3 that when the number of node servers is 4, the speedup rate is between 2.85~3.81 and when the number of node servers is increased to 32, the speedup rate is between 19.25~22.36. In general, with the number of node servers incr easing, the query response time decreases, since in IOT-StatisticDB, the query response time is main decided by the da ta size of each node server V C ONCLUSIONS  Statistical analysis on sensor sampling data is one of the most important procedures in IoT systems to transform dataŽ into knowledgeŽ. In this paper, we propose a 
as follows where is the query response time of single node query processing, and is the query response time of IOT-StatisticDB. Table 3 shows th e speedup rate of  IOT-StatisticDB The main contribution is as follows 1\general statistical database cluster mechanism is proposed, with data typ es and operators for statistical analyzing provided. The mechanism is a general model which can support complicated statistical queries through standard SQL statements 2 methods, including Euclidean-based spatial aggregation, Network-based spatial aggregation, Euclidean-based parameter aggregation, and Network-based parameter aggregation, are proposed with detailed algorithms presented 3\he parallel processing techniques of statistical queries are proposed, so that multiple servers can conduct statistical analysis in parallel and the performance can be greatly improved As the future work, event detections and data mining techniques based on IoT statistical analysis will be studied A CKNOWLEDGMENTS  The work was partially supported by National Natural Science Foundation of Chin a \(NSFC\under grant number 91124001 and by National High-Tech. R&D Program of China \(863 program\gr ant number 2013AA01A603 R EFERENCES   W a ng D, Clustering Mesh-like W i reless Sensor Networks with an Energy-efficient Scheme,Ž International Journal of Sensor Networks vol. 7 No. 4 2010, pp. 199-206  Chen H, Minen o H Mizuno T, A Meta-data-based Data  Aggregation Scheme in Clustering Wireless Sensor NetworksŽ. Proc of Intl. Conf. on Mobile Data Managem ent \(MDM06 May 2006, pp. 154-161  Liu C, W u K Pei J, A Dy nam i c Clustering and Scheduli ng Approach to Energy Saving in Data Collection from Wireless Sensor NetworksŽ, Proc. of IEEE Conf. on Sensor, Mesh and Ad Hoc Communications and Networks \(SECON05 IEEE press, Sep. 2005 pp. 374-385  Z hang Y, W a ng H T i an L   E ner gy and Data Awar e Cluster ing for  Data Aggregation in Wireless Sensor Networ ksŽ, Proc. of IEEE 4th Intl. Conf. on Mobile Ad hoc and Sensor Systems \(MASS07 Press, Oct. 2007 pp. 1-6  Ordonez C S tatistical Model Com putation with UDFs IEEE Transactions on Knowledge and Data Engneering \(TKDE Dec. 2010, pp. 1752-1765  Ester M, K r iegel H P, Sander J Xu X A Density-Ba sed Algorith m for Discovering Clusters in Large Spatial Databases with Noise Proc. of Intl. Conf. on Knowledge Discovery and Data Mining KDD96\, Aug. 1996, pp:226-231  Ankerst M, Breunig M, Kriegel H P, Sander J, Optics: Or der ing Points to Identify the Clustering StructureŽ, Proc. of ACM Intl. Conf on Management of Data \(SIGMOD9 9  Yang Y, W u L Guo J, Liu S, Research on Distrib uted Hilbert R  Tree Spatial Index Based on Birch Clusteri ngŽ, Proc. of Intl. Conf. on Geoinformatics \(Geoinformatics12\IEEE Pr ess, Jun. 2012, pp. 1-5  Chitta R, Jin R Havens T, Jain A   A pproxim ate Ke rnel k-Means  Solution to Large Scale Kernel Clustering Proc. of ACM Intl. Conf on Knowledge Discovery and Data Mining \(SIGKDD11  Zhang Z Yang Y Tung A, Papadias D, Contin uous kMeans Monitoring over Moving Objects IEEE Transactions on Knowledge and Data Engineering \(TKDE May 2008, pp. 1205-1216  Feng X, Ku m a r A, Recht B, Ré C  Towar ds a Unified Ar chitecture for in-RDBMS AnalyticsŽ Proc. of ACM Intl. Conf. on Management of Data \(SIGMOD12\, May 2012, pp. 325-336  Heller stein J R C Schopp m a nn F, W a ng D, Fr atkin E, Gor ajek A et al. The MADlib Analytics Library or MAD skills, the SQL Journal Proceedings of the Very Large Data Base Endowment, vol. 5 issue 12, 2012, pp. 1700-1711  Jam p ani R Xu F W u M, P e rez L Jermaine C, Haas P, The Monte Carlo Database System: Stochastic Analysis Close to the Data ACM Transactions on Database Systems \(TODS\1 pp. 18:1-18:41  Xiong Z Luo W   Chen L Ni L Data Vitalization: A New Par adig m  for Large-Scale Dataset AnalysisŽ. Proc of IEEE 16th Intl. Conf. on Parallel and Distributed Systems ICPADS10 Dec. 2010  Güting R.H, Al m e ida V, Ding Z, Modeling and Quer y i ng Moving Objects in Networks 
543 


  


Bottom Top A B 
Figure 15 Figure 16 
messages seen for all workers in a superstep \(Figures 10 and 13\. When looking at the messages sent by workers in a superstep for METIS, we see that there are message load imbalances within work ers in a superstep, caused due to concentration of vertices being traversed in that superstep in certain partitions This variability is much more pronounced in CP as compared to WG \(Figures 11 and 14\ E.g. in superstep 9 for CP, twice as many messages \(4M\ are generated by a worker compared to another \(2M\.  For Pregel BSP, the time taken in a superstep is determined by the slowest worker in that superstep. Hence increase d variability in CP causes even goodŽ partitioning strategies to cause an increase in total execution time wh en using the Pregel/BSP model VIII A NALYSIS OF E LASTIC C LOUD S CALING  Cloud environments offer elasticity … the ability to scale-out or scale-in VMs on-demand and only pay for what one uses [28   On th e f l i p s i de  on e en ds u p  paying for VMs that are acquired even if they are underutilized. We have already shown the high variation in compute/memory resources used by algorithms like BC and APSP across different supersteps. While our earlier swath initiation heuristics attempt to flatten these out by overlapping swath executions, one can consider leveraging the clouds elasticity to, instead, scale up and down the concurrent workers \(and graph partitions\ allocated in each superstep The peak and trough nature of resource utilization combined with Pregel/BSPs synchronous barrier between supersteps offers a window for dynamic scaleout and …in at superstep boundaries. Peak supersteps can greatly benefit from additional workers, while those same workers will contribute to added synchronization overhead for trough supersteps We offer an analysis of the potential benefits of elastic scaling by extrapolating from observed results for running BC on WG and CP graphs, using four and eight workers.  To provide a fair and focused comparison, we turned off swath heuristics in favor of fixed swath sizes and initiation intervals Figure 15 \(Bottom\ plots the speedup of BC running on eight workers when normalized to BC running on four workers, at corresponding supersteps.  The number of workers does not impact the number of supersteps We also plot the number of active vertices \(i.e. vertices still computing for a given swath\these supersteps which is a measure of how much work is required \(Fig 15 \(Top\. We find that we occasionally get superlinear speedup spikes \(i.e. >2x\ that shows a strong correlation with the peaks of active messages, for both WG and CP graphs. At other times, the sp eedup is sublinear or even a speed-down \(i.e. <1\responding to inactive vertices.  The superlinear speedup is attributable to the lower contention and reduced memory pressure for 8 workers when the active vertices peak \(similar to what we observed for the swath initiation heuristics Similarly, the below par speedup during periods of low activity is contributed by the increased overhead of barrier synchronization across 8 workers. Intuitively, by dynamically scaling up the number of workers for supersteps with peaking active vertices and scaling them down otherwise, we can leverage the superlinear speedup and get more value per worker Using a threshold of 50% active vertices as the threshold condition for between 4 and 8 workers in a superstep, we extrapolate the time per superstep and compared this to the fixed 4 and 8 worker runtimes. We also compute the best-case run time using an oracleŽ approach to i.e. for each superstep, we pick the minimum of the 4 or 8 workers time.  Note that these projections do not yet consider the overheads of scaling, but are rather used to estimate the potential upside if we had an ideal or an automated heuristic for scaling. The total time estimates for running BC on WG and CP graphs, normalized to  
 plot shows speedup of 8 workers relative to 4 workers, for each superstep, when running BC on WG and CP graphs plot shows the number of vertices active in that superstep Estimated time for BC using elastic scaling, normalized to time taken for 4 workers. Normalized cost is shown on secondary Y axis WG graph shown on left CP graph shown on right. Smaller is better 
022\011 022\010 022\007 022\002 006 002 007 006 002 007 010 011 012 013 014 015 006 006\003\002 006\003\007 006\003\010 006\003\011 006\003\012 006\003\013 006\003\014 006\003\015 006\003\016 002 027\031\030\037\020#@\020"\031\030\027\020\035 0201!2#\024$#\015#5\024",\020"#\017\003"\003\031\003#\011#5\024",\020"\035 024"'\033\026\0309\0201#\\031\020 2 035#\032\020"#+!\034 017\020\021\022\023\024\024\025\026\020 027\030\031\022\032\033\031\020\034\031\035 017\020\021\022\023\024\024\025\026\020#?#/\027\031\030\037\020#@\020"\031\030\027\020\035 027\030\031\022\032\033\031\020\034\031\035#?#/\027\031\030\037\020#@\020"\031\030\027\020\035 036\030\034\020\033"#\\0201!2 006 006\003\007 006\003\011 006\003\013 006\003\015 002 002\003\007 006 006\003\002 006\003\007 006\003\010 006\003\011 006\003\012 006\003\013 006\003\014 006\003\015 006\003\016 002 011#5\024",\020 B\034\0267 015#5\024",\020 B\034\0267 1\0332\031\030\037\020 030\034\025 1\0332\031\030\037\020 036\024\017\020 024!\0341 024\035\031#>\024"'\033\026\0309\0201#\031\024#\011#5\024",\020"#.\024\035\031 017\020\021\022\023\024\024\025\026\020#+!\034\022&\030'\020#>\024"'\033\026\0309\0201#\031\024#\011#5\024",\020"#&\030'\020 011#5\024",\020"#&\030'\020 015#5\024",\020"#&\030'\020 024\035\031 006 006\003\007 006\003\011 006\003\013 006\003\015 002 002\003\007 002\003\011 002\003\013 006 006\003\002 006\003\007 006\003\010 006\003\011 006\003\012 006\003\013 006\003\014 006\003\015 006\003\016 002 011#5\024",\020 B\034\0267 015#5\024",\020 B\034\0267 1\0332\031\030\037\020 033\026\030\034\025 1\0332\031\030\037\020 036\024\017\020 024!\0341 024\035\031#>\024"'\033\026\0309\0201#\031\024#\011#5\024",\020"#.\024\035\031 027\030\031\022\032\033\031\020\034\031\035#+!\034\022&\030'\020#>\024"'\033\026\0309\0201#\031\024#\011#5\024",\020"#&\030'\020 011#5\024",\020"#&\030'\020 015#5\024",\020"#&\030'\020 024\035 031 
 
dynamically scaling ideal scaling 
Our hypothesis is that an intelligent adaptive scaling of workers can achieve a similar performance as a large, fixed number of workers, but with reduced cost 
213 


Nature Nature Ecological Applications Nature ACM International Conference on Management of Data \(SIGMOD In Parallel Object-Oriented Scientic Computing \(POOSC Science Communications of the ACM ACM Workshop on Mining and Learning with Graphs Communications of the ACM HotCloud Proceedings of the 19th ACM International Symposium on High PErformance Distributed Computing HPDC Knowledge and Information Systems KAIS International Conference on Computational Science IEEE International Conference on Cloud Computing Technology and Science ACM/IEEE Conference on Advances in Social Network Analysis and Mining \(ASONAM IEEE International Parallel and Distributed Processing Symposium \(IPDPS International Conference on Distributed Computing and Networking Journal of Mathematical Sociology International Conference on Parallel Processing Communications of the ACM 
 
observed time taken using 4 workers, are plotted in Figures 16\(A\ and 16\(B We see that our dynamic scaling heuristic using the percentage of active vertices achieves nearly the same CP\ or better \(WG\ performance as a fixed 8 worker approach. Clearly there is benefit of using fewer workers for low utilization su persteps to eliminate the barrier synchronization overhead. Also, the dynamic scaling heuristic performs almost as well as the ideal scaling. Finally, when we consider the monetary cost of the proposed approaches, assuming a pro-rata normalized cost per VM-second plotted on the secondary Y axis, we see that dynamic scaling is comparable \(CP\ or cheaper \(WG\ than a 4 worker scenario while offering the performance of an 8 worker deployment IX C ONCLUSION  In conclusion, we introduce optimization and heuristics for controlling memory utilization and show they are critical to performance.  By breaking computation into swaths of vertices and using our sizing heuristics we achieve up to 3.5x speedup over the maximum swath size that does not cause the a failure.  In addition overlapping swath executions can provide a 24% gain with automated heuristics and even greater speedup when a priori knowledge of the network characteristics is applied This evaluation offers help to eScience users to make framework selection and cost-performancescalability trade-offs. Our he uristics are generalizable and can be leveraged by other BSP and distributed graph frameworks, and for graph applications beyond BC. Our work uncovered an unexpected impact of partitioning and it would be worthwhile, in future, to examine the ability to pred ict, given certain graph properties, a suitable partitioning model for Pregel/BSP It may also be useful to perform such evaluations on larger graphs and more numbers of VMs. At the same time, it is also worth considering if non-linear graph algorithms are tractable in pr actice for large graphs in a distributed environment B IBLIOGRAPHY  1  F  L i lj er os C   Ed l i n g L  A m a r a l H  S t an ley   and Y    berg The web of human sexual contacts 
vol. 411, pp. 907908, 2001   H Je o n g  S   Ma so n A  L   B a ra b s i  a nd Z   Oltva i  L e t ha l i t y  and centrality in protein networks vol. 411, pp. 41-42 2001   O. B o din and E   E s t r ada    U s i n g n e t w ork c e nt r a l i t y  m e a s ures t o  manage landscape connectivity vol 18, no. 7, pp. 1810-1825, October 2008   D. W a ts s  and S  S t r ogat z  C olle c t i v e  d y nam i cs of  s m a ll-w orl d   networks vol. 393, no. 6684, pp. 440…442, June 1998   G  Ma lew i c z   M A u s t er n A   Bik  J   Dehn er t I  Hor n   N. L e i s er and G. Czajkowski, "Pregel: A system for large-scale graph processing," in 2010   D. G r egor  and A  L u m s dain e  T h e  pa r a llel  B G L  A gen e r i c  library for distributed graph computations," in 2005   B. S h a o  H. W a n g  and Y  L i T he T r init y G r aph E n g i n e    Microsoft Research, Technical Report MSR-TR-2012-30, 2012   A  F ox  C lo ud c o m putin g w h at  s  in it for m e  as  a  s c i e n tis t     vol. 331, pp. 406-407, 2011   S. G h e m a w a t  and J  De an   Map re duc e s i m p lifi e d data  processing on large clusters vol 51, no. 3, pp. 107-113, 2008   J  L i n and M. S c hat z   Des i g n  patt er n s  for eff i ci ent gr aph algorithms in MapReduce," in 2010   L   Va l i ant   A b r id g i n g m o d e l f or pa r a llel com putati o n  vol. 33, no. 8, pp. 103-111, 1990 12 a c h e  Ha ma    O n l i n e    http://hama.apache.org   13 Ap a c h e  Ha d o op    O n l i n e    http://hadoop.apache.org     M Z a h a r i a, M. Ch ow dhu ry M F r ank l in S  S h e n k e r, and I   Stoica, "Spark: Cluster Computing with Working Sets," in 2010   J  Ekana y ak e e t a l     T w i st er A  r untim e f o r it er ati v e  MapReduce," in Chicago, 2010, pp. 810-818   U. K a n g  C  T s o u rakakis   and C. F a l outs o s  Peg a s us   Minin g  Peta-scale Graphs," in 2010   M. P a c e  B S P vs  MapR e duc e    in vol. 103.2081, 2012   S. Seo  E  Yoo n, J  K i m  S  J i n  J-S. K i m   and S   Ma e n g HAMA: An Efficient matrix computation with the MapReduce framework," in 2010, pp. 721-726   S. S a l i h ogl u  and J  W i d o m  G PS A G r a ph P r oc e s s i n g Sy s t em    Stanford University, Technical Report 2011   R L i cht e n w a l t e r and N   Cha w la D is Ne t  A fr am ew ork for  distributed graph computation," in  2011   K  Maddu r i  D. E d i g er K   J i an g  D. Bad e r  and D  Cha v a r riaMiranda, "A faster parallel algorithm and efficient multithreaded implementations for evaluating betweenness centrality on massive datasets," in 2009   E  K r e p s k a, T  K i el m a nn, W  F o kkink, H   Ba l, "A  hi g h level framework for distributed processing of large-scale graphs," in 2011, pp. 155-166   L   Pa ge  S  B r in R. M o t w ani and T  W i nogr ad  T h e P a geRank citation ranking: Bringing order to the web," Stanford InfoLab Technical Report 1999-66, 1999   U  Brand  s  A f a s t er  a l gor ith m for  b e t w eenn e s s c e nt r a l i t y    vol. 25, no. 2, pp. 163-177 2001   Stan fo r d  Net w or k A na l y s is Pro j e c t  O n l in e    http://snap.stanford.edu    I  S t ant o n and G  K l i o t, "S t r e a m i n g G r aph P a rtiti o n in g  for L a rge Distributed Graphs," Microsoft Corp., Technical Report MSRTR-2011-121, 2011   G   K a ry pis and V   K um a r A fas t and hi g h qua l i t y m u l t i l evel scheme for partitioning irregular graphs," in 1995, pp. 113-122   M. A r m b r u s t e t  a l   A v i ew of  c l o u d  c o m putin g    vol. 53, no. 0001-0782, pp. 50-58 April 2010  
214 


  13  or gani c  c he m i s t r y  i n our  Sol ar  Sy s t e m       Xi a n g  L i r e c e i v e d h i s B  S   m is tr y  fr o m  th e  P e k in g  U n iv e r s ity  C h in a  in  2 0 0 3  and P h D   i n P hy s i c al  C he m i s t r y  f r om  t he  J ohns  H opk i ns  Un i v e r s i t y  i n  2 0 0 9   He  h a s  b e e n  a  R e s e a r c h  A s s o c i a t e  wi t h  a  j o i n t  a p p o i n t m e n t  a t  t h e  U n i v e r s i t y  o f  M a r y l a n d   Ba l t i m o r e  C o u n t y  a n d  N AS A G o d d a r d  S p a c e  Fl i  Ce n t e r  s i n c e  2 0 1 1   H i s  r e s e a r c h  f o c u s e s  o n  t h e  d e t e c t i o n  of  t r ac e  e l e m e nt  and as t r obi ol ogi c al l y  r e l e v ant  or gani c  mo l e c u l e s  i n  p l a n e t a r y  s y s t e ms   l i k e  M a r s   He  i s  es p eci a l l y i n t er es t ed  i n  t h e d evel o p m en t  o f  T i m e of  and I on T r ap m as s  s pe c t r om e t e r s w i t h v a r i o u s i o n i z a t i o n  ng te c h n iq u e s   Wi l l  B r i n c k e r h o f f  sp a c e  sc i e n t i st  i n  t h e  Pl a n e t a r y  En v i r o n m e n t s  La b  a t  N A S A  s  G o d d a r d  Spac e  F l i ght  C e nt e r  i n Gr e e n b e l t   M D w i t h  pr i m ar y  r e s pons i bi l i t y  f or  th e  d e v e lo p m e n t o f th e  L D TO F  m a s s  s p e c t r o  th is  p r o je c t H e  h a s  fo c u s e d  re c e n t l y  o n  t h e  d e v e l o p m e n t  o f  m i n i a t u re  l a se r d ma s s  s p e c t r o me t e r s  f o r  f u t u r e  p l a n e t a r y  mi s s i o n s  a l o n g  wi t h  b a s i c  e x p e r i m e n t a l  r e s e a r c h  i n  a s t r o b i o l o g y  a n d  p r e bi ot i c  s y nt he s i s   D r   B r i nc k e r hof f  i s  i nv ol v e d i n t he  de v e l opm e nt  of  m as s  s pe c t r om e t e r  f or  bot h t he  2011 Ma r s  S c i e n c e  L a b o r a t o r y  a n d  t h e  2 0 1 8  E x o Ma r s  mi s s i o n s   


  14   


Copyright © 2009 Boeing. All rights reserved  Issues and Observations Initial load of one day of data ~ 7 hours Optimizations  Write data in batches  Use a mutable data structure to create data strings  Deploy a higher performance machine  Use load instead of insert  Use DB2 Range-Partitioned tables  Database tunings Time reduced from 7 hours to approx 30 minutes 


Copyright © 2009 Boeing. All rights reserved  Optimizations Use a mutable data structure to create data strings  Original application created the SQL statement by appending elements to a Java String  It was taking five hours \(of the seven hours Strings  Instead Java StringBuilder used  Java Strings immutable  Time savings of 71.4 


Copyright © 2009 Boeing. All rights reserved  Optimizations Deployed on a higher-performance machine  Application ported from IBM Blade Center HS21 \(4GB of RAM and 64-bit dual-core Xeon 5130 processor to Dell M4500 computer \(4GB of RAM and 64-bit of quad-core Intel Core i7 processor  Reduced the time to thirty minutes Bulk loading instead of insert  Application was modified to write CSV files for each table  Entire day worth of data bulk loaded  Reduced the time to fifteen minutes 


Copyright © 2009 Boeing. All rights reserved  Optimizations Range-Partitioned tables \(RPT  To limit the size of tables, the original code created multiple tables per table type  This puts burden on the application to query multiple tables when a range crosses several tables  With RPT, user is not required to make multiple queries when a range crosses a table boundary  Increased the time to thirty minutes  Additional fifteen minute cost per day of partitioning enabled time savings during queries 


Copyright © 2009 Boeing. All rights reserved  Optimizations Database tunings  Range periods changed from a week to a month  Automatic table space resizing changed from 32MB to 512KB  Buffer pool size decreased  Decreased the time to twenty minutes Overall, total time savings of 95.2 


Copyright © 2009 Boeing. All rights reserved  20 IBM Confidential Analytics Landscape Degree of Complexity Competitive Advantage Standard Reporting Ad hoc reporting Query/drill down Alerts Simulation Forecasting Predictive modeling Optimization What exactly is the problem What will happen next if What if these trends continue What could happen What actions are needed How many, how often, where What happened Stochastic Optimization Based on: Competing on Analytics, Davenport and Harris, 2007 Descriptive Prescriptive Predictive How can we achieve the best outcome How can we achieve the best outcome including the effects of variability Used with permission of IBM 


Copyright © 2009 Boeing. All rights reserved Initial Analysis Activities Flights departing or arriving on a date Flights departing or arriving within a date and time range Flights between city pair A,B Flights between a list of city pairs Flights passing through a volume on a date. \(sector, center, etc boundary Flights passing through a volume within a date and time range Flights passing through an airspace volume in n-minute intervals All x-type aircraft departing or arriving on a date Flights departing or arriving on a date between city pair A,B Flights departing or arriving on a date between a list of city pairs Flights passing through a named fix, airway, center, or sector Filed Flight plans for any of the above Actual departure, arrival times and actual track reports for any of the above 


Copyright © 2009 Boeing. All rights reserved  Initial SPSS Applications Show all tracks by call sign 


Copyright © 2009 Boeing. All rights reserved  Predictive / Prescriptive Analytics Use-Case For a given Airspace Volume of Interest \(AVOI compute distinct traffic volume at some point in the future  Aim to alert on congestion due to flow control areas or weather if certain thresholds are exceeded  Prescribe solution \(if certain thresholds are exceeded Propose alternate flight paths  Use pre-built predictive model  SPSS Modeler performs data processing Counts relevant records in the database \(pattern discovery Computes traffic volume using statistical models on descriptive pattern Returns prediction with likelihood 


Copyright © 2009 Boeing. All rights reserved  Predictive / Prescriptive Analytics Use-Case Advanced Arrival Procedures with Active Abatement Potentials   9/23/10  24 Pulls in the TRACKINFO table of MAIN using SQL Limits the data to database entries which fall inside the AVOI Combines the SOURCE_DATE and SOURCE_TIME to a timestamp that can be understood by modeler Computes which time interval the database entry falls in. The time interval is 15 minutes Defines the target and input fields needed for creating the model Handles the creation of the model Produces a graph based off of the model results Final prediction 


Copyright © 2009 Boeing. All rights reserved  Initial Cognos BI Applications IBM Cognos Report Studio  Web application for creating reports  Can be tailored by date range, aircraft id, departure/arrival airport etc  Reports are available with links to visuals IBM Framework Manager  Used to create the data package  Meta-data modeling tool  Users can define data sources, and relationships among them Models can be exported to a package for use with Report Studio 


Copyright © 2009 Boeing. All rights reserved  Flights Departing Las Vegas on Jan 1, 2012 1 of 3 Report shows the departure date, departure and arrival locations and hyperlinks to Google Map images DeparturePosition and ArrivalPosition are calculated data items formatted for use with Google Maps Map hyperlinks are also calculated based on the type of fix 


Copyright © 2009 Boeing. All rights reserved  Flights Departing Las Vegas on Jan 1, 2012 2 of 3 DeparturePosition, Departure Map, ArrivalPosition and Arrival Map are calculated data items \(see departure items below DepartureLatitude DepartureLongitude DeparturePosition Departure Map 


Copyright © 2009 Boeing. All rights reserved  Flights Departing Las Vegas on Jan 1, 2012 3 of 3 


Copyright © 2009 Boeing. All rights reserved  Conclusion and Next Steps Current archive is 50 billion records and growing  Approximately 34 million elements per day  1GB/day Sheer volume of raw surveillance data makes analytics process very difficult The raw data runs through a series of processes before it can be used for analytics Next Steps  Continue application of predictive and prescriptive analytics  Big data visualization 


Copyright © 2009 Boeing. All rights reserved  Questions and Comments Paul Comitz Boeing Research & Technology Chantilly, VA, 20151 office Paul.Comitz@boeing.com 


Copyright © 2009 Boeing. All rights reserved Advanced Arrival Procedures with Active Abatement Potentials   9/23/10  31 


Copyright © 2009 Boeing. All rights reserved Advanced Arrival Procedures with Active Abatement Potentials   9/23/10  32 Backup Slides 


Copyright © 2009 Boeing. All rights reserved  Initial Approach Initial Investigations  Apache Solr/Lucene  Data Warehouse Evaluate Hadoop in the future 


Copyright © 2009 Boeing. All rights reserved  Using SOLR Uncompress Track Information Messages To use with Solr  Transforming track messages from their  original schema to Solr required building a “key, value” list using an XSTL  Queries made against this list of “key, value” pairs Transformation Process  One day of data ~ 4.5 hours Once transformation complete search/query performance very good Geo spatial queries using  unique query language 


Copyright © 2009 Boeing. All rights reserved  Representation Aviation data is frequently represented in more than one form 


