Daniel O 037 noro Rubio Artem Lenskiy Jee-Hwan Ryu 
School of Electrical Electronics  Communication Engineering Korea University of Technology and Education Cheonan Korea daniel.onoro@gmail.com lensky@koreatech.ac.kr School of Mechanical Engineering Korea University of Technology and Education Cheonan Korea jhryu@koreatech.ac.kr 
Connected Components for a Fast and Robust 2D Lidar Data Segmentation 
The paper presents a novel segmentation ap 
Abstract 
proach applied to a two-dimensional point-cloud extracted by a LIDAR device The most common approaches perform well in outdoor environments where usually furniture and other objects are rather big and are composed of smooth surfaces However these methods fail to segment uneven rough surfaces In this paper we propose a novel range data segmentation algorithm that is based on the popular one-pass version of the Connected Components algorithm Our algorithm outperforms most commonly used approaches while keeping the low computational complexity The algorithm is used as a part of control and perception system in our unmanned ground 
vehicle where real-time response time is required We presented experimental results obtained indoors and outdoors The latter experiment was conducted in the real test eld while the vehicle was autonomously driven 
I I NTRODUCTION In the past decade or so the rapid growth of robotics and particularly increasing popularity of autonomous vehicles opened up new areas of applications of LIght Detecting And 
 
Keywords 2D Lidar Segmentation Connected Component Intelligent Vehicles Point-cloud analysis Unmanned Ground Vehicle 
Ranging LIDAR devices LIDAR is a remote sensing technology that allows measuring distances by emitting a laser beam and analyzing light reîected by the object LIDAR technology is known to be accurate and the measurements can be obtained at a high frequency These are the reasons why LIDAR technology is found to be useful in various robotics elds Nevertheless the eld of unmanned ground vehicles UGV that is a sub-ìeld of robotics brings its speciìc requirements to range data analysis These requirements include fast processing accurate and reliable performance In this paper we focus on the segmentation task LIDAR data segmentation is a necessary part in many tasks such as 
obstacle detection and object detection/recognition A number algorithms have been reported in the area of range data segmentation 2 3 Ho we v er  most of them focus on 3D data analysis Nevertheless some of the reported works employ 2D data segmentation for car detection and tracking The authors of implemented a general approach based on the idea that beams reîected from the same object have similar distances We investigated Figure 1 This image illustrates a single layer LIDAR In this image each point p 
is deìned by the distance to the device and an angle  this approach by calculating distances between consecutive points This approach generates artifacts that make this technique unacceptable in some UGV applications The contribution of this paper consists proposing a simple yet fast and accurate segmentation algorithm We also 
002 003 
i l i i 
      
overviewing the most common approaches for 2D data segmentation and compare them with the proposed algorithm The remainder of this paper is organized as follows Section II gives an introduction to the problem and discusses the most common approaches and their limitations Section III describes the proposed algorithm and its implementation Section IV presents the experimental results and comparison analysis In section V we give concluding remarks and brieîy describe future directions of our work II L ITERATURE O VERVIEW Before we proceed with the description of the proposed 
algorithm it is important to review the functional principles of the sensor and show some of the issues of commonly used segmentation approaches The LIDAR device consists of a laser and a mirror or a set or mirrors that are constantly rotating within the device The mirror reîects the laser beam and then the sensor measures how far photons have travelled round-trip The device returns an array of distances from the laser to the 
002 
i 
  
2013 7th Asia Modelling Symposium 978-0-7695-5101-2/13 $26.00 © 2013 IEEE DOI 10.1109/AMS.2013.31 160 
2013 7th Asia Modelling Symposium 978-0-7695-5101-2/13 $26.00 © 2013 IEEE DOI 10.1109/AMS.2013.31 160 
2013 7th Asia Modelling Symposium 978-0-7695-5101-2/13 $26.00 © 2013 IEEE DOI 10.1109/AMS.2013.31 160 
2013 7th Asia Modelling Symposium 978-0-7695-5101-2/13 $26.00 © 2013 IEEE DOI 10.1109/AMS.2013.31 160 


002 i l i l i l i i i l i i i th i i i C i C i C i C i C i C i i l C 
   1        1  1  1      1    1   2      1 
0 200 400 600 800 1000 1200 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 Lidar points   drho rho NN distance Next distance 
  002 002    002 002   
   
object that reîected the beam The array index corresponds to the angle of the mirror that varies in the range of  The range of angles is divide into intervals of  A general representation of one of these devices in shown in g 1 Due to the nature of these devices the absolute value of the differences of consecutive distances between a LIDAR point with a distance for an angle and the consecutive point with a distance for an angle should be close to 0 for all the points that lie on the same object If the absolute value of the difference of the distances between two consecutive laser points is less than some certain threshold  these two points are assigned to the same object Otherwise the point is associated with a new object We have implemented and experimented with the abovedescribed approach Figure 2 shows the differences of distances calculated for consecutive points The blue line represents the differences for the distances between two conductive points in polar coordinates i.e and  The back line shows the differences of the Euclidian distances from one point to next one  The points rst were converted from polar coordinate system to Cartesian coordinates The green line shows the differences of the Euclidian distances of one point to its nearest neighbor in the Cartesian plane Lastly the red line shows the values of each laser beam These values have been normalized in order to t them in the same graph Hence in this graph we can see a high response of the differences of the distances every time there is a gab between objects in red line As it can be seen from the gure 5a the segmentation based on comparing the differences in can fail to segment any object with an uneven surface For example this approach will fail to segment a fence made of bars The bars will reîect some of the beams while other beams will penetrate through the fence making each bar labeled separately as a different object The solution that could resolve this problem consists is applying clustering algorithms However to apply clustering algorithms we have to know the number of clusters in advance means clustering algorithm is an example of such algorithm In reality the number of cluster is not given Nevertheless there are clustering algorithms that do not require knowing the number of clusters in advance One of them is Fast-RNN Unfortunately  F ast-RNN has a complexity of  Moreover as it is seen in gure 6a Fast-RNN does not provide good clustering III P ROPOSED M ODEL One of the most essential algorithms in pattern recognition and image processing is the Connected Components CC algorithm The purpose of the CC algorithm is to transform the input binary image into a symbolic image Figure 2 This graph shows the responses of the differences of the distances to consecutive points The blue line represent the difference operator applied directly to the s values from the laser The green line shows the difference of the Euclidian distances from a point to its nearest neighbor The black line shows the difference of the Euclidian distances from the point to the point  Lastly the red line shows the values from the laser Figure 3 The left part of the gure shows an example of a binary image The right side shows a result of the labeling process using CC where each connected component will have a unique label see gure 3 We extend the CC algorithm from labeling binary images to segmentation of 2D LIDAR data by rstly preprocessing LIDAR data The data returned by LIDAR is represented as an array of 2D points The index of the array corresponds to the angle and the value is the distance to the object along the beam emitted in the direction of the angle  Before applying the CC algorithm the points should be converted to Cartesian coordinate system Then points are projected onto occupancy grid This grid is treated as a binary image and used for labeling The whole process is summarized as follows 1 Convert all the input points originally in polar coordinates to points in Cartesian coordinates 2 Discretize the obtained Cartesian values 
003 003 003 002 d p p p 002 003 p 002 003 003 003 d 002 002 002 p p p 002 002 002 K O n 002 p p p 002 k 003 003 p p 
161 
161 
161 
161 


                  
i c i i i T i x i y i i i C x y 
Algorithm 1 procedure while do repeat until end while return end procedure 
3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 
       2 0 0 1    2     0   0   2 2 2  2   2   2    2  2   2  1 
Polar Array Cartesian Point List Map Label Array 
m n p 002 cos 003 sin 003  m n m range max s  n range max s  s m n k x x s l  y y s d l  map unlabelDataList labelsV ector zeros length unlabelDataList currLabel length unlabelDataList  point unlabelData.f irst unlabelData.pop front point LabelList ADD point point Label point LabelList.f irst point LabelList.pop front nh getN eighbourhood point Label deactivateBins map point Label deactivateBins map nh point LabelList ADD nh labelsV ector labelP oint point Label length point LabelList currLabel currLabel labelsV ector x y x y p l l x y 
Figure 4 The diagram shows the segmentation ow of the range data obtained by the LIDAR contains the raw data obtained by the laser and is shown in red is a linked list that is a structure that holds all the unlabeled points in Cartesian coordinates is a occupancy grid which is used as an input data for connected component analysis Finally is an array which contains the labels of the input point-cloud 3 Project all the 2D points onto an occupancy grid 4 Find connected component over the grid 5 Return labels The following formula is used to convert the raw data represented in polar coordinates to a Cartesian coordinate system 1 The dimensions  and  of the grid are calculated as follows 2 3 Where is a scale factor that deìnes the size of each bin of the map Therefore we get a grid of bins Thus each bin can be thought as a portion of a real word with a constant size that can have or points of the scan By putting all together the grid is treated as a binary image where we can consider each bin as a pixel that can have two values or depending if it has points inside or not During the labeling process a bin can have one of two states activated and deactivated depending on whether that bin has been considered for labeling or not The process of lling up of the occupancy grid given by 4 5 Proposed Labeling Algorithm 1 CCL ABELING   2 Where and are the and of the point and and are the and coordinate where the LIDAR is placed on the map After we lled up the occupancy grid we are able to apply CC to the obtained grid There are several versions of the algorithm one pass tw o passes 8 There are serv er ways to decrease the computational by using complex data structures such as binary trees e.g Such algorithms are able to can reach a constant execution time regardless of the number of pixels However for our speciìc model we propose a new single pass version of this algorithm that 
002 002 003 003 003 003 003 003 003 
162 
162 
162 
162 


002 
0 0 0 0   
2 1 5 1  0  5 0 0  5 1 1 5 1 0 1 2 3 4 5 2 1 5 1  0  5 0 0  5 1 1 5 1 0 1 2 3 4 5 
distances and the proposed algorithm of this paper based on Connected Components algorithm In both images the laser is located in the position which is represented by a triangle As we can appreciate a presents some artifacts like dividing some object that should not be divided or by joining other that should be sparse In contrast we can see in b how our algorithm do not divide the object that are clearly just one object while it can separate in a better way those objects that are not connected position In the image a we can see how this algorithm has the problem that divides the long surfaces like in the right wall into different clusters while in b this the effect is not as pronounced can run with an complexity The pseudo-code of our Connected Components algorithm is give in 1 Due to the fact that we have a list of points we can bypass the grid scanning and directly jump into labeling Hence just taking the rst point of our list of points or just by choosing one randomly we can start to label By taking a bin that is activated and occupied we assign the current label to all of the points that fall into that bin Then we deactivate it and begin to expand the labeling process to the neighbor bins in a 4-connected or 8-connected version When there are no activated bins left to expand we will increase the label by choosing a point that has not being labeled yet then the previous process in repeated until all the points are labeled The above-descried algorithm runs in a linear time due to the fact that we know the locations of all the points in the grid from the beginning so we achieved on average a rate of 238 segmentations per second The gure 4 shows the data structures that we is used in the implementation In order to make it fast and efìcient in memory we are handling 4 data 
 3 2 1 0 1 2 3 0 1 2 3 4 5 6  3 2 1 0 1 2 3 0 1 2 3 4 5 6 
002   O n 
Implementation Details 
a This image show the result of a segmentation based on the most common approaches that rely on difference of  b This plot shows the results of the proposed algorithm Figure 5 This gure shows a comparison results between the approach based on the difference of the a This gure shows the results of a data segmentation done by the algorithm Fast-RNN b This graph shows the results of the algorithm proposed in this paper Figure 6 This gure shows a comparison between the clustering algorithm Fast-RNN and our method In both images the laser is represented by a triangle which is located in the 
163 
163 
163 
163 


l C C C l C l 
 30 2 0 1 0 0 1 0 2 0 30 4 0 50 5 0 5 10 15 20 25 30 35 40  60  50 4 0  30 2 0 1 0 0 1 0 2 0 5 0 5 10 15 20 25 30 35 40 
a Obstacle avoidance b Car detection c Pedestrian detection d Obstacle avoidance e Car detection f Pedestrian detection Figure 7 This image shows the results of the proposed algorithm in a real application for an autonomous vehicle The rst row shows the contextual information which is provided by a conventional camera while the second row shows the segmentation results In each graph of the second row each group is represented by a color The position of the lidar device is always placed at 
A Indoors experiments B Outdoor Experiments 
 
0 0 
position and it is represented by a triangle structures at once The rst data structure is the raw input data from the LIDAR represented by red the red color This array contains all the points from the LIDAR sorted from to  This gives us a rigid data structure that will deìne the size of the output The second data structure is a list that contains all the points This structure is just a linked list that points into the occupancy grid Each bin in the grid is a data structure that points to the elements  plus can hold two states activated or deactivated These two states allow us to avoid the labeling the points that has been already labeled Therefore the relationship between and the map is bidirectional In contrast the relationship between and is in one direction as is not modiìed or accessed again IV E XPERIMENTS This section devoted to experimental analysis of the proposed algorithm We analyze the quality of the proposed algorithm by comparing segmentation results with the above-described algorithms The labeling obtained for the data extracted indoors and outdoors In both experimental setups we used a Sick lms511 pro device that provides a maximum of 1141 points for a single scan and runs at 25Hz The algorithm was running on the Intel Core i7-3820 CPU at 3.60GHz The LIDAR device was placed on a table of our lab see image 8 facing various obejcts The scale factor that we used in order to build up the occupancy grid is 10cm The segmentation performance for indoors environment is shown in the gure 5b The point-cloud that is used for labeling is exactly the same as the one shown in the gure 5a It is visually easy to see that our algorithm based on CC has a better capability to properly segment the data into different object that segments that belongs to different objects On the other hand the other method does not separate well some clearly deìned object Comparing the segmentation results obtained by the proposed algorithm gure 6b against the results produced by Fast-RNN algorithm gure 6a it is easy to see how our algorithm preserves the same label even for long and thin objects simultaneously well separating objects that are not connected The purpose of developing our algorithm was to create a method that provides robust and fast laser data segmentation for an autonomous vehicle perception system Therefore in 
 p 003 003 p p p p p p s 
2 5 2 0 1 5 1 0  5 0 5 1 0 1 5 10 0 10 20 30 40 50 60 
164 
164 
164 
164 


a View from lidar b Laboratory hardware setup Figure 8 This two images are shown for a better understanding of the scans of our lab Figure 9 This graph shows a numerical comparison between the algorithm based on the 
ArXiv e-prints Urban Remote Sensing Event 2009 Joint Intelligent Vehicles Symposium IV 2011 IEEE Intelligent Vehicles Symposium 2009 IEEE Signal Processing Real Time/Parallel Computing Image Analysis Proceedings of the 6th International Conference on Image Analysis and Recognition Trans IEICE J72-D-II J ACM 
002 s 
Lab1 Lab2 Car1 Car2 Car3 Car1 
 Sep 2012  W  Y ao S Hinz and U Stilla Object e xtraction based on 3d-segmentation of lidar data by combining mean shift with normalized cuts Two examples from urban areas in  2009 pp 1Ö6  J Aue D Langer  B Muller Bessler  and B Huhnk e Efìcient segmentation of 3d lidar point clouds handling partial occlusion in  2011 pp 423Ö428  M Thuy and F  Leon Non-linear  shape independent object tracking based on 2d lidar data in  2009 pp 532Ö537  R J Lopez-Sastre D Onoro-Rubio P  Gil-Jimenez and S Maldonado-Bascon Fast reciprocal nearest neighbors clustering  pp 270Ö275 2012  R Haralick Some neighborhood operations  p.11 030 201335 1981  L He Y  Chao K Suzuki and H Itoh  A run-based one-scan labeling algorithm in  ser ICIAR 09 Berlin Heidelberg Springer-Verlag 2009 pp 93Ö102  T  G Y  O M Y  Y  Shirai High speed algorithm for component labeling p.247 030 2013255 1989  Y  Han and R A W agner   An ef cient and f ast parallel-connected component algorithm  vol 37 no 3 pp 626Ö642 Jul 1990 A v ailable http://doi.acm.org/10.1145/79147.214077 
differences Diff Fast-RNN and the proposed method CC with respect a handmade ground truth The rst column   corresponds with the scan displayed on 5 the second one   corresponds with 6 and nally the third fourth and fth   and  corresponds to 7 d e and f respectively this subsection we show some of the results obtained in the real outdoors environment We attached the LIDAR to the front bumper of our vehicle placed in the middle of the bumper at 50cm above the ground To provide contextual information for this experiment we synchronized LIDAR with a camera located inside of the vehicle The scale factor was xed to 30cm The gure 7 shows segmentation of the laser data into a number clusters It can be see that most of the objects are correctly labeled The segmentation time of one-scan takes on average about 0.0042 seconds which is about 238 segmentations per second Finally in order to show some numerical results gure 9 on the performance of our algorithm we measured the segmentation accuracy of each discussed algorithm by comparing them to hand-segmented maps Our algorithm outperformed other algorithms in most of the tests except  The reason why our algorithm underperformed is a large amount of noise on the right side of the scan that is labeled as many independent objects V C ONCLUSION In this paper we have presented a 2D point-cloud segmentation algorithm We showed that algorithm outperforms the common 2D point-cloud segmentation approaches We have compared the quality of segmentation and the computational time of our algorithm and the other segmentation approaches based on the range data obtained indoors and outdoors Discretizing the space mapping the point-cloud onto a grid and then applying an efìcient data structure that is used in Connected Components analysis achieves such good performance We are planning to extend the proposed algorithm by creating a non-equal cell sized grid The cell size should depend on the distance to the points The points located closer to the sensor are more densely distributed Moreover there is more uncertainty for the points located farther away from the sensor The larger cell size will take into account such uncertainty R EFERENCES  Y  Ioannou B T aati R Harrap and M Greenspan Dif ference of normals as a multi-scale operator in unorganized point clouds 
165 
165 
165 
165 


978-1-4673-1813-6/13/$31.00 \2512013 IEEE  7 From an edification position, the project participants gain 223real-world\224 understanding of responding to the needs of future employers. From a programmatic position, the lack of payload utilization introduces lack of mission relevance R EFERENCES   1  J  C h o n  H  K i m   C  S  L i n  S e a m l i n e  determination for image mosaicing: A technique minimizing the maximum local mismatch and the global cost. ISPRS Journal of Photogrammetry and Remote Sensing, Volume 65, Issue 1, January 2010, Pages 86-92  2 G  E r us N i c o l a s Lo m\351 ni e  H o w t o i nvo l ve  structural modeling for cartographic object recognition tasks in high-resolution satellite images? Pattern Recognition Letters, Volume 31 Issue 10, 15 July 2010, Pages 1109-1119  3  Y  L i n g  M  E h l e r s  E  L  U s e r y  M  M a d d e n  F F T enhanced IHS transform method for fusing highresolution satellite images. ISPRS Journal of Photogrammetry and Remote Sensing, Volume 61 Issue 6, February 2007, Pages 381-392  4 A  Ad d a i m   A K h e r r a s  E  B  Za n t o u  D S P  implementation of integrated store-and-forward APRS payload and OBDH subsystems for low-cost small satellite. Aerospace Science and Technology Volume 12, Issue 4, June 2008, Pages 308-317 5  Matth e w B r o w n a n d Da v i d  G. L o w e Au to m at i c Panoramic Image Stitching using Invariant Features.  International Journal of Computer Vision. Volume 74, Number 1 \(2007\59-73    D. T u rn er A Lu cieer C  W a ts on 20 12 A n  Automated Technique for Generating Georectified Mosaics from Ultra-High Resolution Unmanned Aerial Vehicle \(UAV\magery, Based on Structure from Motion \(SfM\oint Clouds Remote Sensing  4 5\2-1410  7 L Q i n g yua n L W e n y a n g Z Le i  W  J i nl i ng a n d  L. You. "A New Approach To Fast Mosaic UAV Images International Archives of the Photogrammetry, Remote Sensing and Spatial Information Sciences Vol. XXXCIII-1/C22     A   Z o m e t    S  Pel e g  1998, O c t ober A ppl y i ng  super-resolution to panoramic mosaics. In Applications of Computer Vision, 1998. WACV'98 Proceedings., Fourth IEEE Workshop on pp. 286287    J. S t ra u b  223 M odel Ba s e d Da t a  T ran sm i s s i o n   Analysis of Link Budget Requirement Reduction\224 Communications and Network 2012   S  C  Par k M.K  Par k   M. G  K a ng 2003 Super-resolution image reconstruction: a technical overview Signal processing Magazine, IEEE, 20 3 21-36 1  C a m b ri d g ei n c ol o u r  co m   N  d  Digital Image Interpolation Onlin A v a ila ble http://www.cambridgeincolour.com/tutorials/imageinterpolation.htm   M. Br y s o n  A R e id F Ra m o s    S. S u l l arie h  2010\Airborne vision-based mapping and classification of large farmland environments Journal Of Field Robotics 27\(5\655     O rbi t a l   223S ci ence, E n vi ronm e n t a l a n d T e c h n o l ogy  Satellites \226 Reliable Spacecraft Enabling Affordable Missions\224 \(2012 Corporate brochure  Biographies Abhilasha Bhatia  is a graduate student in the Department of Computer Science at the University of North Dakota. She is a committee member of Student Association of India and also actively involved with Women in Science group at UND. She holds a Bachelor of Technology degree in Computer Science from Gautam Buddh Technical University, India   Kyle Goehner  is an undergraduate student pursuing a BS in Computer Science with a minor in Mathematics at the University of North Dakota  While at UND, Kyle has received numerous honors including the competitive Odegard Scholarship \(2011\, the Microsoft Scholarship 2011\, the Fetter Scholarship \(2010\ and the UND Community of Learners Scholarship \(2009-2013\.  Kyle\222s team placed in the top 10 at the Midwest Instruction and Computing Symposium Programming Competition.  He is active in the Association for Computing Machinery \(ACM serving as the chapter president from 2011 to 2013   John Sand  is an undergraduate student in the Department of Computer Science at the University of North Dakota   Jeremy Straub is a PhD student in the Department of Computer Science at the University of North Dakota.  He currently serves as the Student Program Director for the North Dakota Space Robotics Program.  His research is presently focused on artificial intelligence for space applications.  Before returning to pursue doctoral studies Mr. Straub held progressively responsible positions in industry.  He has over 10 years professional experience in developing and managing the development of cutting-edge commercial systems, including North America\222s first commercial traffic-adaptive nav igation system.  Jeremy holds a BS in Information Technology, a BS in Business, a graduate certificate in Space Studi es, an MBA and an MS in Computer Systems and Software Design.  He is a member of the AIAA, IEEE, SPIE and SSPI 


978-1-4673-1813-6/13/$31.00 \2512013 IEEE  8 Atif Farid Mohammad is an MIT certified Systems Architect and currently a PhD student in the Computer Science department at the University of North Dakota working on Cloud Computing Security. Atif has more than sixteen years of experience in software engineering professional business systems analysis, design, application development and staff management for diversified business and educational organizations. He is a member of IEEE ACM and AST Christoffer Korvald is a MS student in the Department of Computer Science at the University of North Dakota Christoffer is the President of the local chapter of the Upsilon Pi Epsilon Honor Society. He is currently the president of the Association of Norwegian Students Abroad USA, which has over 1500 members. Christoffer holds a BA in Computer Science with a Software Engineering specialization from the University of North Dakota. He is also the Associate Director of Software for the Open Orbiter Satellite Initiative  Anders Kose Nervold is an undergraduate student at the University of North Dakota pursuing a BA in Entrepreneurship with a minor in Space Studies. Anders is currently serving as the Associate Director for Communications, Outreach and Policy for the Open Orbiter Satellite Initiative. While at UND, Anders worked as a console operator for the International Space Station Agricultural Camera \(ISSAC\.  In 2012, Anders and his business partner claimed the 1 st prize in the GIANTS international business plan competition for their planned service venture in the aerospace industry.  Anders is currently serving as the treasurer for the nationwide student organization, the Association of Norwegian Students Abroad \226 USA, which has over 1300 members.  He has also served as the local president for the Association of Norwegian Students Abroad and as the treasurer for the Interfraternity Council.  He was awarded the competitive Mueller Scholarship in 2012 and the Lillian Elsinga Outstanding Student Leader Award in 2011.  Anders is also a member of the Dakota Space Society and mentors other international students at UND    


Jorda Polo, David Carrera, Yolanda Becerra, Malgorzata Steinder  and Ian Whalley. Performance-driven task co-scheduling for  mapreduce environments. In Network Operations and Management  Symposium \(NOMS\2010 IEEE, pages 373 Ö380, 19-23 2010 12 K. Kc and K. Anyanwu, çScheduling hadoop jobs to meet deadlines  in 2nd IEEE International Conference on Cloud Computing  Technology and Science \(CloudCom\, 2010, pp. 388 Ö392 13 Xicheng Dong, Ying Wang, Huaming Liao çScheduling Mixed Real time and Non-real-time Applications in MapReduce Environment  In the proceeding of 17th International Conference on Parallel and  Distributed Systems. 2011, pp. 9 Ö 16 14 Xuan Lin, Ying Lu, J. Deogun, and S. Goddard. Real-time divisible  load scheduling for cluster computing. In Real Time and Embedded  Technology and Applications Symposium, 2007. RTAS ê07. 13th  IEEE pages 303 Ö314, 3-6 2007 15 HDFS  http://hadoop.apache.org/common/docs/current/hdfsdesign.html  16 Chen He, Ying Lu, David Swanson. çMatchmaking : A New  MapReduce Scheduling Techniqueé. In the proceeding of 2011  CloudCom, Athens, Greece, 2011, pp. 40 Ö 47 17 Matei Zaharia, Dhruba Borthakur, Joydeep Sen Sarma and Khaled  Elmeleegy, Scott Shenker, and Ion Stoica, çDelay scheduling: a  simple technique for achieving locality and fairness in cluster  schedulingé. In the proceedings of the 5th European conference on  Computer systems, 2010.  pp 265-278 18 Zhuo Tang, Junqing Zhou, Kenli Li, and Ruixuan Li "A MapReduce  task scheduling algorithm for deadline constraints.", Cluster  Computing, Vol. 15,  2012 19 Eunji Hwang, and Kyong Hoon Kim. "Minimizing Cost of Virtual  Machines for Deadline-Constrained MapReduce Applications in the  Cloud." Grid Computing \(GRID\, 2012 ACM/IEEE 13th  International Conference on. IEEE, 2012 20 Micheal Mattess, Rodrigo N. Calheiros, and Rajkumar Buyya  Scaling MapReduce Applications across Hybrid Clouds to Meet Soft  Deadlines." Technical Report CLOUDS-TR-2012-5, Cloud  Computing and Distributed Systems Laboratory, the University of  Melbourne, August 15, 2012 21 
 
11 
                
Chen He, Ying Lu, David Swanson. çReal-Time Application Scheduling in Heterogeneous MapReduce Environments Technical Report TR-UNL-CSE2012-0004, University  of Nebraska-Lincoln, 2012 Available: http://cse apps.unl.edu/facdb/publications/TR-UNL-CSE20120004.pdf 22 T. Condie, N. Conway, P. Alvaro, J. M. Hellerstein, K  Elmleegy, and R. Sears. çMapreduce Onlineé. In NSDI 2010 23 A. D. Ferguson, P. BodÌk, S. Kandula, E. Boutin, and R  Fonseca. çJockey: Guaranteed Job Latency in Data Parallel Clusters. In EuroSys, 2012 24 G. Wang, A. R. Butt, P. Pandey, and K. Gupta. çA Simulation Approach to Evaluating Design Decisions in MapReduce Setupsé. In MASCOTS 2009 25 H. Herodotou and S. Babu. Profiling, çWhat-if Analysis and Cost-based Optimization of MapReduce Programs In VLDB 2011 26 H. Herodotou, F. Dong, and S. Babu. çNo One \(Cluster Size Fits All: Automatic Cluster Sizing for Dataintensive Analyticsé. In SoCC 2011  
1544 
1544 


Figure 15  3D model of the patio test site Figure 16  Model of the patio test site combining 2D map data with 3D model data a Largest explored area b Smallest explored area Figure 14  Maps built by a pair of 2D mapping robots Yellow indicates area seen by both robots Magenta indicates area seen by one robot and Cyan represents area seen by the other a 3D point cloud built of the patio environment Figure 16 shows a model built combining 2D map data with 3D model data A four-robot mission scenario experiment was conducted at the mock-cave test site This included two 2D mapping robots a 3D modeling robot and a science sampling robot There was no time limit on the run Figure 17 shows a 3D model of the tunnel at the mock cave Figure 18 shows a model built combining 2D map data with 3D model data 7 C ONCLUSIONS  F UTURE W ORK The multi-robot coordination framework presented in this paper has been demonstrated to work for planetary cave mission scenarios where robots must explore model and take science samples Toward that end two coordination strategies have been implemented centralized and distributed Further a core communication framework has been outlined to enable a distributed heterogenous team of robots to actively communicate with each other and the base station and provide an online map of the explored region An operator interface has been designed to give the scientist enhanced situational awareness collating and merging information from all the different robots Finally techniques have been developed for post processing data to build 2  3-D models of the world that give a more accurate description of the explored space Fifteen 2D mapping runs with 2 robots were conducted The average coverage over all runs was 67 of total explorable area Maps from multiple robots have been merged and combined with 3D models for two test sites Despite these encouraging results several aspects have been identi\002ed that can be enhanced Given the short mission durations and small team of robots in the experiments conducted a simple path-to-goal costing metric was suf\002cient To use this system for more complex exploration and sampling missions there is a need for learning-based costing metrics Additional costing parameters have already been identi\002ed and analyzed for future implementation over the course of this study One of the allocation mechanisms in this study was a distributed system however task generation remained centralized through the operator interface In an ideal system robots would have the capability to generate and auction tasks based on interesting features they encounter Lastly the N P complete scheduling problem was approximated during task generation However better results could potentially 10 


Figure 17  3D model of the tunnel in the mock cave test site Figure 18  Model of the mock cave test site combining 2D map data with 3D model data be obtained by releasing this responsibility to the individual robots A CKNOWLEDGMENTS The authors thank the NASA STTR program for funding this project They would also like to thank Paul Scerri and the rCommerceLab at Carnegie Mellon University for lending hardware and robots for this research R EFERENCES  J C W erk er  S M W elch S L Thompson B Sprungman V Hildreth-Werker and R D Frederick 223Extraterrestrial caves Science habitat and resources a niac phase i study\\224 NASA Innovative Advanced Concepts NIAC Tech Rep 2003  G Cushing T  T itus and E Maclennan 223Orbital obser vations of Martian cave-entrance candidates,\224 in First Intl Planetary Caves Workshop  Carlsbad NM 2011  J W  Ashle y  M S Robinson B R Ha wk e A K Boyd R V Wagner E J Speyerer H Hiesinger and C H van der Bogert 223Lunar caves in mare deposits imaged by the LROC narrow angle camera,\224 in First Intl Planetary Caves Workshop  Carlsbad NM 2011  J W  Ashle y  A K Bo yd H Hiesinger  M S Robinson T Tran C H van der Bogert and LROC Science Team 223Lunar pits Sublunarean voids and the nature of mare emplacement,\224 in LPSC  The Woodlands,TX 2011  S Dubo wsk y  K Iagnemma and P  J Boston 223Microbots for large-scale planetary surface and subsurface exploration niac phase i.\224 NASA Innovative Advanced Concepts NIAC Tech Rep 2006  S Dubo wsk y  J Plante and P  Boston 223Lo w cost micro exploration robots for search and rescue in rough terrain,\224 in IEEE International Workshop on Safety Security and Rescue Robotics Gaithersburg MD  2006  S B K esner  223Mobility feasibility study of fuel cell powered hopping robots for space exploration,\224 Master's thesis Massachusetts Institute of Technology 2007  M T ambe D Pynadath and N Chauv at 223Building dynamic agent organizations in cyberspace,\224 IEEE Internet Computing  vol 4 no 2 pp 65\22673 March 2000  W  Sheng Q Y ang J T an and N Xi 223Distrib uted multi-robot coordination in area exploration,\224 Robot Auton Syst  vol 54 no 12 pp 945\226955 Dec 2006  A v ailable http://dx.doi.or g/10.1016/j.robot 2006.06.003  B Bro wning J Bruce M Bo wling and M M V eloso 223Stp Skills tactics and plays for multi-robot control in adversarial environments,\224 IEEE Journal of Control and Systems Engineering  2004  B P  Gerk e y and M J Mataric 223 A formal analysis and taxonomy of task allocation in multi-robot systems,\224 The International Journal of Robotics Research  vol 23 no 9 pp 939\226954 September 2004  M K oes I Nourbakhsh and K Sycara 223Heterogeneous multirobot coordination with spatial and temporal constraints,\224 in Proceedings of the Twentieth National Conference on Arti\002cial Intelligence AAAI  AAAI Press June 2005 pp 1292\2261297  M K oes K Sycara and I Nourbakhsh 223 A constraint optimization framework for fractured robot teams,\224 in AAMAS 06 Proceedings of the 002fth international joint conference on Autonomous agents and multiagent sys11 


tems  New York NY USA ACM 2006 pp 491\226493  M B Dias B Ghanem and A Stentz 223Impro ving cost estimation in market-based coordination of a distributed sensing task.\224 in IROS  IEEE 2005 pp 3972\2263977  M B Dias B Bro wning M M V eloso and A Stentz 223Dynamic heterogeneous robot teams engaged in adversarial tasks,\224 Tech Rep CMU-RI-TR-05-14 2005 technical report CMU-RI-05-14  S Thrun W  Bur g ard and D F ox Probabilistic Robotics Intelligent Robotics and Autonomous Agents  The MIT Press 2005 ch 9 pp 222\226236  H Mora v ec and A E Elfes 223High resolution maps from wide angle sonar,\224 in Proceedings of the 1985 IEEE International Conference on Robotics and Automation  March 1985  M Yguel O A ycard and C Laugier  223Update polic y of dense maps Ef\002cient algorithms and sparse representation,\224 in Intl Conf on Field and Service Robotics  2007  J.-P  Laumond 223T rajectories for mobile robots with kinematic and environment constraints.\224 in Proceedings International Conference on Intelligent Autonomous Systems  1986 pp 346\226354  T  Kanungo D Mount N Netan yahu C Piatk o R Silverman and A Wu 223An ef\002cient k-means clustering algorithm analysis and implementation,\224 IEEE Transactions on Pattern Analysis and Machine Intelligence  vol 24 2002  D J Rosenkrantz R E Stearns and P  M Le wis 223 An analysis of several heuristics for the traveling salesman problem,\224 SIAM Journal on Computing  Sept 1977  P  Scerri A F arinelli S Okamoto and M T ambe 223T oken approach for role allocation in extreme teams analysis and experimental evaluation,\224 in Enabling Technologies Infrastructure for Collaborative Enterprises  2004  M B Dias D Goldber g and A T  Stentz 223Mark etbased multirobot coordination for complex space applications,\224 in The 7th International Symposium on Arti\002cial Intelligence Robotics and Automation in Space  May 2003  G Grisetti C Stachniss and W  Bur g ard 223Impro ving grid-based slam with rao-blackwellized particle 002lters by adaptive proposals and selective resampling,\224 in Proceedings of the IEEE International Conference on Robotics and Automation  2005  227\227 223Impro v ed techniques for grid mapping with raoblackwellized particle 002lters,\224 IEEE Transactions on Robotics  2006  A Geiger  P  Lenz and R Urtasun 223 Are we ready for autonomous driving the kitti vision benchmark suite,\224 in Computer Vision and Pattern Recognition CVPR  Providence USA June 2012  A N 250 uchter H Surmann K Lingemann J Hertzberg and S Thrun 2236d slam with an application to autonomous mine mapping,\224 in Proceedings of the IEEE International Conference on Robotics and Automation  2004 pp 1998\2262003  D Simon M Hebert and T  Kanade 223Real-time 3-d pose estimation using a high-speed range sensor,\224 in Proceedings of the IEEE International Conference on Robotics and Automation  1994 pp 2235\2262241 B IOGRAPHY  Ammar Husain received his B.S in Mechanical Engineering Robotics from the University of Illinois at Urbana-Champaign He is pursuing an M.S in Robotic Systems Development at Carnegie Mellon University He has previously worked on the guidance and control of autonomous aerial vehicles His research interests lie in the 002eld of perception-based planning Heather Jones received her B.S in Engineering and B.A in Computer Science from Swarthmore College in 2006 She analyzed operations for the Canadian robotic arm on the International Space Station while working at the NASA Johnson Space Center She is pursuing a PhD in Robotics at Carnegie Mellon University where she researches reconnaissance exploration and modeling of planetary caves Balajee Kannan received a B.E in Computer Science from the University of Madras and a B.E in Computer Engineering from the Sathyabama Institute of Science and technology He earned his PhD from the University of TennesseeKnoxville He served as a Project Scientist at Carnegie Mellon University and is currently working at GE as a Senior Cyber Physical Systems Architect Uland Wong received a B.S and M.S in Electrical and Computer Engineering and an M.S and PhD in Robotics all from Carnegie Mellon University He currently works at Carnegie Mellon as a Project Scientist His research lies at the intersection of physics-based vision and 002eld robotics Tiago Pimentel Tiago Pimentel is pursuing a B.E in Mechatronics at Universidade de Braslia Brazil As a summer scholar at Carnegie Mellon Universitys Robotics Institute he researched on multi-robots exploration His research interests lie in decision making and mobile robots Sarah Tang is currently a senior pursuing a B.S degree in Mechanical and Aerospace Engineering at Princeton University As a summer scholar at Carnegie Mellon University's Robotics Institute she researched multi-robot coordination Her research interests are in control and coordination for robot teams 12 


Shreyansh Daftry is pursuing a B.E in Electronics and Communication from Manipal Institute of Technology India As a summer scholar at Robotics Institute Carnegie Mellon University he researched on sensor fusion and 3D modeling of sub-surface planetary caves His research interests lie at the intersection of Field Robotics and Computer Vision Steven Huber received a B.S in Mechanical Engineering and an M.S in Robotics from Carnegie Mellon University He is curently Director of Structures and Mechanisms and Director of Business Development at Astrobotic Technology where he leads several NASA contracts William 223Red\224 L Whittaker received his B.S from Princeton University and his M.S and PhD from Carnegie Mellon University He is a University Professor and Director of the Field Robotics Center at Carnegie Mellon Red is a member of the National Academy of Engineering and a Fellow of the American Association for Arti\002cial Intelligence 13 


