Robot: An Efficient Model For Big Data Stor age Systems Based On Erasure Coding Chao Yin 1 Jianzong Wang 3 Changsheng Xie 12 Jiguang Wan 12  Changlin Long 1 and Wenjuan Bi 1  1 School of Computer Science and Technology, Huazhong University of Science and Technology, China 2 Wuhan National Laboratory for Optoelectronics, China 3  NetEase Inc., Guangzhou, China  Corresponding Author: jgwan@mail.hust.edu.cn   Abstract it is well-known that with the explosive growth of data, the age of big data has arrived. How to save huge amounts of data is of great importance to both industry and academia. This paper puts forward a solution based on coding technologies in big data system that store a lot of cold data. By studying existing coding technologies and big data systems, we can not only maintain the system's reliability, but also improve the security and the utilization of storage systems. Due to the remarkable reliability and space saving rate of coding technologies, importing coding schema in to big data systems becomes prerequisite. In our presented schema, the storage node is divided into several virtual nodes to keep load balancing. By setting up different virtual node storage groups for different codec server, we can ensure system availability And by utilizing the parallel decoding computing of the node and the block of data, we can also reduce the system recovery time when data is corrupted Additionally, different users set different coding parameters can improve the robustness of big data storage systems. We configure various data block m and calibration block k to improve the utilization rate in the quantitative experiments The results shows that parallel decoding speed can rise up two times than the past serial decoding speed. The encoding efficiency with ICRS coding is 34.2% higher than using CRS and 56.5% more than using RS coding equally. The decoding rate by using ICRS is 18.1% higher than using CRS and 31.1 higher than using RS averagely  Keywords-distributed file system; erasure coding; big data robustness; availiabilty; cloud storage I   I NTRODUCTION  Along with the development and popularity of internet technologies, information is playing a significant role in a symbol of digital data. In the perspective of enterprises, loss of data could even be destructive; therefore the demand for dependability of data storage system rises up. With the rapid growing number of data, the storage scale has reached TB PB, even ZB level, shown as tremendous development. Jim Gray [1  a Tu r i n g aw ard w i nn er  di cta tes th at th e n e w dat a  amount from the Internet is expected to quadruple in every 18 months compared with all the old data existed. Thereby traditional information storage scheme, which keeps the data in a centralized server, is no longer a satisfying solution to current demand for big data storage. Moreover, local storage technology will encounter resistance when the extension Some factors, such as costs, techniques and communication let data storage to be the main bottleneck to prevent the development  of information technologies In such situation, distributing data for storage and extending from local to remote, for instance cloud storage has been an inevitable tendency. Distributed storage takes outstanding advantage of both storage and transmission technologies, presenting unparalleled superiority in data security, storage volume, disaster backup and recovery For the storage of big data [8, 9, and 10  pr o b lem s  th a t  remain to be solved are as follow   Capacity Capacity can reach the scale of PB/ZB level. As a result, mass data storage systems should have ability for scaling. Meanwhile, the online expansion method must be convenient enough and decrease the degradation serving time   Delay: Big data applications should be real-time especially involved with online trading or financial related applications. Date-intensive computing has the SLA \(Service Level Agreement\quirements. In addition, the popularity of server virtualization has led to a stringent demand for the high IOPS   Security and Privacy: Access control for big data is also a hot topic for research. Big data applications lead to concern about security, especially for private data of company or individual    Cost: To save the cost, we need to make every device work more efficiently and avoid overprovision. Due to the widely implementation of coding, data de-duplication and cloud storage technologies in storage field, big data storage applications can be more effective and valuable  This paper is focus on the big data backup systems Currently erasure coding and deduplication technologies are used in big data storage frequently. Well known cloud storage systems like GFS [2   HDFS 3   A m azon S 3   4  an d  Ceph [5  a l l u s e r e p l i c at io n to p r o v id e d a ta  re d u n d a n c y  Comparing the two redundancy technologies, Erasure code is more suitable for big data backup system since it requires less storage for maintaining reliability. We have developed an optimized erasure coding algorithm, called ICRS Improved CRS\ to store the backup data. The algorithm is improved based on original CRS [6 an d R e e d S ol om on  7   algorithms. By optimizing the determinant of a matrix, the number of identity element “1” in CRS matrix is decreased dramatically. The performance of the system is also improved by increasing the speed of matrix operations The underlying architecture of our system used decentralized storage systems because of its target 2013 IEEE International Conference on Big Data 978-1-4799-1293-3/13/$31.00 ©2013 IEEE 163 


requirements. First of all Robot is targeted mainly at backup applications where there are no updates frequently. Secondly Robot is built for latency sensitive applications that require at least 99.9% of read and write operations to be performed quickly. Different from Pastry [25 S c a lity Rin g 2 6 an d  Chord [1 h ic h ro ute re que sts th r o ugh m u ltip l e n o de s   Robot can be characterized as a zero-hop DHT, where each node maintains enough routing information locally to route a request to the appropriate node directly. This is because multi-hop routing increases variability in response times thereby increasing the latency at higher percentiles We have used consistent hash algorithm to store data in distributed system. In comparison to these systems, a keyvalue store is more suitable in this case. First, it is intended to store relatively small objects \(size < 1M  Second, keyvalue stores are easier to configure on a per-application basis The adoption of Hash not only improves the efficiency of looking up, but also guarantees that node addressing will not conflict In the current era of big data, the storage of data backup should make sure reliability and minimize storage overhead Our aim is to reduce storage consumption and improve the system performance The main contributions of ours paper are listed as below   Research and design ring system architecture, an extension of symmetry, which should favor decentralized techniques over centralized control We imported Peer to Peer systems into big data system so that the system will not crash because of one or more nodes’ damage   Store data in the mechanism including virtual nodes and physical nodes. We built corresponding relationship between them to ensure that data can be stored after coding and fast recovery when data is lost   Presented a coding scheme -ICRS \(Improved CRS which is based on CRS that can reduce the encoding and system down time. The testing result shows that the coding efficiency when using ICRS is 34.2 higher on average than using CRS and 56.5% higher on average than using RS. The decoding efficiency when using ICRS is 18.1% higher on average than using CRS and 31.1% higher on average than using RS The rest of this paper is organized as follows. The architecture and the design of Robot are introduced in Section 2. Section 3 gives the experimental evaluation and results. Section 4 shows related works. We make conclusions in Section 5 II  R OBOT  A  The Design of Robot Most existing systems use triple replication methods to provide reliability. But cold data are barely used by users, so the utilization of space is very slow. Considering the feature of cold data, system can use code methods to provide reliability to optimize the storage usage Coding is one of the key features in distributed system The common distributed system can provide high reliability but the storage space usage is overwhelming waste with much money investment. We are aim to import code methods by replacing duplication schema and two indexes are our optimizing targets in our system Storage Space Utilization and Repair Time    Figure 1  The architecture of Robot Figure 1 show the architecture of Robot, which consists of two components: coding servers and data servers. Coding servers is responsible for choosing suitable storage group encode or decode data and store important information such as metadata. Date servers are composed by virtual nodes which are located in the ring structure. These virtual nodes store original data. The ring structure guarantees loading balance and randomly distributed on each virtual node. The communication on data servers rely on the message exchange between virtual nodes instead of unique metadata The import of ring structure can be advanced compared with the traditional duplication situation and address the cold data storage problems in the big data environment in order to save the space. Due to the low read frequency, the demand of response time is lower than regular system. So we deploy erasure code method to provide reliability and optimize storage usage. Furthermore, by dividing physical nodes into virtual nodes, keep the system load balancing and prove repair speed up by utilizing parallel computing. After receiving the request of users, system will select a virtual node to build coding server based on the storage demand of users, every virtual node use its own storage group. All data of the coding servers will store in this storage group. The data on the coding servers will be first encoded and then store on data servers. When the physical node fails, system will read data from several storage groups concurrently to repair it. So our design can provide better performance on both security and repair speed B  The Disturbution of  Nodes The ring structure and hash method can balance the load and promote the I/O speed. In the storage system, the 164 


physical node is divided into several virtual nodes according to the computing and storage size. Then these virtual nodes are placed on the ring complying with hash method. In Robot each coding server has several virtual nodes, and one virtual node can only be placed on one physical nodes, one physical node can have multiple virtual nodes, as figure 2 shows    Figure 2  The relation among nodes The number of the virtual nodes on one physical node depends on the storage size of the physical node. Physical nodes with different size storage will have different number of virtual nodes. Every virtual node has it unique number, the different virtual nodes on physical node will be hashed according to IP address and port number. The result of hash operation will act as the ID of the virtual node and decide the position of the virtual node in the ring Physical nodes are numbered according to the joining order, first as No.1 second as No.2  nth as No. n Then we carry out hash operation to the IPv6 address and port number of the physical nodes. Then choose 64 bits as the number of the virtual nodes and sort them in order. After sorting, we place these virtual nodes on the ring according to their number. This method can build a mapping between virtual nodes and physical nodes, which has good uniform property The amount of the nodes in the ring is related to the number and storage size of physical nodes. If Mi is the storage size of the No.i physical node n is the data size K is the required size of virtual nodes. The amount of the virtual nodes nr_vnodes   1 _ n i i nr vnodes M K   1 C  ICRS Code We know that the encode time of CRS code depends on the encode matrix. We have developed ICRS code to accelerate the rate of encoding and decoding. The performance of CRS code directly depends on the number of 1 in the Cauchy matrix. So we use matrix transform to build Cauchy matrix with less 1 in it The optimized Cauchy matrix uses less calculation so it has better performance in the repair process. Besides, to the situation when m=2 we gives all optimal Cauchy matrix when w 32 Here w means binary words of a fixed length There are 3 steps 1  Build basic Cauchy matrix M do matrix transform M[i,j 1   i m+j the division is calculated in finite field and plus is normal plus calculation 2  Set all the number in the first row to 1 To column j  divide every number in this column by M [0, j in finite field 3  Optimize the rest row: reduce the amount of 1 in the rest line is main goal of this operation. We implement it by using enumeration. Divide the row by every number in the row and choose the situation with least 1  Through these steps we can significantly improve the performance of encoding/decoding process. Here is an example of the optimizing process for situation where k = m w = 3  Here is the original Cauchy matrix  672 527 134 2 Optimize the first row  111 436 372 3 Optimize the rest row: enumerate every number in the rest row and select the best situation. For the second row, we try 4, 3, and 6 and count the number of 1. The results are 12 11 and 16. So we choose the 3 to optimize the second row Then we divide the last row by 3  111 512 147 4 This optimized matrix have 34 “1” in it, much less than the 46 before optimizing process. Using this method can have better encoding/decoding performance than CRS and RS code, and the reading and writing speed is much better than CRS and RS D  Data Division In Figure 3, we can see this part first divide big request into several fixed-sizes blocks and put them in the data pool After the data pool is filled up, system encodes the data and adds parity data then send encoded data block to virtual nodes in related storage group. When user requests the original data, decoded data from related virtual node and return them to user 165 


  Figure 3  The flowchar of data division The encoded process is as following   Get data requests from the coding server   Divided the data request with certain size and each block has its own number BLOCK_ID consisted with request block number and sub-block number At the same time, system will add the information of the sub-block into the metadata, such as size, amount BLOCK_ID version   Send data into buffer pool whose size is k When the pool is filled up, trig the encoded process   Encode data block, use erasure code such as ICRS CRS etc. to encode the data and add parity block Add the code type into metadata   Send the encoded data to virtual nodes If we adopt M as the data size of the coding server block_m as the size of data block en_data as the amount of the data block en_parity as the amount of parity block, then we can get the following equation The encoded times encoder_num is  _ _ _ M encoder num block m en data 5 Total storage size total_m is   _ _ _ M en parity total m en data  6 Fault-tolerant ability of system Q is   _ Q en parity  7 This method of encoding/decoding data improves the discreteness of data. Every sub-block can be accessed independently. Furthermore, the repair process can be highly paralleled III  E VALUATION M ETHODOLOGY  A  Experimental Setup In the sections, we mainly discuss about the evaluation and analysis of the implementation part All the tests are based on a platform with a CPU \(Intel Xeon CPU E5606 @ 2.13GHz\ and RAM memory \(16GB DDR3\. Test mode of all the tests is data filling and recovery We built a simulation for the performance estimation of all the processes in data encoding, decoding and node recovery B  System Encoding and Decoding Time Test 1  Encoding and Decoding Time of Data Chunks After selection of storage group, coding servers could encode and coding the user data to selected storage group. If the data is corrupted, then decoding and recovery is needed When encoding or decoding, Vandermonde code and Cauchy code are suitable in distributed system due to its fine fault tolerance and dispensability. Therefore we compare these two codes with ICRS in the tests In the encoding process, user data is randomly generated divided into chunks, encoded and stored into virtual nodes The division and size of the chunks, data chunks, parity chunks and total encoded data size differ, the time of encoding and decoding differ. Figure 4 presents encoding and decoding time in different data chunk sizes in two encoding methods. \(Decoding time here mainly refer to recovery time when data is corrupted Figure 4 shows the encoding and decoding time pattern in a single encoding group when data chunk number is 5 and parity chunk number is 2 Chunks size ranging from 1M to 10M is the only variable parameter. From the figure we could know that encoding time rises as chunk size increases Compared to encoding time, decoding time of a single chunk has better efficiency. Meanwhile, because ICRS and CRS adopts bitmap to convert multiplication into XOR operation and requires lower encoding or decoding time than RS code while decoding time of ICRS is obviously shorter than the CRS because of coding optimization. ICRS is more suitable to be deployed on distributed system for decoding work. It is also obvious from the figure that decoding time is less than encoding time, so encoding time in systems need attentions  Figure 4  Encoding and decoding time in single encoding group k=5 m=2  Figure 5 shows the encoding and decoding time pattern in a 5-chunk encoding group when chunk size is 1M and parity chunk number ranges from 2 to 8. As the parity chunks in an encoding group increase, encoding time rises 166 


More parity chunks can tolerate more faults, which means if higher fault tolerance level is needed more encoding time is required. However, the decoding time is more stable Decoding time in RS, CRS and ICRS has no noticeable fluctuation, which indicates that increase in parity chunks numbers will not lead to decoding time increase of a single chunk. We could also indicated that ICRS performs better than RS and CRS in both encoding and decoding time suggesting ICRS is more adaptive to efficient and timedemanding system than the others  Figure 5  Encoding and decoding time \(size=1M, k=5 Figure 6 shows the encoding and decoding time pattern in an encoding group when chunk size is 4M; parity chunk number is 2 and data chunk number ranges from 3 to 9. As the data chunks increase, order of magnitudes of the encoding time rises from 10 seconds to 100 seconds. ICRS code still has a lower encoding time than RS and CRS Unlike encoding time, decoding time presents a smaller fluctuation. That indicates encoding process has larger overhead than decoding and encoding time is more susceptible by data chunk number k. ICRS remain relatively stable and high efficiency than RS, when k changes  Figure 6  Encoding and Decoding Time\(m=2, size=4M Figure 4, 5, 6 show different result of encoding and decoding time in an encoding group when data chunk number, parity chunk number and chunk size change Through these comparison tests, it can be clear seen that encoding time changes when data chunk number, parity chunk number and chunk size change. The relation between recovery time of a data chunk and chunk size is the most obvious. Bigger chunk size needs more decoding time. When data chunk number in an encoding group increases, decoding recovery time increases, while the increment is less than the case when chunk size increases. In these factors, parity chunk number is the least influential one. Decoding time is less than encoding time and it fluctuates less. Besides, ICRS has a higher overall encoding and decoding efficiency in distributed system than CRS and RS. From Figure 4, 5, 6, we can see that the coding efficiency when using ICRS is 34.2 higher on average than using CRS and 56.5% higher on average than using RS. The decoding efficiency when using ICRS is 18.1% higher on average than using CRS and 31.1 higher on average than using RS 2  Encoding and Decoding Time of Nodes Encoded data chunks are stored on virtual nodes and if any data chunk is corrupted the chunk will be decoded, as Section II describes. Node tests of encoding and decoding includes encoding time test of massive data and test on failure of physical nodes Figure 7 is an encoding time chart when size is 1M numbers are 600. Data chunk number in an encoding group ranges from 3 to 9 and the time for generating random data is included. Encoding time of both codes does not fluctuate very much as data chunk number increases. It is because that more data chunks in an encoding group lead to fewer encoding groups. Although encoding time of each group increases, there are fewer groups. Therefore, no significant growth appears. Apart from that, ICRS code has a better encoding performance than CRS and RS code  Figure 7  Encoding time\(size=1M, num=600 IV  R ELATED W ORK  Erasure code has been widely used in present distributed backup storage system It has been applied in many large-scale distributed storage systems, including storage systems at Facebook and Google.  The updated Google File Systems- GFS2 \(Colossus  has imported the Reed-Solomon encoding in action Lots of works on designing efficient erasure codes or improving performance from certain aspects have mushroomed all around the world.  Compare to ICRS in this paper, the performance of RS is much lower 167 


LRC [15  used  i n  W i ndo w s Az ur e St or a g e  r e d u ce s t h e number of erasure coding fragments that need to be read when reconstructing data fragments that are offline, while still keeping the storage overhead low. The basic of LRC is using extra fragments to construct more parity. As a result fragments in a calibration chain are less than ICRS RS Codes, including ICRS, are Maximum Distance Separable- MDS Codes [16 h i c h r e q u i r e m i ni m u m storage overhead for given, fault tolerance. There are also other erasure codes, such as Hover codes [17  W eav er  c o de s   n d X co de [19  b e l o n g i ng t o  M D S cod e s  b u t t h e s e codes are suitable for disk arrays. Jianzong Wang presented a quantitative evaluation model for different redundancy schemes from eight aspects: Availability, Reliability, Storage Overhead, Performance, Network Bandwidth, Energy Consumption and Dollar Cost in order to help the coding selection. [22, 13 t he r s c he m a 1 2] sh o w e d t h at er a s u r e coding used appropriately can improve system performance and save energy V  C ONCLUSIONS  Big Data has become a challenge for many companies around the world. Many enterprises are looking for better ways to organize, manage and store their machine application and user generated data that is quickly expanding to petabytes and Exabyte in size. This paper has studied the situation of present big data backup system and a solution to improving the storage utilization based on erasure code. We put forward a distributed backup system mechanism based on coding. This mechanism applies coding technique to distributed system in which large amounts of cold data are included to protect data and realize load balance. The ICRS Improved CRS\ethod can improve performance by taking advantage of its high speed of CODEC. By using parallel recovery method, the repair time of system has been reduced The system's load balance is improved by using virtual node Results show that it is very fast to complete CODEC by using ICRS There is still much work to do in the future which mainly contains two directions. First, to reduce the decoding time further, we can optimize the present ICRS. Second, as is shown in related work data deduplication is of great value in storage of big data. How to combine coding technique with data deduplication in Robot is a research direction ACKNOWLEDGMENT  This Project supported by the National Basic Research Program \(973\f China \(No. 2011CB302303\,the National High-Tech R&D Program \(863\ of China\(No.2009AA01A402\, the National Natural Science Foundation of China \(No. 60933002\ and 2011QN032\, the Fundamental Research Funds for the Central Universities R EFERENCES  1  R. J. T. Morris, B. J. Truskowski. The evolution of storage systems IBM Systems Journal, 2003, 42\(2\: 205~217 2  Sanjay Ghemawat, Howard Gobioff, and Shun-Tak Leung. The Google File System. SOSP '03 Proceedings of the nineteenth ACM symposium on Operating systems principles, 2003, pp. 29-43 3  K.  Shvachko, H.  Kuang,  S.  Radia,  R.  Chansler. The  Hadoop Distributed File System,  Proceedings of IEEE MSST 2010, Incline Village, NV, USA, May 2010 4  Amazon simple storage service \(S3\, http://www.amazon.com/s3 5  Sage Weil, Scott A. Brandt, Ethan L. Miller, Darrell D. E. Long Carlos Maltzahn, “Ceph: A Scalable, High-Performance Distributed File System,” In Proceedings of the 7th Conference on Operating Systems Design and Implementation, 2006 6  J. Blomer, M. Kalfane, M. Karpinski, R. Karp, M. Luby, and D Zuckerman. An XOR-based erasure-resilient coding scheme Technical Report TR-95-048, International Computer Science Institute, August 1995 7  J. S. Plank, “A tutorial on Reed-Solomon coding for fault-tolerance in RAID-like systems”. Software –Practice & Experience, 27\(9\5 1012, September1997 8  Yang Wang, Manos Kapritsos, Zuocheng Ren, Prince Mahajan Jeevitha Kirubanandam,Lorenzo Alvisi, and Mike Dahlin. Robustness in the Salus scalable block store. The 10th USENIX Symposium on Networked Systems Design and Implementation \(NSDI ’13\, pp. 357370 9  Yan Li, Nakul Sanjay Dhotre, Yasuhiro Ohara,Thomas M. Kroeger Ethan L. Miller, Darrell D. E. Long. Horus Fine-Grained EncryptionBased Security for Large-Scale Storage. The 11th USENIX Conference on File and Storage Technologies, pp. 147-160   Devesh Tiwari, Simona Boboila, Sudharshan S. Vazhkudai, Youngjae Kim ,Xiaosong Ma , Peter J. Desnoyers  and Yan Solihin. Active Flash Towards Energy-Efficient, In-Situ Data Analytics on ExtremeScale Machines. The 11th USENIX Conference on File and Storage Technologies, pp. 119-132   I. Stoica, R. Morris, D. Karger, M. F. Kaashoek, et al. Chord: A scalable peer-to-peer lookup service for internet applications. in Proc of the ACM SIGCOMM Conference, 2001, pp. 149–160   Jiguang Wan, Chao Yin, Jun Wang and Chagnsheng Xie. A New High-performance, Energy-efficient Replication Storage System with Reliability Guarantee. The 28th IEEE Conference on Massive Data Storage \(2012   Wang J, Gong W, Varman P, et al. Reducing Storage Overhead with Small Write Bottleneck Avoiding in Cloud RAID System. In: Grid Computing \(GRID\, 2012 ACM/IEEE 13th International Conference on. IEEE, 2012: 174-183   Google-GFS2 Colossus, “http://www.quora.com/Colossus-Google GFS2” Google, 2012   C. Huang, H. Simitci, Y. Xu, A. Ogus, B. Calder, P. Gopalan, J. Li and S. Yekhanin. Erasure coding in windows azure storage. In Proceedings of the USENIX Annual Technical Conference \(ATC 2012   G. Feng, R. Deng, F. Bao and J. Shen. New efficient MDS array codes for RAID part I: Reed-Solomon-like codes for tolerating three disk failures. IEEE Trans. Comp., 54\(9\:1071–1080, 2005   J. L. Hafner. WEAVER Codes: Highly fault tolerant erasure codes for storage systems. FAST-2005: 4th Usenix Conf. on File and Storage Tech., San Francisco, 2005, pp. 211–224   J. L. Hafner. HoVer erasure codes for disk arrays. DSN-06: Int. Conf on Dependable Sys. and Networks, Philadelphia, 2006   L. Xu and J. Bruck. X-Code: MDS array codes with optimal encoding IEEE Trans. Inf. Thy, 45\(1\:272–276, 1999   Rowstron, A., and Druschel, P. Pastry: Scalable, decentralized object location and routing for large-scale peer to peer systems. Proceedings of Middleware, pages 329-350, November, 2001   Scality's Ring Organic Storage. http://www.scality.com   Jianzong Wang, Weijiao Gong, Changsheng Xie. A Quantitative Evaluation Model for Choosing Efficient Redundancy Strategies over Clouds. In: Networking, Architecture and Storage \(NAS\, 2012 IEEE 7th International Conference on. IEEE, 2012  168 


Fig 6 Number of Disk Accesses and number of similarity calculation on query execution on database fragments of different sizes a distance radius equal to 50 of a given image takes around 1,200 seconds using the Slim-tree for the respective fragment and 18,577 seconds using the Slim-tree for the entire database On the other hand the query to retrieve images annotated with the tag value chamberlains just 2 images and within the same distance radius of 50 from a given image takes less than 1 second using the respective fragment and 12,514 seconds using the Slim-tree index for the entire database Finally Figure 7 presents the results of a conjunctive complex query with the equality predicate tag  puppy and a kN N q predicate with the center in the image presented in the top left corner highlighted by the red square These 4 images are ranked in the results from left to right and from top to bottom The execution of this query using the fragment referring to the tag puppy  which contains the descriptions of 105,570 images took 108 seconds using a B-tree to 002nd the fragment and a Slim-tree to process the similarity-based predicate in the contents of this fragment As the kN N predicate is not commutative with other predicates for data 002ltering we sho w in Figure 8 the results of a query by a Range q predicate with radius 50 and center in the image on the top left corner These results were produced by using a Slim-tree that indexes the entire database This query took 13,176 seconds to execute Filtering these results for the tag value puppy to produce the result showed in Figure 7 would require further processing but the time to solve the Range q predicate on the Slim-tree that indexes the entire database contents is dominant VI C ONCLUSIONS AND F UTURE W ORK This paper introduces an approach for ef\002ciently processing queries on big complex databases by using horizontal fragments of the database and multi-level indexing This approach has three steps i 002nd fragments with data satisfying some query predicate\(s ii 002lter the data in the chosen fragment\(s according to other predicate\(s conjunctively connected to the former iii compose the results obtained from each fragment The experimental results demonstrate that this proposal drastically improve query execution speed They show that it is not viable to run the similarity-based predicates over the Fig 7 Results of a conjunctive query executed by using the fragment that describes only images tagged with puppy Fig 8 Results of a Range q predicate on the entire database that took almost 100 times longer to produce than those in Figure 7 entire CoPhIR database that describes around 106 million images even using the Slim-tree metric index to speedup the execution of similarity-based predicates on image content descriptors In fact even big fragments describing more than a 100 thousand images approximately need to be further fragmented to ensure acceptable response time Though the case study presented in this paper only considers conjunctive queries with an equality predicate and a similarity-based predicate the proposed approach can be employed for ef\002cient execution of queries with arbitrary numbers of predicates of various kinds and logically connected in different ways In fact our approach opens new research paths towards ef\002cient query execution on big complex data Among the challenges involved in the full exploitation of the proposed approach we mention the following ones for future work i develop automatic techniques to create appropriate horizontal fragments of large databases for ef\002cient query execution ii index fragment collections to ef\002ciently 002nd fragments suitable to solve different kinds of predicates iii devise and validate queries optimization techniques that exploit appropriate database fragments and access methods VII A CKNOWLEDGMENTS Thanks to CNPq CAPES FEESC and FAPESP for their 002nancial support 
542 


R EFERENCES   J Darmont O Boussaid J.-C Ralaivao and K Aouiche An architecture framework for complex data warehouses CoRR  vol abs/0707.1534 2007   A Goker J Davies and M Graham Information Retrieval Searching in the 21st Century  John Wiley  Sons 2007   R A Baeza-Yates and B A Ribeiro-Neto Modern Information Retrieval the concepts and technology behind search Second edition  Pearson Education Ltd Harlow England 2011   R Baeza-Yates and M Melucci Eds Advanced Topics in Information Retrieval  Springer 2011   P Zezula G Amato V Dohnal and M Batko Similarity Search The Metric Space Approach  Springer 2006 vol 32   H Blanken A de Vries H Blok and L Feng Eds Multimedia Retrieval  ser Data-Centric Systems and Applications Heidelberg Springer Verlag 2007 iSBN=978-3-540-72894-8   R Datta D Joshi J Li and J Z Wang Image retrieval Ideas in\003uences and trends of the new age ACM Comput Surv  vol 40 no 2 pp 1–60 2008   J Wang J Li and G Wiederhold Simplicity semantics-sensitive integrated matching for picture libraries Pattern Analysis and Machine Intelligence IEEE Trans on  vol 23 no 9 pp 947 963 sep 2001   Y Zhuang Q Li and R Lau Web-based image retrieval a hybrid approach in Computer Graphics International 2001 Proceedings  2001 pp 62 69   J.-R Wen Q Li W.-Y Ma and H.-J Zhang A multi-paradigm querying approach for a generic multimedia database management system SIGMOD Rec  vol 32 pp 26–34 March 2003   D Joshi R Datta Z Zhuang W P Weiss M Friedenberg J Li and J Z Wang PARAgrab a comprehensive architecture for web image management and multimodal querying in Proceedings of the 32nd International Conference on Very Large Databases  ser VLDB VLDB Endowment 2006 pp 1163–1166   N Rasiwasia J C Pereira E Coviello G Doyle G R G Lanckriet R Levy and N Vasconcelos A new approach to cross-modal multimedia retrieval in ACM Multimedia  A D Bimbo S.-F Chang and A W M Smeulders Eds ACM 2010 pp 251–260   C Traina Jr A J M Traina M R Vieira A S Arantes and C Faloutsos Ef\002cient processing of complex similarity queries in rdbms through query rewriting in ACM 15th International Conference on Information and Knowledge Management CIKM 06  P S Yu V J Tsotras E A Fox and B Liu Eds Arlington VA USA ACM Press 2006 pp 4–13   M C N Barioni H L Razente A J M Traina and C Traina Jr Seamlessly integrating similarity queries in SQL Software Practice and Experience  vol 39 no 4 pp 355–384 2009   F Long H Zhang and D Feng Fundamentals of content-based image retrieval Multimedia Information Retrieval and Management  2002   D R Wilson and T R Martinez Improved heterogeneous distance functions J of Arti\002cial Intelligence Research  vol 6 pp 1–34 1997   P H Bugatti A J M Traina and C Traina Jr Assessing the best integration between distance-function and image-feature to answer similarity queries in 23rd Annual ACM Symposium on Applied Computing SAC2008  Fortaleza Cear Brazil ACM Press 2008 pp 1225–1230   T Bozkaya and M Ozsoyoglu Indexing large metric spaces for similarity search queries ACM Trans Database Syst  vol 24 pp 361 404 September 1999   P Ciaccia and M Patella Searching in metric spaces with user-de\002ned and approximate distances ACM Trans Database Syst  vol 27 pp 398–437 December 2002 A v ailable http://doi.acm.org/10.1145/582410.582412   H Samet Foundations of Multidimensional and Metric Data Structures The Morgan Kaufmann Series in Computer Graphics and Geometric Modeling  San Francisco CA USA Morgan Kaufmann Publishers Inc 2005   L C mitsubishi Electric Ite-vil The mpeg-7 color descriptors jensrainer ohm rwth aachen institute of communications engineering   M R P Ferreira L F D Santos A J M Traina I Dias R Chbeir and C Traina Jr Algebraic properties to optimize knn queries in Proc of the 26th Brazilian Symposium on Databases SBBD  2011   M S Lew N Sebe C Djeraba and R Jain Content-based multimedia information retrieval State of the art and challenges ACM Trans Multimedia Comput Commun Appl  vol 2 pp 1–19 February 2006 Onl A v ailable http://doi.acm.or g/10.1145/1126004.1126005   R d S Torres A X F ao M A Gonc¸alves J P Papa B Zhang W Fan and E A Fox A genetic programming framework for content-based image retrieval Pattern Recognition  vol 42 no 2 pp 283  292 2009 learning Semantics from Multimedia Content A v ailable http://www.sciencedirect.com/science/article/pii/S0031320308001623   T Skopal Where are you heading metric access methods a provocative survey in SISAP  P Ciaccia and M Patella Eds ACM 2010 pp 13–21   U Murthy E A Fox Y Chen E Hallerman R d S Torres E J Ramos and T R C Falc  ao Superimposed image description and retrieval for 002sh species identi\002cation in ECDL  ser Lecture Notes in Computer Science M Agosti J L Borbinha S Kapidakis C Papatheodorou and G Tsakonas Eds vol 5714 Springer 2009 pp 285–296   K C L Santos H M de Almeida M A Gonc¸alves and R d S Torres Recuperac  ao de imagens da web utilizando m  ultiplas evid  encias textuais e programac  ao gen  etica in SBBD  A Brayner Ed SBC 2009 pp 91–105   D C G a Pedronette and R da S Torres Exploiting contextual spaces for image re-ranking and rank aggregation in Proceedings of the 1st ACM International Conference on Multimedia Retrieval  ser ICMR 11 New York NY USA ACM 2011 pp 13:1–13:8  A v ailable http://doi.acm.or g/10.1145/1991996.1992009   D Hiemstra and C Hauff Mapreduce for information retrieval evaluation let's quickly test this on 12 tb of data in Proceedings of the 2010 international conference on Multilingual and multimodal information access evaluation cross-language evaluation forum  ser CLEF'10 Berlin Heidelberg Springer-Verlag 2010 pp 64–69  A v ailable http://dl.acm.or g/citation.cfm?id=1889174.1889186   N Alipanah P Parveen L Khan and B Thuraisingham Ontologydriven query expansion using map/reduce framework to facilitate federated queries in Proceedings of the 2011 IEEE International Conference on Web Services  ser ICWS 11 Washington DC USA IEEE Computer Society 2011 pp 712–713 A v ailable http://dx.doi.org/10.1109/ICWS.2011.21   Z Wu B Mao and J Cao Mrgir Open geographical information retrieval using mapreduce in Geoinformatics 2011 19th International Conference on  2011 pp 1–5   D S Kaster P H Bugatti A J M Traina and C T Jr Fmisir A 003exible and ef\002cient module for similarity searching on oracle database JIDM  vol 1 no 2 pp 229–244 2010   F J T Chino M R Vieira A J M Traina and C Traina Mamview a visual tool for exploring and understanding metric access methods in Proceedings of the 2005 ACM Symposium on Applied computing  ser SAC 05 New York NY USA ACM 2005 pp 1218–1223  A v ailable http://doi.acm.or g/10.1145/1066677.1066952   C Traina Jr A J M Traina C Faloutsos and B Seeger Fast indexing and visualization of metric datasets using slim-trees IEEE Transactions on Knowledge and Data Engineering TKDE  vol 14 no 2 pp 244–260 2002   P Bolettieri A Esuli F Falchi C Lucchese R Perego T Piccioli and F Rabitti CoPhIR a test collection for content-based image retrieval CoRR  vol abs/0905.4627v2 2009   H Eidenberger Distance measures for mpeg-7-based retrieval in Proceedings of the 5th ACM SIGMM international workshop on Multimedia information retrieval  ser MIR 03 New York NY USA ACM 2003 pp 130–137 A v ailable http://doi.acm.org/10.1145/973264.973286   R Dorairaj and K R Namuduri Compact combination of mpeg-7 color and texture descriptors for image retrieval in Signals Systems and Computers 2004 Conference Record of the Thirty-Eighth Asilomar Conference on  vol 1 IEEE 2004 pp 387–391 
543 


014 014 
014 014 004 
vol 15, issue 2, 2006, pp165190  Ding Z, Huang G, "Real Time Traffic Flow Statistical Analysis Based on Network-Constrained Moving Object Trajectories", proc. of 20th Intl. Conf. on Database and Expert Systems Applications DEXA'09\August, 2009 
Sensor number 4 Node Servers 32 Node Servers 
speedup Q Q  Q General Statistical Database Cluster Mechanism for Big Data Analysis in the Internet of Things 
VLDB Journal 
 SNQP IOTStatisticDB 
005 1000 
icDB IOTStatist SNQP speedup 
1  2 4 have similar results TABLE III S PEEDUP R ATE OF IOT-S TATISTIC DB 
 
 From Figure 8 we can see that, when data size increases the performance of CSA-DSD decreases rapidly while the performance of IOT-StatisticDB is relatively stable. The main reason is that in CS A-DSD, large volumes of statistical raw data needs to be transferred to and stored at the master server for statistical analysis. Therefore, the query response time is prop ortional to the whole data size On the other hand, in IOT-StatisticDB, the main workload is distributed among the nod e servers, so that the overall performance is less sensitiv e to the overall data size To better analysis how the statistical analysis workload is shared by multiple node servers in IOT-StatisticDB, we define the speedup rate 60 100 140 180 220 2.85 3.05 3.71 3.81 3.73 19.25 21 22.36 22.5 21.85 We can observe from Table 3 that when the number of node servers is 4, the speedup rate is between 2.85~3.81 and when the number of node servers is increased to 32, the speedup rate is between 19.25~22.36. In general, with the number of node servers incr easing, the query response time decreases, since in IOT-StatisticDB, the query response time is main decided by the da ta size of each node server V C ONCLUSIONS  Statistical analysis on sensor sampling data is one of the most important procedures in IoT systems to transform dataŽ into knowledgeŽ. In this paper, we propose a 
as follows where is the query response time of single node query processing, and is the query response time of IOT-StatisticDB. Table 3 shows th e speedup rate of  IOT-StatisticDB The main contribution is as follows 1\general statistical database cluster mechanism is proposed, with data typ es and operators for statistical analyzing provided. The mechanism is a general model which can support complicated statistical queries through standard SQL statements 2 methods, including Euclidean-based spatial aggregation, Network-based spatial aggregation, Euclidean-based parameter aggregation, and Network-based parameter aggregation, are proposed with detailed algorithms presented 3\he parallel processing techniques of statistical queries are proposed, so that multiple servers can conduct statistical analysis in parallel and the performance can be greatly improved As the future work, event detections and data mining techniques based on IoT statistical analysis will be studied A CKNOWLEDGMENTS  The work was partially supported by National Natural Science Foundation of Chin a \(NSFC\under grant number 91124001 and by National High-Tech. R&D Program of China \(863 program\gr ant number 2013AA01A603 R EFERENCES   W a ng D, Clustering Mesh-like W i reless Sensor Networks with an Energy-efficient Scheme,Ž International Journal of Sensor Networks vol. 7 No. 4 2010, pp. 199-206  Chen H, Minen o H Mizuno T, A Meta-data-based Data  Aggregation Scheme in Clustering Wireless Sensor NetworksŽ. Proc of Intl. Conf. on Mobile Data Managem ent \(MDM06 May 2006, pp. 154-161  Liu C, W u K Pei J, A Dy nam i c Clustering and Scheduli ng Approach to Energy Saving in Data Collection from Wireless Sensor NetworksŽ, Proc. of IEEE Conf. on Sensor, Mesh and Ad Hoc Communications and Networks \(SECON05 IEEE press, Sep. 2005 pp. 374-385  Z hang Y, W a ng H T i an L   E ner gy and Data Awar e Cluster ing for  Data Aggregation in Wireless Sensor Networ ksŽ, Proc. of IEEE 4th Intl. Conf. on Mobile Ad hoc and Sensor Systems \(MASS07 Press, Oct. 2007 pp. 1-6  Ordonez C S tatistical Model Com putation with UDFs IEEE Transactions on Knowledge and Data Engneering \(TKDE Dec. 2010, pp. 1752-1765  Ester M, K r iegel H P, Sander J Xu X A Density-Ba sed Algorith m for Discovering Clusters in Large Spatial Databases with Noise Proc. of Intl. Conf. on Knowledge Discovery and Data Mining KDD96\, Aug. 1996, pp:226-231  Ankerst M, Breunig M, Kriegel H P, Sander J, Optics: Or der ing Points to Identify the Clustering StructureŽ, Proc. of ACM Intl. Conf on Management of Data \(SIGMOD9 9  Yang Y, W u L Guo J, Liu S, Research on Distrib uted Hilbert R  Tree Spatial Index Based on Birch Clusteri ngŽ, Proc. of Intl. Conf. on Geoinformatics \(Geoinformatics12\IEEE Pr ess, Jun. 2012, pp. 1-5  Chitta R, Jin R Havens T, Jain A   A pproxim ate Ke rnel k-Means  Solution to Large Scale Kernel Clustering Proc. of ACM Intl. Conf on Knowledge Discovery and Data Mining \(SIGKDD11  Zhang Z Yang Y Tung A, Papadias D, Contin uous kMeans Monitoring over Moving Objects IEEE Transactions on Knowledge and Data Engineering \(TKDE May 2008, pp. 1205-1216  Feng X, Ku m a r A, Recht B, Ré C  Towar ds a Unified Ar chitecture for in-RDBMS AnalyticsŽ Proc. of ACM Intl. Conf. on Management of Data \(SIGMOD12\, May 2012, pp. 325-336  Heller stein J R C Schopp m a nn F, W a ng D, Fr atkin E, Gor ajek A et al. The MADlib Analytics Library or MAD skills, the SQL Journal Proceedings of the Very Large Data Base Endowment, vol. 5 issue 12, 2012, pp. 1700-1711  Jam p ani R Xu F W u M, P e rez L Jermaine C, Haas P, The Monte Carlo Database System: Stochastic Analysis Close to the Data ACM Transactions on Database Systems \(TODS\1 pp. 18:1-18:41  Xiong Z Luo W   Chen L Ni L Data Vitalization: A New Par adig m  for Large-Scale Dataset AnalysisŽ. Proc of IEEE 16th Intl. Conf. on Parallel and Distributed Systems ICPADS10 Dec. 2010  Güting R.H, Al m e ida V, Ding Z, Modeling and Quer y i ng Moving Objects in Networks 
543 


  


Bottom Top A B 
Figure 15 Figure 16 
messages seen for all workers in a superstep \(Figures 10 and 13\. When looking at the messages sent by workers in a superstep for METIS, we see that there are message load imbalances within work ers in a superstep, caused due to concentration of vertices being traversed in that superstep in certain partitions This variability is much more pronounced in CP as compared to WG \(Figures 11 and 14\ E.g. in superstep 9 for CP, twice as many messages \(4M\ are generated by a worker compared to another \(2M\.  For Pregel BSP, the time taken in a superstep is determined by the slowest worker in that superstep. Hence increase d variability in CP causes even goodŽ partitioning strategies to cause an increase in total execution time wh en using the Pregel/BSP model VIII A NALYSIS OF E LASTIC C LOUD S CALING  Cloud environments offer elasticity … the ability to scale-out or scale-in VMs on-demand and only pay for what one uses [28   On th e f l i p s i de  on e en ds u p  paying for VMs that are acquired even if they are underutilized. We have already shown the high variation in compute/memory resources used by algorithms like BC and APSP across different supersteps. While our earlier swath initiation heuristics attempt to flatten these out by overlapping swath executions, one can consider leveraging the clouds elasticity to, instead, scale up and down the concurrent workers \(and graph partitions\ allocated in each superstep The peak and trough nature of resource utilization combined with Pregel/BSPs synchronous barrier between supersteps offers a window for dynamic scaleout and …in at superstep boundaries. Peak supersteps can greatly benefit from additional workers, while those same workers will contribute to added synchronization overhead for trough supersteps We offer an analysis of the potential benefits of elastic scaling by extrapolating from observed results for running BC on WG and CP graphs, using four and eight workers.  To provide a fair and focused comparison, we turned off swath heuristics in favor of fixed swath sizes and initiation intervals Figure 15 \(Bottom\ plots the speedup of BC running on eight workers when normalized to BC running on four workers, at corresponding supersteps.  The number of workers does not impact the number of supersteps We also plot the number of active vertices \(i.e. vertices still computing for a given swath\these supersteps which is a measure of how much work is required \(Fig 15 \(Top\. We find that we occasionally get superlinear speedup spikes \(i.e. >2x\ that shows a strong correlation with the peaks of active messages, for both WG and CP graphs. At other times, the sp eedup is sublinear or even a speed-down \(i.e. <1\responding to inactive vertices.  The superlinear speedup is attributable to the lower contention and reduced memory pressure for 8 workers when the active vertices peak \(similar to what we observed for the swath initiation heuristics Similarly, the below par speedup during periods of low activity is contributed by the increased overhead of barrier synchronization across 8 workers. Intuitively, by dynamically scaling up the number of workers for supersteps with peaking active vertices and scaling them down otherwise, we can leverage the superlinear speedup and get more value per worker Using a threshold of 50% active vertices as the threshold condition for between 4 and 8 workers in a superstep, we extrapolate the time per superstep and compared this to the fixed 4 and 8 worker runtimes. We also compute the best-case run time using an oracleŽ approach to i.e. for each superstep, we pick the minimum of the 4 or 8 workers time.  Note that these projections do not yet consider the overheads of scaling, but are rather used to estimate the potential upside if we had an ideal or an automated heuristic for scaling. The total time estimates for running BC on WG and CP graphs, normalized to  
 plot shows speedup of 8 workers relative to 4 workers, for each superstep, when running BC on WG and CP graphs plot shows the number of vertices active in that superstep Estimated time for BC using elastic scaling, normalized to time taken for 4 workers. Normalized cost is shown on secondary Y axis WG graph shown on left CP graph shown on right. Smaller is better 
022\011 022\010 022\007 022\002 006 002 007 006 002 007 010 011 012 013 014 015 006 006\003\002 006\003\007 006\003\010 006\003\011 006\003\012 006\003\013 006\003\014 006\003\015 006\003\016 002 027\031\030\037\020#@\020"\031\030\027\020\035 0201!2#\024$#\015#5\024",\020"#\017\003"\003\031\003#\011#5\024",\020"\035 024"'\033\026\0309\0201#\\031\020 2 035#\032\020"#+!\034 017\020\021\022\023\024\024\025\026\020 027\030\031\022\032\033\031\020\034\031\035 017\020\021\022\023\024\024\025\026\020#?#/\027\031\030\037\020#@\020"\031\030\027\020\035 027\030\031\022\032\033\031\020\034\031\035#?#/\027\031\030\037\020#@\020"\031\030\027\020\035 036\030\034\020\033"#\\0201!2 006 006\003\007 006\003\011 006\003\013 006\003\015 002 002\003\007 006 006\003\002 006\003\007 006\003\010 006\003\011 006\003\012 006\003\013 006\003\014 006\003\015 006\003\016 002 011#5\024",\020 B\034\0267 015#5\024",\020 B\034\0267 1\0332\031\030\037\020 030\034\025 1\0332\031\030\037\020 036\024\017\020 024!\0341 024\035\031#>\024"'\033\026\0309\0201#\031\024#\011#5\024",\020"#.\024\035\031 017\020\021\022\023\024\024\025\026\020#+!\034\022&\030'\020#>\024"'\033\026\0309\0201#\031\024#\011#5\024",\020"#&\030'\020 011#5\024",\020"#&\030'\020 015#5\024",\020"#&\030'\020 024\035\031 006 006\003\007 006\003\011 006\003\013 006\003\015 002 002\003\007 002\003\011 002\003\013 006 006\003\002 006\003\007 006\003\010 006\003\011 006\003\012 006\003\013 006\003\014 006\003\015 006\003\016 002 011#5\024",\020 B\034\0267 015#5\024",\020 B\034\0267 1\0332\031\030\037\020 033\026\030\034\025 1\0332\031\030\037\020 036\024\017\020 024!\0341 024\035\031#>\024"'\033\026\0309\0201#\031\024#\011#5\024",\020"#.\024\035\031 027\030\031\022\032\033\031\020\034\031\035#+!\034\022&\030'\020#>\024"'\033\026\0309\0201#\031\024#\011#5\024",\020"#&\030'\020 011#5\024",\020"#&\030'\020 015#5\024",\020"#&\030'\020 024\035 031 
 
dynamically scaling ideal scaling 
Our hypothesis is that an intelligent adaptive scaling of workers can achieve a similar performance as a large, fixed number of workers, but with reduced cost 
213 


Nature Nature Ecological Applications Nature ACM International Conference on Management of Data \(SIGMOD In Parallel Object-Oriented Scientic Computing \(POOSC Science Communications of the ACM ACM Workshop on Mining and Learning with Graphs Communications of the ACM HotCloud Proceedings of the 19th ACM International Symposium on High PErformance Distributed Computing HPDC Knowledge and Information Systems KAIS International Conference on Computational Science IEEE International Conference on Cloud Computing Technology and Science ACM/IEEE Conference on Advances in Social Network Analysis and Mining \(ASONAM IEEE International Parallel and Distributed Processing Symposium \(IPDPS International Conference on Distributed Computing and Networking Journal of Mathematical Sociology International Conference on Parallel Processing Communications of the ACM 
 
observed time taken using 4 workers, are plotted in Figures 16\(A\ and 16\(B We see that our dynamic scaling heuristic using the percentage of active vertices achieves nearly the same CP\ or better \(WG\ performance as a fixed 8 worker approach. Clearly there is benefit of using fewer workers for low utilization su persteps to eliminate the barrier synchronization overhead. Also, the dynamic scaling heuristic performs almost as well as the ideal scaling. Finally, when we consider the monetary cost of the proposed approaches, assuming a pro-rata normalized cost per VM-second plotted on the secondary Y axis, we see that dynamic scaling is comparable \(CP\ or cheaper \(WG\ than a 4 worker scenario while offering the performance of an 8 worker deployment IX C ONCLUSION  In conclusion, we introduce optimization and heuristics for controlling memory utilization and show they are critical to performance.  By breaking computation into swaths of vertices and using our sizing heuristics we achieve up to 3.5x speedup over the maximum swath size that does not cause the a failure.  In addition overlapping swath executions can provide a 24% gain with automated heuristics and even greater speedup when a priori knowledge of the network characteristics is applied This evaluation offers help to eScience users to make framework selection and cost-performancescalability trade-offs. Our he uristics are generalizable and can be leveraged by other BSP and distributed graph frameworks, and for graph applications beyond BC. Our work uncovered an unexpected impact of partitioning and it would be worthwhile, in future, to examine the ability to pred ict, given certain graph properties, a suitable partitioning model for Pregel/BSP It may also be useful to perform such evaluations on larger graphs and more numbers of VMs. At the same time, it is also worth considering if non-linear graph algorithms are tractable in pr actice for large graphs in a distributed environment B IBLIOGRAPHY  1  F  L i lj er os C   Ed l i n g L  A m a r a l H  S t an ley   and Y    berg The web of human sexual contacts 
vol. 411, pp. 907908, 2001   H Je o n g  S   Ma so n A  L   B a ra b s i  a nd Z   Oltva i  L e t ha l i t y  and centrality in protein networks vol. 411, pp. 41-42 2001   O. B o din and E   E s t r ada    U s i n g n e t w ork c e nt r a l i t y  m e a s ures t o  manage landscape connectivity vol 18, no. 7, pp. 1810-1825, October 2008   D. W a ts s  and S  S t r ogat z  C olle c t i v e  d y nam i cs of  s m a ll-w orl d   networks vol. 393, no. 6684, pp. 440…442, June 1998   G  Ma lew i c z   M A u s t er n A   Bik  J   Dehn er t I  Hor n   N. L e i s er and G. Czajkowski, "Pregel: A system for large-scale graph processing," in 2010   D. G r egor  and A  L u m s dain e  T h e  pa r a llel  B G L  A gen e r i c  library for distributed graph computations," in 2005   B. S h a o  H. W a n g  and Y  L i T he T r init y G r aph E n g i n e    Microsoft Research, Technical Report MSR-TR-2012-30, 2012   A  F ox  C lo ud c o m putin g w h at  s  in it for m e  as  a  s c i e n tis t     vol. 331, pp. 406-407, 2011   S. G h e m a w a t  and J  De an   Map re duc e s i m p lifi e d data  processing on large clusters vol 51, no. 3, pp. 107-113, 2008   J  L i n and M. S c hat z   Des i g n  patt er n s  for eff i ci ent gr aph algorithms in MapReduce," in 2010   L   Va l i ant   A b r id g i n g m o d e l f or pa r a llel com putati o n  vol. 33, no. 8, pp. 103-111, 1990 12 a c h e  Ha ma    O n l i n e    http://hama.apache.org   13 Ap a c h e  Ha d o op    O n l i n e    http://hadoop.apache.org     M Z a h a r i a, M. Ch ow dhu ry M F r ank l in S  S h e n k e r, and I   Stoica, "Spark: Cluster Computing with Working Sets," in 2010   J  Ekana y ak e e t a l     T w i st er A  r untim e f o r it er ati v e  MapReduce," in Chicago, 2010, pp. 810-818   U. K a n g  C  T s o u rakakis   and C. F a l outs o s  Peg a s us   Minin g  Peta-scale Graphs," in 2010   M. P a c e  B S P vs  MapR e duc e    in vol. 103.2081, 2012   S. Seo  E  Yoo n, J  K i m  S  J i n  J-S. K i m   and S   Ma e n g HAMA: An Efficient matrix computation with the MapReduce framework," in 2010, pp. 721-726   S. S a l i h ogl u  and J  W i d o m  G PS A G r a ph P r oc e s s i n g Sy s t em    Stanford University, Technical Report 2011   R L i cht e n w a l t e r and N   Cha w la D is Ne t  A fr am ew ork for  distributed graph computation," in  2011   K  Maddu r i  D. E d i g er K   J i an g  D. Bad e r  and D  Cha v a r riaMiranda, "A faster parallel algorithm and efficient multithreaded implementations for evaluating betweenness centrality on massive datasets," in 2009   E  K r e p s k a, T  K i el m a nn, W  F o kkink, H   Ba l, "A  hi g h level framework for distributed processing of large-scale graphs," in 2011, pp. 155-166   L   Pa ge  S  B r in R. M o t w ani and T  W i nogr ad  T h e P a geRank citation ranking: Bringing order to the web," Stanford InfoLab Technical Report 1999-66, 1999   U  Brand  s  A f a s t er  a l gor ith m for  b e t w eenn e s s c e nt r a l i t y    vol. 25, no. 2, pp. 163-177 2001   Stan fo r d  Net w or k A na l y s is Pro j e c t  O n l in e    http://snap.stanford.edu    I  S t ant o n and G  K l i o t, "S t r e a m i n g G r aph P a rtiti o n in g  for L a rge Distributed Graphs," Microsoft Corp., Technical Report MSRTR-2011-121, 2011   G   K a ry pis and V   K um a r A fas t and hi g h qua l i t y m u l t i l evel scheme for partitioning irregular graphs," in 1995, pp. 113-122   M. A r m b r u s t e t  a l   A v i ew of  c l o u d  c o m putin g    vol. 53, no. 0001-0782, pp. 50-58 April 2010  
214 


  13  or gani c  c he m i s t r y  i n our  Sol ar  Sy s t e m       Xi a n g  L i r e c e i v e d h i s B  S   m is tr y  fr o m  th e  P e k in g  U n iv e r s ity  C h in a  in  2 0 0 3  and P h D   i n P hy s i c al  C he m i s t r y  f r om  t he  J ohns  H opk i ns  Un i v e r s i t y  i n  2 0 0 9   He  h a s  b e e n  a  R e s e a r c h  A s s o c i a t e  wi t h  a  j o i n t  a p p o i n t m e n t  a t  t h e  U n i v e r s i t y  o f  M a r y l a n d   Ba l t i m o r e  C o u n t y  a n d  N AS A G o d d a r d  S p a c e  Fl i  Ce n t e r  s i n c e  2 0 1 1   H i s  r e s e a r c h  f o c u s e s  o n  t h e  d e t e c t i o n  of  t r ac e  e l e m e nt  and as t r obi ol ogi c al l y  r e l e v ant  or gani c  mo l e c u l e s  i n  p l a n e t a r y  s y s t e ms   l i k e  M a r s   He  i s  es p eci a l l y i n t er es t ed  i n  t h e d evel o p m en t  o f  T i m e of  and I on T r ap m as s  s pe c t r om e t e r s w i t h v a r i o u s i o n i z a t i o n  ng te c h n iq u e s   Wi l l  B r i n c k e r h o f f  sp a c e  sc i e n t i st  i n  t h e  Pl a n e t a r y  En v i r o n m e n t s  La b  a t  N A S A  s  G o d d a r d  Spac e  F l i ght  C e nt e r  i n Gr e e n b e l t   M D w i t h  pr i m ar y  r e s pons i bi l i t y  f or  th e  d e v e lo p m e n t o f th e  L D TO F  m a s s  s p e c t r o  th is  p r o je c t H e  h a s  fo c u s e d  re c e n t l y  o n  t h e  d e v e l o p m e n t  o f  m i n i a t u re  l a se r d ma s s  s p e c t r o me t e r s  f o r  f u t u r e  p l a n e t a r y  mi s s i o n s  a l o n g  wi t h  b a s i c  e x p e r i m e n t a l  r e s e a r c h  i n  a s t r o b i o l o g y  a n d  p r e bi ot i c  s y nt he s i s   D r   B r i nc k e r hof f  i s  i nv ol v e d i n t he  de v e l opm e nt  of  m as s  s pe c t r om e t e r  f or  bot h t he  2011 Ma r s  S c i e n c e  L a b o r a t o r y  a n d  t h e  2 0 1 8  E x o Ma r s  mi s s i o n s   


  14   


Copyright © 2009 Boeing. All rights reserved  Issues and Observations Initial load of one day of data ~ 7 hours Optimizations  Write data in batches  Use a mutable data structure to create data strings  Deploy a higher performance machine  Use load instead of insert  Use DB2 Range-Partitioned tables  Database tunings Time reduced from 7 hours to approx 30 minutes 


Copyright © 2009 Boeing. All rights reserved  Optimizations Use a mutable data structure to create data strings  Original application created the SQL statement by appending elements to a Java String  It was taking five hours \(of the seven hours Strings  Instead Java StringBuilder used  Java Strings immutable  Time savings of 71.4 


Copyright © 2009 Boeing. All rights reserved  Optimizations Deployed on a higher-performance machine  Application ported from IBM Blade Center HS21 \(4GB of RAM and 64-bit dual-core Xeon 5130 processor to Dell M4500 computer \(4GB of RAM and 64-bit of quad-core Intel Core i7 processor  Reduced the time to thirty minutes Bulk loading instead of insert  Application was modified to write CSV files for each table  Entire day worth of data bulk loaded  Reduced the time to fifteen minutes 


Copyright © 2009 Boeing. All rights reserved  Optimizations Range-Partitioned tables \(RPT  To limit the size of tables, the original code created multiple tables per table type  This puts burden on the application to query multiple tables when a range crosses several tables  With RPT, user is not required to make multiple queries when a range crosses a table boundary  Increased the time to thirty minutes  Additional fifteen minute cost per day of partitioning enabled time savings during queries 


Copyright © 2009 Boeing. All rights reserved  Optimizations Database tunings  Range periods changed from a week to a month  Automatic table space resizing changed from 32MB to 512KB  Buffer pool size decreased  Decreased the time to twenty minutes Overall, total time savings of 95.2 


Copyright © 2009 Boeing. All rights reserved  20 IBM Confidential Analytics Landscape Degree of Complexity Competitive Advantage Standard Reporting Ad hoc reporting Query/drill down Alerts Simulation Forecasting Predictive modeling Optimization What exactly is the problem What will happen next if What if these trends continue What could happen What actions are needed How many, how often, where What happened Stochastic Optimization Based on: Competing on Analytics, Davenport and Harris, 2007 Descriptive Prescriptive Predictive How can we achieve the best outcome How can we achieve the best outcome including the effects of variability Used with permission of IBM 


Copyright © 2009 Boeing. All rights reserved Initial Analysis Activities Flights departing or arriving on a date Flights departing or arriving within a date and time range Flights between city pair A,B Flights between a list of city pairs Flights passing through a volume on a date. \(sector, center, etc boundary Flights passing through a volume within a date and time range Flights passing through an airspace volume in n-minute intervals All x-type aircraft departing or arriving on a date Flights departing or arriving on a date between city pair A,B Flights departing or arriving on a date between a list of city pairs Flights passing through a named fix, airway, center, or sector Filed Flight plans for any of the above Actual departure, arrival times and actual track reports for any of the above 


Copyright © 2009 Boeing. All rights reserved  Initial SPSS Applications Show all tracks by call sign 


Copyright © 2009 Boeing. All rights reserved  Predictive / Prescriptive Analytics Use-Case For a given Airspace Volume of Interest \(AVOI compute distinct traffic volume at some point in the future  Aim to alert on congestion due to flow control areas or weather if certain thresholds are exceeded  Prescribe solution \(if certain thresholds are exceeded Propose alternate flight paths  Use pre-built predictive model  SPSS Modeler performs data processing Counts relevant records in the database \(pattern discovery Computes traffic volume using statistical models on descriptive pattern Returns prediction with likelihood 


Copyright © 2009 Boeing. All rights reserved  Predictive / Prescriptive Analytics Use-Case Advanced Arrival Procedures with Active Abatement Potentials   9/23/10  24 Pulls in the TRACKINFO table of MAIN using SQL Limits the data to database entries which fall inside the AVOI Combines the SOURCE_DATE and SOURCE_TIME to a timestamp that can be understood by modeler Computes which time interval the database entry falls in. The time interval is 15 minutes Defines the target and input fields needed for creating the model Handles the creation of the model Produces a graph based off of the model results Final prediction 


Copyright © 2009 Boeing. All rights reserved  Initial Cognos BI Applications IBM Cognos Report Studio  Web application for creating reports  Can be tailored by date range, aircraft id, departure/arrival airport etc  Reports are available with links to visuals IBM Framework Manager  Used to create the data package  Meta-data modeling tool  Users can define data sources, and relationships among them Models can be exported to a package for use with Report Studio 


Copyright © 2009 Boeing. All rights reserved  Flights Departing Las Vegas on Jan 1, 2012 1 of 3 Report shows the departure date, departure and arrival locations and hyperlinks to Google Map images DeparturePosition and ArrivalPosition are calculated data items formatted for use with Google Maps Map hyperlinks are also calculated based on the type of fix 


Copyright © 2009 Boeing. All rights reserved  Flights Departing Las Vegas on Jan 1, 2012 2 of 3 DeparturePosition, Departure Map, ArrivalPosition and Arrival Map are calculated data items \(see departure items below DepartureLatitude DepartureLongitude DeparturePosition Departure Map 


Copyright © 2009 Boeing. All rights reserved  Flights Departing Las Vegas on Jan 1, 2012 3 of 3 


Copyright © 2009 Boeing. All rights reserved  Conclusion and Next Steps Current archive is 50 billion records and growing  Approximately 34 million elements per day  1GB/day Sheer volume of raw surveillance data makes analytics process very difficult The raw data runs through a series of processes before it can be used for analytics Next Steps  Continue application of predictive and prescriptive analytics  Big data visualization 


Copyright © 2009 Boeing. All rights reserved  Questions and Comments Paul Comitz Boeing Research & Technology Chantilly, VA, 20151 office Paul.Comitz@boeing.com 


Copyright © 2009 Boeing. All rights reserved Advanced Arrival Procedures with Active Abatement Potentials   9/23/10  31 


Copyright © 2009 Boeing. All rights reserved Advanced Arrival Procedures with Active Abatement Potentials   9/23/10  32 Backup Slides 


Copyright © 2009 Boeing. All rights reserved  Initial Approach Initial Investigations  Apache Solr/Lucene  Data Warehouse Evaluate Hadoop in the future 


Copyright © 2009 Boeing. All rights reserved  Using SOLR Uncompress Track Information Messages To use with Solr  Transforming track messages from their  original schema to Solr required building a “key, value” list using an XSTL  Queries made against this list of “key, value” pairs Transformation Process  One day of data ~ 4.5 hours Once transformation complete search/query performance very good Geo spatial queries using  unique query language 


Copyright © 2009 Boeing. All rights reserved  Representation Aviation data is frequently represented in more than one form 


