Construction of Exact-BASIC Codes for Distributed Storage Systems at the MSR Point Hanxu Hou   Kenneth W Shum  and Hui Li   Shenzhen Eng Lab of Converged Networks Technology Shenzhen Key Lab of Cloud Computing Tech and App Peking University Shenzhen Graduate School  Institute of Network Coding the Chinese University of Hong Kong  Department of Information Engineering the Chinese University of Hong Kong Abstract Regenerating codes RGC are a class of distributed storage codes that can provide efìcient repair of failure nodes in distributed storage systems In general the reduction of repair bandwidth of RGC is at the expense of a small increase in storage cost and computational cost The high computational complexity of data coding over a nite eld of large size makes it unsuitable for practical distributed storage systems BASIC codes which stands for Binary Addition and Shift Implementable Convolutional codes is introduced in with the aim of r educing computational complexity while retaining the beneìts of RGC In this paper we present a construction of exact-repair BASIC codes at the minimum-storage point MSR A helper node needs no coding to repair a failure node for the minimum-storage BASIC codes The results of simulation show minimum-storage BASIC codes outperform Cauchy Reed-Solomon codes in both repairing cost and coding cost I I NTRODUCTION Distributed storage systems achieve high reliability by storing the big data redundantly in a large collection of unreliable storage nodes There are two ways of providing redundancy The simplest form of redundancy is replicate the data multiple times which is widely used in many practical storage systems e.g Google le system and F acebook data centers 3 As a generation of replication erasure code can provide much better storage efìciency than replication and Reed-Solomon RS code is a typical erasure code The original le can be recovered from any set of k storage nodes and we term this property as MDS Maximum Distance Separable property To repair a failed node RS code will let the new node download k coded pieces from the surviving nodes reconstruct the original le and compute the lost piece Call this process as repairing process  and repair bandwidth is the total network bandwidth of a repairing process The repair bandwidth of RS code is k times of size of the lost piece which is a waste of network bandwidth This work was partially supported by National Basic Research Program of China 973 Program No.2012CB315904 National Natural Science Foundation of China No.NSFC61179028 SZ JCYJ20130331144502026 Guangdong Natural Science Foundation GDNSF No.S2011010000923 and a grant from University Grants Committee of the Hong Kong Special Administrative Region China Project No AoE/E-02/08 The performance of both redundancy-reliability and repair problem was formulated and studied in which is called regenerating codes RGC Consider an  n k d    regenerating code that the le of size B is stored in a distributed storage system with n storage nodes where each node stores  packets All k packets of k storage nodes are downloaded by a data collector DC to reconstruct the object this process is termed as reconstructing process and the total data downloaded of the process is the reconstructing bandwidth Ifa storage node has failed a new storage node can regenerate the  packets by downloading  packets each from any d surviving nodes After that a DC can still reconstruct the original object by downloading all the k packets from any k storage nodes In this repairing process the repair bandwidth of RGC is   d  and the number of nodes accesses d is reffered to as repair-degree  RGC possess an optimal tradeoff curve between the amount of reconstructing bandwidth k and the repair bandwidth d  Two kinds of optimal codes the minimum-storage regenerating MSR point and the minimum-bandwidth regenerating MBR point are proposed in where MSR codes are corresponding to the point with k MSR  B   MSR  Bd  k  d  k 1  and MBR codes are corresponding to the point with  MBR  2 Bd 2 kd  k 2  k   MBR  2 Md 2 kd  k 2  k  The explicit constructions of MSR codes and MBR codes are developed in  Up to no w  the best results are the constructions of MSR codes and MBR codes in which achie v e the optimal tradeoff at the MSR codes  n  2 k  and MBR codes all n and k  using the product-matrix construction With respect to the repairing process and coding process there are arguably several performance merits possible in the design-space of codes for distributed networked storage 1 Repair bandwidth  MBR codes are able to achieve the minimum repair bandwidth and PM product-matrix is a typical construction but take an order of magnitude more computation time than standard erasure codes for both encoding and decoding 2 Repair-degree  Recently proposed SRC self-repairing codes 10 achie v e this optimal by allo wing one repair while contacting only two nodes as long as less 978-1-4799-1293-3/13/$31.00 ©2013  IEEE 


than half of the nodes have failed This is at the price of sacriìcing the MDS property 3 Input/output I/O cost  which measures the number of bits a storage node needs to read out from its memory in order to repair the failed node In the extreme case where I/O cost is minimal the number of bits read out from the memory is exactly equal to the number of bits to be sent out Data combining is only required in the receiving end RGC with minimal I/O cost is called a repair-by-transfer regenerating code The construction of repair-by-transfer minimum-repair-bandwidth regenerating codes can be found in DRESS codes 4 Computation complexity  Traditionally RS codes and RGC are constructed based on nite eld GF q  where q 2  So we have to handle multiplication operations during coding and repairing process results in more computation complexity RGC outperform RS codes in terms of repair bandwidth but take an order of magnitude more computation time than standard erasure codes for both encoding and decoding More accurately gi v e s a system perspecti v e of re gener ating codes and clam that product-matrix codes are good candidates among RGC for replacing RS codes but still with 7 times of the encoding costs when compared to systematic RS codes and more decoding time compared to RS codes BASIC Binary Addition and Shift Implementable Convolutional codes is proposed in that can achie v e all the beneìt of RGC with only addition and shift operations involved in coding process The computational complexity of BASIC code is much less that of RGC The source pack ets of B ASIC codes can also be recovered using ZigZag decoding if we choose the encoding coefìcient which has the increasing difference property  In this paper we give construction of exact minimum storage BASIC codes A helper node needs no coding to repair a failure node the proposed codes are repair-by-transfer minimum storage BASIC codes A similar regenerating codes is presented in The differences of the codes in this paper and in are as follo ws First the operations in mixing the data packets are different Multiplication and addition are involved in while shift and addition are involved in this paper Second to reduce complexity the encoding coefìcient of in dif ferent nodes are the same but just shifted some positions The encoding coefìcient of the minimum storage BASIC codes in different nodes can be different and do not impact the complexity The paper is organized as follows In section II we will review some deìnitions and results of BASIC codes The construction of minimum storage BASIC codes is proposed in section III In section IV we evaluate the complexity of BASIC codes We implement the proposed minimum storage BASIC codes in section V and the results of simulation show that the proposed minimum storage BASIC codes outperform Cauchy Reed-Solomon codes which is widely used in practical storage systems in both repairing cost and decoding cost Finally we conclude with the main contributions and results of our paper in Section VI II BASIC C ODES A Deìnitions of BASIC Codes BASIC codes can achie v e the full beneìt of re generating codes with only shift and addition operations be involved in both encoding and decoding process Many expensive multiplications of nite eld can be avoided Similar to RGC there e xist an optimal tradeof f curv e between  and   We term codes that attain two extremal points of the best storage efìciency and the minimum repair bandwidth as minimum-storage MS BASIC codes and minimum-bandwidth MB BASIC codes respectively Two main versions of repair have been considered in exact repair and functional repair In exact repair the failed data packets are exactly regenerated thus restoring exactly the lost encoded packets with their exact replicas In functional repair the requirement is relaxed the newly generated packets can contain different data from that of the failed node as long as the repaired system maintains the MDS property We term BASIC codes with exact repair functional repair as exactBASIC codes and functional-BASIC codes respectively B Design Framework In the encoding process of BASIC codes the source data le is divided into B data packets with size L bits Similar to  we represent the bits of a pack et by the coef cients of a formal power series p.154 A formal po wer series o v e r GF 2 is a formal sum   j 0 c j z j  c 0  c 1 z  c 2 z 2  c 3 z 3   where z is an indeterminate and c j are elements in GF 2 By a node stores a power series we mean that the coefìcients of the power series are stored In practice the number of bits stored in a node is nite and the power series is a polynomial with nitely many non-zero coefìcients There is no convergence issue in formal power series because a formal power series can be regarded as an inìnite sequence of bits  c 0 c 1 c 2 c 3    with the indeterminate z being the right shift operator The addition of two inìnite sequences  c j   j 0 and  d j   j 0 are performed componentwise and the multiplication is deìned by convolution  c j   j 0   d j   j 0  e j   j 0 with e j  j   0 c  d j    The set of all formal power series thus form a commutative ring with identity and is denoted by GF 2 z   For i 1  2   k  we denote the k data packets as s i  z   Deìne a coded packet as a linear combination of the data packets with coefìcients which is either 0 or a power of z  The coded packet is obtained by shifting the power series to the right appropriately and adding the resulting power series 34 


For i 1  2   n  a coded packet is denoted by p i  z  that can be written in the form p i  z  c i 1  z  s 1  z  c i 2  z  s 2  z    c i,k  z  s k  z   where c i,j  z  belongs to a subset of GF 2 z  that the element of the subset is either 0 or a power of z  and denote this subset as C  When c i,j  z  is nonzero the exponent of c i,j  z  stand for the number of added bits at the head of the packet s j  z  for the coded packet p i  z   The encoding is completely speciìed by c i,j  z  for i 1  2 n and j 1  2 k  We deìne the encoding matrix E as the n  k matrix whose  i j  entry is equal to c i,j  z   If we put the coded packets together in a column vector we have      p 1  z  p 2  z     p n  z        E       s 1  z  s 2  z     s k  z        We say that the MDS property is satisìed if we can recover the data packets s 1  z   s 2  z    s k  z  from any k coded packets in  p 1  z  p 2  z    p n  z    Example Let k 3  n 6  There are three data packets s 1  z   s 2  z  and s 3  z   The coded packets are deìned as p 1  z  s 1  z  p 2  z  s 2  z  p 3  z  s 3  z  p 4  z  zs 1  z  s 2  z  s 3  z  p 5  z  s 1  z  zs 2  z  s 3  z  p 6  z  s 1  z  s 2  z  zs 3  z   The corresponding encoding matrix of the coded packets is E          100 010 001 z 11 1 z 1 11 z          1 Proposition 1  Suppose that s 1  z  to s k  z  are data packets and p 1  z  to p n  z  are n coded packets with global encoding vectors v 1 to v n  respectively Let  i 1 i 2   i k  be any subset of  1  2   n  and D be the sub-matrix of E obtained by retaining rows i 1 to i k  Then we can compute s 1  z  to s k  z  from the k coded packets p i 1  z  p i 2  z    p i k  z  if the determinant of D is nonzero Proof We give a sketch of proof for the sake of completeness Write det D  as z e 1  f  z   where e is a non-negative integer and f  z  is a polynomial with zero constant term The inverse of 1 f  z  is 1 f  z  f  z  2  f  z  3    which is considered as a formal power series Recall that the adjoint of D  denoted by adj  D   is deìned as the transpose of the matrix of cofactors of D  p.20 W e get      s 1  z  s 2  z     s k  z        1 f  z  f  z  2    z e  adj  D        p i 1  z  p i 2  z     p i k  z        Note that the power series in the numerator is the multiplicative inverse of 1 f  z  in GF 2 z   and is well-deìned because each coefìcients can be obtained with nitely many arithmetic operations Conversely if det D   then the rank of D is strictly less than k  Hence we can not solve for s 1  z  to s k  z   For example the determinant of all 3  3 sub-matrices of the encoding matrix E in 1 are 1 z  z 1  z 2 1  z 3  z  and are all nonzero Hence this matrix satisìes the MDS property III C ONSTRUCTION OF MS-BASIC C ODES It is shown in that if we can construct an  n  k  d  optimal regenerating code with  1  then we can construct an  n k d  optimal regenerating code with integer  1 To simplify the system implementation we can assume  1  Then  MS  d  k 1  2 B MS  k  d  k 1  3 A Code Construction An  n k d  MS-BASIC code is composed of n storage nodes denoted by  N 1 N 2   N n   and satisfying the following two conditions  d  k 1   B  n  Therefore by equation 3 they will also satisfy that  MS 2 and B  n 2 k  The encoding of MS-BASIC codes are as follows  Fragment the le into B  n data packets s 1  z  s 2  z    s n  z  equally term these original packets as data packets  Construct n parity-check packets p 1  z  p 2  z    p n  z  by p i  z  k  i  j  i 1 c i,j  z  s j  z  i 1  2   n 4  Store  s i  z  p i  z  in the node N i for i 1  2   n  Where the addition in 4 is mod n addition In the above encoding process c i,j  z  is chosen in the set C such that the encoding matrix of any k nodes satisìes MDS property The coded packets mentioned in the section II include data packets and parity-check packets In general the parity-check packets are generated by 4 35 


B Node Regeneration A failed node can be repaired by the following two steps 1 Download the data packets from the next k nodes in the sequence Note that the next node of N n is N 1  From these data packets the parity-check packet of the newcomer can be calculated 2 Download the parity-check packet from the previous node in the sequence Solving an easy system of equations the data packet of the newcomer can be obtained It is clear that MS-BASIC codes achieve bandwidth optimality for parameter d  k 1 and B  n  by equations 2 and 3 Moreover note that the failed node have to be regenerated by a speciìc subset of d  k 1 nodes not any d nodes C Data Reconstruction We can check that a DC can reconstruct the original object by downloading two packets of any k storage nodes For any k nodes we can retrieve k data packets and k parity-check packets which a linear combination of k data packets The other k data packets can be retrieved using the method of Proposition 1 from k parity-check packets Of course we can also retrieve the other k data packets using the ZigZag decoding method if the corresponding encoding coefìcients satisfy the increasing difference property Ho we v e r  if the encoding coefìcients do not satisfy the increasing difference property the ZigZag decoding method does not work D Example In this subsection we will describe the construction of a 6 3 4 MS-BASIC code First the le is fragmented into B  n 6 data packets s 1  z  s 2  z    s 6  z   Then two packets s i  z  and p i  z  are stored in node N i  where p i  z  is computed using the following form p i  z  3 i  j  i 1 c i,j  z  s j  z  i 1  2    6  and c i,j  z  is given as  c 1  2  z  c 1  3  z  c 1  4  z   c 4  5  z  c 4  6  z  c 4  1  z    z 0 z 1 z 2    c 2  3  z  c 2  4  z  c 2  5  z   c 5  6  z  c 5  1  z  c 5  2  z    z 0 z 2 z 1    c 3  4  z  c 3  5  z  c 3  6  z   c 6  1  z  c 6  2  z  c 6  3  z    z 0 z 0 z 0   For 6 3 4 MS-BASIC code we can repair one failure node by connecting to 4 nodes and downloading one packet from each of 4 helping nodes The repairing process of node 1 is showed in Fig 1 The new node download 4 packets s 2  z   s 3  z   s 3  z   and s 1  z  s 2  z  s 3  z  from nodes 2 3 4 and 6 respectively The two stored packets of node 1 s 1  z  s 2  z  zs 3  z   z 2 s 4  z  N 1 N 2 N 3 N 4 N 5 N 6 s 2  z  s 3  z  s 4  z  s 5  z  s 6  z  s 3  z  z 2 s 4  z  zs 5  z  s 4  z  s 5  z   s 6  z  s 5  z  zs 6  z   z 2 s 1  z  s 6  z  z 2 s 1  z  zs 2  z  s 1  z  s 2  z   s 3  z  z z 2 s 1  z  s 2  z  zs 3  z   z 2 s 4  z  New node Fig 1 The distribution of data packets and redundancy packets of 6 3 4 MS-BASIC code The new node can download 4 packets s 2  z   s 3  z   s 3  z   and s 1  z  s 2  z  s 3  z  and add some shifted packets to repair node 1 can be regenerated by some simple additions and right-shifts of 4 downloaded packets The parity-check packet of node 1 s 2  z  zs 3  z  z 2 s 4  z  can be repaired by adding the data packet s 2  z   one-shift data packet s 3  z  and two-shift data packet s 4  z   The data packet s 1  z  can be repaired by the following equation s 1  z   s 1  z  s 2  z  s 3  z   s 2  z  s 3  z   We can check that a DC can reconstruct the original object by downloading two packets from any 3 storage nodes Suppose a DC connects to nodes 1 2 and 3 and download 3 data packets s 1  z   s 2  z   s 3  z  and 3 parity-check packets s 2  z  zs 3  z  z 2 s 4  z   s 3  z  z 2 s 4  z  zs 5  z   s 4  z  s 5  z  s 6  z   One can retrieve z 2 s 4  z  by adding s 2  z   one right-shift of s 3  z  and s 2  z  zs 3  z  z 2 s 4  z   and we can get the data packet s 4  z  by shifting two bits of z 2 s 4  z   The other data packets s 5  z  and s 6  z  can also be decoded similarly IV O VERHEAD R ATIO AND C OMPLEXITY Due to bitwise shifting the length of the coded packet is L plus the maximal degree of the global encoding coefìcients The maximal degree r of the coefìcients is thus the storage overhead The size of each packet in  n k d  MS-BASIC codes is p  L  r bits where r is the maximal degree This overhead is negligible when the packet size L is large In  n k d  MS-BASIC codes each node stores one data packet and one parity-check packet Each parity-check packet is a linear combination of k data packets which requires k  1 additions of p bits So the encoding computational complexity of  n k d  MS-BASIC codes is O  nkp   In the repairing process of  n k d  MS-BASIC codes both the data packet and the parity-check packet can be regenerated by summing k packets So the repairing process needs 2 k 36 


additions of p bits The repairing computational complexity of  n k d  MS-BASIC codes is O  kp   If DC connects to k consecutive nodes each parity-check packet can be retrieved by adding k packets and there are k parity-check packets The complexity of decoding k consecutive nodes is O  k 2 p  Ifthe k nodes are not continuous to reconstruct the original le DC rst need to compute the inverse matrix of the encoding matrix then multiply the inverse matrix by the coded packets Compared to the computing time of large amounts of data the time of compute the inverse matrix is very small and we do not consider it The multiplication of the inverse matrix and k parity-check packets takes O  k 2  additions Therefore the complexity of  n k d  MS-BASIC codes is O  k 2 p   Remarks It is more convenient to perform byte-wise shift instead of bit-wise shift Also it is not necessary to physically shift the bits in the memory By creating pointers to the data bits the shifting operations are performed by simply incrementing the pointers V E VALUATION Cauchy Reed-Solomon CRS codes were proposed by Blomer et al  in 1995 to improve the performance of encoding complexity using Cauchy distribution matrix Since then CRS codes are widely used in communication and storage systems To evaluate the practicality of the proposed MS-BASIC codes in this section we provide details on the experiments we performed to evaluate the performances of MS-BASIC codes and CRS codes There are many versions of implementation of CRS codes and Jerasure library is considered to be one of the most practical version that can achieve the optimal encoding performance We select this implementation version of CRS codes and select the word size of CRS codes to be 16 bits The machine for testing has a 1GHz single-core processor 1GB of RAM and 20GB of Hard Disk It runs CentOS Linux version 5.6 on VMware Workstation All the experiments have been done for two different les of 78.4MByte and 440MByte in size respectively with the parameters  n k  to be 6 12 8 16 and 10 20 respectively In total three experiments encoding time repairing time and decoding time were performed on the above setup Each data point in the graphs that follow is the average of ve runs A Encoding Time In the encoding process of MS-BASIC codes a data le of M bits is rst divided into n data packets each of M  n bits we assume M is divisible by n  Then we generate n paritycheck packets according to 4 Each of n nodes stores one data packet and one parity-check packet For CRS codes the data le of M bits is divided into many pieces each of kw bits Then divide each piece into k data packets with the same size w bits Each k data packets can be used to generate n  k parity-check packets Each node will store one packet for each piece Note that the n  k paritycheck packets generated by CRS codes using a  n  k   k Cauchy distribution matrix that is deìned over the Galois Field GF 2 w   The  n  k   k Cauchy distribution matrix over GF 2 w  is next converted into a w  n  k   wk binary distribution matrix using a projection deìned by a primitive polynomial of GF 2 w   Fig 2 displays the encoding process of parity-check packets for CRS codes with n 6  k 4 and w 3  With binary distribution matrix one may create a parity-check packet as the XOR of all data packets whose corresponding columns of the binary distribution matrix have ones Note that the expensive matrix multiplication is replaced by binary addition So this is a great improvement over standard RS codes For more information about the encoding and decoding process of CRS codes we refer the reader to The encoding performance of CRS codes and Fig 2 The encoding process of parity-check packets of CRS codes with k 4  n 6 and w 3  MS-BASIC codes shows in Fig 3 The results of Fig 3 show that MS-BASIC codes outperform CRS codes in encoding performance for le size of both 78.4MB and 440MB The encoding time of CRS is roughly two times of the encoding time of MS-BASIC codes for all the evaluated parameters and les   12, 6 16, 8 20, 10 0 20 40 60 80 Parameters \(n, k Encoding time CRS, 78.4MB MS BASIC, 78.4MB CRS, 440MB MS BASIC, 440MB Fig 3 The encoding time of MS-BASIC codes and CRS codes for data le size 78.4MB and 440MB with different parameters The encoding time of CRS codes is roughly two times of the encoding time of MS-BASIC codes 37 


B Repairing Time When there is a node fails MS-BASIC codes only need to download the amount of k 1  2 k M data to repair the failure node using some addition and shift operations For CRS codes the new node rst download M data to reconstruct the stored data le and then re-encode the lost packets The results of repairing performance of CRS codes and MS-BASIC codes show in Fig 4   12, 6 16, 8 20, 10 0 20 40 60 80 100 120 Parameters \(n, k Repairing time CRS codes, 78.4MB MS BASIC, 78.4MB CRS codes, 440MB MS BASIC, 440MB Fig 4 The repairing time of MS-BASIC codes and CRS codes for data le size 78.4MB and 440MB with different parameters The repairing time of CRS codes is greatly larger than that of MS-BASIC codes for all the tested parameters The performance repairing of CRS codes is worse than that of MS-BASIC codes as expected The repairing time of 10 20 CRS codes is about 20 times of that of MS-BASIC codes for le size 440MB C Decoding Time   12, 6 16, 8 20, 10 0 20 40 60 80 100 120 Parameters \(n, k Decoding time CRS, 78.4MB MS BASIC, 78.4MB CRS, 440MB MS BASIC, 440MB Fig 5 The decoding time of MS-BASIC codes and CRS codes for data le size 78.4MB and 440MB with different parameters The decoding time of CRS codes is greatly larger than that of MS-BASIC codes for all the tested parameters The decoding time of CRS codes and MS-BASIC codes shows in Fig 5 The decoding time of CRS codes is also larger than that of MS-BASIC codes for all the evaluated parameters and les The decoding time of 6 12 CRS codes is a little bigger than 10 times of the decoding time of MS-BASIC codes 6 12 for le size 440MB From the evaluation we see that MS-BASIC codes outperform CRS codes in both coding time and repairing time It makes MS-BASIC codes really competitive in practical distributed storage systems VI C ONCLUSION In this paper we give the construction of BASIC codes at the minimum storage point MS-BASIC codes need no coding with minimal I/O cost in the repairing process that is a repair-by-transfer code With the performance evaluation of CRS codes and MS-BASIC codes we show that MS-BASIC codes outperform CRS codes in both repairing cost and coding cost which makes MS-BASIC codes are very attractive in the coding of distributed storage systems R EFERENCES  H Hou K W  Shum M Chen and H Li B ASIC re generating code Binary addition and shift for exact repair in Proc IEEE Int Symp Inf Theory  Istanbul July 2013 pp 1621Ö1625  S Ghema w at H Gobiof f and S Leung The Google le system  i n ACM SIGOPS Operating Systems Review  vol 37 no 5 ACM 2003 pp 29Ö43  N Ellison C Steinìeld and C Lampe The beneìts of f acebook friends social capital and college students use of online social network sites Journal of Computer-Mediated Communication  vol 12 no 4 pp 1143Ö1168 2007  A Dimakis P  Godfre y  Y  W u  M  W ainwright and K Ramchandran Network coding for distributed storage systems IEEE Trans Inf Theory  vol 56 no 9 pp 4539Ö4551 September 2010  V  R Cadambe S A Jaf ar  and H Maleki Minimum repair bandwidth for exact regeneration in distributed storage in IEEE Wireless Network Coding Conference WiNC  IEEE 2010 pp 1Ö6  B Gast  on J Pujol and M Villanueva Quasi-cyclic minimum storage regenerating codes for distributed data compression in IEEE Data Compression Conference DCC  IEEE 2011 pp 33Ö42  K V  Rashmi N B Shah and P  V  K umar  Optimal e xact-re generating codes for distributed storage at the MSR and MBR points via a productmatrix construction IEEE Trans Inf Theory  vol 57 no 8 pp 5227 5239 2011  A Duminuco and E Biersack  A practical study of re generating codes for peer-to-peer backup systems in 29th International Conference on Distributed Computing Systems ICDCSê09 IEEE 2009 pp 376Ö384  F  Oggier and A Datta Self-repairing codes for distrib uted storagea projective geometric construction in IEEE Information Theory Workshop ITW  IEEE 2011 pp 30Ö34  H Hou H Li and K W  Shum General self-repairing codes for distributed storage systems in Proc IEEE Int Conf on Communications  Budapest June 2013 pp 1743Ö1747  S P a w ar  N  Noorshams E R S and K Ramchandran Dress codes for the storage cloud Simple randomized constructions in Proc IEEE Int Symp Inf Theory  Saint-Petersburg July 2011 pp 2338Ö2342  S Jiekak A K ermarrec and N Le Scouarnec Re generating codes A system perspective arXiv preprint arXiv:1204.5028v2  2012  C W  Sung and X Gong  A zigzag-decodable code with the mds property for distributed storage systems in Proc IEEE Int Symp Inf Theory  Istanbul July 2013 pp 341Ö345  T  W  Hungerford Algebra  2nd ed New York Springer-Verlag 1974  R A Horn and C R Johnson Matrix analysis  Cambrdige Cambridge University Press 1985  J Bloemer  M  K alf ane R Karp M Karpinski M Luby  and D Zuckerman An XOR-based erasure-resilient coding scheme 1995  J S Plank Optimizing Cauchy Reed-Solomon codes for f ault-tolerant storage applications University of Tennessee Tech Rep CS-05-569  2005 38 


100 1000 None 10 Test Data Accuracy Rotation interval 95 93 96 94 Seven Subsets \(Scenario 1 Use of only D 1 Seven Subsets \(Scenario 2   Figure 9  Results on the Page-blocks data with ten attributes \(Setting 1 100 1000 10 Test Data Accuracy 92 88 86 90 94 Rotation interval Seven Subsets \(Scenario 1 Use of only D 1 Seven Subsets \(Scenario 2 None  Figure 10  Results on the Segment data with 19 attributes \(Setting 1 100 1000 10 Test Data Accuracy 86 82 80 84 88 Rotation interval None Seven Subsets \(Scenario 1 Use of only D 1 Seven Subsets \(Scenario 2  Figure 11  Results on the Satimage data with 36 attributes \(Setting 1 C  Experimental Results from Setting 2 In the second setting D 1 has no missing attribute while about n 6 attributes are missing in the other six data subsets Similar results are obtained from the first and second settings for the phoneme data with five attributes since the number of missing attributes is one in both settings. Figs. 12-14 show experimental results on the other data sets in Setting 2 Since much more attributes are missing in Figs. 12-14 i.e., two in Fig. 12, four in Fig. 13, and six in Fig. 14\han Figs. 9-11 with a single missing attribute, positive effects of using all the seven data subsets decrease from Figs. 9-11 to Figs. 12-14. However, better results are still obtained by the use of all the seven data subsets \(black and red open circles than the use of D 1 blue closed circles\gs. 12-14 100 1000 10 Test Data Accuracy Rotation interval 95 93 96 None 94 Seven Subsets \(Scenario 1 Use of only D 1 Seven Subsets \(Scenario 2  Figure 12  Results on the Page-blocks data with ten attributes \(Setting 2 100 1000 10 Test Data Accuracy 92 88 86 90 94 Rotation interval None Seven Subsets \(Scenario 1 Use of only D 1 Seven Subsets \(Scenario 2  Figure 13  Results on the Segment data with 19 attributes \(Setting 2 100 1000 10 Test Data Accuracy 86 82 80 84 88 Rotation interval None Seven Subsets \(Scenario 1 Use of only D 1 Seven Subsets \(Scenario 2  Figure 14  Results on the Satimage data with 36 attributes \(Setting 2 One interesting observation in Figs. 12-14 is that better results are obtained in many cases from Scenario 2 than Scenario 1. This may be because new fuzzy rules are always generated from D 1 with no missing attributes in Scenario 2 In Scenario 1, new fuzzy rules are generated from D 1 with no missing attributes and also from the other six data subsets D i   i  2, 3, ..., 7\th missing attributes V  C ONCLUSION  In this paper, we examined the potential usefulness of our parallel distributed fuzzy GBML algorithm for fuzzy rulebased classifier design from multiple data sets with different missing attributes. We also examined its potential usefulness under the assumption of the severe privacy preserving policy where data sets were handled as black-box data sets. More 69 


specifically, we assumed that a black-box data set was used only for calculating the error rate of each classifier. No other information \(e.g., attribute values of each pattern, its true class, and its classification result\ were available In our computational experiments, we divided training patterns into seven data subsets: one complete data subset with no missing attributes and six incomplete data subsets with different missing attributes. We observed that classifier performance was improved by the use of all the seven data subsets in comparison with the use of only the complete data subset. This improvement was also observed even when the six incomplete data subsets were black-box data sets It was always assumed in our computational experiments that one data subset was fully available. It is an interesting future research issue to examine the learning from multiple data subsets where no data subsets are fully available \(i.e., all data subsets have different missing attributes and the severe private preserving policy\ch a difficult situation, more sophisticated handling of missing values may be needed since all data subsets have missing attributes. More efficient evolutionary learning may be also needed since we cannot generate fuzzy rules directly from training patterns R EFERENCES  1  R. Agrawal and R. Srikant, ìPrivacy-preserving data mining Proc of the 2000 ACM SIGMOD International Conference on Management of Data pp. 439-450, Dallas, May 15-18, 2000. DOI: 10.1145 342009.335438 2  Y. Lindell and B. Pinkas, ìPriva cy preserving data mining Proc. of the 20th Annual International Cryptology Conference \(LNCS 1880 Advances in Cryptology - CRYPTO 2000 pp. 36-54, Santa Barbara August 20-24, 2000. DOI: 10.1007/3-540-44598-6_3 3  Y. Lindell and B. Pinkas, ìPrivacy preserving data mining Journal of Cryptology vol. 15, no. 3, pp. 177-206, June 2002. DOI 10.1007 s00145-001-0019-2 4  V. S. Verykios, E. Bertino, I. N. Fovin, L. P. Provenza, Y. Saygin and Y. Theodoridis, ìState-of-the-art in privacy preserving data mining Sigmod Record vol. 33, no. 1, pp. 50-57, March 2004. DOI 10.1145/974121.974131 5  M. Kantarcioglu and C. Clifton, ìPrivacy-preserving distributed mining of association rules on horizontally partitioned data IEEE Trans. on Knowledge and Data Engineering vol. 16, no.9, pp. 10261037, September 2004. DOI: 10.1109/TKDE.2004.45 6  J. Vaidya and C. Clifton, ìPrivacy preserving association rule mining in vertically partitioned data Proc. of the 8th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining  pp. 639-644, Edmonton, July 23-25, 2002. DOI: 10.1145 775047.775142 7  A. Fern·ndez, S. GarcÌa, J. Luengo, E. BernadÛ-Mansilla, and F Herrera, ìGenetics-based machine learning for rule induction: State of the art, taxonomy, and comparative study IEEE Trans. on Evolutionary Computation vol. 14, no. 6, pp. 913-941, December 2010. DOI: 10.1109/TEVC.2009.2039140 8  S. GarcÌa, A. Fern·ndez, J. Luengo, and F. Herrera, ìA study of statistical techniques and performance measures for genetics-based machine learning: Accuracy and interpretability Soft Computing  vol. 13, no. 10, pp. 959-977, August 2009 DOI: 10.1007/s00500008-0392-y  9  J. Bacardit and N. Krasnogor, ìPerformance and efficiency of memetic Pittsburgh learning classifier systems Evolutionary Computation vol. 17, no. 3, pp. 307-342, Fall 2009. DOI: 10.1162 evco.2009.17.3.307 10  M. A. Franco, N. Krasnogor and J. Bacardit, ìGAssist vs. BioHEL critical assessment of two paradigms of genetics-based machine learning,î Soft Computing, vol. 17, no. 6, pp. 953-981, June 2013 DOI: 10.1007/s00500-013-1016-8 11  F. J. Berlanga, A. J. Rivera, M J. del Jesus, and F. Herrera, ìGPCOACH: Genetic Programming-based learning of COmpact and ACcurate fuzzy rule-based classification systems for Highdimensional problems Information Sciences vol. 180, no. 8, pp 1183-1200, April 2010. DOI:10.1016/j.ins.2009.12.020 12  J. Alcal·-Fdez, R. Alcal·, and F. Herrera, ìA fuzzy association rulebased classification model for high-dimensional problems with genetic rule selection and lateral tuning IEEE Trans. on Fuzzy Systems vol. 19, no. 5, pp. 857-872, October 2011. DOI: 10.1109 TFUZZ.2011.2147794 13  J. A. Sanz, A. Fern·ndez, H. Bustince, and F. Herrera, ìIVTURS: a linguistic fuzzy rule-based classification system based on a new Interval-Valued fuzzy reasoning method with TUning and Rule Selection IEEE Trans. on Fuzzy Systems In Press. Available from http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=6420926 DOI: 10.1109/TFUZZ.2011.2147794 14  F. Herrera, ìGenetic fuzzy systems: Taxonomy, current research trends and prospects Evolutionary Intelligence vol. 1, no. 1, pp. 2746, March 2008. DOI: 10.1007/s12065-007-0001-5 15  H. Ishibuchi and Y. Nojima, ìAnalysis of interpretability-accuracy tradeoff of fuzzy systems by multiobjective fuzzy genetics-based machine learning International Journal of Approximate Reasoning  44 \(1\ 2007. DOI: 10.1145/775047.775142 16  M. Fazzolari, R. Alcal·, Y. Nojima, H. Ishibuchi, and F. Herrera, ìA review of the application of multiobjective evolutionary fuzzy systems: Current status and further directions IEEE Trans. on Fuzzy Systems vol. 21, no. 1, pp. 45-65, February 2013. DOI: 10.1109 TFUZZ.2012.2201338 17  Y. Nojima, H. Ishibuchi, and I. Kuwajima, ìParallel distributed genetic fuzzy rule selection Soft Computing vol. 13, no. 5, pp. 511519, March 2009. DOI: 10.1007/s00500-008-0365-1 18  H. Ishibuchi, S. Mihara, and Y. Nojima, ìParallel distributed hybrid fuzzy GBML models with rule set migration and training data rotation IEEE Trans. on Fuzzy Systems vol. 21, no. 2, pp. 355-368 April 2013. DOI: 10.1109/TFUZZ.2012.2215331 19  E. Alba and M. Tomassini, ìParallelism and evolutionary algorithms IEEE Trans. on Evolutionary Computation vol. 6, no. 5 pp. 443-462, October 2002. DOI: 10.1109/TEVC.2002.800880 20  S. Cahon, N. Melab, and E. G. Talbi, ìParadisEO: A framework for the reusable design of parallel and distributed metaheuristics Journal of Heuristics vol. 10, no. 3, pp. 357-380, May 2004. DOI 10.1023/B:HEUR.0000026900.92269.ec 21  H. Ishibuchi, T. Yamamoto, and T. Nakashima, ìHybridization of fuzzy GBML approaches for pattern classification problems IEEE Trans. on Systems, Man, and Cybernetics - Part B vol. 35, no. 2, pp 359-365, April 2005. DOI: 10.1109/TSMCB.2004.842257 22  H. Ishibuchi and T. Nakashima, ìEffect of rule weights in fuzzy rulebased classification systems IEEE Trans. on Fuzzy Systems vol. 9 no. 4, pp. 506-515, August 2001. DOI: 10.1109/91.940964 23  H. Ishibuchi and T. Yamamoto, ìRule weight specification in fuzzy rule-based classification systems IEEE Trans. on Fuzzy Systems vol 13, no. 4, pp. 428-435, August 2005. DOI: 10.1109/TFUZZ.2004 841738 24  H. Ishibuchi, K. Nozaki, and H. Tanaka, ìDistributed representation of fuzzy rules and its application to pattern classification Fuzzy Sets and Systems vol. 52, no. 1, pp. 21-32, November 1992. DOI 10.1016/0165-0114\(92\90032-Y 25  J. Alcal·-Fdez, L. S·nchez, S. GarcÌa, M. J. del Jesus, S. Ventura, J M. Garrell, J. Otero, C. Romero, J. Bacardit, V. M. Rivas, J. C Fern·ndez, and F. Herrera, ìKEEL: A software tool to assess evolutionary algorithms for data mining problems Soft Computing  vol. 13, no. 3, pp. 307-318, February 2009. DOI: 10.1007/s00500008-0323-y  70 


Copyright © 2009 Boeing. All rights reserved  Architecture Server-1 Server-2 DB2 SURVDB XML Shredder WebSphere Message Broker Ext.4 H Ext.3 G Ext.2 F Ext.1 E C WebSphere MQ TCP/IP Live ASDI Stream IBM Cognos Server-3 IBM SPSS Modeler SPSS Collaboration Deployment Services 


Copyright © 2009 Boeing. All rights reserved  Database Modeling Schemas for correlated ASDI messages translated into equivalent relational schemas  Database tables generated based on classes created from schema definitions  Nine main, eleven supporting tables  Each main table contains FLIGHT_KEY 


Copyright © 2009 Boeing. All rights reserved  Database Modeling 


Copyright © 2009 Boeing. All rights reserved  Correlation Process To archive received ASDI data  Track messages must be correlated with flight plan messages FLIGHT_KEY assigned Uncorrelated data tagged Approx 30 minutes to correlate one day of data 


Copyright © 2009 Boeing. All rights reserved  Historical Data Processing To load correlated data  Uncompress, unmarshall  Create a list of files containing the correlated data  Write data to warehouse 


Copyright © 2009 Boeing. All rights reserved  Live Data Processing Processed using IBM MQ IBM Message Broker and a technique called XML Shredding Message Broker Compute Nodes  Uncompress Node  Extract correlated messages  Shred Node adds to DB Stored Procedure ìshreds XML docs and adds to tables 


Copyright © 2009 Boeing. All rights reserved  Issues and Observations Initial load of one day of data ~ 7 hours Optimizations  Write data in batches  Use a mutable data structure to create data strings  Deploy a higher performance machine  Use load instead of insert  Use DB2 Range-Partitioned tables  Database tunings Time reduced from 7 hours to approx 30 minutes 


Copyright © 2009 Boeing. All rights reserved  Optimizations Use a mutable data structure to create data strings  Original application created the SQL statement by appending elements to a Java String  It was taking five hours \(of the seven hours Strings  Instead Java StringBuilder used  Java Strings immutable  Time savings of 71.4 


Copyright © 2009 Boeing. All rights reserved  Optimizations Deployed on a higher-performance machine  Application ported from IBM Blade Center HS21 \(4GB of RAM and 64-bit dual-core Xeon 5130 processor to Dell M4500 computer \(4GB of RAM and 64-bit of quad-core Intel Core i7 processor  Reduced the time to thirty minutes Bulk loading instead of insert  Application was modified to write CSV files for each table  Entire day worth of data bulk loaded  Reduced the time to fifteen minutes 


Copyright © 2009 Boeing. All rights reserved  Optimizations Range-Partitioned tables \(RPT  To limit the size of tables, the original code created multiple tables per table type  This puts burden on the application to query multiple tables when a range crosses several tables  With RPT, user is not required to make multiple queries when a range crosses a table boundary  Increased the time to thirty minutes  Additional fifteen minute cost per day of partitioning enabled time savings during queries 


Copyright © 2009 Boeing. All rights reserved  Optimizations Database tunings  Range periods changed from a week to a month  Automatic table space resizing changed from 32MB to 512KB  Buffer pool size decreased  Decreased the time to twenty minutes Overall, total time savings of 95.2 


Copyright © 2009 Boeing. All rights reserved  20 IBM Confidential Analytics Landscape Degree of Complexity Competitive Advantage Standard Reporting Ad hoc reporting Query/drill down Alerts Simulation Forecasting Predictive modeling Optimization What exactly is the problem What will happen next if What if these trends continue What could happen What actions are needed How many, how often, where What happened Stochastic Optimization Based on: Competing on Analytics, Davenport and Harris, 2007 Descriptive Prescriptive Predictive How can we achieve the best outcome How can we achieve the best outcome including the effects of variability Used with permission of IBM 


Copyright © 2009 Boeing. All rights reserved Initial Analysis Activities Flights departing or arriving on a date Flights departing or arriving within a date and time range Flights between city pair A,B Flights between a list of city pairs Flights passing through a volume on a date. \(sector, center, etc boundary Flights passing through a volume within a date and time range Flights passing through an airspace volume in n-minute intervals All x-type aircraft departing or arriving on a date Flights departing or arriving on a date between city pair A,B Flights departing or arriving on a date between a list of city pairs Flights passing through a named fix, airway, center, or sector Filed Flight plans for any of the above Actual departure, arrival times and actual track reports for any of the above 


Copyright © 2009 Boeing. All rights reserved  Initial SPSS Applications Show all tracks by call sign 


Copyright © 2009 Boeing. All rights reserved  Predictive / Prescriptive Analytics Use-Case For a given Airspace Volume of Interest \(AVOI compute distinct traffic volume at some point in the future  Aim to alert on congestion due to flow control areas or weather if certain thresholds are exceeded  Prescribe solution \(if certain thresholds are exceeded Propose alternate flight paths  Use pre-built predictive model  SPSS Modeler performs data processing Counts relevant records in the database \(pattern discovery Computes traffic volume using statistical models on descriptive pattern Returns prediction with likelihood 


Copyright © 2009 Boeing. All rights reserved  Predictive / Prescriptive Analytics Use-Case Advanced Arrival Procedures with Active Abatement Potentials   9/23/10  24 Pulls in the TRACKINFO table of MAIN using SQL Limits the data to database entries which fall inside the AVOI Combines the SOURCE_DATE and SOURCE_TIME to a timestamp that can be understood by modeler Computes which time interval the database entry falls in. The time interval is 15 minutes Defines the target and input fields needed for creating the model Handles the creation of the model Produces a graph based off of the model results Final prediction 


Copyright © 2009 Boeing. All rights reserved  Initial Cognos BI Applications IBM Cognos Report Studio  Web application for creating reports  Can be tailored by date range, aircraft id, departure/arrival airport etc  Reports are available with links to visuals IBM Framework Manager  Used to create the data package  Meta-data modeling tool  Users can define data sources, and relationships among them Models can be exported to a package for use with Report Studio 


Copyright © 2009 Boeing. All rights reserved  Flights Departing Las Vegas on Jan 1, 2012 1 of 3 Report shows the departure date, departure and arrival locations and hyperlinks to Google Map images DeparturePosition and ArrivalPosition are calculated data items formatted for use with Google Maps Map hyperlinks are also calculated based on the type of fix 


Copyright © 2009 Boeing. All rights reserved  Flights Departing Las Vegas on Jan 1, 2012 2 of 3 DeparturePosition, Departure Map, ArrivalPosition and Arrival Map are calculated data items \(see departure items below DepartureLatitude DepartureLongitude DeparturePosition Departure Map 


Copyright © 2009 Boeing. All rights reserved  Flights Departing Las Vegas on Jan 1, 2012 3 of 3 


Copyright © 2009 Boeing. All rights reserved  Conclusion and Next Steps Current archive is 50 billion records and growing  Approximately 34 million elements per day  1GB/day Sheer volume of raw surveillance data makes analytics process very difficult The raw data runs through a series of processes before it can be used for analytics Next Steps  Continue application of predictive and prescriptive analytics  Big data visualization 


Copyright © 2009 Boeing. All rights reserved  Questions and Comments Paul Comitz Boeing Research & Technology Chantilly, VA, 20151 office Paul.Comitz@boeing.com 


Copyright © 2009 Boeing. All rights reserved Advanced Arrival Procedures with Active Abatement Potentials   9/23/10  31 


Copyright © 2009 Boeing. All rights reserved Advanced Arrival Procedures with Active Abatement Potentials   9/23/10  32 Backup Slides 


Copyright © 2009 Boeing. All rights reserved  Initial Approach Initial Investigations  Apache Solr/Lucene  Data Warehouse Evaluate Hadoop in the future 


Copyright © 2009 Boeing. All rights reserved  Using SOLR Uncompress Track Information Messages To use with Solr  Transforming track messages from their  original schema to Solr required building a ìkey, valueî list using an XSTL  Queries made against this list of ìkey, valueî pairs Transformation Process  One day of data ~ 4.5 hours Once transformation complete search/query performance very good Geo spatial queries using  unique query language 


Copyright © 2009 Boeing. All rights reserved  Representation Aviation data is frequently represented in more than one form 


