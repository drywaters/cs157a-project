Nearest Neighbour Regression Outperforms Model-based Prediction of Speciìc Star Formation Rate Kristoffer Stensbo-Smidt   Christian Igel   Andrew Zirm   Kim Steenstrup Pedersen   Department of Computer Science University of Copenhagen  Dark Cosmology Centre Niels Bohr Institute University of Copenhagen Abstract Data in astronomy is rapidly growing with upcoming surveys producing 30 TB of images per night Highly informative spectra are too expensive to measure for each detected object hence ways of reliably estimating physical properties from images alone are paramount The objective of this work is to test whether a big data ready k nearest neighbour regression can successfully estimate the speciìc star formation rate sSFR from colours of low-redshift galaxies The nearest neighbour algorithm achieves a root mean square error RMSE of 0.30 outperforming the state-of-the-art astronomical model achieving a RMSE of 0.36 Keywords machine learning astronomy nearest neighbour regression speciìc star formation rate I I NTRODUCTION The traditional workîow in astronomy has heavily relied on the analysis of single events Acquiring and processing data was slow and expensive and the resulting postprocessed data were often of low quality In the past decades however ever larger astronomical surveys such as the Sloan Digital Sky Survey SDSS have appeared which have led to an enormous amount of high-resolution and publicly available astronomical images The SDSS alone provides images of nearly 10 9 objects making astronomy enter a new big data era Even larger surveys will start collecting data soon The Large Synoptic Survey Telescope LSST is expected to produce 30 TB of images per night which need to be analysed in near real-time in order to trigger timecritical follow-up observations Thus efìcient large-scale data mining techniques are required Many astronomically interesting properties of an object can only be measured from a spectrum of its light A spectrum is roughly speaking the photon count at each wavelength of the received light and since each chemical element has a unique spectrum a lot of information can be extracted from the light of for instance a star or a galaxy see gure 1 Spectra of stars are very well understood but for galaxies containing stars gas and dust each contributing to the nal spectrum extracting relevant information is more difìcult To extract such information the individual contributions from stars gas and dust must be disentangled To this end astronomers build models These models simulate emission of light from stars from different populations at different ages adding in the contributions from gas and dust in the galaxy and in the intermediate space Comparing the resulting model spectra to the real spectrum then allows astronomers to extract relevant information about the galaxy One particular galactic property that we are concerned with in this study is the rate at which new stars are formed the star formation rate SFR The SFR is an important quantity to measure as it relates to the evolutionary history of a galaxy and it is most easily measured from the spectrum of the galaxy A derived measure often used by astronomers is the speciìc star formation rate sSFR which is the SFR normalised by the mass of stars in the galaxy Observation time is unfortunately a scarce resource and measuring a spectrum is very expensive and time consuming A much cheaper way to study the sky is to take images These images can contain thousands of objects and are usually acquired in multiple bandpass lters each spanning a range of the spectrum see gure 2 From these images it is possible to extract the intensity of an object in each lter and from the intensities one can extract the magnitude of the object in each lter Subtracting two magnitudes from each other effectively removes a bias parameter and the resulting value is known as a colour  The colours of an object can also be found from the spectrum itself the intensity of the object in a given lter is the product of the lter transmission with the spectrum integrated over all wavelengths The colours of an object are therefore linked to its spectrum and so should contain a signiìcant amount of information Against this background we study the potential of using a scalable machine learning approach to predict the sSFR from colour values obtained from galaxy images The next section brieîy describes the data and the current modelbased approach to sSFR calculation and prediction We then describe our machine learning approach Sections IV and V present experiments and results before we conclude Figure 1 Examples of well-resolved galaxies in the SDSS database 141 2013 IEEE International Conference on Big Data 978-1-4799-1293-3/13/$31.00 ©2013  IEEE 


 Figure 2 An example spectrum of a galaxy from the SDSS database black curve overlaid by the ve bandpass lters of SDSS The ve bands are termed u  g  r  i and z  They give rise to four colours which are the basis of our sSFR prediction II S TAR F ORMATION R AT E D ATA FROM THE S LOAN D IGITAL S KY S URVEY The data considered in this study come from Sloan Digital Sky Survey SDSS an astronomical survey that has been scanning the night sky since 2000 see gure 1 The SDSS provides photometric data images as well as spectroscopic data spectra of selected objects The photometric data are observed in ve bandpass lters spanning wavelengths from 3000 to 11 000  while the spectroscopic data span wavelengths from 3800 to 9200  see gure 2 The database currently contains images of 9  3  10 8 objects and spectra of 1  6  10 6 objects about half being galaxies Ground truth sSFR values for selected objects are also made available by SDSS The derivation of these values is described in the following see and 2 for details The SFR of a galaxy is measured from parts of its spectrum associated with newly formed stars These parts however are contaminated by contributions from both interand intragalactic gas and dust and a disentangling of these components is necessary To do so a library of  2  10 5 artiìcial model spectra are generated from simulations with varying physical parameters From these spectra the SFR and stellar mass and in turn the sSFR can be calculated To estimate the sSFR of a real galaxy its spectrum is compared to each of the model spectra The sSFRs of the models are then weighted based on the likelihood of the model spectra given the real spectrum resulting in a probability distribution for the sSFR From this distribution the nal sSFR of the galaxy is calculated as the expected sSFR If only photometric data are available estimation of the sSFR must rely on the magnitude of the galaxy in each bandpass lter The current state-of-the-art approach in this regard see follo ws the procedure outlined abo v e to a large extent a library of model spectra each associated with a particular set of physical parameters is generated but instead of using the spectra directly they are multiplied with the SDSS lter transmissions and integrated over all wavelengths to produce model magnitudes To estimate the sSFR of a real galaxy its photometric magnitudes are compared to the magnitudes of each model in the library The sSFRs of the models are then weighted based on the likelihood of the model magnitudes given the real magnitudes resulting in a probability distribution for the sSFR From this distribution the predicted sSFR of the galaxy is again calculated as the expected sSFR Data used in this study The data used in this study are a subset of SDSS Data Release 7 DR7 For each galaxy only the ve magnitudes we use the SDSS MODEL M AG magnitudes and the sSFR are considered The magnitudes have been subtracted from each other resulting in a fourvector representing the colours We only consider galaxies in SDSS that meet the following selection criteria  A spectrum is available that is a reliable ground truth sSFR is available  Magnitudes are larger than  9999 which indicates a failed magnitude estimation  SSFR is larger than  99 which indicates a failed sSFR estimation A sample of 694 894 galaxies meet these criteria For a small subset of 11 450 low-redshift galaxies within the selected sample we additionally have sSFR predictions obtained by the template-based modelling approach described above No additional selection criteria have been applied to this subset III P REDICTING THE SSFR U SING S IMPLE M ACHINE L EARNING T ECHNIQUES Measuring a spectrum of a galaxy is a time-consuming task so in order to take advantage of the enormous amounts of readily available astronomical data it is essential that one can reliably estimate physical properties from photometric data alone The template-based method as described in section II is however not a viable solution considering the rapidly growing amount of data Instead scalable machine learning techniques provide a promising solution to this problem The large data sets in astronomy require fast algorithms and it is therefore common to resort to very basic machine learning techniques For example nearest neighbour regression has been successfully applied to mining SDSS data for detecting distant quasars one of the most challenging tasks in astronomy In this work we use exact k nearest neighbour regression  k NN see for an o v ervie w o f e f cient scalable implementations to estimate the sSFRs for a set of galaxies using only their four colours computed from ve photometric magnitudes For a given input sample x  R 4  the k nearest neighbours within the training data are determined using the Euclidean distance The average sSFRs of the k neighbours is the predicted sSFR of x  The dimensionality of the feature 142 


space is very low and the training data set is sufìciently large making k NN regression a viable approach IV E XPERIMENTS We performed two experiments one comparing the machine learning with astrophysical modelling results and another assessing the approach on a larger subset of the SDSS database These experiments were conducted using the Shark machine learning library A Comparison with template-based model We compared the nearest neighbour approach with the template-based model described above on the subset of 11 450 galaxies for which results from the template-based model are available To asses the performance of the algorithm we used cross validation CV partitioning the data into 10 folds W e refer to this procedure as the outer CV For each of the 10 folds we independently determined a proper value of k  This was done using an inner 10-fold CV procedure splitting the available training fold from the outer CV We selected the k  1  3  5  25  with the lowest average inner CV test error This k was used to predict the sSFRs of the outer CVês validation data fold using the outer CVês training data fold To make the estimations by the k NN and the templatebased model comparable the predictions by the templatebased model were divided into the same 10 subsets as used in the outer CV of the k NN and the same statistics were calculated B Application to larger subset of SDSS In the previous experiments the k values chosen in the 10 model selection procedures were concentrated around k  21  however different values of k gave similar performance as long as k 15  In the second experiment we considered our full SDSS DR7 subset for which spectrum-based ground truth sSFRs are available We randomly selected 30 000 galaxies for training a 21-NN regression and used the remaining 664 894 galaxies for testing V R ESULTS For the rst experiment we report the average RMSEs and the standard deviations 1 over the 10 validation sets of the outer CV of the predictions by the k NN regression and the state-of-the-art template-based model compared to the ground truth sSFRs The template-based model achieved a RMSE of 0  36  0  01 on our data set while the k NN model achieved a RMSE of 0  30  0  01  The k NN model performs considerably better than the slower templatebased physically motivated model 1 The standard deviations should not be interpreted as strict conìdence intervals since the data folds in the CV procedure are not statistically independent   a k NN regression predictions b Template-based model predictions Figure 3 a Correlations between the sSFR prediction by our nearest neighbour regression and the ground truth referred to as the spectroscopic sSFR b Correlations between the sSFR prediction by template-based physically motivated model and the ground truth A visualisation of the correlations between the predictions of the two models and the ground truths is given in gure 3 The main difference between the predictions by the two models seems to be the position of the peak corresponding to low sSFRs while the k NN model overshoots a bit the template-based model undershoots considerably In the second experiment the k NN regression also achieved a RMSE of 0  30 on the larger more heterogeneous data set A visualisation of the correlations between the predictions of the k NN regression and the ground truths is given in gure 4 VI C ONCLUSIONS Increasingly larger astronomical surveys are leading to an enormous amount of high-resolution and publicly available astronomical images Many astronomically interesting properties of an object can however most reliably be measured from a spectrum of its light which is expensive to measure A much cheaper way to make astronomical discoveries is to use images directly Many physical properties can be 143 


  Figure 4 Correlations between the sSFR prediction by our nearest neighbour regression and the ground truth referred to as the spectroscopic sSFR estimated from these images though much less accurately than from a spectrum The large data sets demand more efìcient ways of estimating quantities than the current stateof-the-art model provides if we are to take advantage of the wealth of information hidden in the data This invites for applying scalable machine learning algorithms We exempliìed this by predicting the speciìc star formation rate sSFR of galaxies using a scalable machine learning approach which outperformed the state-of-the-art astronomical model On a small sample of low-redshift galaxies from the SDSS DR7 database nearest neighbour regression achieved a RMSE of 0  30 compared to 0  36 achieved by a template-based physically motivated model Applied to all galaxies with spectra and reliable colour and sSFR measurements in DR7 the error of our approach was 0  30  The proposed algorithm allows for screening large amounts of imaging data and for picking out samples for further analysis An advantage of the template-based model is of course the additional physical knowledge gained from simulating galaxies The higher accuracy achieved by the k NN model indicates however that the template-based model does not capture all the information available in the colours A CKNOWLEDGEMENTS KSS CI and KSP gratefully acknowledge support from The Danish Council for Independent Research  Natural Sciences through the project Surveying the sky using machine learning Funding for the SDSS and SDSS-II has been provided by the Alfred P Sloan Foundation the Participating Institutions the National Science Foundation the U.S Department of Energy the National Aeronautics and Space Administration the Japanese Monbukagakusho the Max Planck Society and the Higher Education Funding Council for England The SDSS Web Site is http://www.sdss.org The SDSS is managed by the Astrophysical Research Consortium for the Participating Institutions The Participating Institutions are the American Museum of Natural History Astrophysical Institute Potsdam University of Basel University of Cambridge Case Western Reserve University University of Chicago Drexel University Fermilab the Institute for Advanced Study the Japan Participation Group Johns Hopkins University the Joint Institute for Nuclear Astrophysics the Kavli Institute for Particle Astrophysics and Cosmology the Korean Scientist Group the Chinese Academy of Sciences LAMOST Los Alamos National Laboratory the Max-Planck-Institute for Astronomy MPIA the Max-Planck-Institute for Astrophysics MPA New Mexico State University Ohio State University University of Pittsburgh University of Portsmouth Princeton University the United States Naval Observatory and the University of Washington R EFERENCES  J Brinchmann S Charlot S D M White C T remonti G Kauffmann T Heckman and J Brinkmann The physical properties of star-forming galaxies in the low-redshift Universe Monthly Notices of the Royal Astronomical Society  vol 351 no 4 pp 1151Ö1179 2004  G Kauf fmann T  M Heckman D M Simon White S Char lot C Tremonti J Brinchmann G Bruzual E W Peng M Seibert M Bernardi M Blanton J Brinkmann F Castander I Cs·bai M Fukugita Z Ivezic J A Munn R C Nichol N Padmanabhan A R Thakar D H Weinberg and D York Stellar masses and star formation histories for 10 5 galaxies from the Sloan Digital Sky Survey Monthly Notices of the Royal Astronomical Society  vol 341 no 1 pp 33Ö53 2003  S Salim R M Rich S Charlot J Brinchmann B D Johnson D Schiminovich M Seibert R Mallery T M Heckman K Forster P G Friedman D C Martin P Morrissey S G Neff T Small T K Wyder L Bianchi J Donas Y.-w Lee B F Madore B Milliard A S Szalay B Y Welsh and S K Yi UV Star Formation Rates in the Local Universe The Astrophysical Journal Supplement Series  vol 173 no 2 pp 267Ö292 2007  K L Polsterer  P  Zinn and F  Giesek e Finding ne w highredshift quasars by asking the neighbours Monthly Notices of the Royal Astronomical Society  vol 428 no 1 pp 226Ö235 2013  A Andoni and P  Indyk Near Optimal Hashing Algorithms for Approximate Nearest Neighbor in High Dimensions in 2006 47th Annual IEEE Symposium on Foundations of Computer Science FOCSê06  vol 51 no 1 IEEE 2006 pp 459Ö468  C Igel V  Heidrich-Meisner  and T  Glasmachers Shark  Journal of Machine Learning Research  vol 9 pp 993Ö996 2008  T  Hastie R T ibshirani J Friedman and J Franklin The Elements of Statistical Learning Data Mining Inference and Prediction  2nd ed Springer 2009 144 


 
C Extraction data intelligence 
 
deeply extract space knowledge. By using such new knowledge, data can be processed in real time in order to understand and apply the data, to make intelligent judgments and well-informed decisions. Space knowledge can be selflearning, self-enhance, universal, and easily recognized. It could serve as a basis for decision support If businesses take full advantage of spatial knowledge, it will be more precise and dynamic for humans to learn, work life, and achieve wisdom state. It will help to improve resource utilization and productivity level. Moreover, it will also help to respond to the economic crisis, the energy crisis, the deterioration of the environment and many other global issues  Data intelligence is the ability to obtain a more innovative systematic and comprehensive knowledge to solve a particular problem through an in-depth analysis of the collected data. It is an ability to understand and solve problems fast, flexibly and correctly. Spatial data intelligent has three features: more thoroughly perception, more extensive interoperability, and deeper intelligence. The three features are aimed to get bigger and more comprehensive data,  to share and co-operate data via the Internet, to do data analysis and data mining by variety of advanced techniques, and to constitute a hierarchy of spatial data intelligences \(Fig. 3 35   More in-depth data intelligence is to create new value of data. On the one hand, when making full use of spatial data knowledge in all walks of life, it can produce secondary knowledge. In order to form a mining mechanism to mine knowledge in knowledge, it needs to bring primary knowledge together to form an intelligent form of expression. Ultimately the destination knowledge can be achieved. On the other hand based on a general industrial or socio-ecological system, it can redefine the interactive mode of government, companies and individuals, so that it improves the interaction clarity efficiency, flexibility and response speed. It changes from the traditional single dimension such as: production consumption management, or planning execution, to a new multidimensional collaborative relationship. In this new relationship both individuals and organizations can freely contribute and get information and expertise accurately and timely. This new relationship exerts a positive influence on each other to reach smart running macro-effects 40  Spatial data prompted the fusion of world's digital infrastructure and physical infrastructure. Almost anyone or anything can be connected to a digital network at low-cost. It is easy to embed sensors in a variety of ecosystems. It can be more sophisticated, dynamic management of production and life to achieve the smart status, through global infrastructure of equipment and devices, via the integration of human society and the physical system by Internet, with supercomputers and cloud computing. For example, space knowledge can be found through integrating the data from satellite positioning systems sensors, and wireless networks. , Spatial knowledge is then transferred to the mobile phone terminal, which helps users make reasonable judgment based on location services in order to achieve the intelligent data transformation into wisdom \(Fig 3\.  Firstly, the reality space world is thoroughly studied through the acquisition of spatial data from satellite positioning systems, sensors and wireless ne tworks. Secondly, the spatial data is stored and managed by appropriate method, in order to integrate into spatial information. Thirdly, a variety of spatial knowledge is extracted through purposefully data mining methods and mining model. Spatial knowledge is integrated to the new available knowledge, in order to reach deeper data intelligence. Finally, data intelligence is integrated into the digital earth and the "Internet of things", in order to enhance the wisdom of users and machines, and to achieve smarter real world data interaction 41-4    Figure 3 
Location-based data intelligences   
490 
490 
490 
490 


United Nations Global Pulse, 2012, Big Data for Development Challenges & Opportunities, May 2012 2 Office of Science and Technology Policy | Executive Office of the President, 2012, Fact Sheet: Big Data across the Federal Government March 29 9 2012 9 www.WhiteHouse.gov/OSTP 3 Office of Science and Technology Policy | Executive Office of the President, 2012, Obama Administration Unveils 003\014 Big Data 003\015 Initiative Announces $200 Million in New R&D Investments, March 29 9 2012 9 www.WhiteHouse.gov/OSTP 4 McKinsey Global Institute, 2011, Big Data: the Next Frontier for Innovation, Competition, and Productivity, May 2011 5 Rajaraman A, Ullman J D 9 Mining of Massive Datasets, Cambridge University Press, 2011 6 Grossner K, Goodchild M, Clarke K, Defining a digital earth system Transactions in GIS, 12\(1\: 145-160, 2008 7 Densham P J, Goodchild M F, Spatial decision support systems: A research agenda, In: Proceedings GIS/LIS'89, Orlando, FL., 1989, pp 707-716 8 Li D R, Wang S L, Li D Y, Theory and Application of Spatial Data Mining \(the fisrt edition\, Beijing 9 Science Press, 2006 9 Li D R, Wang S L, Li D Y, Theory and Application of Spatial Data Mining \(the second edition\, Beijing 9 Science Press, 2013  Ester M et al., Spatial data mining: databases primitives, algorithms and efficient DBMS support. Data Mining and Knowledge Discovery, 2000 4, 193-216  Miller H J, Han J, Geographic Data Mining and Knowledge Discovery the second edition\, London: Taylor and Francis, 2009  Schoier G., Borruso G., 2012, Spatial data mining for highlighting hotspots in personal navigation routes, International Journal of Data Warehousing and Mining, 8\(3\:45-61  Bimonte S., Bertolotto M., Gensel J., Boussaid O., Spatial OLAP and Map Generalization: Model and Algebra. International Journal of Data Warehousing and Mining, 8\(1\: 24-51, 2012  Silva R., Moura-Pires J., Santos M. Y. 2012, Spatial Clustering in SOLAP Systems to Enhance Map Visualization. International Journal of Data Warehousing and Mining,8\(2\: 23-43 \(2012\ Lapkin A, Hype Cycle for Big Data, 31 July 2012, Gartner, Inc. | G00235042, 2012  Shekar S, Xiong H\(Eds.\ Encyclopedia of GIS. New York: Springer 2007  Mills M P, Ottino J M, The Coming Tech-led Boom[N   2 012 10 12 9 www.wsj.com  Reshef D N et al., 2011, Detecting novel associations in large data sets Science, 334, 1518  Surhone L M, Tennoe M T, Henssonow S F, Big Data: BigTable, Cloud Computing, Database Theory.  Betascript Publishing, 2010  Tu Z 9 Big D ata: Data revolution is coming 9 Guangxi Normal University Press, 2012  Zhu Z, Yu C, Yan L, Big data: Big value,Big chance,Big Change Electronics Industry Press, 2012  Barabasi A.-L 9 Bursts: The Hidden Patterns Behind Everything We Do 9 Plume Books 9 2011  Meyer-Schoenberger V, Cukier K, Big Data: a Revolution That will Transform How We Live, Work and Think, London:John Murray, 2013  Bian F L, Digital vision to see the world, Wuhan: Wuhan University Press, 2011  Wang S L, Zeng Y X, Yuan H N, Service Science Introduction, Wuhan Wuhan University Press 9 2009  Wang S L, Shi W Z, 2012, chapter 5 Data Mining, Knowledge Discovery. In: Wolfgang Kresse and David Danko \(eds.\ Handbook of Geographic Information \(Berlin: Springer\, pp.123-142  Li D R, Wang S L, 2007, Spatial data mining and knowledge discovery Advances in Spatio-Temporal Analysis: in: ISPRS Book Series, Vol. 5 171-192, Editor\(s\inming Tang, Yaolin Liu, Jixian Zhang, Wolfgang Kainz, London:Taylor and Francis  Burstein F, Holsapple C W, Handbook of Decision Support System Berlin: Springer , 2008  Cressie N, Statistics for Spatial Data \(revised edition\, New York: John Wiley and Sons Inc. 1993  Haining R., Spatial Data Analysis: Theory and Practice, Cambridge Cambridge University Press, 2003  Koperski K, A Progressive Refinement Approach to Spatial Data Mining. Ph.D. Thesis. British Columbia: Simon Fraser University, 1999  International Data Corporation, Electronic Medicines Compendium 2011 IDC Digital Universe Study: Big Data is Here, Now What?. June 28, 2011  Smets P, Imperfect information: imprecision and uncertainty. In Uncertainty Management in Information Systems. London: Kluwer Academic Publishers. 225-254, 1996  Smithson M J, Ignorance and Uncertainty: Emerging Paradigms. New York: Springer-Verlag, 1989  Kim W. et al., A taxonomy of dirty data. Data Mining and Knowledge Discovery, 2003,7: 81Ö99  Hern‡ndez M A , Stolfo S J, Real-world data is dirty: data cleansing and the merge/purge problem. Data Mining and Knowledge Discovery 1998, 2, 1-31  Dasu T, Exploratory Data Mining and Data Cleaning. New York: John Wiley & Sons, 2003  Paul M, Cassette tapes are the future of big data storage.  New Scientist 2887, p20, 2012  Smith A, An Inquiry into the Nature and Causes of the Wealth of Nations. New York: The Modern Library, 1776  Ostler T.A., et al. Ultrafast heating as a sufficient stimulus for magnetization reversal in a ferrimagnet. Nature Communications 3, 666 Feb. 07, 2012  W ang S L, Spatial data mining under smart earth, Proceedings of 2011 I EEE International Conference on Granular Computing, 2011, pp.717722  Craglia M, Bie K, Jackson D, Digital Earth 2020: towards the vision for the next decade , International Journal of Digital Earth, 2012, 5\(1\:4-21  Wang S L, Gan W Y, Li D Y, Li D R, Data Field for Hierarchical Clustering. International Journal of Data Warehousing and Mining, 2011 7\(2\ 43-63  Morgan Stanley. Cloud Computing Takes off Market Set to Boom as Migration Accelerates. May 23, 2011 
 
 V C ONCLUSION  The development of big data extends the scope of human activities. The world has been cooperating and integrating on a global scale. It redefines the relationship among individuals businesses, organizations, gove rnments, and societies through networked thinking and further to improve the human living environment, to enhance the quality of public services, to improve performance, efficiency and productivity through the interactive operation. The technological progress and industrial upgrading of big data will create new markets, business models and industry rules, and more importantly it demonstrates the collective will of a country that looking for strategic advantage Although there is still a large gap to gain data intelligence like human wisdom, big data is a promising topic to understand the world from an entirely new aspect A CKNOWLEDGEMENTS  This project is supported by the NSFC \(61173061, 71201120 and the Doctoral Fund of Higher Education \(20121101110036 R EFERENCES  1 
                                           
491 
491 
491 
491 


not possible under other visualization frameworks because they lacked the ability to succinctly express the differences between the different overplotting treatments V I MPLEMENTATION The ability to interactively switch between different Abstract Rendering encodings is a signiìant advantage of Abstract Rendering over other libraries Efìciency changing rest directly on implementation decisions Abstract Rendering has been implemented in Java and Python This section describes the implementation in Java The Python implementation is similarly structured but differs in the parallelization strategy relying heavily on vectorization through NumPy The Abstract Rendering implementation follows the definition provided in Section II Aggregate info and transfer functions are directly represented though aggregate functions are slightly modiìed to provide efìcient execution in out-of-core environments The select function is replaced with a Renderer class that controls the overall data access order This includes access not just to the underlying dataset as the select function implies but also to the aggregate values i.e the order and frequency that the x/y values appear in Renderers fall into two general categories by pixel and by glyph Bypixel renderers perform selection essentially as described in Section II This strategy is efìcient when used with datasets that are spatially arranged such as a quad-tree Any given glyph will be accessed once for each pixel the glyph touches Many data structures do not efìciently handle the highly spatial nature of these queries and thus a pixel-oriented rendering strategy is not effective A glyph-based rendering strategy takes the opposite tack Each glyph is visited exactly once and each pixel may be updated multiple times This enables efìcient rendering when using non-spatial data structures because each glyph is visited in an order convenient to its container However the different iteration order means that synthetic values i.e the s xy values are typically updated multiple times The aggregation function does not receive a list of info function results as described in Section II Instead it receives one info result and a pre-existing aggregate value To compensate for this difference aggregate functions must provide a zero value and must be commutative/associative if deterministic execution is desired The zero is used to initialize the synthetic data space When presented with a list of info results the operator receives all of its operands at once and thus commutativity and associativity are not signiìcant The implementation supports a number of parallelization strategies and data conìgurations A full analysis is beyond the scope of this paper In brief thread-level parallelism and vector-based parallelism have been explored GPU distributed memory and streaming data conìgurations have also been investigated All use the components described   Figure 10 Scaling behavior of Abstract Rendering as processor count increases Scaling behavior is near linear as processors as are added but shows no additional improvements with hyper-thread processors processors 8-15 are hyperthreads and improve by less than 5 vs 8 cores above augmented with various helper functions to facilitate data access or partial result combination The out-of-core conìguration is used in performance analysis Section VI and to handle the Kiva data set Section IV-B VI P ERFORMANCE Section III described several Abstract Rendering phrasings demonstrating its expressive capabilities To be practical the framework must be performant as well as expressive An simple characterization of runtime performance was done with an eight physical core machine Two adjacency matrix visualizations were used The rst was the Kiva dataset described Section IV-B The second dataset is an adjacency-list of links found on Wikipedia receiving the same treatment The Wikipedia data set includes 153 million edges representing the links of the largest connected cluster if the category system is ignored Both data sets were binaryencoded adjacency-lists stored in a memory mapped le The le contents were streamed off disk and rendered in a glyphparallel strategy These datasets were used because the data volume is sufìcient to require out-of-core processing but require simple analysis to create a visual representation Figure 10 presents the average performance over 10 executions while keeping the core count xed In general more processors are more helpful but hyperthreading is not The scaling characteristic is similar between the two datasets but the difference shows the overhead of abstract rendering in general Even though this Wikipedia data set is four times larger than the Kiva data set the overall runtime is only three times longer on average Overall the performance numbers are generally supportive of interactive visualization applications 15 


VII F UTURE W ORK Current Abstract Rendering implementations closely tie the bin-elements with the display resolution and region This decision introduces view-dependent effects View-dependent effects are used advantageously in high-deìnition alpha composition but may not always be desirable Developing techniques for avoiding these effects and guidelines for their usage is an ongoing effort Section V described implementation considerations There are several unexplored options that may lead to more efìcient implementations or to implementations that run in more complex runtime environments Options include distributed memory or efìcient GPU execution The idea of binning is shared inMens Abstract Rendering can be applied to more than just overplotting High-deìnition alpha composition rests on the idea of measuring pixel-level information This same idea can be applied to screen-space metrics for visualization evaluation 17 Such applications are also being e xplored The idea of the transfer function comes from scientiìc visualization However years of research into transfer functions has yielded many interesting techniques Mixed rendering styles and context-aware highlighting are strong candidates for exploration Additionally as noted in Section I Z-ordering creates an implicit volume-like space Some volume-based techniques from scientiìc visualization maybe more directly applicable by more literally applying this metaphor VIII C ONCLUSIONS Visualizing large data sets inevitably runs into overplotting issues By considering the rendering process as binning Abstract Rendering provides a means to unify many overplotting techniques Furthermore those techniques can be encoded succinctly at compile time and executed efìciently at runtime R EFERENCES  S K Card J Mackinlay  and B Shneiderman Readings in Information Visualization Using Vision to Think  Morgan Kaufman 1999  M Bostock and J Heer  Proto vis A graphical toolkit for visualization IEEE Transactions on Visualization and Computer Graphics  vol 15 no 6 pp 1121Ö1128 2009  M Bostock V  Ogie v etsk y  and J Heer  D3 DataDriven Documents IEEE Trans Visualization  Comp Graphics Proc InfoVis  2011 A v ailable http vis.stanford.edu/papers/d3  J A Cottam Design and implementation of a stream-based visualization language Ph.D dissertation Indiana University 2011  L W ilkinson The Grammar of Graphics  2nd ed New York Springer-Verlag 2005  H W ickham  A layered grammar of graphics  Journal of Computational and Graphical Statistics  vol 19 no 1 pp 3Ö28 March 2010  G S Da vidson B Hendrickson D K Johnson C E Meyers and B N Wylie Knowledge mining with VxInsight Discovery through interaction Journal of Intelligent Information Systems  vol 11 no 3 pp 259Ö285 1998  J A Cottam and A Lumsdaine Extended assortitivity and the structure in the open source development community in International Sunbelt Social Network Conference  International Network for Social Network Analysis January 2008 A v ailable http://www.insna.org/PDF/Awards/awards  ms 2007.pdf  C Muelder  F  Gygi and K.-L Ma V isual analysis of inter process communication for large-scale parallel computing IEEE Transactions on Visualization and Computer Graphics  vol 15 no 6 pp 1129Ö1136 Nov 2009 Available http://dx.doi.org/10.1109/TVCG.2009.196  National Historical Geographic Information System V ersion 2.0 University of Minnesota Minneapolis MN 2011  A v ailable http://www nhgis.or g  T  Porter and T  Duf f Compositing digital images  SIGGRAPH Comput Graph  vol 18 no 3 pp 253Ö259 Jan 1984 A v ailable http://doi.acm.or g/10.1145 964965.808606  J Johansson P  Ljung M Jern and M Cooper  Re v ealing structure within clustered parallel coordinates displays in Proceedings of the Proceedings of the 2005 IEEE Symposium on Information Visualization  ser INFOVIS 05 Washington DC USA IEEE Computer Society 2005 pp 17 Available http://dx.doi.org/10.1109/INFOVIS.2005.30  H Hagh-Shenas V  Interrante C Heale y  and S Kim Weaving versus blending a quantitative assessment of the information carrying capacities of two alternative methods for conveying multivariate data with color in Proceedings of the 3rd symposium on Applied perception in graphics and visualization  ser APGV 06 New York NY USA ACM 2006 pp 164Ö164 A v ailable http://doi.acm.org/10.1145/1140491.1140541  T  E Oliphant Guide to NumPy  Provo UT Mar 2006  A v ailable http://www tramy us  Z Liu B Jiang and J Heer  immens Real-time visual querying of big data Computer Graphics Forum Proc EuroVis  vol 32 2013 A v ailable http vis.stanford.edu/papers/immens  J W  T u k e y and P  A T u k e y  Computer Graphics and Exploratory Data Analysis An Introduction in Proceedings of the Sixth Annual Conference and Exposition Computer Graphics  Fairfax VA Nat Computer Graphics Association 1985 pp 773Ö785  A Dasgupta and R K osara P ar gnostics Screen-space metrics for parallel coordinates IEEE Transactions on Visualization and Computer Graphics  vol 16 no 6 pp 1017Ö1026 Nov 2010 A v ailable http dx.doi.org/10.1109/TVCG.2010.184 16 


state of innovation stakeholder  node PQ It  s a balanced node Based on this, we could calculate the  node PQ Calculation process is: set different inn ovation stakeholders state i U  and j U Value of ij 000T can be get from  innovation time difference. Innovation stakeholdersí social effect and industrial effect can be obtained upon ij B  and ij G set according to relation between innovation stakeholders  Model 4.1 points out  that the value of Gij  directly affects social benefits and sector benefits. Large Gij  can lead to increasing benefits of the entire industry and the entire social growth Bij reflects big organizationís impact on businesses. Only strengthening the inter agent association within big organization and enhancing the str ategic partnership between enterprises can jointly promote the development of the entire industry, and bring more social benefits, so that each agent can be improved   5 Summary This paper puts forward the concept of the big organization based on the CSM t heory. It introduces the basic implication of the big organization and theoretical framework of the big organization including: the big organization's perspective  overall perspective, dynamic perspective, and new resource perspective; the big organizat ionís sense  the purpose of the organizational structure is innovation, organizational activities around the flow of information, breaking the traditional organizational structure, encouraging self run structure, and blurring organizational boundaries; the big organizationís platform  the platform ecosystem of the big organization ; the big organizationís operation mode  borderless learning mode, and cluster effect; the big organizationís theory  active management theory  leading consumers, and culture  entropy reduction theory  negative culture entropy and humanistic ecology theory  inspiring humanity, and circuit theory  a virtuous circle, and collaborative innovation theory  collaborative innovation stakeholder. This paper also discusses culture entropy reduction theory of the big organization  negative culture entropy, and coordinated innovation theory  innovation stakeholders collaboration. Culture entropy change model and collaborative in novation model are constructed   The research has just begun for the big organization. It also needs further improvement but remains the trend of the times   Reference  1  Gordon Pellegrinetti, Joseph Bentsman. Nonlinear Control Oriented Boiler Modeling A Benchmark Problem for Controller De sign [J  I E E E tr a n s a c tio n s o n c o n tr o l s y s te m s te c h n o lo g y 2 0 1 0  4 1\57 65  2  Klaus Kruger, Rudiger Franke, Manfred Rode Optimization of boiler start up using a nonlinear 457 


boiler model and hard constraints [J  E n e r gy 201 1 29   22 39 2251  3  K.L.Lo, Y.Rathamarit  State estimation of a boiler model using the unscented Kalman filter [J  I E T  Gener. Transm. Distrib.2008 2 6\917 931  4  Un Chul Moon, Kwang. Y.Lee. Step resonse model development for dynamic matrix control of a drum type boiler turbine system [J IE E E  T ra nsactions on Energy Conversion.2009 24 2\:423 431  5  Hacene Habbi, Mimoun Zelmat, Belkacem Ould Bouamama. A dynamic fuzzy model for a drum boiler turbine system [J  A u to m a tic a 2 0 0 9 39:1213 1219  6  Beaudreau B C. Identity, entropy and culture J   J o ur na l  o f  economic psychology, 2006, 27\(2 205 223  7  YANG M, CHEN L. Information Technique and the Entropy of Culture J  A cad e m i c E x ch a n g e  2006, 7: 048  8  ZHANG Zhi feng. Research on entropy change model for enterprise system based on dissipative structure J  Ind ustrial  Engineering and  Management 2007, 12\(1\ :15 19  9  LI Zhi qiang, LIU Chun mei Research on the Entropy Change Model for Entrepreneurs' Creative Behavior System Based on Dissipative Structure J  C h i n a S of t S c i e n c e  2009   8  1 62 166   458 


A Global Solution COVERAGE North and South America EMEA and Asia White lines are flights in the masFlight platform from February 8, 2013 Yellow pins are weather stations feeding hour ly data to our platform Maps from Google Earth / masFlight masFlight tracks flights, airports and weather around the world  Global daily flight information capture  82,000 flights  350 airlines  1700 airports  Integrated weather data for 6,000 stations  Match weather to delays  Validate block forecasts at granular level  Add weather analytics to IRROPS review and scenario planning 


Example 1: Proposed FAA Tower Closures masFlight used big-data to link airport operations across three large data sets  Current and historical airline schedules  Raw Aircraft Situation Display to Industry \(ASDI\AA  Enhanced Traffic Management System Counts \(ETMS\Airport operations counts by type \(commercial, freight, etc TOWER CLOSINGS Dots indicate closures; Red dots have scheduled service Based on scheduled service March 1 7, 20 13; scheduled service includes scheduled charter flights, cargo flig hts, and passenger flights Dots  indicate  closures  Red  dots  have  scheduled  service Bas ed  o n sc h edu l ed  se rvi ce  M a r c h 1  7, 2013; scheduled se rvi ce includ es scheduled c harter fli g hts car g o fli g hts a nd passen g er fli g hts Findings: Proposed Tower Closings  From schedules database: 55 airports with scheduled passenger airline service  14 EAS Airports  From ASDI & ETMS: 10,600 weekly flights on a flight plan \(ex. VFR and local traffic  6,500 Part 91/125 weekly flights  4,100 Part 135/121 weekly flights  


Example 1: Big-Data Analytics Applied to ASDI and ETMS To Analyze Operations TOWER CLOSINGS  26 44 24 23 11 10 6 2 1 2 Up to 5 5-10 10-15 15-20 20-25 25-30 30-35 35-40 40-45 45 Count of Airports Average Number of Daily Operations with a Flight Plan Filed Distribution of Airports By Average Number of ìDailyî Impacted Flights Airports Affected by Tower Closures Source: ASDI radar data ñ Part 91 151 flying and Part 135/121 flying March 1-7, 2013; masFlight analysis Note: Average ìdailyì operations based on 5-day week 


Example 2: Aviation Safety Causal Factor For example, consider the following ASRS report \(ACN 1031837 Departing IAH in a 737-800 at about 17,000 FT, 11 m iles behind a 737-900 on the Junction departure over CUZZZ Intersection. Smooth air with wind on the nose bearing 275 degrees at 18 KTS We were suddenly in moderate chop which lasted 4 or 5 seconds then stopped and then resumed for another 4 or 5 seconds with a significant amount of ri ght rollingÖ I selected a max rate climb mode in the FMC in order to climb above the wake and flight path of the leading -900 We asked ATC for the type ahead of us and reported the wake encounter. The 900 was about 3,300 FT higher than we were  Synopsis  B737-800 First Officer reported wake encounter from preceding B737-900 with resultant roll and moderate chop What causal factors can be identified from this narrative that could be applied to future predictive applications CAUSAL FACTORS Data-mining algorithms can mine the text of safety reports to obtain specific data that can be used to analyze causal factors  


Example 2: Identifying Causal Factors CAUSAL FACTORS  Indicators ñ Data Element Methods ñ Identifying Context and Causes  Time of day  Date range \(month day  Aircraft type  Fix or coordinates  Originating airport  Destination airport  Weather notes We pinpoint the sequencing of flights on the IAH Junction Seven departure \(at CUZZZ\the specified wind conditions to find cases wher e a B737-900 at 20,000 feet precedes by 11 miles a B737-800 at 17,000 feet  Search related data sets including ASDI flight tracks, local traffic and congestion  Weather conditions for alter native causes \(winds aloft shear and convecti ve activity  Airline specific informati on \(repeated occurrence of event in aircraft type Big data gives us visibility into contextual factors even if specific data points are missing such as a specific date or route Big-data analytics gives us insight into unreported factors as well 


Example 3: Correlating Utilization and Delays  60 65 70 75 80 85 90 95 100 7 9 11 13 ONTIME DEPARTURE PERFORMANCE HOURS OF DAILY UTILIZATION 60.0 70.0 80.0 90.0 100.0 7.0 9.0 11.0 13.0 Narrowbodies By Day of Week 60.0 70.0 80.0 90.0 100.0 7.0 9.0 11.0 13.0 Widebodies by Day of Week Daily Utilization vs. On-time Departures January 2013 System Operations Correlation Coefficient -0.53 Includes AA, AC, AS B6 F9, FL, NK, UA, US VX and WN SOURCE masFlight \(masflight.com COMPARING OTP AND UTILIZATION 


 6.2 6.0 5.8 5.8 5.2 4.9 LGB JFK BOS MCO DCA FLL JetBlue Focus Average Daily Deps per Gate Used UTILIZATION BY HUB Example 4: Daily Utilization of Gates, by Hub Big-data analysis of different carriers daily departures per gate used SOURCE masFlight \(masflight.com June 1 through August 31, 2012 Gates with minimum 1x daily use 7.7 7.4 7.2 6.2 6.1 5.8 3.8 3.6 ORD LAX SFO EWR DEN IAH IAD CLE United Airlines Hubs Average Daily Deps per Gate Used 7.8 6.4 5.5 5.4 5.3 4.4 4.3 4.0 SEA SAN PDX ANC SFO GEG LAX SJC Alaska Airlines Hubs Average Daily Deps per Gate Used 7.2 6.9 6.8 6.4 5.0 2.7 ORD DFW LAX LGA MIA JFK American Hubs Average Daily Deps per Gate Used 7.2 6.9 6.6 4.9 4.2 CLT DCA PHL PHX BOS US Airways Hubs Average Daily Deps per Gate Used 6.6 5.9 5.5 4.7 MCO BWI ATL MKE AirTran Hubs Average Daily Deps per Gate Used ne pe 


Conclusions for Big Data in Aviation  Big-data transforms operational and commercial problems that were practically unsolvable using discrete data and on-premises hardware  Big data offers new insight into existing data by centralizing data acquisition and consolidation in the cloud and mining data sets efficiently  There is a rich portfolio of information that can feed aviation data analytics  Flight position, schedules, airport/gate, weather and government data sets offer incredible insight into the underlying causes of aviation inefficiency  Excessive size of each set forces analysts to consider cloud based architectures to store, link and mine the underlying information  When structured, validated and linked these data sources become significantly more compelling for applied research than they are individually  Todayís cloud based technologies offer a solution CONCLUSIONS 


Conclusions:  Our Approach  masFlightís data warehouse and analysis methods provide a valuable example for others attempting to solve cloud based analytics of aviation data sets  masFlightís hybrid architecture, consolidating secure data feeds in on-premises server installations and feeding structured data into the cloud for distribution, addresses the unique format, security and scale requirements of the industry  masFlightís method is well suited for airline performance review competitive benchmarking, airport operations and schedule design and has demonstrated value in addressing real-world problems in airline and airport operations as well as government applications CONCLUSIONS 





