Tree Projection-based Frequent Itemset Mining on multi-core CPUs and GPUs 003 George Teodoro Nathan Mariano Wagner Meira Jr Renato Ferreira Department of Computer Science Universidade Federal de Minas Gerais f george nathanr meira renato g dcc.ufmg.br Abstract Frequent itemset mining FIM is a core operation for several data mining applications as association rules computation correlations document classi\002cation and many others which has been extensively studied over the last decades Moreover databases are becoming increasingly larger thus requiring a higher computing power to mine them in reasonable time At the same time the advances in high performance computing platforms are transforming them into hierarchical parallel environments equipped with multi-core processors and many-core accelerators such as GPUs Thus fully exploiting these systems to perform FIM tasks poses as a challenging and critical problem that we address in this paper We present ef\002cient multi-core and GPU accelerated parallelizations of the Tree Projection one of the most competitive FIM algorithms The experimental results show that our Tree Projection implementation scales almost linearly in a CPU shared-memory environment after careful optimizations while the GPU versions are up to 173 times faster than standard the CPU version 1 Introduction Frequent itemset mining FIM is a core operation for various data mining applications attracting attention of the research and commercial communities in the recent years 7 Gi v en a database of transactions where each transaction contains a set of items it consists of 002nding all itemsets that occurs more than a given user threshold  support  003 This work is partially supported by CNPq CAPES FINEP FAPEMIG and INWEBthe Brazilian National Institute of Science and Technology for the Web Due to its importance a number of works have focused on this problem and several FIM algorithms have been proposed 2 3 11 These algorithms may be divided into two classes The 002rst class includes those algorithms which are an Apriori  v ariant 20 and 002nd frequent itemsets based on a candidate-generation approach that is levelwise and followed by the frequency counting of the candidates The second class of algorithms which includes Tree Projection and FPGrowth is based on projection techniques that employ a tree construction method based on pre\002x trees and perform mining recursi v ely on progressively smaller databases This second class of algorithms has been shown to outperform the 002rst class being an order of magnitude faster in several scenarios The current advances in computer architecture are transforming traditional high performance distributed platforms into multi-core and many-core hierarchical environments Thus creating ef\002cient FIM algorithms that fully exploit this parallelism is a very important contribution A number of works have also developed parallel formulations for 002nding frequent itemsets based on the candidate-generation approach  Apriori 000 like  both for sharedand distributed-memory computers 10 14 18 including a GPU single node based implementation of Apriori  Ho we v er  the projection-based algorithms have received relatively little attention 5 while the y ha v e been shown to be an order of magnitude faster than the candidate-generation based Moreover to the best of our knowledge it does not exist a projectionbased FIM algorithm for GPUs In this paper we propose the 002rst projectionbased FIM implementation for GPUs We parallelize the Tree Projection algorithm for multicore CPUs and GPUs The Tree Projection was chosen as the target of our implementation be 
2010 22nd International Symposium on Computer Architecture and High Performance Computing 1550-6533/10 $26.00 © 2010 IEEE DOI 10.1109/SBAC-PAD.2010.15 47 


cause its most compute intensive step is suitable for data parallelism using a GPU or multi-core processors After careful analysis our implementation has achieved almost linear speedups in a multicore shared memory machine while its GPUversion is up to 173 times faster than the CPUbased sequential code 2 Tree projection The tree projection-based frequent itemset mining algorithm Tree Projection employs a lexicographic tree as its core data structure which is used to guide mining operations Nodes in this tree are the frequent itemsets and it assumes a lexicographic ordering among items in a database In this tree a node on depth or level k corresponds to an itemset of size k  while the root node has no itemset Figure 1 The lexicographic tree with absolute support value of 2 In order to explain the algorithm we 002rst de\002ne some concepts The 1-extensions of a node X is the set of itemset extensions that are generated from it i.e nodes whose itemsets have node X itemset as pre\002x and so are called frequent lexicographic tree extensions  In our example Figure 1 the frequent lexicographic extensions of node a are c and h  the active extensions of a given node is the subset of its tree extensions that can still generate frequent itemsets a node is inactive when it has no child that can generate more frequent itemsets the candidate branches refers to the set composed by the last item of the itemsets of brothers on the right of a given node and a node that is singleton has no candidate branches the set of active items are the same as its candidate branches if it has been just created thus being at the tree boundary or it is recursively de\002ned as the union of the itemset of its active extensions with the lists of active items of all nodes included in these active extensions The projected transaction of a node is the intersection of the transaction's items with the active items of this node For example if a transaction is abcdef and the active items of a given node are  b,c,e  the resulting projected transaction is bce  If the itemset of the node is not in the transaction the corresponding projected transaction is null For further details please refer to Algorithm 1  BreadthFirst Data  minsupport  s Database  034 Result  Frequent itemsets f reqOnesAtts  f irstScan  support T   buildT opLevelT ree  f reqOnesAtts   k  1 while kth level 6   do createT riangularM atrices  kth 000 1  foreach transaction T 2 034 do addCounts  T RootN ode   checkSupport  kth 000 1  createN ewN odes  kth  1  deleteT riangularM atrices  kth 000 1  pruneT ree  kth  1  k The Tree Projection algorithm extended in this work is based on a breadth-\002rst search on the lexicographic tree where all nodes at level k are created before nodes at level k 1  In Algorithm 1 we present its pseudocode The 002rst step of this algorithm is a scan in the database computing the frequency of each attribute to determine the frequent 1-itemsets  f irstScan  This information is then used to create the top level of the lexicographic tree  buildT opLevelT ree  which consists of the root and its frequent 1-itemsets children nodes After this initial phase the algorithm will expand the tree levelwise when it creates counting matrices in nodes at level k 000 1  createT riangularM atrices  kth 000 1  which are then used to count the frequency of nodes at level k  1  Each node P at level k 000 1 maintains a matrix of dimensions j active extensions  P  j 003 j active extensions  P  j  where a row and column exists in this matrix for each item i 2 active extensions  P   and each entry that exists in this matrix indicates the counting of itemset 
48 


P  i j Since the matrix is symmetric only one lower or upper triangular part is maintained The algorithm then proceeds by incrementing the appropriate entries in the existing counting matrices at level k 000 1  executing the addCounts for each transaction During this phase each transaction is projected from the root node to nodes at level k 000 1  and if the projected transaction is not null its items are combined to increment the matrix entries as shown in Algorithm 2 After processing all transactions the matrix of each node at level k 000 1 is veri\002ed regarding its support  checkSupport  kth 000 1  and a new node in the tree is then created at level k  1 for each entry with adequate support  createN ewN odes  kth  1  Then the matrices of nodes at level k 000 1 are deleted  deleteT riangularM atrices  kth 000 1  Algorithm 2  AddCounts Data  transaction  T N ode  P Level  k if P 2 levelk 000 1 then foreach  i j  2 2 000 ascent 000 combination  T  do P:matrix  i j     else foreach active extension i 2 P do T 0  P roject transaction T onto i  Call addCounts  T 0   The last step of the algorithm prunes the tree  pruneT ree  kth  1  which is done by traversing it in a bottom-up fashion removing the inactive nodes and updating the remaining nodes First the singleton nodes created at level k  1 are removed since they have no one to combine with It then continues pruning the tree and updating the active items in each node After removing the inactive nodes of a level the remaining nodes have their active items lists updated following the recursive de\002nition already discussed The program 002nally ends when the newest level created has no active nodes In Figure 1 we show an example lexicographic tree using absolute support value of 2 that has been generated and examined up to level 2 but the nodes at the level 3 have only been created 3 Parallel Tree Projection This section describes the Tree Projection implementations for multi-core processors and accelerators First in Section 3.1 we discuss the parallelization opportunities of the algorithm and the adopted strategy Section 3.2 then details our implementation to multi-core shared-memory environments where several approaches to avoid race conditions when updating shared objects are studied In Section 3.3 the GPU accelerated version of Tree Projection is presented 3.1 Parallelization strategy As discussed in Section 2 the Tree Projection algorithm performs the frequent itemsets counting based on a lexicographic tree which is built at run-time and may be constructed through various strategies In this paper as in the original Tree Projection implementation we emplo yed a breadth-\002rst strategy which as shown in Algorithm 1 builds each level of tree in consecutive iterations of the algorithm This tree building method embeds two parallelization opportunities i the transactions processing parallelism consists of processing the transactions in parallel on the available hardware updating each counting matrix of the nodes at level k 000 1  ii the node level parallelism where each node being expanded is assigned to a different processor which processes all transactions updating its node matrix While both strategies may have advantages in different scenarios we chose the transactions processing parallelism due to the following reasons i the execution time is dominated by the addCounts method that processes the transactions making it a very interesting candidate for parallelization ii if the node parallelism was employed on the other hand there would be a load imbalance and the number of nodes may not be enough to fully utilize all the processors during the entire execution iii the node level parallelism also demands more memory because the matrices of all nodes being concurrently updated need to be in memory which may be unfeasible in many scenarios Although the transactions processing parallelism has several advantages over node level parallelism it shares the tree nodes that are being expanded among the parallel processes which may try to concurrently update the same cell of a given node matrix requiring synchronized accesses The section below explains different methodologies to deal with this problem on the CPU and GPU implementations 
49 


3.2 CPU parallel implementation This section presents the CPU shared-memory parallel Tree Projection The proposed solution employs transaction processing parallelism discussed in the last section dividing the transactions among different CPU threads that perform the addCounts operations independently Other phases of the algorithm which were shown to be inexpensive are kept sequential The application's parallel section is built based on a work queue transactions that is shared among threads  AdderT hreads  pro viding a dynamic assignment that reduces load imbalance among them Our implementation also assigns blocks of transactions in order to minimize the overhead The addCount operation shown in Algorithm 2 is applied to each input transaction updating the proper matrices However when processing transactions in parallel different AdderT hreads may need to update the same cell  i j  of a given node  P  matrix  P:matrix  i j     demanding synchronized accesses This problem although easily solved in many scenarios is a critical aspect in achieving scalability in Tree Projection as this shared object is at the core of the algorithm A simple way to eliminate the overhead associated with avoiding these race conditions is Data replication  where each process asynchronously updates its local copy with a reduce at the end of the parallel section Unfortunately in the Tree Projection it is an unacceptable solution as the size of data to be replicated matrices for each tree node may be very large and could then create an unfeasible memory requirement Another way to avoid such undesirable conditions is by creating critical sections to prevent threads from updating matrices cells concurrently However when solving this problem it is important to analyze the size of the critical sections and the type of synchronization primitive For instance in the authors assess the impact of the size of critical sections to the performance of data mining tree based applications which has a similar structure to Tree Projection based on software synchronization primitives Next we discuss three different softwarebased lock schemes and a new lock-free implementation using hardware based atomic instructions Tree level locking creates a critical section that is associated with each level of the tree thus only one thread can increment matrices at a time This approach is simple and inexpensive in terms of overhead to create locks but it imposes a barrier among threads accessing different nodes Node level locking employs a lock for each Node at level k 000 1 being updated Despite its higher lock management overhead locking at the node level will allow different threads to update matrices of different nodes in parallel Cell level locking employs a lock for each cell which may generate high memory requirements as the memory used by locks is larger than the needed by nodes matrices Moreover each cell update may generate extra cache misses when reading its lock structure In some conditions where the critical section is very small and frequently executed by the parallel threads using traditional software based synchronization primitives may not be a good choice as it may become a bottleneck to the application scalability Thus in this paper we evaluate the use of Wait-free  instructions which are implemented at the hardware level and are available in most of the modern multi-core processors to update such objects shared among different threads The Wait-free instructions guarantees atomicity when updating memory and eliminates the need for critical sections as provided by mutexes and semaphores Using a wait-free operation as sync add and f etch  address value   included as a gcc built-in a memory address is guaranteed to be incremented by value even when address is a shared object In order to provide the atomic add it loads the old value pointed by address adds value to it and updates the address with a new value if the old is still the same To avoid the ABA problem one solution is to keep a counter to make sure that the threads are updating the correct data generation 3.3 GPU implementation The Tree Projection is a very computateintensive application which makes it an interesting candidate for GPU acceleration As other algorithms for FIM 11 ho we v er  it is irre gular in several dimensions for instance because of the different costs for processing each transaction or node matrix This challenging behavior imposes a barrier for the development of ef\002cient FIM algorithms for GPU as these processors are more suitable for very regular and parallel computations The proposed parallelization of Tree Projection is implemented using CUDA and as in the multi-core shared-memory implementation it exploits the transactions processing parallelism The addCount function was then implemented as a GPU kernel that process several transactions concurrently 
50 


Algorithm 3 shows the pseudo-code of the modi\002ed breadth 002rst tree building strategy As discussed the addCounts is now a kernel function that is executed on the GPU and processes a set of T S transactions each time exploiting the GPU parallelism by assigning different transactions to different GPU threads Since transactions are organized in lines one dimension of blocks and grids is enough In the addCounts step a set of nodes is delivered to GPU always respecting its memory constraints In the GPU transaction blocks are processed for each node where several transactions of one block are projected in the active items of the nodes and various entries of the node matrices are updated simultaneously After all transaction blocks are processed the nodes are brought back to CPU and their matrices are used to build the next tree level It is important to note that in this GPU version the projection of transactions are made directly in the k 000 1 level nodes instead of projecting them all along from the root in a top-down fashion like the original implementation Although this strategy goes against the bene\002ts of eliminating transactions that will not generate frequent itemsets as soon as possible it is easier in the GPU Another critical problem we address is how to ef\002ciently represent a set of transactions on GPUs In the existing FIM algorithm for GPUs the authors use a m 002 n transaction-bitmap approach to represent the database where n is the number of transactions and m is the number of items and bit  i  j  is set to 1 if item i occurs in transaction j  Although this representation is interesting due to its regularity and easy manipulation on GPUs it may not be acceptable to store sparse databases due to the memory requirements Thus we propose a novel compact and simple representation of the database of transactions for GPUs which is not only useful to FIM algorithms but may also for example be used to compute inverted indexes on these processors The proposed structure shown in Figure 2 stores the transactions using a vector adding the size of each transaction just before its items In addition it creates an auxiliary index to identify the beginning of each transaction on the vector where they are stored Besides being a very simple and intuitive way to represent sparse database this approach provides a very ef\002cient access pattern as data elements are successively located in the memory a compact data representation for sparse datasets Algorithm 3  BreadthFirstGrid CPU Data  minsupport  s Database  034 Result  Frequent itemsets f reqOnesAtts  f irstScan  support T   buildT opLevelT ree  f reqOnesAtts   k  1  while kth level 6   do createT riangularM atrices  kth 000 1  foreach transactionsSet T S 2 034 do grid   T S=T h 1  1  threads   T h 1  1  addCounts  grid threads   T S kth 000 1  checkSupport  kth  1  createN ewN odes  kth  1  deleteT riangularM atrices  kth 000 1  pruneT ree  kth  1  k    Figure 2 Sparse data representation 4 Empirical results The experiments were performed using two machines i a dual quad-core AMD Opteron 2.00GHz processor 16GB of main memory an NVidia GeForce GTX260 GPU and Linux operating system and ii a second machine equipped with an NVidia GeForce GTX470 GPU We tested the algorithm implementations using the three databases presented in Table 1 The synthetic datasets were generated using a data generator obtained from IBM Almaden and the procedure described in In order to pro vide a f air compar ison among different versions of the application the programs were compiled using the 003ag O3 The results shown in this section are an average of 5 executions the highest standard deviation for CPU and GPU execution are respectively 0.75 and 0.5 4.1 CPU multi-core analysis This section analyzes the Tree Projection implementations to multi-core shared-memory machines as a function of the input datasets characteristics In Figure 3 we present the performance of the proposed approaches to update shared ob 
51 


Dataset Items Avg Length Transactions Density Characteristics Sparse repr size Bitmap size T25.I20.D1000K 10,000 25 1,000,000 0.25 Synthetic 030 49 MB 030 1,192 MB T35.I20.D1000K 10,000 35 1,000,000 0.35 Synthetic 030 68 MB 030 1,192 MB T45.I20.D1000K 10,000 45 1,000,000 0.45 Synthetic 030 87 MB 030 1,192 MB Table 1 Dataset characteristics jects Tree level locking  Level  Node level locking  Node  Cell level locking  Cell  and Waitfree based  W-F  In our 002rst evaluation the average transaction length is varied for a 002xed support value of 1 as shown in Figures 3\(a 3\(b and 3\(c As a reference the sequential execution times for the databases T25.I20.D100K T35.I20.D1000K and T45.I20.D1000K are respectively 68.96 105.41 and 296.82 seconds For the 002rst dataset Figure 3\(a all proposed solutions achieved good scalability being the W-F scheme slightly better than the others When using the second dataset T35.I20.D1000K on the other hand Level and Node lockings strongly failed to exploit the available parallelism It occurred because as the average transaction length T increases there is a higher pressure over the critical section as the projected transactions are also larger thus only 002ne grained locks could scale These results are interesting because although the synchronization section refers to a very small piece of code just increment a variable it is executed very frequently and will scale poorly for coarse grained critical sections When analyzing the T45.I20.D1000K dataset See Figure 3\(c an even higher degradation of coarse grained lock based solutions is observed while W-F and Node schemes still having good speedups For this database however the W-F speedups is superlinear In order to explain this behavior we measured the number of L2 cache misses for this scheme Figure 3\(d which shows a reduction in misses as the number of threads increases The observed behavior is due to sharing of read only objects among threads when projection transactions in nodes The cache misses where measured using oprof ile  and e v ent counter setted to 10,000 Finally in Figure 3\(e we evaluate the impact of support to the application performance as it assumes the following values 0.5 0.75 and 1 First as shown all schemes suffer with reduction of support which is due to larger resulting projected transactions at the tree nodes and more increments on the critical section For the shown support although the W-F scheme is the most ef\002cient for all con\002guration achieving near 20 higher performance over the Cell locking on average 4.2 Tree Projection on GPUs The Tree Projection implementation to GPUs is evaluated in this section Firstly Table 1 presents the size in MB for 3 databases when using our proposed sparse representation and the Bitmap based currently used by other FIM algorithms on GPUs As sho wn the amount of memory used by Bitmap representation is much higher than our proposed strategy making it unfeasible to represent low density and very large databases This problem is worsened for GPU accelerated applications as data transfers among CPU and GPU is one of the critical problems for achieving high performance in such accelerators We also evaluate the impact of the support and the GPU type for the Tree Projection performance comparing its accelerated version to the sequential CPU based implementation In Figure 4 we present GPUs speedup over the sequential CPU version as the support is varied while Table 2 shows the absolute execution times for each processor and the dataset T45.I20.D1000K Figure 4 GPUs speedup These results show that our proposed GPU based Tree Projection is very ef\002cient when compared to the CPU version and is also capable of scaling up the support decreases The GTX470 and GTX260 achieved maximum speedup over the sequential Tree Projection of 173 002 and 95 002  Moreover the GTX470 near doubles the GTX260 performance for all values of support what was expected as it represents a newer generation containing more stream processors bandwidth etc Although gains of the GPUs version of Tree Projection over the sequential CPU still high as the 
52 


a Speedup T25.I20.D1000K b Speedup T35.I20.D1000K c Speedup T45.I20.D1000K d W-F cache misses L2 T45.I20.D1000K e Support variation T45.I20.D1000K Figure 3 Tree Projection on multi-cores Support CPU GTX260 GTX470 1.5 164.068 1.730 0.945 1.25 203.293 2.509 1.405 1 296.827 3.906 2.221 0.75 332.128 6.179 3.543 0.5 379.314 10.003 5.865 Table 2 T45.I20.D1000K execution times secs per processor support decreases the relative performance among them is reduced This difference in performance is the result of the CPU version's ability to eliminate the transactions which are not useful at lower levels of the tree while the GPU evaluates all transactions of the candidates in each level and consequently is not capable of reducing the computation cost for smaller supports as less transactions are used at the lower levels The Tree Projection on GTX470 GPU relative performance over the sequential CPU-based version as the average transaction length varies for 25 35 and 45 is presented in Figure 5 As shown the GPU relative performance is higher as the average transaction length increases This behavior is due to higher processing costs of larger transactions and consequently more pressure over the parallel section boosting the GPU Tree Projection as its parallel threads have more work per kernel call Finally in Figure 6 we present the relative execution times as the database is scaled having the T45.I20.D1000K as the base case As shown the CPU and GPU execution times increase almost linearly according to the number of transactions Figure 5 TX.I20.D1000K GPU speedup varying avg trans length showing a very good scalability of the algorithm in both implementations Figure 6 Scaling the database 5 Conclusions In this paper we presented a multi-core shared memory and a GPU-based parallelizations of the 
53 


Tree Projection algorithm which is to the best of our knowledge the 002rst projection-based frequent itemset mining implementation for GPUs We also conducted a detailed analysis of the algorithm's performance on multi-core processors providing a study of several strategies to mitigate potential race conditions when processing transactions in parallel The experimental results showed that we could achieve almost linear speedup on multi-core shared memory platforms through the use of low level wait-free atomic instructions while traditional software based locking strategies failed to provide scalability Our GPU-based implementation of the Tree Projection on the other hand proposed a new simple sparse data representation and achieved speedups of up to 173 when compared to sequential code compiled with O3 003ag These results are very relevant as the sequential Tree Projection is already an order of magnitude faster than Apriori based implementation in several scenarios As future work we intend to develop a distributed GPU accelerated Tree Projection and utilize CPU and GPU to concurrently execute its most compute-intensive and parallel section References  Pr e\002xspan Mining sequential patterns ef 002ciently by pre\002x-projected pattern growth In ICDE 01 Proceedings of the 17th International Conference on Data Engineering  page 215 Washington DC USA 2001 IEEE Computer Society  R C Ag arw al C C Agg arw al and V  V  V  Prasad A tree projection algorithm for generation of frequent item sets J Parallel Distrib Comput  61\(3 2001  R Agra w al and R Srikant F ast algorithms for mining association rules in large databases In VLDB 94 Proceedings of the 20th International Conference on Very Large Data Bases  pages 487–499 San Francisco CA USA 1994 Morgan Kaufmann Publishers Inc  J S Berrios and M E Bermudez Using w ait-free synchronization in the design of distributed applications Future Gener Comput Syst  22\(1-2 2006  G Buehrer  S P arthasarath y  S T atik onda T  K urc and J Saltz Toward terabyte pattern mining an architecture-conscious solution In PPoPP 07 Proceedings of the 12th ACM SIGPLAN symposium on Principles and practice of parallel programming  pages 2–12 New York NY USA 2007 ACM Press  D R Butenhof Programming with POSIX threads  Addison-Wesley Longman Publishing Co Inc Boston MA USA 1997  M.-S Chen J Han and P  S Y u Data mining An overview from a database perspective IEEE Transactions on Knowledge and Data Engineering  8:866–883 1996  W  F ang M Lu X Xiao B He and Q Luo Frequent itemset mining on graphics processors In DaMoN 09 Proceedings of the Fifth International Workshop on Data Management on New Hardware  pages 34–42 New York NY USA 2009 ACM  V  Guralnik and G Karypis P arallel treeprojection-based sequence mining algorithms Parallel Comput  30\(4 2004  E.-H Han G Karypis and V  K umar  Sc alable parallel data mining for association rules In SIGMOD 97 Proceedings of the 1997 ACM SIGMOD international conference on Management of data  pages 277–288 New York NY USA 1997 ACM  J Han J Pei and Y  Y in Mining frequent patterns without candidate generation In SIGMOD 00 Proceedings of the 2000 ACM SIGMOD international conference on Management of data  pages 1–12 New York NY USA 2000 ACM  M Herlih y  W ait-free synchronization ACM Trans Program Lang Syst  13\(1 1991  D Jin and S G Zia vras A super progra mming approach for mining association rules in parallel on pc clusters IEEE Trans Parallel Distrib Syst  15\(9 2004  R Jin G Y ang and G Agra w al Shared m emory parallelization of data mining algorithms Techniques programming interface and performance IEEE Trans on Knowl and Data Eng  17\(1 89 2005  J Le v on OPro\002le Manual  Victoria University of Manchester 2004  NVIDIA NVIDIA CUD A SDK 2009  G T eodoro T  D R Hartle y  U V  Ca talyurek and R Ferreira Run-time optimizations for replicated data\003ows on heterogeneous environments In Proc of the 19th ACM International Symposium on High Performance Distributed Computing HPDC  2010  M J Zaki P arallel and distrib uted associ ation mining A survey IEEE Concurrency  7\(4 1999  M J Zaki P arallel sequence mining on s haredmemory machines J Parallel Distrib Comput  61\(3 2001  M J Zaki S P arthasarath y  M Ogihara and W Li New algorithms for fast discovery of association rules In D Heckerman H Mannila D Pregibon R Uthurusamy and M Park editors In 3rd Intl Conf on Knowledge Discovery and Data Mining  pages 283–296 AAAI Press 12–15 1997 
54 


709 


710 


calculating the weight for each web page for respective web site. The proposed approach uses Visiting Frequency and Time Spent on a Web page as two parameters to measure the weight of each web page To estimate the performance of the proposed two algorithms i.e. FPW and FTPW, discussed in section IV based on the above parameters involved in estimation C. Experimental Results The performance of the proposed approach can be evaluated by comparing the performance of FPW and FTPW algorithms which differ in number of parameters considered for experimentation. The comparison is made by taking the attribute like Visiting Frequency in FPW, and further Visiting Frequency and Time spent on a web page are clubbed together in FTPW as another attribute. The experimental setup uses five users and weights are plotted against various parameters Figure 2 shows the plot of Visiting Frequency v/s Weight of a web page              Figure 2: Plot between frequency and weight Algorithm: FTPW Input: Web traversal path database Output: Weight for each page 1 Calculate PageRank for each page \(PRi 3 2 Initially Set W\(Pi 3 Check the user is registered or not, if YES then 4       whether the user is first time visitor, if YES then 5  return W\(Pi 6    else 7      calculate FW\(Pi 4 


8            calculate TW\(Pi 6 9   SET   W\(Pi Pi Pi 10   return W\(Pi A C B    D 0 0.05 0.1 0.15 0.2 0 5 10 15 20 w ei gh t Visiting Frequency User1 User2 User3 user4 User5 2010 5th International Conference on Industrial and Information Systems, ICIIS 2010, Jul 29 - Aug 01, 2010, India 198  Using the weights calculated in Figure the higher weight for more frequently visited information in FPW algorithm the different the scenario described in Figure 1 for all th plotted in Figure 3            


   Figure 3: Recommendation for Web Path Trave Algorithm  The weight assigned to various pages Visiting Frequency and Time spent on web Figure 4                  Figure 4: Plot between \(frequency + time sp  The Figure 5 gives the details of recomm Traversal for different users by FTPW a weights calculated by considering two para and time spent in Figure 4 which indicates for more frequently visited pages and in term on web pages  0 0.02 0.04 0.06 0.08 0.1 0.12 


0.14 0.16 0.18 W ei gh t Web Pages Us Us Us Us Us 0 0.2 0.4 0.6 0.8 1 1.2 1.4 W ei gh t FTPW \(Frequecy  and 2 which indicate pages. Using this traversal paths in e users have been rsal based on FPW by combining the page is plotted in ent ended Web Path lgorithm and use meters frequency the higher weight s more time spent    


         Figure 5: Recommendation W Algo Figure 6 shows the relative on the synthetic data sets, in w more efficient than FPW algor performance of proposed a increase the complexity of alg and provide better Web Path Tr    Figure 6: Relative Access  The proposed FTPW algorithm parameters which otherwise ar FPW algorithm. A matrix dep comparison between above two parameters are performance ce show that the performance o increase the number of param FPW algorithm to FTPW algori The experimental results d better and provides a methodo optimized Web path traversal past navigation behavior by c page 0 1 2 3 4 5 1 2A 


cc es si bi lit y Ti m e fo r M or e re qu ir ed In fo rm at io n er1\(A->C->D->B er2\(D->B->A->C er3\(D->B->C->A er4\(C->B->A->D er5\(B->A->D->C Time User1 User2 User3 User4 User5 0 0.2 0.4 0.6 0.8 1 1.2 


W ei gh t Web Pages eb Path Traversal based on FTPW rithm  execution for FPW and FTPW hich we can see that FTPW is ithm. Hence, it is clear that the lgorithm increases when we orithm in terms of parameters aversal in less time  ibility time for FPW and FTPW consists of clubbing of various e not available in first proposed icted in the Figure 7 describes proposed algorithms. Here the ntric and a comparison results f the system improves as we eters i.e. when we move from thm rawn for FTPW algorithms are logy for effective, efficient and for various users based on their omputing weight for each web 3 4 5 User FTPW FPW User1\(C->B->A->D User2\(A->B->C->D User3\(B->C->A->D User4\(D->A->C->B User5\(B->D->A->C 2010 5th International Conference on Industrial and Information Systems, ICIIS 2010, Jul 29 - Aug 01, 2010, India 199 Figure 6: Comparison Matrix VI.  CONCLUSION & FUTURE WORK 


 Web Usage Mining have been used in improving Web site design and marketing decision support, user profiling, and Web server system performance. Web page prediction technique is a very important role in web technologies. This paper proposes efficient algorithms for web path recommendation based on Weighted Association Rule. Two factors frequency and time spent were used to decide the web path traversal. The experimental results show that in the proposed approach when we increase the number of parameters for finding the web path the accuracy of the system is enhanced drastically and FTPW produces more accurate results than those achieved by FPW In the future, we shall improve the Web Path Traversal by considering the parameter Data Transfer Rate to provide the accurate Web Path traversal REFERENCES 1] M. S. Chen, X. M. Huang and I. Y. Lin, Capturing User Access Patterns in the Web for Data Mining, Proceedings of the IEEE International Conference on Tools with Artificial Intelligence, pp. 345348, 1999 2]  R. Cooley, B. Mobasher, and J. Srivastava, Web Mining: Information and Pattern Discovery on the World Wide Web, Proceedings of the 9th IEEE International Conference on Tools with Artificial Intelligence, pp 558-567, 1997 3]  B. Mobasher,N. Jain,E. Han et al, Web mining: pattern discovery from World Wide Web transactions, Tech Rep: TR96-050, 1996 4]  C. Shahabi, A. Zarkesh, J. Abidi, V. Shah, Knowledge discovery from user's Web-page navigation,  in Proceedings of the 7th IEEE International Workshop on Research Issues in Data Engineering, 1997 5]  Yue-Shi Lee, Show-Jane Yen, Ghi-Hua Tu and Min-Chi Hsieh, Web Usage Mining: Integrating Path Traversal Patterns and Association Rules, Proceedings of International Conference on Informatics Cybernetics, and Systems \(ICICS'2003 6]  Yue-Shi Lee, Show-Jane Yen, Ghi-Hua Tu and Min-Chi Hsieh, Mining Traveling and Purchasing Behaviors of Customers in Electronic Commerce Environment, Proceedings of IEEE International Conference on e-Technology, e-Commerce and e-Service \(EEE'2004 pp. 227-230, 2004 7]  J. Srivastava, et al. Web Usage Mining: Discovery and Applications of Usage Patterns from Web Data. SIGKDD Explorations, pp. 12-23 2000 


8]  Sergey Brin and Lawrence Page. The anatomy of a large-scale hypertextual Web search engine. Proceedings of the seventh international conference on World Wide Web 7: pp. 107-117, 1998 9]  J. Pei, J. Han, B. Mortazavi-Asl and H.Zhu, Mining Access Patterns Efficiently from Web Logs, Proceedings of the Pacific-Asia Conference on Knowledge Discovery and Data Mining, pp. 396-407 2000 10]  C. H. Cai, A. W. C. Fu, C.H. Cheng and W. W. Kwong, Mining Association Rules with Weighted Items, In Database Engineering and Applications Symposium, Proceedings IDEAS'98, pp. 68  77, 1998 11]  F. Tao, F. Murtagh and M. Farid, Weighted Association Rule Mining using Weighted Support and Significance Framework, In Proceedings of the 9th SIGKDD conference, 2003 12]  Show-Jane Yen, An Efficient Approach for Analyzing User Behaviors in a Web-Based Training Environment, International Journal of Distance Education Technologies, Vol. 1, No. 4, pp.55-71, 2003 13]  Show-Jane Yen, Yue-Shi Lee and Chung-Wen Cho, Efficient Approach for the Maintenance of Path Traversal Patterns, In Proceedings of IEEE International Conference on e-Technology, eCommerce and e-Service \(EEE 14]  M. Spiliopoulou and L. C. Faulstich, Wum: A web utilization miner EDBT Workshop WebDB98, Springer Verlag, 1996 15]  M. S. Chen, J. S. Park and P. S. Yu, Efficient data mining for path traversal patterns,  IEEE Transactions on Knowledge and Data Engineering, pp. 209-221, 1998 16]  H. Yao,H. J. Hamilton, and C. J. Butz, A Foundational Approach to Mining Itemset Utilities from Databases, Proceedings of the 4th SIAM International Conference on Data Mining, Florida, USA, 2004 17]  Z. Chen, R. H. Fowler and A. Wai-Chee Fu, Linear Time Algorithm for Finding Maximal Forward References, Proceedings of International Conference on Information Technology. Computers and Communications  \(ITCC'2003 18]  T. Jing, Wan-Li Zou and Bang-Zuo Zhang, An Efficient Web Traversal Pattern Mining algorithm Based On Suffix Array, Proceedings of the 3rd International Conference on Machine Learning and Cybernetics , pp 1535-1539, 2004 19]  Show-Jane Yen, Yue-Shi Lee and Min-Chi Hsieh, An efficient incremental algorithm for mining Web traversal patterns, Proceedings of the 2005 IEEE International Conference on e-Business Engineering ICEBE05 20]  L. Zhou, Y. Liu, J. Wang and Y. Shi, Utility-based Web Path  Traversal Pattern Mining, Seventh  IEEE International Conference on Data 


Mining Workshops, pp. 373-378, 2007 21]  C. F. Ahmed, S. K. Tanbeer, Byeong-Soo Jeong and Young-Koo Lee Efficient mining of utility-based web path traversal patterns, 11th International Conference on Advanced Communication Technology ICACT09 22]   http://en.wikipedia.org/wiki/PageRank 23] en.wikipedia.org/wiki/Association_rule_mining  Attributes? FPW Algorithm FTPW Algorithm Recognition of User behavior Visiting Frequency Page Rank Time Spent on Web page Page Size Accessibility of required information in less time Improving Web navigation and system design of Web applications  Enhancing server performance 2010 5th International Conference on Industrial and Information Systems, ICIIS 2010, Jul 29 - Aug 01, 2010, India 200 


Enhanced Inte r transaction Association Rules Enhanced Inter transaction Association Rules Enhanced Inter transaction Association Rules Extension of association rules Conditional relationships at multiple different time steps e.g itemset a\(0 0 1 2 You sense Higher data rate than normal AND You see New Route g enerated AND 1 minute a g o you detected checksum gg error packets AND 2 minutes ago your encountered wrong checksum   Implies High Chance of Intrusion Enhanced Rules and Confidence Associative IDS for NextGen Frameworks Dr S Dua LA Tech 21 


Complex Spatio temporal Association Complex Spatio temporal Association Rules Further extension of inter transaction association rules Describe event durations e.g itemset a\(0,X j,Y k,Z Eg  You sense high data rates for X seconds AND new route generated j minutes ago task completed in Y AND new route generated j minutes ago task completed in Y seconds AND checksum error packets received k minutes ago for Z seconds High Chance of Intrusion With highest confidence level in association rules  association rules  Associative IDS for NextGen Frameworks Dr S Dua LA Tech 22 


DMITAR Al ith ARD DMITAR Al gor ith m  ARD Problem Domain Problem Statement and Challenges Aiti Miig bd IDS A ssoc i a ti ve Mi n i n g b ase d IDS  Introduction to data mining Association rule in data mining DMITAR Algorithm  ARD New research Associative IDS for NextGen Frameworks Dr S Dua LA Tech 23 


DMITAR Algorithm DMITAR Difference Matrix Based Inter Transaction Association Rule Miner developed in DMRL Uses vertical data format Differences of the transaction IDs are used to generate extended itemsets Windowless mechanism Associative IDS for NextGen Frameworks Dr S Dua LA Tech 24 


Deep into the Mechanism The DMITAR algorithm is based on lhilii comp l ex mat h emat i ca l assoc i at i ve formulation and proofs Four major parts Four major parts Frequent 1 itemset generation Frequent 2 itemset generation Frequent k itemset generation k>2 Spatio temporal rule formation Associative IDS for NextGen Frameworks Dr S Dua LA Tech 25 


DMITAR, Datasets Used Stock Data Stock Data Daily stock information provided by Yahoo finance Wth Dt W ea th er D a t a Provided by the US Department of Commerce and National Climactic Data Center for 700 locations across US Synthetic Data Provided by a CRU weather generator that uses a Markov chain model to generate simulated weather data for 11 UK sites Associative IDS for NextGen Frameworks Dr S Dua LA Tech 26 


DMITAR Results 1/5 Varying Support DMITAR Results 1/5 Stock Database Support FITI ITPMine PROWL DMITAR 14 6424.7s 132.39s 3.03s 5.556s 16 2348.9s 67.14s 2.14s 4.015s 18 861.92s 34.62s 1.55s 2.89s 20 334.51s 18.89s 1.12s 2.07s 22 143 84s 10 87s 0 87s 1 45s 22 143  84s 10  87s 0  87s 1  45s 24 63.62s 7.15s 0.671s 1.04s Weather Database Support FITI ITPMine PROWL DMITAR 14 36362.6s 893.1094s 5.843s 19.8281s 36362.6s 893.1094s 5.843s 19.8281s 16 11913.04s 378.2188s 3.8906s 13.4375s 18 4116s 170.3438s 2.75s 9.1406s 20 1507s 86.5781s 2.14s 6.203s 22 859.2813s 63.3438s 1.7969s 5.7656s 24 378.5313s 36.1875s 1.4375s 3.5625s Synthetic Dataset Support FITI ITPMine PROWL DMITAR 14 1651.6s 199.843s 3.1406s 17.015s 16 574 32 119 32 2 0938 10 875 16 574  32 s 119  32 s 2  0938 s 10  875 s 18 416.109s 95.31s 1.6094s 7.39s 20 370.25s 83.31s 1.453s 5.8438s 22 265.78s 66.3438s 1.3594s 4.75s 24 133.96s 43.0781s 0.9219s 3.5781s 


DMITAR Rlt  DMITAR  R esu lt s 2  5 Rules Formed Associative IDS for NextGen Frameworks Dr S Dua LA Tech 28 


DMITAR Rl  Varying Maxspan DMITAR  R esu l ts 3  5 Varying Maxspan Associative IDS for NextGen Frameworks Dr S Dua LA Tech 29 


DMITAR Res lts 4/5 Vig Di i DMITAR  Res u lts  4/5 V ary i n g Di mens i ons Associative IDS for NextGen Frameworks Dr S Dua LA Tech 30 


DMITAR Rl  Varying Number of Transactions DMITAR  R esu l ts 5  5 Varying Number of Transactions Associative IDS for NextGen Frameworks Dr S Dua LA Tech 31 


N/C t Rh N ew C urren t R esearc h Problem Domain Problem Statement and Challenges Associative Mining based IDS Associative Mining based IDS Introduction to data mining ii lid ii Assoc i at i on ru l e i n d ata m i n i ng DMITAR Algorithm  ARD h New Researc h Associative IDS for NextGen Frameworks Dr S Dua LA Tech 32 


Further Research Further Research Objectives of Our Intrusion Detection System Development Objectives of Our Intrusion Detection System Development 1 Refine and scale the DMITAR algorithm to suit our application 2 Develop methods for dynamically altering the sensor parameters Our Focus is Securing the NextGen Frameworks with New Technology Technology Associative IDS for NextGen Frameworks Dr S Dua LA Tech 33 


Simulated Sensing Environment Simulated Sensing Environment Screenshots of Data C ollected from S ynthetic Sensors Screenshots of Data C ollected from S ynthetic Sensors Simulated in Our Laboratory Three Steps Slides Collect data Collect data from all sources  all attributes  Select Select the source and their hierarchical attributes attributes to be monitored and Select Select the source and their hierarchical attributes attributes to be monitored  and Sample Sample them at different rates different rates and process them Associative IDS for NextGen Frameworks Dr S Dua LA Tech 34 


Data Collection Simultaneous collection of data screen from ENTITIES aircrafts Associative IDS for NextGen Frameworks Dr S Dua LA Tech 35 Source PRTG Network Monitor software screen shot Demo info www.paessler.com 


Parameter Selection Selection of an ENTITY/aircraft and monitoring its parameters and sensor readings Associative IDS for NextGen Frameworks Dr S Dua LA Tech 36 Source PRTG Network Monitor software screen shot Demo info www.paessler.com 


Sensor Sampling Selecting one sensor/probe and reading it at different resolutions or sampling rates Associative IDS for NextGen Frameworks Dr S Dua LA Tech 37 Source PRTG Network Monitor software screen shot Demo info www.paessler.com 


Si l ti Nt k Si mu l a ti on on N e t wor k Most scenarios can be simulated on a computer or computer network network  The aircrafts and sensors are simulated on a computer network bllb b y ana l ogica l su b stitutions Sensors provide information at different rates Sensors provide information at different rates Need Based Sensor Prioritization NSP and Dynamic Sensing Rate Sampling Associative IDS for NextGen Frameworks Dr S Dua LA Tech 38 


Vulnerability Search Scan 39 Sample UQA script with Nmap performed in DMRL Associative IDS for NextGen Frameworks Dr S Dua LA Tech 39 Source Nmap screenshot with a pearl script  Find Namp on Nmap.org 


Modality Aspect Modality Aspect A Multimodal distribution is a continuous probability distribution with two or more modes of underlying data Mltil d i M u lti p l e mo d es i n our model Associative IDS for NextGen Frameworks Dr S Dua LA Tech 40 Source http://en.wikipedia.org/wiki/File:Bimodal bivariate small.png 


Multi Modality Modality Fusion 41 SENSITIVE  UNCLASSIFIED For Official Use Only Associative IDS for NextGen Frameworks Dr S Dua LA Tech 41 


Emphasis Emphasis Our approach emphasizes on pre empting the attack Our intent is NOT to perform an autopsy to discover attacks Instead we aim to detect and prevent in attacks in real time Associative IDS for NextGen Frameworks Dr S Dua LA Tech 42 


Techniques for Discriminative Rules Techniques for Discriminative Rules Resolution Analysis Features Analyzed at Different Depths Anti Monotonic Principle Modality Aspect Treading into Unexplored Feature spaces Associative IDS for NextGen Frameworks Dr S Dua LA Tech 43 


Representative Outcomes Representative Outcomes Illustration of the Final Analysis Our method shifts between modalities and sampling rates for optimization The blue parallelograms are actual intrusions 44 The blue parallelograms are actual intrusions The Red Green Blue Plots are response of system Associative IDS for NextGen Frameworks Dr S Dua LA Tech 44 


Advantages of Our M ethod Advantages of Our M ethod Exploit the memory v ertical data format utilizes slidin g windows to g form a much larger database to analyze  Flexibility in Choosing what to choose  Choosing what to choose to build the rules Computational and memory efficiency We have a team working only on this aspect 45 Associative IDS for NextGen Frameworks Dr S Dua LA Tech 45 


Preliminary Results Intra transaction Relations Data rate simulator NH-134 Mb HOP PATH update \(Y/N Inference 11.5 Y Y 2 0.120 N N      Y   n 0.345 N NH134 Y/N   Inf 1 0.150 N N 2 0 120 Y N Inter transaction Relations 2 0  120 Y N       5 5.55 0.456 Y Relations  n 0.345 N N Nmap on DMRL nmap.org 


Anticipated Outcome Anticipated Outcome Develop algorithm capable of learning from a given heterogeneous diverse Develop algorithm capable of learning from a given heterogeneous diverse data ff Dynamic algorithmic f ramework designed to shi f t modalities and sampling rates based on complex logic Flexibility of integration into the Snort intrusion detection system 47 Associative IDS for NextGen Frameworks Dr S Dua LA Tech 47 


References References Aircraft Cockpit Image courtesy USAF http://www.faa.gov htt p   www.faa g ov  air traffic  technolo gy  p g  _ gy  Acharya R Dua S Du X Sree V Chua C K Automated Diagnosis of Glaucoma Using Texture and Higher Order Spectra Features To appear in IEEE Transactions on Information Technology in Biomedicine  Du X Dua S 2011 Cancer Prognosis Using Support Vector Regression in Imaging  Modality World Journal of Clinical Oncology 2  1   44 49 Du X Dua S 2010 Salient Frame Extraction Using Support Vector Regression and Motion Features pp 5 Proc of the National Aerospace and Electronics Conference July 14 16 2010 D M P D S 2010 Di i i ti Ft d Cl ifi ti Mthd f D essaue r  M  P  D ua S  2010  Di scr i m i na ti ve F ea t ures an d Cl ass ifi ca ti on M e th o d s f or Accurate Classification 1st ed vol 7704 pp 14 Bellingham WA Proceedings of SPIE Dessauer M P Dua S 2010 Low Resolution Vehicle Tracking using Dense and Reduced Local Gradient Features Maps 1st ed vol 7694 pp 8 Bellingham WA Proceedings of SPIE SPIE 


Acknowledgements Acknowledgements Fundin g A g encies  US 4 1 Million direct fundin g g g 4 g LA BoR NIH NSF AFRL AFOSR and NASA Research Team Samuel Kasimalla Brandy McKnight Dr Pradeep Chowriappa Connor Johnson Vasanth Nair Mihir Chowriappa  Connor Johnson  Vasanth Nair  Mihir Karnik Mohit Jain and Swadheen Songmen Associative IDS for NextGen Frameworks Dr S Dua LA Tech 49 All the respective Logos belong to their owners 


Rf d Rdi R e f erence d R ea di ngs Copyright of cover pages held by respective publishers 


Thank You Questions Thank You  Questions Dr Sumeet Dua E mail sdua@latech.edu Web http://dmrl.latech.edu Associative IDS for NextGen Frameworks Frameworks Dr S Dua LA Tech 51 Image Source roadtrafficsigns.com 


