Stock Trading Rule Discovery Based on Temporal Data Mining Asadullah Al Galib 1 Mahbub Alam 2 Nowshad Hossain 3 Rashedur M Rahman 4   Department of Electrical Engineering and Computer Science, North South University Bashundhara, Dhaka, Bangladesh  
1 asad.galib@hotmail.com 2 maha_sayz@live.com 3 nowshad_hossain@hotmail.com 4 rashedur@northsouth.edu Abstract 227 One of the major tasks in stock market analysis is the discovery of specific events that give rise to a particular event. In this research we emphasize on temporal data mining with a time 
dimensional approach. This has led us to the discovery of sequential continuous patterns. The patterns serve as rules that enable us to determine the occurrence of an event on a particular stock-transaction day. In our paper, we have proposed and implemented the STRDTM \(Stock Trading Rule Discovery by Temporal Mining\gorithm with real life data from Dhaka Stock Exchange as input Keywords\227 Datamining, temporal datamining sequential pattern discovery, frequent sets, association rule mining I  INTRODUCTION The Dhaka stock exchange \(DSE th e cen tral s t ock exchange in Bangladesh with 448 companies \(as of 2009\All 
of these corporations are categor ized according to their market capitalization in the DSE The stock market gives rise to an environment of fluctuating stock prices and generates a huge amount of data collected in the form of event time sequences.  The stock market, given its pestering and confusing environment, serves as an apt and ample problem to which the concept and techniques of temporal data mining could be applied. The outcome from this procedure can again be verified with the statistical suggestions to determine how effective temporal data mining on DSE could serve as an indicator The stock market gives rise to time sequences, so it would 
be quite interesting to take note of the various events that progress with time and then concentrate on specific events at particular time periods or analyse the frequency of the occurrence of events for a detailed and informative monitoring process for the prediction of future behaviour. We are interested in the sequence of actions or events that leads to such particular action \(let\222s note them basic events and target event, respectively  So, we intend to mine the target rules rules ending with a target event\n the basis of the training set taken into consideration. Thereafter, all the high confidence rules shall be implemented to determine suitable 
suggestions on the basis of certain events occurring on that day. This is our main objective of research A  Statistical Analysis Shareholders use a number of indicators to determine how much a stock is worth. These might include both fundamental and technical analysis. Fundamental analysis includes the observance of historical behaviour of a stock, rumour broker\222s claim whereas technical analysis includes well educated guesses on stock behaviour. One simple indicator is the price/earnings ratio. This is the price of the stock divided by the earnings per share. Other indicators include analysis of graphs such as MACD \(moving average convergence 
divergence\d PPO \(percentage price oscillator Because of the unpredictability of the stock trading nature of DSE, a survey was undertaken amongst the experienced stockholders to understand the individual point of discretion of whether to buy or sell a share. On the other hand all modes of technical analysis were prepared to verify the extent of coherency of stockholder\222s opinion to statistical approach. As a consequence of this integration and matching scheme MACD turned out to be the most effective indicator in identifying a bullish or bearish market with a 66.23 superposition B  Related Work Mining of sequential patterns was introduced by R Agrawal and R. Srikant in [1 T h ey atte m p ted to d i sco v er 
sequential patterns from a database of sequences, where each sequence was a list of transactions ordered by transaction time, and each transaction was a set of items The research idea described in this paper was inspired by the idea proposed by E. Gudes and L. Marina t h ei r  paper, the authors proposed two algorithms, CTSPD Continuous Target Sequential Pattern Discovery\ and CSPADE \(Continuous Sequential Patterns Discovery using Equivalent Classes\, to discover the customers interested to take the upgraded products of a telecommunication company based on the previous usage data of those customers. The basic idea behind STRDTM comes from the CTSPD algorithm. However, we have made substantial modifications 
to represent our own datasets of stock prices, the sequence database, and above all incorporating the object oriented concept to existing algorithm. Besides, the system could trigger trading rules automatically if regular stock prices from DSE are fed to the system II  ALGORITHM  DESCRIPTION A  Definition and Problem Statement A dataset D is collected from the DSE and filtered according to particular companies as shown in Table 1. As observed, transaction encountered are usually of the type 


213 tradecode, startd, endd, event 1 event 2 205, event n target 233 where event i is the basic event occurring at startd, endd  s  shown in Table 2, and an aggregation of those events is referred to as itemset. Each basic event is associated with the period between startd and endd and each target event is associated with outcomes of the MACD graph as shown in Figure 1   Furthermore, an ordered list of itemsets denoted by l 1   target 1  l 2  target 2  205 l n  target n is called a sequence \(denoted by s where l i is an itemset of basic events and target i  is an event with the boolean feature buy/sell Hence more formally l i denotes the i th basic event and target i  is the i th target level Now a sequence may not necessarily begin with a basic event or end with a target event so in those cases the following sequence may be observed target 1 l 1  target 2  l 2  205 target n  l n The filtered data from dataset D has been sorted by the timestamp in order to generate a single sequence as shown in Table I and is referred to as stock-sequence S D  For a sequence s as mentioned earlier a level is defined as an itemset giving a target event l i target i where i is the i th  level\he absence of a target event or an itemset at any particular level it is then represented as NULL. For example, a sequence target i l i+1  is segregated in the following manner NULL target i and l i+1 NULL  Definition 1 The length of a sequence is the number of levels in the sequence so for the previous sequence target i l i+1 the length is 2  Definition 2 The size of a sequence is the number of events in the sequence  For instance, the sequence l i  target i l i+1  can be represented as AB U C where length equal to 2 and size equal to 4 Definition 3 Provided s\222 is a subset of a sequence s support count indicates the number of occurrences of s\222 in s  Consequently support of sequence s\222 is defined as fraction of transaction \(which in this case is the sequence s that contains a sequence s\222. Support s\222\/n where is n is number of levels in sequence s  Definition 4 Target rule is a sequence trailed with any target event Definition 5 The confidence for target rule, denoted by conf  s defined as the fraction of how often the items in the consequent appears in transactio ns that contain the antecedent A rule with minimum support and minimum confidence is called a frequent rule For instance if s\222=A U B U\222 then Confidence\(s\222 s\222 A U B Given a transaction dataset as defined above, the problem of mining target events rules using continuous sequential mining is to find all frequent target rules B  Algorithm 1  Event Generation  The frequent events corresponding to certain happenings in regard to the stock database such as increase or decrease of attribute values are stored in a database, as partly shown in Table VII  Thereafter the events are mapped to certain integers which serve as positions or indices which are made in 1 in a bit string. For example, the event A in a 4-bit string would be specified as 1000 whereas C would become 0010  2  Getting the Transformed Database Here our prime focus is to generate the single sequences, as mentioned earlier corresponding to an individual company. The events including the target events found earlier are integrated to form the single sequences. However, an infrequent event shall not be utilised in the formation. Moreover, the concept of an individual level is hereafter transformed to that of a pair-level \(i.e l i  target i  where i is the ith pair-level\w the mapping of a pair-level is as follows: AB U is represented by 1100 1. We use single bit for target level, that is set to 1 if the target true and to 0 otherwise 3  Frequent Sequence Generation Plevels and Plevelsd of the form itemset target and target itemset respectively, are extensively used to determine the frequent sequences of size 2. These 2-sequences are used later to generate the k-sequences using appropriate joins. As an attempt to determine all the frequent sequences we carry out multiple passes over the database. In each pass, the ksequence is used to generate the next probable k+1 sequences which are considered as candidates The candidates then undergo a pruning process as shown in Algorithm 1  The frequent candidates now serve as the frequent sequences for the next sequence generation 4  Rule Generation  This is the ultimate part where all the frequent sequences which end with a target event are filtered. The sequences then are subjected to a pruning process, which is the removal of sequences that fail to satisfy the minimum confidence set by the programmer 5  Explanation of Joins used in our program We have currently implemented two different kinds of joins in order to generate the next possible frequently occurring sequences First we have implemented the ExpJoin h ic h tak e s in two sequences S1 and S2 as parameters. The sequences s1 and s2 are of the same length i.e. must have the same number of pair-level. Considering S1 and S2 to be k-sequences, the expjoin\(\ill generate k+1 sequence. Then a suitable pairlevel is selected for performing the expansion join provided that all other pair-levels are the same  For example, two sequences U\222 AC U and U\222 AE U form the candidate U\222 ACE U The join used works in a similar fashion as that of the itemset generation of the Apriori algorithm[1  The ConcatJoin w o rks i n a s i m i lar f a sh ion b y ta k i ng in two inputs, s1 and s2 where s1 is k-sequence and s2 is a 2sequence. The procedure performs a join only if the last level of sequence s1 superposes with the first level of s2 or vice versa  As a result we generate a maximum of two new candidates from a single pair. For example, two sequences U\222 AC U and U C. The new candidate is U\222 AC  U C  6  Explanation of Target Event Generation As mentioned earlier, an integration and comparison of the stockholder\222s discretion with the statistical analysis assured us in using the traditional MACD graph  to analyse stock in DSE The MACD 3  s a t ren d f o l l o w i n g m o m e n t um  i n di cat or t h at  shows the relationship between two moving averages The MACD is calculated by considering the difference between a 26-day and 12-day period exponential moving average \(EMA of closing prices. Subsequently we generated the EMA for a 9-day period of the MACD itself. This produces the signal which can trail the MACD and makes it easier to spot turns in MACD as shown in figure I. A bullish crossover occurs when MACD turns up and crosses above the signal line i.e target i buy A bearish crossover occurs when MACD turns down and crosses below the signal line i.e target i sell More details about MACD could be found elsewh  


 Figure 1: MACD Graph Algorithm1: L2 Generation GenerateL2   Plevels Contains sequence of type basic event  target event   Plevelsd Contains sequence of type target event  basic event   for each element in Plevels generate sequence of size 2 prune infrequent sequences using Prune   for each element in Plevelsd generate sequence of size 2 prune infrequent sequence using Pruned    Algorithm2: Lk Generation & Rule Generation Main  Result = null  while L k null Result = Result U L k   for int i=0 ; i<Lk_index ; i  for int j=i+1 ; j<Lk_index ; j  ExpansionJoin Lk j    Candidate[cand_ind frequent sequences generated by ExpansionJoin after pruning  for int k=0 ; k<L2_index ; k  ConcatenationJoin Lk 2 k    Candidate[cand_ind frequent sequences generated by ConcatenationJoin after pruning using ConcatPrune  for int i=0 ; i<cand_index ; i Result = Result U Candid   for int i=0 ; i<Result_index ; i if \(Resu d s  w i th tar g et ev en t  calculate confidence as per formula if \(confidence min_conf Rules[Rules_index e s u lt[i     Algorithm3: Pruning Prune String s1, String s2   if \(sequence s1 subset_of sequence s2 calculate support of sequence s1  if \(support min_supp return false else return true  Algorithm4: ExpansionJoin ExpansionJoin String s1, String s2   lev = -1 if \(length of seq s1 length of seq s2  for int i=0 ; i<length_s1 ; i if \(plevel_s1 i plevel_s2 i  if target level of s1  target level of s2  if \(lev == -1 lev = I else return as more than one plevel has been matched else return as targets mismatch if \(lev == i  return as no plevels have been matched Temp = Expand s1 and s2 at lev  Candidate = !Prune\(Temp   Algorithm5: ConcatenationJoin ConcatenationJoin String s1, String s2   if \(s1.firstLevel == s2.lastLevel Temp = Concatenate s2 and s1 Candidate = !ConcatPrune\(Temp If \(s1.lastLevel == s2.firstLevel Temp = Concatenate s1 and s2 Candidate = !ConcatPrune\(Temp  III  RESULTS  AND  FINDINGS On the basis of the stock market data available to us we utilized three months data of a particular company \(AB Bank with trade code 100\ generate the transformed dataset T D  shown partly in Table VII & VIII\ with the frequent basic events and target events. The rules generated on the sequential patterns comply with min_support 9 and min_conf 89. In the testing phase we look for the occurrence of certain basic events on a particular day of testing, we thereafter scan for a high confidence rule such that the set of basic events in the rule is a subset of the of the basic events occurring on that day. In the case of similar confidence, we look for the rule with the highest support TABLE  I  DATASET  D Training Trade Code Dat e LTP High Low Close Price Volume 100 3/1 1170 1188 1135 1140 445105 TABLE  II  FREQUENT  BASIC  EVENTS Description Alpha Support Number Binary high u A 42 0 10000000 high d B 55 1 01000000 low u C 48 2 00100000 low d D 50 3 00010000 closeprice u E 40 4 00001000 closeprice d F 57 5 00000100 volume u G 45 6 00000010 volume d H 55 7 00000001    


TABLE  III  FREQUENT  TARGET  EVENTS Description Alpha Support Binary buy y 40 1 sell n 60 0 TABLE  IV  2-SEQUENCE  CANDIDATES Pattern Sequence Supp Count 10000000;0 A U\222 12 10000000;1 A U 13 01000000;0 B U\222 22 0-10000000 U\222 A 13 1-10000000 U A 12 0-01000000 U\222 B 21 TABLE  V A FRACTION OF THE FREQUENT SEQUENCES  Pattern Sequence Supp Cou nt 01010000;0 0-01000000;0 01000000;0-01000000 0-00100001 BD U\222 U\222 B U\222 B U\222 B U\222 CH 16 20 14 12 0-01000001;0 01000000;0-01000000;0 0-00000010;0-01000000 U\222 BH U\222 B U\222 B U\222 U\222 G U\222 B 12 14 12 0-01000000;0-01000000;0 U\222 B U\222 B U\222 13 T ABLE VI  RULES PATTERN  Pattern Sequence Sup p Cou nt Conf 0-00000010;0 0-00010000;0 0-01010000;0 01000000;0-01000000;0 01000000;0-00000001;0 0-01000000;0-1000000;0  0-01000000;000000001;0 1-10000000;1 0-01000000;0 0-10000000;0 1-00010000;1 1-00000001;1 0-01000001;0 00010000;0-01000000;0 0-00100000;0 0-00000001;0 U\222 G U\222 U\222 D U\222 U\222 BD U\222 B U\222 B U\222 B U\222 H U\222 U\222 B U\222 B U\222 U\222 B U\222 H U\222 U A U U\222 B U\222 U\222 A U\222 U D U U D U U\222 BH U\222 D U\222 B U\222 U\222 C U\222 U\222 H U\222 17 16 14 14 13 13  13  12 20 12 12 12 12 12 17 17 100 100 100 100 100 100  100  100 95 92 92 92 92 92 89 89 IV  PERFORMANCE  EVALUATIONS T ABLE VII  TEST  SET  1 TEST SET 1 trade code star tdat e end date high low clos e pric e Vol ume sugg estio n outc ome 100 19/1 20/1 u u u u sell sell 100 20/1 21/1 u u u u sell sell 100 21/1 24/1 u u u u sell sell 100 24/1 25/1 d u d d sell sell 100 25/1 26/1 s u d d sell sell 100 26/1 27/1 u u u u sell sell 100 27/1 28/1 u u d d buy sell 100 28/1 31/1 u d U u buy sell 100 31/1 1/2 u u U u buy sell 100 1/2/ 2/2 u u U d buy sell Using the rules obtained \(Table VI\e outcomes for the test data shown in table VII were generated. On comparing the results with the graph we can successfully infer the accuracy of the rules to be 60% \(in this case\ we notice the graph for the month of January we notice that the small avg is lower than the long avg So, we can clearly state that this would be a suitable \223 sell\224 situation and our rules imply just that, but fail to identify the change or transition from the \223 sell 224 state to the 223 buy 224 state. Hence, the discrepancies are observed. The bolded outcome refers to an incorrect output Let us consider another test set presented in Table VII T ABLE VIII  TEST  SET  2 TEST SET 2 trade code star tdat e End date hi gh lo w clos e pric e Vol ume sugg estio n outco me 100 15/2 16/2 D d d u buy buy 100 16/2 17/2 D d d d buy buy 100 17/2 18/2 D d u d buy buy 100 18/2 22/2 U u d d buy buy 100 22/2 23/2 D d d d buy buy 100 23/2 24/2 D d d d sell buy 100 24/2 25/2 D s d u sell sell 100 25/2 28/2 D d d u sell sell 100 28/2 1/3 D d d d sell sell 100 1/3 2/3 D d s d sell sell The suggestions made on the second test dataset were quite efficient in comparison to the first, the rules misjudged the outcome on 23 rd of Feb \(it was supposed to be \223 sell 224 Thereby for the second test data we achieve an efficiency of 90 V  CONCLUSION The rules generated by our algorithm are accurate to a certain extent compared to MACD approach. The rules suggest investors on the basis of prior data related to a particular stock. With the two test datasets used, we find accuracy of 60% and 90%, respectively. On an average the rules were found to be 70% accurate with tests conducted on various test datasets. Though the results are not 100 complied with the results found by MACD approach, we believe our current attempt reveals the importance of using and further investigating temporal and sequential pattern mining strategies on DSE. As a future work, we would like to test our algorithm with different timing windows rather than a fixed one and derive the rules that will change dynamically with respect to stock market behaviour REFERENCES 1  Rakesh Agrawal and Ramakrishnan Srikant Mining Sequential Patterns In Proc. Of the 11 th Int\222l Conference on Data Engineering Taipei, March 1995 2  Ehud Gudes and Litvak Marina Discovering Target Event Rules based on time-consecutive Pattern Mining 4 th IEEE Conference on Data Mining, Brighton, UK, November 2004 3  MACD Retrieved on 17 th March 2010[Onlin A v a i la b le  http://stockcharts.com/school/doku.php?id=chart_school:technical_indi cators:moving_average_conve  4  Yahoo! Finance website http://finance.yahoo.com  5  Dhaka Stock Exchange website http://www.dsebd.org  6  Appel, Gerald Technical Analysis Power Tools for Active Investors  Financial Times Prentice Hall. pp. 166, 1999 


 Figure 8  Probabilistic inference results for the 26 th student IV  C ONCLUSIONS  A decision support system of integrating DM and BBN is designed to predict the student learning outcomes. It contains four steps: fuzzy theory to identify the factors on learning outcomes; data mining to construct influence diagram machine learning to establish probability tables; and the model to predict the exam scores at the beginning of course and thereby to help students enhance their scores according to their weakness. This system is acceptable because the accuracy rate of prediction on passing calculus is 82.6 A CKNOWLEDGMENT  The authors would like to thank the National Science Council of Taiwan for financially supporting this research under Contract NSC 98-2511-S-131 - 001 R EFERENCES  1  H.J. Walberg, Improving educational productivity,Ž Philadelphia Laboratory for School Success. Retrieved April 2005, from http://www.temple.edu/lss/pdf/publications/pubs2003-1.pdf, 2003 2  O. Simpson, Predicting student success in open and distance learning,Ž Open Learning 21\(2\5…138, 2006 3  P.H. Zhu, Learning factors for technical school students,Ž taipei college of business journal, 12, pp.81-94, 2007.\(in Chinese 4  O. Koller, J. Baumert, M. Clausen, I. Hosenfeld, Predicting mathematics achievement of eighth grade students in Germany: an application of parts of the model of educational productivity to the TIMSS data,Ž Educational Research and Evaluation, 5\(2\, pp.180 194, 1999 5  X.C. Xu, Factors affecting the physical and chemical subjects to junior high school students,Ž master thesis of physics department in Changhua normal university, 2001. \(in Chinese 6  C.F. Liu, Bayesian network as a prediction and diagnosis system for math-related factors,Ž master thesis of department of information engineering of Tamkang university, 2004 7  R.S. Gravoso, A.E. Pasa, T. Mori, Influence of students prior learning experiences, learning conceptions and approaches on their learning outcomes,Ž Higher Educati on Research and Development Society of Australasia's Annual Conference, pp.282-289, 2002 8  M. Laukenmann, M. IBleicher, S. Fub, M. Glaser-Zikuda,  P Mayring, C. Rhoneck, An investigation of the influence of emotional factors on learning in physics instruction,Ž International Journal of Science Education, 25\(4\, pp.489…507, 2003 9  R.M. Smith, P.A. Schumacher, Predicting success for actuarial students in undergraduate mathematics courses,Ž College Student Journal, 39\(1\65-177, 2005 10  S. Gupta, D.E. Harris, N.M. Carrier, P. Caron, Predictors of student success in entry-level undergraduate mathematics courses,Ž College Student Journal 40\(1\006 11  B.M. Gadella, M. Baloglu, R. Stephen, Prediction of GPA with educational psychology grades and critical thinking scores Education, 122\(3\3, 2002 12  Y.Z. Zheng, Learning motivation of physics for vocational students,Ž master thesis of physics department in Changhua normal university, 2004. \(in Chinese 13  J.I. Lee, Bayesian network-based computerized adaptive test selection strategies,Ž master thesis of department of mathematics education in Taichung normal university, 2004. \(in Chinese 14  F. Nassera, B. Freskob, Predicting student ratings: the relationship between actual student ratings and instructors predictions Assessment & Evaluation in Higher Education, 31\(1\pp.1…18, 2006 15  U.H. Chang, Application of Bayesian network in the production performance evaluation and prediction,Ž master thesis of institute of industrial engineering and management information of Tokai university, 2007. \(in Chinese 16  K. Mckenzie, R. Schweitzer, Who Succeeds at University? Factors predicting academic performance in first year Australian university students,Ž Higher Education Research & Development, 20\(1 34, 2001 17  M. Bong, Role of Self-Efficacy and Task-Value in Predicting College Students Course Performance and Future Enrollment Intentions,Ž Contemporary Educational Psychology, 26, pp.553…570 2001 18  H.J. Zhi, learning styles and methods on the impact of learning master thesis of department of information management of Chungyuan christian university, 2003. \(in Chinese 19  C.M. Ping, Prediction of Student Academic Performance with Psychological Constructs beyond Academic Skills,Ž Journal of Humanities and Social Sciences, 1\(1\, 2005 20  R.L. W illiams, L. Clark, College students ratings of student effort student ability and teacher input as correlates of student performance on multiple-choice exams,Ž Educational Research, 46\(3\29-239 2004 21  Q.C. Yeh, Using fuzzy set theory to analyze calculus learning Psychological Testing, 54\(1\.175-196, 2007. \(in Chinese 22  D.I. Cai, Fuzzy set theory for mathematics learning,Ž master thesis of department of mathematics of Tamkang university, 2005. \(in Chinese 23  K.J. Huang, A study on learning attitudes for calculus,Ž master thesis of department of applied mathematics of National Chiao Tung University, 2005. \(in Chinese 24  E.C. Kalkani, L.G. Boussiakou, I.K. Boussiakou, Students SWOT analysis in mechanics of materials determines the action plans for students and instructor,Ž World Transactions on Engineering and Technology Education, 3\(2\p.217-222, 2004 


TABLE III R ESOURCE L EAK I SSUES FROM BUG TRACKING SYSTEM AND V ERIFYING R ESULT  Issue i RI RF RP Duration Affected Files Description Detected  LUCENE-720 478239 478241 1 1days org.apache.lucene.index TestIndexFileDeleter.java org.apache.lucene.index TestBackwardsCompatibility.java added a few missing close's Yes LUCENE-1374 691617 691694 1 1days org.apache.lucene.index TestIndexWriter.java Cannot 002nd close method so this looks like a descriptor leak Yes LUCENE-1455 150802 783595 2295 2527days org.apache.lucene.ant.HtmlDocum ent.java A stream is not closed which may be a descriptor leak Yes LUCENE-2106 836154 887899 87 23days org.apach.lucene.benchmark byTask.tasks.ReadTask.java ReadTask does not close its Reader when OpenReader or CloseReader are not used No CASSANDRA-71 769874 770424 10 1days org.apache.cassandra.db Table.java Close FileStructs after range query Partially CASSANDRA-313 789465 797173 58 24days org.apache.cassandra.db 002lter.CommitLog.java Close temporary logWriters to avoid leaking FD Yes CASSANDRA-1188 932431 954572 246 67days org.apache.cassandra.db.\002lter SSTableNamesIterator.java Close FileStruct in SSTableNamesIterator when opened locally Partially  i https://issues.apache.org/jira/browse/ISSUE  NAME speci\002cation miners Weimer et al present an automatic speci\002cation mining algorithm that uses information about error handling to learn temporal safety rules Kremenek et al use Bayesian learning to match methods with a prede\002ned automata template for speci\002cations J Bloch from Google proposes a new Java 7 feature called Automatic Resource Managements ARM 8  which aims at automatically close resource when it is not used With ARM a few statements would be automatically added by complier to close declared resources within a try statement This proposal is actually a syntax improvement to developers However ARM can only handle local resources leak within method scope In contrast our approach is able to report missing resource closure within class scope or across classes VI C ONCLUSION In order to improve the pattern universality and detect resource leak before code check-in this paper proposes an approach to record the most valueable base API calls during program execution and mine resource usage patterns from the API call traces The patterns are further veri\002ed with real resource leaks from large open source projects The results show that resource usage patterns mined by our approach are universal to detect resource leaks in various projects R EFERENCES 1 B Wright E Perry M Sanko and T Pfaef\003e 223Oracle 9i JDBC developer's guide and reference,\224 Tech Rep May 2002 2 B Livshits and T Zimmermann 223Dynamine Finding common error patterns by mining software revision histories,\224 in Proceedings of ESEC/FSE  2005 pp 296\226305 8 http://jnb.ociweb.com/jnb/jnbMay2010.html#arm 3 Z Li and Y Zhou 223PR-miner Automatically extracting implicit programming rules and detecting violations in large software code,\224 in Proceedings of ESEC/FSE  2005 pp 306\226315 4 H Kagdi M L Collard and J I Maletic 223An approach to mining call-usage patternswith syntactic context,\224 in Proceedings of ASE  2007 pp 457\226460 5 A Michail 223Data mining library reuse patterns using generalized association rules,\224 in Proceedings of ICSE  2000 pp 167\226176 6 M Acharya T Xie J Pei and J Xu 223Mining API patterns as partial orders from source code from usage scenarios to speci\002cations,\224 in Proceedings of ESEC/FSE  2007 pp 25\22634 7 C C Williams and J K Hollingsworth 223Automatic mining of source code repositories to improve bug 002nding techniques,\224 IEEE Transactions on Software Engineering  vol 31 pp 466\226480 June 2005 8 G Ammons R Bod 264 021k and J R Larus 223Mining speci\002cations,\224 in Proceedings of POPL  2002 pp 4\22616 9 J Yang D Evans D Bhardwaj T Bhat and M Das 223Perracotta mining temporal API rules from imperfect traces,\224 in Proceedings of ICSE  2006 pp 282\226291 10 M Gabel and Z Su 223Symbolic mining of temporal speci\002cations,\224 in Proceedings of ICSE  2008 pp 51\22660 11 H Zhong L Zhang T Xie and H Mei 223Inferring resource speci\002cations from natural language API documentation,\224 in Proceedings of ASE  2009 pp 307\226318 12 R Agrawal and R Srikant 223Mining sequential patterns,\224 in Proceedings of ICDE  1995 pp 3\22614 13 T Xie and J Pei 223MAPO Mining API usages from open source repositories,\224 in Proceedings of MSR  2006 pp 54\22657 14 K Chow X Xing Z Wu and Z Yu 223An empirical study of data mining code defect patterns in large software repositories,\224 in Proceedings of PNSQC  2009 15 A Igarashi and N Kobayashi 223Resource usage analysis,\224 ACM Transactions on Programming Languages and Systems  vol 27 pp 264\226313 March 2005 16 D Lo and S.-C Khoo 223SMArTIC Towards building an accurate robust and scalable speci\002cation miner,\224 in Proceedings of FSE  2006 pp 265\226275 17 W Weimer and G C Necula 223Mining temporal speci\002cations for error detection,\224 in Proceedings of TACAS  2005 pp 461\226476 18 T Kremenek P Twohey G Back A Ng and D Engler 223From uncertainty to belief inferring the speci\002cation within,\224 in Proceedings of the 7th OSDI  2006 pp 161\226176 


mining procedures. Our motivation in this study is to utilize the redundancy for extracting algorithm of fuzzy association rules IV. IMPROVEMENT OF APRIORI ALGORITHM BASED ON If max{Conf\(Z ? y X ? y max{CF\(Z ? y X ? y ZEQ Proof From the assumption, there exist P E Q that satisfY Con/\(P ? y X ? Y P ? y 0: CF\(X ? Y CF\(X ? y P ? Y Z ? V ZEQ 70 The necessary point in the Apriori algorithm for extracting association rules is to generate the frequent item sets efficiently Though the confidence of the association rules are calculated mally after all decision of frequent itemsets in traditional Apriori algorithm, the basic idea of our proposal is that the confidence of the rule can be calculated after each step A3 in the Apriori algorithm and used for pruning the redundant itemsets. The issue is to decide which itemset should be pruned utilizing the confidence information. Then we define "strong redundant rule" and "strong redundant itemset Confidence 1.0 2 3 4 The number of items Figure 2. Conceptual Diagram of Pruning Method Definition 2: Let X ? Y be a fuzzy association rule, where X and Yare fuzzy item sets. Let Q be Q = 2 x - X If min\(ConJ\(Z ?Y X ?Y ZEQ X ? Y strong redundant rule Let k-rule denote the rule that has k attributes\(items consequent part, and the "subset rule" denote that itemset corresponding to the rule is subset of the item set of larger rule and the consequent parts of both rules are the same set Definition 3: Let Z be a fuzzy itemset that has k items\( k>2 When all the k-rules generated from Z are strong redundant, we call the itemset Z strong redundant itemset Fig.2 shows the concept of strong redundant rule and strong redundant itemset. Since the Apriori algorithm generates the candidate itemsets in tum from l-itemsets, the pruning based 


on the redundancy should be performed simultaneously In addition to the basic Apriori algorithm, the following procedures are employed for k> I as A4 confidence of k-rule based on Lk and Lk.j AS The concept of the procedure is that the confidence value of rule should increase by increasing the number of antecedent items. In other words, the procedure is based on valid heuristics that the combination of items in antecedent part which deteriorates the confidence value will become redundant in the following iterations. We can expect reduction of computational time and redundant rules pruning by the additional procedures It should be noted that the confidence calculation in each iteration does not lead to the increase of overall calculation time in association rules mining v. NUMERICAL EXAMPLES We develop the fuzzy mining system based on the redundancy pruning and evaluate the proposed algorithms through numerical examples. We apply the system to "abalone data" available from the vcr Machine Learning Repository[7 The abalone data set consists of 4177 measured data with 1 nominal attribute and 8 continuous attributes as shown in 71 Table. I. In the experiments, the nominal attribute is transformed to the continuous attribute. Table 2\(a statistics and the fuzzy partition information of attributes are summarized in Table 2\(b wider than the actual data distribution for performance evaluation. The fuzzy partition example is shown in Fig.3. We use two types of fuzzy sets with different width, i.e. triangle type and trapezoid type. Although it is better to use the factor such as "interesting" for pruning the derived rules in addition we apply the native association rule extraction for proposed algorithm evaluation. The minimal support is set as 0.2 Table.l. Abalone Data No Input Output xl x2 x3 x4 x5 x6 x7 x8 y I 00.455 0.365 0.095 0.5140 0.2245 0.1010 0.150 15 2 00.350 0.265 0.090 0.2255 0.09 95 0.0485 0.070 7 3 2 0.530 0.420 0.135 0.6770 0.2565 0.1415 0.210 9 


4177 010710 0.555101 9511948510 9455 0.3765 10.4 95 1 12 Table.2. Statistical Information and Fuzzy Sets Settings a xl x2 x3 x4 x5 x6 x7 x8 y Min 0 0.075 0.055 0.00 0.002 0.001 0.001 0.002 I Max 2 0.815 0.650 1.13 2.826 1.488 0.760 1.005 29 b xl x2 x3 x4 x5 x6 x7 x8 y Mininum center of 0 0 0 0 0 0 0 0 0 fuzzy set Maximum center of fuzzy set 2 2 2 5 5 2 2 2 30 Number of 3 II II II II II II II 16 partitions Membersh ip Value Lk Di- X2 Membership V 0.0 2.0 Figure 3 Example of Fuzzy Partition 12000 10000 8000 6000 4000 2000 40 en d en E 30  25 0:; 20 0 15 \(1 n 


E 10 s c 1 fr/l 60000 2 s 0 50000 l ro 40000  l 4-; 30000 0 l D 20000 E s s:: 10000 <l s f0 0.7 Itemset Size Figure 4. Results by Apriori Algorithm Candidate Frequent 4 6 The number of itemsets Figure 5. Results by the Proposed Algorithm Extracted Rules Non-Redunda nt Rules 0.75 0.8 0.85 0.9 0.95 Min imal Confidence\(Threshold Figure 6. The number of extracted rules by the conventional algorithm 9 The results by standard Apriori algorithm for fuzzy association rules mining are shown in Fig.4. At around 4th item set calculation, much waste computation is fulfilled. From the results, it can be seen that the waste computation should be reduced 72 250 


Vl 200 0 <I Q d 0 0 .... 100 <I D E ::: 50 I  f0 Deleted Non-Redundant Rules ___ Deleted Rules r 0.7 0.75 0.8 0.85 0.9 0.95 Minimal Confidence\(Threshold Figure 7. The number of deleted rules by the proposed algorithm Fig.5 shows the results of reduction of itemsets by the proposed algorithm. We can see that fair itemsets are pruned by the proposed method. Fig.6 shows the number of extracted rules by the conventional Apriori algorithm. Many redundant rules are extracted as well as the necessary non-redundant rules Our issue is to restrain the extraction of redundant rules. Fig.7 shows the results of the number of deleted rules by the proposed algorithm. Some redundant rules are deleted simultaneously along with frequent itemsets extraction However, since a few non-redundant rules are also unexpectedly deleted at the lower threshold value of minimal confidence, we have to investigate further about heuristics, i.e strong redundant itemsts and relation of threshold values. It should be noted that the number of deleted rules has less dependence on the minimal confidence These results are promising in terms of computational time and redundant rules pruning. However, the improvement is limited in terms of computational time. We consider that the performance of the proposed method must be improved by applying the output field specification method[17]. We expect that the number of pruned rules becomes larger based on the specifications. Moreover, the other measures to prevent redundant rules extraction in fuzzy association rules mining 


could be applied as well as the proposed algorithm VI. CONCLUSION In this paper, we proposed a basic algorithm based on the Apriori algorithm for rule extraction utilizing redundancy of the extracted rules, in order to improve the efficiency of the association rules mining and to prune the redundant rules extracted. We also proved the redundancy defmition of the rule based on the CF\(certainty factor algorithm was evaluated through numerical experiments using benchmark data, "Abalone". From the results, the method was found to be promising in terms of computational time and redundant rule pruning. Our future plan includes sophistication of the proposed algorithm, application to the huge data mining problem, and further improvement of fuzzy association rules mining REFERENCES I] R. Srikant and R. Agrawal, "Mining Generalized Association Rules Proc. of the 21" VLDB Conf, pp.407-419, 1995 2] R. Srikant and R. Agrawal, "Mining Quantitative Association Rules in Large Relational Tables," Proc. of the ACM Corif. on Management of the Data, pp.I-12, 1996 3] G. Chen and Q. Wei, "Fuzzy Association Rules and the Extended Mining Algorithms," Iriformation Sciences, Vo1.l47, pp.20 1-228, 2002 4] H. Ishibuchi H. and T. Yamamoto, "Fuzzy Rule Selection by Data Mining Criteria and Genetic Algorithms," Proc. of Genetic and Evolutionary Computation Coriference, pp. 399-406, 2002 5] Y. Hu, R. Chen, and G. Tzeng, "Discovering Fuzzy Association Rules Using Fuzzy Partition Methods," Knowledge-Based Systems, Vol. 16 pp.137-147,2003 6] T. Watanabe and N. Nakayama, "Fuzzy Rule Extraction Based on the Mining Generalized Association Rules," Proc. of the 2003 IEEE Int Conf on Syst., Man, and Cybern., pp.2690-2695, 2003 7] UCI Machine Learning Repository: http://www ics.uci.edu/-mlearnIMLRepository.html 8] T. Watanabe, A. Kitamura, K. Higuchi, and H. Ikeda, "Intelligent Manufacturing Techniques for Quality and Process Design of Steel Plate," 2003 IEEE International Coriference on Emerging Technologies and Factory Automation Proceedings, Vol.2, pp.596-601, 2003 9] S. Shankar and T. Purusothaman, "Utility Sentient Frequent Itemset Mining and Association Rule Mining: A Literature Survey and Comparative Study," International Journal of Soft Computing Applications, Issue 4, pp.81-95, 2009 


10] M. Delgado, N. Marin, D. Sanchez, and M.-A. Vila, "Fuzzy Association Rules: General Model and Applications," IEEE Trans. on Fuzzy Systems VoU I, No.2, pp.214-225, 2003 II] M. Delgado, N. Marin, M. J. Martin-Bautista, D. Sanchez, and M.-A Vila, "Mining Fuzzy Association Rules: An Overview," Studies in Fuzziness and Soft Computing, Springer, VoU64/2005, pp.351-373 2006 12] H. Verlinde, M. De Cock, and R. Boute, "Fuzzy Versus Quantitative Association Rules: A Fair Data-Driven Comparison," IEEE Trans. on System, Man, and Cybernetics, Part B, Vol.36, No.3, pp.679-684, 2006 13] E. Hullermeier and Y. Yi, "In Defense of Fuzzy Association Analysis IEEE Trans. on System, Man, and Cybernetics, Part B, Vol.37, No.4 pp.1039-1043,2007 14] Y. C. Lee, T. P. Hong, and T. C. Wang, "Mining Fuzzy Multiple-level Association Rules under Multiple Minimum Supports," Proc. of the 2006 IEEE International Conference on Systems, Man, and Cybernetics pp.4112-4117,2006 15] A. Mangalampalli and V. Pudi, "Fuzzy Association Rule Mining Algorithm for Fast and Efficient Performance on Very Large Datasets Proc. of the 2009 IEEE International Coriference on Fuzzy Systems pp.1163-1168,2009 16] Y. Xu, Y. Li, and G. Shaw, "Concise Representations for Approximate Association Rules," Proc. of the 2008 IEEE International Coriference on Systems, Man, and Cybernetics, pp.94-IOI, 2008 17] T. Watanabe, "Mining Fuzzy Association Rules of Specified Output Field ", Proc. of the 2004 IEEE Int. Corif. on Syst., Man, and Cybern pp.5754-5759,2004 73 


General Chair f!!\f  Organizing Chairs  f!!\f  f$% \f!!\f  Organizing Co-chairs f    f  f\f   f\f\f   f*!\f!\f.\f  f f  Program Committee Chairs  f\f\f   f!!\f  Publication Chair 0   


200 250 300  The size of dataset/10,000 R es po ns e tim e S    a 0 50 100 150 200  The size of dataset/10,000 R es po ns e tim e S    b 0 10 20 30 40 50 


60  The size of dataset/30,000 R es po ns e tim e S    c Fig. 9 The scalability of our algorithm compared with FP-growth  Paper [12] proposed a way to reduce times of scanning transaction database to reduce the cost of I/O IV. CONCLUSIONS AND FUTURE WORK This paper first discusses the theory of foundations and association rules and presents an association rules mining algorithm, namely, FP-growth algorithm. And then we propose an improved algorithm IFP-growth based on many association rules mining algorithms. At last we implement the algorithm we propose and compare it with algorithm FPgrowth algorithm. The experimental evaluation demonstrates its scalability is much better than algorithm FP-growth 177 Now, lets forecast something we want to do someday Firstly, we would parallelize our algorithm, because data mining needs massive computation, and a parallelable environment could high improve the performance of the algorithm; Secondly, we would apply our algorithm on much more datasets and study the run performance; At last, we would study the performance when the algorithm deal with other kinds of association rules  REFERENCES 1] S. Sumathi and S. N. Sivanandam. Introduction to Data Mining and its Applications, Springer, 2006 2] V. J. Hodge, J. Austin, A survey of outlier detection 


methodologies, Artificial Intelligence Review, 2004, 22 85-126 3] Han, J. and M. Kamber. Data Mining: Concepts and Techniques. Morgan Kaufmann, San. Francisco, 2000 4] Jianchao Han, Mohsen Beheshti. Discovering Both Positive and Negative Fuzzy Association Rules in Large Transaction Databases, Journal of Advanced Computational Intelligence and Intelligent Informatics 2006, 10\(3 5] Jiuyong Li, Hong Shen, Rodney Topor. Mining Informative Rule Set for Prediction. Journal of Intelligent Information Systems, 2004, 22\(2 6] Jianchao Han, and Mohsen Beheshti. Discovering Both Positive and Negative Fuzzy Association Rules in Large Transaction Databases. Journal of Advanced Computational Intelligence, 2006, 10\(3 7] Doug Burdick, Manuel Calimlim, Jason Flannick Johannes Gehrke, Tomi Yiu. MAFIA: A Maximal Frequent Itemset Algorithm. IEEE Transactions on Knowledge and Data Engineering, 2005, 17\(11 1504 8] Assaf Schuster, Ran Wolff, Dan Trock. A highperformance distributed algorithm for mining association rules. Knowledge and Information Systems, 2005, 7\(4 458-475 9] Mohammed J. Zaki. Mining Non-Redundant Association Rules. 2004, 9\(3 10] J.Han, J.Pei, Y.Yin, Mining frequent patterns without candidate generation, Proceedings ACM SIGMOD 2000 Dallas, TX, May 2000: 1-12 11] P.Viola, M.Jones. Rapid Object Detection Using A Boosted Cascade of Simple Features. Proc. IEEE Conf. on Computer Vision and Pattern Recognition, 2001 12] Anthony K. H. Tung, Hongjun Lu, Jiawei Han, Ling FengJan. Efficient Mining of Intertransaction Association Rules. 2003, 154\(1 178 


For each vertex b in g form j forests body\(a, g, i s.t. bodyAnt\(a, g, i a, g, i with itemsets Ant\(b b and each subset of itemsets Ant\(b b in P\(a, g, j Assign to each leaf l of trees bodyAnt\(a, g, i bodyCons\(a, g, i a fresh variable Vm,M, m, M = size\(itemset\(l Assign to each leaf l of tree headAnt\(a, g, j the variable assigned to itemset l in some leaf of some tree bodyCons\(a, g, i TABLE II.  EXPERIMENTAL DATA Conf. #rules #pruned #dftrs PtC 0.5 6604 2985 1114 0.6 2697 2081 25 0.75 1867 1606 10 0.8 1266 1176 0 0.95 892 866 1 0.98 705 699 1 DSP 0.5 2473 1168 268 0.6 1696 869 64 0.75 1509 844 89 0.8 1290 1030 29 0.95 1032 889 15 0.98 759 723 1 Arry 0.5 770 492 82 0.6 520 353 60 0.75 472 327 39 0.8 408 287 22 0.95 361 255 25 0.98 314 243 30  Our induction algorithm has been launched for each combination of thresholds. Our scheme eliminates all redundant rules in the sense of [25, 31], i.e. those association rules that are not in the covers. All the meta-rule deductive schemes implicitly included in [25] and [31] are induced by our method. The percentage of pruning, thus, outperforms [25 


The results produced for k=3, support 0.25 and confidences between 0.7 and 0.99 are shown in Fig. 3, in terms of pruning percentage \(vertical axis when applied to low confidences \(from 0.7 to 0.9 The percentage of pruning achieved diminishes as the confidence is superior to 0.9. Nevertheless, the pruning is effective with confidence of 0.99 in the majority of cases Pruning at Support = 0.25 0,00 5,00 10,00 15,00 20,00 25,00 30,00 35,00 40,00 45,00 50,00 0,7 0,8 0,9 0,95 0,99 Confidence P ru n in g L e v e l Case 1 Case 2 Case 3  Figure 3.  Pruning experiences at support 0.25  V. DISCUSSION AND CHALLENGES It is important to discuss the technique presented here with focus on the purpose the technique pursues:  to produce semantic recommendation The reader should have noticed that the algorithm presented 


relies strongly on "choice". For instance, the algorithm chooses ears in the graph to form an order for elimination, and the choice is arbitrary. This strategy is essential to maintain low complexity \(polynomial practical. Nevertheless, a warned reader may conclude that this arbitrary choice implies that there are many compactions to produce and therefore the approach as a whole does not show to produce an optimal solution. And the reader is right in this conclusion. Since the goal is compaction, the search for an optimal solution can be bypassed provided a substantial level of pruning is achieved To complete the whole view, we describe how web service descriptions are complemented with the association rules as recommendations. In effect, under our scheme, the document describing the web service is augmented with a set of OWL/RDF/S triples that only incorporate the non-pruned rules with the format of Example 1, that is, the set ARmin of the compaction program obtained by our algorithm, together with the thresholds applied to the mining process and a registered URI of a registered description service. The assumptions and defeaters are not added to the web service description. If the associations encoded in the triples are not sufficient for the client \(a search engine, for instance widening of the response to the description service identified by the given URI, and then the assumptions and defeaters are produced. The reasoning task required for deriving all the implicitly published rules is client responsibility Notice that, under this scheme, the actual rules that appear as members of the set initial ARmin set are irrelevant; the only important issue is the size of the set The developed scheme also supports an extension of the algorithm that admits the assignment of priorities to rules and to itemsets, in order to allow the user to produce a more controlled program as output. Nonetheless, the importance of the extension has not been already tested, and therefore it is beyond the subject of the present paper It would be also interesting to design a scheme that supports queries where the client provides an itemset class and values for support and confidence and the engine produces a maximal class of inferred associated itemsets as a response. This scheme is also under development, so we have not discussed this aspect here 


VI. CONCLUSION In this paper, we have presented a defeasible logic framework for managing associations that helps in reducing the number of rules found in a set of discovered associations. We have presented an induction algorithm for inducing programs in our logic, made of assumption schemas, a reduced set of association rules and a set of counter-arguments to conclusions called defeaters, guaranteeing that every pruned rule can be effectively inferred from the output. Our approach outperform those of [17], because all reduction compactions presented there can be expressed and induced in our framework, and several other patterns, particular to the given datasets, can also be found. In addition, since a set of definite clauses can be obtained from the induced programs, the knowledge obtained can be modularly inserted in a richer inference engine Abduction can be also attempted, asking for justifications that explain the presence of certain association in the dataset The framework presented can be extended in several ways Admitting defeaters to appear in the head of assumption, to define user interest Admitting arithmetic expressions within assumptions for adjustment in pruning Admitting set formation patterns as itemset constants Extending the scope, to cover temporal association rules REFERENCES 1]  R. Agrawal, and R. Srikant: Fast algorithms for mining association rules In Proc. Intl Conf. Very Large Databases. \(1994 2]  A. V. Aho, J. E. Hopcroft, J. Ullman. The design and analysis of computer algorithms, Addison-Wesley, 1974 3]  G. Antoniou, D. Billington, G. Governatori, M. J. Maher, A. Rock: A Family of Defeasible Reasoning Logics and its Implementation. ECAI 2000: 459-463 4]  G. Antoniou, D. Billington, G. Governatori, M. J. Maher: Representation results for defeasible logic. ACM Trans. Comput. Log. 2\(2 2001 5]  A. Basel, A. Mahafzah, M. Al-Badarneh: A new sampling technique for association rule mining, Journal of Information Science, Vol. 35, No. 3 358-376 \(2009 6]  R. Bayardo and R. Agrawal: Mining the Most Interesting Rules. In Proc of the Fifth ACMSIGKDD Intl Conf. on Knowledge Discovery and Data Mining, 145-154, \(1999 


7]  R. Bayardo, R. Agrawal, and D. Gunopulos: Constraint-based Rule Mining in Large, Dense Databases. Data Mining and Knowledge Discovery Journal, Vol. 4, Num-bers 2/3, 217-240. \(2000 8]  A. Berrado, G. Runger: Using metarules to organize and group discovered association rules. Data Mining and Knowledge Discovery Vol 14, Issue 3. \(2007 9]  S. Brin, R. Motwani, J. Ullman, and S. Tsur: Dynamic itemset counting and implication rules for market basket analysis. In Proc. ACMSIGMOD Intl Conf. Management of Data. \(1997 10] L. Cristofor and D.Simovici: Generating an nformative Cover for Association Rules. In ICDM 2002, Maebashi City, Japan. \(2002 11] Y. Fu and J. Han: Meta-rule Guided Mining of association rules in relational databases. In Proc. Intl Workshop on Knowledge Discovery and Deductive and Object-Oriented Databases. \(1995 12] B. Goethals, E. Hoekx, J. Van den Bussche: Mining tree queries in a graph. KDD: 61-69. \(2005 13] G. Governatori, D. H. Pham, S. Raboczi, A. Newman and S. Takur: On Extending RuleML for Modal Defeasible Logic. RuleML, LNCS 5321 89-103. \(2008  14] G. Governatori and A. Stranieri. Towards the application of association rules for defeasible rules discovery In Legal Knowledge and Information Systems, JURIX, IOS Press, 63-75. \(2001 15] J. Han, J. Pei and Y. Yin: Mining frequent patterns without candidate generation. In Proc. ACM-SIGMOD Intl Conf. Management of Data 2000 16] C. Hbert, B. Crmilleux: Optimized Rule Mining Through a Unified Framework for Interestingness Measures. DaWaK: LNCS 4081, 238247. \(2006 17] E. Hoekx, J. Van den Bussche: Mining for Tree-Query Associations in a Graph. ICDM 2006: 254-264 18] R. Huebner: Diversity-Based Interestingness Measures For Association Rule Mining. Proceedings of ASBBS Volume 16 Number 1, \(2009 19] B. Johnston, Guido Governatori: An algorithm for the induction of defeasible logic theories from databases. Proceedings of the 14th Australasian Database Conference, 75-83. \(2003 20] P. Kazienko: Mining Indirect Association Rules For Web Recommendation. Int. J. Appl. Math. Comput. Sci., Vol. 19, No. 1, 165 186. \(2009 21] M. Klemettinen, H. Mannila, P. Ronkainen, H. Toivonen, and A Verkamo: Finding interesting rules from large sets of discovered association rules. In Proc. 3rd Intl Conf. on Information and Knowledge 


Management. \(1994 22] M. J. Maher, A. Rock, G. Antoniou, D. Billington, T. Miller: Efficient Defeasible Reasoning Systems. International Journal on Artificial Intelligence Tools 10\(4 2001 23] C. Marinica, F. Guillet, and H. Briand: Post-Processing of Discovered Association Rules Using Ontologies. The Second International Workshop on Domain Driven Data Mining, Pisa, Italy \(2008 24] N. Pasquier, Y. Bastide, R. Taouil, and L. Lakhal: Closed sets based discovery of small covers for association rules. In Proc. BDA'99 Conference, 361-381 \(1999 25] N. Pasquier, R. Taouil, I. Bastide, G. Stume, and  L. Lakhal: Generating a Condensed Representation for Association Rules. In Journal of Intelligent Information Systems, 24:1, 29-60 \(2005 26] P. Pothipruk, G. Governatori: ALE Defeasible Description Logic Australian Conference on Artificial Intelligence.  110-119 \(2006 27] J. Sandvig, B. Mobasher Robustness of collaborative recommendation based on association rule mining, Proceedings of the ACM Conference on Recommender Systems \(2007 28] W. Shen, K. Ong, B. Mitbander, and C. Zaniolo: Metaqueries for data mining. In Fayaad, U. et al. Eds. Advances in Knowledge Discovery and Data Mining. \(1996 29] I. Song, G. Governatori: Nested Rules in Defeasible Logic. RuleML LNCS 3791, 204-208 \(2005 30] H. Toivonen, M. Klemettinen, P. Ronkainer, K. Hatonen, and H Mannila: Pruning and grouping discovered association rules. In ECML Workshop on Statistics, Machine Learning and KDD. \(1995 31] M. Zaki: Generating Non-Redundant Association Rules. In Proc. of the Sixth ACMSIGKDD Intl Conf. on Knowledge Discovery and Data Mining, 34-43, \(2000 32] w3c. OWL Ontology Web Language Reference. In http://www.w3.org/TR/2004/REC-owl-ref-20040210 33] w3c. RDF/XML Syntax Specification. In: http://www.w3.org/TR/rdfsyntax-grammar 34] w3c. RDF Schema. In: http://www.w3.org/TR/rdf-schema      


 8   2  3\f            8  D    F  \b 1 8 & #J      b 1  1  4    2  


4 1    9  E 1  2 4 1    9 1   4      8 2  8 1  D 1        1 1  b 


     b b b b b  K            8          2 D 9   F  \b 1 8 ,+J  9 


     b 1     1 2  9 1  12 L 1   9  8       1  2      2   


     b b b b b  K            2  0 \b f  b\f      9       


  8 2   E 1   1     M13 31L 1    b  8E 1   1 #3\b?### 1  1     E 1   1 \b?###3        


1   1   b 1  2 2 18 2     8              1    2 \b 1    2  


    2          2   1 L 2 1   1   L 2 2    2 1  2        


    8  2H D \b A             2  2H D \b A 2 \f 3%\f  f   4%\f f !  , \f\b  C    2    2 


 6    3 1      253 6   1 L 2    6   1         f\b3\f       


               1     1     8 2    E       2  1   


     2 8    b 4      1 8             1 2     1  8 2  


1 9    8      2 1       1     2    8    2 3\f        


     8 D 4 9  F  \b 1 8 #J 9 1     2 1   2 #-@ 1   2 9  E 1   1   2 9      6  


    8  8   1  D 1         1 F  \b0         2 D    F  \b 1 8  9  


  1 9  1   E 1  2 9     1 1 F  \b       1    18   F   1    1 #-$+  \b  2 2  


1 D     1 #-$+.B- 0/:% .0             9 1      18    1 6     1 2  1  1  


1   6      2    1 2 E 8 D 1      1 2   1   1 #-4  #-@E     2  1  1  1       


 8     1          2 F    6   F  2   8    2 C<CC/C N\bO 5      


CD    b$44NO F P Q 6   2 b$$$ ,=\b\bA  A N,O 2 C C  b$$4N  92 2   f  9-\b$$4 B N?O  !-    91  2 1 HH111-18-N+O    -1 :3%   2     0-4 


     b N4O 2   2- \f  C b$@$ \b# >\b\b$3\b$N@O  f :.% 9 /9 \f    1  6  f 2  4   A254 


Advantages of Our M ethod Advantages of Our M ethod Exploit the memory v ertical data format utilizes slidin g windows to g form a much larger database to analyze  Flexibility in Choosing what to choose  Choosing what to choose to build the rules Computational and memory efficiency We have a team working only on this aspect 45 Associative IDS for NextGen Frameworks Dr S Dua LA Tech 45 


Preliminary Results Intra transaction Relations Data rate simulator NH-134 Mb HOP PATH update \(Y/N Inference 11.5 Y Y 2 0.120 N N      Y   n 0.345 N NH134 Y/N   Inf 1 0.150 N N 2 0 120 Y N Inter transaction Relations 2 0  120 Y N       5 5.55 0.456 Y Relations  n 0.345 N N Nmap on DMRL nmap.org 


Anticipated Outcome Anticipated Outcome Develop algorithm capable of learning from a given heterogeneous diverse Develop algorithm capable of learning from a given heterogeneous diverse data ff Dynamic algorithmic f ramework designed to shi f t modalities and sampling rates based on complex logic Flexibility of integration into the Snort intrusion detection system 47 Associative IDS for NextGen Frameworks Dr S Dua LA Tech 47 


References References Aircraft Cockpit Image courtesy USAF http://www.faa.gov htt p   www.faa g ov  air traffic  technolo gy  p g  _ gy  Acharya R Dua S Du X Sree V Chua C K Automated Diagnosis of Glaucoma Using Texture and Higher Order Spectra Features To appear in IEEE Transactions on Information Technology in Biomedicine  Du X Dua S 2011 Cancer Prognosis Using Support Vector Regression in Imaging  Modality World Journal of Clinical Oncology 2  1   44 49 Du X Dua S 2010 Salient Frame Extraction Using Support Vector Regression and Motion Features pp 5 Proc of the National Aerospace and Electronics Conference July 14 16 2010 D M P D S 2010 Di i i ti Ft d Cl ifi ti Mthd f D essaue r  M  P  D ua S  2010  Di scr i m i na ti ve F ea t ures an d Cl ass ifi ca ti on M e th o d s f or Accurate Classification 1st ed vol 7704 pp 14 Bellingham WA Proceedings of SPIE Dessauer M P Dua S 2010 Low Resolution Vehicle Tracking using Dense and Reduced Local Gradient Features Maps 1st ed vol 7694 pp 8 Bellingham WA Proceedings of SPIE SPIE 


Acknowledgements Acknowledgements Fundin g A g encies  US 4 1 Million direct fundin g g g 4 g LA BoR NIH NSF AFRL AFOSR and NASA Research Team Samuel Kasimalla Brandy McKnight Dr Pradeep Chowriappa Connor Johnson Vasanth Nair Mihir Chowriappa  Connor Johnson  Vasanth Nair  Mihir Karnik Mohit Jain and Swadheen Songmen Associative IDS for NextGen Frameworks Dr S Dua LA Tech 49 All the respective Logos belong to their owners 


Rf d Rdi R e f erence d R ea di ngs Copyright of cover pages held by respective publishers 


Thank You Questions Thank You  Questions Dr Sumeet Dua E mail sdua@latech.edu Web http://dmrl.latech.edu Associative IDS for NextGen Frameworks Frameworks Dr S Dua LA Tech 51 Image Source roadtrafficsigns.com 


