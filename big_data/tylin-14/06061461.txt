Feature Selection Guided by Perception in Medical CBIR Systems Pedro H Bugatti 1  2  Marcela X Ribeiro 3  Agma J M Traina 1 and Caetano Traina Jr 1 1 Department of Computer Science University of Sao Paulo at Sao Carlos Brazil 2 Department of Computer Engineering Federal Technological University of Parana Brazil 3 Department of Computer Science Federal University of Sao Carlos Brazil 1 f 
pbugatti agma caetano g icmc.usp.br 3 marcela@dc.ufscar.br Abstract This work aims at developing an ef\002cient support to improve the precision of content-based medical image retrieval systems and also accelerate such retrieval introducing a novel retrieval approach that integrates techniques of feature selection and relevance feedback to perform feature selection guided by perceptual similarity Low-level features are commonly employed to represent the images by content Feature selection is performed employing statistical association rules integrated with a relevance feedback process tuning the mining 
process on the 003y according to the user's perception This integration not only improves the feature selection accuracy but also allows personalising such process The experiments performed show that the method improves up to 30 the query precision and decreases up to 11.6 times the number of features employed to compute the similarity in the contentbased query also decreasing the processing costs and memory requirements of the query execution Keywords Feature Selection Relevance Feedback User Perception Content-Based Image Retrieval I I NTRODUCTION Content-based image retrieval CBIR techniques and si 
milarity search ha v e been intensi v ely researched in the recent years CBIR techniques work on the whole information embodied into the stored images and are not limited by a textual description of it The advantage of working with the visual content of an image is to avoid the inherent bias and subjectivity of textual description Textual descriptions of images can be incomplete as the specialist can be interested in speci\002c aspects of the image under analysis letting some others unreported The medical area can greatly bene\002t from CBIR applications due to the huge amount of images daily generated by hospitals and medical centers CBIR employs image processing algorithms to extract relevant characteristics features from the images organizing 
them into feature vectors The feature vectors are employed in place of the images to compare them allowing fast and ef\002cient indexing and retrieval The features quantify intrinsic visual characteristics of the images such as color shape and texture usually leading to high-dimensional vectors The usage of a large number of features to represent images is a problem because the processes of indexing retrieving and comparing images become less accurate and more time consuming This occurs because the usage of a large quantity of features leads the CBIR systems to face the dimensionality curse problem This curse occurs because a usage of a large number of features and consequently a high-dimensional data leads each feature to 
diminish its signi\002cance Thus one of the major challenges in a CBIR system is to determine a minimal subset of features that best represent the images according to each specialist intention This paper aims at dealing with this issue Specialists have different perceptions of image similarity frequently feeling unful\002lled with the CBIR results In fact there is a disparity between low-level features and high-level user perception which is called the semantic gap  One way of gathering subjectivity in CBIR is to introduce the users e.g medical specialists into the process To avoid the semantic gap it is important to have the user interacting and telling what are the truly relevant images from those 
retrieved This way of interaction between the user and the system is called Relevance Feedback RF The RF approach asks the specialist to quantify the relevance of each medical image retrieved by a query allowing the system to automatically adjust future query results It is common that a medical image presents several clinical 002ndings with distinct visual patterns Thus it is important to note that each user should perform a speci\002c feature selection process according to his/her perception This mainly occurs because different specialists may be interested in different clinical 002ndings therefore employing distinct similarity criteria Hence it is crucial to capture information related to the user perceptual similarity during 
the search process in order to describe how each individual understands similarity in his/her speci\002c context to perform a feature selection guided by perception In this paper we propose a method that integrates RF and feature selection to improve the CBIR results In our approach the mining process is re-executed once after the RF iterations taking into account the information fed by the specialist reaching more precise and useful patterns The experiments performed show that our method improved the query precision up to 30 yet the dimensionality reduction allowed discarding up to 91 of the features Besides the method speeds up the whole CBIR system 
2011 First IEEE International Conference on Healthcare Informatics, Imaging and Systems Biology 978-0-7695-4407-6/11 $26.00 © 2011 IEEE DOI 10.1109/HISB.2011.27 127 
2011 First IEEE International Conference on Healthcare Informatics, Imaging and Systems Biology 978-0-7695-4407-6/11 $26.00 © 2011 IEEE DOI 10.1109/HISB.2011.27 323 
2011 First IEEE International Conference on Healthcare Informatics, Imaging and Systems Biology 978-0-7695-4407-6/11 $26.00 © 2011 IEEE DOI 10.1109/HISB.2011.27 323 


since the complexity of the query processing decreases along the dimensionality reduction of the feature vector Moreover the proposed approach is effective in performing feature selection guided by each user perception The remainder of this paper is structured as follows Section II summarizes the concepts and related works Section III details the proposed method and Section IV discusses the experiments and the achieved results Finally Section V presents the conclusions of the work II B ACKGROUND AND T ECHNIQUES Comparing images employing exact matching is not useful in several areas e.g medical applications since searching for the same data already under analysis does not add extra information In fact the retrieval of complex data is mainly performed regarding similarity The most wellknown and useful types of similarity queries are the k nearest neighbor and range queries Similarity search is performed comparing the feature vectors using a distance  or dissimilarity  function to quantify how close or similar is each pair of vectors The distance functions most widely employed to perform similarity queries are those from the Minkowski family also know as the L p distances which are usually employed over vectorial spaces In this paper we employed the Euclidean distance L 2 and L 1  also called City Block or Manhattan  to perform the similarity queries A Relevance Feedback Relevance feedback ful\002lls an important role in CBIR systems due to its ability to gradually reduce the semantic gap through users interaction As a real-time learning strategy it can capture the essence of the user expectation leading to higher precision and improved query re\002nement Basically a relevance feedback technique is composed of three steps in the CBIR process Figure 1 illustrates a classic scenario of RF in conjunction with a CBIR system In Step 1 the system retrieves the most similar images according to the initial query In Step 2 the users guide the search process judging the returned images based on a relevance degree Step 3 the system captures the user expectation based on the performed feedback and automatically adjusts the further queries based on the user's informed relevance Steps 2 and 3 are repeated until the user is satis\002ed with the results As the system captures the user's intention when a new query is performed the resulting set of images can be continually improved until be stagnated In this work we use the query point movement QPM technique to perform RF which consists of estimating the query point according to the user's interaction by moving it towards the positive examples i.e objects selected as relevant and away from the negative examples i.e objects Figure 1 RF in conjunction with CBIR selected as irrelevant Thus at each user interaction cycle an ideal query center is estimated in the query space The most well-known and widely used technique to iteratively improve the query center estimation through relevance feedback is the Rocchio's formula This formula is formally de\002ned in Equation 1 where Q is the original query i.e the initial feature vector Q 0 is the updated query i.e the resultant feature vector D 0 R and D 0 N are respectively the positive and negative examples given by the user N R 0 and N N 0 are the number of relevant i.e positive and irrelevant i.e negative examples in D 0 R and D 0 N  and 002nally 013  014 and 015 are weighting factors experimentally obtained to tune the relevance feedback factors In our approach we employ the Rocchio's technique together with incrementally feature selection to maximize the precision of content-based image retrieval Q 0  013Q  014 0  1 N R 0 X i 2 D 0 R D i 1 A 000 015 0  1 N N 0 X i 2 D 0 N D i 1 A 1 B Statistical Association Rule Mining In this work we employed the StARMiner algorithm which extended statistical rule mining techniques presented in to 002nd patterns in image datasets Let T be an image dataset x an image class T x 2 T the subset of images of class x and f 2 F a feature where F is the set of all original features employed to represent the images Let 026 f  Z  and 033 f  Z  be respectively the mean and standard deviation of the values of the feature f in the subset of images Z  StARMiner uses three thresholds de\002ned by the user 001 026 min  the minimum allowed difference between the average of the feature f in images from class x and the average of f in the remaining dataset 001 033 max  the maximum standard deviation of f values allowed in a given class and 015 min  the minimum con\002dence to reject the hypothesis H 0  The StARMiner algorithm mines rules of the form x  f  given the following conditions are satis\002ed 026 f  T x  000 026 f  T 000 T x  025 001 026 min 2 033 f  T x  024 001 033 max 3 H 0  026 f  T x   026 f  T 000 T x  4 
128 
324 
324 


Equation 4 states that H 0 should be rejected with a con\002dence equal to or greater than 015 min  in favor of the hypothesis that the difference between the means 026 f  T x  and 026 f  T 000 T x  are statistically signi\002cant A rule x  f returned by the algorithm relates a feature f with a class x  where values of f points to a statistically signi\002cant difference in the images of class x  This property indicates that feature f can distinguish images of class x  A set of rules x  f for the same predecessor x can be summarized in the rule x  R  where R is the union of the features returned by StARMiner for the predecessor x  meaning that the features in the set R are the ones that can best distinguish images of class x from the remaining images Hence the relevant features for class x are the features R  The union set S of all sets R returned by the StARMiner algorithm for all image classes contains the features that best discriminate the images into categories The set S is the resulting set of relevant features selected by the StARMiner algorithm In our approach we employ StARMiner to select the set of features that is considered in the similarity computation during the query execution At each relevance feedback iteration the mining algorithm is re-executed considering the feedback information fed by the user increasing its precision and improving the feature selection result The complexity of StARMiner is 002 ckN   where N is the number of instances of the dataset k is the number of features and c is the number of categories This algorithm was chosen because it produced better results when compared with other traditional feature selection algorithms such as the Relief and the Decision Tree Method DTM III F EATURE S ELECTION G UIDED BY P ERCEPTION We propose a method to improve the user satisfaction with the CBIR system that combines relevance feedback and feature selection The relevance feedback process iteratively enhances the training dataset applied to the feature selection process according to the user intention providing for each one a personalized training dataset closer to his/her perception The mining process is performed once as the dataset was tunned by the user expectations Consider G an image database composed of images from different classes  n classes  Every image f 2 F corresponds to a feature vector Therefore the distance between two images is de\002ned as d  q g  where q is a query center Given an initial k-NN query the retrieved images are the ones closest to the query center However these results may not reach the user's expectation due to the semantic gap problem Thus to include the users expectation in the process we employed the QPM relevance feedback technique where the user will label the relevant and irrelevant images from the retrieved ones  result an ordered list of the k most relevant images in G  Algorithm 1 describes the pipeline of the proposed method while the Algorithm 2 describes the process of incrementally building the training set according to the user's expectation Algorithm 1 Pipeline of the proposed method Require query center q  number of k nearest neighbors a feature extraction function v  a distance function d  an image database G  a desirable number N R 0 relevant images to be selected a desirable number N N 0 i irrelevant images to be selected Ensure a list of selectedF eatures 1 initialQuery kN N in:centerq  out result  2 RelevanceFeedback\(in j out result  out N N distinct  3 BuildTrainingSet\(in result  in N R 0  in N N 0 i  in N N distinct  in n classes  out trainingSet  4 MiningRules\(in trainingSet  out selectedF eatures  Algorithm 2 BuildTrainingSet  Performs the incremental construction of the training set according to user feedback Require a desirable number N R 0 relevant images to be selected in a given relevance cycle a desirable number N N 0 i irrelevant images to be selected in i-th class a number N N distinct of irrelevant images selected from different classes Ensure trainingSet 1 if  N N 0 i  N R 0  then 2 trainingSet   N R 0 N N 0 i  irrelevant images from i-th class in result 3 else if  N R 0 N N 0 i  2 result  then 4 trainingSet  randomSelection G  N R 0 N N 0 i  i  5 end if 6 if  n classes  N N distinct  then 7 if  classesN otSelected 2 result  then 8 trainingSet  N R 0 relevant images 9 else 10 trainingSet  randomSelection G  N R 0  classesN otSelected  11 end if 12 end if The steps of the proposed method are illustrated in Figure 2 The proposed method is composed of 002ve main steps 1 initial query 2 relevance feedback loop RF loop 3 relevance feedback mining data 4 association rule mining 5 feature selection which removes noisy features and bursts the most relevant ones When the user decides to 002nalize and visualize the answer similarity queries are executed with the selected features Initially the training dataset used in the process of association rule mining is empty At Step 1 the user performs an initial similarity query using a given image as query center In Step 2 the user labels the retrieved images as relevant or irrelevant Then in Step 3 the labeled images are used by Algorithm 2 to build a training dataset 
129 
325 
325 


Figure 2 Pipeline of the proposed method In Step 4 the association rule mining algorithm takes the built training dataset as input and then mine rules meeting the required support and con\002dence Finally in Step 5 the association rules generated are used in the feature selection process in order to select the most relevant features The feature selection is accomplished according to the user expectation since the training dataset is iteratively built during the relevance feedback performed in Step 2 Since the user remains in the feedback loop of Step 2 until he/she is satis\002ed with the retrieved results the training dataset applied to the process of association rules mining continues to be re\002ned until the relevance feedback process reaches a saturation point Thus each new feedback cycle can re\002ne the training dataset and consequently also the feature selection process In order to compose the training dataset from the relevance feedback iteration we adopted a particular strategy which was formally described by Algorithm 2 At each relevance cycle the user is asked to select a 002xed number of relevant images  N R 0  and a 002xed number of irrelevant images  N N 0  For example in the 002rst relevance cycle  Cycle 1  the user could be asked to select the 5 most relevant images i.e those within the same class of the query image N R 0  5  and 1 irrelevant image i.e in a class distinct from the query image N N 0 i  1  where i is the i-th image class from the dataset Since we construct a balanced training dataset when the user makes the choice and decides to feedback the system with them the irrelevant image is used to choose the other irrelevant images e.g 4 images of its same class i-th image class from the resultant set  result  of k images of the initial query to compose the training dataset too For instance considering an Image dataset G  if the selected irrelevant image belongs to the i-th class the other 4 images will be from this same class However there are some situations to consider Suppose there are insuf\002cient images from the same class e.g class A of the irrelevant ones in the resultant set  result  to complete the required number of images i.e N R 0 000 N N 0 i  and to build a balanced training dataset Then the remaining images that belong to the same class e.g class A of the irrelevant one are randomly selected from the image dataset Another situation occurs when the number of dataset classes  n classes  is greater than the number of irrelevant images selected from distinct classes  N N 0 Distinct  In this case the image classes that were not selected by the user will be randomly selected from the k resultant set  result  until reaching the required number i.e N R 0 000 N N 0 i  If it is not achieved the remaining images are randomly selected from the image dataset For example considering that only one image from the i-th class was selected as irrelevant the other irrelevant images from different classes are selected according to the described process It is important to emphasize that repeated images i.e those previously selected in past relevance cycles are never included in the training dataset in order to not build a biased training dataset This fact may occur when a user in different feedback cycles selects the same image of past cycles as relevant/irrelevant Our method includes the high-level knowledge provided by the user from the relevance feedback process into the training dataset used by the association rule mining algorithm thus helping to reduce the semantic gap and optimizing the feature selection process Moreover the method allows the system personalization since some specialists may have different expectations regarding an image domain thus building different training datasets Another point is that our method not only identi\002es the most relevant features according to the specialist expectation but also performs dimensionality reduction of image features avoiding the dimensionality curse problem The features are modi\002ed during each relevance feedback cycle by selecting the most signi\002cant ones and discarding the irrelevant ones To do so the training dataset employed to the mining of statistical association rules is incrementally increased according to the user expectation captured in each feedback cycle It is important to highlight that although in this paper we employ the StARMiner algorithm see Section II-B to 
130 
326 
326 


perform the association rules mining process without loss of generality other mining methods of association rules can be applied IV E XPERIMENTS This section presents experimental results when using our proposed method to execute similarity queries In order to evaluate our approach we employed precision 002 recall P 002 R graphs The precision of a query is the fraction of the retrieved elements which are relevant Hence precision  j R A j j A j  where j R A j is the number of relevant images retrieved and j A j is the size of the answer set The recall of a query is the fraction of the relevant elements which has been retrieved Thus recall  j R A j j R j  where j R A j is the number of relevant images retrieved and j R j is the number of relevant elements that should be retrieved When analyzing P 002 R graphs the closer the curve to the top the better the corresponding retrieval technique is To build the P 002 R graphs when the user decides to 002nalize and visualize the results we applied sets of k nearest neighbor  kN N  queries using all images of the analyzed image dataset as query centers varying the values of k  in order to compare our approach i.e features selected according the user perception with the original features In the Step 2 RF Loop of the proposed method was employed the Rocchio's technique setting the positive feedback constant as 014  1  0 and the negative feedback constant as 015  0  5  We chose to employ this well-known technique for showing our method applicability However other more sophisticated RF methods could also be used A Dataset Description We used a variety of image datasets acquired from our Hospital University to perform the experiments However due to space limitations we present here only the results obtained from one representative dataset The M RI dataset consists of 800 images obtained from magnetic resonance imaging exams The dataset was divided into 4 classes according to the body region image orientation and the height of the slice Figure 3 illustrates an example of each class a Axial Head MRI 200 images b Coronal Head MRI 200 images c Sagittal Head MRI 200 images d Sagittal Spine MRI 200 images Figure 3 Examples of images from the M RI dataset Each image from the dataset was processed using the Haralick's Texture the T raditional Gray-le v el histograms and the Zernike Moments These feature e xtractors generated feature vectors comprising 140 256 and 256 positions respectively They were used because they describe the gray-level distribution the texture patterns and shape peculiarities of the medical images B Results In our experiments considering the Steps 1 initial query and 2 RF Loop we applied sets of k nearest neighbor  kN N  queries more speci\002cally 80 nearest neighbor queries and the 002rst three relevance feedback cycles in order to build the training dataset For our experiments at the 002rst second and third relevance feedback cycles 5 10 and 15 relevant images were selected respectively For comparison purposes we always required the user to perform 3 relevance cycles Therefore the 002rst relevance feedback cycle always generated a training set with 5 002 n classes  were n classes is the number of classes in the dataset The second cycle generated a training set with 15 002 n classes  because it was increased by 10 new images and thus the third RF cycle always generated a training set with 30 002 n classes images as it was increased by 15 new images In all experiments a weight w  000 0  5 was assigned to the irrelevant images The P 002 R graphs of Figures 4 5 and 6 show the experiments performed over the M RI dataset represented by the Haralick features the gray-level histogram features and by the Zernike moments respectively using L 2 distance The graphs compare the original features i.e 140 features for Haralick and 256 for gray-level histogram and Zernike moments with the proposed method re\002ning the training dataset using the 002rst 3 relevance cycles gradually decreasing the number of features by selecting the relevant ones according to the user perception and at the same time obtaining a gain in the precision of the similarity queries Figure 4 shows the P 002 R graphs obtained using the Haralick features over the M RI image dataset Analyzing the graphs of Figure 4 we observe that the proposed method not only clearly improves the precision of the similarity queries but also achieved a considerable dimensionality reduction The precisions obtained by the relevant features selected using the training set generated in cycles 1 2 and 3 show that the curves practically ties presenting a precision gain of up to 30 over the precision of the original features i.e 140 features for a recall level of 40 It is important to note that the proposed method not only presents a considerable precision gain in all cases but also promoted a signi\002cant reduction of up to 6.7 times less dimensions in the third interaction which reduces the memory and processing cost These results show that the proposed technique improves the precision of similarity queries even when it reduces the dimensionality of the feature vectors performing the feature selection guided by the user perception 
131 
327 
327 


Figure 5 shows the P 002 R graphs obtained from the graylevel histogram features of the M RI dataset Analyzing Figure 5 we see that our method again presented a gain in precision of up to 14 for a recall level of 20 in comparison with the original features and those selected by the mining process using the third re\002ned training set In this case the feature vector size were approximately reduced to up to 11.6 times less dimensions in comparison with the dimension of the complete feature vectors Figure 4 P 002 R graphs using L 2 distance obtained over the M RI dataset represented by Haralick features comparing the retrieval ability both of the original features and of our proposed method after 3 cycles of relevance feedback Figure 5 P 002 R graphs using L 2 distance obtained over the M RI dataset represented by Gray-level Histogram features comparing the retrieval ability both of the original features and of our proposed method after 3 cycles of relevance feedback Figure 6 illustrates the results over the Zernike moments features We can notice that the proposed method achieved a precision gain of up to 11 in comparison with the original features considering a recall level of 60 It is important to highlight that the feature vector size again was reduced to up to 2.2 times less dimensions in comparison with original ones i.e 256 features Figure 6 P 002 R graphs using L 2 distance obtained over the M RI dataset represented by Zernike Moments features comparing the retrieval ability both of the original features and of our proposed method after 3 cycles of relevance feedback Figure 7 P 002 R graphs using L 1 distance obtained over the M RI dataset represented by Haralick features comparing the retrieval ability both of the original features and of our proposed method after 3 cycles of relevance feedback Figures 7 8 and 9 show the P 002 R graphs obtained from the Haralick features gray-level histogram features and Zernike moments of the M RI dataset using L 1 distance Analyzing the graph of Figure 7 we observe that the proposed method not only clearly improves the precision of the similarity queries but also achieved a considerable dimensionality reduction The precisions obtained by the relevant features selected in cycles 1 2 and 3 show that the curves practically ties presenting a gain of 20 over the precision of the original features i.e 140 features for a recall level of 40 Analyzing Figure 8 one can see that our method again present a gain in precision of up to 9 for a recall level of 25 in comparison with the original features considering the third interaction Figure 9 illustrates the results over the Zernike moments features We can notice that in Figure 9 the method achieved a precision gain of up to 11 in comparison with the original features considering a recall level of 50 
132 
328 
328 


Figure 8 P 002 R graphs using L 1 distance obtained over the M RI dataset represented by Gray-level Histogram features comparing the retrieval ability both of the original features and of our proposed method after 3 cycles of relevance feedback Figure 9 P 002 R graphs using L 1 distance obtained over the M RI dataset represented by Zernike Moments features comparing the retrieval ability both of the original features and of our proposed method after 3 cycles of relevance feedback Figure 10 shows an example of a k NN  k 7 query execution using the top left image as the query center Figure 10\(a shows the result using the original features and Figure 10\(b shows the result using our proposed method with fewer features The images highlighted by a dashed line means false positive images A false positive image is a returned image whose class differs from the class of the query center Clearly an improvement on the results was reached when applying our method We also performed analyses based on the time requirements to execute similarity queries since our method reduces in a great extent the dimensionality of the features vectors All values presented were obtained by the average of 680 queries over the M RI dataset with k=200 We performed several tests under Windows Vista 32bit running on a machine equipped with an Intel Core 2 Duo 2.00GHz processor 3GB of RAM and a SATA HD of 320GB and 5.400RPM Figure 11 presents the results of these experiments consideFigure 10 An example of k NN  k 7 query using the top left image as query center a Using the original features b Using our proposed method The images wrapped by a dashed line means false positives images ring a Haralick features texture b histogram features color and c Zernike features shape Analyzing the curves of Figure 11 a we can notice that the proposed method performed the queries about 6 times faster considering the third feedback iteration in comparison with the time obtained by the original features Figure 11 b illustrates a higher gain in the queries time execution up to 10 times faster when compared with the time required by the queries using the original features Finally in Figure 11 c the proposed method again reached a considerable gain in time execution up to 4.1 times faster in comparison with the time required by the original features Therefore notable gains were also accomplished regarding not only in terms of the precision of the similarity queries but also with respect of the time execution of them V C ONCLUSION In this paper we proposed a new approach to improve the CBIR quality dealing with the dimensionality curse and the semantic gap problems It gathers from the users their intentions during the similarity queries and performs a feature selection guided by user perception By coupling the relevance feedback and the mining processes we maximized the accuracy of the feature selection process gathering the user in the CBIR process performing feature selection guided by the user's perception The feature selection performed allowed the reduction of the feature vector up to 11.6 times less dimensions from 256 to 22 tuning the mining process according to the specialist expectation Moreover for each user a speci\002c training set was built according to his/her expectation providing the personalization of the system A simple and well-known RF method was employed only to show the proposed method 
133 
329 
329 


Figure 11 Graphs of k-NN queries execution times using L 2 obtained over the M RI dataset represented by a Haralick features b histogram features and c Zernike features comparing the time execution between the original features and employing our proposed method applying 3 cycles of relevance feedback power The use of more robust RF methods could increase the gain further Analyses done also show that the number of three RF cycles is the most common since after that a saturation point is reached and the gain practically remains the same The experiments showed that the proposed method is effective in improving the query precision contributing to bridge the semantic gap and achieving improvement in the query results of up to 30 Moreover the proposed approach can be straightforwardly extended to other types of relevance feedback techniques feature selection methods and distance functions A CKNOWLEDGMENTS This work has been supported by FAPESP Sao Paulo State Research Foundation CNPq National Council for Scienti\002c and Technological Development CAPES Brazilian Federal Funding Agency for Graduate Education Improvement and Microsoft-Research R EFERENCES   S Jeong S.-W Kim and B.-U Choi Dimensionality reduction in high-dimensional space for multimedia information retrieval in Proceedings of the International Conference on Database and Expert Systems Applications  Regensburg Germany Springer Berlin  Heidelberg 2007 pp 404–413   K S Beyer J Godstein R Ramakrishnan and U Shaft When is nearest neighbor meaningful in Proceedings of the International Conference on Database Theory  vol 1540 Jerusalem Israel Springer Verlag 1999 pp 217–235   T M Deserno S Antani and R Long Ontology of gaps in content-based image retrieval Journal of Digital Imaging  vol 1 no 1 pp 1–14 2008   D R Wilson and T R Martinez Improved heterogeneous distance functions Journal of Arti\002cial Intelligence Research  vol 6 no 1 pp 1–34 1997   Y Liu D Zhang G Lu and W.-Y Ma A survey of contentbased image retrieval with high-level semantics Pattern Recognition Letters  vol 40 no 1 pp 262–282 2007   N Doulamis and A Doulamis Evaluation of relevance feedback schemes in content-based in retrieval systems Signal Processing Image Communication  vol 21 no 4 pp 334–357 2006   J J Rocchio Relevance Feedback in Information Retrieval  ser The SMART Retrieval System Experiments in Automatic Document Processing Englewood Cliffs New Jersey Prentice-Hall 1971   M X Ribeiro A G R Balan J C Felipe A J M Traina and C Traina Jr Mining statistical association rules to select the most relevant medical image features in Proceedings of the International Workshop on Mining Complex Data  Houston USA IEEE Computer Society 2005 pp 91–98   Y Aumann and Y Lindell A statistical theory for quantitative association rules Journal of Intelligent Information Systems  vol 20 no 3 pp 255–283 2003   I Kononenko Estimating attributes  Analysis and extension of relief in Proceedings of the European Conference on Machine Learning  Catania Italy Springer Berlin  Heidelberg 1994 pp 171–182   C Cardie Using decision trees to improve case-based learning in Proceedings of the International Conference on Machine Learning  Amherst USA Morgan Kaufmann 1993 pp 25–32   R A Baeza-Yates and B Ribeiro-Neto Modern Information Retrieval  Boston MA USA Addison-Wesley Longman Publishing Co Inc 1999   R M Haralick K Shanmugam and I Distein Textural features for image classi\002cation IEEE Transactions on Systems Man and Cybernetics  vol 3 no 6 pp 610–621 1973   A Khotanzad and Y H Hong Invariant image recognition by zernike moments IEEE Transactions on Pattern Analysis and Machine Intelligence  vol 12 no 5 pp 489–497 1990   H M  uller N Michoux D Bandon and A Geissbuhler A review of content-based image retrieval systems in medical applications-clinical bene\002ts and future directions International Journal of Medical Informatics  vol 73 no 1 pp 1–23 2004 
134 
330 
330 


0     0     1 0     0     0 0     0     0 153 target e-shopper for the past nT ?  periods prior to time T are given, it is important for marketer how to predict e-shoppers purchase behavior at timeT For solving the above problem, the following measures are taken. First, transaction clustering is conducted, so that all the transactions of e-shoppers are clustered. The SOM technique is used to cluster target e-shoppers transactions Then it is necessary to detect the evolving e-shopper purchase sequences as time passes. These e-shopper behaviors, which are derived from a change in the cluster number of each e-shopper, are kept in the purchase sequence database. Finally sequential purchase patterns over user-specified minimum support and confidence are extracted by using the association rule. The sequential purchase patterns are then stored in the association rule database Although SOM technique can obtains transaction clusters SOM clustering technique often breaks down when handling very high-dimensional data. So it is proposed that using product classes represents the hierarchical relationships among products. The method can make an effective dimensionality reduction while improving clustering results Assume that a product class set P  is classified into n different subclasses, and that each subclass consists of subclasses at a lower level, or eventual leaf products, as follows PPPPP nn ,, 121 ?= "                          \(1 Suppose that C is the set of the transactions of m e-shoppers during s periods before timeT . More specifically letC be composed as follows CCC kTmkTkTC ???= ,,2,1 ,, "                   \(2 11,0 ?= sk "  2?s WhereC kTj ?, ?C  is a non-empty subset of products Each C kTj ?,  represents the product class or classes from which e-shopper j purchased products at time kT EveryC kTj ?,  is transformed into an input matrix composed of a bit vector, and the matrix to be transformed is used in the transaction clustering. The time-ordered vectors for a particular e-shopper represent the purchasing history of the 


e-shopper; this input matrix can be thought of as the dynamic profile of the e-shopper. A dynamic e-shopper profile is defined as follows Let C _ be a dynamic e-shopper profile. Then, C _ is defined by the following matrix for n product classes and m e-shoppers over the course of s periods  3 mj "2,1 11,0 ?= sk " 2?s Where                         1 if Pi?C kTj   All the transactions of e-shoppers in the training e-shopper purchase database are transformed into dynamic e-shopper profiles based on their prior purchase behaviors. Then we use the SOM clustering technique to assign each transaction to a group. This transaction clustering facilitates the discovery of the dynamic cluster sequence of e-shopper The transaction clustering results in the following set of q clusters DDDD q"21 ,=                             \(4 Where each Di is a subset of C _ the given in \(3 A rearrangement of these clusters by  e-shopper  and by time  period is necessary for the identification of the dynamic behavior of each e-shopper. It is possible to learn the cluster sequence of a e-shopper by identifying the cluster to which each transaction of the e-shopper belongs, during each time period. To formalize this concept, we use the following terminology Let BP j be the behavior pattern of e-shopper j . Then, the behavior pattern BPi is identical to the changes in the cluster number of e-shopper j during s periods and is defined as follows  5 Where D kTj ?, ?D ,11,0 ?= sk "  2?s The  process  of searching for  a behavior path can 


be simply conducted through transaction clustering. All e-shoppers  have  a behavior path based on their prior transactions. The association rule technique is well suited for determining the most frequent pattern with confidence, since it provides automatic filtering capabilities. To discover the behavior path of a target e-shopper at time T based on his/her past behavior, the input data should be divided into a conditional part and a consequential part. Association rules are descriptive patterns of the form X?Y, where X and Y are statements regarding the values of attributes of an instance in a database. X is termed the left-hand-side, and is the conditional part of an association rule. Meanwhile, Y is called the right-hand-side, and is the consequent part. The conditional part is composed of the left-hand-side assigned to the consequential part R j represents the association rule about the user specified minimum support and confidence in the following form R j 6 A rule R j  indicates that, if the path of a e-shopper is DD TjsTj 1,1, , ?+? " , then the behavior cluster for that e-shopper is D Tj, at timeT It is necessary to know the degree to which the behavior path of a target e-shopper during 1?s periods beforeT  is similar to the association rule. The cluster path of a target e-shopper, transformed via the SOM, is compared with the association rules derived from other e-shoppers paths, and then the best-matching path is determined. Execution of this 0 if Otherwise    C kTj 154 process requires new measures for calculating the degree of correspondence between the association rules and the behavior path of a target e-shopper. This similarity measure is defined as follows     


1 1  s i i kTj i j SSD                            \(7 Where        1 if RD kTikTi   Si kTj 0 otherwise mj "2,1 11,0 ?= sk " 2?s ni "2,1 The above definition indicates that, if the behavior path of a target e-shopper i is equal to the conditional part of association rule j in the same period, then S j kTi ?,  is equal to one, otherwise is equal to zero. However, even if the similarity measure is high, a choice of the association rule suited to the prediction of the cluster of a target e-shopper at timeT is difficult, since such a rule is not general, given that the support and confidence of the association rule may be remarkably low. Therefore, to assure a good fit between the behavior path of a target e-shopper and the conditional part of the association rule, it is necessary to measure fitness. Fitness is defined as follows Suppose FDij be a degree of the goodness-of-fit between the behavior path i and the association rule j . Then, FDij is defined as follows ConfidenceSupportSDFD jjjiij = ,             \(8 Using the above definition, we can determine the cluster of a target e-shopper at timeT is a consequential part R Tj, of the association rule j with maximum FDij IV.  ILLUSTRATIVE EXAMPLE In this paper, we use Table 3 as example given to illustrate proposed method. The set of product classes given in Table 3 is P={Candy, Can, Milk, Bread, Biscuit}. The transactions of e-shopper CID006 are C June,006 {Candy}, =C May,006 {Can}, =C July,006 {Milk 


Therefore, the dynamic purchase profile of CID006 buying the set of products {Candy, Can, Milk Bread, Biscuit} from May to July may be represented as { }0,0,0,0,1,006 _ C June , { }0,0,0,1,0,006 _ C May and 0,0,1,0,0,006 _ C July . CID016 and CID006 are exactly same as both bought the same products during the same month Therefore, similarly, the transactions of target e-shopper CID016 are =C June,016 {Candy} and =C May,016 {Can The dynamic purchase profile of CID016 buying the products may be represented as 0,0,0,0,1,016 _ C June , { }0,0,0,1,0,016 _ C May TABLE IV. BEHAVIOR PATH OF E-SHOPPER CID 1+? sT  1?T  T 006 007 008  015 016 10 10 3   10 3 1 10   3 9 


3 4  9 9  Suppose 3=s , according to formula \(5 of CID006, BP006  is{ }9,3,10 , as shown in table 4,  which indicates  that  e-shopper  CID006 belonged to the tenth cluster in May and moved into the third cluster in June thereafter reaching the ninth cluster in July According to formula \(6 from e-shoppers path with regard to a minimum support of 0.1 and a minimum confidence of 0.5. The association rules are as shown in table 5. The similarities  between the path of e-shopper CID016  and the derived rules are 22016 =SD and 11016 =SD . Therefore, e-shopper CID016 belongs to the ninth cluster at timeT , since the fitness between CID016 and the rules are =FD2016 0.2 and =FD 1 016 0.2001. Therefore, we predict that the products which e-shopper CID016 is likely to buy are Bread, and Biscuit  TABLE V. THE DERIVED ASSOCIATE RULES Rule 1+? sT  1?T  T  Support Confidence 1 2 3  15 16 10 10 3   10 3 1 10  


 3 9 3 4  9 9 0.3 0.1 0.1 0.2 0.1 0.1 1.0 1.0 1.0 0.5 1.0 1.0 V. CONCLUSION The preferences of e-shopper change over time. In this study, we describe a new approach for mining the changes of e-shopper  purchase behavior over time and discuss solutions to several problems. For predicting e-shoppers purchase behavior, the following concepts are proposed: BP j SDij and FDij . The SOM technique is used to detect the evolving e-shopper purchase sequences as time passes. The purchase sequences are derived from the changes in the cluster number of e-shopper. The sequential purchase patterns over user-specified minimum support and confidence are extracted by using the association rule. Then the sequential purchase patterns are stored in the rule database Finally, we give the example to elaborate the new methodology. The research presented in this paper makes a 155 contribution to mining  e-shoppers purchase behavior basing on transaction data. E-retailer may be able to perform effective  one-to-one marketing campaigns by providing individual target e-shoppers with personalized Product basing on using purchase sequences In the future, some possible extensions to this work are as 


follows. From the results of this study, we know which products target e-shoppers are likely to buy, but we have not yet explored the times at which these purchases are likely to occur. Further research analyzing e-shoppers past purchasing patterns should likewise enable prediction of the most appropriate times. Furthermore, one interesting research extension would be the setting up of a real marketing campaign, in which e-shoppers would be targeted using this methodology, which could then be evaluated with regard to its performance REFERENCES 1]Dhond, Gupta, A., Vadhavkar, S. Data mining techniques for optimizing inventories for electronic commerce[C]. In the Proceeding of the ACM-SIGKDD International Conference on Knowledge Discovery and Data Mining, 2005:480-486 2] Kuo, R. J., Chen, J. H., Hwang, Y. C. An intelligent stock trading decision support system through integration of genetic algorithm based fuzzy neural network and artificial neural network[J]. Fuzzy Sets and Systems, 2001 118\(1 3] Agrawal, D., Schorling, C. Market share forecasting: An empirical comparison of artificial neural networks and multinomial logist model Journal of Retailing[J]. 1997, 72\(4 4] Weigen, A. S., Rumelhart, D. E.Generalization by weight-elimination with application to forecasting. Advances in Neural Information Processing Systems[J]. 1999, 3:875882 5] Chen, M, S, Han, J. Data mining: an overview from a database perspective[J]. IEEE Transactions on Knowledge and Data Engineering, 2006 8\(6 6] Schafer, J. B., Konstan. E-commerce recommendation application[J Journal of Data Mining and Knowledge Discovery, 2001, 16:125153 7] Giudici, P, Passerone, G. Data mining of association structures to model e-shopper behavior. Computational Statistics and Data Analysis[J]. 2002 38:533541 8]Changchien, S. Mining association rules procedures to support on-line recommendation by e-shoppers and products fragmentation[J]. Expert Systems with Applications, 2001, 20\(4 9] Song, H, Kim, J. Mining the change of e-shopper behavior in an Internet shopping mall[J]. Expert System with Applications, 2001, 21\(3 10] Anand, S, Patrick, A. A data mining methodology for cross-sales[J Knowledge-Based Systems, 2006, 10:449-461 11] G. Adomavicius, A. Tuzbilin. Using data mining methods to build e-shopper profiles[J]. IEEE Computer, 2006, 34 \(2 


12] Dhond, Gupta, A., Vadhavkar, S. Data mining techniques for optimizing inventories for electronic commerce[C]. In the Proceeding of the ACM-SIGKDD International Conference on Knowledge Discovery and Data Mining, 2005:480-486 13]Chui-Yu Chiu , Yi-Feng Chen. An intelligent market segmentation system using k-means and particle swarm optimization[J]. Expert Systems with Applications, 2009, 36: 45584565 14]Tzung-Shi Chen , Shih-Chun Hsu. Mining frequent tree-like patterns in large datasets[J]. Data & Knowledge Engineering, 2007,62:6583 15]H. Tsukimoto, Extracting rules from trained neural networks[J]. IEEE Trans.Neural Networks, 2000, 11 \(2 156 


http://datamining.buaa.edu.cn/TopKCos.pdf 14] M. Zaki, Scalable algorithms for association mining, TKDE, vol. 12, pp. 372390, 2000 


enhance item-based collaborative filtering, in 2nd IASTED International Conference on Information and Knowledge Sharing, Scottsdale, Arizona, 2003 476 2010 10th International Conference on Intelligent Systems Design and Applications 


Basi Association Rles Basi c  Association R u les Association is basically connecting or tying up occurrences of Association is basically connecting or tying up occurrences of events Ol dib t f ilt t O n l y d escr ib e se t s o f s i mu lt aneous even t s Cannot describe patterns that iterate over time e g  itemset a  0  b  0  g    Eg If you sense higher data rates on the downlink than normal AND New Route generated Implies high chances of Intrusion AND New Route generated Implies high chances of Intrusion Associative IDS for NextGen Frameworks Dr S Dua LA Tech 20 


Enhanced Inte r transaction Association Rules Enhanced Inter transaction Association Rules Enhanced Inter transaction Association Rules Extension of association rules Conditional relationships at multiple different time steps e.g itemset a\(0 0 1 2 You sense Higher data rate than normal AND You see New Route g enerated AND 1 minute a g o you detected checksum gg error packets AND 2 minutes ago your encountered wrong checksum   Implies High Chance of Intrusion Enhanced Rules and Confidence Associative IDS for NextGen Frameworks Dr S Dua LA Tech 21 


Complex Spatio temporal Association Complex Spatio temporal Association Rules Further extension of inter transaction association rules Describe event durations e.g itemset a\(0,X j,Y k,Z Eg  You sense high data rates for X seconds AND new route generated j minutes ago task completed in Y AND new route generated j minutes ago task completed in Y seconds AND checksum error packets received k minutes ago for Z seconds High Chance of Intrusion With highest confidence level in association rules  association rules  Associative IDS for NextGen Frameworks Dr S Dua LA Tech 22 


DMITAR Al ith ARD DMITAR Al gor ith m  ARD Problem Domain Problem Statement and Challenges Aiti Miig bd IDS A ssoc i a ti ve Mi n i n g b ase d IDS  Introduction to data mining Association rule in data mining DMITAR Algorithm  ARD New research Associative IDS for NextGen Frameworks Dr S Dua LA Tech 23 


DMITAR Algorithm DMITAR Difference Matrix Based Inter Transaction Association Rule Miner developed in DMRL Uses vertical data format Differences of the transaction IDs are used to generate extended itemsets Windowless mechanism Associative IDS for NextGen Frameworks Dr S Dua LA Tech 24 


Deep into the Mechanism The DMITAR algorithm is based on lhilii comp l ex mat h emat i ca l assoc i at i ve formulation and proofs Four major parts Four major parts Frequent 1 itemset generation Frequent 2 itemset generation Frequent k itemset generation k>2 Spatio temporal rule formation Associative IDS for NextGen Frameworks Dr S Dua LA Tech 25 


DMITAR, Datasets Used Stock Data Stock Data Daily stock information provided by Yahoo finance Wth Dt W ea th er D a t a Provided by the US Department of Commerce and National Climactic Data Center for 700 locations across US Synthetic Data Provided by a CRU weather generator that uses a Markov chain model to generate simulated weather data for 11 UK sites Associative IDS for NextGen Frameworks Dr S Dua LA Tech 26 


DMITAR Results 1/5 Varying Support DMITAR Results 1/5 Stock Database Support FITI ITPMine PROWL DMITAR 14 6424.7s 132.39s 3.03s 5.556s 16 2348.9s 67.14s 2.14s 4.015s 18 861.92s 34.62s 1.55s 2.89s 20 334.51s 18.89s 1.12s 2.07s 22 143 84s 10 87s 0 87s 1 45s 22 143  84s 10  87s 0  87s 1  45s 24 63.62s 7.15s 0.671s 1.04s Weather Database Support FITI ITPMine PROWL DMITAR 14 36362.6s 893.1094s 5.843s 19.8281s 36362.6s 893.1094s 5.843s 19.8281s 16 11913.04s 378.2188s 3.8906s 13.4375s 18 4116s 170.3438s 2.75s 9.1406s 20 1507s 86.5781s 2.14s 6.203s 22 859.2813s 63.3438s 1.7969s 5.7656s 24 378.5313s 36.1875s 1.4375s 3.5625s Synthetic Dataset Support FITI ITPMine PROWL DMITAR 14 1651.6s 199.843s 3.1406s 17.015s 16 574 32 119 32 2 0938 10 875 16 574  32 s 119  32 s 2  0938 s 10  875 s 18 416.109s 95.31s 1.6094s 7.39s 20 370.25s 83.31s 1.453s 5.8438s 22 265.78s 66.3438s 1.3594s 4.75s 24 133.96s 43.0781s 0.9219s 3.5781s 


DMITAR Rlt  DMITAR  R esu lt s 2  5 Rules Formed Associative IDS for NextGen Frameworks Dr S Dua LA Tech 28 


DMITAR Rl  Varying Maxspan DMITAR  R esu l ts 3  5 Varying Maxspan Associative IDS for NextGen Frameworks Dr S Dua LA Tech 29 


DMITAR Res lts 4/5 Vig Di i DMITAR  Res u lts  4/5 V ary i n g Di mens i ons Associative IDS for NextGen Frameworks Dr S Dua LA Tech 30 


DMITAR Rl  Varying Number of Transactions DMITAR  R esu l ts 5  5 Varying Number of Transactions Associative IDS for NextGen Frameworks Dr S Dua LA Tech 31 


N/C t Rh N ew C urren t R esearc h Problem Domain Problem Statement and Challenges Associative Mining based IDS Associative Mining based IDS Introduction to data mining ii lid ii Assoc i at i on ru l e i n d ata m i n i ng DMITAR Algorithm  ARD h New Researc h Associative IDS for NextGen Frameworks Dr S Dua LA Tech 32 


Further Research Further Research Objectives of Our Intrusion Detection System Development Objectives of Our Intrusion Detection System Development 1 Refine and scale the DMITAR algorithm to suit our application 2 Develop methods for dynamically altering the sensor parameters Our Focus is Securing the NextGen Frameworks with New Technology Technology Associative IDS for NextGen Frameworks Dr S Dua LA Tech 33 


Simulated Sensing Environment Simulated Sensing Environment Screenshots of Data C ollected from S ynthetic Sensors Screenshots of Data C ollected from S ynthetic Sensors Simulated in Our Laboratory Three Steps Slides Collect data Collect data from all sources  all attributes  Select Select the source and their hierarchical attributes attributes to be monitored and Select Select the source and their hierarchical attributes attributes to be monitored  and Sample Sample them at different rates different rates and process them Associative IDS for NextGen Frameworks Dr S Dua LA Tech 34 


Data Collection Simultaneous collection of data screen from ENTITIES aircrafts Associative IDS for NextGen Frameworks Dr S Dua LA Tech 35 Source PRTG Network Monitor software screen shot Demo info www.paessler.com 


Parameter Selection Selection of an ENTITY/aircraft and monitoring its parameters and sensor readings Associative IDS for NextGen Frameworks Dr S Dua LA Tech 36 Source PRTG Network Monitor software screen shot Demo info www.paessler.com 


Sensor Sampling Selecting one sensor/probe and reading it at different resolutions or sampling rates Associative IDS for NextGen Frameworks Dr S Dua LA Tech 37 Source PRTG Network Monitor software screen shot Demo info www.paessler.com 


Si l ti Nt k Si mu l a ti on on N e t wor k Most scenarios can be simulated on a computer or computer network network  The aircrafts and sensors are simulated on a computer network bllb b y ana l ogica l su b stitutions Sensors provide information at different rates Sensors provide information at different rates Need Based Sensor Prioritization NSP and Dynamic Sensing Rate Sampling Associative IDS for NextGen Frameworks Dr S Dua LA Tech 38 


Vulnerability Search Scan 39 Sample UQA script with Nmap performed in DMRL Associative IDS for NextGen Frameworks Dr S Dua LA Tech 39 Source Nmap screenshot with a pearl script  Find Namp on Nmap.org 


Modality Aspect Modality Aspect A Multimodal distribution is a continuous probability distribution with two or more modes of underlying data Mltil d i M u lti p l e mo d es i n our model Associative IDS for NextGen Frameworks Dr S Dua LA Tech 40 Source http://en.wikipedia.org/wiki/File:Bimodal bivariate small.png 


Multi Modality Modality Fusion 41 SENSITIVE  UNCLASSIFIED For Official Use Only Associative IDS for NextGen Frameworks Dr S Dua LA Tech 41 


Emphasis Emphasis Our approach emphasizes on pre empting the attack Our intent is NOT to perform an autopsy to discover attacks Instead we aim to detect and prevent in attacks in real time Associative IDS for NextGen Frameworks Dr S Dua LA Tech 42 


Techniques for Discriminative Rules Techniques for Discriminative Rules Resolution Analysis Features Analyzed at Different Depths Anti Monotonic Principle Modality Aspect Treading into Unexplored Feature spaces Associative IDS for NextGen Frameworks Dr S Dua LA Tech 43 


Representative Outcomes Representative Outcomes Illustration of the Final Analysis Our method shifts between modalities and sampling rates for optimization The blue parallelograms are actual intrusions 44 The blue parallelograms are actual intrusions The Red Green Blue Plots are response of system Associative IDS for NextGen Frameworks Dr S Dua LA Tech 44 


Advantages of Our M ethod Advantages of Our M ethod Exploit the memory v ertical data format utilizes slidin g windows to g form a much larger database to analyze  Flexibility in Choosing what to choose  Choosing what to choose to build the rules Computational and memory efficiency We have a team working only on this aspect 45 Associative IDS for NextGen Frameworks Dr S Dua LA Tech 45 


Preliminary Results Intra transaction Relations Data rate simulator NH-134 Mb HOP PATH update \(Y/N Inference 11.5 Y Y 2 0.120 N N      Y   n 0.345 N NH134 Y/N   Inf 1 0.150 N N 2 0 120 Y N Inter transaction Relations 2 0  120 Y N       5 5.55 0.456 Y Relations  n 0.345 N N Nmap on DMRL nmap.org 


Anticipated Outcome Anticipated Outcome Develop algorithm capable of learning from a given heterogeneous diverse Develop algorithm capable of learning from a given heterogeneous diverse data ff Dynamic algorithmic f ramework designed to shi f t modalities and sampling rates based on complex logic Flexibility of integration into the Snort intrusion detection system 47 Associative IDS for NextGen Frameworks Dr S Dua LA Tech 47 


References References Aircraft Cockpit Image courtesy USAF http://www.faa.gov htt p   www.faa g ov  air traffic  technolo gy  p g  _ gy  Acharya R Dua S Du X Sree V Chua C K Automated Diagnosis of Glaucoma Using Texture and Higher Order Spectra Features To appear in IEEE Transactions on Information Technology in Biomedicine  Du X Dua S 2011 Cancer Prognosis Using Support Vector Regression in Imaging  Modality World Journal of Clinical Oncology 2  1   44 49 Du X Dua S 2010 Salient Frame Extraction Using Support Vector Regression and Motion Features pp 5 Proc of the National Aerospace and Electronics Conference July 14 16 2010 D M P D S 2010 Di i i ti Ft d Cl ifi ti Mthd f D essaue r  M  P  D ua S  2010  Di scr i m i na ti ve F ea t ures an d Cl ass ifi ca ti on M e th o d s f or Accurate Classification 1st ed vol 7704 pp 14 Bellingham WA Proceedings of SPIE Dessauer M P Dua S 2010 Low Resolution Vehicle Tracking using Dense and Reduced Local Gradient Features Maps 1st ed vol 7694 pp 8 Bellingham WA Proceedings of SPIE SPIE 


Acknowledgements Acknowledgements Fundin g A g encies  US 4 1 Million direct fundin g g g 4 g LA BoR NIH NSF AFRL AFOSR and NASA Research Team Samuel Kasimalla Brandy McKnight Dr Pradeep Chowriappa Connor Johnson Vasanth Nair Mihir Chowriappa  Connor Johnson  Vasanth Nair  Mihir Karnik Mohit Jain and Swadheen Songmen Associative IDS for NextGen Frameworks Dr S Dua LA Tech 49 All the respective Logos belong to their owners 


Rf d Rdi R e f erence d R ea di ngs Copyright of cover pages held by respective publishers 


Thank You Questions Thank You  Questions Dr Sumeet Dua E mail sdua@latech.edu Web http://dmrl.latech.edu Associative IDS for NextGen Frameworks Frameworks Dr S Dua LA Tech 51 Image Source roadtrafficsigns.com 


