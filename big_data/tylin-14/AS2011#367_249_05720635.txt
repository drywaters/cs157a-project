Protecting Privacy while Discovering and Maintaining Association Rules Tran Khanh DANG   Faculty of CSE, HCMUT Ho Chi Minh City, Vietnam khanh@cse.hcmut.edu.vn Josef K\334NG FAW, Johannes Kepler University Linz, Austria josef.kueng@faw.jku.at Huynh V.Q. PHUONG Faculty of CSE, HCMUT Ho Chi Minh City, Vietnam huynhvan.quocphuong@gnt.com.vn   Abstract 227The k-anonymity is an efficient model to preserve data privacy. Of late, this model has been applied to the area of privacy-preserving data mining but the state-of-the-arts are still far from practical needs. In this paper, we propose a new approach that preserves privacy and maintains data utility in 
data mining. Concretely, we use a k-anonymity model to preserve privacy while discovering and maintaining association rules through a novel algorithm, M3AR-member migration technique for maintaining association rules. We do not use the existing generalization and suppression techniques to achieve a kanonymity model. Instead, we propose a member migration technique that is more appropriate for the requirements of maintaining association rules. Experimental results establish the practical value and theoretical analyses of our new technique Keywords-privacy preservation; k-anonymity; data mining member migration technique; association rules I   
I NTRODUCTION  The advance of information technology has brought many benefits to many organizations such as the ability of storing sharing, mining data by data mining techniques. However, this bears a big obstacle of leaking out and abusing privacy. So, as a vital need, privacy preservation \(PP\as born to undertake great responsibility of preserving privacy and maintaining data quality for data mining techniques. Concurrently, focusing on privacy and data quality is a trade-off in PP-related researches A  k-Anonymity Model and Techniques In order to preserve privacy, identification attributes such as id  name etc. must be removed. However, this does not ensure privacy since combinations of remaining attributes such as 
gender  birthday  postcode etc. can uniquely or nearly identify some individuals. Therefore, sensitive information of the individuals will be exposed. Such remaining attributes are called quasi-identifier attributes [1  T h e  k an o n y m it y  m o d e l  1,2 i s a n a ppro a c h  t o  pro t e c t d a t a  f r o m  i n d i vi dua l  identification. The model requires that a tuple in a table representing an individual with respect to quasi-identifier attributes, has to be identical to at least \(k-1\ other tuples. The larger the value of k, the better the protection of privacy. To obtain a k-anonymity model, there are various techniques classified into two types: Generalization and Suppression. The Generalization technique builds a hierarchical system for values of an attribute value domain based on the generality of 
those values and replaces specific values with more general ones. This technique is classified into two generalization levels attribute and cell levels. The attribute level replaces the current value domain of a quasi-identifier attribute with a more general one. For example, the domain of attribute age is mapped from years to 10-year intervals. The cell level just replaces current values of some essential cells with more general ones. Both levels obtain the k-anonymity model. However, the cell level has the advantage over the attribute level of losing less information as it does unnecessarily replace many general values, but it has the disadvantage of creating inconsistent values for attributes because the general values co-exist with the original ones. The attribute level has consistency of 
attribute values but loses much information as there are many changes in original data. It therefore easily falls into a too general state. Generally, the cell level generalization is preferred for its upper hand of less information loss though it is more complicated than the attribute level one. Optimal kanonymity by the cell level generalization is NP-hard [16   Many proposed algorithms [5,6,7,10,11,13 ha ve us e d t h i s  cell level generalization  The Suppression technique executes suppression on original data table. The Suppression can be applied to a single cell, to a whole tuple or column [4 B  Problems and Main Contributions Trade-off between data privacy and data quality is important in PP problem. Traditional approaches have used a 
variety of metrics as the basis for algorithm operations to minimize data information loss such as Precision [2  W H D  Distortion [5 L  6  a n d N C P 7 T h o s e m e t r i c s  ar e t oo general and do not concentrate on maintaining data quality towards any specific data mining technique. However, in reality, data after being modified will be mined by a specific mining technique. Therefore, modified data may not bring high data quality to any mining technique. In this paper, we propose a new approach to preserve data privacy while concentrating on maintaining data quality towards a specific data mining technique. The output data in our approach will have better data quality \(towards data mining techniques that algorithms direct to\ than that of the traditional approach. According to this approach, with the same original dataset 
D if receiver wants to mine data by a mining technique DM he will receive a \221tailored\222 dataset D\222 modified by a PP algorithm which focuses on maintaining data quality towards DM  In this paper, we do not aim at embracing all data mining techniques. We just focus on association rule mining techniques and concurrently preserve data privacy by a kanonymity model. As discussed above, there are various   Part of this research had been done as the author was at FAW institute Johannes Kepler University \(JKU\, Linz, Austria 978-1-4244-8704-2/11/$26.00 \2512011 IEEE 


techniques to obtain a k-anonymity model. However, we do not use those techniques for some reasons: the attribute level generalization has the disadvantage of creating a lot of data distortion. Many replacements of old values of an attribute with new ones will contribute to direct impact on making wrong in many association rule sets. The cell level generalization has less data distortion but it can increase the number of distinctive values of an attribute and its inconsistency is not a good choice to maintain association rules. The cell Suppression technique is not a desired solution as well since null or unknown values have to be pre-processed before mining. The tuple Suppression has two drawbacks. First, it directly has influence on min_sup  of the association rule data mining technique. Second, it can lose many tuples of original data. Also, if the values of an attribute A that needs to be rejected appear in many association rules, then many rules will be loss. The attribute Suppression therefore, is not suitable either. Moreover, if a receiver does not accept the rejection of attribute A out of the dataset received, it is a good reason not to select this technique Hence, to maintain association rules, we will introduce a novel technique, named Member Migration \(MM\. Basically the technique first groups tuples in the original dataset D into separate groups based on the similarity of values on a given quasi-identify attribute set and then performs a MM operation between each group pair where there is at least one group having the number of tuples less than k. If a tuple t in group A  migrates to group B values of t have to change to ones of those in group B with respect to the quasi-identify attribute set. In addition, we propose M3AR algorithm that uses the MM technique to concretize the new approach The rest of this paper is organized as follows. Section II discusses MM technique. Section III introduces typical metrics Section IV presents M3AR algorithm. Section V shows experimental results. Finally, section VI concludes the paper II  T HE M EMBER M IGRATION T ECHNIQUE  Firstly, our technique is to group tuples in the original dataset D into separate groups based on the identity of values on a quasi-identifier attribute set and then, performs a MM operation between every two-group where there is at least one group having the number of tuples less than k. A group can perform a MM operation with one or more other groups. If a tuple t in group A migrates to group B values of t have to change to ones of those in group B with respect to a quasiidentifier attribute set. This technique is illustrated in Fig. 1 Table \(a\ is the result after grouping tuples in a sample dataset into six separate groups based on the identity of values on a quasi-identifier attribute set {Att1,Att2,Att3}. Table \(b\ obtains a 5-anonymity model with four groups after applying three MM operations between groups. One member \(tuple\ in group 5 migrated to group 4, values changed from \(b,y o \(b,x  One member in group 5 migrated to group 2, values changed from \(b,y a,y Two members in group 1 migrated to group 2, values changed from \(a,x o \(a,y  The MM technique only replaces necessary cell values by other ones in the current value domain, so it inherits advantages of Generalization techniques: less information loss as the cell level Generalization, consistent attribute values as the attribute level Generalization. Besides, it possesses other advantages as follows: no difference between numerical and category attributes; no need to build hierarchies for attribute values based on generality; and finally, as a receiver get a modified dataset D he/she will sense that D has never been modified   Figure 1  The migration member technique to obtain a k-anonymity model Definition 1 A group is a subset of tuples \(the number of tuples is greater than zero\ of a table that has same values with respect to a given quasi-identifier attribute set  Definition 2 A group is k-unsafe if has fewer than k tuples otherwise, it is k-safe where k is a given anonymity degree  Risk Assume that the desired anonymity degree is k. A group that has the number of tuples m \(m>0\ will be estimated risk through the function \(cf. Appendix A        k m when m k k m when m F R 0 2 0   1 Consider a dataset D after grouped, resulting in a set of groups G = {g 1 g 2 g n  Let g i  denote the number of tuples in the i th group. Then the total risk Risk D of the dataset D is     n i i R D g F Risk 1   2 Observation 1  Assume Risk D is risk of a dataset D Risk D 0 if and only if D’ has achieved a k-anonymity model  Proof is simple, using the disproof method Definition 3  Let j T i g g    be a MM operation from g i  to  g j     i g T j i   if values of all tuples in T are altered to values of tuples in g j considering a quasi-identify attribute set  Then, there exists two separate migrant directions between two groups g i and g j from g i to g j  g i g j and g j to g i  g i g j  Definition 4  A Member Migration operation j T i g g     is   valuable  when the risk of data is decreased after performing that Member Migration operation  When performing a MM operation j T i g g    there are only changes on risk of two groups g i  and g j   Therefore, risk reduction of all data is equal to the sum of risk reductions in two group g i  and g j  after performing that MM operation Theorem 1  If a Member Migration operation  j T i g g     is  valuable  then the number of k-unsafe groups in set  g i g j   after this operation can not exceed one  Proof The case as both two groups g i  and g j  are k-safe is obviously true. Let’s consider the cases when there is at least one k-unsafe group, using the disproof method. Assume that after performing a valuable MM operation on g i  and g j  we still have two k-unsafe groups. We have two cases as follows 1  When both g i and g j are k-unsafe, the total risk of two groups before migrating is Risk before 4k-|g i g j Assume l is the number of migrant tuples. Without loss of generality assume the migrant direction is g i g j Since the number of kunsafe groups after migrating is two, the risk after migrating is Risk after 4k–\(|g i l\–\(|g j l\=4k-|g i g j Risk before However, this is a “valuable” MM operation, so we have a contradiction 


2  One k-safe group and one k-unsafe one. Assume g i is a k-unsafe group and g j is k-safe. Risk before 2k-|g i Because we have 2 k-unsafe groups after the MM operation, it is obvious that the migrant direction is g i g j with l tuples and satisfies two conditions:0<|g i l<k and 0<|g j l<k. Hence, 0<|g i g j 2k Besides, Risk after 4k-|g i g j Risk before 2k-|g i that means g j 2k \(**\. From \(*\ and \(**\, we have a contradiction III  P RELIMINARIES  A  Association Rule and Budget Metric Given a dataset D a set of tuples with an attribute set  m i i i I   2 1  An association rule from D  A B          B A I B I A  Let C=A 012 B be an itemset Support\(A B\=P\(C is the percentage of tuples containing both A and B in D  Confidence\(A B\=P\(B|A\=P\(C\/ P\(A is the percentage of tuples that contain both A and B in a tuple set containing A  min_sup  s m nd min_conf  c m are minimum support and confidence [15  in d i v i d u al ly  w h ich are tw o in p u t th r e sh o l d s   A rule A B is valuable when Support\(A B\=s s m and Confidence\(A B\=c c m  are strong rules  m s s s   3 For a rule A B to exist, the number of tuples supporting this rule being changed \(on itemset of rule\ can not exceed s  However, we need to consider Confidence\(A B  Case 1 Reduce a rule confidence as changing values of attributes in A Let 1  c’ be the number of tuples supporting this rule being changed and the rule confidence, respectively To keep rule exist, we must have c c m     1         1 1 1 1 1  m m m c c c c s c c s s A Support B A Support c            015 015 015 015 015 4 From \(3\ and \(4\ to keep rule A B exist, the number of tuples supporting this rule on attributes in A can not exceed       1     m m m c c c c s s s MIN 5 Case 2 Similarly, as changing values of attributes in B let 2 c  be the number of tuples supporting this rule, the rule confidence, individually. To keep rule exist c c m must hold   c c c s c c s s A Support B A Support c m m         2 2 2       015 015 015 6 From \(3\ and \(6\ to keep rule A B exist, the number of tuples supporting this rule on attributes in B can not exceed     c c c s s s MIN m m    7 Each rule r  A B has a budget metric budget r  determined from \(5\ the corresponding attribute set of B does not contain a quasi-identify attribute. Otherwise, it  is determined from \(7 When budget r  0, the risk of losing r is high B  Impact of the MM Technique on Association Rules Let D  R  QI  r QI be sets of tuples, association rules mined from D quasi-identify attributes of D quasi-identify attributes corresponding to items of an association rule R r r          QI QI R r r R r care   Therefore, there are only rules in care R impacted during the process of changing data D to data D     sup    r t D t R r r R care t       sup r t tuple t supporting association rule r means that t contains an itemset of r      sup    r t D t R r r R care t       t t care R R R 012     j i g g g G j i         is a set of groups grouped according to the similarity of values of tuples wrt. an attribute set QI Consider an operation j T i g g     T t   we have to change its values in some attributes in QI This attribute set is ij QI  Q I QI QI ji ij   We have association rule sets as follows           j i j i j i j i j i j i j i j i g g t g g t t r ij t g g t r ij t g g t g g t g g t t r ij t g g t r ij t g g t R R R QI QI T t R r r R QI QI T t R r r R R R R QI QI T t R r r R QI QI T t R r r R         012              012                                   8 T t    t migrating from g i to g j does not influence rules in two rule sets  j i g g t R   and  j i g g t R   However it has an impact on rules in two rule sets j i g g t R   and  j i g g t R    budget r  of all rules j i g g t R r    will be reduce one unit for each T t   B A r    in  j i g g t R   it is not certain that its budget r  will be reduced. There exist those cases as follows Case 1 Just increase the support of A Obviously, this case will reduce the confidence of r leading to risk of losing rule Let be the times that the same rule r falls into this case. To keep rule r exist, the following inequality must be satisfied   m m m c c c c s c c s s          015 015 9 Case 2 Just increase the support of B will not influence r  Case 3 Increase the support of an item set containing both A and B This case will concurrently increase the support and confidence of rule r since  1    sup  sup 1  sup 1  sup  sup  sup          r confidence A B A A B A A B A and this condition is true Case 4 All remaining cases will not influence r as well Let p \(0 p 1 be the probability that t impacts on rules j i g g t R r    falling into case 1. Then t reduces p in budget r  for each j i g g t R r    Let C t be the cost of migrating each T t   then j i j i g g t g g t t R p R C       So, the total cost of j T i g g    is                T t g g t T t g g t T t g g t g g t T t t j i j i j i j i R p R R p R C     10 Since a k-anonymity model only considers attributes QI  determining the exact value of p is difficult. There exists a solution to determine exactly t C for each T t  but it must consider all attributes of t increasing the algorithm complexity For each j i g g t R r    case 1 weakens r while other cases do 


not impact or strengthen r To simplify, we can ignore the impact on  j i g g t R   of each T t  So, the cost for each T t  is j i g g t t R C    and the total cost of an operation j T i g g    is      T t g g t T t t j i R C  11 C  Data Quality For the characteristics of PP while preserving association rule set, we propose three metrics appropriate for association rule: NRP, percentage of number of newly generated rules LRP, percentage of number of loss rules; DRP, percentage of number of different rules. Let R  R correspondingly be rule sets mined from an association rule data mining technique of data D and D at min_sup and min_conf   R R R R R DRP R R R LRP R R R NRP               12 D  Policy This section presents some policies that are basic to operation mechanism of the algorithm M3AR. Give a group g  original tuples of g is all tuples that g has when it has never executed a MM operation with any other groups. Because a group can receive from or give to other groups some tuples, let origin  g l remaining  original tuples of g and foreign  g  be all tuples that g receives from other groups 1  A k-unsafe group once has received tuple\(s\, it can only continue receiving tuple\(s\; otherwise, as its tuple\(s migrate to another group, it can only continue giving its tuple\(s\ to other groups. The policy does not apply to k-safe groups 2  j T i g g    and   0          r g g t Budget R r T t j i   3  Consider two groups g i  g j Since there is at least one kunsafe group, assume g i  is a k-unsafe group. The number of migrant tuples mgrtN etermined as follows Case 1  g j  is a k-unsafe group. If g i g j then the number of migrant members is Min\(|g i k-|g j  If g i g j then the number of migrant members is Min\(|g j k-|g i   Case 2  g j  is a k-safe group. If g i g j then mgrtN = |g i  If g i g j then the mgrtN Min  k-|g i g j k, |origin  g j   when Min  g j k, |origin  g j     0 then g i g j is impossible 4  Rule to select a more useful MM operation according to descending priority order of three factors: less cost, more risk reduction, and fewer numbers of migrant members 5  If the number of members that can migrate between g i  and g j is greater than mgrtN then select mgrtN members that have the least cost to be migrant candidates IV  T HE P ROPOSED M3AR  A LGORITHM  Algorithm M3AR is divided into two processing stages First is the Initialization stage: partition tuples of original data D into groups, classify those groups into k-safe and k-unsafe groups, create R care set from input association rule set R and calculate budget for each rule in R care set. Time complexity of this stage is O\(|R|+|D as it linearly depends on the size of rule set R and data D Second is the Process stage: in each while loop, if SelG is null then randomly select a group in UG  to assign to SelG and find the most useful group g in the rest groups that  performs a MM operation with SelG policy 4 in section III.D\. If g can not be found then move SelG into UM  Otherwise, perform the MM operation between SelG and g  update budget for influenced association rules  Figure 2  M3AR algorithm  Figure 3  Disperse function Note that there is at most a k-unsafe group in set SelG  g  after the MM operation \(theorem 1\, the k-unsafe group will be assigned to SelG and processed in next loop. Otherwise if there exists no k-unsafe group in SelG  g then SelG  null and a new k-unsafe group in UG is selected randomly and processed in next loop. When while loop ends, groups in UM will be dispersed by Disperse function. Time complexity of this stage is mainly in while loop because processing groups in UM is much fewer than in while loop, normally UM|=0 Thus, time complexity of this stage is O\(|UG|*|G O\(|G|*|G Line 6 of Disperse function, selecting the most useful group, does not use policy 4, but the following rule: Select a more useful group according to descending priority order of 2 factors: fewer in number of rule r with budget r 0 if t migrates to g less cost V  E XPERIMENTS  Our experiments use a real world database Adult 1 to verify the performance of the M3AR algorithm in both process time and data quality by comparing with 3 algorithms: KACA 5  O K A  6  Bo tt o m U p  B U   7   A l l a l gor it hm s a r e 


implemented using VB.Net, Windows XP on a core 2-duo CPU 2.0GHz, 1GB of physical memory. Adult database has 6 numerical and 8 categorical attributes. It leaves 30162 records after removing the records with missing values. In our experiments, we retain only 9 attributes age, gender, marital country, race, edu, h_p_w, income, workclass The first six attributes are considered as quasi-identifying ones. Mining rule set on original data D and modified data D with min_sup 0.03 and min_conf 0.5. Beside NRP, LRP and DRP metrics, we also use metric CAVG [11  T h e q u a l i t y o f k-a n o nym i t y i s  measured by the average size of groups produced, and an objective is to reduce the normalized average group size. The achieved result is the average of 3 times executing the 4 algorithms with each value of k Fig. 4 shows the result of the 4 algorithms on LRP metric M3AR gets very low, not exceed 0.38%, superior to all remaining algorithms. BU gets higher than KACA, say 16.41 vs. 11.75% at k=30. Fig. 5 shows the result of the 4 algorithms on NRP metric. BU gets the lowest in the four, only 6.5% at k=30. M3AR initially gets higher than KACA but as k increases, KACA increases quickly and higher than M3AR at k>10. KACA gets 25.68% and M3AR gets 9.53% at k=30      Figure 4  Lost rule percent Figure 5.   New rule percent      Figure 6.   Difference rule percent Figure 7.   Elapsed time Fig. 6 shows the result of the four algorithms on DRP metric, M3AR gets the lowest with 9.91%, KACA gets 37.44 and BU gets 22.01% at k=30. So, in this metric, KACA gets approximately 4 times and BU gets more than 2 times higher than M3AR at k=30. With all 3 metrics NRP, LRP and DRP OAK algorithm gets a very high value, the rule set of original data D is greatly destroyed. Consider all 4 metrics, the stability of M3AR is higher than the 3 remaining algorithms. OKA is the most unstable, its executing time \(Fig. 7\ is the longest 4010s at k=5\, but it is quickly reduced as k increases \(482s at k=30\. While CAVG metric \(Fig. 8\ of M3AR, KACA, BU reduces, that of OKA increases as k increases VI  C ONCLUSIONS  In this paper, our main contribution is threefold: \(1\ A new approach to PP while maintaining data quality towards some specific data mining technique; \(2\The MM technique that overcomes crucial drawbacks of the Generalization and Suppression techniques in the k-anonymity protection model; \(3\The M3AR algorithm that preserves individual re-identification and maintains association rule sets to concretize our newly proposed approach Beside the k-anonymity model, there are a variety of its variants proposed to preserve data out of individual reidentification [8,9 Ex t e n d i n g th e M 3 A R alg o r ith m to th ese  models is of our great interests in the future. Also, developing the M3AR to address other problems in the area of privacy preserving data mining [17,18 w ill als o  b e  o u r f u tu re r e se ar c h  R EFERENCES  1  P. Samarati: “Protecting Respondent’s Privacy in Microdata Release TKDE, 13\(6\:1010–1027, 2001 2  L. Sweeney: “Achieving k-Anonymity Privacy Protection using Generalization and Suppression”. IJUFKS, 10\(6\:571–588, 2002 3  L. Sweeney: “k-Anonymity: A Model for Protecting Privacy”. IJUFKS 10\(5\:557–570, 2002 4  C.C. Aggarwal, P.S. Yu: “Privacy-Preserving Data Mining Models and Algorithms”. Springer-Verlag, 2008 5  J.Y. Li, R.C.W. Wong, A.W.C. Fu, J. Pei: “Anonymisation by Local Recoding in Data with Attribute Hierarchical Taxonomies”, TKDE 20\(9\:1181-1194, 2008 6  J.-L. Lin, M.C. Wei: “An Effcient Clustering Method for kAnonymization”. PAIS, pp. 46-50, 2008 7  J. Xu, W. Wang, J. Pei, X. Wang, B. Shi, A. Fu: “Utility-Based Anonymization Using Local Recoding”. SIGKDD, pp. 785–790, 2006 8  N. Li, T. Li, S. Venkatasubramanian:: “t-Closeness: Privacy beyond kAnonymity and l-Diversity”. ICDE, pp. 106–115, 2007 9  H. Jian-min, Y. Hui-qun, Y. Juan, C. Ting-ting: “A Complete \(a,k\Anonymity Model for Sensitive Values Individuation Preservation ISECS, pp. 318-323, 2008   Y. Ye, Q. Deng, C. Wang, D. Lv, Y. Liu, J. Feng: “BSGI: An Effective Algorithm towards Stronger l-Diversity”. DEXA, pp. 19–32, 2008   K. LeFevre, D.J. DeWitt, R. Ramakrishnan: “Mondrian Multidimensional k-Anonymity”. ICDE, 2006   UCI Machine Learning: http://archive.ics.uci.edu/ml/ \(accessed in 2009   J.L. Lin, M.C. Wei, C.W. Li, K.C. Hsieh: “A Hybrid Method for kAnonymization”. APSCC, pp. 385-390, 2008   J. Yu, J. Han, J. Chen, Z. Xia: “TopDown-KACA: An Efficient LocalRecoding Algorithm for k-Anonymity. IEEE GrC, pp. 727-732, 2009   J. Han, M. Kamber: “Data Mining: Concepts and Techniques”. Morgan Kaufman Publishers, 2001   A. Meyerson, R. Williams: “On the Complexity of Optimal kAnonymity”, PODS, pp. 223-228, 2004   H.V.Q. Phuong, T.K. Dang: “eM 2 An Efficient Member Migration Algorithm for Ensuring k-Anonymity and Mitigating Information Loss Secure Data Management-VLDB, pp. 26-40, 2010   Q.C. Truong, T.A. Truong,, T.K Dang: “The Memorizing Algorithm Protecting User Privacy in Location-Based Services using Historical Services Information”. IJMCMC, 2\(4\5-86, 2010 A PPENDIX A  R ISK F UNCTION F R m Choosing F R m\=C–m  C 2 k, 0<m<k, C  N\ is for the satisfaction of theorem 1. In the proof, case 1 does not depend on C In case 2 g i  is k-unsafe and g j  is k-safe Risk before C-|g i  Because we have 2 k-unsafe groups after the MM operation, the migrant direction is g i g j with l tuples and satisfies 2 g i l k1 and 1 g j l k1 3 g i g j  2 k 2 \(*\ Also Risk after  2 C-|g i g j Risk before C-|g i  g j C g j  C 1. Thus g i g j  C 2  From and \(**\ we have C 2 2 k 2 C 2 k 4 \(*’\. The theorem 1 is true if \(*’\ is false C  2 k 3. Finally, we choose C=2k and F R m 2 k – m  0 < m < k   Fi g ure 8.    Avera g e g rou p size 


the largest Qi. This sub-matrix is composed of the corresponding rows with the 1 on the columns of Qi Then, continuing division from remaining sub-matrix Similarly, in the left sub-matrix, all Qi is calculated according to the largest Qi, until all the rows and columns are covered 1420 3 If there exists across the rows on a division, the columns of these rows with 1 form a new sub-matrix If there is more than the largest Qi, the Qi selected is one of Qi from top to bottom. The method is selecting the rows that at least one of their columns includes ones in the row of the largest Qi When divided into sub-matrixes, it is important that the union set of rows and columns in all sub-matrixes shall include rows and columns in the original matrix Note: the itemset of sub-matrixes after intersection operation must be empty. Otherwise, the intersection of the rows is divided into a new sub-matrix The following is an example of division of matrix. The initial matrix is as shown in table 2. Three sub-matrixes after the division are as shown in table 3, 4 and 5. Table 5 is the new sub-matrix composed by the intersection of the rows TABLE II.  INITIAL MATRIX I1 I2 I3 I4 I5 I6 1 1 1    3 1 1 1 3 1 1     2 1 1  2 1   1 2 2 2 2 2 2 2 TABLE III.  SUB- MATRIX 1 I1 I2 I3 1 1 1 3 1 1  2 1 1 2 2 2 TABLE IV.  SUB-MATRIX2 TABLE V.  SUB-MATRIX3  


        Step 6: Using elimination method in step 3 to the submatrixes and Qi queue  by decreasing order until no new sub-matrix can be divided out Step 7: Selecting the combination of rows in the submatrixes According to the minimum support threshold and rows and columns selected in advance in step 3, the number of row which Qi is more than minimum support threshold will be selected out. Selected rows will be combined. The number of possible combinations is r nC : n is the number of rows selected; r is the minimum support threshold Because there are rows or columns selected in advance in step 3, it is necessary to take into account this factor There are four cases discussed The case 1: there is no selected rows and columns in advance Because no selected rows and columns in advance, this case can be dealt with according to normal conditions The case 2: there is rows selected in advance Because there are the rows selected in advance, the number of rows to be selected can be reduced. The number of possible combinations is r t n tC  t is the number of rows selected in advance. In this way, computation can be reduced to improve the algorithm efficiency The case 3: there is columns selected in advance Because there are the columns selected in advance these columns become the part of the maximal frequent itemset. These columns do not change the method. In the 


end, these columns are only added to maximal frequent itemset selected The case 4: there are selected rows and columns in advance The case 4 is the combination of the case 2 and the case 3 According to the case 2, we can use the way to reduce the number of rows. By the case 3, we can use the way to add the columns selected in advance to the maximal frequent itemset, together with the composition of maximal frequent itemset Step 8: Searching for maximal frequent itemset. In accordance with the selected combination of rows, all of one-itemset supports Pi are computed out. The maximal frequent itemset is composed of itemset which the oneitemset supports Pi equals to minimum support threshold The number of the items in the itemset is the maximal frequent itemset length I4 I5 I6 1 1 1 3 1 1  2 1 1 2 2 2 I3 I6 1  1 1 1 1 1 2 2 2 1421 4 B.an example To explain the use of the above algorithm, the following will illustrate an example Transaction database D is as shown in table 6. Let minimum support threshold be min_s = 2 TABLE VI.  TRANSACTION DATABASE D       


     Step 1: Setting up an associated matrix. It is as shown in table 7 TABLE VII.  ASSOCIATED MATRIX             Step 2: Calculating the one-itemset support Pi and one-transaction frequent itemset Qj. All Pi are \(6,7,6,1,2 All Qj are  \(3,1,2,3,2,2,2,4,3 Step 3: Using elimination method to remove the rows and columns of the associated matrix according to certain conditions. Here are items for the I4 column and transaction for T800 row to be eliminated. The I4 column is eliminated by the first condition. The T800 row is eliminated by the forth condition. All Pi are \(5,6,5,1 Qj are \(3,1,2,2,2,2,2,3 is as shown in table 8 TABLE VIII.  COMPRESSED ASSOCIATION MATRIX TID I1 I2 I3 I5 T100 1 1  1 3 T200  1   1 T300  1 1  2 T400 1 1   2 T500 1  1  2 T600  1 1  2 T700 1  1  2 T900 1 1 1  3 5 6 5 1 


Step 4: Qi queue Step 5: Divided into sub-matrix. According to the first row, the matrix can divided into the two sub-matrixes They are as shown in table 9 and 10 TABLE IX.  FIRST SUB-MATRIX            TABLE X.  SECOND SUB-MATRIX         Step 6: Using elimination method to the sub-matrixes and Qi queue by descending order From table 8, T100 row may be eliminated by forth condition. It is as shown in table 11 TABLE XI.   FIRST SUB-MATRIX           As the two rows have been elected, and to meet the minimum support threshold, and therefore, Table 8 Sub 


Matrix task has been finished From table 10, T900 row may be eliminated by forth condition. It is as shown in table 12 TABLE XII.  SECOND SUB-MATRIX        TID Commodity ID T100 I1,I2,I5 T200 I2 T300 I2,I3 T400 I1,I2,I4 T500 I1,I3 T600 I2,I3 T700 I1,I3 T800 I1,I2,I3,I5 T900 I1,I2,I3 TID I1 I2 I3 I4 I5 T100 1 1   1 T200  1 T300  1 1 T400 1 1  1 T500 1  1 T600  1 1 T700 1  1 T800 1 1 1  1 T900 1 1 1 6 7 6 1 2 TID I1 I2 I5 T100 1 1 1 3 T200  1  1 T300  1  1 T400 1 1  2 T500 1   1 T600  1  1 T700 1   1 T900 1 1  2 5 6 1 


TID I1 I2 I3 T300  1 1 2 T500 1  1 2 T600  1 1 2 T700 1  1 2 T900 1 1 1 3 3 3 5 TID I1 I2 I5 T200  1  1 T300  1  1 T400 1 1  2 T500 1   1 T600  1  1 T700 1   1 T900 1 1  2 4 5 0 TID I1 I2 I3 T300  1 1 2 T500 1  1 2 T600  1 1 2 T700 1  1 2 2 2 4 1422 5 As the two rows have been elected, and to meet the minimum support threshold, and therefore, Table 9 SubMatrix task has been finished Step 7: Selecting the combination of rows Two rows of T100 and T800 make up new sub-matrix to search for maximal frequent itemset. It is as shown in table 13 TABLE XIII.  THE COMBINATION OF T100 AND T800 Two rows of T800 and T900 make up new sub-matrix to search for maximal frequent itemset. It is as shown in table 14 TABLE XIV.  THE COMBINATION OF T800 AND T900      Step 8: Searching for maximal frequent itemset 


The first maximal frequent itemset is \(I1,I2,I5 Table 12 The second maximal frequent itemset is \(I1,I2,I3 Table 14 IV. ALGORITHM PERFORMANCE COMPARISON All the experiments are performed on a AMD Athlon 64*2 Dual core processor 3800+ PC machine with 1G main memory, running on Microsoft Windows XP. All the programs are written in Microsoft Visual C++6.0 Experimental data is generated randomly by programming. And the number of items is 39 Experiment result shows that the efficiency of the counting algorithm is higher in comparison with Apriori algorithm and FP-tree algorithm. It is as shown in Figure 1               Figure 1.  Relationship of the support threshold with time consumption V. CONCLUSION The core of association mining is mining frequent itemset. Directly searching for maximal frequent itemset can increase efficiency of association mining algorithm This paper presents a new mining algorithm looking for Maximal Frequent Itemset. The algorithm with simply counting the value of rows and columns on associated matrix can find out the maximal frequent itemset and greatly simplifies the complexity of association mining algorithm. Analysis and experiments show that this algorithm has obvious advantages ACKNOWLEDGEMENTS 


The paper is supported by the Special Funds for Key Program of the China No. 2009ZX01039-002-001-04 2009ZX03001-016, 2009ZX03004-005  REFERENCES 1] R Agrawal. Mining Association Rules Between Sets of Items in Large Databases[ C] .Washington :Proceedings of the ACM SIGMOD International Conference Management of Data,1993 :207- 216 2] Agrawal R, Srikant R. Fast algorithms for mining association rules in large databases [A].Proc. of the 20th Intl Conf on Very Large Data Bases [C]. Santiago: Morgan Kaufmann, 1994:478~499 3] J. Han, M. Kambr. Data Mining Concepts and Techniques M] .Morgan Kaufmann Publishers, 2000 4] Y.Yan, Z.Lee, H.Chen. A Mining Maximal Frequent Itemsets in Depth-First algorithm [J]. Computer Research and Development, 2005, 42\(3 5] Z.Wu, W.Lee, P.He. Based on the matrix of maximal frequent pattern mining and its update algorithm [J Microelectronics and computer, 2007, 24\(12 6] Z.Xu,S. Zhang. Mining Association Rules in an optimized Apriori algorithm [J] Computer Engineering.2003 29\(19 7] G. Grahne, J.Zhu, Efficiently using prefix-trees in mining frequent itemsets. In Proc. ICDM03 Int. Workshop on Frequent Itemsets Mining Implementations \(FIMI03 Melbourne, FL, Nov. 2003     I1 I2 I3 I5 T100 1 1  1 T800 1 1 1 1 2 2 1 2 I1 I2 I3 I5 T800 1 1 1 1 T900 1 1 1 2 2 2 1 0 0.5 


1 1.5 2 2.5 3 3.5 4 0.15 0.16 0.17 Support threshold Runtime\(Seconds Apriori FP-tree Counting 


studies," Bioinformatics, vol. 26, pp. 30-37, Jan 1 2010  11] Noah A. Rosenberg, Jonathan K. Pritchard, James L Weber, Howard M. Cann, Kenneth K. Kidd, Lev A Zhivotovsky, Marcus W. Feldman, "Genetic structure of human populations," Science, vol. 298, pp. 2381-5, Dec 20 2002  12] C Ridruechai, S Mahasirimongkol, J Phromjai, H Yanai N Nishida, I Matsushita, J Ohashi, N Yamada, S Moolphate S Summanapan, C Chuchottaworn, W Manosuthi, P Kantipong, S Kanitvittaya, P Sawanpanyalert, N Keicho, S Khusmith and K Tokunaga, "Association analysis of susceptibility candidate region on chromosome 5q31 for tuberculosis," Genes and Immunity, 2010 323 


REFERENCES 1] R. Agrawal, T. Imielinski, and A. Swami, Mining association rules between sets of items in large databases, in SIGMOD 1993 2] C. Alexander, Market Models: A Guide to Financial Data Analysis. John Wiley & Sons, 2001 3] W. Kuo, T.-K. Jensen, A. Butte, L. Ohno-Machado and I. Kohane, Analysis of matched mrna measurements from two different microarray technologies Bioinformatics, vol. 18, p. 405C412, 2002 4] H. Xiong, X. He, C. Ding, Y. Zhang, V. Kumar, and S. Holbrook, Identi?cation of functional modules in protein complexes via hyperclique pattern discovery in PSB, 2005 5] J. Han, H. Cheng, D. Xin, and X. Yan, Frequent pattern mining: Current status and future directions DMKD, vol. 15, no. 1, pp. 5586, 2007 6] P.-N. Tan, M. Steinbach, and V. Kumar, Introduction to Data Mining. Addison-Wesley, 2005 7] S. Brin, R. Motwani, and C. Silverstein, Beyond market basket: generalizing association rules to correlations, in SIGMOD 1997, Tucson, AZ, 1997, pp 265276 8] E. Omiecinski, Alternative interestmeasures formining associations, TKDE, vol. 15, pp. 5769, 2003 9] H. Xiong, S. Shekhar, P.-N. Tan, and V. Kumar Exploiting a support-based upper bound of pearsons correlation coef?cient for ef?ciently identifying strongly correlated pairs, in KDD 2004, 2004, pp 334343 10] I. Ilyas, V. Markl, P. Haas, P. Brown, and A. Aboulnaga, Cords: Automatic discovery of correlations and soft functional dependencies, in SIGMOD 2004 2004, pp. 647658 11] J. Zhang and J. Feigenbaum, Finding highly correlated pairs ef?ciently with powerful pruning, in CIKM 2006, 2006, pp. 152161 12] H. Xiong, W. Zhou, M. Brodie, and S. Ma, Top-k correlation computation, JOC, vol. 20, no. 4, pp 539552, 2008 13] S. Zhu, J. Wu, and G. Xia, Top-k cosine similarity interesting pairs search, in 


http://datamining.buaa.edu.cn/TopKCos.pdf 14] M. Zaki, Scalable algorithms for association mining, TKDE, vol. 12, pp. 372390, 2000 


enhance item-based collaborative filtering, in 2nd IASTED International Conference on Information and Knowledge Sharing, Scottsdale, Arizona, 2003 476 2010 10th International Conference on Intelligent Systems Design and Applications 


Basi Association Rles Basi c  Association R u les Association is basically connecting or tying up occurrences of Association is basically connecting or tying up occurrences of events Ol dib t f ilt t O n l y d escr ib e se t s o f s i mu lt aneous even t s Cannot describe patterns that iterate over time e g  itemset a  0  b  0  g    Eg If you sense higher data rates on the downlink than normal AND New Route generated Implies high chances of Intrusion AND New Route generated Implies high chances of Intrusion Associative IDS for NextGen Frameworks Dr S Dua LA Tech 20 


Enhanced Inte r transaction Association Rules Enhanced Inter transaction Association Rules Enhanced Inter transaction Association Rules Extension of association rules Conditional relationships at multiple different time steps e.g itemset a\(0 0 1 2 You sense Higher data rate than normal AND You see New Route g enerated AND 1 minute a g o you detected checksum gg error packets AND 2 minutes ago your encountered wrong checksum   Implies High Chance of Intrusion Enhanced Rules and Confidence Associative IDS for NextGen Frameworks Dr S Dua LA Tech 21 


Complex Spatio temporal Association Complex Spatio temporal Association Rules Further extension of inter transaction association rules Describe event durations e.g itemset a\(0,X j,Y k,Z Eg  You sense high data rates for X seconds AND new route generated j minutes ago task completed in Y AND new route generated j minutes ago task completed in Y seconds AND checksum error packets received k minutes ago for Z seconds High Chance of Intrusion With highest confidence level in association rules  association rules  Associative IDS for NextGen Frameworks Dr S Dua LA Tech 22 


DMITAR Al ith ARD DMITAR Al gor ith m  ARD Problem Domain Problem Statement and Challenges Aiti Miig bd IDS A ssoc i a ti ve Mi n i n g b ase d IDS  Introduction to data mining Association rule in data mining DMITAR Algorithm  ARD New research Associative IDS for NextGen Frameworks Dr S Dua LA Tech 23 


DMITAR Algorithm DMITAR Difference Matrix Based Inter Transaction Association Rule Miner developed in DMRL Uses vertical data format Differences of the transaction IDs are used to generate extended itemsets Windowless mechanism Associative IDS for NextGen Frameworks Dr S Dua LA Tech 24 


Deep into the Mechanism The DMITAR algorithm is based on lhilii comp l ex mat h emat i ca l assoc i at i ve formulation and proofs Four major parts Four major parts Frequent 1 itemset generation Frequent 2 itemset generation Frequent k itemset generation k>2 Spatio temporal rule formation Associative IDS for NextGen Frameworks Dr S Dua LA Tech 25 


DMITAR, Datasets Used Stock Data Stock Data Daily stock information provided by Yahoo finance Wth Dt W ea th er D a t a Provided by the US Department of Commerce and National Climactic Data Center for 700 locations across US Synthetic Data Provided by a CRU weather generator that uses a Markov chain model to generate simulated weather data for 11 UK sites Associative IDS for NextGen Frameworks Dr S Dua LA Tech 26 


DMITAR Results 1/5 Varying Support DMITAR Results 1/5 Stock Database Support FITI ITPMine PROWL DMITAR 14 6424.7s 132.39s 3.03s 5.556s 16 2348.9s 67.14s 2.14s 4.015s 18 861.92s 34.62s 1.55s 2.89s 20 334.51s 18.89s 1.12s 2.07s 22 143 84s 10 87s 0 87s 1 45s 22 143  84s 10  87s 0  87s 1  45s 24 63.62s 7.15s 0.671s 1.04s Weather Database Support FITI ITPMine PROWL DMITAR 14 36362.6s 893.1094s 5.843s 19.8281s 36362.6s 893.1094s 5.843s 19.8281s 16 11913.04s 378.2188s 3.8906s 13.4375s 18 4116s 170.3438s 2.75s 9.1406s 20 1507s 86.5781s 2.14s 6.203s 22 859.2813s 63.3438s 1.7969s 5.7656s 24 378.5313s 36.1875s 1.4375s 3.5625s Synthetic Dataset Support FITI ITPMine PROWL DMITAR 14 1651.6s 199.843s 3.1406s 17.015s 16 574 32 119 32 2 0938 10 875 16 574  32 s 119  32 s 2  0938 s 10  875 s 18 416.109s 95.31s 1.6094s 7.39s 20 370.25s 83.31s 1.453s 5.8438s 22 265.78s 66.3438s 1.3594s 4.75s 24 133.96s 43.0781s 0.9219s 3.5781s 


DMITAR Rlt  DMITAR  R esu lt s 2  5 Rules Formed Associative IDS for NextGen Frameworks Dr S Dua LA Tech 28 


DMITAR Rl  Varying Maxspan DMITAR  R esu l ts 3  5 Varying Maxspan Associative IDS for NextGen Frameworks Dr S Dua LA Tech 29 


DMITAR Res lts 4/5 Vig Di i DMITAR  Res u lts  4/5 V ary i n g Di mens i ons Associative IDS for NextGen Frameworks Dr S Dua LA Tech 30 


DMITAR Rl  Varying Number of Transactions DMITAR  R esu l ts 5  5 Varying Number of Transactions Associative IDS for NextGen Frameworks Dr S Dua LA Tech 31 


N/C t Rh N ew C urren t R esearc h Problem Domain Problem Statement and Challenges Associative Mining based IDS Associative Mining based IDS Introduction to data mining ii lid ii Assoc i at i on ru l e i n d ata m i n i ng DMITAR Algorithm  ARD h New Researc h Associative IDS for NextGen Frameworks Dr S Dua LA Tech 32 


Further Research Further Research Objectives of Our Intrusion Detection System Development Objectives of Our Intrusion Detection System Development 1 Refine and scale the DMITAR algorithm to suit our application 2 Develop methods for dynamically altering the sensor parameters Our Focus is Securing the NextGen Frameworks with New Technology Technology Associative IDS for NextGen Frameworks Dr S Dua LA Tech 33 


Simulated Sensing Environment Simulated Sensing Environment Screenshots of Data C ollected from S ynthetic Sensors Screenshots of Data C ollected from S ynthetic Sensors Simulated in Our Laboratory Three Steps Slides Collect data Collect data from all sources  all attributes  Select Select the source and their hierarchical attributes attributes to be monitored and Select Select the source and their hierarchical attributes attributes to be monitored  and Sample Sample them at different rates different rates and process them Associative IDS for NextGen Frameworks Dr S Dua LA Tech 34 


Data Collection Simultaneous collection of data screen from ENTITIES aircrafts Associative IDS for NextGen Frameworks Dr S Dua LA Tech 35 Source PRTG Network Monitor software screen shot Demo info www.paessler.com 


Parameter Selection Selection of an ENTITY/aircraft and monitoring its parameters and sensor readings Associative IDS for NextGen Frameworks Dr S Dua LA Tech 36 Source PRTG Network Monitor software screen shot Demo info www.paessler.com 


Sensor Sampling Selecting one sensor/probe and reading it at different resolutions or sampling rates Associative IDS for NextGen Frameworks Dr S Dua LA Tech 37 Source PRTG Network Monitor software screen shot Demo info www.paessler.com 


Si l ti Nt k Si mu l a ti on on N e t wor k Most scenarios can be simulated on a computer or computer network network  The aircrafts and sensors are simulated on a computer network bllb b y ana l ogica l su b stitutions Sensors provide information at different rates Sensors provide information at different rates Need Based Sensor Prioritization NSP and Dynamic Sensing Rate Sampling Associative IDS for NextGen Frameworks Dr S Dua LA Tech 38 


Vulnerability Search Scan 39 Sample UQA script with Nmap performed in DMRL Associative IDS for NextGen Frameworks Dr S Dua LA Tech 39 Source Nmap screenshot with a pearl script  Find Namp on Nmap.org 


Modality Aspect Modality Aspect A Multimodal distribution is a continuous probability distribution with two or more modes of underlying data Mltil d i M u lti p l e mo d es i n our model Associative IDS for NextGen Frameworks Dr S Dua LA Tech 40 Source http://en.wikipedia.org/wiki/File:Bimodal bivariate small.png 


Multi Modality Modality Fusion 41 SENSITIVE  UNCLASSIFIED For Official Use Only Associative IDS for NextGen Frameworks Dr S Dua LA Tech 41 


Emphasis Emphasis Our approach emphasizes on pre empting the attack Our intent is NOT to perform an autopsy to discover attacks Instead we aim to detect and prevent in attacks in real time Associative IDS for NextGen Frameworks Dr S Dua LA Tech 42 


Techniques for Discriminative Rules Techniques for Discriminative Rules Resolution Analysis Features Analyzed at Different Depths Anti Monotonic Principle Modality Aspect Treading into Unexplored Feature spaces Associative IDS for NextGen Frameworks Dr S Dua LA Tech 43 


Representative Outcomes Representative Outcomes Illustration of the Final Analysis Our method shifts between modalities and sampling rates for optimization The blue parallelograms are actual intrusions 44 The blue parallelograms are actual intrusions The Red Green Blue Plots are response of system Associative IDS for NextGen Frameworks Dr S Dua LA Tech 44 


Advantages of Our M ethod Advantages of Our M ethod Exploit the memory v ertical data format utilizes slidin g windows to g form a much larger database to analyze  Flexibility in Choosing what to choose  Choosing what to choose to build the rules Computational and memory efficiency We have a team working only on this aspect 45 Associative IDS for NextGen Frameworks Dr S Dua LA Tech 45 


Preliminary Results Intra transaction Relations Data rate simulator NH-134 Mb HOP PATH update \(Y/N Inference 11.5 Y Y 2 0.120 N N      Y   n 0.345 N NH134 Y/N   Inf 1 0.150 N N 2 0 120 Y N Inter transaction Relations 2 0  120 Y N       5 5.55 0.456 Y Relations  n 0.345 N N Nmap on DMRL nmap.org 


Anticipated Outcome Anticipated Outcome Develop algorithm capable of learning from a given heterogeneous diverse Develop algorithm capable of learning from a given heterogeneous diverse data ff Dynamic algorithmic f ramework designed to shi f t modalities and sampling rates based on complex logic Flexibility of integration into the Snort intrusion detection system 47 Associative IDS for NextGen Frameworks Dr S Dua LA Tech 47 


References References Aircraft Cockpit Image courtesy USAF http://www.faa.gov htt p   www.faa g ov  air traffic  technolo gy  p g  _ gy  Acharya R Dua S Du X Sree V Chua C K Automated Diagnosis of Glaucoma Using Texture and Higher Order Spectra Features To appear in IEEE Transactions on Information Technology in Biomedicine  Du X Dua S 2011 Cancer Prognosis Using Support Vector Regression in Imaging  Modality World Journal of Clinical Oncology 2  1   44 49 Du X Dua S 2010 Salient Frame Extraction Using Support Vector Regression and Motion Features pp 5 Proc of the National Aerospace and Electronics Conference July 14 16 2010 D M P D S 2010 Di i i ti Ft d Cl ifi ti Mthd f D essaue r  M  P  D ua S  2010  Di scr i m i na ti ve F ea t ures an d Cl ass ifi ca ti on M e th o d s f or Accurate Classification 1st ed vol 7704 pp 14 Bellingham WA Proceedings of SPIE Dessauer M P Dua S 2010 Low Resolution Vehicle Tracking using Dense and Reduced Local Gradient Features Maps 1st ed vol 7694 pp 8 Bellingham WA Proceedings of SPIE SPIE 


Acknowledgements Acknowledgements Fundin g A g encies  US 4 1 Million direct fundin g g g 4 g LA BoR NIH NSF AFRL AFOSR and NASA Research Team Samuel Kasimalla Brandy McKnight Dr Pradeep Chowriappa Connor Johnson Vasanth Nair Mihir Chowriappa  Connor Johnson  Vasanth Nair  Mihir Karnik Mohit Jain and Swadheen Songmen Associative IDS for NextGen Frameworks Dr S Dua LA Tech 49 All the respective Logos belong to their owners 


Rf d Rdi R e f erence d R ea di ngs Copyright of cover pages held by respective publishers 


Thank You Questions Thank You  Questions Dr Sumeet Dua E mail sdua@latech.edu Web http://dmrl.latech.edu Associative IDS for NextGen Frameworks Frameworks Dr S Dua LA Tech 51 Image Source roadtrafficsigns.com 


