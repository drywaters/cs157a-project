 Corresponding author Hong Wang NEW ADAPTATIONS OF CLASSIC ALGORITHM FOR MINING FREQUENT ITEMSETS FROM UNCERTAIN DATA Xiaomei Yu Hong Wang Xiangwei Zheng School of Information Science and Engineering Shandong Provincial Key Laboratory for Distributed Computer software Novel Technology Shandong Normal University Jinan Shandong China Email yxm0708@126.com Abstract Mining frequent itemsets from traditional database is an important research topic in data mining and researchers achieved tremendous progress in this field However with the emergence of new applications the traditional way of mining frequent itemsets is not available in uncertain environment In the past ten years researchers proposed different solutions in extending the conventional techniques into uncertainty environment In this paper we review the previous algorithms based on the two definitions of frequent itemsets then we improve the traditional classic algorithm for mining frequent itemsets in uncertain databases under the definition of frequent probability Finally we tested our algorithm on a number of uncertain data sets The experiments on both sythetic and real data have shown that the new adaptation of classic algorithm is efficient and gain better results on accuracy Keywords frequent itemsets mining uncertain database algorithm data mining 1 INTRODUCTION Frequent itemset mining is a popular and important step to analyze data in a broad range of applications In the past twenty years researchers have made tremendous achievements in developing efficient and scalable algorithms for frequent itemsets mining\(FIM in precise and certain databases The three most classic FIM algorithms are Apriori 1 FP-g r o w th 2  a n d Eclat 3 However in many emerging applications real data is typically subject to noise and measurement error thus the existence of an itemset in a transaction is usually captured by probability which poses a number of unique challenges on exploiting efficient algorithms for mining frequent itemsets in uncertain environment In the case of uncertain databases we do not know whether a transaction contains an itemset with certainty in real world so the Possible World Semantics\(PWS is often used to interpret the uncertain databases Each possible world w is associated with a probability of world exists P\(w thus the database generates a set of possible worlds under the PWS where each world is defined by a fixed set of transactions The sum of possible world probabilities is one and the number of possible worlds is exponentially large Based on the possible worlds semantics two different definitions on frequent itemsets are presented in uncertain databases expected support-based frequent itemsets  4  a nd probabilistic frequent itemset[5  6   Mos t pr e v ious s t udi e s ha v e been developed under the two de finitions respec tively  However Y Tong[9 verified th at th e t w o d e f i n itio ns h a ve a r ath e r close connection And in present research of frequent itemsets mining the novel definition of frequent probability is used more widely In this paper we reviewed the present status of frequent itemsets mining in uncertain database communities and propose a new adaptation of classic algorithm to mine frequent itemsets in uncertain databases which combine the merits of both exact and approximate probabilistic frequent itemsets mining algorithms Finally we analyze its performance and test it over well known benchmark data sets The rest of the paper is organized as follows In section 2 we introduce the problem definition in uncertain database Then we review the novel developments in section 3 and present our improvement in section 4 In section 5 the results of experiments are shown and we draw our conclusion in section 6 2 PROBLEM DEFINITIONS In traditional databases most of the previous studies on frequent itemsets mining assume a data model in which each transaction contains complete and doubtless items However in emerging applications an uncertain database is formed with uncertain transactions of extential uncertain items Therefore it is nature for the researchers to introduce a probability to describe the existence 


of an item in a transaction Table.1 which is the attribute uncertainty model usually adopted for the field of frequent itemsets mining in uncertain environment In the attribute uncertainty model each transaction consists of attributes items with values carrying uncertain information As shown in Table 1 this is just the extended version in traditional databases Since the transactions or items are probabilistic in nature it is impossible to count the frequency of itemsets deterministically Chui et.al[10 p r o po s e d t he e x pe c t e d s upp or t o f ite m s e t s i n t he ir U-Apriori algorithm to depict the degree of frequency under uncertian environments Definition 1 expected support-based frequent itemset Given an uncertain transaction database with N transactions the expected support of an itemset X is defined as the sum of expected probabilities of presence of X in each of the transactions in the database With a minimum expected support ratio min_esup an itemset X is an expected support-based frequent itemset if and only if esup\(X N×min_ esup However considering an itemset frequent only by its expected support has a major drawback[1 U n cert a i n t r an sact i o n d at ab ase naturally involve uncertainty on support of an itemset which is important when evaluating a frequent itemset However this information is forfeited when using the expected support approach Therefore the confidence of an itemset is frequent is introduced to interpret uncertain datasets Thus a probabilistic way is defined as the measurement to evaluate the uncertain data Definition 2 Probabilistic Frequent Itemset Given an uncertain transaction database with N transactions a minimum expected support ratio min_sup  and a probabilitic frequent threshold min_prob  An itemset X is considered a probabilistic frequent itemset if its frequent probability is larger than the probabilistic frequent threshold[12  X N  min_sup}>min_prob By experimental study and theoretical analysis Yongxin Tong[9 p r e s e nts t ha t t he r e is s o m e r e la tion s hip s be tw ee n t he tw o definitions on frequent itemsets Therefore some researchers have proposed that the more efficient algorithms can be gained to mine probabilistic frequent itemsets by employing appropriate expected support-based frequent itemset mining algorithms Provided that the variances of support of each itemset are calculated as well as expected support on each itemset the expected support-based FIM algorithms can be used to mine probabilistic frequent itemsets as well Table 1 Attribute Uncertain Data Sets TID Transaction itemset T1 A\(0.6 B\(0.5 C\(0.3 D\(0.5 T2 A\(0.7 D\(0.8 E\(0.25 T3 A\(0.3 C\(0.8 D\(0.4 T4 C\(0.7 D\(0.3 E\(0.2 T5 A\(0.5 C\(0.7 E\(0.3  3 FIM ALGORITHMS IN UNCERTAIN DATABASES 3.1 Extension of Classic Algorithms into Uncertain Case Consider three classic frequent itemsets mining algorithms Apriori FP-growth and H-mine and their adaptions Although Aproir a l g o rithm i s s low e r t ha n t h e oth e r t wo a l g o rithm s in deterministic databases with the well-known downward closure property UApriori[10 a lg orith m p e r f o rm s v e r y w e l l a m ong the three algorithms and is usually the fastest one in dense uncertain databases with high min_esup  However FP-growth algorithm[14 does not show similar efficient behavior in the uncertain cases There are some possible reasons Firstly the probabilities of items in uncertain database make the database sparse due to fewer shared nodes and paths Secondly in the uncertain cases the compression of UFP-tree[10 i s s u b s t a nt i a l l y red u ced b ecau se i t i s h a rd t o t a ke the advantage of shared prefix path in FP-tree Therefore as the support threshold goes down the UFP-trees constructed become large and too many candidate itemsets generated which leads to sharp increase of memory usage So the FP-tree structure does not extend well in the sparse uncertain databases Based on the divide-and-conquer framework and the depth-first search strategy UH-mine[15 is qu ite s u ita bl e f or s p a r s e uncertain databases As an extension from classical algorithm in deterministic case UH-mine algorithm fails to compress the data structure and use the dynamic frequency order sub-structure so it is faster in building head tables of all levels than building all conditional subtrees Therefore UH-mine always outperforms other algorithms in uncertain sparse databases with low min_sup 3.2 Exact FIM Algorithms in Uncertain Databases Based on the connections of the two definitions on frequent itemsets over uncertain databases most of existing algorithms can be divided into two categories the exact frequent itemsets mining algorithms and the probabilistic frequent itemsets mining algorithms Besides the three most representative exact expected support-based frequent itemset mining algorithms reviewed in subsection 3.1 there are other tw o exact probabilistic frequent algorithms 


Since the support of an itemset is a random variable following the Poisson Binomial distribution 16 de sig n e d a d y n a m ic programming-based algorithm DP to compute frequent probability With the recursive rel ationship frequent probability is deduced as one subtracts the probability computed from the corresponding cumulative distribution function of the support So the time complexity of DP for each itemset is reduced to O N 2 min_esup  Another divide-and-conquer algorithm was also presented in 11 t o c a l c u la te f r e que nt pro b a b ility e x a c tly  U nli k e DP algorithm DC algorithm calls itself recursively to divide an uncertain database until only one transaction left then it records the probability distribution of support of the itemset in transaction At last DC algorithm obtains the probability distribution in conquer part 3.3 Approximate FIM Algorithms in Uncertain Databases There are two kinds of approximate frequent itemsets mining algorithms in uncertain databases the expected support-based frequent algorithms and probabilistic frequent algorithms In reality there are three probabilistic frequent algorithms that are more important in uncertain databases Taking into account that the support of an itemset can be regarded as a random variable following Poisson Binomial distribution the probabilistic frequent algorithms are designed based on the Poisson distribution or Normal distribution respectively when uncertain databases are large enough In Poisson-distribution-based UApriori algorithm[17 th e frequent probability of an itemset is rewritten by the cumulative distribution function CDF of the Poisson distribution in which parameter is the expectation and variance of random variable Following the monotonic of CDF with respect to  PDUApriori computes the corresponding of the given min_prob and calls UApriori to find the results According to the Lyapunov Central Limity the Normal distribution-based approximate probabilistic frequent itemset mining algorithm NDUApriori[18 rewrites t h e f r e q u e n t probability of itemset with standard Normal distribution Then NDUApriori algorithm employs the Apriori framework and uses the cumulative distribution function of standard Normal distribution to calculate the frequent probability Different from PDUApriori NDUApriori algorithm returns frequent probabilities of all probabilistic frequent itemsets However it is impractical to apply NDUApriori on very large sparse uncertain databases since it employs the Apriori framework Summarizing the achievement and the shortage of the previous research Yongxin Tong in 9 i n t egr a t e s t h e f r a m ewo r k o f UH-Mine and the Normal distribution approximation and proposes NDUH-Mine algorithm which achieves a win-win partnership in sparse uncertain databases In particular by comparison of algorithm framework and approximation methods some important conclusions are also drawn in this paper NDUApriori is the fastest algorithm in large enough dense uncertain database while NDUH-Mine requires reasonable memory space and scales well in very large sparse uncertain databases The Normal distribution-based approximation algorithms build a bridge between the expected support-based frequent itemsets and the probabilistic frequent itemsets Approximate probabilistic frequent itemset mining algorithms usually outperforms any existing exact probabilistic frequent itemset mining algorithms in the algorithm efficiency and the memory cost 4 THE NEW ADAPTION OF CLASSIC FIM ALGORITHM Summarizing the achievement and the shortage of the previous research approximate probabilistic frequent algorithms is considered as one of promising approaches that is proved to have the same efficiency as expected support-based algorithms It guarantees to return frequent probabilities of all probabilistic frequent itemsets with high confidence as long as the databases underlying is large enough However there is something worthy of further consideration 4.1 A data-related issue Nowadays a lot of algorithms and techniques are proposed for finding itemsets from transactional databases in which some are more efficient for dense datasets while others are more suitable for sparse datasets So there is no single algorithm that is the most efficient for both sparse datasets and dense ones[1 W h i l e i n uncertain cases the databases are often considered as the sparse ones i.e only a small number of items have a nonzero probability of appearing in a given transaction in uncertain databases Definition 3 A database is dense if the frequent items in it have high relative support A database is sparnse if the frequent items in it have low relative support The relative support can be computed as the ratio of absolute support against number of transactions\(or frequent-item projections in the database[1  In general when the relative support of frequent items is equal 


to or higher than 10 the database is regarded as dense On the other hand when the relative support of frequent items is low such as far below 1 it is sparse However if the relative support is between the value of 10 and 1 the result will depend on the size of the practical database In the case of sparse uncertain databases with a low min_sup given although a large amount of frequent items are generated at the first scan of the database the number of k-frequent itemsets found in the following steps may drop dramatically after several recursive operations Furthermore once a little large min_sup is given the trend of declining in the number of frequent items will reduce more sharply which means that it may be impossible to produce a large enough candidate frequent dataset to find k+1 frequent itemsets with approximate frequent itemsets mining algorithms according to Central Limit Theorem Shown in Fig.1 7   Even in the case of dense uncertain databases the same problem maybe occurs For example in a dense database following Zipf distirbution which is generally used to describe the online sales on the Internet although large enough frequent items are produced at the very beginning there will be a much small size of frequent itemsets generated for the following mining of k+1 frequent itemsets In this case the condition of Lyapunov Central Limit Theory no longer holds and those approximate probabilistic frequent algorithms would have difficulty to accomplish the effective mining Figure 1 Varying Support  Frequent Probability[7 Therefore considering the whole process of frequent itemsets mining we propose an adaptive solution of mining frequent itemsets from uncertain databases which is divided into the approximate mining phase and the exact mining phase 4.2 An Adaption of Classic FIM Algorithm There are three steps in the new algorithm Firstly based on the definition of probabilistic frequent itemsets we calculate the frequentness probability in a systematic manner thanks to its anti-monotonic property With a large enough uncertain database UDB is given it is sensible for us to choose a kind of approximate probabilistic frequent itemsets mining algorithms which avoids the operations of expanding the database into the exponential number of possible worlds In other words under the definition of mining probabilistic frequent itemsets NDUApriori algorithm is applied in large enough dense uncertain databases while NDUH-Mine algorithm is prefer in large enough sparse uncertain databases We calculate the variance of each itemset when obtain the expected support of each itemset then the frequent probability is gained by the standard normal distribution formula  min_ sup 0.5 sup\(X Pr\(X    X  Ne Var  In this way we calculate the frequent itemsets such as 2-frequent itemsets and 3-frequent itemsets In the second step we weigh the number of frequent itemsets based on the conditions of the special form of the Central Limit Theorem as well as the memory usage and switch to exact probabilistic frequent algorithm adaptively if necessary Otherwise we continue the approximate probabilistic frequent algorithms and test again after every two rounds of mining until the frequent itemsets database is not large enough to satisfy the Central Limit Theorem At last since the approximate probabilistic frequent algorithms is not suitable in the following process we prefer the dynamic programming algorithm to mine remaining k+1\-frequent itemsets in the following process That is we produce the exact frequent probability recursively with the formula below   1          1  1  1  j j i j j i j i T X Pr X Pr T X Pr X Pr X Pr Where Pr 0 j=1 0 j T Pr i,j=1 i>j Furthermore some pruning strategies such as Chernoff bound-based pruning and anti-monotonic property are introduced to reduce the running time In the next section we design some experiments to show the performance of the adaptive algorithm in large uncertain data which confirms our goal 5 EXPERIMENTS In this section we introduce the results of preliminary 


experiments conducted The experiments run on a PC with a 2.5 GHz Intel\(R core\(TM i5-2520M processor and 4 Gbytes of RAM The operating system was Window 7 All algorithms were implemented and compiled using Microsoft’s Visual C 2010 5.1 Results on Experimental Databases Experimental data sets comes from the well-known Frequent Item set Mining Data Set Repositiory[19  A m ong the c a s e s th a t data sets follow the Gaussian distribution we conduct our experiments in dense uncertain databases as well as sparse ones In the dense dataset with high mean and low variance namely Connect with the mean 0.95 and the variance 0.05 we run our adaptive algorithm with NDUAprior i algorithm switching to DP algorithm While in the sparse dataset with high mean and low variance namely Gazelle with the mean 0.95 and the variance 0.05 we run our hybrid algorithm with NDUH-Mine algorithm switching to DP algorithm The preliminary results show that our hybrid algorithm is efficient Shown in Fig.2 and more accuracy Shown in Table.1 Figure 2 Results in Dataset of Connect 5.2 Results on Historical Prescriptions Database In the TCM research commercial software such as SPSS Clementine is prevailing for data mining in which the classic Apriori algorithm is used As a comparison we ran our new algorithm on PC with the same environment shown above Meanwhile the same different min_sup values are selected in the two algorithms according to the experience on the syndrome and clinical diagnosis Table 2 Accuracy in Dataset of Gazelle Min_sup NDUH-Mine New Adaption 0.001 0.89 0.93 0.003 0.91 0.95 0.005 0.95 0.97 0.01 0.96 0.98 0.03 0.98 1  Without any doubt the adaptation of classic algorithm wins with overwhelming advantages in the performance of running time and accuracy In shorter time it successfully analyzed 13868 prescriptions the frequency of each herb and association rules among the herbs were computed core combinations and new prescriptions were mined out of the database Taking into account potential error and loss in the historical prescriptions it is difficult for existing traditional data tools such as SPSS Clementine to find all the really existed combination principles and core combinations of herds in prescriptions because of their limitations on component organization In order to make a remedy on this defect we introduced different weights on the potential frequent items in the transaction database which may be lost due to unknown reasons The weights determined by frequent itemsets mined and the experience gained in clinical diagnosis By relaxing the support definition we use the new algorithm for a probabilistic item set mining in incomplete transaction database of prescriptions The adaptation of classic algorithm demonstrated its efficiency and effectiveness in the application of prescriptions analysis of TCM 6 CONCLUSIONS AND FUTURE STUDY Mining frequent item sets is an important problem in data mining and is also the first step of deriving association rules Hence many efficient frequent itemsets mining algorithms have been proposed These algorithms work well for databases with precise values but may not be effici ent in mining probabilistic data In this paper we compared the present algorithms for extracting frequent itemsets from uncertain databases And then we proposed an adaptation of classic algorithms which mines approximate frequent itemsets when the database is large enough while exerts an exact mining process adaptively as the candidate itemsets under consideration are not large enough Although our algorithm is developed on the traditional framework they can be suitable for supporting other improved algorithms for handing uncertain data In the futures we will do more efforts on the research of mining frequent itemsets in uncertain databases With further experiments we will explore the characters of specific uncertain 


databases such as Chinese medicine prescriptions database and improve frequent itemset mining in imperfect database thus utilize and develop the previous studies into emerging applications ACKNOWLEDGEMENT We are grateful for the support of the Natural Science Foundation of China 61373149 and the Shandong Provincial Project for Science and Technology Development 2012GGB01058 REFERENCES 1 R  A g r a w a l  R  S rik a nt  Fa st Alg o rith m s f o r M inin g Association Rules Proceedings 20th International Conference on Very Large Data Bases pp 487–499 September 12-15 1994 2 J  H an  J  P ei  Y  Y in  M i ni ng F r eq uen t Pat t e r n s w i t h ou t Candidate Generation Proceedings of ACM SIGMOD International Conference on Management of Data ACM Press pp 1–12 2000  M  J  Z a k i  S c a l a b le Alg o rith m s f o r A ssoc i a tion M inin g   IEEE Transactions on Knowledge and Data Engineering vol 3 pp 372–390 2000 4 C hun K it C hui  B e n K a o Edw a r d H u n g   Mini ng Fr e q u e nt Itemsets from Uncertain Data PAKDD 2007 LNAI 4426 pp 47-58 2007 5 C h a ru C Ag g a rwal Y a n L i   Freq u e n t Pattern Min i n g with Uncertain Data KDD’09 Paris France pp 29-37 June 28–July 1 2009 6 L  W ang R Ch en g S  D L e e et al   Acce l e rat i n g Probabilistic Frequent Itemset Mining a Model-based Approach In CIKM’10 Toronto Ontario Canada pp 429–438 2010 7 T h o m as Bern ecker  R eyn o l d C h e n g  D avi d W  Ch eun g  Model-based probabilistic frequent itemset mining In Knowl Inf Syst  Vol 37 pp 181-217 2013 8 Y  T ong L C h en  Y  C h e n g  a n d P  S  Y u   M i ni ng F r eq u e nt Itemsets over Uncertain Databases VLDB’12 Istanbul Turkey Vol 5 No 11 pp 1650-1661 August 27th 2012 9 L aila A  A bdE l m e g i d  V e r t i c a l Mini ng of Fr e q u e nt Pa tte r n s from Uncertain Data Computer and Information Science Vol 3 No 2 pp 171-179 May 2010 10 Ca rson Ka i-Sa ng L e ung  L ijing S u n   Equ i v a le nc e C la ss Transformation Based Mining of Frequent Itemsets from Uncertain Data SAC’11 Taichung Taiwan pp 983-984 March 21-25 2011 1 T oon Cal d ers Cal i n Garb o n i  an d B art G o e t h al s E f f i ci en t Pattern Mining of Uncertain Data with Sampling PAKDD 1 pp 480-487 2010 1 M  S o ng S  R a j a sek a r a n   A T r ansact i o n M ap pi n g Algorithm for Frequent Itemsets Mining IEEE Transactions on Knowledge and Data Engineering  Vol 18 No 4 pp 472-481 April 2006 1 T h o m as Bern ecke r  H an s-p e t e r K ri egel  M at t h i a s R en z et al Probabilistic Frequent Itemset Mining in Uncertain Databases KDD’09 Paris France June 28-July 1 2009 1 Y ongxi n T ong L e i C h en  P h i li p S  Y u UF I M T  A n Uncertain Frequent Itemset Mining Toolbox  KDD’12 Beijing China pp 1508-1511 August 12–16 2012 1 Y  T ong L C h en  Y  C h e n g  a n d P  S  Y u   M i n i n g F r eq u e nt Itemsets over Uncertain Databases Proceedings of the VLDB Endowment Istanbul Turkey Vol 5 No 11 pp 1650-1661 August 27 th 31 st 2012 1 Ji an P e i  Ji awei Han  Ho ngj u n L u  e t a l  H-M i n e Hyper-Structure Mining of Frequent Patters in Large Databases  Proceedings IEEE International Conference on Data Mining ICDM 2001 San Jose CA pp 441  448 Nov 29-Dec 2 2001 1 L  W a ng R Ch eng S  D L e e et  a l  Acce l e rat i n g probabilistic frequent itemset mining a model-based approach  In CIKM’10 Toronto Ontario Canada pp.429–438 2010 1 T oon C a l d er s Calin Garbini Bart Goethals Approximation of Frequ entness Probability of Itemsets in Uncertain Data  in ICDM pp.749-754 2010 19 ht tp f im i.ua a c  be  20 1 3   


