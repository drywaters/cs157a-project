978-1-4799-2981-8/14/$31.00 ©2014 IEEE  72 Using Parallel Approach in Pre-processing to Improve Frequent Pattern Growth Algorithm Sheetal Rathi      Dr. Chandrashekhar.A.Dhote SGBAU,Amravati      PRMITR,Badnera Maharashtra       Maharashtra India        India shitalvrathi@rediffmail.com    vikasdhote@rediffmail.com    Abstract   Mining frequent itemset is an important step in association rule mining process .In this paper we are applying a parallel approach in the pre-processing step itself to make the dataset favorable for mining frequent itemsets and hence improve the speed and computation power. Due to data explosion, it is necessary to develop a system that can handle scalable data. Many efficient sequential and parallel algorithms were proposed in the recent years. We first explore some major algorithms proposed for mining frequent itemsets. Sorting the dataset in the pre-processing step parallely and pruning the infrequent itemsets improves the efficiency of our algorithm. Due to the drastic improvement in computer architectures and computer performance over the years, high performance computing is gaining importance and we are using one such technique in our implementation: CUDA  Keywords Association rules; FP-gro wth; parallel computing CUDA  I  I NTRODUCTION   The growing impact of data is gaining importance in data mining and knowledge discovery Given the large database sizes, one of the main challenges in database mining is developing fast and efficient algorithms that can handle large volumes of data. Mining for association rules involves extracting patterns from large databases and inferring useful rules from them.  It helps to find the relationship between the itemset in a large database  Enormous amount of data means large amount of computation power in processing the data and a big chunk of memory requirement. Several algorithms have been proposed to mine these frequent itemsets. Also several refinements have been done on these algorithms to increase their efficiency. Two such fundamental and important algorithms are Apriori [1  proposed by R. Agarwal et.al and FP- growth g o ri t h m  proposed by Han et.al. But none of the algorithms can be said to be superior over the other. The dataset to be mined and an appropriate support threshold to be used determine which algorithm performs best. There is still scope for improvisation in the above algorithms in terms of time and computation complexity. Also being a flat tree like structure, the basic FP growth algorithm fails when it comes to storage space but surpasses Apriori in terms of number of database scans. In this paper, we propose a highly parallel version of FP –Growth which can be implemented on scalable data  We are trying to sort the dataset in ascending order parallely and eliminate all frequent itemset which are less than the minimum support threshold. Thus we are making the dataset more favorable for the mining process II  P RE REQUISITES  2.1   F P G ROWTH  A LGORITHM  A  Problem Description  The formal statement of frequent mining is as follows [2   Let I  i 1 i 2 i n  be a set of literals, called items and n is considered the dimensionality of the problem. Let D be a set of transactions, where each transaction T is a set of items such that T 002  I An itemset X is said to be frequent if its support is greater than or equal to a given minimum support threshold The association rule mining is a two-step process 1\ Find all frequent itemset having minimum support 2\ Generate strong rules having minimum confidence, from the frequent itemset  B  FP-Growth  The pseudo code proposed by Han et. al o r mining FP-tree is depicted in Fig 1 FP-Growth uses a pattern fragment growth method to generate frequent itemsets. It requires only two scans. The first is to collect the support of each item sorted in descending order of frequency. The original database is converted into a compressed tree structure, the FP-tree in the second scan Once a FP-tree is constructed, th e FP-tree is decomposed into a group of independent conditional pattern bases of the frequent items. FP-Growth needs to build conditional FP-tree according to each conditional pattern base. Henceforth, the mining process is conducted on independent processes constructing and mining conditional FP-tree recursively 


2014 International Conference on Information Systems and Computer Networks  73                     Figure 1. Pseudo code of FP-Growth algorithm from [2   2.2  CUDA There has been a drastic improvement in computer applications, computer architectures and computer performance over the past 60 years. Simultaneously, the complexity of the applications harnessing computing power has also increased. CUDA is a parallel programming environment created by NVIDIA which exploits the NVIDIA GPUs for parallel computing. The NVIDIA GPU contains hundreds of ALUs which can be used to individually do operations. It follows the SIMD \(Single Instruction Multiple Data\itecture which allows the individual ALUs to perform the same operation over different data thus introducing parallelism into the system. The CUDA GPU cores have a separate memory bank from the main CPU with a very high bus speed. This helps improve parallelism. The CUDA model differentiates between the processing done on the GPU and the one done on CPU by making different functions for each. The CPU and its memory is known as the Host whereas the GPU and its memory is known as the Device. Calls can be made from the Host to the Device and from the Device to itself by using functions defined as global and device respectively. The CUDA enabled GPUs offer a teraflop of computing power for a very low cost h u s  CUDA programming is heavily used in HPC \(High Performance Computing\ tasks  III  R EVIEW O F IMPROVED FREQUENT ITEMSET MINING ALGORITHMS   Finding frequent itemsets is comparatively more time consuming o in o r d e r t o in c r eas e th e ef f i ci en cy of th e system, the first step will be to enhance the functionality at this core level. A large number of increasingly efficient algorithms to mine frequent itemset have been developed over the years 2 5    6  7    8  a n d  9  S i nc e fi nd i ng fr eq ue nt  i t e m s e t s i s  more time consuming , we have concentrated our work in improving the dataset and making it more favorable for the mining process Min Chen et.al pro p o s e d a no ve l pa ra l l e l F P G ro w t h algorithm GFP-Growth, which is designed to run on the computer cluster to avoid memory overflow. Using projection method and splitting the mining task into number of independent sub-tasks, this algorithm works independently at each node. As a result, it can efficiently reduce the inter-node communication cost. In [11  t h e a u t hor s ha ve t r i e d t o  i m p r ove the basic FP- growth algorithm by using Compound Single Linked List. They use the sequencing table and single linked list as the main data structure and do not need to generate conditional FP-tree. It is mined in one direction, using the header table in the original FP-tree, and a compound single linked list is constructed. A new algorithm [1 ge ner a t e s FP tree using directed acyclic graph data structure. Authors propose an algorithm that scan the database and generate FP tree as DAG so that they can generate frequent patterns directly using DAG without generating conditional FP trees. This approach reduces the total step of the process and also takes less time and less memory. Peiyi Tang et.al [13 h a s ex p l o r e d a  new scheme to parallelize frequent itemset mining algorithm Here the authors have applied the extended conditional databases and k-prefix search space partitioning. The algorithm is able to reduce the execution time of the largest parallel task thus allowing more parallel processors to join to achieve higher speed. Dynamic self-scheduling for parallel task allocation to balance the work load among parallel processors has been used. Buehrer [1  p r op os e d  v a ri an t s of  F P G r o w t h  on  computer clusters and have tried lowering communication costs and improve the cache memory and I/O utilization. In    We nb i n F a ng e t a l  i n t r od uced G P U M i n e r  a n ove l  parallel data mining system. It utilizes new-generation graphics processing units \(GPUs\.The authors have tried to parallelize Apriori algorithm. Their system relies on the massively multithreaded SIMD \(Single Instruction, Multiple Data\rchitecture provided by GPUs.  In this paper we parallelize the sorting process in pre-processing step using GPUs. The advantage of using GPUs is that it is energy efficient as well as cost effective as compared to multiprocessors and does not require a huge setup IV  P ROPOSED MODEL   As mentioned, the algorithm is sorting the dataset in the pre-processing step parallely and pruning the infrequent itemsets so as to make the dataset favorable for mining The sorting process is shown in the following steps 1  All the transactions are read first and a unique character list is made containing all the itemsets used in the transactions along with the count of its occurrence in all the transactions 2  Those itemsets having a count less than that of the minimum support are eliminated from this list procedure FP-Growth Tree  001   if Tree contains a single path P then for each 002\025 nodes combination in P do pattern 002\025  004  001   support = min\(support of the nodes in 002\025  else for each ai in the header of Tree do pattern 002\025   ai 004  001  with support ai support construct conditional pattern base of 002\025  TreeB construct conditional FP-tree of 002\025  if TreeB   then call FP-Growth TreeB 002\025  


2014 International Conference on Information Systems and Computer Networks  74 3  The 2D character array is then converted into a 2D integer array where the characters present in the unique array are converted to their ASCII values and those that are not present are the given a value of 10000 4  The integer value stored in the array is [ASCII value Support count of char*122  5  The integer array is then flattened out and sent to the GPU to be sorted along with a 1D array of size X*Y containing all zeros. The GPU is then used to sort the integer array V  PSP  A LGORITHM   It can be analyzed from the various mining algorithms that pre-processing the dataset appropriately and efficiently generates considerable better and faster results [16  F o r  FP growth it is desired that the transactions be sorted in descending order of frequency so as to speed up the mining process. In our proposed algorithm PSP \(Parallel sorting in preprocessing stage\, we make an attempt to enable faster preprocessing of the dataset by using some parallel programming techniques  A  Procedure of PSP algorithm Our approach for parallel programming is using the high parallel computing platform CUDA T h e C UDA co d e  implemented for sorting an array is done in the following way The initial input is read into a 2D character array. The frequency of each character is then found through a scan of the 2D array. The characters that do not meet the minimum threshold support count are eliminated from the array. This 2D integer array is then flattened [4 to a 1 D in teg e r a r ray  as  shown in the code below. This array is passed on to the GPU for sorting Flattening of the 2D integer array is done as follows               Figure 2. Flattening of 2D Integer array  where X=number of rows in c_int and Y=number of columns in c_int. The GPU addresses the flattened array as      Figure 3. The GPU address of the flattened array where left=the starting index of the part of the array and right the end index of the  part of the array. In this manner, the different blocks in the GPU do not use the same location in the array thus making all the blocks work on disjointed sets of the flattened array 1000 blocks, each with a single thread inside it, are called. The blockId is used to determine the starting position inside the 1D array and blockId + Y is used to determine the ending point Each block, knowing its starting and ending point, sorts that small part of the huge 1D array and writes the sorted section to the empty 1D array that was previously created in the same starting and ending position as the original array. The empty array is thus populated with the entries of the original array but sorted in ascending order. Blank spaces have the value of 10000 whereas the characters which were retained have their values as: \(ASCII value+ support count of char*122\his is then converted back into character array The following example illustrates the above steps in detail. Let the original dataset contain 10 transactions with 8 unique itemsets as follows T ABLE 1   A  TRANSACTION  DATABASE Transaction no Itemsets 1 a, b, c, d, e 2 c, f, a 3 c ,b, e 4 d ,a, f, b, c, e 5 a ,b, d, f 6 g ,e, a, b 7 h ,f 8 c ,d, a, b 9 g ,h, e, f, b, c 10 b, d, c,f  Step 1 Read into the 2D array  T ABLE 2   A  2D  CHARACTER  ARRAY  Unique character list and their support count are  a 6 b  8 c 7 d 4 e 5 f 6 g 2 h 2  Step 2 Eliminate the characters not meeting support count and rearrange in descending order of frequency    a b c e  c f a c b e    d a f b c e a b d f   g e a b  g f     c d a b g h e f b c b d c f b          8 c          7 a          6 f          6 e          5 count=0 for \(i=0; i<X; i  for \(j=0; i<Y; j  flat_c_int[count  c_ i n t  i  j    count    int idx=blockIdx.x*Y+threadIdx.x int left=idx int right=left+Y-1 


2014 International Conference on Information Systems and Computer Networks  75 Steps 3 & 4 Convert the 2D char array into a 2D int array The character assigned to char ‘b’ will be = 98+122*8=1074 Here 98 is the ASCII value of ‘b’, 122 is the base count we use and 8 is the frequency of the character ‘b’. Similar procedure is followed for other characters. The end result is as follows TABLE 3  A 2D INTEGER ARRAY  Step 5 The indexing goes from 0 to 9 in both dimensions This 2D array is then flattened to a 1D array with the index of the 1D array ranging from 0 to 99. This flattened array is then passed to the GPU for sorting. The sorting is done in the ascending order. The original FP algorithm sorts in descending t  w e  do i t i n a s cen di n g order t o bet t e r  utilize our algorithm Each GPU block processes different parts of the 1D array which correspond to individual rows in the original 2D array The indexing is as follows 0-9 = row 1   10-19 = row 2   20-29 = row 3 Hence block 1 of GPU will sort values stored in 1 st 10 locations of the array \(0-9\lock 2 will sort values stored in next 10 locations of the array \(10-19\d so on. For the above example only 10 blocks were invoked in the GPU. The sorted result is as follows T ABLE 4   THE  SORTED  ARRAY e a c b a f c e c b e a f c b a f b e a b f a c b e f c b f c b  The blocks in the GPU sort parts of the flattened 1D integer array and then returns the sorted array back to the host device Each block in turn runs a selection sort algorithm. The blocks run parallely and hence the sorting is also done parallely Blocks called: As many as the number of arrays to be sorted \(or in multiples of 1000 Threads per block: 1  B  Features Of PSP Algorithm When a general CPU deals with large arrays, it often cycles through the entries one after the other. Thus, for each transaction, the CPU will have to run a sorting algorithm on each row of the 2D array. This is done serially and for a really large number of transactions, can be a cumbersome task The advantage that we have taken here is about the fact that individual transactions are independent of each other. The sorting order depends only on the frequency of occurrence of the individual item over all the transactions. After the frequency of each item is recorded, the sorting of all the transactions can be done parallely instead of serial computation. Also, to avoid using a reference for finding the sorting order each time, we can add weights to the individual items in each transaction based on the frequency\(i.e. higher the occurrence, higher the number assigned\. Once it gets converted into integer array, the sorting task becomes simplified.Fig.4 shows the time comparison for executing arrays serially and in parallel    Figure 4. Sorting individual arrays \(a\ sequentially and \(b\ parallely  VI  IMPLEMENTATION DETAILS  We have used AMD Athlon 64 X2 Dual Core Processor 4000+ with 2 GB RAM on an Nvidia GT 520 \(1 GB\PU Our PSP algorithm is tested on a set of 1K, 10K and 50K synthetic transactions respectively. The transactions are tested serially as well as with our PSP algorithm i.e. parallely and it is shown that the processing speeds up remarkably when done parallely Fig.5 shows that time required to sort the dataset serially is far more than that doing it parallely. The difference is more prominent as the number of transactions goes on increasing This is one way we are addressing the scalability issue 829 1074 953 701 10000 10000 10000 10000 10000 10000 953 834 829 10000 10000 10000 10000 10000 10000 10000 953 1074 701 10000 10000 10000 10000 10000 10000 10000 10000 829 834 1074 953 701 10000 10000 10000 10000 829 1074 10000 834 10000 10000 10000 10000 10000 10000 10000 701 829 1074 10000 10000 10000 10000 10000 10000 10000 834 10000 10000 10000 10000 10000 10000 10000 10000 953 10000 829 1074 10000 10000 10000 10000 10000 10000 10000 10000 701 834 1074 953 10000 10000 10000 10000 1074 10000 953 834 10000 10000 10000 10000 10000 10000 


2014 International Conference on Information Systems and Computer Networks  76   Figure 5. Time comparison of serial and parallel processing  VII  C ONCLUSION AND FUTURE WORK  This paper proposes a new approach PSP algorithm of sorting the transactions parallely in pre-processing stage so as to make the dataset favorable for mining. This approach is surely efficient than sequential or serial sorting and can be implemented using high performance computing. By applying PSP algorithm we are making the dataset more favorable for frequent itemset mining in pre-processing stage itself and in a way trying to address the scalability issue by decreasing the time required for sorting considerably However the above process has scope for improved speed by invoking multiple threads within the same block to sort long arrays. One problem faced with multiple threads in the same block is writing to shared memory variables. Since all the threads run at the same time, a lock can be obtained when writing to a shared variable. This considerably slows down the sorting process, hence the current approach was to use separate blocks with individual threads to sort the flattened array Bitonic sort is another way of going ahead with the sorting process. After making the dataset favorable for mining, our next approach will be to parallelize the tree generation and traversing process R EFERENCES   1  R. Agrawal, H.Mannila, R. Srikant, H. Toivonen, and A I.Verkamo, “Fast discovery of association rules”, In: Advances in Knowledge Discovery and Data Mining, MIT Press, 1996 2  Han J, Pei J, Yin Y, “Mining frequent patterns without candidate generation”, In: Proc. of the ACM SIGM0D Conference on Management of Data. Dallas, TX, 2000 3  Pang-Ning Tan, Michael Steinbach and Vipin Kumar Introduction to Data Mining”, In: Pearson Publication, Fourth edition 2009 4  https://developer.nvidia.com/cuda-gpus 5  R. Agrawal, T. Imielinski, a nd A.Swami., “Mining association rules between sets of items in large database”, In: ACM SIGMOD Intl. Conf. Management of Data. 1993 6  J. Pei, J. Han, H. Lu, S. Nishio, S. Tang, and D. Yang, “HMine Hyper-Structure Mining of Frequent Patterns in Large Databases”, In: Proc. of IEEE ICDM, San Jose, and California.2001 7  R. Agrawal and R. Srikant., “Fast Algorithms for Mining Association Rules”, In: Proc. of the 20th Int. Conf. on VLDB Santiago, Chile.1994 8  Y. G. Sucahyo and R. P. Gopalan., “CT-ITL: Efficient Frequent Item Set Mining Using a Compressed Prefix Tree with Pattern Growth”, In: Proc. of 14th Australasian Database Conference Adelaide, Australia.2003 9  M. J. Zaki., “Scalable Algorithms for Association Mining”, In IEEE Transactions on Knowledge and Data Engineering, \(12 May/June 2000\ 372-390 10  Min Chen, XueDong Gao HuiFei Li , “An Efficient Parallel FPGrowth Algorithm” , In: 978-1-4244-5219-4/09, 2009 IEEE 11  Ding Zhenguo, Wei Qinqin, Ding Xinhua, “An Improved FPgrowth Algorithm Based on Compound Single Linked List”, In IEEE 2009 Second International Conference on Information and Computing Science 12  A Vedula Venkateswara Rao, B. Eedala Rambabu Association Rule Mining Using FPTree As Directed Acyclic Graph”, In: IEEE-International Conference On Advances In Engineering, Science And Management \(ICAESM -2012 March 30, 31, 2012 13  Peiyi Tang, Markus P. Turkia, “Parallelizing Frequent Itemset Mining with FP-Trees”, In: proceeding of: 21st International Conference on Computers and Their Applications, CATA-2006 Seattle, Washington, USA, March 23-25, 2006 14  G. Buehrer, S. Parthasarathy, S. Tatikonda, T. Kurc and  J Saltz., “Toward terabyte pattern mining: an architecture conscious solution”, In PPOPP 2007 15  Wenbin Fang, Ka Keung Lau, Mian Lu, Xiangye Xiao, Chi Kit Lam, Philip Yang Yang,Bingsheng He1, Qiong Luo, Pedro V Sander, and Ke Yang, “Parallel Data Mining on Graphics Processors”, In Technical Report HKUSTCS0807, Oct 2008 16  Christian Borgelt, “An implementation of the FP-growth  Algorithm  In  Workshop on Open source Data Mining Software \(OSDM’05, Chicago, IL\, 1-5.ACM Press, New York NY, USA 2005  


IEEE International Conference on Advances in Engineering & Technology Research \(ICAETR - 2014 August 01-02, 2014, Dr. Virendra Swarup Group of Institutions, Unnao, India 978-1-4799-6393-5/14/$31.00 ©2014 IEEE algorithm. It gives us different frequent item set mining results with their support count. Web link sequences below support threshold are pruned. We found different frequent item set mining results by varying minimum support \(2%3%\ssociation rules miner give all the possible rules with their confidence and Lift. Using the knowledge of the web site structure and the behavior of the site’s visitors, we analyzed the pruned rule set from the user ‘s point of view and proposed actions that a webmaster may decide to take based on knowledge extracted from rules in order to enhance a website and improve visitor’s browsing experience. The work can be fu rther extended by developing even more effective data pre-processing modules. Because the current module \(2\ot capable of handle very large number of log entries. Association rule mining of web usage log files is a method that can bring new, previously unknown knowledge about the website visitor behavior. In this research we presented how it can be used by a webmaster to improve a website structure. We leave such analysis out of the scope of this research. Future work in this area may also consider the scalability issue R EFERENCES  1  R. Agrawal, T. Imielinski and A. Swami, “Mining association rules between sets of items in large databases” In Proceeding of the ACM SIGMOD International Conference on Management of Data \(ICMD\, USA, pp. 207–216, 1993 2  P.Tan, V. Kumar, and J. Srivastava, “Selecting the right interestingness measure for asso ciation patterns” Information Systems, Proceeding of the International Conference on Knowledge Discovery and Data Mining \(KDDM\ New York pp. 32-41, 2002 3  R. Agrawal, and R. Srikant, “Fast Algorithms for Mining Association Rules” Proceeding of the 20 th International Conference on Very Large Databases \(VLDB\ 1215, Sanjosh CA, pp. 487-499, 1994 4  Cooley, R., Mobasher, B., and J. Srivastava, “Grouping web page references into transactions for mining World Wide Web browsing patterns” Proceeding of the IEEE Knowledge and Data Engineering Exchange Workshop \(KDEEW\, Newport Beach, CA, pp 2-9,1997 5  E.R. Omiecinski, “Alternative interest measures for mining associations in databases” IEEE Transactions on Knowledge and Data Engineering, vol.15, Issue 1, pp. 57-69, 2003 6  S. S.Anand, M. Mulvenna, and K. Chavielier “On the deployment of web usage mining” Berlin Springer Heidelberg, 2004 7  L.Cristofor and D.Simovici, “Generating an informative cover for association rules” Proceeding of the IEEE International Conference on Data Mining \(ICDM\, Boston, USA, pp. 597600, 2002 8  M.S.B. PhridviRaj and C.V.GuruRao, “Data mining – past present and future – a typical survey on data Streams Proceeding of the 7th International Conference Interdisciplinarity in Engineering Procedia Technology ICIEPT\, Romania, pp. 255 – 263, 2014 9  M.L. Shyu, C. Haruechaiyasak, S.C.Chen and N. Zhao Collaborative Filtering by Mining Association Rules from User Access Sequences” Proceeding of the IEEE International workshop on Web Information Retrieval and Integration IWIRI\, Tokyo, pp. 128-135, 2005 10  V. Nebot and R.Berlanga “Finding association rules in semantic web data” Knowledge Based system \(Elsevier pp.51-62, 2012 11  Cheng and Zheng “An Incremental Updating Technique for Mining Indirect Association Rules  Proceedings of the Seventh International Conference on Machine Learning and Cybernetics, Kunming, pp.12-15, 2008 12  A.Saleem Raja, E.George and Dharma Prakash Raj “MADARM: Mobile Agent based Distributed Association Rule Mining” IEEE International Conference on Computer Communication and Informatics \(ICCCI\ Coimbatore, pp. 15, 2013 13  K. Shimada, K. Hirasawa, and J. Hu “Class Association Rule Mining with Chi-Squared TestUsing Genetic Network Programming”Proceeding of the IEEE International Conference on Systems, Man, and Cybernetics, Taiwan pp.5338-5344, 2006 14  W. Pei-ji1,B. Jin-niu and Z. Yu-lin “Mining Association Rules Based on Apriori Algorithm and Application Proceeding of the International Forum on Computer ScienceTechnology and Applications, Chongqing, pp.141-143, 2009 15 I Mo ha m m a d  A  Ba k a r a nd A  Su ha ilis    A b d u l Ka dir  Mining Positive and Negative Association Rules from Interesting Frequent and Infrequent Itemsets” 9th International Conference on Fuzzy Systems and Knowledge Discovery \(FSKD\, Sichuan, pp.650-655, 2012       


of 0.1 the analyst will ha v e to analyze only 9 itemsets and get a good idea of the content of about one fth of the itemsets Since DIM pro vides fe w itemsets one may w onder if the amount of information pro vided by these itemsets can be also obtained by taking the top p here top is considered w r t support v alue itemsets produced by LCM where p is equal to the number of itemsets produced by DIM T able II gi v es reco v erability for the top p for each dataset precision is by deÞnition 100 in this case the accidents mum support of 10 DIM outputs 9 itemsets so we tak e the top 9 itemsets from the results of LCM and compute their reco v erability  which is 13 The reco v erability of the top p itemsets of LCM is more than 4 times lo wer than those of DIM in real datasets In the synthetic dataset ho we v er  the impro v ement is mar ginal The table in general conÞrms tha t DIM itemsets con v e y more information than traditional top p techniques Dataset p min-supp LCM DIM pumsb 7 40 15 72 accidents 9 10 13 67 T40I10D100k 9 0.1 12 18 T able II Comparing top-p LCM closed itemsets with DIM itemsets VII C ON CLU SION AN D F UT URE W OR K In this study  we ha v e e xamined the problem of frequent itemset mining through decomposi tion of the input matrix Using theoretic al analysis we ha v e sho wn that matrix decomposition can help us mining frequent itemsets Our e xperiments ha v e sho wn that although for high support v alues our approach is less time ef cient than stateof-the-art algorithms for lo w support v alues our approach is much f aster than those algorithms This approach is also highly scalable with respect to other algorithms according to the f act that the classical itemset mining approaches become v ery slo w since the y need to e xplore a huge combinatorial space as the number of items increases The proposed method only nds a handful of itemsets b ut the e xperiments sho w that these itemsets con v e y a signiÞcant portion of the information of all frequent itemsets W e adv ocate that contrary to classical methods the mining time is well in vested  what is the utility of a v ery f ast algorithm that outputs millions of patterns that an analyst will tak e hours to mak e some sense of W ith our method the computer does most of the w ork and the analyst is presented with concise reliable and manageable information This w ork opens man y future research directions such as studying the nature of the itemsets not reco v ered by our method or charac terizing the set of frequent itemsets obtained from latent f actors with respect to the sets of frequent itemsets found by methods such as 5 do such methods also re-disco v er the latent f actors R EF E REN CES 1 R Agra w al and R Srikant F ast algorithms for mining assoin Pr oc of the 20th International Confer ence on V ery Lar g e Databases VLDB 94  Chile 1994 2 A Inokuchi T  W ashio and H Motoda  An apriori-based algorithm for mi ning frequent substructures from graph data  in PKDD  2000 pp 13Ð23 3 N P asquier  Y  Bastide R T aouil L and Lakhal Disco vering frequent closed itemsets for association rules  in oc of 7th international confer ence of database theory 1999 4 T  Uno M Kiyomi and H Arimura Lcm v er  2 Ef cient mining algorithms for frequent/closed/maximal itemsets  in Pr oc of the ICDM W orkshop FIMI 04 2004 5 J Vreek en M v an Leeuwen and A Siebes Krimp mining itemsets that compress  Data Min Knowl Disco v  23 no 1 pp 169Ð214 2011 6 T  Guns S Nijssen and L D Raedt k-pattern set mining under constraints  KU Leuv en T ech Rep CW 596 2010 7 M K o yuturk A Grama and N Ramakrsihnan Compression clustering and pattern disco v ery in v ery-highdimensional discrete-attrib ute dat a sets  Knowledg e Data Eng  v ol 17 pp 447Ð461 2005 8 P  Jiang J Peng M Heath and R Y ang  A clustering approach to constrained binary matrix f actorization  in Data Mining and Knowledg e Dis co very for Big Data  2014 pp 281Ð303 9 R Gupta G F ang B Field M Steinbach and V  K umar  Quantitati v e e v aluation of approximate frequent pattern minin 08  Las V e g as Ne v ada USA 2000 10 B Bringmann and A Zimmermann The chosen fe w On identifying v aluable patterns  in ICDM 63Ð72 11 F  Afrati A Gionis and H Mannila  Approximating a collection of frequent sets  in 04  Seattle W ashington 12Ð19 12 P  Kra jca J Outrata and V  Vychodil Using frequent closed itemsets for data dimensionality reduction  in ICDM 2011 13 P  Miettinen The boolean col umn and column-ro w matrix  Data Mining and Knowledg e Disco very  v ol 17 no 1 pp 39Ð56 2008 14 T  Uno M Kiyomi and H Arimura Lcm v er 3 Collaboration of array  bitmap and preÞx tree for frequent itemset mining  in 05  2005 pp 77Ð86 


002 
                          
R. Agrawal and R. Srikant. Fast algorithms for mining association rules in large databases. In Proc. VLDB, pages 487…499, 1994 2 R. J. Bayardo, Jr. Efficiently mining long patterns from databases SIGMOD Rec., pages 85…93, 1998 3 M. Zaki, S. Parthasarathy, M. Ogihara, and W. Li. Parallel algorithms for discovery of association rules. Data Min. and Knowl. Disc., pages 343…373, 1997 4 J. Dean and S. Ghemawat. MapReduce: Simplified data processing on large clusters. In Proc. OSDI. USENIX Association, 2004 5 Apache hadoop. http://hadoop.apache.org/, 2013 6 Jiawei Han and Micheline Kamber. Data Mining, Concepts and Techniques. Morgan Kaufmann, 2001 7 M. Zaharia, M. Chowdhury, T. Das, A. Dave, J. Ma, M. McCauley M. Franklin, S. Shenker, and I. Stoica. Resilient distributed datasets A fault-tolerant abstraction for in-memory cluster computing Technical Report UCB/EECS-2011-82, EECS Department University of California, Berkeley, Jul 2011 8 M. Zaharia, M. Chowdhury, M. J. Franklin, S. Shenker, and I. Stoica Spark: Cluster Computing with Working Sets. In HotCloud, 2010 9 J. Han, J. Pei, and Y. Yin: Mining Frequent Patterns without Candidate Generation. In: Proceedings of the 2000 ACM SIGMOD International Conference on Management of Data, 29\(2\:1-12, 2000 10 M. J. Zaki. Parallel and distributed association mining: A survey IEEE Concurrency, pages 14…25, 1999 11 J. Li, Y. Liu, W.-k. Liao, and A. Choudhary. Parallel data mining algorithms for association rules and clustering. In Intl. Conf. on Management of Data, 2008 12 E. Ozkural, B. Ucar, and C. Aykanat. Parallel frequent item set mining with selective item replication. IEEE Trans. Parallel Distrib Syst., pages 1632…1640, 2011 13 B.-H. Park and H. Kargupta. Distributed data mining: Algorithms systems, and applications. 2002 14 L. Zeng, L. Li, L. Duan, K. Lu, Z. Shi, M. Wang, W. Wu, and P. Luo Distributed data mining: a survey. Information Technology and Management, pages 403…409, 2012 15 Li L. & Zhang M. \(2011\. The Strategy of Mining Association Rule Based on Cloud Computing. Proceeding of the 2011 International Conference on Business Computing and Global Informatization BCGIN 11\. Washington, DC, USA, IEEE: 475- 478 16 Li N., Zeng L., He Q. & Shi Z. \(2012\. Parallel Implementation of Apriori Algorithm Based on MapReduce. Proc. of the 13th ACIS International Conference on Software Engineering, Artificial Intelligence, Networking and Parallel & Distributed Computing SNPD 12\. Kyoto, IEEE: 236 … 241 17 Lin M., Lee P. & Hsueh S. \(2012\. Apriori-based Frequent Itemset Mining Algorithms on MapReduce. Proc. of the 16th International Conference on Ubiquitous Information Management and Communication \(ICUIMC 12\. New York, NY, USA, ACM: Article No. 76 18 Yang X.Y., Liu Z. & Fu Y. \(2010\. MapReduce as a Programming Model for Association Rules Algorithm on Hadoop. Proc. of the 3rd International Conference on Information Sciences and Interaction Sciences \(ICIS 10\. Chengdu, China, IEEE: 99 … 102 19 S. Hammoud. MapReduce Network Enabled Algorithms for Classification Based on Association Rules. Thesis, 2011 20 Synthetic Data Generation Code for Associations and Sequential Patterns. Intelligent Information Systems, IBM Almaden Research Center http://www.almaden.ibm.com/software/quest/Resources/index.shtml 21 C.L. Blake and C.J. Merz. UCI Repository of Machine Learning Databases. Dept. of Information and Computer Science, University of California at Irvine, CA, USA. 1998 http://www.ics.uci.edu/mlearn/MLRepository.html 22 HadoopApriori. https://github.com/solitaryreaper/HadoopApriori 2 3 H.V. Nguyen, E. Muller, K. Bohm. 4S: Scalable Subspace Search Schema Overcoming Traditional Apriori Processing. 2013 IEEE International Conference on Big Data. 2013 24 S. Moens, E. Aksehirli and Goethals. Frequent Itemset Mining for Big Data. University Antwerpen, Belgium. 2013 IEEE International Conference on Big Data. 2013 25 Y. Bu et al . HaLoop: E cient iterative data processing on large clusters. Proceedings of the VLDB Endowment, 3\(1-2\:285…296 2010 26 Frequent itemset mining dataset repository. http://fimi.us.ac.be/data 2004   
002 
Our experiments show that YAFIM is about 18 faster than Apriori algorithms implemented in MapReduce framework Furthermore, we can achieve a better performance in both sizeup and speedup for different datasets. In addition, we also evaluated YAFIM for medical application and revealed that YAFIM outperforms MRApriori about 25 speedup  A CKNOWLEDGMENT  This work is funded in part by China NSF Grants \(No 61223003\, and the USA Intel Labs University Research Program R EFERENCES  1 
002 
1671 


