 
   
 
 
  
   


            


                          


               


         


that case our proposed mining algorithm outperforms the conventional Apriori algorithm Fig. 3. TicTacToe data   Fig. 4. T8I5D100K   Fig. 5. T6I4D100K  V  CONCLUSIONS  AND  SUMMARY In this paper, we have developed a genetic based approach and compared the results with the results given by the Apriori algorithm for mining maximal frequent item sets. We have obtained the results through experimental analysis on real data sets using both of these algorithms. Several advantages have been demonstrated by the experimental analysis of this algorithm in comparison with Apriori algorithm, which are as follows 200  It gives better results than the Apriori algorithm by accessing large data sets for less numbers of nodes especially when the support value is set low by the users 200  For large data sets and low support value, both of these algorithms give the same solution by giving the same number of maximal frequent item sets. To get this solution Apriori considers a large number of candidate item sets with respect to a genetic based approach 200  For large data sets and high support values, Apriori performs better than a genetic based approach, since the genetic algorithm uses global search mechanism Apriori uses a level by level search procedure and it gets the solution by accessing less numbers of nodes because solution is near the root node. The nodes close to the root of lexicographic tree have higher support values 200  Low support value generates a long size frequent pattern which provides information like frequency of an exponential number of smaller sub patterns. In that case a genetic based approach performs better than other existing algorithms 200  The experimental results of a genetic based approach demonstrate the effect of generations of individuals, and prune all the subsets and supersets in a lexicographic tree, which is cost effective in the case of counting the support value and reducing the search space dramatically The other areas which should be focused for further research include developing genetic operators in such a way that it will help to reduce generating the same individuals and it can increase valid individuals for further generation Considering repetitive individuals sometimes takes a longer time to get the solution A CKNOWLEDGMENT  This research work was funded by School of Engineering and ICT, University of Tasmania, Australia, and website http://www.utas.edu.au/cricos, under CRICOS Provider Code 00586B  R EFERENCES  1  M M. J  K a bir  S  X u  B. H  K a ng a nd Z  Z h ao 223 A N o ve l Approach to Mining Maximal Frequent Itemsets Based on Genetic Algorithm,\224 in International Conference on Information Technology and Applications \(ICITA 2014 2  R C. A g ar w al C. C A g g ar w al and V V  V P r asa d  223 A Tr ee  Projection Algorithm For Generation of Frequent Itemsets,\224 Parallel Distrib. Comput. Spec. Issue High Perform. Data Min vol 61, no. 3, pp. 350\226371, 2001 3  A  S a l leb  Z M a a z ou zi  and C V r a in  223Mi n i n g M a xi m a l F r eq u e nt Itemsets by a Boolean Based Approach,\224 in European Conference on Artificial intelligence 2002, pp. 285\226289 4  J  H a n, J  P e i a n d Y  Y i n 223 M i n i n g F r e que nt P a tte r n s w i tho u t  Candidate Generation,\224 ACM SIGMOD vol. 29, no. 2, pp. 1\22612 2000 5  J  H i p p  U  G 374ntz e r a nd G  N a kh ae iz ade h 223 A l g or ithm s f o r  association rule mining\227a general survey and comparison,\224 ACM sigkdd Explor. \205 vol. 2, no. 1, pp. 58\22664, 2000 6  R. J  K u o an d C  W  S h i h 223 A s s o ciati o n r u l e m i ni ng t h r o ug h the a n t  colony system for National Health Insurance Research Database in 44 


Taiwan,\224 Comput. Math. with Appl vol. 54, no. 11\22612, pp. 1303\226 1318, Dec. 2007 7 J  H Holla n d   Adaptation in Natural and Artificial Systems Ann Arbor: University of Michigan Press, 1975 8  K  F M a n  K S  T a n g   a n d S  Kwo n g  223 G e n e t i c Al g o r i t h m s 037   Concepts and Applications,\224 IEEE Trans. Ind. Electron vol. 43 no. 5, 1996 9  D  Be as l e y  D  R. B u l l  an d R R Ma r tin 223 A n O v e r v iew of  G e ne tic  Algorithms\037: Part 1 , Fundamentals,\224 Univ. Comput vol. 15, no. 2 pp. 58\22669, 1993   M  S r i n i v a s an d L  M  P a tn ai k 223G e n et i c A lgo r i t h m s A S u r v ey  224  Computer \(Long. Beach. Calif vol. 27, no. 6, pp. 17\22626, 1994  D E  G o ld b e rg  Genetic Algorithms in Search, Optimization and Machine Learning Addison-Wesley Longman Publishing Co., Inc Boston, MA, USA, 1989  Z  M i ch a l ew i c z  Genetic algorithms + data structures = evolution programs Berlin: Springer, 1992  R  A gra w a l a n d R  Sri kan t  223F a s t A l gori t h m s for M i n i n g  Association Rules,\224 in 20th International Conference on Very Large Data Bases 1994, pp. 487\226499 14  D  I  L i n and Z  M. K e de m  223 P ince r S e a r c h A  N e w  A l go r ithm f o r  Discovering the Maximal Frequent Set,\224 in 6th International Conference on Extending Database Technology   R  J   B a y a rd o 223E ffic i e nt ly M i ni n g L on g Pa tt ern s from D a t a b a s e s  224 ACM SIGMOD pp. 85\22693, 1998 16  R  C  A g a r w a l  C  C  A g g a r w a l  a n d V  V  V  P r a s a d  223 D e p t h f i r s t  generation of long patterns,\224 Proc. sixth ACM SIGKDD Int. Conf Knowl. Discov. data Min. - KDD \22200 vol. 2, pp. 108\226118, 2000  D Bu rdi c k   M  Ca li m l i m   an d J   Geh r k e  223M AFI A a m a xi m a l  frequent itemset algorithm for transactional databases,\224 Proc. 17th Int. Conf. Data Eng no. X, pp. 443\226452 18  K   G o uda an d M. J  Z a ki, \223 G e n Max 037   A n E f f icie n t A l go r ithm f o r  Mining,\224 Data Min. Knowl. Discov vol. 11, no. 3, pp. 223\226242 2005    A l a t a and E. Akin, \223An efficient genetic algorithm for automated mining of both positive and negative quantitative association rules,\224 Soft Comput vol. 10, no. 3, pp. 230\226237, Apr 2005 20  W D o u  J  Hu  K Hi r a s a wa   a n d  G Wu  223 Q u i c k r e s p on s e d a t a  mining model using genetic algorithm,\224 2008 SICE Annu. Conf pp 1214\2261219, Aug. 2008  A  Sa ll e b a ou i ssi C Vra i n   C  Norte t  X K o n g  a n d D  C a ss a r d  223QuantMiner for Mining Quantitative Association Rules,\224 Mach Learn. Res vol. 14, no. 1, pp. 3153\2263157, 2013 22  A  S a l le b a o u is s i C  V r ai n an d C. N o r te t, \223 Q ua n tM ine r 037  A  Genetic Algorithm for Mining Quantitative Association Rules,\224 in 20th International Joint Conference on Artificial Intelligence 2007 pp. 1035\2261040  J  Hua n g Y  Ch e-t s un g  a nd  C  F u 223 A Gen e t i c A l g ori t h m  B a s e d Searching of Maximal Frequent Itemsets,\224 in International conference on artificial intelligence 2004    45 


0.80 0.76 0.72 0.68 0.64 0.60 0.56 0.52 0.48 CPU Apriori Computation Time \(s Speedup DP time SR time CPU time  Relative Minimum Support Time Breakdown 100 50 0   Apriori-AP counting speedup Apriori-AP overall speedup  Apriori-CPU counting time Apriori-CPU overall time Apriori-AP counting time Apriori-AP overall time 
0.1 1 10 100 3000 2000 1000 0 1000 2000 3000 4000 5000 
0.6 0.5 0.4 0.3 0.2 0.1 0.0 10 100 
1 10 100 6000 4000 2000 0 2000 4000 6000 8000 10000 
0.20 0.19 0.18 0.17 0.16 0.15 0.14 0.13 0.12 0.11 0.10 0.09 0.08 0.07 0.06 0.05 CPU Apriori Computation Time \(s Speedup DP time SR time CPU time  Relative Minimum Support Time Breakdown 100 50 0 Apriori-AP counting speedup Apriori-AP overall speedup  Apriori-CPU counting time Apriori-CPU overall time Apriori-AP counting time Apriori-AP overall time  0 10000 5000 15000 c Webdocs Figure 5 The performance results of Apriori-AP on three real-world benchmarks DP time SR time and CPU time represent the data process time on AP symbol replacement time on AP and CPU time respectively Webdocs switches to 16-bit encoding when relative minimum support is less then 0.1 8-bit encoding is applied in other cases 
E vs Eclat Eclat et al Eclat Eclat 
0.80 0.75 0.70 0.65 0.60 0.55 0 100 200 300 400 Computation Time \(s Relative minimum support 1.0X Symbol replacement time 0.5X Symbol replacement time 0.1X Symbol replacement time Figure 7 The impact of symbol replacement time on Apriori-AP performance for Pumsb how symbol replacement time affects the total AprioriAP computation time A reduction of 90 in the symbol replacement time leads to 2.3X-3.4X speedups of the total computation time The reduction of symbol replacement latency will not affect the performance behavior of AprioriAP for large datasets since data processing dominates the total computation time 
Apriori Eclat Equivalent Class Clustering   is another algorithm based on Downward-closure uses a vertical representation of transactions and depth-ìrst-search strategy to minimize memory usage Zhang  proposed a h ybrid depth-ìrst/breadth-ìrst search scheme to expose more parallelism for both multi-thread and GPU versions of  However the trade-off between parallelism and memory usage still exists For large datasets the nite memory main or GPU global memory will become a limiting factor for performance and for very large datasets the algorithm fails While there is a parameter which can tune the trade-off between parallelism and memory occupancy we simply use the default setting of this parameter for better performance Figure 8 shows the speedups that the sequential 
0.50 0.45 0.40 0.35 0.30 0.25 0.20 0.15 0.10 0.05 CPU Apriori Computation Time \(s Speedup DP time SR time CPU time  Relative Minimum Support Time Breakdown 100 50 0 AP counting speedup Apriori-AP overall speedup    Apriori-CPU counting time Apriori-CPU overall time Apriori-AP counting time Apriori-AP overall time  b Accidents 
T40D500K Counting T40D500K Overall T100D20M Counting T100D20M Overall Webdocs5X Counting Webdocs5X Overall Speedup Relative Minimum Support Figure 6 The speedup of Apriori-AP over Apriori-CPU on three synthetic benchmarks 
1 10 100 
a Pumsb 
696 


0.8 0.7 0.6 0.5 0.4 0.3 0.2 0.1 0.0 0.1 1 10 Pumsb Accidents T40D500K Webdocs Webdocs5X T100D20M ENWiki Speedup Relative Minimum Support 
Figure 8 The performance comparison of CPU sequential and algorithm achieved with respect to sequential Apriori-CPU Though has 8X performance advantage in average cases the vertical bitset representation become less efìcient for sparse and large dataset high trans and freq item ratio This situation becomes worse as the support number decreases The Apriori-CPU implementation usually achieves worse performance than  though the performance boost of counting operation makes Apriori-AP a competitive solution to parallelized  Three factors make a poor t for the AP though it has better performance on CPU 1 requires bit-level operations but the AP works on byte-level symbols 2 generates new vertical representations of transactions for each new itemset candidate while dynamically changing the values in the input stream is not efìcient using the AP 3 Even the hybrid search strategy cannot expose enough parallelism to make full use of the AP chips Figure 9 and 10 show the performance comparison between Apriori-AP 45nm for current generation of AP and sequential multi-core and GPU versions of  Generally Apriori-AP shows better performance than sequential and multi-core versions of  The GPU version of shows better performance in Pumsb Accidents and Webdocs when the minimum support number is small However because of the constraint of GPU global memory Eclat-1G fails at small support numbers for three large datasets ENWiki T100D20M and Webdocs5X ENWiki as a typical sparse dataset causes inefìcient storage of bitset representation in Eclat and leads to early failure of EclatGPU and up to 49X speedup of Apriori-AP over Eclat-6C In other benchmarks Apriori-AP shows up to 7.5X speedup over Eclat-6C and 3.6X speedup over Eclat-1G This gure also indicates that the performance advantage of AprioriAP over GPU/multi-core increases as the size of the dataset grows The AP D480 chip is based on 45nm technology while the Intel CPU Xeon E5-1650 and Nvidia Kepler K20C on which we test are based on 32nm and 28nm technologies respectively To compare the different architectures in the same semiconductor technology mode we show the performance of technology projections on 32nm and 28nm technologies in Figure 9 and 10 assuming linear scaling for clock frequency and square scaling for capacity The technology normalized performance of Apriori-AP shows better performance than multi-core and GPU versions of Eclat in almost all of the ranges of support that we investigated for all datasets with the exception of small support for Pumsb and T100D20M Apriori-AP achieves up to 112X speedup over Eclat-6C and 6.3X speedup over Eclat-1G The above results indicate that the size of the dataset could be a limiting factor for the parallel algorithms By varying the number of transactions but keeping other parameters xed we studied the behavior of Apriori-AP and Eclat as the size of the dataset increases Figure 11 For T100 the datasets with different sizes are obtained by the IBM synthetic data generator For Webdocs the different data sizes are obtained by randomly sampling the transactions or by concatenating duplicates of the whole dataset In the tested cases the GPU version of fails in the range from 2GB to 4GB because of the nite GPU global memory Comparing the results using different support numbers on the same dataset it is apparent that the smaller support number causes Eclat-1G to fail at a smaller dataset This failure is caused by the fact that the ARM with a smaller support will keep more items and transactions in the data preprocessing stage While not shown in this gure it is reasonable to predict that the multicore implementation would fail when the available physical memory is exhausted However Apriori-AP will still work well on much larger datasets assuming the data is streamed in from the hard drive assuming the hard drive bandwidth is not a bottleneck VII C ONCLUSIONS AND THE F UTURE W ORK We present a hardware-accelerated ARM solution using Micronês new AP architecture Our proposed solution includes a novel automaton design for matching and counting frequent itemsets for ARM The multiple-entry NFA based design was proposed to handle variable-size itemsets MENFA-VSI and avoid routing reconìguration The whole design makes full usage of the massive parallelism of the AP and can match and count up to itemsets in parallel on an AP D480 48-core board When compared with the based single-core CPU implementation the proposed solution shows up to 129X speedup in our experimental 
Apriori Eclat Eclat Eclat Eclat Eclat Eclat Eclat Eclat Eclat Eclat Eclat F Normalizing for technology Eclat G Data size Eclat Eclat Eclat Apriori 
18 432 
 
697 


0.20 0.18 0.16 0.14 0.12 0.10 0.08 0.06 1 10 100 1000 10000 Eclat-1C \(32nm Eclat-6C \(32nm Eclat-1G \(28nm Computation Time \(s Relative Minimum Support Apriori-AP 45nm Apriori-AP 32nm Apriori-AP 28nm a Webdocs\(1.4GB 0.20 0.18 0.16 0.14 0.12 0.10 0.08 0.06 10 100 1000 10000 Eclat-1C \(32nm Eclat-6C \(32nm Eclat-1G \(28nm Computation Time \(s Relative Minimum Support Apriori-AP 45nm Apriori-AP 32nm Apriori-AP 28nm Eclat-GPU fails d Webdocs5X 7.1GB Figure 10 Performance comparison among Apriori-AP Eclat-1C Eclat-6C and Eclat-1G with technology normalization on four large datasets 
0.50 0.45 0.40 0.35 0.30 0.25 0.20 0.15 0.10 0.1 1 10 100 1000 Eclat-1C \(32nm Eclat-6C \(32nm Eclat-1G \(28nm Computation Time \(second Relative Minimum Support Apriori-AP 45nm Apriori-AP 32nm Apriori-AP 28nm b Accidents 34MB 0.40 0.36 0.32 0.28 0.24 0.20 0.16 0.12 0.08 0.1 1 10 100 1000 Eclat-1C \(32nm Eclat-6C \(32nm Eclat-1G \(28nm Computation Time \(s Relative Minimum Support Apriori-AP 45nm Apriori-AP 32nm Apriori-AP 28nm c T40D500K\(49MB Figure 9 Performance comparison among Apriori-AP Eclat1C Eclat-6C and Eclat-1G with technology normalization on three small datasets results on seven real-world and synthetic datasets This APaccelerated solution also outperforms the multicore-based and GPU-based implementations of 0.60 0.55 0.50 0.45 0.40 0.35 0.30 0.25 10 100 1000 Eclat-1C \(32nm Eclat-6C \(32nm Eclat-1G \(28nm Computation Time \(s Relative Minimum Support Apriori-AP 45nm Apriori-AP 32nm Apriori-AP 28nm Eclat-GPU fails c T100D20M 6.3GB 
ARM a more efìcient algorithm with up to 49X speedups especially on large datasets When performing technology projections on future generations of the AP our results suggest even better speedups relative to the equivalent-generation of CPUs and GPUs Furthermore by varying the size of the datasets from small to very large our results demonstrate the memory constraint of parallel ARM particularly for GPU 
Eclat Eclat 
0.80 0.76 0.72 0.68 0.64 0.60 0.56 0.52 0.1 1 10 100 1000 Eclat-1C \(32nm Eclat-6C \(32nm Eclat-1G \(28nm Computation Time \(s Relative Minimum Support Apriori-AP 45nm Apriori-AP 32nm Apriori-AP 28nm 
0.20 0.15 0.10 0.05 0.00 1 10 100 1000 10000 100000 Eclat-1C \(32nm Eclat-6C \(32nm Eclat-1G \(28nm Computation Time \(second Relative Minimum Support Apriori-AP 45nm Apriori-AP 32nm Apriori-AP 28nm Eclat-GPU fails b ENWiki\(3.0GB 
a Pumsb 16MB 
698 


 Frequent pattern mining Current status and future directions  2007  R Agra w al and R Srikant F ast algorithms for mining association rules in  1994  M J Zaki Scalable algorithms for association mining  vol 12 no 3 pp 372Ö390 2000  J Han J Pei and Y  Y in Mining frequent patterns without candidate generation in  2000  Y  Zhang F  Zhang and J Bak os Frequent itemset mining on large-scale shared memory machines in  2011  F  Zhang Y  Zhang and J D Bak os  Accelerating frequent itemset mining on graphics processing units  vol 66 no 1 pp 94Ö117 2013  Y  Zhang  An fpga-based accelerator for frequent itemset mining  vol 6 no 1 pp 2:1Ö2:17 May 2013  P  Dlugosch  An efìcient and scalable semiconductor architecture for parallel automata processing  vol 25 no 12 2014  I Ro y and S Aluru Finding motifs in biological sequences using the micron automata processor in  2014  R Agra w al T  Imieli  nski and A Swami Mining association rules between sets of items in large databases in  1993  H No yes Micronês automata processor architecture Reconìgurable and massively parallel automata processing in  June 2014 keynote presentation  M J Zaki  Parallel data mining for association rules on shared-memory multi-processors in  1996  L Liu  Optimization of frequent itemset mining on multiple-core processor in  2007  I Pramudiono and M Kitsure ga w a P arallel fp-gro wth on pc cluster in  2003  E Ansari  Distributed frequent itemset mining using trie data structure  vol 35 no 3 p 377 2008  W  F ang  Frequent itemset mining on graphics processors in  2009  B Goethals Surv e y on frequent pattern mining  Univ of Helsinki Tech Rep 2003  C Bor gelt Ef cient implementations of apriori and eclat in  2003 p 90  Frequent itemset mining dataset repository   http mi.ua.ac.be/data  J Rabae y  A Chandrakasan and B Nik oli  c  2nd ed Pearson Education 2003 
100 1000 10000 5 50 500 5000 re_sup = 0.12 Eclat-6C \(32nm Eclat-1G \(28nm Apriori-AP 45nm Apriori-AP 32nm Apriori-AP 28nm Computation Time \(s Size of Dataset \(MB Eclat-6C \(32nm Eclat-1G \(28nm Apriori-AP 45nm Apriori-AP 32nm Apriori-AP 28nm GPU fails for re_sup = 0.08 re_sup = 0.08 
GPU fails re_sup = 0.42 re_sup = 0.42 Eclat-6C \(32nm Eclat-1G \(28nm Apriori-AP 45nm Apriori-AP 32nm Apriori-AP 28nm  Computation Time \(s Size of Dataset \(MB Eclat-6C \(32nm Eclat-1G \(28nm Apriori-AP 45nm Apriori-AP 32nm Apriori-AP 28nm GPU fails re_sup = 0.3 re_sup = 0.3 b T100 Figure 11 Performance prediction with technology normalization as a function of input size implementation In contrast the capability of our AP ARM solution scales nicely with the data size since the AP was designed for processing streaming data With the challenge of the big data era a number of other complex pattern mining tasks such as frequent sequential pattern mining and frequent episode mining have attracted great interests in both academia and industry We plan to extend the proposed CPU-AP infrastructure and automaton designs to address more complex pattern-mining problems A CKNOWLEDGMENT This work was supported in part by the Virginia CIT CRCF program under grant no MF14S-021-IT by C-FAR one of the six SRC STARnet Centers sponsored by MARCO and DARPA NSF grant EF-1124931 and a grant from Micron Technology R EFERENCES  J Han 
et al Data Min Knowl Discov Proc of VLDB 94 IEEE Trans on Knowl and Data Eng Proc of SIGMOD 00 Proc of CLUSTER 11 J Supercomput et al ACM Trans Reconìgurable Technol Syst et al IEEE TPDS Proc of IPDPSê14 Proc of SIGMOD 93 Proc of Fifth International Symposium on Highly-Efìcient Accelerators and Reconìgurable Technologies et al Proc of Supercomputing 96 et al Proc of VLDB 07 Proc of PAKDD 03 et al IAENG Intl J Comp Sci et al Proc of DaMoN 09 Proc FIMI 03 Digital Integrated Circuits 
1 10 100 1000 10000 0.1 1 10 100 1000 
a Webdocs 
699 


