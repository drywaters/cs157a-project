Adaptive Bitmap Indexes for Space-Constrained Systems Rishi Rakesh Sinhal Marianne Winslett2 Kesheng Wu3 Kurt Stockinger3 Arie Shoshani3 Microsoft Corporation USA rsinha[microsoft.com 2Department of Computer Science University of Illinois d Urbana-Champaign USA winslett@cs.uiuc.edu 3Lawrence Berkeley National Lab USA kwu,stockinger,shoshani}@lbl.gov Abstract Data management systems for big science often have tight memory and disk space constraints In this paper we introduce adaptive bitmap indexes which conform to both space limits while dynamically adapting to the query load and offering excellent performance So that adaptive bitmap indexes can use optimal bin boundaries we show how to improve the scalability of optimal binning algorithms so that they can be used with 
realworld workloads As the removal of false positives is the largest component of lookup time for a small-footprint bitmap index we propose a novel way to materialize and drop auxiliary projection indexes to eliminate the need to visit the data store to check for false positives Our experiments with real-world data and queries show that adaptive bitmap indexes offer approximately 100300 performance improvement compared to standard binned bitmap indexes at a cost of 5 MB of dedicated memory under disk storage constraints that would cripple other indexes I INTRODUCTION Bitmap indexing for business data was proposed in the 1980s 1 and analysed extensively 
in the 1990s it is included today in data warehousing products Several research groups have examined bitmap indexes for scientific data Both application areas are a good fit for bitmap indexes as they involve high-dimensionality queries over very large data sets in a read-and-append-only environment When we tried to convince scientists to use bitmap indexes in their projects we quickly learned that big science is not willing to accept the space over heads traditionally associated with indexing Bitmap indexes have roughly a 100-150 space overhead for indexed data which is much smaller than most high-performance indexes 5 but is 
not currently acceptable for big science A typical reaction If we can allow efficient access to the raw data at around 20-30 additional storage cost then we can help science a lot Joseph Mohr Dark Energy Survey data system designer Scientists are reluctant to invest in more storage because their data sizes are so large their new instruments can generate in one day as much data as is in a typical business data warehouse Doubling the amount of storage is not an option under current funding priorities In this paper we introduce adaptive bitmap indexes which combine the strengths 
of today's leading approaches to bitmap indexes while greatly reducing their size and retaining excellent performance In the full version of this paper 4  We extend current methods to calculate optimal bin boundaries to create locally optimal bin boundaries in a cost effective manner  We materialize and drop auxiliary projection indexes without ever exceeding predefined memory and disk limits to greatly reduce data lookup costs  We use large synthetic and real workloads to show that for a given space limit adaptive bitmap indexes are much faster than standard binned indexes and are comparable to large multi-resolution bitmap indexes Figure 1 Answering queries 
with an unbinned center binned left or multiresolution right bitmap index II RELATED WORK Figure 1 shows the simplest possible bitmap index BI for attribute A where we store one bit vector bitmap for each possible value of A The length of the bitmap is equal to the number of objects or tuples in the database The objects are numbered serially and if object k has value v for attribute A then the bitmap for value v has a 1 as its kth bit The bitmaps for all other values of A have 0 as their kth bit The resulting set of bitmaps is the 
BI for A and the total number of Is in all its bitmaps is the total number of objects If more objects are added to the database we append more bits to the bitmaps To find all objects whose value for A is in 10,12 we fetch the bitmaps for values 10 and 11 into memory perform a bitwise OR on them then OR the result with the bitmap for 12 For a query that restricts 20 attributes we compute the bitmaps resulting from each individual attribute restriction then AND together those 20 bitmaps to get the final result We can reduce the BI size 
by partitioning the domain of A into bins ranges and keeping only one bitmap per bin Then queries will fetch fewer bitmaps but can have false positives whenever the bin boundaries do not align exactly with the query restrictions Researchers have tried to combine the advantages of binned BIs fast bitmap lookups but slow false positive removal and unbinned BIs no false positives but slower lookups due to having to AND and OR so many bit vectors The resulting approach called multi-resolution BIs MBIs uses a hierarchy of bitmaps 3 At the highest level 978-1-4244-1837-4/08/$25.00 251 2008 IEEE 1418 ICDE 2008 


Bound 30 500-00 100 00 50 00 020 35 0891 Lo eolto 800 2 0 00 5 00 50 00 21ue Spta 23alt ofySDSSf qnueries wt Aedons Bitmap Index      Mlmor Fiue Achtcur fa w-evladpie0imp k of an MBI are WAH-compressed bitmaps whose bins are individual values At the next lowest level each bin contains several adjacent bins from the level above and so on down to level 1 which has the widest bins see Figure 1 To find all obj ects whose value for A is in 1I0 12 we start at level 1 of the MBI Any bins there lying entirely inside the query range have their bitmaps fetched and ORed together If the query range partially overlaps a bin we go to level 2 of the MBI to answer that part of the query and so on until if necessary we have reached the highest level of the MBI MBIs incur no false positives and fetch few bitmaps but do require about twice as much space as when there is exactly one WAHcompressed bitmap for each value in the domain III LocALLY OPTimAL BINS Rotem et al use dynamic programming to place bin boundaries to minimize total query processing time for a particular workload 2 They observe that only the endpoints of the range restrictions in queries query endpoints must be considered to find optimal boundaries They use dynamic programming to find optimal bins for a query workload and data distribution in O\(n 2 time where n is the number of endpoints Their approach does not scale to large workloads In the full version of the paper we solve the scale-up problem by first using a fast heuristic approach to choose the number of bins and assign their boundaries The resulting structure is the lowest level of a new MBI Then for each bin at the lowest level we compute a set of bin boundaries that are optimal within that bin to serve as bins at the next highest level We can do this efficiently because only a small fraction of the workload will have query endpoints in that particular bin so n is small We repeat the process with the other bins at the first level of the index then generate additional levels in the same manner This is the locally optimal NMIB or LOMBI IV EXPLOITING QUjERY LOCALITY Even with a LOMBI the cost of removing false positives is still extremely high as shown by experiments presented later Fortunately scientific workloads exhibit spatial and/or temporal locality with respect to the time an observation was made We exploit this locality to reduce workload cost The Sloan Digital Sky Survey SDSS is an astronomy survey collecting images of the sky and generating a map of a million galaxies and quasars In SDSS spatial locality takes the form of similar values for the right ascension RA and declination DEC coordinates used to describe the location of obj ects in the sky Figure 2 shows a graph of the RA values used as query endpoints Y axis during 18 months of SDSS queries X axis Left endpoints are shown in dark blue and are mostly obscured by the magenta-colored right endpoints The graph shows that consecutive queries tend to request very similar values of RA except for brief periods We exploit this locality to reduce the cost of false positive removal When we go to the data to check for false positives we create an auxiliary projection index PI for that particular bin consisting of a objectID attributeValue pair for each object in the bin and sorted on attributeValue A subsequent query whose endpoint e falls in the same bin can do binary search for e in the PI all objects in the PI beyond e are false positives and can be eliminated without visiting the data Scanning a PI is much quicker than parsing a data file and searching for the objects belonging to a particular bin Lower Bound ne-\(B Asshw i igre3 a datiebimp3ndx\(AI cosit o LMI ls mal e o Is s6nAB ano ever exed h ds spc1 etitosipsdb cetss we craete 2OB o hti i1lgtl4mlerta h spcelii heletve ds sac1i5urdik1ahe\(D con Rsoltrans ecnmtraieol ml rion o h I We storedithe RAevalueso asitgrsfion 0,3,0000].Th with re1.6 108cobjects.o Fworlve adrepriesentmativdexwoklAd,Iwe thehow binnngFagorithm and thereapineingm15 quderie forI tenssting We use aOB dlusalsal coreP2.4GAs machne wBIt 1anGB mvemry anced 2t50 GBs dskaers,twicthibndwidthse uptb10M scetsts The creat LOMB hadB 2o level withi 1000tl bismatlleve 1ha 27 MB 15,000 bins aetolvel 2is 120e MB isace\(D Csdonsilde the effect ofe MClasizel onathe ruGimen four RAtorag cnthe a5,00tetqris we a aeithlthe ABIy smlmte tac250o of thePl datae lesizt11M igr hw h result uedPs foro6 MC sizC 400 Upper o aes.oo 1419 


i r0 0 5 10 25 50 1X 0 5 S 25 50 1X D Rotem K Wu Optimizing candidate check costs for bitmap indices In CIKM 2005 a 2level R R Sinha and R R Sinha and For each MC size one X axis entry is for a configuration with both MC and DC and the other has just MC The Y axis for the bar graph shows the time to answer the queries The Y axis for the line graph shows the percent of queries answered from MC and if present DC DC size is 15 MB the amount of disk space left after creating the LOMBI readFP time to read data file to create PIs not already cached writePI time to move overflow PIs from MC to DC readPI time spent moving PIs from DC to MC as needed checkPI time to parse PIs in MC to filter out false positives readBV time to read bit vectors from disk entirely IPO calcBV time spent ORing and ANDing bitmaps no 11O Mem rory iUthe Onhl MarnoC ryor Mem ory ache MC Si ze 100 MB Figure 4 Time to run all P O'Neil Model 204 architecture and performance In Proceedings of the Conference on High Performance Transaction Systems 1987 K Stockinger and K Wu E J Otoo and A Shoshani On the performance of bitmap indices for high cardinality attributes In VLDB 2004 1420 M Winslett Multi-resolution bitmap indexes for scientific data ACM TODS 32:3 August 2007 M Winslett Adaptive bitmap indexes Submitted for publication and available at dais.cs.uiuc.edu/dais/sdm/sdmpubs.php Di k ache 60 E 40 30 4 20 10 L 4it P1B ireadPi 0 0 RA queries in the 15,000 test query log with ABI and 25 space limit The line shows the percent of queries answered without visiting the data The Figure 4 workload times are completely dominated by the time spent visiting the data to find false positives readFP any increase in readFP also increases total run time Such visits are unavoidable when the index has no single-value bins Query locality gives much faster answers once PIs are cached Figure 4 run times improve a lot as MC increases from 0 to 5 MB regardless of DC size As MC grows beyond 5 MB performance continues to improve if there is no DC but plateaus if there is DC This is because the second largest component in MC-without-DC run times is computeBV while in the MC+DC version it is writePI and readBV whose contention for the disk arm and space in the file system cache slows down both components In the full version of the paper we present additional experiments showing that this DC is too small to benefit performance and that any extra disk space available for DC is better spent increasing the LOMBI size With no DC and no MC the average time to answer one query in Figure 4 is 4 seconds From experiments in the full version of the paper we know it takes 7.1 seconds on average to answer a query with a cold file system cache so the 4 second response time reflects very positively on the file system caching algorithms The file system cache would be much less effective in a production run however because this experiment only involves 644 MB of RA on a machine with 1 GB memory A production SDSS run devotes file cache space to many other less popular attributes fetched by concurrent queries with memory orders of magnitude smaller than the recently-accessed data Thus MC and even DC will be very important in production runs For a clearer picture of the expected file system cache behavior in a production system consider the following analysis The first check of a bin for false positives must read the corresponding objects from disk If the file system cache does not already have those objects cached as expected in production runs the average query execution time will be close to 7 seconds For queries whose PIs are already in MC the query time will be 1 second Thus even with 5 MB MC and no DC we can answer 4500 of the queries in 1 second and 5500 of the queries in 7 seconds This means that ABI provides a considerable advantage for the 4500 of queries answered from the MC VI CONCLUSIONS In this paper we introduced adaptive bitmap indexes ABIs as a way to satisfy scientists demands for a high performance index with a tiny footprint An ABI includes a locally-optimal multi-resolution bitmap index and a set of auxiliary projection indexes PIs that are materialized while removing false positives from current query answers then kept in an LRU cache in memory and/or disk for use in answering subsequent queries The PIs greatly reduce the cost of false positive removal which is the dominant factor in query performance The full version of this paper 4 includes much material omitted here In particular we present the algorithms for building adaptive bitmap indexes and include a complete set of experiments explorations of query performance with both RA and DEC for a variety of space limits and with synthetic queries and/or data as well as the SDSS workload We also show that an adaptive bitmap index for RA with a 5000 space limit performs 32 faster on the SDSS workload than an ordinary multi-resolution bitmap index twice its size In other words space limits need not harm lookup performance and can actually improve it by reducing CPU costs which are high for bitmap index lookups Acknowledgements This work was done while R Sinha was at the University of Illinois This research was supported by a Computational Science Fellowship by the Department of Energy under subcontracts B341494 DOE DEFC0201ER25508 and DE-AC03-76SF00098 and by NSF grant NSF ACI 02-05611 REFERENCES 1 2 3 4 5 


expectations are ambiguous or unrealistic. In this situation, the hardworking efforts of people go unrecognized. The “order taker” mindset stands in the way of IT sitting at the table as an equal partner offering valid perspectives on the best way to deliver real value making and meeting commitments, and delighting our business partners  3.2 IT Investment Change Management    Two of the inherent mindsets underlying the legacy processes of managing change in the IT investment agenda are “maximize utilization” and “get it done  The “maximize utilization” mindset is characterized by the notion that 100% utilization of people means maximum efficiency and maximum productivity. Less than 100% allocation for a person means an opportunity to work on another project. Slack time is bad; it means that a person has unproductive time  To leverage our people who are most skilled and have domain expertise, we tend to over-allocate them; they even become unavailable to even casually help others Too much time is spent transitioning from one task to another, reducing overall productivity and quality  Although difficult to prove, striving to achieve maximum efficiency can reduce effectiveness and decrease the ability to respond to change. Slack time actually improves productivity by providing time to think 9 u cin g ti m e to t h in k i m p acts th e creativ it y a n d  quality of the results we are able to deliver  When we over-allocate our skilled resources we cause costly task-switching.  This thrashing results in lost productivity and delays product delivery ou r experience, this loss of time is not accounted for in work estimates and puts even more pressure on our best people to deliver. People become increasingly exhausted decreasingly satisfied at work, and are at risk for burnout  The “get it done” mindset is characterized by the notion that there is a way to accomplish our goals, and our job is to find it. This is a derivative of the “order taker” mindset - our business partners have high expectations, and we must find a way to meet them. We cannot walk away from a request and leave funding on the table. When the going gets tough, the tough get going  The “get it done” mindset sometimes causes us to believe that a best-case plan will succeed. Over the course of the year, we consume our contingency and compromise our ability to deliver. We find ourselves “in the box” and it becomes easy to delude ourselves about the situation. The recognition of situational reality may be delayed until late in the year as we never give up; in these situations we lose credibility with our business partners  3.3 Governance and Oversight    Our processes and behaviors for feedback and control are second-nature to us; as a regulated energy company part of our genetic predisposition is to ensure our work is well-engineered and carefully monitored  Our traditional approach to IT governance shared this control through data” mindset, characterized by the notion that we seek more information and greater details When agile projects flourished and propagated throughout our portfolios, this instinctive need for more data at a portfolio level was brought into question  On agile projects we did not use detailed four-level work breakdown structures, earned value metrics, and fully resource-loaded Gantt charts.  Rather, our burn-up charts, value velocity trends, and team engagement metrics [11 p r o v id ed actio n a b l e in si g h ts   Agile metrics did not resonate with the legacy “control through data” mindset where complex data was needed to make up-front decisions and even more exhaustive information was required to control change over time  The legacy mindset resisted these new factors for project success and new gauges of progress. This was especially prevalent at the project portfolio level where the legacy mindset was comfortable with its ability to understand some of its projects and was frustrated with its inability to understand others  Finally, the “control through data” mindset asserted we could plan out a full year’s slate of projects; this was turned on its head as agile projects ebbed and flowed based on evolving business needs over time  4. Actions Taken and Results Achieved    In this section we discuss the changes initiated to adjust the legacy processes and change mindsets related to IT funding, managing change, and governance. Here we describe the strategies adopted to address the underlying beliefs and to shape the observable behaviors  The previous sections explored three legacy processes and summarized the underlying legacy mindsets that impacted our ability to effectively deliver value; in the subsequent section we characterize our intentions for further enhancements and improvements  4.1 IT Investment Funding    To address the opportunities related to the IT funding and business case development processes in light of the widget engineering” and “order taker” mindsets, we tackled the business case development process  Our strategy was to change the business case development process to provide more flexibility into how 
255 


we managed individual projects and to extend that flexibility to the project portfolio  The goal was to establish a common understanding that a business case was ideal for high-level problem and opportunity statements, with a funding level reasonable to address the need and a general implementation timeframe This approach allows flexibility at a project level as well as a project portfolio level to adjust scope, dollars, or time as an appropriate solution becomes clearer  We established a process improvement team under the auspices of our Software Engineering Process Group SEPG\2  T h e g o al o f th is tea m  w a s to reco n c ile t h e business case development approaches in use, identify the best aspects of each, establish a standard process, and drive toward a common understanding of the approach  We found it a challenge to reconcile viewpoints about the level of detail in the various business case processes Those who used a more detailed approach did so because of a perceived need for specificity \(the “widget engineering” and “order taker” mindsets at work  The work group was successful in their efforts to define a common process and work products, but many of us continue to drive for much lower levels of detail  4.2 IT Investment Change Management    Our approach to managing the set of IT investment projects, coupled with our “maximize productivity” and get it done” mindsets, offered a significant improvement opportunity. We explored insights to leverage lean techniques to better manage the flow of work  To raise awareness and to educate our leadership team we retained Mary Poppendieck, a leading expert on the application of lean manufacturing techniques to IT work  ry prov i d ed u s  w i t h i n s i gh t abou t ou r part i c u l ar situations, and initiated dialog amongst the leadership team about how we could use lean techniques. This was generally well received by our leadership team: Mary’s perspectives about thrashing and applying the theory of constraints to manage the flow work were particularly compelling  At about the same time, we developed and initiated the use of a new portfolio management model in one of the IT groups serving a business unit. We setup a simple model to represent our capacity, the projects that were on the agenda, and the available resources for these projects Similar to agile project planning, we based this portfolio management model on the capacity of our available staff and would run no more projects than the level our staff could support. We recognized it was not feasible to respond to unplanned change by acquiring new contractors to reactively form new project teams  Rather than plan out the entire year, the plan looked out three months and initially allocated our staff to get the most important set of projects started first. We placed the remainder of the projects on a backlog list with a projected start date based upon the expected availability of staff due to completion of in-flight projects  We strove to ensure that the people were focused only on their areas of domain expertise by forming teams of domain experts, using a queue and pull work system to release work to the domain team, and to develop more domain expertise over time  We explained the new portfolio management model to the affected business partners. We also explained that we were limited in what we would take on because of the people constraint. As engineers, they understood the notion of a system constraint, and expressed willingness to work with us using the new model. As the year progressed, the business partners began to realize they were not going to get everything they asked for. This drove healthy conversations within the business unit and with other affected constituents to identify and rally around the most important priorities for the business as a whole \(rather than just a single business unit  4.3 Governance and Oversight    The legacy mindset of “control through data encouraged us to measure success with traditional metrics, and to use this information to control projects and portfolios  We sought to shift our behaviors and processes from Big Plan Up Front” \(BPUF\ to rolling wave planning with clear, well-understood decision gates along the way Specifically, we wanted to employ our company’s FourGate, Nine-Step process for IT projects, each gate having deliberate intentions to be satisfied along the way  First, we brought the implicit gaps within our portfolio management and funding models into the open through a series of retrospectives and staff meetings  From those discussions we sought to address the ways in which the portfolio of projects would be measured recognizing that each project tailored our standard project methodology based on its context and specific challenges  Second, we introduced terminology and concepts from lean manufacturing to help us better understand our constraints and how we could reorganize the way we prioritize our commitments and fund our work  Principles like “sustainable pace” and “make the main thing the main thing” came into focus and we realized that we needed to manage the queue of projects within a portfolio and across the business units based on our scarce resources and subject matter experts, rather than to spread those resources across many parallel initiatives  Thus, we viewed our key resources as platform teams and began managing the queue of pending projects for those teams. As a team completed one project, it began work on the next most important project for its platform 
256 


 Over time we successfully moved from the “control through data” mindset, which sought greater amounts of detail, to an “enable and ensure” mindset, which sought to more effectively manage each platform team given its context and operating parameters  5. Sustaining Results and Moving Forward    In this section we characterize our intentions to sustain the progress we have made thus far, and to further embrace change as we refine our processes and mindsets related to IT funding, managing change, and governance  Previous sections explored three legacy processes summarized the underlying legacy mindsets, and discussed the changes that we inculcated into the organization; in the concluding section we offer some of our biggest lessons learned and recommendations  5.1 IT Investment Funding    One of our overarching strategies in IT is to leverage the DTE Energy Operating System, a combination of lean and Six Sigma thinking, seeing, and doing tools and techniques based upon the Plan-Do-Check-Act cycl The company has invested in, and seen benefits from, this approach by training and rolling it out across the organization  For the business case, we are implementing the Operating System’s Project Charter tool. This tool provides a one-page overview of a proposed project. For the IT business case process, we are using the Project Charter as a means to provide “just enough” description of an IT investment opportunity and to defer definition of a formal business case until the confidence level for commencing the project becomes high  Previously, our standard was to transform the business case document \(and all its details\to a project initiation document. This document tended to be redundant with the business case and other standard documents \(like project budget, timeline, risks, etc.\ a recent process improvement we effort identified the opportunity to phase out the project initiating document and to further leverage the Operating System’s Project Charter tool. We will conduct retrospectives and After Action Reviews \(another Operating System tool\o identify opportunities for further refinement  These actions will move us toward “right sizing” the amount of detail in each business case, thus enabling flexibility to adapt and evolve a solution over the life of the project to better meet the real needs and deliver more value to our business partners. A smaller investment in developing the business case should also enable more flexibility at the portfolio level as there will be less invested interest in the business case document itself  5.2 IT Investment Change Management    Our revised portfolio management model directly addresses our strategic IT goal to broaden our business alignment. Our intention is to further leverage our portfolio management model on two fronts: first, by further refining the model and applying it in the business area for which it was first developed, and second, by leveraging our experience for other IT groups and the business areas they support  To further refine the portfolio management model, we are developing a systematic model of the portfolio production line. Our goal is to see more clearly how the system of delivering projects actually works. Managing the project portfolio first seemed like controlled chaos then like each project was a special situation. We now realize we can view portfolio management as a systematic process. Our goal is to develop a model with simple measures that we can use to quantitatively identify where bottlenecks exist. Then, we can apply classic theory of constraint techniques to further optimize the system  We also hold bimonthly retrospectives to review what’s working and what’s not, and make decisions about what we’re going to do differently. Going forward, we intend to keep revisiting our principle that each person works on a single project \(or task\ntil it is complete  Serendipitously, we are encountering similar problems in other IT groups and business areas. We are working on applying these portfolio management approaches in one additional area at the moment. We are also planning how we will roll out these approaches on a broader scale to other IT and business groups as well  5.3 Governance and Oversight    In our approach to portfolio governance, we moved from a “control through data” legacy mindset to a “enable and ensure” mindset, where we more effectively understood and dispatched queues of work by constraints  One key enabler was to better identify our constraints most prevalently, technical and business expertise\nd more effectively balance our queue of work to the capacity of those constraints  Going forward, we will continue delivering results by continuing to improve how we manage our constraints in the areas that are already using this approach  For our areas that have not yet made this transition, we will manage the culture change in an intentional manner We seek to avoid a “big bang” approach; instead, we will use a consistent pattern - standardizing terminology identifying constraints, prioritizing and re-sequencing the work, and so on  A second enabler to this mindset shift was to embrace a suite of fact-based measures that gave us the insights we 
257 


needed without force-fitting a comprehensive suite of metrics upon all projects and programs  Going forward, we will continue to remind ourselves that the impulse to dive deeper into the details is one of the more prevalent legacy mindsets, to remain aware of when we slip into that old habit, and to challenge ourselves to take a step back rather than a step down  6. Lessons Learned and Recommendations    To those who seek to foster an agile approach to project portfolio funding, change management, and governance, the following reflections and suggestions may provide some degree of utility  First, be aware of your organization’s processes and the mindsets that shape those processes. Rather than simply performing a process because “that’s just how it is,” challenge the underlying assumptions – this will either reinforce its value or prompt meaningful change  We found that agile principles related to process improvement may be of additional benefit in this context Specifically, the habit of introducing frequent, small improvements \(in an incremental and iterative manner tends to ensure that processes do not become too stale  Second, be engaged in your organization’s leadership communities \(both IT and business\her than hoping they recognize their own legacy processes and mindsets guide them to identify what is working well and where problems exist, and to introduce change in a deliberate and intentional manner  We found that quite often, leaders were too close to the situation and its complexity \(accumulated over the years\ to see any other way to operate. We created a safe and enabling environment to take a step back and view those complexities from alternative perspectives \(such as constraints\ and proceed with a fresh set of ideas  Third, be patient in rolling out an agile approach to funding, change management, and governance across a corporate enterprise.  Rather than change everything all at once, select and collaborate with one or two business units first, reflect on the results, and then solidify those gains while branching out to another set of business units  We found that while our business units had variations on the same themes of legacy processes and mindsets each was different enough that a single approach would be inadequate. By adopting and adapting lean and agile techniques within each business unit \(and in general, one unit at a time\we enabled agile funding and portfolio management capability and improved our business-IT alignment along the way  7. References    g ile A l l i an ce Manifesto for Agile Software Development http://agilemanifesto.org   e r, S t ev en W Formalizing Agility: An Agile Organization’s Journey toward CMMI Accreditation  Agile 2005 Proceedings, IEEE Press, 2005   e r, S t ev en W Formalizing Agility, Part 2: How an Agile Organization Embraced the CMMI Agile 2006 Proceedings, IEEE Press, 2006   a k e r, Stev en W an d J o s e ph C  T h o m as  Agile Principles as a Leadership Value System: How Agile Memes Survive and Thrive in a Corporate IT Culture  Agile 2007 Proceedings, IEEE Press, 2007   atis  c om  Business-IT Alignment  http://whatis.techtarget.com/definition/0,,sid9_gci118549 4,00.html   g ile P r oj ect L eaders h ip Net w or k   Declaration of Interdependence http://www.pmdoi.org   lle m a n  Gle n  Agile Program Management: Moving from Principles to Practice Agile Product & Project Management, Vol. 6 No. 9, Cutter Consortium September, 2005   lle m a n  Gle n  ibid    a rco, T. 20 02.S l ac k  Getti n g P a s t Bu rn o u t  Busywork, and the Myth of Total Efficiency. Broadway Publishing, New York   Pop p en di eck M. 2008 Thrashing: What it is, what causes it, and what to do about it  www.agilebazaar.org/DeepLean/DeepLean-2%20%20Poppendieck%20-%20Thrashing%20-%20color.pdf   B a k e r, Stev en W  an d Am bros e, Stev e n B   Measuring Engagement and Predicting Project Performance: The TEAM Score Cutter IT Journal Volume 18, No. 7, 2005    o w l er, P. an d R i f k i n  S   Software Engineering Process Group Guide Software Engineering Institute 1990   Pop p en di eck M. an d Poppen d i eck T   Implementing Lean Software Development: From Concept to Cash The Addison-Wesley, 2006   ean  L earn i ng C e n t e r L ean a n d DT E: L e a n  Transformation Reaps Millions In Savings For DTE Energy http://www.leanlearningcenter.com/aboutus/our_experien ex__dte_energy.cfm 
258 


 8 This same couple of algorithms is also used 200  for module wear identification, hence helping the maintenance workflow 200  for the sensor failure analysis 200  and for any other system that need to get rid of dependencies or external conditions  R EFERENCES  1  H. Hotelling, \223The generaliza tion of Student\222s ratio\224, Ann Math. Statist., vol. 2, pp 360-378, 1931 2  G. E. P. Box, \223A general dist ribution theory for a class of likelihood criteria\224 Biometrika, vol. 36, pp 317-346, 1949 3  T. W. Anderson, \223Asymptotic theory for principal component analysis\224, Ann. Ma th. Statist., vol. 34, pp 122148,  1963 4  K.V. Mardia, J.T. Kent, and J.M. Bibby.. \223Multivariate Analysis\224, Academic Press, 1979 5  B. R. Upadhyaya at al., \223Multivariate Statistical Signal Processing Technique for Faul t Detection and Diagnosis\224 ISA Transactions, vol. 29 n\2604, pp 79-85, 1990 6  V. N. Vapnik, \223The Nature of Statistical Learning\224, Springer Verlag \(NY\95 7  A. Smola and B. Sch\366lkopf, \223O n a kernel based method for pattern recognition regression approximation and operator inversion\224, Algorithmica, 1998 8  R. Azencott, \223Proc\351d\351 de surveillance d\222un syst\350me\224, Patent EP01170650A1, Miriad Technologies, 2002 9  R. Azencott, \223A method for monitoring a system based on performance indicators\224, U S. Patent 6594618B1, Miriad Technologies, 2003 10  J. Lacaille, H. Dubus 223Defectivity Analysis by a Swarm of Intelligent Distributed Ag ents\224, AEC/APC 2005, Palm Spring \(CA 11  J. Lacaille, \223Mathematical Solution to Identify the Causes of Yield Deterioration - A defectiv ity data based solution with an emergent computing tec hnology\224, ISMI 2005, Austin TX 12  M. Zagrebnov, J. Lacaille 223Building a Robust Model for Process Control Using Advanced Mathematical Techniques\224 AEC/APC tutorial 2006, Aix en Provence \(France 13  J. Lacaille, \223Advanced Fault Detection\224, AEC/APC tutorial 2006, Denver \(CO 14  J. Lacaille, M. Zagrebnov, \223A statistical approach of abnormality detection and its applications\224, AEC/APC 2006 Denver \(CO 15  J. Lacaille, \223How to automatically build meaningful indicators from raw data\224 AEC/APC Palm Spring 2007 16  J. Lacaille, M. Zagrebnov, \223A n Unsupervised Diagnosis for Process Tool Fault Detection: the Flexible Golden Pattern\224 IEEE Transactions on Semi conductor Manufacturing Volume 20, Issue 4, Nov. 2007 Page\(s\ \226 363 17  J. Lacaille, \223Global Predictive Monitoring System for a Manufacturing Facility\224 U.S. Patent 20080082197A1  B IOGRAPHY  J\351r\364me Lacaille is senior expert in algorithms for Snecm a. He joined the company in 2007 with responsibility for developing a health monitoring solution for jet engines. J\351r\364me has a PhD from the Ecole Normale Sup\351rieure, France in Mathematics. J\351r\364me has held several positions including scientific consultant and professor. He has also co-founded the Miriad Technologies Company, entered the semiconductor business taking in charge the direction of the Innovation Department for Si Automatio n \(Montpellier - France\ and PDF Solutions \(San Jose CA\. He developed specific mathematic algorithms that where integrated in industrial process. Over the course of his work, J\351r\364me has published several papers on integrating data analysis into industry infrastructure, including neural methodologies and stochastic modeling. J\351r\364me can be reached at jerome.lacaille@snecma.fr    


ogy Results of this paper can be directly useful to the Objective Gateway program of the Air Force where several Battlefield Airborne Communication Nodes BACNs and their ground counterparts the Rapid Attack Information Dissemination Execution Relay RAIDERs The goal of the Objective Gateway program is to provide networking technology to the forward edge of the battlefield and create a high-capacity airborne communication backbone Future Work This paper is the first step towards developing a mission planning toolbox for the airborne network deployment problem A few further research directions could be accounting for link disruptions due to airborne platform banking expanding the optimization search space to include non-circular or tilted loiter orbits accounting for terrain effects providing coverage to mobile airborne nodes that are involved in a mission tactical edge networks planning so as to optimally use satellite communication when certain airborne links are inactive developing multiple tiers of airborne backbones located at different elevations and incorporating topology control such that the airborne nodes can change power levels thus radio range during periods where airborne topology is sparse ACKNOWLEDGMENTS The authors would like to thank Maneesh Varshney and Prof Mario Gerla for insightful discussions on the subject matter of this paper This work was supported under Air Force phase I SBIR grant number FA8750-07-C-0158 7 K Schroth and D Kiwior Interdomain Routing for Mobile Nodes Proceedings of the Military Communications Conference 2007 to appear 8 E G I D Kiwior and S V Pizzi Quality of Service QoS Sensitivity for the OSPF Protocol in the Airborne Networking Environment Proceedings of the Military Communications Conference 2005 9 L V J Cooley 0 Huang and S McGarry Mobile Airborne Networking Experience with Paul Revere Proceedings of the Military Communications Conference 2005 10 K Q Weinberger and L K Saul Unsupervised Learning of Image Manifolds by Semidefinite Programming International Journal of Computer Vision vol 70 no 1 pp 77-90 2006 11 S Boyd and L Vandenberghe Convex Optimization Cambridge University Press 2006 12 J Lfberg Yalmip A toolbox for modeling and optimization in MATLAB in Proceedings of the CACSD Conference Taipei Taiwan 2004 Online Available http://control.ee.ethz.ch joloef/yalmip.php 13 R A Horn and C R Johnson Matrix Analysis Cambridge University Press 1985 14 N Megiddo and A Tamir New results on the complexity of p-center problems SIAM Journal on Computing vol 12 no 4 pp 751-758 November 1983 REFERENCES 1 T A Kostas and T G Macdonald A Methodology for Evaluating and Planning Future Airborne Networks Proceedings of the Military Communications Conference 2004 2 R Ramirez Link Management in the Air Force Airborne Network Proceedings of the Military Communications Conference 2005 3 Y Wang and Y J Zhao Fundamental Issues in Systematic Design of Airborne Networks for Aviation Proceedings of the IEEE Aerospace Conference 2006 4 B Epstein and V Mehta Free Space Optical Communications Routing Performance in Highly Dynamic Airspace Environment Proceedings of the IEEE Aerospace Conference 2004 5 M Dehkordi K Chandrashekhar and J S Baras A placement algorithm for enhanced connectivity and reliability in wireless ad-hoc networks in Conference on Future Networking Technologies CoNEXT Toulouse France October 2005 6 D Kiwior and L Lam Routing Protocol Performance over Intermittent Links Proceedings of the Military Communications Conference 2007 to appear 9 


 10 D e L one  W  H  a n d Mc L e a n E.R   T he D e L one a nd McLean Model of Information Systems Success: A Ten-Year Update Journal of Management Information Systems Vol. 19, No. 4, pp. 9-30, 2003 11 D e nz i n N  K  a nd L i nc o l n, Y  S Handbook of Qualitative Research Sage, Thousand Oaks, CA 1994 1 Di n een  B  L i n g  J  A s h  S  an d Del V ecch i o  D   Aesthetic properties and message customisation Navigating the dark side of web recruitment  Journal of Applied Psychology Vol. 92, No. 2, pp. 356-372 2007 13 Fe l d m a n, D  a nd K l a a s B Inte rne t j o b h unti n g  A  field study of applicant experiences with online recruitment Human Resource Management Vol. 41 No. 2, pp. 175-201, 2002 14 G a la nk i, E The decision to recruit online: A descriptive study  Career Development International  Vol. 7, No. 4, 2002 1 G u eu t a l  H G  an d S t on e D  L    The Brave New World of eHR: Human resources management in the digital age Jossey-Bass, San Francisco, 2005 16 H a da y a  P  a nd Et hie r J  Online purchasing of simple goods: the impact of e-service quality as provided by electronic commerce functionalities  Proceedings of the 41 st Hawaii International Conference on System Science 2008 1 G r  n r oo s C   Service Management and Marketing Customer Management in Service Competition 3rd Edition, Wiley & Sons, Chichester, 2007 18 Ho llow a y  B.B. a nd Be a tty S.E Satisfiers and Dissatisfiers in the Online Environment: A Critical Incident Assessment  Journal of Service Research  Vol. 10, No. 4, pp. 347-364, 2008 1 Kl ei n H K and M y ers M  D  A S e t o f P r i n ci p l es for Conducting and Evaluating Interpretive Field Studies in Information Systems MIS Quarterly Vol 23, No. 1, pp. 67-93, 1999 20 Kri ppe nd orf f  K Reliability in content analysis some common misconceptions and recommendations  Human Communication Research Vol. 30, pp. 411433, 2004 21 L e e  I The evolution of e-recruiting: A content analysis of Fortune 100 career web sites  Journal of Electronic Commerce in Organizations Vol. 3, No. 3 pp. 57-68, 2005 22 Le e  T W   Using qualitative methods in organizational research Sage, Thousand Oaks, 1999 2 Ngw e n g a m a O K and A  S  L ee  Communication Richness in Electronic Mail: Critical Social Theory and the Contextuality of Meaning  MIS Quarterly  Vol. 21, pp. 145 167, 1997 2 L i even s F  an d Harris  M   Research o n I n tern et  recruiting and testing: current status and future directions, In: Cooper, C., Robertson, I. \(Eds International Review of Industrial and Organizational Psychology Vol. 18, pp. 131-165, 2003 25 L i n, C S. a nd W u  S Ex pl oring t h e im pa c t of on line  service quality on portal site usage Proceedings of the 35th Hawaii International Conference on System Science 2002 26 Mc Cu ne J  C Good help is hard to find  Management Review Vol. 86, No. 6, pp. 30-31, 1997 27  Mile s   M.B. a nd H ube rm an, A  M Qualitative data analysis: An expanded sourcebook Thousand Oaks CA, Sage, 1994 28  P a rasu ram a n  A Zeith am l, V  A  an d Mal h o t ra A ES-Qual: A Multiple-Item Scale for Assessing Electronic Service Quality Journal of Service Research Vol. 7, No. 3, pp. 213-233, 2005 29 P a rry  E Drivers of the adoption of online recruitment an analysis using diffurion of innovation theory In Bondarouk, T.V., Ruël, H.J.M. \(Eds\E-HRM in theory and practice. Elsevier, Amsterdam, 2008 30 a tto n  M.Q  Qualitative research and evaluation methods Thousand Oaks, CA, Sage, 2002 31 R odg e r s  W N e g a s h S. a n d Suk  K  The moderating effect of online experience on the antecedents and consequences of online satisfaction  Psychology Marketing Vol. 22, No. 4, pp. 313-331, 2005 32 R o w l e y J An Analysis of the E-Service Literature Towards a Research Agenda  Internet Research Vol 16, No. 13, pp. 339-359, 2006 3 Ru st  R T  an d Kann an   P  K   E-Service: A New Paradigm for Business in the Electronic Environment  Communications of the ACM Vol. 46, No. 5, pp. 3742. 2003 34  Sa c h a f P  a n d Oltm a nn, S M Equality and e-service quality  Proceedings of the 40 st Hawaii International Conference on System Science 2007 35 Sa n t os, J E-service quality A model of virtual service quality dimensions  Managing Service Quality Vol.13, No. 3, pp. 233-246, 2003 3  S m i t h  A  D an d Rup p W  T    Managerial challenges of e-recruiting  Online Information Review Vol. 28 No. 1, pp. 61-74, 2004 37 St one D  L Sto n e Rom e r o, E. F  a nd L u k a s z e w s k i  K Factors affecting the acceptance and effectiveness of electronic human resource systems  Human Resource Management Review Vol. 16, No. 2, pp 229-244, 2006 38 T ong J D u f f y  V Cros s  G  T s ung F. a nd Y e n, B Evaluating the industrial ergonomics of service quality for online recruitment websites  International  Journal of Industrial Ergonomics Vol. 35, pp. 697711, 2005 39  Va n Ma a n e n J  A n End of I nnoc e n c e T h e Ethnography of Ethnography," In: Representation in Ethnography, J. Van Maanen \(ed.\ge, Thousand Oaks, CA, pp. 1-35, 1995 40 W o lf inba rg e r M. a nd G ill y  M.C eTailQ Dimensionalizing, measuring and predicting etail quality  Journal of Retailing Vol. 79, No. 3, pp. 183198, 2003 41 W o lte rs M The Effectiveness of job board Internet Recruitment Proceedings of the First European Academic Workshop on e-HRM, The Netherlands 2006 4 Z u sm an  R an d L a n d i s R   Applicant preferences for web-based versus traditional job posting  Computers in Human Behaviour Vol. 18, pp. 285-296, 2002  Proceedings of the 42nd Hawaii International Conference on System Sciences - 2009 10 


Alan Little is the MEDLI Project Manager at NASA's Langley Research Center He previously served on a variety of earth remote sensing missions and recently served as the NASA-CNES interface manager and the payload assembly integration and test manager on the joint NASAICNES CALIPSO Mission that was launched in April 2006 He has a MS in Optics from the University of Rochester Neil Cheatwood earned B.S MS and Ph.D degrees in aerospace engineering from NC State University He has played key roles in a number of NASA's planetary atmospheric flight programs and is a nationally recognized expert in aerosciences and flight mechanics for planetary entry systems He is currently serving as the Hypersonics Project Scientist for the Fundamental Aeronautics Program with NASA's ARMD Dr Cheatwood is also the Principle Investigator for the Mars Science Laboratory Entry Descent and Landing Instrumentation MEDLI project In recent years he led NASA LaRC efforts to develop inflatable aeroshell technologies He served as CoInvestigator to Claude Graves of NASA JSC on the NASA ESMD ESR&T Inflatable Aeroshell and TPS Development IA TD Project He served as the Principle Investigator for NASA LaRCs Inflatable Reentry Vehicle Experiment IRVE as well as the follow-on Program to Advance Inflatable Decelerators for Atmospheric Entry PAI-DAE Dr Cheatwood was responsible for aerodynamic databases of Stardust Mars Microprobe Genesis and Mars Exploration Rovers He has also contributed to the Mars Global Surveyor and Mars Sample Return flight projects Dr Cheatwood is an AIAA Associate Fellow and the principle author or co-author of 60 technical publications in the fields of fluid dynamics atmospheric entry and systems engineering Jeff Herath serves as the Lead Systems Engineer and Chief Engineer for the Mars Science Laboratory Entry Descent and Landing Instrumentation MEDLI He also serves as the Assistant Head of the Atmospheric Flight and Entry Systems Branch AFESB to plan direct and coordinate Branch activities in the areas offlight and entry systems research and development Mr Herath previously was the Acting Assistant Branch Head for Electronic Systems and served as the branch leadfor new business activities proposals and their development He was also the Principal Investigator PI for the Radiation Tolerant Intelligent Memory Stack RTIMS Project which successfully developed and demonstrated an in-flight reconfigurable radiation tolerant stacked memory array He co-founded Vianix LC a company developing and licensing voice compression technology and served as its Chief Technology Officer He developed the company's voice compression technology and was responsible for all research  development engineering personnel and production efforts He has 6 patents As Manager of Hardware Development at Arc Second Inc he designed and built a unique laser based three-dimensional positioning system which opened new markets for the company At E-Systems he successfully completed several military avionics programs and payload that were classified and consisted of system box and board level designs Michelle Munk has been a NASA employee for nearly 20 years first at the Johnson Space Center then at the Langley Research Center She has been involved in Mars advanced mission studies for many years both robotic and human contributing interplanetary trajectory analysis and entry and descent analysis She has managed the delivery of International Space Station hardware and was on the Mars Odyssey aerobraking operations team In 2002 Ms Munk accepted a detail assignment to become the Lead Engineer for Aerocapture Technology Development under In-Space Propulsion at Marshall Space Flight Center She managed the technical work of ISP Aerocapture for nearly 5 years before becoming the Project Area Manager and returning to Langley in 2007 Ms Munk is also a subsystem leadfor the Mars Science Laboratory Entry Descent and Landing Instrumentation MEDLI project and contributes to other NASA projects developing entry system technologies She has a BSAE from Virginia Tech and completed graduate coursework at the University of Houston Frank Novak is an Assistant Branch Head for Remote Sensing Flight Systems Branch RSFSB at the NASA Langley Research Center LaRC in Hampton VA He serves as the MEDLI Subsystem Manager for the Sensor Support Electronics SSE system Mr Novak has over 20 years of experience in the design development and test of spaceflight electronics He served as the lead development manager for the EVA IR Camera Project lead engineer for the visible imager for the GIFTS project lead electronics engineer for the pointing spectrometer for the Mars ARES project lead integration and test engineer for the SAGE III project and lead engineer for the interface adaptor module for SAGE III He earned a BS in Physics from Christopher Newport University in 1999 11 


Ed Martinez is a Project Manager/Lead Scientist/Project Engineer with 20 years experience in the aerospace and electromechanical field He is responsible for leading the Thermal Protection System TPS instrumentation programs for the NASA Ames Research Center As Project Manager he simultaneously managed multiple teams of scientists engineers and engineering technicians responsible for TPS projects including test analysis and technology advancement As Lead Scientist he was engaged in the characterization and operations of the world's largest shock tube This facility produced simultaneous overpressure and thermal environments at shock speeds up to Mach 5 As a Project Engineer his experience included project initiation coordination and providing design and instrument criteria for operating multi-100 million dollar DoD facilities Mr Martinez also managed data handling performed analysis reporting of test results and maintained technical proficiency in shockwave phenomenology 12 


  13 B IOGRAPHY  Brian Paczkowski is currently the Deputy Section Manager of the Planning and Execution Section within the Systems and Software Division at JPL. Prior to that he spent 9 years as the Cassini Science Planning Manager responsible for the development and implementation of the Science Operations Plan. Prior to Cassini, he was the Science Planning and Operations Team Chief for the Galileo Mission to Jupiter. He has also been involved with the pre-launch development of the science instruments on Galileo, Comet Rendezvous and Asteroid Flyby \(CRAF\ and Cassini missions. He has a BS in Astronomy from Villanova University and did graduate studies in Astronomy at Ohio State University  Barbara Larsen  is the Mission Operations System Engineer for the Cassini Mission. She is also on the science planning staff and previously worked in system engineering for the Mission Sequence Subsystem. She has a MS in Mathematics from California State University Long Beach and a BS in Mathematics from USC Trina Ray  is currently the Titan Orbiter Science Team \(TOST\ co-chair and the Science System Engineer for the Project Scientist for Cassini. She has been working on the Cassini Mission since before launch as an instrument operations lead for the Radio Science Team, and then as part of the Science Planning Team supporting Titan integrati on and sequence development She has a MS in Astronomy from San Diego State University and a BS in Physics, Astronomy option from CSUN  


  14  


 15 7  B.-N. Vo and W.-K. Ma, \223The Gaussian Mixture Probability Hypothesis Density Filter,\224 IEEE Trans Signal Processing Vol. 54, pp. 4091-4104, November 2006 8  B. Ristic, S. Arulampalam, and N. Gordon Beyond the Kalman Filter Artech House, 2004 9  Y. Bar-Shalom, X. Rong Li, and T. Kirubarajan Estimation with Applications to Tracking and Navigation, New York: John Wiley & Sons, pg. 166 2001 10  X. R. Li, Z. Zhao, and V. P. Jilkov, \223Estimator\222s Credibility and Its Measures,\224 Proc. IFAC 15th World Congress Barcelona, Spain, July 2002 11  M. Mallick and S. Arulampalam, \223Comparison of Nonlinear Filtering Algorithms in Ground Moving Target Indicator \(GMTI Proc Signal and Data Processing of Small Targets San Diego, CA, August 4-7, 2003 12  M. Skolnik, Radar Handbook, New York: McGrawHill, 1990 13  A. Gelb, Editor Applied Optimal Estimation The MIT Press, 1974 14  B. D. O. Anderson and J. B. Moore Optimal Filtering  Prentice Hall, 1979 15  A. B. Poore, \223Multidimensional assignment formulation of data ass ociation problems arising from multitarget and multisensor tracking,\224 Computational Optimization and Applications Vol. 3, pp. 27\22657 1994 16  A. B. Poore and R. Robertson, \223A New multidimensional data association algorithm for multisensor-multitarget tracking,\224 Proc. SPIE, Signal and Data Processing of Small Targets Vol. 2561,  p 448-459, Oliver E. Drummond; Ed., Sep. 1995 17  K. R. Pattipati, T. Kirubarajan, and R. L. Popp, \223Survey of assignment techniques for multitarget tracking,\224 Proc  on Workshop on Estimation  Tracking, and Fusion: A Tribute to Yaakov Bar-Shalom Monterey CA, May 17, 2001 18  P. Burns, W.D. Blair, \223Multiple Hypothesis Tracker in the BMD Benchmark Simulation,\224 Proceedings of the 2004 Multitarget Tracking ONR Workshop, June 2004 19  H. Hotelling, \223The generalization of Student's ratio,\224 Ann. Math. Statist., Vol. 2, pp 360\226378, 1931 20  Blair, W. D., and Brandt-Pearce, M., \223Monopulse DOA Estimation for Two Unresolved Rayleigh Targets,\224 IEEE Transactions Aerospace Electronic Systems  Vol. AES-37, No. 2, April 2001, pp. 452-469 21  H. A. P.  Blom, and Y. Bar-Shalom, The Interacting Multiple Model algorithm for systems with Markovian switching coefficients IEEE Transactions on Au tomatic Control 33\(8  780-783, August, 1988 22  M. Kendall, A. Stuart, and J. K. Ord, The Advanced Theory of Statistics, Vol. 3, 4th Edition, New York Macmillan Publishing, pg. 290, 1983 23  T.M. Cover and P.E. Hart, Nearest Neighbor Pattern Classification, IEEE Trans. on Inf. Theory, Volume IT-13\(1 24  C.D. Papanicolopoulos, W.D. Blair, D.L. Sherman, M Brandt-Pearce, Use of a Rician Distribution for Modeling Aspect-Dependent RCS Amplitude and Scintillation Proc. IEEE Radar Conf 2007 25  W.D. Blair and M. Brandt-Pearce, Detection of multiple unresolved Rayleigh targets using quadrature monopulse measurements, Proc. 28th IEEE SSST March 1996, pp. 285-289 26  W.D. Blair and M. Brandt-Pearce, Monopulse Processing For Tracking Unresolved Targets NSWCDD/TR-97/167, Sept., 1997 27  W.D. Blair and M. Brandt-Pearce, Statistical Description of Monopulse Parameters for Tracking Rayleigh Targets  IEEE AES Transactions, Vol. 34 Issue 2,  April 1998, pp. 597-611 28  Jonker and Volgenant, A Shortest Augmenting Path Algorithm for Dense and Sparse Linear Assignment Problems, Computing, Vol. 38, 1987, pp. 325-340 29  V. Jain, L.M. Ehrman, and W.D. Blair, Estimating the DOA mean and variance of o ff-boresight targets using monopulse radar, IEEE Thirty-Eighth SSST Proceedings, 5-7 March 2006, pp. 85-88 30  Y. Bar-Shalom, T. Kirubarajan, and C. Gokberk 223Tracking with Classification-Aided Multiframe Data Association,\224 IEEE Trans. on Aerospace and Electronics Systems Vol. 41, pp. 868-878, July, 2005   


 16 B IOGRAPHY  Andy Register earned BS, MS, and Ph  D. degrees in Electrical Engineering from the Georgia Institute of Technology.  His doctoral research emphasized the simulation and realtime control of nonminimum phase mechanical systems.  Dr. Register has approximately 20 years of experience in R&D with his current employer, Georgia Tech, and product development at two early-phase startups. Dr. Register\222s work has been published in journals and conf erence proceedings relative to mechanical vibration, robotics, computer architecture programming techniques, and radar tracking.  More recently Dr. Register has b een developing advanced radar tracking algorithms and a software architecture for the MATLAB target-tracking benchmark.  This work led to the 2007 publication of his first book, \223A Guide to MATLAB Object Oriented Programming.\224  Mahendra Mallick is a Principal Research Scientist at the Georgia Tech Research Institute \(GTRI\. He has over 27 years of professional experience with employments at GTRI \(2008present\, Science Applications International Corporation \(SAIC Chief Scientist \(2007-2008\, Toyon Research Corporation, Chief Scientist 2005-2007\, Lockheed Martin ORINCON, Chief Scientist 2003-2005\, ALPHATECH Inc., Senior Research Scientist 1996-2002\, TASC, Principal MTS \(1985-96\, and Computer Sciences Corporation, MTS \(1981-85 Currently, he is working on multi-sensor and multi-target tracking and classification bas ed on multiple-hypothesis tracking, track-to-track association and fusion, distributed filtering and tracking, advanced nonlinear filtering algorithms, and track-before-detect \(TBD\ algorithms He received a Ph.D. degree in  Quantum Solid State Theory from the State University of New York at Albany in 1981 His graduate research was also based on Quantum Chemistry and Quantum Biophysics of large biological molecules. In 1987, he received an MS degree in Computer Science from the John Hopkins University He is a senior member of the IEEE and Associate Editor-inchief  of the Journal of Advances in Information Fusion of the International Society of Information Fusion \(ISIF\. He has organized and chaired special and regular sessions on target tracking and classific ation at the 2002, 2003, 2004 2006, 2007, and 2008 ISIF conferences. He was the chair of the International Program Committee and an invited speaker at the International Colloquium on Information Fusion \(ICIF '2007\, Xi\222an, China. He is a reviewer for the IEEE Transactions on Aerospa ce and Electronics Systems IEEE Transactions on Signal Pr ocessing, International Society of Information Fusion, IEEE Conference on Decision and Control, IEEE Radar Conference, IEEE Transactions on Systems, Man and Cybernetics, American Control Conference, European Signal Processing Journal and International Colloquium on Information Fusion ICIF '2007   William Dale Blair is a Principal Research Engineer at the Georgia Tech Research Institute in Atlanta, GA. He received the BS and MS degrees in electrical engineering from Tennessee Technological University in 1985 and 1987, and the Ph.D. degree in electrical engineering from the University of Virginia in 1998. From 1987 to 1990, he was with the Naval System Division of FMC Corporation in Dahlgren, Virginia. From 1990 to 1997, Dr Blair was with the Naval Surface Warfare Center, Dahlgren Division NSWCDD\ in Dahlgren, Virg inia. At NSWCDD, Dr Blair directed a real-time experiment that demonstrated that modern tracking algorithms can be used to improve the efficiency of phased array radars. Dr Blair is internationally recognized for conceptualizing and developing benchmarks for co mparison and evaluation of target tracking algorithms Dr Blair developed NSWC Tracking Benchmarks I and II and originated ONR/NSWC Tracking Benchmarks III and IV NSWC Tracking Benchmark II has been used in the United Kingdom France, Italy, and throughout the United States, and the results of the benchmark have been presented in numerous conference and journal articles. He joined the Georgia Institute of Technology as a Se nior Research Engineer in 1997 and was promoted to Principal Research Engineer in 2000. Dr Blair is co-editor of the Multitarg et-Multisensor Tracking: Applications and Advances III. He has coauthored 22 refereed journal articles, 16 refereed conference papers, 67 papers and reports, and two book chapters. Dr Blair's research interest include radar signal processing and control, resource allocation for multifunction radars, multisen sor resource allocation tracking maneuvering targets and multisensor integration and data fusion. His research at the University of Virginia involved monopulse tracking of unresolved targets. Dr Blair is the developer and coordinator of the short course Target Tracking in Sensor Systems for the Distance Learning and Professional Education Departmen t at the Georgia Institute of Technology. Recognition of Dr Blair as a technical expert has lead to his election to Fellow of the IEEE, his selection as the 2001 IEEE Y oung Radar Engineer of the Year, appointments of Editor for Radar Systems, Editor-InChief of the IEEE Transactions on Aerospace and Electronic Systems \(AES\, and Editor-in- Chief of the Journal for Advances in Information Fusion, and election to the Board of Governors of the IEEE AES Society,19982003, 2005-2007, and Board of Directors of the International Society of Information Fusion   


 17 Chris Burton received an Associate degree in electronic systems technology from the Community College of the Air force in 1984 and a BS in Electrical Engineering Technology from Northeastern University in 1983.  Prior to coming to the Georgia Institute of Technology \(GTRI\ in 2003, Chris was a BMEWS Radar hardware manager for the US Air Force and at MITRE and Xontech he was responsible for radar performance analysis of PAVE PAWS, BMEWS and PARCS UHF radar systems Chris is an accomplished radar-systems analyst familiar with all hardware and software aspects of missile-tracking radar systems with special expertise related to radar cueing/acquisition/tracking for ballistic missile defense ionospheric effects on UHF radar calibration and track accuracy, radar-to-radar handover, and the effects of enhanced PRF on radar tracking accuracy.  At GTRI, Chris is responsible for detailed analysis of ground-test and flight-test data and can be credited with improving radar calibration, energy management, track management, and atmospheric-effects compensation of Ballistic Missile Defense System radars   Paul D. Burns received his Bachelor of Science and Masters of Science in Electrical Engineering at Auburn University in 1992 and 1995 respectively. His Master\222s thesis research explored the utilization of cyclostationary statistics for performing phased array blind adaptive beamforming From 1995 to 2000 he was employed at Dynetics, Inc where he performed research and analysis in a wide variety of military radar applications, from air-to-air and air-toground pulse Doppler radar to large-scale, high power aperture ground based phased array radar, including in electronic attack and protection measures. Subsequently, he spent 3 years at MagnaCom, Inc, where he engaged in ballistic missile defense system simulation development and system-level studies for the Ground-based Midcourse defense \(GMD\ system. He joined GTRI in 2003, where he has performed target tracking algorithm research for BMD radar and supplied expertise in radar signal and data processing for the Missile Defense Agency and the Navy Integrated Warfare Systems 2.0 office.  Mr. Burns has written a number of papers in spatio-temporal signal processing, sensor registration and target tracking, and is currently pursuing a Ph.D. at the Georgia Institute of Technology  


  18 We plan to shift the file search and accessibility aspect outside of the IDL/Matlab/C++ code thereby treating it more as a processing \223engine\224. SciFlo\222s geoRegionQuery service can be used as a generic temporal and spatial search that returns a list of matching file URLs \(local file paths if the files are located on the same system geoRegionQuery service relies on a populated MySQL databases containing the list of indexed data files. We then also plan to leverage SciFlo\222s data crawler to index our staged merged NEWS Level 2 data products Improving Access to the A-Train Data Collection Currently, the NEWS task collects the various A-Train data products for merging using a mixture of manual downloading via SFTP and automated shell scripts. This semi-manual process can be automated into a serviceoriented architecture that can automatically access and download the various Level 2 instrument data from their respective data archive center. This will be simplified if more data centers support OPeNDAP, which will aid in data access. OPeNDAP will also allow us to selectively only download the measured properties of interest to the NEWS community for hydrology studies. Additionally OpenSearch, an open method using the REST-based service interface to perform searches can be made available to our staged A-Train data. Our various services such as averaging and subsetting can be modified to perform the OpenSearch to determine the location of the corresponding spatially and temporally relevant data to process. This exposed data via OpenSearch can also be made available as a search service for other external entities interested in our data as well Atom Service Casting We may explore Atom Service Casting to advertise our Web Services. Various services can be easily aggregated to create a catalog of services th at are published in RSS/Atom syndication feeds. This allows clients interested in accessing and using our data services to easily discover and find our WSDL URLs. Essentially, Atom Service Casting may be viewed as a more human-friendly approach to UDDI R EFERENCES   NASA and Energy and W a t e r cy cl e St udy NEW S website: http://www.nasa-news.org  R odgers, C  D., and B  J. C onnor \(2003 223Intercomparison of remote sounding instruments\224, J Geophys. Res., 108\(D3 doi:10.1029/2002JD002299  R ead, W G., Z. Shi ppony and W V. Sny d er \(2006 223The clear-sky unpolarized forward model for the EOS Aura microwave limb sounder \(MLS Transactions on Geosciences and Remote Sensing: The EOS Aura Mission, 44, 1367-1379  Schwartz, M. J., A. Lam b ert, G. L. Manney, W  G. Read N. J. Livesey, L. Froidevaux, C. O. Ao, P. F. Bernath, C D. Boone, R. E. Cofield, W. H. Daffer, B. J. Drouin, E. J Fetzer, R. A. Fuller, R. F. Jar not, J. H. Jiang, Y. B. Jiang B. W. Knosp, K. Krueger, J.-L. F. Li, M. G. Mlynczak, S Pawson, J. M. Russell III, M. L. Santee, W. V. Snyder, P C. Stek, R. P. Thurstans, A. M. Tompkins, P. A. Wagner K. A. Walker, J. W. Waters and D. L. Wu \(2008 223Validation of the Aura Microwave Limb Sounder temperature and geopotential height measurements\224, J Geophys. Res., 113, D15, D15S11  Read, W G., A. Lam b ert, J Bacmeister, R. E. Cofield, L E. Christensen, D. T. Cuddy, W. H. Daffer, B. J. Drouin E. Fetzer, L. Froidevaux, R. Fuller, R. Herman, R. F Jarnot, J. H. Jiang, Y. B. Jiang, K. Kelly, B. W. Knosp, L J. Kovalenko, N. J. Livesey, H.-C. Liu1, G. L. Manney H. M. Pickett, H. C. Pumphrey, K. H. Rosenlof, X Sabounchi, M. L. Santee, M. J. Schwartz, W. V. Snyder P. C. Stek, H. Su, L. L. Takacs1, R. P. Thurstans, H Voemel, P. A. Wagner, J. W. Waters, C. R. Webster, E M. Weinstock and D. L. Wu \(2007\icrowave Limb Sounder upper tropospheric and lower stratospheric H2O and relative humidity with respect to ice validation\224 J. Geophys. Res., 112, D24S35 doi:10.1029/2007JD008752  Fetzer, E. J., W  G. Read, D. W a liser, B. H. Kahn, B Tian, H. V\366mel, F. W. Irion, H. Su, A. Eldering, M. de la Torre Juarez, J. Jiang and V. Dang \(2008\omparison of upper tropospheric water vapor observations from the Microwave Limb Sounder and Atmospheric Infrared Sounder\224, J. Geophys. Res., accepted  B.N. Lawrence, R. Drach, B.E. Eaton, J. M. Gregory, S C. Hankin, R.K. Lowry, R.K. Rew, and K. E. Taylo 2006\aintaining and Advancing the CF Standard for Earth System Science Community Data\224. Whitepaper on the Future of CF Governance, Support, and Committees  NEW S Data Inform ation Center \(NDIC http://www.nasa-news.org/ndic 


  19   Schi ndl er, U., Di epenbroek, M 2006 aport a l based on Open Archives Initiative Protocols and Apache Lucene\224, EGU2006. SRef-ID:1607-7962/gra/EGU06-A03716 8] SciFlo, website: https://sci flo.jpl.nasa.gov/SciFloWiki 9 ern a, web s ite: h ttp tav ern a.so u r cefo r g e.n et  Java API for XM L W e b Services \(JAX-W S https://jax-ws.dev.java.net  Di st ri but ed R e source M a nagem e nt Appl i cat i on DRMAA\aa.org  Sun Gri d Engi ne, websi t e   http://gridengine.sunsource.net  W 3 C R ecom m e ndat i on for XM L-bi nary Opt i m i zed Packaging \(XOP\te: http://www.w3.org/TR/xop10  W 3 C R ecom m e ndat i on for SOAP M e ssage Transmission Optimization Mechanism \(MTOM website: http://www.w3.org/TR/soap12-mtom  W 3 C R ecom m e ndat i on for R e source R e present a t i on SOAP Header Block, website http://www.w3.org/TR/soap12-rep 16] OPeNDAP, website: http://opendap.org  Yang, M Q., Lee, H. K., Gal l a gher, J. \(2008 223Accessing HDF5 data via OPeNDAP\224. 24th Conference on IIPS  ISO 8601 t h e Int e rnat i onal St andard for t h e representation of dates and times http://www.w3.org/TR/NOTE-datetime 19] ITT IDL, website http://www.ittvis.com/ProductServices/IDL.aspx 20] Python suds, website: h ttps://fedorahosted.org/suds  The gSOAP Tool ki t for SOAP W e b Servi ces and XM LBased Applications, website http://www.cs.fsu.edu/~engelen/soap.html  C hou, P.A., T. Lookabaugh, and R M Gray 1989 223Entropy-constrained vector quantization\224, IEEE Trans on Acoustics, Speech, and Signal Processing, 37, 31-42  M acQueen, Jam e s B 1967 e m e t hods for classification and analysis of multivariate observations\224 Proc. Fifth Berkeley Symp Mathematical Statistics and Probability, 1, 281-296  C over, Thom as. and Joy A. Thom as, \223El e m e nt s of Information Theory\224, Wiley, New York. 1991  B r averm a n, Am y 2002 om pressi ng m a ssi ve geophysical datasets using vector quantization\224, J Computational and Graphical Statistics, 11, 1, 44-62 26 Brav erm a n  A, E. Fetzer, A. Eld e rin g  S. Nittel an d K Leung \(2003\i-streaming quantization for remotesensing data\224, Journal of Computational and Graphical Statistics, 41, 759-780  Fetzer, E. J., B. H. Lam b rigtsen, A. Eldering, H. H Aumann, and M. T. Chahine, \223Biases in total precipitable water vapor climatologies from Atmospheric Infrared Sounder and Advanced Microwave Scanning Radiometer\224, J. Geophys. Res., 111, D09S16 doi:10.1029/2005JD006598. 2006 28 SciFlo Scien tific Dataflo w  site https://sciflo.jpl.nasa.gov  Gi ovanni websi t e   http://disc.sci.gsfc.nasa.gov techlab/giovanni/index.shtml  NASA Eart h Sci e nce Dat a Sy st em s W o rki ng Groups website http://esdswg.gsfc.nasa.gov/index.html   M i n, Di Yu, C h en, Gong, \223Augm ent i ng t h e OGC W e b Processing Service with Message-based Asynchronous Notification\224, IEEE International Geoscience & Remote Sensing Symposium. 2008 B IOGRAPHY  Hook Hua is a member of the High Capability Computing and Modeling Group at the Jet Propulsion Laboratory. He is the Principle Investigator of the service-oriented work presented in this paper, which is used to study long-term and global-scale atmospheric trends. He is also currently involved on the design and development of Web Services-based distributed workflows of heterogeneous models for Observing System Simulation Experiments OSSE\ to analyze instrument models. Hook was also the lead in the development of an ontology know ledge base and expert system with reasoning to represent the various processing and data aspects of Interferometric Synthetic Aperture Radar processing. Hook has also been involved with Web Services and dynamic language enhancements for the Satellite Orbit Analysis Program \(SOAP\ tool.  His other current work includes technology-portfolio assessment, human-robotic task planning & scheduling optimization, temporal resource scheduling, and analysis He developed the software frameworks used for constrained optimization utilizing graph search, binary integer programming, and genetic algorith ms. Hook received a B.S in Computer Science from the University of California, Los  


  20 Angeles, where he also received a B.S. in Applied Mathematics  Eric Fetzer is a Senior Member of the Technical Staff at the Jet Propulsion Laboratory, Pasadena, California specializing in satellite observations of the atmosphere.  His scientific interests include planetary boundary layer processes, tropical phenomena, upper tropospheric variability, and climatologies of temperature, water vapor and clouds.  His technical interests include analysis of large data sets, and of multi-sensor observations. He has over 20 peer-reviewed publications and given numerous scientific presentations, public lectures and media interviews about climate science. Eric received a B.A. in Physics from the University of California Berkeley, and a Ph.D. in Astrophysical, Planetary and Atmospheric Sciences from the University of Colorado, Boulder   Amy Braverman is a Senior Statistician at the Jet Propulsion Laboratory, California Institute of Technology She holds a B.A. in Economics from Swarthmore College an M.A. in Mathematics from UCLA, and a Ph.D. in Statistics also from UCLA. Prior to her current position in JPL's Science Data Understanding Group, she was a Caltech Post-doctoral Scholar at the Jet Propulsion Laboratory, and a Scientist in the Flight Sciences Experiments Section of the Science Division. Dr Braverman conducts research on information-theoretic methods for the analysis of massive data sets and streams statistical data fusion, high-dimensional data analysis, and statistical analysis for climate model evaluation and diagnosis. She has published in both the statistics and geoscience literature, and is active in both communities She is a member of the Multi-angle Imaging SpectroRadiometer Science Team, and serves as a member of the Atmospheric Infrared Sounder Science Integration Team. Her responsibilities on both missions include designing data reduction algorithms for massive, remote sensing data sets. Dr. Braverman also holds an appointment in the Department of Statistics at UCLA as Adjunct Associate Professor, and is active in UCLA\222s Center for Environmental Statistics. She is member of the Committee on Applied and Theoretical Statistics of the US National Academy of Science. She has refereed for the Journal of the American Statistical Association, the Journal of Computational and Gr aphical Statistics, IEEE Transactions on Geoscience and Remote Sensing, and the Journal of Applied Meteorology and Climatology Seungwon Lee is a senior member of the High Capability Computing and Modeling Group at Jet Propulsion Laboratory. She is conducti ng research on comet gas dynamics, nonlinear dynamics control, climate model parameterization, Earth science data analysis, parallel computing, and advanced numerical algorithms. She received her Ph.D in Physics fr om the Ohio State University and her M.S. and B.S. in Physics from the Seoul National University, Korea  Matthew Henderson is software engineer in the High Capability Computing and Mode ling group at JPL. His current work includes Web Services and Instrument Data Level 2 subsetting. He received a B.S. Computer Science from CSU Pomona, and is currently pursuing M.S Computer Science  Steven J. Lewis is a member of the Information System and Computer Science staff member at the Jet Propulsion Laboratory.  He received a BS in Mathematics from the University of California, Los Angeles in June 2001, and the MS and Ph.D. Degree from Claremont Graduate University in May 2004 and May 2007, respectively.  He worked as a post doctoral fellow at Keck Graduate Institute from June 2007 until he joined JPL in March of 2008.  During his graduate and post doctoral work, his studies focused on applications of Bayesian methods to hidden Markov models with particular interest and application to protein sequencing.  His work at JPL has focused on integrating web services into various programming platforms for the purposes of accessing NASA satellite data, as well as developing object tracking so ftware and contributing to image enhancement and restoration efforts Van Dang is a member of the Science Data Understanding Group at the Jet Propulsion Laboratory. She was responsible for the NEWS Level 2 processing that generated the formal merged Level 2 data from multiple A-Train instruments  Manuel de la Torre is a Physicist from the Universidad Complutense at Madrid \(Spain\. After finishing his Ph.D work at the University of Bayreuth \(Germany\ on pattern formation in turbulent flows and a 7 1/2 year stunt as Ass and Assoc. Prof. at the Escuela T\351cnica Superior de Ingenieros Aeron\341uticos in Madrid \(Spain\, he came to the Jet Propulsion Laboratory on a 1-year Sabatical leave in 1997 wanting to apply fundamental concepts of nonlinear systems and geophysical fluid dynamics to something that might be directly useful to soci ety. He discovered the JPL as a great place to achieve that goal and extende d his stay a bit longer, becoming Technical staff and working on different aspects of remote sensing, validation of satellite instruments, and data analysis of atmospheric processes and climate  


