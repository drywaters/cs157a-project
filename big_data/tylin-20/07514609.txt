y              in   t      ich   I     le  s  i te  io n    s le  x-none I  I   x-none    as es        ies  I is  n e  y      e  ated  s ly    ase is  i    d es   s  le  ata  2   ce  ti      l  2       r  s   t     s   19        d n   7   il e asis  o f   y  7 s  g  i e s    f d  er  h   g  it a t  e lat n   s  7    x-none   g  it       es   i lica e 9     s     y    ity    ess  le   ity   a le  7   ity  al  I es  y   7   all y  ess   e  e 9    e se    m et s    e  et s   x-none   atab D    tal  2   It  e s  al  ata  e  r  g   r  c g   ates  2   H   a c ate s    les  t    e   s  7   2016 International Conference on Computational Techniques in Information\ and Communication Technologies \(ICCTICT 978-1-5090-0082-1/16/$31.00 \2512016 IEEE 


  e   e  es n   s  e  m   A m   s 4  s     x-none II  R  W K  U y  ased   g  7   o i m  W  N es  a t  p n  5   UP h  4   Up 3   I H UP 6     a e   all ets  t  ac  til   e  it y  id  Up es   ates  Up  k e y    ite ms    FUP ed  in  2  2   n  e   a  d  o ph        w  til  ld    til  ld  d  e     e til  ld   p U  s  ata    a s   a n  7  i n e es e     1 6    I t  d ef in e s  an  o b j ec tiv e f u n ctio n   a 1 7   x-none III  O  P  O F T  P  S EM  x-none A      m  as T 1 T 2 T 3  T m     as i 1 i 2 i 3  i n     f k  i 1  i 2 i 3  i k  P  d     ty  iu  ty   ty  eu  ty    ty    T j   iu   T j  eu  i       P  y  D    u  P T i e P  T i    i m   ty  TU  ty     i  T i e   i       P     P    P    T i   e  i d  T i     y ase   D as TU   T i e T i     ld      D y  1     se t  25    D   1  til    D      100   lity  PU  PU   i p P   is e lity   P  i p  as   i p   eu   i    P    i p 1  d   TU   P    ty  ty    ity    i p P e  lity  P  k  i p  as   P    i j  e    k    y  RU   It   n   RU  C      C         C   x-none B                     x-none  x-none  1       e  e  g   t wo     978-1-5090-0082-1/16/$31.00 \2512016 IEEE 


x-none    PID ee    n   12   ase D  e  me   tity   ty  ity   e us t    TU   e U   e TU  t    TU d t   ase D i ng  e   U  ity    y  e  U    e  in g U  y as       e il   d   e   ity  ath  ity  t e t    l U   l U   y as    t   ty   cu rs     2      il 2   F u r th e r   r u le u til ity  is  ca lcu la te d  f o r  7   I n    ty  s  ity 9   I t is    RU   b   p   ff     x-none ty C   D   as p   C   D  e s    co 7   I t  c an  b e  d ef in e d  as  p     f  D           le C D is as      s s 9     t   D      t ity   D   f it   i       t  C     D is as       7   I t  c an  b e  d ef in e d  as        f  D     ty       x-none V  A  2  ut e DB ase db  til         2          978-1-5090-0082-1/16/$31.00 \2512016 IEEE 


         x-none g  2     D n  Al         x-none g  3    I s      s               x-none g  4    g           x-none g  5   r s    V  A O M E  t m   6   l   7  w t  t ies n s            x-none   x-none g  6   se      x-none g  7   e   x-none   Fig   8 D h   e T 1 a e   me   m tity    y   e  0  y        F  8   D  T 1   Fig   8 D   s  T 2  T 3         h  n  do   N  N R    N R e       ms i  r  t g  r    i  y  q do    I f  d  N i   N  h  N i i  n     N i    N    t  N i e    i  N i x   q  N i  PU  0    I f q   N i x y    N i x y   q     I f  i  n  e  n   N i   st  e   TU   T    N    N i   I f  T   db  B  n        If   n   HUI     PFI      PFI      e r U I     s   y   l  m HU I    H   HUI  do    h  H  do   Ca l  RU   h   I f RU   H h      h  P         e  st   do      in   h  f  k   t   g  r   WU   N    N R    m  i p    p h  do   e  PU   ip    If  h  N ip   N  h  N     i p  n      N p r  N   t  N p    i  N ip x y   N ip    N ip    If  q   N  x y  n  N p x y   q   if  N ip   n  n   U  n   N ip   st  e   TU   T  N    N ip   e  e r U I    PT  e  PI  t  PB  se    T e  m i  h  i U  l   PT         PFI    N    do        N R  m N     If      e  p  p h     se  Sup      p t    d    B  h  p h  PU   e  PT  PB   d   in  HUI    l  e r  U I         978-1-5090-0082-1/16/$31.00 \2512016 IEEE 


        x-none   e d e    s    e     TWU  e s   late y  at     x-none  x-none  x-none  x-none    e   8  c e t e  m               x-none  e  l le  e 8  d    x-none        x-none e s    e d  WU e 9                  WU                 ty      y e    il  D  f  U  item  til           978-1-5090-0082-1/16/$31.00 \2512016 IEEE 


        E   en    e  ted   e de g  er  of  l U  e s l   l D  l    lo l     B   E  be  h  d   h    n  14   x-none   2   x-none u   1    r e e    x-none e      Fig   12  f          le  4        x-none   e    ate  s    x-none   D   C E    x-none P e  2   s    s  it  les    e  ate s   ted    ts           x-none er    e  cal  e  y  et s   15  x-none   y   e as   RU  C   D    C   D  C   D    C   D  2    3    1   2        3    5    4    1          cr s   to  et  s  as le 1      H SS E Y  n e    y                                                                                   978-1-5090-0082-1/16/$31.00 \2512016 IEEE 


   C N  x-none e  e    le    les h   s  t   s      T le  es  y  ity   ess  le  e 5 th n  n   e  s    a  le   m  s  f     R ES    1   EEE 8    2     3  3   s 2  4    3  5  K  H  U   s  1  6  g   s   7  H  D    5  8  F   s  3  9    i ty   4  0  J  W   e   1    s    2  u   s  3  W   s 9  4    E    t  6 th   5  Y  s 695  6   R   19 26  7    H J   4    8    g  44 th    978-1-5090-0082-1/16/$31.00 \2512016 IEEE 


002 003 004\002 004\003 005\002 005\003 006\002 006\003 007\002 002\004 002\005 002\006 002 002 003 004\002 004\003 005\002 005\003 006\002 006\003 002\004 002\005 002\006 002 002 003 004\002 004\003 005\002 005\003 006\002 006\003 007\002 002\004 002\005 002\006 002 002 003 004\002 004\003 005\002 005\003 006\002 006\003 002\004 002\005 002\006 002 002 003 004\002 004\003 005\002 005\003 006\002 006\003 007\002 002\004 002\005 002\006 002 002 003 004\002 004\003 005\002 005\003 006\002 006\003 007\002 002\004\002\005\002\006\002 
3 6 
 
026\027\012\007\030\004\007\010\005\013\032\013    
Figure 5 Achieved throughput for increasing length rule candidates The Y-axis is measured in billion evaluations per second The X-axis shows the corresponding rule length The gures also depict the theoretical trend-line that is computed as an ampliìcation of the naive-sc on the GPU using Eq 4 cases default-tpsc outperforms naive-sc on the gpu as well as the alternative implementation on the cpu The performance of naive-sc is higher than its cpu counterpart due to the higher resource availability of the GPU However its maximum throughput is only 5 billion evaluations per second and drops very quickly for all the different types of dataset In contrast default-tpsc has a throughput ranging from 2x to 30x times higher for larger rule lengths presenting overall a more gradual drop TPSC relies heavily on a large list of items to achieve increased parallelism during execution and improve performance For this reason we observe a steeper drop in throughput and a lower throughput maximum for synthetic data 2 and 4 The available items in these cases are less than the minimum block size i.e 128 threads that is required to achieve full multiprocessor warp occupancy Therefore resource underutilization is the main reason for the observed performance drop When the number of items in the transaction data is large enough the observed throughput follows the theoretical trendline We determine the theoretic throughput using Eq 4 to amplify the the naive-sc throughput of the GPU The depicted gures show the trend-line and not the actual ampliìed throughput as naive-sc saturates the GPU resources for rule length greater than 18 resulting in signiìcant performance drop So the actual beneìts from tspc are more signiìcant for large rule candidate lengths due to the algorithm being resource efìcient In fact for synthetic data 1,3 5 and 6 the theoretical throughput is around 35 billion evaluations per second Although it is greater than the observed throughput\(i.e 15 to 20 billion compared to naive-sc on the GPU tspc exhibits almost 40x improvement As with the synthetic dataset we performed similar experiments this time on real data We present the observed throughput in Fig 6 Overall the results follow similar pattern with those of the experiments on synthetic data For accidents dataset we observe the highest throughput of 50 billion evaluations per second For all dataset default-tpsc exhibits a gradual decrease in throughput because the number of items are enough to fully utilize the GPUês resources Through this round of experiments we observe that the throughput is also affected by the number of transactions although at a lesser extend Additionally due to the different sparsity patterns variations in the throughput are also noticeable Retail and TK100 although having similar size exhibit different characteristics in relation to their sparsity pattern with the former consisting of many dense regions and the latter having only few This is the reason behind the 10x difference in their observed throughput 
In this section we study in detail the effect of shared memory bank conîicts and uncoalesced off-chip memory accesses Since it was established that default-tpsc has a better performance than naive-sc and its multi-core counterpart we focus on comparing default-tpsc with its optimized variants nbc-tpsc mrs-tpsc and mr-tpsc In Fig 7 and Fig 8 we present the maximum percentage improvement in execution time per iteration which we obtained from using the aforementioned kernel variations on synthetic and real data respectively Resolving bank conîicts produced a stable to improvement in execution time across all dataset Such a performance improvement is evident at the worst case where 32-way bank conîict occurs Bank conîicts are caused during partial result sharing creating additional overhead that is upper bounded by the warp size across multiple warps For this 
027\011$\012\014\017\021\036\021\031\013\020  025\012%&\011\036\013\020\022\036\022'\031\014  025\012%&\011\036\013\020\022\036\022\020\031\014 021\(\011\032\015\011\021\030\020 
026\027\012\007\030\004\007\010\005\013\031\013    026\027\012\007\030\004\007\010\005\013\033\013    026\027\012\007\030\004\007\010\005\013\034\013    026\027\012\007\030\004\007\010\005\013\035\013    026\027\012\007\030\004\007\010\005\013\036\013  
B Shared Memory Utilization  Bank Conîicts 
1430 
1430 


002 004\002 005\002 006\002 007\002 003\002 033\002 034\002 035\002 002\004\002\005\002 006\002 
002 005 007 033 035 004\002 004\005 004\007 004\005\006\007\003\033 
C Increased Rule Length 
002 005 007 033 035 004\002 004\005 004\007 004\033 004\035 005\002 020\020\030\027\011\025\021\013 026\032\025\025\011\020\021\030\032 025 011\021\012\030\017 023\004\002\002 023\004\002\004 
 
002\003\004\005\006\007\010\011\012\013\014\010\015\004\013'\013\022\015\(\023\011\\004\015\004\012\007\013 024\007\024!\004\007\013 002\003\004\005\006\007\010\011\012\013\014\010\015\004\013'\013\022\015\(\023\011\\004\015\004\012\007\013 024\007\024!\004\007\013 
Figure 6 Throughput for increasing length rule candidates The Y-axis is measured in billion evaluations per second The X-axis shows the corresponding rule length As before the gures include the theoretical trend-line computed from amplifying naive-sc on the GPU using Eq 4 reason the observed improvement is stable depending mostly on the item number Assigning multiple candidate rule collections to a single block resulted in Figure 7 Percentage improvement in execution time as compared to the default-tpsc kernel for the individually optimized kernels when using synthetic data   Figure 8 Percentage improvement in execution time as compared to the default-tpsc kernel for the individually optimized kernels when using real data For both kernels we observe a similar behaviour when we increase rule candidate length to a number larger than 32 After that point we require evaluating the preìx in two phases following a technique similar to parallel reduction although using warp vote functions This extra phase requires an additional synchronization step which increases the total execution time per iteration Additionally when we have prominent rules with item indices in sequence i.e accidents dataset as indicated by its sparsity pattern caching transactions does not provide any improvement However when there are many rules with out of sequence preìxes the cost of uncoalesced memory accesses matches the synchronization cost as indicated by experiments on dataset 1 VIII C ONCLUSION In this paper we studied the support count operation commonly used in association rule mining problems We proposed a work-efìcient parallel algorithm that is suitable for massively parallel architectures Furthermore we presented a data layout scheme used to enable low overhead coordination of the processing elements reduce the memory requirements and achieve high off-chip memory bandwidth utilization Furthermore we discussed in detail low level optimization strategies related to effective use of shared memory while presenting a simple strategy for resolving shared memory bank conîicts incurring minimal additional work However there is still some additional issues that we need to address Firstly we already considering resolving the issue of 
025 015\013\036\021\031\013\020 015\036\021\031\013\020 
improvement over the default-tpsc execution time A combination of loop unrolling and increase shared memory utilization from storing more candidate rules in the same block was the reason for the observed improvement In contrast enabling caching of transactions in shared memory with kernel mrs-tpsc presented less improvement in the relative execution time compared to mr-tpsc The culprit is this case is the additional synchronization step which is required after loading the data in shared memory Finally experiments performed on dataset 2 and 4 indicate similar behavior to our previous experiments where multiprocessor underutilization was limiting the maximum possible performance increase Even in the case where we increase the workload of participating blocks interleaved execution of warps is limited since as the block size is small In this section we discuss the effects of discovering rules with length larger than 32 Due to lack of space we present the results from the execution on synthetic data 1 and accidents which are good representatives of the observed behaviour We focus on the mrs-tpsc and mr-tpsc variations which we established to be highly optimized throughout our experiments   
025 015\013\036\021\031\013\020 015\036\021\031\013\020 
037\005\005\010 \004\012\007!\013   002 003 004\002 004\003 005\002 005\003 006\002 006\003 007\002 002\004\002\005\002 006\002 011\012\012\004\005\007\010\011\012\013   002 003 004\002 004\003 005\002 005\003 006\002 006\003 007\002 002\004\002\005\002\006\002 004\007\024\010$\013  014%\031&&\013 
18 
027\011$\012\014\017\021\036\021\031\013\020  025\012%&\011\036\013\020\022\036\022'\031\014  025\012%&\011\036\013\020\022\036\022\020\031\014 021\(\011\032\015\011\021\030\020    002 004 005 006 007 002\004\002\005\002 006\002 
1431 
1431 


 volume 22 pages 207Ö216 ACM 1993  R Agra w al R Srikant et al F ast algorithms for mining association rules In  volume 1215 pages 487Ö499 1994  E Ansari G Dastghaibif ard M K eshtkaran and H Kaabi Distrib uted frequent itemset mining using trie data structure  35\(3 2008  M Atzmueller and F  Puppe Sd-mapÖa f ast algorithm for e xhausti v e subgroup discovery In  pages 6Ö17 Springer 2006  C Creighton and S Hanash Mining gene e xpression databases for association rules  19\(1 2003  W  F ang M Lu X Xiao B He and Q Luo Frequent itemset mining on graphics processors In  pages 34Ö42 ACM 2009  K Geurts G W ets T  Brijs and K V anhoof Proìling of high-frequenc y accident locations by use of association rules  1840 2003  A Ghoting G Buehrer  S P arthasarathy  D Kim A Nguyen Y K Chen and P Dubey Cache-conscious frequent pattern mining on modern and emerging processors  16\(1 2007  G Grahne and J Zhu Ef ciently using preìx-trees in mining frequent itemsets In  volume 90 2003  J Han J Pei and Y  Y in Mining frequent patterns without candidate generation In  volume 29 pages 1Ö12 ACM 2000  J Hipp U G  untzer and G Nakhaeizadeh Algorithms for association rule miningÑa general survey and comparison  2\(1 2000  R Jin and G Agra w al An algorithm for in-core frequent itemset mining on streaming data In  pages 8Öpp IEEE 2005  R Jin and G Agra w al Systematic approach for optimizing comple x mining tasks on multiple databases In  pages 17Ö17 IEEE 2006  E Lindholm J Nick olls S Oberman and J Montrym Nvidia tesla A uniìed graphics and computing architecture  2 2008  J Liu Y  P an K W ang and J Han Mining frequent item sets by opportunistic projection In  pages 229Ö238 ACM 2002  L Liu E Li Y  Zhang and Z T ang Optimization of frequent itemset mining on multiple-core processor In  pages 1275Ö1285 VLDB Endowment 2007  B Mobasher  R Coole y  and J Sri v asta v a Automatic personalization based on web usage mining  43\(8 151 2000  E  Ozkural B Ucar and C Aykanat Parallel frequent item set mining with selective item replication  22\(10 2011  J Pei J Han H Lu S Nishio S T ang and D Y ang H-mine Hyper structure mining of frequent patterns in large databases In  pages 441Ö448 IEEE 2001  I Pramudiono and M Kitsure ga w a P arallel fp-gro wth on pc cluster  In  pages 467Ö473 Springer 2003  C Silv estri and S Orlando gpudci Exploiting gpus in frequent itemset mining In  pages 416Ö425 IEEE 2012  A T ajbakhsh M Rahmati and A Mirzaei Intrusion detection using fuzzy association rules  9\(2 2009  T  T assa Secure mining of association rules in horizontally distrib uted databases  26\(4 2014  K W ang M Stan and K Skadron Association rule mining with the micron automata processor In  2015  M J Zaki Scalable algorithms for association mining  12\(3 2000  M J Zaki M Ogihara S P arthasarathy  and W  Li P arallel data mining for association rules on shared-memory multi-processors In  pages 43Ö43 IEEE 1996  F  Zhang Y  Zhang and J D Bak os Accelerating frequent itemset mining on graphics processing units  66\(1 2013  Y  Zhang F  Zhang Z Jin and J D Bak os An fpga-based accelerator for frequent itemset mining  6\(1 2013 
002 004 005 006 007 002 004\005\035 005\003\033 006\035\007 003\004\005 002 033 004\005 004\035 005\007 002 004\005\035 005\003\033 006\035\007 003\004\005 
ACM SIGMOD Record Proc 20th int conf very large data bases VLDB IAENG International Journal of Computer Science Knowledge Discovery in Databases PKDD 2006 Bioinformatics Proceedings of the fth international workshop on data management on new hardware Transportation Research Record Journal of the Transportation Research Board The VLDB Journal FIMI ACM SIGMOD Record ACM sigkdd explorations newsletter Data Mining Fifth IEEE International Conference on Data Engineering 2006 ICDEê06 Proceedings of the 22nd International Conference on IEEE micro Proceedings of the eighth ACM SIGKDD international conference on Knowledge discovery and data mining Proceedings of the 33rd international conference on Very large data bases Communications of the ACM Parallel and Distributed Systems IEEE Transactions on Data Mining 2001 ICDM 2001 Proceedings IEEE International Conference on Advances in Knowledge Discovery and Data Mining Parallel Distributed and Network-Based Processing PDP 2012 20th Euromicro International Conference on Applied Soft Computing Knowledge and Data Engineering IEEE Transactions on Proceedings of the 2015 IEEE 29th International Parallel and Distributed Processing Symposium Knowledge and Data Engineering IEEE Transactions on Supercomputing 1996 Proceedings of the 1996 ACM/IEEE Conference on The Journal of Supercomputing ACM Transactions on Reconìgurable Technology and Systems TRETS 
Figure 9 Execution time measured for increasing rule size  the Xaxis indicates the rule length multiprocessor under-utilization For dataset with low number of items we can assign individual groups of threads in the same block to different rule collections effectively increasing the block size as well as utilization Secondly we would like to adapt our solution to an architecture consisting of multiple GPUs and address challenges related to partial result sharing A CKNOWLEDGMENT This work was supported by the U.S National Science Foundation under grant ACI-1339756 R EFERENCES  Frequent itemset mining dataset repository  2015 URL http://ìmi.ua.ac.be/data  R Agra w al T  Imieli  nski and A Swami Mining association rules between sets of items in large databases In 
014\010\015\004\013\016!\004\005!\021\013 026\027\012\007\030\004\007\010\005\013\031\013 014\010\015\004\016!\004\005!\021\013 037\005\005\010 \004\012\007!\013 
015\036\021\031\013\020 015\013\036\021\031\013\020 
1432 
1432 


 Frequent pattern mining Current status and future directions  2007  R Agra w al and R Srikant F ast algorithms for mining association rules in  1994  M J Zaki Scalable algorithms for association mining  vol 12 no 3 pp 372Ö390 2000  J Han J Pei and Y  Y in Mining frequent patterns without candidate generation in  2000  Y  Zhang F  Zhang and J Bak os Frequent itemset mining on large-scale shared memory machines in  2011  F  Zhang Y  Zhang and J D Bak os  Accelerating frequent itemset mining on graphics processing units  vol 66 no 1 pp 94Ö117 2013  Y  Zhang  An fpga-based accelerator for frequent itemset mining  vol 6 no 1 pp 2:1Ö2:17 May 2013  P  Dlugosch  An efìcient and scalable semiconductor architecture for parallel automata processing  vol 25 no 12 2014  I Ro y and S Aluru Finding motifs in biological sequences using the micron automata processor in  2014  R Agra w al T  Imieli  nski and A Swami Mining association rules between sets of items in large databases in  1993  H No yes Micronês automata processor architecture Reconìgurable and massively parallel automata processing in  June 2014 keynote presentation  M J Zaki  Parallel data mining for association rules on shared-memory multi-processors in  1996  L Liu  Optimization of frequent itemset mining on multiple-core processor in  2007  I Pramudiono and M Kitsure ga w a P arallel fp-gro wth on pc cluster in  2003  E Ansari  Distributed frequent itemset mining using trie data structure  vol 35 no 3 p 377 2008  W  F ang  Frequent itemset mining on graphics processors in  2009  B Goethals Surv e y on frequent pattern mining  Univ of Helsinki Tech Rep 2003  C Bor gelt Ef cient implementations of apriori and eclat in  2003 p 90  Frequent itemset mining dataset repository   http mi.ua.ac.be/data  J Rabae y  A Chandrakasan and B Nik oli  c  2nd ed Pearson Education 2003 
100 1000 10000 5 50 500 5000 re_sup = 0.12 Eclat-6C \(32nm Eclat-1G \(28nm Apriori-AP 45nm Apriori-AP 32nm Apriori-AP 28nm Computation Time \(s Size of Dataset \(MB Eclat-6C \(32nm Eclat-1G \(28nm Apriori-AP 45nm Apriori-AP 32nm Apriori-AP 28nm GPU fails for re_sup = 0.08 re_sup = 0.08 
GPU fails re_sup = 0.42 re_sup = 0.42 Eclat-6C \(32nm Eclat-1G \(28nm Apriori-AP 45nm Apriori-AP 32nm Apriori-AP 28nm  Computation Time \(s Size of Dataset \(MB Eclat-6C \(32nm Eclat-1G \(28nm Apriori-AP 45nm Apriori-AP 32nm Apriori-AP 28nm GPU fails re_sup = 0.3 re_sup = 0.3 b T100 Figure 11 Performance prediction with technology normalization as a function of input size implementation In contrast the capability of our AP ARM solution scales nicely with the data size since the AP was designed for processing streaming data With the challenge of the big data era a number of other complex pattern mining tasks such as frequent sequential pattern mining and frequent episode mining have attracted great interests in both academia and industry We plan to extend the proposed CPU-AP infrastructure and automaton designs to address more complex pattern-mining problems A CKNOWLEDGMENT This work was supported in part by the Virginia CIT CRCF program under grant no MF14S-021-IT by C-FAR one of the six SRC STARnet Centers sponsored by MARCO and DARPA NSF grant EF-1124931 and a grant from Micron Technology R EFERENCES  J Han 
et al Data Min Knowl Discov Proc of VLDB 94 IEEE Trans on Knowl and Data Eng Proc of SIGMOD 00 Proc of CLUSTER 11 J Supercomput et al ACM Trans Reconìgurable Technol Syst et al IEEE TPDS Proc of IPDPSê14 Proc of SIGMOD 93 Proc of Fifth International Symposium on Highly-Efìcient Accelerators and Reconìgurable Technologies et al Proc of Supercomputing 96 et al Proc of VLDB 07 Proc of PAKDD 03 et al IAENG Intl J Comp Sci et al Proc of DaMoN 09 Proc FIMI 03 Digital Integrated Circuits 
1 10 100 1000 10000 0.1 1 10 100 1000 
a Webdocs 
699 


