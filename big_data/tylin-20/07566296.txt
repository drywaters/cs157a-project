This full-text paper was peer-reviewed and accepted to be presented at the IEEE WiSPNET 2016 conference  A Review on Frequent Itemset Mining Algorithms in Social Network Data  Ankit N. Dharsandiya Department of Computer Engineering C.G.P.I.T, Uka Tarsadia University Bardoli, India ankitnd043@gmail.com Mihir R. Patel Department of Computer Engineering C.G.P.I.T, Uka Tarsadia University Bardoli, India mihir.patel@utu.ac.in   Abstract A social networking site such as Facebook, Twitter and Linked In generates a terabyte of data. The Frequent Itemset 
Mining \(FIM\ is most well known technique to extract knowledge from data. Mining terabytes of data using Frequent Itemset Mining technique on a single computer is not efficient MapReduce framework is used for mining such large data in a parallel manner. MRApriori, IMRApriori, BigFIM ClustBigFIM, MREclat are used for Frequent Itemset Mining with MapReduce framework. In this paper we have discussed different Frequent Itemset mining algorithms with MapReduce framework and compared in terms of scalability, speedup and 
execution time Index Terms Frequent Itemset Mining \(FIM\MapReduce framework, Apriori algorithm, Eclat algorithm, Social network data  I   I NTRODUCTION  Frequent Itemset Mining \(FIM\ is most popular technique in data mining and data analysis for extract frequent itemset from dataset. Frequent Itemset Mining is very useful in some data mining task such as association mining, multidimensional patterns mining, sequential pattern mining, correlation, and 
many other mining tasks [1 Social networking sites generate terabytes or more data per day. This type of data referred as Big Data which have high volume, high velocity and high verity of information. It would be lucrative for companies for knowing the words that are more occurring in particular discussion. Dataset size of social networking sites is very large which is not mining with single computer. Because it have limitation like RAM, processor and storage space Mining such large data needs parallelization for improving 
performance. But when parallelization used several issues such as load balancing, data partition and data distribution, job assignment and job monitoring occurs [1  F o r  ef f e ctiv ely  handle such issues MapReduce framework used MapReduce framework is proposed by Google in 2014 for processing large amount of data in distributed manner [2   MapReduce model is a programming model and written in C 3  It h a ndl e l o a d b a l a nce d  f a ult to le ranc e  da ta  dist ri bu ti on  and partition very effectively so that user only focus on the 
mining algorithm [1   It h a s 2 f u n ction m a p f u n c t i on  a n d reduce function. Map function on each node take input as key/value pair and give local frequent itemset in key/value pair which is given o the reduce function as a input. Reduce function combine key/value pair and generate global key/value pair [1, 3               Fig. 1 Hadoop based MapReduce Architecture [2  Hadoop MapReduce is a software framework for parallel processing of large dataset on multiple computer nodes 
Hadoop is an open source framework proposed by Google for store and process Big Data in a distributed manner using number of computer with simple programming model [3  Hadoop Distributed File System \(HDFS\tore and process Big Data. HDFS is high fault tolerance and designed using lowcost hardwa u c e splits  w hole dataset i n to  number of equal sized blocks and distributed it to the multiple nodes. Map function fetch key/value pair from HDFS and generate intermediate key/value pair. These key/value pair is given to the reduce function for combine value for same key which are fetched from multiple nodes. These whole 
procedures are shown in Fig. 1 II  RELATED  WORKS Several Frequent Itemset Mining Algorithms with MapReduce framework are introduced to extract frequent itemset from Big Data. Here we discuss some of FIM algorithms and compared in terms of speedup scaleup and execution time 1046 978-1-4673-9338-6/16/$31.00 c  2016 IEEE 


This full-text paper was peer-reviewed and accepted to be presented at the IEEE WiSPNET 2016 conference A  MapReduce Apriori algorithm \(MRApriori MRApriori algorithm is based on Hadoop-MapReduce model for extracting frequent itemset from large dataset MRApriori algorithm has 2 phases for extracting frequent itemset from large dataset [3 Ma pRe du c e  li br ary s p lits w hol e dataset into equal sized splits and allocate split to computation nodes. In phase 1 each node apply Apriori algorithm to their splits with partial minimum support count equal the minimum support count multiplied by number of transaction in the splits And generate intermediates key/value pair where key is partial frequent itemset and value is partial count. These intermediate key/value pair is given to reduce function. Reduce function gives partial frequent itemset list \(L p    As shown in Fig. 2 L p is given as input to Map workers nodes\ phase 2. Then Map function of each nodes count occurrence of each element of partial frequent itemset \(L p in split and give output as key/value pair where key is element of L p and value is total occurrence of key in split. These key/value pair given to reduce function as an input and it combine value of same key and give global frequent itemset as a key/value pair where key is global frequent itemset and value is total occurrence in whole dataset [3                 Fig. 2 Data flow of MRApriori algorithm [3  MRApriori algorithm gives high speedup and scaleup as it use MapReduce model but it requires more execution time because of more partial frequent itemset in L p  B  Improved MapReduce Apriori algorithm \(IMRApriori IMRApriori algorithm modify the reduce function of phase 1 of MRApriori algorithm. In reduce function of phase 1 estimate support count as follows X.globalsupportCount  \(X.supportCount + \(\(\(s x D i  M - N x      1 Where s is given minimum support threshold, D i is split of dataset, M is total number of mapper and N x is number of mapper outputting frequent itemset X Due to estimated support count number of key/value pair in L p is less as compare to MRApriori algorithm so it take less execution time in phase 2 for finding global frequent itemset  A ll oth er step f o r extract in g  f r eq u e n t ite m s et i s sa m e  as MRApriori algorithm C  BigFIM BigFIM algorithm is combination of Apriori and Eclat algorithm for mining frequent itemset from large dataset. It has 3 steps for mining frequent itemset  1  Generating k-FIs BigFIM solve the problem of large tid-lists by generating k-FIs using Apriori algorithm. In this step each mapper node receive split of dataset and then it apply Apriori algorithm to generate local frequent itemset and given to the reduce function. Reduce function combine local frequent itemset, purned some itemset due to less support count compare to minimum support count and generate global frequent itemset. This global frequent itemset is redistribute to mapper as a candidates itemset for next level of Apriori algorithm. This procedure can be continuing k times to find kFIs 2  Finding Potential Extensions This step generate global tid-list for \(k+1\-FIs. Mapper fined local tid-list for k-FIs and gives it to reduce function. Reducer combines local tid-lists and makes global tid-list and assign complete prefix group to 3  Subtree Mining This step apply Eclat algorithm to prefix groups and generate \(k+1\-FIs BigFIM overcome the problem of Dist-Eclat such as it not requires whole dataset in memory to mine Subtree. So BigFIM gives high scaleup but speedup is low because of when candidate itemset is more in greater depth, than it not fit into main memory D  ClustBigFIM           Fig. 3 Block diagram of ClustBigFIM algorithm  ClustBigFIM algorithm is combination of k-means, Apriori and Eclat algorithms As s h o w n i n Fi g  3 k m e a n s  clustering algorithm apply to input dataset and generate 1047 


This full-text paper was peer-reviewed and accepted to be presented at the IEEE WiSPNET 2016 conference number of clusters. Then apply 3 step of BigFIM algorithm as we discussed above Due to first apply k-means algorithm and apply Apriori algorithm to separate cluster, less candidate itemset fit into memory which overcome speedup limitation of BigFIM E  MREclat MREclat algorithm use Eclat algorithm with vertical layout  A d v a nta g e of v e rtical la y o u t dataset as co m p are to  horizontal layout dataset is that it has not requires over scanning whole dataset for finding frequent itemset. MREclat is MapReduce based Eclat algorithm for mining frequent itemset from large dataset. It has 3 steps for extract frequent items 1  The Initial Step Map function of this step convert transaction database \(Horizontal database\to vertical database. Reduce function give frequent 2-itemset and their tid-lists 2  Balanced Group For good load balance partition items into balanced groups based on weight of each item Weight of each item is calculated using following equation  w i       2 Where n is the number of frequent 2-items prefixed by A  We sort those frequent 2-itemsets prefixed by A in the lexicographic order, and use   to denote the length of list of the j th frequent 2-itemset After we compute all the w for each frequent 1-itemset, we sort the tuples consisted by the frequent 1-itemset and its weight by the value of weight in a descending order. Then MREclat uses a greedy strategy to divide the tuples into groups, each group associated with an id 3  The Redistribution and Parallel Eclat Step Map function of this step redistributes frequent 2-itemset with same prefix into same node. Reduce function find frequent 2-itemset with its prefix using Eclat algorithm III  COMPARATIVE  ANALYSIS Comparison of various MapReduce based FIM algorithm shown in table I. As shown in table I MRApriori and IMRApriori algorithm gives high speedup and high scaleup because it uses MapReduce framework and require less number of scan to extract frequent itemset. But IMRApriori algorithm take less execution time as compare to MRApriori algorithm In IMRApriori algorithm number of partial frequent itemset in L p is less so phase 2 of IMRApriori algorithm take less execution time to extract frequent itemset from dataset TABLE I. COMPARISON OF MAPREDUCE BASED FIM ALGORITHM  Algorithm Speedup Scaleup Execution Time MRApriori High High More IMRApriori High High Less BigFIM Low High Less ClustBigFIM High High More MREclat High High More  BigFIM gives high scaleup as it not require whole dataset for mining a sub tree in Eclat algorithm. But it gives low speed up as in greater depth size of candidate itemset increase which is not fit into memory for mining k-FIs using Apriori ClustBigFIM overcome the problem of low speedup of BigFIM such as using k-means algorithm for generate cluster and then apply other step of BigFIM. But ClustBigFIM takes more execution time as it needs to execute k-means, Apriori and Eclat MREclat algorithm gives high speedup and scaleup because it use a vertical layout dataset in which it require less number of scan as compare to horizontal layout dataset. But MREclat algorithm takes more execution time because it require to convert horizontal layout dataset to vertical layout dataset first and then after apply another steps IV  CONCLUTION In this paper we analyzed and studied various FIM algorithms such as MRApriori, IMRApriori, BigFIM ClustBigFIM, MREclat used with MapReduce framework for mining Big Data. IMRApriori algorithm gives better result in terms of speedup, scaleup and execution time V  REFERENCES 1  Farzanyar, Zahra, and Nick Cercone. "Efficient mining of frequent itemsets in social network data based on MapReduce framework." In Proceedings of the 2013 IEEE/ACM International Conference on Advances in Social Networks Analysis and Mining pp. 1183-1188. ACM, 2013 2  Gole, Sheela, and Bharat Tidke. "Frequent Itemset Mining for Big Data in social media using ClustBigFIM algorithm In Pervasive Computing \(ICPC\2015 International Conference on pp. 1-6. IEEE, 2015 3  Yahya, Othman, Osman Hegazy, and Ehab Ezat. "An efficient implementation of Apriori algorithm based on HadoopMapreduce model." In Proc. of the 2012 4  Moens, Sandy, Emin Aksehirli, and Bart Goethals. "Frequent itemset mining for big data." In Big Data, 2013 IEEE International Conference on pp. 111-118. IEEE, 2013 5  Zhang, Zhigang, Genlin Ji, and Mengmeng Tang. "MREclat: An Algorithm for Parallel Mining Frequent Itemsets." In Advanced Cloud and Big Data \(CBD\013 International Conference on  pp. 177-180. IEEE, 2013  1048 


IEEE Sponsored World Conference on Futuristic Trends in Research and Innovation for Social Welfare \(WCFTR’16   Fig. 2  Execution Time in chess  Fig. 3  Memory Usage in foodmart  Fig. 4  Memory Usage in chess  Fig. 5  Candidate Count generated in foodmart  Fig. 6  Candidate Count generated in chess The candidate count generated in algorithm for mining the high utility itemset is measured For example in Fig 5. the candidate count generated by Two Phase Miner is less compred to the other algorithm. HUI Miner has high candidate generation with less minimum utility and sharply decreases when the minimum utility increases. The HUI miner performs better when minimum utility value is higher. FHM algorithm show linear decrease in candidate count when increasing the minimum utility. Fig 6 shows the candidate set generated in the chess dataset. HUI Miner has low candidate itemset generated  V  CONCLUSION  AND  FUTURE  WORK From the experiments done we can observe that FHM miner performs better in terms of execution speed but has high memory utilization and candidate set generation. HUI Miner has less candidate set generation and better memory utilization The number of candidate set generation is important to       


IEEE Sponsored World Conference on Futuristic Trends in Research and Innovation for Social Welfare \(WCFTR’16  improve the performance of the algorithm. Two phase algorithm does not save the utility of the itemset computed but the FHM and HUI miner computes and saves the utility of each itemset and the values are discarded after the computation of high utility itemsets. These calcul ated values can be stored for the computation of high utility ite msets whenever there is an insertion and modification in the database thereby decreasing the repetitive computation. Future research can be carried by utilizing the computed utility of itemset in insertion and modification transaction database. Tree based algorithm can be devised with better memory utilization and execution speed  R EFERENCES  1  R.AgraRwal,T.Imielinski, and A.swami “Mining Association rules Between Sets of Items in Large Database” Proc 12th ACM SIGMOD, pp 207-216, 1993 2  R.Agrawal and R.srikant, “Fast Algorithms for Mining Association Rules”, Proc 20th Int’l Conf. Very Large Databases VLDB’94\87 -499 1994 3  R.Agrawal and R.Srikant, “Mining  Sequential Patterns”, Proc 11th Int’l Conf, Data Engg, pp. 3-14, March 1995 4  R.Chan, Q.Yang and Y.Shen “Mining High Utility Itemsets Proc. IEEE Third Int’l Conf.Data Mining , pp 19-26 Nov 2003 5  J.H.Chang, “Mining Weighted Sequential patterns in a Sequence Database with a Time- Interval Weight”, Knowledge – Based Systems, Vol. 24 no. 1, pp 1-9 2011 6  Frequent Itemset Mining Implementations Repository http://fimi.cs.helsink.fi/2012 7  Fournier-Viger, Philippe, et al. "Fhm: Faster high-utility itemset mining using estimated utility co-occurrence pruning." Foundations of intelligent systems. Springer International Publishing, 2014. 83-92 8  Goyal, Vikram, Siddharth Dawar, and Ashish Sureka. "High Utility Rare Itemset Mining over Transaction Databases." Data bases in Networked Information Systems Springer International Publishing, 2015. 27-40 9  Krishnamoorthy, Srikumar. "Pruning strategies for mining high utility itemsets." Expert Systems with Applications 42.5 \(2015 2371-2381 10  Lan, Guo-Cheng, et al. "Fuzzy utility mining with upper-bound measure."Applied Soft Computing 30 \(2015\-777 11  Lin, Jerry Chun-Wei, Wensheng Gan, and Tzung-Pei Hong. "A fast updated algorithm to main tain the discovered high-utility itemsets for transaction modification." Advanced Engineering Informatics 29.3 \(2015\-574 12  Lin, Jerry Chun-Wei, et al. "An Incremental High-Utility Mining Algorithm with Transaction Insertion." The Scientific World Journal 2015 \(2015 13  Lin, Jerry Chun-Wei, et al. "Efficient algorithms for mining upto-date high-utility patterns." Advanced Engineering Informatics 29.3 \(2015\-661 14  Liu, Ying, Wei-keng Liao, and Alok Choudhary. "A two-phase algorithm for fast discovery of high utility itemsets." Advances in Knowledge Discovery and Data Mining. Springer Berlin Heidelberg, 2005. 689-695 15  Liu, Mengchi, and Junfeng Qu. "Mining high utility itemsets without candidate generation." Proceedings of the 21st ACM international conference on Information and knowledge management. ACM, 2012 16  Lu, Tianjun, Yang Liu, and Le Wang. "An Algorithm of Top-k High Utility Itemsets Mining over Data Stream." Journal of Software 9.9 \(2014 17  M.Liu and J.Qu “Mining high utility itemsets without candidate generation” ACM international conference on Information and knowledge management pp.55-64, 2012 18  Sun, Chongjing, et al. "Personalized privacy-preserving frequent itemset mining using randomized response." The Scientific World Journal 2014 \(2014 19  Song, Wei, Yu Liu, and Jinhong Li. "Mining high utility itemsets by dynamically pruning the tree structure." Applied intelligence 40.1 \(2014\43 20  Shie, Bai-En, S. Yu Philip, and Vincent S. Tseng. "Efficient algorithms for mining maximal high utility itemsets from data streams with different models." Expert Systems with Applications 39.17 \(2012\7-12960 21  Tseng, Vincent S., et al. "Efficient Algorithms for Mining the Concise and Lossless Representation of High Utility Itemsets." Knowledge and Data Engineering, IEEE Transactions on 27.3 \(2015\726-739 22  Vincent S. Tseng, Bai-En Shie, Cheng-Wei Wu, Philip S. Yu Efficient Algorithms for Mining High Utility Itemsets from Transactional Databases", IEEE Transactions on Knowledge Data Engineering, vol.25, no. 8, pp. 1772-1786, Aug. 2013 23  Wu, Cheng Wei, et al. "Mining top-K high utility itemsets." Proceedings of the 18th ACM SIGKDD international conference on Knowledge discovery and data mining. ACM 2012  


collaborate collaborate assert  Call pattern Failing test cases  Passing test cases  we tested all four fault locators mentioned in Table 2 in and Ochiai Equation 6 came out as the best performing one For our running example the suspiciousness gets a suspiciousness with the highest suspiciousness Equation 7 We choose the maximum instead of average for the suspiciousness score because the technique is looking for exceptional traces one unique and highly suspicious pattern is more important than several unsuspicious ones Those methods without call patterns set have suspiciousness 0 The suspiciousness for method  we can now compare the e\002ectiveness of these two heuristics from the perspective of a continuous integration scenario We give some details about the dataset used for the comparison  xisting ontrolled ava programs The database contains meta info about each fault including the source classes modi\223ed to 223x the fault the test cases that expose the fault and the test cases that trigger at least one of the modi\223ed classes Although the framework does not explicitly list the modi\223ed methods we could reverse engineer those by means of the patches that come with the framework Note that we excluded 3 faults of Apache Commons Lang 2 and  of Table 5 listing the average and standard deviation per project respectively The high number of for the Closure project is an indication that the Closure tests exercise a lot of the base code yet the high standard deviation of 407 compared to an average of 306 indicating a few outlier tests which cover a lot of the base code 006 007 b t The Defects4J dataset does not distinguish between unit tests or integration tests However one project Closure Compiler gravitates towards integration tests Therefore the results of the Closure Compiler should serve as circumstantial evidence during the comparison As mentioned earlier we compare by means of the wasted e\002ort 7  the evaluation metric Wasted E\002ort to 223nish with the research questions and protocol driving the comparison a 003  and the variant proposed in this paper referred to as S m 006 is the number of non-faulty methods with equal rank to the faulty method This deals with ties in the ranking The comparison is driven by the following research questions 279 Suspiciousness per method W Table 4 An Example Test Coverage Matrix for Method e e s signals the presence of unit tests as well On the other hand the low number of  T T for the other project hints at mostly unit tests yet Chart has a standard deviation dataset does not distinguish between unit tests or integration tests As argued in the Scenario Section 3 this is a crucial factor when assessing a fault localisation heuristic in a continuous integration context We therefore manually inspected a sample of test methods and noticed that four projects Apache Commons Math Apache Commons Lang Joda-Time and JFreeChart mainly contain unit tests they have a small often empty set-up method and test methods contain only a few 3 Wasted E\002ort 003 2 8  Where      X X X X X X X X X X X X X    W e n e W  003 265 265 m n  W metric commonly adopted in recent research 41 42 T he w asted e\002ort i ndicates the n um b er of non-faulty methods to inspect in vain before reaching the faulty method wasted e\002ort  esting that de\223nes a few template methods which are the entry point to several classes in the base code of the project To corroborate this manual inspection we calculated the number of methods triggered in each fault spectrum analysis The assumption here is that integration tests exercise several methods in various classes consequently the fault spectrum analysis should trigger many methods as well Thus projects which gravitate towards integration testing should trigger many methods while projects gravitating towards unit tests should trigger far fewer The results are shown in the last two columns  9 9  1  with highest suspiciousness Table 4   6 6 6 6        Ranking  is the number of non-faulty methods ranked strictly higher than the faulty method m CompilerTestCase patterned spectrum analysis patterned spectrum analysis  which is the suspiciousness of the call pattern       1 0 1 0 0 1 1 1 1 1 0 0 1 1 1 1 0 0 1 1 1 1 0 0       http://defects4j.org faults of Apache Commons Math and 1 fault of Joda-Time since the fault was not located inside a method Unfortunately the 265 Defects4J Defects4J Defects4J   max X\003 Finally a ranking of all executed methods is produced using their suspiciousness W\(m The suspiciousness of the method indicates its likelihood of being at fault Those methods with the highest suspiciousness appear a the top in the ranking 5 CASE STUDY SETUP X        n X  200 m 200 n s One project however Closure Compiler relies on integration tests The test cases there are a subclass of W atabase of aults to collaborate Each method 5 in our running example is 1.0 which is the suspiciousness of the call pattern  Given the current state of the art referred to as We use 351 real faults from 5 open source java projects Apache Commons Math Apache Commons Lang Joda-Time JFreeChart and Google Closure Compiler The descriptive statistics of these projects are reported in Table 5 These faults have been collected by Just et al into a database called nable tudies for 1.0 0.7 0.7 0.7 is given in Table 4 raw spectrum analysis W 6   6 11 15 11 13 11 15 11 11 15 e e n n W t t T\007 T\007 F P f p f p f f f f p Dataset d f c t J       005  007  for each call pattern of method e e m m  1 2 3 


Project 153.1 89.3 586.0 306.9 One dimension of variation in spectrum based fault localisation and Naish2 for raw spectrum analysis Tarantula  or the same  and list the absolute numbers per project See Table 7 Project Lang Chart 101 76  238 68  T 201 8\(6 6\(5 4\(3 7\(27 7\(27 2\(2   85 19 140.8 Lang   22 2,245 55.2  28 53 209.5 Chart   96 50 7 407.5  90 83 5 2043.0 1228.9  Ochiai 46 35 against the state of the art raw spectrum analysis  22 21 13 13 14 23 12 19 3\(12 3\(12 30 23  80 23  351  Table 5 Descriptive Statistics for the Projects Used in Our Experiments 204 Defects4J  http://defects4j.org  Protocol 013 10  Time  for all relevant test cases i.e all test classes which trigger at least one of the source classes modi\223ed to 223x the fault as recorded in the Defects4J Time 1 2 3 4  Apache Commons Lang 205 http://commons.apache.org/lang   Google Closure Compiler 205 http://code.google.com/closure/compiler 201 ofTests  is strictly less  Motivation 202 is the fault locator Table 2 lists the most popular ones As explained in Section 4.5 for comparison purpose we use Ochiai for patterned spectrum analysis 202  Apache Commons Math 205 http://commons.apache.org/math   Joda-Time 205 http://joda.org/joda-time   JFreeChart 205 http://jfree.org/jfreechart  Table 7 Comparing Wasted E\002ort Patterned Spectrum Analysis vs Raw Spectrum Analysis Source KLoC  Methods triggered  3,602 6 4,130 2,205 Closure  7,927 205 Which ranking results in the lowest wasted e\002ort raw spectrum analysis or patterned spectrum analysis  205 How often do raw spectrum analysis and patterned spectrum analysis rankings result in a wasted e\002ort 205 How does the number of triggered methods a\002ect the wasted e\002ort of raw spectrum analysis and patterned spectrum analysis   we actually tested all four fault locators Table 2 Naish2 performed the best on the Defects4J 50 38 75 56 81 61 20 15 109 82 To run the fault spectrum analysis we check out a faulty version   for each project Then we run the actual spectrum based fault localisation dataset Given the continuous integration context for this research this is the most logical way to minimise the number of tests which are fed into the spectrum based fault localisation 205 Which ranking results in the lowest wasted e\002ort raw spectrum analysis or patterned spectrum analysis  accordingly The result can be seen in Figures 1a 1b 1c 1d and 1e Next we count all the faults for which the wasted e\002ort in patterned spectrum analysis 69 66 36 58 16 62 16 62 Closure To illustrate how the rankings of the heuristics di\002er we inspect fault 40 of the Closure project where the wasted e\002ort for patterned spectrum analysis  On the other hand just marking whether or not the method is executed is not discriminating in raw spectrum analysis the wasted e\002ort is 183 This is due to the fact that the faulty method has a call pattern which is unique in all failing test cases hence is easily picked up by patterned spectrum analysis Average number of methods triggered by the Standard deviation  Test KLoC Total Total  1 2 3 4 5 RQ1 RQ2 RQ3 RQ1   Fault Lo cator inthecasestudy  Methods triggered  In this section we address the three research questions introduced in Section 5 This allows for a multifaceted comparison of the e\002ectiveness of patterned spectrum analysis To determine the best performing heuristic we plot the wasted e\002ort for all of the faults for both heuristics To allow for an easy exploration of the nature of the di\002erence we sort the faults according to the wasted e\002ort of raw spectrum analysis Age years Faul Locator Math  Math is 0.5 the faulty method is ranked 223rst while for raw spectrum analysis  of Bugs 106 11 65 12 27 11 26 133 Based on the scenario Section 3 we investigate how many times the location of the fault is ranked in the 223rst 10 items Again based on the scenario Section 3 we gauge the impact of integration tests The number of methods triggered by the fault spectrum analysis acts as a proxy for the degree of integration tests in the test suite dataset with method level granularity as can be seen in Table 6 There we compare the wasted e\002ort of Naish2 against the wasted e\002ort of other fault locators using the 133 defects in the Closure project For most defects Naish2 results in a better or equal ranking only for a few defects is the ranking with other locators better For space reasons we do not show the comparison on other projects but there as well Naish2 was the best Hence we choose Ochiai for patterned spectrum analysis and plot the wasted e\002ort for patterned spectrum analysis 104 62 26 26 133 33 9  However for the optimal con\223guration of raw spectrum analysis  Note that this explains why the number of methods triggered by a fault spectrum is a good indicator for the integration tests since the tests are chosen such that they cover all changes made to 223x the defect 6 RESULTS AND DISCUSSION   strictly more  265 003  V fault   5 This is the 223rst step of the comparison assessing which of the two fault localisation methods provides the best overall ranking Motivation Motivation 204\204 Table 6 Naish within Raw Spectrum Analysis vs Tarantula Ochiai and T Thenumberof failing test cases covering the faulty method and non-faulty methods is the same 169 Yet the non-faulty methods have 280 Spectrum based fault localisation 


Project Lang Chart Table 8 shows for each project the number of faults where the wasted e\002ort is within the range of 10 with both heuristics For three projects Lang Time and Chart the performance of the patterned spectrum analysis is noticeably better These 223ndings con\223rm that patterned spectrum analysis patterned spectrum analysis PSA Time 10 e Closure 59 57 104 54 87 1 14 54 2 13 50 3 56 42 30 23 133 170 48 351 201 PSA  patterned spectrum analysis  202 RSA  raw spectrum analysis  e  is comparable but still better than the one of the raw spectrum analysis n 201 202 RQ2 patterned spectrum analysis raw spectrum analysis raw spectrum analysis 013 013 How often do How does the number of triggered methods a\002ect the wasted e\002ort of and 10   Moreover this improvement is a lot better for the Closure project the one system in the data set which gravitates towards integration tests where we see an improvement for 76 of faults 101 out of 131 more suspiciousness than faulty method because the number of passing test cases covering the non-faulty methods is less Since more passing test cases cover the faulty method high value of p 013 f r 016 017 020 021 is lower than rankings result in a wasted e\002ort  205 Inspired by the scenario in Section 3 we count how many times the location of the fault is ranked in the top 10 To deal with ties in the ranking especially at position 10 we identify these as having a wasted e\002ort 73 70 55 89 16 62 16 62 Closure 216 62 ranks more faults in the top 10 However there are still a large amount of faults where the ranking is poor wasted e\002ort 205 heuristic should obtain a good ranking for a particular fault regardless of the number of triggered methods Again based on the scenario Section 3 we gauge the impact of integration tests Therefore for each fault we calculate the number of methods triggered by the fault spectrum analysis We then sort the faults according to the number of methods and inspect the trend with respect to the number of triggered methods Unfortunately the standard deviation for the number of triggered methods is really high see the 003 patterned spectrum analysis Total Total raw spectrum analysis raw spectrum analysis 201\212\202 Figure 1 The comparison plots of all the rankings in each Lang 013 10 Especially for the Closure project less than half 42 of the faults are ranked in the top 10 Hence there is still room for improvement which we will cover in Section 7 Figure 2  Triggered Methods vs Wasted E\002ort RQ3                                              For 68 faults in the dataset the wasted e\002ort with RSA succeeds in ranking the root cause of the fault in the top 10 for 62 of the faults against 48 for and a Math Math b Lang c Time d Chart  it renders the faulty method less suspicious 10 14 62 26 26 26 46 In Section 5 we argued that the number of methods triggered by the fault spectrum analysis is an indicator of the gravitation towards integration tests see also the last two columns in Table 5 If that is the case a good spectrum based fault localisation column in Table 5 and a normal scatterplot mainly showed the noise Therefore we group the faults according to the triggered methods into 11 bins of 32 elements As these numbers did not divide well there were two bins having 30 and 33 triggered methods respectively This binning was decided as a trade-o\002 for having an equal number of elements per bin and enough bins to highlight a trend in the 281  Whereas for the remaining two projects Math and Closure the performance of the patterned spectrum analysis Patterned Spectrum Analysis Raw Spectrum Analysis Patterned Spectrum Analysis Raw Spectrum Analysis Patterned Spectrum Analysis Raw Spectrum Analysis Patterned Spectrum Analysis Raw Spectrum Analysis Patterned Spectrum Analysis Raw Spectrum Analysis The wasted effort 16 46 99 34 35 70 91 3 8 15 17 27 47 53 55 59 63 75 89 90 94 102 9 10 52 5 49 65 72 100 105 106 73 98 25 31 45 54 93 96 84 92 95 36 41 66 77 101 88 69 83 67 79 86 97 103 42 2 81 26 11 57 13 61 85 43 14 38 1 30 4 33 68 78 64 6 37 56 22 21 60 80 40 28 76 62 50 87 82 23 24 44 51 48 39 29 58 71 19 7 18 32 20 74 1 26 51 76 101 126 151 1 26 51 76 101 126 151 wasted effort 12 22 31 15 21 24 25 29 33 35 36 43 49 51 61 2 14 37 40 46 48 60 4 26 44 45 58 1 5 11 19 28 30 39 53 54 59 62 65 55 63 3 13 16 20 34 41 52 47 42 17 64 38 32 9 6 7 27 10 50 8 18 1 26 51 76 101 1 26 51 76 101 wasted effort 3 15 2 8 9 23 1 14 17 5 18 16 4 7 26 21 25 22 6 13 24 10 12 19 20 27 3 15 2 8 9 23 1 14 17 5 18 16 4 7 26 21 25 22 6 13 24 10 12 19 20 27 1 51 101 151 201 251 301 351 401 451 1 51 101 151 201 251 301 351 401 451 wasted effort 18 24 3 9 10 11 17 5 8 16 20 22 4 13 21 7 6 1 12 2 14 19 26 15 23 25 1 51 101 151 201 251 301 351 401 451 501 1 51 101 151 201 251 301 351 401 451 501 wasted effort 7 46 56 122 48 2 104 124 74 6 109 9 83 68 116 90 86 27 32 97 128 16 115 81 52 57 60 42 62 63 69 75 23 26 88 65 77 84 73 1 133 51 113 76 117 53 61 38 34 105 29 72 78 96 43 103 33 4 87 49 30 85 15 112 25 118 125 82 20 110 132 39 45 89 71 10 114 5 24 64 35 54 40 3 127 70 28 120 98 121 37 19 100 11 99 108 14 17 131 50 95 66 58 41 80 92 93 47 44 91 67 8 126 31 36 79 55 13 21 22 106 119 123 130 102 111 129 12 18 101 94 107 59 7 46 56 122 48 2 104 124 74 6 109 9 83 68 116 90 86 27 32 97 128 16 115 81 52 57 60 42 62 63 69 75 23 26 88 65 77 84 73 1 133 51 113 76 117 53 61 38 34 105 29 72 78 96 43 103 33 4 87 49 30 85 15 112 25 118 125 82 20 110 132 39 45 89 71 10 114 5 24 64 35 54 40 3 127 70 28 120 98 121 37 19 100 11 99 108 14 17 131 50 95 66 58 41 80 92 93 47 44 91 67 8 126 31 36 79 55 13 21 22 106 119 123 130 102 111 129 12 18 101 94 107 59 1 151 351 551 751 951 1151 1401 1651 1901 1 151 351 551 751 951 1151 1401 1651 1901 0 200 400 600 800 1000 bin Wasted effort 4\21243 44\21271 72\21291 92\212134 137\212202 204\212397 423\212892 917\2121262 1273\2121721 1752\2122464 2523\2125825 Table 8  Faults where Wasted E\002ort is patterned spectrum analysis Raw Spectrum Analysis Patterned Spectrum Analysis 16 46 99 34 35 70 91 3 8 15 17 27 47 53 55 59 63 75 89 90 94 102 9 10 52 5 49 65 72 100 105 106 73 98 25 31 45 54 93 96 84 92 95 36 41 66 77 101 88 69 83 67 79 86 97 103 42 2 81 26 11 57 13 61 85 43 14 38 1 30 4 33 68 78 64 6 37 56 22 21 60 80 40 28 76 62 50 87 82 23 24 44 51 48 39 29 58 71 19 7 18 32 20 74 12 22 31 15 21 24 25 29 33 35 36 43 49 51 61 2 14 37 40 46 48 60 4 26 44 45 58 1 5 11 19 28 30 39 53 54 59 62 65 55 63 3 13 16 20 34 41 52 47 42 17 64 38 32 9 6 7 27 10 50 8 18 18 24 3 9 10 11 17 5 8 16 20 22 4 13 21 7 6 1 12 2 14 19 26 15 23 25 


4-43 13.0 11.5 17.6 15.5 23.5 20.0 51.4 70.8 14.0 20.8 11.2 24.0 is often able to push the faulty method high in the ranking however there are several cases where it never reaches the top 10 A nice example is fault 126 in Closure where the wasted e\002ort for in class com.google.javascr patterned spectrum analysis Bin 1.0 1.5 1.5 1.5 1.5 1.5 2.0 3.5 1.9 3.5 5.8 8.2 2.5 5.0 is 85.5 This value is still lower than the one given by Q1 Q3 Q3 PSA Q1 1.5 2.5 1.0 1.8 2.9 3.0 6.8 2.2 2.8 8.5 2.8 9.1 2.4 5.2 2.8 3.8 3.2 9.1 1.5 3.2 8.0 73.0 5.0 9.0 38.5 10.4 263.0 511.6 56.4 33.9 97.8 203.1 40.9 12.4 50.0 196.0 77.5 11.0 115.5 561.1 patterned spectrum analysis raw spectrum analysis patterned spectrum analysis patterned spectrum analysis Table 9  Triggered Methods vs Wasted E\002ort  is an itemset hence the call pattern is not order preserving and has no repetitive method calls Note that the importance of the call-order was also pointed out by Lo et al  016 patterned spectrum analysis patterned spectrum analysis patterned spectrum analysis patterned spectrum analysis its\(Node,int,String number of triggered methods if any For each of the bins we calculated the 223rst quartile median and the third quartile listing them all in Table 9 and plotting them in a series of boxplots Figure 2 Table 9 and Figure 2 illustrate that the number of methods triggered has little e\002ect on Distribution Second ipt.jscomp.MinimizeExitPoints reveals that the developers removed the 215if check\216 with a finally Listing 2 Code snippet for a sample method 1 public boolean contains char ch  2 char  thisBuf  buffer 3  Correct code 4 for in ti=0;i this.size i  5  Incorrect code 6 for  int i  0;i  thisBuf.length;i  7 if   ch  8 return true  9  10  11   205 do we measure what was intended  216in class 215 org.apache.commons.lang.text.StrBuilder 44-71 72-91 92-134 137-202 204-397 423-892 917-1262 1273-1721 1752-2464 2523-5825  however quite a lot on is because the order of method calls is crucial Indeed the call pattern in  In this research we adopted the wasted e\002ort metric to compare raw spectrum analysis 216in class\215 distribution.UniformReal patterned spectrum analysis As a future improvements of heuristic we can infer some suggestions for improvement regarding future variations First of all an inherent limitation is that a faulty method which does not call any other methods will always be ranked at the bottom Indeed such methods don\220t have a call pattern which is the primary coverage element appearing in the test coverage matrix thus the method gets suspiciousness 0 In our case study we noticed a few cases where none of the faulty methods had any call pattern More speci\223cally there are 4 such cases in the Math project 3 in the Chart project 2 in the Time and Lang projects and only 1 in the Closure project The best example corresponds to the highest wasted e\002ort on fault 60 of the Lang project See Listing 2 Indeed the faulty method 215 contains\(char performs better for integration tests 7 POSSIBLE IMPROVEMENTS  we might incorporate statements or branches into the hitspectrum The call-order of methods as well is relevant information to incorporate into the hit-spectrum 8 THREATS TO VALIDITY ndInclusive 202 201 Upon closer inspection of those faults ranked high by the 216 gets suspiciousness 0 because the for loop only performs direct accesses to memory and never calls any methods Similarly the highest wasted e\002ort for fault 22 in the Math project is due to the faulty method 215 isSupportUpperBou  we found a unique call pattern Listing 3 which is only called in the failing tests The bug 223x 4 RSA block This 215if check\216 involves the last 3 calls in Listing 3 lines 4-6 Despite being unique the reason why this call pattern was not picked up by Median Median  The last four bins in particular contain faults which trigger more than thousand methods The median wasted e\002ort for 216 which again never calls any other methods In this case the method body contained a single statement 215 return false 216 the bug 223x replaced it by 215 return true 216 A last example is fault 22 in Time project where the fault resided in a faulty constructor hence did again not have any method call pattern 532.5 yet it is too high to ever be considered in a realistic scenario Manually analysing the traces of the faulty method tryMinimizeEx As with all empirical research we identify those factors that may jeopardise the validity of our results and the actions we took to reduce or alleviate the risk Consistent with the guidelines for case studies research see 37 w e organise them into four categories against  However in information retrieval rankings where users do not want to inspect all outcomes other measures are considered such as Mean Reciprocal 4 https://github.com/google/closure-compiler/commit/bd2803 282 patterned spectrum analysis 201 202 is four to eighteen times lower than raw spectrum analysis raw spectrum analysis patterned spectrum analysis Construct validity The better rankings for Closure in Table 7 and Table 8 are inconclusive as one case is not enough to generalise upon Yet based on an analysis of the number of methods triggered by the fault spectrum there is at least circumstantial evidence that Wasted E\002ort 006 007 b t 017 020 021 raw spectrum analysis Listing 3 Unique call sequence in faulty method tryMinimizeExits\(Node,int,String 1 Node.getLastChild 2 NodeUtil.getCatchBlock\(Node 3 NodeUtil.hasCatchHandler\(Node 4 NodeUtil.hasFinally\(Node 5 Node.getLastChild 6 tryMinimizeExits\(Node int String 


Thanks to prof Martin Monperrus for reviewing an early draft of this paper This work is sponsored by i the Higher Education Commission of Pakistan under a project titled 215Strengthening of University of Sindh Faculty Development Program ii the Institute for the Promotion of Innovation through Science and Technology in Flanders through a project entitled 215Change-centric Quality Assurance CHAQ with number 120028 patterned spectrum analysis patterned spectrum analysis patterned spectrum analysis patterned spectrum analysis raw spectrum analysis 205 is the result dependent on the tools  All the tools involved in this case study i.e creating the traces calculating the  hence there as well the risk of faults is small is a class of heuristics known to be e\002ective for localising faults in existing software systems These heuristics compare execution traces of failing and passing test runs to produce a ranked list of program elements likely to be at fault The current state of the art referred to as  comprises several variants typically classi\223ed according to two dimensions the granularity statement 204 block 204 method 204 class and the fault locator function Tarantula Ochiai T and Naish2 In this paper we explore a third dimension the hitspectrum More speci\223cally we propose a variant referred to as and http://www.philippe-fournier-viger.com/spmf Defects4J performs better for integration tests Despite this improvement we collect anecdotal evidence from those situations where the 5 Internal validity patterned spectrum analysis 205towhatextentisitpossibletogeneralise the 223ndings  In our study we experimented with 351 real faults drawn from 223ve representative open source object oriented projects from 9 CONCLUSION Spectrum based fault localisation 216 The test case which exposes the defect calls both methods yet the test case fails on the 223rst assertion calling the 215 205 are there unknown factors which might a\002ect the outcome of the analyses  patterned spectrum analysis 216 method The question then is what a fault localisation should report one location or all locations  Furthermore how should we assess the ranking of multiple locations In this research inspired by earlier work 39 w e to ok the assumption that rep orting one location is su\003cient and use the highest ranking of all possible locations However one could make other assumptions patterned spectrum analysis renderer.category.MinMaxCategoryRenderer setGroupStroke\(Stroke CorrectnessoftheOracle Defects4J Defects4J raw spectrum analysis Defects4J 10 ACKNOWLEDGMENTS ranking is less adequate and derive suggestions for future improvements 283 216 T h e 223rst change is to override 215 Also equals\(Object setGroupStroke\(Stroke equals\(Object Fault Masking External validity Reliability Multiple faults  One often heard critique on fault localisation heuristics in general and raw spectrum analysis spectrum based fault localisation patterned spectrum analysis raw spectrum analysis raw spectrum analysis patterned spectrum analysis 5  One particular phenomenon which occurs in a few faults in the dataset is 215fault masking\216 This i s a fault whic h is spread o v er m ultiple locations and where triggering one location already fails the test The 223x for fault 23 of project Chart for instance comprises two changes in two separate methods of the class 215  The continuous integration scenario in Section 3 makes the assumption that the test oracle itself is infallible However this does not hold in practice Christophe et al observed that functional tests written in the Selenium library get updated frequently  We ignore the e\002ects of the tests being at fault in this paper but here as well point out that this is something to be studied in future work rankings have been created by one of the authors They have been tested over a period of 2 years thus the risk of faults in the tools is small Moreover for the calculation of the  which extends the hitspectrum with patterns of method calls extracted by means of frequent itemset mining The motivation for the is more e\002ective in localising the fault For 68 faults in the dataset the wasted e\002ort with is lower than succeeds in ranking the root cause of the fault in the top 10 for 63 of the defects against 48 for patterned spectrum analysis using the raw spectrum analysis 216 method and the second involves changes in method 215 is indeed a lot better on integration tests in other systems dataset the most recent defect dataset currently available Obviously it remains to be seen whether similar results would hold for other defects in other systems In particular there is a bias towards unit test in the variant stems from a series of contacts with software developers working in Agile projects and relying on continuous integration to run all the tests Complex systems with multiple branches and staged testing could really bene\223t from fault localisation Faults in integration tests in particular are very relevant they seldom occur but if they do they have a big impact on the team productivity Inspired by the continuous integration motivational example we compare Rank MRR or Mean Average Precision MAP 39 It is unclear whether the use of these relative evaluation metrics would alter the results Nevertheless the use of an absolute metric alleviates other concerns 33 T herefore the impact is minimal 216 method thereby masking the 215 in particular is that when multiple faults exist the heuristic will confuse their e\002ects and its accuracy will decrease Two independent research teams con\223rmed that multiple faults indeed in\224uence the accuracy of the heuristic however it created a negligible e\002ect on the e\002ectiveness 12  W e i gnore t he p o ten tial e\002ect of m ultiple faults in this paper Nevertheless future research should study the e\002ect of multiple faults dataset with only the Closure project gravitating towards integration tests Further research is needed to verify whether the rankings we compared as best as possible against the results reported in earlier papers The algorithm for frequent itemset mining was adopted from open source library SPMF against dataset This dataset contains 351 real faults drawn from 223ve representative open source java projects Despite a bias towards unit tests in the dataset we demonstrate that  Moreover this improvement is a lot better for the Closure project the one system in the data set which gravitates towards integration tests There we see an improvement for 76 defects 101 out of 131 The better rankings for Closure are inconclusive one case is not enough to generalise upon yet based on an analysis of the number of methods triggered by the fault spectrum there is at least circumstantial evidence that 


 ASE 2012 pages 378\205381 NewYork,NY,USA,2012.ACM 8 L Christophe R Stevens C D Roover and W D Meuter Prevalence and maintenance of automated functional tests for web applications In  89:51\20562 Mar 2014 31 A Miller A hundred days of continuous integration In  ISSTA 2014 pages 437\205440 New York NY USA 2014 ACM  F Khomh B Adams T Dhaliw al and Y Zou Understanding the impact of rapid releases on software quality The case of 223refox SIGSOFT Softw Eng Notes Proceedings of the 20th IEEE/ACM International Conference on Automated Software Engineering Proceedings of the 34th International Conference on Software Engineering J Syst Softw Leaders of Tomorrow Future of Software Engineering Proceedings of the 23rd IEEE International Conference on Software Analysis Evolution and Reengineering SANER Proceedings of the 2014 IEEE International Conference on Software Maintenance and Evolution Proceedings of the 2014 International Symposium on Software Testing and Analysis Proceedings of the 22Nd ACM SIGSOFT International Symposium on Foundations of Software Engineering  82\(11 Nov 2009 2 R A b r e u P Z o e t e w e i j a n dA J  C v a nG e m u n d O nt h e accuracy of spectrum-based fault localization In  39\(5 Sept 2014  M Beller G Gousios A P anic hella and A Zaidman When how and why developers do not test in their IDEs In  ISSTA 22011 pages 210\205220 New York NY USA 2011 ACM 13 H Do S Elbaum and G Rothermel Supporting controlled experimentation with testing techniques An infrastructure and its potential impact  ICSE 22094 pages 191\205200 Los Alamitos CA USA 1994 IEEE Computer Society Press  J A Jones a nd M J Harrold Empirical ev aluation o f t he tarantula automatic fault-localization technique In  ICSE 22002 pages 467\205477 New York NY USA 2002 ACM 21 R Just D Jalali and M D Ernst Defects4j A database of existing faults to enable controlled testing studies for java programs In  20\(2 2015 23 G Laghari A Murgia and S Demeyer Localising faults in test execution traces In  20\(5 Oct 2015  T.-D B Le R J Oen tary o and D Lo I nformation retrieval and spectrum based bug localization Better together In  ESEC/FSE 2015 pages 579\205590 New York NY USA 2015 ACM 26 C Le Goues M Dewey-Vogt S Forrest and W Weimer A systematic study of automated program repair Fixing 55 out of 105 bugs for 8 each In  20\(3 Aug 2011 33 C Parnin and A Orso Are automated debugging techniques actually helping programmers In Proceedings of the 29th ACM/IEEE International Conference on Automated Software Engineering Proceedings of the 19th European Conference on Object-Oriented Programming  ICSE 22015 pages 483\205493 Piscataway NJ USA 2015 IEEE Press  M Hutc hins H F oster T Goradia and T  Ostrand Experiments of the e\002ectiveness of data\224owand control\224ow-based test adequacy criteria In 1 R A b r e u P Z o e t e w e i j R G o l s t e i j n a n dA J C v a n Gemund A practical evaluation of spectrum-based fault localization 11 REFERENCES  TAICPART-MUTATION 22007 pages 89\20598 Washington DC USA 2007 IEEE Computer Society 3 B Adams and S McIntosh Modern release engineering in a nutshell 205 why researchers should care In  Addison-Wesley Longman Publishing Co Inc Boston MA USA 1999 7 J Campos A Riboira A Perez and R Abreu Gzoltar An eclipse plug-in for testing and debugging In  ICSME 22014 pages 141\205150 Washington DC USA 2014 IEEE Computer Society 9 V D a l l m e i e r C L i n d i g a n dA Z e l l e r L i g h t w e i g h td e f e c t localization for java In  ASE 22007 pages 433\205436 NewYork,NY,USA,2007.ACM 11 B Daniel V Jagannath D Dig and D Marinov Reassert Suggesting repairs for broken unit tests In  10\(4 2005  P  M Duv a ll S Mat y as and A Glo v er 284 Proceedings of the 27th IEEE/ACM International Conference on Automated Software Engineering Proceedings of the Twenty-second IEEE/ACM International Conference on Automated Software Engineering Proceedings of the Int\220l Conference on Automated Software Engineering ASE Proceedings of the 37th International Conference on Software Engineering Volume 1 Proceedings of the 16th International Conference on Software Engineering Proceedings of the 13th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining  KDD 22007 pages 460\205469 New York NY USA 2007 ACM  Lucia D Lo L Jiang and A Budi C omprehensiv e evaluation of association measures for fault localization In Empirical Softw Engg Empirical Software Engineering Software Maintenance ICSM 2010 IEEE International Conference on ACM Trans Softw Eng Methodol  IWPSE 2015 pages 1\2058 New York NY USA 2015 ACM 24 T.-D B Le D Lo and F Thung Should i follow this fault localization tool\220s output Proceedings of the 2011 International Symposium on Software Testing and Analysis Osaka Japan March 2016 4 P Agarwal and A P Agrawal Fault-localization techniques for software systems A literature review ASE\22005 pages 273\205282 New York NY USA 2005 ACM  J A Jones M J Harrold a nd J Stask o  Visualization o f test information to assist fault localization In ICSE 22012 pages 3\20513 Piscataway NJ USA 2012 IEEE Press  D Lo S.-C Kho o and C Liu E\003cien t mining o f iterativ e patterns for software speci\223cation discovery In ASE\22014 pages 127\205138 New York NY USA 2014 ACM  X Mao Y Lei Z Dai Y Qi a nd C W ang Slice-based statistical fault localization  Addison-Wesley 2007  S Elbaum G  Rothermel and J P enix T ec hniques for improving regression testing in continuous integration development environments In  pages 179\205190 ACM 2015  R  V Binder  pages 433\205444 IEEE CS 2009 12 N DiGiuseppe and J A Jones On the in\224uence of multiple faults on coverage-based fault localization In  pages 1\20510 Sept 2010  Lucia D Lo a nd X Xia F usion f ault lo calizers In  pages 289\205293 Aug 2008  L Naish H J Lee and K  Ramamohanarao A m o del for spectra-based software diagnosis Journal of Systems and Software Proceedings of the 10th Joint Meeting of the European Software Engineering Conference and the ACM SIGSOFT Symposium on the Foundations of Software Engineering ESEC/FSE Testing Object-oriented Systems Models Patterns and Tools Continuous Integration Improving Software Quality and Reducing Risk Empirical Software Engineering Proceedings of the 14th International Workshop on Principles of Software Evolution Proceedings of the 2011  ECOOP\22005 pages 528\205550 Berlin Heidelberg 2005 Springer-Verlag  V Dallmeier and T Z immermann Extraction of bug localization benchmarks from history In Proceedings of the Testing Academic and Industrial Conference Practice and Research Techniques MUTATION Proceedings of the 24th International Conference on Software Engineering  FSE 2014 pages 235\205245 New York NY USA 2014 ACM 16 M Fowler and M Foemmel Continuous integration original version http://http://www.martinfowler.com  Sept 2010 Accessed April 1st 2016  K Herzig M G reiler J Czerw o nk a and B Murph y  The art of testing less without sacri\223cing quality In Proceedings of the 2015 10th Joint Meeting on Foundations of Software Engineering Agile 2008 AGILE 22008 Conference 


Case Study Research Design and Methods 3 edition 285 Proceedings of the 2013 International Symposium on Software Testing and Analysis pages 345\205355 Nov 2013  D St 036 ahl and J Bosch Modeling continuous integration practice di\002erences in industry software development pages 1105\2051112 New York NY USA 2006 ACM  J Zhou H Zhang and D Lo W here should the bugs b e 223xed more accurate information retrieval-based bug localization based on bug reports In ICSE 22012 pages 14\20524 Piscataway NJ USA 2012 IEEE Press IEEE Transactions on Software Engineering International Symposium on Software Testing and Analysis Automated Software Engineering ASE 2013 IEEE/ACM 28th International Conference on  pages 113\205122 Oct 2013  R K Yin IEEE Software IEEE Software Proceedings of the 34th International Conference on Software Engineering Empirical Softw Engineering Proceedings of the Second SIAM International Conference on Data Mining Arlington VA USA April 11-13 2002 SIGSOFT Softw Eng Notes Proceedings of the the 6th Joint Meeting of the European Software Engineering Conference and the ACM SIGSOFT Symposium on The Foundations of Software Engineering  ISSTA 22011 pages 199\205209 New York NY USA 2011 ACM  Y Qi X Mao Y Lei and C  W ang Using a utomated program repair for evaluating the e\002ectiveness of fault localization techniques In  ISSTA 2013 pages 191\205201 New York NY USA 2013 ACM  S Rao H Medeiros and A K ak Comparing i ncremen tal latent semantic analysis algorithms for e\003cient retrieval from software libraries for bug localization  40\(1 Feb 2015  P  Runeson A surv e y o f u nit t esting practices  14\(2 2009  R Saha M Lease S Kh urshid a nd D P erry  Impro ving bug localization using structured information retrieval In  87\(0 204 59 2014  F Steimann and M F renk el Impro ving co v erage-based localization of multiple faults using algorithms from integer linear programming In  ISSTA 2013 pages 314\205324 New York NY USA 2013 ACM  S H T an and A Ro yc houdh ury  R eli\223x Automated repair of software regressions In  ICSE 22015 pages 471\205482 Piscataway NJ USA 2015 IEEE Press  N Tillmann a nd W Sc h ulte Unit tests reloaded parameterized unit testing with symbolic execution  2016  J Xuan and M Monp errus Learning to com bine m ultiple ranking metrics for fault localization In  pages 191\205200 Sept 2014  X Xue and A S Namin Ho w s igni\223can t is the e\002ect of fault interactions on coverage-based fault localizations In  23\(4 2006  P  Runeson a nd M H 250 ost Guidelines for conducting and reporting case study research in software engineering  pages 345\205355 Nov 2013  R K Saha M Lease S  Kh urshid and D E P e rry  Improving bug localization using structured information retrieval In  pages 121\205130 Nov 2012  F Steimann M F renk el and R Abreu Threats to t he validity and value of empirical assessments of the accuracy of coveragebased fault locators In  23\(4 July 2006  J T u  L  C hen Y Zhou J Zhao and B Xu Lev eraging method call anomalies to improve the e\002ectiveness of spectrum-based fault localization techniques for object-oriented programs In  ESEC-FSE 22007 pages 35\20544 New York NY USA 2007 ACM 47 J.Xuan,M.Martinez,F.Demarco,M.Cl\264 ement S Lamelas T Durieux D Le Berre and M Monperrus Nopol Automatic repair of conditional statement bugs in java programs  Sage Publications 2002  A Zaidman B V Rompaey  v a n Arie v an Deursen and S Demeyer Studying the co-evolution of production and test code in open source and industrial developer test processes through repository mining  16\(3 2011  M J Zaki and C J Hsiao CHARM an e\003cien t a lgorithm for closed itemset mining In  pages 457\205473 2002 53 A X Zheng M I Jordan B Liblit M Naik and A Aiken Statistical debugging Simultaneous identi\223cation of multiple bugs In Proceedings of the 2013 International Symposium on Software Testing and Analysis Journal of Systems and Software Software Reliability Engineering ISSRE 2012 IEEE 23rd International Symposium on Proceedings of the 23rd International Conference on Machine Learning ICML 22006 Software Maintenance and Evolution ICSME 2014 IEEE International Conference on Proceedings of the 2012 12th International Conference on Quality Software 2013 ACM  IEEE International Symposium on Empirical Software Engineering and Measurement QSIC\22012 pages 1\2058 Washington DC USA 2012 IEEE Computer Society  A W a sylk o wski A Zeller and C  L indig Detecting ob ject usage anomalies In Empirical Software Engineering Automated Software Engineering ASE 2013 IEEE/ACM 28th International Conference on Proceedings of the 37th International Conference on Software Engineering Volume 1 


LI et al  PRIVACY-PRESERVING-OUTSOURCED ASSOCIATION RULE MINING ON VERTICALLY PARTITIONED DATABASES 1859 the publication of this seminal work a number of privacypreserving association rule mining or frequent itemset mining solutions have been published in the literature see 11   1 3   28]Ð[31 The most relevant work is the privacy-preserving association rule mining solution presented in I n t hi s s ol ut i on a d at a owner known as the master is responsible for the mining The other data owners known as slaves insert ctitious transactions to their respectiv e datasets and send the datasets to the master Each data owner will also send his set of real transactions IDs to a semi-trusted third-party server The third-party server is assumed not to be colluding with any data owner but it cannot be trusted to hold the raw data The master generates association rule candidates from the joint database containing ctitious data For each rule candidate X  Y  the master sends the ID lists of the transactions containing X  Y and the transactions containing X to the third-party server The server veriÞes if the rule is qualiÞed or not Similar to our solutions a semi-trusted third-party is utilized for the mining However unlike our solutions a data owner i.e the master does the majority of the computational work Therefore we can hardly say that such a solution is an outsourced mining solution Though ctitious data are added in datasets to lower data usability the master is able to learn signiÞcant information about other data owners raw data from the received datasets In cont rast our solutions do not leak such information as we do not rely on one particular data owner to undertake the computations and we also encrypt the datasets All existing solutions with the exception of  d o not utilize a third-party server to server to compute the mining result Some solutions  13 us e a s y mmet r i c encryption to compute the supports of itemsets while other solutions 28]Ð[30 us e a s ecure s cal ar product p rot o col  a s et intersection cardinality protocol or a secret sharing scheme to perform these computations A majority of these solutions expose exact supports to all data owners resulting in the leakage of information about the data owners raw data  The only exception is one of s s o l u t i ons  I n  13 t here are two privacy-preserving solutions for frequent itemset mining The rst solution exposes exact supports which is not desirable The second solution does not expose exact supports However association rules cannot be mined based on the result of second solution because conÞdences cannot be computed without the exact supports In addition this solutionÕs method cannot be used to mine association rules because securely computing conÞdence is more complicated than computing support In comparison with this solution our frequent itemset mining solutionÕs computational complexity is signiÞcantly lower Our solutions do not expose exact supports or conÞdences to data owners Different from existing solutions based on homomorphic encryption we use symmetric homomorphic encryption instead of asymmetric homomorphic encryption and the manner in which we use homomorphic encryption also differs from existing solutions In our approach we use homomorphic encryption to create ERVs and build our secure outsourced comparison scheme B Privacy-Preserving Outsour ced Association Rule Mining and Frequent Itemset Mining Privacy-preserving outsourced frequent itemset mining and association rule mining have been studied in the setting of a single data owner  19]Ð[21 I n e xi s t i n g s ol ut i ons  the data owner outsources thei r data and the mining task to the cloud but at the same time wish to keep the raw data secret from the cloud Generally data items in the database are encrypted using a substitution cipher prior to outsourcing Reference  propos ed a s ol ut i o n t o c ount er frequency analysis attack on substitution cipher However a later work demons t r at ed t h at 19 s s o l u t i o n i s not s ecure Giannotti et al proposed a solution based on k anonymity frequency   21 T o c ount er frequenc y a nal y s i s a t t ack the data owner inserts ctitious transactions in the encrypted database to conceal the item frequency After inserting the ctitious transactions any item in the encrypted database will share the same frequency with at least k  1 other items The data owner sends the encrypted database of both the real and ctitious transactions to the cloud The cloud runs a classic frequent itemset mining algorithm and returns the result frequent itemsets and their supports to the data owner The data owner revises these itemsets supports by subtracting them with these itemsets corresponding occurrence counts in the ctitious transactions respectively Finally the data owner decrypts the received itemsets with the revised supports higher than the frequency threshold an d generates association rules based on found frequent itemsets Our solutions use their techniques to conceal the raw data from the cloud and mitigate frequency analysis attack that can be undertaken by the cloud Using these techniques alone however is not sufÞcient to protect data privacy in the vertically partitioned database setting To cancel out ctitious transactions both 21 an d  1 6  require the data owner to count itemset occurrences in ctitious transactions In the vertically partitioned database setting data owners are unable to perform such calculation using the techniques described in and  16 I n our s o l u t i ons  the cloud rather than the data owners cancels out ctitious transactions in a privacy-preserving manner and the underlying techniques are our homomorphic encryption secure comparison and ciphertext tag schemes Another recent work  propos ed a p ri v a c y pres e rving outsourced association rule mining solution based on predicate encryption This solution is resilient to chosen-plaintext attacks on encrypted items but it is vulnerable to frequency analysis attacks Applying this solution to vertically partitioned databases will also result in the leakage of the exact supports to data owners In this paper our adversary model is different We assume the cloud has knowledge of the item frequencies instead of chosen plaintext-ciphertext pairs and our solutions are resilient to frequency analysis attacks C Other Related Work Other than the settings of vertically partitioned databases and cloud/third-party-aided mining privacy-preserving frequent itemset mining and association rule mining have 


1860 IEEE TRANSACTIONS ON INFORMATION FORENSICS AND SECURITY VOL 11 NO 8 AUGUST 2016 been studied in the settings of horizontally partitioned databases   33]Ð[35 d at a publ i s hi ng 36 and d i f ferent i a l privacy  T hes e s e t t i ngs are b e yond t h e s cope of t h i s paper  IX C ONCLUDING R EMARKS In this paper we proposed a privacy-preserving outsourced frequent itemset mining solution for vertically partitioned databases This allows the data owners to outsource mining task on their joint data in a privacy-preserving manner privacypreserving manner Based on this solution we built a privacypreserving outsourced association rule partitioned databases Our solutions protect data ownerÕs raw data from other data owners and the cloud Our solutions also ensure the privacy of the mining results from the cloud Compared with most existing solutions our solutions leak less information about the data owners raw data Our evaluation has also demonstrated that our solutions are very efÞci ent therefore our solutions are suitable to be used by data owners wishing to outsource their databases to the cloud but require a high level of privacy without compromising on performance To realize our solutions an efÞcient homomorphic encryption scheme and a secure outsourced comparison scheme were presented in this paper Both schemes have potential usage in other secure computation applications such as secure data aggregation beyond the data mining solutions described in this paper Demonstrating the u tility of the p roposed homomorphic encryption scheme and outsourced comparison scheme in other settings will be the focus of future research A PPENDIX I NSERTING F ICTITIOUS T RANSACTIONS  s A LGORITHM  An algorithm to counter frequency analysis attacks on the outsourced database encrypted with a substitution cipher was proposed in F or the purpos e o f c oncealing t he item frequency this algorithm inserts ctitious transactions in the database to be oursourced The goal is to ensure that each item share the same frequency with at least k  1 items The algorithm is summarized as follows also see  Firstly the data owner scans the database to count each individual itemÕs support  Secondly the data owner groups items considering the supports and co-occurrence of items The data owner sorts items in decreasing order of support Starting from the rst of the sorted item list i.e the item with the highest support the data owner assigns every k adjacent items to a new created group If there are less than k unassigned items remaining these items will be assigned to the last created group The data owner swaps items from different groups to ensure that all items in the same group do not occur together in the same transaction  Thirdly for each item in each group the data owner calculates the difference between the itemÕs support and the highest support in the group The difference is deÞned as the noise of the item  Fourthly to achieve k anonymity frequency the data owner generates ctitious transactions based on the result of the third step The number of an itemÕs occurrences in the ctitious transactions is equal to its noise calculated in the third step After inserting the ctitious transactions all items in the same group share the same support A CKNOWLEDGMENT The authors would like to thank Quach Vinh Thanh the Associate Editor and the three anonymous reviewers for providing constructive and gen erous feedback Despite their invaluable assistance any erro rs remaining in this paper are solely attributed to the authors R EFERENCES  T  B rijs  G  S winnen K V a nhoof a nd G W e ts   Us ing a s s o ciation r ules for product assortment decisions A case study in Proc SIGKDD  1999 pp 254Ð260  S  E  B ros s e tte A  P  S prague J  M  H ardin K B W a ites  W  T  J ones  and S A Moser Association rules and data mining in hospital infection control and public health surveillance J Amer Med Inform Assoc  vol 5 no 4 pp 373Ð381 1998 3 B  M obas h er  H  D ai T  L uo and M  N akaga w a E f f ecti v e p er s onalization based on association rule discovery from Web usage data in Proc WIDM  2001 pp 9Ð15  C  C reighton and S  H anas h Mining g ene e xpres s i on databas e s f or association rules Bioinformatics  vol 19 no 1 pp 79Ð86 2003 5 X  Y in and J  H an  CP A R  C las s i  cation b as ed on pr edicti v e as s o ciation rules in Proc SIAM SDM  2003 pp 1Ð5 6 R  A gr a w al and R  S r i kant  F a s t algor ithm s f o r m ining a s s o ciation rules in Proc VLDB  1994 pp 1Ð13 7 M  J  Z aki S calable algor ithm s f o r a s s o ciation m ining  IEEE Trans Knowl Data Eng  vol 12 no 3 pp 372Ð390 May/Jun 2000  J  H an J  P ei a nd Y  Y i n Minin g frequent patterns without candidate generation in Proc ACM SIGMOD  pp 1Ð12 2000 9 J  V aidya and C  C lif ton P r i v a c y pr es er ving as s o ciation r ule m ining i n vertically partitioned data in Proc SIGKDD  2002 pp 639Ð644  M Kantarcioglu a nd C Clifton Pri vacy-preserving distributed mining of association rules on horizontally partitioned data IEEE Trans Knowl Data Eng  vol 16 no 9 pp 1026Ð1037 Sep 2004  B Rozenber g and E  G udes   A s s o ciation r ules m i ning in v e rtically partitioned databases Data Knowl Eng  vol 59 no 2 pp 378Ð396 2006  J  Z h an S  M atwin and L  C hang Pri v a c y pres e rving c ollaborati v e association rule mining in Proc DBSEC  2005 pp 153Ð165  S Z hong Pri v a c y pres e rving a lgorithm s for d is trib uted m i ning of frequent itemsets Inf Sci  vol 177 no 2 pp 490Ð503 2007  P  P a illier  P ublick e y cr yptos ys tem s bas e d o n c om pos ite de gr ee r e s i duosity classes in Proc EUROCRYPT  1999 pp 223Ð238  R Cram er  R  G ennaro a nd B Schoenm ak ers   A s ecure and optim ally efÞcient multi-authority election scheme Eur Trans Telecommun  vol 8 no 5 pp 481Ð490 1997  F  G i annotti L  V  S  L a ks hm anan A  M onr eale D  P e dr es chi and H Wang Privacy-preserving mining of association rules from outsourced transaction databases IEEE Syst J  vol 7 no 3 pp 385Ð395 Sep 2013  B Dong R L i u and H  W ang Res ult i nte g rity v e riÞcation o f outsourced frequent itemset mining in Proc 27th Annu IFIP WG Conf Data Appl Secur Privacy DBSec  Newark NJ USA Jul 2013 pp 258Ð265 O A v a ilable http://dx doi o r g 10 1007/978-3-64 239256-6_17  R L i u a nd H W a ng Res ult i nte g rity v e riÞcation o f outs ourced pri v ac ypreserving frequent itemset mining in Proc SIAM Int Conf Data Mining  Vancouver BC Canada Apr./May 2015 pp 244Ð252 Available http://dx.doi.org/10.1137/1.9781611974010.28  W  K W ong D W  Cheung E  Hung B Kao and N  M am oulis  Security in outsourcing of association rule mining in Proc VLDB  2007 pp 111Ð122  I  M o llo y  N  L i  a nd T  L i   O n the  in s ecur ity and  im  p r acticality of outsourcing precise association rule mining in Proc ICDM  Dec 2009 pp 872Ð877  F  G i annotti L  V  S  L a ks hm anan A  M onr eale D  P e dr es chi and W Wang Privacy-preserving data mining from outsourced databases in Proc CPDP  2011 pp 411Ð426 


LI et al  PRIVACY-PRESERVING-OUTSOURCED ASSOCIATION RULE MINING ON VERTICALLY PARTITIONED DATABASES 1861 22 FIPS Publication 180-1 Secure Hash Standard  Nat Inst Standards Technol Gaithersburg MD USA 1995 23 FIPS Publication 180-2 Secure Hash Standard  Nat Inst Standards Technol Gaithersburg MD USA 2002  T  E l Gam a l  A public k e y c ryptos ystem and a signature scheme based on discrete logarithms IEEE Trans Inf Theory  vol 31 no 4 pp 469Ð472 Jul 1985 O A v a ilable http://dx doi o r g 10 1109 TIT.1985.1057074  N  Cour tois  A  K lim o v  J  P atar in a nd A  S h am ir   E f  c ient algor ithm s for solving overdeÞned systems of multivariate polynomial equations in Proc EUROCRYPT  2000 pp 392Ð407  P  F ournier V iger  Real-life Datasets in SPMF Format  accessed on Apr 6 2016 O A v a ilable http://w w w  philippe-fournier viger.com/spmf/index.php?link=datasets.php  P  F ournier V iger  A  G om ariz T  G ueniche A Soltani C  W  W u and V S Tseng SPMF A Java opensource pattern mining library J Mach.Learn.Res  vol 15 no 1 pp 3389Ð3393 2014  J  V a idya and C  C lif ton S ecur e s e t i nter s ection car dinality w ith application to association rule mining J Comput Secur  vol 13 no 4 pp 593Ð622 2005  X Ge L  Y an J  Z hu and W  S hi  Pri v ac y-pres erving dis t rib u ted association rule mining based on the secret sharing technique in Proc SEDM  Jun 2010 pp 345Ð350  R K h ar at M  K um bhar  and P  B ham r e E f  cient p r i v a c y pr es er ving distributed association rule mining protocol based on random number in Intelligent Computing Networking and Informatics  Raipur Chhattisgarh India Springer 2014 pp 827Ð836  C Dong and L  C hen  A f a s t s ecure dot product p rotocol with application to privacy preserving association rule mining in Proc 18th PaciÞc-Asia Conf Adv Knowl Discovery Data Mining PAKDD  Tainan Taiwan May 2014 pp 606Ð617 Available http://dx.doi.o rg/10.1007/978-3-319-06608-0_50  J  L a i Y  L i  R  H  D eng J  W e ng C Guan a nd Q Y a n T o w ards semantically secure outsourcing of association rule mining on categorical data Inf Sci  vol 267 pp 267Ð286 May 2014  T  F ukas a w a  J  W ang T  T a kata a nd M  M i yazaki  A n e f f ecti v e distributed privacy-preserving data mining algorithm in Proc 5th Int Conf IDEAL  2004 pp 320Ð325  C Su and K  S akurai  A d is trib ut ed privacy-preserving association rules mining scheme using frequent-pattern tree in Proc ADMA  2008 pp 170Ð181  M  G  K a os ar  R  P aulet and X  Y i S ecur e tw opar t y a s s o ciation r ule mining in Proc ACSW-AISC  2011 pp 15Ð22  J  L  L in and J  Y  C L i u Pri v a c y pres erving item s et m i ning through fake transactions in Proc ACM Symp Appl Comput SAC  Seoul South Korea Mar 2007 pp 375Ð379 A v a ilable http://doi.acm.org/10.1145/1244002.1244092  B N K e s h a v am urthy  A M Khan a nd D T o s hniw a l Pri v a c y preserving association rule mining over distributed databases using genetic algorithm Neural Comput Appl  vol 22 no 1 pp 351Ð364 2013 Lichun Li received the bachelorÕs degree in information engineering from the Beijing University of Posts and Telecommunications in 2002 the masterÕs degree in communication and information systems from the China Academy of Telecommunication Technology in 2006 and the Ph.D degree in computer science from the Beijing University of Posts and Telecommunications in 2009 He is currently a Postdoctoral Research Fellow with the INFINITUS Laboratory School of Electrical and Electronic Engineering Nanyang Technological University Singapore His research interests include privacy and security in cloud and big data Rongxing Lu SÕ09ÐMÕ11ÐSMÕ15 received the Ph.D degree in computer science from Shanghai Jiao Tong University Shanghai China in 2006 and the Ph.D degree in electrical and computer engineering from the University of Waterloo Waterloo ON Canada in 2012 From 2012 to 2013 he was a Postdoctoral Fellow with the University of Waterloo Since 2013 he has been an Assistant Professor with the School of Electrical and Electronic Engineering Nanyang Technological University Singapore His research interests include computer network security mobile and wireless communication security and applied cryptography He was a recipient of the Ca nada Governor General Gold Metal Kim-Kwang Raymond Choo SMÕ15 received the Ph.D degree in information security from the Queensland University of Technology Australia in 2006 He is currently a Cloud Technology Endowed Associate Professor with the University of Texas at San Antonio an Associate Professor with the University of South Australia and a Guest Professor with the China University of Geosciences He was named one of 10 Emerging Leaders in the Innovation category of The Weekend Australian Magazine MicrosoftÕs Next 100 series in 2009 and is a recipient of the ESORICS 2015 Best Research Paper Award the 2015 Winning Team of GermanyÕs University of Erlangen-Nuremberg Digital Forensics Research Challenge the 2014 Australia New Zealand Policing Advisory AgencyÕs Highly Commende d Award the 2010 Australian Capital Territory Pearcey Award the Fulbright Scholarship in 2009 the 2008 Australia Day Achievement Medallion and the British Computer SocietyÕs Wilkes Award Anwitaman Datta is an Associate Professor with the School of Computer Science and Engineering NTU Singapore He lead s the Self and Algorithmic aspects of Networked Distributed Systems Research Group at NTU Jun Shao received the Ph.D degree from Shanghai Jiao Tong University Shanghai China in 2008 He was a Postdoctoral Fellow with the School of Information Sciences and Technology Pennsylvania State University State College PA USA from 2008 to 2010 He is currently a Full Professor with the Department of Information Security Zhejiang Gongshang University Hangzhou China His research interests include network security and applied cryptography 


