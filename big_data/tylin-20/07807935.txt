 IEEE International Conference On Recent Trends In Electronics Information Communication Technology, May 20-21, 2016, India   978-1-5090-0774-5/16/$31.00 \251 2016 IEEE  795  Hadoop-HBase for Finding Association Rules using Apriori MapReduce Algorithm Ashwini A. Pandagale, Anil R . Surve Abstract  Pattern discovery is the important part of  knowledge discovery in Database , comes under Data mining .To discover useful patterns association rule mining is one of the most popularized and revealing technique in data mining.Association rule mining plays a key role in decision making by discovering useful relations between attributes in the database.For this first Frequent itemsets need to calculate followed by Candidate itemset.While generating frequent itemsets,frequent-1 itemset can be generated easily. But frequent 2-itemsets suffered from both time and space complexity.More overhead and space complexity  occurred in a generation of frequent 2-itemset is the issue of this paper.For more I/O throughput it is essential to generate frequent itemsets as fast as possible and space efficient.To possible this,intermediate data generated by pairing each item with another item in itemset n ee ds access of random read/write To access random data for low latency Apache HBase is the solution.Based on performed results,it is shown that if dataset stored through HBase on HDFS,space and time complexity can be achieved better with Apriori M ap Reduce algorithm for finding association rules  Keywords Pattern discovery Data mining Hadoop Distributed system,  HDFS, MapReduce, HBase x-none I  x-none  x-none INTRODUCTION Data mining also called as Knowledge Discovery in Database\(KDD\,is always the focused issue in Information mining research.Its objective is extracting hidden patterns and rules from a large dataset which are unknown to human life This can be possible using Apriori algorithm implemented on MapReduce framework.After generation of association rules,we can work effectively in fraud detection Market basket analysis, Medical diagnosis, Protein Sequences,Census data.For association rules two basic and important steps are the generation of frequent itemsets and creation of candidate itemsets based on user defined minimum support count.This can be done using algorithm called as Apriori MapReduce algorithm\(AMA\.This algorithm provides scalability as execute in a parallel manner but suffered from somewhat time and space complexity in a generation of frequent 2itemset.With the help of AMA,HBase can provide the good solution for space complexity and helps to minimize time constraints.It nearly minimizes half of the time for accessing the records through HBase as compared to AMA with HDFS x-none II  LITERATURE REVIEW The sequential association rule mining algorithm i.e Apriori algorithm  s c a ns  t h e  e n t i r e  t r a n s a c t i o n  da t a b a s e  a t  a  time in each pass and it incurs high I/O cost and communication overhead to the disk  Ashwini A Pandagale Department of Computer Science and Engineering Walchand College of Engineering Sangli Maharashtra India  ashupandagale@gmail.com   Anil R . Surve, Department of Computer Science and Engineering, Walchand College of Engineering Sangli Maharashtra India  anil.surve@walchandsangli.ac.in    When facing a large volume of the database can be in petabytes,zettabytes will be impractical storage and processing on one node and process single threaded under big data situation with varying data features   Big data has brought challenges to data mining such as finding customer behavior helpful for business analytics fraud detection Market basket analysis   11   Medical diagnosis Protein Sequences,Census data.With massive database it is essential to get results in less time.Apriori algorithm could not fulfill the time constrained requirements.To solve the above mentioned problems much of the work on Apriori algorithm is done R.Agrawal and Shrikant,founder of Apriori algorithm presented parallel apriori algorithms like Count Distribution,Data Distribution,Candidate Distribution  B ut these parallel algorithms faced a problem of synchronization and communication delay.MapReduce is itself an algorithm ,a programming model for processing ultra large dataset on a cluster of nodes which makes easier for implementation of parallel mining algorithms introduced by Google  M e h u l  Vora presented hybrid approach where HDFS contains data and address of stored data maintained by HBase.This hybrid architecture  m a ke s  e a s y  a n d f a s t e r  da t a  s e a r c h  w i t h accuracy in a retrieval of the data which is a rigorous need for low latency while accessing items for finding size 2-frequent itemset. There are number of parallel algorithms proposed. S Singh analyzes the performance of the Apriori algorithm with different data structures  us i n g Ha do o p c l us t e r  M o r e  a b o u t the implementation of HBase for quick and random access data is explained further Remaining paper is organized as follows:Section III gives a brief idea of the Apache Hadoop Framework components including HDFS and MapReduce.It also contains features of HBase.Section IV explained the methodology in detail with the experimental setup.With this performance analysis study is explained for the results concluded in Section V x-none III  HADOOP Hadoop, an open source framework which is overseen by Apache Software Foundation,so called as Apache Hadoop [3   As companies invest much prefers open source software.Hadoop provides storage and processing stored data using map reduce.In 2004 Doug Cutting creates the Hadoop framework and reached at a top-level project in January 2008 by Apache Software Foundation.With Doug many other contributors make Hadoop attention from the rapidly growing user community  Hadoop project  is developed in Java includes mainly   Hadoop Common  The collection of normal utilities that support other  Hadoop modules  Hadoop Distributed File System HDFS A distributed file  system that provides high storage capacity and access to required application data   Hadoop YARN  A structure as a central platform to deliver consistent operations security and  data governance tools 


 IEEE International Conference On Recent Trends In Electronics Information Communication Technology, May 20-21, 2016, India   796  across Hadoop clusters   Hadoop MapReduce  A YARN-based system for parallel  processing of large data sets x-none A  Hadoop Distributed File System  HDFS   Hadoop File System is well known distributed storage used by Hadoop applications It uses commodity hardware for processing the data Not at all like other appropriated frameworks HDFS is profoundly fault tolerant scalable and uses low-price hardware To store tremendous data the documents are put away over various machines called as Datanodes. These files are put away in a repetitive manner to support replication in future data losses in case of failure  Features of HDFS  Distributed parallel storage and processing  Hadoop provides a command interface to collaborate with HDFS  The Namenode i.e Masternode maintains the metadata and datanode keeps blocks of data at appropriate node which help the users to easily check the status of the cluster  Streaming access write once read many times to file system data  Provides file authentication and validation  x-none B  Ma pReduce MapReduce   i s  a  h a n d li ng s t r a t e gy  a n d a  programming model for appropriate processing based on Java Map and Reduce are the two important tasks of the MapReduce algorithm Map takes a dataset and converts it into intermediate data in the form of key/value pairs Secondly, reduce task, used for aggregation takes the output from a map as an input and combines those key value pairs to give a count of each word. The reduce task can not start until map job get s completed.The main characteristic of MapReduce over traditional systems is that it is scalable for data processing. Under the MapReduce component, mappers and reducers are primary data processing models MapReduce follows Write once Read many strategies.That means once an application is written in the MapReduce form, scaling the application to run over hundreds, thousands or even tens of thousands of machines in a cluster need only configuration change Scalability is the attraction of many  need to change the program code And everybody wants to save from the hectic job which is taken care by scalability x-none C  HBase HBase is a distributed no SQL database   b u il t  o n top of the Hadoop file system It s main characteristic is column-oriented storage. It is a part of the Hadoop ecosystem that provides random access of data to read/write in real time manner We can store the data in HDFS either directly or through HBase It is used whenever there is a need to write heavy applications Whenever we need to provide fast random access to available data HBase is the perfect solution   Table is a collection of rows  Row is a collection of column families  Column family is a collection of columns  The column is a collection of <key, value  pairs HBase   i n t e r n a l ly   h a s  s pe c i a l  c a t a l o g t a bl e s  n a m e d ROOT and META  These special catalog tables maintain the current list state and location of all regions buoyed up on the cluster. The ROOT- table carries the list of .META table regions. While .META. table carries the list of all userspace regions Likewise HDFS and Map/Reduce HBase also follow master/slave architecture The responsibility of HMaster master for assigning regions to HRegionServers slaves and for recovering from HRegionServer failures HRegionServer is responsible for managing client requests for reading and writing. HBase uses Zookeeper [1   a n ot h e r  Hadoop subproject plays an important role in the management of HBase cluster There is no support for the SQL query language in HBase,so called as noSQL. There is HBql project   whi c h  a dds  a  d i a l e c t  o f  S QL  a n d J DB C  bindings for HBase             Fig. 1. HBase The following image shows column families in a column-oriented database   x-none  x-none  x-none  x-none  Fig. 2. Example of data storage in HBase x-none IV  PERFORMANCE EVALUATION x-none A  Methodology R.Agrawal  proposed  Apriori  algorithm. In  this  paper   Apriori algorithm implemented with MapReduce for finding association rules is used  Algorithm 1 Apriori MapReduce algorithm Map transaction t in dataset to all Map nodes  1  Scan the dataset to get the support S of each item  2  min_sup = num / total no of items  3  If support S is greater than threshold value i.e.min_sup then add an item to frequent 1-itemset  4  Compute frequent item set for each map node using min_sup and collect all together in reduce phase  5  Remove items that do not meet the min_sup  6  Again to find frequent k-itemsets calculate frequent item set with an  additional item by joining in each map node  


 IEEE International Conference On Recent Trends In Electronics Information Communication Technology, May 20-21, 2016, India   797  7  Collect the frequent item set at the reduce node and count item frequencies compared with min_sup  8  Remove the items that do not meet the min_sup in Reduce Node using prune  This paper represents a systematic evaluation of a noSQL database HBase and shows the comparison of performance by storing metadata \(file address stored in HDFS in HDFS using HBase.The actual dataset used for evaluation is stored in HDFS.This approach for data arrangement achieves time complexity and space complexity.Generating frequent-2 itemsets creates n*n items while pairing each item with another items It requires lots of space and time to find candidate frequent itemsets because of more read and write  As a result it suffered from location overhead  HBase can effectively useful in random access to  read and write If we store metadata directly in HDFS it will take time to perform read and write operation.As actually metadata stored in local file system of the operating system.And when it needs to fetch the block a chunk of data\,location of block is fetched maintained by Namenode   x-none B  Experimental Setup Experiments were performed on Hadoop-HBase cluster of one master and four slaves is used to test the performance.Hadoop 2.7.1 version is used for installation.The hardware required for the master was a processor of IntelItanium having 8-core CPU and 64 GBs of RAM.All slaves with dual core machines and 4 GBs of RAM having 64-bit architecture each Client was running on master node with Ubuntu 14.10  x-none C  Results As mentioned earlier, the issue of this paper is to reduce the time and space complexity occurred during generation of frequent 2-itemset. For this, tests were conducted on HadoopHBase cluster with 1.37GB dataset having  5267657 items 1692082 transactions  For different min_sup values  the time required to run the dataset is calculated  as shown in Fig.3  Minimum support is used to define ho w often a rule is applicable to a given dataset. The rules derived from min_sup are strong rules used in decision making   en-IN    Fig. 3. Time required according to different min-sup en-IN  en-IN Fig.4 shows a comparison of Hadoop cluster and Hadoop-HBase cluster for different number of nodes.While storing Data in HDFS,Namenode does frequent open and close to access the data when needed  Also it does not provide random access to Read/Write data.In contrast,Master Server in HBase opened for time until the process gets completed.With this advent it provides random Read/Write access  This is mainly  required in generating and processing frequent 2itemset. For results,we consider min_sup=0.33 en-IN  en-IN en-IN  en-IN  en-IN Fig. 4. Comparison of Hadoop And Hadoop-HBase for different number of nodes en-IN Also the issue of space complexity is solved using HBase.As it provides column-oriented  database mainly used for large tables  en-IN V  CONCLUSION In this era,digital data is generated in amount having 3    is in the form of big data For business intelligence,data should be analyzed weekly or monthly to increase the sell of products To get the customer behavior  useful patterns are very helpful can be achieved by finding association rules.We can achieve th is by the implementation of Apriori algorithm on Hadoop MapReduce framework.But still frequent 2-itemset suffered the problem of time complexity and space required to store temporary data.It needs continuous access which can be random read or write.HBase is the better solution to store metadata instead of directly HDFS.Also due to scalability a number of nodes can be added and all metadata will be maintained by HBase database.All the experimental results shows the time required to access the items for pairing with each other and to prune the unnecessary itemsets using defined min_sup get minimizes through HBase with a different number of nodes From this,we reached the conclusion that HBase is very effective to random read/write access As a result,the problem in finding size 2-frequent itemsets gets accelerated and provides space while pairing each element with other elements.This can be very effective for business intelligence to find customer behavior and in decision making   A CKNOWLEDGMENT  I would like to express out appreciation to all who helped me directly or indirectly during the course of this research work I also very thankful to Walchand College of Engg Sangli MH India to make available required hardware and facilities related to my project work This is part of my  Master's Dissertation Work  REFERENCES    Agrawal, R., & Srikant, R. \(1994, September\. Fast algorithms for mining association rules In Proc 20th Int Conf Very Large Data Bases,VLDB \(Vol. 1215, pp. 487-499   Lars George HBase: The Definitive Guide 1st edition,O'Reilly Media September 2011, ISBN 9781449396107   Tom White, "Hadoop: The Definitive Guide", 1st edition O'Reilly Media, June 2009, ISBN 9780596521974   Mehul  Vora\(2011\.Hadoop-HBase  for  Large-Scale  Data.International  Conference on Computer Science and Network Technology Volume  1,Pages: 601 605    Ankur Khetrapal, Vinay Ganesh, "HBase and Hypertable for large scale 


 IEEE International Conference On Recent Trends In Electronics Information Communication Technology, May 20-21, 2016, India   798  distributed storage systems",\(http://cloud.pubs.dbs.unileipzig.de/node/46   Agrawal R  Shafer J C 1996 Parallel mining of association rules Knowledge and Data Engineering IEEE Transactions on 8\(6 pp. 962-969   Dean J  Ghemawat S 2008 MapReduce simplified data processing on large clusters. Communications of the ACM, 51\(1\, pp 107-113    Sudhakar Singh 2015 October performance analysis of apriori  algorithm with different data structures on hadoop cluster,ijca,volume 128-number 9    Jongwook Woo,\(2013,November.\Market Basket Analysis Algorithms With Mapreduce Volume 276, Pp 49-54    HBql Homepage - http://www.hbql.com    http://dal loudcomputing.blogspot.com/2011/03/market-basket-analysisexample    Apache ZooKeeper Homepage - http://zookeeper.apache.org       


        x-none   e d e    s    e     TWU  e s   late y  at     x-none  x-none  x-none  x-none    e   8  c e t e  m               x-none  e  l le  e 8  d    x-none        x-none e s    e d  WU e 9                  WU                 ty      y e    il  D  f  U  item  til           978-1-5090-0082-1/16/$31.00 \2512016 IEEE 


        E   en    e  ted   e de g  er  of  l U  e s l   l D  l    lo l     B   E  be  h  d   h    n  14   x-none   2   x-none u   1    r e e    x-none e      Fig   12  f          le  4        x-none   e    ate  s    x-none   D   C E    x-none P e  2   s    s  it  les    e  ate s   ted    ts           x-none er    e  cal  e  y  et s   15  x-none   y   e as   RU  C   D    C   D  C   D    C   D  2    3    1   2        3    5    4    1          cr s   to  et  s  as le 1      H SS E Y  n e    y                                                                                   978-1-5090-0082-1/16/$31.00 \2512016 IEEE 


   C N  x-none e  e    le    les h   s  t   s      T le  es  y  ity   ess  le  e 5 th n  n   e  s    a  le   m  s  f     R ES    1   EEE 8    2     3  3   s 2  4    3  5  K  H  U   s  1  6  g   s   7  H  D    5  8  F   s  3  9    i ty   4  0  J  W   e   1    s    2  u   s  3  W   s 9  4    E    t  6 th   5  Y  s 695  6   R   19 26  7    H J   4    8    g  44 th    978-1-5090-0082-1/16/$31.00 \2512016 IEEE 


002 003 004\002 004\003 005\002 005\003 006\002 006\003 007\002 002\004 002\005 002\006 002 002 003 004\002 004\003 005\002 005\003 006\002 006\003 002\004 002\005 002\006 002 002 003 004\002 004\003 005\002 005\003 006\002 006\003 007\002 002\004 002\005 002\006 002 002 003 004\002 004\003 005\002 005\003 006\002 006\003 002\004 002\005 002\006 002 002 003 004\002 004\003 005\002 005\003 006\002 006\003 007\002 002\004 002\005 002\006 002 002 003 004\002 004\003 005\002 005\003 006\002 006\003 007\002 002\004\002\005\002\006\002 
3 6 
 
026\027\012\007\030\004\007\010\005\013\032\013    
Figure 5 Achieved throughput for increasing length rule candidates The Y-axis is measured in billion evaluations per second The X-axis shows the corresponding rule length The gures also depict the theoretical trend-line that is computed as an ampli“cation of the naive-sc on the GPU using Eq 4 cases default-tpsc outperforms naive-sc on the gpu as well as the alternative implementation on the cpu The performance of naive-sc is higher than its cpu counterpart due to the higher resource availability of the GPU However its maximum throughput is only 5 billion evaluations per second and drops very quickly for all the different types of dataset In contrast default-tpsc has a throughput ranging from 2x to 30x times higher for larger rule lengths presenting overall a more gradual drop TPSC relies heavily on a large list of items to achieve increased parallelism during execution and improve performance For this reason we observe a steeper drop in throughput and a lower throughput maximum for synthetic data 2 and 4 The available items in these cases are less than the minimum block size i.e 128 threads that is required to achieve full multiprocessor warp occupancy Therefore resource underutilization is the main reason for the observed performance drop When the number of items in the transaction data is large enough the observed throughput follows the theoretical trendline We determine the theoretic throughput using Eq 4 to amplify the the naive-sc throughput of the GPU The depicted gures show the trend-line and not the actual ampli“ed throughput as naive-sc saturates the GPU resources for rule length greater than 18 resulting in signi“cant performance drop So the actual bene“ts from tspc are more signi“cant for large rule candidate lengths due to the algorithm being resource ef“cient In fact for synthetic data 1,3 5 and 6 the theoretical throughput is around 35 billion evaluations per second Although it is greater than the observed throughput\(i.e 15 to 20 billion compared to naive-sc on the GPU tspc exhibits almost 40x improvement As with the synthetic dataset we performed similar experiments this time on real data We present the observed throughput in Fig 6 Overall the results follow similar pattern with those of the experiments on synthetic data For accidents dataset we observe the highest throughput of 50 billion evaluations per second For all dataset default-tpsc exhibits a gradual decrease in throughput because the number of items are enough to fully utilize the GPUs resources Through this round of experiments we observe that the throughput is also affected by the number of transactions although at a lesser extend Additionally due to the different sparsity patterns variations in the throughput are also noticeable Retail and TK100 although having similar size exhibit different characteristics in relation to their sparsity pattern with the former consisting of many dense regions and the latter having only few This is the reason behind the 10x difference in their observed throughput 
In this section we study in detail the effect of shared memory bank con”icts and uncoalesced off-chip memory accesses Since it was established that default-tpsc has a better performance than naive-sc and its multi-core counterpart we focus on comparing default-tpsc with its optimized variants nbc-tpsc mrs-tpsc and mr-tpsc In Fig 7 and Fig 8 we present the maximum percentage improvement in execution time per iteration which we obtained from using the aforementioned kernel variations on synthetic and real data respectively Resolving bank con”icts produced a stable to improvement in execution time across all dataset Such a performance improvement is evident at the worst case where 32-way bank con”ict occurs Bank con”icts are caused during partial result sharing creating additional overhead that is upper bounded by the warp size across multiple warps For this 
027\011$\012\014\017\021\036\021\031\013\020  025\012%&\011\036\013\020\022\036\022'\031\014  025\012%&\011\036\013\020\022\036\022\020\031\014 021\(\011\032\015\011\021\030\020 
026\027\012\007\030\004\007\010\005\013\031\013    026\027\012\007\030\004\007\010\005\013\033\013    026\027\012\007\030\004\007\010\005\013\034\013    026\027\012\007\030\004\007\010\005\013\035\013    026\027\012\007\030\004\007\010\005\013\036\013  
B Shared Memory Utilization  Bank Con”icts 
1430 
1430 


002 004\002 005\002 006\002 007\002 003\002 033\002 034\002 035\002 002\004\002\005\002 006\002 
002 005 007 033 035 004\002 004\005 004\007 004\005\006\007\003\033 
C Increased Rule Length 
002 005 007 033 035 004\002 004\005 004\007 004\033 004\035 005\002 020\020\030\027\011\025\021\013 026\032\025\025\011\020\021\030\032 025 011\021\012\030\017 023\004\002\002 023\004\002\004 
 
002\003\004\005\006\007\010\011\012\013\014\010\015\004\013'\013\022\015\(\023\011\\004\015\004\012\007\013 024\007\024!\004\007\013 002\003\004\005\006\007\010\011\012\013\014\010\015\004\013'\013\022\015\(\023\011\\004\015\004\012\007\013 024\007\024!\004\007\013 
Figure 6 Throughput for increasing length rule candidates The Y-axis is measured in billion evaluations per second The X-axis shows the corresponding rule length As before the gures include the theoretical trend-line computed from amplifying naive-sc on the GPU using Eq 4 reason the observed improvement is stable depending mostly on the item number Assigning multiple candidate rule collections to a single block resulted in Figure 7 Percentage improvement in execution time as compared to the default-tpsc kernel for the individually optimized kernels when using synthetic data   Figure 8 Percentage improvement in execution time as compared to the default-tpsc kernel for the individually optimized kernels when using real data For both kernels we observe a similar behaviour when we increase rule candidate length to a number larger than 32 After that point we require evaluating the pre“x in two phases following a technique similar to parallel reduction although using warp vote functions This extra phase requires an additional synchronization step which increases the total execution time per iteration Additionally when we have prominent rules with item indices in sequence i.e accidents dataset as indicated by its sparsity pattern caching transactions does not provide any improvement However when there are many rules with out of sequence pre“xes the cost of uncoalesced memory accesses matches the synchronization cost as indicated by experiments on dataset 1 VIII C ONCLUSION In this paper we studied the support count operation commonly used in association rule mining problems We proposed a work-ef“cient parallel algorithm that is suitable for massively parallel architectures Furthermore we presented a data layout scheme used to enable low overhead coordination of the processing elements reduce the memory requirements and achieve high off-chip memory bandwidth utilization Furthermore we discussed in detail low level optimization strategies related to effective use of shared memory while presenting a simple strategy for resolving shared memory bank con”icts incurring minimal additional work However there is still some additional issues that we need to address Firstly we already considering resolving the issue of 
025 015\013\036\021\031\013\020 015\036\021\031\013\020 
improvement over the default-tpsc execution time A combination of loop unrolling and increase shared memory utilization from storing more candidate rules in the same block was the reason for the observed improvement In contrast enabling caching of transactions in shared memory with kernel mrs-tpsc presented less improvement in the relative execution time compared to mr-tpsc The culprit is this case is the additional synchronization step which is required after loading the data in shared memory Finally experiments performed on dataset 2 and 4 indicate similar behavior to our previous experiments where multiprocessor underutilization was limiting the maximum possible performance increase Even in the case where we increase the workload of participating blocks interleaved execution of warps is limited since as the block size is small In this section we discuss the effects of discovering rules with length larger than 32 Due to lack of space we present the results from the execution on synthetic data 1 and accidents which are good representatives of the observed behaviour We focus on the mrs-tpsc and mr-tpsc variations which we established to be highly optimized throughout our experiments   
025 015\013\036\021\031\013\020 015\036\021\031\013\020 
037\005\005\010 \004\012\007!\013   002 003 004\002 004\003 005\002 005\003 006\002 006\003 007\002 002\004\002\005\002 006\002 011\012\012\004\005\007\010\011\012\013   002 003 004\002 004\003 005\002 005\003 006\002 006\003 007\002 002\004\002\005\002\006\002 004\007\024\010$\013  014%\031&&\013 
18 
027\011$\012\014\017\021\036\021\031\013\020  025\012%&\011\036\013\020\022\036\022'\031\014  025\012%&\011\036\013\020\022\036\022\020\031\014 021\(\011\032\015\011\021\030\020    002 004 005 006 007 002\004\002\005\002 006\002 
1431 
1431 


 volume 22 pages 207…216 ACM 1993  R Agra w al R Srikant et al F ast algorithms for mining association rules In  volume 1215 pages 487…499 1994  E Ansari G Dastghaibif ard M K eshtkaran and H Kaabi Distrib uted frequent itemset mining using trie data structure  35\(3 2008  M Atzmueller and F  Puppe Sd-map…a f ast algorithm for e xhausti v e subgroup discovery In  pages 6…17 Springer 2006  C Creighton and S Hanash Mining gene e xpression databases for association rules  19\(1 2003  W  F ang M Lu X Xiao B He and Q Luo Frequent itemset mining on graphics processors In  pages 34…42 ACM 2009  K Geurts G W ets T  Brijs and K V anhoof Pro“ling of high-frequenc y accident locations by use of association rules  1840 2003  A Ghoting G Buehrer  S P arthasarathy  D Kim A Nguyen Y K Chen and P Dubey Cache-conscious frequent pattern mining on modern and emerging processors  16\(1 2007  G Grahne and J Zhu Ef ciently using pre“x-trees in mining frequent itemsets In  volume 90 2003  J Han J Pei and Y  Y in Mining frequent patterns without candidate generation In  volume 29 pages 1…12 ACM 2000  J Hipp U G  untzer and G Nakhaeizadeh Algorithms for association rule mining„a general survey and comparison  2\(1 2000  R Jin and G Agra w al An algorithm for in-core frequent itemset mining on streaming data In  pages 8…pp IEEE 2005  R Jin and G Agra w al Systematic approach for optimizing comple x mining tasks on multiple databases In  pages 17…17 IEEE 2006  E Lindholm J Nick olls S Oberman and J Montrym Nvidia tesla A uni“ed graphics and computing architecture  2 2008  J Liu Y  P an K W ang and J Han Mining frequent item sets by opportunistic projection In  pages 229…238 ACM 2002  L Liu E Li Y  Zhang and Z T ang Optimization of frequent itemset mining on multiple-core processor In  pages 1275…1285 VLDB Endowment 2007  B Mobasher  R Coole y  and J Sri v asta v a Automatic personalization based on web usage mining  43\(8 151 2000  E  Ozkural B Ucar and C Aykanat Parallel frequent item set mining with selective item replication  22\(10 2011  J Pei J Han H Lu S Nishio S T ang and D Y ang H-mine Hyper structure mining of frequent patterns in large databases In  pages 441…448 IEEE 2001  I Pramudiono and M Kitsure ga w a P arallel fp-gro wth on pc cluster  In  pages 467…473 Springer 2003  C Silv estri and S Orlando gpudci Exploiting gpus in frequent itemset mining In  pages 416…425 IEEE 2012  A T ajbakhsh M Rahmati and A Mirzaei Intrusion detection using fuzzy association rules  9\(2 2009  T  T assa Secure mining of association rules in horizontally distrib uted databases  26\(4 2014  K W ang M Stan and K Skadron Association rule mining with the micron automata processor In  2015  M J Zaki Scalable algorithms for association mining  12\(3 2000  M J Zaki M Ogihara S P arthasarathy  and W  Li P arallel data mining for association rules on shared-memory multi-processors In  pages 43…43 IEEE 1996  F  Zhang Y  Zhang and J D Bak os Accelerating frequent itemset mining on graphics processing units  66\(1 2013  Y  Zhang F  Zhang Z Jin and J D Bak os An fpga-based accelerator for frequent itemset mining  6\(1 2013 
002 004 005 006 007 002 004\005\035 005\003\033 006\035\007 003\004\005 002 033 004\005 004\035 005\007 002 004\005\035 005\003\033 006\035\007 003\004\005 
ACM SIGMOD Record Proc 20th int conf very large data bases VLDB IAENG International Journal of Computer Science Knowledge Discovery in Databases PKDD 2006 Bioinformatics Proceedings of the fth international workshop on data management on new hardware Transportation Research Record Journal of the Transportation Research Board The VLDB Journal FIMI ACM SIGMOD Record ACM sigkdd explorations newsletter Data Mining Fifth IEEE International Conference on Data Engineering 2006 ICDE06 Proceedings of the 22nd International Conference on IEEE micro Proceedings of the eighth ACM SIGKDD international conference on Knowledge discovery and data mining Proceedings of the 33rd international conference on Very large data bases Communications of the ACM Parallel and Distributed Systems IEEE Transactions on Data Mining 2001 ICDM 2001 Proceedings IEEE International Conference on Advances in Knowledge Discovery and Data Mining Parallel Distributed and Network-Based Processing PDP 2012 20th Euromicro International Conference on Applied Soft Computing Knowledge and Data Engineering IEEE Transactions on Proceedings of the 2015 IEEE 29th International Parallel and Distributed Processing Symposium Knowledge and Data Engineering IEEE Transactions on Supercomputing 1996 Proceedings of the 1996 ACM/IEEE Conference on The Journal of Supercomputing ACM Transactions on Recon“gurable Technology and Systems TRETS 
Figure 9 Execution time measured for increasing rule size  the Xaxis indicates the rule length multiprocessor under-utilization For dataset with low number of items we can assign individual groups of threads in the same block to different rule collections effectively increasing the block size as well as utilization Secondly we would like to adapt our solution to an architecture consisting of multiple GPUs and address challenges related to partial result sharing A CKNOWLEDGMENT This work was supported by the U.S National Science Foundation under grant ACI-1339756 R EFERENCES  Frequent itemset mining dataset repository  2015 URL http://“mi.ua.ac.be/data  R Agra w al T  Imieli  nski and A Swami Mining association rules between sets of items in large databases In 
014\010\015\004\013\016!\004\005!\021\013 026\027\012\007\030\004\007\010\005\013\031\013 014\010\015\004\016!\004\005!\021\013 037\005\005\010 \004\012\007!\013 
015\036\021\031\013\020 015\013\036\021\031\013\020 
1432 
1432 


 Frequent pattern mining Current status and future directions  2007  R Agra w al and R Srikant F ast algorithms for mining association rules in  1994  M J Zaki Scalable algorithms for association mining  vol 12 no 3 pp 372…390 2000  J Han J Pei and Y  Y in Mining frequent patterns without candidate generation in  2000  Y  Zhang F  Zhang and J Bak os Frequent itemset mining on large-scale shared memory machines in  2011  F  Zhang Y  Zhang and J D Bak os  Accelerating frequent itemset mining on graphics processing units  vol 66 no 1 pp 94…117 2013  Y  Zhang  An fpga-based accelerator for frequent itemset mining  vol 6 no 1 pp 2:1…2:17 May 2013  P  Dlugosch  An ef“cient and scalable semiconductor architecture for parallel automata processing  vol 25 no 12 2014  I Ro y and S Aluru Finding motifs in biological sequences using the micron automata processor in  2014  R Agra w al T  Imieli  nski and A Swami Mining association rules between sets of items in large databases in  1993  H No yes Microns automata processor architecture Recon“gurable and massively parallel automata processing in  June 2014 keynote presentation  M J Zaki  Parallel data mining for association rules on shared-memory multi-processors in  1996  L Liu  Optimization of frequent itemset mining on multiple-core processor in  2007  I Pramudiono and M Kitsure ga w a P arallel fp-gro wth on pc cluster in  2003  E Ansari  Distributed frequent itemset mining using trie data structure  vol 35 no 3 p 377 2008  W  F ang  Frequent itemset mining on graphics processors in  2009  B Goethals Surv e y on frequent pattern mining  Univ of Helsinki Tech Rep 2003  C Bor gelt Ef cient implementations of apriori and eclat in  2003 p 90  Frequent itemset mining dataset repository   http mi.ua.ac.be/data  J Rabae y  A Chandrakasan and B Nik oli  c  2nd ed Pearson Education 2003 
100 1000 10000 5 50 500 5000 re_sup = 0.12 Eclat-6C \(32nm Eclat-1G \(28nm Apriori-AP 45nm Apriori-AP 32nm Apriori-AP 28nm Computation Time \(s Size of Dataset \(MB Eclat-6C \(32nm Eclat-1G \(28nm Apriori-AP 45nm Apriori-AP 32nm Apriori-AP 28nm GPU fails for re_sup = 0.08 re_sup = 0.08 
GPU fails re_sup = 0.42 re_sup = 0.42 Eclat-6C \(32nm Eclat-1G \(28nm Apriori-AP 45nm Apriori-AP 32nm Apriori-AP 28nm  Computation Time \(s Size of Dataset \(MB Eclat-6C \(32nm Eclat-1G \(28nm Apriori-AP 45nm Apriori-AP 32nm Apriori-AP 28nm GPU fails re_sup = 0.3 re_sup = 0.3 b T100 Figure 11 Performance prediction with technology normalization as a function of input size implementation In contrast the capability of our AP ARM solution scales nicely with the data size since the AP was designed for processing streaming data With the challenge of the big data era a number of other complex pattern mining tasks such as frequent sequential pattern mining and frequent episode mining have attracted great interests in both academia and industry We plan to extend the proposed CPU-AP infrastructure and automaton designs to address more complex pattern-mining problems A CKNOWLEDGMENT This work was supported in part by the Virginia CIT CRCF program under grant no MF14S-021-IT by C-FAR one of the six SRC STARnet Centers sponsored by MARCO and DARPA NSF grant EF-1124931 and a grant from Micron Technology R EFERENCES  J Han 
et al Data Min Knowl Discov Proc of VLDB 94 IEEE Trans on Knowl and Data Eng Proc of SIGMOD 00 Proc of CLUSTER 11 J Supercomput et al ACM Trans Recon“gurable Technol Syst et al IEEE TPDS Proc of IPDPS14 Proc of SIGMOD 93 Proc of Fifth International Symposium on Highly-Ef“cient Accelerators and Recon“gurable Technologies et al Proc of Supercomputing 96 et al Proc of VLDB 07 Proc of PAKDD 03 et al IAENG Intl J Comp Sci et al Proc of DaMoN 09 Proc FIMI 03 Digital Integrated Circuits 
1 10 100 1000 10000 0.1 1 10 100 1000 
a Webdocs 
699 


