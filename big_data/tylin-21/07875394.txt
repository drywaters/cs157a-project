SPECIAL SECTION ON HETEROGENEOUS CROWDSOURCED DATA ANALYTICS  Received February 16 2017 accepted March 8 2017 date of publication March 10 2017 date of current version April 24 2017 Digital Object Identifier 10.1109/ACCESS.2017.2681207 Comparison of Different Data Aggregation Techniques in Distributed Sensor Networks HASSAN HARB 1,2  ABDALLAH MAKHOUL 2  SAMAR TAWBI 3  AND RAPHA\313L COUTURIER 2 1 Department of Computer Science American University of Culture and Education Tyre Lebanon 2 FEMTO-ST Institute Univ Bourgogne Franche-Comt\351 CNRS 19 Av Mar\351chal Juin 90000 Belfort France 3 Department of Computer Science Lebanese University Beirut Lebanon Corresponding author A Makhoul 050abdallah.makhoul@univ-fcomte.fr\051 This project has been performed in cooperation with the Labex ACTION Program under contract ANR-11-LABX-0001-01 ABSTRACT Wireless sensor networks 050WSNs\051 are almost everywhere they are exploited for thousands of applications in a densely distributed manner Such deployment makes WSNs one of the highly anticipated key contributors of the big data nowadays Hence data aggregation is attracting much attention from researchers as ef\034cient way to reduce the huge volume of data generated in WSNs by eliminating the redundancy among sensing data In this paper we propose an ef\034cient data aggregation technique for clustering-based periodic wireless sensor networks Further to a local aggregation at sensor node level our technique allows clusterhead to eliminate redundant data sets generated by neighbouring nodes by applying three data aggregation methods These proposed methods are based on the sets similarity functions the one-way Anova model with statistical tests and the distance functions respectively Based on real sensor data we have analyed their performances according to the energy consumption and the data latency and accuracy and we show how these methods can signi\034cantly improve the performance of sensor networks INDEX TERMS Periodic sensor network 050PSN\051 data aggregation clustering topology big-data sensing similarity and distance functions Anova model I INTRODUCTION Speaking about more than hundreds and sometimes thousands of sensors which are randomly distributed for monitoring target phenomenon makes WSNs one of the big data producers This fact has been supported by the report of ORACLE where some e xamples of applications generating big sensor data were provided in the report In addition the authors in and 3 gi v e man y real WSN applications where the scale of the sensory data has already exceeds several petabytes 050PB\051 annually However such big data applications raise two problems high energy consumption and complex data analysis First the sensing of big data volume leads to a great waste of sensors energy which is usually limited and not rechargeable thus decreases the network lifetime Second it is a complicated mission for decision makers when dealing with a big amount of sensed data that mostly contain a high redundancy level to make the right decisions In order to handle these problems researchers has been focused on the data aggregation methods in WSNs The main goal of these methods is to minimize the huge amount of data generated by neighboring nodes thus conserving network energy and providing a useful information for the end user 5 In this paper we consider a cluster-based periodic sensor network 050CPSN\051 where each sensor monitors the given phenomenon and periodically sends its collected data to its CH Then we introduce a complete data aggregation framework for CPSN Two layer algorithms are introduced at the node level and at the CH level These algorithms aim at optimizing the volume of transmitted data thus saving energy consumption and reducing bandwidth on the network level At the 034rst level an aggregation process aggregates data on a periodic basis avoiding each sensor node to send its raw data to the sink At the second level we present and compare three different methods to search for redundancies between data sets generated by neighboring sensor nodes The 034rst method uses the similarity functions such as the Jaccard function to search the similarities between data sets The second method searches the dependence of conditional variance between data sets based on the one-way Anova model and the Bartlett test Finally dissimilarities between sets are calculated in the third method based on distance functions such as Euclidean and Cosine Indeed it is important to notice that 034rst and second methods are already proposed in our previous works while in this paper we propose the distance functions as new data aggregation method for CPSN Then our objective is to 4250 2169-3536 012 2017 IEEE Translations and content mining are permitted for academic research only Personal use is also permitted but republication/redistribution requires IEEE permission See http://www.ieee.org/publications_standards/publications/rights/index.html for more information VOLUME 5 2017 


H Harb et al  Comparison of Different Data Aggregation Techniques in Distributed Sensor Networks  compare the three methods in terms of energy consumption data accuracy and data latency Finally we give the user the opportunity to choose the solution that matches the most its expectations and requirements The rest of this paper is organized as follows Section II describes some of the existing data aggregation techniques proposed for WSNs Section III provides a brief discussion of the data aggregation system based on clustering topology used in our proposed technique In Section IV we describe the aggregation at the sensor level called local aggregation Sections V VI and VII present the three aggregation methods at the CH level based on the similarity functions the variance study and the distance functions respectively Section VIII details the experimentations we have conducted in real sensors data with discussion of results of the three methods Finally Section IX concludes the paper while highlighting some future scopes of work II STATE OF THE ART Reducing energy consumption is a major issue in WSNs where sensors are usually battery-limited Hence data aggregation is an essential operation in WSNs used to decrease the data transmission thus to enhance the network lifetime It means computing and transmitting partially aggregated data to the end user rather than transmitting raw data in networks to reduce the energy consumption Data aggregation in wireless sensor networks has been well studied in recent years  Indeed the performance of an y data aggregation technique is strongly dependent on the network's topology Hence researchers have proposed many network's topologies for WSNs such as Tree-based Cluster based Chain-based 13 or structure free-based 7 topology The authors 14 and 15 use the clustering methods for aggregating data packets in each cluster separately In the authors propose a data aggre g ation scheme named DMLDA Dynamical Message List based Data Aggregation based on clustering routing algorithm DMLDA mainly de\034nes a special list structure to store history messages which is used to judge the message redundancy instead of the period delay In the authors propose an aggre g ation and transmission protocol 050ATP\051 based on clustering approach to conserve energy in PSNs Instead of sending raw data to the CH ATP allows each sensor to eliminate redundancy among its collected data and to adapt its data transmission to the CH using one way Anova model and Fisher test Other proposed techniques of data aggregation are based on a tree network topology such as and 9 The authors in use Genetic Algorithm 050GA\051 to calculate all possible routes represented by the aggregation tree The objective is to 034nd the optimum tree which is able to balance the data load and the energy in the network In a semi-structured protocol based on the multi-objective tree is proposed in order to reduce transmission delays and enhance the aggregation probability In such a work the routing scheme explores the optimal structure by using the Ant Colony Optimization 050ACO\051 Other works on data aggregation in WSNs are based on a chain routing topology 18 In 10 the authors propose a Cycle-Based Data Aggregation Scheme 050CBDAS\051 in order to reduce the amount of data transmitted to the base station 050BS\051 In CBDAS the network is divided into a grid of cells each with a head The network lifetime is prolonged by linking all cell heads together to form a cyclic chain where the gathered data move from node to node along the chain getting aggregated In a chain-based routing scheme for application-oriented cylindrical networks is proposed After 034nding local optimum paths in separate chains at each scheme the authors formulate mathematical models to 034nd a global optimum path for data transmission through their interconnection Finally some works proposed recently on data aggregation are based on a structure-free of the network 20 In the authors propose a Structure-Free and Ener gyBalanced data aggregation protocol SFEB SFEB features both ef\034cient data gathering and balanced energy consumption which result from its two-phase aggregation process and the dynamic aggregator selection mechanism In a virtual force-based dynamic routing algorithm 050VFE\051 for data aggregation in WSNs is proposed Motivated by the cost 034eld and virtual force theories VFE allows each node to select the optimal node to be the next hop which makes data aggregation more ef\034cient Subsequently clustering is recently considered as an ef\034cient topology control method in WSN that has many advantages especially as far as scalability and network maintenance are concerned compared to other topologies However most of the existing data aggregation techniques based on clustering topology are dedicated to event driven data model 22 and the y mainly focus on the selection of CHs 24 In these techniques only CHs process and aggregate data without any processing at the level of the nodes themselves In this paper we propose three data aggregation techniques dedicated to PSN which achieve an aggregation of data at both nodes and CHs They have two phases which are able to eliminate redundant data generated by nodes at each period III NETWORK TOPOLOGY In this paper we focus on the cluster-based network topology where the whole network is divided into several clusters Each cluster has a cluster-head 050CH\051 which is responsible for managing the sensors in this cluster Indeed grouping sensor nodes into clusters has been widely adopted and studied by the research community to satisfy the scalability objective and achieve high energy ef\034ciency and prolong the network lifetime  Some of proposed techniques aim at forming and maintaining the clustered networks while optimizing cluster size 29 others try to select the Cluster-Head 050CH\051 or to change the entire cluster hierarchies periodically 25 30 others are interested in VOLUME 5 2017 4251 


H Harb et al  Comparison of Different Data Aggregation Techniques in Distributed Sensor Networks  communication among nodes and among clusters 27 or in cluster joining Hence in this paper  we adopt a cluster based architecture and we consider that the network is clustered and the CHs are de\034ned using an appropriate clustering scheme FIGURE 1 Data aggregation based on clustering network topology In Fig 1 we present a cluster-based sensor network topology where sensed data reach their destination 050the sink\051 by traveling via CHs In addition the following constraints are respected in our network's topology 017 Data transmission between member nodes and their appropriate CH or between CHs and the sink is based on single-hop communication 017 Member nodes collect data in a periodic manner Subsequently each member node sends its data to the appropriate CH at each period 017 Sensor nodes sense environment at a 034xed sampling rate where each one takes 034 measures at each period Then our proposed data aggregation technique works in two levels the 034rst one at the sensor nodes level called local aggregation and the second at the CHs level 050Fig 1\051 IV AGGREGATION AT SENSOR LEVEL LOCAL AGGREGATION In WSN measures collected by sensor nodes are highly dependent on the monitored condition Consequently when the monitored condition slows down or speeds up then the measures collected by each sensor are more correlated and redundant That fact is con\034rmed by the example shown in Fig 2 In Fig 2 sensors are deployed in the Intel Laboratory and the y collect temperature measures F or a period of one day readings collected by sensors S 10 and S 46 span over a range of 15  95  21   and 14  01  22   respectively Small ranges of measures shown in Fig 2 indicate that measures collected by each sensor are very similar in this period Therefore if sensors send all the collected measures to their appropriate CHs their energy will be wasted and thus the network energy will be quickly depleted Hence data aggregation becomes a requirement in WSNs to minimize redundant data generated by sensor nodes A DEFINITIONS AND NOTATIONS In PSN each period p is divided into 034 equal time slots as follows p D  s 1  s 2      s 034 003  At each slot s j  each sensor S i captures a new measure m i j  then it forms a vector of measures during the period p as follows M i D 002 m i 1  m i 2      m i 034 003  Fig 3 shows an example of periodic data collection where FIGURE 2 Sensors in the Intel Laboratory FIGURE 3 Data collection in PSN the sensor node S i takes 034ve measures 050e.g 034 D 5\051 at each period p q 050where q 2  and sends its v ector of collected data M i D 002 m i 1  m i 2  m i 3  m i 4  m i 5 003 to the CH at the end of each period As mentioned above a data vector M i formed by the sensor S i may contain similar measurements especially when the monitored condition varies slowly or when the slots are short In order to eliminate redundant values from the vector M i  the sensor node S i searches for measures similarities in the vector Thus we assign to each sensor node the Similar function i.e Similar 050 m i j  m i k 051 to identify if the two measures m i j and m i k captured by the sensor S i in the period p are similar or not The Similar function is de\034ned as follows De\034nition 1 050Similar Function\051 We de\034ne the Similar function between two measurements captured by the same sensor node S i at a period p as Similar 050 m i j  m i k 051 D 050 1 if 015 015 m i j 000 m i k 015 015 024  0 otherwise  where m i j and m i k 2 M i and  is a threshold determined by the application Furthermore two measures are similar if and only if their Similar function is equal to 1 4252 VOLUME 5 2017 


H Harb et al  Comparison of Different Data Aggregation Techniques in Distributed Sensor Networks  In order to save the integrity of the information we de\034ne the weight of a measure as follows De\034nition 2 050Measure's Weight wgt 050 m i j 051 051 The weight of a measurement m i j is de\034ned as the number of similar measures 050according to the Similar function\051 to m i j in the same vector M i  Based on the notations de\034ned above we describe the local aggregation phase which is run by the nodes themselves at each period in the following manner for each new captured measurement a sensor node S i searches for similarities of the new taken measurement If a similar measurement is found it deletes the new one and increments the corresponding weight by 1 else it adds the new measure to the set and initializes its weight to 1 1 After applying local aggregation S i will transform the initial vector of measures M i  to a set of measures M 0 i  associated to their corresponding weights as follows M 0 i D f 050 m 0 i 1  wgt 050 m 0 i 1 051\051 050 m 0 i 2  wgt 050 m 0 i 2 051\051      050 m 0 i k  wgt 050 m 0 i k 051\051 g  where k 024 034  Illustrative example let consider a vector of measures generated by the sensor S i at the period p as follows M i D 10  10  2  10  3  11  11  1  12  11  3  10  4  12  1  12   By taking  D 0  5 Similar function will transform the vector M i to the following set of measures M 0 i D f 05010 I 4\051  05011 I 3\051  05012 I 3\051 g  where 4 3 and 3 are the weights of the measures 10 11 and 12 respectively Based on the set M 0 i  we provide the following de\034nitions De\034nition 3 050Cardinality of the Set M 0 i  j M 0 i j 051 The cardinality of the set M 0 i is equal to the number of elements in M 0 i  i.e j M 0 i j D k  De\034nition 4 050Weighted Cardinality of the Set M 0 i  wgt c 050 M 0 i 051 051 The weighted cardinality of the set M 0 i is equal to the sum of all measures weights in M 0 i as follows wgt c 050 M 0 i 051 D P j M 0 i j j D 1 wgt 050 m i j 051  034  where m i j 2 M 0 i  At the end of each period p  each sensor node S i will have a set M 0 i with no redundant measures The second step is to send it to the appropriate CH which in turn aggregates the data sets coming from different member nodes In the next sections we present three different aggregation methods at the CH level V AGGREGATION AT THE CH USING SETS SIMILARITY FUNCTIONS At the end of each period each CH will receive several sets of measurements and their weights from different nodes The objective of the second aggregation level is to eliminate redundant data sets by identifying all pairs of sets whose similarities are above a given threshold For this reason we used in our previous work the Jaccard similarity function which is one of the most widely accepted functions as it can support many other similarity functions The Jaccard similarity function returns a value in 0   where a higher value indicates that the sets share more similarities Thus we can treat pairs of sets with high Jaccard similarity value as 1 Several methods could be applied like dichotomic search compression etc near duplicate to reduce the size of 034nal data sets transmitted from the CH to the sink A Jaccard similarity function between two sets M 0 i and M 0 j  generated respectively by the sensors S i and S j  can be formulated as follows J 050 M 0 i  M 0 j 051 025 t J  j M 0 i 134 s M 0 j j 025 013 D 2 002 t J 002 034  1 C t J 0501\051 where t J is the Jaccard threshold de\034ned by the application itself and  134 s  is de\034ned as De\034nition 5 Consider two sets of measurements M 0 i and M 0 j  then we de\034ne the overlap 134 s  between them as M 0 i 134 s M 0 j D f 050 m 0 i  m 0 j 051 2 M 0 i 002 M 0 j with weight wgt min 050 m 0 i  m 0 j 051 such that Similar 050 m 0 i  m 0 j 051 D 1 g  where wgt min 050 m 0 i  m 0 j 051 D min 050 wgt 050 m 0 i 051  wgt 050 m 0 j 051\051 the minimum value of the weight of m 0 i and m 0 j  Then in order to prevent CH from enumerating and comparing every pair of sets which has a O 050 n 2 051 number of comparisons we proposed to use a pre\034x frequency 034ltering 050PFF\051 technique The PFF technique works in the following two steps to 034nd the pairs of similar sets 017 Candidate pairs generation in this step the CH searches the candidates 050which may or may not be similar\051 sets for every data set This step is based on the intuition that if all sets of measures are sorted by a global ordering some fragments of them must share several common tokens with each other in order to meet the Jaccard threshold similarity 050 t J 051 Therefore it 034rst de\034nes a pre\034x of length j M 0 i j 000 d t J 002 j M 0 i je C 1 for every set M 0 i  Then two sets M 0 i and M 0 j are candidates if and only if they share at least 014 measurements in their pre\034xes as shown in the following lemma Lemma 1 Assume that all the measures in the sets M 0 i and M 0 j are ordered in decreasing order of the measures weights Let the p-pre\034x be the 034rst p elements of M 0 i  If M 0 i 134 s M 0 j 025 0502 002 t J 002 034 051  0501 C t J 051 then p 000 M 0 i 134 s p 000 M 0 j 025 014 D P j p 000 M 0 i j k D 1 wgt 050 m 0 k 051 000 000 0501 000 t J 051  0501 C t J 051 001 002 034 where m 0 k 2 p 000 M 0 i  Proof 1 We denote by p M 0 i the pre\034x of the set M 0 i and r M 0 i the set of reminder measures where M 0 i D f p M 0 i C r M 0 i  We have M 0 i 134 s M 0 j D p 000 M 0 i 134 s M 0 j C r 000 M 0 i 134 s M 0 j D p 000 M 0 i 134 s p 000 M 0 j C p 000 M 0 i 134 s r 000 M 0 j C r 000 M 0 i 134 s M 0 j 030 D p 000 M 0 i 134 s p 000 M 0 j C r 000 M 0 i 134 s M 0 j 024 p 000 M 0 i 134 s p 000 M 0 j C j r 000 M 0 i j X k D 1 050 wgt 050 m 0 k 2 r 000 M 0 i 051\051 In the second line we can omit the term p 000 M 0 i 134 s r 000 M 0 j because we have assumed that it is negligible compared to the other terms in the equation Indeed if the two sets are similar then the measures having VOLUME 5 2017 4253 


H Harb et al  Comparison of Different Data Aggregation Techniques in Distributed Sensor Networks  highest weights must be in the pre\034x set and not in the reminder which means that the overlapping between the p M 0 i and r M 0 j is almost empty From the above equations and equation 0501\051\050similarity condition\051 we can deduce 2 002 t J 002 034  1 C t J 024 p 000 M 0 i 134 s p 000 M 0 j C j r 000 M 0 i j X k D 1 wgt 050 m 0 k 2 r 000 M 0 i 051  0502\051 From the following equation j p 000 M 0 i j X k D 1 wgt 050 m 0 k 2 p 000 M 0 i 051 C j r 000 M 0 i j X k D 1 wgt 050 m 0 k 2 r 000 M 0 i 051 D 034 0503\051 We obtain p 000 M 0 i 134 s p 000 M 0 j 025 j p 000 M 0 i j X k D 1 wgt 050 m 0 k 2 p 000 M 0 i 051 000 1 000 t J  1 C t J 002 034 0504\051 The lemma is proved Based on the lemma 1 the CH calculates the overlap between the pre\034x of each pair of sets the two sets are considered a candidate pair if their calculated overlap is greater than 014  017 Candidates veri\034cation once all the candidates pairs are found the CH veri\034es the Jaccard similarity for each one in the second step The two sets in a candidate pair are considered similar if their similarity is greater than the Jaccard threshold t J  Algorithm 1 describes the PFF technique to 034nd similar sets Brie\035y the CH searches similar measures between pre\034xes of every pair of sets using the Similar function 050lines 3-21\051 Then it assumes that the two sets are a candidate pair only if the overlap between their pre\034xes is greater than the score determined at lemma 1 050line 22\051 Finally the two sets are considered similar if the overlap between their measures is greater than the Jaccard threshold 050lines 23\02525\051 For more details about this algorithm please refer to Algorithm 1 in In order to decrease the data latency we provided several optimizations of the PFF technique based on the suf\034x 034ltering and the k-means algorithm 36 In 35 we propose a suf\034x 034ltering based on the measure weights in order to prune erroneous candidates that survive after applying pre\034x 034ltering In we propose to group data sets into clusters using k-means algorithm before applying PFF over each one By this way we minimize the number of comparisons thus enhancing the aggregation process time  Algorithm 1 PFF Algorithm  Require Set of measures sets M 0 D f M 0 1  M 0 2  M 0 n g  t J  Ensure All pairs of sets 050 M 0 i  M 0 j 051 such that J 050 M 0 i  M 0 j 051 025 t J  1 S 040  2 I i 040  0501 024 i 024 total number of measures in the pre\034xes of all sets\051 3 for each set M 0 i 2 M 0 do 4 p 040 j M 0 i j 000 d t J 002 j M 0 i je C 1 5 F s 040 empty map from set id to int 6 sumFreq 040 0 7 for k 040 1 to p do 8 sumFreq 040 sumFreq C wgt 050 m 0 k 051  where m 0 k 2 p 000 M 0 i 9 end for 10 for k 040 1 to p do 11 w 040 M 0 i  k  12 if 050 I w s exists such that Similar 050 w  w s 051 D 1\051 then 13 for each Measurement 050 M 0 j  l   wgt 050 M 0 j  l  2 I w s do 14 F s  M 0 j  040 F s  M 0 j  C wgt min 050 M 0 i  k   M 0 j  l  15 end for 16 I w s 040 I w s  f p 000 M 0 i g 17 else 18 create I w 19 I w 040 I w  f p 000 M 0 i g 20 end if 21 end for 22 for each M 0 j such that Fs  M 0 j  025 sumFreq 000 050\0501 000 t J 051  0501 C t J 051\051 002 034 do 23 if J 050 M 0 i  M 0 j 051 025 013 then 24 S 040 S  f 050 M 0 i  M 0 j 051 g 25 end if 26 end for 27 end for 28 return S  VI AGGREGATION AT THE CH USING ANALYSIS OF VARIANCE Studying the variance between measurements in the data sets is another way of 034nding nodes that generate redundant data sets In this section our objective is to brie\035y explain our technique proposed in based on the k-means algorithm adopted by the Anova model and the Bartlett test Indeed the one-way Anova model is used to identify if the variance 050 R 051 between measures in a group of data sets is signi\034cant or not R can be calculated in different manners depending on the statistic tests proposed in the Anova model In 38 we used the Anova model in order to detect all pairs of nodes with identical behavior which generate redundant data logs or sets In a later time we proposed an enhanced k-means clustering method adopted to the one-way Anova model in order to search groups of sensors that generate redundant data In such method we used three tests 050Fisher  T uk e y and Bartlett\051 then we concluded that the Bartlett test gives the 4254 VOLUME 5 2017 


H Harb et al  Comparison of Different Data Aggregation Techniques in Distributed Sensor Networks  best results compared to Fisher and Tukey Therefore in this paper the Bartlett test is compared to the other methods Once R is calculated the sets are considered duplicated if R is less than a threshold T 050signi\034cance level de\034ned in chi-square table\051 for some desired false-rejection probability 050risk 013 051 R is calculated according to the Bartlett test as follows R D 050 034 000 1\051\050 n 002 ln\050 033 2 p 051 000 P n j D 1 ln\050 033 2 j 051\051  025 0505\051 where n is the number of total sets 033 2 j is the variance of the set M 0 j and 025 D 1 C 050 n C 1\051  3 002 n 002 050 034 000 1\051 0506\051 and 033 2 p is the pooled variance which is a weighted average of the period variances and it is de\034ned as 033 2 p D 1  n 002 050 034 000 1\051 002 n X j D 1 033 2 j Thus the decision is based on the following rule 017 if R  T  the variance between the sets is signi\034cant thus the sets are considered redundant 017 if R 024 T  the variance between the sets is not signi\034cant In order to apply the Anova model over the groups of sets we used the k-means algorithm to classify the sets in groups based on the means of these sets Then we proposed a new initialization method to 034nd dynamically the optimal number of groups 050 K 051 in k-means The proposed method divides a parent group into b p  n  2 c children groups where n is the number of total sets at each period every time the Anova model is not satis\034ed Finally the CH sends one data set from each group with the IDs of all the sensors in this group to the sink Algorithm 2 describes the k  means algorithm adopted by the A  nova model and the B  artlett test or simply the KAB technique proposed in First it starts as e xplained previously by grouping all the received sets at the initial same group 050lines 4 to 6\051 Then it searches the variance between measurements in all the sets in the initial group using the Anova model and the Bartlett test 050lines 9 and 10\051 If the test's result indicates a low variance between the sets then the algorithm considers this group as a 034nal group and it puts it in the list of 034nal groups 050lines 11 12 and 13\051 Else it divides the initial group in K sub groups by applying the k-means algorithm 050line 15\051 Once the 034nal groups are obtained CH sends only one useful information to the sink e.g the data set with the highest cardinality and the IDs for the sensors that generate redundant data sets 050lines 19 to 22\051 VII AGGREGATION AT THE CH USING DISTANCE FUNCTIONS In this section we propose a new method to search redundant data sets generated by the sensors using the distance functions Distance functions are an important method that can  Algorithm 2 K-means Adopted to Variance Study  Require Set of measures sets M 0 D f M 0 1  M 0 2  M 0 n g  K  Ensure List of selected sets L  1 C 040   list of all 034nal groups 2 Q 040   a temporary list of groups 3 C 1 040  4 for each set M 0 i 2 M 0 do 5 C 1 040 C 1  f M 0 i g 6 end for 7 Q 040 Q  f C 1 g 8 repeat 9 compute R for C i based on Equation 5 10 034nd T 11 if R 024 T then 12 C 040 C  f C i g 13 remove C i from Q 14 else 15 Q 040 Q  k-means\050 C i  K 051 16 end if 17 until no cluster C i 2 Q 18 L 040  19 for each cluster C i 2 C do 20 consider j M 0 j j  j M 0 j 003 j  where M 0 j 003 2 C i 000 f M 0 j g 21 L 040 L  010\000 M 0 j  ID 050 M 0 j 051  ID 050 M 0 j 003 051 001\011 22 end for 23 return L  034nd duplicated data sets by searching dissimilarities between these sets Hence a great number of distance functions have been proposed in the literature In this paper  we are interested in two distance functions that are widely used in various domains Euclidean and Cosine distances Let us consider two data sets M 0 i and M 0 j  generated by the sensor nodes S i and S j respectively at the period p as follows M 0 i D f 050 m 0 i 1  wgt 050 m 0 i 1 051\051  050 m 0 i 2  wgt 050 m 0 i 2 051\051      050 m 0 i k i  wgt 050 m 0 i k i 051\051 g and M 0 j D f 050 m 0 j 1  wgt 050 m 0 j 1 051\051  050 m 0 j 2  wgt 050 m 0 j 2 051\051      050 m 0 j k j  wgt 050 m 0 j k j 051\051 g where j M 0 i j D k i and j M 0 j j D k j  Therefore M 0 i and M 0 j are considered redundant if the calculated distance between them is less than a threshold 050 t d 051 as follows Dist 050 M 0 i  M 0 j 051 024 t d However two issues must be considered when using distance functions with measures weights 1\051 Calculating the distance between two data sets with different cardinalities e.g k i and k j  and 2\051 integrating the weights when calculating the distance between sets To face these challenges we propose to use the threshold   introduced in the Similar function 050cf Section IV\051 when computing the distance between the sets In order to 034nd the distance between two sets M 0 i and M 0 j  the 034rst step consists in dividing each set into two parts overlap and remained The overlap part of the set M 0 i 050resp M 0 j 051 contains measures that are similar to those in M 0 j 050resp M 0 i 051 VOLUME 5 2017 4255 


H Harb et al  Comparison of Different Data Aggregation Techniques in Distributed Sensor Networks  while the remained part contains the remaining measures of M 0 i 050resp M 0 j 051 Subsequently the overlap part between two sets has already been de\034ned in De\034nition 5 i.e M 0 i 134 s M 0 j  while the remained part in each set is de\034ned as follows De\034nition 6 050Remained Part of M 0 i  M 0 i r 051 Consider two sets of sensor measures M 0 i and M 0 j  We de\034ne the remained part M 0 i r 050respectively M 0 j r 051 as all the measures in M 0 i 050respectively M 0 j 051 minus the measures in the overlap part of M 0 i 050respectively M 0 j 051 as follows 8     M 0 i r D M 0 i 011 050 M 0 i 134 s M 0 j 051 and M 0 j r D M 0 j 011 050 M 0 i 134 s M 0 j 051 Where 011 is a new operation de\034ned as De\034nition 7 050Minus Operation 011 051 We de\034ne the minus operation M 0 i 011 M 0 j  between two sets M 0 i and M 0 j as all the measures in M 0 i and not in M 0 j as follows M 0 i 011 M 0 j D f m 0 i 2 M 0 i  with wgt 050 m 0 i 051 D wgt 050 m 0 i 051 000 wgt 050 m 0 j 051 for all m 0 j 2 M 0 i 134 s M 0 j and Similar 050 m 0 i  m 0 j 051 D 1 g In order to compute the distance between M 0 i and M 0 j  we must to transform M 0 i r 050respectively M 0 j r 051 into a vector as follows vM 0 i r D 002 m 0 i 1      m 0 i 1  z  wgt 050 m 0 i 1 051 times  m 0 i 2      m 0 i 2  z  wgt 050 m 0 i 2 051 times      m 0 i k i      m 0 i k i  z  wgt 050 m 0 i k i 051 times 003 Then we order the measures in vM 0 i r 050respectively vM 0 j r 051 by increasing order of their values to ensure a logical comparison when calculating the distance between them A EUCLIDEAN DISTANCE In mathematics the Euclidean distance is the ordinary distance e.g straight line distance between two points sets or objects It is used in many applications and domains such as computer vision and prevention of identity theft Further more the Euclidean distance is already used in WSN during the deployment phase in terms of sensors localization and inter-sensors distance estimations In this paper  we use the Euclidean distance on the data sets collected by sensors while adapting it to take into account the measures weights In general the Euclidian distance 050 E d 051 between two data sets M i and M j  before applying the local aggregation is given by E d 050 M i  M j 051 D v u u t  034 X k D 1 050 m i k 000 m j k 051 2 where m i k 2 M i and m j k 2 M j Thus M i and M j are said to be redundant if E d 050 M i  M j 051 024 t d  where t d is a threshold determined by the application After applying the local aggregation phase we consider that M i and M j are respectively transformed into M 0 i and M 0 j  Therefore we calculate the Euclidean distance between M 0 i and M 0 j as follows E d 050 M 0 i  M 0 j 051 D v u u u t  j vM 0 i r j X k D 1 050 m 0 i k 000 m 0 j k 051 2 where m 0 i k 2 vM 0 i r and m 0 j k 2 vM 0 j r 0507\051 Proof 2 Consider two sets of data M 0 i and M 0 j  Then E d 050 M 0 i  M 0 j 051 D q  050 M 0 i 000 M 0 j 051 2 D r  020 000 M 0 i 134 s M 0 j C vM 0 i r 001 000 000 M 0 i 134 s M 0 j C vM 0 j r 001 021 2 D r  020 000 M 0 i 134 s M 0 j 000 M 0 i 134 s M 0 j 001 C 000 vM 0 i r 000 vM 0 j r 001 021 2 D q  050 vM 0 i r 000 vM 0 j r 051 2 D r  X j vM 0 i r j k D 1 050 m 0 i k 000 m 0 j k 051 2 where m 0 i k 2 vM 0 i r and m 0 j k 2 vM 0 j r In the above proof we consider that the Euclidean distance between the measures in the overlap is equal to zero because they are redundant Therefore the Euclidean distance between two sets is equal only to distance between measures in the remained parts of M 0 i and M 0 j  i.e vM 0 i r and vM 0 j r respectively B COSINE DISTANCE Cosine distance is a measure of dissimilarity between two vectors that measures the cosine of the angle between them This kind of dissimilarity has been used widely in many aspects such as the anomaly detection in web documents and medical diagnosis Depending on the angle between the vectors the resulting dissimilarity ranges from 000 1 meaning exactly the opposite to 1 meaning exactly the same The Cosine distance 050 C d 051 between two sets M i and M j  before applying local aggregation is given by C d 050 M i  M j 051 D 1 000 P 034 k D 1 050 m i k 002 m j k 051  q  P 034 k D 1 m 2 i k 002 q  P 034 k D 1 m 2 j k where m i k 2 M i and m j k 2 M j  Thus M i and M j are redundant if C d 050 M i  M j 051 024 t d  Then we adapt the Cosine distance to the measures weights in M 0 i and M 0 j as follows C d 050 M 0 i  M 0 j 051 D 1 000 A C P j vM 0 i r j k D 1 050 m 0 i rk 002 m 0 j rk 051  r  A C P j vM 0 i r j k D 1 m 0 2 i rk 002 r  A C P j vM 0 j r j k D 1 m 0 2 j rk where A D j M 0 i 134 s M 0 j j X k D 1 000 wgt min 050 m 0 i k  m 0 j k 051 002 m 0 2 i k 001 0508\051 4256 VOLUME 5 2017 


H Harb et al  Comparison of Different Data Aggregation Techniques in Distributed Sensor Networks  Proof 3 Consider two sets of data M 0 i and M 0 j  Then C d 050 M 0 i  M 0 j 051 D 1 000 M 0 i 002 M 0 j  q  M 0 2 i 002 q  M 0 2 j D 1 000 000 M 0 i 134 s M 0 j C vM 0 i r 001 002 000 M 0 i 134 s M 0 j C vM 0 j r 001  q  050 M 0 i 134 s M 0 j 051 2 C vM 0 2 i r 002 q  050 M 0 i 134 s M 0 j 051 2 C vM 0 2 j r D 1 000 050 M 0 i 134 s M 0 j 051 2 C 050 vM 0 i r 002 vM 0 j r 051  q  050 M 0 i 134 s M 0 j 051 2 C vM 0 2 i r 002 q  050 M 0 i 134 s M 0 j 051 2 C vM 0 2 j r D 1 000 A C P j vM 0 i r j k D 1 050 m 0 i rk 002 m 0 j rk 051  r  A C P j vM 0 i r j k D 1 m 0 2 i rk 002 r  A C P j vM 0 j r j k D 1 m 0 2 j rk where A D X j M 0 i 134 s M 0 j j k D 1 000 wgt min 050 m 0 i k  m 0 j k 051 002 m 0 2 i k 001  C DISTANCE NORMALIZATION In general each distance function has its own method to calculate the distance between data sets For instance straight-line distance in Euclidean distance and the angle between data sets in Cosine distance Therefore normalization becomes essential to scale the distance between data sets into the range 0   to hav e thus the same v ariation between sets before comparing them Hence Gaussian normalization has been considered as a better approach to normalize data sets Consequently  in this paper  data sets sent by the sensor nodes to the CH are normalized using Gaussian normalization Once the CH receives the data sets at each period it calculates 034rst the distance Euclidean or Cosine for each pair of sets as follows d D f d 1 050 M 0 1  M 0 2 051  d 2 050 M 0 1  M 0 3 051      d n 002 050 n 000 1\051  2 050 M 0 n 000 1  M 0 n 051 g where n is the number of total sets and n 002 050 n 000 1\051  2 is the number of all possible distances Then it normalizes the returned distance values using the following Gaussian normalization equation d 0 i D d i 000  Y  6 002 033 C 1  2 0509\051 where  Y is the mean of all distances and 033 is the standard deviation of pairwise distance over all data  Y and 033 are calculated as follows  Y D P j d j k D 1 d k  j d j and 033 D s  P j d j k D 1 050 d i 000  Y 051 2  j d j  where j d j D n 002 050 n 000 1\051  2 After normalizing all pairwise distances the CH will form the distance normalization vector between each pair of sets as follows d 0 D f d 0 1 050 M 0 1  M 0 2 051  d 0 2 050 M 0 1  M 0 3 051      d 0 n 002 050 n 000 1\051  2 050 M 0 n 000 1  M 0 n 051 g  D DISTANCE-BASED ALGORITHM AT THE CH In this section we present our data aggregation method at the CH based on the distance functions Algorithm 3 describes how the CH 034nds redundant sets of measures generated by sensors then how it selects among them data sets to be sent to the sink After normalizing data sets based on Equation 9 050lines 2 to 11\051 the CH considers that two sets are redundant if the normalized distance between them is less than the threshold t d 050line 12 and 13\051 Dist function in line 5 represents Euclidean or Cosine distances and can be calculated based on Equations 7 and 8 respectively Then for each pair of redundant set the CH chooses the one having the highest cardinality 050line 18\051 then it adds it to the list of sets to be sent to the sink 050line 19\051 After that it removes all pairs of redundant sets that contain M 0 i or M 0 j from the set of pairs 050which means it will not check them again\051 Finally the CH assigns to each set its weight 050line 21\051 when sending it to the sink  Algorithm 3 Distance-Based Redundancy Searching Algorithm  Require Set of measures sets M 0 D f M 0 1  M 0 2  M 0 n g  t d  Ensure List of sent sets L  1 S 040  2 d 040   list of pairwise distance 3 for each set M 0 i 2 M 0 do 4 for each set M 0 j 2 M 0 such that j  i do 5 compute Dist 050 M 0 i  M 0 j 051 6 d 040 d  f Dist 050 M 0 i  M 0 j 051 g 7 end for 8 end for 9 compute  Y and 033 for d 10 for each d i 2 d do 11 d 0 i D 050\050 d i 000  Y 051  0506 002 033 051\051 C 0  5 12 if d 0 i 024 t d then 13 S 040 S  f 050 M 0 i  M 0 j 051 g 14 end if 15 end for 16 L 040  17 for each pair of sets 050 M 0 i  M 0 j 051 2 S do 18 Consider j M 0 i j 025 j M 0 j j 19 L 040 L  f M 0 i g 20 Remove all pairs of sets containing one of the two sets M 0 i and M 0 j 21 wgt 050 M 0 i 051  number of removed pairs  1 22 end for 23 return L  VIII EXPERIMENTAL RESULTS AND EVALUATION To validate our proposed data aggregation techniques we developed a Java based simulator that is run on the data collected from 46 sensors deployed in the Intel Berkeley VOLUME 5 2017 4257 


H Harb et al  Comparison of Different Data Aggregation Techniques in Distributed Sensor Networks  Research Lab 2 Mica2Dot sensors with weather boards collect timestamped topology information along with humidity temperature light and voltage values once every 31 seconds The objective of these experiments is to con\034rm that the proposed data agregation methods can successfully achieve desirable results for energy conservation data latency and data accuracy in different monitoring applications Data were collected using TinyDB in-network query processing system built on the TinyOS platform In our experiments we used a 034le that includes a log of about 2  3 million readings collected from these sensors For the sake of simplicity in this paper we are interested in one 034eld of sensor measurements the temperature 3 We assume that all nodes send their data to a common CH placed at the center of the Lab First each node periodically reads real measures while applying the local aggregation At the end of this step each node sends its set of measures with weights to the CH which in its turn aggregates them using the three proposed methods in our technique We evaluated the performance using the following parameters 050a\051 1\051  the threshold   de\034ned in Similar function takes the following values 0  03 0  05 0  07 0  1 2\051 034  the number of sensor measurements taken by each sensor node during a period takes the following values 200 500 and 1000 3\051  the distance threshold t d takes the following values 0  35 0  4 0  45 and 0  5 4\051  the threshold t J of the Jaccard similarity function is 034xed to 0  75 5\051 013  the false-rejection probability in the Anova model is 034xed to 0  01 A DATA AGGREGATION RATIO AT THE SENSOR's LEVEL During the local aggregation each sensor node searches the similarity between measures captured at each period and assigns for each measure its weight Therefore the result of the aggregation in this phase depends on the chosen threshold   the number of the collected measures in period 034 and the changes in the monitored condition Fig 4 shows the percentage of remaining data or aggregated data which will be sent to the CH with and without applying the local aggregation phase at the sensors level At each period the amount of data collected by each sensor is reduced at least by 77 050and up to 94%\051 after applying the aggregation phase Otherwise the sensor node sends all the collected data e.g 100 without applying the aggregation phase Therefore our technique can successfully eliminate redundant measures at each period and reduce the amount of data sent to the CH We can also observe that with the local aggregation phase data redundancy among data increases when 034 or  increases 2 Our techniques has been also applied on real data collected from the ARGO project The obtained results were similar to those presented in this paper which indicate the ef\034ciency of our techniques in underwater sensor applications However the results are not presented in order to not increase the number of pages of this paper 3 the others are done by the same manner FIGURE 4 Percentage of data after applying local aggregation This is because the Similar function will 034nd more similar measures to be eliminated in each period B DATA SETS REDUNDANCY When receiving all the sets from its member nodes at the end of each period CH applies the second aggregation level in order to 034nd all pairs of redundant sets Fig 5 shows the number of pairs of redundant sets obtained at each period when applying Euclidean and Cosine distances KAB and PFF techniques respectively First we 034xed 034 and  and we varied t d as shown in Fig 5\050a\051 then we 034xed 034 and t d and varied  as shown in Fig 5\050b\051 and 034nally we 034xed  and t d and varied 034 as shown in Fig 5\050c\051 The obtained results show that the CH 034nds more redundant sets when applying the distance functions i.e Euclidean and Cosine compared to the Jaccard function used in PFF technique for different values of parameters This is because the distance condition 050Equations 7 and 8\051 is more 035exible compared to the similarity condition 050Equation 1\051 used in PFF On the other hand the Anova model gives the least important number of redundant sets because it searches redundant data sets in groups instead of pairs in distances and similarity methods FIGURE 5 Number of pairs of redundant sets at each period 050a\051 034 D 500  D 0  07 050b\051 034 D 500 t d D 0  4 050c\051  D 0  07 t d D 0  4 4258 VOLUME 5 2017 


H Harb et al  Comparison of Different Data Aggregation Techniques in Distributed Sensor Networks  Several observations can be made based on the obtained results in Fig 5 017 The Euclidean distance 034nds more redundant sets compared to Cosine distance in all cases This is due to the Euclidean distance equation which is more 035exible compared with that used in Cosine distance 017 The number of pairs of redundant sets in Euclidean and Cosine distances increases when t d increases 050Fig 5\050a\051\051 This is because we allow more measures to be lost when t d increases thus we allow more sets to be redundant 017 The number of redundant sets obtained in both distances and KAB technique is almost 034x when 034xing 034 and t d and increasing   while it increases in PFF 050Fig 5\050b\051\051 This is because the data sets save the same distance 050resp variance\051 condition when changing   Otherwise the results of PFF proportionally change to  since they are strongly dependent on the Similar function FIGURE 6 Percentage of sets sent to the sink at each period 050a\051 034 D 500  D 0  07 050b\051 034 D 500 t d D 0  4 050c\051  D 0  07 t d D 0  4 C DATA SETS REDUCTION In this section we show how the CH is able to eliminate redundant sets at each period before sending them to the sink Fig 6 shows the percentage of the remaining sets that will be sent to the sink after eliminating the redundancy Similarly to Fig 5 we varied t d and we 034xed 034 and  in Fig 6\050a\051 then we varied  and 034xed 034 and t d in Fig 6\050b\051 and 034nally we varied 034 and 034xed  and t d in Fig 6\050c\051 Generally the obtained results are dependent on the number of the redundant sets shown in Fig 5 if more redundant sets are found this will lead to more sets being eliminated Therefore Euclidean and Cosine distances allow the CH to eliminate more redundant sets except when t d is small 050e.g t d D 0  35 in Fig 6\050a\051\051 at each period compared to PFF and KAB techniques The results obtained in Fig 5 allow us to conclude some observations shown in Fig 6 017 The percentage of sets sent to the sink using Euclidean distance is inferior to that sent using Cosine distance for different values of parameters This is because the CH 034nds more redundant sets by using Euclidean distance 050see results in Fig 5\051 017 The distance functions allow the CH to send 15 to 61 less of sets to the sink compared to PFF due to the 035exibility of distances regarding the redundancy compared to similarity functions Similarly KAB gives better results 05036 to 49 less of sent sets\051 compared to PFF in all the cases This is because KAB searches redundant sets in groups then sends one set of each group to the sink while PFF searches them by pairs 017 The percentage of sets sent to the sink in Euclidean and Cosine distances decreases when t d increases 050Fig 6\050a\051\051 while it is almost 034x when  or 034 increases 050Fig 6\050b\051 and 6\050c\051\051 017 PFF sends less percentage of sets to the sink when  increases while it is almost 034x when using KAB technique 050Fig 6\050b\051\051 This is because the variance condition in Anova is independent from  while the Jaccard function in PFF is dependent FIGURE 7 Energy consumption in each sensor node 050a\051 034 D 200 050b\051 034 D 500 050c\051 034 D 1000 D ENERGY CONSUMPTION STUDY In this section our objective is to study the energy consumption at the sensor nodes and CH levels In sensor networks energy consumption is highly dependent on the amount of data sent and received First Fig 7 shows the energy consumption comparison with and without applying the local aggregation phase by each sensor node and when varying 034 and   Since the local aggregation signi\034cantly reduces the redundancy among data collected by the sensor node 050see results in Fig 4\051 it allows it to proportionally save its energy when transmitting its data to the CH at each period This result is obvious in Fig 7 when the sensor node applies the local aggregation phase and when  or 034 increases It is important to notice that our technique can save from 76 050Fig 7\050a\051\051 up to 94 050Fig 7\050c\051\051 of the energy of a sensor node VOLUME 5 2017 4259 


H Harb et al  Comparison of Different Data Aggregation Techniques in Distributed Sensor Networks  FIGURE 8 Energy consumption at the CH 050a\051 034 D 500  D 0  07 050b\051 034 D 500 t d D 0  4 050c\051  D 0  07 t d D 0  4 Fig 8 shows the energy consumption comparison at the CH when using distances method KAB and PFF techniques in function of t d in Fig 8\050a\051 of  in Fig 8\050b\051 and of 034 in Fig 8\050c\051 Depending on the results obtained in Fig 6 the distances method gives the best results except for t d D 0  35 in Cosine regarding the energy consumption in the CH Subsequently Euclidean distance can reduce the energy consumed in CH up to 39 and up to 64 compared to the amount of energy consumed using KAB and PFF respectively Otherwise Cosine distance can reduce up to 33 and 60 of the energy consumption in the CH compared to that consumed using KAB and PFF respectively On the other hand energy consumption in the CH is reduced using KAB technique from 32 to 54 compared to that consumed using PFF Since the energy consumption is minimized when the percentage of sets sent is minimized several observations shown in Fig 8 can be concluded 017 Euclidean distance decreases the energy consumption in the CH from 9 to 40 compared to the Cosine distance This is because the Euclidean distance sends less sets to the sink compared to the Cosine distance 017 Using Euclidean and Cosine distances the CH conserves more energy when t d increases 050Fig 8\050a\051\051 017 The energy consumption in the CH using distances and variance methods is almost independent from  threshold 050Fig 8\050b\051\051 Otherwise PFF reduces the energy consumption in the CH when  increases 050Fig 8\050b\051\051 E DATA LATENCY EXECUTION TIME In this section we compare the execution time required for the three data aggregation methods used in our technique when varying t d   and 034 respectively 050Fig 9\051 The execution time is dependent on the normalization process of data sets in distances method on the number of iterative loops in k-means algorithm used in KAB technique and on the number of FIGURE 9 Execution time at the CH 050a\051 034 D 500  D 0  07 050b\051 034 D 500 t d D 0  4 050c\051  D 0  07 t d D 0  4 candidates generated in PFF The obtained results show that KAB signi\034cantly outperforms the other methods function in terms of computation in all cases This is because searching the groups of redundant sets in KAB requires less computation time compared to the computation time required for comparison by pairs used in distances and similarity methods Consequently KAB can accelerate the execution time at the CH from 23 to 57 times compared to distances and from 14 to 26 compared to PFF On the other hand PFF can accelerate the execution time at the CH twice faster than distances method the reason for that is the normalization used in Euclidean and Cosine distances which needs to calculate all distances between pairs of sets while PFF only searches the similarity between the generated candidate pairs Several observations can be made based on the results shown in Fig 9 017 The Euclidean distance decreases the execution time at the CH more than the Cosine distance This is due to the complexity of the calculation of Cosine distance 050Equation 8\051 compared to Euclidean distance 050Equation 7\051 017 The execution time required for both distances is almost 034x when varying t d 050Fig 9\050a\051\051 This is because both distances must normalize all data sets independently from t d value 017 The data latency at the CH is optimized when  increases in all methods 050Fig 9\050b\051\051 This is because the cardinality of a data set decreases when  increases thus the computation between sets decreases as well 017 The CH requires with the three aggregation methods more execution time when 034 increases 050Fig 9\050c\051\051 This is because the cardinality of sets increases which require more time to be compared F DATA ACCURACY INTEGRITY OF INFORMATION Data accuracy is an important factor in WSNs which represents the measure loss rate In our simulation data accuracy 4260 VOLUME 5 2017 


H Harb et al  Comparison of Different Data Aggregation Techniques in Distributed Sensor Networks  FIGURE 10 Data accuracy 050a\051 034 D 500  D 0  07 050b\051 034 D 500 t d D 0  4 050c\051  D 0  07 t d D 0  4 has been evaluated based on the percentage of loss measures at the CH in other words we divided the number of measures taken by the sensor nodes whose values 050or similar values\051 do not reach the sink after applying each aggregation method over the whole measures collected by the sensors at each period Fig 10 shows the results of data accuracy for the data aggregation functions used in our technique for different values of t d   and 034  We can notice that PFF gives the best results for data accuracy 2  81 in the worst case compared to the Euclidean 050up to 12  52%\051 and Cosine 050up to 21  75%\051 distances and KAB technique 050up to 33  8%\051 The reason for this is that the Jaccard function used in PFF is a strong constraint regarding the loss measures compared to distance and variance constraints which are more 035exible We can also notice that Euclidean and Cosine distances conserve the integrity of the information more than the KAB technique Indeed KAB sends one set among a group of sets to the sink which increases the loss of measures It is important to know that with KAB technique the objective is to send the minimum amount of data to the sink which allows decision makers to take the correct decision based on the received information The following observations can be made based on the results obtained in Fig 10 017 The Euclidean distance conserves the integrity of data more than Cosine distance in all cases This is due to the equation of Cosine distance which eliminates the sets that have high cardinality 017 The loss of measures using Euclidean and Cosine distances increases when t d increases 050Fig 10\050a\051\051 This is because the CH eliminates more sets when t d increases 050see results in Fig 6\051 017 The data accuracy in distances and KAB techniques increases when  increases 050Fig 10\050b\051\051 or 034 decreases 050Fig 10\050c\051\051 On the other hand using PFF the data accuracy decreases when  or 034 increases G FURTHER DISCUSSIONS In this section we give further consideration to our proposed techniques We compare the obtained results while applying the three proposed methods We give some directions as to which method should be chosen under which conditions and in which circumstances of the application From the energy preserving point of view at the CHs the three proposed methods signi\034cantly reduce the energy consumption in the CHs 050Figs 8\051 In addition we observe that the distance method conserves more energy compared to the variance and the similarity methods Subsequently it reduces up to 39 and 64 of the energy in CH compared to KAB and PFF respectively Therefore in the applications where we need to conserve the energy of the network as long as possible the distance method is more suitable From the data latency point of view at the CHs we deduce that the variance method gives the best result in terms of minimizing the data latency compared to distance and similarity methods Subsequently KAB can accelerate the execution time at the CH up to 57 and 26 times compared to the best results obtained using distances and PFF These results are logical because searching the groups of redundant sets using KAB has a weak complexity compared to search them in pairs using distances methods or in candidates using PFF Consequently when the priority for the application is to deliver data to the sink the variance method is more suitable From the data accuracy point of view at the CHs the similarity method can totally save the integrity of the collected data without any loss of information e.g up to 2  81 On the other hand the distance method gives better results in terms of data accuracy compared to the variance method Hence if the application does not permit 035exibility regarding data accuracy the similarity functions method is more suitable else distance and variance methods can be used as a compromise between energy saving and data accuracy 035exibility To summarize this section Table 1 shows the 035exibility of each method regarding energy consumption data latency and accuracy and complexity of the method at the CHs TABLE 1 Comparison between distance variance and similarity methods As an analytical study each sensor node S i will form a set M i of 034 measures in each period Due to Similar function the size of this set will be reduced from 034 to j M i j  Therefore our proposed technique has at most O 050 j M i j 2 051 as a computation complexity at the sensor and it will save at most 0502 002 j M i j 051 measures at each period in its memory These complexities are suitable for the case of sensor node since collected measures are usually redundant thus makes j M i j small even in the worst case This fact is showed clearly in Fig 4 VOLUME 5 2017 4261 


H Harb et al  Comparison of Different Data Aggregation Techniques in Distributed Sensor Networks  where the data collected by each sensor in each period is signi\034cantly reduced On the other hand the complexity of our technique at the CH level is dependent on which data aggregation method the CH uses 050see Table 1\051 Since the CH must enumerate and compare every pair of set the complexity of the distance functions is in order of O 050 n 2 051 where n is the number of all received sets Otherwise the complexity of KAB method is at most in order O 050 n 051 thanks to k-means algorithm which only compare the sets in the same cluster Finally the complexity of PFF is dependent on the complexity of the pre\034x 034ltering calculated in which it is at most in order of O 050 n 002 log 050 n 051\051 since the comparison is reduced to the candidates pairs only Finally the message complexity in our technique is highly dependent on the number of data collected in a period e.g 034  which is 034xed by the application in the case where a large 034 is needed different solutions could be applied like packet division etc On the other hand the storage complexity depends on the memory size of the sensor in addition to the period 034  which can be treated similarly to the message complexity Thus the storage complexity is dependent on the sensor nodes capabilities and memories and then data collection frequency can be de\034ned in function of that storage capacity IX CONCLUSIONS AND FUTURE WORK Data aggregation is very essential for WSNs where the huge amounts of data collected by the sensors need to be minimized In this paper we proposed a data aggregation technique for clustering-based periodic sensor networks After eliminating redundant data collected by each sensor we propose three different data aggregation methods allowing CH to eliminate redundant data sets generated by neighboring sensor nodes The proposed methods are based respectively on the sets similarity functions the one-way Anova model with statistical tests and the distance functions We have demonstrated through experiments on real data measures the ef\034ciency of our proposed technique in sensor networks in terms of energy consumption data latency and accuracy In our future work we plan to schedule the sensor nodes in the network in a manner that nodes generating redundant data will not be active at the same time Thus sensor nodes will conserve more energy and network lifetime will be extended REFERENCES   D Baum and C I Matters 0502013\051 Big Data Big Opportunity   A v ailable http://www oracle.com/us/c-central/cio-solutions informationmatters/big-data-big-opportunity/index.html   S Cheng Z Cai J Li and X Fang Drawing dominant dataset from big sensory data in wireless sensor networks in Proc IEEE Conf Comput Commun 050INFOCOM\051  Apr./May 2015 pp 531\025539   T Zhu S Cheng Z Cai and J Li Critical data points retrieving method for big sensory data in wireless sensor networks EURASIP J Wireless Commun Netw  vol 2016 no 1 pp 1\02514 2016   S Cheng and J Li Sampling based 050epsilon delta\051-approximate aggregation algorithm in sensor networks in Proc 29th IEEE Int Conf Distrib Comput Syst 050ICDCS\051  Jun 2009 pp 273\025280   J Li S Cheng Y Li and Z Cai Approximate holistic aggregation in wireless sensor networks in Proc 35th IEEE Int Conf Distrib Comput Syst 050ICDCS\051  Jun./Jul 2015 pp 740\025741   X Kui J Wang S Zhang and J Cao Energy balanced clustering data collection based on dominating set in wireless sensor networks Adhoc Sensor Wireless Netw J  vol 24 nos 3\0254 pp 199\025217 2015   C.-M Chao and T.-Y Hsiao Design of structure-free and energybalanced data aggregation in wireless sensor networks J Netw Comput Appl  vol 17 pp 229\025239 Jan 2014   A Norouzi F S Babamir and Z Orman A tree based data aggregation scheme for wireless sensor networks using GA Wireless Sensor Netw  vol 4 no 8 2012 Art no 21969   Y Lu I S Comsa P Kuonen and B Hirsbrunner Dynamic data aggregation protocol based on multiple objective tree in wireless sensor networks in Proc IEEE 10th Int Conf Intell Sensors Sensor Netw Inf Process 050ISSNIP\051  Apr 2015 pp 1\0257   Y.-K Chiang N.-C Wang and C.-H Hsieh A cycle-based data aggregation scheme for grid-based wireless sensor networks Sensors  vol 14 no 5 pp 8447\0258464 2014   C Wang L Xing V M Vokkarane and Y Sun Reliability of wireless sensor networks with tree topology Int J Performability Eng  vol 8 no 2 pp 213\025216 2012   K R Bhakare R K Krishna and S Bhakare An energy-ef\034cient grid based clustering topology for a wireless sensor network Int J Comput Appl  vol 39 no 14 pp 24\02528 2012   H A Marhoon M Mahmuddin and S A Nor Chain-based routing protocols in wireless sensor networks A survey ARPN J Eng Appl Sci  vol 10 no 3 pp 1389\0251398 2015   P Zou and Y Liu A data-aggregation scheme for WSN based on optimal weight allocation J Netw  vol 9 no 1 pp 100\025107 2014   M Shanmukhi and O B V Ramanaiah Cluster-based comb-needle model for energy-ef\034cient data aggregation in wireless sensor networks in Proc Appl Innov Mobile Comput  2015 pp 42\02547   T Du Z Qu Q Guo and S Qu A high ef\034cient and real time data aggregation scheme for WSNs Int J Distrib Sensor Netw  vol 2015 pp 1\02511 2015   H Harb A Makhoul M Medlej and R Couturier ATP An aggregation and transmission protocol for conserving energy in periodic sensor networks in Proc 24th IEEE Int Conf Enabling Technol Infrastruct Collaborative Enterprises 050Wetice\051  Jun 2015 pp 134\025139   N Javaid M R Jafri Z A Khan N Alrajeh M Imran and A Vasilakos Chain-based communication in cylindrical underwater wireless sensor networks Sensors  vol 15 no 2 pp 3625\0253649 2015   C.-M Chao and T.-Y Hsiao Design of structure-free and energybalanced data aggregation in wireless sensor networks J Netw Comput Appl  vol 37 pp 229\025239 Jan 2014   J Luo and J Cai A dynamic virtual force-based data aggregation algorithm for wireless sensor networks Int J Distrib Sensor Netw  vol 11 no 5 pp 814184-1\025814184-7 2015   M K Al-Azzawi J Luo and R Li Virtual cluster model in clustered wireless sensor network using cuckoo inspired metaheuristic algorithm Int J Hybrid Inf Technol  vol 8 no 4 pp 133\025146 2015   J M Bahi A Makhoul and M Medlej An optimized in-network aggregation scheme for data collection in periodic sensor networks in Proc 11th Int Conf Ad-Hoc Mobile Wireless Netw 050ADHOC-NOW\051  Belgrade Serbia Jul 2012 pp 153\025166   H Natarajan and S Selvaraj A fuzzy based predictive cluster head selection scheme for wireless sensor networks in Proc 8th Int Conf Sens Technol  2014 pp 560\025567   D Kumar Performance analysis of energy ef\034cient clustering protocols for maximising lifetime of wireless sensor networks IET Wireless Sensor Syst  vol 4 no 1 pp 9\02516 Mar 2014   A Anbarasan S Sivasubramaniam and M Mohanasundhram A minimum cost effective cluster algorithm using UWSN Int J Innov Res Sci Eng Technol  vol 3 no 7 p 14656\02514661 2014   K Ovaliadis and N Savage Cluster protocols in underwater sensor networks A research review J Eng Sci Technol Rev  vol 7 no 3 pp 171\025175 2014   M Ayaz A Abdullah I Faye and Y Batira An ef\034cient dynamic addressing based routing protocol for underwater wireless sensor networks Comput Commun  vol 35 no 4 pp 475\025486 2012   L Zhao and Q Liang Optimum cluster size for underwater acoustic sensor networks in Proc IEEE Conf Military Commun 050MILCOM\051  Oct 2006 pp 1\0255 4262 VOLUME 5 2017 


H Harb et al  Comparison of Different Data Aggregation Techniques in Distributed Sensor Networks    N Amini A Vahdatpour W Xu M Gerla and M Sarrafzadeh Cluster size optimization in sensor networks with decentralized clusterbased protocols Comput Commun  vol 35 no 2 pp 207\025220 2012   G Yang M Xiao E Cheng and J Zhang A cluster-head selection scheme for underwater acoustic sensor networks in Proc Int Conf Commun Mobile Comput 050CMC\051  2010 pp 188\025191   H.-S Kim J.-S Han and Y.-H Lee Scalable network joining mechanism in wireless sensor networks in Proc IEEE Topical Conf Wireless Sensors Sensor Netw 050WiSNet\051  Jan 2012 pp 45\02548   S Madden 0502004\051 Intel Berkeley Research Lab  A v ailable http://db.csail.mit.edu/labdata/labdata.html   J M Bahi A Makhoul and M Medlej A two tiers data aggregation scheme for periodic sensor networks Adhoc Sensor Wireless Netw  vol 21 nos 1\0252 pp 77\025100 2014   A Arasu V Ganti and R Kaushik Ef\034cient exact set-similarity joins in Proc 32nd Int Conf Very Large Data Bases 050VLDB\051  2006 pp 918\025929   H Harb A Makhoul R Tawil and A Jaber A suf\034x-based enhanced technique for data aggregation in periodic sensor networks in Proc 10th IEEE Int Wireless Commun Mobile Comput Conf 050IWCMC\051  Aug 2014 pp 494\025499   H Harb A Makhoul D Laiymani A Jaber and R Tawil K-means based clustering approach for data aggregation in periodic sensor networks in Proc 10th IEEE Int Conf Wireless Mobile Comput Netw Commun 050WiMob\051  Oct 2014 pp 434\025441   H Harb A Makhoul and R Couturier An enhanced K-means and ANOVA-based clustering approach for similarity aggregation in underwater wireless sensor networks IEEE Sensors J  vol 15 no 10 pp 5483\0255493 Oct 2015   H Harb A Makhoul D Laiymani A Jaber and O Bazzi An analysis of variance-based methods for data aggregation in periodic sensor networks in Transactions on Large-Scale Dataand Knowledge-Centered Systems XXII  vol 22 New York NY USA Springer 2015 pp 165\025183   M M Deza and E Deza Encyclopedia of Distances  New York NY USA Springer 2009 pp 1\025583   A A Oommen C S Singh and M Manikandan Design of face recognition system using principal component analysis Int J Res Eng Technol  vol 3 no 1 pp 6\02510 2014   A Y Alfakih M F Anjos V Piccialli and H Wolkowicz Euclidean distance matrices semide\034nite programming and sensor network localization Portugaliae Mathematica  vol 68 no 1 pp 53\025102 2011   S Vural and E Ekici On multihop distances in wireless sensor networks with random node locations IEEE Trans Mobile Comput  vol 9 no 4 pp 540\025552 Apr 2010   M Friedman M Last Y Makover and A Kandel Anomaly detection in Web documents using crisp and fuzzy-based cosine clustering methodology Inf Sci  vol 177 no 2 pp 467\025475 2007   J Ye Cosine similarity measures for intuitionistic fuzzy sets and their applications Math Comput Model  vol 53 nos 1\0252 pp 91\02597 2011   Q Gang S Sural Y Gu and S Pramanik Similarity between euclidean and cosine angle distance for nearest neighbor queries in Proc ACM Symp Appl Comput  2004 pp 1232\0251237   Argo 0502000\051 Online Data  A v ailable http://www ar go.ucsd edu/index.html   J Wang G Li and J Feng Can we beat the pre\034x 034ltering An adaptive framework for similarity join and search in Proc ACM SIGMOD Int Conf Manage Data 050SIGMOD\051  2012 pp 85\02596 HASSAN HARB received the master's degree in computer science and risks management from Lebanese University in 2013 and the Ph.D degree in computer science from Lebanese University and the University of Franche-Comt\351 France in 2016 He is currently a member at the Femto-St Laboratory France and also an Instructor with the American University of Culture and Education Lebanon His research interests are in wireless sensor networks emphasizing both practical and theoretical issues data mining and analyzing ABDALLAH MAKHOUL received the M.S degree in computer science from INSA Lyon Lyon France in 2005 and the Ph.D degree in the problems of localization coverage and data fusion in wireless sensor networks from the University of Franche-Comt\351 Belfort France in 2008 Since 2009 he has been an Associate Professor with the University of Franche-Comt\351 His research interests include Internet of Things structural health monitoring and real-time issues in wireless sensor networks Dr Makhoul has been a TPC Member of several networking conferences and a Reviewer for several international journals SAMAR TAWBI received the Ma\356trise degree 050Hons.\051 in computer sciences from Lebanese University in 1997 the M.S degree in mathematical modelisation and scienti\034cal software engineering from Lebanese University the University of Rennes Reims France and EPFL Switzerland in 1998 and the Ph.D degree in software engineering from Paul Sabatier France in 2004 She is involved in data aggregation in wireless sensors networks She is currently an Associate Professor with Lebanese University Her research interest includes web services cloud computing wireless sensors networks and Internet of Things RAPHA\313L COUTURIER received the Ph.D degree in computer science from Henri Poincare University Nancy France in 2000 From 2000 to 2006 he was an Assistant Professor with the University of Franche-Comte where he has been a Professor He has authored or co-authored over 140 papers in conferences and journals and two books His research interests include parallel and distributed algorithms with a strong knowledge on asynchronous iterative methods GPU computing data mining and sensor networks He has also served in many program committees for conferences VOLUME 5 2017 4263 


MA et al  UNRAVELING THE RANK-ONE SOLUTION MYSTERY OF ROBUST MISO DOWNLINK TRANSMIT OPTIMIZATION 1923 It can be veried that 1 005 1  003 2 N    K  1 003 2 N  0 and 1  006 K\003  0  Also the condition in 60 can be rewritten as 005 1 K  1 4 N 2 K  C   62 where C  NK  2 N 006 K  1  note that C 0 for N 004 K 004 5  Now by choosing 005  1 K  1 4 N 2 K  016   63 for any 0 016<C  we see that 62 is satised Hence we have identied instances of  N K 005 003  for which v 006 d 006  We should also verify that the instances constructed above satisfy v 006  007  In Step 1 we showed that Problem 2 has an optimal solution or v 006  007  if 48 holds For the choice of 003 in 61 it can be veried that 48 becomes 005 1 K  1 4 N 2 K As seen the above condition is satised by the choice of 005 in 63 The proof is complete R EFERENCES  M  B engtsson a nd B Ottersten  Optimal and s uboptimal transmit beamforming in Handbook of Antennas in Wireless Communications L.C Godara Ed Boca Raton FL USA CRC Press Aug 2001 ch 18  Q  H  S pencer A  L  Swindlehurst a nd M Haardt  Zero-forcing m ethods for downlink spatial multiplexing in multiuser MIMO channels IEEE Trans Signal Process  vol 52 no 2 pp 461471 Feb 2004  C  B  P eel B M Hochw ald a nd A L Swindlehurst  A vector-perturbation technique for near-capacity multiantenna multiuser communicationPart I Channel inversion and regularization IEEE Trans Commun  vol 53 no 1 pp 195202 Jan 2005  D  G esbert M  K ountouris R  W  H eath J r   C B Chae and T  S  alzer Shifting the MIMO paradigm IEEE Signal Process Mag  vol 24 no 5 pp 3646 Sep 2007  A  B  G ershman N D Sidiropoulos S  S hahbazpanahi M Bengtsson and B Ottersten Convex optimization-based beamforming IEEE Signal Process Mag  vol 27 no 3 pp 6275 May 2010  E  B j  ornson M Bengtsson and B Ottersten Optimal multiuser transmit beamforming A difcult problem with a simple solution structure IEEE Signal Process Mag  vol 31 no 4 pp 142148 Jul 2014  H  B aligh et al  Cross-layer provision of future cellular networks A WMMSE-based approach IEEE Signal Process Mag  vol 31 no 6 pp 5668 Nov 2014  D  J  L o v e  R  W  H eath J r   V  K  L au D  G esbert B  D  R ao a nd M Andrews An overview of limited feedback in wireless communication systems IEEE J Sel Areas Commun  vol 26 no 8 pp 13411365 Oct 2008  M  B  S henouda and T  N  D a v idson Con v e x c onic formulations of rob u st downlink precoder designs with quality of service constraints IEEE J Sel Topics Signal Process  vol 1 no 4 pp 714724 Dec 2007  G Zheng K.-K W ong and T S Ng  Rob u st linear MIMO in the d o w nlink A worst-case optimization with ellipsoidal uncertainty regions EURASIP J Adv Signal Process  vol 2008 pp 115 Jun 2008  G Zheng K.-K W ong and B  O ttersten  Rob u st cogniti v e beamforming with bounded channel uncertainties IEEE Trans Signal Process  vol 57 no 12 pp 48714881 Dec 2009  N V u  ci  c and H Boche Robust QoS-constrained optimization of downlink multiuser MISO systems IEEE Trans Signal Process  vol 57 no 2 pp 714725 Feb 2009  A T ajer N  P rasad and X  W ang Rob ust linear precoder d esign f or multi-cell downlink transmission IEEE Trans Signal Process  vol 59 no 1 pp 235251 Jan 2011  Y  Huang D P  P alomar  and S  Z hang Lorentz-positi v e maps and quadratic matrix inequalities with applications to robust MISO transmit beamforming IEEE Trans Signal Process  vol 61 no 5 pp 11211130 Mar 2013  M Raza viyayn M Sanjabi and Z.-Q Luo A stochastic successi v e minimization method for nonsmooth nonconvex optimization with applications to transceiver design in wireless communication networks Math Programm  vol 157 no 2 pp 515545 2016  Y  Y a ng G Scutari D P  P alomar  and M  P esa v ento  A p arallel decomposition method for nonconvex stochastic multi-agent optimization problems IEEE Trans Signal Process  vol 64 no 11 pp 29492964 Jun 2016  M B Shenouda and T  N  D a v idson Probabilistically-constrained approaches to the design of the multiple antenna downlink in Proc 42nd Asilomar Conf  Pacic Grove Oct 2629 2008 pp 11201124  M B Shenouda T  N  D a v idson and L  L ampe  Outage-based d esign o f robust TomlinsonHarashima transceivers for the MISO downlink with QoS requirements Signal Process  vol 93 no 12 pp 33413352 Dec 2013  F  Sohrabi a nd T  N Da vidson Coordinate update algorithms for rob ust power loading for the MU-MISO downlink with outage constraints IEEE Trans Signal Process  vol 64 no 11 pp 27612773 Jun 2016  K.-Y  W a ng A M.-C S o T  H C hang W  K M a and C Y  Chi Outage constrained robust transmit optimization for multiuser MISO downlinks Tractable approximations by conic optimization IEEE Trans Signal Process  vol 62 no 21 pp 56905705 Sep 2014  Q Li A  M C So a nd W  K M a Distrib utionally rob u st chanceconstrained transmit beamforming for multiuser MISO downlink in Proc IEEE Int Conf Acoust Speech Signal Process  May 2014 pp 34793483  X He and Y C W u   T i ght probabilistic SINR constrained beamforming under channel uncertainties IEEE Trans Signal Process  vol 63 no 13 pp 34903505 Jul 2015  C Shen T H Chang K.-Y  W a ng Z Qiu and C Y  Chi Distrib uted robust multicell coordinated beamforming with imperfect CSI An ADMM approach IEEE Trans Signal Process  vol 60 no 6 pp 29883003 Jun 2012  E V i sotsk y and U  M adho w  Space-time t ransmit p recoding with imper fect feedback IEEE Trans Inf Theory  vol 47 no 6 pp 26322639 Sep 2001  I P  olik and T Terlaky A survey of the S-lemma SIAM Rev  vol 49 no 3 pp 371418 2007  A M.-C S o Y  Y e  a nd J Zhang A unied t heorem on SDP rank reduction Math Oper Res  vol 33 no 4 pp 910920 2008  A M.-C S o a nd Y  Y e   Probabilistic analysis o f s emidenite relaxation detectors for multipleinput multipleoutput systems in Proc Convex Optim Signal Process Commun D.P.PalomarandY.C.Eldar,Eds New York NY USA Cambridge Univ Press 2010 pp 166191  G Sagnol  A class o f s emidenite programs w ith rankone solutions  Linear Algebra Appl  vol 435 no 6 pp 14461463 2011  M E.-Nagy M Laurent and A  V arvitsiotis  F o rbidden m inor char acterizations for low-rank optimal solutions to semidenite programs over the elliptope J Comb Theory Series B  vol 108 pp 4080 2014  Y  Huang a nd D P  P alomar Rank-constrained separable s emidenite programming with applications to optimal beamforming IEEE Trans Signal Process  vol 58 no 2 pp 664678 Feb 2010  E Song Q Shi M Sanjabi R Sun and Z Q Luo Rob ust S INRconstrained MISO downlink beamforming When is semidenite programming relaxation tight EURASIP J Wireless Commun Netw  no 243 pp 111 Apr 2012  T  H C hang W  K M a and C Y  Chi W orst-case r ob ust m ultiuser transmit beamforming using semidenite relaxation Duality and implications in Proc 45th Asilomar Conf Signals Syst Comput  Nov 2011 pp 15791583  Y  W a ng and R  S hi  T i ghtness of semidenite programming relaxation t o robust transmit beamforming with SINR constraints Math Probl Eng  vol 2013 pp 110 2013 Art no 508014  G Zheng K.-K W ong A P a ulraj and B  O ttersten  Rob u st collaborative-relay beamforming IEEE Trans Signal Process  vol 57 no 8 pp 31303143 Aug 2009  J F  Sturm Using SeDuMi 1.02 a M A TLAB t oolbox for optimization over symmetric cones Optim Method Softw  vol 11/12 pp 625653 1999  M Grant a nd S Bo yd CVX Matlab softw a re for d isciplined con v e x programming  A v ailable http://cvxr com/cvx 2011  S X W u  A  M C So a nd W  K M a Rank-tw o t ransmit b eamformed Alamouti space-time coding for physical-layer multicasting in Proc IEEE Int Conf Acoust Speech Signal Process  Mar 2012 pp 2793 2796 


1924 IEEE TRANSACTIONS ON SIGNAL PROCESSING VOL 65 NO 7 APRIL 1 2017  X W e n K L La w S J Alabed a nd M Pesa v e nto Rank-tw o b eamforming for single-group multicasting networks using OSTBC in Proc 7th IEEE Sensor Array Multichannel Signal Process Workshop  Jun 2012 pp 6972  S X W u  W K Ma and A M.-C S o Physical-layer multicasting b y stochastic transmit beamforming and Alamouti space-time coding IEEE Trans Signal Process  vol 61 no 17 pp 42304245 Sep 2013  K L La w X W e n and M  P esa v ento  General-rank transmit beamforming for multi-group multicasting networks using OSTBC in Proc 14th IEEE Workshop Signal Process Adv Wireless Commun  Jun 2013 pp 475479  S X W u  Q  Li A M.-C S o and W K Ma  A s tochastic beamformed amplify-and-forward scheme in a multigroup multicast MIMO relay network with per-antenna power constraints IEEE Trans Wireless Commun  vol 15 no 7 pp 49734986 Apr 2016  A W iesel Y  C Eldar  and S  S hamai Linear precoding via c onic optimization for xed MIMO receivers IEEE Trans Signal Process  vol 54 no 1 pp 161176 Jan 2006  G P ataki On t he rank of e x treme m atrices in semidenite programs a nd the multiplicity of optimal eigenvalues Math Oper Res  vol 23 no 2 pp 339358 1998  A Lemon A M.-C S o and Y  Y e Lo w rank semidenite programming Theory and applications Found Trends Optim  vol 2 no 12 pp 1 156 2016  W  K M a J P a n A M.-C S o and T H Chang A supplementary note for Unraveling the rank-one solution mystery of robust MISO downlink transmit optimization A veriable sufcient condition via a new duality result Dep Electron Eng The Chinese Univ Hong Kong Hong Kong Tech Rep 2016 A v ailable http://www.ee.cuhk.edu.hk 027 wkma/publications/robust-rank1-TR.pdf  A Ben-T a l a nd A Nemiro vski Lectures on Modern Convex Optimization Analysis Algorithms and Engineering Applications MPS-SIAM Series on Optimization Philadelphia PA USA SIAM 2001  W  C L iao T H Chang W  K M a and C Y  Chi QoS-based transmit beamforming in the presence of eavesdroppers An optimized articialnoise-aided approach IEEE Trans Signal Process  vol 59 no 3 pp 12021216 Mar 2011  Z.-Q L uo W  K M a A M.-C S o Y  Y e  a nd S Zhang Semidenite relaxation of quadratic optimization problems IEEE Signal Process Mag  vol 27 no 3 pp 2034 May 2010  A Beck and Y  C  E ldar   Strong duality in noncon v e x quadratic optimization with two quadratic constraints SIAM J Optim  vol 17 no 3 pp 844860 2006  Y  Huang a nd S Zhang Comple x matrix decomposition a nd quadratic programming Math Oper Res  vol 32 no 3 pp 758768 Aug 2007  J.-P  P enot Calculus Without Derivatives  volume 266 of Graduate Texts in Mathematics  New York NY USA Springer Science+Business Media 2013  A Beck and A  B en-T al Duality in rob u st optimization Primal w o rst equals dual best Oper Res Lett  vol 37 no 1 pp 16 2009  M Sion On g eneral minimax t heorems  Paci\036c J Math  vol 8 no 1 pp 171176 1958  H K o miya  Elementary p roof for S ion s m inimax theorem  Kodai Math J  vol 11 no 1 pp 57 1988  M Medra Y  Huang W  K M a and T  N  D a v idson Lo w comple x ity robust MISO downlink precoder design under imperfect CSI IEEE Trans Signal Process  vol 64 no 12 pp 32373249 Jun 2016  D Tse a nd P  V i sw anath Fundamentals of Wireless Communication  Cambridge U.K Cambridge Univ Press 2005 Wing-Kin Ma M01SM11F17 received the B.Eng degree in electrical and electronic engineering from the University of Portsmouth Portsmouth U.K in 1995 and the M.Phil and Ph.D degrees both in electronic engineering from The Chinese University of Hong Kong CUHK Hong Kong in 1997 and 2001 respectively He is currently an Associate Professor in the Department of Electronic Engineering CUHK His research interests include signal processing communications and optimization He currently serves as Senior Area Editor of IEEE T RANSACTIONS ON S IGNAL P ROCESSING and an Associate Editor of Signal Processing  and he is a member of the Signal Processing Theory and Methods Technical Committee TC and the Signal Processing for Communications and Networking TC He received 20132014 CUHK Research Excellence Award the 2015 IEEE Signal Processing Magazine Best Paper Award and the 2016 IEEE Signal Processing Letters Best Paper Award Jiaxian Pan received the B.Eng degree from Sun Yat-sen Zhongshan University Guangzhou China in 2008 and the Ph.D degree in electronic engineering from the Chinese University of Hong Kong CUHK Hong Kong in 2014 He was a Research Associate in CUHK from 2014 to 2015 He is currently a Senior Engineer with MediaTek Inc Hsinchu Taiwan He received the Best Student Paper Award from International Conference on Acoustics Speech and Signal Processing 2011 Anthony Man-Cho So M12 received the Ph.D degree in computer science with a Ph.D minor in mathematics from Stanford University Stanford CA USA He joined The Chinese University of Hong Kong CUHK in 2007 He is currently the Assistant Dean of the Faculty of Engineering and is an Associate Professor in the Department of Systems Engineering and Engineering Management He also holds a courtesy appointment as an Associate Professor in the CUHKBGI Innovation Institute of Transomics Dr So is currently with the editorial boards of IEEE T RANSACTIONS ON S IG NAL P ROCESSING the Journal of Global Optimization  Optimization Methods and Software and SIAM Journal on Optimization  He received the 2015 IEEE Signal Processing Society Signal Processing Magazine Best Paper Award the 2014 IEEE Communications Society Asia-Pacic Outstanding Paper Award the 2010 Institute for Operations Research and the Management Sciences Optimization Society Optimization Prize for Young Researchers and the 2010 CUHK Young Researcher Award Tsung-Hui Chang S07M08 received the B.S degree in electrical engineering and the Ph.D degree in communications engineering from the National Tsing Hua University NTHU Hsinchu Taiwan in 2003 and 2008 respectively He is currently an Assistant Professor with the School of Science and Engineering The Chinese University of Hong Kong Shenzhen China His research interests include signal processing and optimization problems in data communications and machine learning He received the Young Scholar Research Award from National Taiwan University of Science and Technology in 2014 the IEEE ComSoc Asian-Pacic Outstanding Young Researcher Award in 2015 and The Thousand Talents Program of China for Young Professionals in 2016 He is currently an Associate Editor of the IEEE T RANSACTIONS ON S IGNAL P ROCESSING and the IEEE T RANSACTIONS ON S IGNAL AND I NFORMATION P ROCESSING OVER N ETWORKS  


This article has been accepted for inclusion in a future issue of this j\ournal. Content is final as presented, with the exception of pagination EEE   17      e  224         l  h          224 s      264  264 d e           224 h        g y         d e   a                e 224        r n            e       3   G   e   t  1     e  n        g 224       6   T   l 224        7   A e c 224        8   D            t         t         n o l      224 s       224 s         n  t  3         7    6   C e    g      7   G    n          n n 224          d 224  s          224  s      n  224 n e      2   L D e         224         e          r e  e        d    t      g 224        e          r   s       r 224           224 s      2   W    224 s        g e e          e       5   I  s        A  s   


This article has been accepted for inclusion in a future issue of this j\ournal. Content is final as presented, with the exception of pagination 8   EEE     h  e       p 224 s       d 224 n          224        1   G t g  e      2   J  r n   t      l  224 s          e       5   I c 264  t 224         l                  8   Y e  l        9   D            0   M d  g  e       A 224         l e A v a i l a b l e  2    3   K    6 n  A v a i l a b l e  h t t p s   a r x i v o r g  7    4   G r  n   t       g     0      224 n a       g 224        n   s        e       f  ut        r   ut        l h a   s  0     p   t            nt       n  nt      l h   t                  f n l  0      n  o   5                224        n  t      n    s       l n  t       e n E t       224    1 


This article has been accepted for inclusion in a future issue of this j\ournal. Content is final as presented, with the exception of pagination EEE   19 S Gong Cheng om Xidian  in 2007 and the M.S. and technical  3   He is currently an Associate Professor with Northwestern Polytechnical University. His main research interests are computer vision and pat tern recognition ei Han ently techni ch The ersity cher at the Uni His omputer vision, multi and brain imaging analysis. He es such as IEEE T C t T IONS  ON P A t t T ERN  A A YSIS  AND M CHINE  I I N t T ELLIGENCE AMI I I N t T ER NA t T IONAL J OURNAL  OF  C C O m p MP U t T ER V ISION V T C t T IONS  ON  I I m M GE P SSING  TIP C C ONFERENCE  ON  C C O m p MP U t T ER V ISION  AND P A t t T ERN  R R OGNI t T ION VPR I I N t T ERNA t T IONAL  C C ONFERENCE  ON  C C O m p MP U t T ER V ISION V I I N t T ERNA t T IONAL J OIN t T  C C ONFER ENCE  ON  A A R t T IFICIAL  I I N t T ELLIGENCE IJCAI Prof. Han is an Associate Editor of the I E E E IEEE T RANSAC t T IONS  ON  H H U m M AN M ACHINE  S S YS t T E m M S  Neurocomputing   Processing and Machine Vision and Applications  u ently f  tor ests include emote sensing om e eas  international journal, including Neurocomputing Elsevier Cognitive  Computation Springer International Journal of Image and Graphics  World of Scientific 


