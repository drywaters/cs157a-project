The Application of Spatial Data Mining in Railway Geographic Information Systems Wei XU Yong QIN2 Houkuan Huang School of Computer and Information Technology Northem Jiaotong UniversrQ Beijing I OOOl4 China China Academy of Railwq Sciences Beijing, 100081,China Abstract This paper presents in-depth research on various spatial data mining techniques and their applications in railway geographic information systems RGIS through the systems planning design and implementation We propose 
the concept of intelligent RGIS IRGIS An IRGIS uses intelligent spatial data mining to discover the association rules hidden in the vast amount of railway data and will be able to perform not only the generic functions of spatial data presentation query and statistical analysis but also complex spatio-temporal analysis and decision-making support Index Terms Intelligent Railway Geographic Information System Spatial Data Mining Spatio-Temporal Trend Analysis I INTRODUCTION ith the developments in database technology spatial 
ever-increasing attentions of the sectors that use spatial information such as urban planning the utilities industry, and transportation management However, the lack of analytical funclions on spatial data has been the boltleneck of their extensive application To improve the processing capability of spatial data it is of great importance to build on the spatial database platform and its basic analysis functions to introduce machine learning and artificial intelligent algorithms based on the characteristics of spatial information and 
to create uniform data models for spatial data analysis and mining The application of information technology in railway systems places great demands on the management analysis and application of spatial data RGlS is created to meet this challenge and integrates existing railway management information systems MIS One key component of RGIS is the distributed spatial database and its shareware platform built on the railway base information, the environment in which spatial data analysis and mining tools customized to 0-7803-8la5-4/03/S17.00 
0 ZW3 IEEE W data management and applications have captured the the railway industry are designed For a railway base data platform and RGIS providing support for analysis and decision-making related to spatial locations is necessiuy The Chinese railway industry has invested billions of RMB in building a large number of railway MIS successhlly in the nation-wide railway systems These systems play a very important role in railway operations and have accumulated a tremendous amount of data 
Due to the lack of platform and tools to process spatial data it is difficult for these systems to adequately present utilize and proccss the intrinsic spatial distribution of the information and resources in the railway systems This results in low efficiency and flexibility of the query and presentation mechanisms and obstrucu the development of analysis decision-making support and other services that utilize spatial locations Consequently sfatc-of-the-art techniques of spatial data analysis and data mining can enhance the intelligence of railway information systems and extend railway base data 
platform with the ability to perform detailed analysis and assist in decision-making Currently research on spatial data mining is being actively conducted The characteristics of spatial data representation data structures and operations make spatial data mining techniques fairly complex Practical tools that meet industry requirements are rarely seen This paper will introduce spatial data mining techniques into RGlS to extend RGlS with complicated spatio-temporal analysis and decision-making support beyond the generic functions such as spatial data presentation. query and statistical analysis This paper is 
structured as follows In Section I1 is discussed the design and implementation of RGIS Following the retrospection is the complete description of applications of spatial data mining techniques in RGlS in Senion m In Section N the conclusions are given II DESIGN AND IMPLEMENTATION OF RGlS RGlS is a system based on GIS and underpinned by computer networks and serves the need of railway planning 1467 


managemen applications and decision-making It can efficiently store various kinds of data blueprints as well as multimedia information and supports railway operation thematic management spatial analysis strategic decision-making and public service It provides efficient query of track resources and environmental information along a railway line and helps to standardize the operation techniques and data management I A Requirement Analysis of RGIS RGIS can be plied in the following areas operation and maintenance of railway facilities organization of train operation disaster rescue marketing and railway-related decision making Facility operation and maintenance is one of the daily tasks of the railway operators.,Using RGIS information on railway equipments can be collected stored and analyzed to provide statistical data Various kinds of information such as railway transportation signaling and communications equipments lowmotives and track maintenance can be visualized by electronics maps E-map Combined with TMIS RGlS can simulate new operation graphs and train schedules on the E-map RGlS can provide detailed information about accident sites including topography and physiognomy of the sites railway facilities and the distribution of rescue facilities so that rescue plans can be created quickly and railway operations can be restored as soon as possible RGlS can also provide dynamic real-time information about freight passengers and ticketing to enhance the competitiveness of railway transportation RGlS can perform analysis on traffic volume and transportation capacity for specific tracks or railway stations to support decision-making in new railway construction and pricing  I scaling maps I RS data 1 crial photography dst piTzq q httribute datal Other data l+lTl railws MIS Fig.1 Data management ofRGlS C Modules ofRGlS In addition lo generic functions of GIS such as map presentation query on spatial data and attribute data and generation of thematic graphs and summary graphs RGlS need to provide the functions for spatial analysis on railway base data and decision-making suppon Such functions include spatial  data model analysis DEM analysis overlaying analysis spatial buffer analysis spatial topology analysis spatial network analysis spatial statistical analysis spatial deduction and query as well as other space-related analysis and decision-making support required by various operation units of the railway industry I The modular structure of RGIS is shownin Fig.2 B Data managemenf in RGIS Data in the RGlS should include digital maps stored in the railway spatial database base data on tracks, stations, bridges and culverts NMeIS power supply water supply and other equipmenls in the railway network associated attribute database shadow database and DEM database By building the spatial data sharing platform spatial information and  related non-spatial information on the operation of the whole railway network can be handled in a scientific way and shared within the railway industry Uniform services can be provided for applications in railway planning construction and management I The RGIS data model is show in Fig.1 The digital maps in the RGlS should he based on relief maps with standard scaling rules I million 1:0.25 million 1:0.05 million and railway grand scaling maps with relevant thematic information added on top Small'scaling maps based on the relief map of 1:lOO million scaling are usd to present the whole nation-wide railway network as the all-in-one view while medium ones can display regional railway networks with 1:0.25 million or 1:0.05 million scaling relief maps and'large ones cai display railways within local railway operations with 1:lO thousand or 1:2 thousand transportation communication Fig.2 Functional structure graph of RGIS The spatial data module includes functions for spatial database wnnection acquisition, and transformation Spatial 1468 


query consists of attribute search by graph real-time query on tracks stations and mileage positioning by mileage station positioning distance measurement and  area measurement Display control refers to zooming in and out and layer management of maps Data editing refers to appending modifying and deleting spatial data 111 APPLICATIONS OF SPATIAL DATA MINING TECHN~QUES IN RGIS Currently research on spatial data analysis and mining is becoming more active The group led by Han liawei professor in the Department of Computer Science at Simon Fraser University in Canada, created a prototype system for spatial data analysis and mining on the Maplnfo platform The system performs spatial data mining operations such as spatial data feature description spatial comparison spatial correlation spatial clustering and classification 2 De Ren LI professor from the Wuhan Surveying Technology University proposed that multiple kinds of knowledge such as geometrical information spatial correlation relationship between geometrical nature and other attributes can be discovered from a spatial database Using data mining finite spatial data might produce knowledge in unlimited ways However not all data can be effectively processed by general data analysis and mining tools If spatial data mining techniques are applied in RGIS it will greatly improve the utility of RGIS A Spatial data mining techniques Spatial data consist of objects that w-occupy a certain space and are interrelated In other words spatial data are the symbols rewrding spatial position thematic features and time information which are the there basic elements expressing physical world space changes Spatial objects are defined by spatial data types and their spatial inter-relation The vast amount of data stored in spatial databases can represent the objects spatial topological features non-spatial attributes and state changes in time Spatia1,data mining is the process to discover knowledge in spatial data sets to extract spatial modes and features in which the users are interested to identify the relationships between spatial data and non-spatial data Spatial data mining tools include characterization and induction on spatial data spatial correlation rule mining spatial classification and clustering spatial trend analysis and spatio-temporal mining ofdynamic data 3 I Spatial Analysis Using the various spatial analytical models and spatial operations in GIS spatial analysis processes the data in spatial databases to generate new information and knowledge Common spatial analysis techniques include topological analysis buffer analysis distance analysis overlay analysis network analysis topography analysis surface analysis and  forecast analysis The goal is to identify object correlations such as interconnection neighborhood, and interdependency or to determine the shortest or optimum path among objects knowledge that supports decision-making 2 Staristical Analysis Statistical analysis is widely used on spatial daw focusing on non-spatial features of spatial objects and phenomena The statistical approach has a solid theoretical foundation and a large number of maNre algorithms 3 Induction Induction is widely used in machine learning It centers on extracting general rules or modes from a large amount of empirical data In GIS spatial relationship concept tree.can be built for knowledge discovery 4 Classification and clustering approach By either the classification or the clustering approach data can be divided into a series of differentiated groups in accordance with a certain distance or similarity measure Both approaches can be applied to spatial data analysis by making spatial division of the subjects based on the criterion that intra-group differences are smaller than inter-group differences For classification the number of groups and the characteristics of each group are known beforehand whereas for clustering these e determined in the clustering process 5 Sporial characlerislic and trend analysis approach These are mining algorithms based on neighborhood plots and neighborhood paths A spatial characteristic is defined as the set of objects with certain spatial or non-spatial properties The values of interest are the relative frequency of the occurrence of non-spatial attributes and that of objects in different spaces Spatial rules are extracted from the change in relative frequencies when a spatial object set is extended to its neighborhood set Spatial trend analysis starts from a specific spatial object and finds out the rules of change in one or more non-spatial attributes The efficiency of these algorithms to a large extent relies on the ability to deal with the neighborhood relationship 6 Digitai map image analysis andparrern recognition  Spatial databases store alarge number of figures and image data Some image analysis and panem recognition techniques can be directly employed to data mining and knowledge discovery or to preprocessing before other data mining approaches are used Artificial neural networks genetic algorithms fuzzy set and rough set approaches and visualization techniques can also be applied to spatial data mining Because the majority of spatial data are image data with a vast amount of information algorithm efficiency is a very important reswch problem E Applications ofspatial data mining in RGIS Up to now the applications of RGIS.are limited to railway facility management track maintenance management 3-D visualization and visual imaging of railways railway land zoning railway reconnaissance and design train positioning monitoring and scheduling as well as in combination with TMIS RGIS that offers advanced spatial analysis and decision-making support is rarely seen Spatial data mining is not the simple application of classical data mining techniques to spatial data, nor a copy of 1469 


classical geological analysis functions It utilires the powerful spatial analysis functions in GIS and intelligent data mining approaches to discover the knowledge and association rules hidden in spatial data to forecast future trends on the basis of available data and to perform intelligent spatio-temporal analysis RGlS serves the purpose of providing scientific railway-specific space-and-time related analysis forecast and decision-making support I Definition of IRGIS IRGIS is an intelligent integrated and highly compositional system that serves the railway industry with decision-making support IRGIS is built on traditional RGIS systems integrated with artificial neural networks genetic algorithms expert systems and data mining techniques by statc-of-the-art intelligent analytical and computational tools The structure of a typical IRGIS is shown in Fig.3 Fig.3 Integrative model or IRClS 2 Applicnrionr of sparid darn mining techniques in RGIS Spatial data mining has the following applications in I Associalion rule mining To identify the relationship between demographic economic and geogaphic conditions of the area along newly-built railway backs, and kalyze railway distribution location and reachablity so as to provide optimized plan for building new railway backs To identify the relationship between existing railway tracks and the topographical geological demographic economic and traffic conditions of the area connected by the tracks to improve railway operations by optimizing the organization and scheduling oftrains and routes and to identify the factors that affect passenger trailic To identify the primary factors that affect train speed, to better arrange the wain operation graph and reduce travel time To analyze the social and geographical situations of the sites where accidents frequently occur and identify the causes RGIS so as to provide improved emergency response plan To determine the bottlmecks in the railway network by analyzing the correlation among train service data For example we may discover the following correlation rule express\(x y A staiion_si&x S A Station-sizCO L Oregion\(x  regionw 75 It means if a main depm at the small station x directly for grand wain station y the probability that x and y are in the same area is 75 2 Classification and forecast To forecast passenger volume and facilitate train deployment To set up the model to analyze and forecast the volume of passengers and freight both in peak month and low season assisting in railway passenger traffic marketing management railway freight marketing management and quality control of services for passengers and freight To deploy railway resources with precision and identify the primary factors affecting passenger volume and take measures accordingly during the peak period around the spring festival For example by analyzing ticketing data or classifying the population of a city by income to predict passenger volume 3 Trend analysis To simulate accident scenarios and provide integrated information about accident sites in case of emergency and to reduce loss to the minimum To monitor passenger and freight traffic in bottleneck areas and destinations, conduct spatio-temporal trend analysis and collect dynamic information in order to adjust traffic capacity and IO provide decision-making support 4 Planning In addition to providing information to all levels of management RGlS can also provide information to cargo owner and passengers For example to provide information about how and when to transfer to other trains alternative mutes and customized travel plan for passengers C darn Traditional sequential panern mining is based on the time factor and spatial sequential pattern mining is based on the space factor The mining of the spatio-temporal sequential panems in railway data with spatial attributes in the RGlS should be based on both the space factor and the time factor so called spatio-temporal pattern 4 The mining of spatio-temporal sequential panems differs from the normal mining of sequential panems the time-based frequent item sets will first be computed with a variation of the a priori algorithm and the space-based frequent item sets will then be computed with the corresponding spatial algorithm, then the reduction set will be created from these two group of sets by the joining algorithm The pseudo code of this basic algorithm is Spnrio-temporal sequenrinlpnttern mining of spatial 1470 


131 Kaichang DI Spatial Datl Mining and Knowledge 141 Ipwei Han Mchclins Kamk DATA MINING Conccpu and Technquer  Morgan Kauhann Publishen.2001 Input Spatial Database D minimum support threshold Diwovev WUHAN Univerdly.2000 in Chinae Output the spatio-temporal pattems in D frequent item sets in 0 Steps  1  TL=find_temporal_frequent-itemsets\(D 2 1 SLand_spatial_frequent-itemsets\(D  3 L=TL-SL TL time based frequent item sets SL space based frequent item sets n joined reduction set of TL and SL The sewnal changing pattern of railway passenger flow during the holiday season can be determined from the ticketing d,ata with this algorithm For example it could be found that the passenger flow to Beijing from the nearest station increased dramatically from April 30 to May 1 This spatio-temporal sequential pattem is illustrated in Fig.4 Fig 4 Spafirtemporal sequential pattern of railray data IV CONCLUSION The digital railway is a strategic goal for the construction of the Chinese railway systems in the 21st century It is a virtual railway a dynamic information system which provides open and comprehensive services with distributed processing capability By means of storing managing and applying the railway data effectively, the digital railway can really digitize the management of railway transportation Research on intelligent spatial data analysis and data mining based on GIS will improve the level of intelligence and advances of the digital railway system ofour counuy, and  provide powerful tools for market analysis prediction and decision-making It can also increase railway operation efficiency and improve the level of competition in the transportation industry Because of the complexity of spatial data structures and operations it is a key for IRGlS and  intelligent transportation systems ITS to utilize effectively the spatial and temporal attributes of railway data References I China Asadany of Railway Ssienca general design pmjecr ofmilway gcogmphis nJwmnrion wstem ZOO2 in Chinae 21 Kowi K Han 1 Discovery of spatial asmiation mla in geographic informmion databe br ha of the 4th Intl Symprium On Large Spatial Da\(abaws Portland ME 1995.47 66 1471 


2\d all the frequent closed itemsets in a  i n c e    class a cond   and   nclass a cond   cond a in Case 1. Because nclass nclass b       itemsets of   a are not mined 3\d all the frequent closed itemsets in b  i n c e    pure b cond      npure b cond   cond b Case-3 As no itemset has the same support as b  b 3 is added into b  Because of nclass nclass ace        c and e are removed from P. Since sup d  min_sup cond bd ith P  needs to be mined. Clearly cond bd Case-3 as   class bd cond   and   class bd cond    As no itemset has the same support as bd  bd 2 is added into b  The mining then finishes 4\ Find all the frequent closed itemsets in   ecau s e of    class cond   and    nclass cond   cond   Case-3. The task of mining cond  further decomposed into mining of cond c ith P d,e cond d ith P e  and cond e ith P  cond  c Case-3 as   class c cond   and   nclass c cond    Because e appears in every transaction of cond c d sup ce  ce 4 is added into Z   d does not appear in every transaction of nclass c cond    even though ab does so, hence mining  cond cde ith P  is still needed. With sup cde  cde 3 is added into   cond d Case-3 due to   class d cond   and   nclass d cond    Since sup d  d 4 is added into   cond de ith    is in Case-1 as   class de cond   and   nclass de cond   Due to nclass nclass c        cde 3 is not added to   even though sup cde  min_sup cond e Case-1 as   class d cond   and   nclass d cond    Because nclass nclass c        ce 4 is not added to   The mining of    finishes  It is worth of pointing out     pmine  D I,min_sup k  can be directly applied to parallel mining. In this case k is determined by the number of processors in a parallel computing system. Each processor is loaded a conditional database of a class, and the mining of each class can be done in parallel. When a processor finishes its job much earlier than others, load balancing is required 5. Experimental Results  In this section, we compare the performance of our method PMINE with AFOPT. All experiments are performed on a 500MHz Pentium III with 192MB of memory, running RedHat Linux 6.0. For performance comparison we used the original source for AFOPT obtained from its authors  We choose benchmark datasets downloaded from FIMI03 workshop web site. Table 3 shows the datasets characteristics Dataset Size #Trans MaxTL AvgTL T10I4D100K 3.93M 100000 30 10.10 T40I10D100K 15.12M 100000 78 39.61 Connect-4 9.11M 67557 43 43.00 Pumsb 16.30M 49046 74 74.00 Table 3 Dataset characteristics  Figures 3-6 show the running time for different datasets with different minimum support threshold. In the experiment, we combine our technique with FP-Tree data structure. Generally, it is faster than AFOPT.  In addition the new technique can be easily used in the existing frequent closed itemsets mining algorithms to improve their efficiency. The most important is its capability of parallel mining with workload balance  abcde bd cde abce cde D cde ce cond\(ab P={c,d,e bcde bce cond\(a P={c,d,e acde ace d cond\(b P={c,d,e abcde bd abce cde cde cond  P={c,d,e Z ab abce:2 P Z a  P Z b b:3 P={d Z  P={c,d,e abde abe de de cond\(c P={d,e Z ce:4 P={d ace cond\(bd P Z b b:3, bd:2 P abce b ce ce cond\(d P={e abcd cd abc cd cond\(e P ab cond\(cde P Z ce:4,d:4 P={e Z ce:4,d:4 P  Z ce:4,d:4,cde:3 P abc c c cond\(de P Z ce:4,d:4,cde:3 P non-class part class part Note A conditional database is divided into two parts, shown as the right figure. The part above the dashed line is non-class segment. The part under the line is class segment conditional database Z={abce:2, bd:2, b:3,cde:3,ce:4,d:4 Figure 2  Mining frequent closed itemsets using pmine  


6  Conclusions  In this paper, we investigate a new frequent-closeditemset mining method that can greatly enhance the efficiency and scalability of the current association rule algorithms. The main contributions of this work are: 1\he method completely eliminates the computationally expensive closure-checking procedure in the frequent closed itemset mining and thus is particularly useful for mining very large datasets; 2\ the method is applicable to not only sequential mining but parallel mining   Dataset: T10I4D100K 0 2 4 6 4 321 M inim um Suppor t     PM INE AFOPT  Figure 2 Running time for dataset T10I4D100K  Dat aset  T40I 10D100 K 0 5 10 15 20 2 5 21.51 M inim um Suppor t     PM INE AFO PT  Figure 3 Running time for dataset T40I10D100K Dataset: Connect-4 0 2 4 6 8 10 95 90 85 80 M inim um Suppor t     PM INE AFO PT  Figure 4 Running time for dataset Connect-4  Dataset: Pum sb 0 5 10 15 95 90 85 80 M inim um Suppor t     PM INE AFO PT  Figure 5 Running time for dataset Pumsb 7. References 1  N. Pasquier, Y. Bastide, R. Taouil, and L. Lakhal Discovering frequent closed itemsets for association rules In ICDT99, Jan. 1999 2  R. Agrawal, T. Imielinski, and A. Swami.  Mining association rules between sets of items in large databases SIGMOD'93, 207-216, Washington, D.C 3  J. Han, J. Pei, and Y. Yin. Mining frequent patterns without candidate generation. In Proc. 2000 ACMSIGMOD Int. Conf. Management of Data \(SIGMOD00 Dallas, TX, May 2000 4  R. Agrawal and R. Srikant. Fast algorithms for mining association rules. In Proc. 1994 Int. Conf. Very large Data Bases \(VLDB94\es 487-499, Santiago, Chile September 1994 5  H. Mannila, H. Toivonen, and A. I. Verkamo Efficient algorithms for discovering association rules KDD'94, 181-192, Seattle, WA, July 1994 6  A. Savasere, E. Omiecinski, and S. Navathe. An efficient algorithm for mining association rules in large databases. VLDB'95, 432-443, Zurich, Switzerland 7  H. Toivonen.  Sampling large databases for association rules.  VLDB'96, 134-145, Bombay, India Sept. 1996 8  M.J. Zaki, S. Parthasarathy, M. Ogihara, and W. Li New algorithms for fast discovery of association rules KDD97. August 1997 9  S. Brin, R. Motwani, J. D. Ullman, and S. Tsur Dynamic itemset counting and implication rules for market basket analysis. SIGMOD'97, Tucson, Arizona, May 1997 10  D.W. Cheung, J. Han, V. Ng, and C.Y. Wong Maintenance of discovered association rules in large databases: An incremental updating technique. ICDE'96 New Orleans,  LA 


11  J.S. Park, M.S. Chen, and P.S. Yu. An effective hash-based algorithm for mining association rules SIGMOD'95, San Jose, CA, May 1995 12  J. Wang, J. Pei, and J. Han. Closet+: Searching for the best strategies for mining frequent closed itemsets. In SIGKDD 2003 13  C. Liu, H. Lu, J. X. Yu, W. Wang, X. Xiao. AFOPT An Efficient Implementation of Pattern Growth Approach In SDM 2003 14  M. J. Zaki and C. Hsiao. CHARM: An efficient algorithm for closed itemset mining. In SDM, 2002 15  T. Uno, T Asai, Y. Uchida, and H. Arimura. LCM: An Efficient Algorithm for Enumerating Frequent Closed Item Sets. In SDM 2003 16  C. Hughes, T. Hughes. Parallel and Distributed Programming Using C++. Addison Wesley Professional Aug 25, 2003 17  J. Adamo. Data Mining for Association Rules and Sequential Patterns --Sequential and Parallel Algorithms Springer  2000   


Figure 3 Example of a patent abstract with its generated multi-index. The multi-index that has been generated for the above patent abstract corresponds to the \223 Final indexation 224 field. The terms of the generated multi-index are prefixed by the name of the viewpoint to which they are associated: \223adv.\224 for the Advantages viewpoint, \223titre.\224 for the Title viewpoint, \223use.\224 for the Use viewpoint, \223soc.\224 for the Patentees viewpoint Patentees Title Use es GlobMin WEBSOM  WEBSOM  Number of indexed documents \(NID 1000 1000 745 624 1000 1000 Number of rough indexes generated \(NRI 73 605 252 231 1395 1395 Number of final indexes \(NFI 32 589 234 207 1075 1075 Numbers of map nodes with members \(/100 28 55 57 61 89 238 Table 1 Summary of the results of patent indexation and map building. Note that the NRI \(resp. NFI\ \223global viewpoint\224 are less than the sum of the NRIs \(resp. NFIs\ specific viewpoints \(i.e. 1089\ecause there are similar indexes occurring in different viewpoints Patentees Title Use es MSOM GlobMin WEBSOM  WEBSOM R 0,94 0,89 0,78 0,77 0,85 0,87 0,84 P 0,92 0,40 0,63 0,60 0,64 0,48 0,65 F 0,93 0,55 0,70 0,67 0,71 0,61 0,68 Table 2 Summary of the results of Quality, Recall and Precision evaluation. The nearer the different values are from 1, the better are the clustering results. The F value provides a synthesis of the results of R and P Proceedings of the Fourth International Conference on Coordinated Multiple Views in Explor atory Visualization \(CMV\22206 ISBN-10: 0-7695-2605-5/06 $20.00 \251 2006  IEEE 


Figure 4 Example of a generated map. Partial view of a topographic map of 10 x 10 nodes. The map is initially organized as a square 2D grid of nodes. The viewpoint chosen for the showed map is the Advantages viewpoint. The names of the clusters illustrate the topics \(considering the chosen viewpoint\ been highlighted by the learning. After the learning, the no des related to the same topics have been grouped into coherent areas thanks to the topographic properties of the map. The number of nodes of each area can then be considered as a good indicator of the topic weight in the database. Topics or areas near one to another represent related notions. For example, the \223 extending oil live 224 area shares some of its borders with the \223 black sludge control 224 area on the map. The proximity of these two areas illustrates the fact that oil duration strongly depends \of maintaining a low level of sludge in it. The surrounding circles represent the centers of gravity of the areas  1 2 3 Patentees Title Advantages Use 3 2 1 Figure 5 Example of exploitation of the inter-map communication mechanism. The analyst decision to activate the area corresponding to the TONEN CORP. company on the Patentees map and to propagate the activity to the thematic maps associated to the Use  Advantages and Title viewpoints corresponds to a "viewpoints crossing query" whose explicit formulation might look like: "I want to know which are the specific areas of competence \(concerning oil use, oil composition and expected advantages\". The MultiSOM application let him interactively find that TONEN CORP. company is a specialist of the lubrication of the automatic transmissions [arrow n\2602 on th r  this kind of lubrication sulfur-containing organo-molybdenum compound [arrow n advantages are to provide oil with a friction coefficient that is stable on a wide range of temperature [arro In this ca se, an inverted propagation fr om the target topics should be also used to verify that these topics only belong to TONEN CORP. areas of competence. The whiter is the color of a node representing a map cluster \(topic\ing activity Proceedings of the Fourth International Conference on Coordinated Multiple Views in Explor atory Visualization \(CMV\22206 ISBN-10: 0-7695-2605-5/06 $20.00 \251 2006  IEEE 


 Profile of topic Extending oil life Figure 6 Results of a WEBSOM-like global mapping of 10x10 nodes GlobMin The left part of the figure represents the WEBSOM-like mapping \(i.e. without viewpoint management\repre sents the description \(i.e. profile\ \223 extending oil life 224 WEBSOM global topic. Even if a strong relationship between \223 extending oil life 224 and \223 black sludge control 224 topics has been highlighted by the MultiSOM viewpoint-oriented clustering \(see map of figure 3 relationship has been lost by the WEBSOM-like clustering due to the noise of the global clustering \(this relationship do not ap pear neither in the above map, nor in the \223 extending oil life 224 topic profile Figure 7 Comparison between a 11x11 \223Use viewpoint\224 thematic map and a 16x16 \223Use viewpoint\224 thematic map through map extracts The 11x11 map extract is presented at the left, the 16x16 map extract is presented at the right. On the figure, the focus is gi ven 223 machine oil 224 topic. The comparison highlights, as an example, that the logical surrounding of this topic is more precisely defined in the 16x16 map \(optimal quality\n in the 11x11 map \(lower quality\n the 11x11 map, the topic \223 machine oil 224 has been derived in a more fuzzy scope topic named \223 machine and vehicles 224 Proceedings of the Fourth International Conference on Coordinated Multiple Views in Explor atory Visualization \(CMV\22206 ISBN-10: 0-7695-2605-5/06 $20.00 \251 2006  IEEE 


ANNEX: example of interactive dynamic multi-viewpoint analysis Dynamic analysis takes place main ly by using the inter-map communication mechan ism which makes it possible to bring to successful conclusion sets of topics deductions between differen t viewpoints chosen like investigation under-fields. This a nalyze is based on the generation of an initia l activity corresponding to the premises of the deduction to check. According to stages of analyze, this activity can itself be generated several manners by the analyst on one or more source map. If the activity generation is d irectly operated by analyst on a map, it corresponds then to broad a set of topics question. If the activity generation is operated indirectly by projection query on a map or by activation of documents group stored befo rehand in a collector of documents, it corresponds then to more targeted question, which can intervene in one second stage of the analyze The analyst interest is to hi ghlight the specific areas of competence of the Exxon company. On the simulation of analysis we develop on figure 7, we will consider two different viewpoints Patentees which will represent the source of the analysis and the Title viewpoint which will represent its destination The analyst starts the process of deduction by generating an initial activity on the main Exxon topic i.e. Exxon area gravity center\ of the Patentees viewpoint map. To obtain a broad set of potential deductions, he selects the Possibilistic mode of deduction 17  The activity generated by the inter-map  communication mechanism on the Title viewpoint map is focused in two different zone s of this map, corresponding to two potential results In the first active zone \(1\, the analyst makes use two different naming strateg ies to facilitate its interpretation namely a naming strategy based on the profile of the topics more generic\ and a naming strategy based on the profile of the best members \(i.e. patents\of the topics more specific\. These operations enable him to highlight that the Exxon company is specialized in a correlative way on topics: \215 marine diesel engine 216 215 surfactant system 216 and \215 basic calcium compound 216 The expert checks the correlation between these topics by consulting the patents associated to the topic 215 surfactant system 216 \(2\. The title of the patents already confirm him the problematic de tected by the application A thorough examination of th e contents of the documents will show him than the pur pose of use of surfactant containing calcium in add ition with the normal formula of oils is to protect the combustion chambers of the marine diesel engines against corrosion due to the absorption of air charged out of salt during their operation. The problem of protection of the marine engines against corrosion is sufficiently important to represent a field of investigation for an oil manufacturer like Exxon The construction of a query containing the single descriptor \215 surfactant system 216 \(3\ on the Title viewpoint will allow the analyst 1 To validate the correlation between 215 surfactant system 216 and \215 marine diesel engine 216 topics which will be interpreted by the fact that 215 surfactant system 216 is only associated with 215 marine diesel engine 216 2 To check the inverse deduction 215 surfactant system 000\306 Exxon 216 which will insure him that Exxon is the only company whose interest in the conception of \215 surfactant system 216 The result of the projection of the query on the Title viewpoint map \(4\ shows that the generated activity is peculiar to the logical topic area \215 marine diesel engine 216, which confirms th e first assumption Simultaneously with projection the documents that are relevant for the query are presented in a Collector \(5 The global activation of these documents allows analyst to initiate a new de duction.  Then, the result of this latter can be examined on the Patentees map. Like only the main Exxon topic has been activated \(6\, the second assumption of the an alyst is confirmed The second active zone \(7\ generated by the initial process of deduction will allow the analyst to observe that the second major field of activity of Exxon is the 215 biodegradable 216 oils. It will be able to also note that these oils are more specifically us ed for the lubrication of the two-stroke engines \(\215 two cycle engine 216\ that generally reject much unburned oil Probabilistic mode of deduction will allow him to check if the inverse deduction, namely, that Exxon is the only company to be worked on biodegradable oils, can be validated \(8\. This process will lead the analyst to conclude that 215 biodegradable 216 oil manufacturing is shared between Exxon and Mobil companies \(9\, which are the most important oil manufacturers A complementary use of negative activity setting on the \215 two cycle engine 216 topic \(10\ will show more precisely to the analyst that that Mobil company mainly focus on manufacturing of biodegradable oils for \215two stroke engines\216 and, in a complementary way, that Mobil company only focus on manufacturing of biodegradable oils for \215four stroke engines\216 \(11 The simulation of analysis presented here above shows clearly how the analyst can make use of the MultiSOM functionalities in order to highlight all the privileged activity fields of the Exxon company starting from a patents database related to engineering of oils Main functionality is inter-map communication. Multiple naming strategies, generation of queries and collection intermediate results that have been implemented complementary to inter-map communication also play an important role in the analysis process Proceedings of the Fourth International Conference on Coordinated Multiple Views in Explor atory Visualization \(CMV\22206 ISBN-10: 0-7695-2605-5/06 $20.00 \251 2006  IEEE 


     Activated area 1    Inverse validation 10 Categorical rejection Categorical choice Activity resulting from the inverse validation Result  28,6 and 17 11 Focalization Inverse validation Activity resulting from the inverse validation 9 Result 28,6% and 23 5 6 3 Legend  Viewpoint 215Patentees\216 Viewpoint 215Title\216  Projection resulting from the inverse validation Activated area 2 7 1 8 Analysis of deduction 2  4 Figure 8 Diagram of the analysis simulation Result 100 Proceedings of the Fourth International Conference on Coordinated Multiple Views in Explor atory Visualization \(CMV\22206 ISBN-10: 0-7695-2605-5/06 $20.00 \251 2006  IEEE 


per by Ganti et. al. [9] deals with the measurement of similarity \(or deviation, in the authors  vocabulary between decision trees, frequent itemsets and clusters Although this is already a powerful approach, it is not generic enough for our purpose. The most relevant research e?ort in the literature, concerning pattern management is found in the ?eld of inductive databases Proceedings of the 16th International Conference on Scientific and Statistical Database  Management \(SSDBM  04 1099-3371/04 $ 20.00  2004 IEEE meant as databases that, in addition to data, also contain patterns [10], [7]. Our approach di?ers from the inductive database one mainly in two ways. Firstly, while only association rules and string patterns are usually considered there and no attempt is made towards a general pattern model, in our approach no prede?ned pattern types are considered and the main focus lies in devising a general and extensible model for patterns Secondly, di?erently from [10], we claim that the peculiarities of patterns in terms of structure and behavior together with the characteristic of the expected workload on them, call for a logical separation between the database and the pattern-base in order to ensure e?cient handling of both raw data and patterns through dedicated management systems Finally, we remark that even if some languages have been proposed for pattern generation and retrieval 14, 11], they mainly deal with speci?c types of patterns \(in general, association rules sider the more general problem of de?ning safe and su?ciently expressive language for querying heterogeneous patterns 7. Conclusions and Future Work In this paper we have dealt with the issue of modelling and managing patterns in a database-like setting Our approach is enabled through a Pattern-Base Management System, enabling the storage, querying and management of interesting abstractions of data which we call patterns. In this paper, we have \(a de?ned the logical foundations for the global setting of PBMS management through a model that covers data patterns and intermediate mappings and \(b language issues for PBMS management. To this end we presented a pattern speci?cation language for pattern management along with safety constraints for its usage and introduced queries and query operators and identi?ed interesting query classes Several research issues remain open. First, it is an interesting topic to incorporate the notion of type and class hierarchies in the model [15]. Second, we have intentionally avoided a deep discussion of statistical measures in this paper: it is more than a trivial task to de?ne a generic ontology of statistical measures for any kind of patterns out of the various methodologies that exist \(general probabilities Dempster-Schafer, Bayesian Networks, etc. [16 nally, pattern-base management is not a mature technology: as a recent survey shows [6], it is quite cumbersome to leverage their functionality through objectrelational technology and therefore, their design and engineering is an interesting topic of research References 1] Common Warehouse Metamodel \(CWM http://www.omg.org/cwm, 2001 2] ISO SQL/MM Part 6. http://www.sql99.org/SC32/WG4/Progression Documents/FCD/fcddatamining-2001-05.pdf, 2001 3] Java Data Mining API http://www.jcp.org/jsr/detail/73.prt, 2003 4] Predictive Model Markup Language \(PMML http://www.dmg.org 


http://www.dmg.org pmmlspecs v2/pmml v2 0.html, 2003 5] S. Abiteboul and C. Beeri. The power of languages for the manipulation of complex values. VLDB Journal 4\(4  794, 1995 6] B. Catania, A. Maddalena, E. Bertino, I. Duci, and Y.Theodoridis. Towards abenchmark for patternbases http://dke.cti.gr/panda/index.htm, 2003 7] L. De Raedt. A perspective on inductive databases SIGKDD Explorations, 4\(2  77, 2002 8] M. Escobar-Molano, R. Hull, and D. Jacobs. Safety and translation of calculus queries with scalar functions. In Proceedings of PODS, pages 253  264. ACMPress, 1993 9] V. Ganti, R. Ramakrishnan, J. Gehrke, andW.-Y. Loh A framework for measuring distances in data characteristics. PODS, 1999 10] T. Imielinski and H. Mannila. A database perspective on knowledge discovery. Communications of the ACM 39\(11  64, 1996 11] T. Imielinski and A. Virmani. MSQL: A Query Language for Database Mining. Data Mining and Knowledge Discovery, 2\(4  408, 1999 12] P. Kanellakis, G. Kuper, and P. Revesz. Constraint QueryLanguages. Journal of Computer and SystemSciences, 51\(1  52, 1995 13] P. Lyman and H. R. Varian. How much information http://www.sims.berkeley.edu/how-much-info, 2000 14] R.Meo, G. Psaila, and S. Ceri. An Extension to SQL for Mining Association Rules. Data Mining and Knowledge DiscoveryM, 2\(2  224, 1999 15] S. Rizzi, E. Bertino, B. Catania, M. Golfarelli M. Halkidi, M. Terrovitis, P. Vassiliadis, M. Vazirgiannis, and E. Vrachnos. Towards a logical model for patterns. In Proceedings of ER 2003, 2003 16] A. Siblerschatz and A. Tuzhillin. What makes patterns interesting in knowledge discovery systems. IEEE TKDE, 8\(6  974, 1996 17] D. Suciu. Domain-independent queries on databases with external functions. In Proceedings ICDT, volume 893, pages 177  190, 1995 18] M.Terrovitis, P.Vassiliadis, S. Skadopoulos, E. Bertino B. Catania, and A. Maddalena. Modeling and language support for the management of patternbases. Technical Report TR-2004-2, National Technical University of Athens, 2004. Available at http://www.dblab.ece.ntua.gr/pubs Proceedings of the 16th International Conference on Scientific and Statistical Database  Management \(SSDBM  04 1099-3371/04 $ 20.00  2004 IEEE pre></body></html 


The reason of the hiding failure of SWA is the same in Fig.8 Notice the result at x = 0.7646 in Fig.14, because the hiding failure is occurred at the seeds of the sensitive patterns, a high weakness is produced As shown in Fig.15 and Fig.16, the misses cost and dissimil arity of our work decreases as RL2 increases. This is because the larger RL2 is, the less effect on non-sensitive patterns. Also weakness and dissimilarity of SWA are independent of RL2 5. Conclusion In the paper, a novel method improving the balance between sensitive knowledge protecting and discovery on frequent patte rns has been proposed. By setting entries of a sanitization matrix to appropriate values and multiplying the original database by the matrix with some probability policies, a sanitized database is gotten. Moreover, it can avoid F-I Attack absolutely when the confidence level given by users approximates to 1. The experimental results revealed that although misses cost and dissimilarity between the original and sanitized database of our process are little more than SWA, ours provide more safely protection than SWA. Unlike SWA, our sanitization process could not suffer from F-I Attack and the probability policies in our approach also take the minimum support into account, the users only need to decide the confidence level which affects the degree of patterns hiding 6. Reference 1] M. Atallah, E. Bertino, A. Elmagarmid, M. Ibrahim and V. Verykios Disclosure Limitation of Sensitive Rules", Proc. of IEEE Knowledge and Data Engineering Exchange Workshop 1999 2] R. Agrawal and R. Srikant. Fast algorithms for mining association rules. VLDB, Santiago, Chile, 1994 3] R. Agrawal and R. Srikant. Privacy preserving data mining. In ACM SIGMOD, Dallas, Texas, May 2000 4] E. Dasseni, V. Verykios, A. Elmagarmid and E. Bertino, Hiding Association Rules by Using Confidence and Support", Proc. of 4th Intl Information Hiding Workshop \(IHW 5] A. Evfimievski, J. Gehrke, and R. Srikant. Limiting Privacy Breac hed in privacy preserving data mining. SIGMOD/PODS, 2003 6] A. Evfimievski, R. Srikant, R. Agrawal, and J. Gehrke. Privacy preserving mining of association rules. KDD 2002 7] M. Kantarcioglu and C. Clifton. Privacy-preserving distributed mining of association rules on horizontally partitioned data. In ACM SIGMOD Workshop on Research Issues on Data Mining and Knowledge Discovery, June 2002 8] Guanling Lee, Chien-Yu Chang and Arbee L.P Chen. Hiding sensitive patterns in association rules mining. The 28th Annual International Computer Software and Applications Conference 9] Y. Lindell and B. Pinkas. Privacy Preserving Data mining. In CRYPTO, pages 36-54, 2000 10] S. R. M. Oliveira and O. R. Za  ane. Privacy Preserving Frequent Itemset Mining. In Proc. of IEEE ICDM  02 Workshop on Privacy Security, and Data Mining 11] S. R. M. Oliveira and O. R. Za  ane. Algorithms for Balancing Priv acy and Knowledge Discovery in Association Rule Mining. IDEAS  03 12] S. R. M. Oliveira and O. R. Za  ane. Protecting Sensitive Knowledge By Data Sanitization, ICDM  03 13] S. R. M. Oliveira, O. R. Za  ane and Y  cel Saygin. Secure Association Rule Sharing, PAKDD-04 14] Benny Pinks. Cryptographic Techniques For Privacy-Preserving D ata Mining. ACM SIGKDD Explorations Newsletter Vol. 4, Is. 2, 2002 15] S. J. Rizvi and J. R. Haritsa. Maintaining data privacy in association rule mining. VLDB, 2002 16] J. Vaidya and C. W. Clifton. Privacy preserving association rule mining in vertically partitioned data. KDD2002 17] Verykios, V.S.; Elmagarmid, A.K.; Bertino, E.; Saygin, Y.; Dasseni E. Association rule hiding. IEEE Transactions On Knowledge And Data Engineering, Vol. 16, No. 4, April 2004 Proceedings of the 29th Annual International Computer Software and Applications Conference  COMPSAC  05 0730-3157/05 $20.00  2005 IEEE pre></body></html 


pre></body></html 


Batt Power Batt Type Stabilization Type Propulsion Mechanism  of Solar Panels  of Solar Cells Manufacturing Qty Satellites in Constellation On-Orbit Spares Channels Number of Bands Data Storage Processing Power Source type Block Name Thermal Control Material Type Level of Technology Known Inheritance Propulsion station keeping Number of Axes Ground Based Spares Pointing Accuracy APPENDIX C EXISTING MODELS Numerous models are today in use for estimating spacecraft cost Two of the most common are the NASA/Air Force Cost Model and the Aerospace Small Satellite Cost Model Here is a description of the NAFCOM model The NASA/Air Force Cost Model NAFCOM is a parametric estimating toolfor space hardware It is based on historical NASA and Air Force space projects and is primarily used in the very early phases of a development project NAFCOM can be used at the subsystem or component levels The database currently includes 122 missions including 76 unmanned earth orbiting 24 unmanned planetary 11 launch vehicles 8 manned 3 engines It uses parametric relationships to estimate subsystem or component level costs for any aerospace hardware including earth orbital spacecraft manned spacecraft launch vehicle upper stages liquid rocket engines scientific instruments or planetary spacecraft 7 And for the Aerospace Small Satellite Cost Model SSCM employs a parametric methodology for estimation of program cost and is best suited to the early conceptual development phase of a spacecraft program during which time the design is likely to be less mature and when cost and performance trades can be easily performed SSCM consists of a collection of cost-estimating relationships or CERs which estimate the costs of developing andproducing a spacecraft system with the following subsystems  Attitude Determination and Control Subsystem ADCS  Propulsion  Power  Telemetry Tracking  Command TT&C  Command  Data Handling C&DH  Structure  Thermal CERs were also developed for integration assembly and test IA&T program management PM and systems engineering SE and launch and orbital operations support LOOS Individual subsystem cost estimates are statistically rolled up to yield a cost-risk distribution which provides the estimator with a range of cost estimates andpercentiles 8 The SSCM was calibrated from over 100 post-1990 Earth-orbiting andplanetary missions REFERENCES 1 Lack of Disciplined Cost-Estimating Processes Hinders Effective Program Management GAO study 04-642 2 Jilla Cyrus D and Miller David W Satellite Design Past Present and Future International Journal of Small Satellite Engineering 12 February 1997 3 Bearden David A A Complexity Based Risk Assessment of Low-Cost Planetary Missions:When Is A Mission Too Fast and Too Cheap Fourth IAA International Conference On Low-Cost Planetary Missions JHU/APL MAY 2-5 2000 4 Kellogg Mahr and Lobbia An Analogy-based Method for Estimating the Costs of Spacecraft IEEEAC paper 1371 Version 4 5 Hoeting Jennifer A Methodology for Bayesian Model Averaging An Update f 6]btp/ewiieiao iiAaos 7 Keith Smith NASA/Air Force Cost Model Science Applications International Corporation 8 18 


BIOGRAPHIES Lee Fischman served as Principle Investigator for this project Lee is Senior Director of Development at Galorath Incorporated where he directs much of the new product development and research at the firm He developed SEER for Software  Hardware Integrations with Microsoft Project the Comparison Sizing tool COTS Software model in addition to various data mining information extraction and expert systems Previously he was a software designerlprogrammer in the New York financial industry Lee earned a BA from the University of Chicago and an MA from UCLA both in economics Mike Kimel carried out statistical work on the project Mike is an Economist for Galorath Inc in addition to maintaining his own quantitative consulting practice He has also taught Economics and Advanced Statistics at the Graziadio School of Business and Management at Pepperdine University run the Competitive Strategy group for a Fortune 500 Telecom Company and worked as a Consultant at PriceWaterhouse LLC now PriceWaterhouse-Coopers He earned a Ph.D in Economicsfrom UCLA Troy Masters programmed analytic methods and is integrating the Far Out model into its parent product SEER for Hardware previously SEER-H Troy is a Software Engineer with Galorath Incorporated where he has been the primary developer for a range ofproducts He earned a BS in computer science from UCLA David J Pine was our subject matter expert helping us assemble data and gain insight into technical trends Dave is retired after a 34-year career with the National Aeronautics and Space Administration NASA currently is a consultant to various government and industry entities While at NASA his organizations in the Office of the Chief Financial Officer and later at the IPAO at Langley Research Center were responsible for the conduct of major NASA program analyses and evaluations for the NASA Administrator and Deputy Administrator From early 1988 through the end of 1990 he was the Deputy Program Manager for the Hubble Space Telescope Program specifically responsible for the telescope operations and science support aspects of the program He earned a BS in Aerospace Engineering from the Polytechnic Institute of Brooklyn and a Masters of Engineering Administration from the George Washington University 19 


  20 Angeles, where he also received a B.S. in Applied Mathematics  Eric Fetzer is a Senior Member of the Technical Staff at the Jet Propulsion Laboratory, Pasadena, California specializing in satellite observations of the atmosphere.  His scientific interests include planetary boundary layer processes, tropical phenomena, upper tropospheric variability, and climatologies of temperature, water vapor and clouds.  His technical interests include analysis of large data sets, and of multi-sensor observations. He has over 20 peer-reviewed publications and given numerous scientific presentations, public lectures and media interviews about climate science. Eric received a B.A. in Physics from the University of California Berkeley, and a Ph.D. in Astrophysical, Planetary and Atmospheric Sciences from the University of Colorado, Boulder   Amy Braverman is a Senior Statistician at the Jet Propulsion Laboratory, California Institute of Technology She holds a B.A. in Economics from Swarthmore College an M.A. in Mathematics from UCLA, and a Ph.D. in Statistics also from UCLA. Prior to her current position in JPL's Science Data Understanding Group, she was a Caltech Post-doctoral Scholar at the Jet Propulsion Laboratory, and a Scientist in the Flight Sciences Experiments Section of the Science Division. Dr Braverman conducts research on information-theoretic methods for the analysis of massive data sets and streams statistical data fusion, high-dimensional data analysis, and statistical analysis for climate model evaluation and diagnosis. She has published in both the statistics and geoscience literature, and is active in both communities She is a member of the Multi-angle Imaging SpectroRadiometer Science Team, and serves as a member of the Atmospheric Infrared Sounder Science Integration Team. Her responsibilities on both missions include designing data reduction algorithms for massive, remote sensing data sets. Dr. Braverman also holds an appointment in the Department of Statistics at UCLA as Adjunct Associate Professor, and is active in UCLA\222s Center for Environmental Statistics. She is member of the Committee on Applied and Theoretical Statistics of the US National Academy of Science. She has refereed for the Journal of the American Statistical Association, the Journal of Computational and Gr aphical Statistics, IEEE Transactions on Geoscience and Remote Sensing, and the Journal of Applied Meteorology and Climatology Seungwon Lee is a senior member of the High Capability Computing and Modeling Group at Jet Propulsion Laboratory. She is conducti ng research on comet gas dynamics, nonlinear dynamics control, climate model parameterization, Earth science data analysis, parallel computing, and advanced numerical algorithms. She received her Ph.D in Physics fr om the Ohio State University and her M.S. and B.S. in Physics from the Seoul National University, Korea  Matthew Henderson is software engineer in the High Capability Computing and Mode ling group at JPL. His current work includes Web Services and Instrument Data Level 2 subsetting. He received a B.S. Computer Science from CSU Pomona, and is currently pursuing M.S Computer Science  Steven J. Lewis is a member of the Information System and Computer Science staff member at the Jet Propulsion Laboratory.  He received a BS in Mathematics from the University of California, Los Angeles in June 2001, and the MS and Ph.D. Degree from Claremont Graduate University in May 2004 and May 2007, respectively.  He worked as a post doctoral fellow at Keck Graduate Institute from June 2007 until he joined JPL in March of 2008.  During his graduate and post doctoral work, his studies focused on applications of Bayesian methods to hidden Markov models with particular interest and application to protein sequencing.  His work at JPL has focused on integrating web services into various programming platforms for the purposes of accessing NASA satellite data, as well as developing object tracking so ftware and contributing to image enhancement and restoration efforts Van Dang is a member of the Science Data Understanding Group at the Jet Propulsion Laboratory. She was responsible for the NEWS Level 2 processing that generated the formal merged Level 2 data from multiple A-Train instruments  Manuel de la Torre is a Physicist from the Universidad Complutense at Madrid \(Spain\. After finishing his Ph.D work at the University of Bayreuth \(Germany\ on pattern formation in turbulent flows and a 7 1/2 year stunt as Ass and Assoc. Prof. at the Escuela T\351cnica Superior de Ingenieros Aeron\341uticos in Madrid \(Spain\, he came to the Jet Propulsion Laboratory on a 1-year Sabatical leave in 1997 wanting to apply fundamental concepts of nonlinear systems and geophysical fluid dynamics to something that might be directly useful to soci ety. He discovered the JPL as a great place to achieve that goal and extende d his stay a bit longer, becoming Technical staff and working on different aspects of remote sensing, validation of satellite instruments, and data analysis of atmospheric processes and climate  


