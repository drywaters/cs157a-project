Multi-Objective Genetic Algorithm Based Approach for Optimizing Fuzzy Sequential Patterns Mehmet KAYA Department of Computer Engineering Frat University 23119, Elaz  Turkey kaya@firat.edu.tr Reda ALHAJJ ADSA Lab, Department of Computer Science University of Calgary Calgary, Alberta, Canada alhajj@cpsc.ucalgary.ca Abstract This paper introduces the optimized sequential pattern problem and presents a novel approach to find such patterns All the methods described in the literature to optimize association rules employ a single objective measure, such as optimized confidence or optimized support. In this study, we 
propose a novel multi-objective Genetic Algorithm \(GA based optimization method for optimizing quantitative sequential patterns. The objective measures of are support confidence and a parameter related to the total number of fuzzy sets in the sequence. Experimental results on a synthetic database demonstrate the effectiveness and applicability of the proposed method 1. Introduction Mining sequential patterns in large databases has become an important data mining task with broad applications, including business analysis, web mining security and bio-sequences analysis. This approach was first introduced by Agrawal and Srikant [1 f o r  ma r k e t  
basket analysis and can be stated as follows: a sequential pattern is an expression Y X  where X and Y are disjoint sets of items. This expression may be interpreted as: if a customer buys X item/items, then he/she will buy Y item/items with a high probability. First efforts on mining sequential patterns focused on binary valued attributes. While some of them concentrate on mining traversal patterns in web surfing [2 t h e o t h e r s i n v o l ve  shopping sequences in malls, traveling sequences in a tour, plan failure predictions nd ge n e t i c s e que n c e s  
5  H o w e v e r   th e im p o r t an ce o f a t tr i b u t es w i t h  quantitative values was later realized because most of transactional data that exist in real world applications include quantitative attributes. As a result the trend to study has slide towards this direction [6, 7  T h e c l as s i c  algorithm proposed for mining quantitative association or sequential rules discretizes or reduces the domain into interval or categorical [8   A trend to deal with the problem of sharp boundary is based on fuzzy theory. For this purpose, some work has been recently done on the use of fuzzy sets in discovering 
sequential patterns for quantitative attributes [6, 7   Th e patterns obtained by this way are called fuzzy sequential patterns. If meaningful linguistic terms are assigned to fuzzy sets, the fuzzy sequential pattern is more understandable. However, the main problem in existing approaches is that an expert must provide the required fuzzy sets of quantitative attributes and their corresponding membership functions. Also, it is not a realistic method that experts must always provide the most appropriate fuzzy sets for fuzzy association rules mining. This appropriateness can change with respect to 
the criteria user focused on. Existing approaches to overcome this problem can be classified as either based on clustering methods [9  o r e m pl o y G A  b a s e d  methods   In this paper, we propose a novel method based on multi-objective GA for determining the most appropriate fuzzy sets in sequential pattern mining such that the optimized support and confidence rules will be obtained For this purpose, we take into account three measures of the objectives for multi-objective GA problem. Each individual in a population represents a separate sequence In this sense, the objectives are support that indicates the 
percentage of records belonging to that individual confidence and a parameter related to the total number of fuzzy sets in the itemsets. So, the optimized fuzzy sequential patterns are obtained by considering three important criteria. Experimental results obtained using synthetic SALES Database demonstrate that our approach performs well and gives good results even for a larger number of attributes The rest of the paper is organized as follows. Related work is presented in Section 2. Sequential patterns are defined in Section 3. The multi-objective optimization problem is introduced in Section 4. Our approach of 
utilizing multi-objective GA is described in Section 5 Experimental results are reported in Section 6. Section 7 is the conclusions 2. Related Work Existing approaches to find appropriate fuzzy sets for fuzzy association rules mining are mainly classified into two categories. The first is concerned with clustering Proceedings of the 16th IEEE International Conference on Tools with Artificial Intelligence \(ICTAI 2004 1082-3409/04 $20.00  2004 IEEE 


methods and the other employs GA based approaches Under the first category, Fu et al 9  pr op os e d a n  automated method to find fuzzy sets for the mining of fuzzy association rules; their method is based on CLARANS clustering algorithm [14 W e de v e l o pe d a  more efficient approach based on CURE clustering algorithm [10  G y en es ei  1 5  p r o p o s ed a m e t h o d t o f i n d  the fuzzy sets for each quantitative attribute by using clustering techniques. All these studies use a clustering technique and the membership functions of a quantitative attribute are generated with respect to centers of clusters So, no optimization measure is taken into account. The only important point is the distribution of values of quantitative attributes. However, in the second category GA based methods tune the base values of membership functions of quantitative attributes according to an optimization scheme. For instance, Mata et al   presented a technique to find large itemsets in quantitative databases without needing to discretize the attributes Recently, an increase has been observed in the number of such studies [12, 13 w h e r e o p t i m i z e d  m e a s u r e s i n c l ude  number of large itemsets in a given interval of minimum support or number of large itemsets in small time Another optimization problem, introduced by Fukoda et al 16  pr op os e s a n  a p pr oa c h t o d e t e r m i n e bou n d a r i e s  for the intervals of attributes such that the confidence or support of the rule is maximized. The method was used for non-fuzzy domains. Then, Rastogi and Shim  improved the optimized association rule problem such that association rules were allowed to contain a number of uninstantiated attributes. Recently, Ghosh and Nath  proposed a multi-objective rule mining algorithm using genetic algorithms Table 1 A data set grouped by customers Customer ID Transaction Time Purchased Items June 15, 2003 A, 8\, \(B,4 1 June 24, 2003 C, 6\, \(D, 5 June 5, 2003 A, 6 June 11, 2003 C, 2\, \(D, 3 2 June 28, 2003 A, 8\, \(B, 9 3. Sequential Patterns Given a database of customer transactions, where each transaction includes a customer ID, transaction time and some purchased items, where each item is represented by a tuple \(item name, item amount\. On such a database, a sequential pattern is defined as follows Definition 1 Let    1 n x x I  be a set of items, each possibly associated with a set of attributes, such as value or price. The value of attribute A in item x is denoted as x.A An itemset is a non-empty subset of items, and an itemset with k items is called k itemset A sequence    1 l X X s  is an order list of itemsets and an itemset  1  l i X i   in a sequence is called a transaction In a set of sequences, a sequence s is maximal if s is not contained in other sequences 4. Multi-Objective Optimization Multi-objective optimization deals with simultaneous optimization of several incommensurable and often competing objectives such as performance and cost. For example, when the design of a complex hardware is considered, it is required for the cost of such a system to be minimized while maximum performance is expected If there is more than one objective criterion as in the example mentioned above, some of them can be considered as constraints in the problem. For example while trying to optimize a system for large performance and low cost, the size of the system must not exceed given dimensions is a separate optimization criterion. This way a multi-objective optimization problem can be formalized as follows Definition 2 A multi-objective optimization problem includes a set of a parameters \(called decision variables a set of b objective functions, and a set of c constraints objective functions and constraints are functions of the decision variables. The optimization goal is expressed as Y y y y y X x x x x x e x e x e x e x f x f x f x f y b a c b                   where 0          contraints          max min 2 1 2 1 2 1 2 1 where x is decision vector y is objective vector X denotes decision space, and Y is called objective space; the constraints 0    x e determine the set of feasible solutions In this paper, we considered the values of support and confidence utilized in the sequential patterns mining process, a parameter handling the amplitude of the interval and number of attributes together as objective functions. These measures are computed as follows The fuzzy support of a sequence C B A   is defined as the fraction of transactions that contain C B A U U  where A  B and C are items of the sequence. Formally        D C B A Support C B A Support U U    where D is the size of database The confidence of a sequence is the ratio of the support of C B A U U to the support of B A U        B A Support C B A Support C B A Confidence U U U    In this study, the other important measure, i.e Fuzzy Set-Attribute is found by the following formula attributes the of sets fuzzy of number imum the of total sequence the in sets fuzzy of number total Attribute Set Fuzzy max      k i i w sequnces of sets fuzzy of number total 1      m i i w attributes the of sets fuzzy of number imum the of total 1   max Proceedings of the 16th IEEE International Conference on Tools with Artificial Intelligence \(ICTAI 2004 1082-3409/04 $20.00  2004 IEEE 


where m is the number of attributes in the database k is the number of attributes in the sequence and i l is the maximum number of fuzzy sets for attribute i  The above proposed formula generates sequences with both larger fuzzy sets and number of attributes, i.e., we obtain maximal sequences. The next example demonstrates the superiority of the proposed formula Example 1 Consider the sequence C B A   and assume that we have 6 attributes in a database and their maximum fuzzy sets are 5. If we have a sequence  4   3   4  sets C sets B sets A   and the total number of their fuzzy sets is 11, then: Fuzzy Set-Attribute of  4   3   4  sets C sets B sets A     5 6 11  0.36 On the other hand, if we have a sequence  4   4  sets C sets A  then: Fuzzy Set-Attribute of  4   4  sets C sets A   5 6 8  0.26 The latter sequence is eliminated because the former is a maximal sequence. In this regard, a solution defined by the corresponding decision vector can be better than worse or equal to, but also indifferent from another solution with respect to the objective values. Better means a solution is not worse in any objective and better with respect to at least one objective than another. Using this concept, an optimal solution can be defined as a solution which is not dominated by any other solution in the search space Such a solution is called Pareto optimal  and the entire set of optimal trade-offs is called the Pareto-optimal set  Explicitly, the objectives in such an optimization problem are conflicting and cannot be optimized simultaneously. Instead a satisfactory trade-off has to be found. Therefore, it is necessary to have a decision making process in which preference information is used in selecting an appropriate trade-off 5 Multi-Objective GA Based Process In this section, we describe the proposed method for mining optimized fuzzy sequential patterns by employing a Pareto-optimality based multi-objective GA. We first present our encoding scheme and then define the fitness assignment and selection criteria. Finally, we give the algorithmic structure of the proposed approach 5.1. Chromosome Encoding We use the support, confidence and the ratio of the number of fuzzy sets in the sequence to the total number of fuzzy sets as objectives of the multi-objective GA approach employed in determining optimized fuzzy sequential patterns. The values of support and confidence of a rule are maximized in large number of fuzzy sets According to our intuition, stronger rules can be mined with larger number of fuzzy sets because more appropriate fuzzy rules can be found as the number of fuzzy sets increases This section describes the generation of the initial population, where each individual represents the base values of membership functions of a quantitative attribute in the database. We used membership functions in triangular shape To illustrate the encoding scheme utilized in this study, membership functions for a quantitative attribute i k having 3 fuzzy sets and their base variables are shown in Figure 1. Each base variable takes finite values. For instance, the search space of base value 1 k i b lies between the minimum and maximum values of i k denoted  min k i D and  max k i D respectively. Enumerated next to Figure 1 are the search intervals of all the base values and the intersection point k i R of attribute i k  small medium large 1 k i b 2 k i b 3 k i b 4 k i b  i k   min k i D  max k i D k i R   max  min   max      min   max  min   max  min  4 3 2 1 k k k k k k k k k k k k k k k i i i i i i i i i i i i i i i D D b D R b R D b D D R D D b Figure 1 Membership functions and base variables of attribute i k So, based on the assumption of having 3 fuzzy sets per attribute, as it is the case with i k a chromosome consisting of the base lengths and the intersection point is represented as 4 3 2 1 4 3 2 1 4 3 2 1  2 2 2 2 2 1 1 1 1 1 m m m m m i i i i i i i i i i i i i i i b b R b b b b R b b b b R b b  Since it is not possible to know a priori how many attributes will be n ecessary to create a good sequential pattern, this number has to be automatically adjusted by the GA based on the data being mined. Finally, the structure of the genome of an individual is illustrated by  1 1 1 B w v  j j j B w v  m m m B w v where m is the number of attributes j v represents the part \(consequent or antecedent\ in which attribute j will appear. If the value of j v is 00, then j will be available in neither of these parts However, if the value of j v is 11, then j will appear in either part. On the other hand, if it is 01 or 10 then j will appear in consequent or antecedent, respectively j B is the set of variables used to represent the base lengths and the intersecting points corresponding to attribute j Further, gene j i w denotes the number of fuzzy sets for attribute j i If the number of fuzzy set is 2, then the first two base variables are considered while decoding the individual, the others are omitted. However, if j i w is raised to 3, then the next three variables are taken into account as well. So, as the number of fuzzy sets increases Proceedings of the 16th IEEE International Conference on Tools with Artificial Intelligence \(ICTAI 2004 1082-3409/04 $20.00  2004 IEEE 


the number of variables to be taken into account is enhanced too In the experiments we used binary coding; while the value of a variable \(gene\ is reflected under its own search interval, the following formula is employed   min  max 1 2  min k i k i L k i k i j j j j b b d b b     where d is the decimal value of the variable in search L is the number of bits used to represent a variable in the encoding scheme  min k i j b and  max k i j b are, respectively, the minimum and maximum values of the reflected area 5.2. Fitness Assignment and Selection As mentioned earlier, in multi-objective problems both fitness assignment and selection must allow for several objectives. One of the methods used for fitness assignments is to make direct use of the Pareto dominance concept. In this concept, fitness value of individuals is computed using their ranks, which are calculated from their non-dominance property. The ranking step tries to obtain the non-dominated solutions. According to this step, if c i chromosomes dominate an individual then its rank is assigned as c i 1. This process continues until all the individuals are ranked. After computing the fitness value of each individual, individuals with the smallest rank constitutes the highest fitness. Finally, selection \(we have adopted elitism policy in our experiments replacement, crossover and mutation operators are applied to form a new population as in standard GA The whole multi-objective GA process employed in this study can be summarized as follows Algorithm for mining optimized fuzzy sequential rules Input: population size N maximum number of generations G crossover probability c p mutation rate m p Output: Nondominated set S 1. Set   0 P and 0  t  For h=1 to N do a\ Select I i  based on some probability distribution where i is an individual and I is its space b\ Set  i P P   0 0 2. For each individual t P i   a\ Determine the encoded decision and objective vectors b\alculate the scalar fitness value   i F with respect to the approach mentioned above 3. Set    P For h=1 to N do a Select one individual t P i  with respect to its fitness value   i F b\ Set  i P P     4. Set     P For h=1 to N/2 do a Select two individuals P j i    remove them from P  b Recombine i and j the resulting offspring are I l k   c Insert l k  into P   with probability c p otherwise insert j i  into P   5. Set      P  For each individual P i    do a Mutate i with mutation rate m p The resulting individual is I j  b\ Set  j P P          6. Set P P t      1 and 1   t t  If G t  or the threshold-based reproduction stability is satisfied then return   t P p S  where   t P p gives the set of nondominated decision vectors in t P In other words the set   t P p is the nondominated set regarding t P  Otherwise go to Step 2, i.e., execute steps 2 to 6 The algorithm starts by selecting individuals to the initial population. Then the following process is repeated until the threshold-based reproduction stability termination condition is satisfied or the prespecified maximum number of generations is achieved. The encoded decision vector and objective vector as well as the fitness value are all determined for each selected individual. Existing individuals are used in generating new ones by applying cross-over and mutation Individuals survive based on their fitness and are used in the process. This way, the nondominated set is determined and the target is achieved The process of mining fuzzy association rules starts by employing multi-objective GA for tuning membership functions in each generation according to the adjusted number of fuzzy sets and their base values. However while adjusting membership functions of attribute i k by GA, each value of i k intersects with one or more of its membership functions. Therefore, membership functions do not generally have a uniform structure. Based on this i k undergoes a normalization process, which is mainly a transformation that leads to a total contribution of 1.0 for i k The normalization is performed as follows    k i k k k k k k l p k v p i i k v j i i k v j i i i t f i t f i t f 1 1                where k i l is the number of fuzzy sets related to i k      k v j i i i t f k k  is the membership degree in the j th fuzzy set for the value of i k in transaction t v  6. Experimental Results In this section, we report the results of the experiments conducted to analyze the proposed optimization method All the experiments were conducted on a Celeron 2.0 GHz CPU with 512 MB of memory and running Windows XP. As experimental data, a synthetic SALES database with 20 attributes and 20K transactions was generated using a randomized transaction generation Proceedings of the 16th IEEE International Conference on Tools with Artificial Intelligence \(ICTAI 2004 1082-3409/04 $20.00  2004 IEEE 


algorithm. In the experiments, crossover and mutation probabilities are arbitrarily taken as 0.8 and 0.01 respectively, and 5-point crossover operator is used Table 2 Number of generated rules vs number of generations Number of Rules for Number of Generations FS2 FS3 FS4 FS5 MOGA 250 74 67 53 31 68 500 121 82 62 38 104 750 154 91 65 39 127 1000 173 93 66 39 133 1250 178 93 66 40 135 1500 178 93 66 40 136 The first experiment finds the number of rules generated for different numbers of generations. The results are reported in Table 2. Columns 2-5 show the results obtained for cases when the number of fuzzy sets is fixed at 2, 3, 4 and 5, respectively. The last column deals with finding number of fuzzy sets and optimizing ranges of membership functions. Table 2 shows that as the number of fuzzy sets increases, the numbers of rules decrease. Also, a faster convergence is observed for larger number of fuzzy sets. Although the numbers of rules found by MOGA are between FS2 and FS3, the average number of fuzzy sets determined by MOGA is 3.6  0 20 40 60 80 100 0 5 10 15 20 25 30 35 40 Support Confidence FS3 MOGA Figure 2 Non-dominated solutions found The second experiment investigates the distribution of the non-dominated solutions found in case of FS3 and MOGA. The results in Figure 2 only show the support and confidence dimensions. The solution density in the left hand side of Figure 2 is higher, which is an expected case because larger rules are generated for small values of minimum support. Another density region is observed in case minimum support is around 20%. This region constitutes the most effective part of the solutions 7. Conclusions In this paper, we contributed to the ongoing research on sequential pattern mining by proposing a multiobjective GA based method for mining optimized sequential patterns. Our approach uses three measures as objectives, namely: support, confidence and fuzzy setattribute. The advantage of the proposed method is to directly find maximal sequences for different cases. The results obtained from the conducted experiments demonstrate the effectiveness and applicability of the optimized patterns References 1 R A g ra w a l a n d R  S r i k a n t  M in in g S e q u e n ti a l P a t t e r n s   Proc. of IEEE ICDE Taiwan, 1995 2 M   S  C h e n  J  S Pa r k  P S Y u   E f f i c i e n t  d a t a m i n i n g f o r  path traversal patterns IEEE TKDE Vol.10, No.2 pp.209-221, 1998 3 J  P e i J  H a n  B  M o r t a z a v iA s l, H  Z h u   M i n in g a c c e s s  pattern efficiently from web logs Proc. of PAKDD  pp.396-407, 2000 4 M J  Z a k i N  L e s h M  O g ih a r a   P l a n M in e  S e q u e n c e  mining for plan failures, Proc. KDD, pp. 369-374, 1998 5 J  T  W a n g  G  W  C h i r n  T  G   M a r r  B  S h a p i r o  D   Shasha, K. Zhang, Combinatorial pattern discovery for scientific data: some preliminary results Proc. ACM SIGMOD pp. 115-125, 1994 6 T  P  H o n g  C  S  K u o  S  C  C h i   M i n i n g F u z z y  Sequential Patterns from Quantitative Data Proc. of IEEE SMC Conference pp. 962-966, 1999 7 T  P  H o ng  K  Y  L i n  S L  W a ng   M i n i n g f u z z y  sequential patterns from multiple-item transactions Proc of IFSA World Congress and NAFIPS International Conference pp. 1317-1321, 2001 8 R S r ik a n t a n d R  A g ra w a l   M in i n g q u a n t it a t iv e  association rules in large relational tables Proc. of ACM SIGMOD pp.1-12, 1996 9 A  W  C  Fu e t al    F i n di ng Fuz zy Set s f o r t h e M i ni ng of  Association Rules for Numerical Attributes Proc. of IDEAL pp.263-268, 1998 10 M  Ka y a  R  A l h a jj F  P o la t a n d A  A r s l a n    E ffi c i e n t Automated Mining of Fuzzy Association Rules Proc. of DEXA 2002  J  Ma t a  J  L  A l v a r e z  J  C  R i qu el m e   D i s c o v e r i ng  Numeric Association Rules via Evolutionary Algorithm Proc. of PAKDD pp. 40-51, 2002  M K a y a and R  A l haj j  A C l ust e r i ng A l g o r i t h m w i t h  Genetically Optimized Membership Functions for Fuzzy Association Rules Mining Proc. of IEEE-FUZZ 2003 13 M  Ka y a a n d R  A l h a jj  F a c ili ta ti n g F u z z y  A s s o c i a t i o n  Rules Mining by Using Multi-Objective Genetic Algorithms for Automated Clustering Proc. of IEEE ICDM 2003  N g  R  and H a n  J   E f f i c i e n t a nd ef f e c t i v e c l ust er i n g  methods for spatial data mining Proc. of VLDB 1994 15 G y e n e s i A    D e t e r min i n g F u z z y S e t s fo r Qu a n ti ta ti v e  Attributes in Data Mining Problems Proc. of Advance in Fuzzy Systems and Evol. Comp pp.48-53, 2001  T  Fukud a Y  Mo r i m o t o  S Mo r i sh i t a and T  T o kuy am a  Mining Optimized Association Rules for Numeric Attributes Proc. of ACM PODS 1996  R  R a s t o g i an d K  Sh i m   M i n i n g O p t i m i z e d A s s o c i at i o n Rules with Categorical and Numeric Attributes IEEE TKDE Vol.14, No.1, pp.29-50, 2002  G h o s h A  and N a t h  B    M u l t i O bj ec t i v e R u l e M i n i ng  using Genetic Algorithms Information Science Volume 163, Issues 1-3, 14 June 2004, Pages 123-133 Proceedings of the 16th IEEE International Conference on Tools with Artificial Intelligence \(ICTAI 2004 1082-3409/04 $20.00  2004 IEEE 


Table 2. Identified parameter of the model C1 2.62274E-05 C;! -0.001015643 C3 0.01436588 C4 -0.065519084 269 2500 2000 i - 1500  i 1000 500 o _Measured __ Predicted 9 17 25 33 41 49 57 65 73 81 89 97 105 113 121 129 137 numer Of measurements Figure 5. The calculated and the measured time by different database parameter settings To calculate the error of the model the following function was defmed \(also used in [9 e= ?i: lfi - l i n i=1 2 where n is the number of the measurements, fi is the measured time and!;" is the calculated time Figure 5 shows the calculated and the measured execution times by all the different parameter settings where the minimum support threshold changes from 0.5 tom 1 %. It is clearly visible in Figure 5 that the prediction function follows well the behaviour characteristics of the real execution times when varying the different parameters. The average relative error of the model calculated according to Equation 2 was 1 n If; -ll e=-L I I =0.123445 n i=1 f 3 VII. MODEL V ALIDA nON After the model identification process several measurements were taken to validate the model. Table 3 contains the synthetic database parameters that were used during the model validation Figure 6 shows the measured mining time and the predicted mining time by the different datasets. It is possible to realise that the model follows well the measured execution time In some cases, especially in case of low support values the relative error of the model can be the double \(max 30 Table 3. Synthetic dataset parameters during the model validation T 18,22 7,8 D 50K, lOOK, 250K 270 The average relative error of the model calculated according to Equation 2 was e=? tlh -ll n 1=4 h 0.133185 \(4 The average error ratio is not significantly different from the error ratio of the identified model. Therefore the introduced performance model can be used for predicting the execution time of the Apriori algorithm in the investigated dataset parameter and support value intervals VIII. CONCLUSION In this paper a basic level-wise association rule mining algorithm, the Apriori algorithm was developed and its analytical performance model was introduced. Three input parameters were taken into the consideration in this model Two parameters, namely the number of transactions and average size of transactions describes the input dataset The third parameter, the minimum support threshold is the input parameter of the mining process. The constant 


input parameter of the mining process. The constant parameters of the model can be identified by few measurements using least square method A simple formula was given to anticipate the performance of the algorithm, described welI the behaviour of the data mining algorithm for a wide range of parameters. The main contribution of the paper was predicting the behaviour of a complex probability based data mining algorithm in a relatively simple, closed numerical form allowing a good estimation of execution times The model was validated by comparing the calculated and measured performance. Experimental results showed that the suggested model is reasonably accurate in a wide domain having an average error below 15 percent 1 2 3 4 5- 6 1 S 9 10 11 12 13 14 15 16 17 1$ 19 2\(121 22 23 204 25  16 27 2S 29 30 I ....... M88$urai - p,.:lided I Figure 6_ Model validation: the C11lculated and the measured time The introduced model can be used not only for predicting execution times of the Apriori algorithm, but also for predicting the response time of the other level-wise association rule mining algorithms. The reason behind this is that these algorithms are based on the Apriori algorithm thus they inherit several properties from it. Of course the identification of the constants in the formula must be repeated when moving to different algorithm in the same way as when moving to different hardware environments IX. ACKNOWLEDGEMENTS This work was supported by IBM Hungary and the fund of the Hungarian Academy of Sciences for control research and the Hungarian National Research Fund \(grant number T042741 X.REFERENCES 1] R. Agrawal, T. Imielinski and A.Swami, "Mining association rules between sets of items of large databases" in Proc. of the ACM SIGMOD Int/'/ Conf On Management of Data, Washington, D.C.,USA 1993, pp 207-216 2] R. Agrawal and R. Srikant, "Fast algorithms for mining association rules" in Proc. 20'h Very Large Databases Conference, Santiago, Chile, 1994, pp 487-499 3] J. S. Park, M. Chen, and P. S. Yu, "An effective hash based algorithm for mining association rules" in Proc of the 1995 ACM Int. Con/. on Management of Data San Jose, California, USA, 1995, pp. 175-186 4] S.Brin, R. Motawani, J.D. Ullman and S. Tsur Dynamic Item set counting and implication rules for market basket data" in Froc. of the ACM SIGMOD Inti '1 Con/. On Management of Data, Tucson Arizona, USA, 1997, pp. 255-264 5] M. J. Zaki, "Scalable algorithms for association mining", IEEE Transaction on Knowledge and Data Engineering, Vol 12. No 3. May/June 2000, pp. 372390 6] J.Han, J. Pei and Y. Yin, "Mining frequent patterns without candidate generation" in Proc. of the 2000 ACM-SIGMOD Int'l Conf. On Management of Data Dallas, Texas, USA, 2000, pp. 1-12 71 David R. Helman, David A. Bader, and Joseph Jara A randomized parallel sorting algorithm with an experimental study", Journal of Parallel and Distributed Computing, 52\(1 8] J. Landrum, J. Hardwick, and Q.F. Stout, "Predicting algorithm performance", Computing Science and Statistics, 30, 1998, pp. 309  314 9] P. Cremonesi and C. Gennaro, "Integrated Performance Models for SPMD Applications and MIMD Architectures", IEEE Transactions on Parallel and Distributed Systems, Vol. 13, No.7., 2002, pp 745-757 


745-757 10] U. Meyer et aI., Algorithms for Memory Hierarchies LNCS 2625, Springer-Verlag, Berlin, 2003, pp. 32035 4 11] Mohammed J. Zaki, "Scalable Algorithms for 271 Association Mining", IEEE Transaction on Knowledge and Data Engineering, Vo1.l2, No.3 2000, pp. 372-390 pre></body></html 


support count, the smaller the best cutting level 0 5 10 15 20 25 30 35 40 1 2 3 4 5 6 Cutting level T im e s ec  Figure 8. Execution times of CBW for various  s with minsup count = 12 0 1 2 3 4 5 36912 Minimum support count B es t  Figure 9. Evolution of the best cutting level under different minsups 4.2 Synthetic database We next compared the four algorithms on the synthetic data sets under different minsups. The results were shown in Figures 10, 11 and 12. Our observations were as follows 1. CBW outperformed all other methods in all cases 2. While all algorithms suffered from the combinatorial exploration of itemsets due to low support constraints, our CBW exhibited the best in maintaining its performance 3. The longer the itemsets become, the worse all four algorithms performed. The reason is that the cost for candidate generation, support counting Proceedings of the 37th Hawaii International Conference on System Sciences - 2004 0-7695-2056-1/04 $17.00 \(C and conditional pattern and FP-tree construction grows as the itemset length increases 0 400 800 1200 1600 2000 0.0 0.5 1.0 1.5 2.0 2.5 minsup T im e se c  CBW FP-growth Partition Apriori Figure 10. Execution times of Apriori, Partition 


Figure 10. Execution times of Apriori, Partition FP-growth and CBW on T15.I4.D200K 0 400 800 1200 1600 2000 2400 0.0 0.5 1.0 1.5 2.0 2.5 minsup T im e se c  CBW FP-growth Partition Apriori Figure 11. Execution times of Apriori, Partition FP-growth and CBW on T15.I6.D200K We also evaluated the execution times of CBW under different cutting levels \(minsup = 1.0 influence of minsup to the cutting levels. We only showed the results for T6.I4.D100K in Figure 13 and 14; similar results were observed for the other datasets The results conformed to those observed in Figures 8 and 9 Finally, we conducted an experiment to evaluate the scalability of the four algorithms. The results were shown in Figure 15, where we omitted Apriori because its performance was significantly inferior to the others As the figure showed, our CBW exhibited the best in scalability while FP-growth exhibited the worst 0 400 800 1200 1600 2000 2400 0.0 0.5 1.0 1.5 2.0 2.5 minsup T im e se c  CBW FP-growth Partition Apriori Figure 12. Execution times of Apriori, Partition FP-growth and CBW on T15.I8.D200K 0 20 40 60 80 100 120 1 2 3 4 5 6 Cutting level T im e s ec  


Figure 13. Execution times of CBW on T6.I4.D100K for various  s 5. Concluding remarks 5.1. Summary In this paper, we have described a new efficient algorithm for frequent itemsets mining. Unlike contemporary algorithms that either adopt a top-down or a bottom-up traversal throughout the itemset lattice to search for frequent itemsets, our algorithm employs a clever guess on the most promising itemset level cutting-level there. Then it performs a downward search, followed by an upward search to discover all other frequent itemsets. Empirical study showed that our algorithm is more than an order of magnitude faster than the Apriori variants Proceedings of the 37th Hawaii International Conference on System Sciences - 2004 0-7695-2056-1/04 $17.00 \(C 01 2 3 4 5 0.25%0.50%0.75%1.00 minsup B es t cu tt in g l ev el Figure 14. Evolution of the best cutting level for CBW under different minsups, running on T6.I4.D100K Our CBW algorithm has been incorporated into an online multidimensional association rule mining system currently under development [10]. In the future we will incorporate into CBW the taxonomy information and extend it to allow multiple minimum support specification [13 0 100 200 300 400 500 600 700 800 2 4 6 8 10 12 14 16 18 20 Number of transactions \(x 10,000 T im e s ec  CBW FP-growth Partition Figure 15. Scalability evaluation of CBW, FPgrowth and Partition running on T15.I8.D200K with minsup = 1.0 5.2. Comparison with related work To our knowledge, [9] is the only work on combining the top-down and the bottom-up searches for association mining. But their approach and 


for association mining. But their approach and intention are quite different from ours First, rather than starting from the middle of the search space and progressively searching towards both ends, their approach proceeds from both ends of the search lattice and progressively searches towards the middle Second, their approach aims at discovering, instead of all frequent itemsets, the maximal frequent itemsets i.e., itemsets having no supersets, which work is quite simple compared to the work for discovering all frequent itemsets. Furthermore, on applying their approach to the work of frequent itemsets mining, the top-down pruning" technique on which their approach relies will become useless because the subsets of a frequent itemset found in top-down search still have to been counted to know their supports. In this way, the top-down search becomes unnecessary and their method will degenerate to the Apriori algorithm On the contrary, we believe that our method can be adapted to the problem of mining maximal frequent itemsets [1][3][9]. Indeed, we are currently working on applying our CBW to this problem and hope to have result in the near future References 1] R.C. Agarwal, C.C. Aggarwal, and V.V.V. Prasad Depth first generation of long patterns," in Proceedings of 6th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, 2000, pp 108?118 2] R. Agrawal and R. Srikant, "Fast Algorithms for Mining Association Rules," in Proceedings of the 20th VLDB Conference, 1994, pp. 487?499 3] R.J. Bayardo Jr., "Efficiently Mining Long Patterns from Databases," in Proceedings of 1998 ACM SIGMOD International Conference on Management of Data Seattle, Washington, USA, 1998, pp. 85?93 4] S. Brin, R. Motwani, J.D. Ullman, and S. Tsur Dynamic Itemset Counting and Implication Rules for Market Baseket Data," SIGMOD Record, Vol. 26, 1997 pp. 255?264 5] Database Research Group in the Department of Computer Science and Engineering at the Chinese University of Hong Kong http://www.cse.cuhk.edu.hk/~kdd/program.html 6] J. Han, J. Pei, and Y. Yin, "Mining Frequent Patterns Without Candidate Generation," in Proceedings of the 2000 ACM SIGMOD International Conference on Management of Data, Dallas, TX, USA, 2000, pp. 1?12 7] J. Hipp, U. Guntzer, and G. Nakhaeizadeh, "Algorithms for Association Rule Mining?A General Survey and Comparison," SIGKDD Explorations, Vol. 2, 2000, pp 58?64 8] J. Hipp, U. Guntzer, and G. Nakhaeizadeh, "Mining Association Rules: Deriving a Superior Algorithm by Analyzing Today  s Approaches," in Proceedings of 4th European Symposium on Principles of Data Mining and Knowledge Discovery \(PKDD  00 9] D. Lin and Z.M. Kedem, "Pincer-search: An Efficient Algorithm for Discovering the Maximum Frequent Set Proceedings of the 37th Hawaii International Conference on System Sciences - 2004 0-7695-2056-1/04 $17.00 \(C IEEE Transactions on Knowledge and Data Engineering, Vol. 14, No. 3, 2002, pp. 553?566 10] W.Y. Lin, J.H. Su and M.C. Tseng, "OMARS: The Framework of an Online Multi-dimensional Association Rules Mining System," in Proceedings of the 2nd International Conference on Electronic Business, Taipei Taiwan, 2002, pp. 216?225 11] J.S. Park, M.S. Chen, and P.S. Yu, "An Effective HashBased Algorithm for Mining Association Rules," in Proceedings of the 1995 ACM SIGMOD International 


Proceedings of the 1995 ACM SIGMOD International Conference on Management of Data, San Jose, CA USA, 1995, pp. 175?186 12] A. Savasere, E. Omiecinski, and S. Navathe, "An Efficient Algorithm for Mining Association Rules in Large Databases," in Proceedings of the 24th VLDB Conference, 1995, pp. 432?444 13] M.C. Tseng and W.Y. Lin, "Mining Generalized Association Rules with Multiple Minimum Supports," in Proceedings of International Conference on Data Warehousing and Knowledge Discovery, Munich Germany, 2001, pp. 11-20 14] M.J. Zaki, "Scalable Algorithms for Association Mining," IEEE Transactions on Knowledge and Data Engineering, Vol. 12, No. 2, 2000, pp. 372?390 Proceedings of the 37th Hawaii International Conference on System Sciences - 2004 0-7695-2056-1/04 $17.00 \(C pre></body></html 


per by Ganti et. al. [9] deals with the measurement of similarity \(or deviation, in the authors  vocabulary between decision trees, frequent itemsets and clusters Although this is already a powerful approach, it is not generic enough for our purpose. The most relevant research e?ort in the literature, concerning pattern management is found in the ?eld of inductive databases Proceedings of the 16th International Conference on Scientific and Statistical Database  Management \(SSDBM  04 1099-3371/04 $ 20.00  2004 IEEE meant as databases that, in addition to data, also contain patterns [10], [7]. Our approach di?ers from the inductive database one mainly in two ways. Firstly, while only association rules and string patterns are usually considered there and no attempt is made towards a general pattern model, in our approach no prede?ned pattern types are considered and the main focus lies in devising a general and extensible model for patterns Secondly, di?erently from [10], we claim that the peculiarities of patterns in terms of structure and behavior together with the characteristic of the expected workload on them, call for a logical separation between the database and the pattern-base in order to ensure e?cient handling of both raw data and patterns through dedicated management systems Finally, we remark that even if some languages have been proposed for pattern generation and retrieval 14, 11], they mainly deal with speci?c types of patterns \(in general, association rules sider the more general problem of de?ning safe and su?ciently expressive language for querying heterogeneous patterns 7. Conclusions and Future Work In this paper we have dealt with the issue of modelling and managing patterns in a database-like setting Our approach is enabled through a Pattern-Base Management System, enabling the storage, querying and management of interesting abstractions of data which we call patterns. In this paper, we have \(a de?ned the logical foundations for the global setting of PBMS management through a model that covers data patterns and intermediate mappings and \(b language issues for PBMS management. To this end we presented a pattern speci?cation language for pattern management along with safety constraints for its usage and introduced queries and query operators and identi?ed interesting query classes Several research issues remain open. First, it is an interesting topic to incorporate the notion of type and class hierarchies in the model [15]. Second, we have intentionally avoided a deep discussion of statistical measures in this paper: it is more than a trivial task to de?ne a generic ontology of statistical measures for any kind of patterns out of the various methodologies that exist \(general probabilities Dempster-Schafer, Bayesian Networks, etc. [16 nally, pattern-base management is not a mature technology: as a recent survey shows [6], it is quite cumbersome to leverage their functionality through objectrelational technology and therefore, their design and engineering is an interesting topic of research References 1] Common Warehouse Metamodel \(CWM http://www.omg.org/cwm, 2001 2] ISO SQL/MM Part 6. http://www.sql99.org/SC32/WG4/Progression Documents/FCD/fcddatamining-2001-05.pdf, 2001 3] Java Data Mining API http://www.jcp.org/jsr/detail/73.prt, 2003 4] Predictive Model Markup Language \(PMML http://www.dmg.org 


http://www.dmg.org pmmlspecs v2/pmml v2 0.html, 2003 5] S. Abiteboul and C. Beeri. The power of languages for the manipulation of complex values. VLDB Journal 4\(4  794, 1995 6] B. Catania, A. Maddalena, E. Bertino, I. Duci, and Y.Theodoridis. Towards abenchmark for patternbases http://dke.cti.gr/panda/index.htm, 2003 7] L. De Raedt. A perspective on inductive databases SIGKDD Explorations, 4\(2  77, 2002 8] M. Escobar-Molano, R. Hull, and D. Jacobs. Safety and translation of calculus queries with scalar functions. In Proceedings of PODS, pages 253  264. ACMPress, 1993 9] V. Ganti, R. Ramakrishnan, J. Gehrke, andW.-Y. Loh A framework for measuring distances in data characteristics. PODS, 1999 10] T. Imielinski and H. Mannila. A database perspective on knowledge discovery. Communications of the ACM 39\(11  64, 1996 11] T. Imielinski and A. Virmani. MSQL: A Query Language for Database Mining. Data Mining and Knowledge Discovery, 2\(4  408, 1999 12] P. Kanellakis, G. Kuper, and P. Revesz. Constraint QueryLanguages. Journal of Computer and SystemSciences, 51\(1  52, 1995 13] P. Lyman and H. R. Varian. How much information http://www.sims.berkeley.edu/how-much-info, 2000 14] R.Meo, G. Psaila, and S. Ceri. An Extension to SQL for Mining Association Rules. Data Mining and Knowledge DiscoveryM, 2\(2  224, 1999 15] S. Rizzi, E. Bertino, B. Catania, M. Golfarelli M. Halkidi, M. Terrovitis, P. Vassiliadis, M. Vazirgiannis, and E. Vrachnos. Towards a logical model for patterns. In Proceedings of ER 2003, 2003 16] A. Siblerschatz and A. Tuzhillin. What makes patterns interesting in knowledge discovery systems. IEEE TKDE, 8\(6  974, 1996 17] D. Suciu. Domain-independent queries on databases with external functions. In Proceedings ICDT, volume 893, pages 177  190, 1995 18] M.Terrovitis, P.Vassiliadis, S. Skadopoulos, E. Bertino B. Catania, and A. Maddalena. Modeling and language support for the management of patternbases. Technical Report TR-2004-2, National Technical University of Athens, 2004. Available at http://www.dblab.ece.ntua.gr/pubs Proceedings of the 16th International Conference on Scientific and Statistical Database  Management \(SSDBM  04 1099-3371/04 $ 20.00  2004 IEEE pre></body></html 


The reason of the hiding failure of SWA is the same in Fig.8 Notice the result at x = 0.7646 in Fig.14, because the hiding failure is occurred at the seeds of the sensitive patterns, a high weakness is produced As shown in Fig.15 and Fig.16, the misses cost and dissimil arity of our work decreases as RL2 increases. This is because the larger RL2 is, the less effect on non-sensitive patterns. Also weakness and dissimilarity of SWA are independent of RL2 5. Conclusion In the paper, a novel method improving the balance between sensitive knowledge protecting and discovery on frequent patte rns has been proposed. By setting entries of a sanitization matrix to appropriate values and multiplying the original database by the matrix with some probability policies, a sanitized database is gotten. Moreover, it can avoid F-I Attack absolutely when the confidence level given by users approximates to 1. The experimental results revealed that although misses cost and dissimilarity between the original and sanitized database of our process are little more than SWA, ours provide more safely protection than SWA. Unlike SWA, our sanitization process could not suffer from F-I Attack and the probability policies in our approach also take the minimum support into account, the users only need to decide the confidence level which affects the degree of patterns hiding 6. Reference 1] M. Atallah, E. Bertino, A. Elmagarmid, M. Ibrahim and V. Verykios Disclosure Limitation of Sensitive Rules", Proc. of IEEE Knowledge and Data Engineering Exchange Workshop 1999 2] R. Agrawal and R. Srikant. Fast algorithms for mining association rules. VLDB, Santiago, Chile, 1994 3] R. Agrawal and R. Srikant. Privacy preserving data mining. In ACM SIGMOD, Dallas, Texas, May 2000 4] E. Dasseni, V. Verykios, A. Elmagarmid and E. Bertino, Hiding Association Rules by Using Confidence and Support", Proc. of 4th Intl Information Hiding Workshop \(IHW 5] A. Evfimievski, J. Gehrke, and R. Srikant. Limiting Privacy Breac hed in privacy preserving data mining. SIGMOD/PODS, 2003 6] A. Evfimievski, R. Srikant, R. Agrawal, and J. Gehrke. Privacy preserving mining of association rules. KDD 2002 7] M. Kantarcioglu and C. Clifton. Privacy-preserving distributed mining of association rules on horizontally partitioned data. In ACM SIGMOD Workshop on Research Issues on Data Mining and Knowledge Discovery, June 2002 8] Guanling Lee, Chien-Yu Chang and Arbee L.P Chen. Hiding sensitive patterns in association rules mining. The 28th Annual International Computer Software and Applications Conference 9] Y. Lindell and B. Pinkas. Privacy Preserving Data mining. In CRYPTO, pages 36-54, 2000 10] S. R. M. Oliveira and O. R. Za  ane. Privacy Preserving Frequent Itemset Mining. In Proc. of IEEE ICDM  02 Workshop on Privacy Security, and Data Mining 11] S. R. M. Oliveira and O. R. Za  ane. Algorithms for Balancing Priv acy and Knowledge Discovery in Association Rule Mining. IDEAS  03 12] S. R. M. Oliveira and O. R. Za  ane. Protecting Sensitive Knowledge By Data Sanitization, ICDM  03 13] S. R. M. Oliveira, O. R. Za  ane and Y  cel Saygin. Secure Association Rule Sharing, PAKDD-04 14] Benny Pinks. Cryptographic Techniques For Privacy-Preserving D ata Mining. ACM SIGKDD Explorations Newsletter Vol. 4, Is. 2, 2002 15] S. J. Rizvi and J. R. Haritsa. Maintaining data privacy in association rule mining. VLDB, 2002 16] J. Vaidya and C. W. Clifton. Privacy preserving association rule mining in vertically partitioned data. KDD2002 17] Verykios, V.S.; Elmagarmid, A.K.; Bertino, E.; Saygin, Y.; Dasseni E. Association rule hiding. IEEE Transactions On Knowledge And Data Engineering, Vol. 16, No. 4, April 2004 Proceedings of the 29th Annual International Computer Software and Applications Conference  COMPSAC  05 0730-3157/05 $20.00  2005 IEEE pre></body></html 


pre></body></html 


Batt Power Batt Type Stabilization Type Propulsion Mechanism  of Solar Panels  of Solar Cells Manufacturing Qty Satellites in Constellation On-Orbit Spares Channels Number of Bands Data Storage Processing Power Source type Block Name Thermal Control Material Type Level of Technology Known Inheritance Propulsion station keeping Number of Axes Ground Based Spares Pointing Accuracy APPENDIX C EXISTING MODELS Numerous models are today in use for estimating spacecraft cost Two of the most common are the NASA/Air Force Cost Model and the Aerospace Small Satellite Cost Model Here is a description of the NAFCOM model The NASA/Air Force Cost Model NAFCOM is a parametric estimating toolfor space hardware It is based on historical NASA and Air Force space projects and is primarily used in the very early phases of a development project NAFCOM can be used at the subsystem or component levels The database currently includes 122 missions including 76 unmanned earth orbiting 24 unmanned planetary 11 launch vehicles 8 manned 3 engines It uses parametric relationships to estimate subsystem or component level costs for any aerospace hardware including earth orbital spacecraft manned spacecraft launch vehicle upper stages liquid rocket engines scientific instruments or planetary spacecraft 7 And for the Aerospace Small Satellite Cost Model SSCM employs a parametric methodology for estimation of program cost and is best suited to the early conceptual development phase of a spacecraft program during which time the design is likely to be less mature and when cost and performance trades can be easily performed SSCM consists of a collection of cost-estimating relationships or CERs which estimate the costs of developing andproducing a spacecraft system with the following subsystems  Attitude Determination and Control Subsystem ADCS  Propulsion  Power  Telemetry Tracking  Command TT&C  Command  Data Handling C&DH  Structure  Thermal CERs were also developed for integration assembly and test IA&T program management PM and systems engineering SE and launch and orbital operations support LOOS Individual subsystem cost estimates are statistically rolled up to yield a cost-risk distribution which provides the estimator with a range of cost estimates andpercentiles 8 The SSCM was calibrated from over 100 post-1990 Earth-orbiting andplanetary missions REFERENCES 1 Lack of Disciplined Cost-Estimating Processes Hinders Effective Program Management GAO study 04-642 2 Jilla Cyrus D and Miller David W Satellite Design Past Present and Future International Journal of Small Satellite Engineering 12 February 1997 3 Bearden David A A Complexity Based Risk Assessment of Low-Cost Planetary Missions:When Is A Mission Too Fast and Too Cheap Fourth IAA International Conference On Low-Cost Planetary Missions JHU/APL MAY 2-5 2000 4 Kellogg Mahr and Lobbia An Analogy-based Method for Estimating the Costs of Spacecraft IEEEAC paper 1371 Version 4 5 Hoeting Jennifer A Methodology for Bayesian Model Averaging An Update f 6]btp/ewiieiao iiAaos 7 Keith Smith NASA/Air Force Cost Model Science Applications International Corporation 8 18 


BIOGRAPHIES Lee Fischman served as Principle Investigator for this project Lee is Senior Director of Development at Galorath Incorporated where he directs much of the new product development and research at the firm He developed SEER for Software  Hardware Integrations with Microsoft Project the Comparison Sizing tool COTS Software model in addition to various data mining information extraction and expert systems Previously he was a software designerlprogrammer in the New York financial industry Lee earned a BA from the University of Chicago and an MA from UCLA both in economics Mike Kimel carried out statistical work on the project Mike is an Economist for Galorath Inc in addition to maintaining his own quantitative consulting practice He has also taught Economics and Advanced Statistics at the Graziadio School of Business and Management at Pepperdine University run the Competitive Strategy group for a Fortune 500 Telecom Company and worked as a Consultant at PriceWaterhouse LLC now PriceWaterhouse-Coopers He earned a Ph.D in Economicsfrom UCLA Troy Masters programmed analytic methods and is integrating the Far Out model into its parent product SEER for Hardware previously SEER-H Troy is a Software Engineer with Galorath Incorporated where he has been the primary developer for a range ofproducts He earned a BS in computer science from UCLA David J Pine was our subject matter expert helping us assemble data and gain insight into technical trends Dave is retired after a 34-year career with the National Aeronautics and Space Administration NASA currently is a consultant to various government and industry entities While at NASA his organizations in the Office of the Chief Financial Officer and later at the IPAO at Langley Research Center were responsible for the conduct of major NASA program analyses and evaluations for the NASA Administrator and Deputy Administrator From early 1988 through the end of 1990 he was the Deputy Program Manager for the Hubble Space Telescope Program specifically responsible for the telescope operations and science support aspects of the program He earned a BS in Aerospace Engineering from the Polytechnic Institute of Brooklyn and a Masters of Engineering Administration from the George Washington University 19 


  20 Angeles, where he also received a B.S. in Applied Mathematics  Eric Fetzer is a Senior Member of the Technical Staff at the Jet Propulsion Laboratory, Pasadena, California specializing in satellite observations of the atmosphere.  His scientific interests include planetary boundary layer processes, tropical phenomena, upper tropospheric variability, and climatologies of temperature, water vapor and clouds.  His technical interests include analysis of large data sets, and of multi-sensor observations. He has over 20 peer-reviewed publications and given numerous scientific presentations, public lectures and media interviews about climate science. Eric received a B.A. in Physics from the University of California Berkeley, and a Ph.D. in Astrophysical, Planetary and Atmospheric Sciences from the University of Colorado, Boulder   Amy Braverman is a Senior Statistician at the Jet Propulsion Laboratory, California Institute of Technology She holds a B.A. in Economics from Swarthmore College an M.A. in Mathematics from UCLA, and a Ph.D. in Statistics also from UCLA. Prior to her current position in JPL's Science Data Understanding Group, she was a Caltech Post-doctoral Scholar at the Jet Propulsion Laboratory, and a Scientist in the Flight Sciences Experiments Section of the Science Division. Dr Braverman conducts research on information-theoretic methods for the analysis of massive data sets and streams statistical data fusion, high-dimensional data analysis, and statistical analysis for climate model evaluation and diagnosis. She has published in both the statistics and geoscience literature, and is active in both communities She is a member of the Multi-angle Imaging SpectroRadiometer Science Team, and serves as a member of the Atmospheric Infrared Sounder Science Integration Team. Her responsibilities on both missions include designing data reduction algorithms for massive, remote sensing data sets. Dr. Braverman also holds an appointment in the Department of Statistics at UCLA as Adjunct Associate Professor, and is active in UCLA\222s Center for Environmental Statistics. She is member of the Committee on Applied and Theoretical Statistics of the US National Academy of Science. She has refereed for the Journal of the American Statistical Association, the Journal of Computational and Gr aphical Statistics, IEEE Transactions on Geoscience and Remote Sensing, and the Journal of Applied Meteorology and Climatology Seungwon Lee is a senior member of the High Capability Computing and Modeling Group at Jet Propulsion Laboratory. She is conducti ng research on comet gas dynamics, nonlinear dynamics control, climate model parameterization, Earth science data analysis, parallel computing, and advanced numerical algorithms. She received her Ph.D in Physics fr om the Ohio State University and her M.S. and B.S. in Physics from the Seoul National University, Korea  Matthew Henderson is software engineer in the High Capability Computing and Mode ling group at JPL. His current work includes Web Services and Instrument Data Level 2 subsetting. He received a B.S. Computer Science from CSU Pomona, and is currently pursuing M.S Computer Science  Steven J. Lewis is a member of the Information System and Computer Science staff member at the Jet Propulsion Laboratory.  He received a BS in Mathematics from the University of California, Los Angeles in June 2001, and the MS and Ph.D. Degree from Claremont Graduate University in May 2004 and May 2007, respectively.  He worked as a post doctoral fellow at Keck Graduate Institute from June 2007 until he joined JPL in March of 2008.  During his graduate and post doctoral work, his studies focused on applications of Bayesian methods to hidden Markov models with particular interest and application to protein sequencing.  His work at JPL has focused on integrating web services into various programming platforms for the purposes of accessing NASA satellite data, as well as developing object tracking so ftware and contributing to image enhancement and restoration efforts Van Dang is a member of the Science Data Understanding Group at the Jet Propulsion Laboratory. She was responsible for the NEWS Level 2 processing that generated the formal merged Level 2 data from multiple A-Train instruments  Manuel de la Torre is a Physicist from the Universidad Complutense at Madrid \(Spain\. After finishing his Ph.D work at the University of Bayreuth \(Germany\ on pattern formation in turbulent flows and a 7 1/2 year stunt as Ass and Assoc. Prof. at the Escuela T\351cnica Superior de Ingenieros Aeron\341uticos in Madrid \(Spain\, he came to the Jet Propulsion Laboratory on a 1-year Sabatical leave in 1997 wanting to apply fundamental concepts of nonlinear systems and geophysical fluid dynamics to something that might be directly useful to soci ety. He discovered the JPL as a great place to achieve that goal and extende d his stay a bit longer, becoming Technical staff and working on different aspects of remote sensing, validation of satellite instruments, and data analysis of atmospheric processes and climate  


