2004 IEEE International Conference on Systems Man and Cybernetics Hiding Sensitive Items in Privacy Preserving Association Ru.le Mining Shyue-Liang Wang Yu-Huei Lee Steven Billis Ayat Jafari Department of Computer Science New York Institute of Technology New York USA slwang@nyit.edu Absfrad  Pi-ivacy-preserving data mining 3 has recent!y emerged to address one of the negative side.7 of data mining technology: the threat to individual privacy For example, through data mining one 
is able to ii,fer sensitive information, including personal information or even patterns om non-sensitive information or unclassified data There have been two broad approaches for privacy-preserving data mining Thefirst approach is to alter the data before delivery to the data miner so 221hat real values are obscured The second approach assumes the data is distributed between two or more sites md these sites cooperate to leam the global data mining results without revealing the data at their individual sites Given specifc rules to be hidden, many data altering techniques for hiding association classification rind clustering rules have 
been proposed However to specih hidden rules entire data mining process needs to be executed For some applications we are only interested in hiding certain sensitive items In this work we assume that only sensitive items are given and propose wo algorithms to mod data in database so that sensitive items cannot be inferred through association rules mining algorithms Examples illustrating the propo::ed algorithms are given The efficiency of the propo::ed approach is further compared with Dasseni etcs 9 approach It is shown that our approach required less number of databases scanning andprune more number of hidden rules However, our approach must hide all rules 
containing the hidden items on the right hand side wh,?re Dasseni\222s approach can hide speciJic rules Keywords privacy preserving data mining association rule 1 Introduction The concept of privacy preserving data mining has been recently been proposed in response to the concerns of preserving personal information from data mining algorithms 3 141 There have been two broad approaches The first approach is to alter the data before delivery lo the data miner so that real values are obscured One technique of this approach 
is to selectively modify individual values from a database to prevent the discovery  0-7803-8566-7/04/$20.00 0 2004 IEEE of a set of.rules  They apply a group of heuristic solutions for reducing the number of occurrences support of some frequent large itemsets below a minimum user specified threshold The advantage of this technique is that it maximizes the amount of available data although it does not ensure the integrity of the data The second approach is to allow users access to only a subset of 
data while global data mining results can still he discovered Given specific rules to he hidden many data altering techniques for hiding association classification and clustering rules have been proposed However to specify hidden rules entire data mining process needs to be executed For some applications we are only interested in hiding certain sensitive items that appeared in association rules In this work we assume that only sensitive items are given and propose two algorithms to modify data in database so that sensitive items cannot 
be inferred through association rules mining algorithms The proposed algorithms are based on modifying the database transactions so that the confidence of the association rules can be reduced Examples demonstrating the proposed algorithms are shown The efficiency of the proposed approach is further compared with Dasseni etc\222s 191 approach It is shown that our approach required less number of databases scanning and prune more number of hidden rules However our approach must hide all rules containing the hidden items on the right hand side, where Dasseni\222s approach can 
hide specific rules The rest of the paper is organized as follows Section 2 presents the statement of the problem and the notation used in the paper Section 3 presents the proposed algorithms for hiding association rules that contain the specified sensitive items Section 4 shows some examples of the proposed algorithms Section 5 analyses the result of the efficiency of proposed algorithms and further compare with Dasseni etc approach Concluding remarks and future works are described in section 6 3239 


2 Problem Statement 2.1 Mining of Association Rules The problem of mining association rules was introduced in Z Let I   i i i  be a set of literals, called items Given a set of transactions D where each transaction T is a set of items such that T E I an association rule is an expression X 5 Y where xcl Ycl and XnY The Xand Y are called respectively the body left hand side and head right hand side of the rule An example of such a rule is that 90 of customers buy hamburgers also buy Coke The 90 here is called the confidence of the rule which means that 90 of transaction that contains X also contains Y The confidence is calculated as The support of the rule is the percentage of transactions that contain both X and Y which is calculated as IXUYl 1x1  In other words the confidence of a rule IXUYl N measures the degree of the correlation between itemsets while the support of a rule measures the significance of the correlation between itemsets The problem of mining association rules is to find all rules that are greater than the user-specified minimum support and minimum confidence As an example for a given database in Table 1 a minimum support of 33 and a minimum confidence of 70 nine association rules can be found as follows B=>A 66 loo C=>A 66 loo B=>C SO 50 75 BC=>A\(50 loo C=>AB\(SO 75 75 C=>B 50 75 AB=>C 50 75 AC=>B B=>AC\(SO 75 Table 1 Database D pi ABC I T4 I AB I The objective of data mining is to extract hidden or potentially unknown interesting rules or patterns from databases However the objective of privacy preserving data mining is to hide certain sensitive information so that they cannot be discovered through data mining techniques 1,4-12,151 In this work we assume that only sensitive items are given and propose two algorithms to modify data in database so that sensitive items cannot be inferred through association rules mining algorithms More specifically given a transaction database D a minimum support, a minimum confidence and a set of items H to be hidden the objective is to modify the database D such that no association rules containing H on the right hand side will be discovered As an example for a given database in Table 1 a minimum support of 33 a minimum confidence of 70 and a hidden item H  C if transaction T5 is modified as AB then the followiiig rules that contain item C on the right hand side will be hidden B=>C 50 60 AB=>C 50 60 B=>AC\(50 60 The following notation will be used in the paper Each database transaction has three elements T=<TID list-of-elements size The TID is the unique identifier of the transaction 7 and list-of-elements is a list of all items in the database However each element has value 1 if the corresponding item is supported by the transaction and 0 otherwise Size means the number of elements in the list-of-elements having value 1 For example if I  A,B,C a transaction that has the items A C will be represented as 1  T1,101,2 In addition a transaction t supports an itemset I when the elements of t.list-of-elements corresponding to items of I are all set to 1 A transaction tpartially supports an itemset I when the elements are not all set to 1 For example ifI  A,B,C  111],p=<T1,[111],3 andq=<T2,[001],1 thenwe would say that p supports I and q partially supports I 3 Proposed Algorithms In order to hide an association rule we can either decrease its support or its confidence to be smaller than pre-specified minimum support and minimum confidence To decrease the confidence of a rule we can either 1 increase the support ofX i.e the left hand side of the rule but not support of X U Y or 2 decrease the support of the itemset X U Y For the second case if we only decrease the support of Y the right hand side of the rule it would reduce the confidence faster than simply reducing the support ofX U Y To decrease support of an item we will modify one item at a time by changing from 1 to 0 or from 0 to 1 in a selected transaction Based on these two strategies we propose two data mining algorithms for hiding sensitive items in association rules namely Increase Support of LHS First \(ISLF and Decrease Support of RHS First DSRF The fxst algorithm tries to increase the support of left hand side of the rule If it was not successful it tries to decrease the support of the right hand side of the rule The second algorithm reverses the order of the first algorithm The detail of the ISLF algorithm is described as follow 3240 


Algorithm ISLF Input 1\a source database D 2 a min-support 3 a min-confidence 4 a set of hidden items H OutDut a transformed database D\222 where rules 1 2 3 4 5 6 7 8 containing H on RHS will he hidden Find large I-item sets from D  For each hidden item h E H If H is empty, then EXIT no AR contains H in RHS Find large 2-itemsets from D  For each h E H  If h is not a large I-itemset then H  H-{h  For each large 2-itemset containing h  Compute confidence of rule U where U is a rule ofx h 9 IO 11 12 Repeat  13 14 15 16 Until  confidence\(U min-conf or TJ is 17 18 19 20 21 Repeat  22 23 24 25 26 27 28 29 Else 30 3 1 32 Remove h from H 33   end of for each h E H Output updated D as the transfonnedD\222 If Confidence  min-conf then  Increase Support of LHS Find TI   f in D 1 f partially supports LHS U  Sort TI in descending order by the number of supported items  Choose the first transaction f from TI  Modify I to support LHS U  Compute support and confidence of U    empty 1    end if confidence>min-conf Ifconfidence  min-conf then Decrease Find T2   f in D I f supports RHS U  Sort T in descending order by the number of Support of RHS supported items  Choose the first transaction I from Tz Modify f to partially support RHS\(U  Compute support and confidence of U  Until  confidence\(U\<min-conf or T,is empty     end if confidence>min-conf If Confidence  min-conf then CAN NOT HIDE h  Update D with new transaction I   end of for each large 2-itemset 4 Examples This section shows four examples for demonstrating the two proposed algorithms in hiding sensitive item in the association rules mining For a given database in Table I a minimum sup~~ort of 33 and a minimum confidence of 70 the first two examples hide the sensitive items using the ISLF algorithm The difference of the two examples is that the order of hiding item is different The first example hides item C and then item B The second example hides item B and then item C The result is given in section 4.1 The thud and fourth examples hide the sensitive items using DSRF algorithm The difference is also the order of items to he hidden The result is given in section 4.2 Table 2: Database D using the specified notation 4.1 Examples Running ISLF Algorithm EramDle 1 Assuming that the min-supp  33 and min-conf  70 the result of hiding item C and then item Busing ISLF algorithm is as follows To hide item C the rule B  C SO 75%\will be hidden if transaction T is modified from 100 to 110 using ISL Increase Support of LHS The new database DI is shown in Table 3 The rule B  C will have support  50 and Confidence  60 To hide item B the rule A  B 67 83 will be hidden if transaction T is modified from 111 to 101 using DSR Decrease Support of RHS The new database D2 is shown in Table 3 The rule A  B will have support  67% and confidence  67 Example 2 As in example 1, reversing the order of hiding items the result of hiding item B and then item C using ISLF algorithm is as follows To hide item B the rule C  B SO 75 will be hidden if transaction Ts is modified from 100 to 101 using ISL The new database D3 is shown in Table 4 The rule C  B will have support  50% and confidence  60 To hide item C the rule A  C 83 83 will he hidden if transaction TI is modified from 111 to 110 using DSR The new database D4 is shown in Table 4 The rule A  C will have support  83 and confidence  67 Table 3 I latahases before and after hiding item 1 C and item 3241 


Table 4 Databases before and after hiding item B and item One observation is that different sequences of hiding items will result in different transformed databases i.e D5 and D6 5 Analysis This section analyzes some of the characteristics of the proposed algorithms and compares with the algorithms proposed in Dasseni etc 9 The first Dasseni\222s la 4 One observation we can make is that different sequences of hiding items will result in different transformed databases i.e D2 and D 4.1 Examples Running DSRF Algorithm ExamDle 3 Assuming that the min_supp=33 and min_conf=70 the result of hiding item C and then item B using DSRF algorithm is as follows To hide item C the rule B  C 50 75 will be hidden if transaction TI is modified from 11 1 to 110 using DSR The new database DJ is shown in Table 5 The rule B  C will have support  33 and confidence  50 To hide item B the rule C  B 50 67 will be hidden due to transaction TI is modified Table 5 Databases before and after hidine item C and item 0 I Examnle 4 As in example 3 reversing the order of hiding items the result of hiding item B and then item C using DSRF algorithm is as follows To hide item B the rule C  B 50 75 will be hidden if transaction TI is modified from 11 1 to 101 using DSR The new database D6 is shown in Table 6 The rule C  B will have support  33 and confidence  50 To hide item C the rule B  C 33 67 will be hidden due to transaction TI is modified characteristics we show is that the transformed databases are different under different ordering of hiding items even though the same set of sensitive items is specified This characteristic is demonstrated in the four examples in section 4 and is summarized in Table 7 Databases D2 and D are resulting databases using ISLF algorithm and D5 and Da are resulting databases using DSRF algorithm Table 7 Databases before and after hiding items B and C The second characteristic we analyze is the efficiency of the proposed algorithm compared with the Dasseni\222s etc algorithms Even though it is the hidden rules, instead of hidden items, that are specified in we compare the number of database scanning and the number of rules pruned between the two approaches Table 8 summarizes the results For ISLF algorithm the number of database scanning comes from the calculation of large one itemsets large two itemsets and partial support transactions TI The rules pruned are B  AC and AB  C For Dasseni\222s la algorithm the number of database scanning comes from the calculation of large one itemsets large two itemsets large three itemsets and partial support transactions T No rules are pruned in the Dasseni\222s la algorithm It can be seen that the ISLF algorithm requires less database scanning and prune more number of Table 6 Databases before and after hiding item B and item C using DSRF association rules Similar results are obtained for comparing DSRF algorithm and Dasseni\222s lb algorithm Table 8 Database scans and rules pruned in hiding item C Pruned 3242 


One of the reasons that Dasseni\222s approach does not prune rules is that hidden rules are given in advance and the algorithms try to hide every single rule without checking to see if rules can be pruned after some transactions have been changed However our approach needs to hide all rules containing hidden items on the right hand side But Dasseni\222s approach can hide some of the rules containing hidden item on the right hand side For example for hidden item C Dasseni\222s approach can hide A  C but show B  C whereas our approach must hide both A  C and B  C The third characteristic we analyze is efficiency comparison of the ISLF and DSRF algorithms One observation we conclude from the examples in section four is that DSRF algorithm seems to be more effective when the support count of the hidden item is large This is due to when support of right hand side of the rule is large increase support of left hand side usually does not reduce the confidence of the rule However decrcase support of right hand side usually decreases the confidence of the rule 6 Conclusions In this work we have studied the database privacy problems caused by data nuning technology and proposed two nahe algorithms for hiding sensitive data in association rules mining The proposed algorithms are based on modifying the database transactions so that the confidence of the association rules can be reduced Examples demonstrating the proposed algorithms are shown The efficiency of the proposed approach are further compared with Dasseni\222s approach  It 221#as shown that ow approach required less number of datatiase scanning and prune more number of hidden rules However our approach must hide all rules containing the hidden items on the right hand side where Dasseni\222s approach can hide some of the specified rules In addkion more simulation must be carried out to show the feasibility and efficiency of the proposed algorithms References I D Agrawal and C. C Aggarwal 223On the design and quantification of privacy preserving data mining algorithms\224 In Proceedings of the 20th Symposium on Principles of Database Systems Santa Barbara Califomia USA May 2001 R Agrawal T Imielinski and A Swami 223Mining Association Rules between Sets of Items in Lirge Databases\224 In Proceedings of ACM SIGMOD International Conference on Management of Data Washington DC May 1993 2 3 R Agrawal and R Srikant 224Privacy preserving data mining\224 In ACM SIGMOD Conference on Management of Data pages 439450 Dallas Texas May 2000  Ljiljana Brankovic and Vladimir Estivill-Castro 223Privacy Issues in Knowledge Discovery and Data Mining\224 Australian Institute of Computer Ethics Conference, July 1999 Lilydale 5 C Clifton and D Marks 221Security and Privacy Implications of Data Mining\224 in SIGMOD Workshop on Research Issues on Data Mining and knowledge Discovery 1996 6 C Clifton 223Protecting Against Data Mining Through Samples\224 in Proceedings of the Thirteenth Annual IFIP WG 11.3 Working Conference on Database Security, 1999 C Clifton, \223Using Sample Size to Limit Exposure to Data Mining\224 Journal of Computer Security 8\(4 2000 Chris Clifton Murant Kantarcioglu Xiaodong Lin and Michael Y Zhu 221\221 Tools for Privacy Preserving Distributed Data Mining\224 SIGKDD Explorations 4\(2 1-7 Dec 2002 E Dasseni V Verykios A Elmagamid and E Bertino 223Hiding Association Rules by Using Confidence and Support\224 in Proceedings of 4\222h Information Hiding Workshop 369-383 Pittsburgh PA 200 I IO A Evfimievski R Srikant R Agrawal and J Gehrke 223Privacy preserving mining of association rules\224 In Proc Of the 8th ACM SIGKDD Int\222l Conference on Knowledge Discovew and Data Mining Edmonton, Canada, July 2002  1 I Alexandre Evfimievski 223Randomization in Privacy Preserving Data Mining\224 SIGKDD Explorations 4\(2\Issue 2,43-48 Dec 2002  121 Alexandre Evfimievski Johannes Gehrke and Ramakrishnan Srikant 223Limiting Privacy Breaches in Privacy Preserving Data Mining\224 PODS 2003 June 9-12,2003, San Diego, CA  131 M. Kantarcioglu and C Clifton, \223Privacy-preserving distributed mining of association rules on horizontally partitioned data\224 In ACM SIGMOD Workshop on Research Issues on Data Mining and Knowledge Discovely June 2002 14 Y Lindell and B Pinkas 223Privacy preserving data mining\224 In CRYPTO pages 36-54,2000 IS D E 0\222 Leary, \223Knowledge Discovery as a Threat to Database Security\224 In G Piatetsky-Shapiro and W J Frawley editors Knowledge Discovery in Databases, 507-5 16 AAA1 Pressi MIT Press Menlo Park, CA, 1991 I61 S Oliveira 0 Zaiane 223Algorithms for Balancing Priacy and Knowledge Discovery in Association Rule Mining\224 Proceedings of 71h International Database Engineering and Applications Symposium IDEAS03 Hong Kong July 2003 7 XI 9 3243 


I71 S Oliveira 0 Zaiane 223Protecting Sensitive Knowledge by Data Sanitization\224 Proceedings of IEEE International Conference on Data Mining November 2003 IS S J Rizvi and J R Haritsa 223Privacy-preserving association rule mining\224 In Proc of the 28th Int Conference on Vely Large Databases August 2002 I91 Y Saygin V Verykios and C Clifton 223Using Unknowns to Prevent Discovery of Association Rules\224 SIGMOND Record 30\(4 45-54 December 2001 20 J Vaidya and C.W Clifton 223Privacy preserving association rule mining in vertically partitioned data\224 In Proc of the 8Ih ACM SIGKDD Int\222l Conference on Knowledge Discovely and Data Mining Edmonton Canada July 2002.A A Author 223My best paper yet\224 Proc Best Conference in the World BestCity,pp 11-18,March2001 3244 


Aware Home. IEEE Personal Communications, 2000 2] Millennium Homes: A technology support domestic environment for frail and elderly people http://www.brunel.ac.uk/depts/cs/research/index.shtml?mill enium \(available 16.1.2004 3] MIT  s Oxygen project, http://oxygen.lcs.mit.edu available 16.1.2004 4] H. Kautz, D. Fox, O. Etzioni, G. Borriello, and L Arnstein. An Overview of the Assisted Cognition Project Intel Research, 2002 5] D.J. Patterson, L. Liao, D. Fox, and H. Kautz. Inferring High-Level Behavior from Low-Level Sensors. 5th Int Conference on Ubiquitous Computing \(UbiComp 2003 October 12-15, 2003 6] E. Horvitz, J. Breese, D. Heckerman, D. Hovel K.Rommelse. The Lumiere Project: Bayesian User Modeling for Inferring the Goals and Needs of Software Users. Proc. 14th Conf. Uncertainty in Artificial Intelligence, pp. 256-265, 1998 7] D. Pyle, Data Preparation for Data Mining, Morgan Kaufmann Publishers, 1999 8] S. Pirttikangas, J. Riekki, S. Porspakka, J. R  ning Know Your Whereabouts. Communication Networks and Distributed Systems Modeling and Simulation Conference CNDS'04 accepted 9] J.M  ntyj  rvi, J. Himberg, and T. Sepp  nen Recognizing Human Motion with Multiple Acceleration sensors. Proc. IEEE Int. Conf. Systems, Man, and Cybernetics, pp. 747-752, 2001 10] J. M  ntyj  rvi, J. Himberg, P. Korpip  and H Mannila. Extracting the Context of a Mobile Device User IFAC Symposium on analysis, design, and evaluation of human-machine systems, pp. 445-450, 2001 11] V.-M. M  ntyl  J. M  ntyj  rvi, T. Sepp  nen, and E Tuulari. Hand Gesture Recognition of a Mobile Device User. Proc. IEEE Int. Conf. Multimedia and Expo \(ICME 2000  284, 2000 12] A. Schmidt, K.A. Aidoo, A. Takaluoma, U. Tuomela K. Van Laerhoven, and W. Van de Velde. Advanced Interaction in Context. Handheld and Ubiquitous Computing, First International Symposium, Karlsruhe Germany, pp. 89-101, 1999 13] R. Agrawal, H. Mannila, R. Srikant, H. Toivonen, and A. I. Verkamo. Fast Discovery of Association Rules Advances in Knowledge Discovery and Data Mining AAAI Press / The MIT Press, 1996 14] J. Hipp, U. Guntzer, and G. Nakhaeizadeh. Algorithms for Association Rule Mining  A General Survey and Comparison. SIGKDD Explorations, pp. 58-64, 2000 15] Inc. Ekahau. Ekahau Positioning Engine 2.0 Technical report, Ekahau Inc., 2002 16] J. M  ntyj  rvi. Sensor-based context recognition for mobile applications. PhD thesis, VTT Publications University of Oulu, 2003 Proceedings of the International Conference on Information Technology: Coding and Computing  ITCC  04 0-7695-2108-8/04 $ 20.00  2004 IEEE pre></body></html 


 acg abeg   In virtue of the algorithms in section 3.3 we get IR 001 8   a bc ce g   Finally we get to know that the approximate intent core of concept 8 consists of two attributes a and g  by applying Property 5 4.3 Extracting Association Rules On the basis of approximate intent reducts extracting association rules is quite a simple job which can be done as follows Concept c  A B  is frequent if  A t G 327 001 For each frequent concept c  A B   let us 223rstly calculate all its 002 approximate intent reducts IR 001  c   And then for each R 001IR 001  c  anassociationrule R 006 B 212 R would be derived The correctness of such extracted association rules is easy to prove Since c is frequent and R 002 B wehave   R b  B 212 R  001    B 001    A    G 327 001  Because R is a 002 approximate intent reduct of c wehave   R 002  B 212 R  001   R 001   B 001 R 001 t 002  In addition each association rule can be mapped to exactly one concept For each association rule 215 P 006 Q 216 holding in the given context concept  P b Q  001   P b Q  001\001  is also called the host concept Such a mapping is helpful in the proof of the completeness of the method for tracting association rules Before we dive into the problem let us consider the following inference rules for association rules Property 6 Given support threshold 001 and con\223dence reshold 002  if association rule P 006 Q holds then P 006 Q 1 must hold for any Q 1 002 Q  Property 7 Given support threshold 001 and con\223dence reshold 002  if association rule P 006 Q b W holds then P b W 006 Q must hold For any association rule S 006 T that holds let c  A   S b T  001 B  A 001  S b T  001\001  be the host concept There must exist some 002 approximate intent reduct R of c such that R 002 S  Therefore association rule R 006 B 212 R is extracted by the method at the beginning of this subsection Let W  S 212 R Wehave B 212 R  B 212 S  b  S 212 R   B 212 S  b W From R 006 B 212 R 017 R 006  B 212 S  b W  we could infer R b W 006  B 212 S  017 S 006 B 212 S by Property 7 Due to the fact that T 002 B  S 006 T could also be inferred from S 006 B 212 S  5 Conclusions This paper presents the de\223nitions of intent reducts and approximate intent reducts serving as the theoretical foundation for extracting attribute implications and association rules The properies of them are studied and algorithms are developed for their computation We also give out the methods for extracting attribute implications or association rules The resulting set of rules are shown to be complete with respect to some inference rules Futher research work will focus on removing redundancy from the resulting rule sets Acknowledgments This work was funded in part by the Science  Technology Commission of Shanghai Municipality under grant number 03ZR14014 by the project sponsored by SRF for ROCS SEM and by the National Natural Science Fund of China No 60275022 References 1 R  A g r a w l T  I m ielin sk i an d A  S w a m i  M in in g a sso ciation rules between sets of items in large databases In Proc ACM SIGMOD International Conference on Management of Data Washington D.C May 1993 pp 207-216 2 B  G an ter  R  W ille F o rm al Co n cep t A n a ly sis Math ematical Foundations Springer-Verlag Berlin 1999  C  Li ndi g G S n el t i ng As s e s s i ng modul ar s t ruct ure of legacy code based on mathematical concept analysis In Proc International Conference on Software Engineering Boston USA May 1997 pp 349-359  D Maier  T he Theory of R e lational Databas es  C omputer Science Press Rockville 1983 5 R  W ille Restru c tu rin g lattice th eo ry  a n a p p r o ach based on hierarchies of concepts In I Rival Eds Ordered Sets Reidel Dordrecht 1982 pp 445-470 6 Z  X ie Z Liu  Co n cep t l attice an d asso ciatio n r u l e d iscovery Computer Research and Development 2000 37\(12\1415-1421 in Chinese  Z Xie Z Liu Intent reduct of concept lattice node and its computing Computer Enginnering 2001 27\(3 911 in Chinese Proceedings of the 2005 The Fifth International Confer ence on Computer and Information Technology \(CIT\22205 0-7695-2432-X/05 $20.00 \251 2005  IEEE 


Observe that I2 is a superset of I1: it contains all closed itemsets which are under the CAM border \(as I1 plus those itemsets which arise in equivalence classes which are cut by the CAM border \(such as for instance ce and cde in Figure 3\(a Proposition 3 Cl\(FThD\(Cfreq ? CAM FThD\(Cfreq CAM Let us move to the dual problem. In Figure 3\(b show the usual equivalence classes and how they are cut by CM ? sum\(X.prices are upward closed, we have no problems with classes which are cut: the maximal element of the equivalence class will be in the alive part of the class. In other words when we have a CM constraint, the two interpretations I1 and I2 correspond Proposition 4 Cl\(FThD\(Cfreq ? CM FThD\(Cfreq CM The unique problem that we have with this condensed representation, is that, when reconstructing FThD\(Cfreq[D,?] ? CM care of testing itemsets which are subsets of elements in Cl\(FThD\(Cfreq ? CM not to produce itemsets which are below the monotone border B+\(Th\(CM not need to access the transaction dataset D anymore Since we mine maximal itemsets of the equivalence classes it is impossible to avoid this problem, unless we store, together with our condensed representation the border B+\(Th\(CM closed itemset. This could be an alternative. However since closed itemsets provide a much more meaningful set of association rules, we consider a good tradeo? among performance, conciseness and meaningfulness the use of Cl\(FThD\(Cfreq?CM resentation Finally, if we use free sets instead of closed, we only shift the problem leading to a symmetric situation. Using free sets interpretations I1 and I2 coincide when dealing with anti-monotone constraints because minimal elements are not cut o? by the constraint \(e.g. de in Fig. 3\(a constraints \(e.g. no free solution itemsets in Fig. 3\(b Proceedings of the Fourth IEEE International Conference on Data Mining \(ICDM  04 0-7695-2142-8/04 $ 20.00 IEEE 4. Algorithms In this Section we study algorithms for the computation of MP5. We ?rst discuss separately how monotone and anti-monotone constraints can be pushed in the computation, then we show how they can be exploited together by introducing the CCIMiner algorithm 4.1. Pushing Monotone Constraints Pushing CAM constraints deep into the frequent itemset mining algorithm \(attacking the problem FThD\(Cfreq[D,?] ? CAM  since they behave exactly as Cfreq . The case is di?erent for CM constraints, since they behave exactly the opposite of frequency. Indeed, CAM constraints can be used to e?ectively prune the search space to a small downward closed collection, while the upward closed collection of the search space satisfying the CM constraints cannot be exploited at the same time. This tradeo? holding on the search space of the computational problem FThD\(Cfreq[D,?] ? CM extensively studied [18, 9, 4], but all these studies have failed to ?nd the real synergy of these two opposite types of constraints, until the recent proposal of ExAnte [6]. In that work it has been shown that a real synergy of the two opposites exists and can be exploited by reasoning on both the itemset search space and the transactions input database 


set search space and the transactions input database together According to this approach each transaction can be analyzed to understand whether it can support any solution itemset, and if it is not the case, it can be pruned In this way we prune the dataset, and we get the fruitful side e?ect to lower the support of many useless itemsets, that in this way will be pruned because of the frequency constraint, strongly reducing the search space. Such approach is performed with two successive reductions  reduction \(based on monotonicity reduction \(based on anti-monotonicity to  reduction we can delete transactions which do not satisfy CM , in fact no subset of such transactions satis?es CM and therefore such transactions cannot support any solution itemsets. After such reduction, a singleton item may happen to become infrequent in the pruned dataset, an thus it can be deleted by the ?reductions. Of course, these two step can be repeated until a ?xed point is reached, i.e. no more pruning is possible. This simple yet very e?ective idea has been generalized in an Apriori-like breadth-?rst computation in ExAMiner [5], and in a FP-growth [10] based depth-?rst computation in FP-Bonsai [7 Since in general depth-?rst approaches are much more e?cient when mining closed itemsets, and since FP-Bonsai has proven to be more e?cient than ExAMiner, we decide here to use a FP-growth based depth?rst strategy for the mining problem MP5. Thus we combine Closet [16], which is the FP-growth based algorithm for mining closed frequent itemset, with FPBonsai, which is the FP-growth based algorithm for mining frequent itemset with CM constraints 4.2. Pushing Anti-monotone Constraints Anti-monotone constraints CAM can be easily pushed in a Closet computation by using them in the exact same way as the frequency constraint, exploiting the downward closure property of antimonotone constraints. During the computation, as soon as a closed itemset X s.t  CAM \(X ered, we can prune X and all its supersets by halting the depth ?rst visit. But whenever, such closed itemset X s.t  CAM \(X e.g. bcd in Figure 3\(a some itemsets Y ? X belonging to the same equivalence class and satisfying the constraint may exist \(e.g bd and cd in Figure 3\(a ery such X in a separate list, named Edge, and after the mining we can reconstruct such itemsets Y by means of a simple top-down process, named Backward-Mining, described in Algorithm 1 Algorithm 1 Backward-Mining Input: Edge, C, CAM , CM C is the set of frequent closed itemsets CAM is the antimonotone constraint CM is a monotone constraint \(if present Output: MP5 1: MP5 = C split Edge by cardinality 2: k = 0 3: for all c ? Edge s.t. CM \(c 4: E|c| = E|c| ? {c 5: if \(k &lt; |c 6: k=c generate and test subsets 7: for \(i = k; i &gt; 1; i 8: for all c ? E|i| s.t. CM \(c 9: for all \(i? 1 10: if  Y ?MP5 | s ? Y 11: if CAM \(s 12: MP5 = MP5 ? s 13: else 


13: else 14: E|i?1| = E|i?1| ? s The backward process in Algorithm 1, generates level-wise every possible subset starting from the borProceedings of the Fourth IEEE International Conference on Data Mining \(ICDM  04 0-7695-2142-8/04 $ 20.00 IEEE der de?ned by Edge without getting into equivalence classes which have been already mined \(Line 10 such subset satis?es the constraint then it can be added to the output \(Line 12 reused later to generate new subsets \(Line 14 have a monotone constraint in conjunction, the backward process is stopped whenever the monotone border B+\(Th\(CM Lines 3 and 8 4.3. Closed Constrained Itemsets Miner The two techniques which have been discussed above are independent. We push monotone constraints working on the dataset, and anti-monotone constraints working on the search space. It  s clear that these two can coexist consistently. In Algorithm 2 we merge them in a Closet-like computation obtaining CCIMiner Algorithm 2 CCIMiner Input: X,D |X , C, Edge,MP5, CAM , CM X is a closed itemset D |X is the conditional dataset C is the set of closed itemsets visited so far Edge set of itemsets to be used in the BackwardMining MP5 solution itemsets discovered so far CAM , CM constraints Output: MP5 1: C = C ?X 2: if  CAM \(X 3: Edge = Edge ?X 4: else 5: if CM \(X 6: MP5 = MP5 ?X 7: for all i ? flist\(D |X 8: I = X ? {i} // new itemset avoid duplicates 9: if  Y ? C | I ? Y ? supp\(I Y then 10: D |I= ? // create conditional fp-tree 11: for all t ? D |X do 12: if CM \(X ? t 13: D |I= D |I ?{t |I  reduction 14: for all items i occurring in D |I do 15: if i /? flist\(D |I 16: D |I= D |I \\i // ?-reduction 17: for all j ? flist\(D |I 18: if supD|I \(j I 19: I = I ? {j} // accumulate closure 20: D |I= D |I \\{j 21: CCIMiner\(I,D |I , C,B,MP5, CAM , CM 22: MP5 = Backward-Mining\(Edge,MP5, CAM , CM For the details about FP-Growth and Closet see [10 16]. Here we want to outline three basic steps 1. the recursion is stopped whenever an itemset is found to violate the anti-monotone constraint CAM Line 2 2  and ? reductions are merged in to the computation by pruning every projected conditional FPTree \(as done in FP-Bonsai [7 Lines 11-16 3. the Backward-Mining has to be performed to retrieve closed itemsets of those equivalence classes which have been cut by CAM \(Line 22 5. Experimental Results The aim of our experimentation is to measure performance bene?ts given by our framework, and to quantify the information gained w.r.t. the other lossy approaches 


approaches All the tests were conducted on a Windows XP PC equipped with a 2.8GHz Pentium IV and 512MB of RAM memory, within the cygwin environment. The datasets used in our tests are those ones of the FIMI repository1, and the constraints were applied on attribute values \(e.g. price gaussian distribution within the range [0, 150000 In order to asses the information loss of the postprocessing approach followed by previous works, in Figure 4\(a lution sets given by two interpretations, i.e. |I2 \\ I1 On both datasets PUMBS and CHESS this di?erence rises up to 105 itemsets, which means about the 30 of the solution space cardinality. It is interesting to observe that the di?erence is larger for medium selective constraints. This seems quite natural since such constraints probably cut a larger number of equivalence classes of frequency In Figure 4\(b built during the mining is reported. On every dataset tested, the number of FP-trees decrease of about four orders of magnitude with the increasing of the selectivity of the constraint. This means that the technique is quite e?ective independently of the dataset Finally, in Figure 4\(c of our algorithm CCIMiner w.r.t. Closet at di?erent selectivity of the constraint. Since the post-processing approach must ?rst compute all closed frequent itemsets, we can consider Closet execution-time as a lowerbound on the post-processing approach performance Recall that CCIMiner exploits both requirements \(satisfying constraints and being closed ing time. This exploitation can give a speed up of about to two orders of magnitude, i.e. from a factor 6 with the dataset CONNECT, to a factor of 500 with the dataset CHESS. Obviously the performance improvements become stronger as the constraint become more selective 1 http://fimi.cs.helsinki.fi/data Proceedings of the Fourth IEEE International Conference on Data Mining \(ICDM  04 0-7695-2142-8/04 $ 20.00 IEEE Information loss Number of FP-trees generated Run time performance 0 2 4 6 8 10 12 14 x 10 5 10 0 10 1 10 2 10 3 10 4 10 5 10 6 m I 2 I 1  PUMSB@29000 CHESS @ 1200 0 0.2 0.4 0.6 0.8 1 1.2 1.4 1.6 1.8 2 x 10 6 10 


10 1 10 2 10 3 10 4 10 5 10 6 10 7 m n u m b e r o f fp t re e s PUMSB @ 29000 CHESS @ 1200 CONNECT@11000 0 2 4 6 8 10 12 14 x 10 5 10 0 10 1 10 2 10 3 10 4 m e x e c u ti o n  ti m e  s e c  CCI Miner  \(PUMSB @ 29000 closet         \(PUMSB @ 29000 CCI Miner  \(CHESS @ 1200 closet         \(CHESS @ 1200 CCI Miner  \(CONNECT @ 11000 closet         \(CONNECT @ 11000 a b c Figure 4. Experimental results with CAM ? sum\(X.price 6. Conclusions 


6. Conclusions In this paper we have addressed the problem of mining frequent constrained closed patterns from a qualitative point of view. We have shown how previous works in literature overlooked this problem by using a postprocessing approach which is not lossless, in the sense that the whole set of constrained frequent patterns cannot be derived. Thus we have provided an accurate de?nition of constrained closed itemsets w.r.t the conciseness and losslessness of this constrained representation, and we have deeply characterized the computational problem. Finally we have shown how it is possible to quantitative push deep both requirements \(satisfying constraints and being closed process gaining performance bene?ts with the increasing of the constraint selectivity References 1] R. Agrawal, T. Imielinski, and A. N. Swami. Mining association rules between sets of items in large databases In Proceedings ACM SIGMOD, 1993 2] R. Agrawal and R. Srikant. Fast Algorithms for Mining Association Rules in LargeDatabases. InProceedings of the 20th VLDB, 1994 3] R. J. Bayardo. E?ciently mining long patterns from databases. In Proceedings of ACM SIGMOD, 1998 4] F. Bonchi, F. Giannotti, A.Mazzanti, andD. Pedreschi Adaptive Constraint Pushing in frequent pattern mining. In Proceedings of 7th PKDD, 2003 5] F. Bonchi, F. Giannotti, A.Mazzanti, andD. Pedreschi ExAMiner: Optimized level-wise frequent pattern mining withmonotone constraints. InProc. of ICDM, 2003 6] F. Bonchi, F. Giannotti, A.Mazzanti, andD. Pedreschi Exante: Anticipated data reduction in constrained pattern mining. In Proceedings of the 7th PKDD, 2003 7] F. Bonchi and B. Goethals. FP-Bonsai: the art of growing and pruning small fp-trees. In Proc. of the Eighth PAKDD, 2004 8] J. Boulicaut and B. Jeudy. Mining free itemsets under constraints. In International Database Engineering and Applications Symposium \(IDEAS 9] C. Bucila, J. Gehrke, D. Kifer, and W. White DualMiner: A dual-pruning algorithm for itemsets with constraints. In Proc. of the 8th ACM SIGKDD, 2002 10] J. Han, J. Pei, and Y. Yin. Mining frequent patterns without candidate generation. In Proceedings of ACM SIGMOD, 2000 11] L.Jia, R. Pei, and D. Pei. Tough constraint-based frequent closed itemsets mining. In Proc.of the ACM Symposium on Applied computing, 2003 12] H. Mannila and H. Toivonen. Multiple uses of frequent sets and condensed representations: Extended abstract In Proceedings of the 2th ACM KDD, page 189, 1996 13] R. T. Ng, L. V. S. Lakshmanan, J. Han, and A. Pang Exploratory mining and pruning optimizations of constrained associations rules. In Proc. of SIGMOD, 1998 14] N. Pasquier, Y. Bastide, R. Taouil, and L. Lakhal. Discovering frequent closed itemsets for association rules In Proceedings of 7th ICDT, 1999 15] J.Pei, J.Han,andL.V.S.Lakshmanan.Mining frequent item sets with convertible constraints. In \(ICDE  01 pages 433  442, 2001 16] J. Pei, J. Han, and R. Mao. CLOSET: An e?cient algorithm formining frequent closed itemsets. InACMSIGMODWorkshop on Research Issues in Data Mining and Knowledge Discovery, 2000 17] J. Pei, J. Han, and J. Wang. Closet+: Searching for the best strategies for mining frequent closed itemsets. In SIGKDD  03, August 2003 18] L. D. Raedt and S. Kramer. The levelwise version space algorithm and its application to molecular fragment ?nding. In Proc. IJCAI, 2001 


ment ?nding. In Proc. IJCAI, 2001 19] R. Srikant, Q. Vu, and R. Agrawal. Mining association rules with item constraints. In Proceedings ACM SIGKDD, 1997 20] M. J. Zaki and C.-J. Hsiao. Charm: An e?cient algorithm for closed itemsets mining. In 2nd SIAM International Conference on Data Mining, April 2002 Proceedings of the Fourth IEEE International Conference on Data Mining \(ICDM  04 0-7695-2142-8/04 $ 20.00 IEEE pre></body></html 


4] K. Chang, C. Chong, Bar-Shalom, Joint Probabilistic Data Association in Distributed Sensor Networks IEEE Transactions on Automatic Control, AC-31\(10 octobre 1986 5] Bar-shalom, Multitarget Multisensor Tracking Advanced Application ,:YBS Publishing, 1990 6] Bar-shalom, Multitarget Multisensor Tracking Principles and Techenices ,:YBS Publishing, 1995 7] Hu Wenlong, Mao shiyi, Multisensor Data Association Based on Combinatorial Optimization[J]. Journal of Systems Engineering and Electronics . 1997 NO.1,1~9 8] Pattipati K R, Passive Multisensor Data Association Using a New Relaxation Algorithm.In Multitarget-Multisensor Tracking: Advanced and Applications,Y.Barshalom,Norwood,MA:Aretech,199 0 9] Deb S,et al, An S-Dimentional Assignment Algorithm for Track Initiation ,Proc. Of the IEEE Int. Conf Systems Engineering, Kobe, Japan,Sept 1992 527~530 10] Deb S,et al, A Multisensor-Multitarget Data Association Algorithm for Heterogeneous Sensors[J].IEEE Trans. on AES 1993 ,29 \(2 560~568 12] Bar-shalom,Y.,and Fortmann,T.E  Tracking and Data Association  New York:Academic press,1988 13] J,A,Roecher and G.L.Phillis,Suboptimal Joint Probabilistic Data Association .IEEE Transaction on Aerospace Electronic Systems.1993,29\(2 14] J,A,Roecker,A Class of Near Optimal JPDA Algorithm IEEE Transaction on Aerospace and Electronic Systems,1994,30\(2 15] Han Yanfei, Analysis and Improvement of Multisensor Multitarget Probabbilistic Data Association Filting Algorithm[J].  Journal of Systems Engineering and Electronics, 2002, Vol.24, 36~38  569 pre></body></html 


dense data sets for evaluating pattern mining algorithms These two data sets are obtained from IBM Almaden at http://www.almaden.ibm.com/cs/quest/demos.html. Recently, theMAFIA algorithm [6] was proposed to ef?ciently discover maximal frequent patterns. As shown in their paper, MAFIA can be several orders better than some alternatives, such as DepthProject, for mining maximal frequent patterns. Hence, we chose MAFIA as the base line for our performance evaluation. Finally, please note that only the size-2 patterns are generated in the ?rst BFS phase Experimental Platform We implemented the MHP algorithms using C++ and all experiments were performed Proceedings of the 16th IEEE International Conference on Tools with Artificial Intelligence \(ICTAI 2004 1082-3409/04 $20.00 © 2004 IEEE on a Pentium III    MHz PC machine with    megabytes main memory, running Linux Redhat 6.1 operating system 5.2. A Performance Comparison 100 1000 10000 100000 1e+06 1e+07 1e+08 1e+09 1e+10 1e+11 0.02 0.025 0.03 0.035 0.04 0.045 0.05 0.055 0.06 N um be r o f C he ck ed P at te rn s Support threshold Mafia Min_Conf=0 Min_Conf=0.1 Min_Conf=0.3 Min_Conf=0.5 Min_Conf=0.7 Min_Conf=0.9 


Figure 4. The Number of Checked Patterns on the Pumsb* Data Set 10 100 1000 10000 100000 0.02 0.025 0.03 0.035 0.04 0.045 0.05 0.055 0.06 R un T im e s ec  Support Threshold Mafia Min_Conf=0 Min_Conf=0.1 Min_Conf=0.3 Min_Conf=0.5 Min_Conf=0.7 Min_Conf=0.9 Figure 5. The RunTime Comparison on the Pumsb* Data Set Figure 4 shows the number of patterns that MHP and MAFIA have to check during the pattern mining process on the pumsb* data set. As can be seen, for MHP, the number of checked patterns is increased with the decrease of the h-con?dence threshold. However, the number of checked patterns of MHP can be signi?cantly smaller than that of MAFIA even if a low h-con?dence threshold is speci?ed To check a pattern, we need to count the support of the patterns. Counting the support of a pattern is the most timeconsuming task during the pattern mining process, since we need to retrieve all the transactions which include one of its sub-pattern, or for Ma?a, retrieve all the bit of the bitmap of this pattern [6]. Therefore, an algorithm is more ef?cient if smaller number of patterns need to be checked 100 1000 10000 100000 1e+06 1e+07 1e+08 1e+09 0.1 0.2 0.3 0.4 0.5 0.6 0.7 N 


um be r o f C he ck ed P at te rn s Support Threshold Mafia Min_Conf=0.5 Min_Conf=0.7 Min_Conf=0.9 Figure 6. The Number of Checked Patterns on the Pumsb Data Set 10 100 1000 10000 0.1 0.2 0.3 0.4 0.5 0.6 0.7 R un T im e s ec  Support Threshold Mafia Min_Conf=0.5 Min_Conf=0.7 Min_Conf=0.9 Figure 7. The RunTime Comparison on the Pumsb Data Set The runtime comparison of MHP and MAFIA on the Pumsb* data set is shown in Figure 5. In the ?gure, we can observe that the runtime of MHP can be signi?cantly reduced with the increase of h-con?dence thresholds. Also the runtime of MHP can be several orders of magnitude less than that of MAFIA even if the h-con?dence threshold is as low as 0.3. The reason is that the number of checked patterns of MHP is sign?cantly smaller than that of MAFIA Similar results are also obtained from the pumsb data set as shown in Figure 6 and Figure 7. For the pumsb data set the number of checked patterns of MHP is much smaller 


than that of MAFIA and the runtime of MHP can be significantly less than that of MAFIA 5.3. The Effect of the MHP Algorithm on Finding Maximal Hyperclique Patterns Figure 8 and Figure 9 show the number of maximal patterns identi?ed byMHP andMAFIA on Pumsb* and Pumsb data sets respectively. As can be seen, the number of maximal hyperclique patterns identi?ed by MHP can be orders of magnitude smaller than the number of maximal frequent patterns identi?ed by MAFIA. In other words, the number Proceedings of the 16th IEEE International Conference on Tools with Artificial Intelligence \(ICTAI 2004 1082-3409/04 $20.00 © 2004 IEEE 100 1000 10000 100000 1e+06 1e+07 1e+08 1e+09 0.02 0.025 0.03 0.035 0.04 0.045 0.05 0.055 0.06 N um be r o f C ou nt ed P at te rn s Support Threshold Mafia Min_Conf=0 Min_Conf=0.1 Min_Conf=0.3 Min_Conf=0.5 Min_Conf=0.7 Min_Conf=0.9 Figure 8. The Number of MFI/MHP Patterns in the Pumsb* Data Set 100 1000 10000 100000 1e+06 


1e+07 1e+08 0.1 0.2 0.3 0.4 0.5 0.6 0.7 N um be r o f C ou nt ed P at te rn s Support Threshold Mafia Min_Conf=0.5 Min_Conf=0.7 Min_Conf=0.9 Figure 9. The number of MFI/MHP Patterns in the Pumsb Data Set of maximal hyperclique patterns is much easier to manage than that of maximal frequent patterns. Indeed, in realworld applications, it is dif?cult to interpret several million maximal frequent patterns. However, it is possible to interpret the results of maximal hyperclique pattern mining In addition, due to the memory limitation, we cannot extract maximal frequent patterns with MAFIA on the Pumsb data set if the support threshold is less than 0.4, as shown in Figure 7. In contrast, MHP can identify maximal hyperclique patterns when the support threshold is 0.1, if we set the h-con?dence threshold to 0.5. In other words, MHP has the ability to identify patterns which can be dif?cult to identify for MAFIA. Hence, MHP can better explore the pattern space and ?nd interesting patterns at low levels of support 6. Conclusions and Future Work In this paper, we present a two-phase Maximal Hyperclique Pattern \(MHP best features of both the BFS strategy and the DFS strategy. More speci?cally, we adapted DFS pruning methods such as equivalence pruning, to an apriori-like approach In addition, we proved the correctness and completeness of the MHP algorithm. Finally, our experimental results show that the MHP algorithm can be several orders of magnitude faster than standard maximal frequent pattern mining algorithms and has the ability to identify patterns at extremely low levels of support in dense data sets There are several directions for future work. First, in 


this paper, we only generate the size-2 patterns in the BFS phase. It will be interesting to investigate the impact on the performance if the ?rst phase is stopped at a deeper level Also, the projection is a very ef?cient method for ?nding patterns, especially for parallel implementation of pattern mining algorithms [1]. We plan to adapt the projection ideas into our algorithm and design an ef?cient parallel algorithm for mining maximal hyperclique patterns References 1] R. Agarwal, C. Aggarwal, and V. Prasad. A Tree Projection Algorithm For Generation of Frequent Itemsets. pages 350 371, Feb 2001 2] R. Agrawal, T. Imielinski, and A. Swami. Mining Association Rules between Sets of Items in Large Databases. In Proc. of the ACM SIGMOD Conference on Management of Data, pages 207216,May 1993 3] R. Agrawal and R. Srikant. Fast Algorithms for Mining Association Rules. In Proc. of the 20th Intl Conference on Very LargeData Bases, 1994 4] R. Bayardo. Ef?ciently mining long patterns from databases In Proc. of the ACM SIGMOD Conference, 1998 5] R. Bayardo and R. Agrawal. Mining the Most Interesting Rules. In Proc. of the ACM SIGKDD Conference, 1999 6] D. Burdick, M. Calimlim, and J. Gehrke. Ma?a: AMaximal Frequent Itemset Algorithm for Transactional Databases. In Proc. of IEEE Conf. on Data Engineering, 2001 7] Y. Huang, H. Xiong, W. Wu, and Z. Zhang. A Hybrid Approach for Mining Maximal Hyperclique Patterns. In In Technical Report UTDCS-34-04, Department of computer science, University of Texas - Dallas, 2004 8] J.Han, J.Pei, and Y. Yin. Mining Frequent Patterns without Candidate Generation. In Proc. of the ACM SIGMOD International Conference on Management of Data, 2000 9] M.J.Zaki and C.Hsiao. ChARM: An ef?cient algorithm for closed itemset mining. In Proc. of 2nd SIAM International Conference on Data Mining, 2002 10] R.Rymon. Search through Systematic Set Enumeration. In Proc. Third Intl Conference on Principles of Knowledge Representation and Reasoning, 1992 11] H. Xiong, M. Steinbach, P.-N. Tan, and V. Kumar. HICAP: Hierarchial Clustering with Pattern Preservation. In Proc. of 2004 SIAM International Conference on Data Mining \(SDM 12] H. Xiong, P.-N. Tan, and V. Kumar. Mining Strong Af?nity Association Patterns in Data Set with Skewed Support. In Proc. of the Third IEEE International Conference on Data Mining \(ICDM Proceedings of the 16th IEEE International Conference on Tools with Artificial Intelligence \(ICTAI 2004 1082-3409/04 $20.00 © 2004 IEEE 





