Behavior Prediction Based on Daily-Life Record Database in Distributed Sensing Space Taketoshi Mori and Aritoki Takada Mechano-Informatics the University of Tokyo 7-3-1 Hongo Bunkyo-ku Tokyo 113-8656 Japan  tmori takada  ics.t.u-tokyo.ac.jp Hiroshi Noguchi Tatsuya Harada and Tomomasa Sato Graduate School of Information Science and Technology the University of Tokyo 7-3-1 Hongo Bunkyo-ku Tokyo 113-8656 Japan  noguchi harada tomo  ics.t.u-tokyo.ac.jp Abstract 
 This paper proposes a behavior prediction system for supporting our daily lives The behaviors in daily-life are recorded in an environment with embedded sensors and the prediction system learns the characteristic patterns that would be followed by the behaviors to be predicted In this research the authors applied a method of discovering time-series association rules which discovers frequent combinations of events called episodes The prediction system observes behaviors with the sensors and outputs the prediction of the future behaviors based on the rules Index Terms  Ubiquitous Sensing Human Monitoring Knowledge Discovery Daily Behavior Database 
I I NTRODUCTION In recent years it has become possible to collect and accumulate various information on the behavior of people in daily lives This is thanks to increasing sophistication of elements that make up residences such as household appliances By using these information and predicting or complementing behavior of the resident various services and support to residents for example energy conservation providing relevant information and physical support are believed to be possible without explicit and concise 2 Support in daily-life to people can be thought of as support towards behavior in other words activating machines or 
equipment such that people can behave easily and appropriately Therefore as a guideline to select and execute appropriate support when collection of information or a variety of support is possible we can link human behavior and appropriate means of support This method seems easy to implement since we can recognize peopleês behavior from accumulated data and suggest and execute the appropriate means of support However simple correlation of recognition of behavior and appropriate support plans may delay initiation of support therefore we might keep the person waiting for support or even be too late to provide support In addition it is better to be able to supply information and prepare support 
before speciìc behavior To get around these problems it is necessary to predict behavior of people by some method Activities in daily-life are often performed habitually and most behavioral patterns are caused by other behavior or change in environment Therefore by observing daily lives it may be possible to nd out behavior caused by other behavior or change in environment and use the data for prediction In this paper as a means to predict speciìc behavior and support people effectively we will nd relationships between activity and change in environment in a database containing behavior in daily-life and use this data to propose and 
implement methods to predict occurrence of speciìc behavior The prediction is done fast enough to allow time for actual support In addition possibility and usefulness of daily-life prediction is evaluated II B EHAVIOR P REDICTION S YSTEM In this section we discuss the elements of the behavior prediction system we propose in this paper A Behavior Measurement Data for Prediction To predict behavior in daily-life the daily-life in problem must be observable In this paper we will use the Sensing  4 Fig 1 that was designed in our research group 
to observe behavior in daily-life The Sensing Room is designed like a furnished studio apartment However there are various pressure sensors present including on the oor chairs and bed and switch sensors used to detect openings and closings are attached to the refrigerator drawers and other furniture By using these environmental sensors we can detect behavior of the resident in daily-life without using visual aids without any constraints and for prolonged periods The information gathered by environmental sensors can be obtained online and since they are accumulated in a database we can refer to data for any past arbitrary period B Prediction for Resident Support 
If we could predict beforehand the happening of a speciìc behavior using measurements of behavior in daily-life it is possible to supply information or materials useful to that behavior\(to be predicted or robots that could support such behavior For example if we can predict that a resident is leaving the apartment twenty or thirty seconds before he actually leaves the room we can support the resident by checking the weather forecast and inform by voice or other means that rain is coming or a robot can bring her/his briefcase to the 


Fig 1 Sensing Room door These supports are impossible if the support system recognizes that the resident is just about to leave or has left the room and support is only possible if the system can predict beforehand that the resident will leave the apartment Previous research on prediction of human behavior included making a general model of behavior selection when choices are limited for example such as viewings of Web pages[5 Ho we v e r  there are man y dif ferent kinds of beha vior in daily-life and it is difìcult to classify all of them and a number of behaviors can be performed simultaneously Here we discuss properties that are required in behavior prediction for support of daily-life  Use of Accumulated Data by Distributed Sensors Behavior prediction must be done based on output from environmental sensors Environmental sensors are composed of a wide variety of different sensors  Prediction of a Speciìc Behavior We do not need to predict every type of behavior in daily-life but only those speciìc types of behavior that need to be supported  Earliness of Prediction It depends on the behavior to be supported and the contents of the support but in general if the prediction of behavior to be supported is done just before the behavior happens the prediction cannot be used for support Therefore prediction must be made signiìcantly before the behavior happens so that enough support could be done  Accuracy Range of Prediction It is difìcult to predict behavior that will actually be executed and on the contrary some kind of support is favorable even if prediction of such behavior is with uncertainty Therefore upon tolerating some uncertainty in prediction it is better to give information on reliability with behavior prediction Taking into account these properties in this paper we deìne behavior prediction as follows Behavior prediction is to satisfy prediction demand and prediction demand is deìned as the necessity to predict occurrence of certain behavior in a predetermined accuracy range for support The prediction must be done before a certain time prior to its occurrence Based on these deìnitions behavior prediction is realized via two steps First knowledge of environmental change and behavior before execution of a certain behavior under prediction demand is compiled from data accumulated by environmental sensors Second occurrence of behavior is predicted based on this knowledge and is output along with information on its accuracy Fig 2 In the rest of this paper behavior that should be predicted are called behavior to be predicted time that should be left between prediction and actual occurrence is called degree of earliness and the time frame that is tolerated as errors in predicted occurrence time of target behavior is called acceptable temporal error      Fig 2 Prediction System for Support III E XTRACTION AND A PPLICATION OF P REDICTION K NOWLEDGE B ASED ON D AILY L IFE D ATA BA S E In this section we discuss methods to gain knowledge for prediction based on a database containing information on daily-life and methods to actually predict behavior using the information A Predictor In this paper we use a predictor as a means to satisfy each prediction demand Fig 3 Predictors exist for each prediction demand Each predictor outputs prediction of the corresponding demand behavior along with information on accuracy when the behavior\(to be predicted is thought to occur with higher than a predetermined probability after the post-prediction time i.e degree of earliness The total output of the prediction module is the combination of all predictors To realize such a predictor we use the following processes From the environmental sensor data in the daily-life database we detect speciìc behavioral and environmental activity represented as sensor output features before the behavior\(to be predicted Next we organize the set of output features and behavior to be predicted as knowledge on such behavior to be predicted Then the predictors try to locate the respective behavior\(to be predicted based on this knowledge during real-time measurements via the observation of the paired output features From now on we term these output features 


as pre-behavior features and the relationship between prebehavior features and the behavior to be predicted is termed prediction knowledge  Fig 3 Prediction Based on Pre-Behavior Features B Extraction and Application of Prediction Knowledge 1 Detection and Recognition of Behavior to be Predicted To extract prediction knowledge it is necessary to detect at what point had the behavior\(to be predicted began in the accumulated data This detection does not have to be performed in real-time and it is sufìcient to use data accumulated after the behavior\(to be predicted happened In this paper we detect behavior to be predicted based on a set of rules for each such behavior For example we determine that the resident has left the apartment when all the environmental sensors cannot detect the resident for 10 minutes or more Based on these rules we can distinctively know when behavior to be predicted began in the accumulated data 2 Extraction and Learning of Pre-Behavior Features Since we could nd when behavior to be predicted started in the accumulated data we could extract the data preceding this behavior and extract the associated pre-behavior features The problem here is how to decide what part of the data should be taken into consideration when pre-behavior features are extracted Needless to say we cannot use those features of the period just before target behavior in any prediction On the other hand features that occur a long time before the behavior to be predicted generally have little correlation to the behavior In addition if pre-behavior features are extracted over a large time frame the temporal correlation between behavior to be predicted and pre-behavior features becomes unclear and conditions for the acceptable temporal error may not be satisìed Therefore taking into account the need for earliness and an acceptable temporal error in prediction pre-behavior features extraction will be done in a xed time frame that ends at a speciìed point of earliness before target behavior Fig 4 This time frame will be called the period for analysis Since the temporal error is considered to be equivalent to this period of analysis the acceptable temporal error and period of analysis are set equal                  Fig 4 Extraction of Pre-Behavior Features 3 Application of Prediction Knowledge in Real-Time Measurement From the prediction knowledge obtained each predictor monitors for the appearance of pre-behavior features in real-time measurement When a pre-behavior feature of prediction knowledge is observed each predictor gives an output that a behavior to be predicted will happen after the speciìed degree of earliness Ideally behavior to be predicted should be predicted with an exact time prediction and there should be no prediction failure or false alarms but in reality it is difìcult to get rid of such time errors prediction failure or false alarms Therefore output prediction results would be accompanied with probability of behavior\(to be predicted occurrence and the acceptable temporal error C Selection of Time-Series Feature Expression Here we discuss a few methods to describe pre-behavior features In this paper we focus on daily-life environment comprising of various sensors and the data from the sensors ranges from multidimensional coordinate data such as the position of the resident in the room to binary data such as whether the refrigerator door is open or not From these data it is necessary to extract only those appropriate features that are well correlated to the behavior to be predicted Taking this point in mind the following are discussions about methods to express time-series data  Time-series Data Comparison Method by Chiu et It is possible to add weights to transitional parts in the time-series data but since the data is limited to onedimensional continuum values it is difìcult to express information from multiple sensors and to absorb the effects of temporal shifts  Hidden Markov model[7 Multidimensional data can be treated but there are many problems It is hard to treat data where the value rarely changes expression of features of only the environmental sensors that relate to behavior\(to be predicted is difìcult and expression of such features is not easy for 


humans to understand  Time-series Data Mining Method by Das et Time-series data is expressed by multiple events of many kinds and features are expressed as episodes or combination of multiple time-series events We can express as features only the information from relevant environmental sensors However the expression is not unique but becomes a set of multiple episodes and we need to convert time-series information into a set of events After comparing the above methods we chose the timeseries data mining method as a base method that can treat output changes in speciìc sensors appropriately Regarding the problem where there are multiple feature expressions predictors that correspond to single prediction demands keep track of multiple features and check their occurrences If more than one feature is observed the feature that is most correlated to the behavior\(to be predicted outputs the prediction results We treated time-series data as events such that all sensors are binary sensors or a set of binary sensors D Applications of Time-Series Association Rule Method The original method by Das et al is a way of nding feature relationships between events without a speciìc goal To predict speciìc behavior some changes are needed We discuss the application of such reìning changes to the method used in this paper 1 Expression as Event Arrays of the Daily-Life Database First we need to express as event arrays time-series data obtained from the environmental sensors In this paper we presume a binary output sensor as seen in Fig 5 and the change in output was deìned as an event The following are examples of events  Fig 5 Example of Sensors in the Room and Corresponding Events Elements shown with white letters have no sensors attached  Floor pressure sensor event Resident stays  leaves each of the seven areas on the oor  Chair pressure sensor event Residents sits  leaves each of the two chairs  Appliance  furniture open  close sensor events Resident opens  closes appliances such as refrigerators and furniture such as drawers The event array in the daily-life database that express the events shown above is called S  and the duration is called T S  2 Listing of Pre-Behavior Episodes Next we list episodes as candidates for pre-behavior features from the events in the daily-life database The listed episodes are evaluated in the method described later and some episodes are selected as pre-behavior features From now on for simplicity we will try to predict only one type of behavior The set of times where behavior to be predicted occurs in the daily-life database is deìned as  t i  N i 1  degree of earliness as T e  and period for analysis as T w  Here we gain a partial set of events in the daily-life database  s i   If Subseq  S t 1 t 2  is a subsection of S with t 1  t<t 2  then s i  Subseq  S t i  T e  T w t i  T e  All episodes that appear more than once in any partial set of events are listed where episodes are multiple events with different types that occur in a speciìc order For example we take the partial set of events  A t a   C t c   B t b   t a t c t b that are made up of types of events  A  B  C   Here A t  is an event that happens at time t and can be classiìed as type A  The episodes that are included in this set are these seven episodes  A  C  B  A  C  A  B  C  B  A  C  B   The list of episodes derived like this are called  Ep k   3 Calculation of Pre-Behavior Episode Occurence Rate We think of an event array S  where the prediction event is added to an event array S  and the probability of calculating future episode occurrence The prediction event is an imaginary event that occurs at point of earliness earlier than the predicted behavior  t i  T e   and is classiìed as E pre  This expresses the point at which predictions should be performed In addition the occurrence rate p  Ep k  of an episode Ep k in an event array S  is deìned as the probability the Ep k is included when a subarray with time frame T w is taken from S   Thus using the time frame of S   which is equal to the time frame of S or T S  and w t  an arbitrary subarray of S  with time frame of T w  p  Ep k   contains  w t Ep k    T S  T w  dt contains  w t Ep k   1  w t contains Ep k 0  otherwise Using this we calculate the occurrence rate p  Ep k  of the episode in S  in each predicted behavior Next we add a predicted event type E pre after each episode in  Ep k  to make a set  Ep  k   and similarly calculate occurrence rate p  Ep  k   In addition occurrence rate for an episode Ep pre composed of only E pre is also calculated 


4 Generation and Evaluation of Behavior Prediction Rules Time-series association rules  Ep k  E pre  can be obtained from Ep k and Ep  k  The right hand side indicates prediction of behavior and hence these rules could be termed prediction knowledge themselves The accuracy of these rules in other words the probability that when target behavior happens approximately time T e after episode Ep k occurs is Acc  Ep k  E pre  p  Ep  k  p  Ep k  This is calculated by occurrence rate of Ep k and Ep  k so the accuracy will be lower than the value calculated by the number of occurrence of episodes A set of behavior prediction rules can be generated in the above method but rules will be generated for all listed episodes Needless to say some rules that have very low accuracy or rules that are highly accurate but the left hand side is rarely satisìed are included Therefore evaluation and selection of rules is desirable The J measure[9 sho wn in the following equation was chosen as the evaluation criterion J  Ep k  E pre  p  Ep k   p  Ep  k og p  Ep  k  p  Ep pre  1  p  Ep  k  log 1  p  Ep  k  1  p  Ep pre   The J measure is a value in terms of information that shows how much ambiguity is removed in the phenomenon a speciìc rule governs A larger J measure indicates the rule gives more accurate information 5 Prediction Output Based on Application of Rules Each predictor observes events that happen in real-time and if in the last T w period of time an episode that is in the left hand side of the prediction rule happens this results in the output of a prediction Therefore when such prediction is output in the last T w period all events except the last type have been observed in sequence and the last event has just been observed The episodes in the left hand side conditions were extracted from a time frame starting T e  T w before the actual start of the behavior in the daily-life database  t i  and ending at T e before  t i  The partial set  s i   Therefore the predicted behavior is thought to happen in the time frame between T e and T e  T w after prediction The credibility of the prediction output is given by the accuracy of the prediction rule If multiple rules can be applied at the same time the highest accuracy will be selected as output IV E XPERIMENTS In this paper to demonstrate the validity of the proposed prediction method prediction outputs were generated from prediction rules based on an actual daily-life database The experiments are discussed in this section A Experimental Environment and Conditions In the experiments prediction rules were generated and evaluated based on a daily-life database accumulated in the Sensing Room The subject was a male in his 20s and the experimental period was six days The behavior to be predicted was chosen to be leaving the premises since if such a prediction was possible in reality various support could be implemented Here leaving the premises does not mean leaving the Sensing Room but rather leaving the living environment including the Sensing Room B Experiment to Find Prediction Knowledge 1 Objectives and Outline To conìrm appropriate prediction rules can be generated we attempted the generation of prediction knowledge for use in the prediction knowledge application experiment using part of accumulated daily-life database We used the rst four dayês activity of the database and behavior\(to be predicted was observed eight times The degree of earliness for prediction knowledge was set at 15 seconds This time margin is required to supply information when the resident is leaving The period for analysis and hence acceptable temporal error was set at 10 seconds since we think there is no problem in supplying information with this error 2 Results When we generated behavior prediction rules with these conditions we obtained 1250 rules The 10 rules with best J measures are shown in Table I The episodes that are in the left hand side of the rules were comprised only of events corresponding to the resident landing on  getting off oor sensors and a speciìc drawer to store his valuables being opened and closed Thus the event of adding  removing of load in a region of oor k is denoted F k,on  F k,of f  and the event of opening  closing the drawer is denoted D 1 on  D 1 of f respectively TABLE I B EST 10 G ENERATED R ULES TO P REDICT THE R ESIDENT L EAVING J-measure Rank Episode Accuracy   10  4  1 D 1 on 26 9  74 2 F 5 on 9 7  74 3 F 5 on  D 1 on 28 7  65 4 F 4 on  D 1 on 58 5  18 5 F 2 of f  D 1 on 92 4  60 6 F 2 of f  F 5 on  D 1 on 92 4  60 7 F 4 on 12 4  56 8 F 5 on  F 4 on  D 1 on 69 4  54 9 F 2 of f  F 5 on 73 4  30 10 F 2 on  D 1 on 92 4  17 3 Discussion Of the rules generated most of the rules with high J measures were related events of the oor sensor and a speciìc drawer opening or closing This may be because the residentês habit of taking his wallet when he goes out was discovered as a feature where the resident moves to the front of the drawer and opens it 


  Fig 6 Time When Prediction was Done Based on the Rules Dotted line shows when the resident actually left In general it was found that generated rules that are composed of conditions from one sensor have low accuracy while conditions from two sensors have higher accuracy This is because when conditions of two sensors are combined we can separate behavior such as putting back his wallet in the drawer after he has returned removing things from the drawer when he does not intend to go out and behavior concerning other drawers and furniture near the chest of drawers The rules that concerned events other than oor sensors and the drawer and had low evaluation included rules concerning the opening and closing of the refrigerator door One reason is that the refrigerator door is opened and closed at times other than when the resident is leaving and does not happen as frequently as the oor sensor events In addition no rules were generated concerning the chairs since the behavior that the resident stands from the chair happens at a very early point away from when the resident leaves the room C Experiment to Apply Rules and Output Prediction 1 Objective and Outline To conìrm that the discovered prediction knowledge can be used in prediction they were applied to the two days activities that were not used in nding prediction knowledge in the daily-life database and prediction of behavior was attempted The resident left the premises four times in this period The rules used were the 10 best rules evaluated with J measures in the previous experiment i.e the rules in Table I 2 Results The time when prediction was done from the rules the state of prediction when the behavior happened and the evaluation of the prediction for each rule are shown in Fig 6 Table II and Table III respectively In each item the rules are denoted in the order of evaluation in Table I Table II shows the time when the resident left the premises what prediction rules were applied and at what time and the best accuracy of the rules When prediction was done due do occurrence of a different event it is shown separately even if the time difference was less than one second TABLE II P REDICTIONS AND THE A CTUAL B EHAVIOR OF THE R ESIDENT Rule Applied Accuracy Date Time Actual Behavior MAX 1 22:31:06 1 5 10 92 22:31:07 2 9 73 22:31:27 Go Out  1 23:49:45 1 3 4 5 6 10 92 23:50:50 Go Out  2 15:48:26 1 5 10 92 15:48:26 2 9 73 15:48:50 Go Out  2 21:34:24 2 9 21:34:24 1,3,10 92 21:34:39 Go Out  Table III shows application of each rule and how many times the prediction was correct The number of applications is the number when the left hand side of the prediction rule was satisìed and the number of correct prediction was the number of times the behavior occurred between 15 and 25 seconds after the prediction For comparison we show the accuracy calculated in the previous experiment TABLE III S CORE OF E ACH P REDICTION R ULE No Applied Hit Ref.\y 1 7 4 26 2 34 3 9 3 4 2 28 4 2 1 58 5 3 3 92 6 1 1 92 7 22 0 12 8 1 0 69 9 4 2 73 10 4 4 92 


3 Discussion As seen in Table II every occasion that the resident leaving the premises was predicted by a prediction rule In addition as Table III shows the correctness ratio of each prediction rule was close to the accuracy Thus we conìrmed that using rules that had high J measures could result in reasonable prediction V C ONCLUSION In this research we proposed and implemented a behavior prediction system for physical and information support in daily-life In our proposed method we nd characteristic features prior to the behavior to be predicted based on prediction demands from the daily-life database measured and accumulated from environmental sensors in the Sensing Room Simultaneously we can calculate the degree of correlation between pre-behavior feature and behavior to be predicted Therefore we can output a prediction of the occurrence of the targeted behavior with its accuracy by checking for the appearance of pre-behavior features We used a time-series association rule method to nd the features and deìne as set of events the characteristic environmental sensor output changes which occur before behavior to be predicted We attempted the prediction of when the resident leaves the premises using this method and demonstrated that we could actually predict using the generation and application of prediction knowledge Future issues include the automatic location of appropriate feature extraction points As a general rule we pointed out that the earlier the event the less correlated the event is to the behavior to be predicted but there might be some exceptions In addition it is desirable to be able to automatically calculate what accuracy of prediction can be done at what point in time Therefore our method should be expanded so that early prediction with accuracy information can be done for ambiguous prediction demands Application of this method to support systems can also be considered Possible milestones in the near future include predicting when residents leave the premises or start meals In case of the resident leaving we can supply information about the weather and if the resident is going to start a meal information about drinks in the refrigerator can be supplied for example Using these support systems we believe we can present a means of support that is helpful and not annoying to the end user such as support by voice when probability of behavior to be predicted is high and support by showing  when such probability is lo w  R EFERENCES  T a k etoshi Mori and T omomasa Sato Robotics Room Its Concept and Realization Robotics and Autonomous Systems Vol.28 No.2 pp.141148 1999   Seiichi Shin Role of Systematic Approach to the Y a o yorozu Infor mation Society IEEE International Conference on Systems Man and Cybernetics pp.5615-5620 2004   T a k etoshi Mori T omomasa Sato Katsutoshi Asaki Y uji Y oshimoto One-Room-Type Sensing System for Recognition and Accumulation of Human Behavior IEEE/RSJ International Conference on Intelligent Robots and Systems pp.344-350 2000   T a k etoshi Mori Hiroshi Noguchi Aritoki T akada and T omomasa Sato Sensing Room Distributed Sensor Environment for Measurement of Human Daily Behavior 1st International Workshop on Networked Sensing Systems\(INSS pp.40-43 2004  Bernardo A Huberman Peter L T  Pirolli James E Pitk o w and Rajan M Lukose Strong Regularities in World Wide Web Surìng Science Vol 280 pp.95-97 3 April 1998  Bill Chiu Eamonn K eogh and Stef ano Lonardi Probabilistic Disco v ery of Time Series Motifs 9th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining pp.493-498 2003  L.R Rabiner and B.H Juang  A n Introduction to Hidden Mark o v Models IEEE ASSP MAGAZINE pp.4-16 January 1986   Gautam Das King-Ip Lin Heikki Mannila Gopal Reng anathan and Padhraic Smyth Rule Discovery from Time Series Proceedings of the Fourth International Conference on Knowledge Discovery and Data Mining KDD-98 1998   P adhraic Smyth and Rodne y M  Goodman  A n Information Theoretic Approach to Rule Induction from Databases IEEE Transactions on Knowledge and Data Engineering 4\(4 pp.301-316 1992   T a k etoshi Mori Noritaka Hayama Hiroshi Noguchi and T omomasa Sato Informational Support in Distributed Sensor Environment Sensing Room 13th International Workshop on Robot and Human Interactive Communication\(RO-MAN 2004 pp.353-358 2004 


0-7695-2430-3/05 $20.00  2005 IEEE implication \(or dilated 2 same values of intensity of implication \(or dilated 2 mechanism of the original CBA, which is mentioned in section 2.2 4. Empirical Section This part is to validate our adapted CBA algorithms on three credit scoring datasets in table 1. In order to get a more comprehensive evaluation, these datasets are also classified by original CBA, the classical decision tree technique C4.5 [14] and Neural Network three layers and Back propagation employed parameter ?  in dilated chi-square and the number of neurons in hidden layer were tuned for best classification accuracy. C4.5 and Neural Network were implemented by the software package of WEKA [15 The number of The continuous attributes are discretized based on entropy [16] if needed datasets Inputs \(con./dis Austr 14\(6/8 Germ 20\(7/13 Bene 28\(18/10 Table 1. Credit scoring datasets Among these three datasets, Austr and Germ are from UCI repository datasets [17], and Bene is from one major financial institution in the Benelux Belgium, The Netherlands and Luxembourg the dataset size of Austr and Germ are no more than 1000, 10-cross validation method was applied to evaluate the classification performance so as to reduce the fluctuations that stem from random sampling. For dataset Bene, 2/3 of its samples were taken as the training set and 1/3 of them as test set As shown in Table 2, adapted CBA 1 and CBA 2  which correspond to the adapted CBA algorithms that incorporate intensity of implication and dilated 2 respectively, perform well with respect to classification accuracy and number of rules they generated \(for Austr and Germ, the number of rules are the average results of 10-cross validation carried out on Bene in a train/test way, McNemar test 18] are employed to examine whether the predictive performance of these algorithms are significantly different with each other. The test results are listed as follows Original CBA Adapted CBA1 Adapted CBA2 C45 NN Original CBA 1.000 0.393 0.554 0.005 0.752 Adapted CBA1 1.000 0.221 0.038 0.718 Adapted CBA2 1.000 0.001 0.377 C45 1.000 0.019 NN 1.000 Table 3. McNemar test on dataset Bene The p-values in table 3 reveals that there are no significant differences among original CBA, adapted CBA and Neural Networks at 1% confidence level 


CBA and Neural Networks at 1% confidence level while they are all significantly better than C4.5 decision tree. Taking the interpretability of classification model into account, these two adapted CBA algorithm seem to be appropriate choices for credit scoring because they generated much more compact decision lists \(less sequential rules original CBA. They therefore favour the well-known Occam  s Razor theory and are more suitable for decision makers to understand. A deeper insight into the rules structures shows that original CBA and adapted CBA 1 both focus on generating classification rules that predict good clients \(with bad clients as the default class implication, numerous rules with high confidence but low support have lower ranks than they are in original CBA. These rules are finally discarded since they are not fired by any training samples, which are matched by these rules with higher intensity of implications thus making the decision lists generated by adapted CBA 1 more compact. Adapted CBA 2 mainly mines these classification rules for bad clients \(with good clients as the default class compact rule sets Original CBA Adapted CBA1 Adapted CBA2 C45 NN dataset accuracy no. of rules accuracy num. of rules accuracy no. of rules accuracy accuracy 1 Austr 85.65% 130.5 86.52% 26.4 86.96% 12.4 86.52% 85.07 2 Germ 73.30% 134 74.40% 56.5 73.20% 19.7 72.40% 74.90 3 Bene 72.92% 393 72.30% 186 73.51% 51 70.21% 72.63 Table 2. Experiment results Proceedings of the 2005 IEEE International Conference on e-Business Engineering \(ICEBE  05 0-7695-2430-3/05 $20.00  2005 IEEE In addition, decision makers in financial institution certainly pay more attentions to those rules that predict bad clients, which will be extraordinary costly if they are regarded as good ones 5. Conclusion Intensity of implication is proposed in the beginning as an interestingness measure for association rules Another novel interestingness measure called dilated chi-square is designed by us to reveal the statistical interdependence between the antecedents and consequents of association rules We then adapt CBA algorithm, which can be used to build classifiers based on class association rules, by coupling it with intensity of implication and dilated chi-square respectively. More concretely, Intensity of implication \(or dilated chi-square primary criterion to rank class association rules at the first step of the database coverage pruning procedure in CBA algorithm. Experiments on three credit scoring datasets proved that these two adapted algorithms compared with original CBA, classical C4.5 decision tree and neural network, achieve satisfactory performance and generates classifiers much more compact than CBA 6. Acknowledgement The work was partly supported by National Natural Science Foundation of China \(70231010/70321001 7. References 1] Wang, K. and S. Zhou, Growing decision trees on support-less association rules. in KDD'00. 2000. Boston,MA 2] Liu, B., W. Hsu, and Y. Ma, Integrating Classification and Association Rule Mining. in the 4th International Conference on Discovery and Data Mining. 1998. New 


Conference on Discovery and Data Mining. 1998. New York,U.S 3] Dong, G., et al, CAEP:Classification by aggregating emerging patterns. in 2nd International Conference on Discovery Science,\(DS'99 Artificial Intelligence. 1999. Tokyo,Japan: Springer-Verlag 4] Liu, W., J. Han, and J. Pei, CMAR: Accurate and efficient classification based on multiple class-association rules. in ICDM'01. 2001. San Jose, CA 5] Yin, X. and J. Han, CPAR:Classification based on predictive association rules. in 2003 SIAM International Conference on Data Mining \(SDM'03 Fransisco,CA 6] Agrawal, R. and R. Srikant, Fast algorithm for mining association rules. in the 20th International Conference on Very Large Data Bases. 1994. Santiago,Chile 7] Agrawal, R., T. Imielinski, and A. Swami, Mining association rules between sets of items in large databases. in the ACM SIGMOID Conference on Management of Data 1993. Washington,D.C 8] Guillaume, S., F. Guillet, and J. Philippe, Improving the discovery of association rules with intensity of implication Principles of Data Mining and Knowledge Discovery, 1998 1510: p. 318-327 9] Janssens, D., et al, Adapting the CBA-algorithm by means of intensity of implication. in the First International Conference on Fuzzy Information Processing Theories and Applications. 2003. Beijing, China 10] Gras, G. and A. Lahrer, L'implication statistique: une nouvelle methode d'analysis de donnees. Mathematiques Informatique et Sciences Humaines n 20, 1993 11] Suzuki, E. and Y. Kodratoff, Discovery of  surprising exception rules based on intensity of implication. in PKDD'98. 1998. Berlin: Springer 12] Mills, F., Statistical Methods. 1955: Pitman 13] Lan, Y., et al, Dilated Chi-square: A novel interestingness measure to build accurate and compact decision list. in International conference on intelligent information processing. 2004. Beijing,China 14] Quinlan, J.R., C4.5 programs for machine learning 1993: Morgan Kaufmann 15] Witten, I.H. and E. Frank, Data Mining: practical machine learning tools and techniques with Java implementations. 2000: Morgan Kaufmann, San Francisco 16] Fayyad, U.M. and K.B. Irani, Multi-interval discretization of continuous valued attributes for classification learning. in the Thirteenth International Joint Conference on Artificial Intelligence \(IJCAI Chambery,France: Morgan Kaufmann 17] Blake, C.L. and C.J. Merz, UCI repository of machine learning databases http://www.ics.uci.edu/~mlearn/mlrepository.htm]. 1998 Irvine,CA:University of California, Dept. of Information and Computor Science 18] Dietterich, T.G., Approximate statistical tests for comparing supervised classification learning algorithms Neural Computation, 1998. 10\(7 Proceedings of the 2005 IEEE International Conference on e-Business Engineering \(ICEBE  05 0-7695-2430-3/05 $20.00  2005 IEEE pre></body></html 


absolute values. The results can vary on other computers. But it can be guaranteed that performance ratio of the algorithms will remain the same After making the comparisons with sample data, we came to the conclusion that PD algorithm performs significantly better than the other two especially with larger datasets. PD outperforms DCP and PIP regarding running time. On the other hand, since PD reduces the dataset, mining time does not necessary increase as the number of transactions increases and experiments reveals that PD has better scalability than DCP and PIP. So, PD has the ability to handle the large data mine in practical field like market basket analysis and medical report documents mining 5. References 1] R. Agrawal and R. Srikant, "Fast algoritlnns for mining association rules", VLDB'94, pp. 487-499 2] R. J. Bayardo, "Efficiently mining long patterns from databases", SIGMOD'98, pp.85-93 3] J. Pei, J. Han, and R. Mao, "CLOSET: An Efficient Algorithm for Mining Frequent Closed Itemsets \(PDF Proc. 2000 ACM-SIGMOD International Workshop on Data Mining and Knowledge Discovery, Dallas, TX, May 2000 4] Qinghua Zou, Henry Chiu, Wesley Chu, David Johnson, "Using Pattern Decomposition\( PD Finding All Frequent Patterns in Large Datasets", Computer Science Department University of California - Los Angeles 5] J. Han, J. Pei, and Y. Yin, "Mining Frequent Patterns without Candidate Generation \(PDF  SIGMOD International Con! on Management of Data SIGMOD'OOj, Dallas, TX, May 2000 6] S. Orlando, P. Palmerini, and R. Perego, "The DCP algoritlnn for Frequent Set Counting", Technical Report CS2001-7, Dip. di Informatica, Universita di Venezia 2001.Available at http://www.dsi.unive.itl?orlando/TR017.pdf 7] MD. Mamun-Or-Rashid, MD.Rezaul Karim, "Predictive item pruning FP-tree algoritlnn", The Dhaka University  Journal of Science, VOL. 52, NO. 1, October,2003, pp. 3946 8] Park, J. S., Chen, M.-S., and Yu, P. S, "An Effective Hash Based Algoritlnn for Mining Association Rules", Proc ofthe 1995 ACM-SIGMOD Con! on Management of Data 175-186 9] Brin, S., Motwani, R., Ullman, J., and Tsur, S, "Dynamic Itemset Counting and Implication Rules for Market Basket Data", In Proc. of the 1997 ACM-SIGMOD Conf On Management of Data, 255-264 10] Zaki, M. J., Parthasarathy, S., Ogihara, M., and Li, W New Algoritlnns for Fast Discovery of Association Rules In Proc. of the Third Int'l Con! on Knowledge Discovery in Databases and Data Mining, 283-286 11] Lin, D.-I and Kedem, Z. M., "Pincer-Search: A New Algoritlnn for Discovering the Maximum Frequent Set", In Proc. of the Sixth European Conf on Extending DatabaseTechnology, 1998 12] R. Ramakrishnan, Database Management Systems University of Wisconsin, Madison, WI, USA; International Edition 1998 pre></body></html 


tors such as union, di?erence and intersection are de?ned for pairs of classes of the same pattern type Renaming. Similarly to the relational context, we consider a renaming operator ? that takes a class and a renaming function and changes the names of the pattern attributes according to the speci?ed function Projection. The projection operator allows one to reduce the structure and the measures of the input patterns by projecting out some components. The new expression is obtained by projecting the formula de?ning the expression over the remaining attributes [12 Note that no projection is de?ned over the data source since in this case the structure and the measures would have to be recomputed Let c be a class of pattern type pt. Let ls be a non empty list of attributes appearing in pt.Structure and lm a list of attributes appearing in pt.Measure. Then the projection operator is de?ned as follows ls,lm c id s m f p ? c, p = \(pid, s, d,m, f In the previous de?nition, id ing new pids for patterns, ?mlm\(m projection of the measure component and ?sls\(s ned as follows: \(i s usual relational projection; \(ii sls\(s and removing the rest from set elements. The last component ?ls?lm\(f computed in certain cases, when the theory over which the formula is constructed admits projection. This happens for example for the polynomial constraint theory 12 Selection. The selection operator allows one to select the patterns belonging to one class that satisfy a certain predicate, involving any possible pattern component, chosen among the ones presented in Section 5.1.1 Let c be a class of pattern type pt. Let pr be a predicate. Then, the selection operator is de?ned as follows pr\(c p Join. The join operation provides a way to combine patterns belonging to two di?erent classes according to a join predicate and a composition function speci?ed by the user Proceedings of the 16th International Conference on Scientific and Statistical Database  Management \(SSDBM  04 1099-3371/04 $ 20.00  2004 IEEE Let c1 and c2 be two classes over two pattern types pt1 and pt2. A join predicate F is any predicate de?ned over a component of patterns in c1 and a component of patterns in c2. A composition function c pattern types pt1 and pt2 is a 4-tuple of functions c cStructureSchema, cDataSchema, cMeasureSchema, cFormula one for each pattern component. For example, function cStructureSchema takes as input two structure values of the right type and returns a new structure value, for a possible new pattern type, generated by the join. Functions for the other pattern components are similarly de?ned. Given two patterns p1 = \(pid1, s1, d1,m1, f1 p2 = \(pid2, s2, d2,m2, f2 p1, p2 ned as the pattern p with the following components Structure : cStructureSchema\(s1, s2 Data : cDataSchema\(d1, d2 Measure : cMeasureSchema\(m1,m2 Formula : cformula\(f1, f2 The join of c1 and c2 with respect to the join predicate F and the composition function c, denoted by c 1   F  c  c 2   i s  n o w  d e  n e d  a s  f o l l o w s    F  c  c 2     c  p 1   p 2   p 1    c 1  p 2    c 2  F   p 1   p 2     t r u e   5.1.3. Cross-over database operators OCD Drill-Through. The drill-through operator allows one to 


Drill-Through. The drill-through operator allows one to navigate from the pattern layer to the raw data layer Thus it takes as input a pattern class and it returns a raw data set. More formally, let c be a class of pattern type pt and let d be an instance of the data schema ds of pt. Then, the drill-through operator is denoted by c c Data-covering. Given a pattern p and a dataset D sometimes it is important to determine whether the pattern represents it or not. In other words, we wish to determine the subset S of D represented by p \(p can also be selected by some query the formula as a query on the dataset. Let p be a pattern, possibly selected by using query language operators, and D a dataset with schema \(a1, ..., an ible with the source schema of p. The data-covering operator, denoted by ?d\(p,D responding to all tuples in D represented by p. More formally d\(p,D t.a1, ..., t.an In the previous expression, t.ai denotes a speci?c component of tuple t belonging to D and p.formula\(t.a1, ..., t.an instantiated by replacing each variable corresponding to a pattern data component with values of the considered tuple t Note that, since the drill-though operator uses the intermediate mapping and the data covering operator uses the formula, the covering ?\(p,D D = ?\(p not be equal to D. This is due to the approximating nature of the pattern formula 5.1.4. Cross-over pattern base operators OCP Pattern-covering. Sometimes it can be useful to have an operator that, given a class of patterns and a dataset, returns all patterns in the class representing that dataset \(a sort of inverse data-covering operation Let c be a pattern class and D a dataset with schema a1, ..., an pattern type. The pattern-covering operator, denoted as ?p\(c,D all patterns in c representing D. More formally p\(c,D t.a1, ..., t.an true Note that: ?p\(c,D p,D 6. Related Work Although signi?cant e?ort has been invested in extending database models to deal with patterns, no coherent approach has been proposed and convincingly implemented for a generic model There exist several standardization e?orts for modeling patterns, like the Predictive Model Markup Language \(PMML  eling approach, the ISO SQL/MM standard [2], which is SQL-based, and the Common Warehouse Model CWM  ing e?ort. Also, the Java Data Mining API \(JDMAPI 3] addresses the need for a language-based management of patterns. Although these approaches try to represent a wide range of data mining result, the theoretical background of these frameworks is not clear. Most importantly, though, they do not provide a generic model capable of handling arbitrary cases of pattern types; on the contrary only a given list of prede?ned pattern types is supported To our knowledge, research has not dealt with the issue of pattern management per se, but, at best, with peripheral proximate problems. For example, the paper by Ganti et. al. [9] deals with the measurement 


per by Ganti et. al. [9] deals with the measurement of similarity \(or deviation, in the authors  vocabulary between decision trees, frequent itemsets and clusters Although this is already a powerful approach, it is not generic enough for our purpose. The most relevant research e?ort in the literature, concerning pattern management is found in the ?eld of inductive databases Proceedings of the 16th International Conference on Scientific and Statistical Database  Management \(SSDBM  04 1099-3371/04 $ 20.00  2004 IEEE meant as databases that, in addition to data, also contain patterns [10], [7]. Our approach di?ers from the inductive database one mainly in two ways. Firstly, while only association rules and string patterns are usually considered there and no attempt is made towards a general pattern model, in our approach no prede?ned pattern types are considered and the main focus lies in devising a general and extensible model for patterns Secondly, di?erently from [10], we claim that the peculiarities of patterns in terms of structure and behavior together with the characteristic of the expected workload on them, call for a logical separation between the database and the pattern-base in order to ensure e?cient handling of both raw data and patterns through dedicated management systems Finally, we remark that even if some languages have been proposed for pattern generation and retrieval 14, 11], they mainly deal with speci?c types of patterns \(in general, association rules sider the more general problem of de?ning safe and su?ciently expressive language for querying heterogeneous patterns 7. Conclusions and Future Work In this paper we have dealt with the issue of modelling and managing patterns in a database-like setting Our approach is enabled through a Pattern-Base Management System, enabling the storage, querying and management of interesting abstractions of data which we call patterns. In this paper, we have \(a de?ned the logical foundations for the global setting of PBMS management through a model that covers data patterns and intermediate mappings and \(b language issues for PBMS management. To this end we presented a pattern speci?cation language for pattern management along with safety constraints for its usage and introduced queries and query operators and identi?ed interesting query classes Several research issues remain open. First, it is an interesting topic to incorporate the notion of type and class hierarchies in the model [15]. Second, we have intentionally avoided a deep discussion of statistical measures in this paper: it is more than a trivial task to de?ne a generic ontology of statistical measures for any kind of patterns out of the various methodologies that exist \(general probabilities Dempster-Schafer, Bayesian Networks, etc. [16 nally, pattern-base management is not a mature technology: as a recent survey shows [6], it is quite cumbersome to leverage their functionality through objectrelational technology and therefore, their design and engineering is an interesting topic of research References 1] Common Warehouse Metamodel \(CWM http://www.omg.org/cwm, 2001 2] ISO SQL/MM Part 6. http://www.sql99.org/SC32/WG4/Progression Documents/FCD/fcddatamining-2001-05.pdf, 2001 3] Java Data Mining API http://www.jcp.org/jsr/detail/73.prt, 2003 4] Predictive Model Markup Language \(PMML http://www.dmg.org 


http://www.dmg.org pmmlspecs v2/pmml v2 0.html, 2003 5] S. Abiteboul and C. Beeri. The power of languages for the manipulation of complex values. VLDB Journal 4\(4  794, 1995 6] B. Catania, A. Maddalena, E. Bertino, I. Duci, and Y.Theodoridis. Towards abenchmark for patternbases http://dke.cti.gr/panda/index.htm, 2003 7] L. De Raedt. A perspective on inductive databases SIGKDD Explorations, 4\(2  77, 2002 8] M. Escobar-Molano, R. Hull, and D. Jacobs. Safety and translation of calculus queries with scalar functions. In Proceedings of PODS, pages 253  264. ACMPress, 1993 9] V. Ganti, R. Ramakrishnan, J. Gehrke, andW.-Y. Loh A framework for measuring distances in data characteristics. PODS, 1999 10] T. Imielinski and H. Mannila. A database perspective on knowledge discovery. Communications of the ACM 39\(11  64, 1996 11] T. Imielinski and A. Virmani. MSQL: A Query Language for Database Mining. Data Mining and Knowledge Discovery, 2\(4  408, 1999 12] P. Kanellakis, G. Kuper, and P. Revesz. Constraint QueryLanguages. Journal of Computer and SystemSciences, 51\(1  52, 1995 13] P. Lyman and H. R. Varian. How much information http://www.sims.berkeley.edu/how-much-info, 2000 14] R.Meo, G. Psaila, and S. Ceri. An Extension to SQL for Mining Association Rules. Data Mining and Knowledge DiscoveryM, 2\(2  224, 1999 15] S. Rizzi, E. Bertino, B. Catania, M. Golfarelli M. Halkidi, M. Terrovitis, P. Vassiliadis, M. Vazirgiannis, and E. Vrachnos. Towards a logical model for patterns. In Proceedings of ER 2003, 2003 16] A. Siblerschatz and A. Tuzhillin. What makes patterns interesting in knowledge discovery systems. IEEE TKDE, 8\(6  974, 1996 17] D. Suciu. Domain-independent queries on databases with external functions. In Proceedings ICDT, volume 893, pages 177  190, 1995 18] M.Terrovitis, P.Vassiliadis, S. Skadopoulos, E. Bertino B. Catania, and A. Maddalena. Modeling and language support for the management of patternbases. Technical Report TR-2004-2, National Technical University of Athens, 2004. Available at http://www.dblab.ece.ntua.gr/pubs Proceedings of the 16th International Conference on Scientific and Statistical Database  Management \(SSDBM  04 1099-3371/04 $ 20.00  2004 IEEE pre></body></html 


The reason of the hiding failure of SWA is the same in Fig.8 Notice the result at x = 0.7646 in Fig.14, because the hiding failure is occurred at the seeds of the sensitive patterns, a high weakness is produced As shown in Fig.15 and Fig.16, the misses cost and dissimil arity of our work decreases as RL2 increases. This is because the larger RL2 is, the less effect on non-sensitive patterns. Also weakness and dissimilarity of SWA are independent of RL2 5. Conclusion In the paper, a novel method improving the balance between sensitive knowledge protecting and discovery on frequent patte rns has been proposed. By setting entries of a sanitization matrix to appropriate values and multiplying the original database by the matrix with some probability policies, a sanitized database is gotten. Moreover, it can avoid F-I Attack absolutely when the confidence level given by users approximates to 1. The experimental results revealed that although misses cost and dissimilarity between the original and sanitized database of our process are little more than SWA, ours provide more safely protection than SWA. Unlike SWA, our sanitization process could not suffer from F-I Attack and the probability policies in our approach also take the minimum support into account, the users only need to decide the confidence level which affects the degree of patterns hiding 6. Reference 1] M. Atallah, E. Bertino, A. Elmagarmid, M. Ibrahim and V. Verykios Disclosure Limitation of Sensitive Rules", Proc. of IEEE Knowledge and Data Engineering Exchange Workshop 1999 2] R. Agrawal and R. Srikant. Fast algorithms for mining association rules. VLDB, Santiago, Chile, 1994 3] R. Agrawal and R. Srikant. Privacy preserving data mining. In ACM SIGMOD, Dallas, Texas, May 2000 4] E. Dasseni, V. Verykios, A. Elmagarmid and E. Bertino, Hiding Association Rules by Using Confidence and Support", Proc. of 4th Intl Information Hiding Workshop \(IHW 5] A. Evfimievski, J. Gehrke, and R. Srikant. Limiting Privacy Breac hed in privacy preserving data mining. SIGMOD/PODS, 2003 6] A. Evfimievski, R. Srikant, R. Agrawal, and J. Gehrke. Privacy preserving mining of association rules. KDD 2002 7] M. Kantarcioglu and C. Clifton. Privacy-preserving distributed mining of association rules on horizontally partitioned data. In ACM SIGMOD Workshop on Research Issues on Data Mining and Knowledge Discovery, June 2002 8] Guanling Lee, Chien-Yu Chang and Arbee L.P Chen. Hiding sensitive patterns in association rules mining. The 28th Annual International Computer Software and Applications Conference 9] Y. Lindell and B. Pinkas. Privacy Preserving Data mining. In CRYPTO, pages 36-54, 2000 10] S. R. M. Oliveira and O. R. Za  ane. Privacy Preserving Frequent Itemset Mining. In Proc. of IEEE ICDM  02 Workshop on Privacy Security, and Data Mining 11] S. R. M. Oliveira and O. R. Za  ane. Algorithms for Balancing Priv acy and Knowledge Discovery in Association Rule Mining. IDEAS  03 12] S. R. M. Oliveira and O. R. Za  ane. Protecting Sensitive Knowledge By Data Sanitization, ICDM  03 13] S. R. M. Oliveira, O. R. Za  ane and Y  cel Saygin. Secure Association Rule Sharing, PAKDD-04 14] Benny Pinks. Cryptographic Techniques For Privacy-Preserving D ata Mining. ACM SIGKDD Explorations Newsletter Vol. 4, Is. 2, 2002 15] S. J. Rizvi and J. R. Haritsa. Maintaining data privacy in association rule mining. VLDB, 2002 16] J. Vaidya and C. W. Clifton. Privacy preserving association rule mining in vertically partitioned data. KDD2002 17] Verykios, V.S.; Elmagarmid, A.K.; Bertino, E.; Saygin, Y.; Dasseni E. Association rule hiding. IEEE Transactions On Knowledge And Data Engineering, Vol. 16, No. 4, April 2004 Proceedings of the 29th Annual International Computer Software and Applications Conference  COMPSAC  05 0730-3157/05 $20.00  2005 IEEE pre></body></html 


pre></body></html 


Batt Power Batt Type Stabilization Type Propulsion Mechanism  of Solar Panels  of Solar Cells Manufacturing Qty Satellites in Constellation On-Orbit Spares Channels Number of Bands Data Storage Processing Power Source type Block Name Thermal Control Material Type Level of Technology Known Inheritance Propulsion station keeping Number of Axes Ground Based Spares Pointing Accuracy APPENDIX C EXISTING MODELS Numerous models are today in use for estimating spacecraft cost Two of the most common are the NASA/Air Force Cost Model and the Aerospace Small Satellite Cost Model Here is a description of the NAFCOM model The NASA/Air Force Cost Model NAFCOM is a parametric estimating toolfor space hardware It is based on historical NASA and Air Force space projects and is primarily used in the very early phases of a development project NAFCOM can be used at the subsystem or component levels The database currently includes 122 missions including 76 unmanned earth orbiting 24 unmanned planetary 11 launch vehicles 8 manned 3 engines It uses parametric relationships to estimate subsystem or component level costs for any aerospace hardware including earth orbital spacecraft manned spacecraft launch vehicle upper stages liquid rocket engines scientific instruments or planetary spacecraft 7 And for the Aerospace Small Satellite Cost Model SSCM employs a parametric methodology for estimation of program cost and is best suited to the early conceptual development phase of a spacecraft program during which time the design is likely to be less mature and when cost and performance trades can be easily performed SSCM consists of a collection of cost-estimating relationships or CERs which estimate the costs of developing andproducing a spacecraft system with the following subsystems  Attitude Determination and Control Subsystem ADCS  Propulsion  Power  Telemetry Tracking  Command TT&C  Command  Data Handling C&DH  Structure  Thermal CERs were also developed for integration assembly and test IA&T program management PM and systems engineering SE and launch and orbital operations support LOOS Individual subsystem cost estimates are statistically rolled up to yield a cost-risk distribution which provides the estimator with a range of cost estimates andpercentiles 8 The SSCM was calibrated from over 100 post-1990 Earth-orbiting andplanetary missions REFERENCES 1 Lack of Disciplined Cost-Estimating Processes Hinders Effective Program Management GAO study 04-642 2 Jilla Cyrus D and Miller David W Satellite Design Past Present and Future International Journal of Small Satellite Engineering 12 February 1997 3 Bearden David A A Complexity Based Risk Assessment of Low-Cost Planetary Missions:When Is A Mission Too Fast and Too Cheap Fourth IAA International Conference On Low-Cost Planetary Missions JHU/APL MAY 2-5 2000 4 Kellogg Mahr and Lobbia An Analogy-based Method for Estimating the Costs of Spacecraft IEEEAC paper 1371 Version 4 5 Hoeting Jennifer A Methodology for Bayesian Model Averaging An Update f 6]btp/ewiieiao iiAaos 7 Keith Smith NASA/Air Force Cost Model Science Applications International Corporation 8 18 


BIOGRAPHIES Lee Fischman served as Principle Investigator for this project Lee is Senior Director of Development at Galorath Incorporated where he directs much of the new product development and research at the firm He developed SEER for Software  Hardware Integrations with Microsoft Project the Comparison Sizing tool COTS Software model in addition to various data mining information extraction and expert systems Previously he was a software designerlprogrammer in the New York financial industry Lee earned a BA from the University of Chicago and an MA from UCLA both in economics Mike Kimel carried out statistical work on the project Mike is an Economist for Galorath Inc in addition to maintaining his own quantitative consulting practice He has also taught Economics and Advanced Statistics at the Graziadio School of Business and Management at Pepperdine University run the Competitive Strategy group for a Fortune 500 Telecom Company and worked as a Consultant at PriceWaterhouse LLC now PriceWaterhouse-Coopers He earned a Ph.D in Economicsfrom UCLA Troy Masters programmed analytic methods and is integrating the Far Out model into its parent product SEER for Hardware previously SEER-H Troy is a Software Engineer with Galorath Incorporated where he has been the primary developer for a range ofproducts He earned a BS in computer science from UCLA David J Pine was our subject matter expert helping us assemble data and gain insight into technical trends Dave is retired after a 34-year career with the National Aeronautics and Space Administration NASA currently is a consultant to various government and industry entities While at NASA his organizations in the Office of the Chief Financial Officer and later at the IPAO at Langley Research Center were responsible for the conduct of major NASA program analyses and evaluations for the NASA Administrator and Deputy Administrator From early 1988 through the end of 1990 he was the Deputy Program Manager for the Hubble Space Telescope Program specifically responsible for the telescope operations and science support aspects of the program He earned a BS in Aerospace Engineering from the Polytechnic Institute of Brooklyn and a Masters of Engineering Administration from the George Washington University 19 


  20 Angeles, where he also received a B.S. in Applied Mathematics  Eric Fetzer is a Senior Member of the Technical Staff at the Jet Propulsion Laboratory, Pasadena, California specializing in satellite observations of the atmosphere.  His scientific interests include planetary boundary layer processes, tropical phenomena, upper tropospheric variability, and climatologies of temperature, water vapor and clouds.  His technical interests include analysis of large data sets, and of multi-sensor observations. He has over 20 peer-reviewed publications and given numerous scientific presentations, public lectures and media interviews about climate science. Eric received a B.A. in Physics from the University of California Berkeley, and a Ph.D. in Astrophysical, Planetary and Atmospheric Sciences from the University of Colorado, Boulder   Amy Braverman is a Senior Statistician at the Jet Propulsion Laboratory, California Institute of Technology She holds a B.A. in Economics from Swarthmore College an M.A. in Mathematics from UCLA, and a Ph.D. in Statistics also from UCLA. Prior to her current position in JPL's Science Data Understanding Group, she was a Caltech Post-doctoral Scholar at the Jet Propulsion Laboratory, and a Scientist in the Flight Sciences Experiments Section of the Science Division. Dr Braverman conducts research on information-theoretic methods for the analysis of massive data sets and streams statistical data fusion, high-dimensional data analysis, and statistical analysis for climate model evaluation and diagnosis. She has published in both the statistics and geoscience literature, and is active in both communities She is a member of the Multi-angle Imaging SpectroRadiometer Science Team, and serves as a member of the Atmospheric Infrared Sounder Science Integration Team. Her responsibilities on both missions include designing data reduction algorithms for massive, remote sensing data sets. Dr. Braverman also holds an appointment in the Department of Statistics at UCLA as Adjunct Associate Professor, and is active in UCLA\222s Center for Environmental Statistics. She is member of the Committee on Applied and Theoretical Statistics of the US National Academy of Science. She has refereed for the Journal of the American Statistical Association, the Journal of Computational and Gr aphical Statistics, IEEE Transactions on Geoscience and Remote Sensing, and the Journal of Applied Meteorology and Climatology Seungwon Lee is a senior member of the High Capability Computing and Modeling Group at Jet Propulsion Laboratory. She is conducti ng research on comet gas dynamics, nonlinear dynamics control, climate model parameterization, Earth science data analysis, parallel computing, and advanced numerical algorithms. She received her Ph.D in Physics fr om the Ohio State University and her M.S. and B.S. in Physics from the Seoul National University, Korea  Matthew Henderson is software engineer in the High Capability Computing and Mode ling group at JPL. His current work includes Web Services and Instrument Data Level 2 subsetting. He received a B.S. Computer Science from CSU Pomona, and is currently pursuing M.S Computer Science  Steven J. Lewis is a member of the Information System and Computer Science staff member at the Jet Propulsion Laboratory.  He received a BS in Mathematics from the University of California, Los Angeles in June 2001, and the MS and Ph.D. Degree from Claremont Graduate University in May 2004 and May 2007, respectively.  He worked as a post doctoral fellow at Keck Graduate Institute from June 2007 until he joined JPL in March of 2008.  During his graduate and post doctoral work, his studies focused on applications of Bayesian methods to hidden Markov models with particular interest and application to protein sequencing.  His work at JPL has focused on integrating web services into various programming platforms for the purposes of accessing NASA satellite data, as well as developing object tracking so ftware and contributing to image enhancement and restoration efforts Van Dang is a member of the Science Data Understanding Group at the Jet Propulsion Laboratory. She was responsible for the NEWS Level 2 processing that generated the formal merged Level 2 data from multiple A-Train instruments  Manuel de la Torre is a Physicist from the Universidad Complutense at Madrid \(Spain\. After finishing his Ph.D work at the University of Bayreuth \(Germany\ on pattern formation in turbulent flows and a 7 1/2 year stunt as Ass and Assoc. Prof. at the Escuela T\351cnica Superior de Ingenieros Aeron\341uticos in Madrid \(Spain\, he came to the Jet Propulsion Laboratory on a 1-year Sabatical leave in 1997 wanting to apply fundamental concepts of nonlinear systems and geophysical fluid dynamics to something that might be directly useful to soci ety. He discovered the JPL as a great place to achieve that goal and extende d his stay a bit longer, becoming Technical staff and working on different aspects of remote sensing, validation of satellite instruments, and data analysis of atmospheric processes and climate  


