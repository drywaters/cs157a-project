html><head></head><body><pre style="word-wrap: break-word; white-space: pre-wrap;">2004 IEEE  International Conference on Systems, Man and Cybernetics Adjustable Discovery of Adaptive-Support Association Rules for Collaborative Recommendation Systems Sbyue-Liang Wang Mei-Hwa Wang, Wen-Yang Lin Tzung-Pei Hong Department of Computer Science Institute of Information Department of Electrical New York Institute of Technology Management Engineering New York, USA I-Shou University National Kaohsiung University slwang@nyit.edu Kaohsiung, Taiwan Kaohsiung, Taiwan wylin@isu.edu.tw tphong@nuk.edu.tw Abstract - In this work, we propose an adjustable step size data-mining algorithm to discover Adaptive-Support Association Rules \(ASAR  support association rules are constrained association rules with application to collaborative recommendation systems. To discover association rules for recommendation systems, minimum conference and a specific target item in association rules are usually assumed and no minimum support is specified in advance Based on size monotonociry of associatian rules, i.e., the number of association rules decreases when the minimum support increases, on efJicient algorithm using adjustable step size for finding minimum support and therefore adaptive-support association rules is presented Experimental comparison with the fued  step size iterative approach shows that our proposed technique requires less computation, both running time and iteration steps, and will alwaysfind a corresponding minimum support Keywords: data mining, adaptive-support association rules, collaborative recommendation system 1 Introduction Data mining has recently attracted tremendous amount of attention in the database, artificial intelligence and machine learning research because of its wide application in many areas, such as market basket analysis prediction, decision support, financial forecast, world wide web and collaborative recommendation Collaborative recommendation \(sometimes known as collaborative filtering on the preferences and actions of a group of users is tracked by a system which then, based on the patterns it observes, tries to make useful recommendations to individual users. Many techniques have been proposed for collaborative recommendation over the past decade In addition to the classical linear correlation-based method [l  11, there are Bayesian classifier and Bayesian network model [SI, neural networks paired with feature reduction techniques [4], graph-theoretic approach [2 and data mining approach [7,8]. For the data mining approach, constraint-based association rules such as class association rules [SI and adaptive-support association rules [7] techniques have been proposed. In this work, we are particularly interested in improving the efficiency of discovering ASARs for collaborative recommendation systems For a given data set, the discovery of ASARs assumes that a target item, a specified minimum confidence and a desired range for the number of rules are given. It proceeds to discover association rules with the target item in the beads of the rules. Such that the number of rules is in the desired range and the rules have the highest possible support. In [7], an algorithm called ASARM is proposed to discover this type of rules. The algorithm is a variant of the CBA-RG [SI and therefore of the Apriori algorithm [l]. It differs from those two algorithms in that frequent itemsets and rules are generated simultaneously. However, in the process of calculating minimum support in order to obtain desired number of rules, the ASARM algorithm uses a fixed step size iterative approach, which may not be quite efficient and might not he able to find the minimum support for 


and might not he able to find the minimum support for some desired range of association rules. In this work, we propose an adjustable step size approach to calculate the minimum support and therefore ASARs. Experimental comparison with the fixed step size adjustment approach shows that OUI proposed technique requires less computation, both running time and iteration steps, and will always find a corresponding minimum support The rest of our paper is organized as follows Section 2 reviews the problem of the discovery of ASARs Section 3 presents the proposed data-mining algorithm Section 4 shows the numerical comparison with the fixed step size approach. A conclusion is given at the end of paper 2 Problem Statement This section reviews the basic definition and terminology of association rules and adaptive-support association rules 0-7803-8566-7/04/$20.00 0 2004 IEEE 3250 2.1 Mining of Association Rules The problem of mining association rules was introduced in [ l ] .  Let I = {i,, i,;.., i, } he a set of literals, called items. Given a set of transactions D, where each transaction. T is a set of items such that T I., an association rule is an expression X 3 Y where x E I ,  Y E  I ,  and x n Y = \(. The X and are called respectively the body and head of the rule. An example of such a rule is that 90% of customers buy hamburgers also buy Coke. The 90% here is called the confidence of the rule, which means that 90% of transaction that contains x also contains Y.  The support of the rule is the percentage of transactions that contain both X and Y ,  In other words, the confidence of a u l e measures the degree of the correlation between itemsets while the support of a rule measures the significanci: of the correlation between itemsets. The problem of miring association rules is to find all rules that satisfy a user specified minimum support and minimum confidence As an example, assuming that we have a data set of visited web page as listed in Table I .  Given minimum support of 20% and minimum conference of 80%, the 28 association rules that satisfy these thresholds are listed in Table 2 Table 1. Sample data set User ID 1 Visited web pages 1 I hd I j . l  - 4 " I -1 VRAF 2.2 Adaptive-Support Association Rules The problem of mining adaptive-support associalion rules was introduced in [7] .  It is a constrained associalion rule intended for collaborative recommendation systems For recommendation, a specific value of target item rnay he assumed. This target item is the item that will be recommended to users in a collaborative recommendation system. In addition, it is not necessary to mine an arbitrarily large rule set containing all rules above a minimum support level. In fact, a desired number \(or  3251 range given minimum confidence value, wherein no minimum support is specified. Therefore, the problem of mining ASARs can be described as follows Input: Dataset T , targetltem, minconfidence, Nmin  Output: A set S of adaptive-support association rules such that the head of each rule is targetltem, the number of rules in S is in [N,,,;., Nmm], and the confidence of each rule is greater than or equal to minconfidence 


to minconfidence Notice that the number of rules for a given minconfidence may he less than the desired range of rules N,;,,, N,,]. In this case, all rules found will he output Furthermore, no rule outside S with confidence greater than or equal to the minconfidence has a higher support than a rule in S As an example, given a data set as in Table I ,  a target item V, a minimum confidence of 80%, and desired range of rules [5,10], the adaptive-support association rules that can be found are shown in Table 3 Table 3. The adaptive-support association rules found from Table 1 3 The Proposed Algorithm This section describes the proposed algorithm based on adaptive adjustment of minimum supports, to discover ASARs more efficiently. The adjustment of minimum supports in [7] has fixed step size, for example 1%. Based on the property that the number of rules decreases monotonically as support increases, we adjust the minimum supports based on the iterative Secant concept. Secant method is an iterative approach for finding the roots of non-linear functions. It assumes that the derivative of the function is unknown. Hence, two initial points are required to approximate the derivative of a function in looking for the root of an unknown function Depending on the midpoint of zero and support of target item, if the midpoint is assumed as the minimum support and it produces association rules that are greater than N,,  , then the midpoint and the support of target item are assumed to be the initial points. Otherwise, zero and the midpoint are assumed to he the initial points. If the number of association rules generated by the current initial minimum support lies in the desired range, ASARs are found. If the number of rules is not in the desired range, a third point is calculated from the first two points Then the second and third points are used as the new initial points. This process repeats itself until the correct minimum support is found. The proposed Secant-based algorithm is described as follows Input Output: Mfminimum support 1. Right = support count of targetltem 2. Left = 0 3. Mid = \(Leff+Right 4. N = AR - F T \( T ,  targetltem, minCond, Mid 5 .  N, =\(Nmi, +N 6.  if \( N E  \(N,,, NmaX 7. if \(N &gt; Nma 8. x,, =Right 9. x , = M i d T, targetltem, minconjdence, N, N 10 11. if \(N &lt; N 12. x,, =Left 13. X, = M i d 14 15. while \(N gL \(Nmin, NmaX 16 17 18 x2 = \(x, , N I  - N ,  x,, - X, .No i N ,  . x N, -No 19. N = AR - FT\(T,targetZtem, minCond, x 2 20. if N = NI then xI = x2 21. e l s e i f N = N , , t h e n x , , = x 22 23 24. return x2 No = AR - F T \( T ,  targetltem, minCond, x N I  = AR - F T \( T ,  targetltem, minCond, x else xg = xI , xl = x 2 4 Experimental Results 


4 Experimental Results To show the efficiency of the proposed Secant-based technique for the discovery of adaptive-support association rules, we have implemented the algorithm in section 3 and compare it with the fixed step sire approach adopted in [7]. In our implementation, the FTAR in line 4 of the algorithm is an Apriori-based association rule module with fixed target item. For the fixed step size approach, we have implemented a program similar to ASARMl algorithm in [7]. But a major difference is that we do not generate frequent itemsets and rules simultaneously All programs are written in C and run on the same 1.7 GHz Pentium 4 PC with 512 MB of memory running Red Hat Linux operating system release 8.0 We ran the algorithms on a data set called Assocmdb included in the XpertRule Miner software which has two tables: Basket-Data.xls and Basket-Data-Test.xls. The former has 5,000 records of transactions dataset and the later has 4,970 records. In this dataset, there are IO different items and the average length of itemsets is 3.5135, with maximum itemset length 6 and minimum itemset length 1 Figures 1 and 2 show the running time and number of steps required for desired rule range [ I ,  IO respectively for both approaches. It can be observed that for small data sires, the performance of either approach is about the same for small range of rules. But the proposed Secant-based approach is more efficient when data size gets larger Compison  of Fixed and Secanr \(N" time Desiredmnge [l,101  E 2wo I I I Data size \(loo0 records Figure lRunning Time Comparison of Fixed and Proposed Secant Approaches for Desired Rule Range [I 101 3252 Comparison of Fixed and Secant \("Jesteps m e  l1,101 30 2 20 01 10 z 0 1 2 3 4 S 6 7 8 9 10 Data sire \(1wO records Compuison ofFined and Secant \(mn time range 120,301 d 3WO 1 d 2000 I loo0 E 1 E o 1 2 3 4 5 6 Data size \(5CQ records a I Figure 2Number-of-Step Comparison of Fixed and Proposed Secant Approaches for Desired Rule Range [I 101 Figures 3 and 4 show the running time and number of steps required for desired rule range [ZO, 301 respectively for both approaches. When the desired range of rules is large, it can be observed that !he performance of Secant-based approach is obviously more efficient for any data sizes. In fact, the experiments have been cacied out on various data sizes up to 100,000 records with similar effects Figure 3Running Time Comparison of Fixed and Proposed Secant Approaches for Desired Rule Range 120 301 


301 1 Compuison oiFired and Secant \(No-steps I I 0 '  I I I 2 3 4 5 6  Data size \(SW records Figure 4Number-of-Step Comparison of Fixed md Proposed Secant Approaches for Desired Rule Range 120 301 In some cases, fixed step size approach might not be able to find the minimum support corresponding to a desired range of rules. This is due to  the fact that the number of rules corresponding to two consecutive guesses of minimum supports lie outside of the desired range. One is smaller than Nmi, and the other is greater than Nmm. To resolve this problem, step size must be refined in fixed step approach. However, no such problem occurs for the proposed Secant-based approach 5 Conclusion Adaptive-support association rules are constrained association rules with application to collaborative recommendation systems. In this work, we have proposed an eficient data-mining algorithm for the discovery of adaptive-support association rules. Simulation results have demonstrated that its performance is more efficient than the fixed step size approach adopted in [7]. However our implementations d o  not generate frequent itemsets and association rules simultaneously as in [7]. This may require further investigation for performance comparisons References I ]  Agawal, R., hielinski, T. and Swami A.: 1993, Mining Association Rules between Sets of Items in Large Databases In: Proc. of the ACM SIGKDD Conference on Management of Data Washington, D.C., pp. 207-216 2] Agganval, C. C., Wolf, J. L., Wu, K. L. and Yu, P S Horting Hatches an Egg: A New Graph-Theoretic Approach to Collaborative Filtering. In Knowledge Discovery and DataMining. pp. 201-212, 1999 3] Balabanovic, M. and Y. Shoham: 1997, Fab Content-Based Collaborative Recommendation Communications of the ACM 40 \(3 Billsus, D. and Pazeani, M.J. 199% Leaming collaborative information filters. In Proc. Of the Fifteenth International Conference on Machine Leaming, Madison, Wisconsin Morgan Kaufmann Publishers 5] Breese, J., Heckerman, D., and Kadie, C. 1998. Empirical analysis of predictive algorithms for collaborative filtering In Proceedings of the Fourteenth Conference on Uncertainty in Artificial Intelligence, Madison, WI 6] Cooky, R., Tan, P-N., and Srivastava 5.:1999, WebSIFT The Web Site Information Filter System. In: Proc. of the Workshop on Web Usage Analysis and User Profiling WebKDD99 htto:!/,~.acm.or~sipkddioroceedines/~,ebk dd99 7] Lin, W.Y., Sergio A. A., and Ruiz, C., 2002 Jan., Effcient adaptive-support association rule mining for recommender systems. Data Mining and Knowledge Discovery, 6 \(1 105 8] Liu, B., Hsu, W. and Ma, Y. 1998, Integrating Classification and Association Rule Mining. In Proceedings of the Fourth lntemational Conference on Knowledge Discovery and Data Mining, New York, pp. 80-86 9] Sanvar, B.:2001, Sparsity, Scarsity, Scalability, and Distribution in Recommender Systems. Ph.D. thesis University of Minnesota 4 3253 lOISchafer, J .  B., Konstan, 1. A., and Riedl, 1.:2001, E Commerce Recommendation Application Data Minig and Knowledge Discovery, S, pp. 115-153 lllshardanand, U. and Maes, P. 1995. Social information filtering: Algorithms for automating word of mouth. In Proceedings of the Conference on Human Factors in Computing Systems \(CHI95 


2 10-2 17 12]Srikant, R., Vu, Q., and Agrawal, R.: 1997, Mining Association Rules with Constraints, KDD, 1997 3254 pre></body></html 


reader's convenience. In actual cases the top ranked terms are selected as topic descriptors 3.3 Extracting Highly Informative Terms In our third experiment we began with just a simple question or a phrase. This phrase was fed into the Google search engine. The query results were analyzed by the AR algorithm, and the highest ranked terms were collected for further use. We then used the highest ranked terms to expand the original query and refine the search. The following table holds the query phrases, the AR algorithm highest ranked terms, the revised search phrase and it's first retrieved web page Table 5.  Using the AR Algorithm to Extract Highly Informative Terms \(The extracted terms are used for query expansion Original Query Phrase AR Highest Ranked Phrases Revised Query Phrase Topic of the First Retrieved Page  Sleep and appet-ite depressed mood anxiety disorder Sleep and appetite Depressed mood anxiety disorder Informatio nal Reports on Depression and Stress What is the origin of the human race racial evolution ancient scientific What is the origin of the human race racial evolution ancient scientific The Races of Humanity What is the furthest star in the solar system orbiting asteroid gravitational pluto What is the furthest star in the solar system orbiting asteroid gravitational Pluto HubbleSite All FAQs for Solar System Hitchc-ock movies marnie lodger vertigo psycho Hitchcock movies marnie lodger vertigo psycho Auteur theory of Alfred Hitchcock Once again the AR algorithm extracted terms that served as descriptors and could be used for farther query expansion. We chose to expand the query phrase by simply adding the first four terms extracted by the AR algorithm A different approach would have been to give the user the list of extracted terms. The user would then be able to select from the list the most suitable terms to be added to the original query phrase Note that the question "what is the furthest star in the solar system?" was not stated properly, since the users meant to find the furthest Planet and not Star. The AR algorithm was able to find the term, "Pluto" \(the fourth of the ranked terms\ despite this "mistake". Furthermore, very common terms such as "who", "what", "is" are ignored by the Google search engine. Thus, for example, the query what is the furthest star in the solar system", translated to only four terms "furthest, star, solar, and system 3.4 Discussion This chapter presented three different approaches for validation of the AR algorithm. First - the "Free Associations Turing Test" confronts the question whether the AR algorithm can "imitate" human associations. The second - analyzing proxy logs deals with the question whether the AR algorithm can extract human-interest topics from the user's surfing history. And finally, the third part deals with the question whether the AR algorithm can help the user to better express his thoughts and reach valuable information more efficiently While the answer to the first question is based on a solid statistical base \(we compared ten association rules measures, 100 seed terms, 70 different questionnaires and 900 people who answered the different questionnaires\e latter two were based on much smaller samples. Thus the conclusions were qualitative rather than quantitative. Still we believe that the potential for creating a user profile or using the AR algorithm to extract highly informative phrases has been shown 4 Concluding Remarks The AR algorithm that extracts highly informative phrases was shown capable of both "imitating" humans by creating human-like associations and giving highly informative descriptors of Internet pages. The extracted descriptors were used to reveal the user current interest topics and to supply query expansion terms. The algorithm complexity is low, and can be performed in near real-time The success of the algorithm raises the question whether actual human thinking processes are performed similarly The algorithm is rather robust and can be employed for various usages, or to even use other asymmetrical association measures as links between concepts. One of the most promising usages we forecast for this algorithm is user conceptual modeling and prediction. By using the AR algorithm to extract concepts and associations from the pages the user visits, an analysis of "flow" in a conceptual graph can show trends and determine the probability for the user to reach certain concepts within his current surfing session. In future work we intend to identify common properties for similar users, and define a profiling technique based on the random walk algorithm Many other interesting challenges are still waiting to be addressed in the web search algorithms area. For a good review of the most promising is the partitioning of the web by eigenvectors s   5 References   A  Fara h a t, T  L o Faro, an d J  C  Miller Modification of kleinberg's hits algorithm using matrix exponentiation and web log records Proceedings of the 24th International Conference on Research and Development in Information Retrieval SIGIR 2001 New Orleans, USA, September 2001   A  A  Freita s O n r u le i n ter estingn es s m eas u r es   Knowledge-Based Systems 12, 2000, pp. 309-315 Proceedings of the Fifth IEEE International Conference on Data Mining \(ICDM05 1550-4786/05 $20.00  2005 IEEE 


 A  M   T u ring   Computing machinery and intelligence Mind Vol. 59, No. 236, 1950 pp. 433460 4   A  P  Sa ygi n I  Ci c e kl i  a n d V Ak m a n  T ur i ng Test: 50 Years Later Minds and Machines 10\(4 2000, pp. 463-518   C  R  MacC l u er, "T h e m a ny p r oof s an d application s  of Perronss theorem SIAM Rev 42\(3\0, pp 487498   Gan t m ach er F R   The Theory of Matrices  Volume I, II, Chelsea Publ. Co., New York, 1959  Goog le A P I. h ttp www  g oog le.co m api s   H a v e li w a la T  H an d S  D   K a m v ar The second eigenvalue of the Google matrix Stanford University Technical Report, 2003  IR C ach e I n tern et cac h i n g proj ect See http://www.ircache.net  current 6.2005   J. S h i an d J. Malik  N orm alized C u t s an d I m a g e  Segmentation Proc. Computer Vision and Pattern Recognition 1997   J.R S earl   Minds, Brains and Programs   Behavioral and Brain Science 3\(262\1980, pp. 2631 12   L Kl e i nb e r g J   A ut ho r i t a t i v e  so ur c e s  i n a  hyperlinked environment Proceedings of the ACMSIAM Symposium on Discrete Algorithms 1998  M  D   Wils on   The MRC Psycholinguistic Database: Machine Readable Dictionary   Behavioral Research Methods, Instruments and Computers 20\(1\1988, pp. 6-11   M.R Hen zi n g e r A l g orithm i c C h alle ng es in Web Search Engines Internet Mathematics Vol. 1, No 1, 2003, pp. 115-126  Mich ie D  Turing's Test and Conscious Thought   in P. Millican and A. Clark, eds Machines and Thought: The Legacy of Alan Turing Oxford, UK Oxford University Press, 1996, pp. 27-51   N  D e o, an d P G u pta S a m p ling t h e Web With  Random Walks Congressus Numerantium 149 2001\, 32nd Southeastern International Conference on Combinatorics, Graph Theory and Computing Feb. 26 - Mar. 2, 2001, Baton Rouge, LA. pp. 143154   N  D e o, an d P. G u pta G raph T h e oretic Web  Algorithms: An Overview Lecture Notes in Computer Science eds. T. Bhme and H. Unger 2026 \(2001\Innovative Internet Computing Systems, June 21-22, 2001, IImenau Technical University, Germany, pp. 91-102   N e ls on D  L C  L  M c Ev o y an d S c h r eiber T  A   The University of South Florida Word Association Rhyme, and Word Fragment normsNorms 2002 See http://w3.usf.edu/FreeAssociation/Intro.html Current 6.2005   P   T a n  V. Kum ar, an d J  Sriv asta v a  S electing th e  right interestingness measure for association patterns   Technical Report 2002-112 Army High Performance Computing Research Center, 2002  P.D  T u rn e y   Answering Subcognitive Turing Test Questions: A reply to French   Submitted to the Journal of Experimental and Theoretical Artificial Intelligence, 2001    R  L e m p el a n d S   M o rran  SALSA: The stochastic approach for link-structure analysis ACM Transactions on Information Systems 19\(2\001  R   T a m i r  On Confidence Gain Measure for Association Rules Generation and Scoring VLDB Journal forthcoming, 2005   R  T a m i r, an d R  R a pp  M in in g  th e Web to Discover the Meanings of an Ambiguous Word Proceedings of the third IEEE international conference on data mining 19-22 November 2003 Melbourne, Florida, pp. 645  R  M Fren ch   Subcognition and the Limit of the Turing Test   Mind Vol. 99, No. 393, 1990, pp. 5365 25  R  M   S h if f r in    Modeling Memory and Perception   Cognitive Science 27, 2003, pp. 341-378   S. Brin an d L  P a g e  T h e anato m y o f a larg e s cale hypertextual Web search engine Proceedings of the 7 th International World Wide Web Conference Brisbane, Australia 1998  S t ran g  G   Linear Algebra and Its Applications  Third Edition, Harcourt Brace Jovanovich Publishers, San Diego, 1988 28   T J  Pa l m e r i  A n ex em p l ar b a s e d r a n d om  w a lk  model of perceptual categorization". M. Ramscar, U Hahn, E. Cambouropolos, & H. Pain \(Eds Proceedings of the Interdisciplinary Workshop on Similarity and Categorisation Edinburgh, Scotland University of Edinburgh \(1997\p. 181-187 Proceedings of the Fifth IEEE International Conference on Data Mining \(ICDM05 1550-4786/05 $20.00  2005 IEEE 


9 Here are some observations and explanations on the results 1\The total time of our comparison includes the time to write the association rules to a file; Bit-AssocRule is 2 to 3 orders of magnitude faster than the various Apriori algorithms \(64-221 times faster\he test data set, the big the time difference between the BitAssocRule and the various Apriori algorithms. We havent compared our algorithm with some of the other association rule algorithms such as VIPER  13,24] \(CHARM and CL OSE are base d on the closed frequent itemsets concept\d on their published comparison results with Apriori, our BitAssocRule is very competitive compared to them and a direct comparison will be conducted and reported in the near future 2\e or litter longer time than the various Apriori algorithms in constructing the 1-itemsets because of the extra cost of building the bitmaps for the 1-itemsets. But after the 1-itsemtset is done, Bit-AssocRule is significant faster than the Apriori algorithms in constructing large frequent itemsets because it only uses the fast bit operations \(AND COUNT and SHIFT\nd doesnt need to test the subsets of the newly candidate 3\aps of the frequent items, and the bitmap storage \(uncompressed less than the original data set \(1/2 to 1/4 of the original data size The main reasons that Bit-AssocRule algorithm is significant faster than Apriori and its variations are 1\ocRule adopts the divide-and-conquer strategy, the transaction is decompose into vertical bitmap format and leads to focused search of smaller domain There is no repeated scan of entire database in BitAssocRule 2\snt follow the traditional candidate-generate-and test approach, thus saves significant amount of time to test the candidates 3\basic operations are bit Count and bit And operations, which are extremely faster than the pattern search and matching operations used in Apriori and its variations 5. Conclusion The contributions of this paper are in two aspects:  we extend the application domains of bitmap techniques and introduce the bitmap techniques for complex DSS query optimization and association algorithm. We present a bitmap based query optimization algorithm to optimize complex query with multiple table join based on outer join operations and push the outer join operations from the data flow level to the bitmap level and achieve significant performance gain.   We introduce a novel algorithm to calculate the foundset for those tables involved in the prejoin table by using prejoin_bitmap_indexes and integrate this algorithm into the current commercial data flow based query engine seamlessly. Our query optimization can achieve an order of magnitude faster than conventional query engine Secondly we introduce the bitmap technique to the data mining procedure and develop a bitmap-based algorithm Bit-AssocRule to find association rules. Our BitAssocRule avoids the time-consuming table scan to find and prune the itemsets, all the operations of finding large itemsets from the datasets are the fast bit operations. The experimental result of our Bit-AssocRule algorithm with Apriori and AprioirHybrid algorithms shows Bit-AssocRule is2 to 3 orders of magnitude faster. This research indicates that bitmap technique can greatly enhance the performance for decision support queries and finding association rule, and bitmap techniques are very promising for the decision support query optimization and DM applications Bitmap technique is only one way to improve the performance of complex DSS queries and DM algorithm Parallelism is another crucial factor to improve the performance of DSS and data mining.  We are currently working on paralleling the bitmap-based algorithms and hope to report our findings in the near future 6. References  Agrawal R. Sri kant R., Fast al gorithm for mining association rules, Prod. of the 20 th VLDB Conf. 1994  Agrawal R., Mannila H., Sri kant R., Toivone n H., Verkamo A., Fast discovery of  association rules, in Advances in Knowledge Discovery and Data Mining, MIT 1996  AIP D Tec hnical P u blications In Syba se IQ Administration Guide, Sybase IQ Release  11.2 Collection, Sybase Inc Proceedings of the Seventh International Database Engineering and Applications Symposium \(IDEAS03 1098-8068/03 $17.00  2003 IEEE 


10  er-Yahia S., Johnson T., Optimizing queries on compressed bitmaps, Prod. of the 20 th VLDB  Conf  wa l, R., Gunopul os D  Constraint-based rule mining in large, dense databases Proc. of the 15th Int'l Conf. on Data Engineering \(ICDE1999 6] Bertino E., Ooi B.C., Sacks-Davis R. etc, Indexing techniques for advanced database systems Kluwer Academic Publishers  n C Ioa nnidis Y B itm ap index design and evaluation, Prod of the  SIGMOD-96  h atziant oni ou D Akinde  M, Johnson T Kim  S, The md-join: an operator for complex olap. Prod of the 18 th Intl Conference on Data Engineering \(ICDE2001  outer join, Prod of the 2nd International Conf. on Databases   Fre nch C  One size fits all databa se arc hitecture do not work for dss, Prof of the  SIGMOD-95  hal, A., Oute r join simplification and reordering for query optimization, ACM TODS, 22\(1\1997  G., Volcano, an extensible and pa rallel query evaluation system, IEEE Transaction on Knowledge and Data Engineering, 6\(6  e i, J. Yin. Y  Mining fre quent patterns without candidate generation", Prod of the SIGMOD-2002    Hanusa R., A lesso n in outer joins \(learned the hard way!\data Review, Spring 1998  aine C., Data A A novel inde x s u pporting high volume data warehouse insertion Prod of the 25th VLDB Conf  on T , Perform ance m easurem ents of compressed bitmap indices Prod. of the 25th VLDB conf   Y Data m i ni ng and m achine oriented modeling: a granular computing approach, Journal of Applied Intelligence, Oct. 2000  Lin T.Y., Fi nding ass ociation rules using fast bit computation: machine-oriented modeling ISMIS-2000  M., Group bit map index: a structure for association rules retrieval Prod. of the 4 th Intl Conf. on Knowledge Discovery and Data Mining \(KDD-98  ONeil P Graefe G., M ulti-table joi ns  through bitmapped join indexes, SIGMOD September 1995, 8-11   ONeil P., Quass D., Im prove d que ry pe rformance with variant indexes, Prod of the SIGMOD-1997   Inform ix and inde xing s u pport for data warehouses,  Informix Whitepaper  a p join i n dex  http://technet.oracle.com/products/oracle9i/daily/a pr09.html  n, H. Lu, S. Ni shio, S. Ta ng, and D  Yang. "H-mine: hyper-structure mining of frequent patterns in large databases", Proc. The 2001 IEEE Intl Conference on Data Mining  ONeil P.,  ONeil E.,  BitSliced Index Arithmetic, Prod of the SIGMOD2001  vase re , A Om iecinski E Na vat he S  An efficient algorithm for mining association rules in large databases, in Prod. of the 21 st VLDB conf  She noy P Bhal otia G Haritsa J B a wa M Sudarshan S., Shah D., Turbo-charging vertical mining of large database, Prod. of the SIGMOD2000  a processi ng for com plex queries, Red Brick/Informix White Paper  as and starjoi n technology Red Brick/Informix White Paper  P C be nchm ark d de cision s u pport  dard specification, Release 2.2. \(Transaction Processing Performance Council \(TPC  durie x P J oi n indexe s ACM TODS 12\(2\ 1987  W u M Buchm ann A  Encoding bitm ap indexing for data warehouse, Proc. of the 14th  Intl Conference on Data Engineering, 220-231, 1998   Gouda K., F ast vertical usi ng diffsets, Tech report, Dept. of  computer science, RPI  Y., Des hpa nde P., Naughton J Shukla A.,  Simultaneous optimization and evaluation of multiple dimensional queries, SIGMOD-98, 271282 Proceedings of the Seventh International Database Engineering and Applications Symposium \(IDEAS03 1098-8068/03 $17.00  2003 IEEE 


20% 4 4 4 12 12 30% 4 3 3 12 12 40% 3 3 3 12 11 50% 3 2 2 11 10 60% 2 1 2 11 10 70% 2 1 2 11 11 80% 2 2 2 10 11 90% 2 2 2 9 10 99% 0 1 1 6 10 Looking at Table 9, one may wonder why the representation determined for minSup = 70% has shorter longest elements in its Bd  GDFree \(here: length = 1 than the representation determined for minSup = 80 here: length = 2 border elements in Bd  GDFree, which are infrequent in the representation determined for minSup = 80 become frequent when lowering the support threshold to 70 7. Related work The most similar to the representations based on generalized disjunctive sets is the NDR representation which consists of all frequent non-derivable itemsets [7 8], and the representations based on ?-free sets [7, 9]. It was shown in [8], that for each non-empty itemset Z, one can derive the lower bound \(l\(Z u\(Z on sup\(Z from the fact that sup\(Z Non-derivable itemsets are those for which u\(Z Z gt; 0. If u\(Z Z sup\(Z supersets Y of a derivable itemset are also derivable and u\(Y Y Y such that neither sup\(Z Z Z Z It was proved in [7, 8] that u\(Z Z  u\(Z?{a Z?{a for |Z| ? 1 This important result was used in [7, 8] to determine the upper bound on the length of non-derivable itemsets namely: non-derivable itemsets are not longer than log2|D|? + 1 Hence, the bound on the length of non-derivable itemsets is identical to the bound on the length of generalized disjunction-free sets \(please see Theorem 3.2 It has been proved in [7] that ?-free sets are a subset of non-derivable itemsets, so their length is also bounded by ?log2|D|? + 1 There is a claim in [7, 9] that the generalized disjunction-free sets equal the ?-free sets. This claim however, is not correct, which we will prove by the example beneath. Table 4 contains all generalized disjunction-free sets. Among them, there is {fh}, the support of which equals 0. The support bounds for {fh are found as follows \(please, see [7] for the details  sup\({fh f h   sup\({fh f  sup\({fh h  sup\({fh Proceedings of the 16th International Conference on Scientific and Statistical Database  Management \(SSDBM  04 1099-3371/04 $ 20.00  2004 IEEE Hence, l\({fh fh fh sup\({fh free, is not a ?-free set Since the families of the generalized disjunction-free sets and ?-free sets may differ, finding the relationship between them or between the generalized disjunction-free sets and non-derivable itemsets remains a challenge 8. Conclusions The representations based on generalized disjunctionfree sets belong to the most concise ones among all lossless frequent patterns representations with borders. In 


lossless frequent patterns representations with borders. In practice, they are also much more concise than representations based on closed itemsets and approximate representations. In this paper, we offered three methods of deriving an upper bound on the length of sets in such representations. We proved that the upper bound on the length of a longest generalized disjunction-free set depends logarithmically on the number of records in the database. The obtained result is of high importance as it guarantees that any generalized disjunction-free set representation for all patterns \(both frequent and infrequent scans, where n is the number of records in the database irrespectively how strong or weak correlations among items in the database are and irrespectively of the lengths of records and number of distinct items The modifications of the basic estimation take into account the support threshold of the representation to be found or, additionally, the information on the length of longest sets of the representation already calculated for a higher support threshold. Though these estimations are more accurate than the basic one, they are still quite rough. Further improvements of the quality of estimating the length of longest itemsets in generalized disjunctionfree representations is subject to further research References 1] R. Agrawal, H. Mannila, R. Srikant, H. Toivonen, A.I Verkamo  Fast Discovery of Association Rules   Advances in Knowledge Discovery and Data Mining AAAI, CA, 1996 2] J. Baptiste, J.-F. Boulicaut  Constraint-Based Discovery and Inductive Queries: Application to Association Rule Mining  Pattern Detection and Discovery, Springer London, UK, September 2002, pp. 110-124 3] E. Baralis, S. Chiusano, P. Garza  On Support Thresholds in Associative Classification  SAC, ACM, Taipei Taiwan, March 2004, pp. 553-558 4] Y. Bastide, N. Pasquier, R. Taouil, G. Stumme, L. Lakhal  Mining Minimal Non-redundant Association Rules Using Frequent Closed Itemsets  Computational Logic, 2000 pp. 972  986 5] J.-F. Boulicaut, A. Bykowski, C. Rigotti  Approximation of Frequency Queries by Means of Free-Sets  PKDD Springer, Lyon, France, September 2000, pp. 75-85 6] A. Bykowski, C. Rigotti  A Condensed Representation to Find Frequent Patterns  PODS, ACM, Santa Barbara USA, May 2001, pp. 267-273 7] T. Calders, Axiomatization and Deduction Rules for the Frequency of Itemsets, Ph.D. Thesis, University of Antwerp, 2003 8] T. Calders, B. Goethals  Mining All Non-derivable Frequent Itemsets  PKDD, Springer, Helsinki, Finland August 2002, pp. 74?85 9] T. Calders, B. Goethals  Minimal k-free Representations of Frequent Sets  ECML/PKDD, Springer, CavtatDubrovnik, Croatia, September 2003, pp. 71-82 10] J. Han, M. Kamber, Data Mining: Concepts and Techniques, Morgan Kaufmann Publishers, 2000 11] S.K. Harms, J. Deogun, J. Saquer, T. Tadesse  Discovering Representative Episodal Association Rules from Event Sequences Using Frequent Closed Episode Sets and Event Constraints  ICDM, IEEE Computer Society, San Jose, California, USA, November-December 2001, pp. 603  606 12] M. Kryszkiewicz  Closed Set Based Discovery of Representative Association Rules  IDA, Springer Cascais, Portugal, September 2001, pp. 350-359 13] M. Kryszkiewicz  Concise Representation of Frequent Patterns based on Disjunction  free Generators  ICDM IEEE Computer Society, San Jose, California, USA 


IEEE Computer Society, San Jose, California, USA November-December 2001, pp. 305  312 14] M. Kryszkiewicz M  Inferring Knowledge from Frequent Patterns  Soft-Ware, Springer, Belfast, Northern Ireland April 2002, pp. 247  262 15] M. Kryszkiewicz  Concise Representations of Association Rules  Pattern Detection and Discovery, Springer London, UK, September 2002, pp. 92-109 16] M. Kryszkiewicz, Concise Representation of Frequent Patterns and Association Rules, Habilitation Thesis Publishing House of Warsaw University of Technology 2002 Proceedings of the 16th International Conference on Scientific and Statistical Database  Management \(SSDBM  04 1099-3371/04 $ 20.00  2004 IEEE 17] M. Kryszkiewicz  Reducing Infrequent Borders of Downward Complete Representations of Frequent Patterns  Proc. of The First Symposium on Databases Data Warehousing and Knowledge Discovery, Scientific Publishers OWN, Baden-Baden, Germany, July, 2003, pp 29-42 18] M. Kryszkiewicz  Closed Set Based Discovery of Maximal Covering Rules  International Journal of Uncertainty, Fuzziness and Knowledge-Based Systems Vol. 11. World Scientific Publishing Company, Singapore September 2003, pp. 15-29 19] M. Kryszkiewicz  Reducing Borders of k-Disjunction Free Representations of Frequent Patterns  SAC, ACM Taipei, Taiwan, March 2004, pp. 559  563 20] M. Kryszkiewicz  Reducing Main Components of k-Disjunction Free Representations of Frequent Patterns   Proc. of IPMU  2004 \(in print 21] M. Kryszkiewicz, M. Gajek  Concise Representation of Frequent Patterns based on Generalized Disjunction  Free Generators  PAKDD, Springer, Taipei, Taiwan, May 2002, pp. 159-171 22] M. Kryszkiewicz, M. Gajek  Why to Apply Generalized Disjunction-Free Generators Representation of Frequent Patterns  ISMIS, Springer, Lyon, France, June 2002, pp 383  392 23] M. Kryszkiewicz, H. Rybi?ski, M. Gajek  Dataless Transitions between Concise Representations of Frequent Patterns  Journal of Intelligent Information Systems JIIS Netherlands, 2004, pp. 41-70 24] N. Pasquier, Data mining: Algorithmes d  extraction et de R  duction des R  gles d  association dans les Bases de Donn  es, Th  se de Doctorat, Universit  Blaise Pascal   Clermont  Ferrand II, 2000 25] N. Pasquier, Y. Bastide, R. Taouil, L. Lakhal  Efficient Mining of Association Rules Using Closed Itemset Lattices  Journal of Information Systems, Vol. 24, No. 1 1999, pp. 25  46 26] N. Pasquier, Y. Bastide, R. Taouil, L. Lakhal  Discovering Frequent Closed Itemsets for Association Rules  ICDT, Springer, Jerusalem, Israel, January 1999 pp. 398  416 27] J. Pei, G. Dong, W. Zou, J. Han  On Computing Condensed Frequent Pattern Bases  ICDM, IEEE Computer Society, Maebashi City, Japan, December 2002 pp. 378-385 28] V. Phan-Luong V  Representative Bases of Association Rules  ICDM, IEEE Computer Society, San Jose California, USA, November-December 2001, pp. 639-640 29] A. Savinov  Mining Dependence Rules by Finding Largest Itemset Support Quota  SAC, ACM, Taipei Taiwan, March 2004, pp. 525-529 30] M.J. Zaki, C.J. Hsiao  CHARM: An Efficient Algorithm for Closed Itemset Mining  SIAM, Arlington, 2002 


for Closed Itemset Mining  SIAM, Arlington, 2002 Proceedings of the 16th International Conference on Scientific and Statistical Database  Management \(SSDBM  04 1099-3371/04 $ 20.00  2004 IEEE pre></body></html 


                                                  S J       


                                                      


                         L A                                        


          L A  Table 7. Table of Granules at left-hand-side is isomorphic to  at right- hand-side: By Theorem  3.1 one can ?nd patterns in either table as a single generalized concept  Internal points  are:[4]\(1, 1, 0, 0 tions; [5]\(0, 1, 1, 0  0, 1, 0, 1  0, 1, 1, 1  1, 1 1, 0  1, 1, 0, 1  1, 0, 1, 1 11]\(1, 1, 1, 1 form and simplify them into disjoint normal forms 1  T E N    S J    T E N    S J 2  T W E N T Y    L A    T H I R T Y   A 3  T W E N T Y      T H I R T Y   A 4  T W E N T Y            L A 5  T E N      T W E N T Y    L A    T E N    T W E N T Y   A   S J    T W E N T Y   A      T H I R T Y    L A     Y 7  T E N      T W E N T Y      T H I R T Y   L A    T E N   L A    S  J   A 8  T W E N T Y      T E N      T W E N T Y    L A    T E N   T W E N T Y      T H I R T Y 9  T W E N T Y    N Y    T E N    S J    T H I R T Y    L A      T W E N T Y    L A  1 0  T W E N T Y    N Y    T W E N T Y    L A    T H I R T Y   A    J 1 1  T W E N T Y          T W E N T Y    L A   T H I R T Y    L A    a l l If the simpli?ed expression is a single clause \(in the original symbols non-generalized the following associations 1   T E N     S J    T E N    S J  2. SJ   J 4   L A    T W E N T Y    L A    T H I R T Y    6 Conclusions Data, patterns, method of derivations, and useful-ness are key ingredients in AM. In this paper, we formalize the current state of AM: Data are a table of symbols. The patterns are the formulas of input symbols that repeat. The method of derivations is the most conservative and reliable one, namely, mathematical deductions. The results are somewhat surprising 1. Patterns are properties of the isomorphic class, not an individual relation - This implies that the notion of patterns may not mature yet and explains why there are so many extracted association rules 2. Un-interpreted attributes \(features can be enumerated 3. Generalized associations can be found by solving integral linear inequalities. Unfortunately, the number is enormous. This signi?es the current notion of data and patterns \(implied by the algorithms 4. Real world modeling may be needed to create a much more meaningful notion of patterns. In the current state of AM, a pattern is simply a repeated data that may have no real world meaning. So we may need to introduce some semantics into the data model [12],[10],[11 Proceedings of the Fourth IEEE International Conference on Data Mining \(ICDM  04 0-7695-2142-8/04 $ 20.00 IEEE References 1] R. Agrawal, T. Imielinski, and A. Swami  Mining Association Rules Between Sets of Items in Large Databases  in Proceeding of ACM-SIGMOD international Conference on Management of Data, pp. 207216, Washington, DC, June, 1993 


216, Washington, DC, June, 1993 2] Richard A. Brualdi, Introductory Combinatorics, Prentice Hall, 1992 3] A. Barr and E.A. Feigenbaum, The handbook of Arti?cial Intelligence, Willam Kaufmann 1981 4] Margaret H. Dunham, Data Mining Introduction and Advanced Topics Prentice Hall, 2003, ISBN 0-13088892-3 5] Fayad U. M., Piatetsky-Sjapiro, G. Smyth, P. \(1996 From Data Mining to Knowledge Discovery: An overview. In Fayard, Piatetsky-Sjapiro, Smyth, and Uthurusamy eds., Knowledge Discovery in Databases AAAI/MIT Press, 1996 6] H Gracia-Molina, J. Ullman. &amp; J. Windin, J, Database Systems The Complete Book, Prentice Hall, 2002 7] T. T. Lee  Algebraic Theory of Relational Databases  The Bell System Technical Journal Vol 62, No 10, December, 1983, pp.3159-3204 8] T. Y. Lin  Deductive Data Mining: Mathematical Foundation of Database Mining  in: the Proceedings of 9th International Conference, RSFDGrC 2003 Chongqing, China, May 2003, Lecture Notes on Arti?cial Intelligence LNAI 2639, Springer-Verlag, 403-405 9] T. Y. Lin  Attribute \(Feature  The Theory of Attributes from Data Mining Prospect  in: Proceeding of IEEE international Conference on Data Mining, Maebashi, Japan, Dec 9-12, 2002, pp. pp.282-289 10] T. Y. Lin  Data Mining and Machine Oriented Modeling: A Granular Computing Approach  Journal of Applied Intelligence, Kluwer, Vol. 13, No 2, September/October,2000, pp.113-124 11] T. Y. Lin, N. Zhong, J. Duong, S. Ohsuga  Frameworks for Mining Binary Relations in Data  In: Rough sets and Current Trends in Computing, Lecture Notes on Arti?cial Intelligence 1424, A. Skoworn and L Polkowski \(eds 12] E. Louie,T. Y. Lin  Semantics Oriented Association Rules  In: 2002 World Congress of Computational Intelligence, Honolulu, Hawaii, May 12-17, 2002, 956961 \(paper # 5702 13  The Power and Limit of Neural Networks  Proceedings of the 1996 EngineeringSystems Design and Analysis Conference, Montpellier, France, July 1-4, 1996 Vol. 7, 49-53 14] Morel, Jean-Michel and Sergio Solimini, Variational methods in image segmentation : with seven image processing experiments Boston : Birkhuser, 1995 15] H. Liu and H. Motoda  Feature Transformation and Subset Selection  IEEE Intelligent Systems, Vol. 13 No. 2, March/April, pp.26-28 \(1998 16] Z. Pawlak, Rough sets. Theoretical Aspects of Reasoning about Data, Kluwer Academic Publishers, 1991 Proceedings of the Fourth IEEE International Conference on Data Mining \(ICDM  04 0-7695-2142-8/04 $ 20.00 IEEE pre></body></html 


than that of MAFIA and the runtime of MHP can be significantly less than that of MAFIA 5.3. The Effect of the MHP Algorithm on Finding Maximal Hyperclique Patterns Figure 8 and Figure 9 show the number of maximal patterns identi?ed byMHP andMAFIA on Pumsb* and Pumsb data sets respectively. As can be seen, the number of maximal hyperclique patterns identi?ed by MHP can be orders of magnitude smaller than the number of maximal frequent patterns identi?ed by MAFIA. In other words, the number Proceedings of the 16th IEEE International Conference on Tools with Artificial Intelligence \(ICTAI 2004 1082-3409/04 $20.00  2004 IEEE 100 1000 10000 100000 1e+06 1e+07 1e+08 1e+09 0.02 0.025 0.03 0.035 0.04 0.045 0.05 0.055 0.06 N um be r o f C ou nt ed P at te rn s Support Threshold Mafia Min_Conf=0 Min_Conf=0.1 Min_Conf=0.3 Min_Conf=0.5 Min_Conf=0.7 Min_Conf=0.9 Figure 8. The Number of MFI/MHP Patterns in the Pumsb* Data Set 100 1000 10000 100000 1e+06 


1e+07 1e+08 0.1 0.2 0.3 0.4 0.5 0.6 0.7 N um be r o f C ou nt ed P at te rn s Support Threshold Mafia Min_Conf=0.5 Min_Conf=0.7 Min_Conf=0.9 Figure 9. The number of MFI/MHP Patterns in the Pumsb Data Set of maximal hyperclique patterns is much easier to manage than that of maximal frequent patterns. Indeed, in realworld applications, it is dif?cult to interpret several million maximal frequent patterns. However, it is possible to interpret the results of maximal hyperclique pattern mining In addition, due to the memory limitation, we cannot extract maximal frequent patterns with MAFIA on the Pumsb data set if the support threshold is less than 0.4, as shown in Figure 7. In contrast, MHP can identify maximal hyperclique patterns when the support threshold is 0.1, if we set the h-con?dence threshold to 0.5. In other words, MHP has the ability to identify patterns which can be dif?cult to identify for MAFIA. Hence, MHP can better explore the pattern space and ?nd interesting patterns at low levels of support 6. Conclusions and Future Work In this paper, we present a two-phase Maximal Hyperclique Pattern \(MHP best features of both the BFS strategy and the DFS strategy. More speci?cally, we adapted DFS pruning methods such as equivalence pruning, to an apriori-like approach In addition, we proved the correctness and completeness of the MHP algorithm. Finally, our experimental results show that the MHP algorithm can be several orders of magnitude faster than standard maximal frequent pattern mining algorithms and has the ability to identify patterns at extremely low levels of support in dense data sets There are several directions for future work. First, in 


this paper, we only generate the size-2 patterns in the BFS phase. It will be interesting to investigate the impact on the performance if the ?rst phase is stopped at a deeper level Also, the projection is a very ef?cient method for ?nding patterns, especially for parallel implementation of pattern mining algorithms [1]. We plan to adapt the projection ideas into our algorithm and design an ef?cient parallel algorithm for mining maximal hyperclique patterns References 1] R. Agarwal, C. Aggarwal, and V. Prasad. A Tree Projection Algorithm For Generation of Frequent Itemsets. pages 350 371, Feb 2001 2] R. Agrawal, T. Imielinski, and A. Swami. Mining Association Rules between Sets of Items in Large Databases. In Proc. of the ACM SIGMOD Conference on Management of Data, pages 207216,May 1993 3] R. Agrawal and R. Srikant. Fast Algorithms for Mining Association Rules. In Proc. of the 20th Intl Conference on Very LargeData Bases, 1994 4] R. Bayardo. Ef?ciently mining long patterns from databases In Proc. of the ACM SIGMOD Conference, 1998 5] R. Bayardo and R. Agrawal. Mining the Most Interesting Rules. In Proc. of the ACM SIGKDD Conference, 1999 6] D. Burdick, M. Calimlim, and J. Gehrke. Ma?a: AMaximal Frequent Itemset Algorithm for Transactional Databases. In Proc. of IEEE Conf. on Data Engineering, 2001 7] Y. Huang, H. Xiong, W. Wu, and Z. Zhang. A Hybrid Approach for Mining Maximal Hyperclique Patterns. In In Technical Report UTDCS-34-04, Department of computer science, University of Texas - Dallas, 2004 8] J.Han, J.Pei, and Y. Yin. Mining Frequent Patterns without Candidate Generation. In Proc. of the ACM SIGMOD International Conference on Management of Data, 2000 9] M.J.Zaki and C.Hsiao. ChARM: An ef?cient algorithm for closed itemset mining. In Proc. of 2nd SIAM International Conference on Data Mining, 2002 10] R.Rymon. Search through Systematic Set Enumeration. In Proc. Third Intl Conference on Principles of Knowledge Representation and Reasoning, 1992 11] H. Xiong, M. Steinbach, P.-N. Tan, and V. Kumar. HICAP: Hierarchial Clustering with Pattern Preservation. In Proc. of 2004 SIAM International Conference on Data Mining \(SDM 12] H. Xiong, P.-N. Tan, and V. Kumar. Mining Strong Af?nity Association Patterns in Data Set with Skewed Support. In Proc. of the Third IEEE International Conference on Data Mining \(ICDM Proceedings of the 16th IEEE International Conference on Tools with Artificial Intelligence \(ICTAI 2004 1082-3409/04 $20.00  2004 IEEE 





