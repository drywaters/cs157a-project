html><head></head><body><pre style="word-wrap: break-word; white-space: pre-wrap;">Interesting  Measures for Mining Association Rules Liaquat Majeed Sheikh, Basit Tanveer and Syed Mustafa Ali Hamdani FAST-NUCES, Lahore liaquat. majeed@nu. edu. pk, basit. tanveer@gmail. coin, mustafu. harndnni@gmail. com Abstract Discovering ussociation d e s  is  one of' the mosi important l a s h  in data mining and many eflcient algoi'ithms were proposed ifl literature. Ho wever, the number of discovered rules is open so large, so the user cannol analyze all discovered nrles. To uvercome that problem several methods for mining interesting nrIes only huve been proposed. Mony measures have been pvoposcd in litevafure to determine the intercsiingnrss of the rule. In this paper we have selected \(I total of eight dgerent measures, we have compared these rneaszires by zuing a data set and w e have mode some recommendation about the use of the measslriwjbr discoverir?g the most interesting r-ziles 1. Introduction In the previous few years a lot o f  work is done in the field of data mining especially in finding association between items in a data base of customer transaction. Association rules identify items that are mast often bought along with certain other items by a significant fraction of the customers. For example, we may find that"95 percent of the customers who bought bread also bought milk." A rule may contain more than one item in the antecedent and the consequent of the mIe. Every mle must satisfy two user specified constraints: one is a measure of statistical significance called support and the other a measure of goodness of the rule called confidence. Tn this paper we have identified a set of measures as proposed by the literature and we have tried to conclude that a single measure alone can not determine the interestingness of the rule This paper is divided in to three sections the first section gives the fortnal definition \(as presented in the literature measures we have chosen are Support, Confidence Conviction, Lift, Piatetsky-Shapiro, Coverage Correlation, and Odds ratio. The second section gives us the calculatioii of each measure on our sample data customer transactions our recommendation on using which measure for discovering the interesting rules 2. Description of Different Measures To make the measures comparable all measures are defined using probabilities. The probability of encountering itemset X is given by colmt\( x&gt ID1 P \( X Where, count\(X contain the itemset X and ID] is the size \(number of transactions 2.1. Support 111 Introduced by R. Agrawal, T. Imielinski, and A Swami. Mining associations between sets o f  items in large databases. In Proc. o f  the ACM SIGMOD Int'I Conference on Management of Data, pages 207-216 Washington D.C., May 1993 Suppoit is defined on itemsets and gives the proportion of transactions that contain Z and therefore is used as a measure of significance \(importance itemset. Since it basically uses the count of transactions it is often called a frequency constraint An itemset with a support greater than a set minimnm support threshold is called a frequent or large itemset Supports main feature i s  that it possesses the down 


Supports main feature i s  that it possesses the down ward closure property \(anti-monotonicity! which INMIC 2004 means that all subsets of a frequent set are also frequent This property {actually, the fact that no super set of infrequent set can be frequent the search space \(usually thought o f  as a lattice or tree of item sets with increasing size algorithms \(e.g., the Apriori algorithm The disadvantage of support is the rare item problem. Items that occur very infrequently in the data set are pruned although they would still produce interesting and potentially valuable rules. The rare item problem is important for transaction data which usually have a very uneven distribution of support for the individual items \(few items arc used all the time and mos't item are rarely used Its values are in range EO; I]. If antecedent and consequent are not occurring in transactions it is equal to 0. And if they are occurring in all transactions its value is equal to 1 2.2. Confidence [I Introduced by R. Agrawal, T. Imielinski, and A Swami. Mining associations between sets of items in large databases. In Pmc. of the ACM SIGMOD Int'l Conference on Management of Data, pages 207-2 16 Washington D.C., May 1993 P\(X and Y P \( X &gt confidence\(X -+ Y Confidence is defined as the probability of seeing the rule's consequent under the condition that the transactions also contain the antecedent. Confidence is directed and gives different values for the rules X -+Y and Y+ X Confidence is not down-ward closed and was developed together with support by Agrawal et al. \(the so-called suppart-con fidence framework first used to find frequent \(significant exploiting its down-ward closure property to prune the search space. Then confidence is used in a second step to produce rules from the frequent itemsets that exceed a min. confidence threshold A problem with confidence is that it is sensitive to the frequency of the consequent \(Y Caused by the way confidence is calculated consequents with higher support will automatically produce higher confidence values even if there exists no association between the items Its values are i n  range [ O ;  I ] .  If antecedent and consequent are independent it is equal to 0. For implications occurring in all cases measure's value is equal to 1 2.3. Conviction [I Introduced by Sergey Brin, Rajeev itlotwani Jeffrey D. Ullman, and Shalom Tsur. Dynamic itemset counting and implication rules for market basket data In SIGMOD 1997, Proceedings ACM SIGMOD International Conference on Management of Data pages 255-264, Tucson, Arizona, USA, May 1997 Conviction was developed as an alternative to confidence which was found to not capture direction of associations adequately. Conviction compares the probability that X appears without Y if they were dependent with the actual frequency of the appearance of X without Y. In that respect it i s  similar to lift \(see section about lift on this page liR i t  is a directed measure since it also uses the information of the absence of the consequent. An interesting fact is that conviction is monotone in confidence and lift Its values are in range [ O ;  +m]. If antecedent and 


Its values are in range [ O ;  +m]. If antecedent and consequent are independent it is equal to 1. For implications occurring in all cases measure's value is equal to +CO 2.4. Lift [l Introduced by S .  Brin, R. Motwani, J. D. Ullman and S. Tsur. Dynamic itemset counting and impiication rules for market basket data. in Proc. of the ACM SIGMOD Int'l Conf. on Management of Data \(ACM SIGMOD '97 Lift measures how many times more often X and Y occurs together than expected, if they where statistically independent. Lift is not down-ward closed and does not suffer from the rare item problem Its values are in range [a; fq. Values lower than 1 mean, that satisfying condition of antecedent decreases probability of consequent in comparison to unconditional probability. Consequently, values higher than 1 mean, that satisfying condition of antecedent increases probability of consequent. in comparison to unconditional probability. If antecedent and consequent are independent then lift i s  equal to I 642 2.5. Leverage 111 2.8. Odds Ratio Introduced by Piatetsky-Shapiro, G., Discovery analysis, and presentation of strong rules. Knowledge Discovery in Databases, 199 I:  p. 229-248 Leverage measures the difference of X and Y appearing together in the data set and what would be expected if X and Y where statistically dependent. The rational in a sales setting is to find out how many more units \(items X and Y together from the independcnt sells. Using minimum leverage thresholds at the same time incorporates an implicit frequency constraint. e.g., for setting a min. leverage thresholds to 0.01% \(corresponds to 10 occurrence in a data set with 100,000 transactions algoritliin to find all itemsets with minimum support of 0.01% and then filter the found item sets using the lcverage constraint. Because of this property leverage also can suffer from the rare item problem The odds-ratio is a statistical measure which is defined as the ratio of the odds of an event occurring in one group to the odds of it occurring in another group, or to a data-based estimate of that ratio. [3 P\(X and Y x  and r P\(X and y x  and Y odds\( x + v Its values are in range [O; +ocJ. If antecedent and consequent are independent it is equal to 0. For strong associations its value is equal to +e 3. Comparison of Measures This section compares all the measures, discussed in the first section. We have chosen a data set on which we have performed the A-priori algorithm to find out the frequent item set. AH the measure are applied on each of the frequent item set, and then in the end the recommendation d a t e d  to choosing a measure to decide which rule is interesting are given 2.6. Coverage [l 3.1. Sample Data P\(X  and Y PV cov evage\(X + Y I t  shows what  part of iteinsets from consequent is covered by a rule. Its values are in range [O; 11 2.7. Correlation Correlation is a statistical technique which can show whether and how strongly pairs of variableditemsets are related Corcelation is a bi-variant measure of association 


Corcelation is a bi-variant measure of association strength variableditemsets. It varies from -1  \(perfect negative linear relationship and in between them 0 means no relationship. To the extent that there is a nonlinear relationship between the two variables being correlated, correlation will understate the relationship. [4 The sample data for the analysis purpose is taken from a store database of customer transactions there are six different types of items and a total of ten transactions. In each transaction a 1 represents the presence of an item while a 0 represents the absence of an item from the market basket Table 1: Sample Transactions TID I Items 1 643 3.2. Generating Frequent Itemsets Rules A-tF F+A B+D D+B The frequent item set generated by the sample data using A-priori algorithm is shown in the following table Measures Confidence Correlation Odds Ratio 0.83 0.82 ca 1 .oo 0.82 a 1.00 0.65 CO 0.71 0.65 00 ltemset 40 50 5 0 40 The minimum support used for the generation of the frequent item set is 40 3.3. Calculations All the measures discussed in the first section are calculated for each nile, which is the output of the A priori algorithm. The results are shown in table 3 3. Conclusion Any measure alone cannot determine the Interestingness of the rules. We have to look at a combination of different measures in order to get the rule that is really interesting. There are two types of measures one is symmetric measures and the other is asymmetric If we look at a symmetric measure e.g Odds Ratio we can conclude the A-tF, F+A both the rules are interesting but the Confidence value of F+A suggest that it is more interesting as compared to A+F hence we can not conclude alone from a symmetric measure we also have to look for an asymmetric measure in .order to know the interestingness of such types of rules A+B, B+A The table sown above contains the subset of measures and rulcs taken from the above table. The Odds Ratio in this table suggest that all the rules are interesting but if we look at the Correlation along with the Odds Ratio we will come to know that A+F and F+A are more strongly related to each other. On combining another measure i.e. Confidence with these two measures we will come to know that only the rule F+A is more interesting 5. References 11 http://wwwai.wu-wien.ac .atl-hahsleriresearchi association_rules/measures.html 2 ]  www.cisc.ufl.eddclass/cis6930fa03dmlnotcs din4part2 .pdf 3] http://en.wikipedia.org/wiki/Odds-ratio 


3] http://en.wikipedia.org/wiki/Odds-ratio 4] http://www2.chass.ncsu.edulgarsodpa765 5] Discovering interesting rules from correl .htm financial data Przemys3aw So  dacki, Institute of Computer Science, Warsaw University of Technology U1 Andersa 13, 00-159 Warszawa 161 Alternative Interest Measures for Mining Associations in Databases, Edward R. Omiecinski Member, IEEE Computer Society 644 pre></body></html 


it. The evaluation of a rule r with threshold value s over a set D of XML documents can be evaluated by using the following steps Input: D: a set of XML documents r: a rule s: a threshold value Output: D?: a ranked list of XML documents 1 D? ? empty list 2 for each document d ? D 3 sd ? Evaluation\(d,r 4 if sd ? s 5 then D? ? D? ? \(d, sd 6 Order\(D 7 Return D In particular, the function Evaluation\(d,r line 3 the satis?ability degree sd of the document d with respect to the rule r; if the returned value is greater than or equal to s, then the document d and its value sd are inserted in the list D? \(line 5 line 6 D? is ordered with respect to the value sd of the contained documents by using the procedure Order\(D The algorithm is applied to each rule r; at the ?rst step the input set of XML documents is D but after the ?rst call the algorithm is applied assuming as input the set I composed by the XML documents contained in the set D? obtained at the previous step 4.1 An example of approximate querying We suppose to have a set D of three XML documents A B, and C respectively, represented by means of their associated XML graphs \(see Figures 3, 4, and 5 The process starts with the structural rule q1 book ? title. The user speci?es as evaluation strategy the undirect reachability and as satis?ability degree the value 0.6 The step of subgraphs extraction returns the subgraphs highlighted in Figures 3, 4, and 5. The satis?ability degree associated to the XML documents A, B, and C are the following A : ssd = 1 B : ssd = 1  1 2 1  1 3  5 6 C : ssd = 1  1 3 1  1 3  2 3 The set D1 of XML documents is ordered in decreasing order with respect to the values of ssd. The obtained values of ssd associated to the considered documents are greater then the satis?ability degree required by the user, and thus no documents are discarded and D1 A, 1 B, 56 C, 23 After the ?rst request, the user speci?es a value rule to evaluate on the XML documents contained in the set D1 i.e. A, B, and C. The rule q2 is book ? title\(XML the evaluation strategy is the textual strategy. In particular, the user wants to know in which XML documents the node book contains the node title having as value a string containing  XML  The user requires for q2 a satis?ability degree having value 0.5 The step of subgraphs extraction returns the same subgraphs at the previous step and the values of vsd associated to the considered documents are A : vsd = 1 


A : vsd = 1 B : vsd = 1  1 2 1  1 3  5 6 C : vsd = 1  1 3 0  1 3  1 3 At the end of the second step, the set D2 is A, 1 B, 56 C is less than 0.5 4 Proceedings of the 16th International Workshop on Database and Expert Systems Applications  DEXA  05 1529-4188/05 $20.00  2005 IEEE book author title content David Hunter Beginning XML XML complete course A Figure 3. The subgraph of the XML document A which satis?es the rule book ? title book author title title Eliotte Rusty Harold XML Bible XML in a Nutshell B topic Language for Semistructured data Figure 4. The subgraphs of the XML document B which satisfy the rule book ? title book author topic title author topic title Erik T. Ray XML and Java Processing XML with Java Mikeal Kay Languages XSLT: Programmer  s Reference C Figure 5. The subgraphs of the XML document C which satisfy the rule book ? title 5 Conclusions and Future Work In this work we proposed an approximate way to query XML data by using a content-based approach, which does 


XML data by using a content-based approach, which does not discard the structure of XML documents. We have extended the approach proposed in [5] for mining XML data to deal with both content-based and structural queries Moreover we have extended value rules to deal with mixed XML documents and with textual context As future work we aim to extend our approach in order to deal with the conjunction or disjunction of several rules moreover we aim to de?ne the concept of support and con?dence both for structural and value association rules References 1] S. Abiteboul, P. Buneman, and D. Suciu. Data on the Web from relations to semistructured data and XML. Morgan Kaufman, 2000 2] S. Boag, D. Chamberlin, M.F. Fernandez, D. Florescu, J. Robie, and J. Simeon. XQuery 1.0: An XML query language Technical report, World Wide Web Consortium, 2002 3] D. Carmel, Y.S. Maarek, M. Mandelbrod, Y. Mass, and A. Soffer. Searching XML documents via XML fragments In Proceedings of SIGIR  03, pages 151  158. ACM Press 2003 4] J. Cheng and W.Ng. XQzip: Querying Compressed XML Using Structural Indexing. In E. Bertino et al., editor, Proceedings of EDBT  04, volume 2992 of LNCS, pages 219  236. Springer, 2004 5] C. Combi, B. Oliboni, and R. Rossato. Evaluating fuzzy association rules on XML documents. In Proceedings of ITKEM 2004, Special Session of FUZZY DAYS 2004, To appear in the Springer series  Advances in Soft Computing   2005 6] World Wide Web Consortium. W3C eXtensible Markup Language \(XML third edition http://www.w3.org/TR/2004/REC-xml-20040204 7] E. Damiani, B. Oliboni, and L. Tanca. Fuzzy Techniques for XML Data Smushing. In Proceedings of Fuzzy Days 2001 volume 2206 of LNCS, pages 637  652. Springer, 2001 8] N. Fuhr, N. Go  vert, and T. Ro  lleke. DOLORES: a system for logic-based retrieval of multimedia objects. In Proceedings of SIGIR  98, pages 257  265. ACM Press, 1998 9] N. Fuhr, K. Grobjohann, and S. Kriewel. A query language and user interface for XML information retrieval. In H.M. Blanken et al., editor, Intelligent Search on XML Data volume 2818 of LNCS, pages 59  75. Springer, 2003 10] M.A. Hearst and C. Plaunt. Subtopic structuring for fulllength document access. In Proceedings of the SIGIR  93 pages 59  68. ACM Press, 1993 11] E. Kotsakis. Structured information retrieval in XML documents. In Proceedings of the 2002 ACM symposium on Applied computing, pages 663  667. ACM Press, 2002 12] M. Lalmas. Dempster-shafer  s theory of evidence applied to structured documents: modelling uncertainty. In Proceedings of SIGIR  97, pages 110  118. ACM Press, 1997 13] S.H. Myaeng, D. Jang, M. Kim, and Z.C. Zhoo. A ?exible model for retrieval of SGML documents. In Proceedings of SIGIR  98, pages 138  145. ACM Press, 1998 14] G. Navarro and R. Baeza-Yates. Proximal nodes: a model to query document databases by content and structure. ACM Transactions on Information Systems, 15\(4  435, 1997 15] R. Schenkel, A. Theobald, and G. Weikum. HOPI: An Ef?cient Connection Index for Complex XML Document Collections. In E. Bertino et al., editor, Proceedings of EDBT  04, volume 2992 of LNCS, pages 237  255. Springer 2004 16] T.Schlieder and H. Meuss. Querying and ranking XML documents. Journal of the American Society for Information Science and Technology, 53\(6  503, 2002 5 Proceedings of the 16th International Workshop on Database and Expert Systems Applications  DEXA  05 1529-4188/05 $20.00  2005 IEEE 


1529-4188/05 $20.00  2005 IEEE pre></body></html 


14] Kryszkiewicz, M., and Rybinski, H. \(1999  Incomplete Database Issues for Representative Association Rules  ISBN: 3-540-65965-X, pp. 583-591 15] Little, R.J.A., and Rubin, D.B. \(2002 analysis with missing data, Wiley, New York, ISBN 0471183865 16] Omiecinski, E.R. \(2003  Alternative interest measures for mining associations in databases  IEEE TKDE vol. 15, no. 1, pp.57-69 17] Piramuthu, S. \(1998  Evaluating feature selection methods for learning in data mining applications  in the Proceedings of the Thirty-First Annual Hawaii International Conference on System Sciences, vol. 5, pp. 294-301 18] Pyle, D. \(1999 Morgan Kaufmann Publishers, Inc.ISBN:1-55860-529-0 19] Ragel, A., and Cremilleux, B. \(1999  MVC - A preprocessing Method to deal with missing values   knowledge based system, vol. 12, pp.285-291 20] Ramoni, M., and Sebastiani, P. \(2000  Bayesian Inference with Missing Data Using Bound and Collapse   Journal of Computational and Graphical Statistics, vol. 9, no 4, pp. 779-800 21] Ramoni, M., and Sebastiani, P. \(2001  Robust Bayes Classifiers  AI, vol. 125, no. 1-2, pp. 207-224 22] Ramoni, M., and Sebastiani, P. \(2001  Robust Learning with Missing Data  Machine Learning, vol. 45, no 2 , pp. 147-170 23] Scott, R.E. \(1993 Logic and Practice, SAGE Publications, ISBN: 0803941072 24] Zaki, M.J., and Hsiao, C.J. \(2002  CHARM: An efficient algorithm for closed itemset mining  in the Proceedings of the Second SIAM International Conference on Data Mining Proceedings of the Fourth International Conference on Hybrid Intelligent Systems \(HIS  04 0-7695-2291-2/04 $ 20.00 IEEE pre></body></html 


13: else 14: E|i?1| = E|i?1| ? s The backward process in Algorithm 1, generates level-wise every possible subset starting from the borProceedings of the Fourth IEEE International Conference on Data Mining \(ICDM  04 0-7695-2142-8/04 $ 20.00 IEEE der de?ned by Edge without getting into equivalence classes which have been already mined \(Line 10 such subset satis?es the constraint then it can be added to the output \(Line 12 reused later to generate new subsets \(Line 14 have a monotone constraint in conjunction, the backward process is stopped whenever the monotone border B+\(Th\(CM Lines 3 and 8 4.3. Closed Constrained Itemsets Miner The two techniques which have been discussed above are independent. We push monotone constraints working on the dataset, and anti-monotone constraints working on the search space. It  s clear that these two can coexist consistently. In Algorithm 2 we merge them in a Closet-like computation obtaining CCIMiner Algorithm 2 CCIMiner Input: X,D |X , C, Edge,MP5, CAM , CM X is a closed itemset D |X is the conditional dataset C is the set of closed itemsets visited so far Edge set of itemsets to be used in the BackwardMining MP5 solution itemsets discovered so far CAM , CM constraints Output: MP5 1: C = C ?X 2: if  CAM \(X 3: Edge = Edge ?X 4: else 5: if CM \(X 6: MP5 = MP5 ?X 7: for all i ? flist\(D |X 8: I = X ? {i} // new itemset avoid duplicates 9: if  Y ? C | I ? Y ? supp\(I Y then 10: D |I= ? // create conditional fp-tree 11: for all t ? D |X do 12: if CM \(X ? t 13: D |I= D |I ?{t |I  reduction 14: for all items i occurring in D |I do 15: if i /? flist\(D |I 16: D |I= D |I \\i // ?-reduction 17: for all j ? flist\(D |I 18: if supD|I \(j I 19: I = I ? {j} // accumulate closure 20: D |I= D |I \\{j 21: CCIMiner\(I,D |I , C,B,MP5, CAM , CM 22: MP5 = Backward-Mining\(Edge,MP5, CAM , CM For the details about FP-Growth and Closet see [10 16]. Here we want to outline three basic steps 1. the recursion is stopped whenever an itemset is found to violate the anti-monotone constraint CAM Line 2 2  and ? reductions are merged in to the computation by pruning every projected conditional FPTree \(as done in FP-Bonsai [7 Lines 11-16 3. the Backward-Mining has to be performed to retrieve closed itemsets of those equivalence classes which have been cut by CAM \(Line 22 5. Experimental Results The aim of our experimentation is to measure performance bene?ts given by our framework, and to quantify the information gained w.r.t. the other lossy approaches 


approaches All the tests were conducted on a Windows XP PC equipped with a 2.8GHz Pentium IV and 512MB of RAM memory, within the cygwin environment. The datasets used in our tests are those ones of the FIMI repository1, and the constraints were applied on attribute values \(e.g. price gaussian distribution within the range [0, 150000 In order to asses the information loss of the postprocessing approach followed by previous works, in Figure 4\(a lution sets given by two interpretations, i.e. |I2 \\ I1 On both datasets PUMBS and CHESS this di?erence rises up to 105 itemsets, which means about the 30 of the solution space cardinality. It is interesting to observe that the di?erence is larger for medium selective constraints. This seems quite natural since such constraints probably cut a larger number of equivalence classes of frequency In Figure 4\(b built during the mining is reported. On every dataset tested, the number of FP-trees decrease of about four orders of magnitude with the increasing of the selectivity of the constraint. This means that the technique is quite e?ective independently of the dataset Finally, in Figure 4\(c of our algorithm CCIMiner w.r.t. Closet at di?erent selectivity of the constraint. Since the post-processing approach must ?rst compute all closed frequent itemsets, we can consider Closet execution-time as a lowerbound on the post-processing approach performance Recall that CCIMiner exploits both requirements \(satisfying constraints and being closed ing time. This exploitation can give a speed up of about to two orders of magnitude, i.e. from a factor 6 with the dataset CONNECT, to a factor of 500 with the dataset CHESS. Obviously the performance improvements become stronger as the constraint become more selective 1 http://fimi.cs.helsinki.fi/data Proceedings of the Fourth IEEE International Conference on Data Mining \(ICDM  04 0-7695-2142-8/04 $ 20.00 IEEE Information loss Number of FP-trees generated Run time performance 0 2 4 6 8 10 12 14 x 10 5 10 0 10 1 10 2 10 3 10 4 10 5 10 6 m I 2 I 1  PUMSB@29000 CHESS @ 1200 0 0.2 0.4 0.6 0.8 1 1.2 1.4 1.6 1.8 2 x 10 6 10 


10 1 10 2 10 3 10 4 10 5 10 6 10 7 m n u m b e r o f fp t re e s PUMSB @ 29000 CHESS @ 1200 CONNECT@11000 0 2 4 6 8 10 12 14 x 10 5 10 0 10 1 10 2 10 3 10 4 m e x e c u ti o n  ti m e  s e c  CCI Miner  \(PUMSB @ 29000 closet         \(PUMSB @ 29000 CCI Miner  \(CHESS @ 1200 closet         \(CHESS @ 1200 CCI Miner  \(CONNECT @ 11000 closet         \(CONNECT @ 11000 a b c Figure 4. Experimental results with CAM ? sum\(X.price 6. Conclusions 


6. Conclusions In this paper we have addressed the problem of mining frequent constrained closed patterns from a qualitative point of view. We have shown how previous works in literature overlooked this problem by using a postprocessing approach which is not lossless, in the sense that the whole set of constrained frequent patterns cannot be derived. Thus we have provided an accurate de?nition of constrained closed itemsets w.r.t the conciseness and losslessness of this constrained representation, and we have deeply characterized the computational problem. Finally we have shown how it is possible to quantitative push deep both requirements \(satisfying constraints and being closed process gaining performance bene?ts with the increasing of the constraint selectivity References 1] R. Agrawal, T. Imielinski, and A. N. Swami. Mining association rules between sets of items in large databases In Proceedings ACM SIGMOD, 1993 2] R. Agrawal and R. Srikant. Fast Algorithms for Mining Association Rules in LargeDatabases. InProceedings of the 20th VLDB, 1994 3] R. J. Bayardo. E?ciently mining long patterns from databases. In Proceedings of ACM SIGMOD, 1998 4] F. Bonchi, F. Giannotti, A.Mazzanti, andD. Pedreschi Adaptive Constraint Pushing in frequent pattern mining. In Proceedings of 7th PKDD, 2003 5] F. Bonchi, F. Giannotti, A.Mazzanti, andD. Pedreschi ExAMiner: Optimized level-wise frequent pattern mining withmonotone constraints. InProc. of ICDM, 2003 6] F. Bonchi, F. Giannotti, A.Mazzanti, andD. Pedreschi Exante: Anticipated data reduction in constrained pattern mining. In Proceedings of the 7th PKDD, 2003 7] F. Bonchi and B. Goethals. FP-Bonsai: the art of growing and pruning small fp-trees. In Proc. of the Eighth PAKDD, 2004 8] J. Boulicaut and B. Jeudy. Mining free itemsets under constraints. In International Database Engineering and Applications Symposium \(IDEAS 9] C. Bucila, J. Gehrke, D. Kifer, and W. White DualMiner: A dual-pruning algorithm for itemsets with constraints. In Proc. of the 8th ACM SIGKDD, 2002 10] J. Han, J. Pei, and Y. Yin. Mining frequent patterns without candidate generation. In Proceedings of ACM SIGMOD, 2000 11] L.Jia, R. Pei, and D. Pei. Tough constraint-based frequent closed itemsets mining. In Proc.of the ACM Symposium on Applied computing, 2003 12] H. Mannila and H. Toivonen. Multiple uses of frequent sets and condensed representations: Extended abstract In Proceedings of the 2th ACM KDD, page 189, 1996 13] R. T. Ng, L. V. S. Lakshmanan, J. Han, and A. Pang Exploratory mining and pruning optimizations of constrained associations rules. In Proc. of SIGMOD, 1998 14] N. Pasquier, Y. Bastide, R. Taouil, and L. Lakhal. Discovering frequent closed itemsets for association rules In Proceedings of 7th ICDT, 1999 15] J.Pei, J.Han,andL.V.S.Lakshmanan.Mining frequent item sets with convertible constraints. In \(ICDE  01 pages 433  442, 2001 16] J. Pei, J. Han, and R. Mao. CLOSET: An e?cient algorithm formining frequent closed itemsets. InACMSIGMODWorkshop on Research Issues in Data Mining and Knowledge Discovery, 2000 17] J. Pei, J. Han, and J. Wang. Closet+: Searching for the best strategies for mining frequent closed itemsets. In SIGKDD  03, August 2003 18] L. D. Raedt and S. Kramer. The levelwise version space algorithm and its application to molecular fragment ?nding. In Proc. IJCAI, 2001 


ment ?nding. In Proc. IJCAI, 2001 19] R. Srikant, Q. Vu, and R. Agrawal. Mining association rules with item constraints. In Proceedings ACM SIGKDD, 1997 20] M. J. Zaki and C.-J. Hsiao. Charm: An e?cient algorithm for closed itemsets mining. In 2nd SIAM International Conference on Data Mining, April 2002 Proceedings of the Fourth IEEE International Conference on Data Mining \(ICDM  04 0-7695-2142-8/04 $ 20.00 IEEE pre></body></html 


4] K. Chang, C. Chong, Bar-Shalom, Joint Probabilistic Data Association in Distributed Sensor Networks IEEE Transactions on Automatic Control, AC-31\(10 octobre 1986 5] Bar-shalom, Multitarget Multisensor Tracking Advanced Application ,:YBS Publishing, 1990 6] Bar-shalom, Multitarget Multisensor Tracking Principles and Techenices ,:YBS Publishing, 1995 7] Hu Wenlong, Mao shiyi, Multisensor Data Association Based on Combinatorial Optimization[J]. Journal of Systems Engineering and Electronics . 1997 NO.1,1~9 8] Pattipati K R, Passive Multisensor Data Association Using a New Relaxation Algorithm.In Multitarget-Multisensor Tracking: Advanced and Applications,Y.Barshalom,Norwood,MA:Aretech,199 0 9] Deb S,et al, An S-Dimentional Assignment Algorithm for Track Initiation ,Proc. Of the IEEE Int. Conf Systems Engineering, Kobe, Japan,Sept 1992 527~530 10] Deb S,et al, A Multisensor-Multitarget Data Association Algorithm for Heterogeneous Sensors[J].IEEE Trans. on AES 1993 ,29 \(2 560~568 12] Bar-shalom,Y.,and Fortmann,T.E  Tracking and Data Association  New York:Academic press,1988 13] J,A,Roecher and G.L.Phillis,Suboptimal Joint Probabilistic Data Association .IEEE Transaction on Aerospace Electronic Systems.1993,29\(2 14] J,A,Roecker,A Class of Near Optimal JPDA Algorithm IEEE Transaction on Aerospace and Electronic Systems,1994,30\(2 15] Han Yanfei, Analysis and Improvement of Multisensor Multitarget Probabbilistic Data Association Filting Algorithm[J].  Journal of Systems Engineering and Electronics, 2002, Vol.24, 36~38  569 pre></body></html 


dense data sets for evaluating pattern mining algorithms These two data sets are obtained from IBM Almaden at http://www.almaden.ibm.com/cs/quest/demos.html. Recently, theMAFIA algorithm [6] was proposed to ef?ciently discover maximal frequent patterns. As shown in their paper, MAFIA can be several orders better than some alternatives, such as DepthProject, for mining maximal frequent patterns. Hence, we chose MAFIA as the base line for our performance evaluation. Finally, please note that only the size-2 patterns are generated in the ?rst BFS phase Experimental Platform We implemented the MHP algorithms using C++ and all experiments were performed Proceedings of the 16th IEEE International Conference on Tools with Artificial Intelligence \(ICTAI 2004 1082-3409/04 $20.00  2004 IEEE on a Pentium III    MHz PC machine with    megabytes main memory, running Linux Redhat 6.1 operating system 5.2. A Performance Comparison 100 1000 10000 100000 1e+06 1e+07 1e+08 1e+09 1e+10 1e+11 0.02 0.025 0.03 0.035 0.04 0.045 0.05 0.055 0.06 N um be r o f C he ck ed P at te rn s Support threshold Mafia Min_Conf=0 Min_Conf=0.1 Min_Conf=0.3 Min_Conf=0.5 Min_Conf=0.7 Min_Conf=0.9 


Figure 4. The Number of Checked Patterns on the Pumsb* Data Set 10 100 1000 10000 100000 0.02 0.025 0.03 0.035 0.04 0.045 0.05 0.055 0.06 R un T im e s ec  Support Threshold Mafia Min_Conf=0 Min_Conf=0.1 Min_Conf=0.3 Min_Conf=0.5 Min_Conf=0.7 Min_Conf=0.9 Figure 5. The RunTime Comparison on the Pumsb* Data Set Figure 4 shows the number of patterns that MHP and MAFIA have to check during the pattern mining process on the pumsb* data set. As can be seen, for MHP, the number of checked patterns is increased with the decrease of the h-con?dence threshold. However, the number of checked patterns of MHP can be signi?cantly smaller than that of MAFIA even if a low h-con?dence threshold is speci?ed To check a pattern, we need to count the support of the patterns. Counting the support of a pattern is the most timeconsuming task during the pattern mining process, since we need to retrieve all the transactions which include one of its sub-pattern, or for Ma?a, retrieve all the bit of the bitmap of this pattern [6]. Therefore, an algorithm is more ef?cient if smaller number of patterns need to be checked 100 1000 10000 100000 1e+06 1e+07 1e+08 1e+09 0.1 0.2 0.3 0.4 0.5 0.6 0.7 N 


um be r o f C he ck ed P at te rn s Support Threshold Mafia Min_Conf=0.5 Min_Conf=0.7 Min_Conf=0.9 Figure 6. The Number of Checked Patterns on the Pumsb Data Set 10 100 1000 10000 0.1 0.2 0.3 0.4 0.5 0.6 0.7 R un T im e s ec  Support Threshold Mafia Min_Conf=0.5 Min_Conf=0.7 Min_Conf=0.9 Figure 7. The RunTime Comparison on the Pumsb Data Set The runtime comparison of MHP and MAFIA on the Pumsb* data set is shown in Figure 5. In the ?gure, we can observe that the runtime of MHP can be signi?cantly reduced with the increase of h-con?dence thresholds. Also the runtime of MHP can be several orders of magnitude less than that of MAFIA even if the h-con?dence threshold is as low as 0.3. The reason is that the number of checked patterns of MHP is sign?cantly smaller than that of MAFIA Similar results are also obtained from the pumsb data set as shown in Figure 6 and Figure 7. For the pumsb data set the number of checked patterns of MHP is much smaller 


than that of MAFIA and the runtime of MHP can be significantly less than that of MAFIA 5.3. The Effect of the MHP Algorithm on Finding Maximal Hyperclique Patterns Figure 8 and Figure 9 show the number of maximal patterns identi?ed byMHP andMAFIA on Pumsb* and Pumsb data sets respectively. As can be seen, the number of maximal hyperclique patterns identi?ed by MHP can be orders of magnitude smaller than the number of maximal frequent patterns identi?ed by MAFIA. In other words, the number Proceedings of the 16th IEEE International Conference on Tools with Artificial Intelligence \(ICTAI 2004 1082-3409/04 $20.00  2004 IEEE 100 1000 10000 100000 1e+06 1e+07 1e+08 1e+09 0.02 0.025 0.03 0.035 0.04 0.045 0.05 0.055 0.06 N um be r o f C ou nt ed P at te rn s Support Threshold Mafia Min_Conf=0 Min_Conf=0.1 Min_Conf=0.3 Min_Conf=0.5 Min_Conf=0.7 Min_Conf=0.9 Figure 8. The Number of MFI/MHP Patterns in the Pumsb* Data Set 100 1000 10000 100000 1e+06 


1e+07 1e+08 0.1 0.2 0.3 0.4 0.5 0.6 0.7 N um be r o f C ou nt ed P at te rn s Support Threshold Mafia Min_Conf=0.5 Min_Conf=0.7 Min_Conf=0.9 Figure 9. The number of MFI/MHP Patterns in the Pumsb Data Set of maximal hyperclique patterns is much easier to manage than that of maximal frequent patterns. Indeed, in realworld applications, it is dif?cult to interpret several million maximal frequent patterns. However, it is possible to interpret the results of maximal hyperclique pattern mining In addition, due to the memory limitation, we cannot extract maximal frequent patterns with MAFIA on the Pumsb data set if the support threshold is less than 0.4, as shown in Figure 7. In contrast, MHP can identify maximal hyperclique patterns when the support threshold is 0.1, if we set the h-con?dence threshold to 0.5. In other words, MHP has the ability to identify patterns which can be dif?cult to identify for MAFIA. Hence, MHP can better explore the pattern space and ?nd interesting patterns at low levels of support 6. Conclusions and Future Work In this paper, we present a two-phase Maximal Hyperclique Pattern \(MHP best features of both the BFS strategy and the DFS strategy. More speci?cally, we adapted DFS pruning methods such as equivalence pruning, to an apriori-like approach In addition, we proved the correctness and completeness of the MHP algorithm. Finally, our experimental results show that the MHP algorithm can be several orders of magnitude faster than standard maximal frequent pattern mining algorithms and has the ability to identify patterns at extremely low levels of support in dense data sets There are several directions for future work. First, in 


this paper, we only generate the size-2 patterns in the BFS phase. It will be interesting to investigate the impact on the performance if the ?rst phase is stopped at a deeper level Also, the projection is a very ef?cient method for ?nding patterns, especially for parallel implementation of pattern mining algorithms [1]. We plan to adapt the projection ideas into our algorithm and design an ef?cient parallel algorithm for mining maximal hyperclique patterns References 1] R. Agarwal, C. Aggarwal, and V. Prasad. A Tree Projection Algorithm For Generation of Frequent Itemsets. pages 350 371, Feb 2001 2] R. Agrawal, T. Imielinski, and A. Swami. Mining Association Rules between Sets of Items in Large Databases. In Proc. of the ACM SIGMOD Conference on Management of Data, pages 207216,May 1993 3] R. Agrawal and R. Srikant. Fast Algorithms for Mining Association Rules. In Proc. of the 20th Intl Conference on Very LargeData Bases, 1994 4] R. Bayardo. Ef?ciently mining long patterns from databases In Proc. of the ACM SIGMOD Conference, 1998 5] R. Bayardo and R. Agrawal. Mining the Most Interesting Rules. In Proc. of the ACM SIGKDD Conference, 1999 6] D. Burdick, M. Calimlim, and J. Gehrke. Ma?a: AMaximal Frequent Itemset Algorithm for Transactional Databases. In Proc. of IEEE Conf. on Data Engineering, 2001 7] Y. Huang, H. Xiong, W. Wu, and Z. Zhang. A Hybrid Approach for Mining Maximal Hyperclique Patterns. In In Technical Report UTDCS-34-04, Department of computer science, University of Texas - Dallas, 2004 8] J.Han, J.Pei, and Y. Yin. Mining Frequent Patterns without Candidate Generation. In Proc. of the ACM SIGMOD International Conference on Management of Data, 2000 9] M.J.Zaki and C.Hsiao. ChARM: An ef?cient algorithm for closed itemset mining. In Proc. of 2nd SIAM International Conference on Data Mining, 2002 10] R.Rymon. Search through Systematic Set Enumeration. In Proc. Third Intl Conference on Principles of Knowledge Representation and Reasoning, 1992 11] H. Xiong, M. Steinbach, P.-N. Tan, and V. Kumar. HICAP: Hierarchial Clustering with Pattern Preservation. In Proc. of 2004 SIAM International Conference on Data Mining \(SDM 12] H. Xiong, P.-N. Tan, and V. Kumar. Mining Strong Af?nity Association Patterns in Data Set with Skewed Support. In Proc. of the Third IEEE International Conference on Data Mining \(ICDM Proceedings of the 16th IEEE International Conference on Tools with Artificial Intelligence \(ICTAI 2004 1082-3409/04 $20.00  2004 IEEE 





