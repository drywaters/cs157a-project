html><head></head><body><pre style="word-wrap: break-word; white-space: pre-wrap;">25-29 July  2004 Budapest, Hungary Mining Fuzzy Rules for Time Series Classification Wai-Ho Au Department of Computing The Hong Kong Polytechnic University Hung Hom, Kowloon. Hong Kong E-mail: cswhau@comp.polyu.edu.&amp Absfmcf - Time series classification is concerned about discovering classification models in a database of pre-classified time series and using them to classify unseen time series. To better handle the noises and fuzziness in time series data, we propose a new data mining technique to mine fuzzy rules in the data. The fuzzy rules discovered employ fuzzy sets to represent the revealed regularities and exceptions. The resilience of furzy sets to noises allows the proposed approach to better handle the noises embedded in the data. Furthermore, it uses the adjusted residual as an objecthe measure to evaluate the intereslingness of association relationships hidden in the data. The adjusted residual analysis allows the differentiation of interesting relationships from uninteresting ones without any user-specified thresholds. To evaluate the performance of the proposed approach, we applied it to several well-known time series datasets. The experimental results showed that our approach is very promising I. INTRODUCTION Time series classification is an important topic in data mining research. Et is concemed about discovering classification models \(classifiers classified time series and using them to classifL unseen time series. Time series data typically contain a large amount of noises [27]. The ability to handle noises effectively is therefore crucial for a classifier to be useful To better handle the noises in time series data, we propose a new data mining technique to discover fuzzy rules in the data in this paper. The f u a y  rules discovered employ fuzzy sets to represent the revealed regularities and exceptions. The resilience of fuzzy sets to noises allows the proposed approach to better handle the noises embedded in the data Furthermore, it uses the adjzcsted residual [ 151, [ 161 as an objective measure to evaluate the interestingness of association relationships hidden in the data. The adjusted residual analysis allows the differentiation of interesting relationships from uninteresting ones without any user specified thresholds. It is also resilient to noises hidden in the data [15], [16]. It has been shown to be very effective in classification [7], [9] and association rule mining [SI, [13 14] &amp;om relational and transaction data In this paper, we apply the adjusted residual to mine fuzzy rules in time series daata. Although the high dimensionality very high feature correlation, and the large amount of noises that characterize time series data have been considered a Keith C. C. Chan Department of Computing The Hong Kong Polytechnic University Hung Hom, Kowloon, Hong Kong E-mail: cskcchan@comp.polyu.edu.hk unique research challenge [27], our work shows that the adjusted residual is able to perform data mining effectively in not only relational and transaction data but also time series data The rest ofthis paper is organized as follows. In Section 2 we describe the related work in mining time series. In Section 3, we present the details of the proposed approach to mining fiizzy rules in time series data. To evaluate the performance of our approach, we applied it to several well known time series datasets. The experimental results are given in Section 4. Finally, in Section 5 ,  we conclude this paper with a summary 11. RELATED WORK Many data mining approaches have been proposed for time 


Many data mining approaches have been proposed for time series classification in the data mining literature \(e.g., [6 typically focus on the introduction of a new similarity measure as a subroutine to an existing classification algorithm \(e.g., the l-Nearest Neighbor algorithm these approaches may classify unseen time series accurately they do not focus on revealing the regularities and/or exceptions hidden in the time series data explicitly. Recently it has been shown in [27] that these approaches performed poorly when compared to the Euclidean distance in the experiments with some well-known time series datasets Their dissatisfactory performance is perhaps due to the noisy and fuzzy nature of time series data The mining of seqtientiai patterm [2]. .frequent epis0de.s 3 I], and partial periodic patterns [20], which are concemed with discovering event sequences \(i.e., groups of events ordered by time first two techniques aim at identifying frequent event sequences whereas the third technique aims at finding event sequences, which reoccur for a period or a set of periods Furthermore, an approach for clustering time series has been presented in [18]. The problem of event detection, which is concerned with finding time points at which the parameters in a data model or even the model itself are changed, has been introduced in [IY]. However, these techniques are not developed for mining rules \(i.e., the if-then relationships between events In addition to these techniques. the mining of n dimmsionaf inter-trmsuction association ides has been I  11. [231, f251, [ W .  P81, W I ,  E331, [361, 1371 0-7803-8353-2/04/$20.00  2004 IEEE 239 FUZZ-IEEE 2004 introduced in [30]. An n-dimensional inter-transaction association rule is concerned with the association among items from different transaction records. each of which is characterized by n ditnensional attribzites \(e.g.. time, location etc extensions of Apriori [I], have been proposed to deal with the huge search space. An association rule is considered interesting if its support and confidence are greater than or equal to the user-speci fied minimum siipporf and minimum co@ience, respectively. A weakness of these algorithms lies in the difficulty in deciding what these thresholds should be If  it is set too high. a user may miss some usefiil rules but if it is set too low, the user may be overwhelmed by many irrelevant ones [2 I],  [22 Another approach for discovering rules in time series data has been presented in [17]. This approach first forms a set of subsequences by sliding a window through a time series and then clusters the subsequences by using a suitable measure of time series similarity, e.g., the Euclidean distance. The center of each cluster is then encoded to a sequence of primiiive dtuyes. From these sequences of primitive shapes, it mines a set of rules in the form of "if A ,  then B within time 1"' where A and B are sequences of primitive shapes. Each rule is associated with two parameters: frequency and confidence This approach only discovers those rules whose frequencies and confidences are greater than or equal to the user-specified minimum jrequency and niirzimirm coiiJdencc, respectively The discovered rules are then ranked by using the J-measure 35]. However, it can be difficult for the users to decide what the thresholds should be and the inappropriate setting can result in the neglect of some useful rules or the discovery of many irrelevant ones [21]. [22 Recently, an information-theoretic fuzzy approach has been proposed in [29] for knowledge discovery in time series data. This approach cleans and preprocesses the time series data based on signal processing techniques. It then identifies the most useful features of the preprocessed data by constructing an information-theoretic connectionist network A set of rules can then be extracted from the connectionist network. The set of discovered rules is then reduced by 


network. The set of discovered rules is then reduced by fkzifying the rules, reducing the set of fuaified rules by conflict resolution, and merging rules from the reduced set Instead of fuzzifying the crisp rules discovered in crisp data our approach can deal with fuzzy data and discover fuzzy rules to represent the regularities and exceptions hidden in the data 111. THE DETAILS OF THE PROPOSED APPROACH Given a database of time series, St, ..., S,, where S, = \( ~ ~ 1 ,  .... s,,&amp; s,, E [f,, 4 E 93, i = 1, ..., n, j = 1, .... w such that s,, is the value of SI at time fi, each SI is classified into one of the predefiied classes, CI. . . ., C",. The proposed approach mines a set of fuzzy rules in SI, . . ., S, and classify an unseen time series using the discovered rules A Fiizqv Sets We define a set of fuuy  sets over [ I , ,  iz] c_ 91, which is the domain of each s,,, i E { I ,  ..., n denote Ihe fuzzy sets as Fk, k = 1, ..., h. The membership function ofFA is denoted as pFk and is defined as pFk : [ I ,  7 \(2 1 -+ Io, I1 The degree of membership of some value s E [II, I.] c 'Ji with some fuzzy set Fk is given by ,uFk \(x Using the above technique. we can represent s,, i E { I n1.j E [ I ,  ..., w h Fk E F, the degree of membership of s,, j E { I ,  . . .. tvl. in SI with respect to Fk is given by pS \(s s,, in SI can therefore be represented by a set of ordered pairs, g,,, such that gr, = \(\(Ft, &amp;I Fb. ,&amp;,d where L I ~ , ~  = pFA \(s by a ftrzzy time series, GI, such that G, = \(g,i3 .. . , g1,, 1 Let be a subset of integers such that = \(il, .... . j r wherej,, . . . , J r  E { 1, ,. ., i t s further suppose that glco = {g,, 1 .j E q}. Given any g,, it  is associated with a set of fuzzy sets, Fw, p 2 f ,  .... h'. Each Fg, is defined by a set of fuzzy sets. fr', I \(FL, ,ul,k j  E p A k E { 1, . . ., h } } .  The degree to which G, is characterizcd by Fcv, pFT \( G I lfw\(G biy&amp; I \( F L  r p i j k 1 For any fuzzy time series GI, i E { I ,  ..., n degFwc,, \(GI the fuzzy set Fw and the class label C,,, q E \( I ,  .... tn degk '. \(G A j E A k E fl, ...,h w Y G  otherwise 4 2 We further suppose that is the sum of degrees to which GI, i = 1. ..., n, is characterized by the fuzzy set Fw and the class label C,. os,,c-,, is given by 3 240 2 5 2 9  July, 2004 Budapest, Hungary B. The Fuzzy Dura Mining Algorithm It is important to note that a fuzzy rule can be of different orders. A first-order fuzzy rule can be defined lo be a rule involving one fuzzy set in its antecedent; a second-order rule can be defined to have two; and a third-order rule can be defined to have three fuzzy sets, etc. Our approach is given in Fig. 1 RI = {first-order hazy rules for \(d= 2; IRd-lI f 9, dt- f begin T =  \(each fitzzy set in the antecedent of 1 1 I E R,I I for all p composed of d elements in T do begin forallC,,qE { 1  ...., m begin calculate u ~ + ~ , - ~  using \(3 


calculate u ~ + ~ , - ~  using \(3 if interesring\(F,,, C R Fw, C end end end K = U R d d Fig. 1 .  Thc funy data mining algonthm To mine interesting first-order rules, our approach makes use of an objective interestingness measure introduced in Section I1I.C below. After these rules are discovered, they are stored in RI \(Fig. I second-order rules that are then stored in R2. Rz is then used to generate third-order rules that are stored in R3 and so on for 4th and higher order. Our approach iterates until no higher order rule can be found The function, interessting\(Fqp, Cq measure to determine whether the association between Fw and C, is interesting. If interesting\(l;;,, C fw.zy rule is then generated by the nrlegm function. For each rule generated, this function also returns an uncertainty measure associated with the rule \(see Section 1JI.D fuzzy rules generated by rulegen arc stored in X that will then be used later for prediction or for the user to examine C. Discovering hateresting Rules in Fuzzy Time Series In order to decide whether an association between a fuzzy set, FGp, and a class label, C, is interesting, we determine whether 4 q=l is significantly different from h  m where M = 7, oFVCg . I f  this is the case. we consider the p=l q-1 association between Fw and C, interesting The significance of the difference can be objectively evaluated based on the idea of the u&amp;sted residual [ 151, [ 161 defined as where zI  c, is the stundurdized raiduul given by w Y 7 ec7,cq is the sum of degrees to which time series are expected to be characterized by FR calculated by and Y ~ , , ~ ,  is the maximum likelihood estimate of the variance of zF and is computed by R P Y Since d, has a standard normal distribution [3], if I dT7,cg /&gt; 1.96 \(the 95 percentiles ofthe normal distribution we c m  conclude that the discrepancy between Pr\(F, I C,J and Pr\(C between Fyp and C; is interesting  7, 4 24 1 F UZZ-IEEE 2004 In addition, if dFpcq &gt; +1.96 the presence of Fq implies the presence of C,. In other words, it is more likely for a time series having both F ,  and C,. On the other hand, if dFwc9 &lt; - 1.96 , the presence of F,, implies the absence of C In other words, it is less likely for a time series having Fwt and Cy at the same time D. The lincertainty Meiisure we can form the following fuzzy rule Given that the association between F+? and C, is interesting where wF is the wight  of evidence [15], [I61 that is defined as follows Since the association between Fq, and C, is interesting there is some evidence for a time series to be characterized by Cy given it has Fw The weight of evidence is defined in terms of an information-theoretic measure known as mutual 


terms of an information-theoretic measure known as mutual hfurmafion. It measures the change of uncertainty about the presence of C, in a time series given that it has FcT is, in tum defined as W Y Based on mutual information, the weight of evidence is defined in [ 151, [ 161 as Fq,Cq = I\(C, : Fg U\(C, : FqJ I wF can be interpreted intuitively as a measure of the difference in the gain in information when a time series with F,, characterized by C, and when characterized by other class labels. The weight of evidence can be used to measure the significance or importance of fuzzy rules E, Classi3ing Unseen Time Series Using i;iizz.v Rules Given a time series, d = \(a,, . . .. a j =  1 , .  . . , IV, d can be represented by a fuzzy time series d' = \(PI, ..., ,&amp F p6 \(a Ft,, pFh \(a given by the class of d'. For any combination of values. &amp of d', it is characterized by a fuzzy set, FcT,. to a degree of compatibility, p F  , \( d 1, ..., hr those rules implying the assignment of C Fw = C, [wFWcLt 1, for all p E &lt;c f I ,  . ... h'}, the evidence for such assignment is given by w q P . i Suppose that, of the w values, only some combinations of them, f i l l P, l j  E {l .  .... w &gt; }  are found to match one or more rules, then the overall weight of ebidence for the time series to be assigned to C, is given by i=l d belongs to class C, if coCY 2 wc, , i f q 1V. EXPERIMENTAL RESULTS To evaluate the performance of the proposed approach, we applied it to several well-known time series datasets. They are artificial problems used by several researchers in the context of time series classification A. The Dutusets The Control Chart Dataset. It was used for evaluating the performance of classification and clustering algorithms [4 SI. The dataset contains 600 time series, each of which consists of 60 time points and is classified into one of the six possible classes It was introduced in [I21 for evaluating ciassification algorithms. The dataset contains 5,000 time series; each is composed of 21 time points and is classified into one of the three possible classes It was the same as the Wnwjbrm dataset. but 19 random points w,ith mean = 0 and variance = 1 were added to the end of each time series B. The Resiifts Since the membership functions of fitzzy sets can profoundly affect the performance of the classification models discovered, they have to be determined carefully The membership functions can be either determined by human experts or generated directly from data. To evaluate the performance of the proposed approach in an objective manner, we decided to generate the membership functions of the fuzzy sets used in our experiments using the j k ~  c means \(FCM  experts to determine them. The FCM algorithm is a well known fuzzy clustering algorithm. which allows a datum in a dataset to partially belong to multiple clusters. We applied the FCM algorithm to each of the time series datasets to generate the membership functions of the fimy sets. Based on the fiizzy sets generated, each time series in the dataset was then transformed to a fuzzy time series After the data transformation, we divided each of the datasets into a training set. which contained 90% of the time series, and a test set. which contained the remaining time 


series. We then mined a set of fuzzy rules in the training set The Waveform Dataset The Waveform-Noise Dataset 242 25-29 July, 2004 Budapest, Hungary 1 Dataset and used the rules to classify the time series in the test set To facilitate the comparison, we also applied C4.5 [34], a well-known decision tree based algorithm, and the 1-Nearest Neighbor \(I-NN the datasets. The I-NN algorithm using the Euclidean distance was used because a recent study [27] showed that it outperformed many approaches proposed in the data mining literature \(e.g., [6], [ I  11, [23], [25]. [26], [28], [32], [33], [36 37 the 1-NN algorithm is given in Table I Percentage Accuracy Standard Deviation Our I c4.5 I I -NN Noise Avera.ge I Approach I I CiittroiChavt I 100.0% I 90.0% 1 98.6 4.8 3.2 7.0 86.9% 82.1% 84.9?4 The experimental results showed that ow approach obtained higher classification accuracy than C4.5 and the I NN algorithm in the datasets. It is important to note that the classification accuracy of our approach and C4.5 are more or less the same in the Waveform dataset. Nevertheless. when noises were added to the dataset. which resulted in the Wavefii-m-Noise dataset, the proposed approach produced more accurate classification than C4.5. This is perhaps because of the resilience to noises of both fuzzy sets and the adjusted residual used in our approach V. CONCLUS~ONS In this paper, we proposed a new data mining technique to discover fiizzy rules in time series data. The fuzzy rules employ f i r q  sets to represent the revealed regularities and exceptions hidden in the data. The use of fiuzy sets allows the proposed approach to be resilient to noises hidden in the time series data. To distinguish interesting association relationships from uninteresting ones, our approach utilizes the adjusted residual analysis, which has an advantage that it does not require any user-specified thresholds We applied our approach to several well-known time series datasets. To facilitate the comparison, we also applied \(24.5 and the ]-Nearest Neighbor algorithm to the same datasets The experimental results showed that tbe proposed approach achieved higher percentage accuracy than C4.5 and the 1 Nearest Neighbor algorithm in these datasets. The superior results of the proposed approach are perhaps due to the resilience to noises of both fuzzy sets and the objective interestingness measure ACKNOWLEDGMENT The research was supported in part by The Hong Kong Polytechnic University under Grant A-P209 and Grant G V958 REFERENCES I  1 R. Ayawal and R. Srikant  Fast Algorithms for Mining Association Rulcs  in Proc. uf the 20th lnt  I Coi$ on rei? Luqe Data Buser Santiago, Chile, 1994, pp. 387399 R. Apawal and R. Srikant  Mining Sequential Pattcms  in Pruc. qf   the 11th /LEE In  CUT$ on Datu Engitwering, Taipei, Taiwan. 1995 pp. 3--- 14 A. Agresti, Cuie.qot-iculDu&amp; .4nufysi.s, New York, NY: Wiley, 1990 R. J. Alcock and Y. Manolopoulos  Time-Scrics Similarity Queries Employing a Feature-Based Approach  in P roc. of  the 7th fteffenic Cot$ on Iqkmrtics, ioannina. Greccc, 1999 SI R. J. Alonso tionzdez and J. J. Rodriguez Dicz  Time Scrics Classification by Boosting Intend Based LiteraIs  Inteligencia 


Classification by Boosting Intend Based LiteraIs  Inteligencia 4rrIficial, Revistu iherumnericanu de Inteligenciu Artifkid,  vol. 1 I ,  pp 2-1 1,2000 H. Andre-Jonsson and D. Badal  Using Signature Files for Querying Time-Scrics Data  in Proc. ofthe lst Europem Svinp. on Datu Mining undKnowIedge Discovery, Trondhcim, Nonvay, 1997, pp. 2 I 1-220 171 W.-H. h u  and K. C. C. Chan  Classification with Dcgrce of Mcmbcrship: A Fuzzy Approach  in Pruc. ul  the 1st IEEE In1  I C  oizJ on nata Mzning, San Jose, CA, 200 I. pp. 3532 W.-H. Au and K. C:. C.  Chan  Mining Fuzzy Association Rulcs in a Bank-Account Database  IEEE Trans. on Furzy Systems, vol. 11, no. 2 W.-H. h u ,  K. C. C .  Chan, and X. Yao  A Novcl Evolutionaly Data Mining Algorithm with Applications to Chum Prediction  IEEE Trms on Kvofutiunu&gt;y Compzttr;r~ion, vol. 7, no. 6. pp. 532-545, 2003 1 a] J. C. Rczdck. Pattern RecrJgnftion with F u r q  Objective Fuirciion Algol-ithm, Ncw York. NY: Plenum. 1981 l i ]  T. Bozkaya, N. Yazdani. and Z. M. Ozsoyoglu  Matching and Indcxing Scqucnees of Different Lcngths  in Proc:. qf rhe 6th fnt CunJ  un In/brmution und Kizonl~dge .+lunagernenf, Las Vegas, NV I21 L. Breiman, J. H. Friedman, A. Olshcn, and C. J. Stone, Clus.sifimficJ?t izndRqycssion Tree.s, Ncw York, NY: Chapman &amp; Hall. 1993 I31 K. C. C. Chan and W.-1.1. Au  Mining Fuzzy Association Rules  in Proc. of the 6th Int  l Cot$ on itformation and Knowledge 1bfitnilgemen6, Las Vegas, NV, 1997, pp. 209-215 I41 K. C. C. Chan and W.-H. Au  Mining Fumy Association Rules in a Database Containing Rclational and Transactional Data  in A. Kandcl M. Last, and H. Bunke \(E&amp Intelli.qenm, Ncw York. NY: Physica-Vcrlag. 2001, pp. 95-1 14 I51 K. C:. C. Chan and A. K. C. Wong  APACS: A Systcm for the Automatic Analysis and Classification of Conccphrd Pattcms   Cowrpztfafiunal Inielligenc;e, vol. 6, pp. 1 19-1 31, 1990 I61 K. C. C. Chan and A. K. C. Wong  A Statistical Tcchniquc fix Extracting Classificatory Knowlcdgc from Databases  in G. Piatctsky Shapiro and W. J. Prawlcy \(Eds Mcnlo Park, CA; Cambridge. MA: AAAVMIT Prcss, 1991, pp. 107 123 I71 G .  Das. K.4 .  Lin, H. Mannila, G.  Rcnganathm, and P. Smyth  Rulc Discovery from Time Scncs  in Pruc. qf ihe 4th h7t  Cunt on Kno~vledge Dkrcovwy and Datu Mining, New York. NY, 1998, pp. 1 &amp 22 I81 M. Gavrilov, D. Anguclov, P. tndyk, and R. Motwani  Mining the Stock Markct: Which Measure is Best  in Pruc. qf the 6th ACM SIGKDD lni  I Con/: on Knowirdge Discown&gt; und Dum Mining Boston, MA, 2000, pp. 487496 121 r31 4 6 8 pp. 238----248, 7003 9 1997, pp. 128--135 243 FUZZ-1EEE 2004 1191 V Curalnik and .i. Srivastaia  Evcnt Detection from Timc Scncs Data  in Pruc 01 [he Sth ACM SlGKDD lnt f Cowl: o n  Knrndeclge Discovery and Data ibfining, S m  Dicgo, CA. 1999. pp 33-42 20] J Han, G. Dong, and Y. Vin  hfficicnt Mining of Partial Pcriodic Pattcnis in Timc Scries Database  in Proc ojthe 15th IELE lnt  l Conf on Darn Engzneeririg. Sydncy, Australia. 1999, pp 106- I 15 r2ll J Han and M Kambcr. Dofa Mining Conceptt und Technryties, San Francisco, CA Morgan Kaufmann. 200 I 22] D Hand, H blannila, and P Smyth, Prvrrzpler o j  Data M ~ ~ i n g Cambridge. MA The MIT Prcss. 2001 23] Y Huang and P S. Yu  Adaptivc Qucry Proccssiiig for Tinic-Scrics Data  in Proc vj the 5th ACM SIGKDD 1nt I Con/ on Krtuwle&amp;e DISCUWF r241 Y Huhtala, J Karkkainm. and H Toivoncn. -%lining for Similaribcs in Alig~cd Timc Scncs Using Wavclcts  in B V Dasarathy \(Ed Data Mining and Knowledge D.tscovcpt  Tht.ot?., Tooh, and 


Data Mining and Knowledge D.tscovcpt  Tht.ot?., Tooh, and Terhnologv. Proc of SPlE Vol 3695, 1999. pp 150-160 1251 P. Indyk, N Koudas, and S Muthuknshnan  Identtfying Rcprcscntativc Trcnds in Massivc Timc Series Data ScCs L h g Skctchcs  in Proc U/ the 26th Int  l Con/ on C  ew Lurge Data Enw&amp Cairo. Egypt, 2000, pp. 363-372 2G] K liaipakis, D Gada. and V Puttagunta  Distance Vcasurc for Effcctivc Clustcnng of ARIMA Timc Scncs  in Proc. of the 1st IEEE Ini  I ConJ on Dafu .Mining, San Jose, CA. 200 I ,  pp. 273 280 1271 E Keogh and S Kasctty  On the Nccd for Time Series Data Mining Benchmarks A Survcy and Empincal Dcmonstration  Duto Mining 28] E Kcogh and P. Smyth  A Probabilistic Approach to Fabt Pattcm Matching in Timc Scrics Databascs  in Pro&lt;. of the 3rd In  I Cord on flWC/k  nU&gt;dcd&amp; DltccJVen, Vol. 7 .  pp. 349-37 1. 2003 Knowledge Di.srn~ery and Data Mining, Newport Beach, CA. 1997, pp 29] M. Last, Y. Klein, and A. Kandcl  Knowlcdgc Discovcry in Timc Scrics Databasc  IEEB Trans. on Systems. ;Maiz, and Cvbernetics Purr B: Cvbernetics, vol. 3 1, no. 1,200 I ,  pp. lGC169 30] H. Lu. J ,  Han, and L. Fcng  Stock Movcmnt Prcdiction and N Dimensional Intcr-Transactional Association Rulcs  in Proc. oj  the 19% SIGMOD Wurkdrop on Research  issue.^ on Dura Mining and 31] H. hlannila, H. Toivoncn. and A. I. Verkamo  Discovcring Frcqucnt Episodcs in Scqucnccs  in Proc. qf the 1st Iirt  f Con$ on Knowledge Discovcv:r: andDtitu :thing, Montrcal. Canada. 1995, pp. 210-21 5 32] S .  Park. S .  Kim, and W. W. Chu  Scgmcnt-Bascd Approach for Subscqucncc Scarchcs in Scqticncc Databascs  in PITJC. qf  the 26fh ACM Si~mp. on Applieddutnpiiiing~ Las Vcgas, NV, 2001, pp. 248-252 33] K. B. Pratt and E. Fink  Scarch for Pattcnis in Coinprcsscd Timc Scrics  In17 J. of/,nage and Graphics, vol. 2, no. 1, pp. 86106.2002 34] J. R. Quinlan. C4.4.5: Prugrams,/itr hfachine Laming,  San hlatco, CA Morgan Kaufmann, 1993 r35] P. Smyth and R. M. Goodman  An Information Theoretic Approach to Rulc Induction from Databases  IEEE Trans. un Knowledge and Dura Engineering. vol. 4, no. 4, 1992, pp. 301-216 36] Z. Struzik and A. Sicbcs  Thc Haar Wavclct Transform in the Time Scrics Similarity Paradigm  in Proc. of ihe 3rd Europwn COJ$ on Principky of  DU~O Mining cmd Knowledge Dtscovety, Prague. Czcch Republic. 1999, pp. 12.22 37] C. W m g  and X. S. W.any  Supporting Contcnt-Based Scarchcs un Timc Scrics via Approximation  in Pruc. uf the /2rh Inr  I C b n f :  on Scientijic and Stati.srieu1 Datubrrse il.fnnagettrent. Bcrlin, Gcrniany 24.--30 Kno~+I~dg&lt;&lt; D ~ S C O V ~ J ~ ,  Sattlc, WA, 1998, pp. 12: 1-1217 2000. pp. 69-81 244 pre></body></html 


             i s  a  n o n e m p t y  s u b s e t  o f   If we let varies through all non-empty subsets of  we have all possible generalizations of in GDM. We w i l l  d e n o t e  t h e  s e t  o f  a l l  g e n e r a l i z a t i o n s  b y     Observe that the intersection of generalizations is still a generalization. For any given ?nite set of generalizations t h e r e  i s  t h e  s m a l l e s t  g e n e r a l i z a t i o n   S o     i s  c l o s e d under meet \(=the intersection the smallest g e n e r a l i z a t i o n    S o     i s  a  l a t t i c e   M o r e  i m p o r t a n t l y  t h e  m e e t  a n d  j o i n  a r e  t h e  m e e t  a n d  j o i n  i n  t h e  l a t t i c e      of partitions on  Let      b e  t h e  s m a l l e s t  s u b l a t t i c e  o f      t h a t  c o n t a i n s and      b e  t h e  s m a l l e s t  s u b l a t t i c e f      t h a t  c o n t a i n s  a l l  c o a r s e n i n g  o f  Now we have Theorem 4.2         Based on this observation, we de?ne Definition 4.3. GDM           i s  c a l l e d  U n i v e r s a l  M o d e l of      i n  t h e  s e n s e  i t  c o n t a i n s  a l l  i t s  g e n e r a l i z a t i o n s     i s  t h e  f e a t u r e  c o m p l e t i o n  o f   4.4 Intuitive Discussions on Features/attributes We often hear such an informal statement  a new feature  a t t r i b u t e     i s  s e l e c t e d   e x t r a c t e d   o r  c o n s t r u c t e d  f r o m  a s u b s e t                      o f  a t t r i b u t e s  i n  t h e  t a b l e     What does such a statement mean First we observe that feature and attribute have been used interchangeably. In the classical data model, an attribute or a feature is a representation of property, characteristic, and etc.; see e.g., [15]. A feature represents a human perception about the data; each perception is represented by a symbol, and has been called attribute and the set of attributes a schema. Based on our convention, they are words in TDP Section 3 L e t  u s  a s s u m e  a  n e w  f e a t u r e    h a s  b e e  s e l e c t e d   e x t r a c t e d   o r  c o n s t r u c t e d   L e t  u s  i n s e r t  i t  i n t o  t h e  t a b l e    T h e  n e w  t a b l e  i s  d e n o t e d  b y           T h e  i n f o r m a l  s t a t e m e n t  p r o b a b l y  m e a n s  i n  t h e  n e w  t a b l e     i s  a n  a t t r i b u t e   A s i t  i s  d e r i v e d  f r o m     i t  i s  f u n c t i o n a l l y  d e p e n d e d  o n   s extraction and construction are informal words, we can use the functional dependency as formal de?nition of feature selection, extraction and constructions. Formally we de?ne 


selection, extraction and constructions. Formally we de?ne Definition 4.4.1   i s  a  f e a t u r e  d e r i v e d   s e l e c t e d   e x t r a c t e d  a n d  c o n s t r u c t e d f e a t u r e   f r o m     i f    i s  f u n c t i o n a l  d e p e n d e n t  o n    i n  t h e n e w  t a b l e          In Theorem 4.2, we have shown that      i s  f e a t u r e completion of By the convention in Section 4.2    i s  u n i n t e r p r e t e d  f e a t u r e  c o m p l e t e i o n  o f   This theorem is rather anti-intuitive. Taking human  s view there are in?nitely many features. But the theorem says there are only ?nitely many features \(as      i s  a   n i t e set the ?nite-ness slip in? Our analysis says it comes in at the representation phase. We represent the universe by ?nite words. However, in phase two, suddenly these words are reduced to symbols. Thus the in?nite world now is encoded by a ?nite set of symbols. In particular, features can only be encoded in a ?nite distinct ways. A common confusing most likely comes from the confusing of data mining and  facts  mining 5 Generalized Associations in GDM As we have observed that it is adequate to conduct AM in the canonical model, such as GDM Main Theorem 5.1. Let          b e  t h e  u n i v e r s a l m o d e l   L e t  g  b e  a  g r a n u l e  i n  a  p a r t i t i o n          h t h a t         T h e n  g  i s  a n  u n i n t e r p r e t e d  g e n e r a l i z e d associations Proceedings of the Fourth IEEE International Conference on Data Mining \(ICDM  04 0-7695-2142-8/04 $ 20.00 IEEE Let us de?ne an operation of binary number x and a set S We write S*x to be de?ned by The two equations            i f                       i f       r     Main Theorem 5.2                         be the smallest element in     L e t                b e  t h e  g r a n u l e s  i n     T h e n  t h e union                    is a granule that represents a un-interpreted generalized association rule, if its cardinality             where s is the threshold 


where s is the threshold Remark: The cardinal number of     i s  b o u n d e d  b y the Bell number [2] of       t h e  c a r d i n a l  n u m b e r  o f               The total number of derived attributes is bounded by Bell number  However the complexity of  minimal solutions  is bounded by the combination   We will report the calculation on real world data in future report soon 5.1 Find Generalized Association Rule by Linear Inequalities - an example We will illustrate the idea of the procedure of ?nding generalized association rules in Table 7 by linear inequality \(supp o r t         T h e  a s s o c i a t i o n  c a n  b e  e x p r e s s e d  a s  g r a n u l e s  1. Associations of length one  a   T E N                  b   S J                  c   L A          2. Associations of length two  a    T E N  S J     T E N    S J                  w h e r e   T E N  S J        


                        is in table format, that is equivalent to GDM f o r m a t   T E N    S J  3. No associations of length      Now let us examine the universal model in Table ??. The c o l u m n    i n  T a b l e     i s  t h e  s m a l l e s t  e l e m e n t  i n  t h e  c o m plete relation lattice      S o  e v e r y  e l e m e n t  o f     s a  c o a r s e n i n g  o f     I n  o t h e r  w o r d s   e v e r y  g r a n u l e  i n     i s  a  u n i o n  o f  s o m e  g r a n u l e s  f r o m  t h e  p a r t i t i o n     b y  t h e expression  a granule in     we mean a granule belonging to one of its partitions I n  t h i s  e x a m p l e   t h e  g r a n u l e s  i n   e    T W E N T Y    N Y           S J                     T W E N T Y    L A        T H I R T Y          be the cardinality of The following expression represents the cardinality of granules in      w h i c h  i s  a u n i o n  o f  s o m e  g r a n u l e s  f r o m  t h e  p a r t i t i o n     T W E N T Y  Y        N  J       T W E N T Y        


L A         T H I R T Y    L A           By taking the actual value of the cardinalities of the granules, we have                                                                 We will express the solutions in vector form              I t  i s  a n   integral convex set  in 4dimensional space The  boundary solutions  are 1   0   1   0   0    t h i s  s o l u t i o n  m e a n s         s cardinality b y  i t s e l f  a l r e a d y  m e e t s  t h e  t h r e s h o l d        2 \(0, 0, 1, 1 granules T W E N T Y    L A  a n d  T H I R T Y    to meet the threshold. In other words, we need a generalized concept that covers both the sub-tuple  T W E N T Y   L A    T W E N T Y    L A  a n d  T H I R T Y   L A    T H I R T Y    For this particular case, since L A     T W E N T Y   L A      T H I R T Y   L A   hence LA is the desirable generalized concept 3 \(1, 0, 0, 1 granules      T H I R T Y    L A  Proceedings of the Fourth IEEE International Conference on Data Mining \(ICDM  04 0-7695-2142-8/04 $ 20.00 IEEE Table of Granules Table of Symbols                      


                                                       


                                                  S J       


                                                      


                         L A                                        


          L A  Table 7. Table of Granules at left-hand-side is isomorphic to  at right- hand-side: By Theorem  3.1 one can ?nd patterns in either table as a single generalized concept  Internal points  are:[4]\(1, 1, 0, 0 tions; [5]\(0, 1, 1, 0  0, 1, 0, 1  0, 1, 1, 1  1, 1 1, 0  1, 1, 0, 1  1, 0, 1, 1 11]\(1, 1, 1, 1 form and simplify them into disjoint normal forms 1  T E N    S J    T E N    S J 2  T W E N T Y    L A    T H I R T Y   A 3  T W E N T Y      T H I R T Y   A 4  T W E N T Y            L A 5  T E N      T W E N T Y    L A    T E N    T W E N T Y   A   S J    T W E N T Y   A      T H I R T Y    L A     Y 7  T E N      T W E N T Y      T H I R T Y   L A    T E N   L A    S  J   A 8  T W E N T Y      T E N      T W E N T Y    L A    T E N   T W E N T Y      T H I R T Y 9  T W E N T Y    N Y    T E N    S J    T H I R T Y    L A      T W E N T Y    L A  1 0  T W E N T Y    N Y    T W E N T Y    L A    T H I R T Y   A    J 1 1  T W E N T Y          T W E N T Y    L A   T H I R T Y    L A    a l l If the simpli?ed expression is a single clause \(in the original symbols non-generalized the following associations 1   T E N     S J    T E N    S J  2. SJ   J 4   L A    T W E N T Y    L A    T H I R T Y    6 Conclusions Data, patterns, method of derivations, and useful-ness are key ingredients in AM. In this paper, we formalize the current state of AM: Data are a table of symbols. The patterns are the formulas of input symbols that repeat. The method of derivations is the most conservative and reliable one, namely, mathematical deductions. The results are somewhat surprising 1. Patterns are properties of the isomorphic class, not an individual relation - This implies that the notion of patterns may not mature yet and explains why there are so many extracted association rules 2. Un-interpreted attributes \(features can be enumerated 3. Generalized associations can be found by solving integral linear inequalities. Unfortunately, the number is enormous. This signi?es the current notion of data and patterns \(implied by the algorithms 4. Real world modeling may be needed to create a much more meaningful notion of patterns. In the current state of AM, a pattern is simply a repeated data that may have no real world meaning. So we may need to introduce some semantics into the data model [12],[10],[11 Proceedings of the Fourth IEEE International Conference on Data Mining \(ICDM  04 0-7695-2142-8/04 $ 20.00 IEEE References 1] R. Agrawal, T. Imielinski, and A. Swami  Mining Association Rules Between Sets of Items in Large Databases  in Proceeding of ACM-SIGMOD international Conference on Management of Data, pp. 207216, Washington, DC, June, 1993 


216, Washington, DC, June, 1993 2] Richard A. Brualdi, Introductory Combinatorics, Prentice Hall, 1992 3] A. Barr and E.A. Feigenbaum, The handbook of Arti?cial Intelligence, Willam Kaufmann 1981 4] Margaret H. Dunham, Data Mining Introduction and Advanced Topics Prentice Hall, 2003, ISBN 0-13088892-3 5] Fayad U. M., Piatetsky-Sjapiro, G. Smyth, P. \(1996 From Data Mining to Knowledge Discovery: An overview. In Fayard, Piatetsky-Sjapiro, Smyth, and Uthurusamy eds., Knowledge Discovery in Databases AAAI/MIT Press, 1996 6] H Gracia-Molina, J. Ullman. &amp; J. Windin, J, Database Systems The Complete Book, Prentice Hall, 2002 7] T. T. Lee  Algebraic Theory of Relational Databases  The Bell System Technical Journal Vol 62, No 10, December, 1983, pp.3159-3204 8] T. Y. Lin  Deductive Data Mining: Mathematical Foundation of Database Mining  in: the Proceedings of 9th International Conference, RSFDGrC 2003 Chongqing, China, May 2003, Lecture Notes on Arti?cial Intelligence LNAI 2639, Springer-Verlag, 403-405 9] T. Y. Lin  Attribute \(Feature  The Theory of Attributes from Data Mining Prospect  in: Proceeding of IEEE international Conference on Data Mining, Maebashi, Japan, Dec 9-12, 2002, pp. pp.282-289 10] T. Y. Lin  Data Mining and Machine Oriented Modeling: A Granular Computing Approach  Journal of Applied Intelligence, Kluwer, Vol. 13, No 2, September/October,2000, pp.113-124 11] T. Y. Lin, N. Zhong, J. Duong, S. Ohsuga  Frameworks for Mining Binary Relations in Data  In: Rough sets and Current Trends in Computing, Lecture Notes on Arti?cial Intelligence 1424, A. Skoworn and L Polkowski \(eds 12] E. Louie,T. Y. Lin  Semantics Oriented Association Rules  In: 2002 World Congress of Computational Intelligence, Honolulu, Hawaii, May 12-17, 2002, 956961 \(paper # 5702 13  The Power and Limit of Neural Networks  Proceedings of the 1996 EngineeringSystems Design and Analysis Conference, Montpellier, France, July 1-4, 1996 Vol. 7, 49-53 14] Morel, Jean-Michel and Sergio Solimini, Variational methods in image segmentation : with seven image processing experiments Boston : Birkhuser, 1995 15] H. Liu and H. Motoda  Feature Transformation and Subset Selection  IEEE Intelligent Systems, Vol. 13 No. 2, March/April, pp.26-28 \(1998 16] Z. Pawlak, Rough sets. Theoretical Aspects of Reasoning about Data, Kluwer Academic Publishers, 1991 Proceedings of the Fourth IEEE International Conference on Data Mining \(ICDM  04 0-7695-2142-8/04 $ 20.00 IEEE pre></body></html 


than that of MAFIA and the runtime of MHP can be significantly less than that of MAFIA 5.3. The Effect of the MHP Algorithm on Finding Maximal Hyperclique Patterns Figure 8 and Figure 9 show the number of maximal patterns identi?ed byMHP andMAFIA on Pumsb* and Pumsb data sets respectively. As can be seen, the number of maximal hyperclique patterns identi?ed by MHP can be orders of magnitude smaller than the number of maximal frequent patterns identi?ed by MAFIA. In other words, the number Proceedings of the 16th IEEE International Conference on Tools with Artificial Intelligence \(ICTAI 2004 1082-3409/04 $20.00  2004 IEEE 100 1000 10000 100000 1e+06 1e+07 1e+08 1e+09 0.02 0.025 0.03 0.035 0.04 0.045 0.05 0.055 0.06 N um be r o f C ou nt ed P at te rn s Support Threshold Mafia Min_Conf=0 Min_Conf=0.1 Min_Conf=0.3 Min_Conf=0.5 Min_Conf=0.7 Min_Conf=0.9 Figure 8. The Number of MFI/MHP Patterns in the Pumsb* Data Set 100 1000 10000 100000 1e+06 


1e+07 1e+08 0.1 0.2 0.3 0.4 0.5 0.6 0.7 N um be r o f C ou nt ed P at te rn s Support Threshold Mafia Min_Conf=0.5 Min_Conf=0.7 Min_Conf=0.9 Figure 9. The number of MFI/MHP Patterns in the Pumsb Data Set of maximal hyperclique patterns is much easier to manage than that of maximal frequent patterns. Indeed, in realworld applications, it is dif?cult to interpret several million maximal frequent patterns. However, it is possible to interpret the results of maximal hyperclique pattern mining In addition, due to the memory limitation, we cannot extract maximal frequent patterns with MAFIA on the Pumsb data set if the support threshold is less than 0.4, as shown in Figure 7. In contrast, MHP can identify maximal hyperclique patterns when the support threshold is 0.1, if we set the h-con?dence threshold to 0.5. In other words, MHP has the ability to identify patterns which can be dif?cult to identify for MAFIA. Hence, MHP can better explore the pattern space and ?nd interesting patterns at low levels of support 6. Conclusions and Future Work In this paper, we present a two-phase Maximal Hyperclique Pattern \(MHP best features of both the BFS strategy and the DFS strategy. More speci?cally, we adapted DFS pruning methods such as equivalence pruning, to an apriori-like approach In addition, we proved the correctness and completeness of the MHP algorithm. Finally, our experimental results show that the MHP algorithm can be several orders of magnitude faster than standard maximal frequent pattern mining algorithms and has the ability to identify patterns at extremely low levels of support in dense data sets There are several directions for future work. First, in 


this paper, we only generate the size-2 patterns in the BFS phase. It will be interesting to investigate the impact on the performance if the ?rst phase is stopped at a deeper level Also, the projection is a very ef?cient method for ?nding patterns, especially for parallel implementation of pattern mining algorithms [1]. We plan to adapt the projection ideas into our algorithm and design an ef?cient parallel algorithm for mining maximal hyperclique patterns References 1] R. Agarwal, C. Aggarwal, and V. Prasad. A Tree Projection Algorithm For Generation of Frequent Itemsets. pages 350 371, Feb 2001 2] R. Agrawal, T. Imielinski, and A. Swami. Mining Association Rules between Sets of Items in Large Databases. In Proc. of the ACM SIGMOD Conference on Management of Data, pages 207216,May 1993 3] R. Agrawal and R. Srikant. Fast Algorithms for Mining Association Rules. In Proc. of the 20th Intl Conference on Very LargeData Bases, 1994 4] R. Bayardo. Ef?ciently mining long patterns from databases In Proc. of the ACM SIGMOD Conference, 1998 5] R. Bayardo and R. Agrawal. Mining the Most Interesting Rules. In Proc. of the ACM SIGKDD Conference, 1999 6] D. Burdick, M. Calimlim, and J. Gehrke. Ma?a: AMaximal Frequent Itemset Algorithm for Transactional Databases. In Proc. of IEEE Conf. on Data Engineering, 2001 7] Y. Huang, H. Xiong, W. Wu, and Z. Zhang. A Hybrid Approach for Mining Maximal Hyperclique Patterns. In In Technical Report UTDCS-34-04, Department of computer science, University of Texas - Dallas, 2004 8] J.Han, J.Pei, and Y. Yin. Mining Frequent Patterns without Candidate Generation. In Proc. of the ACM SIGMOD International Conference on Management of Data, 2000 9] M.J.Zaki and C.Hsiao. ChARM: An ef?cient algorithm for closed itemset mining. In Proc. of 2nd SIAM International Conference on Data Mining, 2002 10] R.Rymon. Search through Systematic Set Enumeration. In Proc. Third Intl Conference on Principles of Knowledge Representation and Reasoning, 1992 11] H. Xiong, M. Steinbach, P.-N. Tan, and V. Kumar. HICAP: Hierarchial Clustering with Pattern Preservation. In Proc. of 2004 SIAM International Conference on Data Mining \(SDM 12] H. Xiong, P.-N. Tan, and V. Kumar. Mining Strong Af?nity Association Patterns in Data Set with Skewed Support. In Proc. of the Third IEEE International Conference on Data Mining \(ICDM Proceedings of the 16th IEEE International Conference on Tools with Artificial Intelligence \(ICTAI 2004 1082-3409/04 $20.00  2004 IEEE 





