html><head></head><body><pre style="word-wrap: break-word; white-space: pre-wrap;">Proceedings  of the 2004 lEEE Conference on Cybernetics and Intelligent Systems Singapore, 1-3 December, 2004 An Intelligent Recommender System using Sequential Web Access Patterns Baoyao Zhou Siu Cheung Hui Kuiyu Chang School of Computer Engineering Nanyang Technological University Nanyang Technological University Nanyang Technological  University Singapore Sin gapore Singapore zhouby~pmail.ntu.edu.sg asschui  3 ntu.edu.sg askychang@ n tu.edu.sg School of Computer Engineering School of Computer Engineering Abstract-To provide intelligent personalized online services such as web recommendations, it is usually necessary to model users  web acces behavior. To achieve this, onc of the promising approaches is web usage mining, which mines web logs for user models and recommendations. Different from most web recommender systems that are mainly based on clustering and association rule mining, this paper proposes an intelligent web recommender systcm known a5 SWARS \(Sequential Web Access bascd Recommender System mining. In the proposed system, CS-mine, an cffcient sequential pattern mining aIgorithm is used to identify frequent sequential web access patterns. The acces patterns are thcn stored in a compact trce structure, called Pattera-trce, which is then used for matching and generating web links for recommendations. In this paper, the proposed SWARS systcm is described, and its pcrformance is evaluated based on precision, satisfaction and applicability I. INTRODUCTION With the explosive growth of information available on the World Wide Web, it has become much more difficult to access relevant information from the Web. One possible approach to solve this problem is web personalization [ I ] .  To support this, it is usually necessary to model the past access behavior ol users on thc Web. The acquired knowledge can then be used for predicting the access behavior of a current user to support personalized services such as web search and browsing This research focuses on developing an intelligent recommender system to provide personalized web service for accessing related web pages more efficiently and effectively The goal of the intelligent recommender system is to determine which web pages are more likely to be accessed next by the current user i n  the near future  Various traditional techniques such as collaborative filtering [2,3] and hybrid content-based collaborative filtering approaches [4,5] have been developed for supporting web recommendations. However, such approaches suffer from a major drawback in  which most users surf websites anonymously via a proxy, and their identities are hidden and difficult to get. More recent techniques are based on web usage mining, which aims to discover interesting usage patterns derived from the data stored in web server logs or web browser logs. Promising web usage mining techniques 0-7803-8643-4/041$20.00 0 2004 lEEE such as association rule mining [6,7] and clustering [8,9] have been applied for web recommendations Different from the majority of the existing web recommendation techniques, we propose an intelligent web recommender system known as SWARS \(Sequential Web Access-based Recommender System pattern mining technique, Unlike clustering and association rule mining, sequential pattern mining algorithms [ 10,11,12 also consider the sequential characteristic of access patterns which is very suitable for predicting the next web pages. In addition. this paper aIso proposes a compact data model called Pattem-tree, which stores the sequential web access patterns, and an efficient approach for user pattcrn matching and recommendation rules generation. Different evaluation 


and recommendation rules generation. Different evaluation measures including precisian, satisfaction and applicability are proposed to measure the pcrformance of the recommender system The rest of this paper is organized as follows. Section I1 presents thc systcm architecture of SWARS. Section III disc uses  the performance evaluation and experimental results. Finally, Section IV concludes the paper 11. SYSTEM ARCHITECTURE An overview of the architecture of the proposed SWARS system is given in Fig. 1. First, all users  web access activities of a website arc recorded by the WWW server of the website and stored into the Web Server Logs. Each user access record contains the client IP address, request time, requesfed URL user ID, HTTP status code, etc. Users are treated as anonymous since the IP addresses are not mapped to any uscr identifiable profile database. After obtaining the Web Server Logs, the Sequenriul Partern Mining component is applied to mine the user access sequences from the Web Server Logs Then, the Pattern-tree Construction component constructs the recommendation model or Puttem-tree from the mined sequential web access patterns: Both the sequential pattern mining and Pattern-tree construction processes are carried out off-line. The Pattern-tree can be updated or regenerated regularly to incorporate new access data When a user visits the website, the user  s HTTP requests in the current browsing session are recorded in order, and the current access sequence is constructed. Each user accessing the website can be identified using hisher IP address Matching the user  s current access sequence from the 393 recommendation model of thc Pattern-tree, the Recuminendation Rules Generation component will generate recommcndation rules. From the recommendation rules recommended or "related" links will bc dynamicaIly insened into the current requested page. An example browser display is shown in Fig. 2. The upper frame displays the original requested web page and the lower frame displays a list of recommended links MI4ine lining n 1 -  I 3 U I OniirsRemmnmdation 1 1  1 Fig. I System architecture A. Sequential Pattern Mining Every single page access of a website can be recorded automatically in  the web logs by the web server. In general each line of web logs \(one access record following key information: date-timestamp, client IP address user ID, requcsted URL, and HTTP status code. We define web logs to be a collection of sequences comprising web access events from each user during their corresponding session in timestamp ascending order. Preprocessing must be performed on the web logs prior to applying sequential pattern mining. The main data preprocessing techniques [133 used here include data cleaning, user identification, and session identification Let's define sequential pattern mining [ 111 as follows Given a sequence database where each sequence is a list of transactions ordered by transaction time with each transaction comprising a set of items, find all sequential patterns with a user-specified minimum support, which is defined as the number of data sequences containing the pattern Lct E be a set o f  uniquc access events, which represents web resources accesscd by users, i.e. web pages, URLs, topics or categories. A web access sequence S = ele2 ... en \(e, E E 1 I i I rl is an ordered collection \(sequence and IS1 = n is called the length of the web access sequence Note that it is not necessary that e, # ej for i # j in S, that is item-repetitions are allowed. Suppose we have a set of web access sequences with the set of events, E = \(a, 6, c, d, e,A. A sample web access sequence database is shown in Table I 


sample web access sequence database is shown in Table I which contains four unique web access sequences TABLE 1. A SAMPLE DATABASE OF WEB ACCESS SEQUENCES Session ID n b d o c e a t r b c n c b a b f a e 4 a f b a c f c A web access sequence S' = eI 'e2'  ... elt is called a sub sequence of web access sequence S = ele2.. .en. denoted as s c S, if and only if there exists some i,, 1 I i l  &lt; iz &lt; .. . &lt; i, 5 n such thatc,'=e,, for\(1 S j l l e1e2,..ek is called a prefix sequence of S, and SslflE et+le1+2.. e, is called a sirfix sequence of S for 1 5 k 2 n Given a database of web access scquences WASDB = {SI,  Sz ___, Sm} in which S, \(1 5 i 5 m tWASDBl = m is called the length of the database. The supporr of web access sequence S i n  WASDR is the total number of unique web access sequences in  W A S ~ R  that contains S, as defined in the following equation sup\(S Note that although access events can be repeated in a web access sequence, any web access sequence S can get a support of at most one from each web access sequence S,. A web access sequence S is called a sequential web access pattern, if sup\(S An access event e, E E is called a freguenr event, if sup\(e MinSup. Otherwise, it is called an infrequent event TABLE 11. SEQUENTIALWEB ACCESS PATTERNS WITH MINSUP =3 FROM THE SAMPLE DATABASE IN TABLE I a:4. bt4, c:3 ua:4. abr4. oc3.  bur4. bc:3 aac:3, aba;4, obcr3, bac:3 4 abact3 Let's consider the web access sequence database in Table I Suppose the support threshold MinSup = 3, then all the sequential web access patterns supported by at least three web access sequences are listed in Table 11. In this research, an efficient WAP-tree based algorithm, CS-mine [l 11, has been developed for mining sequential web access patterns. A detail 394 discussion on the CS-mine algorithm and its performance can be found in [ 1 11 B. Partern-tree Construction A Pattern-tree model is proposed for storing sequential web access patterns compactly, so that i t  can be used for matching with a uscr  s current access sequcnce and generating recommendation rules more efficiently in the Recornmendarion Rules Generation component. The Pattem tree is based on the Trie 1141 data structure. The Trie is a tree based data structure for storing strings in  ordcr to facilitate fast pattem matching. in  general, the set of sequential web access patterns can be treated as a set of strings over a finite aIphabet E \(the set o f  unique access events tree is labeled with a symbol \(access event corresponding support value. Sometimes, the edges of a Trie are labeled instead of the nodes, but nevertheless rerer to the same structure in  either case. Once the Pattem-tree is constructed, the original web access sequence database is no longer rcquired for subsequent processing To construct a Pattern-tree, we only need to have one scan of all thc sequential web access patterns. Fig. 3 gives the Pattern-tree Construction algorithm, which is based on Ihe set of sequential web access pattcms mined by the Sequentid Portern Mining componcnt using CS-mine  Algorithm: Pattern-tree Construction Input SWAP - set of Sequential Web Access Patterns 7 -  Pattern-tree of SWAP output 


output Method: I I :  Create an empty root node R for Pattem-tree T 2: For each sequence S E SWAP, denoted as S = elez ... e,,, do a: Set cirrrenr-node point to R b: For i = 1 to n do, if current-nude has a child node labeled ei, use the maximum support between S and this child node as the support of ei and-set current-node point to e else mate a new child node with the support of S denoted as \(ei:support of S new child nodc 3: Return Pattern-tree T Fig, 3 The Psttcm-tree construction algorithm Example: The Pattem-tree of the sequential web access pattems given in  Table 11 is shown in Fig. 4. It is constructed as foIlows. First, create one virtual root node R. Then, insert the sequences n:4, b:4 and c:3 into the tree. It creates three new nodes \(n:4 b:4 c:3 labeled as \(event : supporr as the child nodes of R. Next, insert the sequences aa:4, ab:4 ac:3, ba:4 and bc:3 into the tree. Then, five branches  a:4 a:4    4 b:4    a:4 c:3    b:4 a:4  and  b:4 c:3  are derived, in which arrows are used to point from parent nodes to children. When inserting ac:3, there has been a child node of R labeled \(a:4 the maximum value 4 is used as the support. The remaining insertion process can lje derived accordingly. From the Pattem-tree, all the sequential web access patterns can be visited by foHowing the path starting from the root node of the tree Wg. 4 The Pattem-tree derived from the sequentid web access patiems i n Table II Complexity analysis: Inserting a sequential web access pattem S into the Pattem-tree T requires two steps. The first step is to search the matching prefix sequence Sprefix of S in T and the second step is to create a new path for the remaining non-matching suffix sequence SSlflx of S in T. Were we assume equal costs for matching an existing node and creating a new node. Thus, the totaI cost of inserting a sequcntial web acccss pattern S with length m is o\(lS,,,l ls~~~~,r ISI   gt The complexity of constructing the entire Pattern-tree from scratch is equivalent to the cumulative cost of inserting a11 sequential web access patterns Si, S2, ..., S, with a total length n, which is O\(IS,I ISzr IS,I n Actually, the true cost of matching or creating a trie node depends on how the trie is implemented. The Yattem-tree is implemented as a non-compact trie. If the storage is an important consideration, we can use a compact trie, which is also known as a patricia-trie, to implement the Pattem-tree model. As such, the complexity of constructing a patricia-trie based Pattern-tree will be a little different from the analysis above lo  practice, web logs are not static since new updates are constantly being added. However, for web recommendation we can assume it to be relatively static for a certain period of time. Therefore, the Pattem-tree needs to be updated or regenerated offline periodically, such as one week or 10 days The generated Pattern-tree can then be stored in a database or XML file C. Recommendarion Rules Generation The Recommendadion Rules Generation component searches for the best-matching access path in the Pattem-tree according to the user  s current access sequence. In general, the longer the user  s current access sequence is, the lower the possibility is of finding the matching path from the Pattem tree. To increase the applicability of recommendation rules generation, the suffix sequences of the current access sequence will be considered when the matching path of the whole access sequence cannot be found. As such, we will search the matching path based on the same access sequence by removing the first item repeatedly till a matching path is 395 


395 found or when no more item can be removed from the access sequence, In addition, the length of the longest path in the Pattern-tree is the depth of the Pattern-tree. The matching path will not exist when the length of the current access sequence is longer than the depth of the Pattern-tree. Therefore, some initial items can be removed to make the current access sequence shorter than the depth of the Pattem-tree before the sequence matching process begins Generally, the recommendation rules generated from shorter matching paths usually have lower accuracy. In order to improve the precision of recommendation rules generation only web access sequence whose length is not less than a given threshold can be processed. In other words, the sequcnce matching process will be stopped i f  the length of the remaining access sequence is less than the threshold Suppose the current access sequence of a user is S c ~ ~ a ~ . . . a , ,  the algorithm for generating recommendation rules for S, Recommendation Rules Generation, is given i n  Fig. 5 Algorithm: Recommendation Rules Generation Input T - Pattern-trce based on  a support threshold MirrSup S = ula2 ...arr - current access sequence of a user MinLength - minimum length of acccss sequence MnrLength - maximum length of access sequence. which should be less than the depth of the Pattern-tree Output RR - recommendation rule of a set of ordered access events for S Method I: Initialize RR = 0 2: If IS1 &gt; MarLRngth then remove the first ISI-Mun;Lengih+I items 3: If IS1 &lt; MinLengrh then return RR, else set current-node point 4: For each item a, from the head of S to the end do from S to the root node R of 1 a: I f  current-node has a child node labeled a,, then set ciirrenf-node point to this child node b: Else remove the first item from S, and repeat from step 3 5:  If current-node has child nodes, then insert these child nodes 6: Return RR into RR ordered by their supports Fig. 5 Algorithm for Kecommendation Rules Generation based on the Pattem tree Example: Let's consider the Pattern-tree in Fig. 4. Suppose the current access sequencc of a user is S = cab \(infrequent events have been removed access sequence are MinLength = 2 and MaxLength = 4 \(the depth of Pattern-tree in Fig. 4 is 5 for S are generated as follows. The sequence matching process starts from the first sequence item c and the child nodes of the root of the Pattem-tree. We found a node \( ~ 3 directly by the root, then the second sequence item a is scanned. But the node \( ~ 3 first item of S is then removed, and then S = ab. Because IS1 2 1 MinLength, the sequence matching process is repeated Now, the matching path \(a:4 b:4 Pattem-tree. The node \(b:4 a4 and \( ~ 3 access sequence S = cab are gencrated as {a, c ordered by their support, Based on the recommendation rulcs the corresponding web pages can be determined and recommended. In our approach, the top 5 items in thc recommendation rule set are used for recommendation Complexity analysis: The cost of looking up the current access sequence S of length m in a Pattern-trec T with MinLrngrh = Lmin and MaxLengrh = L,, i s  O\(min\(m, L The maximum possible number of lookups is L,, - L,,,,,. This gives the total cost of matching S as O\(\(L,,,, - Lmin m L thus where L,,, should be less than the depth of the 


Pattem-tree 111. PERFORMANCE EVALUATION A. Evaluation Measrrres Let S = ala z...aLak+,...n, be a web access sequence. For the prefix sequence Sprefir = 0 1 ~ 1 2  ... ok \(k 2 MinLength generate a recommendation rule RR = { e , ,  e2, ..., e,] using the Pattern-tree, where all events are ordered by their support If clL+l E RR, we label the recommendation rule as correct, and otherwise incorrect I f  there exists a, E RR \(k+l I i i k+l+m, m &gt; O deem the recommendation rule as m-srep snrisfucroly Othcrwise, we label it as m-step unsatisfactory Let R = \( R R I ,  RR2, ..., RR,} be a set of recommendation rules, where RR, \(1 5 i 5 n is the total numhcr of recommendation rules in R. We define the following measures Definition 1: Let R, be the subset of R that consists of all correct recommcndation rules. The overall web recommendation precision is defined as This precision measures how probable a user will access one of the recommended pages Definition 2: Let R,\(m all m-step satisfactory recommendation rules. The m-sfep satisfaction for web recommendation is defined as The m-step satisfaction is a very important evaluation measure for web recommendation. Actually, the next web page accessed by a user may not be the target page that the user wants. In many cases, a user has to access some intermediate pages before reaching the target page. Therefore it is not appropriate if we only use the precision measure to evaluate a web recommender system. The m-step satisfaction gives the precision that the recommended pages will be accessed in the near future \(within m steps 396 satisfaction and precision measures are equivalent for m = i In order to realistically evaluate our web recommender system m has been set with an appropriate value m = 5 to indicate thal the recommended page should be accessed in  the near future Definition 3: Let R, be the subset of R that consists of all nonempty recommendation rules. The applicability of web recommendation is defined as As the Pattern-tree only stores web access sub-sequences accessed frequently by users \(with a support of at least MinSirp unable to find recommended pages if  the current access sequence does not include a frequent suffix sequence, i n which case the gencrated recommendation rule is empty Therefore, the applicability measure gives a rough idea of how often recommendations will be gencrated. Some parameters such as MinSup in the proposed approach can influence the applicability of web recommendation, Generally, the smaller the MinSup is, the more applicable thc web recommendation is But, this comes at the expense of increased sequential pattern mining and Pattern-tree construction cost B. Experimental Results Let WAS\(MinLengrh S , ,S , ,  ..., S,,] be [he set of weh access sequences, where each sequence has no ICSS than MinLengrh items, i.e., min\(lSJ 1  5 i I n MinLength &gt; 0 construct thc Pattern-tree based on WAS\(MinLength WAS'\(M~~~Le~gth MuxSreps &gt 0, which is the same as m in the definition of m-step satisfaction from the set of sequences in  WAS\(MinLPngth the training sequences The three main components of the proposed SWARS system Sequential Pattern Mining, Partern-tree Construction and Recommendation Rules Generotion, were implemented in C++. All experiments were performed on a 1.6 GHz Intel Pentium 4 PC machine with 384 MB memory, running Microsoft Windows 2000 Professional. We used two datasets from Microsoft Anonymous Web Data \(http:/kdd.ics.uci.edu 


from Microsoft Anonymous Web Data \(http:/kdd.ics.uci.edu databases/msweb/msweb.html proposed web recommender system. These two datasets consist of a collection of sessions with each session containing a sequence of web page references. The Microsoft Anonymous Web Data records the pages within www.microsoft.com that each user visited in  a one-week time frame during February 1998. The training sequence dataset has a total of 32.71 1 sessions, with each scssion containing from 1 up to 35 page references from a total of 294 pages Note that we only use the 22,7 17 valid web access sequences which have more than one item, i.e. M i n k n g t h  = 2. The test sequence dataset has a total of 5,000 sessions and includes 1,405 valid web access sequences \(MinLmgth = 2 and MaxSteps = 5 I 35 i 30 g 25 g 20 F 15 B l o v E 5 0 0 I O  20 30 40 50 60 70 80 90 100 110 Support Threshold a 100 80 70 60% +Precision 50 40 30 20 1 0 90 Sat isfaction 0% 1.. ' " j  ' ^*' ' ' ' ' ' I 1 0 10 20 30 40 50 60 70 80 90 ID0 I10 Support Threshold I tN Fig. 6 Scalability vs. Suppori thresholds In the first experiment, we measured the scalability of the Sequential Pattern Mining and Pattern-tree Construction processes with respect to different support thresholds. We used CS-mine [ 1 I ]  as the sequential pattern mining algorithm This experiment used the 22,717 web access sequences with different support thresholds \(from 5 to 100 results are given in  Fig. 6\(a this process increases sharply as the support threshold is reduced to less than 10. In the second experiment, the scalability of  the precision, satisfaction, and applicability measures of recommendation rules generation had been measured with respect to different support thresholds. This experiment used MinLengrh = 2 and MaxSteps = 5 with different support thresholds \(from 5 to 100 results given in Fig. 6\(b decreased, the precision and satisfaction remain relatively stable, whilst the applicability increascs sharply. Prom both experiments, we can conclude that better recommendations can be obtained with smaller support thresholds, at the expense of increased computational complexity for sequential web access pattern mining and maintaining a larger Pattem tree. Balancing the trade-offs between complexity and applicability, we decided to use a support threshold value of 10 for subsequent experiments In the third experiment, we measured the scalability of the precision and satisfaction of recommendation rules generation with respect to different numbers of recommended pages. This 


with respect to different numbers of recommended pages. This  397 experimenr used M i n k n g t h  = 2 and MuxSteps = 5 with different numbers of recommended pages \(from 1 to 10 experimental results are given in Fig. 7. When the number of recommended pages increases, the precision and srrfisfncfion also increase. But, the increase is not significant after the number of recommended pages is more than 5.  Although the precision and sarisfaction can be further improved with more e.g. 10 pagcs will affect the normal browsing activity. As such, we have used 5 as the default number of recommended pages for our system I I 100 90 80 70 60 50 40 30 20 IO 0         0 I 2  3 4 5 6 7 8 9 I O  II I The number of recommmended pages Hg. 7 Scalability vs. Number of recommended pages The last experiment measured the scalability of the sarisfaction of recommendation rules gcneration with respect to different numbers of steps. This experiment used MinLRngrlx  2  and MaxSteps = 5 with different numbers of steps \(from 1 to 10 8. When the number of steps becomes larger, the salisfaclion of recommendation web pages increases. However, the increase becomes insignificant as the number of steps exceeds 5. Therefore, we used a 5-step satisfaction for evaluating the performance of the web recommender system. The experimental results demonstrate that the proposed web recommendation approach is very effective for recommending related pages in the near future \(within 5 steps 102 90 80 70  50 40 30 2046 IO 0 0 1 2 3 4 5 6 7 8 9 1 0 1 1 m-step Rg. 8 Scatability vs m-step satisfaction To summarize, using a support threshold of 10 and recommending only the top 5 pages, the 5-srep satisjich  on achieves a value of 87% and 68% for the corresponding applicability. In plain English, this means that on average, 7 out of I O  visited pages will carry recommendations, and almost 9 out of 10 recommended pages are likely to be visited within the next 5 ciicks IV. CONCLUSION In this paper, we have proposed an intelligent web recommender system known as SWARS based on sequential web access patterns. In the proposed system, the sequential pattern mining algorithm CS-mine is used to mine frequent sequential web access patterns. The mined patterns are stored in the Pattern-tree, which is then uscd for matching and generating web links for online recommendations. The proposed system has achieved good performance with high 


proposed system has achieved good performance with high satisfaction and applicability REFERENCES M. Eirinaki and M.  Vazirgiannis  Web mining for web personalization   ACM Transaction!, on Internet Technology, Vol. 3, No. I ,  2003, pp. 1 27 1. Konstan, B. Miller, D. Mall i  J. Herlocker, L. Gordon, and 1. Riedl  GroupLens: applying collaborative filtering to usenet news   Communications of the ACM, 40\(3 T.W. Yan and H. Garcia-Molina  The SIFT information dissemination system  ACM Transactions on Database Systems, Vol. 24, No. 4, 19W T. loachims, D. Freitag, and T. Mitchel  Webwatcher: a tour guide for the World Wide Web  Proc. of the 5th International Joint Conference on AI. Japan. 1997, pp. 770-775 C. Shahabi, F. Banaei-Kashani, Y. Chen, and 0. McLeod  Yoda: an accurate and scalable web-based recommendation system  Roc. of the 6th International Conference on Cooperative Information Systems CoopIS 2001 B. Mobasher, H. Dai, T. Luo and M. Nakagawa  Effective personalization based on association rule discovery from web usage data  hoc. of the 3rd ACM Workshop on Web Information and Data Management \(WIDMOI W. Lin, S.  A.AIvarez, and C. Ruiz  ollaborative recommendation via adaptive association rule mining  Proc. of the Web Mining for E Commerce Workshop \(WebKDD2000 B. Mobwher  A web personalization engine baed on user transaction clustering  Prcc. of the 9th Workshop on Information Technologies and Systems \(WlTS  99 D.S. Phatak. and R. Mulvaney  Clustering for personalized mobile web usage  Roc. ofthe IEEE FUZZ  OZ, Hawaii. May 2002. pp. 705-710 pp.529-565 IO] R Agnwal, and R. Srikant  Mining Sequential Patterns  Prw. of the 1 lth International Conference on Data Engineering, Taiwan, 1995 I  11 B.Y. Zhou, S.C. Hui, and A.C.M. Fong  CS-mine: an efficient WAP tree mining for web acces  patlems  the 6th Asia Pacific Web Conference \(APWEBW 532 I21 R. Srikant, and R. Agrawal  Mining sequential patterns: generalizations and performance improvements  hac. of the 5th lntematianal Conference on Extending Darabase Technology \(EDBT France, 1996, pp. 3-17 I131 R. Cooky, B.  Mobasher, and J. Srivasrava  Data preparation for mining World Wide Web browsing patterns  Journal of Knowledge and Information Systems, Vol. 1, No. 1. 1999 1141 D. Knuth  The art of computer programming  Vol. 2, 2nd edition Addison-Wesley, October 1998 398 pre></body></html 


in four unknowns: n, ?np, \(?2?j |HT 2?j |HL The Neyman-Pearson decision rule is said to maximize the probability of detecting the track-lost regime, PDET for a given n, subject to the constraint that PFA is less than or equal to some user-de?ned probability. [6]. However, it is convenient in this context to instead ?x both PDET and PFA at some desired values, and use \(41 43 the corresponding minimum \(integer n that must be used in order to meet these goals. Typically there is a range of values of ?np that will achieve them Appropriate values of n and ?np can be determined for each pe element ?j using \(41 43 determinations for each element can then be made using 38 39 for each pe element; if a single overall track-loss metric is desired, Wishart distributed versions of \(33 35 also be used in the development of the Neyman-Pearson decision rule. However, because of the approximate nature of the distribution in \(35 additional covariance information is useful in the matrix likelihood test [5]. Further, a Wishart implementation has the disadvantage of being more computationally intensive than the implementation outlined above D. Application to the PDAF In order to implement the Neyman-Pearson rule, \(15 be rewritten x  k|k  k|k ? 1 k k 44 where, for the PDAF e?\(k  mk i=1 i zi\(k 1? ?0  k|k ? 1   45 This  effective  measurement innovation is then the single lter prediction error for purposes of calculating the sample variances s2?j . The j-th diagonal of the innovations covariance for the tracking regime, ST?sirf , and track-lost regime SL?sirf , can then be used for \(?2?j |HT 2?j |HL respectively Some method of handling the case of no gated measurements must be implemented. As suggested earlier, it is at least mathematically consistent in this case to de?ne the measurement innovations as zero. However, when there is a signi?cant probability of zero measurements gating the assumption that the prediction errors have a Gaussian distribution will be a poor one; in practice, this probability is likely to be signi?cant both when PD &lt; 1 and when in the track-lost regime. So the goals for PDET and PFA will not generally be met unless the innovations from timesteps when no measurements gate are excluded, and it is necessary to use the previous nC timesteps to ?nd n nonzero innovations with which to compute s2?j . The average number of timesteps n  T used when the ?lter is operating in the tracking regime is approximately n/\(PDPG average number of timesteps n  L used to when the ?lter is in the track-lost regime is problem speci?c E. Extensions to Other Data Association Methods This strategy is suitable for other data association methods. For the NN ?lter, the KF measurement innovations are the prediction errors. For MAP and maximum likelihood ML determined by similarly deriving a relationship between the estimated state, predicted state, and Kalman gain IV. EXAMPLE: PDAF TRACK REGIME TEST In this section, an example system using the PDAF is constructed. The SIRF approximation steady-state innovations covariances for the tracking and track-lost regimes are calculated and compared to simulation results. An example 


calculated and compared to simulation results. An example Neyman-Pearson decision rule is determined. Theoretical and simulation results for the probabilities of detection of the track-lost regime, PDET, and of false alarm while in the tracking regime, PFA, are given. An estimate of the number of timesteps required to detect track-loss is also provided 4320 A. Dynamics The kinematic model system \(with timestep x\(k + 1  1 0 1  x\(k  2/2   w\(k 46 y\(k  1 0  x\(k 47 is the standard zero-order hold discrete approximation to a continuous double-integrator system. For ? = 0.1 x\(k + 1  1 0.1 0 1  x\(k  0.005 0.1  w\(k 48 B. Kalman Filter System For Q = Q = 1000, R = R = 0.1 P  kf  0.3000 1.9998 1.9998 19.9965  Skf = 0.4000 are the steady-state covariances C. Clutter and Gating Though the example system is dependent on Q,R and ?, it can be described in the tracking regime using just three independent parameters [12]: the probability of detecting the truth measurement, PD, the normalized target acceleration, \(NTA sity, \(NCD the target is maneuvering, and NCD is a measure of how dif?cult it is to localize the target from the measurements For the example system, NTA = 1. Choosing PD = 1 0.02 results in NCD = 0.002, and an average track-lifetime of approximately 500 timesteps using the PDAF [8], [12 this is a tracking problem of  moderate  dif?culty for the example dynamics Using a four standard deviation gate \(? = 16 PG = 0.99994. For the example system, nz = 1, cnz = 2 and Vk = 8 |S\(k D. Experimental Tracking and Track-lost Regimes The following experimental setup allows for  controlled  track-loss and is used to verify operation of the trackloss detector. Until timestep 1000, the ?lter is tracking in the sense that PD = 1 \(the truth measurement is always 


available to the gating test 2000, PD = 0 \(the truth measurement is never available to the gating test sense that the truth measurement is never gated. PFA can then be calculated using measurement innovations from the rst 1000 timesteps, and PDET from using measurement innovations from the second 1000 timesteps, with roughly 1000 values of s2?j being tested by the decision rule in each regime. Note that PDET is thus calculated using both data points from the transient of  controlled  track-loss as well as from the  steady-state  operation of the ?lter in the tracklost regime E. PDAF SIRF Tracking Approximation For the example system with tracking regime assumptions: PG ? PD = 1, q1 ? PD = 1 [3], and \(25 T\(?Vk cnz 2  mk=1 exp\(??Vk Vk mk ? 1   nz nz/2  I2\(mk 49 Figure 1 shows the resulting function for ?T\(?Vk 0 1 2 3 4 5 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 Vk   T  L Fig. 1. ?T and ?L as functions of ?Vk for example system ating \(4 6 7 11 24 using \(49 T\(?Vk  T = 0.9602, ?V  k 0.1047, and P  T?sirf  0.3286 2.1122 2.1122 20.5492  ST?sirf = 0.4286 Simulating and then averaging P\(k|k? 1 k example PDAF tracking regime over 1000 timesteps gives P  T?sim  0.3210 2.0831 2.0831 20.3698  ST?sim = 0.4210 Thus ST?sirf has only 1.7% error when compared to the more time-consuming simulation results F. PDAF SIRF Track-lost Approximation Figure 1 shows the function for ?L\(?Vk system with track-lost regime assumptions. Iterating \(4 6 


7 11 30 31  L = 0.3264 V  k = 0.4594, and P  L?sirf  8.1431 15.8765 15.8765 56.2960  SL?sirf = 8.2431 Simulating and then averaging P\(k|k? 1 k example PDAF track-lost regime over 1000 timesteps gives P  L?sim  9.1253 17.3318 17.3318 54.3980  SL?sim = 9.2253 SL?sirf has 10.8% error when compared to the more time-consuming simulation results. In general, it has been observed that the approximation for the tracking regime is more accurate than for the track-lost regime when compared to the simulation results 4321 G. Neyman-Pearson Decision Rule PDET ? 0.99 and PFA ? 0.01 are reasonable targets for the decision rule. The number of effective innovations n necessary to meet these goals can be calculated by incrementing n until, for some value\(s and PFA ? 0.01 \(see Figure 2 the slope of the curve is ?np 0 0.005 0.01 0.015 0.02 0.975 0.98 0.985 0.99 0.995 1 target PD &amp; PFA PFA P D n=6 n=7 n=8 Fig. 2. Neyman-Pearson Threshold Curves As can be seen from the ?gure, the goals require n ? 7 timesteps. A good value for ?np \(one that exceeds the goals for both PDET and PFA 41 43 the means of 25 trials of the example experimental setup and the decision rule \(38 39 ST?sirf = 0.4286, and SL?sirf = 8.2431, the experimental results were PDET = 0.9997 and PFA = 0.0132. Though the actual process of track-loss is dif?cult to quantify, the experimental results n  T = 7.0 and n  L = 24.9 do provide some insight into the number of timesteps necessary for track-loss detection, as the average number of timesteps necessary, n  Loss, should be bounded by n  T ? n  Loss ? n  L V. SIMULATION RESULTS Table 1 provides a comparison of experimental values for PDET, PFA, n  T, and n  F across large ranges of NTA and NCD for PDAF simulation data when PD = 1. For each NTA-NCD combination, n and ?np have been chosen such that, theoretically, PDET ? 0.99 and PFA ? 0.01, with n as small as possible. The mean track-lifetime of all NTA-NCD combinations is approximately 100 timesteps where NCD is labeled  High  1000 timesteps where NCD is labeled  Medium  and 10,000 timesteps where NCD is labeled  Low  12]. The experimental values of PDET, and PFA were calculated using the means of 25 trials of the example experimental setup; trials were selected from realizations where track-loss did not occur until forced at timestep 1001 


where track-loss did not occur until forced at timestep 1001 Having the tracking and track-lost variances of the innovations spaced well apart is the condition for small n As Table 1 shows, this condition is met less often for low values of NTA In the track-lost regime, the assumption that the validated prediction errors are Gaussian distributed is usually quite conservative since the sample variances are generally larger than for a Gaussian distribution. This contributes to generally exceeding the PDET goals. Conversely, the sample variances in the tracking regime, while more Gaussian are still somewhat larger than would be expected from a Gaussian distribution, meaning that the PFA goals may not always be met. However, because n is restricted to integer values, the theoretical values of both PDET and PFA often exceed the desired values signi?cantly for low values of n Unlike the tracking regime, the track-lost regime cannot be described solely in terms of PD , NTA, and NCD. SL is non-linearly dependent on ?, so n, PDET, and PFA vary with ? as well. This can be seen by comparing the Medium NTA results in Table 1 with those in Table 2, where identical values of PD , NTA, and NCD constructed from different values of Q, R, and ? yield different results for n In general, lowering PD increases the tracking regime innovations variance ST?sirf , reducing the separation from SL?sirf and thus having the tendency to raise the required n to meet the goals for PDET and PFA. This can be seen by comparing the Low NTA data in Table 1 \(PD = 1 Table 3 \(PD = 0.9 Over the parameter space explored, the test \(decision rule VI. CONCLUSION AND ONGOING WORK A strategy has been laid out for creating a two-class decision rule to determine the regime of operation for the PDAF in the absence of truth data. Scalar information reduction factors can be used in an iterative scheme to predict the steady-state innovations covariance for both the tracking and track-lost regimes, which results in lower computational burden when compared to Monte Carlo simulation. Then a distribution can be assumed for the sample variances of the prediction errors. Together, these pieces of information constitute a model around which a Neyman-Pearson decision rule can be constructed, where the con?dences in both the probability of track-loss detection and of false alarms are explicitly chosen. Good performance of the test as a trackloss detector was demonstrated for an example system over a large range of tracking dif?culties Ongoing work includes modeling the effective innovations \(45 theoretical distributions for the prediction errors used in the decision rule \(38 desirable to more accurately model the sample distribution of the innovations variance, and it has been shown that the prediction errors of many data association algorithms can be well approximated by a Gaussian mixture [13 REFERENCES 1] Y. Bar-Shalom and T. Fortmann, Tracking and Data Association, Academic Press Inc., 1988 2] T. Fortmann, Y. Bar-Shalom, and Y. Scheffe  Sonar Tracking of Multiple Targets Using Joint Probabilistic Data Association  IEEE J. of Oceanic Engineering, July 1983 4322 TABLE I SIMULATION RESULTS FOR: TRACKING REGIME PD=1, Q=1000, ?=0.1 PDET PFA PDET PFA NTA NCD ST?sirf ST?sim SL?sirf SL?sim n n  T n  L ?np Theory Theory Exper. Exper 0.05 Low 1.152e3 1.153e3 1.073e4 5.963e3 11 11.0 336 0.591 0.9900 0.0081 1.0000 0.0099 5e-5 1e-4 0.1 Low Medium 1.152e3 1.153e3 5.509e3 3.741e3 20 20.0 393 0.647 0.9900 0.0092 1.0000 0.0093 


Low Medium 1.152e3 1.153e3 5.509e3 3.741e3 20 20.0 393 0.647 0.9900 0.0092 1.0000 0.0093 R=1000 1e-4 0.2 High 1.153e3 1.154e3 3.180e3 2.698e3 45 45.0 597 0.214 0.9900 0.0071 1.0000 0.0162 2e-4 2e-4 Low 0.4017 0.4024 109.291 71.994 4 4.0 39.7 0.996 0.9960 0.0075 0.9995 0.0012 2e-3 1.0 1e-3 Medium Medium 0.4128 0.4129 17.488 19.216 6 6.0 29.6 0.992 0.9938 0.0018 0.9987 0.0034 R=0.1 0.01 4e-3 High 0.4612 0.4722 4.1029 5.410e3 12 12.0 28.0 0.992 0.9902 0.0045 1.0000 0.0132 0.04 1e-8 Low 0.0250 0.0272 253.917 155.263 3 3.0 38.0 1.002 0.9991 0.0001 0.9994 0.0008 1e-3 1e4 1e-7 High Medium 0.0338 0.0290 17.303 12.837 3 3.0 14.5 0.332 0.9900 0.0058 0.9951 0.0045 R=1e-5 1e-2 1e-6 High 0.0918 0.0557 1.6071 1.225e5 8 8.0 9.9 0.992 0.9906 0.0034 0.9994 0.0142 1e-3 TABLE II SIMULATION RESULTS FOR: TRACKING REGIME PD=1, Q=100, ?=0.1 PDET PFA PDET PFA NTA NCD ST?sirf ST?sim SL?sirf SL?sim n n  T n  L ?np Theory Theory Exper. Exper 2e-4 Low 0.0408 0.0407 2.9255 2.0060 5 5.0 30.3 0.996 0.9933 0.0016 0.9998 0.0020 0.02 1.0 1e-3 Medium Medium 0.0446 0.0446 0.5143 333.138 10 10.0 27.8 0.996 0.9900 0.0042 0.9995 0.0093 R=0.01 0.1 4e-3 High 0.0763 0.1062 0.1580 3.402e3 84 84.0 90.9 0.793 0.9900 0.0099 1.0000 0.0334 0.4 TABLE III SIMULATION RESULTS FOR: TRACKING REGIME PD=0.9, Q=1000, ?=0.1 PDET PFA PDET PFA NTA NCD ST?sirf ST?sim SL?sirf SL?sim n n  T n  L ?np Theory Theory Exper. Exper 0.05 Low 1.166e3 1.167e3 1.073e4 3.357e4 11 12.2 257 0.542 0.9900 0.0089 1.000 0.0073 5e-5 1e-4 0.1 Low Medium 1.167e3 1.167e3 5.509e3 1.481e4 21 23.2 309 0.858 0.9900 0.0067 1.0000 0.0052 R=1000 1e-4 0.2 High 1.168e3 1.170e3 3.180e3 6.979e3 46 50.6 475 0.798 0.9900 0.0089 1.000 0.0022 2e-4 3] T. Fortmann, Y. Bar-Shalom, Y. Scheffe, and S. B. Gelfand  Detection Thresholds for Tracking in Clutter- A Connection Between Estimation and Signal Processing  IEEE Trans Auto. Ctrl., Mar 1985 4] S. B. Gelfand, T. Fortmann, and Y. Bar-Shalom  Adaptive Threshold Detection Optimization for Tracking in Clutter  IEEE Trans. Aero. &amp; Elec. Sys., April 1996 5] Ch. M. Gadzhiev  Testing the Covariance Matrix of a Renovating Sequence Under Operating Control of the Kalman Filter  IEEE Auto. &amp; Remote Ctrl., July 1996 6] L. C. Ludeman, Random Processes: Filtering, Estimation and Detection, Wiley, 2003 7] L. Y. Pao and W. Khawsuk  Determining Track Loss Without Truth Information for Distributed Target Tracking Applications  Proc. Amer. Ctrl. Conf., June 2000 8] L. Y. Pao and R. M. Powers  A Comparison of Several Different Approaches for Target Tracking in Clutter  Proc Amer. Ctrl. Conf., June 2003 9] X. R. Li and Y. Bar-Shalom  Stability Evaluation and Track Life of the PDAF Tracking in Clutter  IEEE Trans. Auto Ctrl., May 1991 10] X. R. Li and Y. Bar-Shalom  Performance Prediction of 


10] X. R. Li and Y. Bar-Shalom  Performance Prediction of Tracking in Clutter with Nearest Neighbor Filters  SPIE Signal and Data Processing of Small Targets, July 1994 11] X. R. Li and Y. Bar-Shalom  Detection Threshold Selection for Tracking Performance Optimization  IEEE Trans. on Aero. &amp; Elect. Sys., July 1994 12] D. Salmond  Mixture Reduction Algorithms for Target Tracking in Clutter  SPIE Signal and Data Processing of Small Targets, Oct. 1990 13] L. Trailovic and L. Y. Pao  Position Error Modeling Using Gaussian Mixture Distributions with Application to Comparison of Tracking Algorithms  Proc. Amer. Ctrl. Conf., June 2003 4323 pre></body></html 


dense data sets for evaluating pattern mining algorithms These two data sets are obtained from IBM Almaden at http://www.almaden.ibm.com/cs/quest/demos.html. Recently, theMAFIA algorithm [6] was proposed to ef?ciently discover maximal frequent patterns. As shown in their paper, MAFIA can be several orders better than some alternatives, such as DepthProject, for mining maximal frequent patterns. Hence, we chose MAFIA as the base line for our performance evaluation. Finally, please note that only the size-2 patterns are generated in the ?rst BFS phase Experimental Platform We implemented the MHP algorithms using C++ and all experiments were performed Proceedings of the 16th IEEE International Conference on Tools with Artificial Intelligence \(ICTAI 2004 1082-3409/04 $20.00  2004 IEEE on a Pentium III    MHz PC machine with    megabytes main memory, running Linux Redhat 6.1 operating system 5.2. A Performance Comparison 100 1000 10000 100000 1e+06 1e+07 1e+08 1e+09 1e+10 1e+11 0.02 0.025 0.03 0.035 0.04 0.045 0.05 0.055 0.06 N um be r o f C he ck ed P at te rn s Support threshold Mafia Min_Conf=0 Min_Conf=0.1 Min_Conf=0.3 Min_Conf=0.5 Min_Conf=0.7 Min_Conf=0.9 


Figure 4. The Number of Checked Patterns on the Pumsb* Data Set 10 100 1000 10000 100000 0.02 0.025 0.03 0.035 0.04 0.045 0.05 0.055 0.06 R un T im e s ec  Support Threshold Mafia Min_Conf=0 Min_Conf=0.1 Min_Conf=0.3 Min_Conf=0.5 Min_Conf=0.7 Min_Conf=0.9 Figure 5. The RunTime Comparison on the Pumsb* Data Set Figure 4 shows the number of patterns that MHP and MAFIA have to check during the pattern mining process on the pumsb* data set. As can be seen, for MHP, the number of checked patterns is increased with the decrease of the h-con?dence threshold. However, the number of checked patterns of MHP can be signi?cantly smaller than that of MAFIA even if a low h-con?dence threshold is speci?ed To check a pattern, we need to count the support of the patterns. Counting the support of a pattern is the most timeconsuming task during the pattern mining process, since we need to retrieve all the transactions which include one of its sub-pattern, or for Ma?a, retrieve all the bit of the bitmap of this pattern [6]. Therefore, an algorithm is more ef?cient if smaller number of patterns need to be checked 100 1000 10000 100000 1e+06 1e+07 1e+08 1e+09 0.1 0.2 0.3 0.4 0.5 0.6 0.7 N 


um be r o f C he ck ed P at te rn s Support Threshold Mafia Min_Conf=0.5 Min_Conf=0.7 Min_Conf=0.9 Figure 6. The Number of Checked Patterns on the Pumsb Data Set 10 100 1000 10000 0.1 0.2 0.3 0.4 0.5 0.6 0.7 R un T im e s ec  Support Threshold Mafia Min_Conf=0.5 Min_Conf=0.7 Min_Conf=0.9 Figure 7. The RunTime Comparison on the Pumsb Data Set The runtime comparison of MHP and MAFIA on the Pumsb* data set is shown in Figure 5. In the ?gure, we can observe that the runtime of MHP can be signi?cantly reduced with the increase of h-con?dence thresholds. Also the runtime of MHP can be several orders of magnitude less than that of MAFIA even if the h-con?dence threshold is as low as 0.3. The reason is that the number of checked patterns of MHP is sign?cantly smaller than that of MAFIA Similar results are also obtained from the pumsb data set as shown in Figure 6 and Figure 7. For the pumsb data set the number of checked patterns of MHP is much smaller 


than that of MAFIA and the runtime of MHP can be significantly less than that of MAFIA 5.3. The Effect of the MHP Algorithm on Finding Maximal Hyperclique Patterns Figure 8 and Figure 9 show the number of maximal patterns identi?ed byMHP andMAFIA on Pumsb* and Pumsb data sets respectively. As can be seen, the number of maximal hyperclique patterns identi?ed by MHP can be orders of magnitude smaller than the number of maximal frequent patterns identi?ed by MAFIA. In other words, the number Proceedings of the 16th IEEE International Conference on Tools with Artificial Intelligence \(ICTAI 2004 1082-3409/04 $20.00  2004 IEEE 100 1000 10000 100000 1e+06 1e+07 1e+08 1e+09 0.02 0.025 0.03 0.035 0.04 0.045 0.05 0.055 0.06 N um be r o f C ou nt ed P at te rn s Support Threshold Mafia Min_Conf=0 Min_Conf=0.1 Min_Conf=0.3 Min_Conf=0.5 Min_Conf=0.7 Min_Conf=0.9 Figure 8. The Number of MFI/MHP Patterns in the Pumsb* Data Set 100 1000 10000 100000 1e+06 


1e+07 1e+08 0.1 0.2 0.3 0.4 0.5 0.6 0.7 N um be r o f C ou nt ed P at te rn s Support Threshold Mafia Min_Conf=0.5 Min_Conf=0.7 Min_Conf=0.9 Figure 9. The number of MFI/MHP Patterns in the Pumsb Data Set of maximal hyperclique patterns is much easier to manage than that of maximal frequent patterns. Indeed, in realworld applications, it is dif?cult to interpret several million maximal frequent patterns. However, it is possible to interpret the results of maximal hyperclique pattern mining In addition, due to the memory limitation, we cannot extract maximal frequent patterns with MAFIA on the Pumsb data set if the support threshold is less than 0.4, as shown in Figure 7. In contrast, MHP can identify maximal hyperclique patterns when the support threshold is 0.1, if we set the h-con?dence threshold to 0.5. In other words, MHP has the ability to identify patterns which can be dif?cult to identify for MAFIA. Hence, MHP can better explore the pattern space and ?nd interesting patterns at low levels of support 6. Conclusions and Future Work In this paper, we present a two-phase Maximal Hyperclique Pattern \(MHP best features of both the BFS strategy and the DFS strategy. More speci?cally, we adapted DFS pruning methods such as equivalence pruning, to an apriori-like approach In addition, we proved the correctness and completeness of the MHP algorithm. Finally, our experimental results show that the MHP algorithm can be several orders of magnitude faster than standard maximal frequent pattern mining algorithms and has the ability to identify patterns at extremely low levels of support in dense data sets There are several directions for future work. First, in 


this paper, we only generate the size-2 patterns in the BFS phase. It will be interesting to investigate the impact on the performance if the ?rst phase is stopped at a deeper level Also, the projection is a very ef?cient method for ?nding patterns, especially for parallel implementation of pattern mining algorithms [1]. We plan to adapt the projection ideas into our algorithm and design an ef?cient parallel algorithm for mining maximal hyperclique patterns References 1] R. Agarwal, C. Aggarwal, and V. Prasad. A Tree Projection Algorithm For Generation of Frequent Itemsets. pages 350 371, Feb 2001 2] R. Agrawal, T. Imielinski, and A. Swami. Mining Association Rules between Sets of Items in Large Databases. In Proc. of the ACM SIGMOD Conference on Management of Data, pages 207216,May 1993 3] R. Agrawal and R. Srikant. Fast Algorithms for Mining Association Rules. In Proc. of the 20th Intl Conference on Very LargeData Bases, 1994 4] R. Bayardo. Ef?ciently mining long patterns from databases In Proc. of the ACM SIGMOD Conference, 1998 5] R. Bayardo and R. Agrawal. Mining the Most Interesting Rules. In Proc. of the ACM SIGKDD Conference, 1999 6] D. Burdick, M. Calimlim, and J. Gehrke. Ma?a: AMaximal Frequent Itemset Algorithm for Transactional Databases. In Proc. of IEEE Conf. on Data Engineering, 2001 7] Y. Huang, H. Xiong, W. Wu, and Z. Zhang. A Hybrid Approach for Mining Maximal Hyperclique Patterns. In In Technical Report UTDCS-34-04, Department of computer science, University of Texas - Dallas, 2004 8] J.Han, J.Pei, and Y. Yin. Mining Frequent Patterns without Candidate Generation. In Proc. of the ACM SIGMOD International Conference on Management of Data, 2000 9] M.J.Zaki and C.Hsiao. ChARM: An ef?cient algorithm for closed itemset mining. In Proc. of 2nd SIAM International Conference on Data Mining, 2002 10] R.Rymon. Search through Systematic Set Enumeration. In Proc. Third Intl Conference on Principles of Knowledge Representation and Reasoning, 1992 11] H. Xiong, M. Steinbach, P.-N. Tan, and V. Kumar. HICAP: Hierarchial Clustering with Pattern Preservation. In Proc. of 2004 SIAM International Conference on Data Mining \(SDM 12] H. Xiong, P.-N. Tan, and V. Kumar. Mining Strong Af?nity Association Patterns in Data Set with Skewed Support. In Proc. of the Third IEEE International Conference on Data Mining \(ICDM Proceedings of the 16th IEEE International Conference on Tools with Artificial Intelligence \(ICTAI 2004 1082-3409/04 $20.00  2004 IEEE 





