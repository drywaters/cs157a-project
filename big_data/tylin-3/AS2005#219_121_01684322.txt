EPOSee A Tool For Visualizing Software Evolution Michael Burch michael burch@ku-eichstaett.de Stephan Diehl diehl@acm.org Peter WeiB3gerber peter.weissgerber ku-eichstaett de Catholic University Eichstatt-Ingolstadt Ostenstr 14 85072 Eichstatt,Germany Abstract Software archives are a rich source of information about the development process of a software system Using data mining techniques rules can be extracted from these archives Rules can either be association rules which means that software items have been changed together with a certain probability 
or sequence rules which means items have been changed one after the other The change frequency\(support as well as the change probability\(confidence of a given rule are both metrics usedfor visualizing the strength of a rule EPOSeel is a tool designed to interactively explore these kinds of rules To this end we extended standard visualization techniques for association and sequence rules to also show the hierarchical order of items Clusters and outliers in the resulting visualizations provide interesting insights into 
the relation between the temporal development of a system and its static structure 1 Introduction Software archives contain the many versions of a software system produced throughout its lifetime typically using configuration management tools like CVS\(Concurrent Versioning System Subversion or Bitkeeper Analyzing the source code of these versions as well as documentation and other meta-information can reveal regularities and anomalies in the development process EPOSee provides the following visulalizations to interactively explore mining rules extracted from software archives Visualization 
of Binary\(2-ary Rules Pixelmap overview context Support Graph force-directed polar layout 3D Bar Chart of selected association rules focus Rule Detail Window of selected rule focus Visualization of n-ary Association Rules Association Rule Matrix overview context Bar Charts for support and confidence Rule Detail Window of selected rule focus Item Legend Window Evolution 
Patterns Of Software Visualization Tool Visualization of Sequence Rules Parallel Coordinates View overview context Decision Tree overview context 3D Branch View\(of 
selected sequence rules focus Rule Detail Window of selected rule focus Histogram distribution of confidence and support 2 Working with EPOSee Typically the visual data-mining process works as follows first an overview of the rule set is provided here interesting visual patterns like clusters can be detected by the user Next she can inspect the rules of a visual pattern by selecting the rules involved and viewing them in a zoomed display for example in the 3D view Additionally filters allow her to constrain the set of 
rules that are shown at all Histograms give an overview of the support and confidence distribution of all rules in the given dataset Histograms also give a possibility to bound the dataset by support and confidence intervals Last but not least she can select single rules which are shown in detail then This conforms to Ben Shneiderman's visualization mantra Overview first zoom and filter details on demand In the following we will explain how EPOSee integrates the different views for binary association rules 
n-ary association rules and sequence rules and how the visualizations interact with each other Figure 1 shows our tool in the binary association-rule mode Modes for new rule type can easily be added and integrated in the visualization tool The screenshot presented in Figure 1 consists of three windows The left window shows the pixelmap which is a two dimensional representation of the given textual data A color coded pixel stands for the frequency that two software items have been checked into the CVS repository 
together The more red a pixel the higher is this frequency After computing the frequency values for all pairs of software items we get a two dimensional array with integer values which can be visualized as a pixelmap Software items can be directories files classes inner classes or methods For example someone could be interested in what classes have been checked into the repository very frequently and which classes have not In the pixelmap we use a special 127 


Figure 1 EPOSee in the binary association rule mode sorting of the axes which places items of the same hierarchy level close to each other We expect that items in the same hierarchy level should be changed more often than items which are not in the same hierachy level This phenomenon should become visible by red squares along the diagonale of the pixelmap As shown in the left window in Figure 1 this is actually the case for this software project In the case of our class example this means that two classes in the same directory are much more frequently changed together than two classes from two different directories We call items which are changed very frequently and do not correspond to the same hierarchy level an outlier If a software system has lots of outliers the developer should possibly think of restructuring the whole system This could reduce outliers but also could cause other ones to occur Pixelmaps can be very large and an overview of the whole dataset is therefore often not possible For this reason the user can scroll the pixelmap and select an interesting rectangular area This area can be zoomed in by showing it as a three dimensional bar chart diagram An example bar chart can be seen in the right window of Figure 1 Here two metrics can be visualized The color of each bar shows the confidence of the rule and the height represents its support The window in the middle of Figure 1 shows the supportgraph view Each node refers to an item of the data set The color coding corresponds to the hierarchy level an item is placed A coupling between two items is represented by an edge from one node to the other A force-directed layout of the support graph is responsible for the visual structure of this graph that can also be used to detect clusters and outliers in the data set Filtering allows to reduce the data set This is usually done by selecting an interval for the support and confidence values in the histogram view Thus filtering is typically used to only show strong dependencies There is also a textual filtering function which can be used if someone is only interested in items which have a certain text string in their descriptions or which belong to a certain hierarchy level All views have a detail on demand function i.e the user can select an item to get additional information about it So she can interactively explore the data set and look for details whenever she wants to The detailed information given in the pixelmap and 3D bar chart view consists of the item pair which was chosen by the user as well as the support and confidence values for the selected rule shown in the text fields at the bottom of the frame or as a tooltip When the user selects a node in the support graph view the tool will show information about the hierarchy level the item is located in as well as a list of all items connected to the node Selecting an item in the 3D bar chart view can be very difficult because one interesting bar can be hidden by other ones For this reason we have an integrated crosshairs function which makes a selection much easier The crosshairs is indicated by the green bars in the 3D bar chart view of Figure 1 The crossing point is represented in yellow If the user selects a rule in one visualization and afterwards switches to another visualization the same rule is marked in both visualizations making it easier to examine the context of a rule Finally no color coding scheme is equally well suited for all data sets So the tool allows the use to switch between different color coding schemes 128 


 Data classification for intrusion detection can be achieved by the following basic steps 1 In order for a ma chine learning program to learn the classification models  of the normal  and abnormal  system call sequences we need to supply it with a set of training data containing pr e-labeled normal  and abnormal  sequences Different mechanisms based on either linear discrimination decision tre e or rule based methods can be used to scan the normal networ k traces and create a list of unique sequences of sys tem calls This list is generally named as normal list. \(2\ Next step is to scan each of the intrusion traces For each sequ ence of system calls first look it up in the normal list If an exact match can be found then the sequence is labeled as normal  Otherwise it is labeled as abnormal  3 Then ensure that the normal traces include nearly all possible normal  short sequences of system calls. An Intrusion trace conta ins many normal sequences in addition to the abnormal sequen ces since the illegal activities only occur in some pla ces within a trace   As compared to the clustering technique classific ation technique is less popular in the domain of intrusio n detection. The main reason for this phenomenon is t he large amount of data needed to be collected to apply classification To build the traces and form the no rmal and abnormal groups significant amount of data need to  be analyzed to ensure its proximity. Using the collect ed data as empirical models false alarm rate in such case is significantly lower when compared to clustering   Classification approach can be useful for both mis use detection and anomaly detection but it is more com monly used for misuse detection In intrusion detection data mining classification can be applied to a standard set of malicious virus and benign executable using derived  features Secondly RIPPER Naive Bayes and multi-B ayes classifiers can be used to detect malicious virus c ode A decision Tree can be exploited to formulate genetic  algorithm to create rules that match a set of anoma lous connection There are alternative classifier approa ches which we can use for intrusion detection. With intr usion it is observed that over the time user establishes profil e based on the number and types of commands he/she executes. I n such case the attributes will be the number and types o f commands invoked by the user We can reduce dimensionality of such collected data by applying d ata mining classifier approaches like SOM Self Organiz ing Maps and LQM Learning Vector Quantization Neare st neighbor classifier approaches based on SOM and LVQ can be used to refine the collected network data in int rusion detection. Thus the various classification approach es can be employed on network data for obtaining specific information and detecting intrusion  2.3  Outlier Detection  An outlier is an infrequent observation that immens ely deviates from the characteristic distribution of ot her observations. Outlier detection has many applicatio ns, such as data cleaning, fraud detection and network intru sion. The existence of outliers indicates that individuals or  groups that have very different behavior from most of the individuals of the dataset. Many times, outliers ar e removed to improve accuracy of the estimators  Most anomaly detection algorithms require a set of purely normal data to train the model. They assume that an omalies can be treated as previously unobserved patterns. S ince an outlier may be defined as a data point which is ver y different from the rest of the data we can employ several outlier detection schemes for intrusion detection w hich are based on statistical measures clustering methods a nd data mining methods Commonly used outlier techniques in  intrusion detection are Mahalanobis distance detec tion of outliers using Partitioning around medias PAM an d Bay’s algorithm for distance-based outliers Outlie r approaches for categorical data, such as in Guha [6   a r e  n o t  generally available commercially. Unsupervised appr oaches for detecting outliers in large data sets for the p urposes of fraud or intrusion detection are now appearing in t he many research but these approaches are primarily based on ordered data Knorr and Ng 9  r e c e n t l y  d e v e l o p e d  a  distance-based clustering approach for outlier dete ction in large data sets Ramaswarny 12  d e f i n e s  a  n e w  o u t l ier criterion based on the distance of a point to its k th nearest neighbor Breunig 3  d e f i n e  a  n e w  l o c a l  o u t l i e r  f a ctor which is the degree to which a data point is an out lier  Outlier detection is very useful in anomaly based intrusion detection. With outlier detection approac h, we can detect novel attack/intrusion by identifying them a s deviation from normal behavior The basic steps in detecting intrusion based on outlier detection are as follows 1 As outlier detection technique is used  in anomaly detection we first need to identify normal  behavior. This behavior can be data set or pattern of some events on the network 2 Then useful set of featu re need to be constructed and 3 similarity function need to be defined between them. We will need to run specific outlier detection algorithm on the set of feature. The algo rithm can be based on a statistical based approach a distanc e based approach or a model based schema All these approa ches are based on finding the deviation between collecte d and scanned data sets In case of intrusion detection the collected set of data set will be the set of events  and their relation to intrusion. Such relation can be calcula ted based on normal behavior and any other behavior which significantly deviates from normal behavior As wit h such deviation we can preempt attacks based on their beh avioral deviation Outlier detection approaches can useful for detecting any unknown attacks This is the primary reason that makes outlier detection a popular approach for  intrusion detection systems  Statistical based outlier detection scheme uses a probabilistic model as representation of underlying  514 


mechanism of data generation Such probabilistic mo del can be useful in intrusion detection environment to  decide the probability before alarming the system for intr usion Finite mixture and BACON are major statistical base d outlier detection approaches Distance based outlie r detection approaches such as Nearest Neighbor and Mahalanobis approach are engaged in finding outlier  that do not have enough neighbors per define density of local neighborhood Such outlier detection is very useful  in anomaly based intrusion detection systems that are involved in detecting abnormal behavior or deviating pattern s. Such density based and distance based approaches can hel p us to identify abnormal behavior from the set of normal b ehavior and enable us to detect any unknown intrusions  2.4  Association Rule  The Association rule is specifically designed for u se in data analyses The association rule considers each attribute/value pair as an item. An item set is a c ombination of items in a single network request The algorithm  scans through the dataset trying to find item sets that t end to appear in many network data The objective behind u sing association rule based data mining is to derive mul ti-feature attribute correlations from a database table Ass ociation rule mining finds associations and/or correlation relationships among large set of data items Associ ation rules show attributes value conditions that occur f requently together in a given dataset A typical and widely-u sed example of association rule mining is Market Basket  Analysis. Association rules provide information of this type in the form of if-then statements These rules ar e computed from the data. Association rules are proba bilistic in nature. In addition to the antecedent the if part and the consequent \(the "then" part\, an association ru le has two numbers that express the degree of uncertainty abou t the rule. In association analysis the antecedent and co nsequent are sets of items \(called itemsets\ that are disjoi nt. The first number is called the support for the rule The supp ort is simply the number of transactions that include all items in the antecedent and consequent parts of the rule. Th e other number is known as the confidence of the rule. Conf idence is the ratio of the number of transactions that inc lude all items in the consequent as well as the antecedent t o the number of transactions that include all items in th e antecedent Many association rule algorithms have been develope d in the last decades which can be classified into two categories: \(1\ candidate-generation-and-test appro ach such as Apriori 1  a n d   2   p a t t e r n g r o w t h  a p p r o a c h   T h e  challenging issues of association rule algorithms a re multiple scans of transaction databases and a large number of candidates Apriori was the first scalable algor ithm designed for association-rule mining algorithm. The Apriori algorithm searches for large itemsets during its in itial database pass and uses its result as the basis for discovering other large datasets during subsequent searches Th ere are variations of the Apriori algorithm such as Apriori TID and AprioriHybrid AprioriTID works as Apriori but uses  the generated itemsets to search the support instead of  rescanning the database AprioriHybrid is a hybrid of Apriori and AprioriTID. It uses Apriori for its ini tial passes and switches to AprioriTID when it expects the sets  generated would be able to fit into memory Use of association rule in analyzing network data i n intrusion detection is useful in many ways Basic s teps for incorporating association rule for intrusion detect ion as follows 1 First network data need to be formatte d into a database table where each row is an audit record an d each column is a field of the audit records. \(2\ There i s evidence that intrusions and user activities shows frequent correlations among network data For example one o f the reasons that program policies which codify the a ccess rights of privileged programs are concise and capa ble to detect known attacks is in that the intended behavi or of a program e.g read and write files from certain di rectories with specific permissions is very consistent These  consistent behaviors can be captured in association  rules 3 Also rules based on network data can continuous ly merge the rules from a new run to the aggregate rul e set of all previous runs. Thus with the association rule we get the capability to capture behavior in association rule for correctly detecting intrusion and hence lowering th e false alarm rate  3  Data Mining Based IDS  Besides expert systems state transition analysis and statistical analysis data mining is becoming one o f the popular techniques for detecting intrusion Recentl y many IDS vendors are adopting different data mining tech niques for detecting intrusions. We explore several such a vailable IDS which use data mining technique for intrusion detection. This section will provide information ab out these systems and how they are making use of data mining in their overall framework. IDS can be classified on t he basis of their strategy of detection There are two categ ories under this classification misuse detection and ano maly detection  3.1  Misuse Detection Based IDS  Misuse detection searches for known patterns of att ack This strategy is employed by the current generation  of commercial intrusion detection systems One disadva ntage of this strategy is that it can only detect intrusi ons which are based on known patterns Example misuse detection systems that use data mining include JAM \(Java Agen ts for Metalearning MADAM ID Mining Audit Data for Automated Models for Intrusion Detection\, and Auto mated Discovery of Concise Predictive Rules for Intrusion  Detection  JAM 515 


JAM developed at Columbia University uses data mining techniques to discover patterns of intrusion s. It then applies a meta-learning classifier to learn the sig nature of attacks The association rules algorithm determines  relationships between fields in the audit trail rec ords and the frequent episodes algorithm models sequential p atterns of audit events Features are then extracted from b oth algorithms and used to compute models of intrusion behavior The classifiers build the signature of at tacks So thus, data mining in JAM builds misuse detection mo del Classifiers in the JAM are generated by using rule learning program on training data of system usage After training resulting classification rules is used to  recognize anomalies and detect known intrusions The system h as been tested with data from Sendmail-based attacks and with network attacks using TCP dump data  Automated Discovery of Concise Predictive Rules for  ID \(IOWA-IADCPRID Researchers at Iowa State University working on Automated Discovery of Concise Predictive Rules for  Intrusion Detection 7   T h i s  s y s t e m  p e r f o r m s  d a t a  mining to provide global and temporal views of intrusions on a distributed system The rules detect intrusions aga inst programs such as Sendmail using feature vectors t o describe the system calls executed by each process  A genetic algorithm selects feature subsets to reduce  the number of observed features while maintaining or improving learning accuracy This is another exampl e of data mining being used to develop rules for misuse detection  3.2  Anomaly Detection Based IDS  Misuse detection can not detect the attack which signatures have not been defined Anomaly detection  addresses this shortcoming In anomaly detection t he system defines the expected network behavior in adv ance Any significant deviations from the problem are the n reported as possible attacks Such deviations are n ot necessarily actual attacks The Data mining techniq ue are used to extract implicit unknown and useful infor mation from data Applications of data mining to anomaly detection include ADAM Audit Data Analysis and Mining IDDM Intrusion Detection using Data Minin g eBayes  MINDS The MINDS 5  s y s t e m  i s  b e i n g  d e v e l o p e d  a n d  u s e d  b y  the University of Minnesota As the first step in M INDS the net flow tools are used to collect the network traffic data from CISCO routers This data is filtered to remove  network connections not interesting for analysis an d preprocessed to collect basic features. Such create d data is fed into the MINDS system The known attack detecti on module detects network connections that correspond to attacks for which the models are known The remaini ng connections are fed to the anomaly detection module s which assigns a score that reflects how anomalous t he connection is compared to the normal network traffi c Connections that are highly anomalous are analyzed by the UM network security analysts to determine if they a re truly intrusions are false alarms  EBays The eBayes system is a newly developed component fo r the statistical anomaly detector of EMERALD It app lies Bayesian inference on observed and derived variable s of the session on hypotheses. Hypotheses can be either normal events or attacks. Given a Bayes model table is bui lt for the hypotheses and variables Table is adjusted for the  current observations. The eBayes can dynamically generate t he new hypothesis that helps it detect new attacks. The eB ayes may be computationally expensive as the number of hypot hesis states increases. Kohavi [10  s t u d y  d i f f e r e n t  a p p r o aches for handling unknowns and zero counts when estimating probabilities for naïve Bayes classifiers, and prop ose a new variant of the estimator that shows better performa nce  3.3  IDS Using both Misuse and Anomaly Detection   Following are the IDSs that use both misuse and an omaly intrusion detection techniques Thus they are capab le for detecting both known and unknown intrusions. Most o f the IDS are used and developed at an international scop e  IIDS Intelligent Intrusion Detection System Architecture  The IIDS 2  i s  a n  a c t i v e  i n t r u s i o n  d e t e c t i o n  r e s e arch effort being performed at Center for Computer Secur ity Research CCSR at Mississippi State University It  is distributed and network-based modular architecture to monitor activities across the whole network It is based on both anomaly and misuse detection  In IIDS  multip le sensors, both anomaly and misuse detection sensors serving as experts monitor activities on individual workst ations activities of users, and network traffic by detecti ng intrusion from and within network traffic and at individual c lient levels These components use different methods to d etect intrusion information and then pass anomalous/mali cious system behavior indications to the Decision Engine which assess the overall network health Currently the I IDS architecture runs in a high speed cluster environme nt. In this environment the Decision Engine resides in the hea d node and monitors intrusion activities across our experi mental cluster   RIDS-100  RIDS\( Rising Intrusion Detection System\ is provid ed by Rising Tech Rising Tech is a leader in antivirus and content security software and services in China Th e company is a leading provider of client, gateway an d server security solutions for virus protection, firewall a nd intrusion detection technologies and security services to ent erprises and service providers around China. RIDS make the u se of both intrusion detection technique misuse and anom aly 516 


detection. Distance based outlier detection algorit hm is used for detection deviational behavior among collected network data For misuse detection, it has very vast set of collected data pattern which can be matched with scanned netw ork data for misuse detection. This large amount of dat a pattern is scanned using data mining classification Decisio n Tree algorithm  3.4  Summary  IDSs employ various mining techniques as per system  requirement We observe that the association rule i s a common approach to Misuse detection As the associa tion rule facilitates the correlation of different data set associated set of events or patterns can be easily correlated with the intrusion Anomaly detection studies norma l behavior and raises the alarm when any behavior see ms abnormal Outlier detection technique provides the clustering outlier detection mechanism for detectin g any set of data which falls outside cluster or group Thus outlier detection mechanism is widely used for anomaly dete ction  4  Discussion    Intrusion detection systems have been an area of a ctive research for over fifteen years Current commercial  intrusion detection systems employ misuse detection  As such, they completely lack the ability to detect ne w attacks The absence of this capability is a recognized gap in current systems With the shortcomings of current commercia l systems an important research focus is anomaly det ection using data mining. A critical issue for anomaly det ection is the need to reduce false alarms, since any activity outside a known problem raises an alarm Research combining d ata mining and classification has shown great promise i n this area Data mining in intrusion detection is a relat ively new concept. Thus there will likely be obstacles in dev eloping an effective solution As stated previously it is pos sible for a company to collect millions of records per day whic h need to be analyzed for malicious activity With this am ount of data to analyze data mining will become quite computationally expensive Processing power or memo ry are costly Though we only need samples of the data  in order to generate profiles, analyzing network traff ic, without all the data could lead to false conclusions  5  Conclusion   In this paper, we describe different data mining t echnique and their usefulness in the context of an intrusion detection system This paper also provides the description of  the current Intrusion Detection Systems that make use o f data mining for detecting intrusion. Misuse detection te chniques are not sufficient for identifying unknown attacks  For detecting unknown intrusion we need to study norma l behavior inside the data Data mining provide effec tive mechanism for understanding normal behavior inside the data and use this knowledge for detecting unseen in trusions Data mining is becoming an integral part of current  IDS Different data mining techniques like clustering classification association rule and outlier detec tion techniques are helping the various aspects of intru sion data analyses More research will help us to overcome th e limitations in existing data mining technology and will give us effective mechanisms through which we can identi fy intrusion with low false alarm rate  References  1  A g r a w a l  R    M a n n i l a  H    S r i k a n t  R    T o i v o n e n  H   and Verkamo A Fast Discovery of Association Rules Advances in Knowledge Discovery and Data Mining MIT 1996 2  A m b a r e e n  S i r a j   R a y f o r d  B   V a u g h n   a n d  S   M   B r idges Intrusion Sensor Data Fusion in an Intelligent Int rusion Detection System Architecture Proceedings of the 37th Hawaii International Conference on System Sciences 2004 3  B r e u n i g   K r i e g e l   R   T   N g   a n d  J   S a n d e r    L O F  Identifying Density-Based Local Outliers Proceedi ngs of the ACM Sigmod 2000 Intl Conference On Management of Data, Dallas, TX.," 2001 4  E r i c  B l o e d o r n   A l a n  D   C h r i s t i a n s e n   W i l l i a m  H i ll Clement Skorupka, Lisa M. Talbot, and Jonathan Tive l Data Mining for Network Intrusion Detection: How t o Get Started 5  E r t o z  L   e t  A l    M I N D S   M i n n e s o t a  I n t r u s i o n  D e tection System,", Next Generation Data Mining Chapter 3, 20 04 6  S   G u h a   R a s t o g i  R    a n d  S h i m  K     R O C K   A  R o b u st Clustering Algorithm for Categorical Attributes Proceedings of the 15th Int. Conference On Data Eng  Sydney, Australia 1999 7  H e l m e r   W o n g   H o n a v a r   a n d  M i l l e r    A u t o m a t e d  discovery of concise predictive rules for intrusion  detection Technical Report TR 99-01 Department of Computer Science Iowa State University Ames IA  2001 8  H e n e r y  R   J     C l a s s i f i c a t i o n    Machine Learning Neural and Statistical Classification 1994 9  K n o r r  a n d  R   T   N g    A l g o r i t h m s  f o r  M i n i n g  D i s t anceBased Outliers in Large Datasets Very Large DataBases Proceedings of the 24th Int Conference o n Very Large Databases Aug 24-27 1998 New York City, NY, pp. 392-403 1998 10  K o h a v i   B e c k e e r   a n d  S o m m e r    I m p r o v i n g  s i m p l e  bayes In European Conference on Machine Learning Prague, Czech Republic 1997 11  P o r t n o y  L    E   E s k i n   a n d  S t o l f o  S     I n t r u s i on detection with unlabeled data using clustering In ACM Workshop on Data Mining Applied to Security 2000 12  R a m a s w a r n y   R   R   S    a n d  K   S h i m    E f f i c i e n t  Algorithms for Mining Outliers from Large Data Sets  Proceedings of the ACM Sigmod 2000 Int Conference on Management of Data, Dallas, TX 2000 517 


some are best for dense type datasets Currently there is no single algorithm exist that shows global best performance on all types of datasets The main limitation of previous algorithms is that they really upon only single strategy and do no combine the best features of multiple strategies for speedup the process of itemset mining In this paper we show that combining the best features of multiple strategies into a single hybrid is more beneficial and efficient than relying upon single strategy Our different experimental results on benchmark datasets show that mining all and maximal frequent itemsets using our hybrid approach is more efficient than existing algorithms and gives global best performance 13 T Uno M Kiyomi H Arimura LCM ver 3 Collaboration of Array Bitmap and Prefix Tree for Frequent Itemset Mining In 1st Int'l Workshop on Open Source Data Mining in conjunction with SIGKDD2005 2005 14 M J Zaki and C Hsiao Charm An efficient algorithm for closed association rule mining In Technical Report 99-10 Computer Science Rensselaer Polytechnic Institute 1999 8 References 1 R Agrawal T Imielinski and A Swami Mining Association Rules between Sets of Items in Large Databases Proc ACMSIGMOD Int'l Conf Management of Data pp 207-216 May 1993 2 R Agrawal and R Srikant Fast Algorithms for Mining Association Rules Proc Int'l Conf Very Large Data Bases pp 487-499 Sept 1994 3 S Bashir A Rauf Baig HybridMiner Mining Maximal Frequent Itemsets using Hybrid Database Representation Appraoch In Proc of 10th IEEE-INMIC conference Karachi Pakistan 2005 4 D Burdick M Calimlim and J Gehrke Mafia A maximal frequent itemset algorithm for transactional databases In Proc ofICDE Conf pp 443-452 2001 5 Proc IEEE ICDM Workshop Frequent Itemset Mining Implementations B Goethals and M.J Zaki eds CEUR Workshop Proc vol 80 Nov 2003 http:HCEURWS.org/Vol-90 6 K Gouda and M J Zaki Efficiently mining maximal frequent itemsets In ICDM pp 163-170 2001 7 G Grahne and J Zhu Efficiently Using Prefix-trees in Mining Frequent Itemsets In Proc of the IEEE ICDM Workshop on Frequent Itemset Mining Implementations 2003 8 J Han J Pei and Y Yin Mining frequent patterns without candidate generation In SIGMOD pages 1-12 2000 9 J Liu Y Pan K Wang and J Han Mining frequent item sets by opportunistic projection In Proc of KDD Conf 2002 10 G Liu H Lu Y Xu and J X Yu Ascending frequency ordered prefix-tree Efficient mining of frequent patterns In DASFAA 2003 11 J Pei J Han H Lu S Nishio S Tang and D Yang HMine Hyper-structure mining of frequent patterns in large databases In Proc of ICDMConf pp 441.448 2001 12 A Pietracaprina and D Zandolin Mining Frequent Itemsets Using Patricia Tries Proc IEEE ICDM Workshop Frequent Itemset Mining Implementations CEUR Workshop Proc vol 80 Nov 2003 243 


The statement \223g_info := self_general_info;\224 within the worker\222s method 223get_self_general_info\224 can be executed after comparing labels. Note that the manager\222s method 223browse\224 cannot read the worker\222s \223work_hour\224 and \223hour_pay\224. The rationale is described in the last paragraph of section 4.4 Requirement 3 If a worker is not assigned to a manager, the manager can only read the worker\222s general information This requirement is accomplished by the method 223browse\224 of the object \223manager\224 and the labels with the association \223not_assigned\224. To get the general information of a worker not assigned to a manager, the method \223browse\224 invokes the worker\222s method \223get_self_general_info\224 using the manager\222s attribute \223others_general_info\224 as an argument. The statement \223g_info self_general_info;\224 within the worker\222s method 223get_self_general_info\224 can be executed after comparing labels Requirement 4 If a worker and a manager are friends, they can read each other\222s general information This requirement is achieved by the labels with the association \223friend\224. For example, a worker can read his manager friend\222s general information through the worker\222s method 223get_others_general_info\224, which invokes the manager\222s \223get_self_general_info\224 using the worker\222s attribute \223others_general_info\224 as an argument. After comparing the label of the worker\222s attribute \223others_general_info\224 and the manager\222s attribute \223self_general_info\224, one can see that the secure flow condition is true. The statement \223g_info := self_general_info;\224 within the manager\222s method \223get_self_general_info;\224 can be executed Requirement 5 Periodically, the company invokes foreign objects to compute the salaries and taxes of workers This requirement is fulfilled by the stubs \223stub1\224 and stub2\224 in Example 1. Please refer to the description in section 4.3. Moreover, the three rules mentioned in section 3.2 prevent the foreign objects from becoming Trojan horses  7. Evaluation  We implemented a prototype system to evaluate the model. The system uses reusable software repository to simulate foreign object control. Moreover, it uses the language shown in Example 1 to write programs A program written in the language is first pre-processed to produce a program without labels and MLs. The program produced by the preprocessor is conceptually composed of two parts. One is the program before labeling and the other a security monitor The latter checks information flows of the former using Algorithm 1 during program execution Currently, the security monitor checks security dynamically, which contradicts the proposal of static checking [1, 12, 24  N e ve r t he l e ss d yna mi c c he c ki n g  cannot be totally avoided because objects and AGs may be dynamically instantiated or removed during program execution To evaluate the model, we used the example described in section 2 as an assignment to students of different grades and experiences. The students are required to develop a program, namely program a  without the proposed model embedded and another program, namely program b with the model embedded. We then collected and averaged the following metrics data: 1\ LOC \(lines of code\f programs a and b, 2\ecution time of programs a and b, and 3\numbers of non-secure statements found in program b. The collected data showed that the averaged LOC and execution time of program b are respectively 3.2 and 3.8 times those of program a Nevertheless, the data also showed that 2.3 non-secure information flows \(per 100 LOC\n average are identified from program b. Although the runtime overhead seems high, we still think that the model is valuable because of the ability to identify non-secure statements. Nevertheless, reducing the overhead should be an important future work  8. Related work  The simplest information flow control approach is DAC. Since DAC fails to avoid Trojan horses, the multilevel security approach was proposed [6-9  The approach is generally categorized as MAC MAC was criticized as too restricted [5 T o lo o s en  the restriction, quite a few approaches have been proposed. Below we survey some researches The model proposed in t rol s t h e  information flows in object-oriented systems. It uses ACL of objects to compute the ACL of executions. A message filter is used to filter out possibly non-secure information flows. Since the computation of an execution\222s ACL takes information propagation into consideration, no Trojan horses will result Moreover, interactions among executions are categorized into five modes including synchronized unrestricted, synchronous restricted, asynchronous deferred reply unrestricted, and deferred reply restricted. Different modes result in different ACLs Proceedings of t he 36th Ha waii International Conf erence on S y st e m Sciences \(HICSS\22203 0 76 95 18 745/0 3 1 7.00 251 20 02  I E EE 


which loosens the restriction of MAC. More flexibility is added to the model by allowing exceptions during or after method execution [10-11 The purpose-oriented model [21-22 pro pos es  that invoking a method may be allowed for some methods but disallowed for other methods, even when the invokers belong to the same object. This consideration is correct, because the security levels of methods in an object may be different Different methods can thus access information in different security levels The decentralized label approach [1-4 m a rk s t h e  security levels of variables using labels. A label is composed of one or more policies, which should be simultaneously obeyed. A policy in a label is composed of an owner and zero or more readers that are allowed to access the data. When computation are applied to data, join operation is used to compute the label of the result data. This avoids Trojan horses Another feature proposed by this approach is that declassification \(downgrading of security level provided. This allows non-sensitive data, which are in high security level, to be accessed by low security level processes. The model also takes write access control into consideration [4 rren t l y t h e m o d e l  has been used to develop a programming language Jflow [1 ad d itio n   th e m o d e l h a s b e e n  u s ed i n a  distributed system with untrusted hosts through secure program partitioning [30  Role-based access control models [19, 27, 33  define the roles a subject can play. A role is a collection of permissions \(i.e., access rights  When a subject plays a role, it possesses the rights belonging to the role. A subject can play multiple roles and even change role during a session Inheritance and other relationships can be established among roles [27 t o s t ru ct u re t h e m Moreov er  constraints, such as two specific roles should be mutually exclusive, can be attached to roles. The advantage of role-based access control is that subjects can change roles dynamically, which facilitates obeying the \223need-to-know\224 principle. It seems that the role-based models operate well in an application that protects not too many resources because roles should be defined before the application\222s execution. In case that many resources should be protected \(such as every variable in a program should be protected\ining roles becomes tedious and the access control may become imprecise From the survey, we identified many necessary features for controlling information flows in object-oriented systems such as Trojan horse prevention, declassification, purpose-oriented method invocation, and so on. In fact, our model offers those features, although we do not present them in this paper. What we present in this paper are the control of information flows among objects and foreign objects. According to our survey, no model offers the control well  9. Conclusions  This paper proposes a model to control information flows among objects. The model uses associations and method limitations \(ML\ to control information flows among objects. Information flows are controlled by attaching labels to variables. Trojan horses are avoided by join operations. Within an application, every variable and literal is associated with one or more labels. If a variable is associated with multiple labels, each label enforces the security policy of an association. To check the security of an information flow, labels are compared. An information flow is secure if the comparison causes the secure flow condition true In addition to controlling objects developed by programmers, the model also controls foreign objects which are pre-existing objects for reused. Since the details of a foreign object are unknown, our model only prevents foreign objects from becoming Trojan horses. We use the \223Suppression rule\224, \223No ML rule\224 and \223Stuck to rules\224 to control foreign objects We implemented a prototype system to evaluate the model. From the data collected, we found that the model does facilitate identifying non-secure information flows. We thus believe that the model is useful in spite of runtime overhead  Acknowledgement  This research is sponsored by the National Science Council in Taiwan under Grant NSC91-2213-E-259-006  References  1  A  C. My e r s 223 J Flow  P r a c tic a l Mostly S ta tic  Information Flow Control\224 Proc. 26\222th ACM Symp Principles of Programming Language pp. 228-241 1999  A  C M y ers an d B L i sko v  223A De cen t r al i zed M o d e l f o r Information Flow Control\224 Proc. 17\222th ACM Symp Operating Systems Principles pp. 129-142, 1997 3 A  My e r s a nd B  L i s k ov 223 C om ple t e  Sa f e I n f o r m a tion  Flow with Decentralized Labels\224 Proc. 14\222th IEEE Symp Security and Privacy pp. 186-197, 1998 4 A My e r s a nd B. L i sk ov 223 P rote c ting  P r iv a c y using the  Proceedings of t he 36th Ha waii International Conf erence on S y st e m Sciences \(HICSS\22203 0 76 95 18 745/0 3 1 7.00 251 20 02  I E EE 


Decentralized Label Model\224 ACM Trans. Software Eng Methodology vol. 9, no. 4, pp. 410-442, 2000  C J M c Co ll u m  J R M e ssin g  an d L  No tar g iaco m o   223Beyond the Pale of MAC and DAC - Defining New Forms of Access Control\224 Proc. 6\222th IEEE Symp Security and Privacy pp. 190-200, 1990  D E  Bel l a n d L  J L a P a d u l a 223S ecu re Co m p u t er  Systems: Unified Exposition and Multics Interpretation\224 technique report, Mitre Corp Mar. 1976 http://csrc.nist.gov/publications/history/bell76.pdf 7 D  E  D e nn ing  223 A L a ttic e Mode l of Se c u r e I n f o r m a tion Flow\224 Comm. ACM vol. 19, no. 5, pp. 236-243, 1976 8 D  E  D e n n ing a n d P  J  D e nning 223 C e r tif ic a tion of  Program for Secure Information Flow\224 Comm. ACM vol 20, no. 7, pp. 504-513, 1977  D  F  C  Brew er  an d M  J  Nash  223T h e Ch i n ese W a l l  Security Policy\224 Proc. 5\222th IEEE Symp. Security and Privacy pp. 206-214, 1989 10 E Ferrari P   Sam a r a ti, E. Bertin o  an d S. Jajo d i a  223Providing Flexibility in Information Control for Object-Oriented Systems\224 Proc. 13\222th IEEE Symp Security and Privacy pp. 130-140, 1997 11 E B e r tin o Sa br i n a  de C a pita ni di V i m e r c a ti, E  Ferrari, and P. Samarati, \223Exception-based Information Flow Control in Object-Oriented Systems\224 ACM Trans Information System Security vol. 1, no. 1, pp. 26-65 1998 1  F  B S chu ei d er  223E n f o r ceab l e S ecu ri t y P o l i cy 224  ACM Trans. Information System Security vol. 3, no. 1, pp 30-50, 2000 1 G  B o o c h  Object-Oriented Analysis and Design with Application second edition, The Benjamin/Cummings Publishing Company, 1994 1 G  S m i t h an d D  V o l p an o 223S ecu re In f o r m at i o n F l o w  in a Multi-Thread Imperative Language\224 Proc. 25th ACM Symp. on Principles of Programming Languages  pp. 355-364, 1998 15 H M De ite l a n d a n d P  J D e ite l C: How to Program  Prentice-Hall, 2001 16 O M G  223 T he C o m m on O bje c t R e que s t B r ok e r   Architecture and Specification\224 http://doc.ece.uci.edu/CORBA 17 J  A g a t 223 T r a nsf o r m ing out  T i m i ng Le ak s 224  Proc. 27th ACM Symp. on Principles of Programming Languages  pp. 40-53, 2000 1 J Ru m b au gh  M  Bl ah a  W  P r em erl a n i  F  E d d y  an d  W Lo r en s en   Object-Oriented Modeling and Design  Prentice-Hall, 1991 19 K  I z a k i, K  T a na k a a nd M  T a k i z a w a 223 I nf or m a tion Flow Control in Role-Based Model for Distributed Objects\224 Proc. 8\222th International Conf. Parallel and Distributed Systems pp. 363-370, 2001 20 M. D. Mc Ilr o y a nd J A  R e e d s, \223 M ultile v e l Se c u rity  in the UNIX Tradition\224 Software - Practice and Experience vol. 22, no. 8, pp. 673-694, 1992 2  M  Y asu d a T  T ach i k a w a an d M  T aki za w a  223Information Flow in a Purpose-Oriented Access Control Model\224 Proc. 1997 International Conf. Parallel and Distributed Systems pp. 244-249, 1997 22 M. Y a s uda   T   T a c h ik aw a, a nd M  T a k i z a w a  223A  Purpose-Oriented Access Control Model\224 Proc. 12\222th International Conf. Information Networking pp. 168-173 1998 23  P  Sa m a ra ti, E. Be rtino   A  Cia m pic h e tti, a n d S  Jajodia, \223Information Flow Control in Object-Oriented Systems\224 IEEE Trans. Knowledge Data Eng vol. 9, no 4, pp.524-538, Jul./Aug. 1997 24 R  F o c a r di a n d R  G o r r i e r i, \223 T he C o m pos itiona l  Security Checker: A Tool for the Verification of Information Flow Security Properties\224 IEEE Trans Software Eng vol. 23, no. 9, pp. 550-571, 1997 2 G r au b a rt  223On t h e Need f o r a T h i r d  F o rm o f A cce ss  Control\224 Proc. 12\222th Nat\222l Computer Security Conf pp 296-303, 1989 26 R  S  Sa nd hu 223 L a ttic e B a sed A c c e s s C ontr o l M ode ls 224   IEEE Computer vol. 26, no. 11, pp. 9-19, Nov. 1993 27 R  S  S a n d h u  E  J  C o y n e  H  L  F e i n s t e i n  a n d C  E   Youman, \223Role-Based Access Control Models\224 IEEE Computer vol. 29, no. 2, pp. 38-47, 1996 2  S  Jaj o d i a and B  Ko gan  223In t egrat i n g an  Object-Oriented Data Model with Multilevel Security\224 Proc. 6\222th IEEE Symp. Security and Privacy pp. 76-85 1990 29  S. N Fo ley  223A Mo d e l f o r S e cu re In f o rmatio n Fl o w 224  Proc. 5\222th IEEE Symp. Security and Privacy pp. 248-258 1989 30  S. Z d a n c e w ic L Zhe n g N N y s t ro m a nd A C. My e r s   223Untrusted Hosts and Confidentiality: Secure Program Partitioning\224 Proc. 18th ACM Symp. Operating Systems Principles 2001 3 T   T ach i k a w a M  Y asu d a an d M   T aki za w a  223 A  Purposed-Oriented Access Control Model in Object-Based Systems\224 Trans. Information Processing Society of Japan vol. 38, no. 11, pp. 2362-2369, 1997 32 V  V a ra d h a r a j a n a nd S Bla c k 223 A Multile v e l Se c u rity  Model for a Distributed Object-Oriented System\224 Proc 6\222th IEEE Symp. Security and Privacy pp. 68-78, 1990 3 Z   T a ri an d S  W  Ch an 223A Ro l e Bas ed Acces s  Control for Intranet Security\224 IEEE Internet Computing  vol. 1, no. 5, pp. 24-34, 1997 Proceedings of t he 36th Ha waii International Conf erence on S y st e m Sciences \(HICSS\22203 0 76 95 18 745/0 3 1 7.00 251 20 02  I E EE 


absolute values. The results can vary on other computers. But it can be guaranteed that performance ratio of the algorithms will remain the same After making the comparisons with sample data, we came to the conclusion that PD algorithm performs significantly better than the other two especially with larger datasets. PD outperforms DCP and PIP regarding running time. On the other hand, since PD reduces the dataset, mining time does not necessary increase as the number of transactions increases and experiments reveals that PD has better scalability than DCP and PIP. So, PD has the ability to handle the large data mine in practical field like market basket analysis and medical report documents mining 5. References 1] R. Agrawal and R. Srikant, "Fast algoritlnns for mining association rules", VLDB'94, pp. 487-499 2] R. J. Bayardo, "Efficiently mining long patterns from databases", SIGMOD'98, pp.85-93 3] J. Pei, J. Han, and R. Mao, "CLOSET: An Efficient Algorithm for Mining Frequent Closed Itemsets \(PDF Proc. 2000 ACM-SIGMOD International Workshop on Data Mining and Knowledge Discovery, Dallas, TX, May 2000 4] Qinghua Zou, Henry Chiu, Wesley Chu, David Johnson, "Using Pattern Decomposition\( PD Finding All Frequent Patterns in Large Datasets", Computer Science Department University of California - Los Angeles 5] J. Han, J. Pei, and Y. Yin, "Mining Frequent Patterns without Candidate Generation \(PDF  SIGMOD International Con! on Management of Data SIGMOD'OOj, Dallas, TX, May 2000 6] S. Orlando, P. Palmerini, and R. Perego, "The DCP algoritlnn for Frequent Set Counting", Technical Report CS2001-7, Dip. di Informatica, Universita di Venezia 2001.Available at http://www.dsi.unive.itl?orlando/TR017.pdf 7] MD. Mamun-Or-Rashid, MD.Rezaul Karim, "Predictive item pruning FP-tree algoritlnn", The Dhaka University  Journal of Science, VOL. 52, NO. 1, October,2003, pp. 3946 8] Park, J. S., Chen, M.-S., and Yu, P. S, "An Effective Hash Based Algoritlnn for Mining Association Rules", Proc ofthe 1995 ACM-SIGMOD Con! on Management of Data 175-186 9] Brin, S., Motwani, R., Ullman, J., and Tsur, S, "Dynamic Itemset Counting and Implication Rules for Market Basket Data", In Proc. of the 1997 ACM-SIGMOD Conf On Management of Data, 255-264 10] Zaki, M. J., Parthasarathy, S., Ogihara, M., and Li, W New Algoritlnns for Fast Discovery of Association Rules In Proc. of the Third Int'l Con! on Knowledge Discovery in Databases and Data Mining, 283-286 11] Lin, D.-I and Kedem, Z. M., "Pincer-Search: A New Algoritlnn for Discovering the Maximum Frequent Set", In Proc. of the Sixth European Conf on Extending DatabaseTechnology, 1998 12] R. Ramakrishnan, Database Management Systems University of Wisconsin, Madison, WI, USA; International Edition 1998 pre></body></html 


tors such as union, di?erence and intersection are de?ned for pairs of classes of the same pattern type Renaming. Similarly to the relational context, we consider a renaming operator ? that takes a class and a renaming function and changes the names of the pattern attributes according to the speci?ed function Projection. The projection operator allows one to reduce the structure and the measures of the input patterns by projecting out some components. The new expression is obtained by projecting the formula de?ning the expression over the remaining attributes [12 Note that no projection is de?ned over the data source since in this case the structure and the measures would have to be recomputed Let c be a class of pattern type pt. Let ls be a non empty list of attributes appearing in pt.Structure and lm a list of attributes appearing in pt.Measure. Then the projection operator is de?ned as follows ls,lm c id s m f p ? c, p = \(pid, s, d,m, f In the previous de?nition, id ing new pids for patterns, ?mlm\(m projection of the measure component and ?sls\(s ned as follows: \(i s usual relational projection; \(ii sls\(s and removing the rest from set elements. The last component ?ls?lm\(f computed in certain cases, when the theory over which the formula is constructed admits projection. This happens for example for the polynomial constraint theory 12 Selection. The selection operator allows one to select the patterns belonging to one class that satisfy a certain predicate, involving any possible pattern component, chosen among the ones presented in Section 5.1.1 Let c be a class of pattern type pt. Let pr be a predicate. Then, the selection operator is de?ned as follows pr\(c p Join. The join operation provides a way to combine patterns belonging to two di?erent classes according to a join predicate and a composition function speci?ed by the user Proceedings of the 16th International Conference on Scientific and Statistical Database  Management \(SSDBM  04 1099-3371/04 $ 20.00  2004 IEEE Let c1 and c2 be two classes over two pattern types pt1 and pt2. A join predicate F is any predicate de?ned over a component of patterns in c1 and a component of patterns in c2. A composition function c pattern types pt1 and pt2 is a 4-tuple of functions c cStructureSchema, cDataSchema, cMeasureSchema, cFormula one for each pattern component. For example, function cStructureSchema takes as input two structure values of the right type and returns a new structure value, for a possible new pattern type, generated by the join. Functions for the other pattern components are similarly de?ned. Given two patterns p1 = \(pid1, s1, d1,m1, f1 p2 = \(pid2, s2, d2,m2, f2 p1, p2 ned as the pattern p with the following components Structure : cStructureSchema\(s1, s2 Data : cDataSchema\(d1, d2 Measure : cMeasureSchema\(m1,m2 Formula : cformula\(f1, f2 The join of c1 and c2 with respect to the join predicate F and the composition function c, denoted by c 1   F  c  c 2   i s  n o w  d e  n e d  a s  f o l l o w s    F  c  c 2     c  p 1   p 2   p 1    c 1  p 2    c 2  F   p 1   p 2     t r u e   5.1.3. Cross-over database operators OCD Drill-Through. The drill-through operator allows one to 


Drill-Through. The drill-through operator allows one to navigate from the pattern layer to the raw data layer Thus it takes as input a pattern class and it returns a raw data set. More formally, let c be a class of pattern type pt and let d be an instance of the data schema ds of pt. Then, the drill-through operator is denoted by c c Data-covering. Given a pattern p and a dataset D sometimes it is important to determine whether the pattern represents it or not. In other words, we wish to determine the subset S of D represented by p \(p can also be selected by some query the formula as a query on the dataset. Let p be a pattern, possibly selected by using query language operators, and D a dataset with schema \(a1, ..., an ible with the source schema of p. The data-covering operator, denoted by ?d\(p,D responding to all tuples in D represented by p. More formally d\(p,D t.a1, ..., t.an In the previous expression, t.ai denotes a speci?c component of tuple t belonging to D and p.formula\(t.a1, ..., t.an instantiated by replacing each variable corresponding to a pattern data component with values of the considered tuple t Note that, since the drill-though operator uses the intermediate mapping and the data covering operator uses the formula, the covering ?\(p,D D = ?\(p not be equal to D. This is due to the approximating nature of the pattern formula 5.1.4. Cross-over pattern base operators OCP Pattern-covering. Sometimes it can be useful to have an operator that, given a class of patterns and a dataset, returns all patterns in the class representing that dataset \(a sort of inverse data-covering operation Let c be a pattern class and D a dataset with schema a1, ..., an pattern type. The pattern-covering operator, denoted as ?p\(c,D all patterns in c representing D. More formally p\(c,D t.a1, ..., t.an true Note that: ?p\(c,D p,D 6. Related Work Although signi?cant e?ort has been invested in extending database models to deal with patterns, no coherent approach has been proposed and convincingly implemented for a generic model There exist several standardization e?orts for modeling patterns, like the Predictive Model Markup Language \(PMML  eling approach, the ISO SQL/MM standard [2], which is SQL-based, and the Common Warehouse Model CWM  ing e?ort. Also, the Java Data Mining API \(JDMAPI 3] addresses the need for a language-based management of patterns. Although these approaches try to represent a wide range of data mining result, the theoretical background of these frameworks is not clear. Most importantly, though, they do not provide a generic model capable of handling arbitrary cases of pattern types; on the contrary only a given list of prede?ned pattern types is supported To our knowledge, research has not dealt with the issue of pattern management per se, but, at best, with peripheral proximate problems. For example, the paper by Ganti et. al. [9] deals with the measurement 


per by Ganti et. al. [9] deals with the measurement of similarity \(or deviation, in the authors  vocabulary between decision trees, frequent itemsets and clusters Although this is already a powerful approach, it is not generic enough for our purpose. The most relevant research e?ort in the literature, concerning pattern management is found in the ?eld of inductive databases Proceedings of the 16th International Conference on Scientific and Statistical Database  Management \(SSDBM  04 1099-3371/04 $ 20.00  2004 IEEE meant as databases that, in addition to data, also contain patterns [10], [7]. Our approach di?ers from the inductive database one mainly in two ways. Firstly, while only association rules and string patterns are usually considered there and no attempt is made towards a general pattern model, in our approach no prede?ned pattern types are considered and the main focus lies in devising a general and extensible model for patterns Secondly, di?erently from [10], we claim that the peculiarities of patterns in terms of structure and behavior together with the characteristic of the expected workload on them, call for a logical separation between the database and the pattern-base in order to ensure e?cient handling of both raw data and patterns through dedicated management systems Finally, we remark that even if some languages have been proposed for pattern generation and retrieval 14, 11], they mainly deal with speci?c types of patterns \(in general, association rules sider the more general problem of de?ning safe and su?ciently expressive language for querying heterogeneous patterns 7. Conclusions and Future Work In this paper we have dealt with the issue of modelling and managing patterns in a database-like setting Our approach is enabled through a Pattern-Base Management System, enabling the storage, querying and management of interesting abstractions of data which we call patterns. In this paper, we have \(a de?ned the logical foundations for the global setting of PBMS management through a model that covers data patterns and intermediate mappings and \(b language issues for PBMS management. To this end we presented a pattern speci?cation language for pattern management along with safety constraints for its usage and introduced queries and query operators and identi?ed interesting query classes Several research issues remain open. First, it is an interesting topic to incorporate the notion of type and class hierarchies in the model [15]. Second, we have intentionally avoided a deep discussion of statistical measures in this paper: it is more than a trivial task to de?ne a generic ontology of statistical measures for any kind of patterns out of the various methodologies that exist \(general probabilities Dempster-Schafer, Bayesian Networks, etc. [16 nally, pattern-base management is not a mature technology: as a recent survey shows [6], it is quite cumbersome to leverage their functionality through objectrelational technology and therefore, their design and engineering is an interesting topic of research References 1] Common Warehouse Metamodel \(CWM http://www.omg.org/cwm, 2001 2] ISO SQL/MM Part 6. http://www.sql99.org/SC32/WG4/Progression Documents/FCD/fcddatamining-2001-05.pdf, 2001 3] Java Data Mining API http://www.jcp.org/jsr/detail/73.prt, 2003 4] Predictive Model Markup Language \(PMML http://www.dmg.org 


http://www.dmg.org pmmlspecs v2/pmml v2 0.html, 2003 5] S. Abiteboul and C. Beeri. The power of languages for the manipulation of complex values. VLDB Journal 4\(4  794, 1995 6] B. Catania, A. Maddalena, E. Bertino, I. Duci, and Y.Theodoridis. Towards abenchmark for patternbases http://dke.cti.gr/panda/index.htm, 2003 7] L. De Raedt. A perspective on inductive databases SIGKDD Explorations, 4\(2  77, 2002 8] M. Escobar-Molano, R. Hull, and D. Jacobs. Safety and translation of calculus queries with scalar functions. In Proceedings of PODS, pages 253  264. ACMPress, 1993 9] V. Ganti, R. Ramakrishnan, J. Gehrke, andW.-Y. Loh A framework for measuring distances in data characteristics. PODS, 1999 10] T. Imielinski and H. Mannila. A database perspective on knowledge discovery. Communications of the ACM 39\(11  64, 1996 11] T. Imielinski and A. Virmani. MSQL: A Query Language for Database Mining. Data Mining and Knowledge Discovery, 2\(4  408, 1999 12] P. Kanellakis, G. Kuper, and P. Revesz. Constraint QueryLanguages. Journal of Computer and SystemSciences, 51\(1  52, 1995 13] P. Lyman and H. R. Varian. How much information http://www.sims.berkeley.edu/how-much-info, 2000 14] R.Meo, G. Psaila, and S. Ceri. An Extension to SQL for Mining Association Rules. Data Mining and Knowledge DiscoveryM, 2\(2  224, 1999 15] S. Rizzi, E. Bertino, B. Catania, M. Golfarelli M. Halkidi, M. Terrovitis, P. Vassiliadis, M. Vazirgiannis, and E. Vrachnos. Towards a logical model for patterns. In Proceedings of ER 2003, 2003 16] A. Siblerschatz and A. Tuzhillin. What makes patterns interesting in knowledge discovery systems. IEEE TKDE, 8\(6  974, 1996 17] D. Suciu. Domain-independent queries on databases with external functions. In Proceedings ICDT, volume 893, pages 177  190, 1995 18] M.Terrovitis, P.Vassiliadis, S. Skadopoulos, E. Bertino B. Catania, and A. Maddalena. Modeling and language support for the management of patternbases. Technical Report TR-2004-2, National Technical University of Athens, 2004. Available at http://www.dblab.ece.ntua.gr/pubs Proceedings of the 16th International Conference on Scientific and Statistical Database  Management \(SSDBM  04 1099-3371/04 $ 20.00  2004 IEEE pre></body></html 


The reason of the hiding failure of SWA is the same in Fig.8 Notice the result at x = 0.7646 in Fig.14, because the hiding failure is occurred at the seeds of the sensitive patterns, a high weakness is produced As shown in Fig.15 and Fig.16, the misses cost and dissimil arity of our work decreases as RL2 increases. This is because the larger RL2 is, the less effect on non-sensitive patterns. Also weakness and dissimilarity of SWA are independent of RL2 5. Conclusion In the paper, a novel method improving the balance between sensitive knowledge protecting and discovery on frequent patte rns has been proposed. By setting entries of a sanitization matrix to appropriate values and multiplying the original database by the matrix with some probability policies, a sanitized database is gotten. Moreover, it can avoid F-I Attack absolutely when the confidence level given by users approximates to 1. The experimental results revealed that although misses cost and dissimilarity between the original and sanitized database of our process are little more than SWA, ours provide more safely protection than SWA. Unlike SWA, our sanitization process could not suffer from F-I Attack and the probability policies in our approach also take the minimum support into account, the users only need to decide the confidence level which affects the degree of patterns hiding 6. Reference 1] M. Atallah, E. Bertino, A. Elmagarmid, M. Ibrahim and V. Verykios Disclosure Limitation of Sensitive Rules", Proc. of IEEE Knowledge and Data Engineering Exchange Workshop 1999 2] R. Agrawal and R. Srikant. Fast algorithms for mining association rules. VLDB, Santiago, Chile, 1994 3] R. Agrawal and R. Srikant. Privacy preserving data mining. In ACM SIGMOD, Dallas, Texas, May 2000 4] E. Dasseni, V. Verykios, A. Elmagarmid and E. Bertino, Hiding Association Rules by Using Confidence and Support", Proc. of 4th Intl Information Hiding Workshop \(IHW 5] A. Evfimievski, J. Gehrke, and R. Srikant. Limiting Privacy Breac hed in privacy preserving data mining. SIGMOD/PODS, 2003 6] A. Evfimievski, R. Srikant, R. Agrawal, and J. Gehrke. Privacy preserving mining of association rules. KDD 2002 7] M. Kantarcioglu and C. Clifton. Privacy-preserving distributed mining of association rules on horizontally partitioned data. In ACM SIGMOD Workshop on Research Issues on Data Mining and Knowledge Discovery, June 2002 8] Guanling Lee, Chien-Yu Chang and Arbee L.P Chen. Hiding sensitive patterns in association rules mining. The 28th Annual International Computer Software and Applications Conference 9] Y. Lindell and B. Pinkas. Privacy Preserving Data mining. In CRYPTO, pages 36-54, 2000 10] S. R. M. Oliveira and O. R. Za  ane. Privacy Preserving Frequent Itemset Mining. In Proc. of IEEE ICDM  02 Workshop on Privacy Security, and Data Mining 11] S. R. M. Oliveira and O. R. Za  ane. Algorithms for Balancing Priv acy and Knowledge Discovery in Association Rule Mining. IDEAS  03 12] S. R. M. Oliveira and O. R. Za  ane. Protecting Sensitive Knowledge By Data Sanitization, ICDM  03 13] S. R. M. Oliveira, O. R. Za  ane and Y  cel Saygin. Secure Association Rule Sharing, PAKDD-04 14] Benny Pinks. Cryptographic Techniques For Privacy-Preserving D ata Mining. ACM SIGKDD Explorations Newsletter Vol. 4, Is. 2, 2002 15] S. J. Rizvi and J. R. Haritsa. Maintaining data privacy in association rule mining. VLDB, 2002 16] J. Vaidya and C. W. Clifton. Privacy preserving association rule mining in vertically partitioned data. KDD2002 17] Verykios, V.S.; Elmagarmid, A.K.; Bertino, E.; Saygin, Y.; Dasseni E. Association rule hiding. IEEE Transactions On Knowledge And Data Engineering, Vol. 16, No. 4, April 2004 Proceedings of the 29th Annual International Computer Software and Applications Conference  COMPSAC  05 0730-3157/05 $20.00  2005 IEEE pre></body></html 


pre></body></html 


Batt Power Batt Type Stabilization Type Propulsion Mechanism  of Solar Panels  of Solar Cells Manufacturing Qty Satellites in Constellation On-Orbit Spares Channels Number of Bands Data Storage Processing Power Source type Block Name Thermal Control Material Type Level of Technology Known Inheritance Propulsion station keeping Number of Axes Ground Based Spares Pointing Accuracy APPENDIX C EXISTING MODELS Numerous models are today in use for estimating spacecraft cost Two of the most common are the NASA/Air Force Cost Model and the Aerospace Small Satellite Cost Model Here is a description of the NAFCOM model The NASA/Air Force Cost Model NAFCOM is a parametric estimating toolfor space hardware It is based on historical NASA and Air Force space projects and is primarily used in the very early phases of a development project NAFCOM can be used at the subsystem or component levels The database currently includes 122 missions including 76 unmanned earth orbiting 24 unmanned planetary 11 launch vehicles 8 manned 3 engines It uses parametric relationships to estimate subsystem or component level costs for any aerospace hardware including earth orbital spacecraft manned spacecraft launch vehicle upper stages liquid rocket engines scientific instruments or planetary spacecraft 7 And for the Aerospace Small Satellite Cost Model SSCM employs a parametric methodology for estimation of program cost and is best suited to the early conceptual development phase of a spacecraft program during which time the design is likely to be less mature and when cost and performance trades can be easily performed SSCM consists of a collection of cost-estimating relationships or CERs which estimate the costs of developing andproducing a spacecraft system with the following subsystems  Attitude Determination and Control Subsystem ADCS  Propulsion  Power  Telemetry Tracking  Command TT&C  Command  Data Handling C&DH  Structure  Thermal CERs were also developed for integration assembly and test IA&T program management PM and systems engineering SE and launch and orbital operations support LOOS Individual subsystem cost estimates are statistically rolled up to yield a cost-risk distribution which provides the estimator with a range of cost estimates andpercentiles 8 The SSCM was calibrated from over 100 post-1990 Earth-orbiting andplanetary missions REFERENCES 1 Lack of Disciplined Cost-Estimating Processes Hinders Effective Program Management GAO study 04-642 2 Jilla Cyrus D and Miller David W Satellite Design Past Present and Future International Journal of Small Satellite Engineering 12 February 1997 3 Bearden David A A Complexity Based Risk Assessment of Low-Cost Planetary Missions:When Is A Mission Too Fast and Too Cheap Fourth IAA International Conference On Low-Cost Planetary Missions JHU/APL MAY 2-5 2000 4 Kellogg Mahr and Lobbia An Analogy-based Method for Estimating the Costs of Spacecraft IEEEAC paper 1371 Version 4 5 Hoeting Jennifer A Methodology for Bayesian Model Averaging An Update f 6]btp/ewiieiao iiAaos 7 Keith Smith NASA/Air Force Cost Model Science Applications International Corporation 8 18 


BIOGRAPHIES Lee Fischman served as Principle Investigator for this project Lee is Senior Director of Development at Galorath Incorporated where he directs much of the new product development and research at the firm He developed SEER for Software  Hardware Integrations with Microsoft Project the Comparison Sizing tool COTS Software model in addition to various data mining information extraction and expert systems Previously he was a software designerlprogrammer in the New York financial industry Lee earned a BA from the University of Chicago and an MA from UCLA both in economics Mike Kimel carried out statistical work on the project Mike is an Economist for Galorath Inc in addition to maintaining his own quantitative consulting practice He has also taught Economics and Advanced Statistics at the Graziadio School of Business and Management at Pepperdine University run the Competitive Strategy group for a Fortune 500 Telecom Company and worked as a Consultant at PriceWaterhouse LLC now PriceWaterhouse-Coopers He earned a Ph.D in Economicsfrom UCLA Troy Masters programmed analytic methods and is integrating the Far Out model into its parent product SEER for Hardware previously SEER-H Troy is a Software Engineer with Galorath Incorporated where he has been the primary developer for a range ofproducts He earned a BS in computer science from UCLA David J Pine was our subject matter expert helping us assemble data and gain insight into technical trends Dave is retired after a 34-year career with the National Aeronautics and Space Administration NASA currently is a consultant to various government and industry entities While at NASA his organizations in the Office of the Chief Financial Officer and later at the IPAO at Langley Research Center were responsible for the conduct of major NASA program analyses and evaluations for the NASA Administrator and Deputy Administrator From early 1988 through the end of 1990 he was the Deputy Program Manager for the Hubble Space Telescope Program specifically responsible for the telescope operations and science support aspects of the program He earned a BS in Aerospace Engineering from the Polytechnic Institute of Brooklyn and a Masters of Engineering Administration from the George Washington University 19 


  20 Angeles, where he also received a B.S. in Applied Mathematics  Eric Fetzer is a Senior Member of the Technical Staff at the Jet Propulsion Laboratory, Pasadena, California specializing in satellite observations of the atmosphere.  His scientific interests include planetary boundary layer processes, tropical phenomena, upper tropospheric variability, and climatologies of temperature, water vapor and clouds.  His technical interests include analysis of large data sets, and of multi-sensor observations. He has over 20 peer-reviewed publications and given numerous scientific presentations, public lectures and media interviews about climate science. Eric received a B.A. in Physics from the University of California Berkeley, and a Ph.D. in Astrophysical, Planetary and Atmospheric Sciences from the University of Colorado, Boulder   Amy Braverman is a Senior Statistician at the Jet Propulsion Laboratory, California Institute of Technology She holds a B.A. in Economics from Swarthmore College an M.A. in Mathematics from UCLA, and a Ph.D. in Statistics also from UCLA. Prior to her current position in JPL's Science Data Understanding Group, she was a Caltech Post-doctoral Scholar at the Jet Propulsion Laboratory, and a Scientist in the Flight Sciences Experiments Section of the Science Division. Dr Braverman conducts research on information-theoretic methods for the analysis of massive data sets and streams statistical data fusion, high-dimensional data analysis, and statistical analysis for climate model evaluation and diagnosis. She has published in both the statistics and geoscience literature, and is active in both communities She is a member of the Multi-angle Imaging SpectroRadiometer Science Team, and serves as a member of the Atmospheric Infrared Sounder Science Integration Team. Her responsibilities on both missions include designing data reduction algorithms for massive, remote sensing data sets. Dr. Braverman also holds an appointment in the Department of Statistics at UCLA as Adjunct Associate Professor, and is active in UCLA\222s Center for Environmental Statistics. She is member of the Committee on Applied and Theoretical Statistics of the US National Academy of Science. She has refereed for the Journal of the American Statistical Association, the Journal of Computational and Gr aphical Statistics, IEEE Transactions on Geoscience and Remote Sensing, and the Journal of Applied Meteorology and Climatology Seungwon Lee is a senior member of the High Capability Computing and Modeling Group at Jet Propulsion Laboratory. She is conducti ng research on comet gas dynamics, nonlinear dynamics control, climate model parameterization, Earth science data analysis, parallel computing, and advanced numerical algorithms. She received her Ph.D in Physics fr om the Ohio State University and her M.S. and B.S. in Physics from the Seoul National University, Korea  Matthew Henderson is software engineer in the High Capability Computing and Mode ling group at JPL. His current work includes Web Services and Instrument Data Level 2 subsetting. He received a B.S. Computer Science from CSU Pomona, and is currently pursuing M.S Computer Science  Steven J. Lewis is a member of the Information System and Computer Science staff member at the Jet Propulsion Laboratory.  He received a BS in Mathematics from the University of California, Los Angeles in June 2001, and the MS and Ph.D. Degree from Claremont Graduate University in May 2004 and May 2007, respectively.  He worked as a post doctoral fellow at Keck Graduate Institute from June 2007 until he joined JPL in March of 2008.  During his graduate and post doctoral work, his studies focused on applications of Bayesian methods to hidden Markov models with particular interest and application to protein sequencing.  His work at JPL has focused on integrating web services into various programming platforms for the purposes of accessing NASA satellite data, as well as developing object tracking so ftware and contributing to image enhancement and restoration efforts Van Dang is a member of the Science Data Understanding Group at the Jet Propulsion Laboratory. She was responsible for the NEWS Level 2 processing that generated the formal merged Level 2 data from multiple A-Train instruments  Manuel de la Torre is a Physicist from the Universidad Complutense at Madrid \(Spain\. After finishing his Ph.D work at the University of Bayreuth \(Germany\ on pattern formation in turbulent flows and a 7 1/2 year stunt as Ass and Assoc. Prof. at the Escuela T\351cnica Superior de Ingenieros Aeron\341uticos in Madrid \(Spain\, he came to the Jet Propulsion Laboratory on a 1-year Sabatical leave in 1997 wanting to apply fundamental concepts of nonlinear systems and geophysical fluid dynamics to something that might be directly useful to soci ety. He discovered the JPL as a great place to achieve that goal and extende d his stay a bit longer, becoming Technical staff and working on different aspects of remote sensing, validation of satellite instruments, and data analysis of atmospheric processes and climate  


