AFOPT Algorithm for Multi-level Databases Robert Gy 001\030 r\366di  Cornelia Gy 001\030 r\366di  Mirela Pater  Ovidiu Boc  Zoltan David   Assistant professor Phd. Eng  Lecturer Eng. Phd. Student  MSc student Department of Computer Science, Faculty of Electrotehnics and Informatics University of Oradea, Str. Un iversitatii, Nr. 1, Oradea, Romania 
Phone: +40 259 408-226, E-Mail rgyorodi@rdsor.ro   cgyorodi@uoradea.ro  mirelap@uoradea.ro Abstract With the widespread compu terization in business government, and science, the efficient and effective discovery of interesting information from large databases becomes essential. Previous studies on data mining have been focused on the discovery of knowledge at single conceptual level, either at the primitive level or at a rather high conceptual level This paper presents an algorithm based on the AFOPT algorithm for multi-level databases that uses the 
benefits of multileveled databases, by using the information gained by studying items from one concept level for the study of the items from the following concept levels 1. Introduction Finding frequent itemsets and building accurate and efficient classifiers for large databases is one of the essential tasks of data mining and machine learning research The aim of data mining is th e discovery of patterns within data stored in da tabases. Mining for association rules is a data mining method that lends itself to formulating conditional statements such as \215if customers buy product x th en they also buy product y\215 Extensive efforts have bee n devoted to developing efficient algorithms for mining frequent patterns 
Following the pioneering work  algorithms adopting the candidate generate-and-test approach are proposed. Apriori algorithm  first algorithm which uses the Apriori property to prune the search space Some researchers have noticed the long pattern problem and suggested mining only frequent closed patterns [6   5  o r  only m a xim al fre que nt patterns  1    A frequent pattern is closed if all of its proper supersets are less frequent than it A frequent pattern is maximal if none of its proper superset is frequent Most of the previous studies use an Apriori-like approach, which is based on an anti-monotone Apriori  k pa 
ttern is not frequent in the database, its length \(k +1\ super-pattern can not be frequent. The Apriori heuristic achieves good performance gain by reduci ng the size of candidate sets. However, in situations with prolific frequent patterns, long patterns, or quite low minimum support thresholds, an Apriori-like algorithm may still suffer because it is costly to handle a huge number of candidate sets and it is tedious to repeatedly scan the database and check a large set of candidates by pattern matching, especially true for mining long patterns AFOPT\220s efficiency of mining is achieved with three techniques [5    1\abase is compressed into a highly condensed, much smaller data structure, which avoids 
costly, repeated database scans  2\-tree-based mini ng adopts a pattern fragment growth method to avoid the costly generation of a large number of candidate sets  3\de-and-conquer method is used to decompose the mining task into a set of smaller tasks for mining confined patterns in conditional databases, which dramatically reduces the search space It can be stated as follows: Let I  i 1 i 2 203. , i n be a set of items and D  
t 1 t 2 t N be a transaction database, where t i  i 000\217 1 N  transaction and t i 000\216 I Every subset of I is called an itemset If an itemset contains k items, then it is called a k itemset. The support of an itemset l in 
D is defined as the percentage of transactions in D containing l If the support of an itemset exceeds a user-specified minimum support threshold, then the itemset is called a frequent itemset 2. Multi-level Databases With widespread applications of computers and automated data collection tools, massive amount of Proceedings of the Seventh International Symposium on Symbo lic and Numeric Algorithms for Scientific Computing \(SYNASC\22205 0-7695-2453-2/05 $20.00 \251 2005 IEEE 


transaction data have been collected and stored in databases. In this paper, we first introduce the conceptual hierarchy, a hierar chical organization of the data in databases. The problem of finding single level rules in databases has been studied extensi Mining knowledge at multiple levels is both practical and desirable, and thus is an interesting research direction.  Studies on mining association rules have evolved from techniques for discovery of functional dependen cies, strong rules, classification rules, etc. to disk based ef ficient methods for mining association rules in large sets of transaction data However, previous work has been focused on mining association rules at single conceptual level. There are applications that need to find associations at multiple conceptual levels. For example, besides finding that 70% of customers that purchase milk may also purchase bread, it could be informative to also show that 65% of customers that purchase wheat bread may also purchase 2% milk Multilevel databases us e hierarchy-information encoded transaction table, in the transaction table each item is encoded as a sequence of digits \(Table 1 Figure 1. Hierarchy-based multi-level database Table 1, contains category codes and a description for each code \(category or item\ which is only needed for the final display. The c odes and the descriptions for Table 1 are extracted from Figure 1 Table 1. Multi-level items Code Description  0 All Electronics 1 Computer 2 Printers 3 Scanners 4 Monitors 5 Keyboards 1.1 Desktop 1.2 Laptop 2.1 Compaq 2.2 HP 3.1 Mustek 4.1 Philips 5.1 Tech 1.1.1 Athlon 1.1.2 Pentium We assume that a multi-level database contains a\ item data set which contains the description of each item in I in the form of i j  description\ where i j is the  product\220s  code b\nsaction data set, defined as above D A transaction is in the format of \(TID i j  Where TID is a transaction identifier and i j 000\217 I is an item from the item data set Table 2. Transactions from database TID Items T1 3.1.1     1.2.2     2.2.3     2.1.1    1.1.4   1.1.2 T2 2.1.2     4.1.1     1.2.2    1.1.2     3.1.1 T3 2.1.2     4.1.2     5.1.3    1.1.2 T4 1.2.3     1.1.2     3.1.1    4.1.1 T5 1.1.2     3.1.1     1.2.3    1.2.2 3. AFOPT for Multi-level Databases To get the information needed for the k concept level there are 2 methods 1 directly use AFOPT on the requested concept level [4 2 if information from a level lower than k is available, information for the k level can be obtained from l level l  k T without scanning the database, or by scanning just a few transactions The algorithm is obtained by extending the AFOPT algorithm for multi-level databases. By using the AFOPT algorithm no candidate sets are being generated, thus the top-down progressive method doesn\220t really help. The in formation gained at a high concept level is insufficient for the following concept levels. Thus, a new scan of the database is required to get the missing information This way, to get inform ation from the lowest concept level will require at least n 1 scans of the database. In conclusion, this method is inefficient when using pattern algorithms. Still, when getting information from the lowest level, the AFOPT algorithm, directly used on the last concept level, is faster than candidate generati on and testing algorithms for multi-level Like in AFOPT, this algo rithm first traverses the original database to find frequent items or frequent abstract levels. These are sorted in ascending order and sort them in ascending frequency order Then the original database is scanned the second time to construct an AFOPT structure to rep resent the conditional databases of the frequent items.  First, a header is constructed, using only the items that pass the minimum support threshold, and which are ordered in an ascending order, unlike in the FP-Growth algorithm where the items are in descending frequency order Proceedings of the Seventh International Symposium on Symbo lic and Numeric Algorithms for Scientific Computing \(SYNASC\22205 0-7695-2453-2/05 $20.00 \251 2005 IEEE 


Table 3. Items Table 4. Frequent items The conditional database of an item i includes all the transactions containing item i with infrequent items and those items before i removed from each transaction. Arrays are used to store single branches in the AFOPT structure to save space and construction cost. Each node in the AFOPT str ucture contains three pieces of information: an item id, the count of the itemset corresponding to the path from the root to the node, and the pointers pointing to the children of the node Figure 2. AFOP tree In step 1 and step 2, the counts for each individual item is gathered; and the complete information about the transaction database is compressed in the AFOPT structure. They are realized at the cost of two database scans. From now on, the pattern generation process is started by recursively visiting the AFOPT structure Note that no more costly database operations will be involved This method allows us to obtain information for level k when we have already obt ained the results for level l which is a lower concept level than k  The FP-Tree obtained for level l contains almost all information to build th e FP-Tree required for level k  the only information missing is the one from the items that did not meet minimum support. These items may affect the k level FP-Tree Step 1 Create New k level Header The new k level FP-Tree needs a header which has k level items.  We can obtain it using information from section 2. This header is partial and may be completed at step 2 Figure 3. Constructing k header Step 2 Complete the headers ete the l header we already have with the missing items. To do this, we have to read the missing nodes to the header which is quite easy if the header was saved before the pruning step, or the items were just hidden instead of being removed Table 5&6. Completing headers For each added item to the l level header we add the corresponding item to the k level header, and get its support. If, in the k level it doesn\220t meet minimum support, it is pruned; its co rresponding items from the l header are also pruned \(even though it was just added\After this step we have the 2 headers from the k and l levels Step 3 Complete l level tree We also have to read to the tree the transactions that contain the added nodes. This means accessing the database, however only a few transactions are needed as opposed to 2 full scans of D when using method I Table 7: Re-Added transactions TID Items  T1 2.1.1    1.1.4     1.2.2    3.1.1    1.1.2 T2 Not re-added T3 4.1.2     2.1.2    1.1.2 T4 Not re-added T5 Not re-added In Figure 5, notice that item 5.1.3 and 2.2.2 were not added \(or were added but removed\because their corresponding k-level items \(item 5.1 and 2.2\not meet minimum support. Also, the transactions which contained these items were not added to the tree Item Sup 3.1.1 4 1.2.2 3 2.2.3 1 2.1.1 1 1.1.4 1 1.1.2 5 2.1.2 2 4.1.1 2 4.1.2 1 5.1.3 1 1.2.3 2 Item Sup 4.1.1 2 2.1.2 2 1.2.3 2 1.2.2 3 3.1.1 4 1.1.2 5 2.1.1 1 2.2.3 1 4.1.2 1 1.1.4 1 5.1.3 1 l Level Sup 2.1.1 1 2.2.3 1 4.1.2 1 1.1.4 1 5.1.3 1  4.1.1 2 2.1.2 2 1.2.3 2 1.2.2 3 3.1.1 4 1.1.2 5 k Level Sup 2.1 3 2.2 1 4.1 3 1.1 5 5.1 1  4.1 2.1 1.2 1.2 3.1 1.1 Proceedings of the Seventh International Symposium on Symbo lic and Numeric Algorithms for Scientific Computing \(SYNASC\22205 0-7695-2453-2/05 $20.00 \251 2005 IEEE 


Figure 5. Completing l level FP-Tree Step 4 Reorder k level header  The k level tree header was completed at step 2 and contains item IDs corresponding to concept level k  They might need to be reordered by support. To find the missing support of the items from level k we use a recursive algorithm on the l level FP-Tree Table 8. Ordered k-header k Level Sup  2.1 3 4.1 3 3.1 4 1.2 4 1.1 5 Starting from the root and going downwards 1. the support for category 1 \(for example\203 be the support of the first-found item that is part of category 1 \(item 1.1 or 1.1.1 etc 2. if we get to a crossing \(and first item was not found\branch and the support will be the sum of the result of each branch Step 5 Create k level tree  Starting from each terminal item of the l level tree we follow their conditional patterns and extract all the k level items that appear and their support. If a k item appears more than once we consider it only once but sum their supports. We creat e an itemset \(see Table 2 which is added to the new k level tree just like a transaction would be added to an FP-Tree In the end a k level FP-Tree is obtained \(Figure 6 from which, by using the FP-Growth algorithm, we can obtain the frequent itemset s from the first concept level Figure 6. K-level FP-Tree Although it is rare in practice, if no items were pruned from the l level FP-Tree, then steps 1 & 3 are not required, and the database is not accessed at all Thus, if we have the FP-Tree for the lowest concept level with no pruned ite ms, then we can obtain information for any concept level without accessing the database. This is useful to know when we need information for more than one concept level 4. Performance Study Items in the FP-tree are sorted in descending frequency order and these branches are traversed bottom-up, therefore the items in these branches resulted from the traversal\d in ascending frequency order. If these branches are used to build a prefix-tree, it is exactly the AFOPT structure We traverse the AFOPT structure in top-down depth-first order. Each node is visited exactly once The total number of node visits of the FP-Growth algorithm is equal to the total length of its branches The total number of nodes visit of the AFOPT algorithm is equal to th e size of the AFOPT structure which is smaller than th e total length of the n fp branches. Therefore the AFOPT algorithm needs less traversal cost than the FP-Growth algorithm As a result, if we apply the AFOPT and FP-Growth directly on level 3 of a database \(method 1 to obtain the pattern trees after the database scanning which lasts the same for both algorithms\get the following result \(Figure 7 Figure 7. AFOPT vs. FP-Growth If information from a lower level is available saved on either a disk or in memory\use method 2, and thus, there won\220t be any need to scan the database entirely It is possible that all the co nditional databases of a frequent itemset\220s frequent extensions can be represented by a single bran ch using FP-tree structure but the AFOPT structure requ ires multiple branches. In this case, both algorithms do not need to construct new conditional databases, bu t the AFOPT algorithm needs more traversal cost. However the possibility that this Proceedings of the Seventh International Symposium on Symbo lic and Numeric Algorithms for Scientific Computing \(SYNASC\22205 0-7695-2453-2/05 $20.00 \251 2005 IEEE 


situation happens is much lo wer than the possibility that a single conditional da tabase can be represented by a single branch 2 For the AFOPT algorithm additional traversal cost is caused by the push right step. If we did not have this step we would get a conditional database which consists of multiple subtrees. The number of subtrees constituting the conditional database is exponential to the number of items before that item in worst case While the number of merging operations needed is equal to the number of ite ms before that item in worst case. To save the traversal co st, it is better to perform the merging operation The items are sorted in descending frequency order in FP-tree, which improves th e possibility of prefix sharing. Hence FP-tree is more compact than the AFOPT structure. Applying the algorithm at section 3 on an AFOPT structure will be about the same as applying the transformation on a FP-Tree, because the same \(maximal\quent patterns are extracted, the only difference being the order \(reversed\On the other hand, as stated earlier, the AFOPT algorithm needs less traversal cost than the FP-growth algorithm Thus, the use of the AFOPT algorithm is more recommended Experiments were conducted on a 1.6 Ghz Athlon XP with 256 MB memory running Microsoft Windows XP Professional using a real database of 50000 entries in 6000 transactions. All codes were done in Java and compiled using the Eclipse Platform 5. Conclusions General frequent pattern mi ning algorithms focus on mining at single level This way only strong association rules between items will be discovered. For multi-level frequent pattern mining, mining algorithms have to be extended Mining knowledge at multiple levels is both practical and desirable and makes possible the usage of the second method The importance of multi-level frequent patterns goes far beyond market-basket analysis because they serve as an estimation of jo int probabilities of events and therefore are useful whenever such estimation is required The AFOPT algorithm trav erses the trees in topdown depth-first order, and the items in the prefix-trees are sorted in ascending frequency order The combination of these two methods is more efficient than the combin ation of the bottom-up traversal strategy and descending frequency order which is adopted by the FP-Growth algorithm. Both of the above two combinations are much more efficient than the other two combinations \205 the combination of the top-down traversal strategy and the descending frequency order, and the combination of the bottom-up traversal strategy and the ascending frequency order Using method 2 to obtain a AFOPT tree, only a few items will be added and a full database scan will not be required. Considering the fact that database scanning is slow, this is a great advantage 6. References  Agarwal, R.C., Aggarwal, C.C and Prasad, V.V.V  215Depth first generation of long patterns\216 In Proceedings of the 6th ACM SIGKDD Conference,  ACM Press pp. 108\205 116  2000  Agrawal R., Ma nnila H., Srik an t R., Toivon en H., and  Verkamo A.I., \215Fast discovery of association rules\216 In Advances in Knowledge Discovery and Data Mining pp 307\205328, 1996  Agrawal R. and Strikant R., \215Fast algorithms for mining association rules\216 In Proc. 1994 Int. Conf. Very Large Data Bases VLDB\22095\, Chile, pp. 487-499, 1994  Liu, G., Lu, H Lou, W., Xu, Y and Xu Yu, J  215Efficient Mining of Frequent Patterns Using Ascending Frequency Ordered Prefix-Tree\216 Data Mining and Knowledge Discovery, 9, 249\205274 2004   Liu, G., Lu, H Lou, W., Xu, Y and Xu Yu, J  215Ascending Frequency Ordered Prefix-tree: Efficient Mining of Frequent Patterns\216 In Proc. of KDD Conf 2003  Pasquier, N., Bast ide Y Taouil R., and Lakha l, L    215Discovering frequent closed itemsets for association rules\216 In Proceedings of 7th ICDT Conference, Springer 1999 pp 398\205416 Proceedings of the Seventh International Symposium on Symbo lic and Numeric Algorithms for Scientific Computing \(SYNASC\22205 0-7695-2453-2/05 $20.00 \251 2005 IEEE 


The rule above says that for any application XYZ under App Paths the No Name key has the value Path>\\$&XYZ where Path corresponds to the value of the subsumed key Path  The use is described below Fault Diagnosis Fault diagnosis of Windows systems based on registries viz the Change and Con\336guration Management CCM is one of the prominent applications of the proposed approach Section 3 described a few drawbacks of the current registry model for CCM studies mRegistry helps in retrieving relev ant differences thereby reducing the number of differences between cross-machine registry snapshots This is evident as Algorithm 1 captures the relationships within a hive and replaces them with pattern variables For the example described above in 1 as a rule for registries across different machines irrespective of the location an application is installed the No Name key\325s value remains the same  Path\\$&XYZ for an application XYZ  and so they do not differ The location is captured in Path and we create derived keys for the location and have the Path value equal to the derived key  Few other applications include Conceptualization Conceptualization is key to understanding and refers to the process of learning meaningful concepts/explanations from data Rule 1 above says that the No Name key of an application has the value equal to the application located in Path  This rule holds true on all the 20 registry snapshots that we explored Many such rules have been learned using the proposed approach Compression Another important application of the proposed approach considering the large size of registry databases is that of compression Compression is achieved as follows by the creation of derived keys at a parent node we just substitute the derived key in the leaves The size of the derived key being much smaller than that of the actual value results in compression Another source of compression is conceptualization As discussed in section 4 by forming rules and generalized descriptions using regular expressions we can remove those entries corresponding to the consequents of rules from the registry and use the rules instead Thi s results in the removal of a lot of registry entries And while comparison between registries we can use the rule s/concepts We can call this as semantic compression  For the 20 registry snapshots we experimented we noticed a compression ratio between 000 001 002 and 000 001 003  Prediction However large our databases may be with users constantly installing new softwares it might be possible that we may come across a registry hive/entry that is not present in our database In such cases prediction of the entries depending on the rules formulated would provide some clue For example for any new legacy driver we know that the Class e would e LegacyDriver and the Service e would e the XYZ for a driver keyed LEGACY_$&XYZ 6 Conclusions and Future Work In this paper we proposed a novel representation of registries called mRegistry that is concept-based capturing the intra-block inter-block and ancestor-child dependencies among the registry entries Algorithms for 336nding these associations are presented and discussed mRegistry depicts the dependencies using pattern variables and rules With its compact representation mRegistry achieves some compression and results in ef\336cie nt comparison between crossmachine registry snapshots mRegistry is also applicable in fault diagnosis and in the prediction of certain unforeseen entries in the registry based on the concepts learned mRegistry is designed considering only the ASCII string entries in the registry It might be possible that there exist meaningful semantic relationships between some binary entries We would like to extend the current work to incorporate the ignored entries with complementary usage of domain knowledge and explore new representations as future work References 1 A  G anapat hi  Y  M W a ng N L a o and J  R  W e n W h y P C s are Fragile and What We Can Do About It A Study of Windows Registry Problems In Proceedings of IEEE DSN/DCC  2004 2 K  I v e n s  Optimizing the Windows Registry  IDG Books 1998 3 E  K i c i m an and Y  M W a ng Di sco v e r i ng C o r r ect ness C onstraints for Self-Management of System Con\336guration In Proceedings of Int Conf Autonomic Computing  2004 4 J  A  R edst one M  M  S wi f t  a nd B  N B e r s had Usi n g C omputers to Diagnose Computer Problems In Proceedings of HotOS  2003 5 S u n M ic ro Sy ste m s Pre d ic ti v e Se lf-He a lin g i n t h e So la ris\252 1 0 Operating System White paper 2004 6 H  J  W ang J P l at t  Y  C h en R  Z hang and Y  M W a ng PeerPressure A Statistical Method for Automatic Miscon\336guration Troubleshooting Technical report Microsoft Research 2003 7 Y  M W a ng C o mput er Genomi c s T o w a r d s S el f C hange and Con\336guration Management T echnical report Microsoft Research 2004 8 Y  M W a ng C  V e r b o w ski  J Dunagan Y  C h en H  J  W ang C Yuan and Z Zhang STRIDER A Black-box Statebased Approach to Change and Con\336guration Management and Support In Proceedings USENIX LISA  pages 159\320171 2003 Proceedings of the 2005 5th International Conference on Intelligent Systems Design and Applications \(ISDA\22205 0-7695-2286-06/05 $20.00 \251 2005  IEEE 


   retail dataset 0 20 40 60 80 100 120 140 160 180 0.17 0.11 0.08 Support Time in seconds BifoldLeap \(Q only DualMiner \(Q only BifoldLeap \(P only DualMiner \(P only BifoldLeap \(P & Q DualMiner \(P & Q retail dataset 0 20 40 60 80 100 120 140 160 180 0.17 0.11 0.08 Support Time in seconds BifoldLeap \(Q only DualMiner \(Q only BifoldLeap \(P only DualMiner \(P only BifoldLeap \(P & Q DualMiner \(P & Q retail dataset 0 0.5 1 1.5 2 2.5 3 3.5 4 4.5 0.17 0.11 0.08 Support Time in seconds BifoldLeap \(P & Q DualMiner \(P & Q Figure 2 A Pushing   and  B More selective constraints C Extremely selective constraints dataset with absolute support equal to 25 50 and 75 using the two different distributions We used a modiìed version of MAFIA with post-processing as the post-processing counterpart to Dualminer Our implementation of Dualminer always tests minimum support and P together while BifoldLeapês minimum support checks occur at different times and do not contribute to the count for  Figure 4 depicts the results of these experiments Our rst observation is that Dualminer performs a huge number of constraint evaluations as compared to BifoldLeap Even in cases where we only generated 255 patterns Dualminer needed more than 50 thousand evaluations for both and  compared to almost 6 thousand needed by BifoldLeap Our second observation is that MAFIA with post-processing requires fewer constraint evaluations than Dualminer retail dataset 0 20 40 60 80 100 120 140 160 0.17 0.11 0.08 Support Time in seconds BifoldLeap \(z-distribution DualMiner \(z-distribution BifoldLeap \(uniform-distribution DualMiner \(uniform-distribution Figure 3 A Scalability test B Effect of changing the price distribution 5.4 Different Distributions All of our experiments were conducted using uniform and/or zipf price distributions In most of the experiments we found that the effect of changing the distribution on Dualminer was greater than for BifoldLeap This can be justiìed by the effectiveness of the pruning techniques used by BifoldLeap that also reduce the number of candidate checks which consequently affected its performance Figure 3.B depicts one of these results for the retail dataset 6 Related work Mining frequent patterns with constraints has been studied in where the concept of monotone and anti-monotone and Figure 4 No of and evaluations using constraint pushing vs post-processing succinct were introduced to prune the search space Jian Pei et al 14 h a v e also generalized these tw o classes of constraints and introduced a new convertible constraint class In their work they proposed a new algorithm called which is an FP-Growth based algorithm This algorithm generates most frequent patterns before pruning them Its main contribution is that it checks for monotone constraints early and once a frequent itemset is found to satisfy the monotone constraint then all itemsets having this item as a preìx are sure to satisfy the constraint and consequently there is no need to apply further checks Dualminer is the rst algorithm to mine both types of constraints at the same time Nonetheless it suffers from many practical limitations and performance issues First it is built on the top of the MAFIA algorithm which produces the set of maximal patterns and consequently all frequent patterns generated using this model do not have their support attached Second it assumes that the whole dataset can t in main memory which is not always the case FP-Growth and our approach use a very condensed representation namely FPTree which uses signiìcantly less memory Third their top-down computation exploiting the monotone constraint often performs many useless tests for relatively large datasets which raises doubts about the performance gained by pushing constraints in the Dualminer algorithm In a recent study of par7 Proceedings of the Fifth IEEE International Conference on Data Mining \(ICDMê05 1550-4786/05 $20.00 © 2005 IEEE 


allelizing Dualminer 16 the authors sho wed that by mining relatively small sparse datasets consisting of 10K transactions and 100K items the sequential version of Dualminer took an excessive amount of time Unfortunately the original authors of Dualminer did not show any single experiment to depict the execution time of their algorithm but only the reduction in predicate executions A recent strate gy dealing with monotone and anti-monotone constraints suggests reducing the transactional database input via pre-processing by successively eliminating transactions that violate the constraints and then applying any frequent itemset mining algorithm on the reduced transaction set 4 The main drawback of this approach is that it is highly I/O bound due to the iterative process needed in rewriting the reduced dataset to disk This algorithm is also sensitive to the results of the initial monotone constraint checking which is applied to full transactions In other words if a whole transaction satisìes the monotone constraint then no pruning is applied and consequently no gains are achieved even if parts of this transaction do not satisfy the same monotone constraint To overcome some of the issues in the same approach has been tested against the FP-Growth approach in with ne w effective pruning heuristics 7 Conclusion Since the introduction of association rules a decade ago and the launch of the research in efìcient frequent itemset mining the development of effective approaches for mining large transactional databases has been the focus of many research studies Furthermore it is widely recognized that mining for frequent items or association rules regardless of its efìciency usually yields an overwhelming crushing number of patterns This is one of the reasons it is argued that the integration of data mining and database management technologies is required These large sets of discovered patterns could be queried Expressing constraints using a query language could indeed help sift through the large pattern set to identify the useful ones We argue that pushing the consideration of these constraints at the mining process before discovering the patterns is an efìcient and effective way to solve the problem This does not exclude the integration of data mining and database systems but suggests the need for data mining query languages intricately integrated with the data mining process In this paper we address the issue of early consideration of monotone and anti-monotone constraints in the case of frequent itemset mining We propose a leap traversal approach BifoldLeap  that traverses the search space by jumping from relevant node to relevant node and simultaneously checking for constraint violations The approach we propose uses existing data structures FP-tree and COFI-tree but introduces new pruning techniques to reduce the search costs We conducted a battery of experiments to evaluate our constraint-based search and report a fraction of them herein for lack of space The experiments show the advantages of pushing both monotone and anti-monotone constraints as early as possible in the mining process despite the overhead of constraint checking We also compared our algorithm to Dualminer a state-of-the-art algorithm in constraint-based frequent itemset mining and showed how our algorithm outperforms it and can nd all frequent itemsets the closed and the maximal patterns that satisfy constraints along with their exact supports References  R Agra w al T  Imielinski and A Sw ami Mining association rules between sets of items in large databases In Proc 1993 ACM-SIGMOD Int Conf Management of Data  pages 207Ö216 Washington D.C May 1993  R Agra w a l and R Srikant F ast algorithms for mining association rules In Proc 1994 Int Conf Very Large Data Bases  pages 487Ö499 Santiago Chile September 1994  I Almaden Quest synthetic data generation code http://www.almaden.ibm.com/software/quest/Resources/index.shtml  F  Bonchi F  Giannotti A Mazzanti and D Pedreschi Examiner Optimized level-wise frequent pattern mining with monotone constraints In IEEE ICDM  Melbourne Florida November 2004  F  Bonchi and B Goethals Fp-bonsai the art of gro wing and pruning small fp-trees In Paciìc-Asia Conference on Knowledge Discovery and Data Mining PAKDDê04  pages 155Ö160 2004  F  Bonchi and C Lucchese On closed constrained frequent pattern mining In IEEE International Conference on Data Mining ICDMê04  Brighton UK November 2004  C Bucila J Gehrk e D Kifer  and W  White Dualminer A dual-pruning algorithm for itemsets with constraints In Eight ACM SIGKDD Internationa Conf on Knowledge Discovery and Data Mining  pages 42Ö51 Edmonton Alberta August 2002  D Burdick M Calimlim and J Gehrk e Maìa A maximal frequent itemset algorithm for transactional databases In ICDE  pages 443Ö452 2001  S Chaudhuri Data mining and database systems Where is the intersection Bulletin of the Technical Committee on Data Engineering  21 March 1998  M El-Hajj and O R Za  ane Non recursive generation of frequent k-itemsets from frequent pattern tree representations In Proc of 5th International Conference on Data Warehousing and Knowledge Discovery DaWakê2003  September 2003  Frequent itemset mining implementations repository  http://ìmi.cs.helsinki  J Han J Pei and Y  Y in Mining frequent patterns without candidate generation In ACM-SIGMOD  Dallas 2000  L Lakshmanan R Ng J Han and A P ang Optimization of constrained frequent set queries with 2-variable constraints In ACM SIGMOD Conference on Management of Data  pages 157Ö168 1999  J Pie and J Han Can we push more constraints into frequent pattern mining In ACM SIGKDD Conference  pages 350Ö354 2000  J Pie J Han and L Lakshmanan Mining frequent itemsets with convertible constraints In IEEE ICDE Conference  pages 433Ö442 2001  R M T ing J Baile y  and K Ramamohanarao P aradualminer An efìcient parallel implementation of the dualminer algorithm In Eight Paciìc-Asia Conference PAKDD 2004  pages 96Ö105 Sydney Australia May 2004  O R Za  ane and M El-Hajj Pattern Lattice Traversal by Selective Jumps In In Proc 2005 Intêl Conf on Data Mining and Knowledge Discovery ACM SIGKDD Chicago IL USA  pages 729Ö735 August 2005 8 Proceedings of the Fifth IEEE International Conference on Data Mining \(ICDMê05 1550-4786/05 $20.00 © 2005 IEEE 


on the intention to use self- and e-assessment center as well as the influence of PQI, PCS and PTS on PU it might represent a single example for a specific economy, country or cultural region . There might be differences for the intention of different informnation systems with different settings. Future research should discuss this issue more detailed  Furthermore our questionnaire was just answered by large-scale corporations in Germany. So our results might not be directly transferred to small and medium-sized enterprises  In addition, as we collected our data from participants at the same time using the same survey our results may be affected by common method varian  6. Conclusion  Self-assessment and e-assessment as online games in staff recruiting are a valuable solution for companies to support on the one side their employer branding activities and on the other side the selection of the favored candidate. The case study of our papers shows that companies can generate more qualified applications and concurrently save time and money. Based on these findings our empirical research with 191 of the Top-1000 companies of Germany provide statistical evidence that perceived quality improvements, perceived cost savings and perceived time savings are the main reasons beside perceived usefulness and ease of use why companies intend to use self- and e-assessment in their recruiting processes  References   Bago zzi  R  P   T h e Ro l e  of M easu r e m en t i n T h eo ry Construction and Hypothesis Testing: Toward a Holistic Model", in: Conceptual and Theoretical Developments in Marketing, O.C. Ferrell, S.W. Brown and C.W. Lamb eds.\ago, pp. 15-32, 1979 2 Ba g o z z i R  P  a n d Y i  Y   O n t h e Ev a l ua tio n of  Structural Equation Models", Journal of the Academy of Marketing Science \(16\pp 74-94, 1988 3 Ba rtra m  D Testing on the Internet: Issues Challenges and Opportunities in the field of Occupational Assessments in: D. Bartram, and R.K. Hambleton \(eds Computer-Based Testing and the Internet: Issues and Advances, John Wiley & Sons, Ltd., Chichester, England 2006 4 B r o w n, S  A  a nd Ve nk a t e s h V  Model of Adoption of Technology in Households: A Baseline Model Test and Extension Incorporating Household Life Cycle MIS Quarterly \(29:3\pp.399-426, 2005  Bu zzetto M o r e N A   and A l ad e A  J   Best Practices in e-Assessment Journal of Information Technology Education, 2006, Vol. 5, pp. 251-269 6 Ca lig iuri P  M., a n d P h i llips J.M An application of self-assessment realistic job previews to expatriate assignments The International Journal of Human Resource Management, 2003, Vol. 14, No. 7, pp. 11021116 7 Ca rm ine s E. G  Ze lle r R A  1979 Re lia bil ity a nd Validity Assessment. Beverly Hills, CA: Sage Publications 8 Ca s c io, W  F A pplie d P s y c ho log y in H u m a n Re s ourc e  Management, Prentice Hall, Englewood, Cliffs, NJ, 1998 9 Cha p p e ll, D Ea t oug h V D a v i e s M.N  O  a n d  Griffiths, M EverQuest It s Just a Comupter Game Right? An Interpretative Phenomenological Analysis of Online Gaming Addicition International Journal of Mental Health and Addiction, Vol. 4, No. 3, pp. 205-216 10 C h in, W  W  T he P a rtia l L e a s t Squa re s A pproa c h to  Structural Equation Modelling", in: Modern methods for business research, G.A. Marcoluides \(ed.\, Lawrence Erlbaum Associates, London, pp. 295-336, 1998 11 Ch in, W  W  F re que ntly A s k e d Q u e s tions  Partial Least Squares & PLS-Graph", 2000 12 hill J. R a n d G ilbe r t, A  A P a ra dig m  f o r Developing Better Measures of Marketing Constructs  Journal of Marketing Research 15 \(2\pp. 77-94, 1979 13 C o n nol ly T a nd Sta n s f ie ld M  Using GamesBased eLearning Technologies in Overcoming Difficulties in Teaching Information Systems Journal of International Technology Education, 2006, Vol. 5, pp. 459-476 14 D a v i s  F. D   1 9 89  P e r c e i v e d U s ef ulne s s  P e r c e i v e d Ease of Use and User Acceptance of Information Technology. MIS Quarterly, 13:3, pp. 319-339 15 D o ll, W  J A  H e ndric k s on, a n d X  D e ng  Using Davis s Perceived Usefulness and Ease-of-use Instruments for Decision Making: A Confirmatory and Multigroup Invariance Analysis  Decision Sciences 29\(4\, 1998, pp 839-869 16 Eis e n h a r dt, K   M. \(1 98 9 ilding T h e o rie s f r om Ca s e  Study Research, Academy of Management Review, 14, 4 532-550 17  Fa e r be r, F  K e im T a nd W e itz e l T  An Automated Recommendation Approach to Personnel Selection  In: Proceedings of the 2003 Americas Conference on Information Systems; Tampa 18  Fe ng M H e ff e r na n, N  T a nd K o e d ing e r, K  R  Addressing the Testing Challenge with a Web-Based EAssessment System that Tutors as it Assesses  Proceedings of the 15th international conference on World Wide Web, Edinburgh, Scotland, 2006, pp. 307-316 19  For n e ll, C a n d L a rc ke r, D F E v a lua ting S t ruc tura l  Equitation Models with Unobservable Variables and Measurement Errors", Journal of Marketing Research, 18 pp. 39-50, 1981 20 G e org e  D I., a nd Sm ith, M.C An Empirical Comparison of Self-Assessment and Organizational Assessment in Personnel Selection Public Personnel Management, 1990, Vol. 19, No. 2, pp. 175-190 Proceedings of the 42nd Hawaii International Conference on System Sciences - 2009 9 


21 G r iff iths, M.D., Da v i e s  M.N.O., a nd Cha p p e ll, D  Breaking the Stereotype: The Case of Online Gaming  CyberPsychology & Behavior. January 1, 2003, Vol 6, No 1, pp. 81-91 22 Hu l l an d  J U se o f P a rtial L e a s t Sq u a res \(P L S  in   Strategic Management Research: A Review of Four Recent Studies. Strategic Management Journal, 20 \(4\, pp. 195204, 1999 23 J o ne s L a nd Fle t c h e r C  Self-assessment in a selection situation: An evaluation of different measurement approaches Journal of Occupational and Organizational Psychology, 2002, Vol. 75, pp. 145-161 24 K e im T  a nd W e itz e l  T  Strategies for Hiring IT Professionals: An Empirical Analysis of Employer and Job Seeker Behavior on the IT Labor market In: Proceedings of the 2006 Americas Conference on Information Systems AMCIS\ulco, Mexico 25 L a um e r S Ec k h a r dt, A a nd W e itz e l T   Recruiting IT Professionals in a Virtual World In: Proceedings of the 12th Pacific Asia Conference on Information Systems PACIS 2008\uzhou, China 2 L e e I   The Architecture for a Next-Generation Holistic E-Recruiting System Communications of the ACM, Vol. 50, No. 7, 81-85, 2007 27 L e v i ne E.L Flory  A   a nd A s h, R.A  Selfassessment in personnel selection Journal of Applied Psychology, 1977, Vol. 62, No. 4, pp. 428-435 28  Ma lho t ra Y., a n d G a lle tta D. F Extending the Technology Acceptance Model to Account for Social Influence Theoretical Bases and Empirical Validation  Proceedings of the 32 nd Hawaii International Conference on System Sciences 2 Lo u H Lu o  W  and St r ong D  2 00 0   Perceived Critical Mass Effect on Groupware Acceptance  European Journal of Information Systems 9\(2\p.91-103 30 N u nna lly J  C., a nd Be rns t e i n, I. H  Psychometric Theory 3rd ed.\ McGraw-Hill, New York, 1994 31 Phil lips  J.M  Effects of Realistic Job Previews on Multiple Organizational Outcomes: A Meta-Analysis  Academy of Management Journal, 1998, Vol. 41, No. 6 pp. 673-690 3  P o d s ako f f  P   M    M acKen zie S  B  L ee J Y  Podsakoff, N. P. \(2003\. Common Method Bias in Behavioral Research: A Critical Review of the Literature and Recommended Remedies. Journal of Applied Psychology, Vol. 88, No. 5, pp. 879-903 33 Ri dg w a y  J Mc Cus k e r, S., a nd P e a d D   Literature Review of e-Assessment Nesta Future Lab, Bristol, UK 2004 3 Ry n e s S  L   Recru i t m en t   Job Choice, and Post-Hire Consequences in: M.D. Dunnette, and L.M. Hough \(eds Handbook of Industrial and Organizational Psychology Consulting Psychologists Press, Palo Alto, CA, 1991 35 Ste i nk ue hle r   C.A  Learning in massively multiplayer online games Proceedings of the 6th international conference on Learning sciences, Santa Monica, California, 2004 36 U nde rw ood J  D  M Ba ny a r d P.E. a n d D a v i e s  M.N.O Students in digital worlds: Lost in Sin City or reaching Treasure Island BJEP Monograph Series II Number 5 - Learning through Digital Technologies Volume 1, Number 1, 1 July 2007 , pp. 83-99 36  Ve nk a t e s h V M o r r i s  M  G  un d A c k e r m a nn P  L   2000 A Longitudinal Field Investigation of Gender Differences in Individual Technology Adoption DecisionMaking Processes Organizational Behavior and Human Decision Processes, Vol. 83, Nr. 1, S. 33-60 3 W e i ss E  A    Self-Assessment Communications of the ACM, 1990, Vol. 33, No. 11, pp. 110-132 38 W a rd, M G r uppe n, L a n d Re g e hr, G  Measuring Self-assessment: Current State of the Art Advances in Health Sciences Education, 2002, Vol. 7, pp. 63-80 39 Y i n, R. K  20 03 s e Stu d y R e s e a r c h D e s i g n a nd Methods, Sage Publications, Inc., Thousand Oaks, London New Dehli Proceedings of the 42nd Hawaii International Conference on System Sciences - 2009 10 


  11 could be improved by a simple modification of the feed by adding a small tuning vane to th e feed. Therefore, it can be stated that some improvement can be expected by modification of the feeds, and adaptation of the test antenna in such a way that surrounding Ku-band element are closed   Figure 28 Reflection coefficient of Ku-band stacked patch antenna element in dual-frequency antenna stack  Figure 29 shows the influence of the L-band slots on the return loss of the Ku-band antenna element. To this end, the four connectors of the L-band elements were alternately open and terminated by means of 50 loads. The deviations were measured with respect to the set-up where all connectors were terminated Apparently, the deviations are acceptable  Figure 29 Influence of L-band termination on return loss of Ku-band antenna element, with and without termination Figure 30 and Figure 31 show the isolation between the Lband and Ku-band elements in L-band and Ku-band respectively. To this end the S21-parameters have been measured. These figures reveal that the mutual coupling between the L-band and Ku-band elements is sufficiently small  Figure 30 Measured isolation between L-band and Ku-band antennas in L-band frequencies  Figure 31 Measured isolation between L-band and Ku-band antennas in Ku-band frequencies From these measurements it can be concluded that opportunities should be considered to improve the design of the dual-frequency antenna \(by optimizing the feeds of the Ku-band elements antenna and the measurement set-up \(closure of surrounding Ku-band ports and use of appropriate connectors for the open Ku-band ports 7  M ODIFIED DUAL FREQUENCY ANTENNA  In order to benefit the str ong points of the two separate designs as discussed in section 4, an alternative antenna is proposed that exploits the properties of a \221best of both worlds\222 solution employing ideas from both designs. The modified antenna possesses an aperture fed L-band patch of a similar form to first design, but situated towards the bottom of the stack. Ku band el ements are located within the L-band perforations and para sitic patches are situated above a foam spacer \(see Figure 32 and Figure 33\A measurement campaign is underway to assess the behaviour of this modified test antenna 


  12  Figure 32 Bottom view of dual frequency antenna tile with perforated L-band patc h in lower layer with Kuband patches  Figure 33 Layer stack with perforated L-band patch in lower layer with Ku-band patches  8  B EAM FORMING N ETWORK  A major keystone for the su ccess of phased array antenna onboard aircraft is the capability of steering the main beam in the direction of the geosta tionary satellites. This requires the inclusion of a broadband beam forming network. Beam steering can be realized by adding RF-phase shifters and LNA\222s to the antenna elements of the array. However traditional phase shifters in ge neral have a narrow band, and hence do not yield the re quired broadband capability Alternative technologies for broadband beam forming are switched beam networks \(using Butler matrices innovative designs for RF-compone nts such as phase shifter LNA components in \(M\IC technology, or beam forming by using opti cal ring resonators  The German SME IMST is involved in several projects for development of electronica lly steerable phased array antennas for satellite communication. In the NATALIA project \(New Automotive Track ing Antenna for Low-cost Innovative Applications\ ESA, IMST is investigating the possibility of realizing a compact costeffective solution for a recei ve-only full electronically steerable antenna for cars in Ku-band. This antenna is a planar array composed of approximately 150 patches circularly polarised by using a 90\260 hybrid, and arranged in a hexagonal fashion. Each patc h is equipped with a MMIC corechip containing a phase sh ifting unit, LNA and digital steering logic  In the Netherlands, a consortiu m \(consisting of University of Twente, Lionix BV, National Aerospace Laboratory NLR and Cyner Substrates developing in the national FlySmart project technology for a broadband optical beam forming network. For the steering of the beam of the conformal phased array a squi nt-free, continuously tunable mechanism is proposed that is based on a fully integrated optical beam forming network \(OBFN optical ring resonators \(ORRs as tunable delay elements. A narrowband continuously tunabl e optical TTD device is realized as a recirculating wa veguide coupled to a straight waveguide. This straight wave guide can behave as a bandpass filter with a periodic, bell-shaped tunable group delay response. The maximum group delay occurs at a tunable resonance frequency. A larger delay-bandwidth product can be achieved by cascading multiple ORR sections. A complete OBFN can be obtaine d by grouping several delays and combining elements in one optical circuit. Such an OBFN can be realized on a si ngle-chip. Electrical/Optical E/O O E by means of filter based single-sideband modulation suppressing the carrier lanced coherent optical detection. Further details of the optical beamforming network have been presented in Re The proof-ofconcept has been shown by manufacturing a chip for an 8x1 OBFN. Essential components of the OBFN are the optical modulators, which are used to modulate the light in the ORR system 9  C ONCLUSIONS  For enhanced communicati on on board aircraft, novel antenna systems with broa dband satellite-based capabilities are required. So far, existi ng L-band satellite based systems for communications are used primarily for passenger application \(APC\i nistrative communications AAC and now data are tending to evolve towards broadband dig ital applications \(Voice over IP\any studies are going on worldwide to employ Kuband TV geostationary sate llites for communication with mobile terminals on aircraft The inbound traffic is about 5 times higher than the outbound The inbound traffic requires the availability of a broadband Ku-band antenna in receive mode only. The outbound traffic services can be supplied by the Inmarsat SBB link, whic h requires the installation of an L-band transmit antenna. In order to avoid both the installation of L-band antenna and Ku-band antenna, the concept of a hybrid dual frequency antenna operating L 


  13 band and Ku-band with low aerodynamic profile has been investigated in this paper. Keyaspects of this research are 200  Design and testing dual-fre quency antenna elements operating in both L-band and Ku-band 200  Conformal aspects of Ku-band phased array antennas 200  Beam forming algorithms for planar and conformal phased array antennas Two designs for dual-frequency antenna tiles consisting of 8x8 Ku-band antenna elements and one L-band element The designs have been analysed by means of computer simulations. Both designs show promising performance both in L-band and Ku-band. The design with slotted Lband antenna has a resonant fre quency in receive mode with a bandwidth of about 1 GHz. The Ku-band antenna is a stacked patch configuration where a parasitic element is placed above a lower patch separated by dedicated space filler. The manufactured protot ype antennas indicate that the bandwidth is sufficiently large In order to be able to communicate with geostationary satellites also at high latitudes e.g. during inter-continental flights\stem should have sufficient performance at low elevation angles. The antenna Ku-band system is required to have a small beamwidth \(to discriminate between the satellite signals\gain 30 dB angles. The effects of these requirements on the size and positioning of the antenna on the aircraft fuselage have been investigated. These requirements can be best satisfi ed by installing two planar phased array antennas on both side s of the fuselage with at least 1600 Ku-band elements. Each element has two feed lines, one for each polarization Every feed line has to be connected to the beam formi ng network. This means that the connections cannot be routed to one of the four sides of the antenna. Instead the concept of vertical feed lines \(by means of vias in a sufficiently thick substrate recommended. These vertical f eed lines connect the L-band and Ku-band antenna elements in the upper layer with feed networks in multiple lower laye rs. This vertical feed line system was not available so far due to manufacturing problems The performances of one dua l-frequency antenna design have been investigated by manufacturing two test antennas without vertical feed line syst em. The first antenna contains only a multilayer structure with L-band slots and 8x8 Kuband stacked patches. The performances of the L-band slots and Ku-band stacked patches c ould be measured separately It was concluded that opportun ities should be considered to improve the design of the dual-frequency antenna \(by optimizing the feeds of the Ku-b and elements the dual frequency test-antenna and the measurement set-up More important, however, is the realization of a mechanically stable vertical feed line system, so that the properties of L-band and Ku-band elements can be measured adequately The second test antenna contains only a multilayer structure with 8x8 Ku-band stacked patches and a feed network with 8 combiners, where each comb iner coherently sums 8 antenna elements. In combination with a prototype 8x1 OBFN, a Ku-band phased arra y antenna is obtained of which the beam can be steered in one direction. This second test antenna is used to analyze the broadband properties of the 8x8 Ku-band antenna array and 8x1 OBFN. The measured performances of this antenna are presented in Ref   A CKNOWLEDGMENT  This work was part of the EU 6 th Framework project ANASTASIA., and the FlySmart project, supported by the Dutch Ministry of Economic A ffairs, SenterNovem project numbers ISO53030 The FlySmart project is part of the Eureka PIDEA  project SMART Cyner Substrates is acknowle dged for technical assistance during the fabrication of the prototype antennas 


  14 R EFERENCES  1  P. Jorna, H. Schippers, J. Verpoorte, \223Beam Synthesis for Conformal Array Antennas with Efficient Tapering\224 Proceedings of 5 th European Workshop on Conformal Antennas, Bristol, September 11-12, 2007 2  The Radio Regulations, editi on of 2004, contain the complete texts of the Radio Regulations as adopted by the World Radio-communication Conference \(Geneva WRC-95 tly revised and adopted by the World Radio-communication Conference WRC-97\RadioWRC2000\and the World Radio-communication Conference WRC-03 Resolutions, Recommendations and ITU-R Recommendations incorporat ed by reference 3  RECOMMENDATION ITU-R M.1643, Technical and operational requirements for ai rcraft earth stations of aeronautical mobile-satellite service including those using fixed satellite service network transponders in the band 14-14.5 GHz \(Earth-to-space 4  ETSI EN 302 186 v1.1.1 \(2004-01 Stations and Systems \(SES\onised European Norms for satellite mobile Aircraft Earth Stations AESs\the 11 12/14 GHz frequency bands covering essential requirement s under article 3.2 of the R&TTE directive 5  EUROCAE ED-14E; Environmental Conditions and Test procedures for Airbor ne Equipment, March 2005 6  F. Croq and D. M. Pozar, \223Millimeter wave design of wide-band aperture-coupled stacked microstrip antennas,\224 IEEE Trans. Antennas Propagation, vol. 39 pp. 1770\2261776, Dec. 1991 7  S. D. Targonski, R. B. Waterhouse, D. M. Pozar Design of wide-band aperture stacked patch microstrip antennas ", IEEE Transactions on Antennas and Propagation, vol. 46, no. 9, Sep. 1998, pp. 1245-1251 8  R. B. Waterhouse, "Design of probe-fed stacked patches", IEEE Transactions on Antennas and Propagation, vol. 47, no. 12, Dec. 1999, pp. 1780-1784 9  D.M. Pozar, S. D. Targonski, \223A shared aperture dualband dual-polarised microstrip array\224, IEEE Transactions on Antennas and Propagation,Vol. 49 no. 2,Feb. 2001, pp. 150-157 10  http://www.ansoft.com 11  J-F. Z\374rcher, F.E. Gardiol, \223Broadband patch antennas\224 Artech House, \(1995\N 0-89006-777-5 12  H. Schippers, J. Verpoorte, P. Jorna, A. Hulzinga, A Meijerink, C. G. H. Roeloffzen, L. Zhuang, D. A. I Marpaung, W. van Etten, R. G. Heideman, A. Leinse, A Borreman, M. Hoekman M. Wintels, \223Broadband Conformal Phased array with Optical Beamforming for Airborne Satellite Communication\224, Proc. of the IEEE Aerospace Conference, March 2008, Big Sky, Montana US 13  H. Schippers, J. Verpoorte, P. Jorna, A. Hulzinga, L Zhuang, A. Meijerink, C. G. H. Roeloffzen, D. A. I Marpaung, W. van Etten, R. G. Heideman, A. Leinse M. Wintels, \223Broadband Op tical Beam Forming for Airborne Phased Array An tenna\224, Proc. of the IEEE Aerospace Conference, March 2009, Big Sky, Montana US 


  15  B IOGRAPHIES  Harmen Schippers is senior scientist at the National Aerospace Laboratory NLR. He received his Ph. D. degree in applied mathematics from the University of Technology Delft in 1982. Since 1981 he has been employed at the National Aerospace laboratory NLR. He has research experience in computational methods for aero-eleastics, aeroacoustic and electromagnetic problems. His current research activities are development of technology for integration of smart antennas in aircraft structures, and development of computational tools for installed antenna analysis on aircraft and spacecraft  Jaco Verpoorte has more than 10 years research experience on antennas and propagation Electromagnetic compatibility \(EMC and radar and satellite navigation He is head of the EMC-laboratory of NLR. He is project manager on several projects concerning EMCanalysis and development of advanced airborne antennas    Adriaan Hulzinga received his BEng degree in electronics from the hogeschool Windesheim in Zwolle Since 1996 he has been employed at the National Aerospace laboratory \(NLR as a senior application engineer. He is involved in projects concerning antennas and Electromagnetic compatibility \(EMC  Pieter Jorna received the M.Sc degree in applied mathematics from the University of Twente in 1999 From 1999 to 2005 he was with the Laboratory of Electromagnetic Research at the University of Technology Delft. In 2005 he received the Ph.D. degree for his research on numerical computation of electromagnetic fields in strongly inhomogeneous media Since 2005 he is with the National Aerospace Laboratory NLR\ in the Netherlands as R&D engineer   Andrew Thain is a research engineer in the field of electromagnetic modelling of antennas. He specialises in the use of surface integral methods for the calculation of coupling and radiation patterns and works closely with Airbus on the topic of antenna positioning. He has experience in the field of electromagnetic modelling  Gilles Peres is head of the Electromagnetics group of EADS-IW He has a wide experience in computational EM modelling particularly the use of FDTD, integral and asymptotic techniques for antenna structure interactions. He has contributed with Airbus experts to the certification campaign of the A340/500 and A340/600. Dr Peres holds a PhD thesis from University of Toulouse \(1998\ on impulsive Electromagnetic Propagation effects through plasma   Hans van Gemeren has a BEng degree in electronics. From the beginning of Cyner substrates he is involved in development and production of prototyping and nonconventional Printed Circuit boards Working mainly for design and research centers Cyner got involved in many high tech projects and from this developed a great expertise in the use of different \(RF materials. In the FlySmart project Hans and his colleagues are able to do what they like most: In close cooperation with designers, creatively working on substrate solutions 


  16  


NIMBUS NOAA 8 NOAA 15 NPOESS Preparatory Project Orbital Maneuvering Vehicle Orbcomm Orbiting Carbon Observatory Orbiting Solar Observatory-8 Orbview 2 Orion 1 P78 Pas 4 Phoenix Pioneer P-30 Pioneer Venus Bus/Orbiter Small Probe and Large Probe Pioneer-I 0 Polar QuikSCAT Radarsat Reuven High Energy Solar Spectroscopic Imager REX-II Rosetta Instruments Sage III SAMPEX Satcom C3 Satcom C4 SBS 5 SCATHA Seastar SMART-1 SNOE Solar Dynamics Observatory Solar Maximum Mission Solar Mesosphere Explorer Solar Radiation and Climate Experiment Solar Terrestrial Relations Observatory Space Interferometry Mission Space Test Program Small Secondary Satellite 3 Spitzer Space Telescope SPOT 5A Stardust  Sample Return Capsule STEPO STEPI STEP3 STEP4 STRV ID Submillimeter Wave Astronomy Satellite Surfsat Surveyor Swift Gamma Ray Burst Exporer Synchronous Meterological Satellite-I TACSAT TACSAT 2 TDRS F7 Tellura Terra Terriers Tethered Satellite System Thermosphere Ionosphere Mesosphere Energetics and Dynamics TIMED TIROS-M TIROS-N TOMS-EP Total Ozone Mapping Spectrometer TOPEX TRACE Triana Tropical Rain Measuring Mission TSX-5 UFO I UFO 4 UFO 9 Ulysses Upper Atmosphere Research Satellite Vegetation Canopy Lidar VELA-IV Viking Viking Lander Viking Orbiter Voyager Wilkinson Microwave Anisotropy Probe WIND WIRE XMM X-Ray Timing Explorer XTE XSS-iO XSS-ii APPENDIX B FIELDS COLLECTED Mission Mission Scenario Mission Type Launch Year Launch Vehicle Bus Model Bus Config Bus Diameter Location Expected Life Flight Profile Flight Focus Technical Orbit Currency Total Cost Including Launch Unit Sat Costs Average Sat Cost Production Costs Launch Costs Operations Cost Orbit Weight Wet Weight Dry Weight Max Power EOL Power BOL Power  of Batts 17 


Batt Power Batt Type Stabilization Type Propulsion Mechanism  of Solar Panels  of Solar Cells Manufacturing Qty Satellites in Constellation On-Orbit Spares Channels Number of Bands Data Storage Processing Power Source type Block Name Thermal Control Material Type Level of Technology Known Inheritance Propulsion station keeping Number of Axes Ground Based Spares Pointing Accuracy APPENDIX C EXISTING MODELS Numerous models are today in use for estimating spacecraft cost Two of the most common are the NASA/Air Force Cost Model and the Aerospace Small Satellite Cost Model Here is a description of the NAFCOM model The NASA/Air Force Cost Model NAFCOM is a parametric estimating toolfor space hardware It is based on historical NASA and Air Force space projects and is primarily used in the very early phases of a development project NAFCOM can be used at the subsystem or component levels The database currently includes 122 missions including 76 unmanned earth orbiting 24 unmanned planetary 11 launch vehicles 8 manned 3 engines It uses parametric relationships to estimate subsystem or component level costs for any aerospace hardware including earth orbital spacecraft manned spacecraft launch vehicle upper stages liquid rocket engines scientific instruments or planetary spacecraft 7 And for the Aerospace Small Satellite Cost Model SSCM employs a parametric methodology for estimation of program cost and is best suited to the early conceptual development phase of a spacecraft program during which time the design is likely to be less mature and when cost and performance trades can be easily performed SSCM consists of a collection of cost-estimating relationships or CERs which estimate the costs of developing andproducing a spacecraft system with the following subsystems  Attitude Determination and Control Subsystem ADCS  Propulsion  Power  Telemetry Tracking  Command TT&C  Command  Data Handling C&DH  Structure  Thermal CERs were also developed for integration assembly and test IA&T program management PM and systems engineering SE and launch and orbital operations support LOOS Individual subsystem cost estimates are statistically rolled up to yield a cost-risk distribution which provides the estimator with a range of cost estimates andpercentiles 8 The SSCM was calibrated from over 100 post-1990 Earth-orbiting andplanetary missions REFERENCES 1 Lack of Disciplined Cost-Estimating Processes Hinders Effective Program Management GAO study 04-642 2 Jilla Cyrus D and Miller David W Satellite Design Past Present and Future International Journal of Small Satellite Engineering 12 February 1997 3 Bearden David A A Complexity Based Risk Assessment of Low-Cost Planetary Missions:When Is A Mission Too Fast and Too Cheap Fourth IAA International Conference On Low-Cost Planetary Missions JHU/APL MAY 2-5 2000 4 Kellogg Mahr and Lobbia An Analogy-based Method for Estimating the Costs of Spacecraft IEEEAC paper 1371 Version 4 5 Hoeting Jennifer A Methodology for Bayesian Model Averaging An Update f 6]btp/ewiieiao iiAaos 7 Keith Smith NASA/Air Force Cost Model Science Applications International Corporation 8 18 


BIOGRAPHIES Lee Fischman served as Principle Investigator for this project Lee is Senior Director of Development at Galorath Incorporated where he directs much of the new product development and research at the firm He developed SEER for Software  Hardware Integrations with Microsoft Project the Comparison Sizing tool COTS Software model in addition to various data mining information extraction and expert systems Previously he was a software designerlprogrammer in the New York financial industry Lee earned a BA from the University of Chicago and an MA from UCLA both in economics Mike Kimel carried out statistical work on the project Mike is an Economist for Galorath Inc in addition to maintaining his own quantitative consulting practice He has also taught Economics and Advanced Statistics at the Graziadio School of Business and Management at Pepperdine University run the Competitive Strategy group for a Fortune 500 Telecom Company and worked as a Consultant at PriceWaterhouse LLC now PriceWaterhouse-Coopers He earned a Ph.D in Economicsfrom UCLA Troy Masters programmed analytic methods and is integrating the Far Out model into its parent product SEER for Hardware previously SEER-H Troy is a Software Engineer with Galorath Incorporated where he has been the primary developer for a range ofproducts He earned a BS in computer science from UCLA David J Pine was our subject matter expert helping us assemble data and gain insight into technical trends Dave is retired after a 34-year career with the National Aeronautics and Space Administration NASA currently is a consultant to various government and industry entities While at NASA his organizations in the Office of the Chief Financial Officer and later at the IPAO at Langley Research Center were responsible for the conduct of major NASA program analyses and evaluations for the NASA Administrator and Deputy Administrator From early 1988 through the end of 1990 he was the Deputy Program Manager for the Hubble Space Telescope Program specifically responsible for the telescope operations and science support aspects of the program He earned a BS in Aerospace Engineering from the Polytechnic Institute of Brooklyn and a Masters of Engineering Administration from the George Washington University 19 


  20 Angeles, where he also received a B.S. in Applied Mathematics  Eric Fetzer is a Senior Member of the Technical Staff at the Jet Propulsion Laboratory, Pasadena, California specializing in satellite observations of the atmosphere.  His scientific interests include planetary boundary layer processes, tropical phenomena, upper tropospheric variability, and climatologies of temperature, water vapor and clouds.  His technical interests include analysis of large data sets, and of multi-sensor observations. He has over 20 peer-reviewed publications and given numerous scientific presentations, public lectures and media interviews about climate science. Eric received a B.A. in Physics from the University of California Berkeley, and a Ph.D. in Astrophysical, Planetary and Atmospheric Sciences from the University of Colorado, Boulder   Amy Braverman is a Senior Statistician at the Jet Propulsion Laboratory, California Institute of Technology She holds a B.A. in Economics from Swarthmore College an M.A. in Mathematics from UCLA, and a Ph.D. in Statistics also from UCLA. Prior to her current position in JPL's Science Data Understanding Group, she was a Caltech Post-doctoral Scholar at the Jet Propulsion Laboratory, and a Scientist in the Flight Sciences Experiments Section of the Science Division. Dr Braverman conducts research on information-theoretic methods for the analysis of massive data sets and streams statistical data fusion, high-dimensional data analysis, and statistical analysis for climate model evaluation and diagnosis. She has published in both the statistics and geoscience literature, and is active in both communities She is a member of the Multi-angle Imaging SpectroRadiometer Science Team, and serves as a member of the Atmospheric Infrared Sounder Science Integration Team. Her responsibilities on both missions include designing data reduction algorithms for massive, remote sensing data sets. Dr. Braverman also holds an appointment in the Department of Statistics at UCLA as Adjunct Associate Professor, and is active in UCLA\222s Center for Environmental Statistics. She is member of the Committee on Applied and Theoretical Statistics of the US National Academy of Science. She has refereed for the Journal of the American Statistical Association, the Journal of Computational and Gr aphical Statistics, IEEE Transactions on Geoscience and Remote Sensing, and the Journal of Applied Meteorology and Climatology Seungwon Lee is a senior member of the High Capability Computing and Modeling Group at Jet Propulsion Laboratory. She is conducti ng research on comet gas dynamics, nonlinear dynamics control, climate model parameterization, Earth science data analysis, parallel computing, and advanced numerical algorithms. She received her Ph.D in Physics fr om the Ohio State University and her M.S. and B.S. in Physics from the Seoul National University, Korea  Matthew Henderson is software engineer in the High Capability Computing and Mode ling group at JPL. His current work includes Web Services and Instrument Data Level 2 subsetting. He received a B.S. Computer Science from CSU Pomona, and is currently pursuing M.S Computer Science  Steven J. Lewis is a member of the Information System and Computer Science staff member at the Jet Propulsion Laboratory.  He received a BS in Mathematics from the University of California, Los Angeles in June 2001, and the MS and Ph.D. Degree from Claremont Graduate University in May 2004 and May 2007, respectively.  He worked as a post doctoral fellow at Keck Graduate Institute from June 2007 until he joined JPL in March of 2008.  During his graduate and post doctoral work, his studies focused on applications of Bayesian methods to hidden Markov models with particular interest and application to protein sequencing.  His work at JPL has focused on integrating web services into various programming platforms for the purposes of accessing NASA satellite data, as well as developing object tracking so ftware and contributing to image enhancement and restoration efforts Van Dang is a member of the Science Data Understanding Group at the Jet Propulsion Laboratory. She was responsible for the NEWS Level 2 processing that generated the formal merged Level 2 data from multiple A-Train instruments  Manuel de la Torre is a Physicist from the Universidad Complutense at Madrid \(Spain\. After finishing his Ph.D work at the University of Bayreuth \(Germany\ on pattern formation in turbulent flows and a 7 1/2 year stunt as Ass and Assoc. Prof. at the Escuela T\351cnica Superior de Ingenieros Aeron\341uticos in Madrid \(Spain\, he came to the Jet Propulsion Laboratory on a 1-year Sabatical leave in 1997 wanting to apply fundamental concepts of nonlinear systems and geophysical fluid dynamics to something that might be directly useful to soci ety. He discovered the JPL as a great place to achieve that goal and extende d his stay a bit longer, becoming Technical staff and working on different aspects of remote sensing, validation of satellite instruments, and data analysis of atmospheric processes and climate  


