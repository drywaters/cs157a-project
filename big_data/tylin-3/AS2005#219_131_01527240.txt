  Proceedings of the F o ur th Inter n ational Conference on Ma c h ine Lear ning and Cyber n etics  Guangzhou, 18-21 A ugust 2005  THE CUST O MER BEHA V IOR MODEL OF INTERNET SECURITIES DEALING BASED ON DA T A MINING  Z HONG W ANG 1 PI-LIAN HE 1 LAN-SHEN GUO 2 X U E-MEI SUN 3  1 School of El ect roni cs and Inform at i on T i anji n Uni v ersi t y  T i anji n 300072,C h i n a 2 School of M echani cal Engi neeri ng, Hebei Uni v ersi t y of T echnol ogy  T i anji n 300130, C h i n a 3 Depart m e nt of C o m put er  T i anji n Pol y t echni c Uni v ersi t y  T i anji n 300160, C h i n a E-M A IL 
l u t h er2000_1@163.com  pl he@t ju.edu.cn, guol anshen@163.com   Seesea_sun @163.com      Abstract This pape r disc usse s tw o p a tte r n s in data mining assoc i ation r u le s and se que nt ial patter n s and de sc r i be s the  pr ocess to find these patterns by mining histor ic al sec u r i ties tr ading database  Thr o ugh the analy s is of mining r e sult this p a p e r p r es en ts th e con cep t an d r e aliz ati o n of cu s t omer  be havior mode l and suc c e ssfully applie s the mode l to advanc e  th e p erfo r man c e of I n tern et s ecu r i ties d e alin g s y s t em  of CI TI C S ecu rit i es Co. Ltd   Th e cu s t omer b e h avior mo d e l  pr e s e n te d by this pape r is an impor t ant impr ove 
me nt of traditional securiti es trading Keyw ords Data mining; Assoc i ation rule s; Se que ntial patter n s Cu s t omer b e h avior mod e l; I n tern et s ecu rities d e alin g  1.  Intr oducti on  W i t h t h e rapi d devel o pm ent  and wi de ap pl i cat i on o f  database tec hnology pe ople have accum u lated m o re and m o re dat a S t o r i n g dat a wi t h dat a base  m a nagem e nt  sy st em  an d an alyzin g d a ta with mach in e learn i ng m e th o d h a ve becom e t h e best way t o di scover knowl e dge i n dat a base Because of t h e de velopm en t of Internet securities d ealin g in  recen t years, securities co m 
p an ies h a v e already col l ect ed a n d  st ore d a l a r g e am ount o f  hi st ori cal t r a d i n g d a ta If th ese d a ta can b e  u tilized ef fectiv ely  t h e charact e r i s t i c s and re gul ari t y of i nvest or 222 s t r adi n g be ha vi o r  coul d be e f fe ct i v el y percei ved  It i s ve r y im port a nt f o r  secu rities co m p an ies t o i m p r ov e th e serv i ce with th ese characteristics and regularity  2 The c o nc ept of Associ ati o n r u les and Se quen t ial patterns Th e task of data min i n g 
 is to d i scov er p a ttern s fro m  d a ta Asso ciatio n ru les an d sequ en tial p a ttern s are v e ry i m port a nt knowl e dge di scovery pat t e rn 1     De fi ni t i o n 1 Su pp osi n g  is a g r ou p of art i c l e s W i s a set c o m pos ed by a gr o u p  of t r an sact i ons  Each tra n sacti o n T in W i s a gr oup  o f ar ticles, T 
001 R Supposi ng t h ere is an a r ticle set A, a t r ansact ion T  i f A 001 T  we can claim  article set A i s sup ported  by tran saction  T   Asso ciatio n  ru le is a fo 
rm al im p l icatio n  A B A an d B are two group s o f articles A 
001 R B 002 There are fo ur i nde xes t h at wei g h associ at i on r u l e  C onfi d e n c e  Support  Expect ed confi d ence and Li ft       2 1 m I I I R 
001 R and A B 
 2       Th e co n c ep t of sequ ential p a ttern is th e sam e as asso ciatio n ru l e bu t th ere are two d i f f eren ces: Th e relation  b e tween  d a ta is correlated with ti m e in  o r d e r to fi n d  sequ en tial p a ttern Th e elem 
e n t o f sequ en tial p a ttern can  be an elem ent, and also can be an item s et 3 4       De fi ni t i o n 2 It em set  i s  a no n-em pt y set com posed b y  ite m  In g e n e ral, Item set refers to an article set in wh ich  art i c l e s are not i n orderi ng        De fi ni t i o n 3 Se que nce i s  an item s et in wh ich item s are  i n orderi ng     T h ere a r e two se quence s A<a 1 a2\205a n a nd B<b1,b2\205 bm  m  n. If a1 
001 b1 a2 001 b2 205 an 001 bn  
then  A 
001 B. In a set o f seq u e n ces, i f s is no t in cl ud ed in an y o t her sequences, s i s m a xi m a l    3 Minin g association rul e s an d seque ntial p a tterns  fr om hi stori c al tradi n g database 3.1. T h oughts  Hi st o r i cal t r a d i n g dat a base c o m posed by c u st om er  transactions is a lar g e sc ale database, whose e a c h  transaction is com posed by custom er Id, transaction time and st ock code i t e m   A random sam p l e i s as fol l o ws T ab le 1     All tra n sactions of a c u st omer can be re garde d as a    0-7803-9091-1/05/$20.00 \2512005 IEEE 1816 


  Proceedings of the F o ur th Inter n ational Conference on Ma c h ine Lear ning and Cyber n etics  Guangzhou, 18-21 A ugust 2005  seq u ence  or de red by t r a n sa ct i on t i m e, w h i c h co ul d  be called custom er seque nce Usually a c u stom er sequence expresse d as  ite m s et\(T1   ite m s et\(T2  205 ite m s et\(Tn   Il l u st rat e d by t a bl e 2   T a ble 1: Sour ce database sor t ed in custom er I d and tr ansaction tim e  Cu sto m er Id  T ran _ tim e S to ck _ I tem   24731 24731 20030625 20030630 600800 600030 24732 24732 24732 20030610 20030614 20030620 000001 600693 600800 000600 600600 50000 1 2 4 7 3 3  2 0 0 3 0 6 2 5  600800 000002 50000 1 24734 24734 24734 20030625 20030630 20030725 600800 000600 500001 600030 2 4 7 3 5  2 0 0 3 0 7 1 1  6 0 0 0 3 0   T a ble 2 Custom er s equence in database  Custo m er Id   Custom er Sequence 24731 24732 24733 24734 24735  600800  600030   000001 600693  600800  000600 600600 500001   600800 000002 500001   600800  000600 500001  600030   600030     If cust om er sequence of c u stom er A includes se quence  s, th en s is su pp or ted  b y custo m er A  Su ppor t o f  sequ en ce s can  b e  d e fin e d as th e qu antity o f all th e cu st o m ers wh o sup p o rt s  Gi ve n a  dat a base  w h i c h i s c o m pos ed by c u st om er  tran saction s  min i n g sequ ential p a ttern s fro m th e d a tab a se is to loo k  for m a x i m a l se q u e n ce wh ich at least h a s m i nim u m sup p o r t a p poi nt ed be fo re han d  S u ch m a xim a l  sequences t h at represe n t seque n tial p a ttern s are called lar g e sequence     Fo r ex amp l e, su ppo sing  min i m u m v a lu e o f  supp or t s i s  25 nam e ly there are at least two c u st om ers who s u pport s in to tal fiv e custo m ers. Fro m  th e an alysis o f  tab l e 2  we can  see that two c u stom er se que nces a r e m a ximal: < \(600800   600 030  d < \(60 080 0 0 006 00 50 000 1 Cu sto m er s eq uen ce < \(6 008 00    600 030   is su ppo r t ed  by cust om er 24 7 31 a n d 2 4 7 3 4  Al t h o u gh cust om er 24 7 3 4  excha n ge item 00 060 0,500 00 1 b e t w een item  6 0 080 0 and 600 030  he still su p ports th e cu st omer seq u e n c e  600 800  6 000 30  b ecau s e th e p a tter n s w e  look  for do  not al way s  nee d kee p i n g c ont i n u o u s C u st o m er se que nce   600 800   0006 00 50 000 1  is supp or ted b y  cu st o m e r  2 473 2 an d 2 473 4. C u sto m er  2 473 2 ex ch ang e item 6 0 0 600  an d h e also exch ang e 000 600 and 500 001 at th e sam e ti m e  that still supports this patte rn because item  000600,500001 i s t h e subset of i t e m 000600,600600,500001   Cu st o m er s equ e n ce 00 000 1,600 693   600 800    h a s not m i nim u m  sup p o rt  Al t h o u g h  ot her c u st om er seq ue nce s  h a v e m i n i m u m supp or t, such as <\(60 080 0 00 060 0   500 001  6 000 30 60 080 0  0 006 00   600 800   500 001  00 060 0,50 000 1 t h ey ar e no t m a x i mal  because eac h of them can be i n clude d i n t h e m a xim a l custom er sequences     So the two cust om er sequence s are se quential patterns Th e resu lt is as fo llo ws  T a ble 3 M i ning r e sult   Sequential Patter n with suppor t > 25  600800  600030   600800  000600 500001   3.2.  Al gori t hm anal ysi s      Th e leng t h  o f a sequ en ce is th e q u a n tity o f item s et. A  sequence with lengt h of k is called k-s e que nce. Lar g e ite m s et is an ite m s et with  m i n i m u m su p p o r t 5  Ev ery item i n l a r g e i t e m s et has m i nim u m s u p p o rt  La r g e se que nce i s  a list o f lar g e item s et     There are fi ve st eps t o fi nd sequent i a l pat t e rns     S t ep 1. So rt i ng p h ase  S o rt hi st ori cal  t r adi ng dat a bas e  on c u st om er i d m ajor key  an d t r ansact i o n t i m e m i nor  k e y is ph ase, tran sactio n d a tab a se is tran sform e d  into the database that is com posed by custom er sequence      S t ep 2 La r g e i t e m s et phase M i ni ng a ssoci at i on r u l e s with Ap ri o r i alg o rith m is u s ed to fi n d lar g e ite m s et 6 7   These lar g e ite m s et group a set L, whe r e L is also a 1-sequence     S t ep 3. T r ans f orm a t i on phase I n t h i s p h ase w e  constantly ins p ect whether a gi ve n set  o f l a r g e seq u e n ce i s  include d in custom er sequence Eac h cust o m er se que nce  i s  replace d by lar g e itemset that it includes  If a custom er se q uence does not include any l a r g e item s et, it sh ou l d  b e  d e leted  B u t th ese cu sto m ers are co un ted in to tal  num ber al l  t h e sam e S o a c u st om er s eq ue nce i s  tran sform e d to a set   repre s ents a lar g e  item s et      2 1 n l l l i l   S t ep 4  Seq u e n c e Ph ase: Th e sequ en ce can b e f ound b y u tilizin g the lar g e item s et th ro ugh sev e ral ti m e s o f p a ss In e v ery  pass begi nni ng fr o m seed set t h at i s com posed b y  l a r g e se que nce  we ca n ge ner a t e a new l a t e n t l a r g e seq u e n c e  In t h e pr oces s o f  dat a base pass s u p p o r t of can di dat e  sequence can be calculate d So a f ter a dat a base pass, we can find lar g e sequences in c a ndi date se que n ces, a n d form seed set  o f  ne xt pa ss by t h e s e l a r g e se que nces B e f o re t h e  fi rst pa ss, al l t h e 1-se q u ence  obt ai ne d i n l a r g e i t e m s et phase   1817 


  Proceedings of the F o ur th Inter n ational Conference on Ma c h ine Lear ning and Cyber n etics  Guangzhou, 18-21 A ugust 2005  form seed set Ap rio r i alg o r ith m  is as fo llo ws  1 L  Lar ge 1-sequences  Result from Lar g e item s et Phase For  k = 2 003  004 k 1 005 C  K  S t ep 5. Maxim a l phase: Find m a xim a l sequences in lar g e  sequence set For  k = n ; k > 1 ; k do   For each k-sequence S k do   Delete from S all subsequences of Sk   4 S t r u ct uri n g c u st omer  beha vi or m o del b a sed o n  mining r e sult    B a se d o n  s e que nt i a l pat t erns m i ned f r o m hi st ori cal  t r adi n g dat a b a se, c u st om er be havi or m odel  can be  ef fectively structured 212 k L  Begin K C New Candidates Generated from  1 212 k L For each cus t om er s equence c in the database do  Increment the count of all candidates in  K C that are contained in c  K L  Candidates in  with minimum support K C End Answer = Maximal Sequences in k  K L  k L  repres ents  the s e t com pos ed of a l l k-s e q u ence  C k repres ents the s e t com pos ed of candidate k_sequence  New Candidate Generation  algorithm 1 Union Inse rt into  C k  Select  p litem s et1,\205 p litem s etk-1 q litem s etk-1   Fr om  L k-1 p  L k-1 q   Wher e  p litem s et1 q litem s et1,\205  p litem s etk-2 q litem s etk-2  2 e \(k-1  f sequence c is not in cluded in L k-1 , delete all c  0 0 0 0 0 0 1 3 31 2 21 1 11 KP K c b a S S S S S S S S CBM  1   Th is m o d e l is also called b e h a v i or m a trix In t h e matrix each ro w represen ts a sequ en tial pattern Ev ery  ele m en t o f t h e m a trix is a lar g e ite m s et co m p o s ed  by  several st oc ks  Ap pa rent l y l e ngt h of eac h se que nt i a l pat t e r n  is d i f f eren t, so zero is u s ed  to of fset th e sh ortn ess Fro m  row 1 to last row  sup p o r t o f  sequ en tial p a ttern is decreasing   M o del CBM rev eals the m a x i m u m  p r ob ab ility of st ock 222 s t r adi n g or de r whi c h c u st om er exc h a nge i n  Int e rnet  secu rities d ealin g  Fo r ex am p l e, in tab l e 3  if a certain custom er exc h ange s stoc k 60 0800 c o uld forecast that t h e ne xt st o c k he wi l l t r ans f o r m is 6 0 0 0 3 0   or   000 600 5 000 01  rou g h  sear ch i n g th e m a tr ix So  cu sto m er b e h a v i or in  In ternet secu rities dealin g can  b e  deduced t h rough t h e m odel    5  Application of c u stome r behavior m o del in In tern et securities dealing     Th e b e h a v i or m a trix can  b e app lied t o  securities  com p anies\222 Internet dealing system In Internet deali n g sy st em ho w t o q u i c kl y  u pdat e st oc k q uot at i ons  of cl i e nt s i s  a k e y pro b l em Utilizin g  b e h a v i or m a tr ix cu st o m er 222 s  beha vi o r o f  t r adi n g ca n be p r edi c t e d For e x am pl e sup p o si n g c u st om er A i s  b u y i ng st oc k B at  m o m e nt t  i f B  i s  foun d in th e ite m s et  i n  beha vi o r m a t r i x t h e ne xt  t r adi n g st oc k at  m o m e nt t  1 can be det e rm i n ed i n t h e ite m s et k j 1  with  great prob ab ility So th e  qu ot at i o n s of next  st oc k ca n be pus he d i n t o  c u st om er 222 s  com put er beforehand  ij S ik S     O b vi o u sl y  i f t h e val u e o f s u p p o rt  of se que nt i a l pat t e r n  is dif f ere n t, t h e scale of be ha v i or m a trix is d i f f eren t. T oo lar g e scale of b e h a v i or m a t r ix will seriou sly af fect the ef ficiency of Internet deali ng syste m and t oo sm all scale  will d e crease th e p u s h h it ratio After testin g  and u s ing b e h a v i or m o d e l in In tern et dealin g syst e m in C I TIC  Securities Co Ltd Listed  Co m p an ies in Sh ang h a i st ock  excha n ge cod e 60 003 0  our e x perie n ce shows t h at the best val u e of  s u p p o rt  i s 5 5  i n  m i ni ng  ass o ci at i on rul e s  a n d sequent i a l pat t e rns from hi st ori cal t r adi ng dat a base  6.  Concl u si on   M i ni ng a ssoci at i o n r u l e s an d se que nt i a l pat t e rns f r o m  hi st ori cal t r a d i n g dat a base t o st ruct ure cu st om er beha vi o r  m odel are a n i n no vat i v e a n d  pract i cal  m e t hod i n da t a  m i ni ng fi el d    Kn owledg e is streng th, and it is also t r easu res As a po we rf ul a n al y s i s an d a ssi st ant  deci si o n t o ol  dat a m i ni ng t h eo ry a n d t e chn o l o gy ha ve b een  gra d ual l y ap pl i e d a n d  d e v e l o p e d in secu rities i n du st ry Si n ce C h ina h a s b e co m e a me m b er o f  WT O d a ta min i n g techn o l og y will b e come  m o re and m o re im p o r tan t t o adv a n c e do mestic securities co m p an ies\222 co re ab ility o f co m p etitio n     1818 


  Proceedings of the F o ur th Inter n ational Conference on Ma c h ine Lear ning and Cyber n etics  Guangzhou, 18-21 A ugust 2005  7.   Announcement   T h i s  pa per i s s u pp o r t e d by Sci e nce-T e c h n o l o g y  Devel opm ent Pro j ect o f  T i a n ji n \(0 4 3 1 0 9 4 1 R   a n d A ppl i e d B a si c R e search Project of T i anji n \(05YFJM J C 1 1700  Refer e nces 1  M e hm ed Kant ardzi c  Dat a  M i ni ng C onc ept s M odel   Meth od an d Arith m e t i c. Beijin g  T s i n ghu a Un i v ersity Press, 2003  2   H a n JW K a m b r M D a t a Min i ng C o n cep ts and Techni ques. B e i j i ng Hi gher Educat i on Press, 2001 3  Zh on gz hi Shi  K n o w l e d g e Di sco v ery   B e i j i ng  T s i nghua Uni v ersi t y Press, 2002 4   Min g Syan C h en,Jiawei Han and Ph ilip S. \223Data M i ni ng  A n  O v er vi ew f r om a dat a base Per s pect i v e\224  I EEE T r an sactio n s on K now ledg e an d D a ta Engi neeri ng, V o l  8,No.6,pp.866-883,1996 5  M  Ho ut sm a and A  S w am i  223Set O ri ent e d  M i ni ng fo r  Asso ciatio n Ru les in relational Datab a ses.\224 Proc 19 95 In t\222l C o nf. Data En g., pp 25 34  T a ip ei  T a i w an ,C hi na, M a r 1995  6   Ch en X i ao  kai, Hu an g Zhi Q i ang  An alysis an d Research on t h e Arithm e tic of M i ni n g  A ssoci at i o n  R u l e s, M i crocom put er Devel opm ent   No.4 73-75,2003 7   R. Ag rawal T   Im ie lin sk i, and A.Swami. \223Min in g Asso ciatio n Ru les Between Sets o f Item s in Lar g e Dtabases 224 Proc. 1993 AC M SIGMOD Int\222l  Conf M a nagem e nt of Dat a p p  2 07 2 1 6  W a s h i ngt on D.C   M a y 1993     1819 


the example websites. Second, we applied our proposed association mode of panem trek, \(AMPT association probability of the sub-trees  discovered by PFTM and generate the pattern tree for the target site Moreover, to accurately and reliably extract price data is one of the key problems that must be solved by a scalable comparison-shopping tool. For example, suppose there are several numbers in a data block, how to select the proper number as the price? Here we use a verification matrix C to do this job. The verification matrix is defmed as follows The enhy ci.j refers to the price of the #j product in i website. The row vector denotes the price of different products in the same website. The column vector denotes the price of the same product in different website Suppose that the distribution of price fluctuation should obey Gauss distribution Then the verification matrix C is applied to pick the proper price from the noisy data block 4.1 Semi-supervised Wrapping \(SSW Algorithm: SemiSupervisedWrap Input: n \(n&lt;lO m4 sample pages in each sample website Output: a association repository; d The semi-supervised wrapping process is detailed as follows 1 a representation that reflects its HTML tag hierarchy. The parsing tree is displayed in a tree control. Using a GUI, the user hierarchically decomposes the document, outlining the boundary of interest data block and describing their semantics 2 DBFinder generates a pattem tree that handle structural mismatched found among the m data blocks. The panem tree indicates the structure and the textual sumundings of the objects to be extracted 3 DBFinder to wrap data from other pages collected from the same website 4 websites, DBFinder obtains a set of data block. There is a large number of textual information hidden in the data blocks. We apply a Chinese word segmentation tool to segment the texts into words. Taking the words as items and the data blocks as transactions, an association rule mining algorithm \(such as Apriori or FP-tree algorithm a set of all frequent itemsets \(association repository 5 the above wrapped data 4.2 Un-Supervised Wrapping \(USW First, we introduce frequent sub-tree mining in brief Frequent subt-ree mining, which discovers frequent sub-trees as pattems in a forest, is in important data mining problem with broad applications, including web structure mining, extracting pattems from XMUHTML documents and so on. Because the interest data block in one website are generated by a template, one would like to discover the template \(frequent sub-tree mining algorithm. Please refer to.[ll] for details The unsupervised wrapping algorithm is detailed as follows Algorithm: UnSupervisedWrap Input: i  target website; ii repository: iii Output i  iii updated verification matrix 1 lata cleaning process is applied to the pages collected from the target website, such as using the verification matrix to verify the price in the candidate data block. Then we obtain a subset 


price in the candidate data block. Then we obtain a subset of pages containing the interest data block 2 parsing into document trees. The PFTM algorithm takes as input the document trees and generates a complete set of frequent sub-trees sorted by its support value. Then, the n former sub-trees with high support value, denoted by Y = { Y , , Y , , . . . Y , J ,  are selected from the set of frequent sub,trees 3 Ui E Y 1444 Proceedings of the Third International Conference 00 Machine teaming and Cybernetics, Shanghai  26-29 August 2004 equation \(3 me frequent sub-tree y, with the maximum association rate* denoted by Pr\(Y outperforms the unsupervised wrapper by an average of ahout 10 percents. The results show that all sites, except for 139shop, have a preferable precision rates \(at least 0.74 and recall rates \(at least 0.62 iilj..l thepuffem frees for the target website S   4 data from the pages collected from the target website 5 5. Experiment Analysis To demonstrate the feasibility of our approach, we have conducted three kinds of experiments. The first is to calculate the precision and recall of DBFinder. The second is to automatically identify the field-value from the data blocks by using DBFinder. The third is to apply DBFinder to a comparison-shopping system called Ego 5.1 PrefiSionlRecall of DBFinder We apply two measures widely used in evaluating the performance of IR systems, precision and recall rate, to the following experiments and verify the quality of our proposed methods. We write a band-coding wrapper in advance. Regards the records extracted by hand-ceng wrapper as total records, measure of precision and recall are defined in equation \(5 6 5 6 To test the precision-recall of DBFmder, we use the data we have collected from some Chinese popular websites in the domain of mobile phone. The data  is divided into two groups. Each goup contains the data collecfed from 10 mobile phone websites. The fxst is fed to the semi-supervised wrapper. The second is fed to the unsupervised Wrapper Table 1 shows the precision-recalls for semi-supervised wrapper. From table I ,  we can see. that the highest recall \(showji cnool is 0.63. We check the pages collected from showji and fmd that each data block includes three a B L E &gt;  and the format tends to be unique. However, the data block in cnool consists of some noisy tables and the position of price is far from that of the product. These two factors depress the rate of precision and recall Table 2 shows the precision-recalls for unsupervised w r a p r .  The average precision is 0.83 and the average  recall is 0.71. We can see that the semi-supervised wrapper of correctlyxtracted records of extractedrecords of correctlyxtractedrecords of total records P =  Precision R=Recull feasibility of our proposed approach. The precisiodrecall of 139shop. 0.63/0.52 is not perfect. By tracing the pages collected from 139shop, we found that the data block consists of too many noisy anchors and images, such as 


 anchors of related news  Moreover, the position of specification is far from that of the product. The noisy features included in the irrelated anchors degrade the precision/recall rate Table 1: the Recision-Recall for Semi-supervised Wrapper I Site I ~ o t a l  I extra- I cone~tlv I P I R ,I Table 2 the Recision-Recall for Unsupervised Wrapper I site I 5.2 Automatic Identify \(field, value 1445 Proceedings of the Third International Conference on Machine Learning and Cybernetics, Shanghai  26-29 August 2004 Figure 2 shows an example for pattern tree, which is discovered from www.showii.com. This pattem tree covers 562 pages in the website. From figure 2, we can see that there are three &lt;TABLE&gt; in the pattern tree. Three red flag make our method be applicable to general Web pages instead of restricting to tabular pages, we will apply generalization and specialization processes to merge 01 split content blocks based on HTML. document object model represent the values corresponding.to the fields: image product, and price We regard the text node, such as performance, product and price, as field. The feature field remains the same over all the interest pages in a website. -According to this character, we can automatically identify the field and its value 5.3 Application in the comparison-shopping agent We have applied DBFiner technology into a real application, Ego \(http://202.38.215.1:8080/esearch is a comparison-shopping agent. Ego visits over one hundred of hand mobile sites, extract product information and summarize the results for the user. Figure 3 shows the CUI of Ego. The user can input a keyword, such nokia 8250, in the edit box. The detailed information, such product, image, price, and performance, are displayed in 6. Conclusions In this paper, we present a novel approach, DBFmder to discover interest data blocks from a set of Web pages The process of DBFinder consists of two phases semi-supervised wrapping \(SSW wrapper \(USW allows the user to label the sample pages. In the second phase, USW automatically discovers the interest data blocks by using the knowledge learned from the sample pages and from the test pages. No training data will be given to USW. According to the previous experiments, we can conclude that our proposed methods are feasible to discover interest contents from web pages In the future, we will develop other methods to automatically discover pages clusters from Web sites. To References l] A. H. F. Laender, B. A. Ribeiro-Neto, A. S. da Silva and J. S .  Teixeira. A Brief Survey of Web Data Extraction Tools. SIGMOD Record, 2002, 31\(2 84-93 2] I. Muslea, S .  Minton, C. A. Knoblock. Hierarchial Wrapper Induction for Semisturctured Information Sources. Autonomous Agents and Multi-Agent 4, 1/2  2001 3] N. Kushmerick.- Wrapper Induction: Efficiency and Expressiveness. Artificial Intelligence Journal 11 8 1-2 \(2000 V. Crescenzi, G .  Mecca, and P. Merialdo. RqadRunner Towards Automatic Data Extraction from Large Web Sites. In Proceeding of the 2b" Intemational Conference on Very Large Database Systems \(Rome Italy, 2001 5] L. Liu, C. Pu, and W. Han. XWRAP: An XML-enalbe Wrapper Construction System for Web Information 


Wrapper Construction System for Web Information Sources. In Proceedings of the.16" IEEY Intemational Conference on Data Engineering \(San Diego Califomia, 2000 6] G.  Arocena, A. 0. Mendelzon. WebSQL Restructuring Documents, Databases, and Webs. In Proceedings of the 14" LEEE Intemational Conference on Data Engineering \(Orlando, Florida, 1998 pp.24-33 7] S .  Soderlan. Leaming Information Extraction Rules for Semistructured Data Extraction. Master's thesis D e p m e n t  of Computer Science, Federal University of Minas Gerais, Brazil, 2001. In PortuguesP SI A. H. F. Laender, B. A. Ribeiro-Neto, and A. S .  Da Silva. DEByE: Data Extraction by Example. Data and Knowledge Engineenng \(2001 9] D. W. Embley, D. M. Campbell, Y. S .  Jiang, et al Conceptual-Model-Based Data Extraction from Multiple-Record Web Pages. Data and Knowledge Engineering 31,3\(1999 IO] 'P. B. Golgher, A. S .  da Silva, A. H. F. Laender, and B Ribeii-Neto. Bootstrapping for Example-Based Data Extraction. CIKM'OI, Atlanta, Georigia, USA, 2001 111 M. J. Zaki, Efficiently mining frequent trees in a forest In SIGKDD'2002 Edmonton, Alberta, Canada 4 1446 pre></body></html 


Discovery, 8, 2004, pp. 7-23 20] W. Teng, M. Hsieh, and M. Chen. On the Mining of Substitution Rules for Statistically Dependent Items Proceedings of IEEE International Conference on Data Mining \(ICDM  02 Proceedings of the Fourth IEEE International Conference on Data Mining \(ICDM  04 0-7695-2142-8/04 $ 20.00 IEEE pre></body></html 


14] Kryszkiewicz, M., and Rybinski, H. \(1999  Incomplete Database Issues for Representative Association Rules  ISBN: 3-540-65965-X, pp. 583-591 15] Little, R.J.A., and Rubin, D.B. \(2002 analysis with missing data, Wiley, New York, ISBN 0471183865 16] Omiecinski, E.R. \(2003  Alternative interest measures for mining associations in databases  IEEE TKDE vol. 15, no. 1, pp.57-69 17] Piramuthu, S. \(1998  Evaluating feature selection methods for learning in data mining applications  in the Proceedings of the Thirty-First Annual Hawaii International Conference on System Sciences, vol. 5, pp. 294-301 18] Pyle, D. \(1999 Morgan Kaufmann Publishers, Inc.ISBN:1-55860-529-0 19] Ragel, A., and Cremilleux, B. \(1999  MVC - A preprocessing Method to deal with missing values   knowledge based system, vol. 12, pp.285-291 20] Ramoni, M., and Sebastiani, P. \(2000  Bayesian Inference with Missing Data Using Bound and Collapse   Journal of Computational and Graphical Statistics, vol. 9, no 4, pp. 779-800 21] Ramoni, M., and Sebastiani, P. \(2001  Robust Bayes Classifiers  AI, vol. 125, no. 1-2, pp. 207-224 22] Ramoni, M., and Sebastiani, P. \(2001  Robust Learning with Missing Data  Machine Learning, vol. 45, no 2 , pp. 147-170 23] Scott, R.E. \(1993 Logic and Practice, SAGE Publications, ISBN: 0803941072 24] Zaki, M.J., and Hsiao, C.J. \(2002  CHARM: An efficient algorithm for closed itemset mining  in the Proceedings of the Second SIAM International Conference on Data Mining Proceedings of the Fourth International Conference on Hybrid Intelligent Systems \(HIS  04 0-7695-2291-2/04 $ 20.00 IEEE pre></body></html 


13: else 14: E|i?1| = E|i?1| ? s The backward process in Algorithm 1, generates level-wise every possible subset starting from the borProceedings of the Fourth IEEE International Conference on Data Mining \(ICDM  04 0-7695-2142-8/04 $ 20.00 IEEE der de?ned by Edge without getting into equivalence classes which have been already mined \(Line 10 such subset satis?es the constraint then it can be added to the output \(Line 12 reused later to generate new subsets \(Line 14 have a monotone constraint in conjunction, the backward process is stopped whenever the monotone border B+\(Th\(CM Lines 3 and 8 4.3. Closed Constrained Itemsets Miner The two techniques which have been discussed above are independent. We push monotone constraints working on the dataset, and anti-monotone constraints working on the search space. It  s clear that these two can coexist consistently. In Algorithm 2 we merge them in a Closet-like computation obtaining CCIMiner Algorithm 2 CCIMiner Input: X,D |X , C, Edge,MP5, CAM , CM X is a closed itemset D |X is the conditional dataset C is the set of closed itemsets visited so far Edge set of itemsets to be used in the BackwardMining MP5 solution itemsets discovered so far CAM , CM constraints Output: MP5 1: C = C ?X 2: if  CAM \(X 3: Edge = Edge ?X 4: else 5: if CM \(X 6: MP5 = MP5 ?X 7: for all i ? flist\(D |X 8: I = X ? {i} // new itemset avoid duplicates 9: if  Y ? C | I ? Y ? supp\(I Y then 10: D |I= ? // create conditional fp-tree 11: for all t ? D |X do 12: if CM \(X ? t 13: D |I= D |I ?{t |I  reduction 14: for all items i occurring in D |I do 15: if i /? flist\(D |I 16: D |I= D |I \\i // ?-reduction 17: for all j ? flist\(D |I 18: if supD|I \(j I 19: I = I ? {j} // accumulate closure 20: D |I= D |I \\{j 21: CCIMiner\(I,D |I , C,B,MP5, CAM , CM 22: MP5 = Backward-Mining\(Edge,MP5, CAM , CM For the details about FP-Growth and Closet see [10 16]. Here we want to outline three basic steps 1. the recursion is stopped whenever an itemset is found to violate the anti-monotone constraint CAM Line 2 2  and ? reductions are merged in to the computation by pruning every projected conditional FPTree \(as done in FP-Bonsai [7 Lines 11-16 3. the Backward-Mining has to be performed to retrieve closed itemsets of those equivalence classes which have been cut by CAM \(Line 22 5. Experimental Results The aim of our experimentation is to measure performance bene?ts given by our framework, and to quantify the information gained w.r.t. the other lossy approaches 


approaches All the tests were conducted on a Windows XP PC equipped with a 2.8GHz Pentium IV and 512MB of RAM memory, within the cygwin environment. The datasets used in our tests are those ones of the FIMI repository1, and the constraints were applied on attribute values \(e.g. price gaussian distribution within the range [0, 150000 In order to asses the information loss of the postprocessing approach followed by previous works, in Figure 4\(a lution sets given by two interpretations, i.e. |I2 \\ I1 On both datasets PUMBS and CHESS this di?erence rises up to 105 itemsets, which means about the 30 of the solution space cardinality. It is interesting to observe that the di?erence is larger for medium selective constraints. This seems quite natural since such constraints probably cut a larger number of equivalence classes of frequency In Figure 4\(b built during the mining is reported. On every dataset tested, the number of FP-trees decrease of about four orders of magnitude with the increasing of the selectivity of the constraint. This means that the technique is quite e?ective independently of the dataset Finally, in Figure 4\(c of our algorithm CCIMiner w.r.t. Closet at di?erent selectivity of the constraint. Since the post-processing approach must ?rst compute all closed frequent itemsets, we can consider Closet execution-time as a lowerbound on the post-processing approach performance Recall that CCIMiner exploits both requirements \(satisfying constraints and being closed ing time. This exploitation can give a speed up of about to two orders of magnitude, i.e. from a factor 6 with the dataset CONNECT, to a factor of 500 with the dataset CHESS. Obviously the performance improvements become stronger as the constraint become more selective 1 http://fimi.cs.helsinki.fi/data Proceedings of the Fourth IEEE International Conference on Data Mining \(ICDM  04 0-7695-2142-8/04 $ 20.00 IEEE Information loss Number of FP-trees generated Run time performance 0 2 4 6 8 10 12 14 x 10 5 10 0 10 1 10 2 10 3 10 4 10 5 10 6 m I 2 I 1  PUMSB@29000 CHESS @ 1200 0 0.2 0.4 0.6 0.8 1 1.2 1.4 1.6 1.8 2 x 10 6 10 


10 1 10 2 10 3 10 4 10 5 10 6 10 7 m n u m b e r o f fp t re e s PUMSB @ 29000 CHESS @ 1200 CONNECT@11000 0 2 4 6 8 10 12 14 x 10 5 10 0 10 1 10 2 10 3 10 4 m e x e c u ti o n  ti m e  s e c  CCI Miner  \(PUMSB @ 29000 closet         \(PUMSB @ 29000 CCI Miner  \(CHESS @ 1200 closet         \(CHESS @ 1200 CCI Miner  \(CONNECT @ 11000 closet         \(CONNECT @ 11000 a b c Figure 4. Experimental results with CAM ? sum\(X.price 6. Conclusions 


6. Conclusions In this paper we have addressed the problem of mining frequent constrained closed patterns from a qualitative point of view. We have shown how previous works in literature overlooked this problem by using a postprocessing approach which is not lossless, in the sense that the whole set of constrained frequent patterns cannot be derived. Thus we have provided an accurate de?nition of constrained closed itemsets w.r.t the conciseness and losslessness of this constrained representation, and we have deeply characterized the computational problem. Finally we have shown how it is possible to quantitative push deep both requirements \(satisfying constraints and being closed process gaining performance bene?ts with the increasing of the constraint selectivity References 1] R. Agrawal, T. Imielinski, and A. N. Swami. Mining association rules between sets of items in large databases In Proceedings ACM SIGMOD, 1993 2] R. Agrawal and R. Srikant. Fast Algorithms for Mining Association Rules in LargeDatabases. InProceedings of the 20th VLDB, 1994 3] R. J. Bayardo. E?ciently mining long patterns from databases. In Proceedings of ACM SIGMOD, 1998 4] F. Bonchi, F. Giannotti, A.Mazzanti, andD. Pedreschi Adaptive Constraint Pushing in frequent pattern mining. In Proceedings of 7th PKDD, 2003 5] F. Bonchi, F. Giannotti, A.Mazzanti, andD. Pedreschi ExAMiner: Optimized level-wise frequent pattern mining withmonotone constraints. InProc. of ICDM, 2003 6] F. Bonchi, F. Giannotti, A.Mazzanti, andD. Pedreschi Exante: Anticipated data reduction in constrained pattern mining. In Proceedings of the 7th PKDD, 2003 7] F. Bonchi and B. Goethals. FP-Bonsai: the art of growing and pruning small fp-trees. In Proc. of the Eighth PAKDD, 2004 8] J. Boulicaut and B. Jeudy. Mining free itemsets under constraints. In International Database Engineering and Applications Symposium \(IDEAS 9] C. Bucila, J. Gehrke, D. Kifer, and W. White DualMiner: A dual-pruning algorithm for itemsets with constraints. In Proc. of the 8th ACM SIGKDD, 2002 10] J. Han, J. Pei, and Y. Yin. Mining frequent patterns without candidate generation. In Proceedings of ACM SIGMOD, 2000 11] L.Jia, R. Pei, and D. Pei. Tough constraint-based frequent closed itemsets mining. In Proc.of the ACM Symposium on Applied computing, 2003 12] H. Mannila and H. Toivonen. Multiple uses of frequent sets and condensed representations: Extended abstract In Proceedings of the 2th ACM KDD, page 189, 1996 13] R. T. Ng, L. V. S. Lakshmanan, J. Han, and A. Pang Exploratory mining and pruning optimizations of constrained associations rules. In Proc. of SIGMOD, 1998 14] N. Pasquier, Y. Bastide, R. Taouil, and L. Lakhal. Discovering frequent closed itemsets for association rules In Proceedings of 7th ICDT, 1999 15] J.Pei, J.Han,andL.V.S.Lakshmanan.Mining frequent item sets with convertible constraints. In \(ICDE  01 pages 433  442, 2001 16] J. Pei, J. Han, and R. Mao. CLOSET: An e?cient algorithm formining frequent closed itemsets. InACMSIGMODWorkshop on Research Issues in Data Mining and Knowledge Discovery, 2000 17] J. Pei, J. Han, and J. Wang. Closet+: Searching for the best strategies for mining frequent closed itemsets. In SIGKDD  03, August 2003 18] L. D. Raedt and S. Kramer. The levelwise version space algorithm and its application to molecular fragment ?nding. In Proc. IJCAI, 2001 


ment ?nding. In Proc. IJCAI, 2001 19] R. Srikant, Q. Vu, and R. Agrawal. Mining association rules with item constraints. In Proceedings ACM SIGKDD, 1997 20] M. J. Zaki and C.-J. Hsiao. Charm: An e?cient algorithm for closed itemsets mining. In 2nd SIAM International Conference on Data Mining, April 2002 Proceedings of the Fourth IEEE International Conference on Data Mining \(ICDM  04 0-7695-2142-8/04 $ 20.00 IEEE pre></body></html 


4] K. Chang, C. Chong, Bar-Shalom, Joint Probabilistic Data Association in Distributed Sensor Networks IEEE Transactions on Automatic Control, AC-31\(10 octobre 1986 5] Bar-shalom, Multitarget Multisensor Tracking Advanced Application ,:YBS Publishing, 1990 6] Bar-shalom, Multitarget Multisensor Tracking Principles and Techenices ,:YBS Publishing, 1995 7] Hu Wenlong, Mao shiyi, Multisensor Data Association Based on Combinatorial Optimization[J]. Journal of Systems Engineering and Electronics . 1997 NO.1,1~9 8] Pattipati K R, Passive Multisensor Data Association Using a New Relaxation Algorithm.In Multitarget-Multisensor Tracking: Advanced and Applications,Y.Barshalom,Norwood,MA:Aretech,199 0 9] Deb S,et al, An S-Dimentional Assignment Algorithm for Track Initiation ,Proc. Of the IEEE Int. Conf Systems Engineering, Kobe, Japan,Sept 1992 527~530 10] Deb S,et al, A Multisensor-Multitarget Data Association Algorithm for Heterogeneous Sensors[J].IEEE Trans. on AES 1993 ,29 \(2 560~568 12] Bar-shalom,Y.,and Fortmann,T.E  Tracking and Data Association  New York:Academic press,1988 13] J,A,Roecher and G.L.Phillis,Suboptimal Joint Probabilistic Data Association .IEEE Transaction on Aerospace Electronic Systems.1993,29\(2 14] J,A,Roecker,A Class of Near Optimal JPDA Algorithm IEEE Transaction on Aerospace and Electronic Systems,1994,30\(2 15] Han Yanfei, Analysis and Improvement of Multisensor Multitarget Probabbilistic Data Association Filting Algorithm[J].  Journal of Systems Engineering and Electronics, 2002, Vol.24, 36~38  569 pre></body></html 


dense data sets for evaluating pattern mining algorithms These two data sets are obtained from IBM Almaden at http://www.almaden.ibm.com/cs/quest/demos.html. Recently, theMAFIA algorithm [6] was proposed to ef?ciently discover maximal frequent patterns. As shown in their paper, MAFIA can be several orders better than some alternatives, such as DepthProject, for mining maximal frequent patterns. Hence, we chose MAFIA as the base line for our performance evaluation. Finally, please note that only the size-2 patterns are generated in the ?rst BFS phase Experimental Platform We implemented the MHP algorithms using C++ and all experiments were performed Proceedings of the 16th IEEE International Conference on Tools with Artificial Intelligence \(ICTAI 2004 1082-3409/04 $20.00 © 2004 IEEE on a Pentium III    MHz PC machine with    megabytes main memory, running Linux Redhat 6.1 operating system 5.2. A Performance Comparison 100 1000 10000 100000 1e+06 1e+07 1e+08 1e+09 1e+10 1e+11 0.02 0.025 0.03 0.035 0.04 0.045 0.05 0.055 0.06 N um be r o f C he ck ed P at te rn s Support threshold Mafia Min_Conf=0 Min_Conf=0.1 Min_Conf=0.3 Min_Conf=0.5 Min_Conf=0.7 Min_Conf=0.9 


Figure 4. The Number of Checked Patterns on the Pumsb* Data Set 10 100 1000 10000 100000 0.02 0.025 0.03 0.035 0.04 0.045 0.05 0.055 0.06 R un T im e s ec  Support Threshold Mafia Min_Conf=0 Min_Conf=0.1 Min_Conf=0.3 Min_Conf=0.5 Min_Conf=0.7 Min_Conf=0.9 Figure 5. The RunTime Comparison on the Pumsb* Data Set Figure 4 shows the number of patterns that MHP and MAFIA have to check during the pattern mining process on the pumsb* data set. As can be seen, for MHP, the number of checked patterns is increased with the decrease of the h-con?dence threshold. However, the number of checked patterns of MHP can be signi?cantly smaller than that of MAFIA even if a low h-con?dence threshold is speci?ed To check a pattern, we need to count the support of the patterns. Counting the support of a pattern is the most timeconsuming task during the pattern mining process, since we need to retrieve all the transactions which include one of its sub-pattern, or for Ma?a, retrieve all the bit of the bitmap of this pattern [6]. Therefore, an algorithm is more ef?cient if smaller number of patterns need to be checked 100 1000 10000 100000 1e+06 1e+07 1e+08 1e+09 0.1 0.2 0.3 0.4 0.5 0.6 0.7 N 


um be r o f C he ck ed P at te rn s Support Threshold Mafia Min_Conf=0.5 Min_Conf=0.7 Min_Conf=0.9 Figure 6. The Number of Checked Patterns on the Pumsb Data Set 10 100 1000 10000 0.1 0.2 0.3 0.4 0.5 0.6 0.7 R un T im e s ec  Support Threshold Mafia Min_Conf=0.5 Min_Conf=0.7 Min_Conf=0.9 Figure 7. The RunTime Comparison on the Pumsb Data Set The runtime comparison of MHP and MAFIA on the Pumsb* data set is shown in Figure 5. In the ?gure, we can observe that the runtime of MHP can be signi?cantly reduced with the increase of h-con?dence thresholds. Also the runtime of MHP can be several orders of magnitude less than that of MAFIA even if the h-con?dence threshold is as low as 0.3. The reason is that the number of checked patterns of MHP is sign?cantly smaller than that of MAFIA Similar results are also obtained from the pumsb data set as shown in Figure 6 and Figure 7. For the pumsb data set the number of checked patterns of MHP is much smaller 


than that of MAFIA and the runtime of MHP can be significantly less than that of MAFIA 5.3. The Effect of the MHP Algorithm on Finding Maximal Hyperclique Patterns Figure 8 and Figure 9 show the number of maximal patterns identi?ed byMHP andMAFIA on Pumsb* and Pumsb data sets respectively. As can be seen, the number of maximal hyperclique patterns identi?ed by MHP can be orders of magnitude smaller than the number of maximal frequent patterns identi?ed by MAFIA. In other words, the number Proceedings of the 16th IEEE International Conference on Tools with Artificial Intelligence \(ICTAI 2004 1082-3409/04 $20.00 © 2004 IEEE 100 1000 10000 100000 1e+06 1e+07 1e+08 1e+09 0.02 0.025 0.03 0.035 0.04 0.045 0.05 0.055 0.06 N um be r o f C ou nt ed P at te rn s Support Threshold Mafia Min_Conf=0 Min_Conf=0.1 Min_Conf=0.3 Min_Conf=0.5 Min_Conf=0.7 Min_Conf=0.9 Figure 8. The Number of MFI/MHP Patterns in the Pumsb* Data Set 100 1000 10000 100000 1e+06 


1e+07 1e+08 0.1 0.2 0.3 0.4 0.5 0.6 0.7 N um be r o f C ou nt ed P at te rn s Support Threshold Mafia Min_Conf=0.5 Min_Conf=0.7 Min_Conf=0.9 Figure 9. The number of MFI/MHP Patterns in the Pumsb Data Set of maximal hyperclique patterns is much easier to manage than that of maximal frequent patterns. Indeed, in realworld applications, it is dif?cult to interpret several million maximal frequent patterns. However, it is possible to interpret the results of maximal hyperclique pattern mining In addition, due to the memory limitation, we cannot extract maximal frequent patterns with MAFIA on the Pumsb data set if the support threshold is less than 0.4, as shown in Figure 7. In contrast, MHP can identify maximal hyperclique patterns when the support threshold is 0.1, if we set the h-con?dence threshold to 0.5. In other words, MHP has the ability to identify patterns which can be dif?cult to identify for MAFIA. Hence, MHP can better explore the pattern space and ?nd interesting patterns at low levels of support 6. Conclusions and Future Work In this paper, we present a two-phase Maximal Hyperclique Pattern \(MHP best features of both the BFS strategy and the DFS strategy. More speci?cally, we adapted DFS pruning methods such as equivalence pruning, to an apriori-like approach In addition, we proved the correctness and completeness of the MHP algorithm. Finally, our experimental results show that the MHP algorithm can be several orders of magnitude faster than standard maximal frequent pattern mining algorithms and has the ability to identify patterns at extremely low levels of support in dense data sets There are several directions for future work. First, in 


this paper, we only generate the size-2 patterns in the BFS phase. It will be interesting to investigate the impact on the performance if the ?rst phase is stopped at a deeper level Also, the projection is a very ef?cient method for ?nding patterns, especially for parallel implementation of pattern mining algorithms [1]. We plan to adapt the projection ideas into our algorithm and design an ef?cient parallel algorithm for mining maximal hyperclique patterns References 1] R. Agarwal, C. Aggarwal, and V. Prasad. A Tree Projection Algorithm For Generation of Frequent Itemsets. pages 350 371, Feb 2001 2] R. Agrawal, T. Imielinski, and A. Swami. Mining Association Rules between Sets of Items in Large Databases. In Proc. of the ACM SIGMOD Conference on Management of Data, pages 207–216,May 1993 3] R. Agrawal and R. Srikant. Fast Algorithms for Mining Association Rules. In Proc. of the 20th Int’l Conference on Very LargeData Bases, 1994 4] R. Bayardo. Ef?ciently mining long patterns from databases In Proc. of the ACM SIGMOD Conference, 1998 5] R. Bayardo and R. Agrawal. Mining the Most Interesting Rules. In Proc. of the ACM SIGKDD Conference, 1999 6] D. Burdick, M. Calimlim, and J. Gehrke. Ma?a: AMaximal Frequent Itemset Algorithm for Transactional Databases. In Proc. of IEEE Conf. on Data Engineering, 2001 7] Y. Huang, H. Xiong, W. Wu, and Z. Zhang. A Hybrid Approach for Mining Maximal Hyperclique Patterns. In In Technical Report UTDCS-34-04, Department of computer science, University of Texas - Dallas, 2004 8] J.Han, J.Pei, and Y. Yin. Mining Frequent Patterns without Candidate Generation. In Proc. of the ACM SIGMOD International Conference on Management of Data, 2000 9] M.J.Zaki and C.Hsiao. ChARM: An ef?cient algorithm for closed itemset mining. In Proc. of 2nd SIAM International Conference on Data Mining, 2002 10] R.Rymon. Search through Systematic Set Enumeration. In Proc. Third Int’l Conference on Principles of Knowledge Representation and Reasoning, 1992 11] H. Xiong, M. Steinbach, P.-N. Tan, and V. Kumar. HICAP: Hierarchial Clustering with Pattern Preservation. In Proc. of 2004 SIAM International Conference on Data Mining \(SDM 12] H. Xiong, P.-N. Tan, and V. Kumar. Mining Strong Af?nity Association Patterns in Data Set with Skewed Support. In Proc. of the Third IEEE International Conference on Data Mining \(ICDM Proceedings of the 16th IEEE International Conference on Tools with Artificial Intelligence \(ICTAI 2004 1082-3409/04 $20.00 © 2004 IEEE 





