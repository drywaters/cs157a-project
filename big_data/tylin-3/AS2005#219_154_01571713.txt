A New Technique for Fast Frequent Closed Itemsets Mining Li Ning Dept. of Computer Science Uni. of Arkansas at Little Rock Little Rock, AR 72204 lxning@ualr.edu Ningning Wu Dept. of Information Science Uni. of Arkansas at Little Rock Little Rock, AR 72204 nxwu@ualr.edu Jing Zhang Dept. of Applied Science Uni. of Arkansas at Little Rock Little Rock, AR 72204 Jxzhang1@ualr.edu  Abstract  This paper proposes a new technique for fast frequent closed itemsets mining. The method employs the concept of prefix-based equivalence class to partition the database in such a way that the possible frequent itemsets will be uniformly distributed in the partitions. One unique property of this technique is that it guarantees only 
frequent closed itemsets are generated and they are generated only once. Thus it avoids the closed-set examination in the entire mining processing. Our technique can be used in the existing frequent closed itemsets mining algorithms, including both Apriori-based and frequent pattern growth based algorithms, to improve their performance.  Moreover, the technique is well suited for parallel mining of frequent closed itemsets Keywords frequent itemset mining, data mining association rule mining 1. Introduction  As one of key data mining techniques, the association rule mining searches for the statistically meaningful associations among the items of a transaction database. Let I   i 1  i 2  
i m be a set of items and D   t 1  t 2  t n be a database of transactions, where each transaction t has a unique identifier tid and t    I An association rule is defined as X Y where Y   I  X    I  1    Y and    Y X The support of an association rule X Y 
is defined as the number of transactions in D that contain the rule, and the confidence is defined as the ratio of the number of transactions containing the rule Y X  to the number of transactions containing X The major task of association rule mining is to find frequent itemsets, because once the frequent itemsets have been found, finding strong association rules will be easy  Frequent itemsets mining finds all itemsets with supports no less than a user-specified minimum support threshold min_sup Furthermore, based on the concepts of closed set, the problem of mining frequent itemsets in a database is evolved to mining frequent closed itemsets.  An 
itemset X is closed if it has no proper superset X X   in D  such that   sup   sup X X   Given a set of itemsets, there exists a unique smallest closed set that contains the set Any set of itemsets can be represented by its closed set Compared with the frequent-itemset mining, the frequentclosed-itemset mining produces a compact and information rich output  Since the seminal work of R. Agrawal on association rule mining a ny res earch es  h a v e bee n don e t o  m a k e  mining frequent closed itemsets efficient and scalable. The 
existing approaches to frequent closed itemsets mining are either Aprioribased or frequent-pattern-growth  FP  base T h e A p ri ori bas e d al g o ri t h m s  f i n d f r equ e n t  itemsets based upon an anti-monotone property that employs an iterative approach to generate candidate itemsets. Various techniques, such as hash-based techniques, partitioning, transaction reduction, sampling and dynamic itemset counting have been applied to improve their efficiency h o w e v e r A p ri ori bas e d  algorithms suffer from two nontrivial costs: generating a huge number of candiate itemsets and scanning the database repeatedly for the frequency counting of 
candidates set. The FP-growth based algorithms avoid candidate itemsets generation. Instead of generating candidate sets, they recursively partitions the database into conditional databases according to the frequent patterns found and searches for local frequent patterns to assemble longer global patterns. Each conditional database is associated with a frequent pattern, which is shared as a prefix by all the frequent itemsets of the conditional database. To obtain frequent closed itemsets, a closurechecking procedure is used to examine whether a newly found frequent closed candidate is a subset of an already found closed itemset.  Such closure-checking procedure is computationally expensive when mining a large database because the potential frequent closed itemsets are likely very large. Improvements have been proposed to reduce 
any unnecessary closure-checki d m a k i n g t h e  closure-checking more efficien t n o n e of  th e m ca n completely eliminate it from the mining process. In addition, the closure-checking procedure makes it difficult to parallelize the existing efficient frequent closed itemset algorithms among a group of processors due to the overhead of communication cost incurred by closure checking  In this paper, we propose a new method for frequentclosed-itemset mining that eliminates the closed-setchecking procedure. Our method uses the prefix-based equivalence class concept to partition the search space of a 


transaction database into a set of subspaces called classes Then by exploiting the relationships of frequent itemsets among different classes it is able to identify the redundant itemsets before generating them and thus prevents the generation of any non-closed itemsets  Our method is especially suitable for mining very large datasets for two reasons. Firs t, it is stateless, that is no memory is needed for keeping the frequent closed itemsets obtained by the previous iterations of the mining. Second because of the statelessness the entire mining process can be divided into a set of independent subtasks so that each subtask can be accommodated into the main memory.  The method is also suitable for parallel mining frequent closed itemsets among a group of processors such as a cluster from a horizontal partitioned database. Each processor will work independently without any communications with other processors when loaded with a portion of the database, and the final mining result is simply an aggregation of the outputs from all processors. It is worth of pointing out that the method can be easily adopted by existing algorithms to improve their efficiency. To demonstrate the effectiveness of our method, we have implemented the proposed method in a sequential algorithm and conducted the experiments using different datasets  The remainder of this paper is organized as follows Section 2 presents the related work. Section 3 gives a brief overview of the prefixed-based equivalence class and split algorithm on which our work is based on. Section 4 introduces our method. Section 5 presents the experimental results and section 6 offers conclusion of this work 2 Related work   Efficient algorithms are proposed for mining frequent closed itemsets including CHARM C M 15  CLOSET d A F O P T  13]. Bot h C H A R M an d LC M  uses a vertical representation of the database and enumerates frequent closed itemsets. CHARM enumerates closed sets using a dual itemset-tidset search tree, while LCM defines a child-parent relationship between frequent closed itemsets which induces a tree-shaped transversal routes composed only of all the frequent closed itemsets Both CLOSET+ and AFOPT algorithms take FP-growth approach that uses the divide-and-conquer method CLOSET  improves CLOSET algorithm by \(1\hybrid tree-projection method to improve the space efficiency for tree construction of databases, \(2\tem skipping for further pruning search space and speeding up mining, and \(3 efficient subset checking for saving memory and accelerating the closure checking. AFOPT uses an adaptive approach to dynamically adjusts strategy for item search order, conditional tree database representation, conditional database construction, and tree traverse  Our proposed method assumes a horizontal representation of the database. Similar to CLOSET  and AFOPT, it uses the divide-and-conquer methodology to partition the search space of a database and mine each partition recursively. Different from frequent-patter growth based algorithms, our method uses the prefix-based equivalence class concept to partition the search space of a database. By dividing a conditional database into class and non-class segments, our method is able to identify redundant itemsets before generating them and thus ensures that only frequent closed itemsets are generated and they are generated only once 3 Equivalence class and the split algorithm   Let I be a set of m items and D be a database of transactions. Denote 2 I as the power set of I and     I I 2 2  I 2 consists of all possible frequent itemsets defined on I An itemset s  I can be represented as a sequence that is sorted in support ascending order. Such a sequence is referred to as a canonical attribute sequence  cas stance, given an itemset s= {a, c, e, d, f} with the individual item support as 3, 4, 4, 2, and 4 respectively s can be represented by the cas dafec The cardinal of a cas s is denoted as |s|. In the reminder of this paper, an itemset s  is represented by a cas, to which all the set operators are applicable. Without causing confusion, we also use s to represent its corresponding cas and s  d e n o te it s  i th  1   i item Definition 1  Let s be a cas, and k be an integer such that  s k   0 The k-length prefix of s is denoted pre  s,k   Definition 2  Let        2    2 k s s k I I      represent the subset of cass whose sizes are greater than or equal to some fixed threshold k For any   2 k s I   and   2 k r I    012 k defines a prefix-based equivalence relation as follows         k r pre k s pre r s k    012  Definition 3  A prefix-based equivalence class denoted as C  h ere I C  is a set of all cass that share the common prefix C    Let   k 015 be the set of prefix-based equivalence classes induced by 012 i k i   1 Based on the concept of equivalence class, Algorithm 1 provides a way of partitioning  I 2 of a given transaction database D into a set of equal-sized disjoint equivalence classes  In the Algorithm 1 I is a cas representing a set of m  items on which a transaction database D is defined. . is the catenation operator. In this paper we use the notations  1       k j j I k I p    and  1       m j k j I k I s      


for the first k items and the last m  k items of I respectively Given an integer k 1 0    m k the split algorithm partitions  I 2 into k 2 disjoint prefix-based equivalence classes X i  h ere   2 k I i p X  In other words     k X 015   if     k X 015  Each member in a class X i  h ares th e s a m e  prefix X i Each class is of the same size 1 2   k m    The proof of the split algorithm can be referred to 17 Fig u r e 1 s h o w s an e x a m p l e o f p a rtitio n i n g th e searc h  space of a database into the classes by the split algorithm In the example I  abcde  k 2  2    2  015 I split generates 015 2 ab   a   b     h e r e each clas s  h a s  s e v e n members       Figure 1 Equivalent classes  2  015  4. Proposed method 4.1 Motivation   The closure-checking procedure of the existing frequent-closed-itemset mining algorithms not only is computational expensive but also wastes processor time and memory space for producing and keeping redundant itemsets Could it be possible to completely eliminate the closure-checking This question motivates our work To answer this question, we need to understand why the closure-checking is needed by the current algorithms As we know, all FP-growth based approaches employ the  divide-and-conquer methodology. The search space of frequent itemsets of a database D is partitioned into disjoint sub-spaces, and mining frequent itemsets in D is transferred to mining frequent itemsets from a set of conditional databases, each is associated with a search subspace.  As itemsets of one conditional database are potentially the subsets or supersets of the itemsets of other conditional databases, the closure-checking is necessary for removing the redundant itemsets  Thus, is there any way to predict which itemsets are redundant before generating them?  The reminder of this paper discusses a method of partitioning the search space of a databases based on the concept of the prefix-based equivalence class so as to avoid the generation of redundant itemsets in the mining process 4.2 Class segment and non-class segment  In the following discussion, we assume that \(1\iven a database D a predefined integer k and I represented as a cas, the split algorithm partitions the search space of frequent itemsets  I 2 into k 2 classes denoted as   k 015  2 X i  k i 2 1   denotes a prefix-based equivalence class with the prefix X i 3  1       k j j I k I p     denotes the k-prefix-set and  1       m j k j I k I s      the k-suffix-set of I respectively; \(4\or an itemset X    I  X s conditional database, denoted as cond X s defined as       I t X D t t X cond i i i      Lemma 1 Let X  ix bas ed equ i v a le n ce clas s  and Y be any frequent itemset from D If   X Y  then cond Y   cond X  Proof  X Y X Y    so Y t D t i i      X t i  In other words   Y cond t i    we have   X cond t i  Thus,  cond Y   cond X   Lemma 1 states that Y can be mined directly from cond X  Y is a member of X  h en e x te n d in g  L e m m a 1  to all the itemsets of the class X   w e ha ve t h a t  t h e s e  itemsets can all be mined directly form cond X  For any two classes X 1  d  X 2     k 015 their relationships can be summarized as follows 1  Lemma  2.1   2 1 X X  belongs to   k 015  Proof From       2 1 k X X 015  we have   1 k I X p   and  2 k I X p  Thus     2 1 k I X X p   which means     2 1 k X X 015    2  Lemma 2.2 If   2 1  X X and    2 1 X X then   1 X x   no  2 X y  exists such that x y  or y x  holds Proof Given an itemset  1 X x  assume there is an items  2 X y  such that y x  Based on the definition of the prefix-based equivalence class x and y can be represented as 1 1 s X x   and 2 2 s X y   where    2 1 k I s s s      2 1 s X and    1 2 s X   Thus  Algorithm 1 split I  k    k 015    015   k  for  h  k 1 h 0 h  do     1          I k pre S h S S h k I casSet       for each     h k I casSet S   do               k I S S k k  015  015  


       2 1 2 1 2 2 1 1           s X X X s X X y X  It indicates that X 1 is not a subset of y thus 1 1 s X x    cannot be a subset of y either. Similarly we can prove y is not a subset of x either 3  Lemma 2.3 if 2 1 X X  then    2 1 X y X x      such that y x   Proof An itemset  1 X x  can be represented as s X x   1 where   k I s s  Based on s we can construct an itemset  2 X y  such that s X y   2 Since 2 1 X X  and both x and y share the same suffix s we have y x   Lemma 2.1  states that union of the prefixes of any two classes of   k 015 still makes a prefix of some class of   k 015 Thus, when mining frequent closed itemsets of the class X i  t i s pos s i bl e t o av oi d g e n e rat i n g redun dan t  itemsets by examining the X i  s relat i o n s h ip  w i th o t h e r  classes. For example, if X 1 appears in some transactions of cond X 2 be removed from these transactions because the itemsets containing both X 1 and X 2 should be mined from cond  2 1 X X   If X 1 appears in every transaction of cond X 2 en cond X 2 not need to be mined since no itemset x   X 2  be clos ed becau s e of sup x  X 1 p x emma 2.2 states that the itemsets in  X 1  m u tu a l e x cl u s i v e to th e ite m s et s i n  X 2  f     2 1 X X   To identify which itemsets in a class should be generated and which should not, this paper proposed to partition a conditional database cond X i  into a class  segment and non-class segment so as to identify any redundant itemsets in X i  Definition 4  class segment and non-class segment  The conditional database cond X i be partitioned into two parts class segment and non-class segment They are defined as follows             k I X t I t X D t t X cond s i i class i        class i i nclass i X cond X cond X cond            where  1       m j k j I k I s       The class segment of cond X i s made up of the transactions that can be represented as s X i  where   k I s s  The non-class segment is made up the transactions that can be represented as s z X i    where    i p X k I z   When cond X i is not empty, it can have three structures 1       class i nclass i X cond X cond       2       class i nclass i X cond X cond       3       class i nclass i X cond X cond       Let i p X k I G     In the following discuss we explain how to ensure only closed itemsets are generated for each of the above cases Case-1 In this case, each transaction contains both X i  and some items of I p  k  If there exists an itemset G p  appearing in every transaction of cond X i en cond X i ill not be mined because  x   X i  u p x  sup p x  Thus no itemset in X i  clos ed  Otherwise, for any itemset G p   in nclass i X cond    removes p from nclass i X cond    because  any itemset containing p X i  can be mined from   p X cond i    Case-2 In this case, every frequent closed itemset of cond  X i belongs to   i X and is globally closed. To prove it, assume a frequent itemset   i X x  has a superset   j X y  such that y x  and sup  x  sup  y  Let j i X X z   Then z must appear in cond X i his contradicts the condition   nclass i X cond   Thus, if Case-2 holds, any frequent closed itemsets generated from cond X i ed Case-3 In this case some transactions contain an itemset G p  and some not; however, no itemset p is included in every transaction since   class i X cond    If an itemset s p y   with G p  and   k I s s   appears in every transaction of nclass i X cond   then s  is removed from nclass i X cond    due to the fact that no itemset x  X i    s is closed  since sup x up x  p  4.3 Mining frequent closed itemsets without closure checking  Based on the above discussion, Algorithm 2 describes a frequent closed itemsets mining algorithm without closure-checking. Given a support threshold min_sup a prefix X i and I s  k         i i p i Z X cond k I X extract obtains all the frequent closed itemsets in X i  d s t or es t h e m i n  Z i  Definition 5 An itemset x is closed iff there exists no itemset y such that y  x and sup y up x   In the Algorithm 2   class  and nclass  represent the number of transactions in cond X i  class i X cond   and nclass i X cond    respectively, and nclass class        s   denotes the number of transactions in   i X cond  containing s and nclass s     the number of transactions in nclass i X cond    containing s  


extract       i i i Z X cond X  takes an iterative approach, like FP-based algor ithms, to generate frequent closed itemsets of the class X i  o re m i n i ng a n y  frequent itemset  i X x  it examines if x has a superset belonging to a different class that has the same support. If the answer is yes, then x is redundant and will not be generated. This redundancy-evaluating procedure ensures that no subset of a closed frequent itemset is generated, and thus it guarantees that only closed frequent itemsets are generated and they are generated only once  The algorithm first checks if i X is frequent or not. If   min_sup then it stops and returns. Lines 7-9 evaluate which itemset in X i  redu n d a n t f o r C a s e 1. L i n e 10  generates the frequent closed itemset 1 Y X i if it exists for Case 2. Lines 11-13 evaluate which itemset in X i is redundant for Case 3. Line 14  removes 1 Y and 3 Y from  if applicable, because 1 Y X i forms a new common prefix pattern of cond X i ines16-20 recursively call this algorithm until    This algorithm has two advantages First, it uses equivalence class to quickly filter an itemset that is frequent but not closed, without performing closurechecking operation as FP-based algorithms do. Secondly, it ensures that any frequent closed itemsets from D is extracted only once Algorithm 3     pmine  D I,min_sup k describes how to mine the complete set Z of frequent closed itemsets of D The input parameter D of the algorithm is preprocessed and contains only items whose support is no less than min_sup Given a predefined k we assume that the split algorithm      k I k split 015 partitions the itemset space I into disjointed classes, and that the algorithm parallelly constructs k 2 conditional databases and extracts all the frequent closed itemsets of each class    Lets use an example to illustrate this algorithm Table 1 shows a transaction database DB defined on abcde I  Assume min_sup=2 and k 2.  After preprocessing, DB becomes D as shown in Table 2 b I   2  and  P c,d,e  Tid Items tid Items 1 bcade 1 abcde 2 bfd 2 bd 3 cde 3 cde 4 bcae  4 abce 5 cde  5 cde Table 1 Original DB Table 2 Database D   First, the algorithm  2    2  015 I split  generates          2    015 b a ab Then pmine  k  I  min_sup  D  Z  extracts all the frequent closed itemsets of each class Figure 2 illustrates how to parallelly construct and mine the conditional database for each class. The four conditional databases are cond ab ond a d b d cond   The notation x  sp represents an itemset x and its support sp Initially P={c,d,e}.  The algorithm proceeds as follows 1\d all the frequent closed itemsets in ab  ecau s e    class ab cond   and   nclass ab cond   cond ab  Case-2. Since sup abce sup ab  min_sup 2  abce is added into ab  Besides, sup d  min_sup leads to     Therefore, the mining in   ab finishes  Algorithm 3 pmine   D min_sup   I k  1   1     m j k j I       2       k I k split 015  3  foreach      k X i 015   do  4     i Z  5         I X D t X t X cond i i i i      6         i i i Z X cond X extract   7  i i k      2 1  Algorithm 2  extract  i i p i Z X cond k I X       Let i p X k I G     P   k I s  1  if   min_sup  then return 2          1       s s s Y   3             11 nclass nclass s s s s Y           4          2      s G s s Y   5           21 nclass nclass s G s s Y        6   min_sup        3      s s s Y   7  if 0 0      nclass class  then  8   if   2 Y  then 1 Y X X i i   9   else     return  10  if 0 0      nclass class  then 1 Y X X i i   11  if 0 0      nclass class  then  12   1 Y X X i i   13   if   21 Y  then 11 Y      14  3 1 Y Y       15  if     i X  then   i i i X     16  if     then  return  17  foreach   s  do  18     s      19          i i i i i t s X cond t t s X cond      20         i i i Z s X cond s X extract     


2\d all the frequent closed itemsets in a  i n c e    class a cond   and   nclass a cond   cond a in Case 1. Because nclass nclass b       itemsets of   a are not mined 3\d all the frequent closed itemsets in b  i n c e    pure b cond      npure b cond   cond b Case-3 As no itemset has the same support as b  b 3 is added into b  Because of nclass nclass ace        c and e are removed from P. Since sup d  min_sup cond bd ith P  needs to be mined. Clearly cond bd Case-3 as   class bd cond   and   class bd cond    As no itemset has the same support as bd  bd 2 is added into b  The mining then finishes 4\ Find all the frequent closed itemsets in   ecau s e of    class cond   and    nclass cond   cond   Case-3. The task of mining cond  further decomposed into mining of cond c ith P d,e cond d ith P e  and cond e ith P  cond  c Case-3 as   class c cond   and   nclass c cond    Because e appears in every transaction of cond c d sup ce  ce 4 is added into Z   d does not appear in every transaction of nclass c cond    even though ab does so, hence mining  cond cde ith P  is still needed. With sup cde  cde 3 is added into   cond d Case-3 due to   class d cond   and   nclass d cond    Since sup d  d 4 is added into   cond de ith    is in Case-1 as   class de cond   and   nclass de cond   Due to nclass nclass c        cde 3 is not added to   even though sup cde  min_sup cond e Case-1 as   class d cond   and   nclass d cond    Because nclass nclass c        ce 4 is not added to   The mining of    finishes  It is worth of pointing out     pmine  D I,min_sup k  can be directly applied to parallel mining. In this case k is determined by the number of processors in a parallel computing system. Each processor is loaded a conditional database of a class, and the mining of each class can be done in parallel. When a processor finishes its job much earlier than others, load balancing is required 5. Experimental Results  In this section, we compare the performance of our method PMINE with AFOPT. All experiments are performed on a 500MHz Pentium III with 192MB of memory, running RedHat Linux 6.0. For performance comparison we used the original source for AFOPT obtained from its authors  We choose benchmark datasets downloaded from FIMI03 workshop web site. Table 3 shows the datasets characteristics Dataset Size #Trans MaxTL AvgTL T10I4D100K 3.93M 100000 30 10.10 T40I10D100K 15.12M 100000 78 39.61 Connect-4 9.11M 67557 43 43.00 Pumsb 16.30M 49046 74 74.00 Table 3 Dataset characteristics  Figures 3-6 show the running time for different datasets with different minimum support threshold. In the experiment, we combine our technique with FP-Tree data structure. Generally, it is faster than AFOPT.  In addition the new technique can be easily used in the existing frequent closed itemsets mining algorithms to improve their efficiency. The most important is its capability of parallel mining with workload balance  abcde bd cde abce cde D cde ce cond\(ab P={c,d,e bcde bce cond\(a P={c,d,e acde ace d cond\(b P={c,d,e abcde bd abce cde cde cond  P={c,d,e Z ab abce:2 P Z a  P Z b b:3 P={d Z  P={c,d,e abde abe de de cond\(c P={d,e Z ce:4 P={d ace cond\(bd P Z b b:3, bd:2 P abce b ce ce cond\(d P={e abcd cd abc cd cond\(e P ab cond\(cde P Z ce:4,d:4 P={e Z ce:4,d:4 P  Z ce:4,d:4,cde:3 P abc c c cond\(de P Z ce:4,d:4,cde:3 P non-class part class part Note A conditional database is divided into two parts, shown as the right figure. The part above the dashed line is non-class segment. The part under the line is class segment conditional database Z={abce:2, bd:2, b:3,cde:3,ce:4,d:4 Figure 2  Mining frequent closed itemsets using pmine  


6  Conclusions  In this paper, we investigate a new frequent-closeditemset mining method that can greatly enhance the efficiency and scalability of the current association rule algorithms. The main contributions of this work are: 1\he method completely eliminates the computationally expensive closure-checking procedure in the frequent closed itemset mining and thus is particularly useful for mining very large datasets; 2\ the method is applicable to not only sequential mining but parallel mining   Dataset: T10I4D100K 0 2 4 6 4 321 M inim um Suppor t     PM INE AFOPT  Figure 2 Running time for dataset T10I4D100K  Dat aset  T40I 10D100 K 0 5 10 15 20 2 5 21.51 M inim um Suppor t     PM INE AFO PT  Figure 3 Running time for dataset T40I10D100K Dataset: Connect-4 0 2 4 6 8 10 95 90 85 80 M inim um Suppor t     PM INE AFO PT  Figure 4 Running time for dataset Connect-4  Dataset: Pum sb 0 5 10 15 95 90 85 80 M inim um Suppor t     PM INE AFO PT  Figure 5 Running time for dataset Pumsb 7. References 1  N. Pasquier, Y. Bastide, R. Taouil, and L. Lakhal Discovering frequent closed itemsets for association rules In ICDT99, Jan. 1999 2  R. Agrawal, T. Imielinski, and A. Swami.  Mining association rules between sets of items in large databases SIGMOD'93, 207-216, Washington, D.C 3  J. Han, J. Pei, and Y. Yin. Mining frequent patterns without candidate generation. In Proc. 2000 ACMSIGMOD Int. Conf. Management of Data \(SIGMOD00 Dallas, TX, May 2000 4  R. Agrawal and R. Srikant. Fast algorithms for mining association rules. In Proc. 1994 Int. Conf. Very large Data Bases \(VLDB94\es 487-499, Santiago, Chile September 1994 5  H. Mannila, H. Toivonen, and A. I. Verkamo Efficient algorithms for discovering association rules KDD'94, 181-192, Seattle, WA, July 1994 6  A. Savasere, E. Omiecinski, and S. Navathe. An efficient algorithm for mining association rules in large databases. VLDB'95, 432-443, Zurich, Switzerland 7  H. Toivonen.  Sampling large databases for association rules.  VLDB'96, 134-145, Bombay, India Sept. 1996 8  M.J. Zaki, S. Parthasarathy, M. Ogihara, and W. Li New algorithms for fast discovery of association rules KDD97. August 1997 9  S. Brin, R. Motwani, J. D. Ullman, and S. Tsur Dynamic itemset counting and implication rules for market basket analysis. SIGMOD'97, Tucson, Arizona, May 1997 10  D.W. Cheung, J. Han, V. Ng, and C.Y. Wong Maintenance of discovered association rules in large databases: An incremental updating technique. ICDE'96 New Orleans,  LA 


11  J.S. Park, M.S. Chen, and P.S. Yu. An effective hash-based algorithm for mining association rules SIGMOD'95, San Jose, CA, May 1995 12  J. Wang, J. Pei, and J. Han. Closet+: Searching for the best strategies for mining frequent closed itemsets. In SIGKDD 2003 13  C. Liu, H. Lu, J. X. Yu, W. Wang, X. Xiao. AFOPT An Efficient Implementation of Pattern Growth Approach In SDM 2003 14  M. J. Zaki and C. Hsiao. CHARM: An efficient algorithm for closed itemset mining. In SDM, 2002 15  T. Uno, T Asai, Y. Uchida, and H. Arimura. LCM: An Efficient Algorithm for Enumerating Frequent Closed Item Sets. In SDM 2003 16  C. Hughes, T. Hughes. Parallel and Distributed Programming Using C++. Addison Wesley Professional Aug 25, 2003 17  J. Adamo. Data Mining for Association Rules and Sequential Patterns --Sequential and Parallel Algorithms Springer  2000   


Figure 3 Example of a patent abstract with its generated multi-index. The multi-index that has been generated for the above patent abstract corresponds to the \223 Final indexation 224 field. The terms of the generated multi-index are prefixed by the name of the viewpoint to which they are associated: \223adv.\224 for the Advantages viewpoint, \223titre.\224 for the Title viewpoint, \223use.\224 for the Use viewpoint, \223soc.\224 for the Patentees viewpoint Patentees Title Use es GlobMin WEBSOM  WEBSOM  Number of indexed documents \(NID 1000 1000 745 624 1000 1000 Number of rough indexes generated \(NRI 73 605 252 231 1395 1395 Number of final indexes \(NFI 32 589 234 207 1075 1075 Numbers of map nodes with members \(/100 28 55 57 61 89 238 Table 1 Summary of the results of patent indexation and map building. Note that the NRI \(resp. NFI\ \223global viewpoint\224 are less than the sum of the NRIs \(resp. NFIs\ specific viewpoints \(i.e. 1089\ecause there are similar indexes occurring in different viewpoints Patentees Title Use es MSOM GlobMin WEBSOM  WEBSOM R 0,94 0,89 0,78 0,77 0,85 0,87 0,84 P 0,92 0,40 0,63 0,60 0,64 0,48 0,65 F 0,93 0,55 0,70 0,67 0,71 0,61 0,68 Table 2 Summary of the results of Quality, Recall and Precision evaluation. The nearer the different values are from 1, the better are the clustering results. The F value provides a synthesis of the results of R and P Proceedings of the Fourth International Conference on Coordinated Multiple Views in Explor atory Visualization \(CMV\22206 ISBN-10: 0-7695-2605-5/06 $20.00 \251 2006  IEEE 


Figure 4 Example of a generated map. Partial view of a topographic map of 10 x 10 nodes. The map is initially organized as a square 2D grid of nodes. The viewpoint chosen for the showed map is the Advantages viewpoint. The names of the clusters illustrate the topics \(considering the chosen viewpoint\ been highlighted by the learning. After the learning, the no des related to the same topics have been grouped into coherent areas thanks to the topographic properties of the map. The number of nodes of each area can then be considered as a good indicator of the topic weight in the database. Topics or areas near one to another represent related notions. For example, the \223 extending oil live 224 area shares some of its borders with the \223 black sludge control 224 area on the map. The proximity of these two areas illustrates the fact that oil duration strongly depends \of maintaining a low level of sludge in it. The surrounding circles represent the centers of gravity of the areas  1 2 3 Patentees Title Advantages Use 3 2 1 Figure 5 Example of exploitation of the inter-map communication mechanism. The analyst decision to activate the area corresponding to the TONEN CORP. company on the Patentees map and to propagate the activity to the thematic maps associated to the Use  Advantages and Title viewpoints corresponds to a "viewpoints crossing query" whose explicit formulation might look like: "I want to know which are the specific areas of competence \(concerning oil use, oil composition and expected advantages\". The MultiSOM application let him interactively find that TONEN CORP. company is a specialist of the lubrication of the automatic transmissions [arrow n\2602 on th r  this kind of lubrication sulfur-containing organo-molybdenum compound [arrow n advantages are to provide oil with a friction coefficient that is stable on a wide range of temperature [arro In this ca se, an inverted propagation fr om the target topics should be also used to verify that these topics only belong to TONEN CORP. areas of competence. The whiter is the color of a node representing a map cluster \(topic\ing activity Proceedings of the Fourth International Conference on Coordinated Multiple Views in Explor atory Visualization \(CMV\22206 ISBN-10: 0-7695-2605-5/06 $20.00 \251 2006  IEEE 


 Profile of topic Extending oil life Figure 6 Results of a WEBSOM-like global mapping of 10x10 nodes GlobMin The left part of the figure represents the WEBSOM-like mapping \(i.e. without viewpoint management\repre sents the description \(i.e. profile\ \223 extending oil life 224 WEBSOM global topic. Even if a strong relationship between \223 extending oil life 224 and \223 black sludge control 224 topics has been highlighted by the MultiSOM viewpoint-oriented clustering \(see map of figure 3 relationship has been lost by the WEBSOM-like clustering due to the noise of the global clustering \(this relationship do not ap pear neither in the above map, nor in the \223 extending oil life 224 topic profile Figure 7 Comparison between a 11x11 \223Use viewpoint\224 thematic map and a 16x16 \223Use viewpoint\224 thematic map through map extracts The 11x11 map extract is presented at the left, the 16x16 map extract is presented at the right. On the figure, the focus is gi ven 223 machine oil 224 topic. The comparison highlights, as an example, that the logical surrounding of this topic is more precisely defined in the 16x16 map \(optimal quality\n in the 11x11 map \(lower quality\n the 11x11 map, the topic \223 machine oil 224 has been derived in a more fuzzy scope topic named \223 machine and vehicles 224 Proceedings of the Fourth International Conference on Coordinated Multiple Views in Explor atory Visualization \(CMV\22206 ISBN-10: 0-7695-2605-5/06 $20.00 \251 2006  IEEE 


ANNEX: example of interactive dynamic multi-viewpoint analysis Dynamic analysis takes place main ly by using the inter-map communication mechan ism which makes it possible to bring to successful conclusion sets of topics deductions between differen t viewpoints chosen like investigation under-fields. This a nalyze is based on the generation of an initia l activity corresponding to the premises of the deduction to check. According to stages of analyze, this activity can itself be generated several manners by the analyst on one or more source map. If the activity generation is d irectly operated by analyst on a map, it corresponds then to broad a set of topics question. If the activity generation is operated indirectly by projection query on a map or by activation of documents group stored befo rehand in a collector of documents, it corresponds then to more targeted question, which can intervene in one second stage of the analyze The analyst interest is to hi ghlight the specific areas of competence of the Exxon company. On the simulation of analysis we develop on figure 7, we will consider two different viewpoints Patentees which will represent the source of the analysis and the Title viewpoint which will represent its destination The analyst starts the process of deduction by generating an initial activity on the main Exxon topic i.e. Exxon area gravity center\ of the Patentees viewpoint map. To obtain a broad set of potential deductions, he selects the Possibilistic mode of deduction 17  The activity generated by the inter-map  communication mechanism on the Title viewpoint map is focused in two different zone s of this map, corresponding to two potential results In the first active zone \(1\, the analyst makes use two different naming strateg ies to facilitate its interpretation namely a naming strategy based on the profile of the topics more generic\ and a naming strategy based on the profile of the best members \(i.e. patents\of the topics more specific\. These operations enable him to highlight that the Exxon company is specialized in a correlative way on topics: \215 marine diesel engine 216 215 surfactant system 216 and \215 basic calcium compound 216 The expert checks the correlation between these topics by consulting the patents associated to the topic 215 surfactant system 216 \(2\. The title of the patents already confirm him the problematic de tected by the application A thorough examination of th e contents of the documents will show him than the pur pose of use of surfactant containing calcium in add ition with the normal formula of oils is to protect the combustion chambers of the marine diesel engines against corrosion due to the absorption of air charged out of salt during their operation. The problem of protection of the marine engines against corrosion is sufficiently important to represent a field of investigation for an oil manufacturer like Exxon The construction of a query containing the single descriptor \215 surfactant system 216 \(3\ on the Title viewpoint will allow the analyst 1 To validate the correlation between 215 surfactant system 216 and \215 marine diesel engine 216 topics which will be interpreted by the fact that 215 surfactant system 216 is only associated with 215 marine diesel engine 216 2 To check the inverse deduction 215 surfactant system 000\306 Exxon 216 which will insure him that Exxon is the only company whose interest in the conception of \215 surfactant system 216 The result of the projection of the query on the Title viewpoint map \(4\ shows that the generated activity is peculiar to the logical topic area \215 marine diesel engine 216, which confirms th e first assumption Simultaneously with projection the documents that are relevant for the query are presented in a Collector \(5 The global activation of these documents allows analyst to initiate a new de duction.  Then, the result of this latter can be examined on the Patentees map. Like only the main Exxon topic has been activated \(6\, the second assumption of the an alyst is confirmed The second active zone \(7\ generated by the initial process of deduction will allow the analyst to observe that the second major field of activity of Exxon is the 215 biodegradable 216 oils. It will be able to also note that these oils are more specifically us ed for the lubrication of the two-stroke engines \(\215 two cycle engine 216\ that generally reject much unburned oil Probabilistic mode of deduction will allow him to check if the inverse deduction, namely, that Exxon is the only company to be worked on biodegradable oils, can be validated \(8\. This process will lead the analyst to conclude that 215 biodegradable 216 oil manufacturing is shared between Exxon and Mobil companies \(9\, which are the most important oil manufacturers A complementary use of negative activity setting on the \215 two cycle engine 216 topic \(10\ will show more precisely to the analyst that that Mobil company mainly focus on manufacturing of biodegradable oils for \215two stroke engines\216 and, in a complementary way, that Mobil company only focus on manufacturing of biodegradable oils for \215four stroke engines\216 \(11 The simulation of analysis presented here above shows clearly how the analyst can make use of the MultiSOM functionalities in order to highlight all the privileged activity fields of the Exxon company starting from a patents database related to engineering of oils Main functionality is inter-map communication. Multiple naming strategies, generation of queries and collection intermediate results that have been implemented complementary to inter-map communication also play an important role in the analysis process Proceedings of the Fourth International Conference on Coordinated Multiple Views in Explor atory Visualization \(CMV\22206 ISBN-10: 0-7695-2605-5/06 $20.00 \251 2006  IEEE 


     Activated area 1    Inverse validation 10 Categorical rejection Categorical choice Activity resulting from the inverse validation Result  28,6 and 17 11 Focalization Inverse validation Activity resulting from the inverse validation 9 Result 28,6% and 23 5 6 3 Legend  Viewpoint 215Patentees\216 Viewpoint 215Title\216  Projection resulting from the inverse validation Activated area 2 7 1 8 Analysis of deduction 2  4 Figure 8 Diagram of the analysis simulation Result 100 Proceedings of the Fourth International Conference on Coordinated Multiple Views in Explor atory Visualization \(CMV\22206 ISBN-10: 0-7695-2605-5/06 $20.00 \251 2006  IEEE 


per by Ganti et. al. [9] deals with the measurement of similarity \(or deviation, in the authors  vocabulary between decision trees, frequent itemsets and clusters Although this is already a powerful approach, it is not generic enough for our purpose. The most relevant research e?ort in the literature, concerning pattern management is found in the ?eld of inductive databases Proceedings of the 16th International Conference on Scientific and Statistical Database  Management \(SSDBM  04 1099-3371/04 $ 20.00  2004 IEEE meant as databases that, in addition to data, also contain patterns [10], [7]. Our approach di?ers from the inductive database one mainly in two ways. Firstly, while only association rules and string patterns are usually considered there and no attempt is made towards a general pattern model, in our approach no prede?ned pattern types are considered and the main focus lies in devising a general and extensible model for patterns Secondly, di?erently from [10], we claim that the peculiarities of patterns in terms of structure and behavior together with the characteristic of the expected workload on them, call for a logical separation between the database and the pattern-base in order to ensure e?cient handling of both raw data and patterns through dedicated management systems Finally, we remark that even if some languages have been proposed for pattern generation and retrieval 14, 11], they mainly deal with speci?c types of patterns \(in general, association rules sider the more general problem of de?ning safe and su?ciently expressive language for querying heterogeneous patterns 7. Conclusions and Future Work In this paper we have dealt with the issue of modelling and managing patterns in a database-like setting Our approach is enabled through a Pattern-Base Management System, enabling the storage, querying and management of interesting abstractions of data which we call patterns. In this paper, we have \(a de?ned the logical foundations for the global setting of PBMS management through a model that covers data patterns and intermediate mappings and \(b language issues for PBMS management. To this end we presented a pattern speci?cation language for pattern management along with safety constraints for its usage and introduced queries and query operators and identi?ed interesting query classes Several research issues remain open. First, it is an interesting topic to incorporate the notion of type and class hierarchies in the model [15]. Second, we have intentionally avoided a deep discussion of statistical measures in this paper: it is more than a trivial task to de?ne a generic ontology of statistical measures for any kind of patterns out of the various methodologies that exist \(general probabilities Dempster-Schafer, Bayesian Networks, etc. [16 nally, pattern-base management is not a mature technology: as a recent survey shows [6], it is quite cumbersome to leverage their functionality through objectrelational technology and therefore, their design and engineering is an interesting topic of research References 1] Common Warehouse Metamodel \(CWM http://www.omg.org/cwm, 2001 2] ISO SQL/MM Part 6. http://www.sql99.org/SC32/WG4/Progression Documents/FCD/fcddatamining-2001-05.pdf, 2001 3] Java Data Mining API http://www.jcp.org/jsr/detail/73.prt, 2003 4] Predictive Model Markup Language \(PMML http://www.dmg.org 


http://www.dmg.org pmmlspecs v2/pmml v2 0.html, 2003 5] S. Abiteboul and C. Beeri. The power of languages for the manipulation of complex values. VLDB Journal 4\(4  794, 1995 6] B. Catania, A. Maddalena, E. Bertino, I. Duci, and Y.Theodoridis. Towards abenchmark for patternbases http://dke.cti.gr/panda/index.htm, 2003 7] L. De Raedt. A perspective on inductive databases SIGKDD Explorations, 4\(2  77, 2002 8] M. Escobar-Molano, R. Hull, and D. Jacobs. Safety and translation of calculus queries with scalar functions. In Proceedings of PODS, pages 253  264. ACMPress, 1993 9] V. Ganti, R. Ramakrishnan, J. Gehrke, andW.-Y. Loh A framework for measuring distances in data characteristics. PODS, 1999 10] T. Imielinski and H. Mannila. A database perspective on knowledge discovery. Communications of the ACM 39\(11  64, 1996 11] T. Imielinski and A. Virmani. MSQL: A Query Language for Database Mining. Data Mining and Knowledge Discovery, 2\(4  408, 1999 12] P. Kanellakis, G. Kuper, and P. Revesz. Constraint QueryLanguages. Journal of Computer and SystemSciences, 51\(1  52, 1995 13] P. Lyman and H. R. Varian. How much information http://www.sims.berkeley.edu/how-much-info, 2000 14] R.Meo, G. Psaila, and S. Ceri. An Extension to SQL for Mining Association Rules. Data Mining and Knowledge DiscoveryM, 2\(2  224, 1999 15] S. Rizzi, E. Bertino, B. Catania, M. Golfarelli M. Halkidi, M. Terrovitis, P. Vassiliadis, M. Vazirgiannis, and E. Vrachnos. Towards a logical model for patterns. In Proceedings of ER 2003, 2003 16] A. Siblerschatz and A. Tuzhillin. What makes patterns interesting in knowledge discovery systems. IEEE TKDE, 8\(6  974, 1996 17] D. Suciu. Domain-independent queries on databases with external functions. In Proceedings ICDT, volume 893, pages 177  190, 1995 18] M.Terrovitis, P.Vassiliadis, S. Skadopoulos, E. Bertino B. Catania, and A. Maddalena. Modeling and language support for the management of patternbases. Technical Report TR-2004-2, National Technical University of Athens, 2004. Available at http://www.dblab.ece.ntua.gr/pubs Proceedings of the 16th International Conference on Scientific and Statistical Database  Management \(SSDBM  04 1099-3371/04 $ 20.00  2004 IEEE pre></body></html 


The reason of the hiding failure of SWA is the same in Fig.8 Notice the result at x = 0.7646 in Fig.14, because the hiding failure is occurred at the seeds of the sensitive patterns, a high weakness is produced As shown in Fig.15 and Fig.16, the misses cost and dissimil arity of our work decreases as RL2 increases. This is because the larger RL2 is, the less effect on non-sensitive patterns. Also weakness and dissimilarity of SWA are independent of RL2 5. Conclusion In the paper, a novel method improving the balance between sensitive knowledge protecting and discovery on frequent patte rns has been proposed. By setting entries of a sanitization matrix to appropriate values and multiplying the original database by the matrix with some probability policies, a sanitized database is gotten. Moreover, it can avoid F-I Attack absolutely when the confidence level given by users approximates to 1. The experimental results revealed that although misses cost and dissimilarity between the original and sanitized database of our process are little more than SWA, ours provide more safely protection than SWA. Unlike SWA, our sanitization process could not suffer from F-I Attack and the probability policies in our approach also take the minimum support into account, the users only need to decide the confidence level which affects the degree of patterns hiding 6. Reference 1] M. Atallah, E. Bertino, A. Elmagarmid, M. Ibrahim and V. Verykios Disclosure Limitation of Sensitive Rules", Proc. of IEEE Knowledge and Data Engineering Exchange Workshop 1999 2] R. Agrawal and R. Srikant. Fast algorithms for mining association rules. VLDB, Santiago, Chile, 1994 3] R. Agrawal and R. Srikant. Privacy preserving data mining. In ACM SIGMOD, Dallas, Texas, May 2000 4] E. Dasseni, V. Verykios, A. Elmagarmid and E. Bertino, Hiding Association Rules by Using Confidence and Support", Proc. of 4th Intl Information Hiding Workshop \(IHW 5] A. Evfimievski, J. Gehrke, and R. Srikant. Limiting Privacy Breac hed in privacy preserving data mining. SIGMOD/PODS, 2003 6] A. Evfimievski, R. Srikant, R. Agrawal, and J. Gehrke. Privacy preserving mining of association rules. KDD 2002 7] M. Kantarcioglu and C. Clifton. Privacy-preserving distributed mining of association rules on horizontally partitioned data. In ACM SIGMOD Workshop on Research Issues on Data Mining and Knowledge Discovery, June 2002 8] Guanling Lee, Chien-Yu Chang and Arbee L.P Chen. Hiding sensitive patterns in association rules mining. The 28th Annual International Computer Software and Applications Conference 9] Y. Lindell and B. Pinkas. Privacy Preserving Data mining. In CRYPTO, pages 36-54, 2000 10] S. R. M. Oliveira and O. R. Za  ane. Privacy Preserving Frequent Itemset Mining. In Proc. of IEEE ICDM  02 Workshop on Privacy Security, and Data Mining 11] S. R. M. Oliveira and O. R. Za  ane. Algorithms for Balancing Priv acy and Knowledge Discovery in Association Rule Mining. IDEAS  03 12] S. R. M. Oliveira and O. R. Za  ane. Protecting Sensitive Knowledge By Data Sanitization, ICDM  03 13] S. R. M. Oliveira, O. R. Za  ane and Y  cel Saygin. Secure Association Rule Sharing, PAKDD-04 14] Benny Pinks. Cryptographic Techniques For Privacy-Preserving D ata Mining. ACM SIGKDD Explorations Newsletter Vol. 4, Is. 2, 2002 15] S. J. Rizvi and J. R. Haritsa. Maintaining data privacy in association rule mining. VLDB, 2002 16] J. Vaidya and C. W. Clifton. Privacy preserving association rule mining in vertically partitioned data. KDD2002 17] Verykios, V.S.; Elmagarmid, A.K.; Bertino, E.; Saygin, Y.; Dasseni E. Association rule hiding. IEEE Transactions On Knowledge And Data Engineering, Vol. 16, No. 4, April 2004 Proceedings of the 29th Annual International Computer Software and Applications Conference  COMPSAC  05 0730-3157/05 $20.00  2005 IEEE pre></body></html 


pre></body></html 


Batt Power Batt Type Stabilization Type Propulsion Mechanism  of Solar Panels  of Solar Cells Manufacturing Qty Satellites in Constellation On-Orbit Spares Channels Number of Bands Data Storage Processing Power Source type Block Name Thermal Control Material Type Level of Technology Known Inheritance Propulsion station keeping Number of Axes Ground Based Spares Pointing Accuracy APPENDIX C EXISTING MODELS Numerous models are today in use for estimating spacecraft cost Two of the most common are the NASA/Air Force Cost Model and the Aerospace Small Satellite Cost Model Here is a description of the NAFCOM model The NASA/Air Force Cost Model NAFCOM is a parametric estimating toolfor space hardware It is based on historical NASA and Air Force space projects and is primarily used in the very early phases of a development project NAFCOM can be used at the subsystem or component levels The database currently includes 122 missions including 76 unmanned earth orbiting 24 unmanned planetary 11 launch vehicles 8 manned 3 engines It uses parametric relationships to estimate subsystem or component level costs for any aerospace hardware including earth orbital spacecraft manned spacecraft launch vehicle upper stages liquid rocket engines scientific instruments or planetary spacecraft 7 And for the Aerospace Small Satellite Cost Model SSCM employs a parametric methodology for estimation of program cost and is best suited to the early conceptual development phase of a spacecraft program during which time the design is likely to be less mature and when cost and performance trades can be easily performed SSCM consists of a collection of cost-estimating relationships or CERs which estimate the costs of developing andproducing a spacecraft system with the following subsystems  Attitude Determination and Control Subsystem ADCS  Propulsion  Power  Telemetry Tracking  Command TT&C  Command  Data Handling C&DH  Structure  Thermal CERs were also developed for integration assembly and test IA&T program management PM and systems engineering SE and launch and orbital operations support LOOS Individual subsystem cost estimates are statistically rolled up to yield a cost-risk distribution which provides the estimator with a range of cost estimates andpercentiles 8 The SSCM was calibrated from over 100 post-1990 Earth-orbiting andplanetary missions REFERENCES 1 Lack of Disciplined Cost-Estimating Processes Hinders Effective Program Management GAO study 04-642 2 Jilla Cyrus D and Miller David W Satellite Design Past Present and Future International Journal of Small Satellite Engineering 12 February 1997 3 Bearden David A A Complexity Based Risk Assessment of Low-Cost Planetary Missions:When Is A Mission Too Fast and Too Cheap Fourth IAA International Conference On Low-Cost Planetary Missions JHU/APL MAY 2-5 2000 4 Kellogg Mahr and Lobbia An Analogy-based Method for Estimating the Costs of Spacecraft IEEEAC paper 1371 Version 4 5 Hoeting Jennifer A Methodology for Bayesian Model Averaging An Update f 6]btp/ewiieiao iiAaos 7 Keith Smith NASA/Air Force Cost Model Science Applications International Corporation 8 18 


BIOGRAPHIES Lee Fischman served as Principle Investigator for this project Lee is Senior Director of Development at Galorath Incorporated where he directs much of the new product development and research at the firm He developed SEER for Software  Hardware Integrations with Microsoft Project the Comparison Sizing tool COTS Software model in addition to various data mining information extraction and expert systems Previously he was a software designerlprogrammer in the New York financial industry Lee earned a BA from the University of Chicago and an MA from UCLA both in economics Mike Kimel carried out statistical work on the project Mike is an Economist for Galorath Inc in addition to maintaining his own quantitative consulting practice He has also taught Economics and Advanced Statistics at the Graziadio School of Business and Management at Pepperdine University run the Competitive Strategy group for a Fortune 500 Telecom Company and worked as a Consultant at PriceWaterhouse LLC now PriceWaterhouse-Coopers He earned a Ph.D in Economicsfrom UCLA Troy Masters programmed analytic methods and is integrating the Far Out model into its parent product SEER for Hardware previously SEER-H Troy is a Software Engineer with Galorath Incorporated where he has been the primary developer for a range ofproducts He earned a BS in computer science from UCLA David J Pine was our subject matter expert helping us assemble data and gain insight into technical trends Dave is retired after a 34-year career with the National Aeronautics and Space Administration NASA currently is a consultant to various government and industry entities While at NASA his organizations in the Office of the Chief Financial Officer and later at the IPAO at Langley Research Center were responsible for the conduct of major NASA program analyses and evaluations for the NASA Administrator and Deputy Administrator From early 1988 through the end of 1990 he was the Deputy Program Manager for the Hubble Space Telescope Program specifically responsible for the telescope operations and science support aspects of the program He earned a BS in Aerospace Engineering from the Polytechnic Institute of Brooklyn and a Masters of Engineering Administration from the George Washington University 19 


  20 Angeles, where he also received a B.S. in Applied Mathematics  Eric Fetzer is a Senior Member of the Technical Staff at the Jet Propulsion Laboratory, Pasadena, California specializing in satellite observations of the atmosphere.  His scientific interests include planetary boundary layer processes, tropical phenomena, upper tropospheric variability, and climatologies of temperature, water vapor and clouds.  His technical interests include analysis of large data sets, and of multi-sensor observations. He has over 20 peer-reviewed publications and given numerous scientific presentations, public lectures and media interviews about climate science. Eric received a B.A. in Physics from the University of California Berkeley, and a Ph.D. in Astrophysical, Planetary and Atmospheric Sciences from the University of Colorado, Boulder   Amy Braverman is a Senior Statistician at the Jet Propulsion Laboratory, California Institute of Technology She holds a B.A. in Economics from Swarthmore College an M.A. in Mathematics from UCLA, and a Ph.D. in Statistics also from UCLA. Prior to her current position in JPL's Science Data Understanding Group, she was a Caltech Post-doctoral Scholar at the Jet Propulsion Laboratory, and a Scientist in the Flight Sciences Experiments Section of the Science Division. Dr Braverman conducts research on information-theoretic methods for the analysis of massive data sets and streams statistical data fusion, high-dimensional data analysis, and statistical analysis for climate model evaluation and diagnosis. She has published in both the statistics and geoscience literature, and is active in both communities She is a member of the Multi-angle Imaging SpectroRadiometer Science Team, and serves as a member of the Atmospheric Infrared Sounder Science Integration Team. Her responsibilities on both missions include designing data reduction algorithms for massive, remote sensing data sets. Dr. Braverman also holds an appointment in the Department of Statistics at UCLA as Adjunct Associate Professor, and is active in UCLA\222s Center for Environmental Statistics. She is member of the Committee on Applied and Theoretical Statistics of the US National Academy of Science. She has refereed for the Journal of the American Statistical Association, the Journal of Computational and Gr aphical Statistics, IEEE Transactions on Geoscience and Remote Sensing, and the Journal of Applied Meteorology and Climatology Seungwon Lee is a senior member of the High Capability Computing and Modeling Group at Jet Propulsion Laboratory. She is conducti ng research on comet gas dynamics, nonlinear dynamics control, climate model parameterization, Earth science data analysis, parallel computing, and advanced numerical algorithms. She received her Ph.D in Physics fr om the Ohio State University and her M.S. and B.S. in Physics from the Seoul National University, Korea  Matthew Henderson is software engineer in the High Capability Computing and Mode ling group at JPL. His current work includes Web Services and Instrument Data Level 2 subsetting. He received a B.S. Computer Science from CSU Pomona, and is currently pursuing M.S Computer Science  Steven J. Lewis is a member of the Information System and Computer Science staff member at the Jet Propulsion Laboratory.  He received a BS in Mathematics from the University of California, Los Angeles in June 2001, and the MS and Ph.D. Degree from Claremont Graduate University in May 2004 and May 2007, respectively.  He worked as a post doctoral fellow at Keck Graduate Institute from June 2007 until he joined JPL in March of 2008.  During his graduate and post doctoral work, his studies focused on applications of Bayesian methods to hidden Markov models with particular interest and application to protein sequencing.  His work at JPL has focused on integrating web services into various programming platforms for the purposes of accessing NASA satellite data, as well as developing object tracking so ftware and contributing to image enhancement and restoration efforts Van Dang is a member of the Science Data Understanding Group at the Jet Propulsion Laboratory. She was responsible for the NEWS Level 2 processing that generated the formal merged Level 2 data from multiple A-Train instruments  Manuel de la Torre is a Physicist from the Universidad Complutense at Madrid \(Spain\. After finishing his Ph.D work at the University of Bayreuth \(Germany\ on pattern formation in turbulent flows and a 7 1/2 year stunt as Ass and Assoc. Prof. at the Escuela T\351cnica Superior de Ingenieros Aeron\341uticos in Madrid \(Spain\, he came to the Jet Propulsion Laboratory on a 1-year Sabatical leave in 1997 wanting to apply fundamental concepts of nonlinear systems and geophysical fluid dynamics to something that might be directly useful to soci ety. He discovered the JPL as a great place to achieve that goal and extende d his stay a bit longer, becoming Technical staff and working on different aspects of remote sensing, validation of satellite instruments, and data analysis of atmospheric processes and climate  


