A FRAMEWORK FOR E-COMMERCE ORIENTED RECOMMENDATION SYSTEMS Li-Tung Weng,Yue Xu and Yuefeng Li Centre for Information Technology Innovation Faculty of Information-Technology GPO Box 2434 Brisbane QLD 4001 Australia l.weng@student.qut.edu.au vue.xu@,qut.edu.au y2.li\(iilqut.edu.au Abstruct-This paper presents a framework for developing and deploying the recommendation systems that are applicable to the complex dynamic and challenging business environment Recommendation accuracy and computation performances are the two major research focuses in the domain of recommendation systems However, from a business side point of view, it 
is vital to maximize the adoptability of recommendation systems for various business models aspects and strategies To date little research is conducted that aims at increasing the productivity of recommendation systems to business value En this paper we propose a\222 framework that enables recommendation systems to be easily adjusted to suit the overarching needs of various business types and further carve out the potential market for recommendation systems recommendation systems component technolog custonaiurlion colla borarive$lfering 1 INTRODUCTION   Information overload is one of the most serious issues 
in today\222s high-tech era and it is posed by the drastic increment in the amount of information. Consequently it would be more difficult for humans.to fmd and locate the information they desired efficiently and correctly The I initial goal of recommendation systems is for solving  this issue Recommendation systems are designed to benefit humans\222 information extracting experiences by giving information recommendations according to their information needs Recommendation systems have also been applied to the domain of e-commerce in which a recommendation system is 
usedin e-commerce websites to suggest products to customers and .these product suggestions are often tailored to individual customer\222s interests In essence recommendation systems support customization of the customer experience by altering the presentation of the products sold on a website 93  Prior to the preliminary of recommendation systems, data mining techniques are often employed by merchandisers to discover the relationships between the purchase of one item and the purchase of another, and these techniques are regarded as being the embryo of recommendation systems 
SI Collaborative filtering is the earliest and most successful recommendation system technology to date The technique is based on finding customers with similar interests to the target customer and then giving suggestions according to the preferences of these customers  42,s-101 Alternatively content based filtering is another mainstream of recommendation techniques which makes recommendations through the contents analysis of the targeted items and its relation io the user\222s preferences 1,4,10 In addition to the approaches mentioned above there are still man other different recommendation techniques with their own 
distinct strengths and limitations such as content-based collaborative filtering 6 multi-level association rule 3 item-to-item collaborative filtering 5 and others A viable technology must provide its market sufficient business value and maximize the busitiess owner\222s profits at any point of time Much research on the 221area of recommendation systems has focused on improving recommendation accuracy and computational performances To date recorrqendation systems have achieved great success in generating accurate and personalized recormizendations to their customers However few of them have considered 
the various business-related needs of the marketers Consequentially the 6iggest challenge in developing modem recommendation  system is to connect recommendation systems with marketers IO]\222 as well as provide adaptability to different business models aspects and strategies The motivation of this research paper aims at developing,a framework that enables recommendation systems to be easily adjusted to suit the overarching needs of various business types and further carve out the potential market for recommendation systems The 
paper is divided into fok sections starting fkom section 2 In\222 section 2 a new market structure for recommendation systems is proposed and discussed Section 3 describes 221a component based framework supporting the proposed market structure In section 4,\222 an experiment is conducted to demonstrate the dynamic composition unit selection supported by the\222 proposed framework Finally section 5 summarizes and outlines the major conhibutions of this paper as well as hture relevant research  0-7803-9035-0/05/$20.00 02005 IEEE 309 


11 RECOMMENDATION SYSTEM MARKET No matter how superior a technology is it will not be able to survive if there is no a market of certain size exist to support it Fortunately a large potential market does exist for recommendation system technologies because of the increasing number of online shopping sites information and products available on the Internet The role of rscommendation system becomes extremely significant because shops need such systems to increase profitshales and customers need them to relief the efforts of searching and targeting desired products or information Notwithstanding, this market is not yet mature because there is not much effort made to carve out this market This paper suggests a component based market for recommendation systems with the hope of making recommendation systems not only beneficial to the customers but also brining business value to the business owners Many existing recommendation systems failed to bring as much business value as expected by their owners, it is mainly because 1 The nature of business is dynamic: new products come every day and business strategies or decisions change rapidly as the environment changed It is important that the recommendation systems can be adjusted to support these changes However it is so far not yet being successfully achieved by many recommendation systems simply because that the time required to adjust a recommendation system in corresponding to business\222s needs cannot follow the changing speed of business environment 2 The costs associated with adjusting the system is high different recommendation algorithms can bring different values to businesses in other words different recommendation algorithms support different marketing strategies or applications As business is such a dynamic environment, it would be necessary that the employed recommendation algorithms can also be adjusted according to the continuously changing environment. Yet, such optimism so far is not applicable due to the cost-inefficiency As most of the recommendation systems in e-commerce firms nowadays are custom-made, thus changing or adjusting these systems might require new business and system analysis, system development debugging and user- interface refinement Therefore it is understandable that such system changing or adjusting process will not happen fresuently within organizations because of the high costs The causes of recommendation system failure indicate that the reusability is the key factor to solve the time and costs problems associated with adjusting and changing recommendation systems As mentioned above different marketing strategies need different recornmendation algorithms or diEerent combination of recommendation algorithms It is desirable that a different recommendation algorithm or a different combination of recommendation algorithms can be easily constructed once a new or a different marketing strategy is needed in corresponding to the environment change This can be achieved by implementing each pdmary recommendation algorithm as a standardized, portable and reusable component The component concept is now the most popular software engineering technique aiming at reducing the software development costs and time as well as maximizing the reusability Component technology is not only a new software engineering process and standard but it also holds a large potential market and business values Firms such as 223ComponentSource\224 http://www.componentsource.com and 223ObjectTools\224 http://www.objectools.com are welI-known for selling and reselling software components and they have gained great revenues by doing this business It can be concluded that the modem software development process has already switched fiom programmingicodmg the entire system to buying and composing components since the supporting market is getting mature drastically This paper suggests that the desired market structure for recommendation systems can inherit the structure of existing software component market with only a few distinctions. The proposed market structure and its three constituent parties are described below Recommendation service user  people constituting this party mainly include customers receiving recommendations from the online-stores, e-commerce websites, e-libraries and etc This party is the core that keeps the market alive since the market size is proportional to the strength of this party Because of the successes of internet technology and e-commerce nowadays this party is expected to grow stronger continually in future, and therefore the existence of the potential market of recommendation system could be ensured Recommendation service provider  this party mainly consists of e-commerce websites e-libraries online stores and etc and its the major activity is to generate recommendations to the 223recommendation service user\224 party Through this activity the party is expecting to receive certain amount of business value and profits either directly or indirectly In this proposed market structure the recommendation service provider will no longer need to build its recommender fiom scratch as well as spending extra time and costs to keep the recommender concurrent and up-to-date with the dynamic business environment In order to construct a recommendation system that best meets the up-to-date business needs the recommendation service provider first plans a blueprint of the desired recommendation system according to the business\222s requirements or needs Based on the blueprint the recommendation service provider can purchase the required recommendation components fiom one or more recommendation component producers and then compose these components into the recommendation system model according to the blueprint. Finally the recommendation service provider can integrate the recommendation system model with its system environment such as databases, user interfaces data warehouses and other e-commerce systems and result in a fully workable recommendation system Recommendation component producer  This party requires primarily technical knowledge about component technology recommendation algorithms and related data mining techniques It mainly consists of programmers, software engineers and data mining specialists As its name implied the task of 310 


recommendation component producer is to produce and innovate the components for recommendation systems The recommendation component producer should not take too much care on business logic side of recommendation systems rather it should mainIy focus on improving the recommendation algorithm's scalability efficiency and accuracy This party might also be able to help recommendation service providers to install their purchased components as it owns a relatively good understanding and knowledge to the components and their installation details 111 A COMPONENT BASED RECOMMENDATION SYSTEM FRAMEWORK A Components A component is the smallest unit of the proposed frrunework which will be described in subsection 3.3 There are several types of the components mainly for representation integration and recommendation It is possible to categorize the components into one of the four types filter, mixer sorter and recommender. Separating components into more specific types potentially facilitates the processes of component composition and business analysis A filter accepts incoming recommendations from other components and filters out the recommendations that don't meet user predefined constraints and pushes the passed recommendations to other components The typical constraint being used to filter the recommendations is item attributes i.e types prices expiry dates and etc A mixer is used to combine results fiom two or more components and it is the key component to realize hybridization of recammender algorithms in this fiamework A mixer can be implemented in different ways such as mixed switching cascade feature augmentation and etc  11 A sorter manages the order of recommendations which is normally determined based on the item attributes such as scores types prices expiry dates and etc The purpose of a recommender component is to generate recommendations. Recommender components are basically implementations of different recommendation algorithms such as content-based filtering collaborative filtering associate rule based filtering and etc E Composition Units A business problem can be simple or complex In many cases a single recommender camponent is not sufficient to achieve a business strategy to deal with a complex business situation ln order to provide satisfactory recommendations in different business situations we propose the concept of composition units Several components or composition units composed together form a composition unit A composition unit encapsulates logics or solutions to a certain business situation It can be as simple as containing only one component in the case of a simple business situation, or as complex as consisting of several components or even several other composition units in the case of a complex business situation such as selling a newly arrived product in combination with an obsolete product as a bundle In order to achieve reusability the fkamework should allow composition units to be managed distributed, stored, destroyed and reused once they were constructed for some particular business needs Figure 1 shows an example of the structure of a composition unit For combining recommendation algorithms there are two different levels to implement them. Firstly and most obviously the hybridization can be realized in the composition unit level through composing two or more recommender components together Secondly a recommender component is implemented using a hybrid recommendation algorithm The major difference between these two hybridization approaches is that the hybridization in composition unit level focuses on solving business problem where as in recommender component level the performance and recommendation accuracy are the main concerns Figure 1 Structure of the proposed recommendation system framework  System Environment System CompodDlon Unlt Resourcea Composltlon unn j Recommendation Re8ult 2   Message-bard Wiring User Interface C Framework struclure Figure 1 provides the structure of the proposed recommendation system fiamework A general e-commerce system might require more than one application to the recommendation system For example an online bookshop might want the recommendation system to produce personalized recommendations for each particular customer and also generate daily promotion recommendations as well Clearly different applications may require difference recommendation algorithms as they oRen possess different business logic requirements Within this fi-amework the 311 


solution to each business problem is conceptualized and implemented as a composition unit By using different composition units the goal of different applications can be achieved The foilowing gives more precise defmitions and descriptions to the terms mentioned in Figure 1 System Environment  A system environment indicates all the software and hardwires that are related to the recommendation system For example the operation system run time environment network, web server, database server, and etc System Resources  System resources include data warehouses, databases financial analysis tool and etc In comparison to the system environment a system resource is more about the recommendation system applicable information or data within an organization Since different organizations have different system resources therefore a recommendation component should be designed to accommodate different system resources requirements A common approach for linking the component to the existing system resources is to provide a thin wrapper above the system resources and this wrapper then convert the system resources into a format that is recognizable to the component Messagebased Wiring  Instead of connecting two or more components through method or procedure calls the notion of the message based wiring indicates that the components are linked or wired based on the dabflow More specifically, it can be assumed that a component has only one input port and one output port The input port accepts the message or data passed by another component and then based on the message or data e component generates message or data to other components through the output port Within the proposed system the key benefit of the message-based wiring protocol is to allow the logic of the composition can be analyzed simply through the analysis of the dataflow User Interface  The output of a recommendation system is a list of item recommendations, and the goal of the user interface is to display these resulting recothmendations in the manner such that the recommendation service user can absorb them easily and effectively  Recommendation Result  In the context of this framework, the message passed between components are recommendation results. The proposed format for this message is just an unordered list of item id and score pairs Components generally can be purchased from recommendation component producers by recommendation service providers The recommendation service providers wire the purchased components into composition units based on their business requirements The output of a composition unit is a list of recommended items or products The key to accomplish this interpretability among the composition bits is through the use of the unified message 4 based wiring protocol The message based wiring protocol indicates that all components communicate through a unified message format and the input and output ports of any components all accept such message format. Therefore it can be assumed that the input and output ports of the composition units also use this message format In theory if the communication protocol \(the common message format among the composition units is unified, the interpretability among the composition units then could be ensured D Dynamic Recommender Selection As mentioned above the proposed recommendation system framework allows multiple recommenders i.e composition units running within an organization\222s system In this paper we suggest that the customization of recommendation systems in a business oriented context should be achieved in the composition unit level In other words different composition units could be applied to solve different business problems or situations In a traditional recommendation system it is cost ineffective to have various recommenders or compositions of recommenders running to solve different problems, because the recommenders are built from scratch However with the concept of this recommendation system fiamework, the efforts required for importing or building recommenders composition units is-trivial because the components can be import from other sources or reused and more important, the composition units can be determined dynamically In this paper a decision tree based classifier is used to dynamically select the most suitable composition unit fiom a group of pre-configured composition units for a given business situation A decision tree takes a situation described by a set of attributes as input and returns a 223decision\224 In the case of composition unit selection, the \223decision\224 is a selected composition unit and the attributes are domain related information An experiment has been conducted on a real website www.coo1soft.com.au Coolsoft is a multimedia development company which provides low cost and trivial flash templates for small or medium size businesses that don\222t need complex and full functional flash sites We have developed an experimental recommendation system in Coolsoft\222s website to help its customers to find their desired templaies In the system six composition units are designed and implemented which are illustrated in Figure 2  The details of these composition units are given below C1 The composition unit produce general product recommendations, it generate recommendations based on user specified criteria and ranking based on the degree of similarity between the criteria and the item CZ This composition unit provides better personalization than Cl It uses collaborative filtering to predict user interested items and then use content based filtering to filter out items that are not related to the user specified criteria C3 The composition unit is specially designed for solving the over stock issues \(too many old goods in the stack The composition unit gives older items higher rank so users are more likely to find and possibly purchase these old items first 3 12 


C4 The composition unit is designed for promotion period or price-sensitive customers It mixes regular current promoted item together to attract customers C5 The composition unit gives lower prices and warm colored red orange yellow items higher rank it might be suitabte for attract female customers cool colored \(red, orange yellow items higher rank it might be suitable for attract male customers Figure 3 An example decision tree personalized recommendations and a list of cheap or  PrdktwAtblbutrr  D.J unll~a UnM elow Grey Black C6 The composition unit gives latest imported and Figure 2 Examples of composition units J The attributes used for the decision tress describe the user's personal information and the user's preference to the template such as registered user, gender, template color preference, user affordability and item stock level Even though it is possible to build the decision tree manually based on the personal experiences and knowledge, it is often desired to build more accurate and objective decision tree classifier through employing some learning algorithms based on the available training dataset. The ID3 algorithm 7 has been used in this research to build the decision tree which is given in Figure 3 By using the decision tree for a given set of attributes about the current user we can select the most proper composition unit to make recommendation for this user That means, customization is no longer static in the recommendation algorithm level It is now possible to tailor various customer and business needs based on selecting the most appropriate recommender among multiple available recommenders IV EXPERIMENTAL RESULT In this experiment we demonstrate the application of dynamic composition unit selection as explained in section 3.4 A training dataset with 200 rows has been constructed manually and as each row represents a purchase scenario it contains six attributes registered user gender, template color preference user affordability item stock level and suggest composition unit The first five attributes are obtained from the past transaction history of the site, and we manually assign the suggested composition unit to each row according to the observed profitability For the purpose of simplification, computation efficiency and bias elimination, the tree was compressed with standard MDL tree pruning algorithm 7 as shown in figure 3 During the pruning process the irrelevant test attribute \(item stock level has been detected and also excluded from classification consideration. The training dataset was then used to inspect the resulting decision tree and a certain degree of misclassifications are found After studying fiom these misclassified cases we found most of them are the result of the outliers of the dataset Therefore, it could be concluded that the tree pruning is a preferred approach to improve the performance and reduce the outliers of the proposed dynamic recommendation selection algorithm hother dataset different fiom the training dataset contains no outliers has also been employed to evaluate the compressed tree During the process we found that the result is relatively promising as there are over 85 cases yield acceptable results  A comparison between using the proposed dynamic recommender selection for selecting a composition unit dynamically and using a fmed standard collaborative filtering recommender has also been made In the experiment a hundred manually constructed test cases are used to evaluate both system?. Each test case consists of a set of buyer attributes affordability gender and etc.\a transaction history set arid a search query As the result of the comparison we found that the standard collaborative filtering recommender does not well cooperate with the ever-changing business considerations d by contrast, the proposed approach results in more dynamic recommendations in accordance with different business aspects For example, when a customer is identified as low afYordability the fixed collaborative filtering recommender does not fully 313 


aware of this it only suggest cheaper items if the neighbors of his or her belonging cluster also made certain amounts of transactions or ratings in cheaper items. In the case of dynamic recommender selection it actively recommends cheap or discount items fkom the stock to the customers with low affordability for the promotion and possible up-sell i.e C5 is selected V RELATED WORK AND CONCLUSION The primary goal of developing recommendation systems is for facilitating humans\222 information retrieving experiences by generating lists of web-documents that are relevant to the user\222s interests Notwithstanding, due to the advance of e commerce, recommendations considering only user preferences and item contents are no longer sufficient Modern recommenders must incorporate with business aspects in order to maximize value to the business and augment utility to the customer at the same time[lO Business or e-commerce oriented recommendation systems are required to cooperate with data of various aspects however, none of any individual techniques being able to utilize this rich dataset has been proposed We proposed a component-based approach for designing and developing recommendation systems for recommendation hybridization because it allows hybridizing recommendation algorithms become a low cost instantaneous dynamic and adaptable process This paper suggested an inheritance of the concept of component technology fiom both marketing and technical perspectives A new market structure for recommendation systems is defined and proposed This market structure is expected to be more complex, challenging dynamic, and most important more profitable than the existing recommendation systems For the purpose of supporting this new market structure a component based framework for developing recommendation systems is also proposed designed and implemented in this research With this proposed hework the costs and time involved in developing maintaining and adjusting recommendation systems in corresponding to the dynamic business nature are reduced Moreover the employment of the message based wiring within the fiamework also significantly simplifies and benefits the business analysis process to recommendation systems This paper also presents an approach for composition unit selection allowing the most appropriated composition unit or recommender\to be selected dynamically in real time based on given business and customer information or needs However the current fimctionalities of this approach require a set of different composition units to be constructed before the selection algorithm can be applied Moreover the selected composition unit is only the most suitable one within the provided composition unit set, and there is no guaranty if the suggested composition unit is the best one Therefore in addition to the dynamic composition unit selection we suggest that there could be a Mer research for 223dynamic recommender composition\224, that is rather than selecting the composition units within a predefined set the composition units or recommendation components can be composed and applied dynamically based on different business requirement and customer needs The recommendation system framework presented in this paper has already made attempts to solve the system level problems of the suggested further research i.e dynamically composing recommendation component at runtime One of the future works for this research is the mining and learning algorithms for compositing appropriate composition units dynamically REFERENCES Burke R Hybrid Rccommender Systems Survey and Expcriments User Modeling and User-Adapted Interaction 12 2002 331-370 Heylighcn F Collaborative Filtering Vol 2003 Kim C and Kim J A Recommendation Algorithm Using Multi-Level Association Rules IEEWIC International Confercnce on Web Intelligence Seoul Korea 2003 pp 524-527 Kwak M and Cho D.-S Collaboralivc Filtering with Automatic Rating for Rccommendation IEEE International Symposium on Industrial Electronics Vol I Busan Korea 2001 pp 625-628 v0l.l Linden G Smith B and York I Amazon.com recommendations item-to-item collaborative filtering Intemet Computing IEEE 7 2003 Metercn R.v and Somcrcn M.v Using Contcnt-Based Filtering for Recommendation ECML 2000 Workshop Machine Learning in New Information Age, Barcelona, Spain 2000 pp 47-56 P W Wagacha Induction of Decision Trees University of Nairobi Nairobi 2003 Sarwar B.M Karypis G Konstan J.A and Reidl 3 Item-bawd collaborative filtering recommendation algorithms 10th lntemational Conference on World Wide Wcb ACM Press, Hong Kong 2001 pp Sarwar B.M Karypis G Konstan J.A and Riedl J Analysis of recommendation algorithms for e-commerce 2nd ACM conference on Electronic commerce ACM Press Minneapolis Minnesota United States 2000 pp 158-167 Schafer J.B Konstan J.A and Riedl J E-Commerce Recommendation Applications Journal of Data Mining and Knowledge Discovery 5 2000 115-152 76-80 xxw 314 


mxXf  r Figure 5 Contraception database class 223no use\224 Figure 7 Contraceptive database class 223Short-term\224 222 Figure 6 Contraceptive database class \223Long-term\224 Results for the class 223long-term use\224 are presented in Fig 6 In these results TS produces more non-dominated solutions and the spread of solutions in the front is reason able except for those of high coverage greater than 65 where NSGA I1 finds a large number of solutions Results for the class 223short-term use\224 are presented in Fig 7 In the Pareto front area of high accuracy above 65 and low coverage below 25 the NSGA I1 algo rithm finds all but one of the non-dominated solutions However in the other area the algorithms perform very sim ilarly both in terms of solution spread and quality 6.1 Efficiency Comparisons To compare the execution time of both algorithms is not straightforward in terms of computing time since they were run on different machines However one method of com parison is to establish the number of evaluations that each algorithm performed to arrive to a particular set of solu tions This is possible because both algorithms use the same underlying evaluation function for a solution This can only give a rough approximation as both algorithms per form other operations However evaluation is the dominat ing operation in both algorithms so it can be an initial point of comparison The comparison was established using the Adult database For this database, the TS required approximately 5000 evaluations on average to find one of the solutions that is to find a single rule which is represented as one point in the graphs above The algorithm was run 5 times per X value, with a range of X values previously described This means that 138 experiments were run to get the set of solutions shown in Figure 2 Hence the total number of evaluations performed is nearly 700,000 Even if only one run per x\222 value was performed which may deteriorate the quality of the front obtained approximately 140,000 eh uations would have to he performed On the other hand the NSGA II\222algorithm evaluates a population of 2n solu tions, in this case n  120 at each generation and the ex periments shown on graph 2 were run for I00 generations Hence the total number of evaluations performed by this al gorithm is 24,000 Therefore we can conclude that the TS algorithm is a much less efficient way to achieve a set of results of similar quality, in terms ofthe number of evalua tions performed 7 Conclusions and further work In this paper we propose\222the use of Pareto-based MOEA in the extraction of rules from databases This is novel and complements previous research in nugget discovery using heuristic techniques The ability to present the user with a number of interest measures which may be selected, and then to search for a set of solutions which represent an ap proximation to the Pareto optimal front for those measures is desirable for a partial classification algorithm We have implemented the NSGA I1 Pareto-based MOEA and compared it to the TS algorithm We have performed parameter experimentation for the former and having found a range of suitable parameters we have applied the algo rithm to a range of well known classification databases The results have shown that in terms of quality of indi vidual solutions both algorithms are comparable However the spread of solutions across the approximated Pareto-front found by the NSGA I1 algorithm was always better Also in terms of efficiency the NSGA I1 algorithm significantly outperforms the TS approach Therefore we can conclude 1558 


that in order to find an approximation to the Pareto front it is best to use the NSGA I1 algorithm Given our results the potential of NSGA I1 for nugget discovery is clear The flexibility of this algorithm will make it advantageous for solving this type of data mining problem As the subject of further research, the first step is to com pare the performance of the NSGA I1 algorithm with the true Pareto optimal front We are already working in this area and results will be reported shortly It may be interest ing to introduce more objectives into the search, such as the simplicity of a rule It may also be worth while to compare the performance of other Pareto-based algorithms against NSGA I1 for this particular problem  Bibliography I R Agrawal T Imielinski and A Swami Database mining A performance perspective In Nick Cercone and Mas Tsuchiya editors Special Issue on Learning and Discover in Knowledge-Based Databases num her 6 in 5 pages 914-925 Institute of Electrical and Electronics Engineers, Washington U.S.A 1993 2 S Ah K Manganaris and R Srikant Partial clas sification using association rules In D Heckerman H Mannila,,D Pregibon and R Uthurusamy, editors Proceedings of the Thid.Int Cunf on Knowledge Dis coven andData Mining pages 115-1 18 AAAI Press 1997 3 R J Bayardo and R Agrawal Mining the most inter esting rules In S Chaudhuri and D Madigan. editors Proceedings of the Fiffli ACM SIGKDD Int Conf on Knowledge Discovery and Data Mining pages 145 155. New York USA 1999 ACM 4 R J Bayardo R Agrawal and D Gunopulos Constraint-based rule mining in large, dense datasets In Proc of the 15th lnt Con on Data Engineering pages 188-197,1999 5 C.A Coello Coello A comprehensive suri'ey of evolutionary-based multiobjective-optimization tech niques Knowledge and Information Systems 1\(3 1999 161 B de la Iglesia J C W Debuse and V J Rayward-Smith Discovering knowledge in commer cial databases using modem heuristic techniques In E Sirnoudis J W Han and U M Fayyad edi tors Proceedings of the Second Int Con on Knowl edge Discover\andData Mining pages 4449 AAAI Press 1996  7 B de la Iglesia and V J Rayward-Smith The discov ery of interesting nuggets using heuristic techniques In H A Abbass R A Sarker and C S Newton ed itors Data Mining a Heuristic Approach pages 72 96 Idea group Publishing USA 2002 SI K Deb S Agrawal A. Pratap and T Meyarivan A fast elitist non-dominated sorting genetic algorithm for multi-objective optimization NSGA-11 In Pmceed ings of the Parallel Problem Solving from Nature VI Conference Lecture Notes in Computer Science, No 1917 pp 849-958,2000 Springer 9 J Horn N Nafpliotis and D E Goldberg A Niched Pareto .Genetic Algorithm for Multiobjective Opti mization In Pioceedings of the First IEEE Conference on Evolutiona~y Coniputation IEEE World Congress on Computational Intelligence volume 1 pages 82 87 Piscataway, New Jersey 1994 IEEE Service Cen ter  A A Knopf The Audubon SocieQ Field Guide to North AniericalMushrooms G H Lincoff New York 1981 I 11 J Knowles and D Come The Pareto archived evo lution strategy A new baseline algorithm for Pareto multiobjective optimisation In Peter J Angeline Zbyszek Michalewicz Marc Schoenauer Xin Yao and Ali Zalzala editors Proceedings of the Congress on Evolutionary Computation volume 1 pages 98 105 Mayflower Hotel Washington D.C USA 6-9 1999 IEEE Press I21 C J Merz and P M Murphy UCI repos itory of machine learning databases Uni versity of California Irvine Dept of In formation and Coumputer Sciences 1998 http://www.ics.uci.edu/-mleardMLRepositoryhtmI  131 J R Quinlan and R L Rivest Inferring decision trees using the minimum description length principle Infor mation and Coniputation 80:227-248,1989 I41 V J Rayward-Smith J C W Dehuse, and B de la Iglesia Using a genetic algorithm to data mine in the financial services sector In A Macintosh and C Cooper editors Applications and Innovations in Expert Sysfenis 111 pages 237-252 SGES Publica tions 1995 IS N Srinivas and Kalyanmoy Deb Multiobjective op timization using nondominated sorting in genetic al gorithms Evolutionary Coniputation 2\(3 1-248 1994  161 X Yang and M. Gen Evolution program for bicriteria transportation problem In M Gen and T Kobayashi editors Proceedings of the 16th International Confer ence on Computers and Industrial Engineering pages 451454 Ashikaga, Japan, 1994 1559 


  Query creates a table of product-month pairs for which there are more than 00 sales transactions in the Sales table.  Query 2 creates a table ReducedSales which extracts from the Sales fact table only those sale transactions that involve product-month pairs resulting from Query The result of Query 2, a reduced Sales table ReducedSales is based on question B.  This reduced table is used in Query 3 to create a table of product-month-zip triples for which there are more 00 sales transactions in the Sales fact table and later in Query 4 to create a table ReducedSales2 that extracts all sale transactions that involve product-month-zip triples resulting from Query 3.  We did not have to use the original Sales fact table, because we know that all possible transactions that satisfy conditions of Query 3 and 4 are replicated in much smaller ReducedSales table Finally, Query 5 performs a join of the ReducedSales2 table with itself in order to find the final result  6. Experiments  In this section we describe an experimental performance study of mining real world data that uses the system and methods described in previous sections of this paper For our experiments we used Oracle 9i relational DBMS running on a 28KB Linux machine.  The data we used reflects the aggregated daily purchases for a major US-based retailer during a six-month period and conforms to the schema shown in Figure 2.  The sizes of the tables are as follows The Product table has around 5000 tuples The Location table has around 2000 tuples with about 50 different Regions The Calendar table has around 200 tuples The Sales table has around 3 million tuples As we discussed in Section 4, standard association rules are not defined for such data.  However, as we also outlined in Section 4, we can still mine association rules by approximating or redefining the meaning of 223frequently together.\224  In our experiments we mined both association rules and extended association rules.  In this paper, we present the results of two queries that are typical for our experiments The first query finds regular association rules based on the following question Find all pairs of items that appear together in more than 9000 transactions Our implementation of this query \(code available by contacting the authors\ involves a pruning of all infrequent items as described in Section 5.2.  The result of the query is thirteen pairs of items shown in Table 2  Table 2  8130 13380 64 521 3060 8130 10226 13890 15240 64 561 13890 15150 9498 8130 13380 11192 123660 123690 54 565 600 8130 48 521 PRODUCTID1 PRODUCTID2 SUM PRODUCTID1 PRODUCTID2 REGIONID SUM 7740 8130 9811 8130 8280 12473 8130 8310 13717 8130 8550 9057 8130 13890 11906 8130 15150 9642 8130 15240 11541 13890 15240 11157 15150 15240 10749  The second query finds extended association rules using the Approach Section 4\o approximating 223frequently together\224, and it is based on the following question  Find all pairs of items that appear together in more than 300 transactions in the same region Our implementation of this query \(code available by contacting the authors\volves pruning all item-region pairs that do not appear in more than 300 transactions The result of this query, shown in Table 3, is a set of fifteen rules, where each rule involves two items and a region  Table 3  15150 18420 62 562 123660 123720 53 556 123660 123780 54 507 123690 123720 53 736 123690 123720 54 803 123690 123840 53 535 123720 123840 53 1081 164490 168420 62 599 167520 167640 17 530 168120 168420 62 555 168420 169650 62 575  Comparing the two queries and their implementation in our system we make the following observations.  The extended association rule mining takes significantly less Proceedings of t he 36th Ha waii International Conf erence on S y st e m Sciences \(HICSS\22203 0 76 95 18 745/0 3 1 7.00 251 20 02  I E EE 600 8130 16853 


 time to produce about the same number of rules as association rule mining.  Furthermore, in order to find a similar \(manageable\ber of rules, the support threshold for the association rules had to be set significantly larger than the threshold for extended rules This fact supports our claim that association rules find coarser granularity correlations among items while extended rules discover finer patters The experiments also validate the viability of our tightly-coupled integration with the relational DBMS The running times for all of our queries are measured in seconds and minutes; and there is still a room for significant performance improvement by, for example upgrading hardware or through the addition of indexing In practice, in cases when a data warehouse is heavily utilized with OLAP and reporting requests, a separate data mart dedicated exclusively to data mining can be a good alternative in order to minimize the hits on the enterprise data warehouse and improve overall performance  7. Conclusions  In this paper, we presented a new data-mining framework that is tightly integrated with the data warehousing technology.  In addition to integrating the mining with database technology by keeping all query-processing within the data warehouse, our approach introduces the following two innovations Extended association rules using the other non-item dimensions of the data warehouse, which results in more detailed and ultimately actionable rules Defining association rules for aggregated \(nontransactional\ata We have shown how extended association rules can enable organizations to find new information within their data warehouses relatively easily, utilizing their existing technology.  We have also defined several exact approaches to mining repositories of aggregated data which allows companies to take a new look at this important part of their data warehouse We have conducted experiments that implement our approach on real-life aggregated data and the results support the viability of our integration approach as well as the appropriateness of extended association rules In our future work we plan to elaborate on the optimization algorithm.  We also intend to undertake a further performance study with larger data sets, using different hardware platforms and various types of indexes  References    A g ra wa l R., Im ie linsk i T. a n d A  Sw a m i.  Mining  Association Rules Between Sets of Items in Large Databases Proceeding of ACM SIGMOD International Conference  993\, 207-2 6  2 A g ra wa l R. a nd Srik a n t R Fa st A lg o rithm s f o r Mining  Association Rules Proceeding of International Conference On Very Large Databases VLDB  994\, 487-499  3 R. A g ra wa l, H. Ma nnila R Srik a n t, H. T o iv one n, a n d A   Verkamo.  Fast Discovery of Association Rules Advances in Knowledge Discovery and Data Mining AAAI/MIT Press  996  4 Berry M. an d L i n o f f   G    Data Mining Techniques for Marketing, Sales and Customer Support Wiley 997  5 C h a u dhr i  S. a n d D a y a l, U  A n ov e r v i ew of  D a ta Warehousing and OLAP Technology ACM SIGMOD Record  26   997\, 65-74  6 H ilde r m a n, R.J Ca rte r C L H a m ilton, H J a nd Ce rc one   N.  Mining Association Rules from Market Basket Data Using Share Measures and Characterized Itemsets International Journal of Artificial Intelligence Tools 7 \(2 998 89-220  7 In m o n  W  H  Building the Data Warehouse Wiley 996  8 K i m b a ll, R., Re e v e s L Ros s M., a nd T hor nthw hite W   The Data Warehouse Lifecycle Toolkit Wiley 998  9 L e a v itt, N. Da ta Mi ning f o r the C o rp ora te Ma sse s IEEE Computer 2002\, 22-24     S  S a r a w a gi  S  Th o m a s  R  A gr a w a l  I n t e gr at i n g M i n i n g  with Relational Database Systems: Alternatives and Implications Proceedings of ACM SIGMOD Conference   998\, 343-354    S  T s ur, J. Ullm a n S. A b ite b oul C. Clif ton  R. M o tw a n i, S  Nestorov, A. Rosenthal.  Query Flocks: A Generalization of Association-Rule Mining Proceedings of ACM SIGMOD Conference  998 2   2 W a ng K H e Y  a n d H a n J  Mi ni ng Fr e que nt I t e m s e ts Using Support Constraints Proceedings of International Conference on Very Large Databases VLDB 2000\, 43-52   3 W a ts on H  J A nni no D   A a nd W i x o m  B  H  C u r r e nt  Practices in Data Warehousing Information Systems Management  8 200   Proceedings of t he 36th Ha waii International Conf erence on S y st e m Sciences \(HICSS\22203 0 76 95 18 745/0 3 1 7.00 251 20 02  I E EE 


 11 B IOGRAPHY  Ying Chen is a Senior Consultant with Booz Allen Hamilton Inc. She has 5 years of professional experience in system design and development with J2EE and SOA technologies. She is now involved in a research and development project in support of United States Intelligence Community, designing and implementing Advanced Information Sharing and Collaboration solutions. She holds an MS degree in Computer Sc ience from Virginia Tech and BS degree in Computer Science from Fudan University in Shanghai, China  Brad Cohen is an Associate with Booz Allen Hamilton Inc He has 8 years of professional experience in developing and implementing enterprise-class systems for both commercial and government applications.  Currently he is serving as the technical manager on a research and development project in support of the United States Intelligence Community.  He holds an MBA and MS in Information Systems, and a BS in Decision and Information Scien ces from the University of Maryland, College Park   


Proceedings of the Ninth ACM SIGKDD International Conference on Knowledge Discovery and Data Mining 7 Conclusion and Future Work References frontier  pages 487\320499 Morgan Kaufmann 1994  W orkshop on frequent itemset mining implementations 2003 http://\336mi.cs.helsinki.\336/\336mi03  W orkshop on frequent itemset mining implementations 2004 http://\336mi.cs.helsinki.\336/\336mi04  J  Han J  Pei and Y  Y in Mining frequent patterns without candidate generation In Proceedings of 20th International Conference on Very Large Data Bases VLDB VLDB Journal Very Large Data Bases Data Mining and Knowledge Discovery An International Journal Lecture Notes in Computer Science  2004  J W ang and G Karypis Harmon y Ef 336ciently mining the best rules for classi\336cation In The Tenth ACM SIGKDD International Conference on Knowledge Discovery and Data Mining KDD\32504 Symposium on Principles of Database Systems 2 b Average time taken per frequent itemset shown on two scales T10I4D100K is increased and hence the number of frequent items decreases Figure 5\(c also shows that the maximum frontier size is very small Finally we reiterate that we can avoid using the pre\336x tree and sequence map so the only space required are the itemvectors and the minSup SIAM International Conference on Data Mining required drops quite quickly as ACM SIGMOD Workshop on Research Issues in Data Mining and Knowledge Discovery 2000 ACM SIGMOD Intl Conference on Management of Data Figure 5 Results  8\(3\3204 2000  F  P an G C ong A T ung J Y ang and M Zaki Carpenter Finding closed patterns in long biological datasets In  2121:236 2001  M Steinbach P N T an H Xiong and V  K umar  Generalizing the notion of support In a Runtime ratios T10I4D100K c Number of Itemvectors needed and maximum frontier size T10I4D100K  pages 1\32012 ACM Press May 2000  F  K orn A Labrinidis Y  K otidis and C F aloutsos Quanti\336able data mining using ratio rules  Morgan Kaufmann 2003  J Pei J Han and L Lakshmanan Pushing convertible constraints in frequent itemset mining We showed interesting consequences of viewing transaction data as itemvectors in transactionspace and developed a framework for operating on itemvectors This abstraction gives great 337exibility in the measures used and opens up the potential for useful transformations on the data Our future work will focus on 336nding useful geometric measures and transformations for itemset mining One problem is to 336nd a way to use SVD prior to mining for itemsets larger than  pages 205\320215 2005  We also presented GLIMIT a novel algorithm that uses our framework and signi\336cantly departs from existing algorithms GLIMIT mines itemsets in one pass without candidate generation in linear space and time linear in the number of interesting itemsets Experiments showed that it beats FP-Growth above small support thresholds Most importantly it allows the use of transformations on the data that were previously impossible  That is the space required is truly linear  D Achlioptas Database-friendly random projections In  2001  R Agra w al and R Srikant F ast algorithms for mining association rules In  8:227\320252 May 2004  J Pei J Han and R Mao CLOSET An ef 336cient algorithm for mining frequent closed itemsets In  pages 21\32030 2000  S Shekhar and Y  Huang Disco v ering spatial colocation patterns A summary of results 


mator from sensor 1 also shown 6. CONCLUSIONS This paper derives a Bayesian procedure for track association that can solve a large scale distributed tracking problem where many sensors track many targets. When noninformative prior of the target state is assumed, the single target test becomes a chi-square test and it can be extended to the multiple target case by solving a multidimensional assignment problem. With the noninformative prior assumption, the optimal track fusion algorithm can be a biased one where the regularized estimate has smaller mean square estimation error. A regularized track fusion algorithm was presented which modifies the optimal linear unbiased fusion rule by a less-than-unity scalar. Simulation results indicate the effectiveness of the proposed track association and fusion algorithm through a three-sensor two-target tracking scenario 7. REFERENCES 1] Y. Bar-Shalom and W. D. Blair \(editors Tracking: Applications and Advances, vol. III, Artech House, 2000 2] Y. Bar-Shalom and H. Chen  Multisensor Track-to-Track Association for Tracks with Dependent Errors  Proc. IEEE Conf. on Decision and Control, Atlantis, Bahamas, Dec. 2004 3] Y. Bar-Shalom and X. R. Li, Multitarget-Multisensor Tracking Principles and Techniques, YBS Publishing, 1995 4] Y. Bar-Shalom, X. R. Li and T. Kirubarajan, Estimation with Applications to Tracking and Navigation: Algorithms and Software for Information Extraction, Wiley, 2001 5] S. Blackman, and R. Popoli  Design and Analysis of Modern Tracking Systems  Artech House, 1999 10 15 20 25 30 35 40 45 50 55 60 2 4 6 8 10 12 14 Time N o rm a li z e d e s ti m a ti o n e rr o r s q u a re d Target 1 Sensor 1 Centralized Est Track Fusion 10 15 20 25 30 35 40 45 50 55 60 0 2 


2 4 6 8 10 12 14 Time N o rm a li z e d e s ti m a ti o n e rr o r s q u a re d Target 2 Sensor 1 Centralized Est Track Fusion Fig. 7. Comparison of the NEES for centralized IMM estimator \(configuration \(i estimators \(configuration \(ii sensor 1 also shown 6] H. Chen, T. Kirubarajan, and Y. Bar-Shalom  Performance Limits of Track-to-Track Fusion vs. Centralized Estimation: Theory and Application  IEEE Trans. Aerospace and Electronic Systems 39\(2  400, April 2003 7] H. Chen, K. R. Pattipati, T. Kirubarajan and Y. Bar-Shalom  Data Association with Possibly Unresolved Measurements Using Linear Programming  Proc. 5th ONR/GTRI Workshop on Target Tracking Newport, RI, June 2002 8] Y. Eldar, and A. V. Oppenheim  Covariance Shaping Least-Square Estimation  IEEE Trans. Signal Processing, 51\(3 pp. 686-697 9] Y. Eldar  Minimum Variance in Biased Estimation: Bounds and Asymptotically Optimal Estimators  IEEE Trans. Signal Processing, 52\(7 10] Y. Eldar, A. Ben-Tal, and A. Nemirovski  Linear Minimax Regret Estimation of Deterministic Parameters with Bounded Data Uncertainties  IEEE Trans. Signal Processing, 52\(8 Aug. 2004 11] S. Kay  Conditional Model Order Estimation  IEEE Transactions on Signal Processing, 49\(9 12] X. R. Li, Y. Zhu, J. Wang, and C. Han  Optimal Linear Estimation Fusion  Part I: Unified Fusion Rules  IEEE Trans. Information Theory, 49\(9  2208, Sept. 2003 13] X. R. Li  Optimal Linear Estimation Fusion  Part VII: Dynamic Systems  in Proc. 2003 Int. Conf. Information Fusion, Cairns, Australia, pp. 455-462, July 2003 14] X. D. Lin, Y. Bar-Shalom and T. Kirubarajan  Multisensor Bias Estimation Using Local Tracks without A Priori Association  Proc SPIE Conf. Signal and Data Processing of Small Targets \(Vol 


SPIE Conf. Signal and Data Processing of Small Targets \(Vol 5204 15] R. Popp, K. R. Pattipati, and Y. Bar-Shalom  An M-best Multidimensional Data Association Algorithm for Multisensor Multitarget Tracking  IEEE Trans. Aerospace and Electronic Systems, 37\(1 pp. 22-39, January 2001 pre></body></html 


20 0  50  100  150  200  250  300 Pe rc en ta ge o f a dd iti on al tr af fic Cache size 200 clients using CMIP 200 clients using UIR c Figure 6. The percentage of additional traf?c the cache at every clock tick. A similar scheme has been proposed in [13], which uses fv, a function of the access rate of the data item only, to evaluate the value of each data item i that becomes available to the client on the channel If there exists a data item j in the client  s cache such that fv\(i j replaced with i A prefetch scheme based on the cache locality, called UIR scheme, was proposed in [7]. It assumes that a client has a large chance to access the invalidated cache items in the near future. It proposes to prefetch these data items if it is possible to increase the cache hit ratio. In [6], Cao improves the UIR scheme by reducing some unnecessary prefetches based on the prefetch access ratio \(PAR scheme, the client records how many times a cached data item has been accessed and prefetched, respectively. It then calculates the PAR, which is the number of prefetches divided by the number of accesses, for each data item. If the PAR is less than one, it means that the data item has been accessed a number of times and hence the prefetching is useful. The clients can mark data items as non-prefetching when PAR &gt; b, where b is a system tuning factor. The scheme proposes to change the value of b dynamically according to power consumption. This can make the prefetch scheme adaptable, but no clear methodology as to how and when b should be changed. Yin et al. [19] proposed a power-aware prefetch scheme, called value-based adaptive prefetch \(VAP the number of prefetches based on the current energy level to prolong the system running time. The VAP scheme de?nes a value function which can optimize the prefetch cost to achieve better performance These existing schemes have ignored the following characteristics of a mobile environment: \(1 query some data items frequently, \(2 during a period of time are related to each other, \(3 miss is not a isolated events; a cache miss is often followed by a series of cache misses, \(4 eral requests in one uplink request consumes little additional bandwidth but reduces the number of future uplink requests. In this paper, we addressed these issues using a cache-miss-initiated prefetch scheme, which is based on association rule mining technique. Association rule mining is a widely used technique in ?nding the relationships among data items. The problem of ?nding association rules among items is clearly de?ned by Agrawal et al. in [5]. However in the mobile environment, one cannot apply the existing association rule mining algorithm [4] directly because it is too complex and expensive to use This makes our algorithm different from that of [4] in 


This makes our algorithm different from that of [4] in twofold. First, we are interested in rules with only one data item in the antecedent and several data items in the consequent. Our motivation is to prefetch several data items which are highly related to the cache-miss data item within Proceedings of the 2004 IEEE International Conference on Mobile Data Management \(MDM  04 0-7695-2070-7/04 $20.00  2004 IEEE the cache-miss initiated uplink request. We want to generate rules where the antecedent is one data item, but the cache-missed data item and the consequent is a series of data items, which are highly related to the antecedent. If we have such rules, we can easily ?nd the data items which should also be piggybacked in the uplink request. Second in mobile environment, the client  s computation and power resources are limited. Thus, the rule-mining process should not be too complex and resource expensive. It should not take a long time to mine the rules. It should not have high computation overhead. However, most of the association rule mining algorithms [4, 5] have high computation requirements to generate such rules 5. Conclusions Client-side prefetching technique can be used to improve system performance in mobile environments. However, prefetching also consumes a large amount of system resources such as computation power and energy. Thus, it is very important to only prefetch the right data. In this paper, we proposed a cache-miss-initiated prefetch \(CMIP scheme to help the mobile clients prefetch the right data The CMIP scheme relies on two prefetch sets: the alwaysprefetch set and the miss-prefetch set. Novel association rule based algorithms were proposed to construct these prefetch sets. When a cache miss happens, instead of sending an uplink request to only ask for the cache-missed data item, the client requests several items, which are within the miss-prefetch set, to reduce future cache misses. Detailed experimental results veri?ed that the CMIP scheme can greatly improve the system performance in terms of increased cache hit ratio, reduced uplink requests and negligible additional traf?c References 1] S. Acharya, M. Franklin, and S. Zdonik. Prefetching From a Broadcast Disk. Proc. Int  l Conf. on Data Eng., pages 276  285, Feb. 1996 2] S. Acharya, M. Franklin, and S. Zdonik. Balancing Push and Pull for Data Broadcast. Proc. ACM SIGMOD, pages 183  194, May 1997 3] S. Acharya, R. Alonso, M. Franklin, and S. Zdonik. Broadcast disks: Data Management for Asymmetric Communication Environments. Proc. ACM SIGMOD, pages 199  210 May 1995 4] R. Agrawal and R. Srikant. Fast Algorithms for Mining Association Rules. In J. B. Bocca, M. Jarke, and C. Zaniolo editors, Proc. 20th Int. Conf. Very Large Data Bases, VLDB pages 487  499. Morgan Kaufmann, 12  15 1994 5] R. Agrawal, Tomasz Imielinski, and Arun Swami. Mining Association Rules Between Sets of Items in Large Databases. In Proc. of the ACM SIGMOD Conference on Management of Data, pages 207  216, Washington, D.C May 1993 6] G. Cao. Proactive Power-Aware Cache Management for Mobile Computing Systems. IEEE Transactions on Computers, 51\(6  621, June 2002 7] G. Cao. A Scalable Low-Latency Cache Invalidation Strategy for Mobile Environments. IEEE Transactions on Knowledge and Data Engineering, 15\(5 ber/October 2003 \(A preliminary version appeared in ACM MobiCom  00 8] K. Chinen and S. Yamaguchi. An Interactive Prefetching Proxy Server for Improvement of WWW Latency. In Proc INET 97, June 1997 9] E. Cohen and H. Kaplan. Prefetching the means for docu 


9] E. Cohen and H. Kaplan. Prefetching the means for document transfer: A new approach for reducing web latency. In Proceedings of IEEE INFOCOM, pages 854  863, 2000 10] R. Cooley, B. Mobasher, and J. Srivastava. Data preparation for mining world wide web browsing patterns. Knowledge and Information Systems, 1\(1  32, 1999 11] C. R. Cunha, Azer Bestavros, and Mark E. Crovella. Characteristics of WWW Client Based Traces. Technical Report TR-95-010, Boston University, CS Dept, Boston, MA 02215, July 1995 12] D. Duchamp. Prefetching hyperlinks. In USENIX Symposium on Internet Technologies and Systems \(USITS  99 1999 13] V. Grassi. Prefetching Policies for Energy Saving and Latency Reduction in a Wireless Broadcast Data Delivery System. In ACM MSWIM 2000, Boston MA, 2000 14] S. Hameed and N. Vaidya. Ef?cient Algorithms for Scheduling Data Broadcast. ACM/Baltzer Wireless Networks \(WINET  193, May 1999 15] Q. Hu and D. Lee. Cache Algorithms based on Adaptive Invalidation Reports for Mobile Environments. Cluster Computing, pages 39  48, Feb. 1998 16] Z. Jiang and L. Kleinrock. An Adaptive Network Prefetch Scheme. IEEE Journal on Selected Areas in Communications, 16\(3  11, April 1998 17] V. Padmanabhan and J. Mogul. Using Predictive Prefetching to Improve World Wide Web Latency. Computer Communication Review, pages 22  36, July 1996 18] N. Vaidya and S. Hameed. Scheduling Data Broadcast in Asymmetric Communication Environments. ACM/Baltzer Wireless Networks \(WINET  182, May 1999 19] L. Yin, G. Cao, C. Das, and A. Ashraf. Power-Aware Prefetch in Mobile Environments. IEEE International Conference on Distributed Computing Systems \(ICDCS 2002 Proceedings of the 2004 IEEE International Conference on Mobile Data Management \(MDM  04 0-7695-2070-7/04 $20.00  2004 IEEE pre></body></html 


um be r o f C he ck ed P at te rn s Support Threshold Mafia Min_Conf=0.5 Min_Conf=0.7 Min_Conf=0.9 Figure 6. The Number of Checked Patterns on the Pumsb Data Set 10 100 1000 10000 0.1 0.2 0.3 0.4 0.5 0.6 0.7 R un T im e s ec  Support Threshold Mafia Min_Conf=0.5 Min_Conf=0.7 Min_Conf=0.9 Figure 7. The RunTime Comparison on the Pumsb Data Set The runtime comparison of MHP and MAFIA on the Pumsb* data set is shown in Figure 5. In the ?gure, we can observe that the runtime of MHP can be signi?cantly reduced with the increase of h-con?dence thresholds. Also the runtime of MHP can be several orders of magnitude less than that of MAFIA even if the h-con?dence threshold is as low as 0.3. The reason is that the number of checked patterns of MHP is sign?cantly smaller than that of MAFIA Similar results are also obtained from the pumsb data set as shown in Figure 6 and Figure 7. For the pumsb data set the number of checked patterns of MHP is much smaller 


than that of MAFIA and the runtime of MHP can be significantly less than that of MAFIA 5.3. The Effect of the MHP Algorithm on Finding Maximal Hyperclique Patterns Figure 8 and Figure 9 show the number of maximal patterns identi?ed byMHP andMAFIA on Pumsb* and Pumsb data sets respectively. As can be seen, the number of maximal hyperclique patterns identi?ed by MHP can be orders of magnitude smaller than the number of maximal frequent patterns identi?ed by MAFIA. In other words, the number Proceedings of the 16th IEEE International Conference on Tools with Artificial Intelligence \(ICTAI 2004 1082-3409/04 $20.00  2004 IEEE 100 1000 10000 100000 1e+06 1e+07 1e+08 1e+09 0.02 0.025 0.03 0.035 0.04 0.045 0.05 0.055 0.06 N um be r o f C ou nt ed P at te rn s Support Threshold Mafia Min_Conf=0 Min_Conf=0.1 Min_Conf=0.3 Min_Conf=0.5 Min_Conf=0.7 Min_Conf=0.9 Figure 8. The Number of MFI/MHP Patterns in the Pumsb* Data Set 100 1000 10000 100000 1e+06 


1e+07 1e+08 0.1 0.2 0.3 0.4 0.5 0.6 0.7 N um be r o f C ou nt ed P at te rn s Support Threshold Mafia Min_Conf=0.5 Min_Conf=0.7 Min_Conf=0.9 Figure 9. The number of MFI/MHP Patterns in the Pumsb Data Set of maximal hyperclique patterns is much easier to manage than that of maximal frequent patterns. Indeed, in realworld applications, it is dif?cult to interpret several million maximal frequent patterns. However, it is possible to interpret the results of maximal hyperclique pattern mining In addition, due to the memory limitation, we cannot extract maximal frequent patterns with MAFIA on the Pumsb data set if the support threshold is less than 0.4, as shown in Figure 7. In contrast, MHP can identify maximal hyperclique patterns when the support threshold is 0.1, if we set the h-con?dence threshold to 0.5. In other words, MHP has the ability to identify patterns which can be dif?cult to identify for MAFIA. Hence, MHP can better explore the pattern space and ?nd interesting patterns at low levels of support 6. Conclusions and Future Work In this paper, we present a two-phase Maximal Hyperclique Pattern \(MHP best features of both the BFS strategy and the DFS strategy. More speci?cally, we adapted DFS pruning methods such as equivalence pruning, to an apriori-like approach In addition, we proved the correctness and completeness of the MHP algorithm. Finally, our experimental results show that the MHP algorithm can be several orders of magnitude faster than standard maximal frequent pattern mining algorithms and has the ability to identify patterns at extremely low levels of support in dense data sets There are several directions for future work. First, in 


this paper, we only generate the size-2 patterns in the BFS phase. It will be interesting to investigate the impact on the performance if the ?rst phase is stopped at a deeper level Also, the projection is a very ef?cient method for ?nding patterns, especially for parallel implementation of pattern mining algorithms [1]. We plan to adapt the projection ideas into our algorithm and design an ef?cient parallel algorithm for mining maximal hyperclique patterns References 1] R. Agarwal, C. Aggarwal, and V. Prasad. A Tree Projection Algorithm For Generation of Frequent Itemsets. pages 350 371, Feb 2001 2] R. Agrawal, T. Imielinski, and A. Swami. Mining Association Rules between Sets of Items in Large Databases. In Proc. of the ACM SIGMOD Conference on Management of Data, pages 207216,May 1993 3] R. Agrawal and R. Srikant. Fast Algorithms for Mining Association Rules. In Proc. of the 20th Intl Conference on Very LargeData Bases, 1994 4] R. Bayardo. Ef?ciently mining long patterns from databases In Proc. of the ACM SIGMOD Conference, 1998 5] R. Bayardo and R. Agrawal. Mining the Most Interesting Rules. In Proc. of the ACM SIGKDD Conference, 1999 6] D. Burdick, M. Calimlim, and J. Gehrke. Ma?a: AMaximal Frequent Itemset Algorithm for Transactional Databases. In Proc. of IEEE Conf. on Data Engineering, 2001 7] Y. Huang, H. Xiong, W. Wu, and Z. Zhang. A Hybrid Approach for Mining Maximal Hyperclique Patterns. In In Technical Report UTDCS-34-04, Department of computer science, University of Texas - Dallas, 2004 8] J.Han, J.Pei, and Y. Yin. Mining Frequent Patterns without Candidate Generation. In Proc. of the ACM SIGMOD International Conference on Management of Data, 2000 9] M.J.Zaki and C.Hsiao. ChARM: An ef?cient algorithm for closed itemset mining. In Proc. of 2nd SIAM International Conference on Data Mining, 2002 10] R.Rymon. Search through Systematic Set Enumeration. In Proc. Third Intl Conference on Principles of Knowledge Representation and Reasoning, 1992 11] H. Xiong, M. Steinbach, P.-N. Tan, and V. Kumar. HICAP: Hierarchial Clustering with Pattern Preservation. In Proc. of 2004 SIAM International Conference on Data Mining \(SDM 12] H. Xiong, P.-N. Tan, and V. Kumar. Mining Strong Af?nity Association Patterns in Data Set with Skewed Support. In Proc. of the Third IEEE International Conference on Data Mining \(ICDM Proceedings of the 16th IEEE International Conference on Tools with Artificial Intelligence \(ICTAI 2004 1082-3409/04 $20.00  2004 IEEE 





