1 A User-guided Association Rules Mining Method and Its Application Yanhong Li School of Information Management and Engineering 002\310 Shanghai University of Finance Economics Shanghai, 200433, China E-mail: lyhong@shufe.edu.cn Abstract Association rules method is important in mining large sets of data, but there are often many meaningless rules discovered, which affects the algorithm\220s efficiency, moreover, the presentation of rules is not easy for users to understand. User guide often works during association rules mining procedure. This paper presents a user-guided association rules mining method, considering users\220 differential emphasis on each item through fuzzy regions. This is more realistic and practical than prior association rules methods. Moreover, the discovered rules are expressed in natural language that is more understandable to humans. The paper finally uses the proposed method to analyze data sets of appliance rmance of the proposed approach is demonstrated Key words: data mining, association rules, fuzzy sets, weighted items 1 Introduction 1.1 Association rules mining Association rules mining method provides valuable information in assessing significant correlations that can be found in large databases An association rule is an expression of YX 001 where X and Y are ts of items. The rule YX 001 has minimum support value minsup if minsup percent of transactions support YX 002 the rule YX 001 holds with minimum confidence value minconf if minconf percent of transactions that support X also support Y  Minsup and minconf will be assigned to measure the frequency and the strength of association rules Many algorithms have been proposed to find association rules in large databases. Most, such as the Apriori algorithm d its improvemen tify correlations among transactions consisting of categorical attributes using binary values. Some data mining approaches involve weighted association rules for binary values. Ca pr opos ed t w o  algorithms of association rules mining with weighted items. Lu s i g n e d a w e i g h t n o t on l y  f o r each time interval but also for each item in his mixed weighted association rules mining. Most of the previous studies focused on categorical attributes Transaction data in real-world applications, however usually consist of quantitative attributes, so some data mining algorithms for quantitative values also have been proposed w h er e th e alg orithm f i n d s  association rules by partitioning the attribute domain combining adjacent partitions and then transforming the problem into a binary state 1 2 Fuzzy set theory and Fuzzy association rules mining Real-world application is full of vagueness and uncertainty. Several  theories on managing uncertainty and imprecision have been advanced, to include fuzzy set theory, probability theory, rough set theory etc Fuzzy set theory is used more than the others because of its simplicity and similarity to human reasoning Fuzzy set theory was first proposed by Zadeh in 1965  prim aril y co n cern ed  w i t h qu a n ti fy ing an d  reasoning using natural language in which many words have ambiguous meanings. Accordingly, fuzzy association rules described in linguistic terms help increase the flexibility for supporting users in making decisions A fuzzy set A in universe U is defined as  1  0          003\003 xUxxxA AA 265 265 where  x A 265 is a membership function indicating the degree of membership of x to A The greater the value of Proceedings of the 2005 The Fifth International Confer ence on Computer and Information Technology \(CIT\22205 0-7695-2432-X/05 $20.00 \251 2005  IEEE 


2  x A 265 the more x belongs to A Fuzzy sets can also be thought of as an extension of the traditional crisp sets Mining fuzzy association rules for quantitative values has been considered by a number of researchers 3, 6, 8, 9, 13, 16 o s t o f  wh o m bas ed t h ei r m e t h ods on  Apriori algorithm. Each of these researchers treated all attributes \(or all the linguistic terms\uniform However, in real-world applications, the users perhaps have more interest in the rules that contain fashionable items. Decreasing minsup or minconf to get rules containing fashionable items is not the best, because the efficiency of the algorithm will be reduced and many uninteresting rules will occur simultaneously  en e s ei [5] con s idered th is is s u e an d u s ed  weighted quantitative association rules mining based on a fuzzy approach, proposing two different definitions of weighted support: with and without normalization. In the non-normalized case, he used the product operator for defining the combined weight and fuzzy value. The combined weight or fuzzy value is very small and even tends to zero when the number of items in a candidate itemset is large, so the support level is very small, this will result in data overflow and make the algorithm terminate unexpectedly when calculating the confidence value. So does the normalized case for the product operator is included in the calculation of the combined fuzzy value although Gyenesei used the geometric mean of item weights as the combined weight. Moreover, the proposed two algorithms use categorical regions in the data mining procedure for each categorical attribute, the corresponding membership values is 0 or 1, which loses the flexibility of fuzzy representations of real data, especially when the number of categorical regions is large To avoid the problems occurred in literatu  this paper, combining and extending the technologies of fuzzy sets and association rules mining, allowing different emphases on each item, proposes a userguided association rules mining method, the discovered rules which are expressed in natural language are more understandable to users 2 The steps of the proposed method In the proposed method, we predefine suitable linguistic terms \(fuzzy regions\nd their corresponding membership functions to transform numeric or categorical data into fuzzy values.  Weights of items should be given to reflect their importance to users. The support and confidence thresholds are also needed. We then can begin to search for some interesting association rules by using the proposed algorithm. Notations used by the algorithm are stated as follows n the total number of transaction observations m the total number of attributes j A the j-th categorical or quantitative attribute mj 004\004 1  j A   j A the number of fuzzy regions of j A  jk R the k-th fuzzy region of j A  004\004 k 1  j A called item jk 005 the weight of jk R  10 004\004 jk 005   i D the i-th transaction datum ni 004\004 1   i j v the categorical or quantitative value of j A for  i D   i jk f the membership value of  i j v in jk R  0 004  i jk f 004 1  jk Sup R the calculated support value of jk R  Sup the calculated support value of each candidate itemset conf the calculated confidence value of each large itemset minsup the predefined minimum support value minconf the predefined minimum confidence value r C the set of candidate itemsets with r attributes\(items mr 004\004 1  r L the set of large itemsets with r attributes\(items mr 004\004 1  The user-guided association rules mining algorithm for quantitative values is as follows Input n  m  jk 005 membership function of each item minsup and minconf Output: fuzzy association rules Step 1 Transform the quantitative or categorical value  i j v of each transaction datum  i D  1  i to n  for  each attribute j A  1  j to m into fuzzy membership values  i jk f  004\004 k 1  j A sing given membership function of jk R  Proceedings of the 2005 The Fifth International Confer ence on Computer and Information Technology \(CIT\22205 0-7695-2432-X/05 $20.00 \251 2005  IEEE 


3 Step 2 Calculate  jk Sup R    1 n i jk jk i f n 005  000\246  mj 004\004 1  004\004 k 1  j A the support value of fuzzy region jk R to form 1 C the set of candidate 1-itemsets Step 3 If  jk Sup R 006 minsup then put jk R in 1 L  the set of large 1-itemsets Step 4 If 1 L is not null, then do the next step otherwise, exit the algorithm Step 5 itemsets in r L under the condition that 1 r 212 items in two itemsets are the same and the other one is different then keeps in 1  r C the itemsets which have all their sub-itemsets of r items existing in r L and do not have any two items jp R and jq R  p q 007  of the same attribute j A ts are called candidate r-itemsets Step 6 Do the following substeps for each newly formed 1 r  itemset S th items 12 1      tr s ss s  000"\000 in 1  r C  11 tr 004\004  a Calculate the fuzzy value of each transaction datum  i D of S as  i s f  1  1 tt r i s s t f 005   b where  t i s f is the membership value of  i D in fuzzy region t s  t s 005 is the weight of the item t s If the minimum operator is used for the intersection then  i s f  1  1 min  tt r i s s t f 005    b Calculate the support value  Sup S of S in the transactions as  Sup S   1 n i s i f n  000\246  1  1 1 min  tt n r i s s t i f n 005    000\246 c  Sup S 006 minsup then put S in 1 r L  Step 7 If 1 r L  is null, then do the next step otherwise, set 1 rr  and repeat Step5 to 6 Step 8 Collect the large itemsets together Step 9 Construct association rules for each large q itemset S with items 12   q s ss 000  2 q 006 using the following substeps a Form each possible association rule as follows 1 xy q k s ss s s b\001 000"\000  1 k  to q  1 x k 212  1 yk   b Calculate the confidence value of each association rule,  using 1  xy q k Conf s s s s s b\b\b\b\b\001  000"\000  1 1   1 1 min  min\(min min  kk kk kk n q i ss k i n q x ii ss ss kky i f f f 005 005\005     000\246 000\246 Step 10 Output the relative and interesting association rules with 1  xy q k Conf s s s s s b\b\b\b\b\001 006 000"\000 minconf The above algorithm meets the following two lemmas, indicating the proposed algorithm have downward closure property, which can reduce the number of candidate itemsets, that is why the steps of proposed  algorithm is able to be similar to the important Apriori algorithm  Lemma 1 if an itemset is a small fuzzy weighted itemset, each of its supersets must be a small fuzzy weighted itemset Lemma 2 if an itemset is a large fuzzy weighted itemset, each of its subsets must be a large fuzzy weighted itemset The proofs of them are omitted for the purpose of saving space here 3 Application We applied the proposed method to analyze data of application loan which consist of 650 data points of applicants for appliance loans, whose attributes are Age  Income  Assets  Debts  Credit with red for bad credit, amber for some credit problems, and green for clean credit record Want the amount requested in the appliance loan applications\d Result it is 1 if all s were received on time and 0 if not \(late or default\A new attribute Risk is generated based on Assets, Debts and Want using the formula Risk Assets- Debts \205 Want there are both quantitative and categorical attributes in the application background We assign the attribute Age  Income and Risk three fuzzy regions for each Credit and Result two fuzzy regions. Weight for each attribute which is based on opinions of users is as Credit 0.8 006 Risk 0.7  Result 0.7 006 Income 0.55 006 Age\(0.45\ The weights of fuzzy regions of each attribute are the same as that of the attribute here. You can assign different Proceedings of the 2005 The Fifth International Confer ence on Computer and Information Technology \(CIT\22205 0-7695-2432-X/05 $20.00 \251 2005  IEEE 


4 weights to different fuzzy regions of the same attribute such as assigning fuzzy region-young of the attribute Age a larger weight value when users are just interested in young people\220s loan applications, so more association rules involving the young will occur. The here focuses on the relationship between Result and other attributes here, a larger weight value are assigned to Result  The curves of membership functions of fuzzy regions for attribute Age  Income and Risk are trapezoid separately, points for attribute Credit and Result which are as the figure1-5  Under the condition of minsup 0.25 and minconf 0.90, we discovered the following rules involving Result by using the proposed method, each of their confidence values are greater than 90 is received on time If Credit is good, then all payment is received on time If Income is middle, Credit is good, then all payment is received on time If Risk is high and Credit is good, then all payment is received on time The above rules derives from the data in database which can provide meaningful information that benefits decision-making, moreover, the discovered rules are easy to understand 4 Performance analysis We did more tests besides the application in section 3 based on the same data Figure 6 shows the relationships between the number of association rules and minsup and Figure 7 shows the relationship between the number of association rules and minconf using the proposed method, when weights of the items are same to section 3. According to Figure 6 and Figure 7, it is obvious that the number of association rules decreases along with an increase in minsup or minconf under a given specific minconf or minsup which shows an  Figure 5 The membership functions of attribute Result 0 0.5 1 1.5 10 Result Good Bad Figure 4 The membership functions of attribute Credit 0 0.2 0.4 0.6 0.8 1 Red Amber Green Credit Good Bad Membership value Figure 3 The membership functions of attribute Risk 0 0.2 0.4 0.6 0.8 1 1.2 40000-30000 15000 5000 10000 20000 Risk Membership value Low Middle High Figure 2 The  membership functions of attibute Age 0 0.2 0.4 0.6 0.8 1 1.2 0 5 5 0 0 100 Age Membership value Young Middle Old Figure 1 The  membership functions of attibute Age 0 0.2 0.4 0.6 0.8 1 1.2 0 5 5 0 0 100 Age Young Middle Old Membership value Membership value Proceedings of the 2005 The Fifth International Confer ence on Computer and Information Technology \(CIT\22205 0-7695-2432-X/05 $20.00 \251 2005  IEEE 


5 appropriate minsup or minconf constraint the number of association rules and avoid the occurrence of some meaningless association rules. The results are as expected and quite consistent with our intuition. T he curves for large minconf \(or minsup moother than those for small ones in Figure 6 \(or Figure 7\meaning that the minsup or minconf had a large effect on the number of association rules when smaller minconfs \(or minsups were used, the above results are same to those in  Figure 6 The relationship between number of association rules and minsup using the proposed method 0 5 10 15 20 0.2 0.25 0.3 0.35 0.4 0.55 minsup minconf=0.55 minconf=0.65 minconf=0.75 minconf=0.85 minconf=0.95 minconf=1 the number of ation rules 0 2 4 6 8 10 12 14 16 18 0.55 0.65 0.75 0.85 0.95 1 minconf minsup=0.2 minsup=0.25 minsup=0.3 minsup=0.35 minsup=0.4 minsup=0.55 Figure 7 er of association rules and minconf  using the proposed method the number of ation rules Let minconf=0.65, the result of comparing the numbers of weighted \(weights are as that in section 3 large itemsets with those of the unweighted \(weights are actually equal to 1\ is shown in Figure 8.It is easy to see that the number of unweighted large itemsets dashed line\s always larger than that of the corresponding one of the weighted \(solid one\whether it is large 1-itemset\(L1\itemset\(L2\e 3itemset\(L3\ation of them, which are as we expect, so meaningless rules can be pruned early by assigning weights to some attributes, which can reduce the execution time of algorithm. In addition, we can find that the less of the items included in the large itemsets, the smoother the corresponding curve is which is natural because higher requirements are asked for the candidate itemsets that include more items more candidate itemsets can not become the corresponding large itemsets Figure 8 Comparison of the numbers of large itemsets of the weighted and unweighted methods 0 10 20 30 40 50 0.2 5 3 0.35 0.4 5 5 minsup unweighted L1 unweighted L2 unweighted L3 unweighted L1+L2+L3 weighted\( as example\L1 weighted\( as example\L2 weighted\( as example\L3 weighted\( as example\L1+L2+L3 Number of large itemsets Figure 9 How the number of large itemsets involvin g specific items var y with an increase in the item's weight 0 5 10 15 20 25 0.2 0.4 0.6 0.8 1 Weight R22 R33 R41 R51 Number of large itemsets involving some ecific item The relationship between the number of large itemsets involving some item and the item\220s weight is shown in Figure 9, when minsup=0.2, minconf=0.65 of the four items  22 R Income-middle 33 R Risk-middle 41 R Creditgood\d 51 R Result-on time\the different curves respectively in Figure 9} vary by an increase, weights of other items are 1 . Figure 9 shows the number of large itemsets with regard to some item increases along with an increase in the item\220s weight, which is also as we expected and verified that users\220 preference\( or the Proceedings of the 2005 The Fifth International Confer ence on Computer and Information Technology \(CIT\22205 0-7695-2432-X/05 $20.00 \251 2005  IEEE 


6 ability of guidance\ be added into the procedure of data mining by adjusting weight Next, we selected 550 cases randomly used for inducing rules from 650 cases in the original data set the remaining 100 cases are used for testing accuracy of the induced rules of the proposed method by measuring the average percentage of correct predictions. Our experiment is based on the following conditions: randomly assign a set of weights to each fuzzy region of each attribute, let minsup 0.35, cut set of  the fuzzy set transforming quantitative value to fuzzy value is 0.7. Figure 10 presents how the accuracy of the proposed method varies along with minsup and minconf It is easily seen that the accuracy of the proposed method increases on the whole with an increase in minsup and minconf which is not counterintuitive and shows the contributions \(functions minsup and minconf to accuracy. But there is some variance or exception at the latter part of the curve because some statistics features disappear \(such as cases with only one or two rules left\when minsup is large enough, at the same time, it is just a roughly result of accuracy testing here, because our rule is with linguistic terms, we have to use the cut set technology percentage of correct rules predictions for testing accuracy. Although there is some information lost in the processing conducted some base features of the curves can be seen  Figure 10 The relation between accuracy and minsup for various  values of minconf 0.4 0.45 0.5 0.55 0.6 0.65 0.7 0  35 0 4 0  45 0 5 0  55 0 6 0  65 minsup weighted minconf=0.7 weighted minconf=0.8 weighted minconf=0.9 Accuracy Figure 11 compares the accuracy of the proposed weighted method with an unweighted method \(that is thod in Hong et al h ic h s h o w s t h e  accuracy of unweighted method \(dashed line\ on the whole lower than that of the proposed weighted method \(solid line\o does every pair of corresponding curves under the same minconf In addition, the accuracy of crisp-partition method is lower than that of unweighted method, which has been verified in Hong et al o  w e don\220 t i llus t rate it  again here.  Figure 11 has the same features of Figure 10 for the latter parts of the curves, where the unweighted method has more rules selected than weighted method Figure11 Comparison of the accuracy of the unweighted and weighted methods 0.4 0.45 0.5 0.55 0.6 0.65 0.7 0  35 0  4 0  45 0  5 0  55 0  6 0  65 minsup unweighted f=0.7 unweighted f=0.8 unweighted f=0.9 weighted f=0.7 weighted f=0.8 weighted f=0.9 Accuracy 5 Conclusions and future work The paper proposes a user-guided association rule mining method for quantitative or categorical data. For the proposed method, it is easy to add users\220 guide to data mining procedure, meaningless rules can be pruned early, so it is quicker to find association rules interested by users, and reduce the work burden of choosing interesting rules, in addition, the feature that the proposed method satisfies downward closure property is another reason to decrease computation time. The problem of data overflowing in Gyenes can be avoided in the proposed method because of the adoption of minimum operator. In the proposed algorithm, we assign fuzzy regions to each categorical attribute, which can describe categorical attribute in linguistic language more flexible according to situations especially when the number of categorical regions is large. The proposed method can also resolve conventional binary value problem by using a degraded membership functions and let all weights be 1. In a word, the proposed method is more flexible natural and understandable. Experimental results have showed its good performance, also The construction of membership functions in fuzzy association rules mining has always been a bottleneck our method assumes we have known the membership functions of attributes in advance. We could make the ction of membership functions more open or automatic according to distribution of data or users\220 opinions, based on some existing research on Proceedings of the 2005 The Fifth International Confer ence on Computer and Information Technology \(CIT\22205 0-7695-2432-X/05 $20.00 \251 2005  IEEE 


7 automatically deriving membership functions  in Hong et al. [7 or m a k i ng probabil i t y an d fu zz y s e t t h eor y  work in concert such as that in Nozer et al [1 r th e issue of weight, we could consider different weight schemes such as centroid weights terv al-v alue  weights, assigning a weight for each time interval as  did in th eir alg orithm  w i th bin a r y v a l u e. It is also worthy to improve the proposed method to find fuzzy association rules for interval values. All of the above discussions will be interesting topics in near future References 1 R. Ag ra w a l T  I m ielinsk i an d A  S w a m i 001\000 Mining association rules between sets of items in massive databases 001\001 Proceedings of the ACM SIGMOD International Conference on Management of Data Washington DC, USA \(1993\, pp207-216 2 R. A g ra wal an d R Srik an   001\000 Fast algorithms for mining association rules in large databases 001\001 Proceeding of the 20 th VLDB Conference \(1994\, pp 487-499 3 P. Bo sc an d O Piv ert 001\000 On some fuzzy extensions of association rules 001\001 Proceedings of IFSA-NAFIPS 2001 Piscataway, NJ, IEEE Press \(2001\pp 1104-9 4 C.H. Cai, W  C. F u C  H. Ch e n g an d W  W  Kw o n g  001\000 Mining association rules with weighted items 001\001  Proceedings of 1998 International Database Engineering and Applications Symposium, Cardiff, Wales \(1998\ pp 68-77    Gyen esei  001\000 Mining weighted association rules for fuzzy quantitative items 001\001 Proceedings of  PKDD Conference, September 13-16, 2000, Lyon, France 2000\, pp 416-423 6 T  P  Ho n g  C.-S K u o an d S C. Ch i   001\000 Trade-off between computation time and numbers of rules for fuzzy mining from quantitative data 001\001 International Journal of Uncertainty,Fuzziness and Knowledge-based Systems 9 \(2001\, pp 587-604 7 T  P  Ho n g  S.-L W a n g  001\000 Determining appropriate membership functions to simplify fuzzy induction 001\001  Intelligent Data Analysis 4 \(2000\p 51-66 8  C  K uok A  Fu a nd H  W ong  001\000 Mining fuzzy association rules in databases 001\001 ACM SIGMOD Record 27 \(1998\pp 41-46 9 R  L a dne r, F.E P e try a nd M.A C obb 001\000 Fuzzy set approaches to spatial data mining of association rules 001\001  Transactions in GIS 7 \(2003\, pp 123-138 10 S.-F. L u H  H u a n d F. L i  001\000 Mining weighted association rules 001\001 Intelligent Data Analysis 5 \(2001 pp 211-225 11  N o z e r D  J  Si ng purw a lla a n d M B o ok e r  001\000 Membership function and probability measures of fuzzy sets 001\001 Journal of  the American Statistical Association 9 \(2004\, pp 867-877 1   Olso n   001\000 Comparison of Weights in Topsis Methods 001\001 Mathematical and Computer Modeling 40 2004\, pp 721-727 1 J S h u E  Tsan g an d D Yeu n g   001\000 Query fuzzy association rules in relational databases 001\001 In proceedings of IFSA-NAFIPS 2001 Piscataway, NJ IEEE Press \(2001\89-2993 14 R. Srik a n t a n d R. A g ra w a l 001\000 Mining quantitative association rules in large relational tables 001\001 The 1996 ACM SIGMOD International Conference on Management of Data. Montreal,Canada, June \(1996\p 1-12 15 L  A   Za de h 001\000 Fuzzy sets 001\001 Information and Control 8 1965\, pp 338-356 1 W  Z h an g  001\000 Mining fuzzy quantitative association rules 001\001 Proceedings of IEEE International Conference on Tools with Artificial Intelligence 1999 Piscataway NJ,IEEE Press \(1999\, pp 99-110 Proceedings of the 2005 The Fifth International Confer ence on Computer and Information Technology \(CIT\22205 0-7695-2432-X/05 $20.00 \251 2005  IEEE 


8 Proceedings of the 2005 The Fifth International Confer ence on Computer and Information Technology \(CIT\22205 0-7695-2432-X/05 $20.00 \251 2005  IEEE 


can test whether the hyperlinks on a page have been placed appropriately by analyzing significant navigational patterns \(association rules In our experiments the percentage of hyperlinks confirmed by rules was calculated by dividing the number of common items in hyperlink sets and whole ranking lists for a given page, by the number of hyperlinks on the page separately for direct, indirect and complex rules \(Fig. 8 Note that the number of hyperlinks was put in the denominator as opposed to calculations in section 7.4 where it was ranking length 48 89%87 0 20 40 60 80 100 direct indirect complex Figure 8. The average percentage of all hyperlinks confirmed by rules Proceedings of the 2005 5th International Conference on Intelligent Systems Design and  Applications \(ISDA  05 0-7695-2286-06/05 $20.00  2005 IEEE The average percentage of hyperlinks confirmed by direct rules amounted to only 48%, probably because there were too few of them. Indirect and complex rules, on the other hand, confirmed many more hyperlinks  87% and 89%, respectively, due to their larger quantity. These relatively great values that we received may have resulted from the enormous differences between the average number of hyperlinks on a page  10 and the average ranking length: 51, 177, 180 for direct, indirect and complex rules respectively. Concluding, indirect and complex rules appear to be better at assessing the usefulness of hyperlinks compared to direct rules Note that in any case at least 11% of hyperlinks were not confirmed by any rule, so they may be recommended to be removed from the content of pages 8. Conclusions and future work Complex rules combining both direct and indirect rules usually increase the length of rankings compared to those based on direct associations. This helps overcome the problem of a multitude of pages with too short rankings Fig. 5 quested ranking length \(Fig. 6 rules substantially change the order of ranking lists \(Fig. 2 and 3 greater extent only confirm hyperlinks existing on web pages compared to lists extracted from complex rules, for short and long ranking lengths \(Fig. 7 of rules, especially indirect and complex ones, can be useful for the assessment of hyperlinks Concluding, far more diverse indirect rules can significantly improve potential value of recommendation. Nevertheless, to confirm the usefulness of indirect rules for end users, some tedious tests with their participation are required Acknowledgements The authors are indebted to thank Marcin Pilarczyk for providing cleansed data about hyperlinks on WUT pages 9. References 1] Agrawal R., Imieli?ski T., Swami A.: Mining association rules between sets of items in large databases. ACM SIGMOD Int. Conference on Management of Data, ACM Press 1993 2] Boley D., Gini, M., Gross, R., Han, E.H., Hastings, K Karypis, G., Kumar, V., Mobasher, B., Moorey, J.: Document Categorization and Query Generation on the World Wide Web Using WebACE. Artificial Intelligence Review 


Wide Web Using WebACE. Artificial Intelligence Review 13 \(5-6 1999 3] Cho Y.H., Kim J.K., Kim S.H.: A personalized recommender system based on web usage mining and decision tree induction. Expert Systems with Applications 23 \(3 2002 4] Chun J., Oh J.-Y., Kwon S., Kim D.: Simulating the Effectiveness of Using Association Rules for Recommendation Systems. AsiaSim 2004. LNCS 3398, Springer Verlag 2005 5] G  ry M., Haddad M.H.: Evaluation of web usage mining approaches for user's next request prediction. WIDM 2003 ACM Press \(2003 6] Ha S.H.: Helping Online Customers Decide through Web Personalization. IEEE Intelligent Systems 17 \(6 2002 43 7] Hamano S., Sato M.: Mining Indirect Association Rules ICDM 2004. LNCS 3275, Springer Verlag \(2004 8] Kazienko P.: IDARM - Mining of Indirect Association Rules. IIS: IIPWM  05. Advances in Soft Computing Springer Verlag \(2005 9] Kazienko P.: Multi-agent Web Recommendation Method Based on Indirect Association Rules. KES  2004. Part II LNAI 3214, Springer Verlag \(2004 10] Kazienko P., Product Recommendation in E-Commerce Using Direct and Indirect Confidence for Historical User Sessions. DS  04. LNAI 3245, Springer Verlag \(2004 269 11] Kazienko P., Kiewra M.: Link Recommendation Method Based on Web Content and Usage Mining. IIS: IIPWM  03 Advances in Soft Computing, Springer Verlag \(2003 534 12] Kazienko P., Kiewra M., Personalized Recommendation of Web Pages. Chapter 10 in: Nguyen T. \(ed Technologies for Inconsistent Knowledge Processing. Advanced Knowledge International, Adelaide, South Australia 2004 13] Kazienko P., Kolodziejski P.: WindOwls - Adaptive System for the Integration of Recommendation Methods in Ecommerce. AWIC  05, LNAI, Springer Verlag \(2005 14] Kazienko P., Matrejek M.: Adjustment of Indirect Association Rules for the Web. SOFSEM 2005. LNCS 3381 Springer Verlag \(2005 15] Kendall, M. G.: Rank correlation methods. London: Charles Griffin &amp; Company, Ltd., London \(1948 16] Lu Z., Yao Y., Zhong N.: Web Log Mining. Chapter 9 in Zhong N., Liu J., Yao Y. \(eds Berlin, New York \(2003 17] Mobasher B., Cooley R., Srivastava J.: Automatic Personalization Based on Web Usage Mining. Communications of the ACM, 43 \(8 2000 18] Tan P.-N., Kumar V.: Mining Indirect Associations in Web Data. WEBKDD 2001. LNCS 2356, Springer Verlag \(2002 145-166 19] Tan P.-N., Kumar V., Srivastava J.: Indirect Association Mining Higher Order Dependencies in Data. PKDD 2000 LNCS 1910, Springer Verlag \(2000 20] Wan Q., An A.: Efficient Mining of Indirect Associations Using HI-Mine. AI 2003. LNCS 2671, Springer Verlag 2003  221 21] Wang D., Bao Y., Yu G., Wang G.: Using Page Classification and Association Rule Mining for Personalized Recommendation in Distance Learning. ICWL `02. LNCS 2436 Springer Verlag \(2002 22] Yang H., Parthasarathy S.: On the Use of Constrained Associations for Web Log Mining. WEBKDD 2002. LNCS 2703 Springer Verlag \(2003  118 Proceedings of the 2005 5th International Conference on Intelligent Systems Design and  Applications \(ISDA  05 0-7695-2286-06/05 $20.00  2005 IEEE pre></body></html 


pre></body></html 


lossless frequent patterns representations with borders. In practice, they are also much more concise than representations based on closed itemsets and approximate representations. In this paper, we offered three methods of deriving an upper bound on the length of sets in such representations. We proved that the upper bound on the length of a longest generalized disjunction-free set depends logarithmically on the number of records in the database. The obtained result is of high importance as it guarantees that any generalized disjunction-free set representation for all patterns \(both frequent and infrequent scans, where n is the number of records in the database irrespectively how strong or weak correlations among items in the database are and irrespectively of the lengths of records and number of distinct items The modifications of the basic estimation take into account the support threshold of the representation to be found or, additionally, the information on the length of longest sets of the representation already calculated for a higher support threshold. Though these estimations are more accurate than the basic one, they are still quite rough. Further improvements of the quality of estimating the length of longest itemsets in generalized disjunctionfree representations is subject to further research References 1] R. Agrawal, H. Mannila, R. Srikant, H. Toivonen, A.I Verkamo  Fast Discovery of Association Rules   Advances in Knowledge Discovery and Data Mining AAAI, CA, 1996 2] J. Baptiste, J.-F. Boulicaut  Constraint-Based Discovery and Inductive Queries: Application to Association Rule Mining  Pattern Detection and Discovery, Springer London, UK, September 2002, pp. 110-124 3] E. Baralis, S. Chiusano, P. Garza  On Support Thresholds in Associative Classification  SAC, ACM, Taipei Taiwan, March 2004, pp. 553-558 4] Y. Bastide, N. Pasquier, R. Taouil, G. Stumme, L. Lakhal  Mining Minimal Non-redundant Association Rules Using Frequent Closed Itemsets  Computational Logic, 2000 pp. 972  986 5] J.-F. Boulicaut, A. Bykowski, C. Rigotti  Approximation of Frequency Queries by Means of Free-Sets  PKDD Springer, Lyon, France, September 2000, pp. 75-85 6] A. Bykowski, C. Rigotti  A Condensed Representation to Find Frequent Patterns  PODS, ACM, Santa Barbara USA, May 2001, pp. 267-273 7] T. Calders, Axiomatization and Deduction Rules for the Frequency of Itemsets, Ph.D. Thesis, University of Antwerp, 2003 8] T. Calders, B. Goethals  Mining All Non-derivable Frequent Itemsets  PKDD, Springer, Helsinki, Finland August 2002, pp. 74?85 9] T. Calders, B. Goethals  Minimal k-free Representations of Frequent Sets  ECML/PKDD, Springer, CavtatDubrovnik, Croatia, September 2003, pp. 71-82 10] J. Han, M. Kamber, Data Mining: Concepts and Techniques, Morgan Kaufmann Publishers, 2000 11] S.K. Harms, J. Deogun, J. Saquer, T. Tadesse  Discovering Representative Episodal Association Rules from Event Sequences Using Frequent Closed Episode Sets and Event Constraints  ICDM, IEEE Computer Society, San Jose, California, USA, November-December 2001, pp. 603  606 12] M. Kryszkiewicz  Closed Set Based Discovery of Representative Association Rules  IDA, Springer Cascais, Portugal, September 2001, pp. 350-359 13] M. Kryszkiewicz  Concise Representation of Frequent Patterns based on Disjunction  free Generators  ICDM IEEE Computer Society, San Jose, California, USA 


IEEE Computer Society, San Jose, California, USA November-December 2001, pp. 305  312 14] M. Kryszkiewicz M  Inferring Knowledge from Frequent Patterns  Soft-Ware, Springer, Belfast, Northern Ireland April 2002, pp. 247  262 15] M. Kryszkiewicz  Concise Representations of Association Rules  Pattern Detection and Discovery, Springer London, UK, September 2002, pp. 92-109 16] M. Kryszkiewicz, Concise Representation of Frequent Patterns and Association Rules, Habilitation Thesis Publishing House of Warsaw University of Technology 2002 Proceedings of the 16th International Conference on Scientific and Statistical Database  Management \(SSDBM  04 1099-3371/04 $ 20.00  2004 IEEE 17] M. Kryszkiewicz  Reducing Infrequent Borders of Downward Complete Representations of Frequent Patterns  Proc. of The First Symposium on Databases Data Warehousing and Knowledge Discovery, Scientific Publishers OWN, Baden-Baden, Germany, July, 2003, pp 29-42 18] M. Kryszkiewicz  Closed Set Based Discovery of Maximal Covering Rules  International Journal of Uncertainty, Fuzziness and Knowledge-Based Systems Vol. 11. World Scientific Publishing Company, Singapore September 2003, pp. 15-29 19] M. Kryszkiewicz  Reducing Borders of k-Disjunction Free Representations of Frequent Patterns  SAC, ACM Taipei, Taiwan, March 2004, pp. 559  563 20] M. Kryszkiewicz  Reducing Main Components of k-Disjunction Free Representations of Frequent Patterns   Proc. of IPMU  2004 \(in print 21] M. Kryszkiewicz, M. Gajek  Concise Representation of Frequent Patterns based on Generalized Disjunction  Free Generators  PAKDD, Springer, Taipei, Taiwan, May 2002, pp. 159-171 22] M. Kryszkiewicz, M. Gajek  Why to Apply Generalized Disjunction-Free Generators Representation of Frequent Patterns  ISMIS, Springer, Lyon, France, June 2002, pp 383  392 23] M. Kryszkiewicz, H. Rybi?ski, M. Gajek  Dataless Transitions between Concise Representations of Frequent Patterns  Journal of Intelligent Information Systems JIIS Netherlands, 2004, pp. 41-70 24] N. Pasquier, Data mining: Algorithmes d  extraction et de R  duction des R  gles d  association dans les Bases de Donn  es, Th  se de Doctorat, Universit  Blaise Pascal   Clermont  Ferrand II, 2000 25] N. Pasquier, Y. Bastide, R. Taouil, L. Lakhal  Efficient Mining of Association Rules Using Closed Itemset Lattices  Journal of Information Systems, Vol. 24, No. 1 1999, pp. 25  46 26] N. Pasquier, Y. Bastide, R. Taouil, L. Lakhal  Discovering Frequent Closed Itemsets for Association Rules  ICDT, Springer, Jerusalem, Israel, January 1999 pp. 398  416 27] J. Pei, G. Dong, W. Zou, J. Han  On Computing Condensed Frequent Pattern Bases  ICDM, IEEE Computer Society, Maebashi City, Japan, December 2002 pp. 378-385 28] V. Phan-Luong V  Representative Bases of Association Rules  ICDM, IEEE Computer Society, San Jose California, USA, November-December 2001, pp. 639-640 29] A. Savinov  Mining Dependence Rules by Finding Largest Itemset Support Quota  SAC, ACM, Taipei Taiwan, March 2004, pp. 525-529 30] M.J. Zaki, C.J. Hsiao  CHARM: An Efficient Algorithm for Closed Itemset Mining  SIAM, Arlington, 2002 


for Closed Itemset Mining  SIAM, Arlington, 2002 Proceedings of the 16th International Conference on Scientific and Statistical Database  Management \(SSDBM  04 1099-3371/04 $ 20.00  2004 IEEE pre></body></html 


                                                  S J       


                                                      


                         L A                                        


          L A  Table 7. Table of Granules at left-hand-side is isomorphic to  at right- hand-side: By Theorem  3.1 one can ?nd patterns in either table as a single generalized concept  Internal points  are:[4]\(1, 1, 0, 0 tions; [5]\(0, 1, 1, 0  0, 1, 0, 1  0, 1, 1, 1  1, 1 1, 0  1, 1, 0, 1  1, 0, 1, 1 11]\(1, 1, 1, 1 form and simplify them into disjoint normal forms 1  T E N    S J    T E N    S J 2  T W E N T Y    L A    T H I R T Y   A 3  T W E N T Y      T H I R T Y   A 4  T W E N T Y            L A 5  T E N      T W E N T Y    L A    T E N    T W E N T Y   A   S J    T W E N T Y   A      T H I R T Y    L A     Y 7  T E N      T W E N T Y      T H I R T Y   L A    T E N   L A    S  J   A 8  T W E N T Y      T E N      T W E N T Y    L A    T E N   T W E N T Y      T H I R T Y 9  T W E N T Y    N Y    T E N    S J    T H I R T Y    L A      T W E N T Y    L A  1 0  T W E N T Y    N Y    T W E N T Y    L A    T H I R T Y   A    J 1 1  T W E N T Y          T W E N T Y    L A   T H I R T Y    L A    a l l If the simpli?ed expression is a single clause \(in the original symbols non-generalized the following associations 1   T E N     S J    T E N    S J  2. SJ   J 4   L A    T W E N T Y    L A    T H I R T Y    6 Conclusions Data, patterns, method of derivations, and useful-ness are key ingredients in AM. In this paper, we formalize the current state of AM: Data are a table of symbols. The patterns are the formulas of input symbols that repeat. The method of derivations is the most conservative and reliable one, namely, mathematical deductions. The results are somewhat surprising 1. Patterns are properties of the isomorphic class, not an individual relation - This implies that the notion of patterns may not mature yet and explains why there are so many extracted association rules 2. Un-interpreted attributes \(features can be enumerated 3. Generalized associations can be found by solving integral linear inequalities. Unfortunately, the number is enormous. This signi?es the current notion of data and patterns \(implied by the algorithms 4. Real world modeling may be needed to create a much more meaningful notion of patterns. In the current state of AM, a pattern is simply a repeated data that may have no real world meaning. So we may need to introduce some semantics into the data model [12],[10],[11 Proceedings of the Fourth IEEE International Conference on Data Mining \(ICDM  04 0-7695-2142-8/04 $ 20.00 IEEE References 1] R. Agrawal, T. Imielinski, and A. Swami  Mining Association Rules Between Sets of Items in Large Databases  in Proceeding of ACM-SIGMOD international Conference on Management of Data, pp. 207216, Washington, DC, June, 1993 


216, Washington, DC, June, 1993 2] Richard A. Brualdi, Introductory Combinatorics, Prentice Hall, 1992 3] A. Barr and E.A. Feigenbaum, The handbook of Arti?cial Intelligence, Willam Kaufmann 1981 4] Margaret H. Dunham, Data Mining Introduction and Advanced Topics Prentice Hall, 2003, ISBN 0-13088892-3 5] Fayad U. M., Piatetsky-Sjapiro, G. Smyth, P. \(1996 From Data Mining to Knowledge Discovery: An overview. In Fayard, Piatetsky-Sjapiro, Smyth, and Uthurusamy eds., Knowledge Discovery in Databases AAAI/MIT Press, 1996 6] H Gracia-Molina, J. Ullman. &amp; J. Windin, J, Database Systems The Complete Book, Prentice Hall, 2002 7] T. T. Lee  Algebraic Theory of Relational Databases  The Bell System Technical Journal Vol 62, No 10, December, 1983, pp.3159-3204 8] T. Y. Lin  Deductive Data Mining: Mathematical Foundation of Database Mining  in: the Proceedings of 9th International Conference, RSFDGrC 2003 Chongqing, China, May 2003, Lecture Notes on Arti?cial Intelligence LNAI 2639, Springer-Verlag, 403-405 9] T. Y. Lin  Attribute \(Feature  The Theory of Attributes from Data Mining Prospect  in: Proceeding of IEEE international Conference on Data Mining, Maebashi, Japan, Dec 9-12, 2002, pp. pp.282-289 10] T. Y. Lin  Data Mining and Machine Oriented Modeling: A Granular Computing Approach  Journal of Applied Intelligence, Kluwer, Vol. 13, No 2, September/October,2000, pp.113-124 11] T. Y. Lin, N. Zhong, J. Duong, S. Ohsuga  Frameworks for Mining Binary Relations in Data  In: Rough sets and Current Trends in Computing, Lecture Notes on Arti?cial Intelligence 1424, A. Skoworn and L Polkowski \(eds 12] E. Louie,T. Y. Lin  Semantics Oriented Association Rules  In: 2002 World Congress of Computational Intelligence, Honolulu, Hawaii, May 12-17, 2002, 956961 \(paper # 5702 13  The Power and Limit of Neural Networks  Proceedings of the 1996 EngineeringSystems Design and Analysis Conference, Montpellier, France, July 1-4, 1996 Vol. 7, 49-53 14] Morel, Jean-Michel and Sergio Solimini, Variational methods in image segmentation : with seven image processing experiments Boston : Birkhuser, 1995 15] H. Liu and H. Motoda  Feature Transformation and Subset Selection  IEEE Intelligent Systems, Vol. 13 No. 2, March/April, pp.26-28 \(1998 16] Z. Pawlak, Rough sets. Theoretical Aspects of Reasoning about Data, Kluwer Academic Publishers, 1991 Proceedings of the Fourth IEEE International Conference on Data Mining \(ICDM  04 0-7695-2142-8/04 $ 20.00 IEEE pre></body></html 


than that of MAFIA and the runtime of MHP can be significantly less than that of MAFIA 5.3. The Effect of the MHP Algorithm on Finding Maximal Hyperclique Patterns Figure 8 and Figure 9 show the number of maximal patterns identi?ed byMHP andMAFIA on Pumsb* and Pumsb data sets respectively. As can be seen, the number of maximal hyperclique patterns identi?ed by MHP can be orders of magnitude smaller than the number of maximal frequent patterns identi?ed by MAFIA. In other words, the number Proceedings of the 16th IEEE International Conference on Tools with Artificial Intelligence \(ICTAI 2004 1082-3409/04 $20.00  2004 IEEE 100 1000 10000 100000 1e+06 1e+07 1e+08 1e+09 0.02 0.025 0.03 0.035 0.04 0.045 0.05 0.055 0.06 N um be r o f C ou nt ed P at te rn s Support Threshold Mafia Min_Conf=0 Min_Conf=0.1 Min_Conf=0.3 Min_Conf=0.5 Min_Conf=0.7 Min_Conf=0.9 Figure 8. The Number of MFI/MHP Patterns in the Pumsb* Data Set 100 1000 10000 100000 1e+06 


1e+07 1e+08 0.1 0.2 0.3 0.4 0.5 0.6 0.7 N um be r o f C ou nt ed P at te rn s Support Threshold Mafia Min_Conf=0.5 Min_Conf=0.7 Min_Conf=0.9 Figure 9. The number of MFI/MHP Patterns in the Pumsb Data Set of maximal hyperclique patterns is much easier to manage than that of maximal frequent patterns. Indeed, in realworld applications, it is dif?cult to interpret several million maximal frequent patterns. However, it is possible to interpret the results of maximal hyperclique pattern mining In addition, due to the memory limitation, we cannot extract maximal frequent patterns with MAFIA on the Pumsb data set if the support threshold is less than 0.4, as shown in Figure 7. In contrast, MHP can identify maximal hyperclique patterns when the support threshold is 0.1, if we set the h-con?dence threshold to 0.5. In other words, MHP has the ability to identify patterns which can be dif?cult to identify for MAFIA. Hence, MHP can better explore the pattern space and ?nd interesting patterns at low levels of support 6. Conclusions and Future Work In this paper, we present a two-phase Maximal Hyperclique Pattern \(MHP best features of both the BFS strategy and the DFS strategy. More speci?cally, we adapted DFS pruning methods such as equivalence pruning, to an apriori-like approach In addition, we proved the correctness and completeness of the MHP algorithm. Finally, our experimental results show that the MHP algorithm can be several orders of magnitude faster than standard maximal frequent pattern mining algorithms and has the ability to identify patterns at extremely low levels of support in dense data sets There are several directions for future work. First, in 


this paper, we only generate the size-2 patterns in the BFS phase. It will be interesting to investigate the impact on the performance if the ?rst phase is stopped at a deeper level Also, the projection is a very ef?cient method for ?nding patterns, especially for parallel implementation of pattern mining algorithms [1]. We plan to adapt the projection ideas into our algorithm and design an ef?cient parallel algorithm for mining maximal hyperclique patterns References 1] R. Agarwal, C. Aggarwal, and V. Prasad. A Tree Projection Algorithm For Generation of Frequent Itemsets. pages 350 371, Feb 2001 2] R. Agrawal, T. Imielinski, and A. Swami. Mining Association Rules between Sets of Items in Large Databases. In Proc. of the ACM SIGMOD Conference on Management of Data, pages 207216,May 1993 3] R. Agrawal and R. Srikant. Fast Algorithms for Mining Association Rules. In Proc. of the 20th Intl Conference on Very LargeData Bases, 1994 4] R. Bayardo. Ef?ciently mining long patterns from databases In Proc. of the ACM SIGMOD Conference, 1998 5] R. Bayardo and R. Agrawal. Mining the Most Interesting Rules. In Proc. of the ACM SIGKDD Conference, 1999 6] D. Burdick, M. Calimlim, and J. Gehrke. Ma?a: AMaximal Frequent Itemset Algorithm for Transactional Databases. In Proc. of IEEE Conf. on Data Engineering, 2001 7] Y. Huang, H. Xiong, W. Wu, and Z. Zhang. A Hybrid Approach for Mining Maximal Hyperclique Patterns. In In Technical Report UTDCS-34-04, Department of computer science, University of Texas - Dallas, 2004 8] J.Han, J.Pei, and Y. Yin. Mining Frequent Patterns without Candidate Generation. In Proc. of the ACM SIGMOD International Conference on Management of Data, 2000 9] M.J.Zaki and C.Hsiao. ChARM: An ef?cient algorithm for closed itemset mining. In Proc. of 2nd SIAM International Conference on Data Mining, 2002 10] R.Rymon. Search through Systematic Set Enumeration. In Proc. Third Intl Conference on Principles of Knowledge Representation and Reasoning, 1992 11] H. Xiong, M. Steinbach, P.-N. Tan, and V. Kumar. HICAP: Hierarchial Clustering with Pattern Preservation. In Proc. of 2004 SIAM International Conference on Data Mining \(SDM 12] H. Xiong, P.-N. Tan, and V. Kumar. Mining Strong Af?nity Association Patterns in Data Set with Skewed Support. In Proc. of the Third IEEE International Conference on Data Mining \(ICDM Proceedings of the 16th IEEE International Conference on Tools with Artificial Intelligence \(ICTAI 2004 1082-3409/04 $20.00  2004 IEEE 





