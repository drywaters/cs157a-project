EDOS Employing Mini-DB for High Semantic Object Store Xudong Tu 002 DanFeng 002 and Zhipeng Tan 002 002 Wuhan National Laboratory for Optoelectronics School of Computer Science and Technology Huazhong University of Science and Technology Email tuxudong@163.com  dfeng,tanzhipeng  hust.edu.cn Abstract Storage management server compatible with decoupled data and meta data fashion is being employed frantically to build large-scale distributed storage system for performance and capacity To design this hot commodity on  exibly managing the extracted data with little meta data but extended attributes has become a big challenge This paper breaks a new way to object orient store and implement the dedicated prototype called EDOS We reexamine several new requirements and prior works and employ Mini-DB as the back-end  like DBFS  to guarantee the scalability and durability for EDOS We design three kinds of object locators and multi-indices to improve retrieval performance and absorb random I/O utilize a swap mechanism between internal and external objects for tunable throughput which nested beneath the generic key-value database schema and bene  ted from memory pool technique The replication component in Mini-DB helps to build the multi nodes in the distributed environment It is easy to build up the object-based distributed  le system by EDOS with ACID transaction semantics and high reliability The experimental results show that our kernel-level implementation of EDOS performed better than the other existences in practice Keywords database object store  le system search I I NTRODUCTION The nowadays distributed st orage systems trend to separate the metadata and data operations by of  oading the data store service from the storage system to obtain a signi  cant positive impact on the scalability in the data path The most immediate effect of this separation is the data store is just responsible for storage management and high I/O throughput while do not need to maintain any  lelevel metadata services Object storage as a representative design in this fashion has many advantages such as security data sharing intelligence etc to be the future architecture for distributed storage system However there are a small body of work on building a dedicated object-based storage manager This paper introduce EDOS a new paradigm for objectbased storage With EDOS the developers can easily build their object-based distributed system in scalable  exible and reliable fashion EDOS prefers to use a database-like storage schema rather than age-old hierarchical structure Our speci  c hypothesis that a database-like infrastructure is more feasible and suitable f or the object-based storage system is motivated by several observations the  rst one is that an object is a logical structured collection of data descriptive attributes and security policies A database-like infrastructure provide a well-de  ned schema that can be used to store the objects as well as re  ect the relationships between these properties  F urthermore each object s e rv er involves tremendous number of objects and organizes them by  at labels instead of directory-oriented abstraction  3 A d atabas e-lik e i nfras t ructure w ith a p o w erful d ataretrieval capability can quickly locate data attributes and any other properties that the objects consists of e.g google bigtable The t hi rd one s i n ce a database-like infrastructure has more knowledge about the data it stores the storage manager can accurately understand the format of objects and thus make more effective optimizing policies to improve the performance of overall system The last observation is that storage manager requires t o maintain the integrity and consistency of the objects A database-like infrastructure can conveniently implement tra nsactional object service to guarantee the reliability A key challenge of building a database-like object storage manager is performance in many aspects The  rst one is derived from the weakness of database it easily suffers the poor throughput The second one since object can sense its internal organization large size object easily incurs extra overhead to seek the speci  c data positions We leverage Hash-table abstraction for st ructured attribute data and Btree for object data respectively In addition we build multiple indices to feasibly locate the relevant elements in an object for example users only need to get the relevant small part of the whole data wh ile transferring and loading entire object may suffer high cost and risk for such big unit II D ISCUSSION M OTIVATION A Object-based characters  Object can be used to store different data structures such as  les database tables medical images or multimedia and their associated attributes 5 6 U n l i k e t radi t i onal c hunk t h at has n o kno w l edge about its  xed size data treated as BLOB 7 8  d ata object is of variable size and can sense its data organization Consequently the object commonly suffers heterogeneous workloads varied from small random access for partial data sections to extremely large sequential access for entire object data Then again the attributes which is regarded as the description of corresponding object characters are 2010 Fifth IEEE International Conference on Networking, Architecture, and Storage 978-0-7695-4134-1/10 $26.00 © 2010 IEEE DOI 10.1109/NAS.2010.35 420 


structured data and mainly accessed by storage or data mining applications B Storage managers  Traditional data management solutions include  le system and full edged database system File system provides high performance but have many disadvantages for achieving better performance and  exibility to build a object-based storage manager these systems must reorganize large number of  at labelled objects as a hierarchical directory for preventing them in a single directory These systems must integrate extra service to coordinate the operations of de pendent attribute and object data Moreover the  le-based design scarcely serve both structured attribute and unstructured object data well as the local storage requirements of them are signi  cant different For example the major access operations on the former are random query insert  while the latter often suffers high I/O streaming access At last an object manager is proposed as a intelligent autonomy unit yet these designs typically treat the attributes as unstructured  le data and thus make it dif  cult to mine and exploit knowledge for supporting decision-making On the other hand database provides a convenient high-level interface and powerful data-retrieval capability but they do not measure up to the performance requirements of large-scale storage application In a nutshell the storage requirements of object-based storage deviate from traditional workloads 9 and t hus either  le system or database management fails to meet these requirements well This observation motivates us make our research  development investments on these requirements and propose EDOS which combines the advantages of these two typical storage abstraction so that it is very compliant with object-based storage system The reminder of this paper is organized as follows In section 3 we describe the general design and characters of EDOS mainly expound the provenance of our idea and in section 4 we describe our measurement methodology and results The relevant research work is presented in Section 5 We suggest some future work and conclude in Section 6 III D ESIGN AND IMPLEMENTATION Fig 1 shows the overview of the prototype architecture about EDOS The Mini-DB holds the internal objects and communicate with the local  le system by the way of swap 10  T he object is acces s e d b y object locator  T o absorb the random I/O attacks the performance and provide a mechanism for ef  ciently maintaining information about storage that can be re-used after the object data contained thereon is no longer needed is the storage usage issue We also leverage the object index to store lists of reusable blocks Speci  cally the object index is used to store both used block entries and reusable block entries 0002\000E\000M\000H\000F\000W\000\003\000/\000R\000F\000D\000W\000R\000U 000V\000Z\000D\000S 000P\000L\000J\000U\000D\000W\000L\000R\000Q 000/\0005\0008 000\(\000[\000W\000H\000U\000Q\000D\000O\000\003\0002\000E\000M\000H\000F\000W 000&\000K\000X\000Q\000N 0002\000E\000M\000H\000F\000W\000\003\000\(\000Q\000W\000U\000 0005\000D\000Q\000G\000R\000P\000\017\000\003\000\003\000S\000D\000U\000W\000L\000D\000O\000\003\000D\000F\000F\000H\000V\000V 0006\000H\000T\000X\000H\000Q\000W\000L\000D\000O\000\003\000,\000\022\0002 0005\000H\000X\000V\000D\000E\000O\000H 000/\000L\000V\000W 000,\000Q\000W\000H\000U\000Q\000D\000O\000\003 0002\000E\000M\000H\000F\000W  000,\000Q\000\003\000P\000H\000P\000R\000U\000\\\000\003\0000\000L\000Q\000L\000\020\000'\000 Figure 1 Architecture of EDOS A Object Store Schema We designed the schema for object store to be simple and relatively general so that similar implementations could be undertaken on top of similar systems We took a chunkbased approach rather than storing each object data as one Binary Large Object BLOB The free-space table freespace.db manages free extents of the partition Initially free space database has one record whose data is just one big extent which means a whole partition When a change in  le size happens this database will update its records Extents table the external object consists of the unique extent which size is not  xed The extents database extents.db maps  le offset to physical blocks address of the extent including the  le data As this database corresponds to each  le its life time is also same with that of a  le The exact database name is identi  ed with an object ID This database  le is only dynamically removable while all other databases are going on with the  le system The Object tables map unique object identi  ers to object data indexed by a balanced tree which may be sorted and it is possible to in  uence data layout policies by modifying the identi  er assignment and sort function We assign the identi  er by the pair of PID,UID PID denotes partition ID UID is the user object ID which is randomly created The actual data associated with the object is also stored in the object tables which have different page size respectively For the given object of variable size the segmentation job from object to several page of unequal different size is running background We  rst sort the tree by the object identi  er and then by the page size This guarantee the pages belong to an object contiguous layout The data store of  les will be called a view The reason not to use search or query but use  lter instead is because 
421 


Database Key Va l u e Index Type Layout Internal Object.db Object Entry Chunk Data B+-Tree Private Partition External Object.db Alias File Descriptor HashTable Decoupled with Internal Table Attribute.db ObjectID,AttrbuteID Attribute Value HashTable Cluster with Internal Object Index.db ID Object Locator HashTable In Memory Free Space.db Free Extent NO Free Space Start Address B+-Tree Boot Partition Log.db Transaction ID Log Content Queue Private Disk Table I Database schema of object store search or query sound too much single shot though the terms are almost analogous It is not that all  les should be stored as one large  le but more that closely related  les should be treated as one unit B Min-DB in Kernel Our Mini-DB integrates transactional hash queue balanced tree to store data following the above hybrid schemas The application native data format is proposed to  t static and predictable object access patterns in our workloads which indicate little relational structure inherently We implement three kinds of object locators to track the Mini-DB in memory disk or both and deliver robust data storage features such as ACID transactions for strong semantic like 11 di rect Mi ni db b as ed reco v e ry  h i g h c oncurrenc y for share-all context and single-master replication for high availability These enable our object store to scale massively with lower latency and more reliable Rather than storing each object as one binary large object BLOB which will damage the performance issue Two different types  internal and external  of objects are de  ned respectively Internal objects are stored in the Mini-DB with copy semantics and participation in the transactional model so that all the properties of Mini-DB objects also pertain to internal objects External obj ects with reference semantics similar to shared  les in a  le system are large extra data stored in operating system  les outside of the Mini-DB In this case all clients effectively perform operations on a single copy of an external object as opposed to being supplied their own separate copies as the internal To client’s perspective whether a particular object is stored inside or outside the Mini-DB is largely transparent For higher performance we hand-tailor and port Berkeley DB running in kernel model called Kernel BDB Subsystem\(KBDBS with the advantage of minimizing data copies and context switches To address the non-trivial problem we use kernel functions instead of system calls to handle shared memory and ensure coherency  rstly Shared memory had to be carefully reexamined in the context of the kernel address space the only one address space Secondly KBDBS requires some form of self-blocking mutual exclusion Thirdly we make efforts involved in porting to kernel  test bed platform  which is chosen as our experimental OSD platform At last wrapper functions for routines like operation on above schemas and integrity ensuring with concurrent accesses to the Mini-DB by more than one process or kernel thread are isolate with other OS code C Extensible Hash for Attributes Most attributes tend to follow a write-once read-many paradigm and are relatively  xed in size structured and are used more or less for the duration of the transaction So the workload is characterized as small request and intensive random I/O and differs from objects To address the assumptions we elaborate the extensible hash storage schema to support unconstrained size of attribute value fast look-up and in-place overwrite and small space overhead However hashing is intuitively simple as long as you  nd a good hash function while hashing is a trade of speed and space i.e Using more space to speed up searching Dynamic hashing is to solve this space problem do not allocate huge space for small number of data Instead the space is allocate when needed We keep a hash array in your main memory and the array stores the pointers to bucket in disk where your data is stored in those buckets We de  ne two types of length bench when the bucket is full but the local depth is smaller than global depth Split bucket and re-distribute old records into two bucket then re-try inserting To protect against corruption due to potentially simultaneous access by multiple processes all accesses to an attribute setting retrieving or enumerating are wrapped with  ock system calls In our system we adopt this extensible hash table in mini-db for attribute storage Other implementation includes liner table and B-Tree to address this problem Liner table is inef  cient and does not scale well to large numbers of attributes specially in retrieval B-Tree undertakes more overhead than extensible for most attributes of the  xed size D Object Locators To address the security and performance for object store the data structure of locator is used to indicate to which area the corresponding object belongs and it is stored within the cell of table rather than the e xternal because transaction routines can be used on it The security rules used to govern access to the locators of the objects just as the real data but with different storage schema and decoupled data path In 
422 


addition three types of locators are proposed respectively by durable and enable-trigger characters and stored as arrays of static length of values so that they can be sent back and forth between the clients and the server in the platformindependent model Next we will introduce the design of the tree kinds of locators in detail NEME ODLIO IMLIO LEO length 002 002 002 version 002 002 002  ag 002 002 002 byte wd 002 002 002 object id 002 002 002 object num 002 002  le id 002 Table II Three kinds of Locators Tab II shows the three kinds locators in our system In locator for internal objects on disk ODLIO  the length  eld has a  xed value for internal objects the version value is incremented when updating the locator  ag  eld indicates objects state such as NULL or initialized and object id as the key to index columns that contain objects The inmemory locator  IMLIO  generated in dynamic memory for an object contains all of the  elds of ODLIO except the additional object-number  eld indicating the size of the chunk the object was divided Lastly both on-disk and inmemory locators for external objects  LEO  incrementally include   leid  eld which stores an unique identi  er supplied by the operating system how the  le is opened In general the design of the locators help servers not maintain state information to indicate which locators have been supplied to each client by the dynamic versions The privilege check is performed and results of the privilege check are buffered for the  rst access time since an object that has been accessed once is much more likely to be accessed again Consequently the amount of server-side resources consumed by locators is reduced particularly when clients perform operations on a relatively small percentage of the objects The operation on external objects depends on the fd  le operation handler which indicates where the external object resides and is kept by KBDBS by the mapping table of alias-to-fd Once the client has received the external object locators the server retrieves th e fd-alias from the locator and inspects the alias-to-fd mapping to determine the relevant  le containing the external object With the  le descriptor the server can access the external object through the operating system simply E Multi-Indices for objects A storage object is a logical collection of bytes of variable size and can be used to store entire data structures such as  les database tables medical images or multimedia Storing such kind of data as BLOB affects the performance To address this problem we employ multi-indices as wellknown methods to absorb more random object I/O In simple case by using secondary index include one entry in the form objectid addr for each object in the column the table scan could be avoided by directly traversing the index to locate the entry with objectid and then following the addr pointer in that index entry to the beginning of the data for object Unfortunately a traditional index could  nd the start address quickly though the act of scanning from the beginning of the object data to the speci  ed starting position is inef  cient and time consuming even if accesses a little portion of large data So the combination of the objectid and a pointer number is used to generate the key of the index entry since the index is allowed to store index entries for any given object across more than one leaf node of the object indices Instead of storing the  rst entry in the index itself the  rst entry contains up to N pointers to indicate the location of the  rst N chunks of object data where N is determined by the maximum size of the entri es This scheme will increases ef  ciency both in the common case that an object is accessed at near the beginning of the object data and other parts of the data which denotes the hot one Some control information in the  rst index entry such as the current version and total size of an object avoids accessing the object index Both object data and the  rst index entry for a object is optionally stored in the table with the locators To avoid the time and space overhead associated with manipulating object chunks attached with holes within index when object is copied or otherwise manipulated we only performed on object chunks identi  ed by non-null pointers F Space Allocation Objects that fall below a certain size threshold are stored within Mini-DB conversely split into external objects stored outsides According to incremental or decremental object update this procedure is dynamical adjustment by objects migration and chunks swapping The  chunk size  is speci ed for an object column and indicates the unit of directly accessible portions  object chunks  of the object data In KBDBS the unit of locking operation is object chunk so bigger chunk size harm concurrency because less data is unavailable to other users when the chunk is locked The KBDBS employs disk devices to be allocated for database usage and speci  es the individual chunk size for each table respectively And the disk blocks within each chunk are contiguous the chunk blocks belong to any given object do not have to be contiguous The free space table ensure that they are initially contiguous by two type sorted indices free extents size ASC and chunk number DESC respectively The indices could guarantee quick time to  nd the suitable free extent for new allocation and the more higher cluster ratio between usable chunks 
423 


The pre-allocation used to leave a portion of tables pace or index empty and available to store newly added data and ensuring a proper amount of free space for KBDBS provides the several bene  ts Incremental updates are faster when free space is available and properly clustered Variablelength and altered objects have room to expand potentially reducing the number of relocated objects More object data on physically continuous chunks do a favour in read-ahead operations with optimal performance for the majority of queries access data randomly G Consistency In semantic storage systems it is important to be able to supply data items as they existed at a particular point in time Our system employed the version-based consistency policy to guarantee the client be able to obtain the non-current state object in speci  ed time To address   ne-grained consistency for concurrent access by multiple versions of internal objects which denote the hot data with requirement of transaction scenarios we supply the particular snapshot rules to ensure only the appropriate visioned object sent to the client For example the version  eld of each inmemory locator indicates the snapshot being used by the client that requested the object locator it allows the client to operate on a separate copy of the object that was made at the snapshot time Specially when performing any modi  cations on portion of data the client locks the associated row to prevent other clients from updating to the object before its modi  cation commits meanwhile only the locator used to perform an modi  cation is updated with the new snapshot identi  er Object versioning is performed by making a copy of a chunk of object data before it is modi  ed subsequent operations that access that object chunk through the current version of the object index will be directed to the most recently modi  ed version of that object chunk Besides we specify an attribute  PCTVERSION  derived from database which determines the percent of all maximum quantity used object data space that can be occupied by old versions of object data chunks As soon as old versions of object data chunks start to occupy more than the PCTVERSION amount of used object space the server tries to reclaim and reuse the storage containing old versions of object data chunks Thus the server must keep track of which blocks are reusable IV P ERFORMANCE OF THE EDOS P ROTOTYPE To compare with some general-purpose  le sytems we want to have the insight on the difference between traditional  le system and object store Besides Ext3 is used by Lustre for object based storage and has the same disk layout as Ext2 but adds a journal for reliability XFS JFS and ReiserFS are modern  le systems with high-performance by using B-trees and extent-based allocation techniques EDOS also need to be compared with the prior objectbased storage techniques such as EOBFS and OSDFS We de  ne EOBFS as such kind of object store that use B+tree to index and variable size of extents to allocation like the OBFS w hi ch i s t h e s t o rage manager i n C eph[12  OSDFS denotes the concept of simulator for object store in which the object is a logical collection of several  les supported by the native  le systems so that the main job for OSDFS is to maintain the mapping between objects and  les In order to allow for a fair comparison the two method are implemented in kernel model as EDOS Then for attribute storage we compared our dynamic hash method to linear table and B-Tree method the evaluation metrics includes the retrieval update response time and space utility cost A Experimental Setup A Test bed  Our EDOS ran on embedded devices reference to Intel IOP348 I/O Processors platform with 2GB memory and eight Seagate ST3160815AS Ultra320 SCSI disks of 160GB in size and con  gured as RAID0 They ran the Linux operating system of a patched 2.6.18 kernel version Network Interface is Intel Pro PCI-X Gigabit Ethernet NIC Our Client acted as the common PC machines the performance parameter as follows B Benchmark Workload  The workload presented to the object store is quite different from that of general-purpose  le systems even the standard and private benchmark for object store is hard to be available To solve this problem synthetic workloads composed of create/write read and delete operations in ratios learnt from the workload model of large scale distributed  le systems These allowed us to examine the performance of the object store on the expected workload The distributed  le system workloads are inherently dynamic with signi  cant variation in data and metadata access as active applications and data sets change over time as our target workload So we choose LLNL 1 trace to synthesis workloads as our benchmark workload for the comparable test The LLNL trace we download indicates that  le size scales up from 0B to 2GB the total number of  les reach 900 million and they are 33TB space in which dominated  les distributed between 512KB 16MB even accurately two thirds of all between 2MB and 8MB The disk space mainly dominated by  les of the size from 2MB to 1GB As the statistics table III shows benchmark I is a readintensive workload in which reads account for 70 of all requests and the total size of the read requests is around 22.6GB The writes and deletes account for 15.6 and 14.4 of the requests Contrarily benchmark II is likely the somewhat write-intensive workload reads account for 29 of the requests and writes and deletes account for 36.2 and 34.8 1 Lawrence Livermore National Laboratory site https://www.llnl.gov 
424 


 0  10  20  30  40  50  60  70 Total-Throughput Read-Throughput Write-Throughput Throughput \(MB/s a EDOS EBOFS OSDFS XFS JFS ReiserFS EXT3 EXT2  0  10  20  30  40  50  60 Total-Throughput Read-Throughput Write-Throughput Throughput \(MB/s b EDOS EBOFS OSDFS XFS JFS ReiserFS EXT3 EXT2  0.1  10  100  1000 1 2 5 10 20 25 30 40 50 Elapsed time \(millisecond of Attributes c B+-Tree-write B+-Tree-read  Linear-write  Linear-read  ex-Hash-write  ex-Hash-read   25  30  35  40  45  50  55  60  65  70 0 1 2 3 4 5 6 7 8 9 10 Average Throughput \(MB/S OPT# \(10^4 d g EDOS EBOFS  OSDFS  XFS  JFS  ReiserFS  EXT3   Figure 2 EDOS performance using the two benchmarks Operation Benchmark I Benchmark II Object Bytes Object Bytes Read 71038 22.6G 29613 9.6G Create/Write 15790 5.1G 36826 11.5G Delete 14240 4.6G 35297 11G Sum 101068 32.3G 101736 32.1G  Table III T RACE D ISTRIBUTION B Read/Write Test We take several groups of test to evaluate the average performance of EDOS on the above benchmarks The main type data type in object store are objects and attributes so the evaluation focuses on object and attributes separately Considering the long-term operation on  le system the performance may decline for the fragment thus we also adopt long-time span and operation intensive trace to compare our phototype with other solutions 1 For Objects  Figure 2\(a shows that average throughput of object operations on Benchmark I and  gure 2\(b denotes the test on Benchmark II As we can see the storage systems adopt the variable size allocation beats a lot with what based on  xed size allocation such as Ext2/3 It is the nearly the same r ead performance between EBOFS XFS and JFS because th ey are employ the similar index and allocation method EBOFS write perform better than the two because it segment the partition into several independent regions building multiple B+-trees associated with these areas Besides the adaptive granularity of allocation leads a better write performance The underlying  le system backing end for OSDFS is XFS in our testing so it is performance dependent on the native  le system but the one more catching layer helps to performance a little improvement EDOS exhibits the best read performance almost more than 10 better than EBOFS because the multiple indices and the locators to make it more sensitive to its data and no need to maintain the directory-based hierarchy which cause the loss of performance For example Ext2/3 use linear table to organize directory structure 2 For Attributes  The test measured the time required to write several string-valued attributes in succession followed by the time to read all of the attributes written  in which each string-valued attribute was given a random string varying uniformly in size between 1 and 1024 bytes Although we anticipate the common scenario to associate more than ten attributes with an object we repeated this test for attribute counts of up to 2000 attributes per object to stress the scalability of the linear design The result was shown in  gure 2\(c and tells us the comparing cumulative attributes reading and writing times for three kinds method to store attributes Linear table has lower disk space and access time costs compared to the B+Tree indexing table in KBDBS however the overhead of extensible hash table is the fewest Because the nature of balance of B-Tree make extra cost when reorganization and an average space inef  ciency make B-Tree the worst per 
425 


 0  100  200  300  400  500 1 2 4 8 16 Throughput \(MB/s Number of I/O threads Random Read Performance Under Different Backend Rawdisk EXT2  EXT3  XFS   150  200  250  300  350 1 2 4 8 16 Throughput \(MB/s Number of I/O threads Sequential Read Performance Under Different Backend Rawdisk EXT2  EXT3  XFS   100  1000  10000 1 2 4 8 16 Maximum Latency Time\(ms Number of I/O threads Maxmum Latency Time Under Different Backend RAWDISK EXT2  EXT3  XFS   0  2  4  6  8  10  12 1 2 4 8 16 Throughput \(MB/s Number of I/O threads Random Write Performance Under Different Backend Rawdisk EXT2  EXT3  XFS   0  5  10  15  20 1 2 4 8 16 Throughput \(MB/s Number of I/O threads Sequential Write Performance Under Different Backend Rawdisk EXT2  EXT3  XFS   0.2  0.4  0.6  0.8  1  1.2  1.4  1.6  1.8 1 2 4 8 16 Average Latency Time\(ms Number of I/O threads Average Latency Time Under Different Backend RAWDISK EXT2  EXT3  XFS  Figure 3 Performance of different storage back-end for EDOS formance Our extensible hash operates several times faster than linear table because of its weak retrieval capability 3 Hybrid Stress Testing  Lastly we compared these  le system performance with several solution on object store including EDOS on the long term span and veri  ed the durable performance since durability and slow degradation is the key to build powerful service Based on the Benchmark II in table III we enlarged the trace samples to long term emulation Figure 2\(d shows that the average throughput of each solution degrades by the escaped time EXT2/3 adopt the allocation with  xed length which are more sensitive to the space continuity and degrades more obviously than other does The Reusable blocks and the swap mechanism make it resilient to space management EDOS realized allocation with variable size by the attribute  PCTVERSION  C Storage Back-end There will have several problems with respect to whether using a raw disk directly or native storage abstraction To verify this impact on pe rformance  we replace the underlying  open   read   write and lseek  interface calls to work on a raw partition for raw disk I/O emulation We leverage Tiobench 2  a portable threaded  le system benchmark program supporting pthreads  to test the concurrency I/O performance for the various back-end storage media Before testing a object-based  le system client needs to be created which kept to the VFS-style architecture and was used to wrap the local  le operations by OSD protocol Each thread running on the client then creates a  le to measure read and write operations across the network Figure 3 shows the average read and write throughput at sequential or random offsets inside of  les and raw block devices as well as average and maximum access latencies 2 http://sourceforge.net/projects/tiobench The result in  gure 3 shows that EXT2 is the best performing Linux  le system for transaction process applications but it may lead to data corruption because EXT2 lacks ordered data mode For that reason we recommend using EXT3 as it both performs well and supports ordered data mode The measurement was performed for XFS as well it has problems with applications which repeatedly extend  les and that is a common usage pattern in KBDBS D Chunk size In KBDBS the different tables could be assigned page size\(for objects we call it chunk size It is the basic access unit and decides the granularity of concurrency since the bigger chunk size the fewer chunks in which the more data will be locked However space allocator guarantee the continuity inside the chunk so that big chunk leads to high throughput usually Some evidences can be found in  gure 4 To access small chunk is possible to create more random I/O which dose harm to the performance a lot However when chunk size up to 2MB it is not so much enhancement 16MB is the preference choice for our testing workload and up to the threshold the throughput starts to drop down Intuitively the performance will be dominated by how long it takes to get the data to or from the disks Given the request unit the small disk I/O will be easy to be accomplished with more request circle the large chunk will mean that most I/Os get serviced by a single disk I/Os However We leverage the KBDB’s own strategies to gather I/Os to minimize I/O overhead In that case we need to know what the database is actually doing to choose the right chunk size E Cost of Operation Replication The prototype uses a replication degree of one and strict replication the cost of replication is expressed by the cost of transporting the operation to replicate to the succeeding 
426 


 0  10  20  30  40  50  60 0 1 2 4 8 16 32 64 128 256 512 1024 2048 4096 8192 16384 32768 65536 Average Throughput \(MB/S MINI-DB Chunk Size \( x 1KB 0 0.5 1 2 4 6 8 14 22 32 42 48 53.5 55 56 57.5 56 52 Figure 4 Chunk size in MINI-DB impact the performance Replication Average response time Comparison Disabled 10.7 ms 100 Enabled 21.2 ms 198 Table IV Replication of EDOS node and the time it takes the s ucceeding node to execute the operation and reply.In addition replication comes with the cost of using extra storage In our prototype there are two copies of each record the primary and the replica The actual cost of replication compared to the time it takes to execute on the primary node can be greatly affected by two factors 1 work load on the succeeding node 2 network latency/bandwidth according to the size of operation data If the network latency between the primary and replica node is on the order of hundred s of milliseconds or even seconds the cost of replication is very high An application deployed on the Internet would have to relax the response time bounds The network latency between the nodes in our test system is in the range 0.1 0.3 milliseconds shared with each host of the same performance Test results for two equal test runs are show in Table IV below where replication was disabled in the  rst run and enabled in the second 100000 put-operations were executed for each run The size of the successor list was set to two As can be seen we experienced nearly a twofold increase in response times when replication was enabled This seems reasonable as the request must be carried out at two nodes instead of one The extra usage of CPU resources related to the replication should be low as the prototype simply sends the request to the succeeding node executes the operation locally and then fetches the r esult from the succeeding node V R ELATED W ORK Database File Systems  Before Gnome Storage WinFS and now Apple Spotlight IBM’s AS/400 is based on an object-oriented database  lesystem which is implemented at the  rmware level rather than at the OS-level The PICK OS was an even earlier example of a database  lesystem it has an SQL-like language to query databases and create reports KBDBFS and I3FS of FSL lab employed in-kernel database to support extra characters wrapped standard  le system operations the useful extensions include extended attributes ACLs a new operation to retrieve  le integrity checker and intrusion detection  le system 13   14  15    16  DB F S is a block-structured embeddable  le system developed on top of the Berkeley DB BDB with an interface largely consistent with the normal POSIX  le system interface by FUSE.The Mac has used a database to store  les and their attendant meta-data since HFS was introduced It uses Btrees idea of having a resource fork to all  les a little name badge for every  le that tells type information Contrary to HFS BeOS 17 al l o w s for c reat i o n o f your o w n obj ect s and in the  le system Close but replace   lename with attributes Besides some  le systems are built on the top of very famous open source database such as PqsqlFS from inverted  le system mysqlFS and tabFS uses SQLlite as its storage end Object-based File System  With the advent of OSD Object Storage Device 18  IBM released OSDFS 19 it is an extension to Ext2 that works with an OSD The Panfs integrates an object-bas ed clustered architecture to orchestrate  le activity across the Storage Cluster and manage system performance Solaris OSD Project consists of the Solaris SCSA-compliant device drivers and related software to provide both initiator and target support for storage devices that adhere to the OSD protocol Intel’s Open Storage Toolkit contains reference implementations of OSD and comes up with whole suite containing OSDFS OSD initiator OSD Target simulator which DISC-OSD suite was built based on PDL has a OSD implementation of its own called the ursa minor They are integrating it with their pnfs implementation Ceph 12  i s a di s t ri b u t e d  le system for petabyte scale  les in which intelligent OSDs manage data replication failure detection and data migration during failure recovery or system expansion VI C ONCLUSION AND F UTURE WORK With the rethinking of object-b ased characters and storage managers technique clues the novel search based architecture for object store EDOS has been analyzed and proposed which employs a stable Mini-DB core supporting transaction and replication The EDOS makes it easy to ensure the reliability and extensibility for object store and innovative features can be rapidly prototyped and stronger storage semantics can be explored Our experiments veri  ed our hypothesis on the issue The competition for iSCSI is Object-based storage This competition will become more intense in the near future with the advent of the high performance interconnection and transport technique such as Remote Direct Memory 
427 


Access\(RDMA 20 W e will tar g et th e n e w co n d itio n t o rethink the storage management again A CKNOWLEDGMENT This work is supported by the National Basic Research 973 Program of China under Grant No 2004CB318201 863 project 2008AA01A402 Changjiang innovative group of Education of China No IRT0725 National Universitys Special Resarch Fee\(C2009m052 R EFERENCES 1 S  A bi t e boul  S  C l u et  a nd T  Mi l o   A d at abase i nt er f a ce for  le update in SIGMOD 95 Proceedings of the 1995 ACM SIGMOD international conference on Management of data  vol 24 no 2 New York NY USA ACM Press May 1995 pp 386–397 Onlin  A v a i l a bl e ht t p  dx.doi.org/10.1145/223784.223854  F  W ang S  A Br  E  L  M iller  and D  D  E  L ong Obfs A  le system for object-based storage devices in FA S T 03 The 2003 Conference on File and Storage Technologies FAST  IEEE 2003 pp 283–300 3 B  W el ch M  U nangst  Z  A bbasi  G  G i b son B  Muel l e r  J Small J Zelenka and B Zhou Scalable performance of the panasas parallel  le system in FAST’08 Proceedings of the 6th USENIX Conference on File and Storage Technologies  Berkeley CA USA USENIX Association 2008 pp 1–17 A v a ilable http://portal acm o r g  citation.cfm?id=1364815 4 F  C hang J D ean S  G hema w a t  W  C  H s i e h D  A  Wallach,M.Burrows,T.Chandra,A.Fikes,andR.E Gruber Bigtable A distributed storage system for structured data in OSDI’06 Seventh Symposium on Operating System Design and Implementation  Seattle WA USA November 2006 pp 205–218 Onlin  A v a i l a bl e ht t p  www.usenix.org/events/osdi06/tech/chang.html  K i r an D  A  H ol l a nd U Braun and M  S el t zer   P r o v e nanceaware storage systems in ATEC 06 Proceedings of the annual conference on USENIX 06 Annual Technical Conference  Berkeley CA USA USENIX Association 2006 p 4 A v a ilable h ttp://portal.acm.org/citation cfm?id=1267359.1267363 6 M  M esni er  E  T her e ska G  R  G a nger  D  E l l a r d  and M Seltzer File classi  cation in self storage systems 2004 pp 44–51 Onlin  A v a i l a bl e ht t p  ieeexplore.ieee.org/xpls/abs  all.jsp?arnumber=1301346 7 R  S ear s C  v a n I ngen and J  G r a y  T o b l o b o r not t o bl ob Large object storage in a database or a  lesystem 8 A  B iliris  An e f  cient database storage structure for large dynamic objects in In Proceedings of the International Conference on Data Engineering  1992 pp 301–308 9 A  T r a e g er  E  Z adok N  Jouk o v  a nd C  P  W r i ght   A nine year study of  le system and storage benchmarking in FAST 08 Proceedings of the 7th USENIX Conference on File and Storage Technologies  vol 4 no 2 New York NY USA ACM 2008 pp 1–56 Onlin  A v a i l a bl e http://dx.doi.org/10.1145/1367829.1367831  John R  A  T h ekkat h  a nd L  Z hou B oxw ood A b st r act i o ns as the foundation for storage infrastructure in OSDI 04 Proceedings of the 5th symposium on Operating systems design and implementation  pp 105–120 Onlin  A v a i l a bl e http://www.usenix.org/events/osdi04/tech/maccormick.html  D  K  G i f f or d P  Jouv el ot  M  A  S hel don and J  W  O  T ool e  Semantic  le systems in Proceedings of 13th ACM Symposium on Operating Systems Principles  Association for Computing Machinery SIGOPS 1991 pp 16–25 Onlin  Available http://citeseer.ist.p su.edu/gifford91semantic.html  S  A W e il S  A Brandt E  L  M iller  D D E  L ong and C Maltzahn Ceph a scalable high-performance distributed  le system in OSDI 06 Proceedings of the 7th symposium on Operating systems design and implementation  Berkeley CA USA USENIX Association 2006 pp 307 320 A v a ilable http portal.acm.org/citation.cfm id=1298455.1298485  C P  W r ight R  S pillane  G Sivathanu and E Zadok Extending acid semantics to the  le system vol 3 no 2 New York NY USA ACM Press June 2007 Onlin  Available http://dx.doi.org/10.1145/1242520.1242521  A Kashyap S  P a til G S i v a thanu and E Zadok I3FS An In-Kernel Integrity Checker and Intrusion Detection File System in Proceedings of the 18th USENIX Large Installation System Administration Conference LISA 2004  Atlanta GA USENIX Association November 2004 pp 69–79  M A  O l son T he desi gn and i mpl e ment at i o n o f t he i n v e r s i o n  le system in In Proceedings of the Winter 1993 USENIX Technical Conference  San Diego CA USENIX 1993 pp 205–218 16 A Ka sh y a p   F ile Sy ste m Ex te n s ib ility a n d R e lia b ility U sing an in-Kernel Database Master’s thesis Stony Brook University December 2004 technical Report FSL-04-06 www.fsl.cs.sunysb.edu/docs/kbdbfs-msthesis/kbdbfs.pdf  D  G i ampaol o Practical File System Design with the Be File System  Morgan Kaufmann Publishers January 1999 Onlin  A v a i l a bl e ht t p    w w w  a mazon ca e x ec obi dos redirect?tag=citeulike09-20  amp;path=ASIN/1558604979  M Fact or  K  M et h D  N a or  O  R odeh and J  S at r a n O bj ect storage the future building block for storage systems Local to Global Data Inter operability C hallenges and Technologies 2005  pp 119–123 20-24 June 2005 Onlin  Available http://dx.doi.org/10.1109/LGDI.2005.1612479  M Mesni e r  G R Ganger  and E  R i e del  Obj ect based storage in Communications Magazine IEEE  vol 41 no 8 2003 pp 84–90 A v a ilabl e http://dx.doi.org/10 1109/MCOM.2003.1222722  M Chadal apaka H S h ah U  E l z ur  P  T hal e r  and M Ko A study of iscsi extensions for rdma iser in NICELI 03 Proceedings of the ACM SIGCOMM workshop on Network-I/O convergence NewYork,NY USA ACM Press 2003 pp 209–219 Onlin  A v a i l a bl e http://dx.doi.org/10.1145/944747.944754 
428 


IMPROVEMENTS ARE SHOWN Matrix Nc Benchmark IrregRed SpMV Avg. Max Min Avg. Max Min s3dkq4m2 2 -6,9 -5,6 -7,4 4,2 4,4 4,04 -4,5 -0,6 -6,5 0,8 3,0 -0,2 8 -2,0 3,0 -3,0 2,0 6,3 -1,9 3dtube 2 -2,5 -0,8 -3,9 5,3 5,7 5,14 4,4 8,1 1,9 -3,2 -0,9 -4,7 8 2,2 18,3 -2,7 2,4 8,0 -1,7 nasasrb 2 -3,7 -0,2 -5,1 3,0 4,1 2,64 -2,3 2,7 -3,3 -2,5 0,4 -5,0 8 -0,1 12,1 -1,9 6,8 12,6 2,5 struct3 2 1,1 3,9 0,3 -3,6 -1,0 -5,64 0,1 4,3 -0,4 -1,2 3,4 -3,1 8 0,2 6,5 -1,5 3,0 7,3 0,6 bcsstk29 2 0,1 2,1 -0,3 -2,2 1,0 -2,94 -0,1 5,2 -1,0 0,6 3,0 -0,1 8 0,7 11,1 -2,7 -1,4 3,5 -2,6 bcsstk17 2 -0,1 2,9 -0,4 0,9 4,1 0,54 0,5 12,6 -1,4 0,6 3,6 0 8 1,4 20,4 -3,6 -0,6 5,0 -1,8 IARD, where there are no dependencies between threads, the outcomes in Table VIII show that all differences are below 6%, except for some cases in the biggest matrices: nasasrb SpMV, 8 threads IrregRed, 2 threads In general, especially for small matrices, our distribution performs better than the automatic one C. Influence of Cache Coherency Taking into account that this kind of irregular codes strives to maximise the thread locality, we do not expect to notice important performance decreases due to the cache coherency protocols when the input matrices are big enough, since they will be masked by the traffic in the bus. If the matrices fit in each core  s cache, all misses, except the capacity ones, will be solved by the snooping protocol inside the bus, faster than 152 asking the directory. However, this will not usually be the case in real applications, because this type of codes usually operates with matrices far bigger than the cache size VI. CONCLUSIONS This paper presented the results of several tests carried out to characterise FINISTERRAE, an SMP-NUMA machine, in order to study the suitability of applying strategies to parallelise irregular codes initially developed for SMP systems The main factors considered were the thread-to-core distribution and the memory allocation. Firstly, a benchmark was executed to test the performance influence of several cores when sharing a bus and allocating the data in local or remote memory. Secondly, another benchmark was used to evaluate the influence of the cache coherency between two cores when sharing data. Furthermore, another test evaluated the memory access latency depending on the memory module allocated \(local, remote or interleaving At the sight of the results, we can claim that, especially for applications which use the bus intensively, the effect of sharing a bus between two or more cores degrades the performance and should be avoided by spreading the threads among cores in different buses when possible. We must take into account, though, that the test to evaluate the local and remote memory access latencies yielded important differences between them. Therefore, in cases where the threads must be spread in two cells the best policy will be to analyse and split the data in both memory zones, maximising the locality or, when not possible, allocating the data in the interleaving zone Regarding the cache coherency, the effects in the performance are noticeable when dealing with small sizes of data which fit into caches. The more the memory size increases the less significant the effect is. Therefore, for small data sizes, it would be advisable to map the threads on cores in the same bus. For bigger data sizes, the effect of sharing a bus will be more important and it will mask the effect of cache coherency. A noteworthy fact is that every core in the same processor behaves as an independent processor, so we can consider two processors in a bus as four independent 


can consider two processors in a bus as four independent cores After the benchmarking stage, an actual strategy to parallelise irregular codes, successfully tested on SMP architectures, was ported to FINISTERRAE. A set of matrices was chosen and reordered with this strategy, being applied subsequently to the sparse matrix-vector product and the Irregular Reduction benchmarks. Since this code works with sparse data, the effects regarding bus sharing were not as noticeable as in the previous stage. However, it was possible to confirm the importance of spreading the threads among cores in different buses when dealing with big data sizes the behaviour of each core as an independent processor, and the fact that the coherency effects are masked by the bus sharing when increasing the data size As a future work, we intend to develop strategies to guide applications at run-time in the frame of our project, so the conclusions presented here will help to define a thread-tocore mapping and memory allocation policies ACKNOWLEDGEMENTS This work was supported by the MCyT of Spain through the TIN2007-67537-C03-01 project and by the 2008/CE377 contract among HP, CESGA, UDC and USC REFERENCES 1] L. Rauchwerger, N. M. Amato, and D. A. Padua  Run-time methods for parallelizing partially parallel loops  in Proc. of the Int. Conf. on Supercomputing. ACM press, 1995, pp 137  146 2] R. Eigenmann, J. Hoeflinger, and D. Padua  On the automatic parallelization of the perfect benchmarks  IEEE Trans Parallel Distrib. Syst., vol. 9, no. 1, pp. 5  23, 1998 3] E. Gutie  rrez, O. Plata, and E. L. Zapata  A compiler method for the parallel execution of irregular reductions in scalable shared memory multiprocessors  in Proc. of the Int. Conf on Supercomputing, ACM SIGARCH. Springer-Verlag, May 2000, pp. 78  87 4] Galicia Supercomputing Centre, http://www.cesga.es 5] J. W. Tobias Klug, Michael Ott and C. Trinitis  Autopin - automated optimization of thread-to-core pinning on multicore systems  in Transactions on HiPEAC, vol. 3, no. 4, 2008 6] S. Williams, L. Oliker, R. Vuduc, J. Shalf, K. Yelick, and J. Demmel  Optimization of sparse matrix-vector multiplication on emerging multicore platforms  in SC  07: Proc. of the 2007 ACM/IEEE Conf. on Supercomputing. New York NY, USA: ACM, 2007, pp. 1  12 7] M. Norde  n, H. Lo  f, J. Rantakokko, and S. Holmgren  Dynamic data migration for structured amr solvers  International Journal of Parallel Programming, vol. 35, no. 5, pp 477  491, 2007 8] Performance Application Programming Interface http://icl.cs.utk.edu/papi 9] S. Eranian, The perfmon2 Interface Specification. Technical Report HPL-2004-200R1. HP Labs, February 2005 10] Perfmon2 monitoring interface and Pfmon monitoring tool http://perfmon2.sourceforge.net 11] HP Integrity rx7640 Server Quick Specs, http://h18000 www1.hp.com/products/quickspecs/12470 div/12470 div.pdf 12] D.E.Singh, M.J.Martin, and F.F.Rivera  A run-time framework for parallelizing loops with irregular accesses  in Proc Seventh Workshop Languages, Compilers, and Run-Time Systems for Scalable Computers, Washington DC, USA, 2002 13] The Harwell-Boeing Sparse Matrix Collection http://math.nist.gov/MatrixMarket/collections/hb.html 153 pre></body></html 


also be used to define constraints for service selection At run-time, the workflow engine for XML nets interprets and evaluates Filter Schemas and transition inscriptions to filter and create Web service descriptions as XML documents. With process monitoring and administration tools which are usual components of workflow management systems, new criterions and constraints for WS discovery and selection can be incorporated at run-time by reconfiguring transition inscription statements and variable instantiations in Filter Schemas  Instantiating abstract WS transition Figure 4 shows a fragment of the abstract WSC process in Section 5.1 to demonstrate the ability of XML nets in WS discovery. To obtain transport information, Web services whose descriptions are stored in an unknown WSDL repository should be discovered The token count of the place representing the repository is supposed to be unlimited. The abstract transitions find transport info service? and ?get transport information? are used to bind and call Web services at runtime. The incoming arc of the transition ?find transport info service? is a reading connection \(represented by a dashed arc nipulative Filter Schema FS2 used to create Web service descriptions is assigned to the outgoing arc of this transition. FS1 and FS2 are both generated according to WSDL Schema  Adapting abstract WS transition at run-time Suppose that the transition ?get transport information? is used to acquire flight information. Variables in FS1 should be \(partly  3 http://www.w3.org/TR/wsdl#A4.1 4 http://uddi.org/schema/uddi_v3.xsd es supplying flight information. As shown in Figure 5a the variable of the attribute filter ?name? of the element filter ?service? is instantiated with a regular expression for filtering Web services whose name contains the string ?flight?. This regular expression, together with the Filter Schema, is parsed to XQuery/XPath statements in process simulation or execution. If we use a reconfiguration tool to modify the regular expression at run-time as shown for example in Figure 5b, the transition ?get transport information? can then be adapted to acquire other transport information, e.g., train information. After a suitable WSDL document has been found, FS2 is used to create a new WSDL document for the place ?WS description by cloning the discovered document. Figure 5c shows the diagram of FS2 containing the WSDL root element definitions? and an element placeholder, which is used because the internal structure and details of the document to be created are not of interest in the case of document duplication  QoS-aware WS selection XML nets can also be used to select desired Web services if service constraints like QoS or customized preferences are taken into consideration. As WSDL and OWL-S provide no or limited ways for describing Web service?s QoS, we use in this paper OWL-QoS 43], which complements OWL-S with an ontology to specify QoS metrics for Web services, to demonstrate the ability of XML nets for \(QoS-aware Naturally, other Web service ontologies \(e.g., MOQ 11 e.g., WSLA [18 can also be used for this purpose Figure 6 shows another XML net fragment for the acquisition of transport information by selecting OWL 


acquisition of transport information by selecting OWLQoS documents which describe quality of Web services from a repository that contains 3 OWL-QoS documents discovered previously. Similar to the example in Figure 2, the Filter Schema FS1 is used to read and select appropriate OWL-QoS documents, and the Filter Schema FS2 to create new OWL-QoS documents for the place ?OWL-QoS document?. As Filter Schema provides no means for formulating inequality operators like ?&gt;? and ?&lt;=?, which are usually used to express constraints with parameters whose quantitative values are limited to a certain interval, transition inscriptions Figure 4. XML net for Web service discovery Figure 5. Filter Schemas for Web service discovery definitions 1 service name: \\s*flight\\s*/i c definitions service name: \\s*train\\s*/i b a definitions 1 1 Proceedings of the 42nd Hawaii International Conference on System Sciences - 2009 8 can be used in combination with Filter Schemas to formulate QoS constrains Suppose that the traveler wants to use only the Web services that cost no more than 100 US Cent. The Filter Schema FS1 should then be created as shown in Figure 7. The variable of the attribute filter ?rdf: resource? of the element filter ?owl: onProperty? is instantiated with a regular expression to filter OWL-QoS documents specifying the property ?costUSCent?. To ensure that the maximal cost of the Web service doesn?t exceed 100 US cent, the inscription of the transition ?select transport info service? should be formulated as owl:maxCardinality &lt;= 100?. In process simulation or execution, the inscription is parsed and integrated into XQuery statements using XPath inequality operators  6. Conclusions  In this paper we presented a WSC method based on XML nets, which inherit advantages of Petri nets such as formal semantics and graphical expression. XML nets have additional strengths in the description of process and data objects, and the exchange of XMLbased structured data. The advantage of using XML nets for WSC is that control flow modeling, data and data flow modeling, and WS discovery and selection can be realized using a uniform powerful modeling language. Some uncomplicated tasks, as illustrated before, can be fulfilled without developing or using additional software components or agents. Naturally XML nets can also be combined with other Web service techniques to fulfill more complicated and demanding tasks  7. Acknowledgement  The authors would like to thank the anonymous referees for many valuable comments on an earlier version of this paper  8. References  1] P. Alvarez, J. Banares, and J. Ezpeleta, ?Approaching 


1] P. Alvarez, J. Banares, and J. Ezpeleta, ?Approaching Web Service Coordination and Composition by Means of Petri Nets: the Case of the Nets-within-Nets Paradigm?, ICSOC 2005, LNCS 3826, pp.185-197, 2005 2] M. ter Beek, A. Bucchiarone, and S. Gnesi, ?Web Service Composition Approaches: From Industrial Standards to Formal Methods?, Second International Conference on Internet and Web Applications and Services \(ICIW?07 Computer Society, 2007 3] X.N. Feng, Q. Liu, and Z. Wang, ?A Web Service Composition Modeling and Evaluation Method Used Petri Net?, LNCS Volume 3842/2006, pp. 905-911, SpringerVerlag, 2006 4] H. Foster, S. Uchitel, J. Magee, and J. Kramer, ?Modelbased verification of Web Service Compositions?, 18th IEEE International Conference on Automated Software Engineering, pp. 152- 161, 2003 5] X. Fu, T. Bultan, and J.W. Su, ?Analysis of Interacting BPEL Web Services?, WWW2004, pp. 17-22, New York USA, May 2004 6] J.D. Ge, H.Y. Hu, P. Lu, H. Hu, and J. L  Translation of Nets Within Nets in Cross-Organizational Software Process Modeling?, SPW 2005, LNCS 3840, pp. 60-375 Springer-Verlag, 2005 7] Group for program system, faculty of Information Technique University Dortmund, ?PDDL?, http://ls5www.cs.uni-dortmund.de/~edelkamp/ipc-4/pddl.html 8] R. Hamadi and B. Benatallah, ?A Petri Net-based Model for Web Service Composition?, Fourteenth Australasian Database Conference \(ADC2003 CRPIT, Vol. 17, pp. 191-200, 2003 9] S. Hinz, K. Schmidt, and C. Stahl, ?Transforming BPEL to Petri Nets?, BPM 2005, LNCS 3649, pp. 220?235, Springer-Verlag, 2005 10] H. Kang, X.L. Yang, and S.M. Yuan, ?Modeling and verification of Web Services Composition based on CPN 2007 IFIP International Conference on Network and Parallel Computing-Workshops, pp. 613-617, 2007 11] H.M. Kim, A. Sengupta, and J. Evermann, "MOQ: Web Services Ontologies for QOS and General Quality EvaluaFigure 6. XML net for Web service selection Figure 7. Filter Schema for QoS-aware WS selection owl:Ontology owl:Class rdfs:subClassOf owl:Restriction rdf :resource : "\\s+#costUSCent owl:onProperty owl:maxCardinality   rdf:RDF Proceedings of the 42nd Hawaii International Conference on System Sciences - 2009 9 tions", European Conference on Information Systems \(ECIS 2005 12] S. Klink, Y. Li, and A. Oberweis, "INCOME2010 - a Toolset for Developing Process-Oriented Information Systems Based on Petri Nets", International Workshop on Petri Nets Tools and APplications \(PNTAP 2008, associated to SIMUTools 2008 March 2008 13] O. Kluge, ?Petri nets as a Semantic Model for message Sequence Chart Specifications?, proceedings of INT 2002 pp. 138-147, 2002 14] K. Lenz and A. Oberweis, ?Inter-Organizational Business Process Management with XML Nets?, H. Ehrig, W Reisig, G. Rozenberg, H. Weber \(Eds gy for Communication Based Systems, LNCS 2472, pp. 243263, Springer-Verlag, 2003 15] K. Lenz and A. Oberweis, "Workflow Services: A Petri Net-Based Approach to Web Services", Int. Symposium on Leveraging Applications of Formal Methods, pp. 35-42, Pa 


Leveraging Applications of Formal Methods, pp. 35-42, Paphos/Cyprus, November 2004 16] L. Lin and I.B. Arpinar, ?Discovery of Semantic Relations between Web Services?, IEEE International Conference on Web Services \(ICWS?06 17] Q. Lin, J.D. Ge, H. Hu, and J. Lu, ?An Approach to Model Cross-Organizational Processes using Object Petri net?, 2007 IEEE Congress on Services \(SERVICES 2007 pp. 146-152, July 2007 18] H. Ludwig, A. Keller, A. Dan, R. P. King, and R Franck, ?Web Service level Agreement \(WSLA Specification version 1.0?, IBM, 2003 19] N. Lohmann, P. Massuthe, C. Stahl, and D. Weinberg Analyzing Interacting BPEL Process?, S. Dustdar, J.L. Fiadeiro, and A. Sheth \(Eds 32, Springer-Verlag, 2006 20] S.A. Mcllraith and T.C. Son, ?Adapting Golog for Composition of Semantic Web Services?, 8th International Conference on Knowledge Representation and Reasoning KR2002 21] S.A. Mcllraith, T.C. Son, and H.L. Zeng, ?Semantic Web Services?, IEEE Intelligent Systems, March/April 2001 16\(2 22] N. Milanovic and M. Malek, ?Current Solution for Web Service Composition?, IEEE Internet Computing, NovemberDecember 2004 23] S. Narayanan and S.A. Mcllraith, ?Simulation, Verification and Automated Composition of Web Service?, 11th International World Wide Web Conference, Honolulu, Hawaii, USA, May 2002 24] The Organization for the Advancement of Structured Information Standards \(OASIS Process Execution Language Version 2.0?, 11 April, 2007 http://docs.oasis-open.org/wsbpel/2.0/wsbpel-v2.0.pdf 25] S.R. Ponnekanti and A. Fox, ?SWORD: a Developer Toolkit for Web Services Composition?, 11th International World Wide Web Conference, Honolulu, Hawaii, USA, May 2002 26] Z.Z. Qian, S.L. Lu, and L. Xie, ?Colored Petri Nets Based Automatic Service Composition?, 2007 IEEE AsiaPacific Services Computing Conference, pp. 431-438, 2007 27] C. Ouyang, E. Verbeek, W.M.P. van der Aalst, S. Breutel1, M. Dumas1, and A.H.M. ter Hofstede1, ?Formal semantics and analysis of Control flow in WS-BPEL?, BPM center Technical Report, BPM-05-15, 2005 28] J.H. Rao and X.M. Su, ?A Survey of Automated Web Service Composition Methods?, SWSWPC 2004, LNCS 3387, pp. 43-54, Springer-Verlag, 2005 29] J.H. Rao, P. Kuegas, and M. Matskin, ?Application of Linear Logic to Web Service Composition?, 1st International Conference on Web Services, Las Vegas, USA, June 2003 30] J.H. Rao, P. Kuegas, and M. Matskin, ?Logic-based Web Services Composition: From Service Description to Process Model?, 2004 International Conference on Web Services, pp.446-453, San Diego, USA, July 2004 31] M. Sgroi, A. Kondratyev, Y. Watanabe, L. Lavagno and A. Sangiovanni-Vincentelli, ?Synthesis of Petri Nets from Message Sequence Charts Specifications for Protocol Design?, Conference on Design, Analysis, and Simulation of Distributed Systems, pp. 193-199, 2004 32] W.M.P. Van der Aalst, "The Application of Petri Nets to Workflow Management", The Journal of Circuits, Systems and Computers, 8\(1 33] The World Wide Web Consortium \(W3C Semantic Markup for Web Services?, 22 November, 2004 http://www.w3.org/Submission/OWL-S 34] The World Wide Web Consortium \(W3C vices Choreography Description Language Version 1.0?, 17 December, 2004, http://www.w3.org/TR/2004/WD-ws-cdl10-20041217 35] The World Wide Web Consortium \(W3C vice Choreography Interface \(WSCI 


http://www.w3.org/TR/wsci 36] The World Wide Web Consortium \(W3C vice Modeling Language \(WSML http://www.w3.org/Submission/WSML 37] The World Wide Web Consortium \(W3C vice Modeling Ontology \(WSMO http://www.w3.org/Submission/WSMO 38] J. Yang and M.P. Papazoglou, ?Web Component: A Substrate for Web Service Reuse and Composition?, Proc 14th Conf. Advanced Information Systems Eng. \(CAiSE 02 LNCS 2348, pp. 21?36, Springer-Verlag, 2002 39] Y.P. Yang, Q.P. Tan, and Y. Xiao, ?Verifying Web Services Composition Based on Hierarchical Colored Petri Nets?, IHIS?05, pp. 47-53, Bremen, Germany, 2005 40] Y.P. Yang, Q.P. Tan, Y. Xiao, J.S. Yu, and F. Liu, ?Exploiting Hierarchical CP-Nets to Increase the Reliability of Web Services Workflow?, Symposium on Applications and the Internet \(SAINT?06 41] X.C. Yi and K.J. Kochut, ?Process Composition of Web Services with Complex Conversation Protocols: a Colored Petri Nets Based Approach?, Conference on Design, Analysis, and Simulation of Distributed Systems, pp.141-148, 2004 42] D. Zhovtobryukh, ?A Petri Net-based Approach for Automated Goal-Driven Web Service Composition?, SIMULATION, Vol. 83, Issue 1, pp.33-63, January 2007 43] C. Zhou, L.T. Chia, and B.S. Lee, "Web Services Discovery with DAML-QoS Ontology", International Journal of Web Services Research, vol. 2: no. 2: pp. 43-66, 2005   Proceedings of the 42nd Hawaii International Conference on System Sciences - 2009 10 pre></body></html 


  17 Mission Phase Relevant Archit ecture Informat ion Purpose Funct ion Mat urit y Pr oduct s DODAF M odel Re f e r e nce N ot e s Preliminary System Design Integrated Risk List Cross  functional list of risks compiled across integrated product team PDR Delivery Consolidated Ri sk Li st FFP1A Operational Environment M atrix documenting how test requirements that have been levied are satisfied with test \(at both the component and system levels Identification of the method that w ill be used to verify the requirement Identification of any potential non-conformances  Initial Delivery Environmental Te st  Verification Matrix FFP7 This will show the capability of the SV to withstand various environments \(i.e. launch vehicles System Interface Control Documentation This will be a suite of documents, the mission plan s hould identify critical system boundaries that reuqire a formal interface control document M inimum Criteria:  SV - Ground and Payload to SV ICD initial drafts must be compl e t e Other pertinent ICDs:  LV - Spacecraft, Component interface ICD Initial Delivery Interface Control Documentation SV 1  SV 6 Schedule Program Driving Schedule Requirements Key schedule driven technical decisions Giver receiver relationships that span different program elements Li v i n g Document Intgrated Milestone Schedule PV2 System Sub-system Design Specifications Partial Preliminary understanding of system subsystem design Allocation of required system functions to configuration items Demonstration of how system requirements are satisfied by design Initial Delivery PDR De si gn  Presentation SV 5 Open System Trades Desription organized by susbsystem of open design trades and decsions that need to be completed Each trade should have an owner and assocaited due dates that are aligned with program constriants Li v i n g Document Trade  Decision tracking matrix FFP5 Technical Performance Measures Demonstrate design peformance to critical program requirements outlined within the requirements document Initial Delivery Technical performance budget SV 7 Values in the budget should be compared to industry standards for a given maturity in the devleopment De t ai l e d De si gn System  Design Specifications Detailed description of "to be"  system subsystem design Allocation of required system functions to configuration items Demonstration of how system requirements are satisfied by design Final Delivery CDR De si gn  Presentation SV 4  SV 5 Note: Reference Lesson 11 - Need to look at some views and diagrams that would be useful for every subsystem Integrated Risk List Cross  functional list of risks compiled across integrated product team CDR Delivery Consolidated Ri sk Li st FFP1A Operational Environment Matrix documenting how test requirements that have been levied are satisfied with test \(at both the component and system levels Identification of the method that w ill be used to verify the requirement Identification of any potential non-conformances  Final Delivery Environmental Te st  Verification Matrix FFP7 Note: previous delivery s houl d have defined how requirements would be satisfied for long lead components.  This delivery would address all remaiing compents and system levels System Interface Control Documentation This will be a suite of documents, the mission plan s hould identify critical system boundaries that reuqire a formal interface control document M inimum Criteria:  SV - Ground and Payload to SV ICD initial drafts must be compl e t e Other pertinent ICDs:  LV - Spacecraft, Component Interface ICD Final Delivery Interface Control Documentation SV 1  SV 6 Schedule Program Driving Schedule Requirements Key schedule driven technical decisions Giver receiver relationships that span different program elements CDR De l i v e r y Intgrated Milestone Schedule PV2 Integration Prodcution Plan List of all components under procurement and their expected and need dates List should include all piece parts, miscellaneous mat ls, connectors and required ground support equipment Initial Delivery Sy st e m Pa r t s  Li st  FFP6 Technical Performance Measures Demonstrate design peformance to critical program requirements outlined within the requirements document Final Delivery Technical performance budget SV 7 Values in the budget should be compared to industry standards for a given maturity in the devleopment Open System Trades Desription organized by susbsystem of open design trades and decsions that need to be completed Each trade should have an owner and assocaited due dates that are aligned with program constriants Li v i n g Document Trade  Decision tracking matrix FFP5   


 LNCRITIC 0.884 \(.005 0.362 352 0.593 053  CRPRO -0.007 \(.306 0.012 183 0.002 798  CRCON 0.010 \(.291 0.013 230 0.019 095  Model fit F p value 24.900 lt;.0001 11.110 lt;.0001 5.940 lt;.0001 Adjusted R2 0.559 0.553 0.320 p &lt; .10 p &lt; .05 Notes: p values are in parentheses  4.5. South Korean versus American market  In terms of the effect of WOM, we find no discernable difference in the motion picture markets of South Korea and the United States. Volume of WOM is positively correlated to the following week?s revenue in both markets, and valence of WOM is not significant The effect of critical reviews, however, did not concur While the literature on the American market data reports that positive critical reviews are positively related to box office revenue[21, 34], the results on the Korean market was different. There could be several reasons for this. First, South Korea and the United States have different sources for critical reviews, and the sources may have different impacts on moviegoers Second, the characteristics of critics might be different i.e., Korean critics may prefer movies that are considered less commercial or artistic than American critics  5. Conclusion  WOM and critical reviews both are important attributes that influence box office revenue in the motion picture industry. In this study, six hypotheses related to this issue were set up and tested. Data was collected on the motion picture industry of South Korea by using several websites that provide content and statistical data about movies. Finally, data on 118 movies was collected and the movies were categorized into two groups based on the distributors of the movies If the distributor of a movie was one of the major distributors in South Korea, that movie was categorized into mainstream movies, and if not then the movie was categorized into non-mainstream movies. As expected mainstream movies had much higher box office revenue and volume of WOM than non-mainstream Proceedings of the 42nd Hawaii International Conference on System Sciences - 2009 8 movies. In the case of the volume of critical reviews 


movies. In the case of the volume of critical reviews however, there was no big difference between mainstream and non-mainstream movies. WOM and critical reviews were usually positive H1 and H2 tested the relationship between WOM and weekly box office revenue, and the results supported the hypotheses. The volume of WOM was positively related to weekly box office revenue, while the valence of WOM had no significant effect. H3 H4a, and H4b tested the impact of critical reviews, and the results also supported the hypotheses except H4b The volume and valence of critical reviews had no consistent significances to weekly box office revenue H3 H4b. Table 7 showed that the number of critical reviews was statistically significant to aggregate box office revenue \(H4a for the attitude of critical reviews \(H4b the result more detail, an additional test was performed using only those factors related to critical reviews as independent variables. The result of the additional test supported H4, but the signs were reversed, i.e. positive critical reviews had minus signs, and negative critical reviews had plus signs. This reversed signs imply that the preference of critical reviewers is very similar to that of normal moviegoers. H5s and H6s tested the different effects of WOM and critical reviews on mainstream and non-mainstream movies. The result failed to determine that WOM give different impact on mainstream and non-mainstream movies, so H5a and H5b were rejected. H6, however, was supported, i.e the effects of critical reviews were different for mainstream and non-mainstream movies. There were no significant relationships between critical reviews and aggregate box office revenue in mainstream movies. For non-mainstream movies, however, the volume of critical reviews and the percentage of negative critical reviews were significant. Nonmainstream movies have fewer sources from which consumers can get information, and this might explain the results The above findings lead to several managerial implications. First, producers and distributors of movies could forecast weekly box office revenue by looking at previous weeks? volume of WOM. It does not matter what attitude people have when they spread WOM, the important factor is its volume. Therefore producers and distributors need to develop an appropriate strategy to manage WOM for their movies For example, the terms related to WOM marketing such as buzz and viral marketing are easily found Second, for the distributors who usually distribute less commercial and more artistic movies, and consequently have a smaller market compared to the major distributors, critical reviews can impact their movies box office revenues in a significant way. There are usually fewer sources for information for nonmainstream movies than mainstream movies, and so small efforts could leverage the outcomes. Finally, for those who are dealing with mainstream movies, the finding that the valence of WOM and critical reviews do not have significant relationship with box office revenue can have certain implications. Particularly, the attitude of critical reviews showed reversed effects Therefore, they may need to concentrate on other features rather than attitude of moviegoers or critical reviews, such as encouraging moviegoers to spread WOM This study contributes to the understanding of the motion picture industry, especially the relationship between box office revenue and WOM including critical reviews. There are existing studies that already 


critical reviews. There are existing studies that already dealt with similar issues, but this study has some differentiated features compare to prior studies. First the data used in this study was collected from South Korea, while most of the relevant studies usually focus on the North American market. This helps to provide the opportunity to understand the international market especially the Asian market, even though South Korea is a small part of it in terms of the motion picture industry. Second, movies were categorized to two groups, i.e. mainstream and non-mainstream and this study attempted to determine how WOM impacts these categories differently by testing several hypotheses In this study, there are also several limitations that could be dealt with in future research. First, using box office revenue as a dependent variable is more meaningful for distributers rather than producers. Due to there is close correlation between box office revenue and number of screens, one of producers? main concerns is how many screens their movies can be played on. Moreover, DVD sales are also important measurement for success of movies these days, and so it also could be a dependent variable. Therefore, it could be possible to give more fruitful managerial implications to various players in the motion picture industry by taking some other dependent variables Second, in this study, movies were categorized simply as mainstream and non-mainstream movies, but there could be further studies with diverse techniques of movie categorizations. For example, it would be possible to study the varying influence of WOM or critical reviews on different genres or movie budgets Third, an interesting finding of this study is that positive critical reviews could have negative relationship with box office revenue while negative critical reviews could have positive relationship. This study tried to provide a reasonable discussion on the issue, but more studies could be elaborate on it  Proceedings of the 42nd Hawaii International Conference on System Sciences - 2009 9 References  1] Dellarocas, C., The Digitization of Word of Mouth Promise and Challenges of Online Feedback Mechanisms Management Science, 2003. 49\(10 2] Bone, P.F., Word-of-mouth effects on short-term and long-term product judgments. Journal of Business Research 1995. 32\(3 3] Swanson, S.R. and S.W. Kelley, Service recovery attributions and word-of-mouth intentions. European Journal of Marketing, 2001. 35\(1 4] Hennig-Thurau, F., et al., Electronic word-of-mouth via consumer-opinion platforms: What motivates consumers to articulate themselves on the internet? Journal of Interactive Marketing, 2004. 18\(1 5] Fong, J. and S. Burton, Electronic Word-of-Mouth: A Comparison of Stated and Revealed Behavior on Electronic Discussion Boards. Journal of Interactive Advertising, 2006 6\(2 6] Gruen, T.W., T. Osmonbekov, and A.J. Czaplewski eWOM: The impact of customer-to-customer online knowhow exchange on customer value and loyalty. Journal of Business Research, 2006. 59\(4 7] Garbarino, E. and M. Strahilevitz, Gender differences in the perceived risk of buying online and the effects of receiving a site recommendation. Journal of Business Research, 2004. 57\(7 8] Ward, J.C. and A.L. Ostrom, The Internet as information minefield: An analysis of the source and content of brand information yielded by net searches. Journal of Business Research, 2003. 56\(11 


9] Goldsmith, R.E. and D. Horowitz, Measuring Motivations for Online Opinion Seeking. Journal of Interactive Advertising, 2006. 6\(2 10] Eliashberg, J., A. Elberse, and M. Leenders, The motion picture industry: critical issues in practice, current research amp; new research directions. HBS Working Paper, 2005 11] S&amp;P, Industry surveys: Movies and home entertainment 2004 12] KNSO, Revenue of Motion Picture Industry 2004 Ministry of Culture, Sports, and Tourism, 2004 13] Duan, W., B. Gu, and A.B. Whinston, Do Online Reviews Matter? - An Empirical Investigation of Panel Data 2005, UT Austin 14] Zhang, X., C. Dellarocas, and N.F. Awad, Estimating word-of-mouth for movies: The impact of online movie reviews on box office performance, in Workshop on Information Systems and Economics \(WISE Park, MD 15] Mahajan, V., E. Muller, and R.A. Kerin, Introduction Strategy For New Products With Positive And Negative Word-Of-Mouth. Management Science, 1984. 30\(12 1389-1404 16] Moul, C.C., Measuring Word of Mouth's Impact on Theatrical Movie Admissions. Journal of Economics &amp Management Strategy, 2007. 16\(4 17] Liu, Y., Word of Mouth for Movies: Its Dynamics and Impact on Box Office Revenue. Journal of Marketing, 2006 70\(3 18] Austin, B.A., Immediate Seating: A Look at Movie Audiences. 1989, Wadsworth Publishing Company 19] Bayus, B.L., Word of Mouth: The Indirect Effects of Marketing Efforts. Journal of Advertising Research, 1985 25\(3 20] Faber, R.J., Effect of Media Advertising and Other Sources on Movie Selection. Journalism Quarterly, 1984 61\(2 21] Eliashberg, J. and S.M. Shugan, Film critics: Influencers or predictors? Journal of Marketing, 1997. 61\(2 22] Reinstein, D.A. and C.M. Snyder, The Influence Of Expert Reviews On Consumer Demand For Experience Goods: A Case Study Of Movie Critics. Journal of Industrial Economics, 2005. 53\(1 23] Gemser, G., M. Van Oostrum, and M. Leenders, The impact of film reviews on the box office performance of art house versus mainstream motion pictures. Journal of Cultural Economics, 2007. 31\(1 24] Wijnberg, N.M. and G. Gemser, Adding Value to Innovation: Impressionism and the Transformation of the Selection System in Visual Arts. Organization Science, 2000 11\(3 25] De Vany, A. and W.D. Walls, Bose-Einstein Dynamics and Adaptive Contracting in the Motion Picture Industry Economic Journal, 1996. 106\(439 26] Bagella, M. and L. Becchetti, The Determinants of Motion Picture Box Office Performance: Evidence from Movies Produced in Italy. Journal of Cultural Economics 1999. 23\(4 27] Basuroy, S., K.K. Desai, and D. Talukdar, An Empirical Investigation of Signaling in the Motion Picture Industry Journal of Marketing Research \(JMR 2 295 28] Neelamegham, R. and D. Jain, Consumer Choice Process for Experience Goods: An Econometric Model and Analysis. Journal of Marketing Research \(JMR 3 p. 373-386 29] Lovell, G., Movies and manipulation: How studios punish critics. Columbia Journalism Review, 1997. 35\(5 30] Thompson, K., Film Art: An Introduction. 2001 McGraw Hill, New York 31] Zuckerman, E.W. and T.Y. Kim, The critical trade-off identity assignment and box-office success in the feature film industry. Industrial and Corporate Change, 2003. 12\(1 


industry. Industrial and Corporate Change, 2003. 12\(1 27-67 32] KOFIC, Annual Report of Film Industry in Korea 2006 Korean Film Council, 2006 33] Sutton, S., Predicting and Explaining Intentions and Behavior: How Well Are We Doing? Journal of Applied Social Psychology, 1998. 28\(15 34] Basuroy, S., S. Chatterjee, and S.A. Ravid, How Critical Are Critical Reviews? The Box Office Effects of Film Critics Star Power, and Budgets. Journal of Marketing, 2003. 67\(4 p. 103-117  Proceedings of the 42nd Hawaii International Conference on System Sciences - 2009 10 pre></body></html 





