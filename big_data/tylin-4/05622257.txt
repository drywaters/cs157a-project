Clusteri ng Toward Detecting Cyber Attacks  Xiaofe n g Yang, Wei Li, Mingming Sun Xuelei Hu, Shuqin Li Scho ol of Computer Science and Technology Nanjing University of Science and Technology Nanjing, China Yo ngzhi Li D epartment of Information and Computer Science Nanjing Forestry University Nanjing, China E-mail: yzli@njfu.com.cn  Abstract 227 s everal anomaly methods have been proposed to cope with the recent booming of HTTP-related vulnerabilities which renders the security breaches of lots of vital HTTP 
based services on the internet. This paper proposes a novel bottom-up agglomerative clustering method which not only spares the nuisance of a learni ng process that involves a big amount of manual sample taggings, but also presents a much stronger adaptiveness in being able to coping with variant situations and in detecting new samples Keywords: agglomerative clustering; intrusion detection HTTP attacks; data minning I   I NTRODU CTIO N  The Hy per text Transfer Protocol \(HTTP n much more widely used in recent years. More applications are designed to run as a web service and deployed across the internet, which wires HTTP as its standard communication protocol. For example, news publishing, bank transaction 
email processing, file transferring, etc. The thriving trend of web service and its popularity ensures a heavier dependency of people on HTTP-based web applications to conduct carry out their business The popularity of HTTP applications is a big motive for attackers to exploit HTTP related vulnerabilities. Latest released CVE vulnerability trends o int s ou t th a t t h r ee  typical HTTP-related attacks, namely Cross Site Scripting\(XSS\QL-injection and Remote File Inclusion\(RFI\mount for more than half of the totally reported vulnerabilities. As the report also pointed out, it was mainly due to the ease of probing and exploitation of web vulnerabilities, combined with the proliferation of web service applications developed by inexperienced coders To detect attacks, traditional Intrusion Detection System 
IDS\as since long been used as a key security instrument It is configured with a big number of signatures to detect known attacks. The sharp increase of the vulnerabilities instantly propels the number of IDS signatures, as the case with Snor whi ch r e n d er s th e h i gher d etec tin g  consumption and lower network throughput. The dilemma was partly solved by anomaly detection, which builds normal behavior patterns rather than modeling every known attack However, performance of anomaly methods depends heavily on how complete the samples collected represent and  1 Corres pondenc e Authors Xiaof e ng. YANG     yangxf.nj@gmail.com 
Yongzhi. LI yz li@njf u com.cn  t h e accuracy of human taggings. Furthermore, one model learned from a given sample set applies only to very limitted detecting situations In this paper, we propose a bottom-up agglomerative clustering method which spares the nuisance of a learning process and has a strong adaptiveness for variant detection tasks The remainder of this paper is organized as follows section II introduces the related works and methods with regard to both anomaly methods and clustering algorithms Section III defines the problems we are facing and the motive of our work, followed by the elaboration of our clustering method in section IV. In section V, we designed a 
test to demonstrate the strength of our method. Section VI concludes the paper II  R ELATED WO RKS  Anom a ly detection builds a normal behavior model, and marks attack on behaviors which significantly deviate from the normal model. Though anomaly IDS researches have largely focused on traditional all-in-one IDSes, a few anomaly methods tailored for HTTP attacks have already been proposed C. Kruegel and G. Vign o p o s ed a gr oup of a n o m a ly  detecting models Attribute length usually, parameters of a specific HTTP request are either fixed-sized tokens or short strings delivered from human inputs, therefore, the lengths of  the 
parameter values should not vary too much between requests associated with a certain program. With mean u and standard deviation s trained with normal sample lengths, anomaly score of new sample length l is computed by l-u|/s  Character distribution a statistical way of measuring the distribution sequence of a string. Other include token finder attribute presence or absence, attribute order and NFA KL. Ingham and H. Inoue [5  s u m m a r i zed an d co m p ared  existent anomaly detection methods for HTTP, and mentioned Ngram, a strong means of distinguishing normal and abnormal requests These methods invariantly need to learn from a human tagged normal sample set before putting into detection, their 
performances heavily depend on the selection of the learning sample set H Debar and A Wes s t arted us ing b a sic cl uster ing  techniques to cope with traditional IDS alerts. S Zanero and SM Savaresi propo s e an u n s uper v ise d c l usteri ng m e t h od to improve the automation of IDS alerts processing. K 2010 International Conference on Computer Application and System Modeling \(ICCASM 2010 V12-243 C 9 78 1 42 4 4 7 237 6   2 6  0 0  201 0 I E EE 


2009-09-28 0 2 26:25 mysite.com 60.190.218.135 GET  defa u lt.asp cat  1&page=9 8 0 226 124.115.0.170 200 0 0 program param e ters met h od Fig. 1: sam p le log entry J ulis rais ed the i d ea th at  t h e r oot cau ses o f  m o s t I D S  alert, which represented by dense clusters of alerts shareing much resemblances can be localized by a clustering method Though these methods are designed to deal with traditional IDS alerts, they are a big inspiration to our work III  P ROBEM DE FI NITIONS  Be f o re proceeding to the next section where our clustering method is unfolded in details, we introduce in this section the challenges in front of us, followed by some presumptions that works as the cornerstone in our research A  Web Service and HTTP Protocol Web services are deployed by providing a globally accessible IP address or a domain name, they are programs that mostly listen on port 80 and answer to requests from clients, mostly launched by web browsers \(Microsoft Internet Explorer, or Firefox etc.\. Web service takes the client/server mode for communications, both sides must comply to HTTP protocol specifications to enable the proper working A typical web service application consists of a bunch of dynamic scripts suffixed with \223.asp\224 or \223.php\224 etc., which we call programs. Each of these programs provides a part of the service interfaces the application is designed for. Programs are organized in a root directory directly or indirectly in variant subdirectories under the root directory. Therefore every program has a unique sub-path relative to the root directory which can locate the program. We call the unique identity as program name A request routed to the server mainly consists of an URL the program name that is to receive and process the request and request parameters As stated by HTTP protocol, two methods are employed to send request, namely \221GET\222 and \221POST\222. They differ in how to send the parameters, \221GET\222 sends the parameters by appending them to the end the URL, while \221POST\222 puts parameters in the deeper sections of the request packet Server side platform \(e.g. IIS and Apache\ logs every HTTP request from all clients scattered around any corner of the internet. A sample log entry is shown in Fig. 1 Our method analyzes these server logs to detect malicious requests. Because request parameter sent with method \221POST\222 are not logged at all, POST requests are not considered in our research. However, our method is capable of coping with POST requests as well by adding a more sophisticated data capturing mechanism Any request to a program spawns a lot of additional requests to resource files that are referred by the program these additional request will also be logged in log files however these logs not only provide little information in our analysis but also confuse a lot, so we ignored them in our work and focused only on logs for program requests B  Presumption The goal of our research is to classify a large request samples into normal and malicious groups. Clustering carries the nature of producing one or more clusters from a large dataset We observed some apparent statistical characteristics with regard to normal and abnormal requests  Normal requests take similar forms  Normal requests reoccurs frequently, and takes a predominant proportion  Abnormal requests are take a much bizarre look than the normal request, and they are much smaller in numbers We believe by picking up an appropriate dissimilarity measurement and a proper clustering strategy, clustering process is capable of gathering a dense cluster of normal requests in the center and leaving abnormal requests out, by which properly classify requests into normal and abnormal groups IV  C LU STERING M ETHOD  A b ot tom-up agglomerative clustering method is unfolded as follows A  Definitions and Notations Attribute An attribute attr is a name and value pair a,v  Parameters parameters consist of a group attributes which are catenated with a symbol \221&\222 Request since the program name and its parameters are all what we are interested in a request, we define a request as pname,\(a 1 v 1  a 2 v 2 205  a n v n  wi t h pname representing the program name and a 1 v 1  attri b utes passed in the request Abnormal  Request Attribute value, where is supposed to transfer normal user parameters, is always manipulated by attackers to probe internal information or execute malicious commands. We define a request abnormal if one of the attribute values is manipulated Sample set a sample set X is the values with the same attribute name and program name. Any sample x belongs to X takes the form of a string Cluster cluster C={x 1 x 2 205,x n  i s a set of samples that are supposed to be close to each other Stage a stage in a clustering process S={C 1 C 2 205,C n  is a  set o f sample clusters, where the union of all C k is X and the i ntersection of any pair of C i C j  is em p ty Sample Distance  d\(x i x j  i s the distance between the sample pair x i and  x j  Cluster d ist ance  D\(C i C j  is th e clu ster distance between cluster C i and C j a.k a. di ssimilarity of C i and C j  In ner C luster Distance We measure the density of a cluster C as D\(C which is the farthest sample distance between any sample pair within cluster C  Cluster momentum cluster momentum N\(C is defined as the counts of samples belong to the cluster C  2010 International Conference on Computer Application and System Modeling \(ICCASM 2010 V12-244 


B  Cl u stering Framework Clustering starts from an initial stage S 0 where every  single sample is counted as a cluster. With every clustering step, a cluster pair which among all has the shortest distance is clustered together and marked as a new cluster. It process goes on until the final stage where all samples are in a single cluster, thus a bottom-up hierarchy is formed with every later stage perches on top the previous one The algorithm is as follows  Step 1: initialize stage S 0 by ad din g every single sample into a separate cluster S 0 C i x i i=1 205N t=0   Step 2: repeat Step 3 to Step 5 sequentially until all sample are in a single cluster  Step 3 t=t+1   Step 4: find cluster pair C i C j  fr o m all possible pairs C r C s  sa tis fying D\(C i C j  m in D\(C r C s    Step 5 Crea te new cluster C q C i C j update stage  S t S t-1  C i C j  C q  For clarity we  call a repeat from step 3 to step 5 a stage move. This clustering process creates a sequence of stages S 0 S 1 205S n wit h each move to the next stage, normal samples which share a high resemblance tend to be grouped into a single cluster in an early stage. Every stage except the last one contains a group of clusters. Given a stage, we single out the cluster with the maximum number of samples as MaxC  and mark as normal, while those left out as abnormal The distance sequence that involved in stage moves monotonously increases. However, there are occasions where more than 2 consecutive distances are the same, though the corresponding stage moves are carried out one after another they nevertheless share equal priorities if parallelism is allowed. Therefore, we consider stages clustered with same distances as a single stage, and we simplify this by preserving the last one in the consecutive stage sequence. By doing so, we yield a shorter sequence S 0 S 1 205S M where m n  and n o d i stances with regard to two consecutive moves are the same Any stage provides a classification that whether a sample is normal or abnormal. A cutting strategy which selects the best stage from the stage sequence S 0 S 1 205S M is decide d by two conditions  Condition1: The momentum of maximum cluster accounts for more than half of the total samples. We define the max cluster in the first stage out of stage sequence which satisfies this criteria as MaxC 0  N MaxC 0 X   Con diti ons2: Inner cluster distance of max cluster is no more than twice that of MaxC 0  D\(Ma xC 2D\(MaxC0  The best stage is the last one that satisfies both condition1 and condition2 out of the stage sequence Two deciding parts of cluster process that influences greatly on how the classifying result turns out are the definitions of the sample distance and cluster distance, both of which are elaborated in the following part of this paper C  Distance Definitions  Sample distance Our samples are values with regard to a specific pair of attribute name and program name. A single sample is a string sample distance are then the distance of 2 strings. Several distinct natures with normal and abnormal requests are taken into consideration a  string length distance between two strings with radically different lengths tends to be far away b  string shift if one string is generated from another by few shifting operations, the two strings tend to be close. For instance, string \221aabbccdd\222 and 221daabbccd\222 are close We picked up a sophisticated string distance definition 221edit distance\222 as our sample distance. Given string a and b  edit distance ED\(a,b defines as the smallest number of elemental operations needed to change a to b Elemental operations include \221insert\222, \221delete\222, \221replace\222 and \221substitute\222 Shift operation that we mentioned can be accomplished by a combination of \221insert\222s and \221delete\222s  Cluster distance Because we observed the normal samples are close to each other, the cluster they represented must be dense, and the union of two normal clusters will maintain the density of its previous ones. So we choose the maximum sample distance between samples from both clusters as their cluster distance D\(C i C j a x d\(x q x r e r e x q i r j this ens u res the monotonous increase of the distance sequence V  T EST AN D D ISCUSSIONS  A  Test D ata Few attack data sets are made public, they include DARPA data sets RP A  MI T L i nc o l n Laboratories and KDDCup s t l y  th ey were recorded 10 years ago, and somewhat outdated, therefore are hard to represent the current attacking and defensive techniques. Secondly, they consist of few HTTP-based attacks, so are unable to test our HTTP-targeted methods Some researchers use more accurate but non-public data sets due to some privacy regulations, these data sets are not available either. So, we collected our own data set from websites under the domain of \221njust.edu.cn\222 to compare and evaluate the methods The log files were collected in the second half year of 2009, which covers a time-span of more than 5 months. Data set contains HTTP attacks such as SQL injection, Cross-site script, file inclusion \(remote and local\d buffer overflow etc. These log files were processed and labeled halfmanually and aided by specific programs. We prepared more than 100,000 labelled logs as our test data set B  Test Settings We strive to highlight the following points in designing our test  To compare the performance of our method with other typical abnormal methods in usual detection tasks 2010 International Conference on Computer Application and System Modeling \(ICCASM 2010 V12-245 


 Fig.3-b  ROC part view of test2 Fig.3a ROC overview of test2  To hi ghlight the strength of our method We selected anomaly methods proposed by C. Krue  and H. Inoue to  co ndu ct  t h e co m p ar ison T h ey ar e 221length\222, \221character distribution\222 and Ngram with n 5. These methods need to learn from a normal dataset to build normal behavior models before detection. In test1, we picked up all normal samples to feed these learning processes, and the whole dataset for detection. In test2, we randomly picked up half of the normal samples for learning, and still the entire dataset for detection. A fact we maintained deliberately in the second test is that the other half of the normal samples that are excluded from the learning process have no intersection with the learning half. That is to say, only half of the normal samples are learnt before detection, we did this to demonstrate the adaptiveness of all methods C  Test Result Receiver operating characteristic \(ROC\urve shows a trade off between true positive rate and false positive rate and is employed in our work to visualize the test results Fig.2-b and Fig.3-b are zoomed-in plots of Fig.2-a and Fig.3-a, they amplified the differences of every curve In both tests, Character distribution method has poor performances. We see from Fig.2-a and Fig.2-b that Length cluster and Ngram can all achieve high detection rate while maintaining a zero false positive rate. However, in test2 where learning dataset was not quite sufficient, Ngram\222s performance dropped dramatically. In both tests, length and our method kept stably high detection rates and low false positive rates with our method slightly taking the leads D  Discussion Our method has demonstrated some advantages High detection rate and low false positive rates  achieving a more than 99% detection rate while keeps a zero false positive rate. Low false positive rate is very important in real practice Strong adaptiveness other abnormal methods like Ngram though quite effective if trained well, are highly dependent on the learning sample set, if learning sample set is not complete, detection performance could be well under expectation VI  C ONC LUSION AND FUTURE WORK  I n th is paper, following the observation that normal requests are a predominant majority among all requests and they share a high resemblance, we proposed a clustering method for detecting HTTP attacks, which bears the merits of both high detection performance and strong adaptiveness Though a fine result did we achieve in the test, there are some simple doings like the selections of sample distance and cutting strategy left, more considerations taking the advantage of application priories are still needed to be added into the method for further improvements, which will be investigated in our future work A CK NOWLEDG MENT  This wor k is funded by the National Natural Science Foundation No.60705020, Jiangsu Natural Science Foundation No.BK2007594, and the Research Foundation of NJUST No.XKF09073 R EF E RENCES  1  S Christey, R.A. Martin. \223Vulnerability type distributions in CVE\224. http://cwe.mitre.org/docu ments/vuln-trends.html. 2009 2  M R oesch, \223Snort \226 lightweight intrusion detection for networks\224. Proc of the 13th USENIX Conference on System Administration \(LISA\USEN IX Association, Nov. 1999 pp.229-238 3  R. Fi e lding, J. Gettys, J Mogul, et al. \223Hypertext transfer protocol \226 HTTP/1.1\224. RFC-2616, 1999 Fi g 2-a ROC overview of test1 Fig.2 b ROC part view of test1 2010 International Conference on Computer Application and System Modeling \(ICCASM 2010 V12-246 


4  C. Krue g el, G. Vigna. \223Anomaly detection of web-based attacks\224. Proc. of the 10th ACM conference on Computer and communications security \(CCS\s, Oct. 2003 pp.251\226261. dio  http://doi acm org/10.1145/948109.948144 5  K.L Ingham H. Inoue. \223Comparing anomaly detection techniques for HTTP\224. In Recent Advances of Intrusion Detection \(RAID\pringer. Sep. 2007, pp.42-62. dio  10.1007/978-3-5 40-74320-0_3 6  H Debar, A Wespi 223Aggr egation and correlation of intrusiondetection alerts\224. Recent Advances in Intrusion Detection Springer. Oct. 2001, pp. 85-103. dio:10.1007/3-540-454748_6 7  S Z a nero, SM Savaresi. \223Unsupervised learning techniques for an intrusion detection system\224. Proceedings of the 2004 ACM symposium on Applied computing. Mar. 2004, pp. 412419. dio  http://d o i acm.org/10.1145/967900.967988 8   K Julis ch 223Clustering intrusion detection alarms to support root cause analysis\224. ACM Transactions on Information and System Security \(TISSEC 6 ,ACM press. Nov. 2003,.pp 443\226471.dio  http://doi acm org/10.1145/950191.950192 9   J W. Hai nes, R.P. Lippmann, D.J Fried, E. Tran, S. Boswell M.A. Zissman. \2231999 DARPA in trusion detection system evaluation: design and procedures\224. 2001, Technical Report TR-1062, Lincoln Laboratory, Massachusetts Institute of Technology, Lexington, MA, USA 10   R P. Lippmann, J.W. Haines, D.J. Fried, J. Korba, K. Das 223Analysis and Results of the 1999 DARPA Off-Line Intrusion Detection Evaluation\224. Recent Advances of Intrusion Detection, Springer. Oct. 2000, pp. 162-182. dio  10.1007/3540-39945-3_11 11   http://kdd.ic s uci.edu/databases/kddcup99/kddcup99.html 2009  2010 International Conference on Computer Application and System Modeling \(ICCASM 2010 V12-247 


We use different colors to represent the performance of different methods: light green for GEP, dart green for sGEP, red cross for vCGH Viterbi decoding, and the rest colors for a series of vCGH Posterior decoding with posterior probabilities equal to 0.5, 0.6, 0.7, 0.8 and 0.9. The ideal performance point should be at the upper right corner where both sensitivity and specificity are good. From Figure 4 and 5, it is obvious that vCGH outperforms GEP and sGEP methods by lying at the most upper right corner for most chromosomes. GEP method laid at the most lower left corner, indicating a bad agreement with the experimental CGH. sGEP, which is a simple processing of GEP data, lying in the middle, improved the prediction a little bit. But vCGH, both Viterbi and Posterior decoding, has the best sensitivity and specificity values, benefiting from the model refinement and the training process As expected, under the vCGH Posterior decoding increasing the posterior probability \(from p 0.5 to p 0.9\ulted in an increased specificity and a decreased sensitivity in predicting gains or losses. We noticed that the vCGH prediction were good for the majority of chromosomes, but not good for some chromosomes, such as chr1, chr6, chr9, chr10 and chr13 for gains and chr4, chr5, chr15 and chr18 for losses. The reason for this is due to infrequent aberration of these chromosomes being observed in MCL. For example, in the experimental CGH, of the 64 MCL cases, only one, three, one, two and one case were observed with gains on chr1, chr6, chr9, chr10 and chr13, respectively, and two, one, one and two cases with losses on chr4, chr5, chr15 and chr18 respectively In general, in predicting gain, sensitivity was improved from 40% in GEP to 45% in sGEP and to 75% in vCGH, and specificity from 70% in GEP to 85% in sGEP and to 90% in vCGH \(Figure 4\n predicting loss, sensitivity from 30% in GEP to 50% in sGEP and to 60% in vCGH, and specificity from 80 in GEP to 90% in sGEP and vCGH \(Figure 5\n predicting normal, sensitivity from 40% in GEP to 60% in sGEP and to 70% in vCGH, and specificity from 45% in GEP to 50% in sGEP to 65% in vCGH figure was not shown  4.2. Prediction on Cytoband Level  We showed the predicted gains and losses on the cytoband level by vCGH Viterbi decoding \(Figure 6 left d Posteriori decoding \(Figure 6 right he losses were plotted on the left side and gains on the right side. In Posterior decoding, we also plotted a range of posterior probability values, from p 0.5 to p 0.9, denoted by different colors in the figure. Under Posterior decoding we found that the number of predicted gains/losses increas es as posterior probability decreases, but the shapes of the plots were in concordant trend. Comparing the shapes of Viterbi and Posterior, a good agreement was also observed The cytoband-level vCGH prediction was also compared with CGH gold standard using Fisher s exact test. In Fisher s exact, the sums of the gains and losses from vCGH Viterbi and CGH were compared on a band-by-band basis. Among a total of 290 cytobands only 6 cytobands in the two groups exhibits nonrandom association if p-value <5% \(Table 1\This holds true for the comparison between vCGH Posterior and CGH as well. This indicates the prediction from vCGH are similar to CGH for most of the cytobands  Table 1. Cytobands exhibiting different patterns of gains and losses between CGH and vCGH using Fisher s exact test \(p<0.05  band p-value band p-value 3p24 0.019 6p25 0.011 3p26 0.031 6p24 0.011 3p25 0.031 8p23 0.032   5. Conclusions  In this paper, we proposed a novel computational approach, vCGH, for the prediction of CGH profiles DNA copy number alterations\rom GEP profiles in tumor cases. vCGH was constructed on a hidden Markov model, which was trained in the light of the paired GEP and CGH data on the same set of a sufficient number of tumor cases, and then applied to new cases of the same tumor type for the prediction of chromosomal gains and losses based on their GEP data. Viterbi and Posterior algorithms were used as the decoding methods in the vCGH model. The prediction performance was tested using leave-one-out cross validation on 64 MCL cases. The results showed that vCGH predictor reached 70% sensitivity and 90 specificity in predicting both chromosomal gains and losses, which is significantly better than simple processing methods of GEP raw observations In this study, we used MCL as an application, but vCGH is a general tool which can be applied to other types of tumors. In addition, our model does not only highlight DNA copy number alterative regions but also served as an integrative tool cross-linking genomic and transcriptiomic data. In conclusion, vCGH is a powerful tool that may significantly enhance the data analysis of GEP and the detection of genetic abnormalities in cancer research Proceedings of the 42nd Hawaii International Conference on System Sciences - 2009 6 
 


  Figure 4. Sensitivity and specificity in predicting gains by GEP, sGEP, vCGH Viterbi and Posterior decoding with p 0.5, 0.6, 0.7, 0.8 and 0.9, respectively  Proceedings of the 42nd Hawaii International Conference on System Sciences - 2009 7 
 


   Figure 5. Sensitivity and specificity in predicting losses by GEP, sGEP, vCGH Viterbi and Posterior decoding with p 0.5, 0.6, 0.7, 0.8 and 0.9, respectively   Proceedings of the 42nd Hawaii International Conference on System Sciences - 2009 8 
 


   Figure  6. Chromosomal gains and losses predicted by vCGH Viterbi left and vCGH Posterior  right   In Posterior decoding, different probability cutoff values p=0.5, 0.6, 0.7, 0.8 and 0.9 are shown by different colors. Left-sided bars of each figure correspond to losses whereas right-sided bars indicate gains. X-axis represents the frequency of the alterations. In Y-axis, cytobands are ordered along the chromosome from pter to qter  Acknowledgment  We would like to thank Lymphoma/Leukemia Molecular Profiling Project \(LLMPP http://llmpp.nih.gov\ for sharing the GEP and CGH data. This work was supported in part by the NCI grant number 5U01/CA114778, Department of Health and Human Services, and the NIH grant number P20 RR16469 from the INBRE program of the National Center for Research Resources  References   S  du  M a n o i r   M  R S p ei cher S  J o o s  E   Schrock, S. Popp, H. Dohner, G. Kovacs, M. RobertNicoud, P. Lichter, and T. Cremer, "Detection of complete and partial chromosome gains and losses by comparative genomic in situ hybridization Hum Genet vol. 90, pp 590-610, Feb 1993 2 A  Ka llionie m i, O P  Ka lli onie m i, D. Suda r D  Rutovitz, J. W. Gray, F. Waldman, and D. Pinkel Comparative genomic hybridization for molecular cytogenetic analysis of solid tumors Science vol. 258, pp 818-21, Oct 30 1992 3 J. Fridly a nd, A  M. Snijde r s, D  P i nk e l D. G   Albertson, and A. N. Jain, "Hidden Markov Models Proceedings of the 42nd Hawaii International Conference on System Sciences - 2009 9 
 


Approach to the Analysis of Array CGH Data J Multivariate Anal vol. 90, pp. 132-153., 2004 4  A  O l s h e n a nd E. Ve nk a t r a m a n C ha ng e point  analysis of array-based comparative genomic hybridization data In proceedings of Joint Statistical Meetings pp 2530-2535, 2002 5 A  M. Snijde r s  N  N o w a k  R. Se g r a v e s S Blackwood, N. Brown, J. Conroy, G. Hamilton, A. K Hindle, B. Huey, K. Kimura, S. Law, K. Myambo, J Palmer, B. Ylstra, J. P. Yue, J. W. Gray, A. N. Jain, D Pinkel, and D. G. Albertson, "Assembly of microarrays for genome-wide measurement of DNA copy number Nat Genet vol. 29, pp. 263-4, Nov 2001  P  W a n g  Y Ki m  J P o l l ack B Narasi m h an  an d R. Tibshirani, "A method for calling gains and losses in array CGH data Biostatistics vol. 6, pp. 45-58, Jan 2005 7 S. Be a   A  Ze ttl G   W r ig ht, I. Sa l a v e rria  P  Je hn  V. Moreno, C. Burek, G. Ott, X. Puig, L. Yang, A. LopezGuillermo, W. C. Chan, T. C. Greiner, D. D. Weisenburger J. O. Armitage, R. D. Gascoyne, J. M. Connors, T. M Grogan, R. Braziel, R. I. Fisher, E. B. Smeland, S. Kvaloy H. Holte, J. Delabie, R. Simon, J. Powell, W. H. Wilson, E S. Jaffe, E. Montserrat, H. K. Muller-Hermelink, L. M Staudt, E. Campo, and A. Rosenwald, "Diffuse large B-cell lymphoma subgroups have distinct genetic profiles that influence tumor biology and improve gene-expressionbased survival prediction Blood vol. 106, pp. 3183-90 Nov 1 2005 8 I. Sa la v e rria   A  Ze ttl, S. Be a  V   More n o J  Valls, E. Hartmann, G. Ott, G. Wright, A. LopezGuillermo, W. C. Chan, D. D. Weisenburger, R. D Gascoyne, T. M. Grogan, J. Delabie, E. S. Jaffe, E Montserrat, H. K. Muller-Hermelink, L. M. Staudt, A Rosenwald, and E. Campo, "Specific secondary genetic alterations in mantle cell lymphoma provide prognostic information independent of the gene expression-based proliferation signature J Clin Oncol vol. 25, pp. 1216-22 Apr 1 2007 9 J. Iqba l, R. J. De L e e u w   G  Sriva s ta v a C. Kuc u k   H. Geng, W. Tam, D. Klinkebiel, K. Patel, K. Cao, L Shen, K. Dybkaer, I. F. L. Tsui, J. K. Christman, H. Ali, N Shimizu, W. Au, W. L. Lam, and W. C. Chan, "High resolution comparative genomic hybridization and gene expression analysis of chromosomal aberrations in natural killer-cell malignancies Submitted 2008 10  K  V i r t a n e v a  F  A  W r i g h t  S  M  T a n n e r  B   Yuan, W. J. Lemon, M. A. Caligiuri, C. D. Bloomfield, A de La Chapelle, and R. Krahe, "Expression profiling reveals fundamental biological differences in acute myeloid leukemia with isolated trisomy 8 and normal cytogenetics Proc Natl Acad Sci U S A vol. 98, pp. 1124-9, Jan 30 2001 11  J  Cla r k  S Ed w a rd s  M. J o h n  P. F l o h r, T   Gordon, K. Maillard, I. Giddings, C. Brown, A Bagherzadeh, C. Campbell, J. Shipley, R. Wooster, and C S. Cooper, "Identification of amplified and expressed genes in breast cancer by comparative hybridization onto microarrays of randomly selected cDNA clones Genes Chromosomes Cancer vol. 34, pp. 104-14, May 2002 12  J  R  P o l l a c k  T  S o r l i e  C  M  P e r o u  C  A  R e e s   S. S. Jeffrey, P. E. Lonning, R. Tibshirani, D. Botstein, A L. Borresen-Dale, and P. O. Brown, "Microarray analysis reveals a major direct role of DNA copy number alteration in the transcriptional program of human breast tumors Proc Natl Acad Sci U S A vol. 99, pp. 12963-8, Oct 1 2002 13  E. Hy m a n, P  K a ura n ie m i S H a uta n ie m i M Wolf, S. Mousses, E. Rozenblum, M. Ringner, G. Sauter O. Monni, A. Elkahloun, O. P. Kallioniemi, and A Kallioniemi, "Impact of DNA amplification on gene expression patterns in breast cancer Cancer Res vol. 62 pp. 6240-5, Nov 1 2002 14  J  L  P h i l l i p s  S  W  H a y w a r d  Y  W a n g  J   Vasselli, C. Pavlovich, H. Padilla-Nash, J. R. Pezullo, B M. Ghadimi, G. D. Grossfeld, A. Rivera, W. M. Linehan G. R. Cunha, and T. Ried, "The consequences of chromosomal aneuploidy on gene expression profiles in a cell line model for prostate carcinogenesis Cancer Res vol. 61, pp. 8143-9, Nov 15 2001 15  A  V a ris, M W o lf O. Mo n n i M  L  V a k k a ri, A   Kokkola, C. Moskaluk, H. Frierson, Jr., S. M. Powell, S Knuutila, A. Kallioniemi, and W. El-Rifai, "Targets of gene amplification and overexpression at 17q in gastric cancer Cancer Res vol. 62, pp. 2625-9, May 1 2002 16  S  C  L i n n  R  B  W e s t  J  R  P o l l a c k  S  Z h u  T   Hernandez-Boussard, T. O. Nielsen, B. P. Rubin, R. Patel J. R. Goldblum, D. Siegmund, D. Botstein, P. O. Brown, C B. Gilks, and M. van de Rijn, "Gene expression patterns and gene copy number changes in dermatofibrosarcoma protuberans Am J Pathol vol. 163, pp. 2383-95, Dec 2003 17  R. D u rbi n S  E ddy A  K r og h, a nd G  Mitc his o n  Biological sequence analysis: probabilistic models of proteins and necleic acids New York: Cambridge Unisersity Press, 1998 1 H. G e n g H. H. A li, and W  C  Ch an  A Hidden Markov Model Approach for Prediction of Genomic Alterations from Gene Expression Profiling LNBI 4983 pp. 414-425  Berlin Heidelberg: Springer, 2008  19  H   G e ng J  Iqba l, D e ng X., W   C  C h a n a nd H   H. Ali, "Virtual CGH: Prediction of Novel Regions of Chromosomal Alterations in Natural Killer Cell Lymphoma from Gene Expression Profiling," in Proceedings of the 40th Annual Hawaii International Conference on System Sciences \(HICSS 07 2007, p. 129a \(6 pages 20  LL MPP  L y m phom a  L e uk emia Mole c u la r  Profiling Project 21  R i c h a r d Sim on, A m y  Lam  Ming C hu ng L i  Michael Ngan, Supriya Menenzes, and Y. Zhao, "Analysis of Gene Expression Data Using BRB-Array Tools Cancer Informatics vol. 2, pp. 11-17, 2007 22   F inis hing t h e e u c h rom a tic s e que nc e of the  human genome Nature vol. 431, pp. 931-45, Oct 21 2004 23  S  B e a  M  R i b a s  J  M  H e r n a n d e z  F  B o s c h  M   Pinyol, L. Hernandez, J. L. Garcia, T. Flores, M. Gonzalez A. Lopez-Guillermo, M. A. Piris, A. Cardesa, E Montserrat, R. Miro, and E. Campo, "Increased number of chromosomal imbalances and high-level DNA amplifications in mantle cell lymphoma are associated with blastoid variants Blood vol. 93, pp. 4365-74, Jun 15 1999  Proceedings of the 42nd Hawaii International Conference on System Sciences - 2009 10 
 


  11  Raffi P. Tikidjian received his B.S degree in Computer Science from the University of Cal Poly Pomona in 2003 and went on to receive his M.S. degree in Computer Science speci alized in the area of Software Engineering from the University of Southern California \(USC in 2006.  He is presently a member of technical staff for the Reasoning, Modeling, and Simulation Group at the Jet Propulsion Laboratory and a PhD candidate in the Center for Systems and Software Engineering \(CSSE at the University of Southern California \(USC guidance of Dr. Barry Boehm His interests are in the areas of systems health management, simulation and modeling model based engineering technologies, software methodologies and processes, mobile and web application user interface design Doug Abraham is a Senior Engineer within the Architecture and Strategic Planning Office of JPL\222s Interplanetary Network Directorate.  As the Strategic Forecasting Lead, he oversees efforts to forecast future mission customer requirements and trends, assesses their implications for Deep Space Network evolution, and assists in the development of the roadmaps and plans needed to guide this evolution.  Doug also supports NASA HQ-led study activ ities pertaining to future lunar and Mars communications architectures Prior to his current assignment, Doug worked on the Galileo, Ulysses, and Cassini flight projects.  He has also worked on several pre-project formulation activities including Pluto Fast Flyb y and the \223Fire and Ice\224 collaboration with Russia Doug began his career as a graduate student intern in the International Space Station Program Office \(1988 graduated Magna Cum Laude from Texas A&M University in Physics \(1986\.S. in Technology and Science Policy, with specialization in technology assessment and electrical engi neering, from Georgia Tech 1990 Janet Wu received her Bachelor of Science \(2000\.S. \(2002 degrees in Planetary Science from the Massachusetts Institute of Technology in Cambridge, MA She has been a technical staff member in the Optical Communications group at the Jet Propulsion Laboratory in Pasadena, CA since 2002 


target incoming target incoming target incoming source outgoing Figure 6. EIS System Network View Meta-model operations are those used for service description and must be ultimately decomposed into elementary ones \(i.e. data processing, storing and transferring are estimated through parameter values that are propagated by service invocation parameters to parameters describing application operations constituting the service description which are further propagated to parameters describing elementary operations 4.3. EIS Architecture Design Task Implementation EIS Architecture Design tasks may be supported by existing tools [20]. Systems Modeling Language \(SysML 15] is considered as the most appropriate for EIS System Network model representation and requirement engineering, since it supports the concepts of requirements and resource allocation. As a direct consequence, SysML allows the representation of requirements as model elements which means that requirements are part of the system architecture. For representation purposes, a SysML pro?le for EIS System Network meta-model \(?gure 6 mented as a plugin to MagicDraw modeling tool [2]. In order to facilitate model exchangeability, EIS System Network model is being realized in XML, which is a standard exchangeable format. In order to exchange data with speci?c software tools, model transformations will be accomplished through appropriate XSLTs developed for each tool for example as the one transforming XMI to the EIS System Network document type description \(DTD 5. Case Study In the following we discuss the case of renovating a legacy information system supporting a large-scale public organization based on the proposed concepts. The organization supports more than 350 interconnected regional of?ces and its main purpose is to provide services to the public both citizens and businesses. Regional of?ces are divided into three categories according to their size and information infrastructure requirements \(large, medium and small More than 15.000 employees work in the organization having on-line access to the legacy system. There are more than 300 different services provided to the public, while each citizen is required to register in the one belonging to his/her residential area, called residential of?ce. Some of them require the actual presence of citizens in their residential of?ce Existing system architecture is based on a fat clientserver architecture. All application logic is programmed within the client platform, while data is distributed in local database servers located in each regional of?ce. A Central database is supported in the Datacenter for data synchronization and lookup purposes. The Datacenter and all regional of?ces participate in a private TCP/IP network to facilitate ef?cient data replication. Most data related to a speci?c citizen are maintained as local data in his/her residential of?ce. Client programs access the local database to store data, while they access the central database mostly for lookup purposes. Local data are asynchronously replicated in the central database using a transaction management system \(TMS Proceedings of the 42nd Hawaii International Conference on System Sciences - 2009 8 to facilitate communication with the central database. The central database provides the overall view of each citizen  s record 


record To enhance the level of services provided by the organization, we decided to establish an enhanced e-services environment through an e-government portal. The main target of the portal is to minimize the need for citizen  s presence in regional of?ces and intents to deal with all the drawbacks of the current e-service platform. It provides easy access to citizens and businesses twenty four hours per day, seven days per week. It also promotes the increase of e-services to users, facilitating the organization to accomplish its strategic goals. The portal facilitates on-line transactional services and ensures on-line access to the databases of the legacy information system Provision of transactional e-services re?ects the operation of the legacy system and thus results in its renovation. In order to effectively support both systems \(e.g the portal and the legacy system able to apply the same policies and minimize maintenance cost. Thus, it was decided to explore the renovation of the legacy information system by adopting modern technological trends, such as multi-tiered application architecture server-based computing and light clients. It was decided also to rewrite application code based on J2EE architecture to develop a web interface for the legacy information system in order to support a uni?ed environment for both the legacy system and the portal. This decision affected the legacy system architecture, described in System Network View. Some of issues raised included: \(a database architecture? It is currently distributed. Should it become centralized? What are the implications in the network infrastructure? \(b complished to minimize maintenance cost Though EA was never fully described, the organization had already decided to establish an EA based on Zachman framework a few years ago. RUPmethodology was used for software development, thus application description models were developed within Rational Rose platform. In order to be able to apply the proposed tasks identi?ed in section 4, relative information had to be extracted from the corresponding cells. Application description \(e.g. applications and modules tracted from corresponding Rational Rose ?les. Though the process was not automated, the provision of System Network meta-model, helped architecture designer to identify the information needed to obtain from software designers Detailed service description in terms of load requirements could not be extracted from software description. This was crucial in order to decide upon Intranet and Datacenter architecture. This information was collected by interviewing software developers The new system has to deal with a number of require&lt;&lt;Site&gt;&gt Central Organization Building lt;&lt;ServerProcess&gt;&gt Oracle Central database lt;&lt;Site&gt;&gt Medium Regional Office lt;&lt;Site&gt;&gt Datacenter server room lt;&lt;Site&gt;&gt Large Regional Office lt;&lt;Site&gt;&gt Small Regional Office oracle L.R.O lt;&lt;ServerProcess&gt;&gt tuxido L.R.O lt;&lt;ServerProcess&gt;&gt lt;&lt;Site&gt;&gt L.R.O. department tuxido Central 


tuxido Central lt;&lt;ServerProcess&gt;&gt lt;&lt;Site&gt;&gt R.O. server room lt;&lt;ClientProcess&gt;&gt oracle net lt;&lt;Site&gt;&gt Organization lt;&lt;ClientProcess&gt;&gt tuxido lt;&lt;ClientProcess&gt;&gt application lt;&lt;UserProfile&gt;&gt officer lt;&lt;invoke&gt;&gt lt;&lt;invoke&gt;&gt lt;&lt;invoke&gt;&gt lt;&lt;invoke&gt;&gt lt;&lt;invoke&gt;&gt lt;&lt;invoke&gt;&gt lt;&lt;invoke&gt;&gt lt;&lt;initiate&gt;&gt Figure 7. Topology View - Existing System ments, with security and availability being the most important ones. Security issues have to do with the security of the network, security of data, authentication control, etc. Availability requirements deal with the backup subsystem, the recovery system and high availability UPS. Privacy must be enforced with the use of cryptography and compression techniques. All these requirements were identi?ed during the System Architecture design process and consequently exported in System Motivation cell where all system requirements are gathered using a simpli?ed text-based requirement description method System Architecture design tasks were performed by existing tools already described in [20]. The existence of System Network meta-model and its implementation in XML facilitated tool integration and interoperability. The identi?cation of primary EIS engineering activities served by Zachman matrix rows and columns facilitated a better understanding between software developers, architecture designers and organization management and enhanced discrete methodology integration. Existing and renovated application architecture of the legacy system de?ned by Topology View are presented in ?gures 7 and 8 respectively. The screenshots are from the MagicDraw [2] tool, enhanced with EIS pro?le to provide the appropriate functionality 6. Conclusions &amp; Future Work MB-EISE process based on Zachman framework was explored in the paper. The designer may adjust basic MB-EISE activity model for each cell, formulate a methodology-independent EIS cell-related view, and ?nally identify methods and tools appropriate for implementing each speci?c task. One could argue that in such a case, 36 distinct EIS sub-views should be de?ned, each of them being rather complex, while basic MB-EISE activity should be adjusted 36 times, resulting in a very complicated process Proceedings of the 42nd Hawaii International Conference on System Sciences - 2009 9 lt;&lt;Site&gt;&gt Central Organization Building lt;&lt;ServerProcess&gt;&gt Oracle Application Server lt;&lt;ServerProcess&gt;&gt Oracle Central database lt;&lt;Site&gt;&gt Medium Regional Office lt;&lt;Site&gt;&gt Datacenter server room lt;&lt;Site&gt;&gt Large Regional Office lt;&lt;Site&gt;&gt 


lt;&lt;Site&gt;&gt Small Regional Office lt;&lt;Site&gt;&gt L.R.O. department lt;&lt;Site&gt;&gt Organization lt;&lt;ClientProcess&gt;&gt web browser lt;&lt;ServerProcess&gt;&gt Web Server lt;&lt;UserProfile&gt;&gt officer &lt;&lt;initiate&gt;&gt lt;&lt;invoke&gt;&gt lt;&lt;invoke&gt;&gt lt;&lt;invoke&gt;&gt Figure 8. Topology View - Renovated System However, EIS engineering process, as enterprise architecture, is itself complex. The bene?t of the proposed approach is that all aspects \(simple or complex form and modular fashion. Cell-related sub-views and corresponding meta-models, as well as cell-related MB-EISE activity model may be progressively formed according to the designer  s priorities and perspectives Having a black-box view of each Zachman cell, the proposed approach focuses on EIS view integration and interview consistency. The notion of external entities when de?ning EIS cell-related views provides the means for interoperability with external cells, while at the same time facilitates atomicity within the limits of each cell. We are currently emphasizing Business and System rows, and especially Function and Network cells, exploring in parallel Motivation column and the way non-functional requirements are managed Having a white-box view of each Zachman cell, it is evident that the de?nition of a technology neutral metamodel and the identi?cation of basic engineering tasks, corresponding to EIS cell-related views, contributes to the integration of different methodologies and tools. A library of EIS System Network models has been already implemented in XML. Emphasis is given to requirements management and especially requirements derivation References 1] Institute For Enterprise Architecture Developments http://www.enterprise-architecture.info 2] MagicDraw UML. http://www.magicdraw.com 3] A. Aurum and C. Wohlin. Engineering and Managing Software Requirements. Springer, 2005 4] F. S. d. Boer, M. M. Bonsangue, J. Jacob, A. Stam, and L. W N. v. d. Torre. A Logical Viewpoint on Architectures. In EDOC, pages 73  83. IEEE Computer Society, 2004 5] E. R. Byrne. IEEE Standard 830: Recommended Practice for Software Requirements Speci?cations, 1998 6] B. Dave and D. Jim. The new, improved RUP SE Architecture Framework, 2005. IBM Rational Edge 7] D. J. de Villiers. Using the Zachman Framework to assess RUP. Rational Edge, 2001 8] J. A. Estefan. Survey of Model-based Systems Engineering \(MBSE May 2007 9] A. Fatolahi and F. Shams. An investigation into applying UML to the Zachman Framework. Information Systems Frontiers, 8\(2  143, 2006 10] M. Glinz. On non-functional Requirements. 15th IEEE International Requirements Engineering Conference, 2007 11] F. Goethals, W. Lemahieu, M. Snoeck, and J. Vandenbulcke. An overview of enterprise architecture framework deliverables. In Banda RKJ \(ed Introduction. ICFAI University Press., 2006 12] H.-P. Hoffmann. Harmony-SE/SysML Deskbook: ModelBased Systems Engineering with Rhapsody, Rev. 1.51 Telelogic/I-Logix white paper. Telelogic AB, May 2006 


Telelogic/I-Logix white paper. Telelogic AB, May 2006 13] IEEE. IEEE Recommended Practice for Architectural Description for Software-Intensive Systems - Std 1471. Technical report, oct 2000 14] O. M. G. Inc. UML 2.0 Superstructure Speci?cation, October 2004 15] O. M. G. Inc. Systems Modeling Language \(SYSML i?cation. Version 1.0, September 2007 16] INCOSE. INCOSE Handbook SE Process Model, September 2003. http://g2sebok.incose.org 17] Institute for Electrical and Electronic Engineers. IEEE Std 15288 -2004, Systems Engineering -System Life Cycle Processes, June 2005 18] A. v. Lamsweerde. Goal-Oriented Requirements Engineering: A Guided Tour. In Fifth IEEE International Symposium on Requirements Engineering \(RE  01 19] S. Leist and G. Zellner. Evaluation of current architecture frameworks. In H. Haddad, editor, SAC, pages 1546  1553 ACM, 2006 20] M. Nikolaidou and N. Alexopoulou. Enterprise Information System Engineering: A Model-Based Approach Based on the Zachman Framework. In HICSS  08. IEEE Computer Society, 2008 21] M. Nikolaidou and D. Anagnostopoulos. A systematic approach for con?guring web-based information systems Journal of Distributed and Parallel Databases, 17\(3  290, May 2005 22] C. M. Pereira and P. Sousa. A method to de?ne an Enterprise Architecture using the Zachman Framework. In H. Haddad A. Omicini, R. L. Wainwright, and L. M. Liebrock, editors SAC, pages 1366  1371. ACM, 2004 23] K. Pohl and E. Sikora. Supporting the Co-Design of Requirements and Architectural Artifacts. In 15th IEEE International Requirements Engineering Conference \(RE  07 pages 258  261, India Habitat Center, New Delhi, 2007 24] J. Schekkerman. How to Survive in the Jungle of Enterprise Architecture Frameworks: Creating or Choosing an Enterprise Architecture Framework. Trafford, 2003 25] J. F. Sowa and J. A. Zachman. Extending and Formalizing the Framework for Information Systems Architecture. IBM Systems Journal, 31\(3  616, 1992 Proceedings of the 42nd Hawaii International Conference on System Sciences - 2009 10 pre></body></html 


C. \(2005 Implementation and Use in an Existing Clinical Information System. In Connecting Medical Informatics and Bio-Informatics: Proceedings of MIE2005 - The XIXth International Congress of the European Federation for Medical Informatics, 328-333. IOS Press, 2005  4] Fetterman, D. M. Ethnography, 2nd ed. Thousand Oaks CA: Sage, 1997  5] Furukawa, N.  Ikeda, H.  Kato, Y.  Sako, H. D-Pen: a digital pen system for public and business enterprises. In Frontiers in Handwriting Recognition 2004: Proceedings of the Ninth International Workshop on Frontiers in Handwriting Recognition \(IWFHR-9 2004  6] Guimbreti  re, F. 2003. Paper augmented digital documents. In Proceedings of the 16th Annual ACM Symposium on User interface Software and Technology Proceedings of the 42nd Hawaii International Conference on System Sciences - 2009 9 UIST ?03 November 2003  7] Holman, D., Vertegaal, R., Altosaar, M., Troje, N., and Johns, D. 2005. Paper windows: interaction techniques for digital paper. In Proceedings of the SIGCHI Conference on Human Factors in Computing Systems \(CHI ?05 Portland, Oregon. New York: ACM, 2005  8] Kiewra, K., DuBois, N., Christian, D., McShane, A Meyerhoffer, M., &amp; Roskelley, D. Note-taking functions and techniques. Journal of Educational Psychology, 83 240-245, 1991  9] Kobayashi, K. Combined effects of note-taking/reviewing on learning and enhancements through interventions: a meta-analytic review. Educational Psychology, 26, 459-477, 2006  10] Liao, C., Guimbreti  re, F., and Hinckley, K. 2005 PapierCraft: a command system for interactive paper. In Proceedings of the 18th Annual ACM Symposium on User interface Software and Technology \(UIST ?05 Seattle, WA. New York: ACM, 2005  11] Livescribe. Pulse Smartpen [electronic device http://www.livescribe.com/, last retrieved May 28, 2008  12] Logitech. io2 Digital Pen [electronic device http://www.logitech.com/index.cfm/mice_pointers/digital_ pen/devices/408&amp;cl=us,en, last retrieved May 28, 2008  13] Norrie, M. C., Signer, B., and Weibel, N. Print-n-link weaving the paper web. In Proceedings of the 2006 ACM Symposium on Document Engineering \(DocEng '06 New York: ACM, 2006  14] Randall, D., Harper, R., and Rouncefield, M Fieldwork for Design: Theory and Practice. London Springer-Verlag, 2007  15] Searle, J. R. Speech Acts: An Essay in the Philosophy of Language. Cambridge: Cambridge Univ. Press, 1969  16] Sellen, A. J. and Harper, R. H. The Myth of the Paperless Office. Cambridge, MA: MIT Press, 2003  17] Signer, B. and Norrie, M. C. 2007. PaperPoint: a paper-based presentation and interactive paper prototyping 


paper-based presentation and interactive paper prototyping tool. In Proceedings of the 1st international Conference on Tangible and Embedded interaction \(TEI ?07 Baton Rouge, Louisiana. New York: ACM, 2007  18] Tanabe, K., Yoshihara, M., Kameya, H., Mori, S Omata, S., Ito, T., Automatic Signature Verification Based on the Dynamic Feature of Pressure. Proceedings of the Sixth International Conference on Document Analysis and Recognition \(ICDAR ?01 Computer Society, 2001   Proceedings of the 42nd Hawaii International Conference on System Sciences - 2009 10 pre></body></html 


The HyspIRI mission utilizes innovative techniques to both reduce the amount of data that must be transmitted to the ground and accommodate the required data volume on the ground The infrastructure and techniques developed by this mission will open the door to future high data volume science missions The designs presented here are the work of the authors and may differ from the current HyspIRI mission baseline A CKNOWLEDGMENTS This research was carried out at the Jet Propulsion Laboratory California Institute of Technology and was sponsored by the Space Grant program and the National Aeronautics and Space Administration R EFERENCES  K W ar\002eld T  V  Houten C Hee g V  Smith S Mobasser B Cox Y He R Jolly C Baker S Barry K Klassen A Nash M Vick S Kondos M Wallace J Wertz Chen R Cowley W Smythe S Klein L Cin-Young D Morabito M Pugh and R Miyake 223Hyspiri-tir mission study 2007-07 002nal report internal jpl document,\224 TeamX 923 Jet Propulsion Laboratory California Institute of Technology 4800 Oak Grove Drive Pasadena CA 91109 July 2007  R O Green 223Hyspiri summer 2008 o v ervie w  224 2008 Information exchanged during presentation  S Hook 2008 Information e xchanged during meeting discussion July 16th  R O Green 223Measuring the earth wi th imaging spectroscopy,\224 2008  223Moore s la w Made real by intel inno v ation 224 http://www.intel.com/technology/mooreslaw/index.htm  T  Doggett R Greele y  S Chein R Castano and B Cichy 223Autonomous detection of cryospheric change with hyperion on-board earth observing-1,\224 Remote Sensing of Environment  vol 101 pp 447\226462 2006  R Castano D Mazzoni N T ang and T  Dogget 223Learning classi\002ers for science event detection in remote sensing imagery,\224 in Proceedings of the ISAIRAS 2005 Conference  2005  S Shif fman 223Cloud detection from satellite imagery A comparison of expert-generated and autmatically-generated decision trees.\224 ti.arc.nasa.gov/m/pub/917/0917 Shiffman  M Griggin H Burk e D Mandl and J Miller  223Cloud cover detection algorithm for eo-1 hyperion imagery,\224 Geoscience and Remote Sensing Symposium 2003 IGARSS 03 Proceedings 2003 IEEE International  vol 1 pp 86\22689 July 2003  V  V apnik Advances in Kernel Methods Support Vector Learning  MIT Press 1999  C Bur ges 223 A tutorial on support v ector machines for pattern recognition,\224 Data Mining and Knowledge Discovery  vol 2 pp 121\226167 1998  M Klemish 223F ast lossless compression of multispectral imagery internal jpl document,\224 October 2007  F  Rizzo 223Lo w-comple xity lossless compression of h yperspectral imagery via linear prediction,\224 p 2 IEEE Signal Processing Letters IEEE 2005  R Roosta 223Nasa jpl Nasa electronic parts and packaging program.\224 http://nepp.nasa.gov/docuploads/3C8F70A32452-4336-B70CDF1C1B08F805/JPL%20RadTolerant%20FPGAs%20for%20Space%20Applications.pdf December 2004  I Xilinx 223Xilinx  Radiation-hardened virtex-4 qpro-v family overview.\224 http://www.xilinx.com/support/documentation data sheets/ds653.pdf March 2008  G S F  Center  223Tdrss o v ervie w  224 http://msp.gsfc.nasa.gov/tdrss/oview.html 7  H Hemmati 07 2008 Information e xchanged during meeting about LaserComm  223W orldvie w-1 224 http://www digitalglobe.com/inde x.php 86/WorldView-1 2008  223Sv albard ground station nor way.\224 http://www.aerospacetechnology.com/projects/svalbard 7 2008  223Satellite tracking ground station 224 http://www.asf.alaska.edu/stgs 2008  R Flaherty  223Sn/gn systems o v ervie w  224 tech rep Goddard Space Flight Center NASA 7 2002  223Geoe ye-1 f act sheet 224 http://launch.geoeye.com/launchsite/about/fact sheet.aspx 2008  L-3 Communications/Cincinnati Electronics Space Electronics 7500 Innovation Way Mason OH 45040 T-720 Transmitter  5 2007 PDF Spec Sheet for the T720 Ku-Band TDRSS Transmitter  L-3 Communications/Cincinnati Electronics Space Electronics 7500 Innovation Way Mason OH 45040 T-722 X-Band  7 2007 PDF Spec Sheet for the T-722  J Smith 07 2008 Information e xchanged during meeting about GDS  J Carpena-Nunez L Graham C Hartzell D Racek T Tao and C Taylor 223End-to-end data system design for hyspiri mission.\224 Jet Propulsion Laboratory Education Of\002ce 2008  J Behnk e T  W atts B K obler  D Lo we S F ox and R Meyer 223Eosdis petabyte archives Tenth anniversary,\224 Mass Storage Systems and Technologies 2005 Proceedings 22nd IEEE  13th NASA Goddard Conference on  pp 81\22693 April 2005 19 


 M Esf andiari H Ramapriyan J Behnk e and E So\002nowski 223Evolving a ten year old data system,\224 Space Mission Challenges for Information Technology 2006 SMC-IT 2006 Second IEEE International Conference on  pp 8 pp.\226 July 2006  S Marle y  M Moore and B Clark 223Building costeffective remote data storage capabilities for nasa's eosdis,\224 Mass Storage Systems and Technologies 2003 MSST 2003 Proceedings 20th IEEE/11th NASA Goddard Conference on  pp 28\22639 April 2003  223Earth science data and information system esdis project.\224 http://esdis.eosdis.nasa.gov/index.html  M Esf andiari H Ramapriyan J Behnk e and E So\002nowski 223Evolution of the earth observing system eos data and information system eosdis\\224 Geoscience and Remote Sensing Symposium 2006 IGARSS 2006 IEEE International Conference on  pp 309\226312 31 2006Aug 4 2006  223Earth science mission operations esmo 224 http://eos.gsfc.nasa.gov/esmo  E Masuoka and M T eague 223Science in v estig ator led global processing for the modis instrument,\224 Geoscience and Remote Sensing Symposium 2001 IGARSS 01 IEEE 2001 International  vol 1 pp 384\226386 vol.1 2001  M Esf andiari H Ramapriyan J Behnk e and E So\002nowski 223Earth observing system eos data and information system eosdis 227 evolution update and future,\224 Geoscience and Remote Sensing Symposium 2007 IGARSS 2007 IEEE International  pp 4005\2264008 July 2007  D McAdam 223The e v olving role of tape in the data center,\224 The Clipper Group Explorer  December 2006  223Sun microsystems announces w orld s 002rst one terabyte tape storage drive.\224 http://www.sun.com/aboutsun/pr/200807/sun\003ash.20080714.2.xml July 2008  223P anasas 227 welcome 224 http://www panasas.com  R Domikis J Douglas and L Bisson 223Impacts of data format variability on environmental visual analysis systems.\224 http://ams.confex.com/ams/pdfpapers/119728.pdf  223Wh y did nasa choose hdf-eos as the format for data products from the earth observing system eos instruments?.\224 http://hdfeos.net/reference/Info docs/SESDA docs/NASA chooses HDFEOS.php July 2001  R E Ullman 223Status and plans for hdfeos nasa's format for eos standard products.\224 http://www.hdfeos.net/hdfeos status HDFEOSStatus.htm July 2001  223Hdf esdis project.\224 http://hdf.ncsa.uiuc.edu/projects/esdis/index.html August 2007  223W elcome to the ogc website 224 http://www.opengeospatial.org 2008  223Open gis Gis lounge geographic information systems.\224 http://gislounge.com/open-gis Christine M Hartzell received her B.S in Aerospace Engineering for Georgia Institute of Technology with Highest Honors in 2008 She is currently a PhD student at the University of Colorado at Boulder where she is researching the impact of solar radiation pressure on the dynamics of dust around asteroids She has spent two summers working at JPL on the data handling system for the HyspIRI mission with particular emphasis on the cloud detection algorithm development and instrument design Jennifer Carpena-Nunez received her B.S in physics in 2008 from the University of Puerto Rico where she is currently a PhD student in Chemical Physics Her research involves 002eld emission studies of nanostructures and she is currently developing a 002eld emission setup for further studies on nano\002eld emitters The summer of 2008 she worked at JPL on the HyspIRI mission There she was responsible for the science analysis of the data handling system speci\002cally de\002ning the data level and processing and determining potential mission collaborations Lindley C Graham is currently a junior at the Massachusetts Institute of Technology where she is working towards a B.S in Aerospace Engineering She spent last summer working at JPL on the data handling system for the HyspIRI mission focusing on developing a data storage and distribution strategy 20 


David M Racek is a senior working toward a B.S in Computer Engineering at Montana State University He works in the Montana State Space Science and Engineering Laboratory where he specializes in particle detector instruments and circuits He spent last summer working at JPL on compression algorithms for the HyspIRI mission Tony S Tao is currently a junior honor student at the Pennsylvania State University working towards a B.S in Aerospace Engineering and a Space Systems Engineering Certi\002cation Tony works in the PSU Student Space Programs Laboratory as the project manager of the OSIRIS Cube Satellite and as a systems engineer on the NittanySat nanosatellite both of which aim to study the ionosphere During his work at JPL in the summer of 2008 Tony worked on the communication and broadcast system of the HyspIRI satellite as well as a prototype Google Earth module for science product distribution Christianna E Taylor received her B.S from Boston University in 2005 and her M.S at Georgia Institute of Technology in 2008 She is currently pursing her PhD at the Georgia Institute of Technology and plans to pursue her MBA and Public Policy Certi\002cate in the near future She worked on the ground station selection for the HyspIRI mission during the summer of 2008 and looks forward to working at JPL in the coming year as a NASA GSRP fellow Hannah R Goldberg received her M.S.E.E and B.S.E from the Department of Electrical Engineering and Computer Science at the University of Michigan in 2004 and 2003 respectively She has been employed at the Jet Propulsion Laboratory California Institute of Technology since 2004 as a member of the technical staff in the Precision Motion Control and Celestial Sensors group Her research interests include the development of nano-class spacecraft and microsystems Charles D Norton is a Principal Member of Technical Staff at the Jet Propulsion Laboratory California Institute of Technology He received his Ph.D in Computer Science from Rensselaer and his B.S.E in Electrical Engineering and Computer Science from Princeton University Prior to joining JPL he was a National Research Council resident scientist His work covers advanced scienti\002c software for Earth and space science modeling with an emphasis on high performance computing and 002nite element adaptive methods Additionally he is leading efforts in development of smart payload instrument concepts He has given 32 national and international keynote/invited talks published in numerous journals conference proceedings and book chapters He is a member of the editorial board of the journal Scienti\002c Programming the IEEE Technical Committee on Scalable Computing a Senior Member of IEEE recipient of the JPL Lew Allen Award and a NASA Exceptional Service Medal 21 


this paper, we only generate the size-2 patterns in the BFS phase. It will be interesting to investigate the impact on the performance if the ?rst phase is stopped at a deeper level Also, the projection is a very ef?cient method for ?nding patterns, especially for parallel implementation of pattern mining algorithms [1]. We plan to adapt the projection ideas into our algorithm and design an ef?cient parallel algorithm for mining maximal hyperclique patterns References 1] R. Agarwal, C. Aggarwal, and V. Prasad. A Tree Projection Algorithm For Generation of Frequent Itemsets. pages 350 371, Feb 2001 2] R. Agrawal, T. Imielinski, and A. Swami. Mining Association Rules between Sets of Items in Large Databases. In Proc. of the ACM SIGMOD Conference on Management of Data, pages 207216,May 1993 3] R. Agrawal and R. Srikant. Fast Algorithms for Mining Association Rules. In Proc. of the 20th Intl Conference on Very LargeData Bases, 1994 4] R. Bayardo. Ef?ciently mining long patterns from databases In Proc. of the ACM SIGMOD Conference, 1998 5] R. Bayardo and R. Agrawal. Mining the Most Interesting Rules. In Proc. of the ACM SIGKDD Conference, 1999 6] D. Burdick, M. Calimlim, and J. Gehrke. Ma?a: AMaximal Frequent Itemset Algorithm for Transactional Databases. In Proc. of IEEE Conf. on Data Engineering, 2001 7] Y. Huang, H. Xiong, W. Wu, and Z. Zhang. A Hybrid Approach for Mining Maximal Hyperclique Patterns. In In Technical Report UTDCS-34-04, Department of computer science, University of Texas - Dallas, 2004 8] J.Han, J.Pei, and Y. Yin. Mining Frequent Patterns without Candidate Generation. In Proc. of the ACM SIGMOD International Conference on Management of Data, 2000 9] M.J.Zaki and C.Hsiao. ChARM: An ef?cient algorithm for closed itemset mining. In Proc. of 2nd SIAM International Conference on Data Mining, 2002 10] R.Rymon. Search through Systematic Set Enumeration. In Proc. Third Intl Conference on Principles of Knowledge Representation and Reasoning, 1992 11] H. Xiong, M. Steinbach, P.-N. Tan, and V. Kumar. HICAP: Hierarchial Clustering with Pattern Preservation. In Proc. of 2004 SIAM International Conference on Data Mining \(SDM 12] H. Xiong, P.-N. Tan, and V. Kumar. Mining Strong Af?nity Association Patterns in Data Set with Skewed Support. In Proc. of the Third IEEE International Conference on Data Mining \(ICDM Proceedings of the 16th IEEE International Conference on Tools with Artificial Intelligence \(ICTAI 2004 1082-3409/04 $20.00  2004 IEEE 





