Multiresolution motion estimation and compensation for video coding Najib BEN AOUN, Maher ELARBI, Chokri BEN AMAR REGIM: REsearch Group on Intelligent Machines National School of Engineers \(ENIS BP 1173, Sfax, 3038, Tunisia Najib.benaoun, Maher.elarbi, Chokri.benamar}@ieee.org Abstract Recently, the quantity of data has known a big evolution especially with the emergence of many video applications over networks such as the videophone and the videoconferencing, and multimedia devices such as the highdefinition TV and the personal digital assistants. So, it was crucial to reduce the quantity of data stored or transmitted by compressing it spatially and temporally. Hence, motion estimation and compensation are employed in video coding systems to remove temporal redundancy while keeping a high visual quality. They are the most important parts of the video coding process since they require the most computational power and the biggest consumption in resources and bandwidth Therefore, many techniques have been developed to estimate motion between successive frames. In this paper, we will present our motion estimation and compensation method applied on the discrete wavelet transform coefficients and based on the block matching algorithm which is the simplest, the most efficient and the most popular technique. Additional techniques are introduced to accelerate the estimation process and improve the prediction quality Keywords-component; Discrete Wavelet Transform; motion estimation; multiresolution domain; video coding I I NTRODUCTION The development of new applications and the spread of Internet all over the world have produced a big quantity of data that must be stored and transmitted. With the increasing capacity of the storage media, the data storage problem was resolved but it remains the transmission problem especially with the limited channel bandwidth Therefore, a need for efficient ways for signals encoding made signal compression central to digital communications That is why, motion estimation and compensation \(ME/MC introduced as a solution to reduce the quantity of data by eliminating the temporal redundancy between adjacent frames in an image sequence. Motion estimation process serves to predict motion between two successive frames and produce the motion vectors \(MVs\displacements between these two frames. So, instead of transmitting two frames, we will send only one frame which is the reference frame, the motion vectors and the residue which is the difference between the current frame and the reconstructed frame by motion compensation. The combination of the motion estimation and motion compensation is a key part of the video coding There are many methods to achieve ME/MC. They can be divided on two such as the statistical methods, the differentials methods as an indirect methods \(applied to features optical flow, and the block based method as a direct ones applied to pixels\matching algorithm \(BMA  effective and popular technique for block based motion estimation. It has been widely adopted in various video coding standards and highly desirable since it maintain an acceptable prediction errors Conventional video coding system applies ME in spatial domain directly on frame without transformation. After that they follow it by a discrete cosine transform \(DCT giving the promising performances of the multiresolution analysis especially the discrete wavelet transform \(DWT which provides a multiresolution expression of the signal with localization in both space and frequency, many methods have been developed to construct a wavelet based video coding system DW T  was integrated in new c odi ng standards such as JPEG2000, MPEG-4, and H.264 For this, we have developed a block based ME/MC method in the wavelet domain. Our method exploits the benefits of DWT and the hierarchical relationship between its subbands  quadtree n wavelet coefficients, especially in the low frequency subband where we find the most significant visual information. This method is consolidated by several techniques to ameliorate the results. With this method we have achieved good results in terms of prediction quality compression performance and computational complexity This paper is organized as follows: in Sec. II, we present the motion estimation principle and techniques focusing on the wavelet domain. Sec. III describes the proposed method. In Sec. IV, we will introduce supplementary techniques which are used to improve our method. In Sec. V, we evaluate our method comparing to some conventional methods. This will prove that our method outperforms conventional method in many terms. Finally, Sec. VI summarizes the key findings and suggests future research possibilities II M OTION ESTIMATION AND COMPENSATION ME/MC are the fundamental parts of video coding systems and form the core of many video processing applications Motion estimation eliminates temporal redundancy from video by exploiting the temporal correlation between successive frames, so that reduces the amount of data to be transmitted or Manuscript received June 14, 2010; revised August 10, 2010 Corresponding author: N. BEN AOUN \(najib.benaoun@ieee.org  112 1 ___________________________________ 978-1-4244-5 900 1 10/$26.00 ©2010 IEEE   ICSP2010 Proceedings  


stored while maintaining sufficient data quality. However, ME extract temporal motion information from video sequences while motion compensation uses this motion information for efficient interframe coding Motion estimation predicts motion between two successive frames to generate a motion vectors \(MVs\which represent the change between them. Consequently, these motion vectors and the prediction error are transmitted instead of the frame itself. With this process, the encoder will have sufficient information to faithfully reproduce the frame sequence Block-based motion estimation is most used method because of their simplicity and performances, which made it the standard approach in the video coding systems. The procedure of BMA is to divide the frames into a block of N×N pixels, to match every block of the current frame \(CF most similar block inside a research window in the reference frame \(RF\nd to generate the motion vector. Consequently for this method, the most important parameters here are the size of the block N and the size of the search window P However, the block matching is based on minimizing a criterion like the Mean Absolu te Error \(MAD\or the Mean Square Error \(MSE\which is the most common block distortion measure for matching two blocks and it provide more accurate block matching. The MV will be applicable to every pixels of the same block which reduce the computational requirement To identify the best corresponding block, the simplest way is to evaluate every block in the reference frame \(exhaustive search, ES\But, although this method find generally the appropriate block, it consumes a high computations time Hence, others fast searching strategies have been developed where search is done in a particular order. There are the Three Step Search \(TSS\ple and Efficient Search SES\he Four Step Search \(4SS\he Adaptive Rood Pattern Search \(ARPS\ and the Diamond Search \(DS\has proved to be the best searching strategies coming close to the ES results. So, the DS was improved in many variant such as the Cross DS \(CDS\e Small CDS \(SCDS\d the New CDS \(NCDS In conventional coding systems such as H.261 and MPEG1/2, BMA is conducted directly on frame which need a large computing power. That is why many studies have been made and proved that is better to transform the frame before executing the ME techniques. However, with the development of new video coding standards, wavelets have received an important interest since it has shown good and effective results. The main idea behind wavelet is to generate a spacefrequency representation focusing only on the spatial frequencies that are most significant to the human eye. This wavelet decomposition is a reversible procedure which is performed by successive approximations of the initial information \(original frame\is process, will improve the coding efficiency since the wavelet coefficients are much correlated and this representation reduce the blocking effects especially in the edges Exploiting the hierarchical relationship between the wavelet coefficients of the different subbands in different levels different hierarchical ME methods were developed which are adapted to the wavelet transformation. The hierarchical relationship means that every wavelet coefficients has four descendants in the lower level of the DWT. So, there are two main ME categories of schemes for DWT based: forward and backward schemes The forward approach consists on conducting the ME in the DWT details subbands of the low level and using it to determine the motion in the higher level subbands coarse-tofine hers like F.G. Meyer, A. Averbuch and R.R Coifman  the forward scheme to propose a ME method with a new pyramid structure. Recent researchers   6  have  devel ope d a backwa r d sc he m e  coarse-to-fine  where they estimated the motion in the finest DWT resolution higher level\n progressively refined the ME by incorporating the finer level. This scheme has proved its superiority over the fo rward scheme The effectiveness of the BMA and the suitability of the DWT in the video coding, has conducted us to develop a block based motion estimation method in the wavelet domain O UR PROPOSED METHOD The proposed method makes use of the wavelet properties to apply the motion estimation directly in the wavelet coefficients. By adopting the fine-to-coarse motion estimation strategy, we have provided a better estimation since the approximation contains the most visual information. The motion vectors of the approximation are directly calculated and then the motion vectors of the details subbands are deducted using hierarchical relationship that exists between the DWT subbands as shown in Fig.1. Working with a 3 level DWT, we compute the m tio v e details subbands o n ectors of th following this formula            012   015        1 With i={1, 2, 3}, j={1, 2, 3, 4}, V i,j x,y\e motion vector for the subband jŽ at the  level iŽ and  i,j is the refinement factor \(equal to 0 if iŽ is equal to 3 Moreover, by predicting the motion only in the approximation which has a small size compared to the original frame, not only the computation requirement is highly reduced and the compression ratio is increasing, but also our method maintains a good prediction quality Figure 1 DWT subbands motion vectors representation 1122 


The BMA is an efficient method for motion estimation which encourages us to use it in our multiresolution based method. Unfortunately, despite their encouraging proprieties and their promising results, the BMA and DWT suffer from some problems. For this, a several improvement techniques have been implemented to surmount these problems and make our method more robust giving best results I MPROVEMENT TECHNIQUES The proposed method outperforms the conventional motion estimation methods, but still having some problems. That is what we drive us to develop some additional techniques to overcome these problems. These techniques are to detect the motion zone to limit the estimation operation to it; to add a sub-pixel precision to the motion vector computing; to shift the frame to better predict the motion; to overlap the frame blocks to correct the motion vector by their neighboring vectors and finally, to refine the prediction by changing the block size and re-predicting the block which are falsely predicted. In this section we will describe these techniques as well as the causes that conduct us to implement them A Temporal Segmentation To accelerate the ME process, we have reduced the motion estimation area with a Background subtraction technique  to detect the zone which contains the movements. This detection is based on a temporal segmentation which allows us to predict motion only on a limited area.  This technique will reduce the computations of the ME process since it assume that the motion vectors of the blocks that are out of the detected area are null. This gain is increased if the movement is concentrated in a very limited area B Sub-pixel precision Block based motion estimation assume that every block have an integer displacement which is, in reality, not true Therefore, to improve the motion estimation and to increase the accuracy of the prediction, we have moved to sub-pixel precision by developing a sub-pixel technique with a bilinear interpolation process. This is done by interposing a line between each two lines and a column between each two columns of the image. Then, ME is applied to the new image With this technique, a motion vector can point in a half or quarter of pixel position or even more. In this case, a block that has a real location at a fraction of pixels will be better predicted. The sub-pixel accuracy can not only increase the accuracy of motion vectors \(augmenting the PSNR of the reconstructed image by more than 2dB\errors, but also filter the image to eliminate noise and rapid changes. That is true that this technique causes a doubling of image size, but it also allow a quick search by minimizing the path to find the corresponding block. For all this, in block based ME methods sub-pixel technique is becoming crucial C Shifting technique The DWT has many advantages of multiresolution domain which has made this space-frequency transformation very useful for the ME. However, the shift-variant property of the DWT caused by the decimation process has made the ME/MC less inefficient in the wavelet domain. Otherwise, there is a big difference between the DWT of an image and the DWT of the same image shifted by one pixel. This property is often seen on the edges of the image, but less important in the lowpass frequencies, which reinforce our choice to conduct ME in the approximation of the DWT To overcome the shift-variant property of the DWT, a shifting technique is used which increase the prediction  ME, we shift t h e fram e in spatial domain by one pixel in all directions. Then, the shifted frames are transformed to the wavelet domain for motion estimation more precise and more real. After calculating a motion vector for the block in every direction, we generate the final motion vector which is the mean of all calculated vectors. This technique has increased the estimation results by smoothing the predicted vectors and reducing the aliasing effect D Overlapping block matching technique Supplementary technique for improving the motion estimation is to overlap the neighboring block to smooth the motions vectors in a way to have a more real prediction. So each motion vector will be the average of itself and the direct neighboring motion vectors This overlapped block matching technique will surmount the false prediction especially the discontinuity at the edges which gives the high frequencies in the estimated image. This is done since the technique is somewhat averaging the possible candidates for each pixel. Hence, this technique will make the visual quality more clear and net E Refinement techniques The basic idea in the BMA is to divide the frame into blocks of a fixed size N×N. This means that all the pixel of the same block has the same displacement. But, this is not true in m o st cases, since there may be different movements in the same block. So, we have divided the blocks which are poorly predicted and re-estimate the motion on them. This will fix the blocks size relatively to the movements and we will use variable block h is technique is ve ry powerful si nce  it corrects the motion vectors by a hierarchical procedure based on modifying the block sizes. It provides a good estimation and tries to minimize the error by taking into account the intra-block movements Another refinement technique is also carried out for our method, which is to move the estimation to a lower level larger resolution\the DWT. This process is not performed for all blocks, but it runs only on poorly predicted blocks. The refinements will re-estimate the motion of the blocks that has an error greater than certain threshold. This technique has given a more accurate estimation prediction quality. We have 1123 


proved that the second refinement technique has better results which have encouraged us to use it in our method Our method gives a good visual estimate that resembles to the estimate in the spatial domain All these techniques have united to improve our methods which make it fast, efficient and accurate. In addition, we can even exploit the human visual system and remove the small variations not recognized by the human eye between the two frames. The motion vectors and the prediction error are encoded after transformed by DWT using the Embedded Zerotree wavelet algorithm \(EZW\s an algorithm that exploit the wavelet structure for an efficient coding E XPERIMENTAL RESULTS In our block based method, we have fixed the DS as a block searching strategy and the MSE as a block matching criterion since it gives better compression performance while not sacrificing image quality. We have also fixed the size of the window to 7 and the size of the block to 2 since we work in the approximation in the third level of the DWT. Furthermore we have integrated all the techniques mentioned previously with a quarter of pixel precision Figure 2 The 129th frame of foremanŽ and the 17th frame of Tennis sequences. \(a\The original image. The estimated image: \(b\DCT domain, \(c\DWT domain, \(d\with our method C ONCLUSION Whatever the motion estimation algorithm considered, a large computing power is needed. That is why many studies have been made to improve and simplify the algorithms. This paper proposes a multiresolution motion estimation and compensation method based on block matching applying in the wavelet coefficients. We will reinforce our method, in the future works with others techniques, such as the spatial segmentation, to identify the moving objects Our method has proved its performance and robustness for several video benchmarks used to test the ME/MC methods such as the "Tennis", "Foreman", "Susie," "Claire" sequences and even the "Football" sequence which contains large movements. The reached results showed large performance in terms of quality of reconstructed frame as shown in Table I\(we have used the PSNR as a criterion to compare the original frame to the reconstructed frame after estimation\and also in terms of compression ratio. All this, amounts to the accuracy of the estimation and the corrections made for the motion vectors A CKNOWLEDGMENT The authors would like to acknowledge the financial support of this work by grants from the General Direction of Scientific Research \(DGRST\Tunisia, under the ARUB program TABLE I PSNR OF THE RECONSTRUCTED IMAGE Sequences Methods Tennis Foreman Susie Claire  Spatial domain 34.3983 33.5550 36.6450 37.7992 DCT domain 28.2568 31.3646 31.2833 33.0233 Conventional DWT 31.7586 31.2889 33.1613 32.5908 Proposed method 35.6263 34.6025 38.3417 38.5418 R EFERENCES  H. Gharavi and M. Mi lls Block Matching Motion Estimation Algorithms: New Results IEEE Trans. Circuits and Systems for Video Technology, Vol. 37, pp. 649-651, 1990  P. C. Shenolikar, S P. Narote, Motion estim ation on DW T based i m age sequence International Journal of Recent Trends in Engineering Vol 2, No. 4, November 2009  Aroh Barjatya Block Matching Algorithms For Motion Estimation  Student Member, IEEE, DIP 6620 Spring 2004 Final Project Paper  François G Mey er Am ir Averbuch, and Ronald R. C o if m a n   Motion compensation of wavelet coefficients for very low bit rate video coding  Proc. IEEE Inter. Conference on Image Processing, Vol. 3, pp. 638641, 1997 Our experiments verify the superiority of the proposed algorithm, not only versus several other well-known algorithms in the frequency and the multiresolution domains but also versus the ME/MC method in the spatial domain Moreover, it is faster than other methods and the compression ratio is highly increased because it works on the approximation level of the DWT, which is 8 times smaller than the original image  A. Lund m a rk, H. Li, and R. Forchheim er   Motion vector certainty reduces bit rate in backward motion estimation video coding In Proc of SPIE Visual Comm. and Image Processing, pages 95…104, 2000  Yufei Yuan and Mrinal K Mandal  L ow-Band-Shifted Hierarchical  Backward Motion Estimation and Compensation for Wavelet-Based Video Coding ICVGIP02 2002  Z Zivkovic and F. van der Heijden, Efficient adaptive density  estimation per image pixel for the task of background subtraction Pattern Recognition Letters 27\(7\:773…780, May 2006 The Fig.2 shows an increase in visual quality of the image estimate. We can observe that when applying motion estimation on the transformed DCT, block effects appeared On the other hand, using the classical DWT domain, there are also blocks effects, despite its superiority to the DCT domain  M G. Arvanitidou, et al, Global m otion estim ation using variable block sizes and its application to object segmentation,Ž Workshop on Image Analysis for Multimedia Interactive Services, 2009 1124 


byte packets are transmitted from source to destination. The results are shown in Fig. 5a. The ETX throughput decrease dramatically as the number of hops increases. While OMB with dual paths \(l == 2 worse than MCMP \(two radios l == 3 scheduling two non-adjacent paths \(link 1 and link 3 in parallel while link 2 is idle and reversely, link 2 is active in the next time slot while link 1 and link 3 are idle, link 1 and link 3 do not interference each other B. Impact of Distance V Because the backbone nodes are equipped with single radio only, it is obvious that the distance between two adjacent links will affect the performance of data transmission. We adjust the distance from 100 meter to 700 meters to see the reaction of end-to-end throughput. As showed in the Fig. 5b both OMB \(l == 2 l == 3 when the distance V increases. After V reaches over the interference range \(500 meters increases sharply. Also, only OMB with triple links \(l == 3 performs better than MCMP, which does not be affected by distance V thanks to doubly-equipped radios   35 lt;r - - ~ - - ~ - - -&lt _. _  _. "'*-. -. *. _. _ 25Or 1 2 OMB \(1=3 15 - - ~ - - ~- - -&lt;r - - ~ - - ~- 10 d. Data Size \(500Mbytes _ oL----'-_-'-------'-_--'--_"-----l 100 200 300 400 500 600 700 Distance V \(meter ol----'-_-'------'-_--'--_ 100 200 300 400 500 600 700 Disance V \(meter b. Impact of Distance V jJ200 i i 2 150  E  100 f lt;:\( 50 _ 15 20 25 30 Slot Size \(msec j 20 ._ -*.~j. 18 116 ~ __ -~ ---&lt;r - - -0- - _ Jl 14  MCMP \(1024 bytes 12 __ OMB \(1=3,1024 bytes 10 C'-.....==.OM==B\(::1=3=:;:,1=536=b=ytes 10 4 5 Path length \(hop o l----'-_-'------'-_--'--_ 100 200 300 400 500 600 700 Distance V \(meter 22 


22 a. Impact of Path Length lt;r - - ~ - - ~ - - -&lt 5 _. _. ,*.-._.*. _. - ..... _.",*- ._*. _._ c. Data Size \(100Mbytes 20 25 30 _. - .*._. _. -41-. _. - ...... _ ._ amp;-ETX 20 ~ MCMP \(2 radios  OMB\(I=2 OMB \(1=3 10 15 25 10 e. Impact of Slot Size Fig. 4. Simulation results 6] V. D. Park and M. S. Corson, "A highly adaptive distributed routing algorithm for mobile wireless networks," in INFOCOM, 1997, pp. 14051413 7] D. B. Johnson and D. A. Maltz, "Dynamic source routing in ad hoc wireless networks," in Mobile Computing, Imielinski and Korth, Eds Kluwer Academic Publishers, 1996, vol. 353. [Online]. Available citeseer.ist.psu.edu/johnson96dynamic.html 8] S. Lee and M. perla, "Smr: split multipath routing with maximally disjoint paths in ad hoc networks," in ICC, 200 1 9] Z. Ye, S. V. Krishnamurthy, and S. K. Tripathi, "A framework for reliable routing in mobile ad hoc networks," in INFOCOM, 2003 10] M. K. Marina and M. K. Das, "On-demand multi path distance vector routing in ad hoc networks," in ICNP, 2001, pp. 14-23 11] D. S. J. D. Couto, D. Aguayo, J. C. Bicket, and R. Morris, "A highthroughput path metric for multi-hop wireless routing," in MOBICOM 2003, pp. 134-146 12] W.-H. Tam and Y.-C. Tseng, "Joint multi-channel link layer and multipath routing design for wireless mesh networks," in INFOCOM, 2007 pp. 2081-2089 13] C. T. Hieu and C. S. Hong, "Securely deliver data by multi-path routing scheme in wireless mesh networks," in International Conference on Computational Science \(4 14] D. Cansever, A. Michelson, and A. Levesque, "Quality of service support in mobile ad-hoc ip networks," in Military Communications Conference Proceedings, 1999. MILCOM 1999. IEEE, 1999, pp. 30-34 15] The Network Simulator Ns-2. [Online]. Available http://www.isLedu/nsnamlns/index.html V. CONCLUSIONS In this paper, we have shown that the WMNs can achieve good performance and utilize scheduling availability with only one radio card by carefully design multi-path routing protocol with multi-channel capacity. When the packet loss rate is high or the amount of data is large, the number of disjoint paths also needs to be increased on-demand to reduce transmission time The proposed protocol especially works very well with bigger amount of data as well as bigger data packet size. Although the proposed protocol is affected by interference due to the chronically single interface problem, the experiment results show that OMB performs very well with triple disjoint links thanks for effective time scheduling D. Impact of Slot Size In time division method, slot size can influence the performance of routing protocol. If the length of slot size is too short, the channel switching overhead becomes considerable and degrades the system performance. In contrary, longer slot size may result in increased end-to-end delay as well as the buffer requirement at each node. To find the balance value we vary the slot size from 10 milliseconds to 35 milliseconds with packet size of 1024 bytes and 1536 bytes. In the Fig. 5e the results show that OMB \(I == 3 MCMP in both cases: 1024 bytes and 1536 bytes packet size The figure also shows that at slot size of 30 milliseconds, the OMB reaches the best aggregate throughput while this case 


OMB reaches the best aggregate throughput while this case happens in MCMP with 25 milliseconds slot ACKNOWLEDGMENT This research was supported by the MKE under the ITRC support program supervised by the IITA" \(IITA-2008-\(C10900801-0002  Dr. CS Hong is corresponding author REFERENCES 1] I. F. Akyildiz, X. Wang, and W. Wang, "Wireless mesh networks: a survey," Computer Networks, vol. 47, no. 4, pp. 445-487, 2005 2] S. Keshav, "A control-theoretic approach to flow control," in SIGCOMM 1991, pp. 3-15 3] T. Goff, N. B. Abu-Ghazaleh, D. S. Phatak, and R. Kahvecioglu Preemptive routing in ad hoc networks," in MOBICOM, 2001, pp. 4352 4] A. Adya, P. Bahl, J. Padhye, A. Wolman, and L. Zhou, "A multi-radio unification protocol for ieee 802.11 wireless networks," in BROADNETS 2004, pp. 344-354 5] R. Draves, 1. Padhye, and B. Zill, "Routing in multi-radio, multi-hop wireless mesh networks," in MOBICOM, 2004, pp. 114-128 C. Impact of Data Size As discussed above, the proposed scheme works very well with the big data size needed to transmit in a communication session. First, we send a 100 Mbytes data with the incensement of distance V as the same previous model. Next, we increase the data size to 500 Mbytes and compare with the transmission time of the first case. Even though the shapes of line in Fig 5c and Fig. 5d are almost same, we can easily figure out that the needed time to transfer 500 Mbytes data is considerable larger than five times of one of 100 Mbytes. This evaluation proves that our declaration is reasonable pre></body></html 


7  pre></body></html 


10   The function values needed to interpolate data or otherwise develop prelters are 1\(1 1 0 1 1  1 2  1  1 2  3 s 3 10 and !2  1 2   4 s 6 5  Orthonormal basis elements for the left and right boundaries of a data set are constructed by keeping the right and left half of !1, respectively, and normalizing; that is O1 s 2!1"[0>1] and !U1 s 2!1"[1>0 respectively. Their decomposition lters reect this normalization in all but the entries corresponding to dilated versions of these functions The multiwavelet 1> #2 the GHM scaling vector is illustrated in Figure 11 and satises the equation \(5 trix coecients g2 


0 120 0 s 2 20  g1  3 s 2 20 9 20 3 10 9 s 2 20  g0 s 2 2 9 20 0 9 s 2 20  g1  3 s 2 20 1 20 310 s 2 20   Only truncated and normalized versions of the symmetric #1 are needed at the boundaries O1 s 


2#1"[0>1] and #U1 s 2#1"[1>0 on the left and right, respectively 1 #2 Figure 11: The GHM multiwavelet Proceedings of the 42nd Hawaii International Conference on System Sciences - 2009 5 2.2 Approximation-Order-4 Basis The groundwork for this basis was laid in [2 although the scaling vector was not explicitly constructed in that paper. The scaling vector  1> !2> !3> !4 approximation order 4. The Y0 space that it generates also includes the spline space S03\(Z one may notice that !2 and !3 are quadratic and cubic polynomials, respectively, restricted to [0> 1 and normalized 1 2 3 4 Figure 12: An approximation-order-4 scaling vector The scaling vector satises the dilation equation \(3 ing vector. However, the four 4  4 matrix coecients are too large to provide here, and are available instead from the author?s website www.wku.edu/?bruce.kessler, as are the function values needed to interpolate data or otherwise develop prelters As before, orthonormal basis elements for the left and right boundaries of a data set are constructed by keeping the right and left half of !1 respectively, and normalizing; that is O1 s 2!1"[0>1] and !U1 s 2!1"[1>0 respectively. Their decomposition lters reect this normalization in all but the entries corresponding to dilated versions of these functions The multiwavelet 1> #2> #3> #4 ated with this scaling vector is illustrated in Fig 


ure 13, with the matrix solutions to the dilation equation \(5 Again, only truncated and normalized versions of the symmetric #1 are needed at the boundaries O1 s 2#1"[0>1] and #U1 s 2#1"[1>0 on the left and right, respectively 1 2 3 4 Figure 13: The multiwavelet associated with the scaling vector in Section 2.2 2.3 Dierentiable Basis with Approximation Order 4 Each of the bases shown in the previous sections include a continuous spline space, but the Y0 space in each case also contains much more than that With each basis, Y0 will also contain functions that look like the left and right halves of the !1 function in that particular scaling vector. Hence, each approximation space, even at the lowest resolution will contain functions that have at least one nondierentiable ?corner?. This may not be desirable Proceedings of the 42nd Hawaii International Conference on System Sciences - 2009 6 especially if the points of interest in the original signal happen to fall on these corners at every resolution \(for example, at the midpoint of the data set basis \(i.e., has no corners A scaling vector was developed by the author in 6] that has approximation order 4, and generates a space that contains the spline space S13\(Z is, the space of piecewise cubic polynomials that are both continuous and dierentiable at the integer knots. This scaling vector 1> !2> !3> !4 is illustrated in Figure 14. As with the basis discussed in Section 2.2, the matrix coecients that satisfy the dilation equation \(3 are available on the author?s website, as are the function values needed to interpolate data or otherwise develop prelters. Left- and right-hand versions of both !1 and 2 can be created to handle bounded data 


1 !2 3 !4 Figure 14: A digerentiable approximation-order-4 scaling vector The multiwavelet 1> #2> #3> #4 ated with this scaling vector is illustrated in Figure 15, with the matrix solutions to the dilation equation \(5 The website also contains the matrices needed for lter construction of the left and right boundary wavelets 1 #2 3 #4 Figure 15: The multiwavelet associated with the scaling vector in Section 2.3 3. Pattern Matching The premise behind using wavelets for pattern matching is that the wavelet decomposition for the pattern for which you are searching and for the pattern added to data sampled from a polynomial of degree less than the approximation order of your scaling vector will be equal. For example, the wavelet decompositions for both data sets shown in Figure 16 will be identical when using either of the bases discussed in Sections 2.2 and 2.3. It is necessary that the pattern not be in the lowest-resolution approximation space, so that it will not have a wavelet decomposition with only 0 coecients. This problem is rare, but if it occurs, it is remedied by either continuing the decomposition to an even lowerresolution space, or by using a dierent scaling vector of lower approximation order In most cases, the pattern will not be overlaid upon perfectly polynomial data, and so, the wavelet decompositions will not match exactly. However, if the pattern is prominent enough in the signal so that the root mean square error \(UPVH new decomposition {gl} when compared to the decomposition {gl } of the original pattern, as dened Proceedings of the 42nd Hawaii International Conference on System Sciences - 2009 7 by UPVH vuuuut QX l=1 gl  gl Q 


is suciently small, then the pattern will still be detected Figure 16: Pattern data \(top data obscured by cubic polynomial data bottom When using a single scaling function and wavelet are used in applications, each successively smoother approximation of the data stretches the support of the basis functions, eectively drawing more data from outside the region where the pattern actually occurs. By using the scaling vectors and multiwavelets mentioned in Section 2, we are able to analyze data on a bounded region, and ignore data outside of that region 3.1 When to Use Wavelets Wavelet decompositions can be used to nd patterns in any type of data, but there are no advantages to using them for exact pattern matching. For example, if searching for the word ?the? in a text le or in packet data, we have to search for the exact ASCII values 116, 104, and 101 in succession Changing those values, even by a constant amount changes the word. Also, to apply the wavelet bases mentioned in Section 2, we need 2q + 1 data values for some integer q A 1 for the DGM and the approximation-order-4 basis, and 2q+2 data values for some integer q A 1 for the basis in Section 2.3 so we would have to pad the target pattern with spaces. This type of search can be conducted much more eciently using other search methods, such as Bloom lters, etc However, for quantitative data like packet trac dependent upon time, multiwavelets have the potential to spot patterns that are not immediately noticable to the human eye, such as in the bottom graph of Figure 16. The following section gives an example of how multiwavelets can be used to detect a ?low and slow? pattern caused by data exltration 3.2 Trac Analysis Example Suppose that we have a corrupted computer and we are aware through previous experience that this particular piece of malevolent code tends to sneak? data out under the ?TCP? protocol in the following pattern a single packet of size 256 bytes, followed approximately 1 second later by another packet of size 512 bytes one second later, four packets of size 256 bytes are sent with a quarter second gap between 


the packets, and one quarter-second later, three packets of size 512 bytes are sent, followed one-quarter second later by one packet of size 256 bytes The accumulated bytes sent with respect to time in seconds are shown in Figure 17 Total Bytes Seconds Figure 17: Accumulated bytes for the example pattern The packets described above have been inserted into a set of network trac packet collected from the author?s laptop over roughly 4 minutes of usage starting at w = 240 seconds. The total accumulated outgoing bytes are illustrated in Figure 18. To apply the basis looking for this specic pattern, we Proceedings of the 42nd Hawaii International Conference on System Sciences - 2009 8 accumulate the bytes on quarter-second intervals and generate a wavelet decomposition for a sliding 4-second window, which is compared to the original pattern?s decomposition with the UPVH. The UPVH for the dierent starting times are shown in Figure 19. Note the low value of the UPVH at w = 240 seconds, indicating a close match to our target pattern at that time Total Bytes Seconds Figure 18: Accumulated outgoing bytes of a sample usage period plus the packets in our pattern UPVH Seconds Figure 19: UPVH values \(less than 50 blocks of data with digerent starting times Note the low value of the UPVH at w = 240 seconds, indicating a close match to our target pattern at that time In fairness, this method of nding patterns has many of the same weaknesses found in other signature-matching approaches. The pattern has to be known ahead of time, which means that this detection scheme would still be vulnerable to rst-time attacks. Also, a completely innocuous data ow occurring with very similiar timing and quantities as our pattern will still cause a low UPVH value, possibly causing a false-positive alert. We do claim 


however, that we have a greater capacity for nding patterns in quantiable amounts that are obscured by standard network trac. Also, we can adjust the sensitivity of the search without changing the signature for which we are searching, by adjusting the threshold of the UPVH?s for which an alert is issued. Thus, statistical techniques and adaptive learning can be used to help develop optimal threshold levels for a particular pattern 4. Conclusion Wavelet analysis holds an as-of-yet untapped potential for analyzing usage patterns in network trac ows, due to their ability to lter out data up to a given approximation order. Neither simple character searches nor Fourier analysis has this capability. Also, while Fourier analysis generally gives only frequency information within an analysis window, wavelet analysis gives some amount of both frequency information and the location of that frequency activity. The additional information comes at no additional computational costs, since the bases are generally applied by convolving matrix lters over the data \(repeated matrix multiplication over sliding blocks of data tiwavelet bases introduced in this document should prove to be particularly useful in pattern-matching applications, due to their short support \(that is, non-zero only over a small interval the inclusion of splines in the approximation spaces instead of just polynomials, and the ability to use them on time series with left and right boundaries The author is currently working with computer scientists at the CyberDefense Lab \(CDL at Western Kentucky University to develop software that will utilize these bases in network security, intrusion-detection, and data-extrusion applications. Once developed, we will study the eectiveness of this type of analysis in detecting malicious behavior as compared to the more commonly used techniques, with the hope of improving detection capabilities while maintaining a low false-positive rate. The software will initially be tested in the CDL?s sandbox while running attacks from its attack library with various background usage scripts being implemented, but will eventually move to less controlled network environments Acknowledments: This work supported in part by the NACMAST consortium under contract 


EWAGSI-07-SC-0003 Proceedings of the 42nd Hawaii International Conference on System Sciences - 2009 9 References 1] C. K. Chui and Q. T. Jiang, ?Multivariate Balanced Vector-Valued Renable Functions?, in: V. W. Haussmann, K. Jetter, M Reimer, and J. Sto¨ckler \(Eds velopment in Multivariate Approximation, vol 145, Birkha¨user Verlag, Basel \(2003 102 2] G. Donovan, J. Geronimo, and D. Hardin Intertwining Multiresolution Analyses and the Construction of Piecewise Polynomial Wavelets?, SIAM J. Math. Anal. 27\(6 1996 1791?1815 3] J. Geronimo, D. Hardin, and P. Massopust Fractal Functions and Wavelet Expansions Based on Several Scaling Functions?, J. Approx. Theory 78:3 \(1994 4] D. Hardin and B. Kessler, ?Orthogonal Macroelement Scaling Vectors and Wavelets in 1-D?, Arab. J. Sci. Eng. Sect. C \(Theme Issue: Wavelet and Fractal Methods in Science and Engineering: Part 1 2003 5] D. Hardin and D. Roach, ?Multiwavelet Prelters I: Orthogonal Prelters Preserving Approximation Order s  2?, IEEE Trans. Circuits Syst. II: Analog Digital Signal Proces 45\(8 1998 6] B. Kessler, ?An Orthogonal Scaling Vector Generating a Space of F1 Cubic Splines Using Macroelements?, J. Concrete Appl. Math Special Issue on Wavelets and Applications 4\(4 2006 7] J. Lebrun and M. Vetterli, ?Balanced Multiwavelet Theory and Design?, IEEE Trans. Signal Process. 46\(4 1998 8] J. Lebrun and M. Vetterli, ?High Order Balanced Multiwavelets?, in Proc. IEEE Int. Conf. Acoust., Speech, Signal Processing ICASSP May 1998 1532 9] J. Lian, ?Armlets and Balanced Multiwavelets Flipping Filter Construction?, IEEE Trans Signal Process. 53\(5 2005 10] I. W. Selesnick, ?Balanced GHM-like Multiscaling Functions?, IEEE Signal Process. Lett 6\(5 1999 


Proceedings of the 42nd Hawaii International Conference on System Sciences - 2009 10 


The HyspIRI mission utilizes innovative techniques to both reduce the amount of data that must be transmitted to the ground and accommodate the required data volume on the ground The infrastructure and techniques developed by this mission will open the door to future high data volume science missions The designs presented here are the work of the authors and may differ from the current HyspIRI mission baseline A CKNOWLEDGMENTS This research was carried out at the Jet Propulsion Laboratory California Institute of Technology and was sponsored by the Space Grant program and the National Aeronautics and Space Administration R EFERENCES  K W ar\002eld T  V  Houten C Hee g V  Smith S Mobasser B Cox Y He R Jolly C Baker S Barry K Klassen A Nash M Vick S Kondos M Wallace J Wertz Chen R Cowley W Smythe S Klein L Cin-Young D Morabito M Pugh and R Miyake 223Hyspiri-tir mission study 2007-07 002nal report internal jpl document,\224 TeamX 923 Jet Propulsion Laboratory California Institute of Technology 4800 Oak Grove Drive Pasadena CA 91109 July 2007  R O Green 223Hyspiri summer 2008 o v ervie w  224 2008 Information exchanged during presentation  S Hook 2008 Information e xchanged during meeting discussion July 16th  R O Green 223Measuring the earth wi th imaging spectroscopy,\224 2008  223Moore s la w Made real by intel inno v ation 224 http://www.intel.com/technology/mooreslaw/index.htm  T  Doggett R Greele y  S Chein R Castano and B Cichy 223Autonomous detection of cryospheric change with hyperion on-board earth observing-1,\224 Remote Sensing of Environment  vol 101 pp 447\226462 2006  R Castano D Mazzoni N T ang and T  Dogget 223Learning classi\002ers for science event detection in remote sensing imagery,\224 in Proceedings of the ISAIRAS 2005 Conference  2005  S Shif fman 223Cloud detection from satellite imagery A comparison of expert-generated and autmatically-generated decision trees.\224 ti.arc.nasa.gov/m/pub/917/0917 Shiffman  M Griggin H Burk e D Mandl and J Miller  223Cloud cover detection algorithm for eo-1 hyperion imagery,\224 Geoscience and Remote Sensing Symposium 2003 IGARSS 03 Proceedings 2003 IEEE International  vol 1 pp 86\22689 July 2003  V  V apnik Advances in Kernel Methods Support Vector Learning  MIT Press 1999  C Bur ges 223 A tutorial on support v ector machines for pattern recognition,\224 Data Mining and Knowledge Discovery  vol 2 pp 121\226167 1998  M Klemish 223F ast lossless compression of multispectral imagery internal jpl document,\224 October 2007  F  Rizzo 223Lo w-comple xity lossless compression of h yperspectral imagery via linear prediction,\224 p 2 IEEE Signal Processing Letters IEEE 2005  R Roosta 223Nasa jpl Nasa electronic parts and packaging program.\224 http://nepp.nasa.gov/docuploads/3C8F70A32452-4336-B70CDF1C1B08F805/JPL%20RadTolerant%20FPGAs%20for%20Space%20Applications.pdf December 2004  I Xilinx 223Xilinx  Radiation-hardened virtex-4 qpro-v family overview.\224 http://www.xilinx.com/support/documentation data sheets/ds653.pdf March 2008  G S F  Center  223Tdrss o v ervie w  224 http://msp.gsfc.nasa.gov/tdrss/oview.html 7  H Hemmati 07 2008 Information e xchanged during meeting about LaserComm  223W orldvie w-1 224 http://www digitalglobe.com/inde x.php 86/WorldView-1 2008  223Sv albard ground station nor way.\224 http://www.aerospacetechnology.com/projects/svalbard 7 2008  223Satellite tracking ground station 224 http://www.asf.alaska.edu/stgs 2008  R Flaherty  223Sn/gn systems o v ervie w  224 tech rep Goddard Space Flight Center NASA 7 2002  223Geoe ye-1 f act sheet 224 http://launch.geoeye.com/launchsite/about/fact sheet.aspx 2008  L-3 Communications/Cincinnati Electronics Space Electronics 7500 Innovation Way Mason OH 45040 T-720 Transmitter  5 2007 PDF Spec Sheet for the T720 Ku-Band TDRSS Transmitter  L-3 Communications/Cincinnati Electronics Space Electronics 7500 Innovation Way Mason OH 45040 T-722 X-Band  7 2007 PDF Spec Sheet for the T-722  J Smith 07 2008 Information e xchanged during meeting about GDS  J Carpena-Nunez L Graham C Hartzell D Racek T Tao and C Taylor 223End-to-end data system design for hyspiri mission.\224 Jet Propulsion Laboratory Education Of\002ce 2008  J Behnk e T  W atts B K obler  D Lo we S F ox and R Meyer 223Eosdis petabyte archives Tenth anniversary,\224 Mass Storage Systems and Technologies 2005 Proceedings 22nd IEEE  13th NASA Goddard Conference on  pp 81\22693 April 2005 19 


 M Esf andiari H Ramapriyan J Behnk e and E So\002nowski 223Evolving a ten year old data system,\224 Space Mission Challenges for Information Technology 2006 SMC-IT 2006 Second IEEE International Conference on  pp 8 pp.\226 July 2006  S Marle y  M Moore and B Clark 223Building costeffective remote data storage capabilities for nasa's eosdis,\224 Mass Storage Systems and Technologies 2003 MSST 2003 Proceedings 20th IEEE/11th NASA Goddard Conference on  pp 28\22639 April 2003  223Earth science data and information system esdis project.\224 http://esdis.eosdis.nasa.gov/index.html  M Esf andiari H Ramapriyan J Behnk e and E So\002nowski 223Evolution of the earth observing system eos data and information system eosdis\\224 Geoscience and Remote Sensing Symposium 2006 IGARSS 2006 IEEE International Conference on  pp 309\226312 31 2006Aug 4 2006  223Earth science mission operations esmo 224 http://eos.gsfc.nasa.gov/esmo  E Masuoka and M T eague 223Science in v estig ator led global processing for the modis instrument,\224 Geoscience and Remote Sensing Symposium 2001 IGARSS 01 IEEE 2001 International  vol 1 pp 384\226386 vol.1 2001  M Esf andiari H Ramapriyan J Behnk e and E So\002nowski 223Earth observing system eos data and information system eosdis 227 evolution update and future,\224 Geoscience and Remote Sensing Symposium 2007 IGARSS 2007 IEEE International  pp 4005\2264008 July 2007  D McAdam 223The e v olving role of tape in the data center,\224 The Clipper Group Explorer  December 2006  223Sun microsystems announces w orld s 002rst one terabyte tape storage drive.\224 http://www.sun.com/aboutsun/pr/200807/sun\003ash.20080714.2.xml July 2008  223P anasas 227 welcome 224 http://www panasas.com  R Domikis J Douglas and L Bisson 223Impacts of data format variability on environmental visual analysis systems.\224 http://ams.confex.com/ams/pdfpapers/119728.pdf  223Wh y did nasa choose hdf-eos as the format for data products from the earth observing system eos instruments?.\224 http://hdfeos.net/reference/Info docs/SESDA docs/NASA chooses HDFEOS.php July 2001  R E Ullman 223Status and plans for hdfeos nasa's format for eos standard products.\224 http://www.hdfeos.net/hdfeos status HDFEOSStatus.htm July 2001  223Hdf esdis project.\224 http://hdf.ncsa.uiuc.edu/projects/esdis/index.html August 2007  223W elcome to the ogc website 224 http://www.opengeospatial.org 2008  223Open gis Gis lounge geographic information systems.\224 http://gislounge.com/open-gis Christine M Hartzell received her B.S in Aerospace Engineering for Georgia Institute of Technology with Highest Honors in 2008 She is currently a PhD student at the University of Colorado at Boulder where she is researching the impact of solar radiation pressure on the dynamics of dust around asteroids She has spent two summers working at JPL on the data handling system for the HyspIRI mission with particular emphasis on the cloud detection algorithm development and instrument design Jennifer Carpena-Nunez received her B.S in physics in 2008 from the University of Puerto Rico where she is currently a PhD student in Chemical Physics Her research involves 002eld emission studies of nanostructures and she is currently developing a 002eld emission setup for further studies on nano\002eld emitters The summer of 2008 she worked at JPL on the HyspIRI mission There she was responsible for the science analysis of the data handling system speci\002cally de\002ning the data level and processing and determining potential mission collaborations Lindley C Graham is currently a junior at the Massachusetts Institute of Technology where she is working towards a B.S in Aerospace Engineering She spent last summer working at JPL on the data handling system for the HyspIRI mission focusing on developing a data storage and distribution strategy 20 


David M Racek is a senior working toward a B.S in Computer Engineering at Montana State University He works in the Montana State Space Science and Engineering Laboratory where he specializes in particle detector instruments and circuits He spent last summer working at JPL on compression algorithms for the HyspIRI mission Tony S Tao is currently a junior honor student at the Pennsylvania State University working towards a B.S in Aerospace Engineering and a Space Systems Engineering Certi\002cation Tony works in the PSU Student Space Programs Laboratory as the project manager of the OSIRIS Cube Satellite and as a systems engineer on the NittanySat nanosatellite both of which aim to study the ionosphere During his work at JPL in the summer of 2008 Tony worked on the communication and broadcast system of the HyspIRI satellite as well as a prototype Google Earth module for science product distribution Christianna E Taylor received her B.S from Boston University in 2005 and her M.S at Georgia Institute of Technology in 2008 She is currently pursing her PhD at the Georgia Institute of Technology and plans to pursue her MBA and Public Policy Certi\002cate in the near future She worked on the ground station selection for the HyspIRI mission during the summer of 2008 and looks forward to working at JPL in the coming year as a NASA GSRP fellow Hannah R Goldberg received her M.S.E.E and B.S.E from the Department of Electrical Engineering and Computer Science at the University of Michigan in 2004 and 2003 respectively She has been employed at the Jet Propulsion Laboratory California Institute of Technology since 2004 as a member of the technical staff in the Precision Motion Control and Celestial Sensors group Her research interests include the development of nano-class spacecraft and microsystems Charles D Norton is a Principal Member of Technical Staff at the Jet Propulsion Laboratory California Institute of Technology He received his Ph.D in Computer Science from Rensselaer and his B.S.E in Electrical Engineering and Computer Science from Princeton University Prior to joining JPL he was a National Research Council resident scientist His work covers advanced scienti\002c software for Earth and space science modeling with an emphasis on high performance computing and 002nite element adaptive methods Additionally he is leading efforts in development of smart payload instrument concepts He has given 32 national and international keynote/invited talks published in numerous journals conference proceedings and book chapters He is a member of the editorial board of the journal Scienti\002c Programming the IEEE Technical Committee on Scalable Computing a Senior Member of IEEE recipient of the JPL Lew Allen Award and a NASA Exceptional Service Medal 21 


this paper, we only generate the size-2 patterns in the BFS phase. It will be interesting to investigate the impact on the performance if the ?rst phase is stopped at a deeper level Also, the projection is a very ef?cient method for ?nding patterns, especially for parallel implementation of pattern mining algorithms [1]. We plan to adapt the projection ideas into our algorithm and design an ef?cient parallel algorithm for mining maximal hyperclique patterns References 1] R. Agarwal, C. Aggarwal, and V. Prasad. A Tree Projection Algorithm For Generation of Frequent Itemsets. pages 350 371, Feb 2001 2] R. Agrawal, T. Imielinski, and A. Swami. Mining Association Rules between Sets of Items in Large Databases. In Proc. of the ACM SIGMOD Conference on Management of Data, pages 207–216,May 1993 3] R. Agrawal and R. Srikant. Fast Algorithms for Mining Association Rules. In Proc. of the 20th Int’l Conference on Very LargeData Bases, 1994 4] R. Bayardo. Ef?ciently mining long patterns from databases In Proc. of the ACM SIGMOD Conference, 1998 5] R. Bayardo and R. Agrawal. Mining the Most Interesting Rules. In Proc. of the ACM SIGKDD Conference, 1999 6] D. Burdick, M. Calimlim, and J. Gehrke. Ma?a: AMaximal Frequent Itemset Algorithm for Transactional Databases. In Proc. of IEEE Conf. on Data Engineering, 2001 7] Y. Huang, H. Xiong, W. Wu, and Z. Zhang. A Hybrid Approach for Mining Maximal Hyperclique Patterns. In In Technical Report UTDCS-34-04, Department of computer science, University of Texas - Dallas, 2004 8] J.Han, J.Pei, and Y. Yin. Mining Frequent Patterns without Candidate Generation. In Proc. of the ACM SIGMOD International Conference on Management of Data, 2000 9] M.J.Zaki and C.Hsiao. ChARM: An ef?cient algorithm for closed itemset mining. In Proc. of 2nd SIAM International Conference on Data Mining, 2002 10] R.Rymon. Search through Systematic Set Enumeration. In Proc. Third Int’l Conference on Principles of Knowledge Representation and Reasoning, 1992 11] H. Xiong, M. Steinbach, P.-N. Tan, and V. Kumar. HICAP: Hierarchial Clustering with Pattern Preservation. In Proc. of 2004 SIAM International Conference on Data Mining \(SDM 12] H. Xiong, P.-N. Tan, and V. Kumar. Mining Strong Af?nity Association Patterns in Data Set with Skewed Support. In Proc. of the Third IEEE International Conference on Data Mining \(ICDM Proceedings of the 16th IEEE International Conference on Tools with Artificial Intelligence \(ICTAI 2004 1082-3409/04 $20.00 © 2004 IEEE 





