Relationship between SAR and Biomass Derived from LiDAR in Mountain Areas Qisheng He a,b,c Chunxiang Cao a,b Erxue Chen c Feilong Ling c Hao Zhang a,b a State Key Laboratory of Remote Sen sing Science, Jointly Sponsored by the Institute of Remote Sensing Applications of Chinese Academy of Sciences and Beijing Normal University, Beijing 100101 PR. China b Institute of Remote Sensing Applications Chinese Academy of Sciences Datun Road, Chaoyang District, Beijing 100101, PR 
China c Institute of Forest Resource Information Technique The Chinese Academy of Forestry Dong Xiao Fu 1 Hao, Haidian District, Beijing 1000 91, PR. China Abstract In this paper, the response of ALOS \(the Advanced Land Observ the Phased Array type L-band Synthetic Aperture Radar data to the forest biomass was analyzed in the Qilian Mountain area within Gansu province western China. Due to not en ough field biomass, the Light Detection and Ranging \(LiDAR\data was used to extract biomass in 20m 20m cell. Then, the relationship between PALSAR backscattering coefficient in HH and HV 
polarization and Lidar-derive d forest aboveground biomass was analyzed. The result showed that at each biomass level the range of backscatter coefficient in HH and HV polarization was very big and there was no obvious relationship between SAR backscatter coefficient and biomass in pixel scale, while after averaging backscatter coefficients in different biomass level, backscatter coefficient in HV polarization increased with the increase of forest biomass and following one logarithm equation. The reason may be that forest structure is complex in pixel scale, while the average value partly removes he forest structure difference Keywords A LOS PALSAR; A boveground biomass; LiDAR Forest; Polarization  
1. Introduction Forest biomass is an essentia l factor in environmental and climate modeli ng. Also, standing forest biomass forms an essential part of active carbon pool participating in the global carbon cycle. Mapping the amount and geographic distribution of forest biomass and its change with time … is important for understanding the development of the carbon cycle. Forest biomass mapping from SAR data has become one of the most promising applications of radar remote sensing to vegetation studies Many studies have shown that it is possible to retrieve forest biomass using S AR data. The relationship between SAR backscatter and aboveground biomass or volume density 
has been investigated in various forest types  As to the relationship between L band back scatter and forest biomass the saturation point and the cor relation coefficient vary from different forest types and ground surface type  A deficiency is that there is not en ough sample field data for these studies. In th is study, the LiDAR data provides an opportunity to better ev aluate the potential of ALOS PALSAR for quantifying biomass. So firstly, the biomass distribution was extracted us ing LiDAR data. Then the relationship between SAR backscatter and aboveground biomass was analyzed in Picea crassifolia forest community 
in the Qilian Moun tain, western China 2. Study area and data 2.1. Study area The study site of Dayek ou is situated in the Qilian Mountain area, with its geographic coordinate ranging from N38°3132 to 38°3218 in latitude and from E100°1437 to 100°1610 in longitude within Gansu province, western China \(Fig. 1\e elevation varies from 2500 to 3800m above the sea level. The area has a temperate continental mountainous climate. In winter th e atmospheric circulation is controlled by the Mongolia anticyclone; the conditions are cold and dry, with little precipitati on. When the atmospheric circulation is controlled by th e continental cyclone in the summer, the diurnal difference of temperature is dramatic 
The difference of precipitation between summer and winter is large, and annual precipitation tak es place mainly in the summer. Influenced by the climate and the terrain, the prevalent vegetation types in the study area are mountainous pastures and forests. The domin ant vegetation includes Picea crassifolia Sabina przewalski, and grassland. Vegetation density varies with terrain, soil, water, and climate factors 9   In this study, the coniferous tree species Picea crassifolia  was selected as a target 2.2. Data ALOS PALSAR data was acquired in May 12, 2008 in HH and HV polarization, with azimuth and range pixel size of 3.20 and 9.37m and the incidence angle of 38.7 degree 
LiDAR data were acquired on 23 June 2008 using laser scanner Riegl LMS-Q560, an Litemapper 5600 system operating at a flight altitude of 800 m configured to acquire data using a narrow scan angle of <0.5mrad either side of NADIR and with a point dens ity of about 1 returns/m2 to maximize canopy penetration a nd minimize any potential scan angle effect. The x, y, z po sition \(easting, northing and elevation pulse were supplied for the first and last pulse and ge o-referenced to WGS 84, UTM North 48. The accuracy report that accompanied the LiDAR _______________ ______________ 978-1-4244-2732-1/09/$25.00 ©2009 IEEE 


data indicates the accuracy in x…y position is 0.10 m and in z position is 0.03m. Like most discrete return LiDAR systems the Riegl LMS-Q560 records intensity for each pulse in the near infrared \(1550 nm\gion. The intensity of each return pulse, sometimes referred to as laser amplitude, represents the reflected energy from a highly culminated beam of light footprint size of 0.20 m if the sensor's operating height is 800 m\. In this study, LiDAR data were mainly used to generate DEM and to extract aboveground biomass The ground truth data were collected through field work from June 1 to J une 13 of 2008. A sample plot of 100m 100m \(hereinafter referred as super plots\ with 16 small sample plots of 25× 25m and a strip sample plot\(hereinafter referred as strip plots\ with 20 small sample plots of 20× 20m along the flight direction with the  length of 1km every 50m were laid\(Fig.1\The height \(H\eter at breast height of 1.3m \(DBH\h individual tree of each plot was calculated, which we defined as pl ot level ground truth data The location of each sample plot was fixed using differential GPS system   Fig.1. Forest plots position of study area 3. Method 3.1. Field forest biomass calculation Biomass of all the organs of Picea crassifolia were estimated on diameter at breast height \(DBH\height measurements using relative growth equations \(Eqs.\(1 Eqs.\(4\rding to   8665  0 2   0.0478 _ H DBH biomass stock    1 2 3 4 8905  0 2   0.0061 _ H DBH biomass branch    4701  0 2   2650  0 _ H DBH biomass leaf    5779  0 2   0.0342 _ H DBH biomass fruit    Then we can obtain the aboveground biomass of each individual tree by summing up the stock, branch, leaf and fruit biomass. By summing up th e biomass of individual tree of each plot, we can obtain the plot biomass 3.2. LiDAR data processing The first step involves the elimination of pulses identified a s  below t h e nominal ground surface or above the expected canopy height. The remaining pulses are divided into those that reached the ground surface and those that did not. TerraScan software was used to classify ground points and then to use only th ese points to generate a digital elevation model \(DEM  First a triangulated irregular network \(TIN\ is constructed fo r the point cloud, based on a Delaunay triangulation of its elevation data. Then a rectangular grid of pixels is extracted from each TIN using linear interpolation with a constant sampling interval of one meter. Finally, the raster DEM of 0.5m spatial resolution are generated. In order to rectify the PALSAR data, the DEM was re-sampled to 20m in pixel All points were interpolated to a raster image. When the grid unit had multiple echoes, the maximum value was selected as the interpolation valu e. According to the point cloud density, the DSM was interpol ated into the resolution of 0.5 meters CHM was obtained to make difference between DSM and DEM  The sm oot hing algorithm with the search window 3 × 3 was used to smooth the CHM. With the support of TreeVAW, parameter of individual tree such as tree location tree height and crown diameter is extracted Multivariate linear regression analysis method was used to estab lish th e relatio nship between measured forest aboveground biomass and LID AR derived parameters. The Independent variables were the LIDAR measurements for each plot, including H_ave \(average height/plot maximum height\, H_min \(minimum height\, H_std standard deviation of heights\ CD_ave \(average crown diameter/plot\ax \(maximum crown diameter CD_min \(minimum crown diameter\d \(standard deviation of crown diameter\Co unt_ha \(number of trees per hectare\model with a sign ificant level of 0.01 was established for forest above ground biomass estimation Eqs.\(5\ple data, all data were used to build the equation. The LIDAR-measured variables that proved significant for predicting aboveground biomass were H_ave, Count_ha with R 2 of 0.721. Fig.2 showed scatterplots of field measured vs. predicted values for aboveground biomass. Spatial distribution of forest aboveground biomass could be obtained based on the establishment of forest biomass estimation equation, and the result was shown in Fig.3. The range of estimated forest aboveground biomass was 0-239ton/ha ha Count ave H biomass _ 077  0 _ 284  16 792  130       5   


Fig.2. Scatterplots of Predicted vs. Field Aboveground Biomass    0 239\(ton/ha Fig. 3. Spatial D istribution of Fore st Aboveground Biomass 3.3. SAR data processing The PALSAR data of this test site was required as Level 1.1 pr oduct, so we started from SLC data for all the following processing steps such as radiometric calibration, multilooking, DEM generation, geocode d terrain correction \(GTC and terrain radiometric correction \(TRC The sigma zero radiometric calibration function provided b y JAXA is as fo llows   C CF  Q I  10log 1 2 2 10 0      6 where, I and Q is the real and imagery part of the complex SAR image pixel value; CF1 and C are calibration constant, CF1=-83.0, C=32.0. NRCS of HV are recommended to be upgraded referring to the manuscript   NRCS \(new\NRCSHV \(old\n decibel. Here we define K=CF1-C, and will not get the d ecibel \(db radiometric calibrated intensity value until before analyzing the data. So we use equation \(5\t step of our data processing  10 K 2 2 0 I 10  Q I      7 where, K=-115.0 for HH pola rization and -112.0 for HV polarization, the subscrip t of sigma zero means the sigma zero calibration result of each SLC pixel is in intensity domain, not decibel we multi-look the intensity im age with 10 looks in azimuth direct ion and 2 looks in range direction to produce one image of pixel size about  30m. With the support of GAMMA software, the GTC and TRC image were generated Terrain radiometric correction is to correct the effect of different effective backscattering surface area caused by the local topography and SAR imagery geometry. This has been already derived as the slope correctionŽ by several researchers   4. Results and discussion 4.1. Relationship be tween backscatter coefficient and LiDAR-derived biomass From Fig.4 and Fig.5, we can see that at each biomass level, the range of ba ckscatter coefficient in HH and HV polarization is very big. Th ere is no obvious relationship between SAR backscatter coefficient and LiDAR-derived biomass. The result may be not in agreement with many researches. The reason may be that in this study area, the forest structure is complex. At the same biomass level, the tree density is very different, which affects the SAR signal Another reason may be that the terrain is complex, and the slope correction is not enough for the forest area  Fig.4. Backscatter Coefficient vs. LiDAR-derived Biomass  Fig.5. Backscatter Coefficient vs. LiDAR-derived Biomass 4.2. Relationship between aver age backscatter coefficient and bi omass derived fr om LIDAR in different bi om ass level Average backscatter coefficients were calculated in di ffe re nt bi o mass level, i.e. 0-10, 10-20, 20-30, 3040\(ton/ha\,ƒThe result was shown in Fig.6 and Fig.7. We can see that backscatter coefficients in HV polarization increases with the increase of biomass and following one logarithm equation. We also can see that in HV polarization the saturation was about 60 ton/ha. While in HH polarization a very high backscatter coefficient in the biomass level of 35ton/ha is very strange. The result in HV polarization may be in agreement with many researches. The reason is that the average backscatter coefficient may remove the forest structure difference From Fig.4 to Fig.7, we can conclude that due to the complexity in forest stru cture, the relationship between SAR backscatter coefficient and forest biomass is not obvious in pixel scale, while the average backscatter coefficients in different biomass level increa se with the increase of biomass and following one loga rithm equation, especially in HV 


polarization, because the average value partly remove he forest structure difference Fig.6. Backscatter Coefficient vs. LiDAR-derived Biomass in Different Biomass Level Fig.7. Backscatter Coefficient vs. LiDAR-derived Biomass in Different Biomass Level 5. Conclusion The paper experiences with digital analysis of ALOS PALSAR dual polarization L-band data in the Qilian Mountain, western China. So me results are obtained for estimating the potential of ALOS PALSAR data to extract biomass. The result showed there is no obvious relationship between SAR backscatter coefficient and biomass in pixel scale. When average backscatter coefficients were calculated in different biomass level, th e result showed that backscatter coefficients in HV polarization increased with the increase of biomass and following one logarithm equation and in HV polarization the saturation was about 60 ton/ha. The reason may be that forest structure is complex in pixel scale, while the average value partly removes he forest structure difference As many published papers have reported, the biomass extraction was affected by many other factors, such as terrain soil types, tree density and so on. The further study also should be strengthened for accurate estimating the biomass inversion using ALOS PALSAR data Acknowledgements The ALOS PALSAR data were provided by JAXA through the ALO S PI project \(Number315\This research has been supported by a grant from the Major State Basic NO 2007CB714400 thors also wish to thank all people who participated in the field experiment References  M.C.Dobson, F.T  Ulab y T.L e Toan  A.Beaudoin, E.S.Kasischke and N.Christensen, Dependence of radar backscatter on coniferous forest biomass,Ž IEEE Trans. Geosci. Remote Sens Vol. 30, No.2, 1992, pp.412… 415  T.LeToan  A.Beaudoin J.R iom and D.Gu yon, Relating fo rest biomass to SAR data,Ž IEEE Trans. Geosci. Remote Sens.Vol.30, No.2, Mar.1992 pp.403…411  A.Luckman, J.Bak er T. M  Kuplich C  C. F.Yanasse and A C.Frery, A study of the relationship between radar backscatter and regenerating tropical forest biomass for spaceborne SAR instrumentsŽ. Remote Sens. Environ.Vol 60, No.1,1997, pp.113  D.Pairman, S.McNeill  N.Scott, S.Belliss, Vegetation identif ica tion a nd biom ass estimation using A IRSAR data Geocarto Int. Vol.14,No.3, 1999, pp.67-75  M. L. Imhoff, Radar backs catter and b i omass saturati on Ramifications for global biomass inventory,Ž. IEEE Trans Geosci. Remote Sens. Vol. 33, 1995, pp.511… 518  H.Israelsson, J.Askne, J.Fransson, and R  Sy lv ander JER S-1 SAR analysis of boreal forest biomass, Final report of JERS1/ERS-1 system verification program,Ž MITI and NASDA, Vol II, Mar 1995, pp. 2- 45  J.Fransson and H.Israelsson, Estimation of stem volume in  boreal forests using ERS-1 C- an d JERS-1 L-band SAR data Int. J. Remote Sens. Vol.20,No.1,pp.123…137   T.Kuplich V.Salvator i and P.Curran JERS-1/SAR backscatter  and its relationship with biomass of r egenerating forests,Ž Int. J Remote Sens.,Vol.21,No.12, 2000, pp.2513… 2518  Y.Zhou, Q.Zhu, J. M.Ch en Observation an d simulation of  net primary productivity in Qilian Mountain, western China Journal of Environmental Management,  Vol.85, 2007, pp.574584  Wang J.Y Ju K. J  Fu H   E Chang X. X He H. Y,Ž Study on Biomass of Water Conservation Forest on North Slope of Qilian MountainsŽ. Journal of Fujian College of Forestry,Vol.18,No.4, 1998, pp.319-323  K.Kraus, and N. Pfeifer D eterm inatio n o f t errain models in wooded areas with airborne laser scanner data,Ž ISPRS Journal of Photogrammetry and Remote Sensing, Vol.53, 1998 pp.193Š203  M. Shimada, O. Isoguch i T. Tadono, R. Hig uchi and K Isono PALSAR CALVAL Summary and upd ate in 2007,Ž Proc. of IGARSS07, Barcelona, 3593-3596\(2007  M. Shimada, O. Isoguch i T Tadono and K  Isono, PALSAR  Radiometric and Geometric Calibration,Ž  ALOS Special issue  L. M. H. Ulander, Radiom etric Slop e Corr ection of S y nth eticAperture Radar Images IEEE Trans. Geosci. Remote Sens.Vol.34, 1996,1115 … 1122  M. Shimada and H  Hirosawa, Slope Corr ections to Normalized  RCS Using SAR Interferometr y,Ž IEEE Trans. Geosci. Remote Sens.Vol.38, 2000, 1479-1484 


Unfortunately, virtualization as developed by IBM was not possible on x86-CPUs as the 32/64-bit Intel ISA does not trap every incident that should lead to VMM intervention. Consequently, the conclusion in the 1990ies was that x86 cannot be virtualized in the way the old mainframes were virtualized. Other CPU ISAs such as PowerPC and Alpha are \223clean\224 enough to be virtua lized in the classic manner  VIRTUALIZATION OF X86 COMPATIBLE CPUS  Seventeen instructions of the x86-architecture which are classified as \223sensitive\224 cannot be intercepted because the ISA knows Ring-depending-instructions which work differently depending on the context of their execution mode. All of those critical instructions are affecting either i/o or memory operations which are executed in kernel mode This fact would increase the complexity of a x86-VMM drastically  Unlike IBM mainframes, where the VMM simply utilizes a CPU flag of a sensitive instruction in order to intercept critical calls, the VMM of a x86-CPU has to scan the entire code prior to execution for sensitive but non-interceptable calls  This method is called \223Scan before Execution\224 \(SBE\ shortened: Prescan  Prescan or "Scan Before Execution  The VMM translates the binary code which the kernel of a guest OS wants to execute on the fly and stores the adapted x86 code in a Translator Cache \(TC\. User-Mode applications will not be touched by a Binary Translator \(BT\ because the user code is considered to be safe. User mode applications are executed directly as if they were running natively  Kernel-Mode instructions are intercepted and altered by the VMM and deferred to virtual hardware Changed kernel code is slightly longer than the original one. If the kernel of the guest OS has to run a privileged instruction, the BT will change this kind of code into "safer" user mode code. If the kernel needs to get control of the physical hard ware, the BT will replace that binary code with code that manipulates the virtual hardware  The technological core competence of companies whic h provide virtualization tech nology is to minimize binary code translations and code overhead in order to keep latencies down  Essentially, software virtualization techniques move the operating systems \(kernels\ at a less privileged ring than normal  The software layer that performs the interception and translation of kernel mode calls is \(again\lled V irtual M achine M onitor \(VMM\ or Hypervisor  The VMM is a controlling instance in between the hardware and virtual machines. A hypervisor runs directly on the host hardware in Ring 0 and offers resources to \223Guest Virtual Machines\224. The advantage of the hypervisor solution is that operating systems of the virtual machines remain \(almost\ untouched and therefore still execute privileged operations as though running in ring 0 of the CPU  Furthermore, modern hypervisors provide interfaces for higher level administration and monitoring tools  Virtualization by hypervisor, sometimes also name d \223Full Virtualization\224, delivers \226compared to pure hardware virtualization or even system emulation- much higher processing performance  I/O Virtualization and Memory Management Virtual memory addresses need to be converted into physical ones in case of usage of virtual memory X86- compatible CPU perform this in three steps. \(Three tables LDTR \(Local Descriptor Tables Register IDTR \(Interrupt Descriptor Tables Register\d GDTR \(Global Descriptor Tables Register\. The OS maintains page tables to translate the virtual memory pages into physical memory addresses. All modern x86 CPUs provide support for virtual memory in hardware.  Different CPUs \(ARM, PowerPC, MIPS etc work in a similar manner 


 Translation from virtual to physical addresses is performed by the Memory Management Unit, or MMU The current address \(instructions and data!\ is available in the CR3 register \(hardware page table pointer\e most used domains of the page table are cached in the Translation Look-Aside Buffer TLB It is obvious that a guest OS running on a virtual machine cannot have access to the real page tables because this lead to uncontrolled collisions. Instead, the guest OS sees page tables which run on an emulated MMU Every time the guest OS modifies its page mapping, the virtual MMU module will capture \(trap\e modification and adjust the shadow page tables accordingly  Depending on the virtualization technique and the changes made in the page tables, this bookkeeping takes 3 to 400 times more cycles than in the native situation   DIFFERENT FORMS OF VIRTUALIZATION  Paravirtualization  The kernel of the Guest operating system is ported under Paravirtualization to run on a hypervisor    With Paravirtualization hardware is neither emulated nor virtualized. Critical CPU-instructions which directly access hardware need to be modified in the Guest OS An interception like mentioned in the chapter before is thus obsolete. But a s a result, Paravirtualization is restricted to operating systems like Linux with openly available source code  The advantage of Paravirtualization is that ported guests allow a much simpler design of a virtual machine \(VM\ability of the guest kernel to commu nicate directly with the hypervisor results in greater performance levels than in any other method of virtualization  The latest commercial Hypervisors and Guest OSes of Microsoft are designed to cooperate as Paravirtualized guest and Hypervisor  Finally, the hypervisor\222s job is reduced to simple sc heduling tasks for resources of the virtual machines  Hardware Accelerated Virtualization: Intel VT-x and AMD-V The main problem with the application of virtualization software is the performance loss compared to a bare OS installation. Pure emulation of the computer hardware is very inefficient. Performance losses of 50% and more are not unusual  The idea behind hardware virtualization has -as already outlined- its origin in the fact that the x86 instructions architecture cannot be virtualized. Hardware virtualization is based on the philosophy of trying to intercept all exceptions and privileged instructions by forcing a transition from the guest OS to the VMM, called a "VMexit". Trapped instruction would furthermore be processed by the VMM  The idea to improve virtualization performance by executing more instructions than before natively on the CPU was not far to seek. AMD and Intel developed independently \(AMD-V, Intel VT\ction set extensions to overcome constraints of the old x86-ISA. Both extensions are not compatible but they are based on the same principles  To put it simply, we can say that above all the formerly management and separation of kernel-calls is managed on silica instead of software. But in addi tion to this AMD and Intel implemented also mechanisms on their CPUs that allow guest OSes to modify memory page tables in order to decrease the emulation efforts of the VMM  


The improvement is based on the induction of a ring with a privilege level higher than 0. Guest OSes run at the originally intended privilege level \(Ring 0\. The CPU-cycle-consuming \223World-Switch\224, which handles the processing of ring 0 calls which arrive in a VMM, is avoided   Picture 3 Additional Layer \(Ring -1\s wit virtualization support   Native Virtualization thus provides certain parts of the physical hardware in the form of virtual hardware to the Guest OS  This is why -compared to the host performance- only 60-80% of the theoretical performance of a CPU can be achieved by virtualization 


VIRTUALIZED COMPUTER INFRASTRUCTURES  Initially, IBM invented Virtualization to extend a single task system to multitasking systems. A modern hypervisor transfers the old ideas to state of the art hardware, considering the entity of an OS with all installed software as \223Guest\224 or task  Vendors of virtualization software developed many sophisticated features and tools around the core of virtualization in order to the range of additional value for virtualization users  Physical to Virtual - P2V Before any virtualization can commence, it is necessary to find ways to convert an existing physical machine into a VM. Conversion is a procedure of transferring a physical computer with all of its hardware the installed OS and applications into a \223Virtual Machine\224  The definition of a Virtual Machine according to Forrester Research is as follows  A virtual machine is stored as a set of files in a directory in the DATASTORE. A virtual disk inside each virtual machine is one or more files in the directory. As a result, you can operate on a virtual disk \(copy move, backup,\205\ just like a file. New virtual disks can be \223hot added\224 to a virtual machine without powering it off. In this case a virtual disk file \(.vmdk\ is created in a V irtual M achine F ile S ystem \(VMFS to provide new storage for the hot added virtual disk or an existing virtual disk file associated with a virtual machine  Vendors in the field of virtualization software are offering software tools for P2V purposes. Physical machines can be virtualized on the fly, i.e. while they are running and performing their usual work. Other methods are using boot-CDs, hard disks or hard disk images to convert a computer. Furthermore back-up file formats of most important back-up solution providers are supported as base for a P2V conversion   Virtual Infrastructure The real benefits of virtualization become possible with the implementation of a virtual infrastructure layer Virtualization software vendors coined the term \223cloud computing\224 for this issue. One of these vendors even claims to offer the first \223cloud computing operating system\224   Picture 4 Set of host computers administrated by a Virtualization Layer with numerous "Guests\224   The infrastructure layer abstracts hardware to a very high degree. The layer considers no individual elements of hardware but it pools all available rescores instead. The virtual infrastructure would provide the aggregate of RAM of MHz to potential guests. All features regarding redundancy and high  availability 


are configured and maintained within the \223Administrat ion layer\224. The \223administration layer\224 itself can even just be a Guest in the virtual environment  Along with the implementation of the administration layer the storage philosophy needs to be adapted to benefit from virtualization. Virtual machine files should be no longer physically located on a hard disk of an individual server, but on a common S torage A rea N etwork \(SAN\ instead. Now the critical point of failure has changed in virtualized environments from the hard-disk of an individual server to the SAN  Flexibility Virtual machines handled by system management software must not continuously reside on an initially assigned computer. In fact a \223Guest\224 can move around while still provid ing all service from one physical machine to another. This feature enables hardware maintenance without risks and interruption of computer operation in a very simple way  A growing demand of resources by additional applications or increased machine load can be covered by adding new machines and distributing the Guests differently in the extended cluster This process can even be automated, meaning that load balancing between computer resources can be realized without manual inte rvention \(if the hardware is already in place  Rapid provisioning and backup As said before, a virtual machine is in essence just a file on file system. This file represents a computer with everything in it, to run on a virtualization host This hardware independence enables administrators to create clones of working images for roll out purposes In case of tests of hot fixes or updates, snapshots of the running machine can be taken to which one can revert in case a test fails Backups are simplified a lot, because third party tools are almost obsolete  Quick recovery After a failure \226no matter hard- or software caused a virtual machine can reboot automatically elsewhere in the virtual environment in order to keep the service. As this type of quick recovery causes interruptions to computer operation it is not suitable for process automation purposes  Failover Real failover has only been available in commercial products since approximately two years. In principle it consists of a foreground Guest VM with a \223Shadow-VM\224 of this Guest running in the background on different hardware of the resource pool. The shadow VM is an identical bit-copy of the foreground machine. It would become activated in case the foreground machine suffers a hardware breakdown  Both features, Failover and Quick Recovery make use of the mobility of Virtual Ma chines in administrated environments The applied principle to achieve failover is highly comparable with system backup software which is capable of backing up system partitions while the system is running  The working principle is a method which takes a snap-shot at a point in time and monitors the deviation to the snap shot while the initial snap shot is taken. The procedure is applied as long as the delta file size between snapshot and data to be copied\ero. At this moment the Copy-VM takes over The dead time for taking over by the Shadow-VM is just some \(we only found one\ packets - thus just some milliseconds  But beware  Breakdowns caused by \223buggy\224 software are not covered by this technology, because the shadow-VM would crash as well  


Impact on automation layout in a cement plant Next picture shows a generic control system layout as used at HeidelbergCement with logical segregation of production stages and an \223automation backbone\224 which connects subordinate control systems  Each control system consists of a redundant set of servers for failsafe reasons   Picture 5 Standard PCS layout  Process control systems are typically installations which are subject to evolution rather than to revolution Most cement plants would never do a \223one-shot replacement\224 of an installed system \(or version\ by another but proceed in steps  Logically, the approach towards virtualization is logically very similar to PCS upgrades The reason for the reference plant which introduced Virtualization Technology in 2008 for online control purposes were hardware failures and obsolete hardware for Windows-NT-based-CEMAT-V4-control systems The first machine to be virtualized was not \223mission critical\224 but represented in principle the entire functionality of CEMAT V4. It was an engineering station which was set up as a combined \223server-clientengineering station\224  Almost at the same time, this plant introduced a Process Data Acquisition System \(Management Information System\. According to the vendor\222s specification, the whole system should be installed on 5 different computers \(Com-Server, OPC Server, Database Server,\205\ough it was obvious that it could be done on fewer machines the plant decided to follow the vendor\222s specification because of warranty issues. However, setting up 5 machines for a relatively unimportant job was considered to be excessive and as the virtualization platform was availabl e we utilized it for the PDAS installation  Due to the positive experience after step one, it was decided, to migrate also one PCS Server of the redundant server-set into a VM and install it to a host. The process control system software runs untouched on both machines and realizes failover between a physical and a virtual machine  The decisive steps at our pilot plant were also done at a relatively early point in time \(immediately after the tests with the engineering station were completed\ September 2008  The infrastructure software layer was installed \226although we could not use it extensively- almost at the very beginning, i.e. with the first host, in order to give our staff the opportunity to become familiarized with this new \(to automation people\y 


  Picture 6 PCS layout with virtual infrastructure and SAN  The second very important step was the installation and commissioning of a Storage Area Network SAN\, because only a network storage enables to make use of virtualization infrastructure features such as failover. This is due to the fact that virtual machine disk files may not exist on a certain host, as in case of failure it would not be accessible and available any longer to be restarted on a different physical host  SANs are either based on Fibre Channel or iSCSI Technology. The idea of both technologies is to extend the \(usually\nal data lines between hard disk controllers and hard-disks to external devices Fibre Channel has been a proven technology for this type application for years. It has a slightly better performance, but is more expensive than iSCSI iSCSI stands for Internet Small Computer System Interface It  means encapsulation  of the SCSI protocol within TCP/IP packages. Today iSCSI delivers sufficient performance to build up SANs for process automation purposes at a cement works  In such an arrangement, from a failure point of view, the SAN is the most critical peace of hardware in virtualized computer architecture  Although SANs are built up internally fail safe \(redundant power supply, NICs, hard disk controllers,\205 and data sheets give impressive figures for availability, any concept for process control purposes should allow for setting up auto-synchronizing SANs at different spots  User interface VMs running on a host are comparable to applications running on a Terminal Server. In other words, VMs obviously need input and output devices to be handled. Fat clients \(PC\222s\o good choice if it is intended to simplify the maintenance of the process control system hardware. Moreover, they are costly and sometimes prone to error Another step forward -with limited risk only- was to replace some operator stations of a segment by Thin Clients without hard disk The connection between thin client and VM is either done by vendor specific client software, RDP or VNC  Obstacles Minor issues may occur while transferring physical control systems into virtual ones Most of the problems the reference plant encountered had to do with the hardware interfaces such as serial and parallel ports and multi-media features  


Unresolved points \(minor\are to date realizing failover with legacy interfaces and sound output with Windows NT guests   CONCLUSION  Virtualization is no new but a revitalized technol ogy. First virtualization solutions \(purely based on software\ell as computer emulation deliver poor results in terms of performance  Hardware supported virtualization and pure software virtualization are totally different approaches  Virtualization today is most powerful when it combines the strengths of the different technologies. CPU demanding applications are wasting less performance than memory-intense application. \(TLB miss costs  VMware ESX is a good example of this. ESX uses Para-virtualized drivers for the most critical I/O components \(but not for the CPU\, emulation for the le ss important I/O and Binary Translation in order to avoid the high "trap and emulate" performance penalty. In this way, virtualized applications perform quite well, in some cases almost as if th ere were no extra VMM layer involved  The user benefit of virtualization is manifold. Virtualization 225  decouples software from hardware \(provides availability for \223legacy platforms\224, enables software in a cloud 225  utilizes installed hardware more efficient 225  safes space, energy, and invest cost 225  eases system administration extensively  225  but requires additional know-how of system administrators  At this point in time we can say that virtualization has met all of our expectations and offered \226in particular with respect to system administration- even more. The number of plants that started using Virtualization is growing  The process automation staff is still on a learning curve with virtualization in order to take maximum benefit of this technology  Unexploited potential is likely to be found in the field of setting up systems, handling of back-ups and disaster recovery procedures     REFERENCES  200  K. Lawton, Running muliple operating systems concurrently on an IA32 PC using virtualization techniques,http://plex86.org/research/paper.txt 200 www.codinghorror.com/blog/archives/001029.html 200 it.anandtech.com 200 en.wikipedia.org/wiki/Platform_virtualization 200  Virtualization for dummies SUN and AMD special edition 200 www.intel.com/technology/virtualizatio n/technology.htm?iid=tech_vt+tech 200  2008 Automation Summit - ID#: 1474 - Dow Chemical R&D\222s Global Rollout of PCS7\256 Using VMWare\256, Chicago    200 en.wikipedia.org/wiki/Ring_\(computer_security 


  13 edge of the aperture.  The distance of the reflected beam from the center of the aperture is then used to calculate I  which varies from about -0.8\260 to +0.8\260 in the experiment Figures 24-28 show the change r I    found by taking the difference of the center of each spectral image and subtracting from its location when I and compared the modeled values over the same range of I Figure 23 illustrates that there is some amount of random error in these measurements, but overa ll the data is grouped around r 0 pixel difference between the measured and modeled values.  The 404.7nm source shows the most variation  Figure 23 \226 The difference in pixel displacement at the detector array between measurements from modeled and collected data as a function of I     Figure 24 \226 Measured and modeled r   p  for the 404.7nm spectral line   Figure 25 \226 Measured and modeled r   p  for the 435.8nm spectral line   Figure 26 \226 Measured and modeled r   p or the 546nm spectral line   Figure 27 \226 Measured and modeled r   p  for the 577.5nm spectral line   Figure 28 \226 Measured and modeled r   p  for the 635nm spectral line   Given that the model is able to predict the displacement of energy as a result of an error in p   due to incident angle data was collected similar to that with the tilted camera to examine the effect system atic error due to unknown I  caused by a misaligned prism Here, the prism was angled in the mount in two directions to create the angles x and y  between the prism face and the normal to the optical axis as shown in Fig. 10.  The mo unt itself was tilted in two directions to create the misalignment angles x and y as shown in Fig. 12.  The magnitudes of these angles were measured by a laser as described above.  The aperture was placed such that each mm of separation at the aperture equates to 0.25\260 of angle at th e prism.  Misalignment in the instrument was used that gave values x  0.5\260 y  0.5\260 x 0.75\260 and y  0.5\260 with the instrument design again limiting the amount of error that could be imparted  The r   p  expression from Equation 17 will be compared to see how the displacement of each of the 5 wavelengths as a function of rotation angle varies given the different I  due to misalignment as the prism rotates.  The estimation in 3 2 1 0 1 2 3 4 5 6 1.0 0.5 0.0 0.5 1.0 r from model \(pixels I degrees 404.7nm 435.8nm 546nm 578nm 635nm 400 390 380 370 360 350 0 90 180 270 360 r   p pixels p degrees 404 nm, measured 404 nm, modeled 258 255 252 249 246 243 240 237 234 231 0 90 180 270 360 r   p pixels p degrees 435 nm, measured 435 nm, modeled 0 1 2 3 4 5 6 7 8 9 0 90 180 270 360 r   p pixels p degrees 546 nm, measured 546 nm, modeled 28 30 32 34 36 38 40 0 90 180 270 360 r   p pixels p degrees 578 nm, measured 578 nm, modeled 76 78 80 82 84 86 88 90 0 90 180 270 360 r   p pixels p degrees 635 nm, measured 635 nm, modeled 


  14 error for angles and is +/-0.2\260 and is incorporated into the model prediction.  Results are shown in Figures 24-29  Here, the measured data match the overall trends of the model very well, with some slight offset of about 2 pixels in each of the r   p  comparisons.  This would lead to the assumption that the estimate of x is not accurate, but is likely not the case since the mean of the model is too high in the 404nm data, and too low in the 435nm data.  This indicates that there are other errors being observed, as again it is nearly impossible to lim it the measurement to error in the intended so urce.  Also, note the decrease in impact the rotation error has as wavelength increases.  This is due to the lowered bearing P has on p as shown in the previous section.  However, the error magnitudes are a ratio of the distance from the undeviated wavelength, and in this data set are large due the large fractional error of and   4  R ESULTS  The systematic errors in a CTI instrument affect the spectral and spatial resolutions and locations in the reconstructed hyperspectral data cube in similar ways that these errors would affect the results of a traditional prism spectrograph This would be expected since the 3-D data is constructed from 2-D projection data.  The CTI becomes much more sensitive to error dependent on how the error kernel in the reconstruction behaves as a function of the prism rotation angle p and degree of freedom not in a fixed element dispersion system.  Four type s of systematic error were examined in this study; those due to tilt in the detector array  between the det ector array and the lens L 3  d   error in knowledge of the angular prism dispersion p    and error in estimation of the prism rotation angle p   s that can be inse rted into the error kernel functions were developed for each to model the effects For reasonably large array tilts of up to 3\260 and error in distance of up to 2mm, only a slightly noticeable shift of less than a pixel in spatial location was observed, mostly dependent on the tilt angle.  A more substantial spectral peak shift resulted which was due to error in distance, with a 7nm shift seen at the longer wavelengths at d  2mm.  The spatial and spectral resolu tions remained virtually unchanged, indicating that an accurate construction occurs in a shifted location The dispersion angle can be in error due to faulty estimation of prism performance.  This w ill cause an apparent shift of spectral peaks as shown in Figu re 8.  A more complicated  is the result of its dependence on the incident angle to the prism face I This is caused by mi salignment of the prism in the mount, or misalignment of the mount itself.  Mount misalignment is similar to cons tant error in estimation of p   with a shift in spectral p eaks observed.  For the AFIT CTI, this shift is only a few nm per 1\260 of misalignment Mount misalignment produces a more complex error kernel as shift and loss of resolutio n occur for relatively smaller angular errors.  More impor tantly, the spectral peaks become split into two peaks for errors of total misalignment in both the x and y directions of 1\260.  The spectral resolution may be recovered if the entire spatial area of the image is integrated.  However, simila r to splitting of peaks, the spatial distribution is a donut shape in the bin of emission  Finally, the error in projection angle p was examined though in a more obligatory fa shion since it is a relative error \(i.e. not a systematic erro r necessarily, but an error in choice of the reference coordinate system\.  There is no shifting of spectral peaks or lo ss of spectral resolution however there is a circular displacement of the spatial image again causing donut shap es for large enough   Most importantly, the error mode l was verified by collecting measured data from the AFIT CTI instrument with systematic error intentionally created in the instrument to assess the effect.  While in some cases it was apparent that sources of error other than those being investigated were influencing the results, the data did match the model for the situations where th e studied error effect was dominant usually at higher angular dispersi on, or spectral resolution Further investigation of some error may be necessary, as our CTI system design could only support a certain degree of component alteration to assess er ror.  In some cases, due to sampling of the detector array w ith respect to the size of the PSF of the system, slight changes in performance caused by error could not be resolved  4  C ONCLUSIONS  The purpose of this study wa s to assess the effect of systematic error on the reconstr ucted data sets collected by a rotating prism CTI instrument While the results are specific to the AFIT CTI desi gn, it is intended that the relative magnitude of each error and result on the reconstructed data will apply to any set of data given the general nature of the equations describing the reconstruction and error kernel that is con volved with each spectral bin  The consequence of each systematic error was quantified by the shift in spectral and/or spatial location, and degradation of spectral and/or spatial reso lution.  Table 2 summarizes the contribution of each analy zed error to these quantities   Table 2 \226The effect of systematic error.  An \223x\224 indicates an effect exists, a \223-\223 indicates no effect is observed   


  15 The model of the system allows for a quick assessment of the error, and provides a more illustrative demonstration of the prism misalignment error an d how each spectral peak is affected differently.  Figure 29 shows how the spectral peak changes as the prism mount alignment is increased in both the x and y directions for the 400nm and the 450nm spectral peaks   Figure 29 \226 The 400nm and 450nm peak shapes with varying misalignment of the prism mount   Similarly, Figure 30 represents the situation where the prism mount misalignment is constant at x  y 0.5\260 but the misalignment of the prism in the mount is changing so that a constant shape is produced, but shifted as x increases   Figure 30\226 Shifting of the 400nm spectral peak as x  increases.  The shape remains the same as the misalignment of the mount is constant   Though presented independently, the obvious contribution of the errors of the system are cumulative and must be considered in total.  Given th e great number of variations possible, this was not attempted here, but can be done based on the mathematics  This study is intended to explore the effect of systematic error for the purpose of examining sensitivity of performance when designing th e instrument.  In practice the reconstruction of collected data is done using after calibration of the instrument to directly measure r  p   without regard for the sources of error.  While this measurement can be a diagnostic of the instrument, the fact that it is well known is enough to perform acceptable reconstructions.  If instrume nt components are accessible the diagnostics be used to correct for second order error created in the instrument.  For example, errors in distance to the focal plane or tilt also result in a defocus error which cannot be easily recovered in the reconstruction algorithm R EFERENCES  1  C G r o s s, G  P. Perram an d R. F. Tu ttle, \223Mo d el i n g  infrared spectral intensity data from bomb detonations\224 Proceedings of SPIE  5881 p. 100 \(2005  2 o oney, \223A ngu l arly Mu ltip lex ed  Sp ectral Im ag er\224 Proceedings of SPIE  2480 pp. 65\22677, 1995   a ster, \223De sign and M o del Verification of an Infrared Chromotomographic Imaging System.\224 AFIT Masters Thesis, 2004  4 bb ins D  J. Go dfrey 223D ig ital x-ray tomosynthesis: current state of the art and clinical potential\224 Phys Med. Biol 48, pp. R65-R106, 2003   R.A Br oo ks an d G Di Chi r o 223Pri nci p l e s o f Com p u t er Assisted Tomography \(CAT\n Radiographic and Radioisotopic Imaging\224 Phys. Med. Biol  21 No. 5, pp 689-732, 1976  6 R.L. Bostick, G.P. Perr am, \223Hyperspectral Imaging Using Chromotomography: A Fieldable Visible Instrument for Transient Events\224 International Journal of High Speed Electronics and Systems  18 no. 3, pp. 519\226529, 2008  7 Bo stick   G  P.Perram an d R.F.Tu tt le 223Characterization of spatial and spectral resolution of a rotating prism chromotomographic hyperspectral imager\224 Proceedings of the SPIE  Next-Generation Spectroscopic Technologies II Conference, April 2009  B IOGRAPHY  Randy Bostick is a part-time PhD student at AFIT developing a metrology for a rotating prism chromotomographic imaging system.  Mr. Bostick is employed full time at the National Air and Space Intelligence Center at Wright-Patterson Air Force Base as an intelligence analyst for national remote sensing assets  


http://www.w3.org/TR/wsci 36] The World Wide Web Consortium \(W3C vice Modeling Language \(WSML http://www.w3.org/Submission/WSML 37] The World Wide Web Consortium \(W3C vice Modeling Ontology \(WSMO http://www.w3.org/Submission/WSMO 38] J. Yang and M.P. Papazoglou, ?Web Component: A Substrate for Web Service Reuse and Composition?, Proc 14th Conf. Advanced Information Systems Eng. \(CAiSE 02 LNCS 2348, pp. 21?36, Springer-Verlag, 2002 39] Y.P. Yang, Q.P. Tan, and Y. Xiao, ?Verifying Web Services Composition Based on Hierarchical Colored Petri Nets?, IHIS?05, pp. 47-53, Bremen, Germany, 2005 40] Y.P. Yang, Q.P. Tan, Y. Xiao, J.S. Yu, and F. Liu, ?Exploiting Hierarchical CP-Nets to Increase the Reliability of Web Services Workflow?, Symposium on Applications and the Internet \(SAINT?06 41] X.C. Yi and K.J. Kochut, ?Process Composition of Web Services with Complex Conversation Protocols: a Colored Petri Nets Based Approach?, Conference on Design, Analysis, and Simulation of Distributed Systems, pp.141-148, 2004 42] D. Zhovtobryukh, ?A Petri Net-based Approach for Automated Goal-Driven Web Service Composition?, SIMULATION, Vol. 83, Issue 1, pp.33-63, January 2007 43] C. Zhou, L.T. Chia, and B.S. Lee, "Web Services Discovery with DAML-QoS Ontology", International Journal of Web Services Research, vol. 2: no. 2: pp. 43-66, 2005   Proceedings of the 42nd Hawaii International Conference on System Sciences - 2009 10 pre></body></html 


  17 Mission Phase Relevant Archit ecture Informat ion Purpose Funct ion Mat urit y Pr oduct s DODAF M odel Re f e r e nce N ot e s Preliminary System Design Integrated Risk List Cross  functional list of risks compiled across integrated product team PDR Delivery Consolidated Ri sk Li st FFP1A Operational Environment M atrix documenting how test requirements that have been levied are satisfied with test \(at both the component and system levels Identification of the method that w ill be used to verify the requirement Identification of any potential non-conformances  Initial Delivery Environmental Te st  Verification Matrix FFP7 This will show the capability of the SV to withstand various environments \(i.e. launch vehicles System Interface Control Documentation This will be a suite of documents, the mission plan s hould identify critical system boundaries that reuqire a formal interface control document M inimum Criteria:  SV - Ground and Payload to SV ICD initial drafts must be compl e t e Other pertinent ICDs:  LV - Spacecraft, Component interface ICD Initial Delivery Interface Control Documentation SV 1  SV 6 Schedule Program Driving Schedule Requirements Key schedule driven technical decisions Giver receiver relationships that span different program elements Li v i n g Document Intgrated Milestone Schedule PV2 System Sub-system Design Specifications Partial Preliminary understanding of system subsystem design Allocation of required system functions to configuration items Demonstration of how system requirements are satisfied by design Initial Delivery PDR De si gn  Presentation SV 5 Open System Trades Desription organized by susbsystem of open design trades and decsions that need to be completed Each trade should have an owner and assocaited due dates that are aligned with program constriants Li v i n g Document Trade  Decision tracking matrix FFP5 Technical Performance Measures Demonstrate design peformance to critical program requirements outlined within the requirements document Initial Delivery Technical performance budget SV 7 Values in the budget should be compared to industry standards for a given maturity in the devleopment De t ai l e d De si gn System  Design Specifications Detailed description of "to be"  system subsystem design Allocation of required system functions to configuration items Demonstration of how system requirements are satisfied by design Final Delivery CDR De si gn  Presentation SV 4  SV 5 Note: Reference Lesson 11 - Need to look at some views and diagrams that would be useful for every subsystem Integrated Risk List Cross  functional list of risks compiled across integrated product team CDR Delivery Consolidated Ri sk Li st FFP1A Operational Environment Matrix documenting how test requirements that have been levied are satisfied with test \(at both the component and system levels Identification of the method that w ill be used to verify the requirement Identification of any potential non-conformances  Final Delivery Environmental Te st  Verification Matrix FFP7 Note: previous delivery s houl d have defined how requirements would be satisfied for long lead components.  This delivery would address all remaiing compents and system levels System Interface Control Documentation This will be a suite of documents, the mission plan s hould identify critical system boundaries that reuqire a formal interface control document M inimum Criteria:  SV - Ground and Payload to SV ICD initial drafts must be compl e t e Other pertinent ICDs:  LV - Spacecraft, Component Interface ICD Final Delivery Interface Control Documentation SV 1  SV 6 Schedule Program Driving Schedule Requirements Key schedule driven technical decisions Giver receiver relationships that span different program elements CDR De l i v e r y Intgrated Milestone Schedule PV2 Integration Prodcution Plan List of all components under procurement and their expected and need dates List should include all piece parts, miscellaneous mat ls, connectors and required ground support equipment Initial Delivery Sy st e m Pa r t s  Li st  FFP6 Technical Performance Measures Demonstrate design peformance to critical program requirements outlined within the requirements document Final Delivery Technical performance budget SV 7 Values in the budget should be compared to industry standards for a given maturity in the devleopment Open System Trades Desription organized by susbsystem of open design trades and decsions that need to be completed Each trade should have an owner and assocaited due dates that are aligned with program constriants Li v i n g Document Trade  Decision tracking matrix FFP5   


 LNCRITIC 0.884 \(.005 0.362 352 0.593 053  CRPRO -0.007 \(.306 0.012 183 0.002 798  CRCON 0.010 \(.291 0.013 230 0.019 095  Model fit F p value 24.900 lt;.0001 11.110 lt;.0001 5.940 lt;.0001 Adjusted R2 0.559 0.553 0.320 p &lt; .10 p &lt; .05 Notes: p values are in parentheses  4.5. South Korean versus American market  In terms of the effect of WOM, we find no discernable difference in the motion picture markets of South Korea and the United States. Volume of WOM is positively correlated to the following week?s revenue in both markets, and valence of WOM is not significant The effect of critical reviews, however, did not concur While the literature on the American market data reports that positive critical reviews are positively related to box office revenue[21, 34], the results on the Korean market was different. There could be several reasons for this. First, South Korea and the United States have different sources for critical reviews, and the sources may have different impacts on moviegoers Second, the characteristics of critics might be different i.e., Korean critics may prefer movies that are considered less commercial or artistic than American critics  5. Conclusion  WOM and critical reviews both are important attributes that influence box office revenue in the motion picture industry. In this study, six hypotheses related to this issue were set up and tested. Data was collected on the motion picture industry of South Korea by using several websites that provide content and statistical data about movies. Finally, data on 118 movies was collected and the movies were categorized into two groups based on the distributors of the movies If the distributor of a movie was one of the major distributors in South Korea, that movie was categorized into mainstream movies, and if not then the movie was categorized into non-mainstream movies. As expected mainstream movies had much higher box office revenue and volume of WOM than non-mainstream Proceedings of the 42nd Hawaii International Conference on System Sciences - 2009 8 movies. In the case of the volume of critical reviews 


movies. In the case of the volume of critical reviews however, there was no big difference between mainstream and non-mainstream movies. WOM and critical reviews were usually positive H1 and H2 tested the relationship between WOM and weekly box office revenue, and the results supported the hypotheses. The volume of WOM was positively related to weekly box office revenue, while the valence of WOM had no significant effect. H3 H4a, and H4b tested the impact of critical reviews, and the results also supported the hypotheses except H4b The volume and valence of critical reviews had no consistent significances to weekly box office revenue H3 H4b. Table 7 showed that the number of critical reviews was statistically significant to aggregate box office revenue \(H4a for the attitude of critical reviews \(H4b the result more detail, an additional test was performed using only those factors related to critical reviews as independent variables. The result of the additional test supported H4, but the signs were reversed, i.e. positive critical reviews had minus signs, and negative critical reviews had plus signs. This reversed signs imply that the preference of critical reviewers is very similar to that of normal moviegoers. H5s and H6s tested the different effects of WOM and critical reviews on mainstream and non-mainstream movies. The result failed to determine that WOM give different impact on mainstream and non-mainstream movies, so H5a and H5b were rejected. H6, however, was supported, i.e the effects of critical reviews were different for mainstream and non-mainstream movies. There were no significant relationships between critical reviews and aggregate box office revenue in mainstream movies. For non-mainstream movies, however, the volume of critical reviews and the percentage of negative critical reviews were significant. Nonmainstream movies have fewer sources from which consumers can get information, and this might explain the results The above findings lead to several managerial implications. First, producers and distributors of movies could forecast weekly box office revenue by looking at previous weeks? volume of WOM. It does not matter what attitude people have when they spread WOM, the important factor is its volume. Therefore producers and distributors need to develop an appropriate strategy to manage WOM for their movies For example, the terms related to WOM marketing such as buzz and viral marketing are easily found Second, for the distributors who usually distribute less commercial and more artistic movies, and consequently have a smaller market compared to the major distributors, critical reviews can impact their movies box office revenues in a significant way. There are usually fewer sources for information for nonmainstream movies than mainstream movies, and so small efforts could leverage the outcomes. Finally, for those who are dealing with mainstream movies, the finding that the valence of WOM and critical reviews do not have significant relationship with box office revenue can have certain implications. Particularly, the attitude of critical reviews showed reversed effects Therefore, they may need to concentrate on other features rather than attitude of moviegoers or critical reviews, such as encouraging moviegoers to spread WOM This study contributes to the understanding of the motion picture industry, especially the relationship between box office revenue and WOM including critical reviews. There are existing studies that already 


critical reviews. There are existing studies that already dealt with similar issues, but this study has some differentiated features compare to prior studies. First the data used in this study was collected from South Korea, while most of the relevant studies usually focus on the North American market. This helps to provide the opportunity to understand the international market especially the Asian market, even though South Korea is a small part of it in terms of the motion picture industry. Second, movies were categorized to two groups, i.e. mainstream and non-mainstream and this study attempted to determine how WOM impacts these categories differently by testing several hypotheses In this study, there are also several limitations that could be dealt with in future research. First, using box office revenue as a dependent variable is more meaningful for distributers rather than producers. Due to there is close correlation between box office revenue and number of screens, one of producers? main concerns is how many screens their movies can be played on. Moreover, DVD sales are also important measurement for success of movies these days, and so it also could be a dependent variable. Therefore, it could be possible to give more fruitful managerial implications to various players in the motion picture industry by taking some other dependent variables Second, in this study, movies were categorized simply as mainstream and non-mainstream movies, but there could be further studies with diverse techniques of movie categorizations. For example, it would be possible to study the varying influence of WOM or critical reviews on different genres or movie budgets Third, an interesting finding of this study is that positive critical reviews could have negative relationship with box office revenue while negative critical reviews could have positive relationship. This study tried to provide a reasonable discussion on the issue, but more studies could be elaborate on it  Proceedings of the 42nd Hawaii International Conference on System Sciences - 2009 9 References  1] Dellarocas, C., The Digitization of Word of Mouth Promise and Challenges of Online Feedback Mechanisms Management Science, 2003. 49\(10 2] Bone, P.F., Word-of-mouth effects on short-term and long-term product judgments. Journal of Business Research 1995. 32\(3 3] Swanson, S.R. and S.W. Kelley, Service recovery attributions and word-of-mouth intentions. European Journal of Marketing, 2001. 35\(1 4] Hennig-Thurau, F., et al., Electronic word-of-mouth via consumer-opinion platforms: What motivates consumers to articulate themselves on the internet? Journal of Interactive Marketing, 2004. 18\(1 5] Fong, J. and S. Burton, Electronic Word-of-Mouth: A Comparison of Stated and Revealed Behavior on Electronic Discussion Boards. Journal of Interactive Advertising, 2006 6\(2 6] Gruen, T.W., T. Osmonbekov, and A.J. Czaplewski eWOM: The impact of customer-to-customer online knowhow exchange on customer value and loyalty. Journal of Business Research, 2006. 59\(4 7] Garbarino, E. and M. Strahilevitz, Gender differences in the perceived risk of buying online and the effects of receiving a site recommendation. Journal of Business Research, 2004. 57\(7 8] Ward, J.C. and A.L. Ostrom, The Internet as information minefield: An analysis of the source and content of brand information yielded by net searches. Journal of Business Research, 2003. 56\(11 


9] Goldsmith, R.E. and D. Horowitz, Measuring Motivations for Online Opinion Seeking. Journal of Interactive Advertising, 2006. 6\(2 10] Eliashberg, J., A. Elberse, and M. Leenders, The motion picture industry: critical issues in practice, current research amp; new research directions. HBS Working Paper, 2005 11] S&amp;P, Industry surveys: Movies and home entertainment 2004 12] KNSO, Revenue of Motion Picture Industry 2004 Ministry of Culture, Sports, and Tourism, 2004 13] Duan, W., B. Gu, and A.B. Whinston, Do Online Reviews Matter? - An Empirical Investigation of Panel Data 2005, UT Austin 14] Zhang, X., C. Dellarocas, and N.F. Awad, Estimating word-of-mouth for movies: The impact of online movie reviews on box office performance, in Workshop on Information Systems and Economics \(WISE Park, MD 15] Mahajan, V., E. Muller, and R.A. Kerin, Introduction Strategy For New Products With Positive And Negative Word-Of-Mouth. Management Science, 1984. 30\(12 1389-1404 16] Moul, C.C., Measuring Word of Mouth's Impact on Theatrical Movie Admissions. Journal of Economics &amp Management Strategy, 2007. 16\(4 17] Liu, Y., Word of Mouth for Movies: Its Dynamics and Impact on Box Office Revenue. Journal of Marketing, 2006 70\(3 18] Austin, B.A., Immediate Seating: A Look at Movie Audiences. 1989, Wadsworth Publishing Company 19] Bayus, B.L., Word of Mouth: The Indirect Effects of Marketing Efforts. Journal of Advertising Research, 1985 25\(3 20] Faber, R.J., Effect of Media Advertising and Other Sources on Movie Selection. Journalism Quarterly, 1984 61\(2 21] Eliashberg, J. and S.M. Shugan, Film critics: Influencers or predictors? Journal of Marketing, 1997. 61\(2 22] Reinstein, D.A. and C.M. Snyder, The Influence Of Expert Reviews On Consumer Demand For Experience Goods: A Case Study Of Movie Critics. Journal of Industrial Economics, 2005. 53\(1 23] Gemser, G., M. Van Oostrum, and M. Leenders, The impact of film reviews on the box office performance of art house versus mainstream motion pictures. Journal of Cultural Economics, 2007. 31\(1 24] Wijnberg, N.M. and G. Gemser, Adding Value to Innovation: Impressionism and the Transformation of the Selection System in Visual Arts. Organization Science, 2000 11\(3 25] De Vany, A. and W.D. Walls, Bose-Einstein Dynamics and Adaptive Contracting in the Motion Picture Industry Economic Journal, 1996. 106\(439 26] Bagella, M. and L. Becchetti, The Determinants of Motion Picture Box Office Performance: Evidence from Movies Produced in Italy. Journal of Cultural Economics 1999. 23\(4 27] Basuroy, S., K.K. Desai, and D. Talukdar, An Empirical Investigation of Signaling in the Motion Picture Industry Journal of Marketing Research \(JMR 2 295 28] Neelamegham, R. and D. Jain, Consumer Choice Process for Experience Goods: An Econometric Model and Analysis. Journal of Marketing Research \(JMR 3 p. 373-386 29] Lovell, G., Movies and manipulation: How studios punish critics. Columbia Journalism Review, 1997. 35\(5 30] Thompson, K., Film Art: An Introduction. 2001 McGraw Hill, New York 31] Zuckerman, E.W. and T.Y. Kim, The critical trade-off identity assignment and box-office success in the feature film industry. Industrial and Corporate Change, 2003. 12\(1 


industry. Industrial and Corporate Change, 2003. 12\(1 27-67 32] KOFIC, Annual Report of Film Industry in Korea 2006 Korean Film Council, 2006 33] Sutton, S., Predicting and Explaining Intentions and Behavior: How Well Are We Doing? Journal of Applied Social Psychology, 1998. 28\(15 34] Basuroy, S., S. Chatterjee, and S.A. Ravid, How Critical Are Critical Reviews? The Box Office Effects of Film Critics Star Power, and Budgets. Journal of Marketing, 2003. 67\(4 p. 103-117  Proceedings of the 42nd Hawaii International Conference on System Sciences - 2009 10 pre></body></html 





