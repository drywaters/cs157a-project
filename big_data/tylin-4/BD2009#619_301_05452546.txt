Query an image database by segmentation and content   Enrique Castillo Ju·rez, Ivo H. Pineda Torres, Maria J. Somodevilla, Manuel MartÌn OrtÌz Universidad AutÛnoma de Puebla \(BUAP\, Facultad de Ciencias de la ComputaciÛn BUAP Puebla Pue, Mexico coffinov99@gmail.com ipineda,mariasg,mmartin}@solarium.cs.buap.mx      Abstract The Recent advances on image databases have been developed and most of them consider several methods to query image, the amount of information stored is so big that it is a must to use a combination of different techniques such as image segmentation in order to reduce the dimensionality of the search space. Taking advantage of an image pictographic expressiveness together with the soundness of image segmentation methods, it is possible to rely on an efficient method to query an image database. In this work, it is proposed a new method of image segmentation, indexation and retrieval by content. In this paper an image is not considered as a set of objects, is considered as a feature vector where its components represent a segment of color. Color is treated in another color space rather than to work on RGB space. For each image a fuzzy histogram is obtained in order to get for each image its own signature together whit its own feature vector. Fuzzy theory is applied to solve color uncertainty which it comes from color quantification and human perception of colors. The whole set of images, which are in RGB representation are transformed to LAB model, obtaining better color representation in order to obtain a feature vector together with wavelet coefficients Keywords-Image retrieval base on content, fuzzy logic, feature vector, image segmentation, LAB color space I   I NTRODUCTION  Current technology is able to create a vast amount of digital images, and most of the tools and retrieval methods use labels to describe categories and other characteristic especially when color is involved those methods lack of consistency to describe texture, or color itself; current research has proved that using image content and visual interaction gives better results Researchers put emphasis on automatic retrieval of visual content, in order to obtain specific information of an image and then an index is created, that approach is known as Content Based Image Retrieval \(CBIR\IR focuses on efficient retrieval methods especially on large image databases, where imageís characteristics are obtained in an automatic fashion. The features obtained are forms of texture, color, objects, and so on The similarity between images is measured using a similarity measure among feature vectors of images. The feature vectors are a minimal representation of relevant features inside an image which are automatically obtained reducing the space dimensionality and help to perform a query process faster instead of working with the entire set of images. In this work an image is divided into blocks, and each block provides enough information to the feature vector. The process of extraction imageís information and the use of new query methods are combined in order to improve the process of CBIR. Color is considered as a dominant feature and is easily recognized, in such case color histogram becomes an important image descriptor and used in many applications because image histogram captures color distribution. While color histograms are computed without much effort, the results can be used as an index In this paper are combined elements such as Color as a visual feature that is perceived from the moment a person looks as a picture. But the process of image retrieval by color requires a perfect specification of the color model \(Model CIELAB\ this case color must be capable to ensure the correct correspondence between the ranges of colors as perceived by the eye of a human being in contrast to how they are quantified by a CBIR system Color quantification is an important task in the process of image retrieval by color; It should be noted that once is defined a color space, it is necessary to find methods that allow us to quantify the existence of colors, i.e. the correct separability of color within the working space. It is suggested the use of fuzzy techniques and their corresponding functions in conjunction with the application of the color space to allow us to correct discrimination of colors in the defined space The advents of new segmentation methods have increased in recent years because of there is not an optimal algorithm capable of segmenting different types of images with different characteristics. This problem has motivated researchers to work with wavelets such as Haar wavelet and Daubechies wavelets, in our case Haar wavelet are used to extract information from many differents kinds of data such as images The coefficients represent information of a specific block which is used as elements of the feature vector This paper consist of 6 sections where Section 2 reports state of the art with respect to this research, in Section 3 is presented in depth color analysis and why it is used for these experiments; while in Section 4 the segmentation process and clustering method are explained and how they were 
2009 Mexican International Conference on Computer Science 978-0-7695-3882-2/09 $26.00 © 2009 IEEE DOI 10.1109/ENC.2009.39 127 


adapted to work with images, also in this section, the feature vector is obtained. Dealing with color lead us to use a fuzzy approach and here it is explained the use of a fuzzy image histogram. In Section 5 is where is incorporated the similarity measure to determine whether two images or regions are similar. Finally, Section 6 present results of all the experiments that were carried out and conclusions about the method we propose in order to have an efficient CBIR  II  S TATE OF THE ART  Day after day, it is possible to assess how new applications dealing with large collections of images do not perform correctly, mostly because of the retrieval/query process are inadequate. Some examples of these applications can be found in places where large stocks of images and/or art collections need to be stored  T h ere a r e m a ny implementations for CBIR, some of them are Photobook Blobworld, Virage, VisualSEEK and WebSEEK among others a t y pical C B IR  s y s t e m  con s is t o n a collect ion  of images and when a query is  performed invest of the times the result is a combination of images together with some  sort of classification and/or relationships among images; in some situations more than one similarity measure is used in order to come up with correct results The use of low level visual characteristics to perform an information retrieval has brought the attention of researchers  o lor is con s idered, perh aps  th e m o s t do m i n a nt characteristic and the easiest one to distinguish Currently there are different techniques used in CBIR global approach, which is one of the most used, it can be divided in two categories, global approach based on learning process and global approach per region, where each region is identified by its own characteristics [6 T h e g l o b a l approach per region is based on to obtain features such as texture, color, spatial forms and the way those are represented can be used as an imageís signature for each image. The most used characteristic in this idea is image color histogram. Mostly, all the implantations based on histograms have a poor performance the reason behind is that none of those include semantic queries, given the fact that is a hard problem to identify two objects with same color but in different images A system based on image segmentation, performs better when it is possible to assign a compound characteristics that only appears in one region, making the process to identify similarity between images much easier For instance, some studies propose sequential algorithms to label regions by considering color representation of each region or colors that are represented in a chromatic region represented by a histogram and some time by a fuzzy histogram In this paper is assumed a semantic approach to perform a CBIR, it consist that images with some sort of relationship are physically grouped in some feature space. Thus the image retrieval process can be done by getting the nearest neighbor inside the visual space of characteristics. Thus the grouping approach can be applied to a large number of images and obtain a low number of errors [5  Image segmentation is a process that cannot be considered without errors and when it is incorporated to obtain image characteristic to identify images and some other issues have to be cons  T h at s  w h y global pro perties of an  image do not depend on image segmentation accuracy However to segment an image gives an opportunity to gain access inside an image to an object level where each object can be considered as a represent and of a region, let us say texture and chromatic properties are some of those representatives of a region. There is a strong believe that when more features of a region are considered the better will perform a retrieval process  In this paper the image segmentation process is based on threshold histogram with a clustering of color spaces like in 9 It is i m p o r tan t to  m e n tio n th at i n th is research i m a g e  segmentation by color is done without supervision Different approaches have defined image similarity, either using a classic metric or defining a new one. Sometimes color histogram is used as a discriminant function but recently wavelets have been used to have a closer idea about image similarity, even though wavelets have been used as a technique for image compression itís possible to use wavelets together with color and texture as elements to be considered between similarities among images th i s  research wavelets are used to perform image segmentation in a 4x4 block is where wavelets are computed together with the characteristics associated to this region; after some tests the Haar wavelets were selected, because recent studies have shown how using HVS color space to find similarity between images performs well  T h i s  m odel i s su pport ed  on a Gaussian decomposition applied to a XYZ model, by considering some characteristics such as color, contrast and image orientation                    
128 


In general this work involves some process such as  a  Preprocessing of the image: this process includes the exchange between color spaces b  Calculation of the color histogram and its correct representation as a fuzzy histogram c  Compute of the Haar wavelet coefficients in a 4x4 blocks \(1         1 d  Obtaining the components of the feature vector \(2           2 e  Segmentation process by clustering algorithm f  Calculating the similarity between regions and specification of the measure of similarity   III  LAB COLOR SPACE  This section presents and extends the definition of the color space that it will be used throughout the process of segmentation and image retrieval One of the problems when studying color is how to reproduce primary sources of illumination. Experiments carried out by CIE \(commission International de l Eclairage\ave shown that most of the spectral components can be classified in to three primary components  According to a monochromatic stimulus, a color distribution given by C d three primary sources of illumination, it is possible to recover a proportion of color  B k result of  the three sources of illumination  combined with C 3.1     3.1  That is known as a tri stimulus of color is represented by T k c\where w k is the proportion of the primary sources necessary to obtain a reference about the white color in some power distribution and C ents a colour spectral distribution Values of tri stimulus for a color with unique energy spectrum and energy for a wavelength are called spectral curve and CIE recommends three monochromatic sources of color which they correspond to color sensation of green blue and red respectively, with such energy distributions 3.4     Where is considered the distribution function of spectral energy used per color Values obtained from previous equations a chromatic diagram can be represented, where any physical color represents a point in such space. The chromatic coordinateís xyz can be obtained from tri stimulus values XYZ according 3.6\d \(3.7    3.5   3.6      LAB model CIE recommends by identify the amount of color differences based on illumination component. This model has incorporated some chromatics transformations to adapt different sources of illumination Coordinates for LAB model can be obtained from XYZ factors and its corresponding tri stimulus values, according 3.8\o \(3.11     3.8      3.9     3.10     3.11   Where X 0 Y 0 Z 0 correspond to XYZ vars with reference to white color Equation \(3.12\ and \(3.13\ show values that a function can get for a given threshold    
129 


TABLE 1 Suggested tristimulus values  X0 Y0 Zo 0.950456 0.9886 1 1 0.98072 1.13 1 0.98072 1.118225 0.950456 0.950456 1.088754   3.12     3.13  Where the threshold  is use for a good adaptation of the model according different lights sources  After several experiments in our database with 2000 images The values for tristimulus most efficient to represent our image collection are showing in Table 1  It is important to mention that according with tests the most representativeís tristimulus values for different type of images and different kinds of source of lights are: 0.950456 0.950456 and 1.088754 with a threshold predefined and a range of change around 0.008856  IV  IMAGE SEGMENTATION  In this section, is presented the bases for the   segmentation process and clustering method and how they were adapted to work with images, also in this section is where the feature vector is obtained. Dealing with color lead us to use a Fuzzy approach and here is explained how  use of a Fuzzy image histogram Image segmentation is a long standing problem in computer vision. Often it is viewed as an ill-defined problem in comparison to other vision tasks which have apparently well defined   objectives, such as detection, recognition, and tracking. Unfortunately, without addressing segmentation problems, those special purpose vision tasks are fundamentally ill-defined To extract the characteristics of color has been decided the use of CIELAB color space and the corresponding transformations. Taken as a descriptor for this situation, is adopted a fuzzy histogram Once for each region is generated a fuzzy histogram, the large value in each histogram represents a color with higher probability inside of an image, that values represents which color appears more frequently in each region, remember that in LAB model we have three components that represent color information; the first tw o correspond to color \(as in RGB\d the third one corresponds to the amount of illumination in a region, each component is represented by c1, c2, c3} respectively  F UZZY COLOR HISTOGRAM  There are many reasons to include a Fuzzy approach in this research. The most important of them are as follows 1  Fuzzy techniques are powerful tools for knowledge representation and processing 2  Fuzzy techniques can manage the vagueness and ambiguity efficiently After the image data are transformed from gray-level plane to the membership plane \(fuzzification\, in our case CIELAB, appropriate fuzzy techniques modify the membership values. This sometimes is considered as a fuzzy clustering, a fuzzy rule-based approach, and a fuzzy integration approach and so on The representation for our work would be vague only if we extract the features in a single block of the image representing size\nd considering only the signature of the region. Color is one of the most critical features when it is used to discriminate images. Therefore we can take advantage of all available information contained in the characteristic block Taking into consideration the above as well as to quantify human perception colors, it is necessary to create a descriptor for each region based on a modified color histogram For the color descriptor for the application of fuzzy techniques will focus on the color distribution per region The important point of this step will be to assume that each color will be included in a set of fuzzy modeling set a membership function. Fuzzy sets F in a space of features R n  that is defined by a mapping R n  f: R n 0, 1 k n o w n a s a  member ship function. For each vector f R n the value of f f\ called degree of membership of the fuzzy set f The fuzzy descriptor represents similarity in a way that it decreases in the same amount as similarity becomes larger The Cauchy function was selected to map color from CIELAB space to a fuzzy set; according to equation 4.1 Cauchy function has been widely used as a heavy-tailed distribution, with application on fuzzy set theory Cauchy function can be defined as \(4.1        4.1  Where v     d  R, d > 0  0,  v represents the local center of fuzzy set, d represents the width of the function and determines the body of the function, d and  describes the degree of  fuzziness Thus, the similarity metric is defined as \(4.2       4.2  
130 


   Fig. 3.Coefficent of a wavelet  Where d represents the Euclidean Distance between color  and color c in the LAB color space and is the average distance between the colors as seen in \(4.3         4.3  Where the iteration B is the number of bins that exist in a partition or a region The fuzzy color model enables us to expand the influence of a color according to their neighborhood, based on a principle of percentage of similarity. That means each color found in the image is associated with the quantification of all colors according to their similarities. This is represented in \(4.4    4.4  Where is the universe of colors in the image and   corresponds to the image histogram. Finally, fuzzy color histogram under amortization process using \(4.5\ order to have values between    4.5  For the purpose of this work the number of bins selected was around of 96 bins As it was stated before, the last three components of the feature vector correspond to the energy of high frequency for a Haar wavelet. This transformation is applied to each L component and to each pixel in a 4x4 region, where each band will have 2x2 coefficients. Assuming, that in HL band the coefficients will be       Where each component will be computed as \(4.6        4.6  If D \(n\ponds to the application of a wavelet in one dimension in a region associated with a one-dimension function then a Wavelet coefficients is represented by equation 4.9  D V n, m\ = C\(n\ D\(N LH D H n, m\ = D\(n\ C\(N HL                                         \(4.9 D D n, m\ = D\(n\ D\(N LL   Where m,n represents the size of the image, this is shown more clearly in Fig. 3 The frequency components are calculated for each region as T1, T2, T3} and the feature vector for each region have six components  At this point what we have is: an image that has been segmented in blocks of 4x4 sizes where each region is represented by a feature vector as \(4.7           4.7 We think that the best method that we can use to classify an image is the k-means algorithm, whose basic task is to group the vectors in a minimal set of classes, where each class will be associated to a region or segment of the image to explore. As initial condition for the implementation of minimum-k algorithm we suggest the next steps  1  The initial numbers of clusters for each image at first iteration , the centroids are randomly choosen among the feature vectors of colors  2  For the k-means algorithm is proposed a similarity measure defined as L2 as shown in \(4.8       4.8  Where c 1 c 2 y  t 1 t 2 corresponds to the characteristics of color and frequency, respectively, before initializing  w c 0.65 , w t 0.35 based on a process of trial and error within the experiment. Where w c and w t are defined in   Figure 7 shows the segmentation results of two sample images. In this figure, \(a\nd \(c\ two images in the database, respectively, figur d\e segmentation in the new color space. Each region is marked by the segmentation of the average color of all blocks associated with the region       
131 


 a\                                                   \(b  c\                                               \(d  Figure 7: Regions obtained for two example image s labeled with the average color of blocks belonged to it a\ Image 5985 blocks b\gmented image \(3 regions c\ Image 14260 blocks d\gmented image \(3 regions  V  S IMILARITY MEASURES AND I M In this section we show how is incorpora t measure to determine whether two imag e similar For each image and for each region a futur e as an image signature Once images are characterized b y a featu r precede to the analysis of similarity betwe This process generates from the charact e each class  in order to find the minimum d the vectors of each image \(5.1  Similarity= [min [DIST \(FV i   Where FV i and FV j represent the featur e section 4  The Euclidian Distance for this experiment   007&\007+\0075\0076 015L 000\003\000\003\000\003 015 007S 013 003 000\003 022 007 013·\013 0135 015F\007 013·\013 0136 022 0136\000\003\000\003\000\003 0137 013‹\013@\0135 015F\000\003\007S 013 003 000\003 022 007 013 0135 0137 013‹\013@\0135  Where  c 1 n c 2 n and  c 1 m c 2 m corresp o characteristics of the feature vector for a  000  For a region n in I 1 and region m i n 000  Images \(I 1 d \(I 2 d the i regions   s each region is t  M AGE PROCESS  t ed the similarity e s or regions are e vector is stored r e vectors, it will e en these images e ristic vectors of d istance between FV j  5 1  e vectors for the is show in \(5.2 013 013 0135 015F\007 013‡\013 0136 022 0136\000\003\000\003\000\003 5.2 o nds to the color n I 2  i r correspondent  By setting set w c 0.65, which it w tests o r der to determ i n e h o w similar, it is necessary to  Step 1. Calculating the minimum d of image 1 and all regions of image  007+\007I\007=\007C\007A\000\003\0075\007E\007I\007E\007H\007=\007N\007E\007P\007U 015L 000  Where Image Similarity corres p distance between a region of imag e image 2, which is evaluated b y m a similarity between two regions  Step 2.  In this step the sum of mi n region is calculated and the amoun t images is evaluated. In other word s distances approaches to zero; it m similar to \(5.4  005*\000\003\022:\007+\001 007,\022 015L 003 000è\000ã\000ê\000\003\022:\000\003\007  VI  EXPERIMENTS AN D In this section the experiments are p extract some conclusions about th e order to have an efficient CBIR Experiments were carried out in image database has 2000 images a with 120 images that are not st o number of images in each class; a n query images are classified Given a query image, it is segme n computed .or each image in the d a vector \(images signature\which i queried image in order to have a va l In order to evaluate the method, t w    0072\007N\007A\007O\007E\007?\007E\007K\007J 015L 000\003\000\003 002\001 013¬\013‡\013‘\013⁄\013À\013ÿ\013ﬂ\013ÿ\013È\013 013 002\001 013¬\013‡\013 013  0074\007A\007?\007=\007H\007H 015L 000\003\000\003 002\001 013¬\013‡\013‘\013⁄\013À\013ÿ\013ﬂ\013ÿ\013È\013‘\013·\013Á\000\003\005Í\000\003\013 002\001 013¬\013‡\013‘\013⁄\013À\013ÿ\013ﬂ\013 013   Where  imageRelevant correspond that the users thinks that has a  clea r query and imageResult correspond s retrieved by the system  Table 8 shows how those ratios 6 can see precision performs better t h In general we can conclude that the r in the concept of precision and reca w as obtained after several w given two  images are d istance between a region 2 as defined in \(5.3 000 000ã\000ê\000\003\022<\000\003\007&\007+\0075\0076\022:\007+\001 007,\022;\022 5.3 p ond to the minimum e 1 and all regions of the ximizing the potential of n imum distances for each t of similarity between de s if the sum of minimum m eans that  images are 007+\0075\0076 022 007+\001 007 022 022 0136 5.4 D  C ONCLUSIONS  p resented and analyzed to e method we proposed in different fashions. The a nd a query set of images red. Table 6 shows the n d table 7 shows how the n ted, its feature vector is a tabak we have a feature i t is compared with the l ue of similarity w o measures are defined 013 013Á\000\003\005Í\000\003\013¬\013‡\013‘\013⁄\013À\013ÿ\013Ê\013Ë\013ﬂ\013Á\000\003 002\001 013 013À\013ÿ\013Ê\013Ë\013ﬂ\013Á\000\003 002\001 6.1 013‡\013‘\013⁄\013À\013ÿ\013Ê\013Ë\013ﬂ\013Á\000\003 002\001 013 013‘\013·\013Á\000\003 002\001 6.2 to the number of images r similarity according the s to the number of images 6 1 & 6.2.\ work as you an recall r e is a very low error rate ll 
132 


TABLE 7 Classification of images of the test universe  TEST UNIVERSE CLASS  NUMBER OF ELEMENTS ANIMALS  22 SPORTS  7 FIGURES  7 PEOPLE  18 TRANSPORT  17 OTHERS  23 FRUITS AND FOOD  9 GRAY  0 PLANTS  13  TABLE 6 Classification of images of the universe in the database  DATA BASE UNIVERSE CLASS  NUMBER OF IMAGES ANIMALS  401 SPORTS  158 FIGURES  153 PEOPLE  246 TRANSPORT  143 OTHERS  161 FRUITS AND FOOD  267 GRAY  103 PLANTS  368  TABLE 8 Result of the measure of performance  TEST UNIVERSE CLASS precision Recall ANIMALS  0.186604764 0.260361715 SPORTS  0.242973973 0.338666863 FIGURES  0.271378713 0.384758091 PEOPLE  0.186242822 0.246916303 TRANSPORT  0.33525437 0.577798009 OTHERS  0.403626766 0.738559301 FRUITS AND FOOD  0.238778354 0.334442123 GRAY  0 0 PLANTS  0.226628522 0.312526742  We can also note that the images of animals, plants and fruits are the most difficult to retrieve because of its high content of color and variety of content, demonstrating that our approach is designed to retrieve content \(color\ an image Consistent with the above in this work we present the development of a methodology for image retrieval based on features extracted from a simple model of the human visual system. Our emphasis is not geared to this specific model but according to the proposal of vector component layers of characterizing an image In particular, this new methodology seems to be a reliable option against the conventional methods of image retrieval by content. In contrast our method is not designed for image retrieval by shape or texture, simply it is  away to obtain an mage a description of a single color image Furthermore, we have demonstrated that features such as color, diffuse components and the frequency can be of great value for images retrieval           R EFERENCES   1  Del Bimbo A, Corridoni J.M., De Magistris S., ìImage query by semantical color contentî,  Year of Publication:1996, ISBN: 0-89791834-7  2  Zhang  Ruofei , Zhang  Zhongfei \(Mark\,î A robust color object analysis approach to efficient image retrievalî, EURASIP Journal on Applied Signal Processing archive Volume 2004 ,  Issue 1  \(January 2004\ ISSN:1110-8657  3  Deng Yining, Manjunath B. S., Kenney Charles, S. Moore Michael Shin Hyundoo, ìAn Efficient Color Representation for Image Retrievalî, Year of Publication: 2000  4  Sharon, Tait John, ìSearch strategies in content-based image retrievalî, Full Source Annual ACM Conference on Research and Development in Information Retrieval archive, Year of Publication: 2003,ISBN:1-58113-646-3  5  Jin Xiangyu, French James C, ìImproving   Image Retrieval Effectiveness via Multiple Queriesî, MMDBí03, November 7, 2003 New Orleans, Louisiana, USA. Copyright 2003 ACM 1-58113-7265/03/0011  6  Carson Chad, Belongie Serge, Greenspan Hayit, Malik Jitendra Blobworld: image segmentation using expectation-maximization and its application to image queryingî, Pattern Analysis and Machine Intelligence, IEEE Transactions, Publication Date: Aug. 2002, ISSN 0162-8828  7  Chen  Yixin,  Z. Wang  James, Krovetz Robert, ìContent-based image retrieval by clustering Full textî, Proceedings of the 5th ACM SIGMM international workshop on Multimedia information, year of Publication: 2003 ,ISBN:1-58113-778-8   8  Xia Yong, Dagan Feng, and Zhao Rongchun, ëíOptimal Selection of Image Segmentation Algorithms Based on Performance Prediction Center for Multimedia Signal Processing, Dept. of Electronic and Information Engineering, Hong Kong Polytechnic University,Year of Publication: 2004,   ISBN ~ ISSN:1445-1336 , 1-920682-18-X   
133 


9  David X. Zhong, ëíColor Space Analysis in Color Image Segmentationíí, School of Electrical and Information Engineering The University of Sydney, Year of Publication: 2000, ISBN ISSN:1445-1336 , 0-909-92580-1     Pedro F. Felzenszwalb, Pedro F. Felzenszwalb, Daniel P Huttenlocher, ëí Efficient Graph-Based Image Segmentation Artificial Intelligence Lab, Massachusetts Institute of Technology and Computer Science Department, Cornell University, International Journal of Computer Vision, Volume 59, Number 2, September 2004    Thomas Frese, Charles A. Bouman and Jan. P. Allebach, íëA Methodology for Designing Image Similarity Metrics Based on Human Visual System Modelsíí, School of Electrical Engineering Purdue University, West Lafayette, IN 47907-1285, Feb.\\ 10-13 1997 
134 


ate for such review as notes are paper and PC. In tory context were a ed ethnographically  US notes  anese notes ct Field Trials from ethnographic abits appropriate for rticipate in a monthting DP product e ?DP appropriate detailed notes on a fessional purposes iew, and expressed Proceedings of the 42nd Hawaii International Conference on System Sciences - 2009 4 interest in using a DP product given a Logitech io2 Digital Pen kit [12] and additional notebooks \(approximate retail value US 150 interviewed at intervals of one to two weeks and again at one month to determine their DP usage pattern. Follow-up interviews included discussion of how they used the DP product, benefits and limitations, review of notes taken with it, and changes in their note-taking behavior, including continued usage or abandonment of the product  3.3.2. Findings. 8 full-time office workers and 7 fulltime university students participated. After two weeks, 7/8 knowledge workers and 5/7 students had stopped using the DP product. Primary reasons they stopped were \(a special pen and paper; \(b notes taken on dedicated paper, as opposed to the value of writing on handouts and other documents c instead of paper; \(d of handwriting recognition ? users frequently said that a digital system has little value unless it can automatically transcribe notes Among the 3/15 people who continued using DP the primary value was to have an archive in case of loss of important handwritten documents, such as artistic sketches. After one month, no knowledge worker \(0/8 1/7 the product. The 7 college students were asked: if they lost the product, how much would they pay for a replacement? Most said they would pay $10 or less and none said he or she would pay more than $25  3.3.3. Implications for DP. The primary finding is that existing behavior with pen and paper fits most people?s needs well and is difficult to change. People experience significant advantages from the ability to use any paper, from any source, with existing pens; to be able to use existing writing devices with any paper-based document; the ready availability of pens pencils, and paper in their common environments and the low cost of traditional pens and papers Using DP requires attention to one specific pen and one kind of paper. Given the low perceived benefit of PC-based review of notes, most users had little incentive to engage in such a change in behavior The low stated value and nearly unanimous abandonment of product usage in this trial imply that adoption of similar products would likely be low  


 3.4. Research Series 4: Enterprise Site Visits  3.4.1. Method. The research team identified 28 organizations that represented a breadth of industries that were expected either to be significantly interested in DP note-taking applications for individual employees \(e.g., professional services expected to be largely uninterested \(e.g manufacturing team visited in person if possible \(N=23 scheduled conference calls with representatives N=5 interviewed both individual knowledge workers and IT management who were responsible for knowledge worker productivity systems. The interviews surveyed organizations? note-taking and retention practices, collected samples of hand-written artifacts observed knowledge worker workplaces \(when possible to what they viewed as potential applications for DP in their workplaces  3.4.2. Findings. The breakdown of organizations visited is shown in Table 2. Among the organizations 8/28 expressed high interest in DP technology principally in professional services, law, and education and research organizations. Common penrelated artifacts in those organizations were personal notes taken during meetings \(either internal meetings or client meetings do lists; and business-related drawings \(charts engineering drawings, architectural sketches, etc  Table 2: Summary of Organizations Visited  Line of business US  Outside US Finance N=3 N=2 \(Japan Insurance N=1 N=1 \(Japan Healthcare N=3 N=1 \(Japan Law N=3 Professional services and consulting N=2 N=1 \(India N=1 \(Canada N=1 \(Japan Transportation and manufacturing N=4 Education and research N=2 Government services N=2 Publishing  N=1 \(Japan  Organization size US  Outside US Medium \(100-999 employees N=3 N=1 \(Japan N=1 \(Canada Large \(1000-9999 employees N=6 N=3 \(Japan N=1 \(India Very large \(&gt;10000 employees N=11 N=2 \(Japan  The key benefits of DP technology were viewed as retention of information for intellectual property Proceedings of the 42nd Hawaii International Conference on System Sciences - 2009 5 backup, assurance of regulatory compliance issues e.g., documentation for patents 


search for information \(assuming handwriting recognition within centrally archived DP documents Among work artifacts, we observed frequent mixture of work-related and personal information on a single piece of paper \(for instance, meeting notes together with personal reminders frequently taken on environmental paper \(meeting handouts, the unprinted side of discarded documents sheets of copy paper, note pads, etc freely mixed text and drawings In some cases, text was mixed between a native language and a foreign language or other linguistic context. For example, engineering and research organizations often included mathematical symbols healthcare facilities used many abbreviations, drug names, chemical terms, and Latin phrases themselves often abbreviated terms were often borrowed from German and English A frequent observation in business settings was the free availability and exchange of pens: people could expect offices and meeting rooms to have extra pens available such that there was little need to possess a personal pen. Participants also reported frequently losing pens Another striking observation was the sheer prevalence of paper documents. As Sellen &amp; Harper noted in The Myth of the Paperless Office [16], paper provides an interaction model that is well optimized for many uses and appears to be growing, not shrinking, in importance as offices are increasingly handling digital documents. In many cases, we observed the sheer exposed surface area of paper documents in an office \(e.g., the tops of document piles on a desk screen We observed significant cultural differences between the US and Japan. In Japan, knowledge workers reported attending fewer formal meetings than in the US, and it was common for meetings to have a dedicated note taker ? often a junior employee who produced formal notes \(minutes attendees. Thus, individual note taking in meetings appeared to be less necessary in Japan than in the US although the automation value of DP for the specified note-taking employee might be high Multi-color ballpoint pens appeared to be popular in Japan. In our individual sessions in Japan Research Series 2 above participants to have three-color retractable ballpoint pens. Ink colors were used for idiosyncratic patterns of content differentiation, e.g., separating facts recorded in a meeting from personal conjectures by writing them in different colors This pattern of writing with color was also observed during our enterprise site visits in Japan and suggests that DP technology may need to provide a simple way to meet the need for ad hoc content differentiation that color provides. Finally, signatures in Japan are generally given with a personal ink stamp \(?hanko This is a more important consideration for formal documents using DP than for note taking, but the need to implement a ?digital hanko? was a common observation of participants We also observed user-perceived barriers that were specific to various lines of business. For instance, in the Japanese insurance industry insurance agents are independent and sell policies for multiple companies; a single insurance company would find it difficult to require agents to work with proprietary DP technology. In US medical settings, a common concern was compliance with the 


common concern was compliance with the Healthcare Insurance Portability and Accountability Act \(HIPAA information privacy. Organizations were unsure whether DP products would be HIPAA compliant and even if the products themselves were secure whether their onboard information could be kept secure when the pens are small and easily lost  3.4.3. Implications for DP. Although there was substantial interest in DP technology among professional services and white collar organizations the ethnographic findings suggest that delivering appropriate value from DP technology would be difficult. The first barrier would be providing a platform that either conforms to or changes current behaviors around pen and paper: free availability of pens and unpatterned paper in the workplace behaviors of writing on environmental paper, and the need to keep up with a personal pen with one?s data The second barrier would be to meet expectations around text; much of the value was seen as being in retention and searching of textual information, but this would be made difficult by the frequent inclusion of acronyms, abbreviations symbols, and foreign languages. Many organizations saw value in centralized repositories that would manage DP information across many employees; this would require an IT infrastructure that was not available \(e.g., to manage the DP pattern space might be difficult and expensive to develop and maintain. It also poses questions about privacy, since employees might not wish the archive to retain personal information captured alongside work notes Finally, because we noted real or perceived barriers that were highly specific to various industries it appeared that DP solutions would be most likely to succeed if they were tailored to very specific settings Proceedings of the 42nd Hawaii International Conference on System Sciences - 2009 6 and use cases. This does not argue against DP usage and its value, but it suggests that delivering value to organizations may require substantially more design and development effort than a single general solution or platform would provide  4. Discussion  Our findings show that the interaction model of DP technology diverges substantially from common pen and paper usage. This divergence leads to unclear utility of DP for consumer note-taking purposes, and in a field trial, resulted in high abandonment rate of a consumer DP product. Among the most significant limitations were the low value seen in review of facsimile notes on a PC, the requirement with DP to use a special pen paired with patterned paper, and the low perceived value of capturing only notes taken on blank paper as opposed to handouts and other materials. In the enterprise space, the environmental issues were even more prominent due to the common infrastructure of freely available, communal pens and paper and the lack of IT infrastructure for DP document retention The note-taking research reported here suggests that writing behavior comprises many important areas besides capture, retention, and review of specific data. For instance, a single blank piece of paper or a one-word reminder may adequately serve as a reminder to do something that one intends, even though there may be little or no content as such Likewise, in interpersonal contexts such as attending 


Likewise, in interpersonal contexts such as attending a lecture, it may be socially desirable to take notes even if they are later simply disposed. Taking notes may also serve purposes of memory consolidation even when the content is never reviewed [8][9  4.1 DP and Writing Acts  Linguistic acts in social context have been described using a model of performative behavior commonly known as ?speech acts? theory [15 Chapman [2] extended that model to encompass writing, suggesting that many aspects of ?writing acts are unique and separate from spoken language.  In the extended model, writing acts may be described with a multidimensional taxonomy encompassing a writer?s context, aspects of the process, type of content, and linguistic features of the content Table 3 summarizes the dimensions of writing acts \(from [2 exemplify each dimension. For instance, ?separability denotes the extent to which items in a document are logically independent of one another; in a contract nothing is separable because the document is a single piece, while on a to-do list, many or all items may be independent of one another [2 DP technology may benefit from attention to the dimensions that are exemplified by writing acts embedded in social contexts. DP systems may be able to perform some kinds of writing acts quite well, but in other cases, DP may be inconvenient, unnecessary or inappropriate. Models such as the writing acts framework can be used both to understand user behavior broadly and systematically to explore the applicability of DP products across the general space of writing behavior A key problem for DP in note taking applications is that note taking can involve nearly every possible dimension of writing acts. Notes may be separable or not; they may serve as functional content or as contextual reminders; they may present just the facts? or be more interpretive; they may be transient or might be intended to be archival documents; and so forth. In short, notes are able to present a vast array of writing styles that pose substantially different value propositions and technological implications for DP products Delivering a general DP solution for note taking may therefore be expected to be difficult  Table 3: Dimensions of Writing Acts [2  Dimension Exemplars Separability a contract vs. a to-do list Function a typed inventory list vs calligraphy Emotionality a love letter vs. a packing slip Spatiality a transcript of speech vs. a diagram depicting concept relationships Associativity notes from class vs. doodling Linearity chronological notes vs. notes placed in a spatial ordering scheme Originality an essay vs. feedback on a manuscript Prescriptivity a signature vs. general notes Finality a document that will be archival vs. one that is a draft Structure a grocery list vs. concepts from a brainstorm Personality a letter to someone vs. a 


Personality a letter to someone vs. a journalistic essay Formality a business letter vs. a greeting card to a close friend  Proceedings of the 42nd Hawaii International Conference on System Sciences - 2009 7 For product development purposes, the writing acts framework can be used to ensure coverage of use cases by generating possible scenarios combining various attributes of written documents. These potential combinations may then be explored evaluated, and prioritized for research attention development effort, or testing  4.2 Possible Directions for DP Technology  4.2.1. Note taking. What would make DP technology more popular for note taking? Our research suggests that this is a complex question because there are numerous behavioral barriers. The largest single problem for DP may be that it is a closed system comprising a special pen and patterned paper and does not function with the wide array of writing utensils and paper products that people use especially for environmentally available pens, paper and documents. If this problem could be solved or mitigated through an expanded DP technology platform, DP would avoid the large behavioral block posed by the current need for users to change their existing pen and paper habits DP effectively focuses on notes as data neglecting many aspects of the embedded social nature and process function of notes. If DP notes were easily integrated into a wider range of behavioral processes, adoption should increase. For example, if notes could be automatically handled for content such as phone numbers, appointment times reminders, temporary content, and the like, then the DP platform would come closer to matching current pen and paper usage. However, in many cases, there is a separate and larger issue: computer technology today also is not integrated into such processes. To take a simple example, consider a written grocery list Even if the problem could be solved to recognize extract, and transfer the list to a PC, it would be of little use because, for most people, the PC itself is not integrated into the grocery shopping process. Much information of this kind is transient; there is no need to manage or retain it once the paper has been used An example of potentially closer workflow integration is shown in the recently released Livescribe Pulse Smartpen [11], which couples the Anoto DP platform with audio recording such that note takers can review the audio of a meeting or lecture at the exact point that a note was written. We believe that these kinds of additions to base DP functionality are likely to appeal to specific niches of users, but as more use cases like these are enabled over time, DP may successively attain value for larger numbers of users In our field trials and organizational visits, one of the most common customer expectations was that DP notes should be converted from handwriting to text; respondents commonly noted that PC data is of little use unless it is transcribed to text. To meet customer demands, a DP product will need to address this expectation: the DP must either deliver text recognition with very high accuracy, which is a difficult problem, or it should manage the expectation in some other way that preserves customer perception of value from PC integration 


of value from PC integration The high cost of DP products \(approximately US 100 for a pen, plus the need for specially patterned paper demonstrable additional benefit. Transferring notes from paper to a PC today merely involves typing Unless the need for automation is great and the DP function is nearly perfect, users may simply prefer to type or to carry paper rather than to change behavior to use expensive and less flexible technology  4.2.2. Structured input. As noted in the Introduction above, another use case for DP technology is structured input of information. In particular, DP technology may be useful for form-based input into database and workflow systems, where information is initially recorded on paper forms and then automatically transferred from the pen to a database application. Although the present research report is concerned primarily with note taking applications, in the course of our enterprise research we discussed potential applications for forms-based DP usage We noted possible use cases that fell into five general areas: \(1 easier input of information by customers, such as clients filling out deposit or withdrawal slips at a bank; \(2 information from paper to database without needing to rekey or type the information, such as factory inspection and quality assurance logs, traffic tickets shipping manifests, and so forth; \(3 environments that were not suitable for handheld computing devices, such as construction sites and some kinds of manufacturing facilities; \(4 in which paper-based records are desirable for either employee compliance or customer comfort, such as medical settings; and \(5 based records are necessary, e.g., for legal reasons but a DP product could support faster turnaround and error correction. An example of such application involved financial forms that undergo offsite optical character recognition; a DP system might allow immediate recognition and error correction We plan to report this line of research fully in the future. For now, we note that each of those areas has various benefits and potential limitations with regard to DP technology. Forms-based use cases are more precisely defined and structured than note taking, in Proceedings of the 42nd Hawaii International Conference on System Sciences - 2009 8 terms of environment, workflow, and content; the information context, form design, and potential for systems integration with rapid feedback may mitigate issues with handwriting recognition; and enterprise customers may be less price sensitive than consumers Thus, structured input appears to be a more promising near-future application of DP technology than note taking  4.3 Research Discussion  As we noted above, the present research was primarily behavioral and qualitative. Thus, despite the strength and consistency of our results across multiple samples, contexts, and locations, we present no specific metrics or tested hypotheses on user behavior with DP products. Our findings could be used to inform directional hypotheses for future depth or quantitative research. For instance, one might formulate and test hypotheses about cultural differences, interest levels in DP between various groups such as professional and non-professional 


office workers, market research metrics such as price sensitivity, and the like It is important to underscore the value of ethnographic fieldwork in the present research. It would be possible to conduct design research that explores how to make DP technology better, e.g., in terms of usability and function, without investigating exactly what people would do with such products and why. It was only when we investigated behavior in depth that we discovered the divergence of DP products? limited current value for note taking, as opposed to the high value that one might presume in the absence of depth research  5. Conclusion  In our research, initial trials of digital pens in a controlled setting \(Research Series 2 above suggested potentially good fit between digital pen functionality and consumer note taking needs However, when we explored real world behavior in note taking \(Research Series 1, 3, and 4 above found many potential barriers to adoption of digital pens for note taking. In particular, traditional pen and paper offer advantages in terms of cost, widespread and ad hoc availability, flexibility to work with multiple sources seamlessly, behavioral workflow integration, and manageability of content The value of using digital pens will increase if manufacturers are able to expand their platform technology progressively to enable broader coverage of behavioral scenarios and habits, focusing on the broad range of writing behaviors rather than just needs for facsimile replication on a computer Alternatively, digital pen technology may be more easily applied to tasks involving structured input rather than unstructured note taking We suggest that DP development efforts should use existing linguistic frameworks \(e.g., [2 the space of writing acts of interest. This should allow DP products to target behavioral needs in a more focused manner, leading to higher customer adoption  6. Acknowledgements  We thank many people who participated in this research: first and foremost, the numerous research participants, firms, and organizations who so generously shared their time and insights, but who must remain confidential; and many colleagues and research partners at Microsoft who collaborated on the technology investigation and research efforts especially Jeff Staiman, Vince Ball, Brian Williams Yoshiyuki Moriya, Stephen Cooper, Dave Shen Setsuko Arimatsu, Benjamin Babcock, Dennis Meinhardt, John Chiloyan, Glen Larsen, Mehrdad Basseri, Lori Birtley, Ken Hinckley, and Jian Wang  7. References  1] Anoto Group. Digital pen and paper. Web page http://www.anoto.com/?id=158, last retrieved May 28 2008  2] Chapman, C. N. Writing acts: taxonomy and technological implications. Paper presented at North American Computing and Philosophy \(CAP Corvallis, OR, August 2005  3] Despont-Gros, C., B?uf, C., Geissbuhler, A., and Lovis C. \(2005 


C. \(2005 Implementation and Use in an Existing Clinical Information System. In Connecting Medical Informatics and Bio-Informatics: Proceedings of MIE2005 - The XIXth International Congress of the European Federation for Medical Informatics, 328-333. IOS Press, 2005  4] Fetterman, D. M. Ethnography, 2nd ed. Thousand Oaks CA: Sage, 1997  5] Furukawa, N.  Ikeda, H.  Kato, Y.  Sako, H. D-Pen: a digital pen system for public and business enterprises. In Frontiers in Handwriting Recognition 2004: Proceedings of the Ninth International Workshop on Frontiers in Handwriting Recognition \(IWFHR-9 2004  6] Guimbreti  re, F. 2003. Paper augmented digital documents. In Proceedings of the 16th Annual ACM Symposium on User interface Software and Technology Proceedings of the 42nd Hawaii International Conference on System Sciences - 2009 9 UIST ?03 November 2003  7] Holman, D., Vertegaal, R., Altosaar, M., Troje, N., and Johns, D. 2005. Paper windows: interaction techniques for digital paper. In Proceedings of the SIGCHI Conference on Human Factors in Computing Systems \(CHI ?05 Portland, Oregon. New York: ACM, 2005  8] Kiewra, K., DuBois, N., Christian, D., McShane, A Meyerhoffer, M., &amp; Roskelley, D. Note-taking functions and techniques. Journal of Educational Psychology, 83 240-245, 1991  9] Kobayashi, K. Combined effects of note-taking/reviewing on learning and enhancements through interventions: a meta-analytic review. Educational Psychology, 26, 459-477, 2006  10] Liao, C., Guimbreti  re, F., and Hinckley, K. 2005 PapierCraft: a command system for interactive paper. In Proceedings of the 18th Annual ACM Symposium on User interface Software and Technology \(UIST ?05 Seattle, WA. New York: ACM, 2005  11] Livescribe. Pulse Smartpen [electronic device http://www.livescribe.com/, last retrieved May 28, 2008  12] Logitech. io2 Digital Pen [electronic device http://www.logitech.com/index.cfm/mice_pointers/digital_ pen/devices/408&amp;cl=us,en, last retrieved May 28, 2008  13] Norrie, M. C., Signer, B., and Weibel, N. Print-n-link weaving the paper web. In Proceedings of the 2006 ACM Symposium on Document Engineering \(DocEng '06 New York: ACM, 2006  14] Randall, D., Harper, R., and Rouncefield, M Fieldwork for Design: Theory and Practice. London Springer-Verlag, 2007  15] Searle, J. R. Speech Acts: An Essay in the Philosophy of Language. Cambridge: Cambridge Univ. Press, 1969  16] Sellen, A. J. and Harper, R. H. The Myth of the Paperless Office. Cambridge, MA: MIT Press, 2003  17] Signer, B. and Norrie, M. C. 2007. PaperPoint: a paper-based presentation and interactive paper prototyping 


paper-based presentation and interactive paper prototyping tool. In Proceedings of the 1st international Conference on Tangible and Embedded interaction \(TEI ?07 Baton Rouge, Louisiana. New York: ACM, 2007  18] Tanabe, K., Yoshihara, M., Kameya, H., Mori, S Omata, S., Ito, T., Automatic Signature Verification Based on the Dynamic Feature of Pressure. Proceedings of the Sixth International Conference on Document Analysis and Recognition \(ICDAR ?01 Computer Society, 2001   Proceedings of the 42nd Hawaii International Conference on System Sciences - 2009 10 pre></body></html 


The HyspIRI mission utilizes innovative techniques to both reduce the amount of data that must be transmitted to the ground and accommodate the required data volume on the ground The infrastructure and techniques developed by this mission will open the door to future high data volume science missions The designs presented here are the work of the authors and may differ from the current HyspIRI mission baseline A CKNOWLEDGMENTS This research was carried out at the Jet Propulsion Laboratory California Institute of Technology and was sponsored by the Space Grant program and the National Aeronautics and Space Administration R EFERENCES  K W ar\002eld T  V  Houten C Hee g V  Smith S Mobasser B Cox Y He R Jolly C Baker S Barry K Klassen A Nash M Vick S Kondos M Wallace J Wertz Chen R Cowley W Smythe S Klein L Cin-Young D Morabito M Pugh and R Miyake 223Hyspiri-tir mission study 2007-07 002nal report internal jpl document,\224 TeamX 923 Jet Propulsion Laboratory California Institute of Technology 4800 Oak Grove Drive Pasadena CA 91109 July 2007  R O Green 223Hyspiri summer 2008 o v ervie w  224 2008 Information exchanged during presentation  S Hook 2008 Information e xchanged during meeting discussion July 16th  R O Green 223Measuring the earth wi th imaging spectroscopy,\224 2008  223Moore s la w Made real by intel inno v ation 224 http://www.intel.com/technology/mooreslaw/index.htm  T  Doggett R Greele y  S Chein R Castano and B Cichy 223Autonomous detection of cryospheric change with hyperion on-board earth observing-1,\224 Remote Sensing of Environment  vol 101 pp 447\226462 2006  R Castano D Mazzoni N T ang and T  Dogget 223Learning classi\002ers for science event detection in remote sensing imagery,\224 in Proceedings of the ISAIRAS 2005 Conference  2005  S Shif fman 223Cloud detection from satellite imagery A comparison of expert-generated and autmatically-generated decision trees.\224 ti.arc.nasa.gov/m/pub/917/0917 Shiffman  M Griggin H Burk e D Mandl and J Miller  223Cloud cover detection algorithm for eo-1 hyperion imagery,\224 Geoscience and Remote Sensing Symposium 2003 IGARSS 03 Proceedings 2003 IEEE International  vol 1 pp 86\22689 July 2003  V  V apnik Advances in Kernel Methods Support Vector Learning  MIT Press 1999  C Bur ges 223 A tutorial on support v ector machines for pattern recognition,\224 Data Mining and Knowledge Discovery  vol 2 pp 121\226167 1998  M Klemish 223F ast lossless compression of multispectral imagery internal jpl document,\224 October 2007  F  Rizzo 223Lo w-comple xity lossless compression of h yperspectral imagery via linear prediction,\224 p 2 IEEE Signal Processing Letters IEEE 2005  R Roosta 223Nasa jpl Nasa electronic parts and packaging program.\224 http://nepp.nasa.gov/docuploads/3C8F70A32452-4336-B70CDF1C1B08F805/JPL%20RadTolerant%20FPGAs%20for%20Space%20Applications.pdf December 2004  I Xilinx 223Xilinx  Radiation-hardened virtex-4 qpro-v family overview.\224 http://www.xilinx.com/support/documentation data sheets/ds653.pdf March 2008  G S F  Center  223Tdrss o v ervie w  224 http://msp.gsfc.nasa.gov/tdrss/oview.html 7  H Hemmati 07 2008 Information e xchanged during meeting about LaserComm  223W orldvie w-1 224 http://www digitalglobe.com/inde x.php 86/WorldView-1 2008  223Sv albard ground station nor way.\224 http://www.aerospacetechnology.com/projects/svalbard 7 2008  223Satellite tracking ground station 224 http://www.asf.alaska.edu/stgs 2008  R Flaherty  223Sn/gn systems o v ervie w  224 tech rep Goddard Space Flight Center NASA 7 2002  223Geoe ye-1 f act sheet 224 http://launch.geoeye.com/launchsite/about/fact sheet.aspx 2008  L-3 Communications/Cincinnati Electronics Space Electronics 7500 Innovation Way Mason OH 45040 T-720 Transmitter  5 2007 PDF Spec Sheet for the T720 Ku-Band TDRSS Transmitter  L-3 Communications/Cincinnati Electronics Space Electronics 7500 Innovation Way Mason OH 45040 T-722 X-Band  7 2007 PDF Spec Sheet for the T-722  J Smith 07 2008 Information e xchanged during meeting about GDS  J Carpena-Nunez L Graham C Hartzell D Racek T Tao and C Taylor 223End-to-end data system design for hyspiri mission.\224 Jet Propulsion Laboratory Education Of\002ce 2008  J Behnk e T  W atts B K obler  D Lo we S F ox and R Meyer 223Eosdis petabyte archives Tenth anniversary,\224 Mass Storage Systems and Technologies 2005 Proceedings 22nd IEEE  13th NASA Goddard Conference on  pp 81\22693 April 2005 19 


 M Esf andiari H Ramapriyan J Behnk e and E So\002nowski 223Evolving a ten year old data system,\224 Space Mission Challenges for Information Technology 2006 SMC-IT 2006 Second IEEE International Conference on  pp 8 pp.\226 July 2006  S Marle y  M Moore and B Clark 223Building costeffective remote data storage capabilities for nasa's eosdis,\224 Mass Storage Systems and Technologies 2003 MSST 2003 Proceedings 20th IEEE/11th NASA Goddard Conference on  pp 28\22639 April 2003  223Earth science data and information system esdis project.\224 http://esdis.eosdis.nasa.gov/index.html  M Esf andiari H Ramapriyan J Behnk e and E So\002nowski 223Evolution of the earth observing system eos data and information system eosdis\\224 Geoscience and Remote Sensing Symposium 2006 IGARSS 2006 IEEE International Conference on  pp 309\226312 31 2006Aug 4 2006  223Earth science mission operations esmo 224 http://eos.gsfc.nasa.gov/esmo  E Masuoka and M T eague 223Science in v estig ator led global processing for the modis instrument,\224 Geoscience and Remote Sensing Symposium 2001 IGARSS 01 IEEE 2001 International  vol 1 pp 384\226386 vol.1 2001  M Esf andiari H Ramapriyan J Behnk e and E So\002nowski 223Earth observing system eos data and information system eosdis 227 evolution update and future,\224 Geoscience and Remote Sensing Symposium 2007 IGARSS 2007 IEEE International  pp 4005\2264008 July 2007  D McAdam 223The e v olving role of tape in the data center,\224 The Clipper Group Explorer  December 2006  223Sun microsystems announces w orld s 002rst one terabyte tape storage drive.\224 http://www.sun.com/aboutsun/pr/200807/sun\003ash.20080714.2.xml July 2008  223P anasas 227 welcome 224 http://www panasas.com  R Domikis J Douglas and L Bisson 223Impacts of data format variability on environmental visual analysis systems.\224 http://ams.confex.com/ams/pdfpapers/119728.pdf  223Wh y did nasa choose hdf-eos as the format for data products from the earth observing system eos instruments?.\224 http://hdfeos.net/reference/Info docs/SESDA docs/NASA chooses HDFEOS.php July 2001  R E Ullman 223Status and plans for hdfeos nasa's format for eos standard products.\224 http://www.hdfeos.net/hdfeos status HDFEOSStatus.htm July 2001  223Hdf esdis project.\224 http://hdf.ncsa.uiuc.edu/projects/esdis/index.html August 2007  223W elcome to the ogc website 224 http://www.opengeospatial.org 2008  223Open gis Gis lounge geographic information systems.\224 http://gislounge.com/open-gis Christine M Hartzell received her B.S in Aerospace Engineering for Georgia Institute of Technology with Highest Honors in 2008 She is currently a PhD student at the University of Colorado at Boulder where she is researching the impact of solar radiation pressure on the dynamics of dust around asteroids She has spent two summers working at JPL on the data handling system for the HyspIRI mission with particular emphasis on the cloud detection algorithm development and instrument design Jennifer Carpena-Nunez received her B.S in physics in 2008 from the University of Puerto Rico where she is currently a PhD student in Chemical Physics Her research involves 002eld emission studies of nanostructures and she is currently developing a 002eld emission setup for further studies on nano\002eld emitters The summer of 2008 she worked at JPL on the HyspIRI mission There she was responsible for the science analysis of the data handling system speci\002cally de\002ning the data level and processing and determining potential mission collaborations Lindley C Graham is currently a junior at the Massachusetts Institute of Technology where she is working towards a B.S in Aerospace Engineering She spent last summer working at JPL on the data handling system for the HyspIRI mission focusing on developing a data storage and distribution strategy 20 


David M Racek is a senior working toward a B.S in Computer Engineering at Montana State University He works in the Montana State Space Science and Engineering Laboratory where he specializes in particle detector instruments and circuits He spent last summer working at JPL on compression algorithms for the HyspIRI mission Tony S Tao is currently a junior honor student at the Pennsylvania State University working towards a B.S in Aerospace Engineering and a Space Systems Engineering Certi\002cation Tony works in the PSU Student Space Programs Laboratory as the project manager of the OSIRIS Cube Satellite and as a systems engineer on the NittanySat nanosatellite both of which aim to study the ionosphere During his work at JPL in the summer of 2008 Tony worked on the communication and broadcast system of the HyspIRI satellite as well as a prototype Google Earth module for science product distribution Christianna E Taylor received her B.S from Boston University in 2005 and her M.S at Georgia Institute of Technology in 2008 She is currently pursing her PhD at the Georgia Institute of Technology and plans to pursue her MBA and Public Policy Certi\002cate in the near future She worked on the ground station selection for the HyspIRI mission during the summer of 2008 and looks forward to working at JPL in the coming year as a NASA GSRP fellow Hannah R Goldberg received her M.S.E.E and B.S.E from the Department of Electrical Engineering and Computer Science at the University of Michigan in 2004 and 2003 respectively She has been employed at the Jet Propulsion Laboratory California Institute of Technology since 2004 as a member of the technical staff in the Precision Motion Control and Celestial Sensors group Her research interests include the development of nano-class spacecraft and microsystems Charles D Norton is a Principal Member of Technical Staff at the Jet Propulsion Laboratory California Institute of Technology He received his Ph.D in Computer Science from Rensselaer and his B.S.E in Electrical Engineering and Computer Science from Princeton University Prior to joining JPL he was a National Research Council resident scientist His work covers advanced scienti\002c software for Earth and space science modeling with an emphasis on high performance computing and 002nite element adaptive methods Additionally he is leading efforts in development of smart payload instrument concepts He has given 32 national and international keynote/invited talks published in numerous journals conference proceedings and book chapters He is a member of the editorial board of the journal Scienti\002c Programming the IEEE Technical Committee on Scalable Computing a Senior Member of IEEE recipient of the JPL Lew Allen Award and a NASA Exceptional Service Medal 21 


this paper, we only generate the size-2 patterns in the BFS phase. It will be interesting to investigate the impact on the performance if the ?rst phase is stopped at a deeper level Also, the projection is a very ef?cient method for ?nding patterns, especially for parallel implementation of pattern mining algorithms [1]. We plan to adapt the projection ideas into our algorithm and design an ef?cient parallel algorithm for mining maximal hyperclique patterns References 1] R. Agarwal, C. Aggarwal, and V. Prasad. A Tree Projection Algorithm For Generation of Frequent Itemsets. pages 350 371, Feb 2001 2] R. Agrawal, T. Imielinski, and A. Swami. Mining Association Rules between Sets of Items in Large Databases. In Proc. of the ACM SIGMOD Conference on Management of Data, pages 207ñ216,May 1993 3] R. Agrawal and R. Srikant. Fast Algorithms for Mining Association Rules. In Proc. of the 20th Intíl Conference on Very LargeData Bases, 1994 4] R. Bayardo. Ef?ciently mining long patterns from databases In Proc. of the ACM SIGMOD Conference, 1998 5] R. Bayardo and R. Agrawal. Mining the Most Interesting Rules. In Proc. of the ACM SIGKDD Conference, 1999 6] D. Burdick, M. Calimlim, and J. Gehrke. Ma?a: AMaximal Frequent Itemset Algorithm for Transactional Databases. In Proc. of IEEE Conf. on Data Engineering, 2001 7] Y. Huang, H. Xiong, W. Wu, and Z. Zhang. A Hybrid Approach for Mining Maximal Hyperclique Patterns. In In Technical Report UTDCS-34-04, Department of computer science, University of Texas - Dallas, 2004 8] J.Han, J.Pei, and Y. Yin. Mining Frequent Patterns without Candidate Generation. In Proc. of the ACM SIGMOD International Conference on Management of Data, 2000 9] M.J.Zaki and C.Hsiao. ChARM: An ef?cient algorithm for closed itemset mining. In Proc. of 2nd SIAM International Conference on Data Mining, 2002 10] R.Rymon. Search through Systematic Set Enumeration. In Proc. Third Intíl Conference on Principles of Knowledge Representation and Reasoning, 1992 11] H. Xiong, M. Steinbach, P.-N. Tan, and V. Kumar. HICAP: Hierarchial Clustering with Pattern Preservation. In Proc. of 2004 SIAM International Conference on Data Mining \(SDM 12] H. Xiong, P.-N. Tan, and V. Kumar. Mining Strong Af?nity Association Patterns in Data Set with Skewed Support. In Proc. of the Third IEEE International Conference on Data Mining \(ICDM Proceedings of the 16th IEEE International Conference on Tools with Artificial Intelligence \(ICTAI 2004 1082-3409/04 $20.00 © 2004 IEEE 





