html><head></head><body><pre style="word-wrap: break-word; white-space: pre-wrap;">  1 Fuzzy Clustering Means Data Association Algorithm using an Adaptive Neuro-Fuzzy Network Abdolreza Dehghani Tafti a and  Nasser Sadati, Member IEEE b a Islamic Azad University, Science and Research Branch, Tehran, Iran \(Email: dehghani@ieee.org b Electrical and Computer Engineering Department, The University of British Columbia Vancouver, BC Canada \(Email: sadati@ece.ubc.ca  Abstract  A significant problem in multi-sensor multitarget tracking system is measurement to track association Based on fuzzy clustering means algorithm, an efficient algorithm has been proposed to solve this problem. The fuzzy clustering means data association \(FCMDA algorithm has better performance than the other already known fuzzy logic data association algorithms. However, it is still worthy to investigate the characteristics of the FCMDA algorithm, which has high accuracy in measurement to track association when targets are far from each other, while it has low accuracy when targets are close to each other. The FCMDA algorithm usually loses its performance in this situation, especially when the noise of measurement is high. In this paper, to overcome the disadvantage of the FCMDA algorithm, an adaptive neurofuzzy inference system \(ANFIS adjusts the predicted state of targets which are used as cluster centers in the FCMDA algorithm. The ANFIS has the advantage of expert knowledge of fuzzy inference system and the learning capability of neural networks. This is so, since a trained ANFIS is able to compensate the effect of wrong data association in the FCMDA algorithm. Monte Carlo simulation results show considerable improvement in terms of accuracy and performance achieved by using the ANFIS in the FCMDA algorithm. 1 2  TABLE OF CONTENTS 1. INTRODUCTION.................................................................1 2. FCMDA ALGORITHM.........................................................2 3. ANFIS ................................................................................2 4. FCMDA ALGORITHM WITH NEURO-FUZZY NETWORK...3 5. SIMULATION RESULTS .....................................................4 6. CONCLUSION ....................................................................5 REFERENCES ........................................................................5 BIOGRAPHY ..........................................................................5  1. INTRODUCTION A key problem in the field of multi-sensor multi-target MSMT association. A number of algorithms have been proposed in the literature to solve this problem; for example, the nearest neighbor \(NN PDA joint probabilistic data association \(JPDA  1 1978-1-4244-2622-5/09/$25.00  2009 IEEE 2 IEEEAC paper #1723, Version 7, Updated Dec 18, 2008 Singh and Bailey developed the first fuzzy logic approach to the data association based on the fuzzy knowledge-base IF THEN rules  case of more than three or four targets is computationally infeasible due to the large number of rules [6]. M. Aziz [6 7] developed a nearest-neighbor fuzzy logic data association algorithm based on fuzzy clustering means \(FCM algorithm which is called fuzzy clustering means data association \(FCMDA that the association performance of the FCMDA algorithm in terms of the percentage of perfect association, decreases when the number of targets increases in a surveillance environment, and also targets move close to each other This situation becomes critical when the covariance of measurement noise increases [7, 8]. This is so, since the risk of updating the target model by a wrong measurement which obviously leads to a wrong estimation of target state 


which obviously leads to a wrong estimation of target state increases. In the FCMDA algorithm, the cluster centers are determined by the predicted state of targets, as good initial guess for them. The predicted state of target can be obtained using the Kalman filter as a usual tracker/filter in a practical application. The wrong measurement to track association leads to generation of wrong prediction of state of target The wrong prediction can cause next wrong association too The effect of wrong association usually is not compensated in tracking process, at the next step time in the dense environment. So, the sequence of wrong association is produced which causes the loss of tracking performance. To avoid this situation, the effect of wrong association must be compensated to determine the next cluster centers Therefore, possibility of the correct association is generated for the next step time by using a compensator unit. For this purpose, in this paper, the predicted state of target is corrected by an adaptive neuro-fuzzy inference system ANFIS FIS implemented in the framework of an adaptive fuzzy neural network. It is very powerful approach for building complex and nonlinear relationship between a set of input and output data. It combines the explicit knowledge representation of the FIS with the learning power of artificial neural network to achieve a desired performance. Fast and accurate learning, excellent explanation facilities in the form of semantically meaningful fuzzy rules, the ability to accommodate both data and existing expert knowledge about the problem, and good generalization capability have already made the neuro-fuzzy system popular in recent years [9, 10]. For all these attractive features present in ANFIS, this network is used to improve the performance of 2 the FCMDA algorithm in this paper. The remainder of this paper is organized as follows. A brief overview of the FCMDA algorithm is given in Section 2. The ANFIS is described briefly in Section 3. The proposed FCMDA algorithm with ANFIS is presented in Section 4 Performance evaluation and results using Monte Carlo simulations are reported in Section 5. Section 6 contains conclusion 2. FUZZY CLUSTERING MEANS DATA ASSOCIATION \(FCMDA Suppose that n  measurements are received at time k  \(scan k MSMT environment. The number of measurements n  does not necessarily equals to the number of targets C . It is required to assign/associate only one measurement to each target such that each measurement can have only one origin Gating techniques cannot easily solve the problem of associating measurements with tracks; when a measurement falls within the gates of multiple target tracks or when multiple measurements fall within the gate of a target track Our goal is to associate each measurement nlZl ,...,2,1, =  with one of C  possible tracks, given predicted values iV  for each track of  Cii ...,,2,1; = . The targets predicted values iV  can be estimated using optimal filtering techniques, such as ?? ?  tracker and Kalman filtering techniques [11]. The choice of a particular optimal filtering technique is not arbitrary, but depends on the application and the assumed target state model. In [7], based on the fuzzy clustering means \(FCM logic data association algorithm has been proposed that is known as the fuzzy clustering means data association FCMDA steps Step 1: Apply the fuzzy clustering means \(FCM for a fixed 21 cvvvV  and find the partition matrix U , which represents the degrees of membership of all measurements to all tracks. The association matrix U represents the assignment matrix between all measurements and all targets. Each element in the partition matrix 


and all targets. Each element in the partition matrix  nkCiuik ==  represents an association measure between the predicted value of track i , as cluster center i , and the measurement k . The value of iku  and the optimum fuzzy cluster centers civi =  are obtained according to the FCM algorithm [12] as follows ki dd u C j m jkik ik   1 1  122     1 i u Zu v n k m ik n k k m ik i    1 1     2 where 2ikd  stands for the Euclidean distance \(or the Mahalanobis distance the predicted value of track i . Also the parameter m  is a real number usually is set to 2, as this value has proven to give a good result with the FCM [12 Step 2: Search for the maximum degree of membership max?iku  \(the closest measurement to track i indicated assignment, i.e. associate the measurement k  to track i Step 3: Remove the associated measurement to track which is identified in step 2, form the assignment matrix U  and obtain the reduced matrix Step 4:  Repeat step 2 and 3 for each remaining track until all n  measurements are assigned to the C  existing tracks Step 5: Obtain the final assignment of measurements to track, based on results of step 4 The main advantages of this approach are simplicity and efficiency with low computational cost [7, 8 3. ADAPTIVE NEURO-FUZZY INFERENCE SYSTEM ANFIS ANFIS is a multilayer feed-forward network which searches for the fuzzy decision rules that perform well on any given task. The fuzzy decision rules are implemented as membership functions \(MFs best fitting parameters of the MFs. The architecture of ANFIS is shown in Fig. 1. Even though ANFIS is a fivelayer neural network, only two of these layers have adjustable weights \(here represented by square 


adjustable weights \(here represented by square layer is composed of n MFs, each implementing a fuzzy decision rule. Any type of distributions can be modeled by MFs and the set of parameters to minimize is determined accordingly. Parameters in this layer are referred to as the premise parameters. The second layer computes every possible conjunction of the n decision rules. The third layer normalizes the conjunctives MFs in order to rescale the inputs. In the fourth layer, the nodes are adaptive nodes The output of each node in this layer is simply the product of the output of third layer, and a first-order polynomial \(for a first-order Sugeno model 3 referred to as the consequent parameters. Finally, the fifth layer computes the overall output as the summation of all incoming signals. The ANFIS has two set of adjustable parameters, namely the premise and consequent parameters During the learning process, the premise parameters in first layer and the consequent parameters in the fourth layer are tuned until the desired response of the FIS is achieved When the premise parameters are fixed, the output of the ANFIS can be written as a liner combination of the consequent parameters. The least square method \(LSM be used to identify the optimal values of these parameters easily. When the premise parameters are not fixed, the search space becomes larger and the convergence of the training becomes slower. A hybrid algorithm combining the LSM and the gradient descent method is adopted to solve this problem. The hybrid algorithm is composed of a forward pass and a backward pass. The LSM \(forward pass is used to optimize the consequent parameters with the premise parameters fixed. Once the optimal consequent parameters are found, the backward pass starts immediately The gradient descent method \(backward pass adjust optimally the premise parameters. The output of the ANFIS is calculated by employing the consequent parameters found in the forward pass. The output error is used to adapt the premise parameters by a standard backpropagation algorithm. It has been proven that this hybrid algorithm is highly efficient in training the ANFIS [9, 10 4. FCMDA ALGORITHM WITH NEURO-FUZZY NETWORK In the FCMDA algorithm, the association between measurements and tracks is determined using the optimal membership functions derived from the fuzzy clustering means \(FCM The predicted state of targets is considered as the cluster center for reduction of the computational burden in practical application; this assumption is avoided when the number of measurements and targets are the same. Therefore, the predicted state of target has important role in determination of the partition matrix between the measurements and targets ,in the FCMDA algorithm. The predicted state of targets usually is obtained in practice, by standard Kalman filter \(KF is obtained when a wrong measurement is associated to the target. This incorrect prediction for a target can cause the next wrong measurement association and so on. Until the performance of the FCMDA algorithm is lost completely The possibility of occurrence of this condition increases in dense surveillance environment, where the number of targets is high and they are close to each other. Also, the worse case happens when the noise of measurement is high If the effect of update KF with wrong measurement is compensated, then the correct prediction can be obtained Thus the wrong association can be prevented at the next step time. A fuzzy inference system \(FIS the effect of wrong association as a non-linear mapping between perfect state prediction and the KF prediction Production of optimal FIS with this property is very hard However, the ANFIS can obtain the mapping relation between the input and output data through a learning 


between the input and output data through a learning algorithm to optimize the parameters of a given FIS [9 13]. Therefore, the ANFIS is used as suitable compensator for KF in the FCMDA algorithm. The proposed structure is shown in Fig. 2. It shows that the ANFIS aides the KF for compensation of predicted target state in multi-sensor multitarget tracking system. The input parameters of ANFIS are the sequence of corrections, i.e. multiplication of innovation sequences  kk ZZ ?  and KF gain       111 nknknkkkkkkk ZZKZZKZZK ?????? ???       \(3 where its output is the error between the correct and KF prediction, which should be added to the KF predicted state for compensating the effect of wrong measurement association in the previous step. Also the notion D denotes the delay. The obtained output from this structure is considered as the cluster centers in the FCMDA algorithm The performance of FCMDA algorithm increases significantly by using the proposed structure    KALMAN   FILTER A N F I S  D D   kZkZkK   1\(1 ???? kZkZkK   nkZnkZnkK  1  kkx 1  kkx 1   kkx  Figure 2  The ANFIS aids Kalman Filter Figure 1  The general architecture of ANFIS 4 5. SIMULATION RESULTS A scenario having two targets is considered. The dynamic and measurement model of targets are assumed to be    kWkXFkX +=+                                         \(4    kVkXHkZ +=                                                \(5 where          1000 100 0010 001 T T F   and    


0100 0001 H          \(6  The kX  is the state vector which contains the positions and velocities in x  and y  directions \(i.e yx vyvx kZ  is the measurement vector  kF  and kH  denote the transition matrices pertaining to the state and the measurement models, respectively. The process noise vector kW  and the measurement noise vector kV  are independent, zero mean noises with known covariances kQ  and kR , respectively. The overall mean estimated error is computed by Nyyxxe N i i true ii true i     1 22  Ni ,...,2,1=          \(7 where N is number of the targets. ix  iy  stands for the estimated position of target i  and itruex i truey  indicates its actual position.  The initial positions and speeds of the targets are [6000    100    5900    3; 6000   100    5870    3 The standard deviations of positions and speeds are considered the same for each target, such that it is assumed 0004.0=iiQ  and 15=iiR 2km  tracking based on processing 200 measurements \(20 seconds algorithm with ANFIS. It shows that the FCMDA algorithm loses its performance completely such that the track of target 1 achieves the trajectory of target 2, vice versa. For more illustration, the mean estimation error is shown in Fig 4. From Fig. 4, it is seen that the FCMDA algorithm with ANFIS has lower estimation error than the standard FCMDA algorithm. In order to provide a meaningful comparison, 50 Monte Carlo runs are performed and the mean estimation error of both methods is compared. As a result, it is seen that the average value of mean estimation error for the FCMDA algorithm with ANFIS is lower than the FCMDA algorithm \(near 16   6000 6200 6400 6600 6800 7000 7200 7400 7600 7800 8000 5840 5860 5880 5900 5920 5940 5960 5980 x \(m y m    Trajectory of Target 1 Trajectory of Target 2 FCMDA for Target 1 FCMDA for Target 2 FCMDA with ANFIS for Target 1 


FCMDA with ANFIS for Target 1 FCMDA with ANFIS for Target 2  Figure 3 - Actual and estimated tracks using various data association algorithms 5 6. CONCLUSION In this paper, a fuzzy clustering means data association FCMDA problem of data association in multi-sensor multi-target tracking system is considered. The FCMDA algorithm usually loses its performance completely by wrong measurement to track association when the targets are close to each other. In this paper, the prediction of target state is compensated by the ANFIS to reduce the effect of wrong associated measurement. The prediction of target state is used as a cluster center or a good initial guess for it, in the FCMDA algorithm. Therefore, the use of the compensated prediction of target state can save the FCMDA algorithm performance when the targets move closer to each other Monte Carlo simulations have been provided to demonstrate the efficacy of using ANFIS in the FCMDA algorithm REFERENCES 1] Y. Bar-shalom and T. Fortman, Tracking and Data Association, Academic Press, New York, 1998 2] Y. Bar-shalom, Multi-target Multi-sensor Tracking Applications and Advances vol. I, Artech House Norwood, MA, 1990 3] Y. Bar-shalom, Multi-target Multi-sensor Tracking Applications and Advances vol. II, Artech House Norwood, MA, 1992 4] Y. Bar-Shalom and X. Li, Multi-target Multi-sensor Tracking: Principles and Techniques, Storrs, CT: YBS Publishing, 1995 5] R. Singh and W. H. Bailey  Fuzzy Logic Applications to Multi-sensor Multi-target Correlation  IEEE Trans on Aerospace and Electronic Systems 33, 752-769 1997 6] A. M. Aziz, New Data Fusion Algorithms for Distributed Multi-sensor Multi-target Environments AD Reports, 51-75, 1999 7] A. M. Aziz, M. Tummala and R. Cristi  Fuzzy Logic Data Approach in Multi-sensor Multi-target Tracking Systems  Journal of Signal Processing, Elsevier 76 195-209, 1999 8] L. q. Li and H. B. Ji  A Multiple FCMs Data Association Based Algorithm for Multi-target Tracking  2004 IEEE International Conference on Signal Processing \(ICSP'04 9] J. S. R. Jang  ANFIS: Adaptive Network Based Fuzzy Inference System  IEEE Trans. on Systems Man and Cybernetics 23, 665-685, 1993 10] J. S. R. Jang, C. T. Sun and E. Mizutani, Neuro-fuzzy and Soft Computing: A Computational Approach to Learning and Machine Intelligence, Prentice Hall 1997 11] R. E. Kalman  A New Approach to Liner Filtering and Prediction Theory  Journal of Basic Eng., 34-45 1960 12] J. C. Bezdek, Pattern Recognition with Fuzzy Objective Function Algorithms, Plenum Press, New York, 2001 13] S. Horikawa and T. Furuhashi and Y. Uchikawa  On Fuzzy Modeling Using Fuzzy Neural Network with Back Propagation Algorithm  IEEE Trans. On Neural Network 3, 801-806, 1992 BIOGRAPHY Abdolreza Dehghani Tafti was born in Karaj, Tehran, Iran, on December 6 1976. He received his B.S. degree from Islamic Azad University, Karaj Branch 


Islamic Azad University, Karaj Branch in 1999, in electronic engineering, and the M.S. degree from Islamic Azad University, South Tehran Branch, in 2001, in control engineering. Currently, he is a Ph.D student in Islamic Azad University, Science and Research Branch, Tehran. His current research activities include pattern recognition, estimation and neuro-fuzzy networks and their applications in target tracking Nasser Sadati at present, is a Visiting Professor with the Department of Electrical and Computer Engineering, The University of British Columbia Vancouver, BC Canada URL: http://ee.sharif.edu/~sadati 0 20 40 60 80 100 120 140 160 180 200 0 5 10 15 20 25 30 35 40 sample time M ea n Es tim at io n Er ro r m    FCMDA FCMDA with ANFIS  Figure 4 - Mean estimated errors using various data association algorithms  pre></body></html 


 24  F. H a ns e n   P s y c holog ic a l T h e o r i e s of C ons um e r  Choice", Journal of Consumer Research, 3:December 1976\, 117-142  25 M  B. Ho l b ro o k an d  E  C. Hirsch m a n   T h e  Experiental Aspects of Consumption: Consumer Fantasies Feelings, and Fun", The Journal of Consumer Research, 9:2 1982\, 132-140  26 J  A  H o w a r d a n d J  N  S h e t h  T h e T h e o r y o f B u y e r  Behavior, John Wiley & Sons, Inc., New York, 1969  27 C  L H s u a nd H  P. L u  C ons um e r B e ha v i or in Online Game Communities: a Motivational Factor Perspective", Computers in Human Behavior, 23:2007 2005\, 1642-1659  28 C.-L H s u a nd H  P L u  W hy D o P e ople  P l a y O n line  Games? An Extended TAM with Social Influences and Flow Experiences", Information & Management:41 \(2004 853-868  29 J Juu l  G a m e s Te lling Storie s    Ha nd bo ok of  Computer Games \(J. Raessens and J. Goldstein, eds.\he MIT Press, Cambridge, Massachusetts, 2005  30 K   P  K a lli o, K  K a ipa i ne n a nd F. M y r   G am ing Nation? The Pilot Case Finland: International Study of Games Cultures", vol. Hypermedia Laboratory Net Series 14, University of Tampere, Hypermedia Laboratory Tampere, 2007  3 J N Kap f erer  T h e Ne w S t rat e gi c Br an d Management, Kogan Page, 2004  32 K. L  Ke lle r C onc e p tu a liz ing  Me a s uring a n d  Managing Customer-Based Brand Equity", Journal of Marketing, 57:January \(1993\ 1-22  33 K  L  K e l l e r a n d D  R  L e h m a n n   B r a n d s a n d  Branding: Research Findings and Priorities", Marketing Science, 25:6 \(2006\, 740-759  34 O  K o ppi us  D im e n s i ons of Inta ng ib le G oods    P r oc   32nd Hawaii International Conference on Systems Sciences Hawaii, USA, 1999  35 T  Kuja np   T  Ma n n ine n a nd L   V a llius  W ha t s M y  Game Character Worth - The Value Components of MMOG Characters", DiGRA 2007 Conference, Situated Play, Tokyo, Japan, 2007  36 Z   V. L a m b e r t P r i c e a nd C hoic e B e ha v i or   J our na l  of Marketing Research, 9:February \(1972\35-40  37 F  L a nd T he I n f o r m ation Sy s t em s D o m a in   Information Systems Research \(R. Galliers, ed., Alfred Waller Ltd., Warwick, 1992  38 R P. L e o n e V  R. Rao  K L  Keller A  M. L u o  L   McAlister, and R. Srivastava, "Linking Brand Equity to Customer Equity", Journal of Service Research 9:November \(2006\, 125-138  39 A   P a r a s u r a m a n T ec hnolo g y r e a d ine s s I nde x  T R I     Journal of Service Research, 2:4 \(2000\ 307-320  40 J  R a e s s e ns a nd J   G o lds t e i n, H a ndb ook of C o m pute r  Game Studies, The MIT Press Cambridge, Massachusetts 2005  41 E. M  R o g e rs  N ew produc t a dopti on a n d dif f u s i on   Journal of Consumer Research, 2:March \(1976  42 J. R o ssite r a nd L   P e rc y   Adv e rtising a nd P r om otion  Management, McGraw, New York, 1987  43 J. Rutte r a nd J. Bry c e e ds  rsta nd ing Dig ita l Games, Sage Publications, London, UK, 2006  44 B. H. Sc hm itt E x p e r ie nta l Ma rk e ting  Journa l of  Marketing Management, 15 \(1999\53-67  45 C Sh ap iro an d H. R V a ri an In f o rm atio n Ru les: A  Strategic Guide to the Network Economy, Harvard Business School Press, Boston, Massachusetts, 1999  4 S  E   S i w e k V i d eo G a mes i n th e 21 st Ce n t u r y    Entertainment Software Association, 2007, p. 36  4 V S r i n i v asan  C S  P a rk an d D R Ch an g  A n  approach to the measurement, analysis, and prediction of brand equity and its sources", Management Science, 51:9 2005\, 1433-1448  48 J  Sw e e n ey a nd J  Sw a it  T he E f f e c t s of B r a nd Credibility on Customer Loyalty", Journal of Retailing and Consumer Services, 15 \(2008\179-193  49 H   Va n de r H e ijde n  U s e r A c c e pta n c e of H e donic  Information Systems", MIS Quarterly, 28:4 \(2004\, 695704  50 H  R   Va ria n  M a r k e ts f o r Inf o r m a tion G oods    http://people.ischool.berkeley.edu/~hal/Papers/japan  1998  51 A  Ve nk a t e s h C om pute r s a nd O t he r Inte ra c tiv e  Technologies for the Home", Communications of the ACM, 39:12 \(1996\ 47-54  52 K  W e ic k  T he ore tic a l  A s s u m p tions a nd Re s e a r c h  Methodology Selection", Research Issues in IS Research McFarlan et al., ed., 1986  53 N. Ye e   M otiv a tions of P l a y in Online G a m e s   Journal of CyberPsychology and Behavior, 6 \(2006\, 772775  5  V  A  Z e i t h am l  M  J Bi t n er an d D D G r em l e r  Services Marketing Vol. 4, McGraw Hill, Singapore, 2006  Proceedings of the 42nd Hawaii International Conference on System Sciences - 2009 9 
 


 Appendix 1. Beliefs on the digital game's perceived quality on attribute level \(t-test, rank ordered by mean Variable  N Mean SD SE t Value Pr > |t Direction Statistically significant difference A lot to discover and play Branded 67 5.99 0.93 0.11 52.72 <.0001 NEGATIVE NO Non Branded 60 6.13 0.95 0.12 50.16 <.0001 Difference  0.15 0.94 0.17 0.89 0.3754 Availability Branded 67 5.72 1.14 0.14 41.08 <.0001 SLIGHTLY NEGATIVE NO Non Branded 60 5.75 0.91 0.12 48.75 <.0001 Difference  0.03 1.04 0.18 0.18 0.856 Graphics and audio Branded 67 5.13 1.10 0.13 38.22 <.0001 POSITIVE NO Non Branded 60 4.87 1.27 0.16 29.72 <.0001 Difference  0.27 1.18 0.21 1.27 0.2051 Groups Branded 67 4.76 1.05 0.13 37.27 <.0001 SLIGHTLY NEGATIVE NO Non Branded 60 4.82 1.08 0.14 34.50 <.0001 Difference  0.06 1.06 0.19 0.29 0.7695 Character development Branded 54 4.74 1.53 0.21 23.89 <.0001 POSITIVE NO Non Branded 52 4.50 1.64 0.23 19.80 <.0001 Difference  0.24 1.59 0.31 0.78 0.4362 Socializing Branded 67 4.64 1.56 0.19 31.04 <.0001 NEGATIVE NO Non Branded 60 4.98 1.08 0.14 35.70 <.0001 Difference  0.34 1.36 0.24 1.42 0.1594 Easy to start to play Branded 67 4.55 1.47 0.18 25.35 <.0001 SLIGHTLY NEGATIVE NO Non Branded 60 4.63 1.18 0.15 30.46 <.0001 Difference  0.08 1.34 0.24 0.34 0.7341 Real money usage  for success Branded 55 4.42 1.62 0.22 20.25 <.0001 SLIGHTLY POSITIVE NO Non Branded 52 4.38 1.78 0.25 17.72 <.0001 Difference  0.04 1.70 0.33 0.10 0.9189 Easy to learn Branded 67 4.30 1.38 0.17 25.46 <.0001 NEGATIVE NO Non Branded 60 4.47 1.42 0.18 24.37 <.0001 Difference  0.17 1.40 0.25 0.68 0.5004 Easy to play Branded 67 4.30 1.21 0.15 29.17 <.0001 SLIGHTLY NEGATIVE NO Non Branded 60 4.38 1.38 0.18 24.62 <.0001 Difference  0.08 1.29 0.23 0.37 0.7122 Experience level Branded 54 4.30 1.45 0.20 21.79 <.0001 POSITIVE NO Non Branded 52 4.06 1.47 0.20 19.85 <.0001 Difference  0.24 1.46 0.28 0.84 0.4026 Price Branded 67 4.04 1.67 0.20 19.78 <.0001 NEGATIVE NO Non Branded 60 4.17 1.60 0.21 20.22 <.0001 Difference  0.13 1.64 0.29 0.42 0.6761 Story telling Branded 67 4.01 1.55 0.19 21.17 <.0001 NEGATIVE NO Non Branded 60 4.43 1.33 0.17 25.77 <.0001 Difference  0.42 1.45 0.26 1.62 0.1076 Fun Branded 67 3.91 1.69 0.21 18.99 <.0001 NEGATIVE YES Non Branded 60 4.58 1.49 0.19 23.86 <.0001 Difference  0.67 1.60 0.28 2.37 0.0192 Usefulness Branded 55 2.71 1.34 0.18 14.96 <.0001 NEGATIVE NO Non Branded 52 3.13 1.46 0.20 15.53 <.0001 Difference  0.43 1.40 0.27 1.57 0.1187 Fame Branded 67 2.63 1.32 0.16 23.74 <.0001 NEGATIVE NO Non Branded 60 2.77 1.67 0.22 12.83 <.0001 Difference 0.14 1.50 0.27 0.53 0.6004 Lower or equal than 0.10 difference in mean is considered as slightly negative or slightly positive Proceedings of the 42nd Hawaii International Conference on System Sciences - 2009 10 
 


pre></body></html 


lossless frequent patterns representations with borders. In practice, they are also much more concise than representations based on closed itemsets and approximate representations. In this paper, we offered three methods of deriving an upper bound on the length of sets in such representations. We proved that the upper bound on the length of a longest generalized disjunction-free set depends logarithmically on the number of records in the database. The obtained result is of high importance as it guarantees that any generalized disjunction-free set representation for all patterns \(both frequent and infrequent scans, where n is the number of records in the database irrespectively how strong or weak correlations among items in the database are and irrespectively of the lengths of records and number of distinct items The modifications of the basic estimation take into account the support threshold of the representation to be found or, additionally, the information on the length of longest sets of the representation already calculated for a higher support threshold. Though these estimations are more accurate than the basic one, they are still quite rough. Further improvements of the quality of estimating the length of longest itemsets in generalized disjunctionfree representations is subject to further research References 1] R. Agrawal, H. Mannila, R. Srikant, H. Toivonen, A.I Verkamo  Fast Discovery of Association Rules   Advances in Knowledge Discovery and Data Mining AAAI, CA, 1996 2] J. Baptiste, J.-F. Boulicaut  Constraint-Based Discovery and Inductive Queries: Application to Association Rule Mining  Pattern Detection and Discovery, Springer London, UK, September 2002, pp. 110-124 3] E. Baralis, S. Chiusano, P. Garza  On Support Thresholds in Associative Classification  SAC, ACM, Taipei Taiwan, March 2004, pp. 553-558 4] Y. Bastide, N. Pasquier, R. Taouil, G. Stumme, L. Lakhal  Mining Minimal Non-redundant Association Rules Using Frequent Closed Itemsets  Computational Logic, 2000 pp. 972  986 5] J.-F. Boulicaut, A. Bykowski, C. Rigotti  Approximation of Frequency Queries by Means of Free-Sets  PKDD Springer, Lyon, France, September 2000, pp. 75-85 6] A. Bykowski, C. Rigotti  A Condensed Representation to Find Frequent Patterns  PODS, ACM, Santa Barbara USA, May 2001, pp. 267-273 7] T. Calders, Axiomatization and Deduction Rules for the Frequency of Itemsets, Ph.D. Thesis, University of Antwerp, 2003 8] T. Calders, B. Goethals  Mining All Non-derivable Frequent Itemsets  PKDD, Springer, Helsinki, Finland August 2002, pp. 74?85 9] T. Calders, B. Goethals  Minimal k-free Representations of Frequent Sets  ECML/PKDD, Springer, CavtatDubrovnik, Croatia, September 2003, pp. 71-82 10] J. Han, M. Kamber, Data Mining: Concepts and Techniques, Morgan Kaufmann Publishers, 2000 11] S.K. Harms, J. Deogun, J. Saquer, T. Tadesse  Discovering Representative Episodal Association Rules from Event Sequences Using Frequent Closed Episode Sets and Event Constraints  ICDM, IEEE Computer Society, San Jose, California, USA, November-December 2001, pp. 603  606 12] M. Kryszkiewicz  Closed Set Based Discovery of Representative Association Rules  IDA, Springer Cascais, Portugal, September 2001, pp. 350-359 13] M. Kryszkiewicz  Concise Representation of Frequent Patterns based on Disjunction  free Generators  ICDM IEEE Computer Society, San Jose, California, USA 


IEEE Computer Society, San Jose, California, USA November-December 2001, pp. 305  312 14] M. Kryszkiewicz M  Inferring Knowledge from Frequent Patterns  Soft-Ware, Springer, Belfast, Northern Ireland April 2002, pp. 247  262 15] M. Kryszkiewicz  Concise Representations of Association Rules  Pattern Detection and Discovery, Springer London, UK, September 2002, pp. 92-109 16] M. Kryszkiewicz, Concise Representation of Frequent Patterns and Association Rules, Habilitation Thesis Publishing House of Warsaw University of Technology 2002 Proceedings of the 16th International Conference on Scientific and Statistical Database  Management \(SSDBM  04 1099-3371/04 $ 20.00  2004 IEEE 17] M. Kryszkiewicz  Reducing Infrequent Borders of Downward Complete Representations of Frequent Patterns  Proc. of The First Symposium on Databases Data Warehousing and Knowledge Discovery, Scientific Publishers OWN, Baden-Baden, Germany, July, 2003, pp 29-42 18] M. Kryszkiewicz  Closed Set Based Discovery of Maximal Covering Rules  International Journal of Uncertainty, Fuzziness and Knowledge-Based Systems Vol. 11. World Scientific Publishing Company, Singapore September 2003, pp. 15-29 19] M. Kryszkiewicz  Reducing Borders of k-Disjunction Free Representations of Frequent Patterns  SAC, ACM Taipei, Taiwan, March 2004, pp. 559  563 20] M. Kryszkiewicz  Reducing Main Components of k-Disjunction Free Representations of Frequent Patterns   Proc. of IPMU  2004 \(in print 21] M. Kryszkiewicz, M. Gajek  Concise Representation of Frequent Patterns based on Generalized Disjunction  Free Generators  PAKDD, Springer, Taipei, Taiwan, May 2002, pp. 159-171 22] M. Kryszkiewicz, M. Gajek  Why to Apply Generalized Disjunction-Free Generators Representation of Frequent Patterns  ISMIS, Springer, Lyon, France, June 2002, pp 383  392 23] M. Kryszkiewicz, H. Rybi?ski, M. Gajek  Dataless Transitions between Concise Representations of Frequent Patterns  Journal of Intelligent Information Systems JIIS Netherlands, 2004, pp. 41-70 24] N. Pasquier, Data mining: Algorithmes d  extraction et de R  duction des R  gles d  association dans les Bases de Donn  es, Th  se de Doctorat, Universit  Blaise Pascal   Clermont  Ferrand II, 2000 25] N. Pasquier, Y. Bastide, R. Taouil, L. Lakhal  Efficient Mining of Association Rules Using Closed Itemset Lattices  Journal of Information Systems, Vol. 24, No. 1 1999, pp. 25  46 26] N. Pasquier, Y. Bastide, R. Taouil, L. Lakhal  Discovering Frequent Closed Itemsets for Association Rules  ICDT, Springer, Jerusalem, Israel, January 1999 pp. 398  416 27] J. Pei, G. Dong, W. Zou, J. Han  On Computing Condensed Frequent Pattern Bases  ICDM, IEEE Computer Society, Maebashi City, Japan, December 2002 pp. 378-385 28] V. Phan-Luong V  Representative Bases of Association Rules  ICDM, IEEE Computer Society, San Jose California, USA, November-December 2001, pp. 639-640 29] A. Savinov  Mining Dependence Rules by Finding Largest Itemset Support Quota  SAC, ACM, Taipei Taiwan, March 2004, pp. 525-529 30] M.J. Zaki, C.J. Hsiao  CHARM: An Efficient Algorithm for Closed Itemset Mining  SIAM, Arlington, 2002 


for Closed Itemset Mining  SIAM, Arlington, 2002 Proceedings of the 16th International Conference on Scientific and Statistical Database  Management \(SSDBM  04 1099-3371/04 $ 20.00  2004 IEEE pre></body></html 


                                                  S J       


                                                      


                         L A                                        


          L A  Table 7. Table of Granules at left-hand-side is isomorphic to  at right- hand-side: By Theorem  3.1 one can ?nd patterns in either table as a single generalized concept  Internal points  are:[4]\(1, 1, 0, 0 tions; [5]\(0, 1, 1, 0  0, 1, 0, 1  0, 1, 1, 1  1, 1 1, 0  1, 1, 0, 1  1, 0, 1, 1 11]\(1, 1, 1, 1 form and simplify them into disjoint normal forms 1  T E N    S J    T E N    S J 2  T W E N T Y    L A    T H I R T Y   A 3  T W E N T Y      T H I R T Y   A 4  T W E N T Y            L A 5  T E N      T W E N T Y    L A    T E N    T W E N T Y   A   S J    T W E N T Y   A      T H I R T Y    L A     Y 7  T E N      T W E N T Y      T H I R T Y   L A    T E N   L A    S  J   A 8  T W E N T Y      T E N      T W E N T Y    L A    T E N   T W E N T Y      T H I R T Y 9  T W E N T Y    N Y    T E N    S J    T H I R T Y    L A      T W E N T Y    L A  1 0  T W E N T Y    N Y    T W E N T Y    L A    T H I R T Y   A    J 1 1  T W E N T Y          T W E N T Y    L A   T H I R T Y    L A    a l l If the simpli?ed expression is a single clause \(in the original symbols non-generalized the following associations 1   T E N     S J    T E N    S J  2. SJ   J 4   L A    T W E N T Y    L A    T H I R T Y    6 Conclusions Data, patterns, method of derivations, and useful-ness are key ingredients in AM. In this paper, we formalize the current state of AM: Data are a table of symbols. The patterns are the formulas of input symbols that repeat. The method of derivations is the most conservative and reliable one, namely, mathematical deductions. The results are somewhat surprising 1. Patterns are properties of the isomorphic class, not an individual relation - This implies that the notion of patterns may not mature yet and explains why there are so many extracted association rules 2. Un-interpreted attributes \(features can be enumerated 3. Generalized associations can be found by solving integral linear inequalities. Unfortunately, the number is enormous. This signi?es the current notion of data and patterns \(implied by the algorithms 4. Real world modeling may be needed to create a much more meaningful notion of patterns. In the current state of AM, a pattern is simply a repeated data that may have no real world meaning. So we may need to introduce some semantics into the data model [12],[10],[11 Proceedings of the Fourth IEEE International Conference on Data Mining \(ICDM  04 0-7695-2142-8/04 $ 20.00 IEEE References 1] R. Agrawal, T. Imielinski, and A. Swami  Mining Association Rules Between Sets of Items in Large Databases  in Proceeding of ACM-SIGMOD international Conference on Management of Data, pp. 207216, Washington, DC, June, 1993 


216, Washington, DC, June, 1993 2] Richard A. Brualdi, Introductory Combinatorics, Prentice Hall, 1992 3] A. Barr and E.A. Feigenbaum, The handbook of Arti?cial Intelligence, Willam Kaufmann 1981 4] Margaret H. Dunham, Data Mining Introduction and Advanced Topics Prentice Hall, 2003, ISBN 0-13088892-3 5] Fayad U. M., Piatetsky-Sjapiro, G. Smyth, P. \(1996 From Data Mining to Knowledge Discovery: An overview. In Fayard, Piatetsky-Sjapiro, Smyth, and Uthurusamy eds., Knowledge Discovery in Databases AAAI/MIT Press, 1996 6] H Gracia-Molina, J. Ullman. &amp; J. Windin, J, Database Systems The Complete Book, Prentice Hall, 2002 7] T. T. Lee  Algebraic Theory of Relational Databases  The Bell System Technical Journal Vol 62, No 10, December, 1983, pp.3159-3204 8] T. Y. Lin  Deductive Data Mining: Mathematical Foundation of Database Mining  in: the Proceedings of 9th International Conference, RSFDGrC 2003 Chongqing, China, May 2003, Lecture Notes on Arti?cial Intelligence LNAI 2639, Springer-Verlag, 403-405 9] T. Y. Lin  Attribute \(Feature  The Theory of Attributes from Data Mining Prospect  in: Proceeding of IEEE international Conference on Data Mining, Maebashi, Japan, Dec 9-12, 2002, pp. pp.282-289 10] T. Y. Lin  Data Mining and Machine Oriented Modeling: A Granular Computing Approach  Journal of Applied Intelligence, Kluwer, Vol. 13, No 2, September/October,2000, pp.113-124 11] T. Y. Lin, N. Zhong, J. Duong, S. Ohsuga  Frameworks for Mining Binary Relations in Data  In: Rough sets and Current Trends in Computing, Lecture Notes on Arti?cial Intelligence 1424, A. Skoworn and L Polkowski \(eds 12] E. Louie,T. Y. Lin  Semantics Oriented Association Rules  In: 2002 World Congress of Computational Intelligence, Honolulu, Hawaii, May 12-17, 2002, 956961 \(paper # 5702 13  The Power and Limit of Neural Networks  Proceedings of the 1996 EngineeringSystems Design and Analysis Conference, Montpellier, France, July 1-4, 1996 Vol. 7, 49-53 14] Morel, Jean-Michel and Sergio Solimini, Variational methods in image segmentation : with seven image processing experiments Boston : Birkhuser, 1995 15] H. Liu and H. Motoda  Feature Transformation and Subset Selection  IEEE Intelligent Systems, Vol. 13 No. 2, March/April, pp.26-28 \(1998 16] Z. Pawlak, Rough sets. Theoretical Aspects of Reasoning about Data, Kluwer Academic Publishers, 1991 Proceedings of the Fourth IEEE International Conference on Data Mining \(ICDM  04 0-7695-2142-8/04 $ 20.00 IEEE pre></body></html 


than that of MAFIA and the runtime of MHP can be significantly less than that of MAFIA 5.3. The Effect of the MHP Algorithm on Finding Maximal Hyperclique Patterns Figure 8 and Figure 9 show the number of maximal patterns identi?ed byMHP andMAFIA on Pumsb* and Pumsb data sets respectively. As can be seen, the number of maximal hyperclique patterns identi?ed by MHP can be orders of magnitude smaller than the number of maximal frequent patterns identi?ed by MAFIA. In other words, the number Proceedings of the 16th IEEE International Conference on Tools with Artificial Intelligence \(ICTAI 2004 1082-3409/04 $20.00 © 2004 IEEE 100 1000 10000 100000 1e+06 1e+07 1e+08 1e+09 0.02 0.025 0.03 0.035 0.04 0.045 0.05 0.055 0.06 N um be r o f C ou nt ed P at te rn s Support Threshold Mafia Min_Conf=0 Min_Conf=0.1 Min_Conf=0.3 Min_Conf=0.5 Min_Conf=0.7 Min_Conf=0.9 Figure 8. The Number of MFI/MHP Patterns in the Pumsb* Data Set 100 1000 10000 100000 1e+06 


1e+07 1e+08 0.1 0.2 0.3 0.4 0.5 0.6 0.7 N um be r o f C ou nt ed P at te rn s Support Threshold Mafia Min_Conf=0.5 Min_Conf=0.7 Min_Conf=0.9 Figure 9. The number of MFI/MHP Patterns in the Pumsb Data Set of maximal hyperclique patterns is much easier to manage than that of maximal frequent patterns. Indeed, in realworld applications, it is dif?cult to interpret several million maximal frequent patterns. However, it is possible to interpret the results of maximal hyperclique pattern mining In addition, due to the memory limitation, we cannot extract maximal frequent patterns with MAFIA on the Pumsb data set if the support threshold is less than 0.4, as shown in Figure 7. In contrast, MHP can identify maximal hyperclique patterns when the support threshold is 0.1, if we set the h-con?dence threshold to 0.5. In other words, MHP has the ability to identify patterns which can be dif?cult to identify for MAFIA. Hence, MHP can better explore the pattern space and ?nd interesting patterns at low levels of support 6. Conclusions and Future Work In this paper, we present a two-phase Maximal Hyperclique Pattern \(MHP best features of both the BFS strategy and the DFS strategy. More speci?cally, we adapted DFS pruning methods such as equivalence pruning, to an apriori-like approach In addition, we proved the correctness and completeness of the MHP algorithm. Finally, our experimental results show that the MHP algorithm can be several orders of magnitude faster than standard maximal frequent pattern mining algorithms and has the ability to identify patterns at extremely low levels of support in dense data sets There are several directions for future work. First, in 


this paper, we only generate the size-2 patterns in the BFS phase. It will be interesting to investigate the impact on the performance if the ?rst phase is stopped at a deeper level Also, the projection is a very ef?cient method for ?nding patterns, especially for parallel implementation of pattern mining algorithms [1]. We plan to adapt the projection ideas into our algorithm and design an ef?cient parallel algorithm for mining maximal hyperclique patterns References 1] R. Agarwal, C. Aggarwal, and V. Prasad. A Tree Projection Algorithm For Generation of Frequent Itemsets. pages 350 371, Feb 2001 2] R. Agrawal, T. Imielinski, and A. Swami. Mining Association Rules between Sets of Items in Large Databases. In Proc. of the ACM SIGMOD Conference on Management of Data, pages 207–216,May 1993 3] R. Agrawal and R. Srikant. Fast Algorithms for Mining Association Rules. In Proc. of the 20th Int’l Conference on Very LargeData Bases, 1994 4] R. Bayardo. Ef?ciently mining long patterns from databases In Proc. of the ACM SIGMOD Conference, 1998 5] R. Bayardo and R. Agrawal. Mining the Most Interesting Rules. In Proc. of the ACM SIGKDD Conference, 1999 6] D. Burdick, M. Calimlim, and J. Gehrke. Ma?a: AMaximal Frequent Itemset Algorithm for Transactional Databases. In Proc. of IEEE Conf. on Data Engineering, 2001 7] Y. Huang, H. Xiong, W. Wu, and Z. Zhang. A Hybrid Approach for Mining Maximal Hyperclique Patterns. In In Technical Report UTDCS-34-04, Department of computer science, University of Texas - Dallas, 2004 8] J.Han, J.Pei, and Y. Yin. Mining Frequent Patterns without Candidate Generation. In Proc. of the ACM SIGMOD International Conference on Management of Data, 2000 9] M.J.Zaki and C.Hsiao. ChARM: An ef?cient algorithm for closed itemset mining. In Proc. of 2nd SIAM International Conference on Data Mining, 2002 10] R.Rymon. Search through Systematic Set Enumeration. In Proc. Third Int’l Conference on Principles of Knowledge Representation and Reasoning, 1992 11] H. Xiong, M. Steinbach, P.-N. Tan, and V. Kumar. HICAP: Hierarchial Clustering with Pattern Preservation. In Proc. of 2004 SIAM International Conference on Data Mining \(SDM 12] H. Xiong, P.-N. Tan, and V. Kumar. Mining Strong Af?nity Association Patterns in Data Set with Skewed Support. In Proc. of the Third IEEE International Conference on Data Mining \(ICDM Proceedings of the 16th IEEE International Conference on Tools with Artificial Intelligence \(ICTAI 2004 1082-3409/04 $20.00 © 2004 IEEE 





