html><head></head><body><pre style="word-wrap: break-word; white-space: pre-wrap;">  1 A Residual Estimation Based Approach for Isolating Faulty Parameters  Sachin Kumar, Eli Dolev, and Michael Pecht  Prognostics Health Management Group Center for Advanced Life Cycle Engineering \(CALCE University of Maryland, College Park, MD 20742 301-405-5323 pecht@calce.umd.edu  Mark Pompetzki  HBM  nCode Products Southfield, MI 48076 248 945 4352 mark.pompetzki@ncode.com  Abstract  This paper presents a new residual estimation based diagnostic approach that includes detection and fault isolation using the Mahalanobis distance \(MD performance parameter isolation approach is based on the analysis of residual MD values. The residual value is calculated by taking the difference between MD values estimated in two different scenarios: first, when a performance parameter is present, and second, when that performance parameter is absent. The residual of the MD values for each parameter is obtained by using training data from several experiments as part of the training data analysis planned by the design-of-experiment concept to analyze the impact of each parameter. The distribution of residual MD values for each parameter is analyzed and a 95% probabilistic range is established. This range represents the expected contribution by parameters toward a healthy system  s MDs, and it is used to identify the parameters that are responsible for the anomalous behavior of a system Parameters that fall below the lower bound of the 95 probabilistic range are considered candidates for the anomalous behavior, and the parameter that has the lowest residual value is isolated as the faulty parameter. A case study on computers is presented to demonstrate and test the suggested new approach  s ability to isolate faulty parameters.1, 2 TABLE OF CONTENTS 1. INTRODUCTION......................................................1 2. FAULT ISOLATION METHODOLOGY .....................3 3. CASE STUDY ..........................................................4 4. SUMMARY AND CONCLUSIONS..............................6 ACKNOWLEDGEMENTS .............................................7 REFERENCES .............................................................7 BIOGRAPHY ...............................................................8 1. INTRODUCTION All electronics application areas call for enhancing the safety and reliability of electronic systems in ways that reduce their vulnerability to serious failures and the failure of the host systems. Prognostics and health management PHM 1 1 978-1-4244-2622-5/09/$25.00  2009 IEEE 2 IEEEAC paper #1715, Version 5, Updated Dec 19, 2008 system by assessing the extent of deviation or degradation of a product from its expected normal \(healthy conditions in a preemptive and opportunistic manner in order to anticipate failures [1]. PHM involves continuous autonomous, real-time monitoring of the health conditions of a system by means of embedded or attached sensors with a minimal level of manual intervention needed to evaluate its actual life-cycle conditions, determine the advent of failure, and mitigate system risks [2]. An understanding of failures, their location, and the amount of damage is 


failures, their location, and the amount of damage is essential for providing prognostic estimates such as the remaining useful life of a system [3] and for the development of fault-tolerant systems Key terminologies used in fault diagnostics are fault failure, and fault isolation. A fault is an unexpected deviation from acceptable behavior of at least one performance property of a system. Failure is a permanent interruption of a system  s functionality or a time lag in the performance of a system  s expected functionality under specified operating conditions. It is not always easy to determine system failure because some faults may not lead to functionality loss; therefore, definition and characterization of faults should be performed in the failure detection process. Fault isolation is the determination of the type and location of a fault, and it follows fault detection [4 5]. One or more performance parameters may reflect different systems  failure modes. Identification of performance parameters is essential for locating the faulty components that are responsible for system  s failure [6] [7 Fault isolation methods are broadly grouped into two classes: model-based and data-based. Model-based methods are generally functionality-dependent: system functionality is modeled into mathematical form and residuals are connected to specific faults [8] [9]. These methods are based on a deterministic process model that must be correct for a system  s proper functionality. This approach is suitable for isolating specific known faults. On the other hand, data-based methods rely on performance parameter measurements. For fault detection, the definitions of thresholds are based on the measurements made during a system  s healthy operation. For fault isolation, different abnormal health states of a system are defined using data 2 collected when a system was operating abnormally in order to distinguish different faults. Fault isolation is accomplished by comparing systems current health state to the known regions of the systems healthy state space. Some data-based approaches consider the contribution of particular states to the overall shift from healthy states to identify and isolate faults [10], [11 The data-based fault isolation approach includes dimensionality reduction techniques, state-based techniques regression techniques, and techniques based on distance measures. One of the dimensional reduction techniques principle component analysis \(PCA handling large amounts of data [12]. In the PCA approach reduction in dimensionality results in information loss [13 In this technique, the contributions of different parameters to a distance measure are analyzed to identify faulty parameters. However, a parameter contributing more does not indicate that the parameter is exhibiting anomalous behavior because these are the parameter  s contributions in the variability of an observation State based techniques define state models for parameters in order to capture linear or nonlinear characteristics of a system  s performance parameters. The analysis of residuals obtained from parameters  observed and estimated values from the state model are used for characterizing faults [14 In this characterization process, a model is defined for each fault type to isolate the fault. However, these fault-specific models are only useful for identifying specific known faults The regression model of performance parameters is another approach to obtain a parameter  s estimate, but it often fails to capture variability in the parameters Distance-based methods have been used for fault detection The Mahalanobis distance \(MD detection in computers [15], [16]. In addition, MD has also been used for fault isolation where data from both healthy and unhealthy systems were used to isolate faults [17 In this paper, a data-based approach that utilizes residuals 


In this paper, a data-based approach that utilizes residuals estimated using MD for isolating faults is proposed. The MD method is good for two reasons; first, MD reduces a multivariate system to a univariate system, and second, MD is sensitive to inter-variable changes in a multivariate system. It includes all observed performance parameters in defining the health of a system \(i.e., no information loss in the health estimation process not require definition of a faulty state during training and fault isolation, so it does not depend on any specific fault type. The approach defines the threshold bound on MD residuals for parameters, which are estimated from healthy data. The residual for each parameter is obtained by performing experimental analysis planned by the Design of Analysis \(DoA formed to evaluate the residual of MD \(i.e., impact of each parameter on MD been used to determine parameters that are contributing most to Mahalanobis distance [18], [19 Experiments were performed on computers to generate training data that are used to define the threshold for the proposed fault isolation approach. The experimental details the algorithmic approach to fault isolation, and a case study are discussed later in the paper. Both MD and DoA are briefly described in the following sections Mahalanobis Distance The Mahalanobis distance methodology is a process of distinguishing multivariable data groups by a univariate distance measure that is defined by several performance parameters. The MD value is calculated using the normalized value of performance parameters and their correlation coefficients, which is the reason for MD  s sensitivity [18], [19]. A data set formed by measuring the performance parameters of a healthy product is used as the training set for MD. The collection of MD values for a healthy system is known as the Mahalanobis Space The parameters collected from a system are denoted as Xi where i = 1, 2  m. The observation of the ith parameter on the jth instance is denoted by xij, where i = 1, 2  m, and j 1, 2  n. Here, m is the number of parameters, and n is the number of observations. Thus the \(m  1 for the healthy product are denoted by Xj, where j = 1, 2   n. Each individual parameter in each data vector is normalized by subtracting the mean of the parameter \(Xi and dividing it by the standard deviation \(Si and standard deviations are calculated from the healthy data. Thus, the normalized values are as follows   i iij ij S Xx z  i = 1, 2  m, j = 1, 2  n,  \(1 where   n j iji xn X 1 1 and   1 2   


    n Xx S n j iij i  Next, the values of the MDs are calculated for the healthy items using the following  j T jj zCzm MD 11 ?=     \(2 where zjT=[z1j,z2j  zmj] is a transpose vector of vector zj that comprises zij , and C is the correlation matrix calculated as     n j T jj zzn C 1  1      \(3 For fault detection, a threshold MD is defined using training i.e., healthy calculated for each observation by using the performance 3 parameter  s mean, standard deviation, and a correlation coefficient matrix obtained from the training data Significant Input Parameters Identification Design of Experiments \(DoE method for determining the relationship between different input parameters affecting a process and the output of that process. DoE is used to quantify indeterminate measurements of parameters through observance of forced changes made methodically as directed by mathematically systematic tables. For evaluating parameters, DoE involves designing a set of experimentation in which all relevant parameters are varied systematically. The parameters that influence the process output most are identified by analyzing the output of these experimentations [19 Different performance parameters are considered as input parameters of the process while applying DoE approach to MD method and the MD value is used as an output of the process. In order to do fault isolation, DoE experimentation implement  one change at a time  because it allows for a judgment on the significance of input variables acting alone to the output. Some kinds of dependency or interaction among parameters are considered in MD value itself because the MD method utilizes correlation among parameters 2. FAULT ISOLATION METHODOLOGY A diagnostic algorithm would have wider applicability if it has the capability of fault isolation in addition to fault detection. The detection capability identifies a fault \(i.e malfunction classification of a system  s health \(faulty or non-faulty whereas the fault isolation capability enables identification of faulty parameters. A system  s fault or failure mode, and the fault  s location could be determined by applying reasoning to the faulty parameters 


reasoning to the faulty parameters In the fault detection approach, a system  s health is classified by comparing the MD value with a threshold MD value healthy detection approach \(Figure 1 performance parameters followed by MD calculation and comparison with the threshold value for classification of a system  s health. In a situation when a system is classified as unhealthy, further investigation for determining the fault type is then performed by the fault isolation approach The fault isolation approach discussed here is based on the analysis of residual MD value. A residual MD bound MDi obtained for healthy systems. The threshold defining procedure \(Figure 2 analytical DoE considering  one change at a time  Training data for these experiments are extracted from the healthy data set collected from healthy systems. In each experiment the MD value for each observation is calculated, where MDp represents an MD calculated considering that all parameters are present, and MDia is an MD where parameter i is absent Threshold Mahalanobis distance Mahalanobis distance \(MD Parameter monitoring System not healthy Parameter identification System healthy MD ? ? N Y Health evaluation  Figure 1. Fault detection approach The residual MD corresponding to a parameter i is represented by ?MDi. The ?MDi is obtained by subtracting the MDp from MDia for each observation. The distribution of ?MDi for a parameter represents that parameter  s contribution to MD. A threshold value \(?MDi corresponding to a 95% bound on the ?MDi for each parameter is defined as an expected range of ?MD for parameter i Construct orthogonal design of experiment Training data from healthy system for each experiment Calculate MDp when all parameters are present Calculate MDia when one parameter i is absent Calculate ?MDi when parameter i is absent \(i.e., MDia  MDp Calculate 95  bounds  MDi Figure 2. Parameter Isolation: Threshold Determination for Parameters \( ?MDi Parameters that are contributing significantly to MD are identified first in order to be considered in the parameter isolation process. For each analytical experiment, the signalto-noise ratio \(S/N ratio that correspond to observations of the training data. Largerthe-better-type S/N ratios are used because true levels of abnormality are not known, and the MD value would be 4 large for any abnormalities in the system. Taguchi  s largerthe-better S/N ratio is defined as          


  n j jMDn 1 11log10     \(5 where n is the number of observations for an entity For a given parameter i the average value of the S/N ratio is determined using all the observations with the parameter present, S/Np, and parameter absent, S/Nia. The information withheld due to the absence of a parameter is quantified by the difference between two S/N ratios: S/Nia  S/Np. If the S/N ratio difference is negative \(i.e., information loss the parameter i is considered significant; otherwise, it is not The procedure for isolating a faulty parameter for a test system is shown in Figure 3. Each observation from a test system is analyzed for each analytical experiment. The MD value for each test observation is calculated using the mean standard deviation, and correlation matrix of a healthy system. The ?MDi, where i represent a parameter, for each test observation is calculated and compared with the threshold ?MDi?. The parameter with an ?MDi below the lower bound of threshold range \(?MDi candidate of faulty parameter, and the highest  MDi  is determined to be the faulty parameter. Other parameters are evaluated as well in order to validate the faulty parameter identification Test data for each experiment Calculate MDp when all parameters are present Calculate MDia when one parameter i is absent Calculate ?MDi when parameter i is absent Compare ?MDi with 95  bounds  MDi Faulty parameter: parameter with highest  MDi Parameters with  MDi are chosen as potentially faulty Use orthogonal design of experiment  Figure 3. Parameter Isolation \(Test Data Evaluation 3. CASE STUDY The fault detection and faulty parameter isolation methodology was applied to computers. Experiments were conducted on ten brand new identical computers with the assumption that these computers were representative of healthy systems. The data from the healthy computers were used to define a healthy baseline and to study the parameters  behaviors. The performance parameters monitored during the experiments were fan speed, CPU temperature, motherboard temperature, video card temperature, two power saving states \(%C2, and %C3 CPU usage, and %CPU throttle. These parameters are represented as P1 to P8 in the following discussion The experiment was designed to replicate the real-time usage of computers. The computers were exposed to six environmental conditions, as shown in Table 1. For each temperature-humidity combination, four usage conditions and three power supply conditions were considered. A set of user activities was defined to execute different usage conditions on the computers. Details on experimental setup and training data collection can be found in the authors   previous publications [15], [16]. In total, 72 experiments were conducted. The same usage conditions were applied simultaneously to all computers to achieve time synchronization between computer and software application responses. The computer  s power mode was always set to ON. The screen saver and hibernation options were disabled to prevent these functions from occurring during the experiment Table 1. Environmental Conditions Temperature and Humidity 1. 5  C with uncontrolled RH 2. 25  C with 55% RH 


2. 25  C with 55% RH 3. 25  C with 93% RH 4. 50  C with 20% RH 5. 50  C with 55% RH 6. 50  C with 93% RH The Mahalanobis distance values were obtained for the experimental \(i.e., training used to determine a threshold MD value \(=5.8 system. The threshold was used to compare the MD values of test systems to determine the health state or presence of faults. Once the presence of a fault was established, the next objective was to isolate the parameter that was responsible for the fault in the computer For this study, eight parameters were monitored with  one change at a time  and nine analytical experiments were defined as listed in Table 2. Each cell entry in Table 2 represents a parameter  s status in the MD calculation  1   means that a parameter was included, and  2  means that a parameter was excluded from the MD calculation For each experiment \(Table 2 from the training data. The differences in S/N ratios with the inclusion and exclusion of each parameter in MD 5 calculation are presented in Figure 4. The parameters that have downward slopes \(i.e., a loss of information due to a parameter  s absence degree of slope defines the significance level of a parameter  s importance in MD calculation. Figure 4 suggests that at least four out of eight parameters must be considered for MD calculation, including fan speed, CPU temperature, motherboard temperature, and video card temperature Table 2. Orthogonal Design of Experiment Performance Parameters Exp No. P1 P2 P3 P4 P5 P6 P7 P8 E1 1 1 1 1 1 1 1 1 E2 2 1 1 1 1 1 1 1 E3 1 2 1 1 1 1 1 1 E4 1 1 2 1 1 1 1 1 E5 1 1 1 2 1 1 1 1 E6 1 1 1 1 2 1 1 1 E7 1 1 1 1 1 2 1 1 E8 1 1 1 1 1 1 2 1 E9 1 1 1 1 1 1 1 2 5 6 7 8  1     2 1     2 1     2 1     2 1     2 1     2 1     2 1     2 P1 P2 P3 P4 P5 P6 P7 P8 S N ra tio S N ra tio  Figure 4. Graph of parameters  effects on MD 2 1 0 1 P1 P2 P3 P4 P5 P6 P7 P8  M D  M D 


D  Figure 5. ?MD values for an observation of training data The MD values for the first analytical experimentation contain all parameters. The second, third, and subsequent experimentations exclude one parameter in the MD calculation. Subtracting the first analytical experiment  s MD from other analytical experiment  s MD gave the quantitative measure \(?MDi = MDia  MDp parameter  s contribution. For each observation, the ?MDs resulting from the absence of different parameters are shown in Figure 5 From the training data, ?MDs for each observation were calculated and sample distributions of the ?MDs for four parameters are shown in Figure 6. The ?MDs followed Normal distribution, and a 95% confidence range on ?MD was estimated to define a threshold boundary for each parameter in order to isolate faulty parameters, as shown in Table 3 MD?MD Fr eq ue nc y Fr eq ue nc y Fan speed CPU temperature Motherboard temperature Videocard temperature 1.20.60.0-0.6-1.2 4000 3000 2000 1000 0 1.20.60.0-0.6-1.2 4000 3000 2000 1000 0 1.20.60.0-0.6-1.2 4000 3000 2000 1000 0 1.20.60.0-0.6-1.2 4000 3000 2000 1000 0 MD?MD Fr eq ue nc y Fr eq ue nc y  Figure 6. ?MD distribution of different parameters 


Figure 6. ?MD distribution of different parameters Table 3. Threshold Bound \(95% range MD from Training Data Parameters ?MD at 2.5 MD at 97.5 P1 - Fan Speed -0.85 0.34 P2 - CPU temperature -0.86 0.33 P3 - Motherboard temperature -0.61 0.28 P4 - Videocard temperature -0.86 0.34 P5 - %C2 state -0.66 0.28 P6 - %C3 state -0.67 0.34 P7 - %CPU usage -0.58 0.37 P8 - %CPU throttle -0.64 0.34 The upper bound \(i.e., + MD performance but no loss in information, whereas the lower 6 bound \(i.e  MD MD value should increase when there is an abnormality The lower bound is used as threshold for identifying faulty parameters A field-returned computer  test computer   verify the anomaly detection methodology. Five thousand data points from the test computer were analyzed. Figure 7 shows the MDs of healthy computers \(lower plot test computer \(above plot computer  s MD values were higher than the threshold MD 5.8 anomaly that was the reason for its being returned The next step was to isolate faulty parameters. Analysis on MDi was performed. The observations from the test data  s MDi analysis is shown in Table 4. The table presents the number of observations falling out of the 95% threshold bound \(NBTB the lower bound \(NBLB had the highest  MD  and which were below the lower bound of the threshold bound; the number of observations falling above the upper bound \(NAUB observation indicating faulty parameters \(PFP example, PF \(P1 with the highest percentage observation of the highest  MD  was most likely the faulty parameter. The components related to that parameter were most likely causing the fault. Parameters that exhibited more than 2.5 i.e., 97.5% confidence PFP the lower threshold bound should be investigated Approximately 73% time of the observations of the fan speed parameter, followed by videocard temperature for 24% and CPU temperature for 3% of the time was identified as faulty. Since, more than one parameter was under the scanner, correlation analysis should be performed to study the relationship between them 0 4 8 12 16 20 24 28 32 0 1000 2000 3000 4000 5000 Observation number M D v al ue Test Baseline  Figure 7. Comparison of MDs of test system with baseline 


Figure 7. Comparison of MDs of test system with baseline CPU performance-related parameters in the MD analysis fell beyond the threshold bound almost entire test time \(i.e 56% below lower bound and 42% above upper bound did not had the highest  MD  which suggested that there might be a problem with the CPU and should be analyzed further. The correlation coefficient analysis showed that the CPU performance parameters were not strongly correlated with the fan or temperature parameters. Whereas, a strong positive correlation \(correlation coefficient &gt; 0.75 the fan and temperature parameters was observed. The S/N ratio estimation suggested that the parameters related to CPU performance were of least importance in MD calculation. These two analyses suggested that CPU performance parameters were not causing the faults and thus were not considered as faulty. The results presented in Table 4 indicate that fan speed was the most likely faulty parameter because the fan parameter had highest PFP, and the fan speed was correlated with the temperature parameters At the 2,700th data point \(Figure 7 observed because the computer shutdown by itself and was then restarted manually. This resulted in temporary fan start-up and a drop in three temperatures. However, these temperatures were above the nominal/expected value of the CPU and video card temperatures during that period Therefore, these temperatures were identified as anomalous as well. Intuitively, if the fan were not functioning well, the temperature of the system would rise and become abnormally high. Manual investigation of the data set also indicated that the fan was not functioning well and that the three monitored temperatures were higher than the nominal temperature values by ~10  C. Therefore, it can be affirmed that this new approach did identify the faulty parameter of the computer Table 4. Observation of Parameters ?MDs from Test Data Parameters NBTB out of 5000 NBLB NAUB NHND PFP P1 4409 3791 618 3654 73 P2 4425 3357 1068 155 3 P3 4325 2947 1378 0 0 P4 3944 3941 3 1190 24 P5 4852 2736 2116 0 0 P6 4853 2764 2089 0 0 P7 4868 2774 2094 1 0 P8 4815 2763 2052 0 0 4. SUMMARY AND CONCLUSIONS A new fault isolation approach that utilizes the Mahalanobis distance has been demonstrated. The work expands the 7 applicability of the Mahalanobis distance from detection to fault isolation. In the literature, unhealthy system data has been used to scale MD values for fault isolation. In the new approach presented in this paper, data from an unhealthy system is not required; rather, a threshold bound based on healthy training data for each parameter is defined considering design of analysis \(DoA strength of the MD method is that it preserves all the information available because it does not reduce the dimensionality of the data A set of experiments was conducted to establish the  healthy  or  normal  operation on a set of notebook computers subjected to a range of usages and environmental conditions. A field-returned computer was evaluated in situ using Mahalanobis distance techniques. The Mahalanobisdistance-based faulty parameter identification method was used to identify the fault and the related key parameters for 


used to identify the fault and the related key parameters for root cause analysis of the anomalies. Four important parameters  fan speed and three temperature components CPU temperature, motherboard temperature and video card temperature  were identified for health estimation using the MD method. In the analysis of a field-returned computer using the suggested fault isolation approach, the fan speed parameter was identified as being faulty and verfied later The results showed that the suggested approach could be used for quick fault detection at a system level, and the same distance measure can also be used for faulty parameter isolation ACKNOWLEDGEMENTS This work is sponsored by the members of the CALCE Prognostics and Health Management Consortium at the University of Maryland, College Park REFERENCES 1] M. Pecht, Prognostics and Health Management of Electronics, New York: Wiley-Interscience, 2008 2] G. Zhang, C. Kwan, R. Xu, N. Vichare, and M. Pecht  An Enhanced Prognostic Model for Intermittent Failures in Digital Electronics  IEEE Aerospace Conference, Big Sky, MT, March 2007 3] N. Vichare, P. Rodgers, V. Eveloy, and M. Pecht  Environment and Usage Monitoring of Electronic Products for Health Assessment and Product Design   International Journal of Quality Technology and Quantitative Management. Vol. 2, No. 4, pp. 235  250 2007 4] S. N. Huang and K. K. Tan  Fault Detection, Isolation and Accommodation Control in Robotic Systems   IEEE Transactions on Automation Science and Engineering, Vol. 5, No. 3, pp. 480  489, July 2008 5] B. J. Ohran, J. Rau, P. D. Christofides, and J. F. Davis  Plant Wide Fault Isolation Using Nonlinear Feedback Control  Industrial and Engineering Chemistry Research, Vol. 47, No.12, pp. 4220  4229, June 18 2008 6] N. Vichare and M. Pecht  Enabling Electronic Prognostics Using Thermal Data  Proceedings of the 12th International Workshop on Thermal Investigation of ICs and Systems, Nice, C  te d'Azur, France September 27  29, 2006 7] N. Vichare, P. Rodgers, and M. Pecht  Methods for Binning and Density Estimation of Load Parameters for Prognostics and Health Management  International Journal of Performability Engineering, Vol. 2, No. 2 April 2006 8] H. Chen, G. Jiang, C. Ungureanu and K. Yoshihira  Failure Detection and Localization in Component Based Systems by Online Tracking  KDD, 2005 9] H. Wang, Z. Song, and P. Li  Fault Detection Behavior and Performance Analysis of Principal Component Analysis Based Process Monitoring Methods   American Chemical Society, Vol. 41, pp. 2455  2464 2002 10] H. H. Yue and S. J. Qin  Reconstruction-Based Fault Identification Using a Combined Index  American Chemical Society, Vol. 40, pp. 4403-4414, 2001 11] M. A. Demetriou  A Model-Based Fault Detection and Diagnosis Scheme for Distributed Parameter Systems A Learning Systems Approach  ESAIM?Control Optimization and Calculus of Variations, Vol. 7, pp 43  67, 2002 12] P. M. Frank, S. X. Ding, and T. Marcu  Model-Based Fault Diagnosis in Technical Processes  Transactions of the Institute for Measurement and Control, Vol. 22 pp. 57  101, 2000 13] D. Antory, G. W. Irwin, U. Kruger, and G McCullough  Improved Process Monitoring Using 


McCullough  Improved Process Monitoring Using Nonlinear Principal Component Models  International Journal of Intelligent Systems, Vol. 23, No. 5, pp. 520  544, May 2008 14] M. Kettunena, P. Zhangb, and S. Jamsa-Jounelaa  An Embedded Fault Detection, Isolation and Accommodation System in a Model Predictive Controller for an Industrial Benchmark Process   Computers and Chemical Engineering, Vol. 32, pp 2966  2985, 2008 8 15] S. Kumar, V. Sotiris, and M. Pecht  Mahalanobis Distance and Projection Pursuit Analysis for Health Assessment of Electronic Systems  IEEE Aerospace Conference, Big Sky, Montana, March 2008 16] S. Kumar, V.  Sotiris, M.  Pecht  Health Assessment of Electronic Products using Mahalanobis Distance and Projection Pursuit Analysis  International Journal of Computer, Information, and Systems Science, and Engineering, Vol. 2, No. 4, pp. 242  250, Fall 2008 17] G. Taguchi and R. Jugulum, The Mahalanobis  Taguchi Strategy, John Wiley and Sons, NY, 2002 18] G. Taguchi, S. Chowdhury, and Y. Wu. The Mahalanobis  Taguchi System, New York: McGrawHill, 2001 19] E. B. Martin, A. J. Morris and J. Zhang  Process Performance Monitoring Using Multivariate Statistical Process Control  IEEE Proceedings on Control Theory Application, Vol. 143, No.2, March 1996  BIOGRAPHY Sachin Kumar received the B.S. in Metallurgical Engineering from the Bihar Institute of Technology and the M.Tech. in Reliability Engineering from the Indian Institute of Technology, Kharagpur, India. He is currently pursuing the Ph.D. degree in Mechanical Engineering at the University of Maryland, College Park. He is IEEE student member. His research interests include reliability evaluation, models and algorithms development for electronic system diagnostics and prognostics, and electronic system health management Eli Dolev received a B.S. in Mechanical Engineering, an M.S. in Mechanical Engineering, and an MBA from the University of the Negev, Beer Sheva, Israel. He is chief system engineer at the Engineering and Production Department at the Nuclear Research Center  Negev, Israel. He is involved with the research, design, and development of mechanical systems. Previously he was head of the Electronic Packaging Department at the Nuclear Research Center  Negev, and engaged in the development, design and manufacturing of electronic handheld instruments and systems for radiation detecting and monitoring. He has authored or co-authored over 30 conferences and refereed journal publications. Currently he is a guest researcher at the CALCE Electronic Products and Systems Center at the University of Maryland, College Park where he is involved in evaluating models and algorithms for prognostics and health management Michael Pecht has a B.S. in Acoustics, an M.S. in Electrical Engineering and an M.S. and Ph.D. in Engineering Mechanics from the University of Wisconsin at Madison He is a Professional Engineer, an IEEE 


He is a Professional Engineer, an IEEE Fellow, and an ASME Fellow. He has received the 3M Research Award for electronics packaging, the IEEE Award for chairing key Reliability Standards, and the IMAPS William D. Ashman Memorial Achievement Award for his contributions in electronics reliability analysis. He has written over twenty books on electronic products development, use, and supply chain management. He served as chief editor of the IEEE Transactions on Reliability for eight years and on the advisory board of IEEE Spectrum. He has been the chief editor for Microelectronics Reliability for over eleven years and an associate editor for the IEEE Transactions on Components and Packaging Technology. He is visiting Professor at City University of Hong Kong and Director of the Center for Advanced Life Cycle Engineering \(CALCE and the Electronic Products and Systems Consortium at the University of Maryland. He has also been leading a research team in the area of prognostics, and formed the Prognostics and Health Management Consortium at the University of Maryland. He has consulted for over 50 major international electronics companies, providing expertise in strategic planning, design, test, prognostics, IP, and risk assessment of electronic products and systems   pre></body></html 


4] M. Bishop  What is computer security  IEEE Sec. Priv. Mag., vol. 1 no. 1, pp. 67  69, Jan.-Feb. 2003 5] B. Farquhar  One approach to risk assessment  Computers and Security, vol. 10, no. 10, pp. 21  23, February 1991 6] G. Stoneburner, A. Goguen, and A. Feringa  Risk management guide for information technology systems  National Institute of Standards and Technology \(NIST Publication 800-30, July 2002 7] R. Fredriksen, M. Kristiansen, B. A. Gran, K. Stolen, T. A. Opperud and T. Dimitrakos  The coras framework for a model-based risk management process  in SAFECOMP  02: Proceedings of the 21st International Conference on Computer Safety, Reliability and Security London, UK: Springer-Verlag, 2002, pp. 94  105 8] C. Alberts, A. Dorofee, J. Stevens, and C. Woody  Introduction to the OCTAVE approach  Carnegie Mellon - Software Engineering Institute Pittsburgh, PA 15213-3890, Tech. Rep., August 2003 9] DCSSI  Expression des Besoins et Identi?cation des Objectifs de Scurit EBIOS  General Secretariat of National Defence Central Information Systems Security Division \(DCSSI 2004 10] ISO/IEC  ISO/IEC 27005:2007, Information technology - Security techniques - Information security risk management  November 2007 11] BSI  IT Grundschutz Manual  2004. [Online]. Available http://www.bsi.de/english/gshb/manual/download/index.html 12] M. Vitale  The growing risks of information systems success  MIS Quarterly, vol. 10, no. 4, pp. 327  334, December 1986 13] K. Bandyopadhyay and P. Mykytyn  A framework for integrated risk management in information technology  Management Decision, vol. 37 no. 5/6, pp. 437  444, 1999 14] C. Jung, I. Han, and B. Suh  Risk analysis for electronic commerce using case-based reasoning  International Journal of Intelligent Systems in Accounting, Finance &amp; Management, vol. 8, pp. 61  73, 1999 15] W. Baker and L. Wallace  Is information security under control?: Investigating quality in information security management  IEEE Security and Privacy, vol. 5, no. 1, pp. 36  44, 2007 16] R. Baskerville  Information systems security design methods: Implications for information systems development  ACM Computing Surveys vol. 25, no. 4, pp. 375  414, December 1993 17] ISO/IEC  ISO/IEC 27001:2005, Information technology - Security techniques - Information security management systems - Requirements  2005 18] W. Baker, L. Rees, and P. Tippett  Necessary measures: metric-driven information security risk assessment and decision making  Communications of the ACM, vol. 50, no. 10, pp. 101  106, 2007 19] S. Frosdick  The techniques of risk analysis are insuf?cient in themselves  Disaster Prevention and Management, vol. 6, no. 3, pp. 165  177, 1997 20] A. Ekelhart, S. Fenz, M. Klemen, and E. Weippl  Security Ontologies Improving Quantitative Risk Analysis  in 40th Hawaii International Conference on System Sciences \(HICSS  07 IEEE Computer Society, Jan 2007, pp. 156  162 21] A. Ekelhart, S. Fenz, G. Goluch, and E. Weippl  Ontological Mapping of Common Criteria  s Security Assurance Requirements  in New Approaches for Security, Privacy and Trust in Complex Environments Proceedings of the IFIP TC 11 22nd International Information Security Conference, IFIPSEC2007, May 14-16, ser. IFIP International Federation for Information Processing, H. Venter, M. Eloff, L. Labuschagne J. Eloff, and R. von Solms, Eds., vol. 232/2007. Sandton, South Africa International Federation for Information Processing, May 2007, pp. 85  95, 978-0-387-72366-2 22] A. Ekelhart, S. Fenz, T. Neubauer, and E. Weippl  Formal threat descriptions for enhancing governmental risk assessment  in Proceedings of the First International Conference on Theory and Practice of Electronic Governance. ACM Press, 2007 23] T. Neubauer, A. Ekelhart, and S. Fenz  Interactive Selection of ISO 27001 Controls under Multiple Objectives  in Proceedings of the IFIP TC 11 23rd International Information Security Conference, IFIPSec 2008, vol. 278/2008. Boston: Springer, July 2008, pp. 477  492 


2008, vol. 278/2008. Boston: Springer, July 2008, pp. 477  492 24] T. Neubauer, C. Stummer, and E. Weippl  Workshop-based Multiobjective Security Safeguard Selection  in Proceedings of the First International Conference on Availability, Reliability and Security ARES IEEE Computer Society, 2006, pp. 366  373 25] T. Neubauer and C. Stummer  Interactive Decision Support for multiobjective COTS Selection  in Proceedings of the 40th Annual Hawaii International Conference on System Sciences, no. 01, 2007 26    Extending Business Process Management to Determine Ef?cient IT Investments  in Proceedings of the 2007 ACM Symposium on Applied Computing, 2007, pp. 1250  1256 27] W3C  OWL - web ontology language  http://www.w3.org/TR/owlfeatures/, February 2004 28] J. Burtles, Principles and Practice of Business Continuity: Tools and Techniques. Rothstein Associates Inc., 2007 29] T. R. Peltier, Information Security Risk Analysis, 2nd ed. Auerbach Publications, 2005 30] S. Kairab and L. Kelly, A Practical Guide to Security Assessments Boston, MA, USA: Auerbach Publications, 2004 Proceedings of the 42nd Hawaii International Conference on System Sciences - 2009 10 pre></body></html 


well as from practitioners, is available, IL strategy including DWH/BI strategy IL strategies are addressed at all, either actual artifacts/documents are proposed without an integrating meta model/methodology, or the strategy making process is described without proposing specific and consistent result templates/structures Since it consumes a significant amount of resources and may constitute significant potentials for business, IL needs strategy. IL strategy must not be limited to hardware/software selection and architectural considerations, but should address the entire business scope of sourcing services, integrating acquired and self-made services into customer-oriented IL solutions, and delivering such solutions to create customer value Our survey of the state of IL strategy in practice reveals that IL sourcing, IL delivery and IL portfolio strategies are regarded as important strategy components. The larger companies are, the more international their focus is, and the more their IL is organized according to the CC model, the more components of a supply-chain oriented explicit IL strategy they are likely to have deployed The IIM model provides a suitable conceptual foundation for structuring such strategy components and also provides best practices from IT management which often can be easily adapted to IL. Regarding IL product/service development and maintenance certain functional oriented strategy sub-components are differentiated in our framework. These strategy components are adapted from an established data management functional framework in order to reflect IL specifics. While traditional, more technically oriented sub-components such as system and data architecture are covered in most companies, business oriented components like change management and project/business requirements management are covered less frequently. Additional research is necessary to develop appropriate solution components based on existing fragments and experiences Based on a more complete comprehension of IL strategy and its components, the strategy development and update process needs to be addressed in future research as well. Instead of developing and updating business strategies, IT strategies and IL strategies in independent processes, dependencies and cycles need to be addressed. A comprehensive understanding of IL strategy and respective processes may also serve as a foundation for establishing maturity models, reference models and best practices  References 1] Arnott, D. and G. Pervan, Eight key issues for the decision support systems discipline. Decision Support Systems 44\(3  2] Baum  l, U., Strategic Agility through Situational Method Construction. Proceedings of the European Academy of Management Annual Conference 2005, 2005  3] Burton, B., et al., Activity Cycle Overview: Business Intelligence and Information Management. Gartner Research G00138711, 2006  4] Chan, J.O., Optimizing Data Warehousing Strategies Communications of the IIMA, 5\(1  5] Earl, M., Management Strategies for Information Technology, Prentice Hall, New York et al., 1989  6] Eckerson, W.W., Data Quality and the Bottom Line 


6] Eckerson, W.W., Data Quality and the Bottom Line Achieving Business Success through a Commitment to High Quality Data. TDWI, Chatsworth, 2002  Proceedings of the 42nd Hawaii International Conference on System Sciences - 2009 9 7] Elliott, T., Implementing Business Intelligence Standards. BusinessObjects, 2004  8] English, L.P., Improving Data Warehouse and Business Information Quality: Methods for Reducing Costs and Increasing Profits, Wiley Computer, New York et al., 1999  9] Foshay, N., Best Practices in Business Intelligence Strategy. Blue Hammock, 2006  10] Friedman, T. and B. Hostmann, Management Update The Cornerstones of Business Intelligence Excellence Gartner Research G00120819, 2004  11] Gonzales, M., Creating a BI Stragey Document. DM Review, 2004\(November  12] Henderson, J.C. and N. Venkatraman, Strategic alignment: Leveraging information technology for transforming organizations. IBM Systems Journal, 32\(1  13] Hoffmann, O., Performance Management - Systeme und Implementierungsans  tze. 3 ed, Haupt, Bern et al 2002  14] Klesse, M. and R. Winter, Organizational Forms of Data Warehousing: An Explorative Analysis. in: IEEE Computer Society, Proceedings of the 40th Hawaii International Conference on System Sciences \(HICSS-40 Alamitos, 2007  15] Laudon, J. and K. Laudon, Management Information Systems: Managing the Digital Firm. 10 ed, Prentice Hall 2006  16] Losey, R., Enterprise Data Warehouse Strategy: Articulating the Vision. Dm Review, 2003\(January  17] Luftman, J.N. and R. Kempaiah, Key Issues For IT Executives 2007. MISQ Executive, 7\(2  18] MAIS and AIMS, A Business Intelligence Strategy Proposal for The University of Michigan. 2005  19] Melchert, F., Metadatenmanagement im Data Warehousing. Ergebnisse einer empirischen Studie. Institut f  r Wirtschaftsinformatik, Universit  t St. Gallen, 2004  20] Mosley, M., DAMA-DMBOK Functional Framework Version 3. DAMA International, 2008  21] Olszak, C.M. and E. Ziemba, Business Intelligence as a Key to Management of an Enterprise. in: Informing Science Institute, Informing Science + Information Technology Education, Pori, Finland, 2003  22] R  egg-St  rm, J., The New St. Gallen Management Model: Basic Categories of an Approach to Integrated Management, Palgrave Macmillan, Basingstoke, NY, 2005  23] Sommer, T., et al., Business Intelligence-Strategie bei der Volkswagen AG. in: Integrierte Informationslogistik B. Dinter and R. Winter, Editors, 2008, Springer, Berlin Heidelberg. pp. 261-284  


 24] Subramaniam, A., et al., Strategic planning for Data warehousing. Information &amp; Management, 33, 1997, pp 99-113  25] Totok, A., Entwicklung einer Business-IntelligenceStrategie. in: Analytische Informationssysteme - Business Intelligence-Technologien und -Anwendungen, P. Chamoni and P. Gluchowski, Editors, 2006, Springer, Berlin et al pp. 51-70  26] Vaduva, A. and T. Vetterli, Metadata Management for Data Warehousing: An Overview. International Journal of Cooperative Information Systems, 10\(3 298  27] Watson, H.J., D.L. Goodhue, and B.H. Wixom, The benefits of data warehousing: why some organizations realize exceptional payoffs. Information &amp; Management 39\(6  28] Watson, H.J., C. Fuller, and T. Ariyachandra, Data warehouse governance: best practices at Blue Cross and Blue Shield of North Carolina. Decision Support Systems 38\(3  29] Winter, R. and M. Meyer, Organization Of Data Warehousing In Large Service Companies: A Matrix Approach Based On Data Ownership and Competence Centers. Proceedings of the Seventh Americas Conference on Information Systems \(AMCIS 2001  30] Winter, R., Enterprise-wide Information Logistics Conceptual Foundations, Technology Enablers, and Management Challenges. ITI2008, 2008  31] Zarnekow, R., W. Brenner, and U. Pilgram, Integrated Information Management. Applying Successful Industrial Concepts in IT. 1 ed, Springer, Berlin, 2006  32] Zeid, A., Your BI Competency Center: A Blueprint for Successful Deployment. Business Intelligence Journal 11\(3    Proceedings of the 42nd Hawaii International Conference on System Sciences - 2009 10 pre></body></html 


The HyspIRI mission utilizes innovative techniques to both reduce the amount of data that must be transmitted to the ground and accommodate the required data volume on the ground The infrastructure and techniques developed by this mission will open the door to future high data volume science missions The designs presented here are the work of the authors and may differ from the current HyspIRI mission baseline A CKNOWLEDGMENTS This research was carried out at the Jet Propulsion Laboratory California Institute of Technology and was sponsored by the Space Grant program and the National Aeronautics and Space Administration R EFERENCES  K W ar\002eld T  V  Houten C Hee g V  Smith S Mobasser B Cox Y He R Jolly C Baker S Barry K Klassen A Nash M Vick S Kondos M Wallace J Wertz Chen R Cowley W Smythe S Klein L Cin-Young D Morabito M Pugh and R Miyake 223Hyspiri-tir mission study 2007-07 002nal report internal jpl document,\224 TeamX 923 Jet Propulsion Laboratory California Institute of Technology 4800 Oak Grove Drive Pasadena CA 91109 July 2007  R O Green 223Hyspiri summer 2008 o v ervie w  224 2008 Information exchanged during presentation  S Hook 2008 Information e xchanged during meeting discussion July 16th  R O Green 223Measuring the earth wi th imaging spectroscopy,\224 2008  223Moore s la w Made real by intel inno v ation 224 http://www.intel.com/technology/mooreslaw/index.htm  T  Doggett R Greele y  S Chein R Castano and B Cichy 223Autonomous detection of cryospheric change with hyperion on-board earth observing-1,\224 Remote Sensing of Environment  vol 101 pp 447\226462 2006  R Castano D Mazzoni N T ang and T  Dogget 223Learning classi\002ers for science event detection in remote sensing imagery,\224 in Proceedings of the ISAIRAS 2005 Conference  2005  S Shif fman 223Cloud detection from satellite imagery A comparison of expert-generated and autmatically-generated decision trees.\224 ti.arc.nasa.gov/m/pub/917/0917 Shiffman  M Griggin H Burk e D Mandl and J Miller  223Cloud cover detection algorithm for eo-1 hyperion imagery,\224 Geoscience and Remote Sensing Symposium 2003 IGARSS 03 Proceedings 2003 IEEE International  vol 1 pp 86\22689 July 2003  V  V apnik Advances in Kernel Methods Support Vector Learning  MIT Press 1999  C Bur ges 223 A tutorial on support v ector machines for pattern recognition,\224 Data Mining and Knowledge Discovery  vol 2 pp 121\226167 1998  M Klemish 223F ast lossless compression of multispectral imagery internal jpl document,\224 October 2007  F  Rizzo 223Lo w-comple xity lossless compression of h yperspectral imagery via linear prediction,\224 p 2 IEEE Signal Processing Letters IEEE 2005  R Roosta 223Nasa jpl Nasa electronic parts and packaging program.\224 http://nepp.nasa.gov/docuploads/3C8F70A32452-4336-B70CDF1C1B08F805/JPL%20RadTolerant%20FPGAs%20for%20Space%20Applications.pdf December 2004  I Xilinx 223Xilinx  Radiation-hardened virtex-4 qpro-v family overview.\224 http://www.xilinx.com/support/documentation data sheets/ds653.pdf March 2008  G S F  Center  223Tdrss o v ervie w  224 http://msp.gsfc.nasa.gov/tdrss/oview.html 7  H Hemmati 07 2008 Information e xchanged during meeting about LaserComm  223W orldvie w-1 224 http://www digitalglobe.com/inde x.php 86/WorldView-1 2008  223Sv albard ground station nor way.\224 http://www.aerospacetechnology.com/projects/svalbard 7 2008  223Satellite tracking ground station 224 http://www.asf.alaska.edu/stgs 2008  R Flaherty  223Sn/gn systems o v ervie w  224 tech rep Goddard Space Flight Center NASA 7 2002  223Geoe ye-1 f act sheet 224 http://launch.geoeye.com/launchsite/about/fact sheet.aspx 2008  L-3 Communications/Cincinnati Electronics Space Electronics 7500 Innovation Way Mason OH 45040 T-720 Transmitter  5 2007 PDF Spec Sheet for the T720 Ku-Band TDRSS Transmitter  L-3 Communications/Cincinnati Electronics Space Electronics 7500 Innovation Way Mason OH 45040 T-722 X-Band  7 2007 PDF Spec Sheet for the T-722  J Smith 07 2008 Information e xchanged during meeting about GDS  J Carpena-Nunez L Graham C Hartzell D Racek T Tao and C Taylor 223End-to-end data system design for hyspiri mission.\224 Jet Propulsion Laboratory Education Of\002ce 2008  J Behnk e T  W atts B K obler  D Lo we S F ox and R Meyer 223Eosdis petabyte archives Tenth anniversary,\224 Mass Storage Systems and Technologies 2005 Proceedings 22nd IEEE  13th NASA Goddard Conference on  pp 81\22693 April 2005 19 


 M Esf andiari H Ramapriyan J Behnk e and E So\002nowski 223Evolving a ten year old data system,\224 Space Mission Challenges for Information Technology 2006 SMC-IT 2006 Second IEEE International Conference on  pp 8 pp.\226 July 2006  S Marle y  M Moore and B Clark 223Building costeffective remote data storage capabilities for nasa's eosdis,\224 Mass Storage Systems and Technologies 2003 MSST 2003 Proceedings 20th IEEE/11th NASA Goddard Conference on  pp 28\22639 April 2003  223Earth science data and information system esdis project.\224 http://esdis.eosdis.nasa.gov/index.html  M Esf andiari H Ramapriyan J Behnk e and E So\002nowski 223Evolution of the earth observing system eos data and information system eosdis\\224 Geoscience and Remote Sensing Symposium 2006 IGARSS 2006 IEEE International Conference on  pp 309\226312 31 2006Aug 4 2006  223Earth science mission operations esmo 224 http://eos.gsfc.nasa.gov/esmo  E Masuoka and M T eague 223Science in v estig ator led global processing for the modis instrument,\224 Geoscience and Remote Sensing Symposium 2001 IGARSS 01 IEEE 2001 International  vol 1 pp 384\226386 vol.1 2001  M Esf andiari H Ramapriyan J Behnk e and E So\002nowski 223Earth observing system eos data and information system eosdis 227 evolution update and future,\224 Geoscience and Remote Sensing Symposium 2007 IGARSS 2007 IEEE International  pp 4005\2264008 July 2007  D McAdam 223The e v olving role of tape in the data center,\224 The Clipper Group Explorer  December 2006  223Sun microsystems announces w orld s 002rst one terabyte tape storage drive.\224 http://www.sun.com/aboutsun/pr/200807/sun\003ash.20080714.2.xml July 2008  223P anasas 227 welcome 224 http://www panasas.com  R Domikis J Douglas and L Bisson 223Impacts of data format variability on environmental visual analysis systems.\224 http://ams.confex.com/ams/pdfpapers/119728.pdf  223Wh y did nasa choose hdf-eos as the format for data products from the earth observing system eos instruments?.\224 http://hdfeos.net/reference/Info docs/SESDA docs/NASA chooses HDFEOS.php July 2001  R E Ullman 223Status and plans for hdfeos nasa's format for eos standard products.\224 http://www.hdfeos.net/hdfeos status HDFEOSStatus.htm July 2001  223Hdf esdis project.\224 http://hdf.ncsa.uiuc.edu/projects/esdis/index.html August 2007  223W elcome to the ogc website 224 http://www.opengeospatial.org 2008  223Open gis Gis lounge geographic information systems.\224 http://gislounge.com/open-gis Christine M Hartzell received her B.S in Aerospace Engineering for Georgia Institute of Technology with Highest Honors in 2008 She is currently a PhD student at the University of Colorado at Boulder where she is researching the impact of solar radiation pressure on the dynamics of dust around asteroids She has spent two summers working at JPL on the data handling system for the HyspIRI mission with particular emphasis on the cloud detection algorithm development and instrument design Jennifer Carpena-Nunez received her B.S in physics in 2008 from the University of Puerto Rico where she is currently a PhD student in Chemical Physics Her research involves 002eld emission studies of nanostructures and she is currently developing a 002eld emission setup for further studies on nano\002eld emitters The summer of 2008 she worked at JPL on the HyspIRI mission There she was responsible for the science analysis of the data handling system speci\002cally de\002ning the data level and processing and determining potential mission collaborations Lindley C Graham is currently a junior at the Massachusetts Institute of Technology where she is working towards a B.S in Aerospace Engineering She spent last summer working at JPL on the data handling system for the HyspIRI mission focusing on developing a data storage and distribution strategy 20 


David M Racek is a senior working toward a B.S in Computer Engineering at Montana State University He works in the Montana State Space Science and Engineering Laboratory where he specializes in particle detector instruments and circuits He spent last summer working at JPL on compression algorithms for the HyspIRI mission Tony S Tao is currently a junior honor student at the Pennsylvania State University working towards a B.S in Aerospace Engineering and a Space Systems Engineering Certi\002cation Tony works in the PSU Student Space Programs Laboratory as the project manager of the OSIRIS Cube Satellite and as a systems engineer on the NittanySat nanosatellite both of which aim to study the ionosphere During his work at JPL in the summer of 2008 Tony worked on the communication and broadcast system of the HyspIRI satellite as well as a prototype Google Earth module for science product distribution Christianna E Taylor received her B.S from Boston University in 2005 and her M.S at Georgia Institute of Technology in 2008 She is currently pursing her PhD at the Georgia Institute of Technology and plans to pursue her MBA and Public Policy Certi\002cate in the near future She worked on the ground station selection for the HyspIRI mission during the summer of 2008 and looks forward to working at JPL in the coming year as a NASA GSRP fellow Hannah R Goldberg received her M.S.E.E and B.S.E from the Department of Electrical Engineering and Computer Science at the University of Michigan in 2004 and 2003 respectively She has been employed at the Jet Propulsion Laboratory California Institute of Technology since 2004 as a member of the technical staff in the Precision Motion Control and Celestial Sensors group Her research interests include the development of nano-class spacecraft and microsystems Charles D Norton is a Principal Member of Technical Staff at the Jet Propulsion Laboratory California Institute of Technology He received his Ph.D in Computer Science from Rensselaer and his B.S.E in Electrical Engineering and Computer Science from Princeton University Prior to joining JPL he was a National Research Council resident scientist His work covers advanced scienti\002c software for Earth and space science modeling with an emphasis on high performance computing and 002nite element adaptive methods Additionally he is leading efforts in development of smart payload instrument concepts He has given 32 national and international keynote/invited talks published in numerous journals conference proceedings and book chapters He is a member of the editorial board of the journal Scienti\002c Programming the IEEE Technical Committee on Scalable Computing a Senior Member of IEEE recipient of the JPL Lew Allen Award and a NASA Exceptional Service Medal 21 


this paper, we only generate the size-2 patterns in the BFS phase. It will be interesting to investigate the impact on the performance if the ?rst phase is stopped at a deeper level Also, the projection is a very ef?cient method for ?nding patterns, especially for parallel implementation of pattern mining algorithms [1]. We plan to adapt the projection ideas into our algorithm and design an ef?cient parallel algorithm for mining maximal hyperclique patterns References 1] R. Agarwal, C. Aggarwal, and V. Prasad. A Tree Projection Algorithm For Generation of Frequent Itemsets. pages 350 371, Feb 2001 2] R. Agrawal, T. Imielinski, and A. Swami. Mining Association Rules between Sets of Items in Large Databases. In Proc. of the ACM SIGMOD Conference on Management of Data, pages 207216,May 1993 3] R. Agrawal and R. Srikant. Fast Algorithms for Mining Association Rules. In Proc. of the 20th Intl Conference on Very LargeData Bases, 1994 4] R. Bayardo. Ef?ciently mining long patterns from databases In Proc. of the ACM SIGMOD Conference, 1998 5] R. Bayardo and R. Agrawal. Mining the Most Interesting Rules. In Proc. of the ACM SIGKDD Conference, 1999 6] D. Burdick, M. Calimlim, and J. Gehrke. Ma?a: AMaximal Frequent Itemset Algorithm for Transactional Databases. In Proc. of IEEE Conf. on Data Engineering, 2001 7] Y. Huang, H. Xiong, W. Wu, and Z. Zhang. A Hybrid Approach for Mining Maximal Hyperclique Patterns. In In Technical Report UTDCS-34-04, Department of computer science, University of Texas - Dallas, 2004 8] J.Han, J.Pei, and Y. Yin. Mining Frequent Patterns without Candidate Generation. In Proc. of the ACM SIGMOD International Conference on Management of Data, 2000 9] M.J.Zaki and C.Hsiao. ChARM: An ef?cient algorithm for closed itemset mining. In Proc. of 2nd SIAM International Conference on Data Mining, 2002 10] R.Rymon. Search through Systematic Set Enumeration. In Proc. Third Intl Conference on Principles of Knowledge Representation and Reasoning, 1992 11] H. Xiong, M. Steinbach, P.-N. Tan, and V. Kumar. HICAP: Hierarchial Clustering with Pattern Preservation. In Proc. of 2004 SIAM International Conference on Data Mining \(SDM 12] H. Xiong, P.-N. Tan, and V. Kumar. Mining Strong Af?nity Association Patterns in Data Set with Skewed Support. In Proc. of the Third IEEE International Conference on Data Mining \(ICDM Proceedings of the 16th IEEE International Conference on Tools with Artificial Intelligence \(ICTAI 2004 1082-3409/04 $20.00  2004 IEEE 





