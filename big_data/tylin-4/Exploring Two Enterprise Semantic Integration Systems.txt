Exploring Two Enterprise Semantic Integration Systems  Mark Ginsburg   Alex Kass   Peter Z. Yeh Accenture Technology Labs Accenture Technology Labs Accenture Technology Labs Mark.Ginsburg@Accenture.com Alex.Kass@Accenture.com Peter.Z.Yeh@Accenture.com   Abstract  An Enterprise Semantic Integration System \(ESIS provides cross-domain and cross-department insights 
by normalizing and merging structured, semistructured, and unstructured data sources from both internal and external source, into a knowledge model that can then be visualized in an integrated portal The interface of an ESIS shows data, metadata, and semantic connections. Search and analysis tool and integration points to other enterprise systems can be made available to the knowledge worker in the ESIS In this paper, we first present an overview of the complex task of data aggregation, cleansing, and import into a knowledge model. We go on to explore 
two major types of ESIS: a market or competitive intelligence system, with illustrative examples Corporate Radar and Business Event Advisor, and a knowledge management system, the Knowledge Discovery Capability.  Each of these case studies provides interesting insights into the challenges involved in the design and deployment of an ESIS  1. Introduction  Semantic integration involves a challenging array of data manipulation tasks.  The motivation for the effort is sense making in the context of heterogeneous data sources [1  T o ge t a b i r d 
s eye view that synthesizes various sources is a strategic goal that can be only met with the assistance of semantic integration h en this is done successfully, knowledge workers can access a cross-silo model in a visual interface to review established insight or synthesize new insight. Ideally, this translates into actionable intelligence insight immediately useful in garnering business intelligence, decision making and/or 
constructing a work product To achieve this integration, a knowledge model is formulated, and then populated from existing data sources.  This is challenging for a number of reasons: First of all, the data being integrating will typically differ in format, data quality, security access, retrieval methods, numerical units, language, and more. When data sources are pre-conditioned and merged, they must be deconflicted, validated, and tagged to accurately represent their relationships inside a knowledge 
model.  Enterprise knowledge architects face the additional challenge of handling and codifying both external and internal data sources so that they coexist and can be accessed in a common framework Internal silos have their own security access model specialized vocabulary and idiosyncratic access and retrieval. The same is true of important heterogeneous external data While the need for this kind of integration has been widely recognized, there has thus far been too little work done establishing common frameworks 
and application classes to support this kind of integration.  In this paper, we first describe and define key requirements for Enterprise Semantic Integration Systems \(ESIS\, and describe the general steps in their deployment. We then present two case studies, corporate radars, and the Knowledge Discovery Capability. Each case provides interesting insights into the advantages and challenges involved in the design and deployment of an ESIS  2. Enabling the Enterprise Semantic 
Integration System \(ESIS     Figure 1 ESIS Up To the Creation of the Enterprise Ontology The first stage in enabling an ESIS is to construct Proceedings of the 42nd Hawaii International Conference on System Sciences - 2009 1 978-0-7695-3450-3/09 $25.00  2009 IEEE 
 


and load the knowledge model that represents the first pass at the enterprise ontology. This involves several discrete steps as shown in Figure 1  As shown in Figure 1, the ESIS may wish to access external data sources. If this is the case, the external data sources are marshalled and brought across the enterprise firewall \(or, alternatively mediator systems are built to read external data and shape it for subsequent processing using data wrappers   Similarly, internal enterprise data sources may be marshalled or handled with mediators. Data \(both textual and numeric\ then cleansed and normalized in the step labelled Pre-Conditioning  Text analytics tools may be employed to extract named entities from semi-structured document data and controlled vocabularies gleaned. At this stage automated relationship extractor tools may then be run to deduce associations between named entities These pre-processing steps aim to reduce the manual effort necessary in constructing the initial controlled vocabulary, relationships between named entities and knowledge model by the Knowledge Architect KA  A related approach to increase the semantic useability of documents is to add logical links between text documents and relevant structured data     3. Mandatory, Recommended, and Optional Features of the ESIS   Now that the knowledge model exists, and is loaded with initial data, what features do we expect in the user interface? We need facilities to access and retrieve the normalized, heterogeneous data However, a great many other features are possible and perhaps highly desirable depending on the business domain. Let us review some of these possible features  3.1. Internal Knowledge Model Inconsistencies and Conflict Resolution  It is often the case that the processing of numerous data sources will come across a situation where two or more incompatible assertions are being made regarding a given Named Entity. How do we know which assertion to load into the knowledge base This is where Conflict Resolution features come in handy. The set of incompatible assertions are forwarded to an arbiter for manual action, for example in an administrative section of the knowledge vendor s user interface.  Or, there may be semi-automated cleanup by comparing the set of problematic assertions to a core set of axiomatic assertions. A related effort, as described by Noy the reconciliation of previously built ontologies into a unified knowledge model. They may use, for example the same linguistic term to describe different concepts  d th u s requ ire cleanu p  before import. It is beneficial to store the discarded assertions, including metadata such as source, date and author, for audit and rollback.   One can imagine this facility to be very useful when attempting to reconcile multiple semantic models inside the same enterprise   3.2. Uncertainty and Lineage  One feature that is certainly useful is the representation of the uncertainty of an assumption; in other words, the confidence one has in making the assertion.. In addition, the system when it automatically fetches associations, can assign less confidence to an implied association than a direct one. This is useful in applications \(for example crimonology\where observations are stated as the car may have been red, but it was dark The confidence can either be built after fetching raw data from the underlying data stores, or built directly into the data model as demonstrated by the TRIO system 8 Another appreciated feature is a lineage engine  the explication of relationships displayed on demand in language accessible to the user the closer to natural language, the better. The easier it is for the user to read and understand the system s explication for an assertion, the better  3.3 Workspaces and Collaboration  Another handy feature is the ability to store common queries in the personal workspace for re-use  shoeboxing members can share personal updates and arrive at consensus updates Collaboration mechanisms can be synchronous \(for example, instant messaging facilities\or asynchronous \(for examples, wikis, e-mails, bulletin boards\  The question then becomes, how to arrive at consensus and where do we position authority This is discussed in the next section        Proceedings of the 42nd Hawaii International Conference on System Sciences - 2009 2 
 


3.4. Scoped Knowledge Models  Dividing the knowledge model into onion layers  has advantages. Consider the Core Knowledge Model CKM\sertions that are axiomatic in nature. These givens form the backbone of the user s view in the ESIS UI. The user also sees here a Domain Knowledge Model \(DKM enterprise-level assertions that the user may want to change.  Changes are reflected in the personal workspace and are labeled as Personal Knowledge Model \(PKM Scoped knowledge models are very useful when the user is banded into a workgroup \(that often crosses intra-organizational boundaries d is s o lv i n g a  joint task. For example, a team of intelligence analyst may be given a set of facts and they work individually on the fact set, communicating interim progress in a collaboration workspace \(CW\. Thus changes made to each PKM should be reflected in the CW at the moment of PKM publication  Conflicting PKM s can be resolved, as discussed in Section 3.1,, by consensus mechanisms or by thirdparty arbitration, such as a knowledge librarian  PKMs can take the form of entirely new assertions new named entities new relationships between existing named entities\r the dispute of an existing assertion in the DKM \(named entity or relationship The CKM should only be revised rarely by its nature.  The work product of a collaborative semantic exploration in this case would be an intelligence report summing up interesting relationships discovered, and potentially making recommendations on the basis of the discoveries These work products can in turn be routed to the higher level arbitrator for potential further update to the EKM  3.5. Convenient Extensions: Geospatial and Timeline Many business problems can benefit from integration of the ESIS to common extension platforms. One of these is a geospatial representation We will see more of this in our discussion of KDC in Section 6. The ESIS, in it s preconditioning step, can extract latitudes and longitudes via, e.g. MetaCarta and feed them into a geospatial visualizer such as Google Earth or Microsoft Virtual Earth. One example of a powerful semantic geospatial setting is the visualization of large-scale environmental models 10 Another convenient ESIS extension is timeline visualization. A slider bar in the interface provides the user with a way to go forward and back in time to replay sequences of events of interest. Appendix 1 contains Table 1 that presents a sample list of essential, recommended, and optional features of an ESIS  4. How the ESIS Is Used  Turning to the question of ESIS use - one or more knowledge workers will interface with the visual representation of the knowledge model to perform inquiries, or gain additional insight \(knowledge synthesis\. These steps may have a collaborative workgroup component. The basic components are shown in Figure 2  Figure 2 Using the ESIS  The steps shown in Figure 1 occupy the top left of Figure 2. These steps lead to the creation of the initial knowledge model which is used by the ESIS to display the welcome page UI to the knowledge worker \(labeled KW in the figure\learly, some of the functions in Figure 2 such as Inquiry are mandatory in an ESIS and some are optional, such as Workgroup Alert mechanisms when a new contribution or synthesis of interest occurs. In the center bottom of Figure 2 we have the scoped Proceedings of the 42nd Hawaii International Conference on System Sciences - 2009 3 
 


knowledge models discussed previously in Section 3.4. It is critical to insulate pre-vetted material and to establish vetting mechanisms before the putative new material percolates upward into the group view 4.1. Organization of the Rest of the Paper  In the remainder of this paper  we will discuss two ESIS case studies: i\nterprise Corporate Radars including Business Event Advisor and Technology Investment Radar, and ii\owledge Discovery Capability. This will help illustrate how broad this class of applications is in terms of end-user functionality and purpose as well as the complexity in data handling and representation 5. Two ESIS Case studies 5.1. Enterprise Corporate Radars  A better-informed decision-maker is obviously better positioned to make good decisions.  For example, a decision-maker running a business will make better decisions if he/she is more informed about what is going on in and around the business Furthermore, information about what is happening outside the enterprise plays an important role in informing good decisions. Accessing this external data, should be where the Web is used to inform decision-makers. After all, the Web has dramatically  increased the amount of information about the business environment that can be accessed on demand. The Web, for example, has information about the activities of players upstream in the extended supply chain and downstream in the distribution network. It also has information about what is going on with customers, competitors regulators, complementary products, relevant technologies, and so forth. These information resources, however, come in disparate forms, are often unstructured, and are often inconsistent in their coverage.  Addressing this problem requires systems that can automatically mine the Web to detect business-relevant events; to normalize the descriptions of these events \(which will include both structured and unstructured source material\nto a standardized representation that are independent of the original source \(which includes the event types participants, and so forth\; and to map those standardized, normalized event descriptions to a model of the business dynamics in which the decision-maker s organization operates to generate actionable insights.  This mapping serves to resolve  or at least surface inconsistencies and to make the business-relevant relationships between events explicit  Figure 3. A schematic of the Enterprise Corporate Radar technology platform  These systems which we call enterprise corporate radars  can be built on the platform defined in w h ich con s i s ts of th ree co m pon e n ts see Figure 3 models, reasoners, and web-sensors Models provide semantic representations of events and entities that are relevant to decisionmakers and their organization \(i.e. the business dynamics\hese models, for example, can include representations of entities like the manufacturers, the products they make, their suppliers, their customers etc., and can include representations of events like deployments, mergers and acquisitions, price changes, etc. Models are used by the reasoner to guide the detection of relevant events from the Web and to interpret their implications The reasoner generates actionable insights from detected external events by applying the implications associated with the corresponding event representations in the business dynamics models. The reasoner also determines the appropriate web sensors to invoke \(and hence what events to detect from the Web\based on what events are encoded in the models Web-sensors detect relevant unstructured signals on the Web and produce from them structured event descriptions that are consumed by the reasoner to generate actionable insights. The implementation of the sensors depend on the corporate radar being built but they all require some form of natural language processing as most information on the Web are in the form of unstructured text We have used this platform to build corporate radars like the Business Event Adviso d  the Technology Investment Radar [1 des c ribed  below 5.1.1. Business Event Advisor  Proceedings of the 42nd Hawaii International Conference on System Sciences - 2009 4 
 


Many corporate executives would like a more systematic way of monitoring the external environment in which their company operates. They seek a way to spot the external business/economic events that might constitute threats to and opportunities for their business. For example, there would be important business value for executives who could more consistently notice signs that a competitor might introduce a new product to directly compete with one of their products, or that a supplier was at risk of failing to deliver. Everything from a competitor s online job-recruiting advertisements to announcements of deals made, contracts won, real estate purchased, changes in the price of raw materials, and so forth are examples of the types of information that if systematically tracked and interpreted in terms of the business dynamics that govern the executive s business can be used to provide these early warning signals. This in turn can help executives respond quickly The Business Event Advisor is designed to address these needs by detecting, organizing, and interpreting a broad range of external business events in order to help business decision-makers spot external threats and opportunities affecting their business. The Business Event Advisor achieves this capability using a model of the business dynamics in which a business operates. The specific representations encoded depend on the company and industry that the model \(and hence the system customized for. Obviously the richer the model, the better the system can perform, but even with a simple model the system can still provide valuable insight through targeted text processing and simple inferences. For example, a simple model encoding the products a company makes, its competitors, and their suppliers can enable the system to infer that a new-product introduction by a competitor's supplier may change the demand for products made by the company. It can infer this possibility even if it does not recognize the new product being reported it just needs to recognize the supplier and the product introduction event The Business Event Advisor uses this model to continuously scan many relevant sources of news and information on the Web to generate an executive dashboard like the one detailed in Figure 4. This dashboard makes it possible to see systematically what is happening in the external business environment by reporting the types of events detected, the entities involved in these events, the estimated importance of each event, and whether an event was directly detected from a news source or predicted from one that was   Figure 4. A portion of the executive dashboard produced by the Business Event Advisor  Once the system has produced the normalized event descriptions, it then uses those descriptions to populate a graphical interface which facilitates the access and retrieval of various facets of the user s competitive situation. The system also allows the user to drill down on any event to see the raw signals from which the event was detected and the implications that could be inferred from it.  The design thus provides lineage information relating implications back to explicitly-detected events Figure 5 details this feature for a product introduction event that the system has detected. This event was detected from a story about Denso introducing new hybrid vehicle components and suggests to corporate executives the possible threats \(e.g competitors can change features to their products d opportunities e.g the executive s company can expand its product line at might impact their company 5.1.2. Technology Investment Radar  Decision-makers often recognize early on the potential for a technology to have an important impact on their business, but have difficulty determining when this potential will be realized. For example, many executives in the mobile phone industry recognize WiMax as a technology that may have a very significant impact on their industry, but they are less certain about whether \(and when\at impact will be realized. Some technologies that look promising in the lab never make it to market       Proceedings of the 42nd Hawaii International Conference on System Sciences - 2009 5 
 


  Figure 5. A drilled down view of an event detected by the Business Event Advisor  Some that go to market become niche products which never deliver on the impact they promised originally, and some that do deliver on their promise do so on a different time-line than one might have imagined when the technology first began to emerge. In order to manage their company effectively, executives need to continuously track technologies to determine when various levels of investment are worthwhile e.g. when to invest in building up in-house expertise on the technology when to start designing and offering products based on the technology; etc The Technology Investment Radar is designed to address these needs by helping decision-makers track the maturation of technologies that relate to their business and understand when these technologies are mature enough to justify investing in them. The Technology Investment Radar achieves this capability by using a model of the business dynamics surrounding the technology being tracked \(like the Business Event Advisor\d a model of the technology maturation lifecycle. The lifecycle model consists of the following six stages that a technology can advance through as it matures:  1 Pre-market stage: Research is still being conducted on the technology.  2. Potential market stage: Companies are beginning to conduct trials and demos of the technology. 3. Emerging market stage: A company has sold or deployed the technology.  4. Growing market stage: Many companies have sold or deployed the technology.  5. Mature market stage: The market has solidified with a few major players remaining. 6 Declining market stage: Companies are beginning to leave the market Associated with each stage are a set of gates \(i.e metrics\hat must be met in order for a technology to enter into that stage. These gates encode how the entities \(e.g. manufacturers, suppliers, etc.\nd events \(e.g. sales, deployments, etc.\rom the business dynamics model determine a technology s placement in the maturation lifecycle. For example some user s company may require that there be at least five sales \(or deployments\ of the technology in order for that technology to be considered as being in the emerging stage. This is an example of a gate Using a set of standardized stages and gates offers a normalized view of the unstructured and disparate information detected by the system  Figure 6. The executive dashboard produced by the Technology Investment Radar  Like the Business Event Advisor, the Technology Investment Radar uses its models to continuously scan a variety of sources e.g. RSS feeds, blogs public forums, standards sites, etc to produce a dashboard. Its dashboard is detailed in Figure 6 which shows where each technology, that is being tracked, has gotten to in the maturation lifecycle The system also allows the user to drill down into any stage to examine the gates for that stage, and how close the gates are to being satisfied. This design similar to that of the Business Event Advisor facilitates the access and retrieval of various facets of the information collected. Figure 7 shows the gates for the emerging market stage and which of these gates are satisfied for WiMax   Proceedings of the 42nd Hawaii International Conference on System Sciences - 2009 6 
 


Figure 7. A drilled down view of the emerging stage in the Technology Investment Radar  The user can further drill down on any gate to view the events that have been detected which support the gate The Technology Investment Radar was evaluated through a pilot with Accenture s Wireless Community of Practice \(CoP an organization within Accenture that focuses on wireless technology consulting. Nine analysts from the Wireless CoP used the Technology Investment Radar over a 6 week period to track the maturity of various wireless technologies like WiMax, WiFi, etc. At the end of this period, we conducted an exit survey designed to help us assess the utility of the tool from the end user s perspective \(e.g. will the analysts continue to use the system after the pilot, how satisfied are the analysts with the tool, and so forth The survey was completely anonymous. It was hosted on a third party survey hosting site where the identities of the respondents were not known to us Hence, the respondents were not under any pressure to respond favorably The survey consisted of 25 questions, but given the limitation in space, we will not present responses from all these questions. Instead, we give an overview of highlights from the survey   When asked to indicate their overall satisfaction with the system the possible answer choices are very satisfied, somewhat satisfied, neutral somewhat dissatisfied, and very dissatisfied 6 of the analysts said very satisfied, 2 said somewhat satisfied, and 1 said neutral. No analysts gave a somewhat dissatisfied or very dissatisfied response   When asked to indicate if they will continue to use the system after the pilot study the possible answer choices are yes and no 8 of the analysts said yes and 1 said no   When asked to indicate if they would recommend the system to a colleague the possible answer choices are yes and no 8 of the analysts said yes and 1 said no   When asked to indicate how using the Technology Investment Radar to track technology maturation compared to their current method the possible answer choices are much better, somewhat better, about the same somewhat worse, and much worse 2 of the analysts said much better, 6 said somewhat better, and 1 said somewhat worse. No analysts gave a much worse or about the same response  These responses show that the majority of the analysts found the Technology Investment Radar to be useful and will continue to use the system after the pilot, demonstrating the practical value of the tool 5.2. Knowledge Discovery Capability  The Knowledge Discovery Capability \(KDC synthesis of a set of commercial off the shelf \(COTS applications and custom integration code that extracts, transforms, indexes, integrates and manages information and knowledge derived from a wide variety of sources; structured/unstructured, and internal/external to the organization.  This content is organised around a knowledge model which incorporates the lexicons and ontologies of interest KDC organizes vast collections of data so that any given concept can be a focal point, while related data remains visible providing context to the focal concept. Multiple views \(classifications supported in the end-user session depending on role activity and privileges. The system displays large amounts of data and their interconnections simultaneously.  KDC is able to surface inferred relationships by hopping across multiple sources facilitating knowledge workers in uncovering hidden relationships The knowledge model provides a framework to capture annotations and to share them within a team or with the wider organization.  Associations between researchers and concepts can be used to identify social networks and subject matter experts, so that knowledge workers can better leverage the organization s tacit knowledge KDC uses workflow orchestration and routing System maintenance uses workflow orchestration to sequence the events in the fetching, pre-processing and cleanup, and subsequent load of data into the knowledge model which is effectively a set of ontologies and taxonomic classifiers.  Routing is used to notify the right personnel when discrete events occur.  For example, end-user alerting based on content changes, or communication of system Proceedings of the 42nd Hawaii International Conference on System Sciences - 2009 7 
 


generated flags where data load yields conflicting assertions.  Routing can take place via synchronous or asynchronous messaging, using existing enterprise communication mechanisms Maintenance is accomplished via a GUI client.  A user with administrative privileges uses a GUI tool to modify the knowledge model or the business rules associated with filtering and end-user GUI display In addition, end-users with sufficient permission can modify their local view of the knowledge model Depending on business need, local changes can be propagated to the workgroup level for vetting and, if approved, subsequent publication to the group Visualization of the ontology model is via an administrative GUI console. In this console, the administrator can view, edit, or delete ontology entries Since the KDC solution uses standard relational databases, we serialize RDF triples as notated in XML syntax to standard database table storage There are special structural triples to describe the ontologies including system-information version numbers for administrative use kept in our system Each ontology can have its own sequence of version numbers, effective dates, and termination dates i.e. timeboxing each ontology Some visual examples will be useful to see its operation. We discuss a KDC pharmacology research data that culled from structured \(citation and unstructured \(full article text\ources. As Figure 8 shows, named entities and their relationships are presented in the patented user interface   Figure 8.    The Knowledge Discovery Capability Avian Flu Demonstration   On the right, named entities \(in this case Avian Flu case numbers\ are linked to other categories of interest via connector lines. A mouse hover event on a certain entity brings up the metadata for that entity On the left is a project explorer and below that, a Search Results window. The power of the patented interface rests in the user s ability to double-click on an entity, focus that in the center pane, and quickly redraw the connections. Thus, previously unknown commonalities may be discovered during this activity. To load this demonstration, unstructured documents were parsed and named entities were placed into the appropriate category \(HumanCase reportSource, ContractedFrom, and so on\By rightclicking, Figure 8 shows a pop-up box.  The user may elect to View Document Source integrating to an enterprise document management system As mentioned in Section 3.5., certain business domains are good candidates for geospatial integration. A medical epidemiology demo such as this one qualifies. The flow of cases can be visualized on the US/Mexico border; in this case using Microsoft Virtual Earth as shown in Figure 9 Similar work has been done implementing KDC instances with another geospatial vendor, Google Earth  Figure 9.  Geospatial Integration Showing Possible Mexico/USA Avian Flu Routes   KDC also allows the user to contribute new named entities and classify them. By viewing document source, the user is able to highlight a phrase, select the link type, confidence level related entity, and overall category and then submit the entry. In any contribution mechanism, the effort opportunity cost\must be low enough that the user s input has sufficient marginal utility KDC is not meant to bring the knowledge worker to a hard and fast decision point. Rather, the user can surf relationships, discovering previously unknown connections. This is especially valuable in large knowledge spaces. The system has discovered Proceedings of the 42nd Hawaii International Conference on System Sciences - 2009 8 
 


novel linkages in pilot tests in the intelligence community but to date no user surveys of the style in Section 5.1.2 have been performed 6. Conclusion We have illustrated the steps that go into the initial load and display of an enterprise knowledge model. We have also talked about essential preferred, and optional features that might go into an ESIS depending on the problem at hand. As we have seen, the idea of collaboration is a powerful one that helps individual workers communicate as they inquire from and contribute to the knowledge base. In our discussion of the two case studies, Enterprise Radars and Knowledge Discovery Capability, we have an example of a Business Intelligence and a Knowledge Management approach that span a wide variety of high-level enterprise strategic needs Strategically, the costs of the initial build and ongoing maintenance must be weighed against the value to the enterprise. Integration points to existing enterprise applications and low-cost COTS components undoubtedly add to the value. Increased business intelligence, especially the variety that is not gleanable with conventional database or data warehouse technology, is another good argument for an ESIS being a value differentiator  7. References     Vin cent L a n d Bu rlat, P  2005   Ontology Urbanization for Semantic Integration Dealing with Semantics within Large and Dynamic Enterprises. Proc, 9 th IEEE International EDOC Enterprise Computing Conference \(EDOC 05   P.X., Yu Q., an d Ju n  L  2006 E IS I  Toward Enterprise Information Semantic Integration Proc, 2006 IEEE Asia-Pacific Conf. on Services Computing \(APSCC 06  alo w s k i M Am bi t e J  L  T h ak k a r, S Tuchinda, R., Knoblock, C., and Minton, S. \(2004 Retrieving and Semantically Integrating Heterogeneous Data from the Web. IEEE Intelligent Systems May/June, 72-79  ch old, M. an d G r u n i ng er, M. \(20 04  Ontologies and Semantics for Seamless Connectivity SIGMOD Record 33\(4\, 58-64  h a k arav art h y   V., G upta, H., R o y  P  an d Mohania, M. \(2006\ficiently Linking Text Documents with Relevant Structured Information VLDB 06, Seoul, Korea, 667-678. ACM    N. F  2004 e m a ntic I n teg r at ion   A Survey of Ontology-Based Approaches. SIGMOD Record, 33\(4\65-70  Pe j t ers e n  A  M. \(1998 S e m a n t i c i n f o r m at i on retrieval.  Communications of the ACM, 41\(4 92  j ellou n  O., Das Sar m a, A Ha y w ort h  C  an d  Widom, J. \(2006\n Introduction to ULDBs and the Trio System, IEEE Data Engineering Bulletin, March 2006  a k a I 199 4 dy n a m i c th eor y of organizational knowledge creation. Organization Science, 5\(1\37  ay D. S  199 9 S e m a n tic In te g r ation o f  Environmental Models for Application to Global Information Systems and Decision-Making SIGMOD Record, 28\(1\3-19   P F a ri n a D., an d Kas s  A  2007  Semantic Interpretation of the Web without the Semantic Web: Toward Business-Aware Web Processors. IEEE First International Conference on Semantic Computing \(ICSC 2007  s  A  an d C o w e l l S hah C  2006 s i n e s s  Event Advisor: Mining the Net for Business Insight with Semantic Models, Lightweight NLP, and Conceptual Inference. In KDD Workshop on Data Mining for Business Applications  a s s A  a n d C o w e l l S h a h C  2006 s i ng Lightweight NLP and Semantic Modeling to Realize the Internet s Potential as a Corporate Radar. AAAI Fall Symposium  ol i s H. \(1991  F r ee R i di ng v e r s us Cooperation. Chapter in Strategy and Choice, R Zeckhauser, Ed., MIT Press, Cambridge, MA   Proceedings of the 42nd Hawaii International Conference on System Sciences - 2009 9 
 


Appendix 1 Table 1 A Sample of ESIS Required, Recommended and Optional Features   ESIS Feature Grid Required Preferred Optional Comments Normalized Presentation of Heterogeneous Data Sources   Beyond the scope of a relational database system, the ESIS presents a wide spectrum of input data sources Access and Retrieval Mechanisms in the User Interface   Often a tricky requirement to fulfill, the ESIS must provide UI handles for the user to quickly and easily zoom around potentially vast stores of normalized information Maintenance and administration   Usually provided by an administrative console, the ESIS can be configured as to: source\(s\ of input data, preprocessing \(handling\ of same, presentation of same in UI Pre-conditioning  Both textual and numeric data require normalization and cleanup before a knowledge model load Support for both structured and unstructured data   Organizations have unstructured documents and structured database, spreadsheet\ata to consider  Conflict Detection and Resolution  When data is loaded into the knowledge model, conflicts should be flagged and referred to either an automated or a manual cleanup process. All conflict-related activities should be logged   Workgroup Support Collaboration and Alerts  Without this component, individual knowledge workers must communicate insights offline to their peers.  Alerts let group members know when new contributions or syntheses of interest have been made  Shoeboxing  The ability to save certain queries and/or certain data source subsets locally to assist in future work in the personal workspace  Contribution  The user s ability to contribute to the knowledge model in the UI \(add/edit/delete connections; add/edit/delete data components or metadata properties   GeoSpatial Often desirable is an integration point from ESIS to enterprise components such as geo-spatial visualization using e.g. MetaCarta tagged documents   Timeline To track events as they unfolded in a certain time window usually accomplished by a slider control in the UI    Workflow Component Business Logic to establish waypoints, triggers, and alerts to accomplish subtasks en route to the accomplishment of the larger task   Lineage ESIS explanation for how a particular connection was established between data items an explanatory rationale The more like natural language, the better    Uncertainty Modeling The ability to represent and/or toggle confidence levels when viewing connections   Contribution Merge and Deconfliction Ability of system to process and merge multiple sources of contribution and refer conflicts for manual or automated resolution   Vetting An administrative role to accept/edit/deny user s contribution to the knowledge model \(usually coupled with a workflow component that alerted the vetter that a contribution had been made Proceedings of the 42nd Hawaii International Conference on System Sciences - 2009 10 
 


several projects at NASA Glenn Research Center in Cleveland Ohio.  His career spans nearly twenty years involving the research implementation, and troubleshooting of network protocols and applications within satellite, mobile, and aeronautical environments pre></body></html 


common concern was compliance with the Healthcare Insurance Portability and Accountability Act \(HIPAA information privacy. Organizations were unsure whether DP products would be HIPAA compliant and even if the products themselves were secure whether their onboard information could be kept secure when the pens are small and easily lost  3.4.3. Implications for DP. Although there was substantial interest in DP technology among professional services and white collar organizations the ethnographic findings suggest that delivering appropriate value from DP technology would be difficult. The first barrier would be providing a platform that either conforms to or changes current behaviors around pen and paper: free availability of pens and unpatterned paper in the workplace behaviors of writing on environmental paper, and the need to keep up with a personal pen with one?s data The second barrier would be to meet expectations around text; much of the value was seen as being in retention and searching of textual information, but this would be made difficult by the frequent inclusion of acronyms, abbreviations symbols, and foreign languages. Many organizations saw value in centralized repositories that would manage DP information across many employees; this would require an IT infrastructure that was not available \(e.g., to manage the DP pattern space might be difficult and expensive to develop and maintain. It also poses questions about privacy, since employees might not wish the archive to retain personal information captured alongside work notes Finally, because we noted real or perceived barriers that were highly specific to various industries it appeared that DP solutions would be most likely to succeed if they were tailored to very specific settings Proceedings of the 42nd Hawaii International Conference on System Sciences - 2009 6 and use cases. This does not argue against DP usage and its value, but it suggests that delivering value to organizations may require substantially more design and development effort than a single general solution or platform would provide  4. Discussion  Our findings show that the interaction model of DP technology diverges substantially from common pen and paper usage. This divergence leads to unclear utility of DP for consumer note-taking purposes, and in a field trial, resulted in high abandonment rate of a consumer DP product. Among the most significant limitations were the low value seen in review of facsimile notes on a PC, the requirement with DP to use a special pen paired with patterned paper, and the low perceived value of capturing only notes taken on blank paper as opposed to handouts and other materials. In the enterprise space, the environmental issues were even more prominent due to the common infrastructure of freely available, communal pens and paper and the lack of IT infrastructure for DP document retention The note-taking research reported here suggests that writing behavior comprises many important areas besides capture, retention, and review of specific data. For instance, a single blank piece of paper or a one-word reminder may adequately serve as a reminder to do something that one intends, even though there may be little or no content as such Likewise, in interpersonal contexts such as attending 


Likewise, in interpersonal contexts such as attending a lecture, it may be socially desirable to take notes even if they are later simply disposed. Taking notes may also serve purposes of memory consolidation even when the content is never reviewed [8][9  4.1 DP and Writing Acts  Linguistic acts in social context have been described using a model of performative behavior commonly known as ?speech acts? theory [15 Chapman [2] extended that model to encompass writing, suggesting that many aspects of ?writing acts are unique and separate from spoken language.  In the extended model, writing acts may be described with a multidimensional taxonomy encompassing a writer?s context, aspects of the process, type of content, and linguistic features of the content Table 3 summarizes the dimensions of writing acts \(from [2 exemplify each dimension. For instance, ?separability denotes the extent to which items in a document are logically independent of one another; in a contract nothing is separable because the document is a single piece, while on a to-do list, many or all items may be independent of one another [2 DP technology may benefit from attention to the dimensions that are exemplified by writing acts embedded in social contexts. DP systems may be able to perform some kinds of writing acts quite well, but in other cases, DP may be inconvenient, unnecessary or inappropriate. Models such as the writing acts framework can be used both to understand user behavior broadly and systematically to explore the applicability of DP products across the general space of writing behavior A key problem for DP in note taking applications is that note taking can involve nearly every possible dimension of writing acts. Notes may be separable or not; they may serve as functional content or as contextual reminders; they may present just the facts? or be more interpretive; they may be transient or might be intended to be archival documents; and so forth. In short, notes are able to present a vast array of writing styles that pose substantially different value propositions and technological implications for DP products Delivering a general DP solution for note taking may therefore be expected to be difficult  Table 3: Dimensions of Writing Acts [2  Dimension Exemplars Separability a contract vs. a to-do list Function a typed inventory list vs calligraphy Emotionality a love letter vs. a packing slip Spatiality a transcript of speech vs. a diagram depicting concept relationships Associativity notes from class vs. doodling Linearity chronological notes vs. notes placed in a spatial ordering scheme Originality an essay vs. feedback on a manuscript Prescriptivity a signature vs. general notes Finality a document that will be archival vs. one that is a draft Structure a grocery list vs. concepts from a brainstorm Personality a letter to someone vs. a 


Personality a letter to someone vs. a journalistic essay Formality a business letter vs. a greeting card to a close friend  Proceedings of the 42nd Hawaii International Conference on System Sciences - 2009 7 For product development purposes, the writing acts framework can be used to ensure coverage of use cases by generating possible scenarios combining various attributes of written documents. These potential combinations may then be explored evaluated, and prioritized for research attention development effort, or testing  4.2 Possible Directions for DP Technology  4.2.1. Note taking. What would make DP technology more popular for note taking? Our research suggests that this is a complex question because there are numerous behavioral barriers. The largest single problem for DP may be that it is a closed system comprising a special pen and patterned paper and does not function with the wide array of writing utensils and paper products that people use especially for environmentally available pens, paper and documents. If this problem could be solved or mitigated through an expanded DP technology platform, DP would avoid the large behavioral block posed by the current need for users to change their existing pen and paper habits DP effectively focuses on notes as data neglecting many aspects of the embedded social nature and process function of notes. If DP notes were easily integrated into a wider range of behavioral processes, adoption should increase. For example, if notes could be automatically handled for content such as phone numbers, appointment times reminders, temporary content, and the like, then the DP platform would come closer to matching current pen and paper usage. However, in many cases, there is a separate and larger issue: computer technology today also is not integrated into such processes. To take a simple example, consider a written grocery list Even if the problem could be solved to recognize extract, and transfer the list to a PC, it would be of little use because, for most people, the PC itself is not integrated into the grocery shopping process. Much information of this kind is transient; there is no need to manage or retain it once the paper has been used An example of potentially closer workflow integration is shown in the recently released Livescribe Pulse Smartpen [11], which couples the Anoto DP platform with audio recording such that note takers can review the audio of a meeting or lecture at the exact point that a note was written. We believe that these kinds of additions to base DP functionality are likely to appeal to specific niches of users, but as more use cases like these are enabled over time, DP may successively attain value for larger numbers of users In our field trials and organizational visits, one of the most common customer expectations was that DP notes should be converted from handwriting to text; respondents commonly noted that PC data is of little use unless it is transcribed to text. To meet customer demands, a DP product will need to address this expectation: the DP must either deliver text recognition with very high accuracy, which is a difficult problem, or it should manage the expectation in some other way that preserves customer perception of value from PC integration 


of value from PC integration The high cost of DP products \(approximately US 100 for a pen, plus the need for specially patterned paper demonstrable additional benefit. Transferring notes from paper to a PC today merely involves typing Unless the need for automation is great and the DP function is nearly perfect, users may simply prefer to type or to carry paper rather than to change behavior to use expensive and less flexible technology  4.2.2. Structured input. As noted in the Introduction above, another use case for DP technology is structured input of information. In particular, DP technology may be useful for form-based input into database and workflow systems, where information is initially recorded on paper forms and then automatically transferred from the pen to a database application. Although the present research report is concerned primarily with note taking applications, in the course of our enterprise research we discussed potential applications for forms-based DP usage We noted possible use cases that fell into five general areas: \(1 easier input of information by customers, such as clients filling out deposit or withdrawal slips at a bank; \(2 information from paper to database without needing to rekey or type the information, such as factory inspection and quality assurance logs, traffic tickets shipping manifests, and so forth; \(3 environments that were not suitable for handheld computing devices, such as construction sites and some kinds of manufacturing facilities; \(4 in which paper-based records are desirable for either employee compliance or customer comfort, such as medical settings; and \(5 based records are necessary, e.g., for legal reasons but a DP product could support faster turnaround and error correction. An example of such application involved financial forms that undergo offsite optical character recognition; a DP system might allow immediate recognition and error correction We plan to report this line of research fully in the future. For now, we note that each of those areas has various benefits and potential limitations with regard to DP technology. Forms-based use cases are more precisely defined and structured than note taking, in Proceedings of the 42nd Hawaii International Conference on System Sciences - 2009 8 terms of environment, workflow, and content; the information context, form design, and potential for systems integration with rapid feedback may mitigate issues with handwriting recognition; and enterprise customers may be less price sensitive than consumers Thus, structured input appears to be a more promising near-future application of DP technology than note taking  4.3 Research Discussion  As we noted above, the present research was primarily behavioral and qualitative. Thus, despite the strength and consistency of our results across multiple samples, contexts, and locations, we present no specific metrics or tested hypotheses on user behavior with DP products. Our findings could be used to inform directional hypotheses for future depth or quantitative research. For instance, one might formulate and test hypotheses about cultural differences, interest levels in DP between various groups such as professional and non-professional 


office workers, market research metrics such as price sensitivity, and the like It is important to underscore the value of ethnographic fieldwork in the present research. It would be possible to conduct design research that explores how to make DP technology better, e.g., in terms of usability and function, without investigating exactly what people would do with such products and why. It was only when we investigated behavior in depth that we discovered the divergence of DP products? limited current value for note taking, as opposed to the high value that one might presume in the absence of depth research  5. Conclusion  In our research, initial trials of digital pens in a controlled setting \(Research Series 2 above suggested potentially good fit between digital pen functionality and consumer note taking needs However, when we explored real world behavior in note taking \(Research Series 1, 3, and 4 above found many potential barriers to adoption of digital pens for note taking. In particular, traditional pen and paper offer advantages in terms of cost, widespread and ad hoc availability, flexibility to work with multiple sources seamlessly, behavioral workflow integration, and manageability of content The value of using digital pens will increase if manufacturers are able to expand their platform technology progressively to enable broader coverage of behavioral scenarios and habits, focusing on the broad range of writing behaviors rather than just needs for facsimile replication on a computer Alternatively, digital pen technology may be more easily applied to tasks involving structured input rather than unstructured note taking We suggest that DP development efforts should use existing linguistic frameworks \(e.g., [2 the space of writing acts of interest. This should allow DP products to target behavioral needs in a more focused manner, leading to higher customer adoption  6. Acknowledgements  We thank many people who participated in this research: first and foremost, the numerous research participants, firms, and organizations who so generously shared their time and insights, but who must remain confidential; and many colleagues and research partners at Microsoft who collaborated on the technology investigation and research efforts especially Jeff Staiman, Vince Ball, Brian Williams Yoshiyuki Moriya, Stephen Cooper, Dave Shen Setsuko Arimatsu, Benjamin Babcock, Dennis Meinhardt, John Chiloyan, Glen Larsen, Mehrdad Basseri, Lori Birtley, Ken Hinckley, and Jian Wang  7. References  1] Anoto Group. Digital pen and paper. Web page http://www.anoto.com/?id=158, last retrieved May 28 2008  2] Chapman, C. N. Writing acts: taxonomy and technological implications. Paper presented at North American Computing and Philosophy \(CAP Corvallis, OR, August 2005  3] Despont-Gros, C., B?uf, C., Geissbuhler, A., and Lovis C. \(2005 


C. \(2005 Implementation and Use in an Existing Clinical Information System. In Connecting Medical Informatics and Bio-Informatics: Proceedings of MIE2005 - The XIXth International Congress of the European Federation for Medical Informatics, 328-333. IOS Press, 2005  4] Fetterman, D. M. Ethnography, 2nd ed. Thousand Oaks CA: Sage, 1997  5] Furukawa, N.  Ikeda, H.  Kato, Y.  Sako, H. D-Pen: a digital pen system for public and business enterprises. In Frontiers in Handwriting Recognition 2004: Proceedings of the Ninth International Workshop on Frontiers in Handwriting Recognition \(IWFHR-9 2004  6] Guimbreti  re, F. 2003. Paper augmented digital documents. In Proceedings of the 16th Annual ACM Symposium on User interface Software and Technology Proceedings of the 42nd Hawaii International Conference on System Sciences - 2009 9 UIST ?03 November 2003  7] Holman, D., Vertegaal, R., Altosaar, M., Troje, N., and Johns, D. 2005. Paper windows: interaction techniques for digital paper. In Proceedings of the SIGCHI Conference on Human Factors in Computing Systems \(CHI ?05 Portland, Oregon. New York: ACM, 2005  8] Kiewra, K., DuBois, N., Christian, D., McShane, A Meyerhoffer, M., &amp; Roskelley, D. Note-taking functions and techniques. Journal of Educational Psychology, 83 240-245, 1991  9] Kobayashi, K. Combined effects of note-taking/reviewing on learning and enhancements through interventions: a meta-analytic review. Educational Psychology, 26, 459-477, 2006  10] Liao, C., Guimbreti  re, F., and Hinckley, K. 2005 PapierCraft: a command system for interactive paper. In Proceedings of the 18th Annual ACM Symposium on User interface Software and Technology \(UIST ?05 Seattle, WA. New York: ACM, 2005  11] Livescribe. Pulse Smartpen [electronic device http://www.livescribe.com/, last retrieved May 28, 2008  12] Logitech. io2 Digital Pen [electronic device http://www.logitech.com/index.cfm/mice_pointers/digital_ pen/devices/408&amp;cl=us,en, last retrieved May 28, 2008  13] Norrie, M. C., Signer, B., and Weibel, N. Print-n-link weaving the paper web. In Proceedings of the 2006 ACM Symposium on Document Engineering \(DocEng '06 New York: ACM, 2006  14] Randall, D., Harper, R., and Rouncefield, M Fieldwork for Design: Theory and Practice. London Springer-Verlag, 2007  15] Searle, J. R. Speech Acts: An Essay in the Philosophy of Language. Cambridge: Cambridge Univ. Press, 1969  16] Sellen, A. J. and Harper, R. H. The Myth of the Paperless Office. Cambridge, MA: MIT Press, 2003  17] Signer, B. and Norrie, M. C. 2007. PaperPoint: a paper-based presentation and interactive paper prototyping 


paper-based presentation and interactive paper prototyping tool. In Proceedings of the 1st international Conference on Tangible and Embedded interaction \(TEI ?07 Baton Rouge, Louisiana. New York: ACM, 2007  18] Tanabe, K., Yoshihara, M., Kameya, H., Mori, S Omata, S., Ito, T., Automatic Signature Verification Based on the Dynamic Feature of Pressure. Proceedings of the Sixth International Conference on Document Analysis and Recognition \(ICDAR ?01 Computer Society, 2001   Proceedings of the 42nd Hawaii International Conference on System Sciences - 2009 10 pre></body></html 


The HyspIRI mission utilizes innovative techniques to both reduce the amount of data that must be transmitted to the ground and accommodate the required data volume on the ground The infrastructure and techniques developed by this mission will open the door to future high data volume science missions The designs presented here are the work of the authors and may differ from the current HyspIRI mission baseline A CKNOWLEDGMENTS This research was carried out at the Jet Propulsion Laboratory California Institute of Technology and was sponsored by the Space Grant program and the National Aeronautics and Space Administration R EFERENCES  K W ar\002eld T  V  Houten C Hee g V  Smith S Mobasser B Cox Y He R Jolly C Baker S Barry K Klassen A Nash M Vick S Kondos M Wallace J Wertz Chen R Cowley W Smythe S Klein L Cin-Young D Morabito M Pugh and R Miyake 223Hyspiri-tir mission study 2007-07 002nal report internal jpl document,\224 TeamX 923 Jet Propulsion Laboratory California Institute of Technology 4800 Oak Grove Drive Pasadena CA 91109 July 2007  R O Green 223Hyspiri summer 2008 o v ervie w  224 2008 Information exchanged during presentation  S Hook 2008 Information e xchanged during meeting discussion July 16th  R O Green 223Measuring the earth wi th imaging spectroscopy,\224 2008  223Moore s la w Made real by intel inno v ation 224 http://www.intel.com/technology/mooreslaw/index.htm  T  Doggett R Greele y  S Chein R Castano and B Cichy 223Autonomous detection of cryospheric change with hyperion on-board earth observing-1,\224 Remote Sensing of Environment  vol 101 pp 447\226462 2006  R Castano D Mazzoni N T ang and T  Dogget 223Learning classi\002ers for science event detection in remote sensing imagery,\224 in Proceedings of the ISAIRAS 2005 Conference  2005  S Shif fman 223Cloud detection from satellite imagery A comparison of expert-generated and autmatically-generated decision trees.\224 ti.arc.nasa.gov/m/pub/917/0917 Shiffman  M Griggin H Burk e D Mandl and J Miller  223Cloud cover detection algorithm for eo-1 hyperion imagery,\224 Geoscience and Remote Sensing Symposium 2003 IGARSS 03 Proceedings 2003 IEEE International  vol 1 pp 86\22689 July 2003  V  V apnik Advances in Kernel Methods Support Vector Learning  MIT Press 1999  C Bur ges 223 A tutorial on support v ector machines for pattern recognition,\224 Data Mining and Knowledge Discovery  vol 2 pp 121\226167 1998  M Klemish 223F ast lossless compression of multispectral imagery internal jpl document,\224 October 2007  F  Rizzo 223Lo w-comple xity lossless compression of h yperspectral imagery via linear prediction,\224 p 2 IEEE Signal Processing Letters IEEE 2005  R Roosta 223Nasa jpl Nasa electronic parts and packaging program.\224 http://nepp.nasa.gov/docuploads/3C8F70A32452-4336-B70CDF1C1B08F805/JPL%20RadTolerant%20FPGAs%20for%20Space%20Applications.pdf December 2004  I Xilinx 223Xilinx  Radiation-hardened virtex-4 qpro-v family overview.\224 http://www.xilinx.com/support/documentation data sheets/ds653.pdf March 2008  G S F  Center  223Tdrss o v ervie w  224 http://msp.gsfc.nasa.gov/tdrss/oview.html 7  H Hemmati 07 2008 Information e xchanged during meeting about LaserComm  223W orldvie w-1 224 http://www digitalglobe.com/inde x.php 86/WorldView-1 2008  223Sv albard ground station nor way.\224 http://www.aerospacetechnology.com/projects/svalbard 7 2008  223Satellite tracking ground station 224 http://www.asf.alaska.edu/stgs 2008  R Flaherty  223Sn/gn systems o v ervie w  224 tech rep Goddard Space Flight Center NASA 7 2002  223Geoe ye-1 f act sheet 224 http://launch.geoeye.com/launchsite/about/fact sheet.aspx 2008  L-3 Communications/Cincinnati Electronics Space Electronics 7500 Innovation Way Mason OH 45040 T-720 Transmitter  5 2007 PDF Spec Sheet for the T720 Ku-Band TDRSS Transmitter  L-3 Communications/Cincinnati Electronics Space Electronics 7500 Innovation Way Mason OH 45040 T-722 X-Band  7 2007 PDF Spec Sheet for the T-722  J Smith 07 2008 Information e xchanged during meeting about GDS  J Carpena-Nunez L Graham C Hartzell D Racek T Tao and C Taylor 223End-to-end data system design for hyspiri mission.\224 Jet Propulsion Laboratory Education Of\002ce 2008  J Behnk e T  W atts B K obler  D Lo we S F ox and R Meyer 223Eosdis petabyte archives Tenth anniversary,\224 Mass Storage Systems and Technologies 2005 Proceedings 22nd IEEE  13th NASA Goddard Conference on  pp 81\22693 April 2005 19 


 M Esf andiari H Ramapriyan J Behnk e and E So\002nowski 223Evolving a ten year old data system,\224 Space Mission Challenges for Information Technology 2006 SMC-IT 2006 Second IEEE International Conference on  pp 8 pp.\226 July 2006  S Marle y  M Moore and B Clark 223Building costeffective remote data storage capabilities for nasa's eosdis,\224 Mass Storage Systems and Technologies 2003 MSST 2003 Proceedings 20th IEEE/11th NASA Goddard Conference on  pp 28\22639 April 2003  223Earth science data and information system esdis project.\224 http://esdis.eosdis.nasa.gov/index.html  M Esf andiari H Ramapriyan J Behnk e and E So\002nowski 223Evolution of the earth observing system eos data and information system eosdis\\224 Geoscience and Remote Sensing Symposium 2006 IGARSS 2006 IEEE International Conference on  pp 309\226312 31 2006Aug 4 2006  223Earth science mission operations esmo 224 http://eos.gsfc.nasa.gov/esmo  E Masuoka and M T eague 223Science in v estig ator led global processing for the modis instrument,\224 Geoscience and Remote Sensing Symposium 2001 IGARSS 01 IEEE 2001 International  vol 1 pp 384\226386 vol.1 2001  M Esf andiari H Ramapriyan J Behnk e and E So\002nowski 223Earth observing system eos data and information system eosdis 227 evolution update and future,\224 Geoscience and Remote Sensing Symposium 2007 IGARSS 2007 IEEE International  pp 4005\2264008 July 2007  D McAdam 223The e v olving role of tape in the data center,\224 The Clipper Group Explorer  December 2006  223Sun microsystems announces w orld s 002rst one terabyte tape storage drive.\224 http://www.sun.com/aboutsun/pr/200807/sun\003ash.20080714.2.xml July 2008  223P anasas 227 welcome 224 http://www panasas.com  R Domikis J Douglas and L Bisson 223Impacts of data format variability on environmental visual analysis systems.\224 http://ams.confex.com/ams/pdfpapers/119728.pdf  223Wh y did nasa choose hdf-eos as the format for data products from the earth observing system eos instruments?.\224 http://hdfeos.net/reference/Info docs/SESDA docs/NASA chooses HDFEOS.php July 2001  R E Ullman 223Status and plans for hdfeos nasa's format for eos standard products.\224 http://www.hdfeos.net/hdfeos status HDFEOSStatus.htm July 2001  223Hdf esdis project.\224 http://hdf.ncsa.uiuc.edu/projects/esdis/index.html August 2007  223W elcome to the ogc website 224 http://www.opengeospatial.org 2008  223Open gis Gis lounge geographic information systems.\224 http://gislounge.com/open-gis Christine M Hartzell received her B.S in Aerospace Engineering for Georgia Institute of Technology with Highest Honors in 2008 She is currently a PhD student at the University of Colorado at Boulder where she is researching the impact of solar radiation pressure on the dynamics of dust around asteroids She has spent two summers working at JPL on the data handling system for the HyspIRI mission with particular emphasis on the cloud detection algorithm development and instrument design Jennifer Carpena-Nunez received her B.S in physics in 2008 from the University of Puerto Rico where she is currently a PhD student in Chemical Physics Her research involves 002eld emission studies of nanostructures and she is currently developing a 002eld emission setup for further studies on nano\002eld emitters The summer of 2008 she worked at JPL on the HyspIRI mission There she was responsible for the science analysis of the data handling system speci\002cally de\002ning the data level and processing and determining potential mission collaborations Lindley C Graham is currently a junior at the Massachusetts Institute of Technology where she is working towards a B.S in Aerospace Engineering She spent last summer working at JPL on the data handling system for the HyspIRI mission focusing on developing a data storage and distribution strategy 20 


David M Racek is a senior working toward a B.S in Computer Engineering at Montana State University He works in the Montana State Space Science and Engineering Laboratory where he specializes in particle detector instruments and circuits He spent last summer working at JPL on compression algorithms for the HyspIRI mission Tony S Tao is currently a junior honor student at the Pennsylvania State University working towards a B.S in Aerospace Engineering and a Space Systems Engineering Certi\002cation Tony works in the PSU Student Space Programs Laboratory as the project manager of the OSIRIS Cube Satellite and as a systems engineer on the NittanySat nanosatellite both of which aim to study the ionosphere During his work at JPL in the summer of 2008 Tony worked on the communication and broadcast system of the HyspIRI satellite as well as a prototype Google Earth module for science product distribution Christianna E Taylor received her B.S from Boston University in 2005 and her M.S at Georgia Institute of Technology in 2008 She is currently pursing her PhD at the Georgia Institute of Technology and plans to pursue her MBA and Public Policy Certi\002cate in the near future She worked on the ground station selection for the HyspIRI mission during the summer of 2008 and looks forward to working at JPL in the coming year as a NASA GSRP fellow Hannah R Goldberg received her M.S.E.E and B.S.E from the Department of Electrical Engineering and Computer Science at the University of Michigan in 2004 and 2003 respectively She has been employed at the Jet Propulsion Laboratory California Institute of Technology since 2004 as a member of the technical staff in the Precision Motion Control and Celestial Sensors group Her research interests include the development of nano-class spacecraft and microsystems Charles D Norton is a Principal Member of Technical Staff at the Jet Propulsion Laboratory California Institute of Technology He received his Ph.D in Computer Science from Rensselaer and his B.S.E in Electrical Engineering and Computer Science from Princeton University Prior to joining JPL he was a National Research Council resident scientist His work covers advanced scienti\002c software for Earth and space science modeling with an emphasis on high performance computing and 002nite element adaptive methods Additionally he is leading efforts in development of smart payload instrument concepts He has given 32 national and international keynote/invited talks published in numerous journals conference proceedings and book chapters He is a member of the editorial board of the journal Scienti\002c Programming the IEEE Technical Committee on Scalable Computing a Senior Member of IEEE recipient of the JPL Lew Allen Award and a NASA Exceptional Service Medal 21 


this paper, we only generate the size-2 patterns in the BFS phase. It will be interesting to investigate the impact on the performance if the ?rst phase is stopped at a deeper level Also, the projection is a very ef?cient method for ?nding patterns, especially for parallel implementation of pattern mining algorithms [1]. We plan to adapt the projection ideas into our algorithm and design an ef?cient parallel algorithm for mining maximal hyperclique patterns References 1] R. Agarwal, C. Aggarwal, and V. Prasad. A Tree Projection Algorithm For Generation of Frequent Itemsets. pages 350 371, Feb 2001 2] R. Agrawal, T. Imielinski, and A. Swami. Mining Association Rules between Sets of Items in Large Databases. In Proc. of the ACM SIGMOD Conference on Management of Data, pages 207216,May 1993 3] R. Agrawal and R. Srikant. Fast Algorithms for Mining Association Rules. In Proc. of the 20th Intl Conference on Very LargeData Bases, 1994 4] R. Bayardo. Ef?ciently mining long patterns from databases In Proc. of the ACM SIGMOD Conference, 1998 5] R. Bayardo and R. Agrawal. Mining the Most Interesting Rules. In Proc. of the ACM SIGKDD Conference, 1999 6] D. Burdick, M. Calimlim, and J. Gehrke. Ma?a: AMaximal Frequent Itemset Algorithm for Transactional Databases. In Proc. of IEEE Conf. on Data Engineering, 2001 7] Y. Huang, H. Xiong, W. Wu, and Z. Zhang. A Hybrid Approach for Mining Maximal Hyperclique Patterns. In In Technical Report UTDCS-34-04, Department of computer science, University of Texas - Dallas, 2004 8] J.Han, J.Pei, and Y. Yin. Mining Frequent Patterns without Candidate Generation. In Proc. of the ACM SIGMOD International Conference on Management of Data, 2000 9] M.J.Zaki and C.Hsiao. ChARM: An ef?cient algorithm for closed itemset mining. In Proc. of 2nd SIAM International Conference on Data Mining, 2002 10] R.Rymon. Search through Systematic Set Enumeration. In Proc. Third Intl Conference on Principles of Knowledge Representation and Reasoning, 1992 11] H. Xiong, M. Steinbach, P.-N. Tan, and V. Kumar. HICAP: Hierarchial Clustering with Pattern Preservation. In Proc. of 2004 SIAM International Conference on Data Mining \(SDM 12] H. Xiong, P.-N. Tan, and V. Kumar. Mining Strong Af?nity Association Patterns in Data Set with Skewed Support. In Proc. of the Third IEEE International Conference on Data Mining \(ICDM Proceedings of the 16th IEEE International Conference on Tools with Artificial Intelligence \(ICTAI 2004 1082-3409/04 $20.00  2004 IEEE 





