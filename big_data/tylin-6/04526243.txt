A Future Global Atmospheric Composition Mission CACM Concept Nathaniel Livesey Michelle Santee Paul Stek Joe Waters Jet Propulsion Laboratory 4800 Oak Grove Drive Pasadena CA 91109 818-354-4214 liveseyWmls.jpl.nasa.gov Pieternel Levelt Pepijn Veefkind Royal Dutch Meteorological Institute The Netherlands Jack Kumer Aidan Roche Lockheed Martin Palo Alto California Abstract Resolution of important outstanding questions in air quality climate change and ozone layer stability demands global observations of multiple 
chemical species with high horizontal and vertical resolution from the boundary layer to the stratopause We present a mission concept that delivers the needed atmospheric composition observations along with cloud ice and water vapor data needed for improvements in climate and weather forecasting models The mission comprises ultraviolet and infrared nadir and microwave limb viewing instruments observing wide swaths each orbit We review the scientific goals of the mission and the measurement capabilities this 
concept will deliver We describe how precessing orbits offer significant improvements in temporal resolution and diurnal coverage compared to sun-synchronous orbits Such improvements are needed to quantify the impact of critical fast processes such as deep convection on the composition and radiative properties of the upper troposphere a region where water vapor and ozone are strong but poorly understood greenhouse gases This concept can serve 
as the Global Atmospheric Composition Mission GACM recently recommended by the National Academy of Sciences decadal survey as one of 17 priority earth science missions for the coming decade.12 TABLE OF CONTENTS 1 INTRODUCTION 1 2 BACKGROUND OF THE MEASUREMENTS 2 3 TECHNICAL OBJECTIVES AND APPROACH 3 1 11-4244-1488-1/08/$25.00 
C 2008 IEEE 2IEEEAC paper  1147 Version 4 Updated 12/14/07 4 JUSTIFICATION AND BENEFITS 4 
5 TECHNOLOGY COMPARISONS AND READINESS  6 6 MEASUREMENT COVERAGE AND RESOLUTION COMPARISONS 6 7 CONCLUSIONS 7 1 INTRODUCTION This paper describes a mission concept known herein as the Low Earth Orbit Multispectral Atmospheric Composition mission LEOMAC LEOMAC can serve as the Global Atmospheric Composition Mission GACM identified in the recent National Acadamy of Science decadal survey of future earth-science satellite missions for NASA and NOAA NRC 2007 The LEOMAC3 mission 
addresses crucial issues on how changes in atmospheric composition affect the quality and well-being of life both regionally and for the entire Earth LEOMAC provides data that are essential for making informed policy decisions on issues related to regional and global air quality and climate change It determines if regulations on ozone depleting substances are having the desired effect on stratospheric chemistry and ozone recovery LEOMAC provides data 
at better horizontal and vertical resolution and in the case of LEOMAC-P at much better temporal resolution all of which are needed to address critical current questions in atmospheric science and to improve the accuracy of global circulation models used for weather and climate predictions It continues the measurements from Aura that are needed long-term but will not be provided by other planned missions while adding new measurement 
capabilities that are not currently possible LEOMAC's measurements are essential for meeting the goals of NASA's 2006 Strategic Plan As stated above LEOMAC can serve as the Global 1 3 Either a precessing or sun-synchronous orbit is being considered for LEOMAC 
We here use LEOMAC-P to denote the precessing orbit version and LEOMAC-S to denote the sun-synchronous version LEOMAC is used when referring to items applicable to both orbits 1 


Atmospheric Composition Mission GACM recommended by the National Research Council Decadal Survey as one of the 14 priority Earth Observation missions for NASA to implement in the next decade The specific objectives of LEOMAC are to 1 Quantify how increasing emissions of pollutants affect air quality globally 2 Determine how the ozone layer and its chemistry are changing 3 Quantify how changing atmospheric composition is affecting climate and 4 Quantify the processes that control upper tropospheric water vapor and cloud ice Producing the measurements necessary to meet these objectives with the needed combination of global coverage accuracy precision and resolution requires multi-spectral measurements covering bands in the microwave thermal infrared short-wavelength infrared near-infrared visible and ultraviolet spectral regions LEOMAC covers these spectral bands with three instruments The candidate instruments are either advanced versions of instruments proved successful on previous missions and/or are instruments for which NASA has development programs underway The mission implementation would consist of a single satellite in low-Earth orbit producing geolocated mapped data from all instruments In addition to producing archived data for scientific research LEOMAC would also produce direct broadcast and near-real-time data for measurements not available from operational satellites that could also be used operationally 2 BACKGROUND OF THE MEASUREMENTS Human activities are changing atmospheric composition in ways that can adversely affect life on Earth Unhealthful pollution episodes are common Increasing pollution worldwide affects global and regional air quality and can affect the atmosphere's ability to cleanse itself Policy decisions related to atmospheric composition requiring balances between economic and environmental concerns must be made and continuously validated Obtaining political consensus needed for making the decisions is difficult but regulations on ozone depleting substances Montreal Protocol demonstrate that consensus on such issues can be reached if sufficient scientific information is produced and adequately communicated Such information requires global measurements of atmospheric composition LEOMAC is designed to provide these measurements with the needed and previously unavailable combination of horizontal vertical and temporal resolution It also provides key measurements needed to improve the accuracy of weather and climate prediction models The LEOMAC measurements are chosen to fulfill recognized needs in the following applications areas  Air quality LEOMAC makes all the priority tropospheric measurements 03 CO NO2 CH2O SO2 aerosols identified by the February 2006 Community Workshop on Air Quality Remote Sensing from Space Defining an Optimum Observing Strategy and the NRC Decadal Study Panel on Human Health and Security It provides the global measurements that are essential for obtaining international agreements on air quality issues  UV exposure LEOMAC makes all the NRC Decadal Study Human Health and Security Panel's UV exposure and skin cancer priority chemical measurements 03 H20 HO2 NO2 ClO BrO HNO3 HCl H2CO HDO H2180 C02 CO NOY N20 CH4 and IO recently measured by SCIAMACHY as a goal except for OH for which HO2 is a good proxy and halogen source molecules for which HCl and BrO give adequate information LEOMAC's additional measurements of H202 NO HOCl CH3Cl and volcanic SO2 give additional information for tracking ozone layer stability  Climate change LEOMAC makes measurements for assessing climate change that have been identified as crucial by many studies including the NRC Decadal Study Panel on Climate Variability and Change Its measurements of pollutants aerosol optical depth and index cloud ice amount and particle size parameter cloud height and albedo water vapor and temperature all made simultaneously and with global coverage will enable progress in quantifying climate change associated with anthropogenic effects on clouds and aerosols It measures the convective deposition of pollutants that affect ozone in the upper troposphere where ozone's radiative forcing of climate is greatest It continues the long-term global aerosol data set from TOMS and OMI that is needed to provide crucial information on changes in aerosol that affect climate  Global circulation models used for climate and weather predictions LEOMAC s simultaneous measurements of water vapor and cloud ice amount with information on ice particle size made with resolution needed for progress in quantifying the effects of convection will improve parameterizations e.g of convection cloud formation and sedimentation in models used to predict weather and seasonal interannual and long-term climate variability 2 


LEOMAC-P's new temporal sampling will improve the performance of data assimilation systems and regional forecast models and should help improve worldwide extreme-event forecasting and hazard assessment LEOMAC s measurements are essential to meeting the NASA 2006 Strategic Plan goal 3A 1  Progress in understanding and improving predictive capability for changes in the ozone layer climate forcing and air quality associated with changes in atmospheric composition They also contribute significantly to goals 3A.2 and 3A.5  Progress in enabling improved predictive capability for weather and extreme weather events  Progress in understanding the role of oceans atmosphere and ice in the climate system and in improving predictive capability for its future evolution 3 TECHNICAL OBJECTIVES AND APPROACH The overall objectives of LEOMAC elaborated in section 4 of this document are to 1 Quantify how increasing emissions of pollutants affect air quality globally 2 Determine how the ozone layer and its chemistry are changing 3 Quantify how changing atmospheric composition is affecting climate and 4 Quantify the processes that control upper tropospheric water vapor and cloud ice Figure 1 shows the measurements required to meet these objectives and candidate instruments to provide them Producing these measurements with the needed combination of coverage accuracy precision and resolution requires a multi-spectral capability covering microwave thermal infrared short-wave-length infrared near-infrared visible and ultraviolet spectral regions LEOMAC costeffectively covers the required bands in these six spectral regions with a combination of three candidate instruments having the required sensitivity spectral resolution broad measurement swaths and spatial resolution The candidate instruments all of which have significant heritage from previous satellite instruments and/or have development programs underway are described below A Scanning Microwave Limb Sounder SMLS for measurements of H20 cloud ice and key chemical species in the upper troposphere and stratosphere SMLS an advanced version of MLS on Aura Waters et al 2006 measures thermal microwave limb emission in broad spectral bands centered at 240 and 640 GHz Major improvements from Aura MLS are a azimuth scanning simultaneous with vertical scanning to give 50x50 km horizontal sampling cross-track sampling 50x better than Aura MLS along-track 3x better over a broad 5000-km wide measurement swath to quantify convective depositions into the upper troposphere and long-range pollution transport b vertical resolution of 1.5-2 km 2x better than Aura MLS and c measurement of NO NO2 HDO and H218O SMLS measures more molecules than Aura MLS while having a simpler signal chain and fewer radiometers  A TROpospheric Pollution Imager TROPI for measurements of the key tropospheric pollutants 03 NO2 SO2 and CH2O and for measurements of aerosol/cloud properties e.g aerosol index and optical depth cloud height and albedo TROPI an advanced version of OMI on Aura Levelt et al 2006 and with long heritage from TOMS measures reflected/backscattered solar radiation at ultraviolet/visible 0.3 to 0.5 ptm and near-infrared 0.76 ptm wavelengths Major improvements over OMI are a 10x10 km horizontal resolution 2-4x better than OMI needed for resolving pollution sources and obtaining more cloud-free observations while achieving a broad measurement swath of 3000 km b addition of a near-infrared band for improved measurements of cloud and surface properties to greatly improve the accuracy of the tropospheric pollution measurements and c improved radiation hardness of the detectors  A Tropospheric Infrared Mapping Spectrometer TIMS for measurements of the key tropospheric pollutant CO the key greenhouse gases CO2 and CH4 and measurements of 03 and CO in the middle troposphere for long-range transport TIMS measures both reflected and backscattered short-wavelength infrared at 2.1 and 2.3 ptm and thermal infrared at 4.7 and 9.6 pm Its design with two compact pushbroom mapping grating spectrometers is being demonstrated through NASA's Instrument Incubator Program This design achieves the very high spectral resolution needed for tropospheric measurements of CO 03 CH4 H20 and CO2 k2JAk of 33,000 at 2.1 and 2.3 gim and 11,000 at 4.7 and 9.6 gim Each spectrometer uses multiple orders to obtain measurements in at least two channels TIMS has 3000-km wide measurement swath and 3 km or better horizontal resolution These three instruments work together in an extremely synergistic manner to provide the needed measurements For example their sensitivities to different height ranges in the troposphere enable vertical profiles of tropospheric 3 


pollution to be retrieved with unprecedented capability by combining the simultaneous measurements from SMLS TIMS and TROPI A cloud camera is added to the main instrument suite to enhance the science return of TIMS and TROPI The mission implementation would consist of a single satellite in low-Earth orbit Figure 2 shows the conceptual design for this observatory and lists its basic characteristics 4 JUSTIFICATION AND BENEFITS Justification and benefits are discussed in the following subsections for each of the LEOMAC objectives 4a Quantify how increasing emissions of pollutants affect air quality globally Near-surface emissions are mixed throughout the global troposphere by convection and large-scale winds Primary emissions generate secondary pollutants far from their sources causing the rapidly increasing industrialization in developing countries to affect air quality worldwide An especially important example for the United States is the effect of pollution from the newly industrializing Asian countries on American air quality Models indicate Stohl et al 2002 that for pollutants with 10-day lifetime which includes ozone and its precursors Asia makes the largest contribution to the column over North America as shown in Figure 3 The models indicate that after being emitted into the boundary layer the transport of Asian pollution to the United States is predominantly in the upper and middle troposphere and occurs through episodic events Liang et al 2004 The LEOMAC measurements will enable for the first time direct observational tracing of pollution around the globe to its emission sources such as the example of Asian pollution over America discussed above TROPI and TIMS provide the high spatial resolution required to identify the source emissions of 03 NO2 S02 CO and CH2O into the boundary layer For the measurement of boundary-layer 03 emissions which is more difficult because of the large amounts of 03 in the stratosphere the combination of TROPI TIMS and SMLS simultaneous measurements with their very different sensitivities to different altitude regions allow inference of lower tropospheric 03 Boundary layer values are inferred by their morphology and temporal variation TIMS provides the measurements needed for tracking the long-range transport of CO and 03 in the middle troposphere and SMLS for tracking the transport of these pollutants and possibly others in the upper troposphere The improvements of TROPI resolution over that of OMI on Aura and of SMLS over Aura MLS are illustrated in Figure 4 LEOMAC-P will provide improved temporal resolution that is needed on a global scale for quantifying the variations in pollution throughout the day It will for the first time provide global measurements of pollutants at multiple times per day Figure 5 shows an example of NO2 pollution over the southeastern U.S Here as in other polluted areas around the world largest abundances of NO2 occur early in the morning and late in the day and are thus missed by the A-Train and SCIAMACHY They will also be missed by planned operational missions and LEOMAC-S The LEOMAC-P measurements precess through all times of day over the course of 36 days All longitudes over a wide latitude range are measured each day over month-long periods that switch between northern and southern hemispheres Measurements at all longitudes are crucial for tracking the worldwide long-range transport of pollution which is predominantly west to east and for observationally tracing pollution back to its specific sources The orbit phase is chosen for summer air quality measurement priorities Measurement coverages are quantified in section 5 Benefits These measurements give crucial information for quantifying the global distribution of pollutants and their sources and for progress in determining how pollution may be changing the ability of the atmosphere to cleanse itself By giving a direct observational connection between the global distribution of pollution and the pollution emission sources they are essential for supporting the development of national and international policy to maintain and improve the quality of the air we breathe LEOMAC's measurements of tropospheric 03 CH4 CO N02 CH2O as a proxy for VOCs and SO2 provide information needed for improving assessment of how the atmosphere's oxidizing capacity may be changing 4b Determine how the ozone layer and its chemistry are changing Changes in halocarbons and climate are affecting the chemistry of the stratosphere and the upper troposphere particularly near the tropopause region LEOMAC provides the measurements needed to determine how stratospheric chemistry is changing and thus determine the stability of the ozone layer It measures both the dominant chlorine reservoir HCI and reactive radical CIO involved in stratospheric 03 depletion giving crucial information on whether chlorine partitioning is changing with changing climate e.g a cooler stratosphere predicted by climate change models would cause more chlorine to be in the 03-destroying CIO form and changing halocarbons Its simultaneous daily maps of lower stratospheric temperature HNO3 H20 CGO HC1 NO2 and possibly measurements of aerosol extinction by thick polar stratospheric clouds provide needed information for understanding/tracking climate-sensitive microphysical processes that can trigger increased 03 destruction 4 


Measurements of the long-lived tracers N20 CO and in many situations H20 03 HCl and HNO3 give information on dynamics and transport that could also be affected by a changing climate These measurements along with temperature and geopotential height diagnose tropopause structure and other dynamical effects that strongly influence column ozone Measurements of the chemical species can be made in the presence of volcanic aerosol that can substantially perturb stratospheric chemistry Measurements of volcanically-injected S02 provide information on the formation of aerosols that affect both chemistry and climate HC1 in the upper stratosphere is indicative of the total chlorine loading of the stratosphere and its measurement provides crucial information on whether international regulations to reduce stratospheric chlorine are having the desired effect LEOMAC continues the long-term global HC1 measurements from UARS and Aura The observed decrease in HC1 is consistent with the rate at which anthropogenic chlorine is expected to be cleansed from the stratosphere which will take more than 50 years We must continue tracking HC1 to ensure that chlorine is being cleansed from the stratosphere as expected BrO also measured by LEOMAC is both the dominant form of bromine in the stratosphere and the dominant form of bromine that destroys O3 e.g WMO 2006 There are still regulatory issues regarding certain bromine compounds and the BrO measurement provides information needed for policy decisions balancing economic and environmental concerns The LEOMAC measurements of H20 HO2 and H202 provide information to track destruction of ozone by hydrogen chemistry The measurements of N20 HNO3 NO2 and NO provide information to track destruction of ozone by nitrogen chemistry LEOMAC's high-resolution data will enable progress in stratospheric and upper tropospheric dynamics that was planned for Aura but lost due to a HIRDLS mishap at launch The improved temporal resolution will help quantify the extent to which fast convective processes might be transporting short-lived ozone-depleting substances into the stratosphere Benefits These measurements will provide data needed for assessing how changes in halocarbons and climate are affecting the stability of the ozone layer and for determining if international regulations are having the desired effect 4c Quantify how changing atmospheric composition is affecting climate Atmospheric pollutants can affect the formation and properties of aerosols and clouds that influence climate Short-lived pollutants can also affect the concentration of long-lived atmospheric constituents that have climate impact such as ozone water vapor ice clouds carbon dioxide and methane Determining the extent to which pollution and anthropogenic aerosols affect upper tropospheric cloudiness is crucial for improving the accuracy of climate change predictions Figure 6 shows Aura MLS observations of correlations in large values of upper tropospheric cloud ice and uplifted pollution Li Q et al 2005 Has anthropogenic pollution contributed to the observed enhancement in clouds This question is starting to be addressed with Aura data but much better resolution in the microwave measurements as can be provided by SMLS is required As also needed to improve climate models TROPI will distinguish between reflecting and absorbing aerosols and continue the long TOMS/OMI global aerosol dataset It is crucial that this record be continued with key related measurements in order to make progress in quantifying the effects of changing atmospheric composition on climate Quantifying the processes that affect upper tropospheric 03 is also crucial for reducing uncertainties in predictions of climate change The increase in tropospheric 03 since preindustrial times is estimated to give the third-largest increase in direct radiative forcing of climate and it is in the upper troposphere that the effect of 03 is largest LEOMAC provides needed information on the processes affecting upper tropospheric 03 that will reduce the existing uncertainties in climate forcing by upper tropospheric 03 An important question which applies to how atmospheric composition affects both upper tropospheric aerosols and ozone is the extent to which the upper troposphere is short-circuited to the boundary layer by convection This has serious implications for climate change long-range transport of pollution and ozone layer stability Figure 7 illustrates the typical spatial and temporal scales for convective deposition of boundary layer air into the upper troposphere Mullendore et al 2005 Figure 8 shows the diurnal variation of convection and how LEOMAC provides needed new sampling to quantify its effects LEOMAC's simultaneous measurements of cloud ice H20 H218O and HDO allow unique identification of air masses associated with convection Benefits These measurements will improve our ability to understand and predict the effects of changes in atmospheric composition on climate forcings and thus improve the accuracy of prediction models 4d Quantify the processes that control upper tropospheric water vapor and cloud ice Upper tropospheric H20 and cloud ice are poorly measured by the existing operational network Global data with better spatial and temporal resolution are needed for parameterizing convection and cloud formation processes to improve weather and climate prediction models 5 


Upper tropospheric H2O can either amplify or attenuate the climatic effects of increases in other greenhouse gases depending upon the process affecting it and the spatial and temporal scales of the process e.g Su et al 2006 Measurement of upper tropospheric H2O has historically been very difficult due both to its relatively small abundance and to the presence of ice clouds that degrade or prevent its measurement by many techniques Microwave limb sounding however is well-suited to this measurement because of its combination of good vertical resolution sensitivity and long wavelengths that can measure both gas phase abundances in the presence of ice clouds and the larger ice amounts that saturate or block shorter wavelength techniques Scattering is inversely proportional to the 4th power of wavelength small particles affect 1 mm wavelength microwaves 108 times less than 10 ptm infrared The dramatic improvement in coverage and resolution of SMLS on LEOMAC particularly on LEOMAC-P compared to previous MLS instruments and its additional measurements of H218O and HDO which yield key information on convection and condensation processes will provide crucial details of mechanisms affecting upper tropospheric H2O and its influence on climate variability One of the most significant shortcomings in current weather and climate models is the representation of clouds and their feedbacks on the global water and energy cycles This shortcoming includes both convective and non-convective clouds applies to both global circulation models GCMs and regional models and impacts both weather and climate predictions The accurate depiction of clouds and related hydrological processes in the upper troposphere is essential for predicting climate change It is in the upper troposphere that water vapor feedbacks are most acute and cloud feedbacks in this case from deep convective and high cirrus/ice clouds are undeniably significant Aura MLS has demonstrated simultaneous observations of cloud ice and water vapor which are important for understanding cloud formation These data have been used by the European Center for Medium Range Weather Forecasting ECMWF to justify changing ice supersaturation parameters in their Integrated Forecast System which has led to clear improvements in performance in particular the simulation of the location and intensity of tropical deep convection through indirect radiative feedbacks Li J et al 2005 SMLS on LEOMAC-P provides the improvement in resolution needed for additional progress to improve the accuracy of model predictions Figure 9 shows for example the diurnal variation of convection over the southeastern U.S in summer and measurement time examples for SMLS on LEOMAC-P Benefits These measurements will provide data needed to improve quantification of processes that control upper tropospheric water vapor and cloud ice and thus should improve the accuracy of global circulation models used for weather and climate predictions 5 TECHNOLOGY COMPARISONS AND READINESS 5a Comparisons to Other Techniques LEOMAC-P's main advantage over previous low-earthorbiting missions is its ability from a single satellite to deliver the improved temporal resolution and coverage of the diurnal cycle required to address critical outstanding questions in atmospheric composition and climate These needed improvements are made without the sacrifices of either global coverage or the good vertical resolution associated with limb sounding that need to be made in moving to a geostationary orbit GEO The multi-sensor approach of LEOMAC encompassing observations in the UV/Visible near and thermal infrared and microwave results in a comprehensive measurement suite offering unprecedented vertical resolution in the troposphere 5b Technology Readiness All of the LEOMAC instruments represent mature measurement techniques and technology SMLS and TROPI are advanced versions of highly successful instruments that have flown in previous NASA and other missions The TIMS instrument has been developed under the NASA Instrument Incubator Program All the critical technologies for SMLS are Technology Rediness Level TRL 5 or better For TROPI some development will be required to bring the planned CMOS detector technology to TRL 5/6 The TIMS instrument technology is currently TRL 3/4 further funding will be required to raise this to 516 A NASA missions study undertaken by Goddard Space Flight Center in collaboration with the instrument teams identified no significant risks or uncertainties associated with the spacecraft design Commercial technology in the form of Control Moment Gyros exists to perform the momentum compensation required to absorb the antenna the motion from the SMLS vertical scan Mass and power and data downlink requirements are comparable to those of many previous highly successful earth-science missions 6 MEASUREMENT COVERAGE AND RESOLUTION COMPARISONS Figures 10 and 11 compare coverage and resolution for LEOMAC-P LEOMAC-S and GEOMAC a geosynchronous satellite atmospheric composition mission also being studied As quantified in Figure 10 LEOMAC-P gives more frequent measurements at mid-latitudes where most of the population lives whereas LEOMAC-S gives measurements heavily weighted to polar regions where planned operational missions will provide a wealth of such 6 


observations Planned operational measurements will fill the gaps where the LEOMAC-P coverage switches monthly between northern and southern hemispheres Figure 11 is an overview of the overarching scientific issues that need to be addressed by future atmospheric composition missions the coverage and resolution needed to address these issues and the capabilities of LEOMAC-P LEOMAC-S and GEOMAC LEOMAC-P provides global measurements with better temporal resolution than LEOMAC-S and provides both the global coverage and vertical resolution not available from GEOMAC 7 CONCLUSIONS LEOMAC makes needed measurements of atmospheric composition humidity and clouds that are critical to our understanding of important issues in air quality climate and earth-system modeling The proposed mission and its four instruments offer an unprecedented combination of vertical horizontal and temporal resolution needed to addresss these questions without sacrifice of global coverage The technology to implement LEOMAC is at a high state of maturity Acknowledgements The research described in this publication or paper carried out at the Jet Propulsion Laboratory California Institute of Technology was under a contract with the National Aeronautics and Space Administration REFERENCES NRC 2007 Earth Science and Applications from Space National Imperatives for the Next Decade and Beyond National Academy of Science Waters et al 2006 Waters J.W et al The Earth Observing System Microwave Limb Sounder EOS MLS on the Aura satellite IEEE Trans Geosci Remote Sensing 44 no 5 2006 Geophys Res 109:D23S07 doi 10.1029/2003JD004402 2004 WMO 2006 Scientific Assesment of Ozone Depletion 2006 World Meteorological Organization Global Ozone Research and Monitoring Project report No 50 2006 Li Q et al 2005 Li Q.B et al Convective outflow of South Asian pollution A global CTM simulation compared with EOS MLS observations Geophys Res Lett 32 L14826 doi:10.1029/2005GL022762 2005 Mullendore et al 2005 Mullendore et al Crosstropopause tracer transport in midlatitude convection J Geophys Res 110 D06113 doi 10.1029/2004JD005059 Li J et al 2005 Li J-L et a Comparisons of EOS MLS Cloud Ice Measurements with ECMWF analyses and GCM Simulations Initial Results Geophys Res Lett 32 L18710 doi:10.1029/2005GL023788 2005 BIOGRAPHY Nathaniel Livesey is an atmospheric scientist at the Jet Propulsion Laboratory and is currently the Principal Investigator for the Microwave Limb Sounder MLS instrument on the Earth Observing System Aura spacecraft launched in 2004 His research interests are centered on microwave space based observations of the chemistry hydrology and dynamics of Earth's atmosphere Most of his work has focused on the MLS experiments both on Aura and the earlier Upper Atmosphere Research Satellite UARS launched in 1991 Before becoming Aura MLS PI he was responsible for the MLS retrieval algorithms These convert the raw observations of the microwave signature of the atmosphere into measurements of atmospheric composition temperature humidity and cloud ice van den Oord et al 2006 van den Oord et al The Ozone Monitoring Instrument IEEE Trans Geosci Remote Sensing 44 no 5 2006 Stohl et al 2002 A Stohl et al On the pathways and timescales of intercontinental air pollution transport J Geophys Res 107\(D23 doi 10.1029/2001 JD001396 Liang et al 2004 Q Liang L Jaegl e D A Jaffe P Weiss-Penzias A Heckman and J A Snow Long-range transport of asian pollution to the northeast Pacifc Seasonal variations and transport pathways of carbon monoxide J 7 


a Tropospheric Infrared Mapping Spectrometer SMLS 4m Velocity Figure 2 LEOMAC conceptual design and characteristics 9 Performance Data Includes Margins g Mass kg 1026 Payload 2284 Observatory Wet Total g Power Avg W 858 Payload 1360 Observatory Total g Data Rate Mbps 14.4 Payload Obit Avg 300 Downlink g Pointing 3cr asec 360 Control 60 Real-Time Knowledge g Lifetime years 2.5 Design 5.0 Goal  Consumables S/C Bus TIMS  TROPI Nadir y Mission Features g Orbit Circular 520 inclination 824 km altitude n Launch Vehicle Atlas V 401 or Delta IV 4040-12 V Ground Stations Polar Svalbard Alaska McMurdo V Science Data Down-linked Per Day 1.43 T bits Figure 1 LEOMAC measurements indicating candidate instruments to provide them SMLS is tzm UK a 92 a a MM I A 8  0 mm gm ro mm f on F-EW-01 I NFIFUMMA a a Scanning Microwave Limb Sounder TROPI is a Tropospheric Pollution Imager TIMS is 


over that of MLS as would be mapped by Aura MLS and by SMLS Among many features evident from SMLS but not from Aura MLS is the thin filament arrow connecting enhanced CO sources to the column of pollution over N America over that of OMI age time since emitted of the tracer CO Sources of pollution from other regions to the N American column to North America from N America from Asia E from Europe 2 days 5 days 10 days 20 days*h g Figure 3 Relative contributions from domestic Asian and European some urban areas e.g B for Brussels in this region of Belgium Holland and Germany Right two panels the improvement in SMLS resolution sources of pollution emission Letters indicate over America to pollution from Asia 100 75 50 25 0 on Aura The improved TROPI resolution allows better identification of the on Aura This example is of are negligible Stohl et al J Geophys Res vol 107 No D23 4684 2002 Figure 4 Left two panels the improvement in TROPI resolution as a function of the a high-resolution model field of upper tropospheric CO 


0 2 4 6 8 10 12 14 x106 1cm2 1lowr trop 1000-700 hPa NO2 co]umn noise level for TROP I is O.1 101 cm2 Figure 5 Daily variation of NO2 pollution over the southeastern U.S on 17 August 2000 Each panel is a map of the lower tropospheric 1000-700 hPa column NO2 abundance at different Atlanta local times throughout the day EPA CMAQ regional model results from Yongtao Hu of Georgia Tech Current and planned satellite instruments that measure NO2 make measurements near mid-day and miss the larger values that occur both earlier and later TROPI on LEOMAC-P will provide the first global measurements of NO2 and other pollutants at multiple times per day and will thus provide needed new information on quantifying the overall magnitude of global pollution events Blue outward-pointing arrows indicate LEOMAC-P TROPI measurement time examples for 17 August and a particular choice of orbit parameters The corresponding solar zenith angles sza are also indicated The TROPI NO2 column measurement noise is _0.Ix0'16 cm-2 CO pollution large crystal ice small crystal ice Figure 6 Upper tropospheric CO pollution and cloud ice averages for 25 Aug through 6 Sep 2004 from Aura LEOMAC will provide such measurements with better resolution multiple times per day and provide additional key measurements such as CO in the lower and middle troposphere 11 


15 E Nat 1X 1 Figure 7 Deposition of boundary layer air into the upper troposphere Model predictions from Figure 5 of Mullendore et al J Geophys Res vol 110 D06113 2005 with crosses added to show the SMLS resolution Color indicates the abundance of a boundary layer tracer at 2 and 10 hours into a convective simulation XE 20.0 LE A G6-P_ _ W 150r CWEvery 36 days Nn N Sl N N NA.TM hea oi or eGboP LOMC Local time rour Figure 8 Diurnal variation of convection where the green curve is for convection over land and the blue is over ocean For 208 K infrared temperature thresholds from Figure 4 of Chen and Houze Q J Roy Met Soc vol 123 pp 357-388 1997 with the temporal samplings of the A-train A and of SMLS on LEOMAC-P P and LEOMAC-S S added Figure 9 Diurnal variation of convection over the southeastern U.S in summer and temporal coverage example for SMLS on LEOMAC-P Each panel shows the Jun-Jul-Aug 1999 average occurrence of strong convection to at least 10 km height at different local times throughout the day from Baijun Tian of JPL and based on GOES 11 m brightness temperatures less than 230 K Red colors for 6 hours per day typical of this region corresponds to 5 inches of rain over Jun-Jul-Aug Dark blue colors indicate essentially no convection Blue outward-pointing arrows indicate LEOMAC-P SMLS measurement time examples for for 17 August and a particular choice of orbit parameters The A-train makes measurements at 1:30 am and 1:30 Dm and misses the evolution and intense convection in late afternoon 12 


DAily SMLS TIROPI TMMS solar 90 243 60 A IIt I  I 1111X   L _~17A Hi FMAMJ ASOND 0.3 1.0 1.5 20 3.0 4.0 5.0 6.0 0 80 9.0 Nunber of observatio  24h Figure 10 Number of observations per each 24 hour period for LEOMAC-P top row and LEOMAC-S bottom row Everywhere in a given color is measured that number of times with lOxIO km horizontal resolution for TROPI TIMS and 50x50 km for SMLS The left three columns show an example for Aug 17 The rightmost column shows the annual variation for the TROPI and TIMS solar measurements where the vertical line is 17 August The number of measurements per 24 hour period for SMLS and TIMS/thermal has only a minor variation throughout the year 1000 km i 100 km 10 km GUobal I Global j Figure 11 Overarching scientific issues that need to be addressed by future atmospheric composition missions and LEOMAC-P LEOMAC-S and GEOMAC horizontal vertical and temporal coverage and resolution For the various measurement objectives L indicates that observations are needed in the lower troposphere U that they are needed in the upper troposphere and S that they are needed in the stratosphere The right end of each horizontal arrow is the required horizontal resolution and the left end is the required coverage The upper end of each vertical arrow is the desired temporal resolution and the lower end is the required resolution 13 


assumes that around 20% of the attribute and text values are different from the template values Table 3 lists results from this experiment. The third column of the table shows the number of bytes transmitted for each sample document, while the 6 th column shows the time used to construct tokens from the compressed document. The table shows that, under above-described setup, the amount of data transmitted are reduced to 2.6% to 15.7% of the original size second column, listed in KB time is reduced to 5.4% to 11.3% of the Nature mode tokenization time, or 11.5% to 25% of the Swift mode tokenization time 5.5 Discussion Since in our implementations, we make changes to base systems \(KXML and XT changes are required to implement Structure Encoding performance differences demonstrated in this section are caused by differences in techniques rather than differences in implementations Our experiments clearly show that Structure Encoding can, potentially, greatly improve the efficiency of XML processing with relatively low penalty for worst cases. The worst case scenario happens when a receiver uses hash function to identify the structure of a document, only to find out that the document structure is not in cache. The penalty it pays for such worst case scenario, 11.1% for DOM-style parsing and 8.9% for transformation, can easily be compensated by future structure recurrence. Such cache-miss penalty is negligible when sender-assigning scheme is used Systems that are conscious of such client-side penalty can let the sender or anyone in the middle of the transmission path to assign ID without altering the semantics of the message or document Although we didn’t measure the impact of compression on parsing and transformation, it can be inferred from tables 2 and 3. For example, in the book case, with tokenization time reduced from 8.6ms Swift mode\s \(compressed\e will likely be further reduced from 8.8ms to around 1.3ms compared with 24.4ms for KDOM\Similarly transformation time may be further reduced from 11.5ms to around 4.0ms \(compared with 48.3ms for XT\Encoding based XML compression offers additi onal, significant performance improvements for XML parsing and transformation in mobile environments, where closelycoupled proxies commonly exists. With compression turned off, Structure Enc oding is fully compatible with Web specifications and can be used between any two Internet hosts, and it still offer very significant performance improvements when there is structure recurrence Without compression, for documents with recurrent structures, tokenization and structure hashing cost dominates the overall cost for parsing, and is the major part of the cost for transformation. Tokenization and structure hashing however are relatively simple operations that may be implemented in hardware with low cost. \(In fact, some mobile chipsets already have hardware implementation of hash functions such as MD5 for security purposes implementation can reduce tokenization and structure hashing cost to a fifth of the current cost, then there will be additional substantial improvement for the parsing and transformation of most of the documents used in our experiments In our system, a document havi ng a structure slightly different \(e.g., added a new element\from a previous structure will not be able to reuse the structure processing result of the previous structure. However our system pays off as long as this new, slightly different structure recurs in future documents 6 CONCLUSION, LIMITATIONS, AND FUTURE WORK In this paper we motivated exploiting structure recurrence to speedup XML processing in mobile environments, by reduci ng structure related transmission and processing costs. We presented the concept of Structure Encoding, and described approaches to quickly identifying recurring structures including one using collision-resistant hash function We explained in detail how to use structure encoding to speedup XML transmission, tokenization, treebuilding, and transformation. We described our implementation of st ructure encoding based tokenizer DOM parser \(based on kXML\processor \(based on XT\pression scheme. Our experiments conducted on a mobile test-bed demonstrated dramatic performance improvement in the presence of structure recurrence and low overhead otherwise. In ideal cases structure encoding offers speedups of up to 7 for parsing and over 38 for XSL transformation, and up to 97.4% in size reduction when 20% of the text and attribute values change Structure encoding, however, is not applicable to all XML applications. Rather, it is more applicable to data-centric XML processing than to document-centric XML processing. A user randomly browsing Web pages is not likely to have high structure recurrence probabilities 
323 


Our current implementa tion does not support documents with “variable-le ngth arrays” – lists of identically structured elements with non-fixed lengths Otherwise identically structured documents with different array lengths are currently considered as having different structure We are currently working on supporting “variablelength arrays” to extend the applicability of Structure Encoding. We are also looking at provide similar, but less aggressive, optimization support for schemaconforming documents REFERENCES  Nokia Web Services – Helping Operators Mobilize the Internet Http://www.projectliberty.org/resources/whitepapers/W S_Operators_A4_0408.pdf  The SAX Project. http://www.saxproject.org  XML Pull Parsing. http://www.xmlpull.org  W3C Document Object Model http://www.w3.org/DOM  WAP Binary XML Content Format http://www.w3.org/TR/wbxml  Efficiency Structured XML. http://www.esxml.org  VTD-XML. http://vtd-xml.sourceforge.net  XSLTC Documentation. http://xml.apache.org/xalanj/xsltc  kXML. http://www.kxml.org  Liefke, H. and D. Suciu. XMill: An Efficient Compressor for XML Data. In Proc. of the ACM SIGMOD Conference on Management of Data. May 2000  Liu, L., C. Pu, and W. Tang. WebCQ: Detecting and Delivering Information Changes on the Web" In the Proceedings of International Conference on Information and Knowledge Management \(CIKM  The XT XSLT processor http://www.blnz.com/xt/index.html  Sarvega,Inc. http://www.sarvega.com  DataPower Technology, Inc http://www.datapower.com  Rax Content Processor http://www.tarari.com/rax/index.html  The Sarvega XSLT Benchmark Study, Sarvega Inc http://www.sarvega.com/xslt-benchmark.php  XSLTMark http://www.datapower.com/xmldev/xsltmark.html  Eisenhauer, G. and L. K. Daley. Fast Heterogenous Binary Data Interchange. In Proceedings of the 9th Heterogeneous Computing Workshop \(HCW 2000 90-101  Bustamente, F., G. Eisenhauer, K.Schwan, and P Widener. Efficient Wire Formats for High Performance Computing. In Proceedings of High Performance Networking and Computing Conference, 2000 SC’2000  Toshiro Takase, Hisashi Miyashita, Toyotaro Suzumura, and Michiaki Tatsubori, An Adaptive, Fast and Safe XML Parser Based on Byte Sequence Memorization. In Proc. of WWW’2005  XML-RPC. http://www.xmlrpc.com  Open  Mobile Alliance http://www.openmobilealliance.org  RSS 2.0 Specification http://blogs.law.harvard.edu/tech/rss  Open Mobile Alliance http://www.openmobilealliance.org  M ogul, J., F. Douglis, A. Feldm an, and B Krishnamurthy. Potential benefits of deltaencoding and compression for HTTP In Proc SIGCOMM’97 1997  Spring, N. T., and D. W e therall. A protocolindependent technique for eliminating redundant network traffic In Proc. SIGCOMM’00 2000  Chiu, K., and W  Lu. A Com piler-Based Approach to Schema-Specific XML Parsing. In First Internati onal Workshop on High Performance XML Processing, May 2004  Matsa, M., E. Perkins, A. Heifets, M. G.aitatzes Kostoulas, D. Silva, N. Mendelsohn, M. Leger. A high-performance interpretive approach to schema-directed parsing. In Proceedings of the 16th International Conference on World Wide Web, 2007  Noga, M  L., Schott, S., and Löwe, W  2002. Lazy  XML processing. In Proceedings of the 2002 ACM Symposium on Document Engineering McLean, Virginia, USA, November 08 - 09 2002\02. ACM, New York, NY  Farfán, F., V. Hristidis and R. Rangaswam i Beyond Lazy XML Parsing. In Proceedings of the 18th International Conference \(DEXA 200 September 3-7, 2007  
324 


 15 Fourier transform spectrometers at the Internationa l Scientific Station of the Jungfraujoch Switzerland  for atmospheric measurements and at the Institute of Astrophysics in Liège for laboratory measurements He was hired by JPL in August 1990 as MkIV cognizant engin eer and participated in all the MkIV campaigns since th en \(one DC-8 campaign 19 balloon campaigns Dr J.-F Bla vier obtained his Ph.D in Physics from the University o f Liège in July 1998 Paula Pingree is a Senior Engineer in the Instruments and Science Data Systems Division at JPL She has been involved in the design integration test and operation of several JPL flight projects most recently Deep Impact DI She has worked on the Tunable Laser Spectrometer development for the 2009 Mars Rover and is presently the Electronics CogE for the Juno Mission s Microwave Radiometer She also enjoys research and technology development for Smart Payloads in her s pare time Paula has a Bachelor of Engineering degree i n Electrical Engineering from Stevens Institute of Te chnology in Hoboken, NJ, and an MSEE degree from California State University Northridge.  She is a member of IEEE 


 16  A High Capacity Solid Sate Recorder \(HC-SSR\is suggested using devices predicated to be available for each decade.   The design is robu st and easily implemented using conservative design and manufacturing techniques D EFINITIONS  rad radiation absorbed dose\:   the dose causing 0.01 joule of energy to be absorbed per kilogram of matter.   As the absorption is greatly affected by the molecular structure of the material, citations should al so indicate the material as a subscript to the term 223rad\224, as in rad Si indicating Silicon equivalency.  For the purposes of this paper, radiation equivalency always assumes Silicon For completeness, it should be noted that System International replaced the \223rad\224 with the unit Gr ay \(Gy\nd having an equivalency of 100 rads = 1 Gy [27 How e v e r   the use of rads, kilorads, megarads remains in the industry vernacular and is used in this document Moore\222s Law Named after Fairchild Semiconductor technologist Gordon Moore, Moore\222s law was derived from empirical data which shows that the dimensions of basic memory cells will shrink by approximately 50% of the previous value every 30 to 36 months.  It is Moore\222s Law more or less, that forms the backbone of the ITRS examinations for memory devices A DDITIONAL M ATERIAL  Standard Dose Rates for Various Orbits and Missions per year Earth    LEO  100 rad \(protons  MEO  100 krad \(protons electrons  GEO  1 krad \(electrons  Transfer Orbit  10 krad \(protons electrons Mars     Surface  2 krad \(electrons  Orbit  5 krad \(protons  Transit  5 krad \(protons Jovian     Transfer  100 Mrad \(protons electrons A CKNOWLEDGEMENT  The research described in this paper was carried out at the Jet Propulsion Laboratory, California Institute of Technology, under a contract with the National Aeronautics and Space Administration.   The Author thanks the many who guided the concept and offered support all along the way.   With special thanks to fellow-JPL\222ers Gary Noreen who provided funding\nd Taher Daud who provided editing ad-hoc extraordinaire  R EFERENCES    G M o o r e C r a m m i ng m o re C o m pone nt s o n t o  Integrated Circuits Electronics vol. 38, no. 8, April 1965 2 G M o ore, "No Expo n e n tial is Forev er: B u t 223Forever\224 Can Be Delayed Digest of Technical Papers, International Solid State Circuits Conference pp. 1.1-1 thru 1.1-19, 2003  S eagate Tec hnology Com p any. Seagate Tec hnical Corporation. [Onlin http://www.seagate.com/docs/pdf/marrketing/Article _Perpendicular_Recording.pdf   B l u R ay Di sc Ass o ci at i on  2 00 5 M a rc h B l u-R a y  Disc Technical Papers  J Vel e v K  D B e l a shche n ko  an d et _al   2 0 0 7  October\ MSREC - University of Nebraska Onlin http://www.mrsec.unl.edu/research/nuggets/nugget_2 6.shtml  6 R Katti, "Honeywell Rad i atio n Hard en ed  No nVolatile Memory \(MRAM\ Product Development in Proceedings, IEEE No n-Volatile Memory Technology Symposium Orlando, 2004, pp. L2:1-15 7 S aif u n  Sem ico n d u c tor  2 008 NV M Techno log y  Over http://www.saifun.com/content.asp?id=113  


 17    J. Ta usc h  S. T y son a n d T T a i r ba nks  Multigenerational Radiation Response Trends in SONOSb ased NROM Flash Memories with Neutron Latch-up Mitigation," in NSREC Radiation Effects Workshop Honolulu, 2007, pp. 189-193 9  Semico n du c to r In du str y A s sociatio n SIA  2 008   August\ Home. [Online  www.itrs.net  1  S. Ty s o n P ri v a t e C o m m uni que Tra n sEl  Semiconductor, Albuquerque, NM, 2008 1  T. M i k o l a ji c k  and C U Pi n n o w  2 00 8 N o vem b er Indo-German Winter Academy, 2008, Course 3 Onlin http://www.leb.eei.unierlangen.de/winterakadem ie/2008/courses/course3_ material/futureMemory/Mikolajick_TheFutureofNV M.pdf   BAE System s North Am erica, [Data Sheet Microcircuit, CMOS, 3.3V, NVRAM 8406746, April 28, 2008, Rev A 1  N Ha dda d a n d T Scot t  A da pt i n g C o m m erci al  Electronics to the Natura lly Occurring Radiation Environment," in IEEE Nuclear and Space Radiation Effects Conference Short Course Tucson, 1994, pp iv-14 1  D. R  R o t h a n d et _al S EU a n d TI D Test i n g of t h e Samsung 128 Mbit and the Toshiba 256 Mbit flash memory," in Radiation Effects Data Workshop  Reno, 2000 1  F. I r o m and D N guy e n  S i n gl e E v ent  Ef fe ct  Characterization of High Density Commercial NAND and NOR Nonvolatile Flash Memories Honolulu, 2007 1  C Ha fer M  L a hey a n d et _al R adi a t i o n H a rd ness  Characterization of a 130nm Technology," in Proceedings IEEE Nuclea r and Space Radiation Effects Conference Honolulu, 2007 17  T. R O l dh am J. Fr iend lich  an d et_ a l, "TID  an d SEE Response of an Advanced Samsung 4Gb NAND Flash Memory," , Honolulu, 2007  R. C. Lac o e C MOS Scaling, Desi gn Princi ples a n d Hardening-by-Design Methodologies," in Nuclear and Space Radiation Effects Conference Short Course Notebook Monterey, 1993, pp. II-1 thru II142 1 J. Pat t e rs o n a n d S  Gue rt i n   E m e rgi ng S E F I M o des and SEE Testing for Highly-Scaled NAND FLASH Devices," in Proceedings 2005 Non-Volatile Memory Technology Symposium vol. CD-ROM, Dallas, TX 2005, pp. G-3, Session G ; Paper 3 2 J. Ta usc h  S. T y son a n d T F a i rba nks  Mulitgenerational Radiation Response Trends in SONOSb ased NROM Flash Memories with Neutron Latch-up Mitigation," in Honolulu Radaition Effects Data Workshop, NSREC, 2007, pp. 189-193 2 M Janai  B Ei t a n A Sha p pi r I B l o o m and G  Cohen, "Data Retention Reliability Model of NROM Nonvolatile Memory Products IEEE Transactions on Device and Materials Reliability vol. 4, no. 3, pp 404-415, September 2004 2 D N g uy en a n d F I r o m Tot al Io ni zi n g  Do se \(T ID  Tests on Non-Volatile Memories: Flash and MRAM," in 2007 IEEE Radiation Effects Workshop  vol. 0, Honolulu, 2007, pp. 194-198  G. Noree n  a n d et_al L ow Cost Deep Space Hybrid Optical/RF Communications Architecture," , Big Sky, Montana, 2009, Pre-print 2 T. Sasa da a n d S. I c hi kawa  A p p l i cat i o n o f  Sol i d  State Recorders to Spacecraft," in Proceedings, 54th International Astronautical Cogress Bremen, 2003 2 H Ka nek o  E rr or C o nt r o l C odi ng f o r  Semiconductor Memory Systems in the Space Radiation Environment," in Proceedings, 20th IEEE International Symposium in Defect and Fault Tolerance in VLSI Systems, DFT2005 Monterey 2005 2 T. Sasa da a n d H Ka nek o  D evel o p m e nt an d Evaluation of Test Circuit for Spotty Byte Error Control Codes," in Proceedings, 57th International 


 18  Astronautical Congress Valencia, 2006 27  Bu reau  In tern atio n a l d e s Po ids et Mesures. \(2 008  August\SI Base Units. [On http://www.bipm.org/en/si/base_units   B IOGRAPHY  Author, Karl Strauss, has been employed by the Jet Propulsion Laboratory for over 22 years.  He has been in the Avionics Section from day One.  He is considered JPL\222s memory technology expert with projects ranging from hand-woven core memory \(for another employer\o high capacity solid state designs.  He managed the development of NASA\222s first Solid State Recorder, a DRAM-based 2 Gb design currently in use by the Cassini mission to Satu rn and the Chandra X-Ray observatory in Earth Orbit.  Karl was the founder, and seven-time chair of the IEEE NonVolatile Memory Technology Symposium, NVMTS, deciding that the various symposia conducted until then were too focused on one technology.  Karl is a Senior IEEE member and is active in the Nuclear and Plasma Scie nce Society, the Electron Device Society and the Aerospace Electronic Systems Society Karl is also an active member of SAE Karl thanks his wonderful wife of 28 years, Janet, for raising a spectacular family: three sons, Justin, Jeremy Jonathan.  Karl\222s passion is trains and is developing a model railroad based upon a four-day rail journey across Australia\222s Northern Outback   


 19 Bollobás, B. 2001. Random Graphs. Cambridge University Press; 2nd edition. 500pp  Cawley, G. C., B. L. C. Talbot, G. J. Janacek, and M. W Peck. 2006. Sparse Bayesian Ke rnel Survival Analysis for Modeling the Growth Domain of Microbial Pathogens  Chiang C. L. 1960. A stochastic study of life tables and its applications: I. Probability distribution of the biometric functions. Biometrics, 16:618-635  Cox,  D. R. 1972. Regression models and life tables J. R Stat. Soc. Ser. B 34:184-220  Cox, D. R. 1975.   Partial likelihood Biometrika 62:269276  Cox, D. R. & D. Oakes. 1984 Analysis of Survival Data  Chapman & Hall. London  Cressie, N. A. 1993 Statistics for Spatial Data John Wiley Sons. 900pp  Duchesne, T. 2005. Regression models for reliability given the usage accumulation history. In "Modern Statistical and Mathematical Methods in Reliability". Edited by A. Wilson N. Limnios, S. Kelly-McNulty Y. Armijo. pp.29-40. World Scientific, New Jersey  Eleuteri, A., R. Tagliaferri, L. Milano, G. Sansone, D D'Agostino, S. De Placido,  M. Laurentiis. 2003.  Survival analysis and neural networks. Proceedings of the International Joint Conference on Neural Networks, Vol. 4 20-24 July 2003 Page\(s\:2631 - 2636  Ellison, E., L. Linger, and M Longstaff. 1997.  Survivable Network Systems: An Emerging Discipline, Carnegie Mellon, SEI, Technical Report CMU/SEI-97-TR-013, 1997  Fleming, T. R. & D. P. Harrington. 1991. Counting process and survival analysis. John Wiley & Sons. 429pp  Graver, J. and M. Sobel 2005. You may rely on the Reliability Polynomial for much more than you might think Communications in Statistics: Theory and Methods  34\(6\1411-1422  Graves, T. and M. Hamada. 2005. Bayesian methods for assessing system reliability: models and computation. In Modern Statistical and Mathematical Methods in Reliability". Edited by A. Wilson, et al. pp.41-53  Grimmett, G. 2006 The Random-Cluster Model Springer  Grimmett, G. 1999 Percolation Springer  Hougaard, P. 2000. Analysis of Multivariate Survival Data Springer. 560pp  Ibrahim, J. G., M. H. Chen and D. Sinha. 2005. Bayesian Survival Analysis.  Springer. 481pp  Jin Z. 2005. Non-proportional semi-parametric regression models for censored data. In "Modern Statistical and Mathematical Methods in Reliability". Edited by A. Wilson N. Limnios, S. Kelly-McNulty, Y. Armijo. pp.279-292 World Scientific  Kalbfleisch, J. D. & R. L. Prentice. 1980 The Statistical Analysis of Failure Time Data John Wiley & Sons.  New York. 1980  Kalbfleisch, J. D. &  R. L. Prentice, 2002. The Statistical Analysis of Failure Time Data.  Wiley-InterScience, 2nd ed 462pp  Lisboa, P. J. G. and H. Wong. 2001. Are neural networks best used to help logistic regression? Proceedings of International Joint Conference on Neural Networks, IJCNN 01. Volume 4, 15-19,  July 2001. Page\(s\:2472 - 2477 vol.4  Kauffman, R. J. and B. Wang. 2002. Duration in the Digital Economy. Proceedings of th e 36th Hawaii International Conference on System Sciences \(HICSS’03\ Jan 2003  Kaplan, E. L. & P.  Meier.  1958.  Nonparametric estimation from incomplete observations J. Amer. Statist. Assoc  53:457-481  Klein, J. P. and P. K. Goel 1992. Survival Analysis: State of the Art.  Kluwer Academic Publishes. 450pp  Klein, J. P. and  M. L Moeschberger. 20 03. Survival analysis techniques for ce nsored and truncated data Springer  Krings, A. and Z. S. Ma. 2006.  "Fault-Models in Wireless Communication: Towards Survivable Ad Hoc Networks MILCOM 2006, Military Communications Conference, 2325 October, 7 pages, 2006  Krings, A. W. 2008.  Survivable Systems.  in Information Assurance: Dependability and Security in Networked Systems Yi Qian, James Joshi, David Tipper, and Prashant Krishnamurthy, Morgan Kaufmann Publishers. \(in press  Lawless, J. F. 1982. Statistical models and methods for lifetime data.  John Wiley & Sons. 579pp  Lawless, J. F. 2003. Statistical models and methods for lifetime data.  John Wiley & Sons. 2nd ed. 630pp  Li, M. and P. Vitanyi. 1997. Introduction to  Kolmogorov Complexity and Its Applications. 2nd ed, Springer  Ma, Z. S. 1997.  Survival analysis and demography of Russian wheat aphid populations.  Ph.D dissertation, 307pp University of Idaho Moscow, Idaho, USA 


 20 Ma, Z. S., and E. J. Bechinski. 2008.  Developmental and Phenological Modeling of Russian Wheat Aphid Annals of Entomological Soc. Am In press  Ma, Z. S. and A. W. Krings. 2008a. The Competing Risks Analysis Approach to Reliability Survivability, and Prognostics and Health Management.  The 2008 IEEEAIAA AeroSpace Conference. BigSky, Montana, March 18, 2008. \(In Press, in the same volume  Ma, Z. S. and A. W. Krings 2008b. Multivariate Survival Analysis \(I\e Shared Frailty Approaches to Reliability and Dependence Modeling. The 2008 IEEE-AIAA AeroSpace Conference. BigSky Montana, March 1-8, 2008 In Press, in the same volume  Ma, Z. S. and A. W. Krings. 2008c. Multivariate Survival Analysis \(II\ Multi-State Models in Biomedicine and Engineering Reliability. 2008 IEEE International Conference on Biomedical Engineering and Informatics BMEI 2008\27th-30th, 2008 Accepted   Mani, R., J. Drew, A. Betz, P. Datta. 1999. Statistics and Data Mining Techniques for Lifetime Value Modeling ACM Conf. on Knowledge Discovery and Data Mining  Mazzuchi, T. A., R Soyer., and R. V Spring. 1989. The proportional hazards model in reliability. IEEE Proceedings of Annual Reliability and Maintainability Symposium pp.252-256  Meeker, W. Q. and L. A. Escobar. 1998. Statistical Methods for Reliability Data. Wiley-Interscience  Munson, J. C. 2003. Software Engineering Measurement Auerbach Publications  Nelson, W. 1969. Hazard plotting for incomplete failure data J. Qual. Tech 1:27-52  Nakagawa, T. 2006.  Shock and Damage Models in Reliability Theory. Springer  Osborn, B. 2005. Leveraging remote diagnostics data for predictive maintenance.   In "Modern Statistical and Mathematical Methods in Reliability". Edited by A. Wilson N. Limnios, S. Kelly-McNulty, Y. Armijo. pp. 353-363  Pena, E. A. and E. H. Slate. 2005. Dynamic modeling in reliability and survival analysis. In "Modern Statistical and Mathematical Methods in Reliability". Edited by A. Wilson N. Limnios, S. Kelly-McNulty, Y. Armijo. pp.55-71  Reineke, D. M., E. A. Pohl, and W. P. Murdock. 1998 Survival analysis and maintenance policies for a series system, with highly censore d data.  1998 Proceedings Annual Reliability and Maintainability Symposium. pp 182-188  Schabenberger, O. and C. A. Gotway. 2005. Statistical Methods for Spatial Data Analysis.  Chapman & Hall/CRC  Severini, T. A. 2000. Likelihood methods in statistics Oxford University Press  Shooman, M. L. 2002. Reliability of Computer Systems and Networks: Fault Tolerance, Analysis and Design. John Wiley and Sons. 551pp  Stillman, R. H. and M. S. Mack isack, B. Sharp, and C. Lee 1995. Case studies in survival analysis of overhead line components. IEE Conferen ce of the Reliability and Distribution Equipment. March 29-31, 1995. Conference Publication No. 406. pp210-215  Therneau, T. and P. Grambsch. 2000 Modeling Survival Data: Extending the Cox Model Springer  Wilson, A.  N. Limnios, S Kelly-McNulty, Y. Armijo 2005. Modern Statistical and Mathematical Methods in Reliability. World Scientific, New Jersey  Xie, M. 1991. Software Reliability Modeling. World Scientific Press    B IOGRAPHY   Zhanshan \(Sam\ Ma holds a Ph.D. in Entomology and is a Ph.D. candidate in Computer Science at the University of Idaho. He has published approximately 30 journal and 30 conference papers, mainly in the former field.  Prior to his recent return to academia, he worked as senior network/software engineers in software industry.  His current research interests include reliability and survivability of wireless sensor networks, fault tolerance survival analysis, evolutionary game theory, evolutionary computation and bioinformatics  Axel W. Krings is a professor of Computer Science at the University of Idaho.  He received his Ph.D. \(1993\ and M.S 1991\ degrees in Computer Science from the University of Nebraska - Lincoln, and his M.S. \(1982\ in Electrical Engineering from the FH-Aachen, Germany.  Dr. Krings has published extensively in the area of Computer Network Survivability, Security, Fault-Tolerance and Realtime Scheduling. In 2004/2005 he was a visiting professor at the Institut d'Informatique et Mathématiques Appliquées de Grenoble, at the Institut National Polytechnique de Grenoble, France.  His work has been funded by DoE/INL DoT/NIATT, DoD/OST and NIST 


States\nWAb-3.4: NEW RESULTS IN THE ANALYSIS OF DECISION-FEEDBACK 2118\nEQUALIZERS\nAhmed Mehana, Samsung Electronics, Co Ltd., United States; Aria Nosratinia, University of Texas at \nDallas, United States\nWAb-5: TARGET TRACKING II\nWAb-5.1: POSTERIOR DISTRIBUTION PREPROCESSING FOR PASSIVE 2125\nDTV RADAR TRACKING: SIMULATED AND REAL DATA\nEvan Hanusa, Laura Vertatschitsch, David Krout, University of Washington, United States\nWAb-5.2: DEPTH-BASED PASSIVE TRACKING OF SUBMERGED SOURCES  ............................................2130\nIN THE DEEP OCEAN USING A VERTICAL LINE ARRAY\nLisa Zurk, John K. Boyle, Jordan Shibley, Portland State University, United States\nWAb-5.3: GENERALIZED LINEAR MINIMUM MEAN-SQUARE ERROR 2133\nESTIMATION WITH APPLICATION TO SPACE-OBJECT TRACKING\nYu Liu, X. Rong Li, Huimin Chen, University of New Orleans, United States\nWAb-5.4: FEATURE-AIDED INITIATION AND TRACKING VIA TREE SEARCH ..........................................2138\nHossein Roufarshbaf Jill Nelson, George Mason University, United States\nxxxiii\nWAb-6: DIRECTION OF ARRIVAL ESTIMATION\nWAb-6.1: A SELF-CALIBRATION TECHNIQUE FOR DIRECTION 2145\nESTIMATION WITH DIVERSELY POLARIZED ARRAYS\nBenjamin Friedlander, University of California, Santa Cruz, United States\nWAb-6.2: CRAMER-RAO PERFORMANCE BOUNDS FOR SIMULTANEOUS  ..............................................2150\nTARGET AND MULTIPATH POSITIONING\nLi Li, Jeff Krolik, Duke University, United States\nWAb-6.3: COPY CORRELATION DIRECTION-OF-ARRIVAL ESTIMATION  .................................................2155\nPERFORMANCE WITH A STOCHASTIC WEIGHT VECTOR\nChrist Richmond, Keith Forsythe, MIT Lincoln Laboratory, United States; Christopher Flynn, Stevens nInstitute of Technology, United States\nWAb-6.4: LOCATING CLOSELY SPACED COHERENT EMITTERS USING 2160\nTDOA TECHNIQUES\nJack Reale, Air Force Research Laboratory / Binghamton University, United States; Lauren Huie, Air \nForce Research Laboratory, United States Mark Fowler, State University of New York at Binghamton, \nUnited States\nWAb-7: ENERGY- AND RELIABILITY-AWARE DESIGN\nWAb-7.1: LOW-ENERGY ARCHITECTURES FOR SUPPORT VECTOR 2167\nMACHINE COMPUTATION\nManohar Ayinala, Keshab K Parhi, University of Minnesota, United States\nWAb-7.2: TRUNCATED MULTIPLIERS THROUGH POWER-GATING FOR 2172\nDEGRADING PRECISION ARITHMETIC\nPietro Albicocco, Gian Carlo Cardarilli, University of Rome Tor Vergata, Italy; Alberto Nannarelli, \nTechnical University of Denmark Denmark; Massimo Petricca, Politecnico di Torino, Italy; Marco Re, \nUniversity of Rome Tor Vergata Italy\nWAb-7.3: A LOGARITHMIC APPROACH TO ENERGY-EFFICIENT GPU 2177\nARITHMETIC FOR MOBILE DEVICES\nMiguel Lastras Behrooz Parhami, University of California, Santa Barbara, United States\nWAb-7.4: ON SEPARABLE ERROR DETECTION FOR ADDITION ..................................................................2181\nMichael Sullivan, Earl Swartzlander, University of Texas at Austin, United States\nWPb-1: PAPERS PRESENTED IN 2012\nWPb-1.1 DYNAMICALLY RECONFIGURABLE AVC DEBLOCKING FILTER  .............................................2189\nWITH POWER AND PERFORMANCE CONSTRAINTS\nYuebing Jiang, Marios Pattichis, University of New Mexico\nxxxiv\n 


on science teams for numerous planetary missions including Magellan, Mars Observer, Mars Global Surveyor and Rosetta. He was the US Project Scientist for the international Mars NetLander mission, for which he was also principal investigator of the Short-Period Seismometer experiment, and is currently the Project Scientist for the Mars Exploration Rovers. He led the Geophysics and Planetary Geology group at JPL from 1993-2005, and is the JPL Discipline Program Manager for Planetary Geosciences. He has held several visiting appointments at the Institut de Physique du Globe de Paris. He has a BS in physics and a PhD in geophysics from the University of Southern California  David Hansen is a member of the technical staff in the Communications Systems and Operations Group at the Jet Propulsion Laboratory. Current work includes the development of the telecom subsystem for the Juno project. David received a B.S. in Electrical Engineering from Cornell University and an M.S. in Electrical Engineering from Stanford University  Robert Miyake is a member of the technical staff in the Mission and Technology Development Group at the Jet Propulsion Laboratory. Current work includes the development of thermal control subsystems for interplanetary flagship missions to Jupiter and Saturn missions to Mars and the Earth Moon, and is the lead Thermal Chair for the Advanced Project Design Team Robert graduated with a B. S. from San Jose State University, with extensive graduate studies at UCLA University of Washington, and University of Santa Clara  Steve Kondos is a consultant to the Structures and Mechanisms group at the Jet Propulsion Laboratory. He currently is generating the mechanical concepts for small Lunar Landers and Lunar Science Instrument packages in support of various Lunar mission initiatives. He also provides conceptual design, mass and cost estimating support for various Team X studies as the lead for the Mechanical Subsystem Chair. Steve is also involved with various other studies and proposals and provides mentoring to several young mechanical and system engineers. He graduated with a B.S. in Mechanical Engineering from the University of California, Davis and has 28 years of experience in the aerospace field ranging from detail part design to system of systems architecture development. He has worked both in industry and in government in defense, intelligence commercial and civil activities that range from ocean and land based systems to airborne and space systems. Steve has received various NASA, Air Force, Department of Defense and other agency awards for his work on such projects as the NASA Solar Array Flight Experiment, Talon Gold, MILSTAR, Iridium, SBIRS, Mars Exploration Rovers ATFLIR, Glory Aerosol Polarimeter System and several Restricted Programs  Paul Timmerman is a senior member of technical staff in the Power Systems Group at the Jet Propulsion Laboratory Twenty-five years of experience in spacecraft design including 22 at JPL, over 250 studies in Team-X, and numerous proposals. Current assignments include a wide variety of planetary mission concepts, covering all targets within the solar system and all mission classes. Paul graduated from Loras College with a B.S. in Chemistry in 1983  Vincent Randolph is a senior engineer in the Advanced Computer Systems and 


the Advanced Computer Systems and Technologies Group at the Jet Propulsion Laboratory. Current work includes generating Command and Data Handling Subsystem conceptual designs for various proposals and Team X.  He also supports Articulation Control and Electronics design activities for the Advanced Mirror Development project. Vincent graduated from the University of California at Berkeley with a B.S. in Electrical Engineering 18  pre></body></html 


i models into time and covariate dependent dynamic counterparts  ii models and reliability analysis in a more realistic manner  iii level  whether or not functional components \(loyal generals diagnose correctly and take proper actions such as fault mask of failed components \(traitors asymmetric  iv survivability analysis. Evolutionary game modeling can derive sustainable or survivable strategies \(mapped from the ESS in EGT such as node failures such as security compromise level modeling in the so-called three-layer survivability analysis developed in Ma \(2008a this article  v offer an integrated architecture that unite reliability survivability, and fault tolerance, and the modeling approaches with survival analysis and evolutionary game theory implement this architecture. Finally, the dynamic hybrid fault models, when utilized to describe the survival of players in EGT, enhance the EGT's flexibility and power in modeling the survival and behaviors of the game players which should also be applicable to other problem domains where EGT is applicable  5. OPERATIONAL LEVEL MODELING AND DECISION-MAKING  5.1. Highlights of the Tactical and Strategic Levels  Let's first summarize what are obtainable at both tactical and strategic levels. The results at both tactical and strategic levels are precisely obtainable either via analytic or simulation optimization. With the term precisely, we mean that there is no need to assign subjective probabilities to UUUR events. This is possible because we try to assess the consequences of UUUR events \(tactical level ESS strategies \(strategic level time prediction of survivability. The following is a list of specific points. I use an assumed Wireless Sensor Network WSN  i of UUUR events: \(a actions which can be treated as censored events; \(b Cont' of Box 4.2 It can be shown that the replicator differential equations are equivalent to the classical population dynamics models such as Logistic differential equation and LotkaVolterra equation \(e.g., Kot 2001 Logistic equation, or the limited per capital growth rate is similar to the change rate of the fitness  xfxfi which can be represented with the hazard function or survivor functions introduced in the previous section on survival analysis.  This essentially connects the previous survival analysis modeling for lifetime and reliability with the EGT modeling. However, EGT provides additional modeling power beyond population dynamics or survival analysis approaches introduced in the previous section. The introduction of evolutionary theory makes the games played by a population evolvable. In other words, each player \(individual 


other words, each player \(individual agent and players interact with each other to evolve an optimized system Box 4.3. Additional Comments on DHF Models  The above introduced EGT models are very general given they are the system of ordinary differential equations. Furthermore, the choice of fitness function f\(x complexity to the differential equation system.  The system can easily be turned into system of nonlinear differential equations. The analytical solution to the models may be unobtainable when nonlinear differential equations are involved and simulation and/or numerical computation are often required  In the EGT modeling, Byzantine generals are the game players, and hybrid fault models are conveniently expressed as the strategies of players; the players may have different failure or communication behaviors Furthermore, players can be further divided into groups or subpopulations to formulate more complex network organizations. In the EGT modeling, reliability can be represented as the payoff \(fitness, the native term in EGT of the game. Because reliability function can be replaced by survivor function, survival analysis is seamlessly integrated into the EGT modeling. That is, let Byzantine generals play evolutionary games and their fitness reliability function  The evolutionary stable strategy \(ESS counterpart of Nash equilibrium in traditional games ESS corresponds to sustainable strategies, which are resistant to both internal mutations \(such as turning into treason generals or nodes such as security compromises represent survivable strategies and survivability in survivability analysis. Therefore, dynamic hybrid fault models, after the extension with EGT modeling, can be used to study both reliability and survivability 13 risks such as competing risks which can be described with CRA; \(c captured with the shard frailty.  We believe that these UUUR events are sufficiently general to capture the major factors/events in reliability, security and survivability whose occurrence probabilities are hard or impossible to obtain  Instead of trying to obtain the probabilities for these events which are infeasible in most occasions, we focus on analyzing the consequences of the events.  With survival analysis, it is possible to analyze the effects of these types of events on survivor functions. In addition, spatial frailty modeling can be utilized to capture the heterogeneity of risks in space, or the spatial distribution of risks \(Ma 2008a d UUUR events introduced previously. These approaches and models that deal with the effects of UUUR events form the core of tactical level modeling  To take advantage of the tactical level modeling approaches it is obviously necessary to stick to the survivor functions or hazard functions models. In other words, survival analysis can deal with UUUR events and offer every features reliability function provides, but reliability function cannot deal with UUUR events although survivor function and reliability function have the exactly same mathematical definition. This is the junction that survival analysis plays critical role in survivability analysis at tactical level. However, we 


recognize that it is infeasible to get a simple metric for survivability similar to reliability with tactical level modeling alone. Actually, up to this point, we are still vague for the measurement of survivability or a metric for survivability. We have not answered the question: what is our metric for survivability? We think that a precise or rigorous definition of survivability at tactical level is not feasible, due to the same reason we cited previously  the inability to determine the probabilities of UUUR events However, we consider it is very helpful to define a work definition for survivability at the tactical level  We therefore define the survivability at tactical level as a metric, Su\(t t function or reliability function with UUUR events considered. In the framework of three-layer survivability analysis, this metric is what we mean with the term survivability. The "metric" per se is not the focus of the three-layer survivability analysis. It is not very informative without the supports from the next two levels  strategic and operational models.  However, it is obvious that this metric sets a foundation to incorporate UUUR effects in the modeling at the next two levels  Due to the inadequacy of tactical level modeling, we proposed the next level approach  strategic level modeling for survivability. As expected, the tactical level is one foundation of strategic level modeling ii objectives: \(a affect survivability which survival analysis alone is not adequate to deal with; \(b survivability at tactical level is necessary but not sufficient for modeling survivability, we need to define what is meant with the term survivability at strategic level  With regard to \(a behaviors or modes which have very different consequences. These failure behaviors can be captured with hybrid fault models. However, the existing hybrid fault models in fault tolerance field are not adequate for applying to survivability analysis. There are two issues involved: one is the lack of real time notion in the constraints for hybrid fault models \(e.g., N&gt;3m+1 for Byzantine Generals problem synthesize the models after the real-time notions are introduced. The solution we proposed for the first issue is the dynamic hybrid fault models, which integrate survivor functions with traditional hybrid fault models. The solution we proposed for the second issue is the introduction of EGT modeling  With regard to \(b modeling our problem at strategic level, EGT modeling is essentially a powerful optimization algorithm.  One of the most important results from EGT modeling is the so-called evolutionary stable strategies \(ESS We map the ESS in EGT to survivable strategies in survivability analysis.   Therefore, at the strategic level, our work definition for survivability refers to the survivable strategies or sustainable strategies in the native term of EGT, which can be quantified with ESS  In addition to integrating dynamic hybrid fault models another advantage for introducing EGT modeling at strategic level is the flexibility for incorporating other node behaviors \(such as cooperative vs. non-cooperative those behaviors specified in standard hybrid fault models, as well as anthropocentric factors such as costs constraints  Without UUUR events, both tactical and strategic level 


Without UUUR events, both tactical and strategic level models default to regular reliability models. This implies that, in the absence of UUUR events, reliable strategies are sustainable or survivable.  This also implies that three-layer survivability analysis defaults to reliability analysis however, the three-layer approach does offer some significant advantages over traditional reliability analysis, as discussed in previous sections. Nevertheless, when UUUR events exist, reliable strategies and survivable strategies are different. This necessitates the next operational level modeling  5.2. Operational Level Modeling and Decision-Making  When UUUR events are involved, we cannot make real time predictions of survivability at tactical and strategic levels This implies that the implementations of survivable 14 strategies need additional measures that we develop in this section.  Box 5.1 explains the ideas involved with possibly the simplest example  Figure 4 is a diagram showing a simplified relationship between action threshold survivability \(TS survivability \(ES view since both TS and ES are multidimensional and dynamic in practice. Therefore, the sole purpose of the diagram is to illustrate the major concepts discussed above The blue curve is the survivability when survivable strategies specified by ESS are implemented at some point before time s.  The system is then guaranteed to hold survivability above ES. In contrary, if no ESS implemented before time s, then the system quickly falls below to the survivable level at around 40 time units  T i m e 0 1 0 2 0 3 0 4 0 5 0 6 0 7 0 8 0 9 0 1 0 0 Su rv iv ab ili ty M et ric S u t 0 . 0 0 . 1 0 . 2 0 . 3 0 . 4 0 . 5 0 . 6 0 . 7 0 . 8 0 . 9 1 . 0 E S S  i s  I m p lm e n t e d N o  E S S  is  I m p lm e n t e d ts E S T S  Figure 4. A Diagram Showing the Relationship Between TS and ES, as well as timing of s and t, with s &lt; t  6. SUMMARY  The previous sections discussed the major building blocks 


The previous sections discussed the major building blocks for the new life-system inspired PHM architecture. This section first identifies a few minor aspects that have not been discussed explicitly but are necessary for the implementation of the architecture, and then we summarize the major building blocks in a diagram  6.1. Missing Components and Links  Optimization Objectives  Lifetime, reliability, fault tolerance, and survivability, especially the latter two, are application dependent. Generally, the optimization of reliability and survivability are consistent; in that maximization of reliability also implies maximization of survivability. However, when application detail is considered, optimization of lifetime is not necessarily consistent with the optimization of reliability. Consider the case of the monitoring sensor network as an example. The network reliability is also dependent on connectivity coverage, etc, besides network lifetime. What may be further complicated is the time factor. All of the network metrics are time-dependent. A paradoxical situation between lifetime and reliability could be that nodes never 'sleep                                                   


          Box 5.1 Operational Level Modeling  Assuming that the ESS solution for a monitoring sensor network can be expressed with the following simple algebraic conditions: survivability metric at tactical level SU = 0.7, Router-Nodes in the WSN &gt; 10%, Selfish Nodes &lt; 40%. Even with this extremely simplified scenario, the ESS strategies cannot be implemented because we do not know when the actions should be taken to warrant a sustainable system.  These conditions lack a correlation with real time  The inability to implement ESS is rooted in our inability to assign definite probabilities to UUUR events, which implies that we cannot predict when something sufficiently bad will jeopardize the system survivability What we need at the operational level is a scheme to ensure ESS strategy is in place in advance  The fundamental idea we use to implement the ESS strategy is to hedge against the UUUR events. The similar idea has been used in financial engineering and also in integrated pest management in entomology. This can be implemented with the following scheme  Let us define a pair of survivability metrics: one is the expected survivability \(ES threshold survivability or simply threshold survivability \(TS ES is equivalent to the survivability metric at tactical level. ES corresponds to ESS at strategic level, but they are not equivalent since ESS is strategy and ES is survivability. TS is the survivability metric value \(at tactical level and TS can be obtained from strategic level models. For example, TS = SU\(s t condition for the implementation of ESS. In other words, the implementation of strategies that ensures TS at time s will guarantee the future ES level at time t.  To make the implementation more reliable and convenient multiple dynamic TSs can be computed at time s1, s2 sk, with si &lt; t for all i.  These TS at times s1, s2, ..., sk should be monitored by some evaluation systems  Unlike tactical and strategic levels, the operational level modeling is approximate. The term "approximate means that we cannot predict the real time survivability or we do not know the exact time an action should be taken. Instead, the action is triggered when the monitored survivability metric SU\(r survivability \(TS scheme of TS and ES, we ensure the ES by taking preventative actions \(prescribed by ESS and triggered by the TS consequences of UUUR events  Figure 4 is a diagram showing the above concepts and the decision-making process involved 15 This wakefulness \(never 'sleep short period but at the expense of network lifetime. Of course, when the network is running out of lifetime, network reliability ultimately crashes. This example reminds us that 


reliability ultimately crashes. This example reminds us that multi-objective optimization should be the norm rather than exception  Constraints and Extensions  Many application specific factors and constraints are ignored in this article. For example, we mentioned about spatial heterogeneity of environment, but never present a mathematical description The spatial heterogeneity can be modeled with the so-called spatial frailty in multivariate survival analysis \(Ma 2008a  Evolutionary Algorithm  Evolutionary game modeling when implemented in simulation, can be conveniently implemented with an algorithm similar to Genetic Algorithms \(GA ESS in the evolutionary game model with simulation is very similar to GA. Dynamic populations, in which population size varies from generation to generation \(Ma &amp; Krings 2008f of node failures. Another issue to be addressed is the synchronous vs. asynchronous updating when topology is considered in the simulation. This update scheme can have profound influences on the results of the simulation. Results from cellular automata computing should be very useful for getting insights on the update issue  6.2. Summary and Perspective  To recapture the major points of the article, let us revisit Figure 3, which summarizes the principal modules of the proposed life-system inspired PHM architecture. The main inspiration from life systems is the notion of individuals and their assemblage, the population. Population is an emergent entity at the next level and it has emergent properties which we are often more concerned with. Survival analysis, which has become a de facto standard in biomedicine, is particularly suitable for modeling population, although it is equally appropriate at individual level. Therefore, survival analysis \(including competing risks analysis and multivariate survival analysis comprehensively in the context of PHM in a series of four papers presented at IEEE AeroSpace 2008 \(Ma &amp; Krings 2008a, b, c, &amp; d proposed architecture. Survival analysis constitutes the major mathematical tools for analyzing lifetime and reliability, and also forms the tactical level of the three-layer survivability analysis  Besides lifetime and reliability, two other major modules in Figure 3 are fault tolerance and survivability. To integrate fault tolerance into the PHM system, Dynamic Hybrid Fault DHF 2008e, Ma 2008a make real-time prediction of reliability more realistic and make real-time prediction of fault tolerance level possible DHF models also unite lifetime, reliability and fault tolerance under a unified modeling framework that consists of survival analysis and evolutionary game theory modeling  DHG models also form the partial foundation, or strategic level, for the three-layer survivability analysis. At the strategic level, the Evolutionary Stable Strategies \(ESS which is mapped to survivable or sustainable strategies, can be obtained from the evolutionary game theory based DHF models. When there is not any UUUR event involved reliability and survivability are consistent, and reliable strategies are survivable. In this case, the strategic level modeling up to this point is sufficient for the whole PHM system modeling, and there is no need for the next level  operational level modeling  When there are UUUR events in a PHM system, the 


When there are UUUR events in a PHM system, the inability to determine the occurrence probabilities of UUUR events makes the operational level modeling necessary Then the principle of hedging must be utilized to deal with the "hanging" uncertainty from UUUR events. In this case reliability strategies are not necessarily survivable strategies At the operational level modeling, a duo of survivability metrics, expected survivability \(ES survivability \(TS the survivable strategies \(ESS level are promptly implemented based on the decisionmaking rules specified with the duo of survivability metrics then the PHM system should be able to endure the consequences of potentially catastrophic UUUR events. Of course, to endure such catastrophic events, the cost may be prohibitively high, but the PHM system will, at least, warn decision-makers for the potentially huge costs.  It might be cheap to just let it fail  Figure 3 also shows several other modules, such as security safety, application systems \(such as Automatic Logistics CBM+, RCM, Life cycle cost management, Real-time warning and alert systems architectures, but we do not discuss in this paper. Generally the new architecture should be fully compatible with existing ones in incorporating these additional modules. One point we stressed is that PHM system can be an ideal place to enforce security policies. Enforcing security policies can be mandatory for PHM systems that demand high security and safety such as weapon systems or nuclear plant facilities.  This is because maintenance, even without human-initiated security breaches, can break the security policies if the maintenance is not planned and performed properly  In perspective, although I did not discuss software issues in this paper, the introduced approaches and models should provide sufficient tools for modeling software reliability and survivability with some additional extension. Given the critical importance of software to modern PHM systems, we present the following discussion on the potential extension to software domain. Specifically, two points should be noted: \(1 architecture to software should be a metric which can 16 replace the time notion in software reliability; I suggest that the Kolmogorov complexity \(e.g., Li and Vitanyi 1997 be a promising candidate \(Ma 2008a change is because software does not wear and calendar time for software reliability usually does not make much sense 2 software reliability modeling.  Extending to general survivability analysis is not a problem either. In this article I implicitly assume that reliability and survivability are positively correlated, or reliability is the foundation of survivability. This positive correlation does not have to be the case. A simplified example that illustrates this point is the 'limit order' in online stock trading, in which limit order can be used in either direction: that stock price is rising or falling.  The solution to allow negative or uncorrelated relationships between reliability and survivability are very straightforward, and the solutions are already identified in previous discussions. Specifically, multiple G-functions and multi-stage G-functions by Vincent and Brown \(2005 very feasible solution, because lifetime, reliability and survivability may simply be represented with multiple Gfunctions. Another potential solution is the accommodation of the potential conflicts between reliability and survivability with multi-objective GA algorithms, which I previously suggested to be used as updating algorithms in the optimization of evolutionary games  


 The integration of dynamic hybrid fault models with evolutionary game modeling allows one to incorporate more realistic and detailed failure \(or survival individual players in an evolutionary game. This is because dynamic hybrid fault models are supported by survival analysis modeling, e.g., time and covariate dependent hazard or survivor functions for individual players. If necessary, more complex survival analysis modeling including competing risks analysis and multivariate survival analysis, can be introduced.  Therefore, any field to which evolutionary game theory is applicable may benefit from the increased flexibility in modeling individual players.  Two particularly interesting fields are system biology and ecological modeling.  In the former field, dynamic hybrid fault models may find important applications in the study of biological networks \(such as gene, molecular, and cell networks 2008g conjecture that explains the redundancy in the universal genetic code with Byzantine general algorithm. In addition they conducted a comparative analysis of bio-robustness with engineering fault tolerance, for example, the strong similarity between network survivability and ecological stability \(Ma &amp; Krings 2008g survivability analysis can be applied for the study of survivals or extinctions of biological species under global climate changes \(Ma 2008b  In this paper, I have to ignore much of the details related to the implementation issues to present the overall architecture and major approaches clearly and concisely. To deal with the potential devils in the implementation details, a well funded research and development team is necessary to take advantages of the ideas presented here. On the positive side I do see the great potential to build an enterprise PHM software product if there is sufficient resource to complete the implementation. Given the enormous complexity associated with the PHM practice in modern engineering fields, it is nearly impossible to realize or even demonstrate the benefits of the architecture without the software implementation. The critical importance of PHM to mission critical engineering fields such as aerospace engineering, in turn, dictates the great value of such kind software product  6.3. Beyond PHM  Finally, I would like to raise two questions that may be interested in by researchers and engineers beyond PHM community. The first question is: what can PHM offer to other engineering disciplines? The second question is: what kinds of engineering fields benefit most from PHM? Here, I use the term PHM with the definition proposed by IEEE which is quoted in the introduction section of the paper  As to the first question, I suggest software engineering and survivability analysis are two fields where PHM can play significant roles. With software engineering, I refer to applying PHM principles and approaches for dealing with software reliability, quality assurance, and even software process management, rather than building PHM software mentioned in the previous subsection. For survivability analysis, borrowing the procedures and practices of PHM should be particularly helpful for expanding its role beyond its originating domain \(network systems that control critical national infrastructures is a strong advocate for the expansion of survivability analysis to PHM. Therefore, the interaction between PHM and survivability analysis should be bidirectional. Indeed, I see the close relationships between PHM, software engineering, and survivability as well-justified because they all share some critical issues including reliability survivability, security, and dependability  


 The answer to the second question is much more elusive and I cannot present a full answer without comparative analysis of several engineering fields where PHM has been actively practiced. Of course, it is obvious that fields which demand mission critical reliability and dependability also demand better PHM solutions. One additional observation I would like to make is that PHM seems to play more crucial roles for engineering practices that depend on the systematic records of 'historical' data, such as reliability data in airplane engine manufacturing, rather than on the information from ad hoc events.  This may explain the critical importance of PHM in aerospace engineering particularly in commercial airplane design and manufacturing.  For example, comparing the tasks to design and build a space shuttle vs. to design and manufacture commercial jumbo jets, PHM should be more critical in the latter task  17    Figure 2. States of a monitoring sensor node and its failure modes \(after Ma &amp; Krings 2008e     Figure 3. Core Modules and their Relationships of the Life System Inspired PHM Architecture    REFERENCES  Adamides, E. D., Y. A. Stamboulis, A. G. Varelis. 2004 Model-Based Assessment of Military Aircraft Engine Maintenance Systems Model-Based Assessment of Military Aircraft Engine Maintenance Systems. Journal of the Operational Research Society, Vol. 55, No. 9:957-967  Anderson, R. 2001. Security Engineering. Wiley  Anderson, R. 2008. Security Engineering. 2nd ed. Wiley  Bird, J. W., Hess, A. 2007.   Propulsion System Prognostics R&amp;D Through the Technical Cooperation Program Aerospace Conference, 2007 IEEE, 3-10 March 2007, 8pp  Bock, J. R., Brotherton, T., W., Gass, D. 2005. Ontogenetic reasoning system for autonomic logistics. Aerospace Conference, 2005 IEEE 5-12 March 2005.Digital Object Identifier 10.1109/AERO.2005.1559677  Brotherton, T., P. Grabill, D. Wroblewski, R. Friend, B Sotomayer, and J. Berry. 2002. A Testbed for Data Fusion for Engine Diagnostics and Prognostics. Proceedings of the 2002 IEEE Aerospace Conference  Brotherton, T.; Grabill, P.; Friend, R.; Sotomayer, B.; Berry J. 2003. A testbed for data fusion for helicopter diagnostics and prognostics. Aerospace Conference, 2003. Proceedings 2003 IEEE  Brown, E. R., N. N. McCollom, E-E. Moore, A. Hess. 2007 Prognostics and Health Management A Data-Driven Approach to Supporting the F-35 Lightning II. 2007 IEEE AeroSpace Conference  Byington, C.S.; Watson, M.J.; Bharadwaj, S.P. 2008 Automated Health Management for Gas Turbine Engine Accessory System Components. Aerospace Conference 2008 IEEE, DOI:10.1109/AERO.2008.4526610 


2008 IEEE, DOI:10.1109/AERO.2008.4526610 Environment Covariates &amp; Spatial Frailty Applications: AL; Life Cycle Mgmt; Real-Time Alerts CBM+, RCM, TLCSM; Secret Sharing and Shared Control 18 Chen, Y. Q., S. Cheng. 2005. Semi-parametric regression analysis of mean residual life with censored survival data Biometrika \(2005  29  Commenges, D. 1999. Multi-state models in Epidemiology Lifetime Data Analysis. 5:315-327  Cook, J. 2004. Contrasting Approaches to the Validation of Helicopter HUMS  A Military User  s Perspective Aerospace Conference, 2004 IEEE  Cook, J. 2007. Reducing Military Helicopter Maintenance Through Prognostics. Aerospace Conference, 2007 IEEE Digital Object Identifier 10.1109/AERO.2007.352830  Cox, D. R. 1972. Regression models and life tables.  J. R Stat. Soc. Ser. B. 34:184-220  Crowder, M. J.  2001. Classical Competing Risks. Chapman amp; Hall. 200pp  David, H. A. &amp; M. L. Moeschberger. 1978. The theory of competing risks. Macmillan Publishing, 103pp  Ellison, E., L. Linger, and M. Longstaff. 1997.  Survivable Network Systems: An Emerging Discipline, Carnegie Mellon, SEI, Technical Report CMU/SEI-97-TR-013  Hanski, I. 1999. Metapopulation Ecology. Oxford University Press  Hallam, T. G. and S. A. Levin. 1986. Mathematical Ecology. Biomathematics. Volume 17. Springer. 457pp  Hess, A., Fila, L. 2002.  The Joint Strike Fighter \(JSF concept: Potential impact on aging aircraft problems Aerospace Conference Proceedings, 2002. IEEE. Digital Object Identifier: 10.1109/AERO.2002.1036144  Hess, A., Calvello, G., T. Dabney. 2004. PHM a Key Enabler for the JSF Autonomic Logistics Support Concept. Aerospace Conference Proceedings, 2004. IEEE  Hofbauer, J. and K. Sigmund. 1998. Evolutionary Games and Population Dynamics. Cambridge University Press 323pp  Hougaard, P. 2000. Analysis of Multivariate Survival Data Springer. 560pp  Huzurbazar, A. V. 2006. Flow-graph model for multi-state time-to-event data. Wiley InterScience  Ibrahim, J. G., M. H. Chen and D. Sinha. 2005. Bayesian Survival Analysis. Springer. 481pp  Kacprzynski, G. J., Roemer, M. J., Hess, A. J. 2002. Health management system design: Development, simulation and cost/benefit optimization. IEEE Aerospace Conference Proceedings, 2002. DOI:10.1109/AERO.2002.1036148  Kalbfleisch, J. D., and R. L. Prentice, 2002. The Statistical Analysis of Failure Time Data. Wiley-InterScience, 2nd ed  Kalgren, P. W., Byington, C. S.   Roemer, M. J.  2006 Defining PHM, A Lexical Evolution of Maintenance and Logistics. Systems Readiness Technology Conference 


Logistics. Systems Readiness Technology Conference IEEE. DOI: 10.1109/AUTEST.2006.283685  Keller, K.; Baldwin, A.; Ofsthun, S.; Swearingen, K.; Vian J.; Wilmering, T.; Williams, Z. 2007. Health Management Engineering Environment and Open Integration Platform Aerospace Conference, 2007 IEEE, Digital Object Identifier 10.1109/AERO.2007.352919  Keller, K.; Sheahan, J.; Roach, J.; Casey, L.; Davis, G Flynn, F.; Perkinson, J.; Prestero, M. 2008. Power Conversion Prognostic Controller Implementation for Aeronautical Motor Drives. Aerospace Conference, 2008 IEEE. DOI:10.1109/AERO.2008.4526630  Klein, J. P. and M. L. Moeschberger. 2003. Survival analysis techniques for censored and truncated data Springer  Kingsland, S. E. 1995. Modeling Nature: Episodes in the History of Population Ecology. 2nd ed., University of Chicago Press, 315pp  Kot, M. 2001. Elements of Mathematical Ecology Cambridge University Press. 453pp  Krings, A. W. and Z. S. Ma. 2006. Fault-Models in Wireless Communication: Towards Survivable Ad Hoc Networks Military Communications Conference, 23-25 October, 7 pages, 2006  Lamport, L., R. Shostak and M. Pease. 1982. The Byzantine Generals Problem. ACM Transactions on Programming Languages and Systems, 4\(3  Lawless, J. F. 2003. Statistical models and methods for lifetime data. John Wiley &amp; Sons. 2nd ed  Line, J. K., Iyer, A. 2007. Electronic Prognostics Through Advanced Modeling Techniques. Aerospace Conference 2007 IEEE. DOI:10.1109/AERO.2007.352906  Lisnianski, A., Levitin, G. 2003. Multi-State System Reliability: Assessment, Optimization and Applications World Scientific  Liu, Y., and K. S. Trivedi. 2006. Survivability Quantification: The Analytical Modeling Approach, Int. J of Performability Engineering, Vol. 2, No 1, pp. 29-44  19 Luchinsky, D.G.; Osipov, V.V.; Smelyanskiy, V.N Timucin, D.A.; Uckun, S. 2008. Model Based IVHM System for the Solid Rocket Booster. Aerospace Conference, 2008 IEEE.DOI:10.1109/AERO.2008.4526644  Lynch, N. 1997. Distributed Algorithms. Morgan Kaufmann Press  Ma, Z. S. 1997. Demography and survival analysis of Russian wheat aphid. Ph.D. dissertation, Univ. of Idaho 306pp  Ma, Z. S. 2008a. New Approaches to Reliability and Survivability with Survival Analysis, Dynamic Hybrid Fault Models, and Evolutionary  Game Theory. Ph.D. dissertation Univ. of Idaho. 177pp  Ma, Z. S. 2008b. Survivability Analysis of Biological Species under Global Climate Changes: A New Distributed and Agent-based Simulation Architecture with Survival Analysis and Evolutionary Game Theory. The Sixth 


International Conference on Ecological Informatics. Dec 25, 2008. Cancun, Mexico  Ma, Z. S. and E. J. Bechinski. 2008. A Survival-Analysis based  Simulation Model for Russian Wheat Aphid Population Dynamics. Ecological Modeling, 216\(2 332  Ma, Z. S. and A. W. Krings. 2008a.  Survival Analysis Approach to Reliability Analysis and Prognostics and Health Management \(PHM  AIAA AeroSpace Conference, March 1-8, 2008, Big Sky, MT, 20pp  Ma, Z. S. and A. W. Krings. 2008b. Competing Risks Analysis of Reliability, Survivability, and Prognostics and Health Management \(PHM  AIAA AeroSpace Conference, March 1-8, 2008.  Big Sky, MT. 20pp  Ma, Z. S. and A. W. Krings. 2008c. Multivariate Survival Analysis \(I Dependence Modeling", Proc. IEEE  AIAA AeroSpace Conference, March 1-8, 2008, Big Sky, MT. 21pp  Ma, Z. S. and A. W. Krings., R. E. Hiromoto. 2008d Multivariate Survival Analysis \(II State Models in Biomedicine and Engineering Reliability IEEE International Conference of Biomedical Engineering and Informatics, BMEI 2008.  6 Pages  Ma, Z. S. and A. W. Krings. 2008e. Dynamic Hybrid Fault Models and their Applications to Wireless Sensor Networks WSNs Modeling, Analysis and Simulation of Wireless and Mobile Systems. \(ACM MSWiM 2008 Vancouver, Canada  Ma, Z. S. &amp; A. W. Krings. 2008f. Dynamic Populations in Genetic Algorithms. SIGAPP, the 23rd Annual ACM Symposium on Applied Computing, Ceara, Brazil, March 16-20, 2008. 5 Pages  Ma, Z. S. &amp; A. W. Krings. 2008g. Bio-Robustness and Fault Tolerance: A New Perspective on Reliable, Survivable and Evolvable Network Systems, Proc. IEEE  AIAA AeroSpace Conference, March 1-8, Big Sky, MT, 2008. 20 Pages  Ma, Z. S.  and A. W. Krings. 2009. Insect Sensory Systems Inspired Computing and Communications.  Ad Hoc Networks 7\(4  MacConnell, J.H. 2008. Structural Health Management and Structural Design: An Unbridgeable Gap? 2008 IEEE Aerospace Conference, DOI:10.1109/AERO.2008.4526613  MacConnell, J.H. 2007. ISHM &amp; Design: A review of the benefits of the ideal ISHM system. Aerospace Conference 2007 IEEE. DOI:10.1109/AERO.2007.352834  Marshall A. W., I. Olkin. 1967. A Multivariate Exponential Distribution. Journal of the American Statistical Association, 62\(317 Mar., 1967  Martinussen, T. and T. H. Scheike. 2006. Dynamic Regression Models for Survival Data. Springer. 466pp  Mazzuchi, T. A., R. Soyer., and R. V. Spring. 1989. The proportional hazards model in reliability. IEEE Proceedings of Annual Reliability and Maintainability Symposium pp.252-256  Millar, R.C., Mazzuchi, T.A. &amp; Sarkani, S., 2007. A Survey of Advanced Methods for Analysis and Modeling of 


of Advanced Methods for Analysis and Modeling of Propulsion System", GT2007-27218, ASME Turbo Expo 2007, May 14-17, Montreal, Canada  Millar, Richard C., "Non-parametric Analysis of a Complex Propulsion System Data Base", Ph.D. Dissertation, George Washington University, June 2007  Millar, R. C. 2007. A Systems Engineering Approach to PHM for Military Aircraft Propulsion Systems. Aerospace Conference, 2007 IEEE. DOI:10.1109/AERO.2007.352840  Millar, R. C. 2008.  The Role of Reliability Data Bases in Deploying CBM+, RCM and PHM with TLCSM Aerospace Conference, 2008 IEEE, 1-8 March 2008. Digital Object Identifier: 10.1109/AERO.2008.4526633  Nowak, M. 2006. Evolutionary Dynamics: Exploring the Equations of Life. Harvard University Press. 363pp  Oakes, D. &amp; Dasu, T. 1990. A note on residual life Biometrika 77, 409  10  Pintilie, M. 2006. Competing Risks: A Practical Perspective.  Wiley. 224pp  20 Smith, M. J., C. S. Byington. 2006. Layered Classification for Improved Diagnostic Isolation in Drivetrain Components. 2006 IEEE AeroSpace Conference  Therneau, T. and P. Grambsch. 2000. Modeling Survival Data: Extending the Cox Model. Springer  Vincent, T. L. and J. L. Brown. 2005. Evolutionary Game Theory, Natural Selection and Darwinian Dynamics Cambridge University Press. 382pp  Wang. J., T. Yu, W. Wang. 2008. Research on Prognostic Health Management \(PHM on Flight Data. 2008 Int. Conf. on Condition Monitoring and Diagnosis, Beijing, China, April 21-24, 2008. 5pp  Zhang, S., R. Kang, X. He, and M. G. Pecht. 2008. China  s Efforts in Prognostics and Health Management. IEEE Trans. on Components and Packaging Technologies 31\(2             BIOGRAPHY  Zhanshan \(Sam scientist and earned the terminal degrees in both fields in 1997 and 2008, respectively. He has published more than 60 peer-refereed journal and conference papers, among which approximately 40 are journal papers and more than a third are in computer science.  Prior to his recent return to academia, he worked as senior network/software engineers in semiconductor and software industry. His current research interests include: reliability, dependability and fault tolerance of distributed and software systems behavioral and cognitive ecology inspired pervasive and 


behavioral and cognitive ecology inspired pervasive and resilient computing; evolutionary &amp; rendezvous search games; evolutionary computation &amp; machine learning bioinformatics &amp; ecoinformatics                 pre></body></html 


