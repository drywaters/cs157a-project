c 015 2008 The Institution of Engineering and Technology Printed and published by the IET Michael Faraday House Six Hills Way Stevenage Herts SG1 2AY 426 VIE 08 


427 


428 


429 


430 


431 


TABLE III R ESULTS OF THE FIRST STAGE OF THE EVALUATION PROCESS  T HE REPORTED ARE THE MEDIAN OVER 10 RUNS    Entry  Ruudskogen  Street-1  Speedway     Kinnaird-Heether et al  6716.7  3692.9  14406.9    Lucas  4134.2  5502.8  12664.5    Simmerson  5934.0  6477.8  12523.3    Perez et al  3786.9  2984.8  317.3    Tan et al  3443.5  2998-5  10648.2     C Sample Controller  4465.1  4928.8  7464.5    Java Sample Controller  5593.8  2963.2  5689.9   behaved in a reasonable way only with the exception of some speci\002c circuits the oval ones These circuits similar to Nascar tracks have banked curves which make the zig-zag movement completely uncontrollable E Chin Hiong Tan and Kay Chen Tan The entry submitted by Chin Hiong Tan and Kay Chen Tan was developed in a three-step process First the sensory information was aggregated and preprocessed second a parametrized controller based on simple rules was designed 002nally the parameters of controller were optimized using evolution strategies The resulting controller drives in the direction where the range\002nder sensors indicate the largest free distance with a speed dependent on that distance IV R ESULTS The entries were scored through a two stages process which involved three tracks available in TORCS the Ruudskogen the Street-1 and the D-Speedway The 002rst warm up stage was aimed at eliminating particularly bad performing controllers Each controller raced alone in each of the three tracks and its performance was measured as the distance covered in 10000 game tics approximately 200 seconds of actual game time For each of the three selected tracks we run each controller ten times The performance has been computed as the median the 50th percentile over the ten runs to avoid any issue about skewness Table III compares the performance of the 002ve controllers submitted to the one of the two sample programmed controllers provided by the organizers The results show that the controller submitted by Leonard Kinnaird-Heether and Robert Reynolds outperforms the other controllers in all the tracks but the Street-1 track As can be noted the performances of the controllers are highly different among the three tracks but they generally compare well to the performances of the sample controllers provided by the organizers In particular the entries submitted respectively by Leonard Kinnaird-Heether et al by Simon Lucas and by Matt Simmerson the 002rst three controllers reported in Table III performs consistently better than the sample controllers almost in all the three tracks As all the 002ve submitted controllers performed well on the 002rst stage none of them was eliminated from the second stage in which the controllers competed together in each of the three tracks In this stage the task consisted of completing three laps and each controller was scored based on its arrival order TABLE IV R ESULTS OF THE SECOND STAGE OF THE EVALUATION PROCESS  T HE SCORES REPORTED ARE THE MEDIAN OVER 10 RUNS    Entry  Ruudskogen  Street-1  Speedway  Total     Simmerson  10  10  6  26    Kinnaird-Heether et al  4  8  10  22    Lucas  6  6  8  20    Tan et al  5  5  5  15    Perez et al  5.5  4.5  5  14   using the same point system used in F1 10 points to the 002rst controller that completed the three laps 8 points to the second one 6 to the third one 5 to the fourth and 4 to the 002fth one Ten runs for each track were performed using as start grid a random permutation of the competitors in order to test the reliability of the controllers performance Then the score of a controller on one track was computed as the median of the scores obtained during the ten runs The 002nal score for each controller was 002nally computed as the sum of the points collected on each track Table IV shows the 002nal scoreboard Matt Simmerson won the competition with 26 points followed by Leonard Kinnaird-Heether et al with 22 points by Simon Lucas with 20 points by Tan Chin Hiong with 15 points and 002nally by Diego P 264 erez 14 points This results suggest that although the controllers submitted by Kinnaird-Heether and Reynolds is fast the one submitted by Simmerson is more reliable especially in the presence of other controllers Finally it is worthwhile to underline that the second stage of the evaluation process suggested that all the submitted controllers have poor overtaking and obstacle-avoidance capabilities whereas these features are very important to succeed in a racing competition Additional results and a video with the highlights of the competition are available on the webpage of the competition The reason Simmerson's controller won over KinnairdHeether and Reynold's was probably that the latter had been optimized for racing on tracks with smooth curves in the presence of other cars Simmerson's controller had been trained on the 223G3\224 track that included sharp turns like Ruudskogen but on its own Both of these controllers were optimized with stochastic algorithms and it stands to reason that such approaches outperform the hand-tuning used by Lucas V T HE FUTURE OF THE CAR RACING COMPETITION While this competition differed greatly from the competitions organized during 2007 in that a more sophisticated racing game was used there was also a great deal of continuity Not only in that some of the participants of the 2007 competitions also participated in the current competition but also in the similarity of rules and arrangements The organizers believe that this continuity is very important for the competition to be successful We need a high participation level to ensure that a broad spectrum of approaches are represented and regular repetitions of the competition to ensure that the participants have time 


to perfect their approaches Our aim is to ensure further continuity through holding a series of future competitions using gradual re\002nements of the rules and software used in the current competition The following improvement will be made to the software in time for the CIG competition 017 The installation process will be streamlined 017 Reliability will be improved 017 Support for multi-car and multi-track training will be added making it easier to apply co-evolution and incremental evolution 017 More sample controllers and trainers e.g temporal difference learning trainers will be supplied An amusing illustration of the need to improve reliability is that in an early version of the software it was possible to achieve the 002tness value of driving a whole lap simply by slowly driving up to and passing the start line the car starts 100 meters before that line then turning and passing the line again This 003aw is inherent in TORCS presumably because its developers never thought of anyone doing something so bizarre Evolutionary algorithms however are good at coming up with bizarre solutions and Matt Simmerson's algorithm quickly evolved a controller that exploited this bug A patch for this bug is now part of the software package A reviewer of the paper summarizing the previous car racing competitions pointed out that in its current form the competition is not only about learning algorithms It is certainly possible to hand-code a non-learning controller that outperforms the best CI-based controllers Indeed the best controllers that come with the TORCS game developed by the TORCS developers are non-learning and by far outperform all the controllers submitted to this competition so far though they often access information state information that is not directly available through the competition API Of course we hope that future editions of this competition will see CI-based contributions that perform better than the best hand-coded ones and there are no reasons why this should not happen Still it would be interesting to run a version of the competition that compared only the quality of the learning algorithm One way could be to de\002ne a standard e.g neural network-based controller architecture and then provide an interface for a learning algorithm to set the parameters for this controller optimally given a certain numbers of laps around an unknown track The participants would then submit an algorithm rather than a controller to be run and evaluated by the organizers of the competition Another interesting version of the competition would be one where the controllers where presented with a richer but more primitive state description in particular visual data This could come in the form of the full rendered 3D view through the controlled car's windscreen or a part of it Such a state description would ultimately give the controllers more information and thus allow for better driving but would also require more complex controllers Given the various interesting variations on the car racing concept that are possible our plan is to organize editions of the car racing competition in conjunction with several international conferences and at each conference hold both the competition in its original form and some variation on the concept like the ones suggested above VI C ONCLUSION We have described the organization rules and software of the car racing competition in the form it was organized in conjunction with IEEE WCCI 2008 Four out of 002ve participating teams described the architecture and training of their controllers We have also reported the scoring procedure and results of the competition and plans for future competitions We hope that this paper in addition to serving as a record of the competition will provide organizers of similar competitions with inspiration and insights and that the descriptions of the controllers will be useful for researchers working on learning vehicle control in general and for participants in future car racing competitions in particular R EFERENCES  J T ogelius S M Lucas H Duc Thang J M Garibaldi T Nakashima C H Tan I Elhanany S Berant P Hingston R M MacCallum T Haferlach A Gowrisankar and P Burrow 223The 2007 ieee cec simulated car racing competition,\224 Genetic Programming and Evolvable Machines  2008 A v ailable http://dx.doi.org/10.1007/s10710-008-9063-0  223The open raci ng car simulator  224 Online A v ailable http://torcs.sourceforge.net  223Softw are manual of the car racing competition 224 WCCI-2008 A v ailable http://cig.dei.polimi.it/wpcontent/uploads/2008/04/manual  v03.pdf  R G Re ynolds and M Z Ali 223Computing with the social f abric The evolution of social intelligence within a cultural framework,\224 IEEE Computational Intelligence Magazine  vol 3 no 1 pp 18\22630 2008  R G Re ynolds M Z Ali and T  Jayyouzi 223Mining the social f abric of archaic urban centers with cultural algorithms,\224 Computer  vol 41 no 1 pp 64\22672 2008  K O Stanle y  223Ef 002cient e v olution of neural netw orks through complexi\002cation,\224 Ph.D dissertation Department of Computer Sciences University of Texas Austin TX 2004  M Simmerson 223Neat4j homepage 224 2006 Online A v ailable http://neat4j.sourceforge.net  S Baluja and R Caruana 223Remo ving the genetics from the standard genetic algorithm,\224 in Proceedings of the international conference on machine learning ICML  1995  R Sukthankar  S Baluja and J Hancock 223Proto yping intelligent vehicle modules,\224 in Proceedings of the International Conference on Robotics and Automation ICRA  1997  J T ogelius and S M Lucas 223Ev olving controllers for simulated car racing,\224 in Proceedings of the Congress on Evolutionary Computation  2005  227\227 223Ev olving rob ust and specialized car racing skill s 224 in Proceedings of the IEEE Congress on Evolutionary Computation  2006  J Bernard J Gruening and K Hof fmeister  223Ev aluat ion of v ehicle/driver performance using genetic algorithms,\224 Society of Automotive Engineers  1998  D Floreano T  Kato D Marocco and E Sauser  223Coe v olution of active vision and feature selection,\224 Biological Cybernetics  vol 90 pp 218\226228 2004  J T ogelius and S M Lucas 223 Arms races and car races 224 in Proceedings of Parallel Problem Solving from Nature  Springer 2006  223The car racing competition homepage 224 WCCI-2008 Online Available http://cig.dei.polimi.it/?page  id=5 


Table 3 Compressed sizes and number of extracted itemsets f or the itemset selection algorithms Candidate Itemsets S ET P ACK S ET P ACK G REEDY K RIMP Dataset min-sup  sets c  T  c  T  c  T b    sets c  T  c  T  c  T b    sets  bits  sets anneal 175 8837 20777 89.9 103 20781 89.9 69 31196 53 breast 1 9920 5175 63.7 42 5172 63.9 49 4613 30 courses 55 5030 64835 84.9 268 64937 85.1 262 73287 93 mammals 700 7169 65091 83.4 427 65622 84.1 382 124737 125 mushroom 1000 123277 313428 70.9 636 262942 59.5 1225 474240 140 nursery 50 25777 314081 93.0 276 314295 93.1 218 265064 225 pageblocks 1 63599 11961 78.3 92 11967 78.3 95 10911 53 tic–tac–toe 7 34019 23118 92.0 620 23616 94.0 277 28957 159 large candidate family for mushroom  For comparison we use the same candidates for K RIMP  We also compare to S ET P ACK G REEDY  which required 1–12 minutes 7 minutes typically with an exception of 2 1 2 hours for mushroom  Comparing the results of this experiment Table 3 with the results of G REEDY P ACK in the previous experiment we see that the selection process is more strict now even fewer itemsets are regarded as interesting enough Large candidate collections are strongly reduced in number up to three orders of magnitude On the other hand the compression ratios are still very good The reason that G REEDY P ACK produces smaller compression ratios is because it is allowe d to consider any itemset Further the fact alone that even with this very strict selection the compression ratios are generally well below 90 show that these few sets are indeed of high importance to describing the major interactions in the data If we compare the number of selected sets to K RIMP  we see that our method returns in the same order as many itemsets These descriptions require far less bits than tho se found by K RIMP  As such ours are a better approximation of the Kolmogorov complexity of the data Between S ET P ACK and S ET P ACK G REEDY the outcomes are very much alike this goes for both the obtained compression as well as the number of returned itemsets However the greedy search of S ET P ACK G REEDY allows for much shorter running times 8 Discussion The experimentation on our methods validates the quality of the returned models The models correctly detect dependencies in the data while ignoring independencies Only a small number of itemsets is returned which are shown to provide strong compression of the data By the MDL principle we then know these describes all important regularities in the data distribution in detail ef\002ciently and witho ut redundancy This claim is further supported by the high classi\002cation accuracies our models achieve The G REEDY P ACK algorithm generally uses more itemsets and obtains better packing ratios than S ET P ACK  While G REEDY P ACK is allowed to use any itemset S ET P ACK may only use frequent itemsets This suggests that we may able to achieve better ratios if we use different candidates  for example low-entropy sets 16  The running times of the experiments reported in this work range from seconds to hours and depend mainly on the number of attributes and rows of the datasets The exhaustive version S ET P ACK may be slow on very large candidate sets however the greedy version S ET P ACK G REEDY can even handle such families well Considering that our curren t implementation is rather na¨\021ve and the fact that both methods are easily parallelized both G REEDY P ACK and S ET P ACK G REEDY are suited for the analysis of large databases The main outcomes of our models are the itemsets that identify the encoding paths However the decision trees from which these sets are extracted can also be regarded as interesting as these provide an easily interpretable view o n the major interactions in the data Further just consideri ng the attributes used in such a tree as an itemset also allows for simple inspection of the main associations In this work we employ the MDL criterion to identify the optimal model Alternatively one could consider using either BIC or AIC both of which can easily be applied to judge between our decision tree-based models 9 Conclusions In this paper we presented two methods that 002nd compact sets of high quality itemsets Both methods employ compression to select the group of patterns that describe all interactions in the data best That is the data is considere d symmetric and thus both the 0s and 1s are taken into account in these descriptions Experimentation with our methods 
596 
596 


showed that high quality models are returned Their compact size typically tens to thousands of itemsets allow fo r easy further analysis of the found interactions References 1 C  C  A g g a r w a l a n d P  S  Y u  A n e w f r a m e w o r k f o r itemset generation In Proceedings of the ACM SIGACTSIGMOD-SIGART symposium on Principles of Database Systems PODS  pages 18–24 ACM Press 1998 2 R  A g r a w a l  H  M a n n i l a  R  S r i k a n t  H  T o i v o n e n  a n d A  I  Verkamo Fast discovery of association rules In Advances in Knowledge Discovery and Data Mining  pages 307–328 AAAI 1996 3 S  B r i n  R  M o t w a n i  a n d C  S i l v e r s t e i n  B e y o n d m a r k e t baskets Generalizing association rules to correlations In ACM SIGMOD International Conference on Management of Data  pages 265–276 ACM Press 1997 4 S  B r i n  R  M o t w a n i  J  D  U l l m a n  a n d S  T s u r  D y n a m i c itemset counting and implication rules for market basket data In ACM SIGMOD International Conference on Management of Data  pages 255–264 1997 5 B  B r i n g m a n n a n d A  Z i m m e r m a n n  T h e c h o s e n f e w  O n identifying valuable patterns In IEEE International Conference on Data Mining ICDM  pages 63–72 2007 6 T  C a l d e r s a n d B  G o e t h a l s  M i n i n g a l l n o n d e r i v a b l e f r e quent itemsets In Proceedings of the 6th European Conference on Machine Learning and Principles and Practice of Knowledge Discovery in Databases  pages 74–85 2002 7 V  C h a n d o l a a n d V  K u m a r  S u m m a r i z a t i o n c o m p r e s s i n g data into an informative representation In Proceedings of the IEEE Conference on Data Mining  pages 98–105 2005 8 F  C o e n e n  T h e L U C S K D D d i s c r e t i s e d  n o r m a l i s e d A R M and CARM data library 2003 9 G  F  C o o p e r a n d E  H e r s k o v i t s  A B a y e s i a n m e t h o d f o r the induction of probabilistic networks from data Machine Learning  9:309–347 1992 10 T  C o v e r a n d J  T h o m a s  Elements of Information Theory 2nd ed John Wiley and Sons 2006 11 W  D u M o u c h e l a n d D  P r e g i b o n  E m p i r i c a l b a y e s s c r e e n i n g for multi-item associations In ACM SIGKDD Conference on Knowledge Discovery and Data Mining  pages 67–76 2001 12 C  F a l o u t s o s a n d V  M e g a l o o i k o n o m o u  O n d a t a m i n i n g  compression and kolmogorov complexity In Data Mining and Knowledge Discovery  volume 15 pages 3–20 Springer 2007 13 P  D  G r  u n w a l d  The Minimum Description Length Principle  MIT Press 2007 14 J  H a n  H  C h e n g  D  X i n  a n d X  Y a n  F r e q u e n t p a t t e r n mining Current status and future directions In Data Mining and Knowledge Discovery  volume 15 Springer 2007 15 J  H a n a n d J  P e i  M i n i n g f r e q u e n t p a t t e r n s b y p a t t e r n growth methodology and implications SIGKDD Explorations Newsletter  2\(2\:14–20 2000 16 H  H e i k i n h e i m o  E  H i n k k a n e n  H  M a n n i l a  T  M i e l i k  a i nen and J K Sepp¨anen Finding low-entropy sets and trees from binary data In ACM SIGKDD Conference on Knowledge Discovery and Data Mining  pages 350–359 2007 17 S  J a r o s z e w i c z a n d T  S c h e f f e r  F a s t d i s c o v e r y o f u n e x p ected patterns in data relative to a bayesian network In ACM SIGKDD Conference on Knowledge Discovery and Data Mining  pages 118–127 2005 18 S  J a r o s z e w i c z a n d D  A  S i m o v i c i  I n t e r e s t i n g n e s s o f frequent itemsets using bayesian networks as background knowledge In ACM SIGKDD Conference on Knowledge Discovery and Data Mining  pages 178–186 2004 19 A  J  K n o b b e a n d E  K  Y  H o  M a x i m a l l y i n f o r m a t i v e k itemsets and their ef\002cient discovery In ACM SIGKDD Conference on Knowledge Discovery and Data Mining  pages 237–244 2006 20 A  J  K n o b b e a n d E  K  Y  H o  P a t t e r n t e a m s  I n Proceedings of the 10th European Conference on Machine Learning and Principles and Practice of Knowledge Discovery in Databases  pages 577–584 2006 21 P  K o n t k a n e n a n d P  M y l l y m  a k i  A l i n e a r t i m e a l g o r i t h m for computing the multinomial stochastic complexity Information Processing Letters  103\(6\:227–233 2007 22 M  v a n L e e u w e n  J  V r e e k e n  a n d A  S i e b e s  C o m p r e s s i o n picks the item sets that matter In Proceedings of the 10th European Conference on Machine Learning and Principles and Practice of Knowledge Discovery in Databases  pages 585–592 2006 23 M  L i a n d P  V i t  a n y i  An Introduction to Kolmogorov Complexity and its Applications  Springer-Verlag 1993 24 R  M e o  T h e o r y o f d e p e n d e n c e v a l u e s  ACM Trans Database Syst  25\(3\:380–406 2000 25 A  J  M i t c h e l l J o n e s  G  A m o r i  W  B o g d a n o w i c z  B Krystufek P J H Reijnders F Spitzenberger M Stubb e J B M Thissen V Vohralik and J Zima The Atlas of European Mammals  Academic Press 1999 26 K  V  S  M u r t h y  On growing better decision trees from data  PhD thesis Johns Hopkins Univ Baltimore 1996 27 S  N i j s s e n a n d  E Fromont Mining optimal decision trees from itemset lattices In ACM SIGKDD Conference on Knowledge Discovery and Data Mining  pages 530–539 2007 28 N  P a s q u i e r  Y  B a s t i d e  R  T a o u i l  a n d L  L a k h a l  D i s c o vering frequent closed itemsets for association rules Lecture Notes in Computer Science  1540:398–416 1999 29 J  R i s s a n e n  F i s h e r i n f o r m a t i o n a n d s t o c h a s t i c c o m p l e xity IEEE Transactions on Information Theory  42\(1\:40–47 1996 30 A  S i e b e s  J  V r e e k e n  a n d M  v a n L e e u w e n  I t e m s e t s t h a t compress In Proceedings of the SIAM Conference on Data Mining  pages 393–404 2006 31 N  T a t t i  M a x i m u m e n t r o p y b a s e d s i g n i 002 c a n c e o f i t e m s e t s Knowledge and Information Systems KAIS  2008 Accepted for publication 32 N  T a t t i a n d H  H e i k i n h e i m o  D e c o m p o s a b l e f a m i l i e s o f itemsets In Proceedings of the 12th European Conference on Machine Learning and Principles and Practice of Knowledge Discovery in Databases  2008 33 J  V r e e k e n  M  v a n L e e u w e n  a n d A  S i e b e s  C h a r a c t e r i s i ng the difference In ACM SIGKDD Conference on Knowledge Discovery and Data Mining  pages 765–774 2007 34 J  V r e e k e n  M  v a n L e e u w e n  a n d A  S i e b e s  P r e s e r v i n g privacy through data generation In Proceedings of the IEEE Conference on Data Mining  pages 685–690 2007 
597 
597 


