  6 


 


 


 


introduced to adjust the slope of the line controlling the dependence of the steering on the speed The original intention with hacked controller was to extract the main variables into a vector and then use an evolutionary strategy to evolve the values of those However in order to meet the competition deadline there was insuf\002cient time for this and instead the values of the variables were optimised by hand The 002rst approach was to observe the behaviour of the car as it was being driven by the hacked controller and then to make adjustments to the variables to correct problems that were observed Due to the non-linear interactions of the variables and the excessive time spent watching the car in visual mode this approach proved to be ineffective Best results were obtained by running the simulation in results only mode which allows evaluations to be done much faster than real-time and therefore many more settings of the variables can be tried The approach taken was a kind of direct policy optimisation where variables were initially set based on intuition or taken from the SimpleSoloController Trials were made with each one adjusted by around 10 or 20 of its current value The 002tness of each setting was noted and I looked for patterns in values of variables or combinations of variables that worked well In total around 50 trials were made The variables adjusted in this way together with their 002nal values in parentheses were steeringFac\(0.35 trackFac\(0.38 breakSpeedLimit\(105 trackPositionLimit 0.15 On three trials on E-Track 3 this hacked controller scored 7815 7776 and 7811 giving an average of 7801 a signi\002cant improvement over the original controller In summary hacked controller represents a somewhat hastily designed effort to use the available sensor data to improve on the supplied SimpleSoloController The supplied controller was extended in the ways described above and a kind of manually operated evolutionary process was used to tune the parameters This was found to me more effective than tuning the parameters by trying to directly observe their effects on speci\002c aspects of the driving behaviour It would be interesting to try evolving these values using an evolution strategy to see whether the manually chosen parameters can be signi\002cantly improved on they probably can C Matt Simmerson NEAT controller The idea behind this controller was to evolve a neural network that controlled a racing car around many tracks equally well based on a set of input data provided by the racing environment The added complication for my controller was to evolve the network topology given no domain knowledge a priori 1 De\002ning the controllers The controller was trained using the NEAT algorithm that e v olv ed populations of neural networks and was created using the NEAT4j software an implementation of the NEAT algorithm The NEAT4j implementation allows for the initial selection of a sub set of 3 inputs of the available 29 sources of input data The 3 outputs controlled the power in the range the gear change in the range and the steering in the range  The throttle and brak e actions were Boolean so the power output node was used to apply throttle for 277 0.6 or apply the brake for 241 0.4 For the middle values then the neither the throttle or brake would be applied and hence the controller would coast The gear change would attempt to change up if the output node was 277 0.5 and change down otherwise The gears selected were limited to R N 1 2 3 4 5 As all the output nodes used a sigmoid acti v ation function the actual values created as the controller actions were scaled from to the appropriate range The subset of inputs from the table de\002ned above available for this controller were 1 Current speed 2 Angle to track axis 3 The 19 track sensors 4 Track position with respect to left and right edges 5 Current gear selection 6 The 4 wheel spin sensors 7 Current RPM All the inputs were scaled to be in the range or 0,1 depending on the sign of the input This prevents large input values completely swamping other smaller input signals The initial controllers were very simple with 3 randomly selected input nodes connected to one of the output nodes such that all output nodes were connected to exactly one input node but an input node could be connected to more than one output node 2 Controller evolution The NEAT algorithm in essence uses a genetic algorithm to create a neural network topology from a given genome Each genome consists of a set of node genes that describe an individual neuron and connection genes which describe a nodes connections The population size was just 100 as this was a reasonable compromise between evolution and the time it took for each epoch The mutation and crossover operators were those de\002ned by the NEAT algorithm The parent selector function was a tournament round where the allowed parents were pitted against each other with the winner taking the spoils i.e the 002ttest Recurrency was allowed in this experiment 3 Training the controllers The car was trained on just one track G3 which was not one selected for the initial valuation This track was selected as it had some varying turns i.e left right curve and also straights of varying lengths into the various corners Ideally for the sake of generalisation I would have liked to train the cars over several tracks however the current version of the TORCS environment prevented this 4 Controller evaluation The car was tested on the track for a maximum of 4000 steps equivalent to around 80 seconds real time If the car sustained more than 100 points of damage out of a maximum of 10000 the evaluation for that car was aborted The overall 002tness of the car was calculated thus F c  2 003 Dr  do  speedmax  C 1 1 Dr was the distance raced value reported by TORCS engine and could be both positive and negative 


2 d was the value reported by the TORCS engine and has a maximum value of 10000 3 o is a measure of how much the car stayed on the track This was necessary to prevent the car using the barriers as a guide with no damage penalty Until this variable was added it prevented any really successful controllers The edge of the track was represented by 1 left and 1 right The outside value was calculated as 0 if the car was in these limits and Abs\(track position 1 for values outside these edges 4 Max speed was calculated throughout the cars trial based on the speeds reported by the TORCS engine This was to try and reward fast cars early on that crashed as the name of the game is speed 5 C was used to ensure the 002tness value was always positive and was set to 10000 Negative values were created when cars went the wrong way round the track or had high-speed crashes near the start resulting in large damage Whilst the 4000 time steps used for evaluation represented 80 seconds real time the TORCS engine allowed a non-GUI version which was evaluated in around 3-4 seconds With the population was set to 100 each evolutionary epoch lasted 400 seconds The entry for Neat4J was selected from the winning phenotype from the 170th generation i.e nearly 19 hours on my dual core laptop This had a good level of performance over a number of different track types e.g oval twisty etc D Diego Perez and Yago Saez Rule-based controller The idea of this controller is to evolve a set or rules that drives a vehicle using sensors as input data The usage of sensors to obtain autonomous driving has been addressed by numerous researchers 9 10 11 as well as the use of evolutionary algorithms in this 002eld 13 14 1 Input data effectors and rules The input data is discretized from the values of four sensors  angle  discretized to where 0 means the smaller angles trackPos  with a discretization performed in a range where 0 means centered on the track and 1 the car near the edges speedX  in a range where 0 means lo wer speed than higher v alues and track  where only three of these sensors have been used front and inmediate sensors on right and left and discretized to a unique range where 0 means that a track edge has been detected beyond 20 meters 1 when the track edge is up to 20 meters and 2 in case no track edge is detected A key part of the design is the usage of symmetry for the 002rst two sensors This concept works using the absolute value of the sensor to match to the proper discretized value The objective of this approach is to avoid duplication of efforts by reducing the search space The effectors of the controller have been designed as follows throttle and brake  where both pedals have been codi\002ed in a common output to avoid non-sense values as full gas in both pedals simultaneously Hence a unique value is applied and both gas pressures are extracted from it steer  codi\002ed as a real number from 1 to 1 and discretized with a precision of 0,1 gear  which changing process consists on increasing the current gear when the rpm value is higher than 6000 and decreasing it if it is below 3000 The discretization and codi\002cation applied over the input data and effectors allows us to create a set of 120 rules where conditional part is composed by the sensors and the actions are formed by acceleration braking and steering These rules compose the base individual 2 Application of an evolutionary rule system Traditional random initialization of individuals used in evolutionary techniques do not work properly in this 002eld because it is almost impossible to obtain a con\002guration that drives the vehicle correctly by chance This is the reason of getting a base individual before evolve it to obtain better results The algorithm used to get this base individual is a generation of a subset of rules that allows the vehicle to end a lap minimizing the angle of the car with the track axis Each one of this rules is created by testing how each allowed combination of acceleration and steering behaves when the condition of the rule is triggered Once we get the base rule set the evolving individual is extracted from it taking all its rules Therefore the individual is composed by a set of rules each one of them formed by condition and effectors that need to be evolved to obtain the controller To evolve this individual the algorithm executes evolutionary steps until a stopping criteria is reached The evaluation of the individual is performed recording lap time and damage suffered setting the 002tness using a linear combination of both values with weights of 0.4 and 0.6 respectively in order to avoid over\002tting to the training circuit In this system we can not decide when a rule is better than another because the behaviour of the individual depends on the whole set of rules used Because of this selection operator has been designed as a random pick-up from the rules pool taking two of them to apply uniform crossover Finally mutation operator is performed over the new rule applying an addition of 006 1 unit to the left part and 006 0  3 to the effectors of the rule obeying limits and codi\002cation precision The next step in this algorithm consists of searching for a rule from the individual where its conditional part is most similar to the new rule This rule is extracted from the pool and the new one substitutes it The new set of rules is then evaluated and its 002tness is compared with the one calculated before inserting that new rule Only if the new rule set is worse the substituted one is retrieved and the new rule is eliminated Results have proved this algorithm to be effective reducing lap times of the base individual in few generations keeping the car damage almost nonexistent The usage of symmetry however brought a side effect that was not expected the car drives in a smoothly zig-zag trajectory centered on the circuit This is because a small steering value can center the vehicle on the track but not necessarily drive it parallel to the track axis Nevertheless the controller 


TABLE III R ESULTS OF THE FIRST STAGE OF THE EVALUATION PROCESS  T HE REPORTED ARE THE MEDIAN OVER 10 RUNS    Entry  Ruudskogen  Street-1  Speedway     Kinnaird-Heether et al  6716.7  3692.9  14406.9    Lucas  4134.2  5502.8  12664.5    Simmerson  5934.0  6477.8  12523.3    Perez et al  3786.9  2984.8  317.3    Tan et al  3443.5  2998-5  10648.2     C Sample Controller  4465.1  4928.8  7464.5    Java Sample Controller  5593.8  2963.2  5689.9   behaved in a reasonable way only with the exception of some speci\002c circuits the oval ones These circuits similar to Nascar tracks have banked curves which make the zig-zag movement completely uncontrollable E Chin Hiong Tan and Kay Chen Tan The entry submitted by Chin Hiong Tan and Kay Chen Tan was developed in a three-step process First the sensory information was aggregated and preprocessed second a parametrized controller based on simple rules was designed 002nally the parameters of controller were optimized using evolution strategies The resulting controller drives in the direction where the range\002nder sensors indicate the largest free distance with a speed dependent on that distance IV R ESULTS The entries were scored through a two stages process which involved three tracks available in TORCS the Ruudskogen the Street-1 and the D-Speedway The 002rst warm up stage was aimed at eliminating particularly bad performing controllers Each controller raced alone in each of the three tracks and its performance was measured as the distance covered in 10000 game tics approximately 200 seconds of actual game time For each of the three selected tracks we run each controller ten times The performance has been computed as the median the 50th percentile over the ten runs to avoid any issue about skewness Table III compares the performance of the 002ve controllers submitted to the one of the two sample programmed controllers provided by the organizers The results show that the controller submitted by Leonard Kinnaird-Heether and Robert Reynolds outperforms the other controllers in all the tracks but the Street-1 track As can be noted the performances of the controllers are highly different among the three tracks but they generally compare well to the performances of the sample controllers provided by the organizers In particular the entries submitted respectively by Leonard Kinnaird-Heether et al by Simon Lucas and by Matt Simmerson the 002rst three controllers reported in Table III performs consistently better than the sample controllers almost in all the three tracks As all the 002ve submitted controllers performed well on the 002rst stage none of them was eliminated from the second stage in which the controllers competed together in each of the three tracks In this stage the task consisted of completing three laps and each controller was scored based on its arrival order TABLE IV R ESULTS OF THE SECOND STAGE OF THE EVALUATION PROCESS  T HE SCORES REPORTED ARE THE MEDIAN OVER 10 RUNS    Entry  Ruudskogen  Street-1  Speedway  Total     Simmerson  10  10  6  26    Kinnaird-Heether et al  4  8  10  22    Lucas  6  6  8  20    Tan et al  5  5  5  15    Perez et al  5.5  4.5  5  14   using the same point system used in F1 10 points to the 002rst controller that completed the three laps 8 points to the second one 6 to the third one 5 to the fourth and 4 to the 002fth one Ten runs for each track were performed using as start grid a random permutation of the competitors in order to test the reliability of the controllers performance Then the score of a controller on one track was computed as the median of the scores obtained during the ten runs The 002nal score for each controller was 002nally computed as the sum of the points collected on each track Table IV shows the 002nal scoreboard Matt Simmerson won the competition with 26 points followed by Leonard Kinnaird-Heether et al with 22 points by Simon Lucas with 20 points by Tan Chin Hiong with 15 points and 002nally by Diego P 264 erez 14 points This results suggest that although the controllers submitted by Kinnaird-Heether and Reynolds is fast the one submitted by Simmerson is more reliable especially in the presence of other controllers Finally it is worthwhile to underline that the second stage of the evaluation process suggested that all the submitted controllers have poor overtaking and obstacle-avoidance capabilities whereas these features are very important to succeed in a racing competition Additional results and a video with the highlights of the competition are available on the webpage of the competition The reason Simmerson's controller won over KinnairdHeether and Reynold's was probably that the latter had been optimized for racing on tracks with smooth curves in the presence of other cars Simmerson's controller had been trained on the 223G3\224 track that included sharp turns like Ruudskogen but on its own Both of these controllers were optimized with stochastic algorithms and it stands to reason that such approaches outperform the hand-tuning used by Lucas V T HE FUTURE OF THE CAR RACING COMPETITION While this competition differed greatly from the competitions organized during 2007 in that a more sophisticated racing game was used there was also a great deal of continuity Not only in that some of the participants of the 2007 competitions also participated in the current competition but also in the similarity of rules and arrangements The organizers believe that this continuity is very important for the competition to be successful We need a high participation level to ensure that a broad spectrum of approaches are represented and regular repetitions of the competition to ensure that the participants have time 


to perfect their approaches Our aim is to ensure further continuity through holding a series of future competitions using gradual re\002nements of the rules and software used in the current competition The following improvement will be made to the software in time for the CIG competition 017 The installation process will be streamlined 017 Reliability will be improved 017 Support for multi-car and multi-track training will be added making it easier to apply co-evolution and incremental evolution 017 More sample controllers and trainers e.g temporal difference learning trainers will be supplied An amusing illustration of the need to improve reliability is that in an early version of the software it was possible to achieve the 002tness value of driving a whole lap simply by slowly driving up to and passing the start line the car starts 100 meters before that line then turning and passing the line again This 003aw is inherent in TORCS presumably because its developers never thought of anyone doing something so bizarre Evolutionary algorithms however are good at coming up with bizarre solutions and Matt Simmerson's algorithm quickly evolved a controller that exploited this bug A patch for this bug is now part of the software package A reviewer of the paper summarizing the previous car racing competitions pointed out that in its current form the competition is not only about learning algorithms It is certainly possible to hand-code a non-learning controller that outperforms the best CI-based controllers Indeed the best controllers that come with the TORCS game developed by the TORCS developers are non-learning and by far outperform all the controllers submitted to this competition so far though they often access information state information that is not directly available through the competition API Of course we hope that future editions of this competition will see CI-based contributions that perform better than the best hand-coded ones and there are no reasons why this should not happen Still it would be interesting to run a version of the competition that compared only the quality of the learning algorithm One way could be to de\002ne a standard e.g neural network-based controller architecture and then provide an interface for a learning algorithm to set the parameters for this controller optimally given a certain numbers of laps around an unknown track The participants would then submit an algorithm rather than a controller to be run and evaluated by the organizers of the competition Another interesting version of the competition would be one where the controllers where presented with a richer but more primitive state description in particular visual data This could come in the form of the full rendered 3D view through the controlled car's windscreen or a part of it Such a state description would ultimately give the controllers more information and thus allow for better driving but would also require more complex controllers Given the various interesting variations on the car racing concept that are possible our plan is to organize editions of the car racing competition in conjunction with several international conferences and at each conference hold both the competition in its original form and some variation on the concept like the ones suggested above VI C ONCLUSION We have described the organization rules and software of the car racing competition in the form it was organized in conjunction with IEEE WCCI 2008 Four out of 002ve participating teams described the architecture and training of their controllers We have also reported the scoring procedure and results of the competition and plans for future competitions We hope that this paper in addition to serving as a record of the competition will provide organizers of similar competitions with inspiration and insights and that the descriptions of the controllers will be useful for researchers working on learning vehicle control in general and for participants in future car racing competitions in particular R EFERENCES  J T ogelius S M Lucas H Duc Thang J M Garibaldi T Nakashima C H Tan I Elhanany S Berant P Hingston R M MacCallum T Haferlach A Gowrisankar and P Burrow 223The 2007 ieee cec simulated car racing competition,\224 Genetic Programming and Evolvable Machines  2008 A v ailable http://dx.doi.org/10.1007/s10710-008-9063-0  223The open raci ng car simulator  224 Online A v ailable http://torcs.sourceforge.net  223Softw are manual of the car racing competition 224 WCCI-2008 A v ailable http://cig.dei.polimi.it/wpcontent/uploads/2008/04/manual  v03.pdf  R G Re ynolds and M Z Ali 223Computing with the social f abric The evolution of social intelligence within a cultural framework,\224 IEEE Computational Intelligence Magazine  vol 3 no 1 pp 18\22630 2008  R G Re ynolds M Z Ali and T  Jayyouzi 223Mining the social f abric of archaic urban centers with cultural algorithms,\224 Computer  vol 41 no 1 pp 64\22672 2008  K O Stanle y  223Ef 002cient e v olution of neural netw orks through complexi\002cation,\224 Ph.D dissertation Department of Computer Sciences University of Texas Austin TX 2004  M Simmerson 223Neat4j homepage 224 2006 Online A v ailable http://neat4j.sourceforge.net  S Baluja and R Caruana 223Remo ving the genetics from the standard genetic algorithm,\224 in Proceedings of the international conference on machine learning ICML  1995  R Sukthankar  S Baluja and J Hancock 223Proto yping intelligent vehicle modules,\224 in Proceedings of the International Conference on Robotics and Automation ICRA  1997  J T ogelius and S M Lucas 223Ev olving controllers for simulated car racing,\224 in Proceedings of the Congress on Evolutionary Computation  2005  227\227 223Ev olving rob ust and specialized car racing skill s 224 in Proceedings of the IEEE Congress on Evolutionary Computation  2006  J Bernard J Gruening and K Hof fmeister  223Ev aluat ion of v ehicle/driver performance using genetic algorithms,\224 Society of Automotive Engineers  1998  D Floreano T  Kato D Marocco and E Sauser  223Coe v olution of active vision and feature selection,\224 Biological Cybernetics  vol 90 pp 218\226228 2004  J T ogelius and S M Lucas 223 Arms races and car races 224 in Proceedings of Parallel Problem Solving from Nature  Springer 2006  223The car racing competition homepage 224 WCCI-2008 Online Available http://cig.dei.polimi.it/?page  id=5 


Table 3 Compressed sizes and number of extracted itemsets f or the itemset selection algorithms Candidate Itemsets S ET P ACK S ET P ACK G REEDY K RIMP Dataset min-sup  sets c  T  c  T  c  T b    sets c  T  c  T  c  T b    sets  bits  sets anneal 175 8837 20777 89.9 103 20781 89.9 69 31196 53 breast 1 9920 5175 63.7 42 5172 63.9 49 4613 30 courses 55 5030 64835 84.9 268 64937 85.1 262 73287 93 mammals 700 7169 65091 83.4 427 65622 84.1 382 124737 125 mushroom 1000 123277 313428 70.9 636 262942 59.5 1225 474240 140 nursery 50 25777 314081 93.0 276 314295 93.1 218 265064 225 pageblocks 1 63599 11961 78.3 92 11967 78.3 95 10911 53 tic–tac–toe 7 34019 23118 92.0 620 23616 94.0 277 28957 159 large candidate family for mushroom  For comparison we use the same candidates for K RIMP  We also compare to S ET P ACK G REEDY  which required 1–12 minutes 7 minutes typically with an exception of 2 1 2 hours for mushroom  Comparing the results of this experiment Table 3 with the results of G REEDY P ACK in the previous experiment we see that the selection process is more strict now even fewer itemsets are regarded as interesting enough Large candidate collections are strongly reduced in number up to three orders of magnitude On the other hand the compression ratios are still very good The reason that G REEDY P ACK produces smaller compression ratios is because it is allowe d to consider any itemset Further the fact alone that even with this very strict selection the compression ratios are generally well below 90 show that these few sets are indeed of high importance to describing the major interactions in the data If we compare the number of selected sets to K RIMP  we see that our method returns in the same order as many itemsets These descriptions require far less bits than tho se found by K RIMP  As such ours are a better approximation of the Kolmogorov complexity of the data Between S ET P ACK and S ET P ACK G REEDY the outcomes are very much alike this goes for both the obtained compression as well as the number of returned itemsets However the greedy search of S ET P ACK G REEDY allows for much shorter running times 8 Discussion The experimentation on our methods validates the quality of the returned models The models correctly detect dependencies in the data while ignoring independencies Only a small number of itemsets is returned which are shown to provide strong compression of the data By the MDL principle we then know these describes all important regularities in the data distribution in detail ef\002ciently and witho ut redundancy This claim is further supported by the high classi\002cation accuracies our models achieve The G REEDY P ACK algorithm generally uses more itemsets and obtains better packing ratios than S ET P ACK  While G REEDY P ACK is allowed to use any itemset S ET P ACK may only use frequent itemsets This suggests that we may able to achieve better ratios if we use different candidates  for example low-entropy sets 16  The running times of the experiments reported in this work range from seconds to hours and depend mainly on the number of attributes and rows of the datasets The exhaustive version S ET P ACK may be slow on very large candidate sets however the greedy version S ET P ACK G REEDY can even handle such families well Considering that our curren t implementation is rather na¨\021ve and the fact that both methods are easily parallelized both G REEDY P ACK and S ET P ACK G REEDY are suited for the analysis of large databases The main outcomes of our models are the itemsets that identify the encoding paths However the decision trees from which these sets are extracted can also be regarded as interesting as these provide an easily interpretable view o n the major interactions in the data Further just consideri ng the attributes used in such a tree as an itemset also allows for simple inspection of the main associations In this work we employ the MDL criterion to identify the optimal model Alternatively one could consider using either BIC or AIC both of which can easily be applied to judge between our decision tree-based models 9 Conclusions In this paper we presented two methods that 002nd compact sets of high quality itemsets Both methods employ compression to select the group of patterns that describe all interactions in the data best That is the data is considere d symmetric and thus both the 0s and 1s are taken into account in these descriptions Experimentation with our methods 
596 
596 


showed that high quality models are returned Their compact size typically tens to thousands of itemsets allow fo r easy further analysis of the found interactions References 1 C  C  A g g a r w a l a n d P  S  Y u  A n e w f r a m e w o r k f o r itemset generation In Proceedings of the ACM SIGACTSIGMOD-SIGART symposium on Principles of Database Systems PODS  pages 18–24 ACM Press 1998 2 R  A g r a w a l  H  M a n n i l a  R  S r i k a n t  H  T o i v o n e n  a n d A  I  Verkamo Fast discovery of association rules In Advances in Knowledge Discovery and Data Mining  pages 307–328 AAAI 1996 3 S  B r i n  R  M o t w a n i  a n d C  S i l v e r s t e i n  B e y o n d m a r k e t baskets Generalizing association rules to correlations In ACM SIGMOD International Conference on Management of Data  pages 265–276 ACM Press 1997 4 S  B r i n  R  M o t w a n i  J  D  U l l m a n  a n d S  T s u r  D y n a m i c itemset counting and implication rules for market basket data In ACM SIGMOD International Conference on Management of Data  pages 255–264 1997 5 B  B r i n g m a n n a n d A  Z i m m e r m a n n  T h e c h o s e n f e w  O n identifying valuable patterns In IEEE International Conference on Data Mining ICDM  pages 63–72 2007 6 T  C a l d e r s a n d B  G o e t h a l s  M i n i n g a l l n o n d e r i v a b l e f r e quent itemsets In Proceedings of the 6th European Conference on Machine Learning and Principles and Practice of Knowledge Discovery in Databases  pages 74–85 2002 7 V  C h a n d o l a a n d V  K u m a r  S u m m a r i z a t i o n c o m p r e s s i n g data into an informative representation In Proceedings of the IEEE Conference on Data Mining  pages 98–105 2005 8 F  C o e n e n  T h e L U C S K D D d i s c r e t i s e d  n o r m a l i s e d A R M and CARM data library 2003 9 G  F  C o o p e r a n d E  H e r s k o v i t s  A B a y e s i a n m e t h o d f o r the induction of probabilistic networks from data Machine Learning  9:309–347 1992 10 T  C o v e r a n d J  T h o m a s  Elements of Information Theory 2nd ed John Wiley and Sons 2006 11 W  D u M o u c h e l a n d D  P r e g i b o n  E m p i r i c a l b a y e s s c r e e n i n g for multi-item associations In ACM SIGKDD Conference on Knowledge Discovery and Data Mining  pages 67–76 2001 12 C  F a l o u t s o s a n d V  M e g a l o o i k o n o m o u  O n d a t a m i n i n g  compression and kolmogorov complexity In Data Mining and Knowledge Discovery  volume 15 pages 3–20 Springer 2007 13 P  D  G r  u n w a l d  The Minimum Description Length Principle  MIT Press 2007 14 J  H a n  H  C h e n g  D  X i n  a n d X  Y a n  F r e q u e n t p a t t e r n mining Current status and future directions In Data Mining and Knowledge Discovery  volume 15 Springer 2007 15 J  H a n a n d J  P e i  M i n i n g f r e q u e n t p a t t e r n s b y p a t t e r n growth methodology and implications SIGKDD Explorations Newsletter  2\(2\:14–20 2000 16 H  H e i k i n h e i m o  E  H i n k k a n e n  H  M a n n i l a  T  M i e l i k  a i nen and J K Sepp¨anen Finding low-entropy sets and trees from binary data In ACM SIGKDD Conference on Knowledge Discovery and Data Mining  pages 350–359 2007 17 S  J a r o s z e w i c z a n d T  S c h e f f e r  F a s t d i s c o v e r y o f u n e x p ected patterns in data relative to a bayesian network In ACM SIGKDD Conference on Knowledge Discovery and Data Mining  pages 118–127 2005 18 S  J a r o s z e w i c z a n d D  A  S i m o v i c i  I n t e r e s t i n g n e s s o f frequent itemsets using bayesian networks as background knowledge In ACM SIGKDD Conference on Knowledge Discovery and Data Mining  pages 178–186 2004 19 A  J  K n o b b e a n d E  K  Y  H o  M a x i m a l l y i n f o r m a t i v e k itemsets and their ef\002cient discovery In ACM SIGKDD Conference on Knowledge Discovery and Data Mining  pages 237–244 2006 20 A  J  K n o b b e a n d E  K  Y  H o  P a t t e r n t e a m s  I n Proceedings of the 10th European Conference on Machine Learning and Principles and Practice of Knowledge Discovery in Databases  pages 577–584 2006 21 P  K o n t k a n e n a n d P  M y l l y m  a k i  A l i n e a r t i m e a l g o r i t h m for computing the multinomial stochastic complexity Information Processing Letters  103\(6\:227–233 2007 22 M  v a n L e e u w e n  J  V r e e k e n  a n d A  S i e b e s  C o m p r e s s i o n picks the item sets that matter In Proceedings of the 10th European Conference on Machine Learning and Principles and Practice of Knowledge Discovery in Databases  pages 585–592 2006 23 M  L i a n d P  V i t  a n y i  An Introduction to Kolmogorov Complexity and its Applications  Springer-Verlag 1993 24 R  M e o  T h e o r y o f d e p e n d e n c e v a l u e s  ACM Trans Database Syst  25\(3\:380–406 2000 25 A  J  M i t c h e l l J o n e s  G  A m o r i  W  B o g d a n o w i c z  B Krystufek P J H Reijnders F Spitzenberger M Stubb e J B M Thissen V Vohralik and J Zima The Atlas of European Mammals  Academic Press 1999 26 K  V  S  M u r t h y  On growing better decision trees from data  PhD thesis Johns Hopkins Univ Baltimore 1996 27 S  N i j s s e n a n d  E Fromont Mining optimal decision trees from itemset lattices In ACM SIGKDD Conference on Knowledge Discovery and Data Mining  pages 530–539 2007 28 N  P a s q u i e r  Y  B a s t i d e  R  T a o u i l  a n d L  L a k h a l  D i s c o vering frequent closed itemsets for association rules Lecture Notes in Computer Science  1540:398–416 1999 29 J  R i s s a n e n  F i s h e r i n f o r m a t i o n a n d s t o c h a s t i c c o m p l e xity IEEE Transactions on Information Theory  42\(1\:40–47 1996 30 A  S i e b e s  J  V r e e k e n  a n d M  v a n L e e u w e n  I t e m s e t s t h a t compress In Proceedings of the SIAM Conference on Data Mining  pages 393–404 2006 31 N  T a t t i  M a x i m u m e n t r o p y b a s e d s i g n i 002 c a n c e o f i t e m s e t s Knowledge and Information Systems KAIS  2008 Accepted for publication 32 N  T a t t i a n d H  H e i k i n h e i m o  D e c o m p o s a b l e f a m i l i e s o f itemsets In Proceedings of the 12th European Conference on Machine Learning and Principles and Practice of Knowledge Discovery in Databases  2008 33 J  V r e e k e n  M  v a n L e e u w e n  a n d A  S i e b e s  C h a r a c t e r i s i ng the difference In ACM SIGKDD Conference on Knowledge Discovery and Data Mining  pages 765–774 2007 34 J  V r e e k e n  M  v a n L e e u w e n  a n d A  S i e b e s  P r e s e r v i n g privacy through data generation In Proceedings of the IEEE Conference on Data Mining  pages 685–690 2007 
597 
597 


